{
  "name" : "2021.acl-long.507.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "CCMatrix: Mining Billions of High-Quality Parallel Sentences on the Web",
    "authors" : [ "Holger Schwenk", "Sergey Edunov", "Edouard Grave", "Angela Fan" ],
    "emails" : [ "schwenk@fb.com", "guw@fb.com", "edunov@fb.com", "egrave@fb.com", "ajoulin@fb.com", "angelafan@fb.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6490–6500\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n6490"
    }, {
      "heading" : "1 Introduction",
      "text" : "Parallel data, i.e. sentences in two languages which are mutual translations, are a crucial resource for many multilingual natural language processing tasks. Traditionally, high quality parallel texts are obtained from the publications of international organizations like the the United Nations (Ziemski et al., 2016) or the European Parliament (Koehn, 2005). These are professional human translations, but they are in a more formal language and tend to be limited to political topics. Another direction\nis to rely on volunteers to provide translations for public texts, such as the TED corpus (Qi et al., 2018), news commentary (Tiedemann, 2012) or OpenSubtitles (Lison and Tiedemann, 2016), but this approach lacks scalability.\nThere is also a large body of works which aims in mining bitexts by comparing huge collections of monolingual data. Our aim is to mine at massive scale, both in number of possible languages and in quantity of mined parallel sentences. Most existing large scale bitext mining techniques use a hierarchical approach. First, a subset of texts that may contain parallel sentences are selected at the document level. Subsequently, sentences within these aligned documents are compared to identify parallel ones. This local mining is potentially fast since only a few thousand sentences need to be compared for each document pair. However, sentences not present in these pre-selected documents cannot be aligned, which vastly limits the quantity of mineable bitext. A first system to globally compare all sentences in monolingual collections for many language pairs was presented in Schwenk et al. (2019), but was limited to only Wikipedia.\nIn this paper, we show that this type of global mining scales to extremely huge corpora: 71 billion sentences, about 120x larger than the work of Schwenk et al. (2019). Our contributions are:\n• development of a new highly efficient and parallelized processing pipeline to confront the substantial computational challenge;\n• unprecedented size: 10.8 billion mined parallel sentences in 90 different languages;\n• all these resources are freely available;\n• we demonstrate the quality of our mined data on a variety of machine translation benchmarks, such as TED, WMT, and WAT, achieving highly competitive results."
    }, {
      "heading" : "2 Related work",
      "text" : "Much previous work has explored the automatic creation of parallel data from monolingual resources. In this section, we detail various approaches and illustrate the differences of our algorithmic approach and the scale of our mining.\nMining Methodology At the start, various approaches used alignment on information beyond text itself, such as with document metadata (Resnik, 1999; Resnik and Smith, 2003). Later, work aligned based on text with techniques such as Jaccard similarity (Etchegoyhen and Azpeitia, 2016; Azpeitia et al., 2017, 2018), crosslingual document retrieval (Utiyama and Isahara, 2003; Munteanu and Marcu, 2005), language models (Buck and Koehn, 2016), translation (AbdulRauf and Schwenk, 2009; Bouamor and Sajjad, 2018), or bag-of-words (Buck and Koehn, 2016). In contrast, we use massively multilingual sentence embeddings trained on almost 100 languages, and then conduct margin-based mining in the multilingual embedding space (Schwenk, 2018; Artetxe and Schwenk, 2018a,b; Kvapilı́ková et al., 2020). Previous work such as España-Bonet et al. (2017); Hassan et al. (2018); Guo et al. (2018); Yang et al. (2019) used bilingual embeddings, which is not scalable for mining many different languages.\nCompared to work such as Schwenk (2018), we drastically increase the scale of our mining and produce two orders of magnitude more data — this is possible by the increased efficiency and scalability of our improved mining methods. A few mining approaches were applied to large quantities of language pairs. For example, the ParaCrawl project1 mined data for all European languages. Bitextor (Esplà-Gomis and Forcada, 2010) was applied to many languages, but took an approach that required identifying parallel documents first and then extracting aligned sentences. This is similar to the ccAligned project (El-Kishky et al., 2020). In contrast to these, we mine much larger quantities of parallel data due to the global margin-based mining approach that we take.\nData used to Mine Many previous methods for data mining focused on Wikipedia. Otero and López (2010) and Patry and Langlais (2011), for instance, aligned entire parallel documents. For example, Adafre and de Rijke (2006) and Mohammadi and GhasemAghaee (2010) used machine translation systems to compare Dutch and Per-\nsian Wikipedias to English, to identify aligned sentences. Various other worked used similarities in mentioned entities to align text, such as Gottschalk and Demidova (2017) and Tsai and Roth (2016). Work such as Smith et al. (2010); Tufis et al. (2013); Aghaebrahimian (2018) used Wikipedia to mine parallel sentences, but focused on fewer languages, often high resource. In contrast, our system mines not in Wikipedia but in CommonCrawl, a much larger source of data — and is applied to a much larger quantity of languages.\nWork has extended mining beyond Wikipedia. For example, ParaCrawl1 has been heavily used (e.g. in WMT), which is based on several noisy multilingual crawls (Koehn et al., 2018, 2019). ElKishky et al. (2019) focused on mining documents in Common Crawl rather than sentences. Our work continues this line of scalable mining on the web, but pushes to large-scale mining to produce billions of aligned sentences."
    }, {
      "heading" : "3 Distance-based mining approach",
      "text" : "We leverage massively multilingual sentence embeddings and a margin-based criterion to mine parallel sentences. The core idea is to learn a multilingual sentence embedding, or an embedding space in which semantically similar sentences are close, independent of the language they are written in. This means that distance in the embedding space can be used to determine if two sentences are mutual translations or not. We use the open source LASER (Artetxe and Schwenk, 2018b) embeddings as they cover over 90 different languages.2 Another recent multilingual sentence embedding is LaBSE (Feng et al., 2020)."
    }, {
      "heading" : "3.1 Margin criterion",
      "text" : "Given two sentence embeddings, how can we decide if they are mutual translations? Using an absolute threshold on the cosine distance was shown to achieve competitive results (Schwenk, 2018), but is globally inconsistent (Guo et al., 2018). Therefore, we use margin-based mining (Artetxe and Schwenk, 2018a). The margin M(x, y) between two sentence embeddings x and y is defined as the ratio between the cosine distance between x and y, and the average cosine similarity of its nearest\n1http://www.paracrawl.eu/ 2https://github.com/facebookresearch/\nLASER\nneighbors in both directions:\nM(x, y) = cos(x, y)∑\nz∈NNk(x)\ncos(x, z)\n2k + ∑ z∈NNk(y) cos(y, z) 2k\nwhere NNk(x) denotes the k unique nearest neighbors of x in the other language, and analogously for NNk(y). We set k to 16.\nArtetxe and Schwenk (2018a) describe the maxstrategy as one of the best performing ones: the margin is calculated in both directions for all sentences in languages L1 and L2. Then, the union of forward and backward candidates is built, candidates are sorted, and pairs with source or target sentences which were already used are omitted. Finally, a threshold is applied to the margin score to decide if two sentences are mutual translations. This strategy was motivated by evaluation on the BUCC corpus (Zweigenbaum et al., 2018), where the reference alignments are known to be strictly 1:1. Our aim is to mine at the billion-scale, and at this size, the probability of finding multiple perfect translations increases. Therefore, we take the union of the best forward and backward alignments, excluding duplicate bitexts."
    }, {
      "heading" : "3.2 Scaling to billions of sentences",
      "text" : "In this work, we mine billions of parallel sentences from the Web by using the data released in Common Crawl.3 We preprocess the raw text following the pipeline used to create the CCNet dataset (Wenzek et al., 2019). We use 32 crawls spanning the period from December 2017 to February 2020.\nOur CCNet corpus is about 120 times larger than Wikipedia: 71 billion compared to 595 million unique sentences (Schwenk et al., 2019). The largest corpora are English (14.3 billion), then German, French, and Spanish (more than 5.2 billion\n3https://commoncrawl.org/\nsentences). For 17 different languages, CCNet contains over one billion unique sentences (see Table 1). This requires a carefully designed mining approach in order to tackle the substantially computational complexity and successfully scale. We developed a multi-step mining procedure that is structured into three distinct tasks:\n1. text extraction and processing including sentence splitting and language identification;\n2. creation of a FAISS index for each language;\n3. mining parallel data for each language pair using the sentence embeddings and indices.\nEach step is parallelized as much as possible by splitting the data into several blocks.\nText extraction. The first task, text extraction and processing, consists of three steps: 1) extract text from the JSON data of CCNet and split the paragraphs into sentences; 2) mark duplicate sentences; and 3) perform language identification (LID) and exclude sentences not in the expected language. Each of these three steps processes blocks in parallel. At the final step, we merge all the block-wise deduplicated sentences and create one set of globally unique sentences for each language. We used a Python library4 to detect sentence boundaries. If specific rules for a language are not available, we fall-back to a linguistically similar languages, e.g. using Spanish rules for Gallican, and default to English otherwise. Most of the Asian languages are handled by regular expressions. We exclude sentences with more than 500 characters. A major challenge of web data is noise. This particularly manifests in text that has the wrong language label. As noise in this stage will affect our mining process, we perform strict filtering using two LID systems on each sentence, fastText (Grave et al.,\n4https://pypi.org/project/ sentence-splitter/\n2018) and LangID (Lui and Baldwin, 2011), and discard the data if the two disagree or have low confidence. This processing yields a corpus of Ni unique sentences for each language Li. These texts are the basis for index creation and mining (see column size in Table 1).\nIndex creation. We follow Schwenk et al. (2019) and use the highly optimized FAISS library (Johnson et al., 2017)5 to create compact indices of the sentence embedding. LASER’s sentence representations are 1024-dimensional, which means that the embeddings of all sentences would require 71 · 109 × 1024× 4 ≈ 290 TB to store. To practically handle this scale, we use an aggressive vector compression based on a 64-bit product-quantizer (Jégou et al., 2011), and 64k cells to partition the search space. This corresponds to the index type OPQ64,IVF65536,PQ64 in FAISS.\nExhaustive search in huge indices is tractable only if performed on GPU. FAISS supports sharding of a single index on multiple GPUs - this is most efficient if the GPUs are in the same machine and communicate very quickly. Our index type, using eight GPUs with 32GB of memory each, allows us to handle an index size of 3.2 billion sentences. Seven languages exceed this threshold, so we proceed to create multiple indices (English, German, French, Spanish, Russian, Chinese, and Japanese).\nThe processing pipeline to train and create the indices is summarized in Figure 1. We train an index on 40 million sampled sentences of the whole corpus. Once the index is trained, the data in each block is independently added to this common index, which can be performed in parallel. The individual indices are subsequently merged into one index per language. The largest indices have a size of around 210GB, making 90 indices total almost 4TB.\n5https://github.com/facebookresearch/ faiss/wiki/Faiss-indexes\nMining. After indices for all languages are created, we begin the mining process for each language pair. To illustrate the process, we describe it concretely with the example of two high resource languages, Italian and Portuguese, which have 2.5 billion sentences each. This requires 2.5 109×2.5 109 = 6.25 1018 distance calculations. Performing this on a single node with 8 GPUs would require more than 6 months. Instead, we tackle this computational challenge by decoupling the distance calculations of the forward and backward direction and the margin calculation, and processing these in parallel. This processing pipeline is illustrated in Figure 2.\nFor all language pairs, we compute both forward and backward distances, even for languages with multiple indices, such as English, French and German. All available alignments for one pair are merged, excluding duplicate sentence pairs.\nIn the current CCMatrix corpus, we have mined data for a diverse set of 90 languages, covering a variety of different language families and scripts (full list in the Appendix). As the mining process is computationally intensive, we focus on many commonly spoken languages to support existing translation systems, as well as mine several mid to low resource languages to provide parallel data for directions with limited to no public training data. We organized all languages into twelve groups which mostly correspond to well established linguistic language families, but we have also performed some geographic groupings, in particular for small language families or isolated languages. In addition, we have identified major languages in each group and use them as “bridge languages”. We mine for all bitexts among these 27 bridge languages. The motivation for this bridge language approach is to connect the languages of the various groups, but sill avoid mining the full matrix. Additional details are given in the Appendix."
    }, {
      "heading" : "3.3 Choosing the margin threshold",
      "text" : "The margin threshold used to mine parallel sentences impacts the quality of mined bitexts. A higher threshold leads to better aligned sentences, and thus higher quality bitexts, but also to smaller datasets. Thus, there is a trade-off between size and quality. Exploratory experiments based on training different NMT models showed that a threshold around 1.06 gave good results. We display a representative example on Hungarian-Danish in Fig. 3."
    }, {
      "heading" : "4 Quantity of Mined Data",
      "text" : ""
    }, {
      "heading" : "4.1 Total Quantity",
      "text" : "We mine a total of 10.8 billion parallel sentences out of which only 2913 million are aligned with English, considering a margin threshold of 1.06 for all language pairs. Table 1 gives a summary for the 54 largest languages. The full list of supported languages is given in the Appendix. In contrast to other works, such as the European ParaCrawl project,1 we do not limit to alignments with English, but provide alignments for 1197 language pairs.\nThis yielded unprecedented amounts of bitexts of non-English language pairs, for example 286M for Spanish-French, 24M for Arabic-French and Spanish-Chinese, and a total of 326M bitexts with Norwegian (which is not present in Europarl). Further, a variety of different Asian languages were mined, producing 7.2M pairs for Japanese-Korean, 7.8M for Indonesian-Malay, and 1.3M for BengaliHindi. To the best of our knowledge, this makes CCMatrix the largest collection of high-quality mined parallel texts, with coverage over a wide variety of languages. Providing multiple aligned bitexts for many languages also opens the possibility of improved training of massively multilingual\nNMT systems (Fan et al., 2020), as this substantially increases the amount of bitexts for low resource languages. As an example, Nepali has less than 1M bitexts with English, but 17M bitexts with multiple languages (see last column of Table 1)."
    }, {
      "heading" : "4.2 Analysis of mined bitexts",
      "text" : "Table 1 gives the amount of mined bitexts for various language pairs. The general tendency is of course that mining in large monolingual corpora leads to larger extracted bitexts. This is however not systematically true. Let us consider for example Danish, a Germanic language. When aligned with Norwegian, also a Germanic language, we obtain 17.7M bitexts. The pair Danish-Italian, however, has only 14.7M bitexts although Italian has almost six times more sentences than Norwegian. One one hand, a possible explanation could be that LASER alignments are more reliable for languages which are very similar, i.e. in the same language family. On the other hand, it may also be that people which live in nearby countries have similar interests which increases the chance to find translations on the Web. Additional analysis and examples are provided in the Appendix."
    }, {
      "heading" : "5 Evaluation on Translation Benchmarks",
      "text" : "To assess our mined bitext, we train NMT systems only on our mined data and evaluate on several public benchmarks. We do not use any of the training data provided with these corpora, so do not use any available human translated data, and have no guarantee our bitext covers the same domain as the test sets. Nevertheless, we show on the many to many TED corpus that our mined data produces high quality translation systems, even through distant language pairs not aligned through English and low resource languages. Finally, we demonstrate that models trained on CCMatrix can surpass state of the art systems in WMT’19 and WAT’20."
    }, {
      "heading" : "5.1 TED Evaluation",
      "text" : "We examine the quality of our mined bitext across a diverse set of languages, focusing on performance of bitext pairs not aligned through English. Following Gottschalk and Demidova (2017), we evaluate on the test sets of the TED corpus (Qi et al., 2018), which contains parallel TED talk transcripts in 58 languages. This corpus is tokenized, so we detokenize using Moses, with the exception of pairs\nIS O\nN am\ne Si\nze ko\nvi zh\naf da\nde en\nis nl\nno sv\nca es\nfr gl\nit pt\nro be\nbg cs\nhr pl\nru sk\nsl sr\nuk el\net fi\nhu lt\nlv eu\nsq tr\nar he\nfa sw\nbn hi\nm r\nne si\nur ta\nid m\ng m\ns m\nl tl\nTo ta\nl\nja Ja\npa ne\nse 39\n29 7.\n2 3.\n4 12\n.4 -\n4. 1\n14 .5\n40 .9\n- 12\n.4 4.\n0 12\n.2 -\n15 .4\n15 .0\n- 8.\n5 8.\n8 4.\n1 -\n4. 1\n10 .9\n- 11\n.6 9.\n5 4.\n1 3.\n5 3.\n4 2.\n0 3.\n9 -\n4. 0\n4. 2\n2. 8\n- -\n- 13\n.0 3.\n8 7.\n1 2.\n3 0.\n9 1.\n7 1.\n8 -\n- -\n- 0.\n7 7.\n7 -\n1. 7\n1. 1\n0. 3\n26 8. 7 ko K or ea n 14 92 - 3. 9 5. 1 - 2. 5 9. 8 19 .4 - 8. 4 2. 7 9. 3 - 10 .3 10 .1 - 4. 6 9. 4 - - 2. 4 6. 7 - 7. 6 7. 1 3. 0 2. 2 2. 0 1. 0 2. 1 1. 7 2. 4 2. 4 1. 7 1. 2 - - 6. 3 2. 5 4. 3 1. 6 0. 6 0. 9 1. 5 - - - - 0. 5 2. 8 - - - - 16 7. 1 vi V ie tn am es e 20 03 - 8. 0 - 4. 0 12 .8 50 .1 - 12 .2 4. 4 7. 4 - 34 .0 16 .0 - 8. 8 8. 2 4. 8 0. 2 4. 7 9. 9 - 5. 8 8. 4 5. 5 3. 8 3. 5 1. 9 8. 4 2. 6 7. 6 8. 0 5. 5 1. 9 - - 7. 3 8. 8 6. 0 5. 6 2. 5 2. 8 3. 3 - - - - 1. 3 9. 3 - 4. 2 - 1. 6 30 8. 3 zh C hi ne se 43 63 - - 4. 9 18 .6 71 .4 - 8. 2 4. 7 7. 5 - 24 .1 21 .4 - 10 .4 12 .2 5. 1 - 5. 3 6. 6 2. 6 7. 4 14 .0 4. 8 3. 7 3. 7 2. 3 5. 0 3. 2 4. 6 4. 8 3. 4 2. 4 - - 7. 2 6. 6 5. 2 4. 9 1. 1 1. 9 2. 3 - - - - 1. 1 6. 2 0. 5 2. 0 1. 2 0. 5 32 8. 3 af A fr ik aa ns 15 - 1. 1 3. 6 8. 7 0. 3 2. 3 1. 4 1. 7 - - - - - - - - - - - - - - - - - - - - - - - - - 2. 7 - - - - - - - - - - - - - - - - 21 .8 da D an is h 45 3 - 28 .3 52 .3 1. 3 16 .6 17 .7 23 .1 2. 2 24 .1 24 .3 - 14 .7 14 .0 7. 7 0. 2 7. 6 5. 3 2. 9 5. 9 8. 5 7. 9 6. 4 4. 1 2. 5 7. 6 5. 4 9. 5 7. 7 5. 8 4. 2 1. 0 2. 3 5. 5 4. 5 3. 2 2. 2 - - - - - - - 0. 5 5. 6 - - - - 35 8. 9 de G er m an 57 26 - 24 7 3. 4 68 .8 23 .8 43 .9 - 11 2 13 7 - 71 .6 53 .7 21 .7 0. 7 20 .6 32 .9 8. 9 44 .6 45 .9 25 .0 18 .0 12 .0 7. 5 19 .7 12 .5 20 .0 23 .4 13 .1 9. 6 - 8. 6 20 .5 16 .0 9. 2 7. 4 2. 4 3. 7 5. 7 - - - - 2. 3 17 .0 0. 7 4. 0 2. 4 1. 1 12 86 .4 en E ng lis h 14 33 3 - 8. 7 10 7 47 .8 77 .0 21 .3 40 9 32 9 13 .2 14 6 17 4 55 .6 1. 9 44 .6 56 .3 18 .8 74 .1 14 0 38 .1 27 .4 26 .5 20 .2 49 .3 22 .0 36 .0 36 .4 23 .3 16 .7 7. 8 22 .4 47 .0 49 .7 25 .2 24 .6 5. 8 10 .1 15 .1 2. 9 0. 7 6. 3 6. 1 7. 3 70 .5 1. 7 10 .7 6. 8 3. 1 28 33 .5 is Is la nd ic 32 - 1. 7 1. 3 1. 7 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 18 .5 nl D ut ch 17 12 - 14 .0 23 .8 - 48 .6 38 .1 - 29 .3 25 .8 11 .7 0. 3 10 .5 25 .5 - 30 .1 25 .7 11 .8 8. 9 5. 9 3. 3 11 .0 6. 9 11 .4 11 .6 7. 4 5. 5 - - 18 .9 7. 7 9. 5 7. 4 1. 2 1. 8 2. 8 - - - - 1. 0 9. 4 - - - - 66 3. 9 no N or w eg ia n 43 6 - 23 .3 2. 0 20 .6 20 .7 - 12 .7 12 .0 6. 3 0. 2 6. 1 8. 0 2. 5 5. 0 7. 5 6. 7 5. 5 4. 5 2. 5 5. 9 4. 2 8. 1 6. 2 4. 6 3. 4 0. 9 2. 3 6. 1 4. 6 3. 3 2. 3 - - - - - - - 0. 7 6. 1 - - - - 32 6. 4 sv Sw ed is h 17 33 - - 38 .0 36 .6 - 21 .1 31 .1 9. 2 0. 3 8. 9 22 .6 - 27 .0 21 .4 12 .1 9. 4 5. 7 2. 9 9. 1 6. 2 18 .1 10 .0 6. 5 4. 8 - 3. 8 19 .4 6. 6 8. 8 3. 3 0. 9 1. 6 2. 6 - - - - 0. 8 7. 9 - - - - 58 7. 2 ca C at al an 16 2 - 65 .4 24 .4 3. 0 11 .4 12 .7 5. 8 - 2. 0 - - - - 2. 0 1. 7 1. 4 1. 1 2. 5 1. 2 1. 8 2. 0 1. 4 1. 0 1. 1 1. 2 - 1. 6 1. 3 1. 1 0. 3 0. 6 0. 6 - - - - 0. 4 1. 8 - - - - 17 6. 4 es Sp an is h 52 68 - 28 6 32 .2 14 8 19 8 57 .1 - 9. 6 33 .4 - 43 .6 55 .9 22 .5 16 .3 12 .6 8. 6 45 .2 11 .4 34 .1 37 .8 23 .7 9. 2 6. 6 10 .6 24 .3 35 .4 22 .0 19 .2 6. 9 3. 9 11 .8 - - - - 9. 1 39 .9 - - - -2 07 7. 5 fr Fr en ch 56 84 - 17 .2 14 8 12 8 58 .6 - 10 .3 34 .2 9. 2 44 .0 48 .3 22 .7 16 .6 12 .3 7. 6 44 .4 11 .8 36 .3 38 .7 24 .6 9. 3 - - 24 .2 24 .4 23 .2 8. 3 8. 1 10 .1 11 .4 - - - - 8. 2 21 .9 - 4. 4 2. 3 1. 1 18 26 .6 gl G al ic ia n 43 - 4. 0 9. 9 1. 8 - - - - - - - - - - - - - - - - - - 4. 5 - - - - - - - - - - - - - - - - 85 .8 it It al ia n 24 41 - 69 .6 29 .7 0. 4 14 .0 10 .0 - 13 .0 18 .6 13 .9 10 .7 7. 0 2. 7 16 .0 7. 1 11 .4 13 .5 8. 3 5. 8 1. 9 5. 9 11 .1 11 .0 - 4. 5 1. 2 1. 8 3. 2 - - - - 1. 1 10 .8 - - - - 94 3. 3 pt Po rt ug ue se 25 48 - 18 .6 - 6. 7 25 .6 - 33 .9 27 .1 13 .0 9. 6 7. 0 4. 7 23 .3 6. 7 10 .8 12 .6 8. 0 5. 5 2. 0 - 20 .9 18 .3 11 .3 9. 8 3. 6 5. 2 6. 4 - - - - 4. 6 20 .8 - - - -1 08 3. 5 ro R om an ia n 56 6 - 0. 3 10 .5 10 .4 3. 7 12 .9 - 8. 8 6. 7 5. 1 3. 4 9. 6 5. 0 6. 4 9. 2 6. 2 4. 4 - 3. 4 5. 5 5. 2 3. 2 2. 7 - 1. 2 1. 8 - - - - 0. 7 6. 0 - - - - 43 0. 1 be B el ar us ia n 25 - 0. 9 1. 5 0. 1 2. 3 4. 0 0. 9 0. 6 0. 5 0. 9 0. 2 0. 2 0. 2 0. 4 0. 2 0. 1 - 0. 1 2. 0 - - - 0. 0 0. 1 0. 1 - - - - - - - - - - 19 .6 bg B ul ga ri an 27 1 - 11 .1 4. 1 19 .5 32 .3 13 .3 9. 9 8. 7 8. 1 9. 5 5. 6 6. 5 8. 3 7. 1 4. 9 0. 9 3. 2 5. 4 2. 7 3. 3 - 0. 6 1. 2 1. 9 - - - - 0. 6 3. 5 - - - - 34 0. 9 cs C ze ch 98 6 - 4. 5 31 .8 28 .0 37 .4 9. 9 6. 1 4. 0 9. 1 6. 7 8. 9 11 .3 7. 5 5. 3 - 3. 2 14 .4 5. 5 3. 8 2. 9 0. 7 1. 4 2. 0 - - - - 0. 7 6. 2 - - - - 52 2. 0 hr C ro at ia n 81 - 5. 2 7. 7 3. 8 4. 2 4. 9 1. 8 - 2. 4 2. 5 3. 3 2. 9 2. 0 - 1. 6 - 1. 8 - 1. 2 - - - - - - - 0. 6 - - - - - 10 3. 1 pl Po lis h 15 98 - 36 .6 26 .0 16 .4 11 .6 5. 8 10 .4 7. 0 10 .0 12 .6 9. 2 6. 0 - 4. 0 17 .3 7. 2 8. 8 7. 1 1. 0 1. 6 2. 4 - - - - 0. 9 13 .7 - - - - 64 0. 9 ru R us si an 42 55 - 21 .7 15 .8 14 .2 26 .5 12 .8 10 .1 10 .3 12 .4 14 .8 10 .1 - 5. 8 11 .0 11 .9 9. 5 5. 5 1. 4 2. 6 3. 5 0. 7 0. 2 1. 4 1. 4 1. 5 14 .1 0. 4 2. 5 1. 6 0. 6 77 0. 9 sk Sl ov ak 39 5 - 14 .4 8. 6 6. 1 7. 6 5. 8 7. 4 10 .8 7. 0 5. 1 1. 1 3. 1 6. 6 5. 0 3. 2 2. 2 0. 6 1. 1 1. 8 - - - - 0. 5 5. 0 - - - - 40 8. 0 sl Sl ov en ia n 18 6 - 7. 8 4. 5 6. 1 5. 3 6. 0 7. 4 6. 2 5. 1 0. 9 2. 5 4. 7 3. 7 2. 4 1. 8 0. 5 0. 9 1. 7 - - - - 0. 5 4. 1 - - - - 29 3. 4 sr Se rb ia n 16 5 - 4. 6 4. 6 3. 4 3. 6 4. 3 3. 9 3. 3 0. 8 2. 9 4. 1 3. 3 2. 4 1. 9 0. 5 0. 9 1. 8 - - - - 0. 5 4. 2 - - - - 22 9. 9 uk U kr ai ni an 48 1 - 2. 7 2. 0 2. 3 2. 6 3. 0 1. 9 - 1. 5 2. 4 2. 1 1. 8 1. 1 0. 3 0. 6 0. 9 - - - - 0. 3 2. 2 - - - - 16 4. 1 el G re ek 57 8 - 4. 7 6. 3 7. 6 5. 4 4. 1 2. 5 3. 2 10 .8 3. 9 6. 3 2. 6 1. 5 3. 0 3. 3 - - - - 1. 8 9. 0 - - - - 40 1. 7 et E st on ia n 92 - 6. 0 5. 5 5. 6 4. 1 1. 5 1. 4 3. 3 2. 7 2. 0 1. 5 0. 8 0. 8 1. 4 - - - - 0. 4 3. 4 - - - - 20 1. 3 fi Fi nn is h 47 7 - 7. 8 5. 4 3. 9 2. 4 2. 0 5. 3 4. 0 5. 6 2. 0 1. 4 2. 8 3. 1 - - - - 1. 8 8. 1 - - - - 34 8. 3 hu H un ga ri an 57 9 - 6. 3 4. 4 2. 5 2. 5 6. 2 4. 3 5. 7 2. 1 1. 4 3. 0 3. 2 - - - - 1. 8 4. 5 - - - - 37 0. 6 lt L ith ua ni an 15 9 - 5. 3 1. 6 1. 6 7. 4 3. 2 3. 9 1. 6 0. 9 2. 1 2. 5 - - - - 1. 4 3. 7 0. 5 - - - 26 6. 1 lv L at vi an 85 - 1. 4 1. 2 2. 6 2. 2 1. 6 1. 0 0. 8 0. 6 1. 2 - - - - 0. 3 2. 5 - - - - 16 5. 7 eu B as qu e 32 - 0. 9 3. 8 2. 0 1. 8 1. 8 - - - - - - - - - - - - - 47 .0 sq A lb an ia n 84 - 7. 5 2. 6 1. 5 2. 0 - - - - - - - - - - - - - 11 4. 6 tr Tu rk is h 21 57 - 5. 7 7. 6 4. 0 3. 4 5. 1 5. 5 1. 8 4. 5 3. 7 3. 2 3. 3 6. 6 - 4. 1 3. 4 1. 5 42 2. 4 ar A ra bi c 78 6 - 3. 7 4. 5 1. 8 3. 1 3. 6 1. 1 2. 2 2. 0 1. 7 1. 9 9. 6 - 2. 7 2. 0 0. 9 32 0. 9 he H eb re w 26 3 - 4. 1 1. 0 2. 3 2. 8 1. 0 1. 2 1. 9 0. 9 1. 9 6. 1 0. 5 1. 9 1. 9 0. 8 24 6. 0 fa Fa rs i 77 8 - 1. 6 2. 6 2. 8 0. 9 1. 7 1. 6 1. 9 1. 8 6. 4 - 2. 2 1. 7 0. 7 18 4. 1 sw Sw ah ili 9 - 0. 9 1. 0 - - - - 1. 4 2. 4 - - - - 61 .3 bn B en ga li 13 6 - 1. 3 0. 2 0. 0 0. 4 0. 5 0. 3 3. 3 0. 4 0. 5 0. 5 0. 1 91 .4 hi H in di 0 - 0. 5 0. 1 0. 4 0. 8 0. 4 4. 0 0. 4 0. 6 0. 5 0. 1 12 5. 7 m r M ar at hi 23 - 0. 0 0. 1 0. 1 0. 1 1. 3 - - - - 10 .5 ne N ep al i 19 - 0. 0 0. 0 0. 0 6. 3 - - - - 17 .0 si Si nh al a 32 - 0. 3 0. 2 2. 3 - - - - 20 .6 ur U rd u 35 - 0. 3 2. 0 - - - - 19 .3 ta Ta m il 15 4 - 2. 3 0. 2 0. 3 0. 3 0. 2 68 .7 id In do ne si an 10 14 - 1. 2 7. 8 2. 3 1. 7 39 3. 6 m g M al ag as y 1 - 0. 1 0. 1 0. 1 6. 8 m s M al ay 45 - 0. 3 0. 2 50 .1 m l M al ay am 59 - 0. 2 28 .5 tl Ta ga lo g 42 - 14 .9\nTa bl\ne 1:\nC C\nM at\nri x:\nnu m\nbe ro\nfe xt\nra ct\ned pa\nra lle\nls en\nte nc\nes fo\nre ac\nh la\nng ua\nge pa\nir (a\nll nu\nm be\nrs in\nm ill\nio ns\n)f or\na m\nar gi\nn th\nre sh\nol d\nof 1.\n06 .S\nee te\nxt fo\nrd et\nai ls\n.\ninvolving Chinese, Japanese and Korean as it creates artifacts.\nWe consider 29 different languages, resulting in 778 NMT systems to train. We apply the same preprocessing and training procedure for all language pairs. We train a SentencePiece Model (Kudo and Richardson, 2018) with a vocabulary of size 50k. The bitext were not filtered to remove sentences which may appear in the TED dev or test sets. Also, we did not try to optimize the architecture of the NMT models to to size of the bitexts for each language pair. Instead, for all the pairs, we use the same architecture, a Transformer model with six layers for both the encoder and decoder. We use a dimension of 512 and 4096 for the feed-forward. We train each model for 50 epochs with an initial learning rate of 0.001. We keep the model with the best BLEU on the TED validation set.\nIn Table 2, we report tokenized BLEU on the test sets. When translating into Chinese, we scored with sacrebleu -tok zh, and Kytea6 was used to tokenize Japanese, respectively. The average BLEU over all pairs is 18.8 and 33.0 for pairs with English. There are 86 pairs out of 778 with BLEU above 30, compared to 10 out of 1620 language pairs for WikiMatrix. The best WikiMatrix pair reached 37.3 BLEU (for Brazilian Portuguese to English), while here 25 pairs are over 37.3, the best pair reaching 51.2 BLEU (Norwegian to English).\n6http://www.phontron.com/kytea/\nThese results show the quality of the mined bitexts and suggest that our mining strategy is robust to the noise and domain differences existing in large corpora like Common Crawl. However, since we did not optimize the NMT systems for each language pair, these BLEU score should not be considered as the best possible ones based on the CCMatrix bitexts. In particular, we anticipate that better results can be obtained when using models with more parameters for the high-resource language pairs.\nFurther, our mined data provides a starting point for those interested in training translation systems directly between languages that currently have no available bitext training data. In particular CCMatrix bitexts have been used to train a massively multilingual NMT systems for 100×100 languages (Fan et al., 2020)."
    }, {
      "heading" : "5.2 WMT’19 Evaluation",
      "text" : "Next, we focus on arguably the most competitive translation benchmark, the WMT news translation task, to compare our mined data to the best existing systems. We only consider the high resource directions, as they constitute the largest challenge — existing systems perform strongly, and previous work incorporating mined data from Paracrawl (Ott et al., 2018) only found marginal gains.\nWe follow Ng et al. (2019) and trained systems on en-de, en-ru, en-zh, and de-fr. We used the Transformer Big architecture with FFN size 8192,\nembedding size 2048, with 9 encoder/decoder layers, with LayerDrop (Fan et al., 2019). We trained for 400k updates on 8 GPUs. Given the large amounts of mined bitext (see Table 1), we train only on data with a margin threshold at least 1.07, and perform some additional filtering, resulting in 146M for en-de, 78M for en-ru, 82M for de-fr and 31M for en-zh. For each direction, we learn joint source-target BPE (Sennrich et al., 2016) and share input/output embeddings. We tune training parameters on WMT’12-13 when available and on the WMT’19 dev set for de-fr.\nIn Table 3 we demonstrate that the performance of a single model trained on mined data is better than the performance of the best published single models trained on WMT bitext, this can be seen as a clear indicator of the quality of the mined data.\nBecause CCMatrix data is mined from the Web, we want to make sure there is no significant leakage of the test sets that might be available online into the training data. While there are no exact matches of test and train samples, partial overlap\nis still possible. Following Radford et al. (2019) and Shoeybi et al. (2019) in Table 4 we report the percentage of 8-gram BPE tokens from the test data that are also found in CCMatrix training data. Finally, in Table 3 we also report performance on Newstest’20 tests sets that were not available at the time of mining the data.\nWe further investigate the impact of training on a combination of human translated and mined data. We examine En-De and include the WMT’19 training data. We found that this system outperforms the system trained on CCMatrix data only on average by only 0.6 BLEU, achieving BLEU score 50.9 on newstest2018 and 45.1 on newstest2019."
    }, {
      "heading" : "5.3 WAT’20 Evaluation",
      "text" : "Finally, we examine the quality of our mined data on low resource, distant language pairs. We focus on Russian-Japanese, a language direction in the 2020 Workshop on Asian Translation (WAT) (Nakazawa et al., 2020).The organizers provide a tiny amount of parallel data from the Global Voices domain for training (12k sentences), and a development (486 sentences) and test set (600 sentences) from the News Commentary domain, respectively.7\nWe trained an NMT system on CCMatrix Japanese-Russian mined data only, without using other resources or texts aligned with English. We applied a threshold of 1.06 on the margin which yielded 9.5 million parallel sentences. We filtered the mined bitexts to exclude all sentences which\n7https://github.com/aizhanti/JaRuNC\nappear in the WAT dev or test set. We use the same NMT architecture as in Section 5.1. We report tokenized BLEU in Table 5. When translating from Russian into Japanese, tokenization was performed with Kytea and then scored with multi-bleu.perl.\nWe outperform the best performing system at WAT’20,8 in particular when translating into Japanese. On one hand, the participants in WAT were constrained to only use the provided resources. But on the other hand, Russian/English and Japanese/English were included and participants were encouraged to train multilingual models, and use techniques like monolingual pre-training or back-translation. Therefore, our results are not directly comparable, but remain a positive indicator of the quality of our mined bitexts."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We show that margin-based mining in a joint multilingual sentence embedding space can be scaled to monolingual texts of more than 71 billion unique sentences in 90 languages, including several low resource languages. This procedure yields 10.8 billion parallel sentences, out of which only 2.9 billions are aligned with English. We performed an extensive evaluation of the quality of the mined bitexts by training NMT systems for many language pairs. Training only on mined data, we outperform the best single NMT systems at WMT’19 for translations between German, Russian, and Chinese with English, as well as between German and French. We also achieve state-of-the-art BLEU scores for translation between Russian and Japanese at WAT’20.\nAll mined data is freely available.9 We hope this will enable widespread research on multilingual NMT, particularly on languages where training data is not currently available.\n8See results at http://lotus.kuee.kyoto-u.ac. jp/WAT/evaluation/index.html\n9https://github.com/facebookresearch/ LASER/tree/master/tasks/CCMatrix"
    } ],
    "references" : [ {
      "title" : "On the Use of Comparable Corpora to Improve SMT performance",
      "author" : [ "Sadaf Abdul-Rauf", "Holger Schwenk." ],
      "venue" : "EACL, pages 16–23.",
      "citeRegEx" : "Abdul.Rauf and Schwenk.,? 2009",
      "shortCiteRegEx" : "Abdul.Rauf and Schwenk.",
      "year" : 2009
    }, {
      "title" : "Finding similar sentences across multiple languages in Wikipedia",
      "author" : [ "Sisay Fissaha Adafre", "Maarten de Rijke." ],
      "venue" : "Proceedings of the Workshop on NEW TEXT Wikis and blogs and other dynamic text sources.",
      "citeRegEx" : "Adafre and Rijke.,? 2006",
      "shortCiteRegEx" : "Adafre and Rijke.",
      "year" : 2006
    }, {
      "title" : "Deep neural networks at the service of multilingual parallel sentence extraction",
      "author" : [ "Ahmad Aghaebrahimian." ],
      "venue" : "Coling.",
      "citeRegEx" : "Aghaebrahimian.,? 2018",
      "shortCiteRegEx" : "Aghaebrahimian.",
      "year" : 2018
    }, {
      "title" : "Marginbased Parallel Corpus Mining with Multilingual Sentence Embeddings",
      "author" : [ "Mikel Artetxe", "Holger Schwenk." ],
      "venue" : "https://arxiv.org/abs/ 1811.01136.",
      "citeRegEx" : "Artetxe and Schwenk.,? 2018a",
      "shortCiteRegEx" : "Artetxe and Schwenk.",
      "year" : 2018
    }, {
      "title" : "Massively multilingual sentence embeddings for zeroshot cross-lingual transfer and beyond",
      "author" : [ "Mikel Artetxe", "Holger Schwenk." ],
      "venue" : "https: //arxiv.org/abs/1812.10464.",
      "citeRegEx" : "Artetxe and Schwenk.,? 2018b",
      "shortCiteRegEx" : "Artetxe and Schwenk.",
      "year" : 2018
    }, {
      "title" : "Weighted Set-Theoretic Alignment of Comparable Sentences",
      "author" : [ "Andoni Azpeitia", "Thierry Etchegoyhen", "Eva Martı́nez Garcia" ],
      "venue" : "In BUCC,",
      "citeRegEx" : "Azpeitia et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Azpeitia et al\\.",
      "year" : 2017
    }, {
      "title" : "Extracting Parallel Sentences from Comparable Corpora with STACC Variants",
      "author" : [ "Andoni Azpeitia", "Thierry Etchegoyhen", "Eva Martı́nez Garcia" ],
      "venue" : "BUCC",
      "citeRegEx" : "Azpeitia et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Azpeitia et al\\.",
      "year" : 2018
    }, {
      "title" : "H2@BUCC18: Parallel Sentence Extraction from Comparable Corpora Using Multilingual Sentence Embeddings",
      "author" : [ "Houda Bouamor", "Hassan Sajjad." ],
      "venue" : "BUCC.",
      "citeRegEx" : "Bouamor and Sajjad.,? 2018",
      "shortCiteRegEx" : "Bouamor and Sajjad.",
      "year" : 2018
    }, {
      "title" : "Findings of the wmt 2016 bilingual document alignment shared task",
      "author" : [ "Christian Buck", "Philipp Koehn." ],
      "venue" : "Proceedings of the First Conference on Machine Translation, pages 554–563, Berlin, Germany. Association for Computational Linguistics.",
      "citeRegEx" : "Buck and Koehn.,? 2016",
      "shortCiteRegEx" : "Buck and Koehn.",
      "year" : 2016
    }, {
      "title" : "A massive collection of cross-lingual web-document pairs",
      "author" : [ "Ahmed El-Kishky", "Vishrav Chaudhary", "Francisco Guzman", "Philipp Koehn." ],
      "venue" : "arXiv preprint arXiv:1911.06154.",
      "citeRegEx" : "El.Kishky et al\\.,? 2019",
      "shortCiteRegEx" : "El.Kishky et al\\.",
      "year" : 2019
    }, {
      "title" : "A massive collection of cross-lingual web-document pairs",
      "author" : [ "Ahmed El-Kishky", "Vishrav Chaudhary", "Francisco Guzman", "Philipp Koehn." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages",
      "citeRegEx" : "El.Kishky et al\\.,? 2020",
      "shortCiteRegEx" : "El.Kishky et al\\.",
      "year" : 2020
    }, {
      "title" : "An Empirical Analysis of NMT-Derived Interlingual Embeddings and their Use in Parallel Sentence Identification",
      "author" : [ "Cristina España-Bonet", "Ádám Csaba Varga", "Alberto Barrón-Cedeño", "Josef van Genabith." ],
      "venue" : "IEEE Journal of Selected Topics in Signal",
      "citeRegEx" : "España.Bonet et al\\.,? 2017",
      "shortCiteRegEx" : "España.Bonet et al\\.",
      "year" : 2017
    }, {
      "title" : "Combining content-based and url-based heuristics to harvest aligned bitexts from multilingual sites with bitextor",
      "author" : [ "Miquel Esplà-Gomis", "Mikel L. Forcada." ],
      "venue" : "The Prague Bulletin of Mathematical Linguistics, 9:77–86.",
      "citeRegEx" : "Esplà.Gomis and Forcada.,? 2010",
      "shortCiteRegEx" : "Esplà.Gomis and Forcada.",
      "year" : 2010
    }, {
      "title" : "SetTheoretic Alignment for Comparable Corpora",
      "author" : [ "Thierry Etchegoyhen", "Andoni Azpeitia." ],
      "venue" : "ACL, pages 2009–2018.",
      "citeRegEx" : "Etchegoyhen and Azpeitia.,? 2016",
      "shortCiteRegEx" : "Etchegoyhen and Azpeitia.",
      "year" : 2016
    }, {
      "title" : "Beyond english-centric multilingual machine translation",
      "author" : [ "Michael Auli", "Armand Joulin." ],
      "venue" : "JMLR.",
      "citeRegEx" : "Auli and Joulin.,? 2020",
      "shortCiteRegEx" : "Auli and Joulin.",
      "year" : 2020
    }, {
      "title" : "Reducing transformer depth on demand with structured dropout",
      "author" : [ "Angela Fan", "Edouard Grave", "Armand Joulin" ],
      "venue" : null,
      "citeRegEx" : "Fan et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Fan et al\\.",
      "year" : 2019
    }, {
      "title" : "Languageagnostic bert sentence embedding",
      "author" : [ "Fangxiaoyu Feng", "Yinfei Yang", "Daniel Cer", "Naveen Arivazhagan", "Wei Wang." ],
      "venue" : "arXiv preprint arXiv:2007.01852.",
      "citeRegEx" : "Feng et al\\.,? 2020",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2020
    }, {
      "title" : "Multiwiki: Interlingual text passage alignment in Wikipedia",
      "author" : [ "Simon Gottschalk", "Elena Demidova." ],
      "venue" : "ACM Transactions on the Web (TWEB), 11(1):6.",
      "citeRegEx" : "Gottschalk and Demidova.,? 2017",
      "shortCiteRegEx" : "Gottschalk and Demidova.",
      "year" : 2017
    }, {
      "title" : "Learning word vectors for 157 languages",
      "author" : [ "Edouard Grave", "Piotr Bojanowski", "Prakhar Gupta", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "https://arxiv. org/abs/1802.06893.",
      "citeRegEx" : "Grave et al\\.,? 2018",
      "shortCiteRegEx" : "Grave et al\\.",
      "year" : 2018
    }, {
      "title" : "Effective Parallel Corpus Mining using Bilingual Sentence Embed",
      "author" : [ "Mandy Guo", "Qinlan Shen", "Yinfei Yang", "Heming Ge", "Daniel Cer", "Gustavo Hernandez Abrego", "Keith Stevens", "Noah Constant", "Yun-Hsuan Sung", "Brian Strope", "Ray Kurzweil" ],
      "venue" : null,
      "citeRegEx" : "Guo et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2018
    }, {
      "title" : "Achieving Human Parity on Automatic Chinese to English News Translation",
      "author" : [ "Xu Tan", "Fei Tian", "Lijun Wu", "Shuangzhi Wu", "Yingce Xia", "Dongdong Zhang", "Zhirui Zhang", "Ming Zhou." ],
      "venue" : "arXiv:1803.05567.",
      "citeRegEx" : "Tan et al\\.,? 2018",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2018
    }, {
      "title" : "Billion-scale similarity search with GPUs",
      "author" : [ "Jeff Johnson", "Matthijs Douze", "Hervé Jégou." ],
      "venue" : "arXiv preprint arXiv:1702.08734.",
      "citeRegEx" : "Johnson et al\\.,? 2017",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2017
    }, {
      "title" : "Product quantization for nearest neighbor search",
      "author" : [ "H. Jégou", "M. Douze", "C. Schmid." ],
      "venue" : "IEEE Trans. PAMI, 33(1):117–128.",
      "citeRegEx" : "Jégou et al\\.,? 2011",
      "shortCiteRegEx" : "Jégou et al\\.",
      "year" : 2011
    }, {
      "title" : "Europarl: A parallel corpus for statistical machine translation",
      "author" : [ "Philipp Koehn." ],
      "venue" : "MT summit.",
      "citeRegEx" : "Koehn.,? 2005",
      "shortCiteRegEx" : "Koehn.",
      "year" : 2005
    }, {
      "title" : "Findings of the wmt 2019 shared task on parallel corpus filtering for low-resource conditions",
      "author" : [ "Philipp Koehn", "Francisco Guzmán", "Vishrav Chaudhary", "Juan M. Pino." ],
      "venue" : "Proceedings of the Fourth Conference on Machine Translation, Volume",
      "citeRegEx" : "Koehn et al\\.,? 2019",
      "shortCiteRegEx" : "Koehn et al\\.",
      "year" : 2019
    }, {
      "title" : "Findings of the wmt 2018 shared task on parallel corpus filtering",
      "author" : [ "Philipp Koehn", "Huda Khayrallah", "Kenneth Heafield", "Mikel L. Forcada." ],
      "venue" : "Proceedings of the Third Conference on Machine Translation: Shared Task Papers, pages 726–739, Bel-",
      "citeRegEx" : "Koehn et al\\.,? 2018",
      "shortCiteRegEx" : "Koehn et al\\.",
      "year" : 2018
    }, {
      "title" : "SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
      "author" : [ "Taku Kudo", "John Richardson." ],
      "venue" : "EMNLP, pages 66–71.",
      "citeRegEx" : "Kudo and Richardson.,? 2018",
      "shortCiteRegEx" : "Kudo and Richardson.",
      "year" : 2018
    }, {
      "title" : "Unsupervised multilingual sentence embeddings for parallel corpus mining",
      "author" : [ "Ivana Kvapilı́ková", "Mikel Artetxe", "Gorka Labaka amd Eneko Agirre", "Ondřej Bojar" ],
      "venue" : null,
      "citeRegEx" : "Kvapilı́ková et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Kvapilı́ková et al\\.",
      "year" : 2020
    }, {
      "title" : "Opensubtitles2016: Extracting large parallel corpora from movie and tv subtitles",
      "author" : [ "P. Lison", "J. Tiedemann." ],
      "venue" : "LREC.",
      "citeRegEx" : "Lison and Tiedemann.,? 2016",
      "shortCiteRegEx" : "Lison and Tiedemann.",
      "year" : 2016
    }, {
      "title" : "Cross-domain feature selection for language identification",
      "author" : [ "Marco Lui", "Timothy Baldwin." ],
      "venue" : "IJCNLP, pages 553–561.",
      "citeRegEx" : "Lui and Baldwin.,? 2011",
      "shortCiteRegEx" : "Lui and Baldwin.",
      "year" : 2011
    }, {
      "title" : "Building bilingual parallel corpora based on Wikipedia",
      "author" : [ "Mehdi Zadeh Mohammadi", "Nasser GhasemAghaee." ],
      "venue" : "2010 Second International Conference on Computer Engineering and Applications, pages 264–268.",
      "citeRegEx" : "Mohammadi and GhasemAghaee.,? 2010",
      "shortCiteRegEx" : "Mohammadi and GhasemAghaee.",
      "year" : 2010
    }, {
      "title" : "Improving Machine Translation Performance by Exploiting Non-Parallel Corpora",
      "author" : [ "Dragos Stefan Munteanu", "Daniel Marcu." ],
      "venue" : "Computational Linguistics, 31(4):477–504.",
      "citeRegEx" : "Munteanu and Marcu.,? 2005",
      "shortCiteRegEx" : "Munteanu and Marcu.",
      "year" : 2005
    }, {
      "title" : "Overview of the 7th workshop",
      "author" : [ "Toshiaki Nakazawa", "Hideki Nakayama", "Chenchen Ding", "Raj Dabre", "Shohei Higashiyama", "Hideya Mino", "Isao Goto", "Win Pa Pa", "Anoop Kunchukuttan", "Shantipriya Parida", "Ondřej Bojar", "Sadao Kurohashi" ],
      "venue" : null,
      "citeRegEx" : "Nakazawa et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Nakazawa et al\\.",
      "year" : 2020
    }, {
      "title" : "Facebook fair’s wmt19 news translation task submission",
      "author" : [ "Nathan Ng", "Kyra Yee", "Alexei Baevski", "Myle Ott", "Michael Auli", "Sergey Edunov." ],
      "venue" : "Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day",
      "citeRegEx" : "Ng et al\\.,? 2019",
      "shortCiteRegEx" : "Ng et al\\.",
      "year" : 2019
    }, {
      "title" : "Wikipedia as multilingual source of comparable corpora",
      "author" : [ "Pablo Gamallo Otero", "Isaac González López." ],
      "venue" : "Proceedings of the 3rd Workshop on Building and Using Comparable Corpora, LREC, pages 21–25.",
      "citeRegEx" : "Otero and López.,? 2010",
      "shortCiteRegEx" : "Otero and López.",
      "year" : 2010
    }, {
      "title" : "Scaling Neural Machine Translation",
      "author" : [ "Myle Ott", "Sergey Edunov", "David Grangier", "Michael Auli." ],
      "venue" : "arXiv:1806.00187.",
      "citeRegEx" : "Ott et al\\.,? 2018",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2018
    }, {
      "title" : "Identifying parallel documents from a large bilingual collection of texts: Application to parallel article extraction in Wikipedia",
      "author" : [ "Alexandre Patry", "Philippe Langlais." ],
      "venue" : "Proceedings of the 4th Workshop on Building and Using Comparable Corpora:",
      "citeRegEx" : "Patry and Langlais.,? 2011",
      "shortCiteRegEx" : "Patry and Langlais.",
      "year" : 2011
    }, {
      "title" : "When and why are pre-trained word embeddings useful for neural machine translation",
      "author" : [ "Ye Qi", "Devendra Sachan", "Matthieu Felix", "Sarguna Padmanabhan", "Graham Neubig" ],
      "venue" : "In Proceedings of the 2018 Conference of the North American Chapter",
      "citeRegEx" : "Qi et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Qi et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "A. Radford", "Jeffrey Wu", "R. Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "https://openai.com/blog/ better-language-models/.",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Mining the Web for Bilingual Text",
      "author" : [ "Philip Resnik." ],
      "venue" : "ACL.",
      "citeRegEx" : "Resnik.,? 1999",
      "shortCiteRegEx" : "Resnik.",
      "year" : 1999
    }, {
      "title" : "The Web as a Parallel Corpus",
      "author" : [ "Philip Resnik", "Noah A. Smith." ],
      "venue" : "Computational Linguistics, 29(3):349–380.",
      "citeRegEx" : "Resnik and Smith.,? 2003",
      "shortCiteRegEx" : "Resnik and Smith.",
      "year" : 2003
    }, {
      "title" : "Filtering and mining parallel data in a joint multilingual space",
      "author" : [ "Holger Schwenk." ],
      "venue" : "ACL, pages 228–234.",
      "citeRegEx" : "Schwenk.,? 2018",
      "shortCiteRegEx" : "Schwenk.",
      "year" : 2018
    }, {
      "title" : "Wikimatrix: Mining 135m parallel sentences in 1620 language pairs from wikipedia",
      "author" : [ "Holger Schwenk", "Vishrav Chaudhary", "Shuo Sun", "Hongyu Gong", "Francisco Guzmán." ],
      "venue" : "http://arxiv. org/abs/1907.05791.",
      "citeRegEx" : "Schwenk et al\\.,? 2019",
      "shortCiteRegEx" : "Schwenk et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural machine translation of rare words with subword units",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 1715–1725.",
      "citeRegEx" : "Sennrich et al\\.,? 2016",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2016
    }, {
      "title" : "Megatron-lm: Training multi-billion parameter language models using model parallelism",
      "author" : [ "Mohammad Shoeybi", "Mostofa Patwary", "Raul Puri", "Patrick LeGresley", "Jared Casper", "Bryan Catanzaro." ],
      "venue" : "CoRR, abs/1909.08053.",
      "citeRegEx" : "Shoeybi et al\\.,? 2019",
      "shortCiteRegEx" : "Shoeybi et al\\.",
      "year" : 2019
    }, {
      "title" : "Extracting parallel sentences from comparable corpora using document level alignment",
      "author" : [ "Jason R. Smith", "Chris Quirk", "Kristina Toutanova." ],
      "venue" : "NAACL, pages 403–411.",
      "citeRegEx" : "Smith et al\\.,? 2010",
      "shortCiteRegEx" : "Smith et al\\.",
      "year" : 2010
    }, {
      "title" : "Parallel data, tools and interfaces in OPUS",
      "author" : [ "J. Tiedemann." ],
      "venue" : "LREC.",
      "citeRegEx" : "Tiedemann.,? 2012",
      "shortCiteRegEx" : "Tiedemann.",
      "year" : 2012
    }, {
      "title" : "Cross-lingual wikification using multilingual embeddings",
      "author" : [ "Chen-Tse Tsai", "Dan Roth." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages",
      "citeRegEx" : "Tsai and Roth.,? 2016",
      "shortCiteRegEx" : "Tsai and Roth.",
      "year" : 2016
    }, {
      "title" : "Wikipedia as an smt training corpus",
      "author" : [ "Dan Tufis", "S Radu Ion", "tefan Daniel", "Dumitrescu", "Dan S", "tefănescu" ],
      "venue" : "In RANLP,",
      "citeRegEx" : "Tufis et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Tufis et al\\.",
      "year" : 2013
    }, {
      "title" : "Reliable Measures for Aligning Japanese-English News Articles and Sentences",
      "author" : [ "Masao Utiyama", "Hitoshi Isahara." ],
      "venue" : "ACL.",
      "citeRegEx" : "Utiyama and Isahara.,? 2003",
      "shortCiteRegEx" : "Utiyama and Isahara.",
      "year" : 2003
    }, {
      "title" : "CCNet: extracting high quality monolingual datasets from web crawl data",
      "author" : [ "Guillaume Wenzek", "Marie-Anne Lachaux", "Alexis Conneau", "Vishrav Chaudhary", "Francisco Guzmán", "Armand Joulin", "Edouard Grave." ],
      "venue" : "https://arxiv.org/abs/",
      "citeRegEx" : "Wenzek et al\\.,? 2019",
      "shortCiteRegEx" : "Wenzek et al\\.",
      "year" : 2019
    }, {
      "title" : "Improving multilingual sentence embedding using bi-directional dual encoder with additive margin",
      "author" : [ "Yinfei Yang", "Gustavo Hernández Ábrego", "Steve Yuan", "Mandy Guo", "Qinlan Shen", "Daniel Cer", "Yun-Hsuan Sung", "Brian Strope", "Ray Kurzweil" ],
      "venue" : null,
      "citeRegEx" : "Yang et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "The United Nations Parallel Corpus v1.0",
      "author" : [ "Michał Ziemski", "Marcin Junczys-Dowmunt", "Bruno Pouliquen" ],
      "venue" : null,
      "citeRegEx" : "Ziemski et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Ziemski et al\\.",
      "year" : 2016
    }, {
      "title" : "Overview of the Third BUCC Shared Task: Spotting Parallel Sentences in Comparable Corpora",
      "author" : [ "Pierre Zweigenbaum", "Serge Sharoff", "Reinhard Rapp." ],
      "venue" : "Proceedings of the 11th Workshop on Building and Using Comparable Corpora.",
      "citeRegEx" : "Zweigenbaum et al\\.,? 2018",
      "shortCiteRegEx" : "Zweigenbaum et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 50,
      "context" : "We use 32 Common Crawl snapshots (Wenzek et al., 2019), totalling 71 billion unique sentences.",
      "startOffset" : 33,
      "endOffset" : 54
    }, {
      "referenceID" : 52,
      "context" : "Traditionally, high quality parallel texts are obtained from the publications of international organizations like the the United Nations (Ziemski et al., 2016) or the European Parliament (Koehn, 2005).",
      "startOffset" : 137,
      "endOffset" : 159
    }, {
      "referenceID" : 23,
      "context" : ", 2016) or the European Parliament (Koehn, 2005).",
      "startOffset" : 35,
      "endOffset" : 48
    }, {
      "referenceID" : 37,
      "context" : "Another direction is to rely on volunteers to provide translations for public texts, such as the TED corpus (Qi et al., 2018), news commentary (Tiedemann, 2012) or OpenSubtitles (Lison and Tiedemann, 2016), but this approach lacks scalability.",
      "startOffset" : 108,
      "endOffset" : 125
    }, {
      "referenceID" : 46,
      "context" : ", 2018), news commentary (Tiedemann, 2012) or OpenSubtitles (Lison and Tiedemann, 2016), but this approach lacks scalability.",
      "startOffset" : 25,
      "endOffset" : 42
    }, {
      "referenceID" : 28,
      "context" : ", 2018), news commentary (Tiedemann, 2012) or OpenSubtitles (Lison and Tiedemann, 2016), but this approach lacks scalability.",
      "startOffset" : 60,
      "endOffset" : 87
    }, {
      "referenceID" : 39,
      "context" : "Mining Methodology At the start, various approaches used alignment on information beyond text itself, such as with document metadata (Resnik, 1999; Resnik and Smith, 2003).",
      "startOffset" : 133,
      "endOffset" : 171
    }, {
      "referenceID" : 40,
      "context" : "Mining Methodology At the start, various approaches used alignment on information beyond text itself, such as with document metadata (Resnik, 1999; Resnik and Smith, 2003).",
      "startOffset" : 133,
      "endOffset" : 171
    }, {
      "referenceID" : 13,
      "context" : "Later, work aligned based on text with techniques such as Jaccard similarity (Etchegoyhen and Azpeitia, 2016; Azpeitia et al., 2017, 2018), crosslingual document retrieval (Utiyama and Isahara, 2003; Munteanu and Marcu, 2005), language models (Buck and Koehn, 2016), translation (AbdulRauf and Schwenk, 2009; Bouamor and Sajjad, 2018), or bag-of-words (Buck and Koehn, 2016).",
      "startOffset" : 77,
      "endOffset" : 138
    }, {
      "referenceID" : 49,
      "context" : ", 2017, 2018), crosslingual document retrieval (Utiyama and Isahara, 2003; Munteanu and Marcu, 2005), language models (Buck and Koehn, 2016), translation (AbdulRauf and Schwenk, 2009; Bouamor and Sajjad, 2018), or bag-of-words (Buck and Koehn, 2016).",
      "startOffset" : 47,
      "endOffset" : 100
    }, {
      "referenceID" : 31,
      "context" : ", 2017, 2018), crosslingual document retrieval (Utiyama and Isahara, 2003; Munteanu and Marcu, 2005), language models (Buck and Koehn, 2016), translation (AbdulRauf and Schwenk, 2009; Bouamor and Sajjad, 2018), or bag-of-words (Buck and Koehn, 2016).",
      "startOffset" : 47,
      "endOffset" : 100
    }, {
      "referenceID" : 8,
      "context" : ", 2017, 2018), crosslingual document retrieval (Utiyama and Isahara, 2003; Munteanu and Marcu, 2005), language models (Buck and Koehn, 2016), translation (AbdulRauf and Schwenk, 2009; Bouamor and Sajjad, 2018), or bag-of-words (Buck and Koehn, 2016).",
      "startOffset" : 118,
      "endOffset" : 140
    }, {
      "referenceID" : 7,
      "context" : ", 2017, 2018), crosslingual document retrieval (Utiyama and Isahara, 2003; Munteanu and Marcu, 2005), language models (Buck and Koehn, 2016), translation (AbdulRauf and Schwenk, 2009; Bouamor and Sajjad, 2018), or bag-of-words (Buck and Koehn, 2016).",
      "startOffset" : 154,
      "endOffset" : 209
    }, {
      "referenceID" : 8,
      "context" : ", 2017, 2018), crosslingual document retrieval (Utiyama and Isahara, 2003; Munteanu and Marcu, 2005), language models (Buck and Koehn, 2016), translation (AbdulRauf and Schwenk, 2009; Bouamor and Sajjad, 2018), or bag-of-words (Buck and Koehn, 2016).",
      "startOffset" : 227,
      "endOffset" : 249
    }, {
      "referenceID" : 41,
      "context" : "In contrast, we use massively multilingual sentence embeddings trained on almost 100 languages, and then conduct margin-based mining in the multilingual embedding space (Schwenk, 2018; Artetxe and Schwenk, 2018a,b; Kvapilı́ková et al., 2020).",
      "startOffset" : 169,
      "endOffset" : 241
    }, {
      "referenceID" : 27,
      "context" : "In contrast, we use massively multilingual sentence embeddings trained on almost 100 languages, and then conduct margin-based mining in the multilingual embedding space (Schwenk, 2018; Artetxe and Schwenk, 2018a,b; Kvapilı́ková et al., 2020).",
      "startOffset" : 169,
      "endOffset" : 241
    }, {
      "referenceID" : 12,
      "context" : "Bitextor (Esplà-Gomis and Forcada, 2010) was applied to many languages, but took an approach that required identifying parallel documents first and then extracting aligned sentences.",
      "startOffset" : 9,
      "endOffset" : 40
    }, {
      "referenceID" : 10,
      "context" : "This is similar to the ccAligned project (El-Kishky et al., 2020).",
      "startOffset" : 41,
      "endOffset" : 65
    }, {
      "referenceID" : 4,
      "context" : "We use the open source LASER (Artetxe and Schwenk, 2018b) embeddings as they cover over 90 different languages.",
      "startOffset" : 29,
      "endOffset" : 57
    }, {
      "referenceID" : 16,
      "context" : "2 Another recent multilingual sentence embedding is LaBSE (Feng et al., 2020).",
      "startOffset" : 58,
      "endOffset" : 77
    }, {
      "referenceID" : 41,
      "context" : "Given two sentence embeddings, how can we decide if they are mutual translations? Using an absolute threshold on the cosine distance was shown to achieve competitive results (Schwenk, 2018), but is globally inconsistent (Guo et al.",
      "startOffset" : 174,
      "endOffset" : 189
    }, {
      "referenceID" : 19,
      "context" : "Given two sentence embeddings, how can we decide if they are mutual translations? Using an absolute threshold on the cosine distance was shown to achieve competitive results (Schwenk, 2018), but is globally inconsistent (Guo et al., 2018).",
      "startOffset" : 220,
      "endOffset" : 238
    }, {
      "referenceID" : 3,
      "context" : "Therefore, we use margin-based mining (Artetxe and Schwenk, 2018a).",
      "startOffset" : 38,
      "endOffset" : 66
    }, {
      "referenceID" : 53,
      "context" : "This strategy was motivated by evaluation on the BUCC corpus (Zweigenbaum et al., 2018), where the reference alignments are known to be strictly 1:1.",
      "startOffset" : 61,
      "endOffset" : 87
    }, {
      "referenceID" : 50,
      "context" : "3 We preprocess the raw text following the pipeline used to create the CCNet dataset (Wenzek et al., 2019).",
      "startOffset" : 85,
      "endOffset" : 106
    }, {
      "referenceID" : 42,
      "context" : "Our CCNet corpus is about 120 times larger than Wikipedia: 71 billion compared to 595 million unique sentences (Schwenk et al., 2019).",
      "startOffset" : 111,
      "endOffset" : 133
    }, {
      "referenceID" : 29,
      "context" : "2018) and LangID (Lui and Baldwin, 2011), and discard the data if the two disagree or have low confidence.",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 21,
      "context" : "(2019) and use the highly optimized FAISS library (Johnson et al., 2017)5 to create compact indices of the sentence embedding.",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 22,
      "context" : "To practically handle this scale, we use an aggressive vector compression based on a 64-bit product-quantizer (Jégou et al., 2011), and 64k cells to partition the search space.",
      "startOffset" : 110,
      "endOffset" : 130
    }, {
      "referenceID" : 37,
      "context" : "Following Gottschalk and Demidova (2017), we evaluate on the test sets of the TED corpus (Qi et al., 2018), which contains parallel TED talk transcripts in 58 languages.",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 26,
      "context" : "We train a SentencePiece Model (Kudo and Richardson, 2018) with a vocabulary of size 50k.",
      "startOffset" : 31,
      "endOffset" : 58
    }, {
      "referenceID" : 35,
      "context" : "We only consider the high resource directions, as they constitute the largest challenge — existing systems perform strongly, and previous work incorporating mined data from Paracrawl (Ott et al., 2018) only found marginal gains.",
      "startOffset" : 183,
      "endOffset" : 201
    }, {
      "referenceID" : 15,
      "context" : "embedding size 2048, with 9 encoder/decoder layers, with LayerDrop (Fan et al., 2019).",
      "startOffset" : 67,
      "endOffset" : 85
    }, {
      "referenceID" : 43,
      "context" : "For each direction, we learn joint source-target BPE (Sennrich et al., 2016) and share input/output embeddings.",
      "startOffset" : 53,
      "endOffset" : 76
    }, {
      "referenceID" : 32,
      "context" : "We focus on Russian-Japanese, a language direction in the 2020 Workshop on Asian Translation (WAT) (Nakazawa et al., 2020).",
      "startOffset" : 99,
      "endOffset" : 122
    } ],
    "year" : 2021,
    "abstractText" : "We show that margin-based bitext mining in a multilingual sentence space can be successfully scaled to operate on monolingual corpora of billions of sentences. We use 32 Common Crawl snapshots (Wenzek et al., 2019), totalling 71 billion unique sentences. Using one unified approach for 90 languages, we were able to mine 10.8 billion parallel sentences, out of which only 2.9 billions are aligned with English. We illustrate the capability of our scalable mining system to create high quality training sets from one language to any other by training hundreds of different machine translation models and evaluating them on the many-to-many TED benchmark. Further, we evaluate on competitive translation benchmarks such as WMT and WAT. Using only mined bitext, we set a new state of the art for a single system on the WMT’19 test set for English-German/Russian/Chinese. In particular, our English/German and English/Russian systems outperform the best single ones by over 4 BLEU points and are on par with best WMT’19 systems, which train on the WMT training data and augment it with backtranslation. We also achieve excellent results for distant languages pairs like Russian/Japanese, outperforming the best submission at the 2020 WAT workshop. All of the mined bitext will be freely available.",
    "creator" : "LaTeX with hyperref"
  }
}