{
  "name" : "P19-1001.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues",
    "authors" : [ "Chongyang Tao", "Wei Wu", "Can Xu", "Wenpeng Hu", "Dongyan Zhao", "Rui Yan" ],
    "emails" : [ "chongyangtao@pku.edu.cn", "wenpeng.hu@pku.edu.cn", "zhaody@pku.edu.cn", "ruiyan@pku.edu.cn", "wuwei@microsoft.com", "caxu@microsoft.com", "(ruiyan@pku.edu.cn)." ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1–11 Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics\n1"
    }, {
      "heading" : "1 Introduction",
      "text" : "Building a chitchat style dialogue systems in opendomain for human-machine conversations has attracted increasing attention in the conversational artificial intelligence (AI) community. Generally speaking, there are two approaches to implementing such a conversational system. The first approach leverages techniques of information retrieval (Lowe et al., 2015; Wu et al., 2017; Yan and Zhao, 2018), and selects a proper response from an index; while the second approach directly synthesizes a response with a natural lan-\n∗Corresponding author: Rui Yan (ruiyan@pku.edu.cn).\nguage generation model estimated from a largescale conversation corpus (Serban et al., 2016; Li et al., 2017b). In this work, we study the problem of multi-turn response selection for retrievalbased dialogue systems where the input is a conversation context consisting of a sequence of utterances. Compared with generation-based methods, retrieval-based methods are superior in terms of response fluency and diversity, and thus have been widely applied in commercial chatbots such as the social bot XiaoIce (Shum et al., 2018) from Microsoft, and the e-commerce assistant AliMe Assist from Alibaba Group (Li et al., 2017a).\nA key step in multi-turn response selection is to measure the matching degree between a conversation context and a response candidate. Stateof-the-art methods (Wu et al., 2017; Zhou et al., 2018b) perform matching within a representationinteraction-aggregation framework (Wu et al., 2018b) where matching signals in each utteranceresponse pair are distilled from their interaction based on their representations, and then are aggregated as a matching score. Although utteranceresponse interaction has proven to be crucial to the performance of the matching models (Wu et al., 2017), it is executed in a rather shallow manner where matching between an utterance and a response candidate is determined only by one step of interaction on each type or each layer of representations. In this paper, we attempt to move from shallow interaction to deep interaction, and consider context-response matching with multiple steps of interaction where residual information from one time of interaction, which is generally ignored by existing methods, is leveraged for additional interactions. The underlying motivation is that if a model extracts some matching information from utterance-response pairs in one step of interaction, then by stacking multiple such steps, the model can gradually accumulate useful signals\n2 for matching and finally capture the semantic relationship between a context and a response candidate in a more comprehensive way. We propose an interaction-over-interaction network (IoI) for context-response matching, through which we aim to investigate: (1) how to make interaction go deep in a matching model; and (2) if the depth of interaction really matters in terms of matching performance. A key component in IoI is an interaction block. Taking a pair of utteranceresponse as input, the block first lets the utterance and the response attend to themselves, and then measures interaction of the pair by an attentionbased interaction function. The results of the interaction are concatenated with the self-attention representations and then compressed to new representations of the utterance-response pair as the output of the block. Built on top of the interaction block, IoI initializes each utterance-response pair via pre-trained word embeddings, and then passes the initial representations through a chain of interaction blocks which conduct several rounds of representation-interaction-representation operations and let the utterance and the response interact with each other in an iterative way. Different blocks could distill different levels of matching information in an utterance-response pair. To sufficiently leverage the information, a matching score is first calculated in each block through aggregating matching vectors of all utterance-response pairs, and then the block-wise matching scores are combined as the final matching degree of the context and the response candidate. We conduct experiments on three benchmark data sets: the Ubuntu Dialogue Corpus (Lowe et al., 2015), the Douban Conversation Corpus (Wu et al., 2017), and the E-commerce Dialogue Corpus (Zhang et al., 2018b). Evaluation results indicate that IoI can significantly outperform stateof-the-art methods with 7 interaction blocks over all metrics on all the three benchmarks. Compared with deep attention matching network (DAM), the best performing baseline on all the three data sets, IoI achieves 2.9% absolute improvement on R10@1 on the Ubuntu data, 2.3% absolute improvement on MAP on the Douban data, and 3.7% absolute improvement on R10@1 on the Ecommerce data. Through more quantitative analysis, we also show that depth indeed brings improvement to the performance of IoI, as IoI with 1 interaction block performs worse than DAM on the Douban data and the E-commerce data, and on the Ubuntu data, the gap on R10@1 between IoI and DAM is only 1.1%. Moreover, the improvement brought by depth mainly comes from short contexts. Our contributions in this paper are three-folds: (1) proposal of a novel interaction-over-interaction network which enables deep-level matching with carefully designed interaction block chains; (2) empirical verification of the effectiveness of the model on three benchmarks; and (3) empirical study on the relationship between interaction depth and model performance."
    }, {
      "heading" : "2 Related Work",
      "text" : "Existing methods for building an open-domain dialogue system can be categorized into two groups. The first group learns response generation models under an encoder-decoder framework. On top of the basic sequence-to-sequence with attention architecture (Vinyals and Le, 2015; Shang et al., 2015; Tao et al., 2018), various extensions have been made to tackle the “safe response” problem (Li et al., 2015; Mou et al., 2016; Xing et al., 2017; Zhao et al., 2017; Song et al., 2018); to generate responses with specific personas or emotions (Li et al., 2016a; Zhang et al., 2018a; Zhou et al., 2018a); and to pursue better optimization strategies (Li et al., 2017b, 2016b). The second group learns a matching model of a human input and a response candidate for response selection. Along this line, the focus of research starts from single-turn response selection by setting the human input as a single message (Wang et al., 2013; Hu et al., 2014; Wang et al., 2015), and moves to context-response matching for multi-turn response selection recently. Representative methods include the dual LSTM model (Lowe et al., 2015), the deep learning to respond architecture (Yan et al., 2016), the multi-view matching model (Zhou et al., 2016), the sequential matching network (Wu et al., 2017, 2018b), and the deep attention matching network (Zhou et al., 2018b). Besides model design, some attention is also paid to the learning problem of matching models (Wu et al., 2018a). Our work belongs to the second group. The proposed interaction-over-interaction network is unique in that it performs matching by stacking multiple interaction blocks, and thus extends the shallow interaction in state-of-the-art methods to a deep\n3\nResponse GRU\nform. As far as we know, this is the first architecture that realizes deep interaction for multi-turn response selection.\nEncouraged by the big success of deep neural architectures such as Resnet (He et al., 2016) and inception (Szegedy et al., 2015) in computer vision, researchers have studied if they can achieve similar results with deep neural networks on NLP tasks. Although deep models have not yet brought breakthroughs to NLP as they do to computer vision, they have proven effective in a few tasks such as text classification (Conneau et al., 2017), natural language inference (Kim et al., 2018; Tay et al., 2018), and question answering (Tay et al., 2018; Kim et al., 2018), etc. In this work, we attempt to improve the accuracy of multi-turn response selection in retrieval-based dialogue systems by increasing the depth of context-response interaction in matching. Through extensive studies on benchmarks, we show that depth can bring significant improvement to model performance on the task."
    }, {
      "heading" : "3 Problem Formalization",
      "text" : "Suppose that there is a conversation data set D = {(yi, ci, ri)}Ni=1. ∀i ∈ {1, . . . , N}, ci = {ui,1, . . . , ui,li} represents a conversation context with ui,k the k-th turn, ri is a response candidate, and yi ∈ {0, 1} denotes a label with yi = 1 indicating ri a proper response for ci, otherwise yi = 0. The task is to learn a matching model g(·, ·) fromD, and thus for a new context-response pair (c, r), g(c, r) measures the matching degree\nbetween c and r. In the following sections, we will elaborate how to define g(·, ·) to achieve deep interaction between c and r, and how to learn such a deep model from D."
    }, {
      "heading" : "4 Interaction-over-Interaction Network",
      "text" : "We define g(·, ·) as an interaction-over-interaction network (IoI). Figure 1 illustrates the architecture of IoI. The model pairs each utterance in a context with a response candidate, and then aggregates matching information from all the pairs as a matching score of the context and the response candidate. For each pair, IoI starts from initial representations of the utterance and the response, and then feeds the pair to stacked interaction blocks. Each block represents the utterance and the response by letting them interact with each other based on the interactions before. Matching signals are first accumulated along the sequence of the utterances in each block, and then combined along the chain of blocks as the final matching score. Below we will describe details of components of IoI and how to learn the model with D."
    }, {
      "heading" : "4.1 Initial Representations",
      "text" : "Given an utterance u in a context c and a response candidate r, u and r are initialized as Eu = [eu,1, · · · , eu,m] and Er = [er,1, · · · , er,n] respectively. ∀i ∈ {1, . . . ,m} and ∀j ∈ {1, . . . , n}, eu,i and er,j are representations of the i-th word of u and the j-th word of r respectively which\n4 are obtained by pre-training Word2vec (Mikolov et al., 2013) on D. Eu and Er are then processed by stacked interaction blocks that model different levels of interaction between u and r and generate matching signals."
    }, {
      "heading" : "4.2 Interaction Block",
      "text" : "The stacked interaction blocks share the same internal structure. In a nutshell, each block is composed of a self-attention module that captures long-term dependencies within an utterance and a response, an interaction module that models the interaction between the utterance and the response, and a compression module that condenses the results of the first two modules into representations of the utterance and the response as output of the block. The output is then utilized as the input of the next block. Before diving to details of the block, we first generally describe an attention mechanism that lays a foundation for the self-attention module and the interaction module. Let Q ∈ Rnq×d and K ∈ Rnk×d be a query and a key respectively, where nq and nk denote numbers of words and d is the embedding size, then attention from Q to K is defined as Q̂ = S(Q,K) ·K, (1) where S(·, ·) is a function for attention weight calculation. Here, we exploit the symmetric function in (Huang et al., 2017b) as S(·, ·) which is given by: S(Q,K) = softmax(f(QW)Df(KW)>). (2) In Equation (2), f is a ReLU activation function, D is a diagonal matrix, and both D ∈ Rd×d and W ∈ Rd×d are parameters to estimate from training data. Intuitively, in Equation (1), each entry of K is weighted by an importance score defined by the similarity of an entry of Q and an entry of K. The entries of K are then linearly combined with the weights to form a new representation of Q. A residual connection (He et al., 2016) and a layer normalization (Ba et al., 2016) are then applied to Q̂ as Q̃. After that, Q̃ is fed to a feed forward network which is formulated as ReLU(Q̃W1 + b1)W2 + b2, (3) where W{1,2} ∈ Rd×d and b{1,2} are parameters. The output of the attention mechanism is defined with the result of Equation (3) after another round of residual connection and layer normalization. For ease of presentation, we denote the entire attention mechanism as fATT (Q,K). Let Uk−1 and Rk−1 be the input of the k-th block where U0 = Eu and R0 = Er, then the self-attention module is defined as Ûk = fATT(U k−1,Uk−1), (4) R̂k = fATT(R k−1,Rk−1). (5) The interaction module first lets Uk−1 and Rk−1 attend to each other by U k = fATT(U k−1,Rk−1), (6) R k = fATT(R k−1,Uk−1). (7) Then Uk−1 and Rk−1 further interact with Uk and Rk respectively, which can be formulated as Ũk = Uk−1 Uk, (8) R̃k = Rk−1 Rk, (9) where denotes element-wise multiplication. Finally, the compression module updates Uk−1 and Rk−1 to Uk and Rk as the output of the block. Suppose that eku,i and e k r,i are the i-th entries of Uk and Rk respectively, then eku,i and e k r,i are calculated by eku,i = ReLU(wp  ek−1u,i êku,i eku,i ẽku,i + bp) + ek−1u,i , (10) ekr,i = ReLU(wp  ek−1r,i êkr,i ekr,i ẽkr,i + bp) + ek−1r,i , (11) where wp ∈ R4d×d and bp are learnable projection weights and biases, êk{u,r},i, e k {u,r},i, ẽ k {u,r},i, and ek−1{u,r},i are the i-th entries of {Û, R̂} k, {U,R}k, {Ũ, R̃}k, and {U,R}k−1, respectively. Inspired by Huang et al. (2017a), we also introduce direct connections from initial representations to all their corresponding subsequent blocks."
    }, {
      "heading" : "4.3 Matching Aggregation",
      "text" : "Suppose that c = (u1, . . . , ul) is a conversation context with ui the i-th utterance, then in the kth interaction block, we construct three similarity\n5 matrices by Mki,1 = Uk−1i · (Rk−1)>√ d , Mki,2 = Ûki · (R̂k)>√ d , Mki,3 = U k i · (R k )>√ d , (12) where Uk−1i and R k−1 are the input of the k-th block, Ûki and R̂ k are defined by Equations (4-5), and Uki and R k are calculated by Equations (6-7). The three matrices are then concatenated into a 3- D matching tensor Tki ∈ Rmi×n×3 which can be written as Tki = M k i,1 ⊕Mki,2 ⊕Mki,3, (13) where ⊕ denotes a concatenation operation, and mi and n refer to numbers of words in ui and r respectively. We exploit a convolutional neural network (Krizhevsky et al., 2012) to extract matching features from Tki . The output of the final feature maps are flattened and mapped to a d-dimensional matching vector vki with a linear transformation. (vk1 , · · · ,vkl ) is then fed to a GRU (Chung et al., 2014) to capture temporal relationship among (u1, . . . , ul). ∀i ∈ {1, . . . , l}, the i-th hidden state of the GRU model is given by hki = GRU(v k i ,h k i−1), (14) where hk0 is randomly initialized. A matching score for context c and response candidate r in the k-th block is defined as gk(c, r) = σ(hkl ·wo + bo), (15) where wo and bo are parameters, and σ(·) is a sigmoid function. Finally, g(c, r) is defined by g(c, r) = L∑ k=1 gk(c, r), (16) where L is the number of interaction blocks in IoI. Note that we define g(c, r) with all blocks rather than only with the last block. This is motivated by (1) only using the last block will make training of IoI difficult due to the gradient vanishing/exploding problem; and (2) different blocks may capture different levels of matching information in (c, r), and thus leveraging all of them could enhance matching accuracy."
    }, {
      "heading" : "5 Learning Methods",
      "text" : "We consider two strategies to learn an IoI model from the training data D. The first strategy estimates the parameters of IoI (denoted as Θ) by minimizing a global loss function that is formulated as − N∑ i=1 [ yi log(g(ci, ri))+(1−yi) log(1−g(ci, ri)) ] . (17) In the second strategy, we construct a local loss function for each block and minimize the summation of the local loss functions. By this means, each block can be directly supervised by the labels in D during learning. The learning objective is then defined as − L∑ k=1 N∑ i=1 [ yi log(g k(ci, ri)) + (1− yi) log(1− gk(ci, ri)) ] . (18) We compare the two learning strategies through empirical studies, as will be reported in the next section. In both strategies, Θ are optimized using back-propagation with Adam algorithm (Kingma and Ba, 2015)."
    }, {
      "heading" : "6 Experiments",
      "text" : "We test the proposed IoI on three benchmark data sets for multi-turn response selection."
    }, {
      "heading" : "6.1 Experimental Setup",
      "text" : "The first data we use is the Ubuntu Dialogue Corpus (Lowe et al., 2015) which is a multi-turn English conversation data set constructed from chat logs of the Ubuntu forum. We use the version provided by Xu et al. (2017). The data contains 1 million context-response pairs for training, and 0.5 million pairs for validation and test. In all the three sets, positive responses are human responses, while negative ones are randomly sampled. The ratio of the positive and the negative is 1:1 in the training set, and 1:9 in both the validation set and the test set. Following Lowe et al. (2015), we employ recall at position k in n candidates (Rn@k) as evaluation metrics. The second data set is the Douban Conversation Corpus (Wu et al., 2017) that consists of multiturn Chinese conversations collected from Douban group1. There are 1 million context-response pairs 1https://www.douban.com/group\n6 for training, 50 thousand pairs for validation, and 6, 670 pairs for testing. In the training set and the validation set, the last turn of each conversation is taken as a positive response and a negative response is randomly sampled. For each context in the test set, 10 response candidates are retrieved from an index and their appropriateness regarding to the context is annotated by human labelers. Following Wu et al. (2017), we employ Rn@ks, mean average precision (MAP), mean reciprocal rank (MRR) and precision at position 1 (P@1) as evaluation metrics. Finally, we choose the E-commerce Dialogue Corpus (Zhang et al., 2018b) as an experimental data set. The data consists of multi-turn realworld conversations between customers and customer service staff in Taobao2, which is the largest e-commerce platform in China. It contains 1 million context-response pairs for training, and 10 thousand pairs for validation and test. Positive responses in this data are real human responses, and negative candidates are automatically constructed by ranking the response corpus based on conversation history augmented messages using Apache Lucene3. The ratio of the positive and the negative is 1:1 in training and validation, and 1:9 in test. Following (Zhang et al., 2018b), we employ R10@1, R10@2, and R10@5 as evaluation metrics."
    }, {
      "heading" : "6.2 Baselines",
      "text" : "We compare IoI with the following models: Single-turn Matching Models: these models, including RNN (Lowe et al., 2015), CNN (Lowe et al., 2015), LSTM (Lowe et al., 2015), BiLSTM (Kadlec et al., 2015), MV-LSTM (Wan et al., 2016) and Match-LSTM (Wang and Jiang, 2016), perform context-response matching by concatenating all utterances in a context into a single long document and calculating a matching score between the document and a response candidate. Multi-View (Zhou et al., 2016): the model calculates matching degree between a context and a response candidate from both a word sequence view and an utterance sequence view. DL2R (Yan et al., 2016): the model first reformulates the last utterance with previous turns in a context with different approaches. A response candidate and the reformulated message are then represented by a composition of RNN and CNN. 2https://www.taobao.com 3http://lucene.apache.org/ Finally, a matching score is computed with the concatenation of the representations. SMN (Wu et al., 2017): the model lets each utterance in a context interact with a response candidate at the beginning, and then transforms interaction matrices into a matching vector with CNN. The matching vectors are finally accumulated with an RNN as a matching score. DUA (Zhang et al., 2018b): the model considers the relationship among utterances within a context by exploiting deep utterance aggregation to form a fine-grained context representation. Each refined utterance then matches with a response candidate, and their matching degree is finally calculated through an aggregation on turns. DAM (Zhou et al., 2018b): the model lets each utterance in a context interact with a response candidate at different levels of representations obtained by a stacked self-attention module and a cross-attention module. For the Ubuntu data and the Douban data, since results of all baselines under fine-tuning are available in Zhou et al. (2018b), we directly copy the numbers from the paper. For the E-commerce data, Zhang et al. (2018b) report performance of all baselines except DAM. Thus, we copy all available numbers from the paper and implement DAM with the published code4. In order to conduct statistical tests, we also run the code of DAM on the Ubuntu data and the Douban data."
    }, {
      "heading" : "6.3 Implementation Details",
      "text" : "In IoI, we set the size of word embedding as 200. For the CNN in matching aggregation, we set the window size of convolution and pooling kernels as (3, 3), and the strides as (1, 1) and (3, 3) respectively. The number of convolution kernels is 32 in the first layer and 16 in the second layer. The dimension of the hidden states of GRU is set as 200. Following Wu et al. (2017), we limit the length of a context to 10 turns and the length of an utterance (either from a context or from a response candidate) to 50 words. Truncation or zero-padding is applied to a context or a response candidate when necessary. We gradually increase the number of interaction blocks (i.e., L) in IoI, and finally set L = 7 in comparison with the baseline models. In optimization, we choose 0.2 as a dropout rate, and 50 as the size of mini-batches. The learning rate is initialized as 0.0005, and exponentially decayed 4 https://github.com/baidu/Dialogue\n7\nduring training."
    }, {
      "heading" : "6.4 Evaluation Results",
      "text" : "Table 1 and Table 2 report evaluation results on the three data sets where IoI-global and IoI-local represent models learned with Objective (17) and Objective (18) respectively. We can see that both IoIlocal and IoI-global outperform the best performing baseline, and improvements from IoI-local on all metrics and from IoI-global on a few metrics are statistically significant (t-test with p-value < 0.05). IoI-local is consistently better than IoIglobal over all metrics on all the three data sets, demonstrating that directly supervising each block in learning can lead to a more optimal deep structure than optimizing the final matching model."
    }, {
      "heading" : "6.5 Discussions",
      "text" : "In this section, we make some further analysis with IoI-local to understand (1) how depth of in-\nteraction affects the performance of IoI; (2) how context length affects the performance of IoI; and (3) importance of different components of IoI with respect to matching accuracy. Impact of interaction depth. Figure 2 illustrates how the performance of IoI changes with respect to the number of interaction blocks on test sets of the three data. From the chart, we observe a consistent trend over the three data sets: there is significant improvement during the first few blocks, and then the performance of the model becomes stable. The results indicate that depth of interaction indeed matters in terms of matching accuracy. With shallow interaction (L = 1), IoI performs worse than DAM on the Douban data and the E-commerce data. Only after the interaction goes deep (L ≥ 5), improvement from IoI\n8\nto DAM on the two data becomes significant. On the Ubuntu data, improvement to DAM from the deep model (L = 7) is more than twice as much as that from the shallow model (L = 1). The performance of IoI becomes stable earlier on the Ubuntu data than it does on the other two data. This may stem from the different nature of test sets of the three data. The test set of the Ubuntu data is in large size and built by random sampling, while the test sets of the other two data are smaller and constructed through response retrieval. Impact of context length. Context length is measured by (1) number of turns in a context and (2) average length of utterances in a context. Figure 3 shows how the performance of IoI varies across contexts with different lengths, where we bin test examples of the Ubuntu data into buckets and compare IoI (L = 7) with its shallow version (L = 1) and DAM. We find that (1) IoI, either in a deep form or in a shallow form, is good at dealing with contexts with long utterances, as the model achieves better performance on longer utterances; (2) overall, IoI performs well on contexts with more turns, although too many turns (e.g., ≥ 8) is still challenging; (3) a deep form of our model is always better than its shallow form, no matter how we measure context length, and the gap between the two forms is bigger on short contexts than it is on long contexts, indicating that depth mainly improves matching accuracy on short contexts; and (4) trends of DAM in both charts are consistent with those reported in (Zhou et al., 2018b), and on both short contexts and long contexts, IoI is superior to DAM. Ablation study. Finally, we examine how different components of IoI affects its performance. First, we remove ek−1u,i (e k−1 r,i ), ê k u,i (ê k r,i), e k u,i (ekr,i), and ẽ k u,i (ẽ k r,i) one by one from Equation (10) and Equation (11), and denote the models as IoI-E, IoI-Ê, IoI-E, and IoI-Ẽ respectively. Then, we keep all representations in Equation (10) and Equation (11), and remove Mki,1, M k i,2, and M k i,3 one by one from Equation (13). The models are named IoI-M1, IoI-M2, and IoI-M3 respectively. Table 3 reports the ablation results5. We conclude that (1) all representations are useful in representing the information flow along the chain of interaction blocks and capturing the matching information between an utterance-response pair within the blocks, as removing any component gener5Due to space limitation, we only report results on main metrics.\n9 ally causes performance drop on all the three data sets; and (2) in terms of component importance, Ê > E > E > Ẽ and M2 > M1 ≈M3, meaning that self-attention (i.e., Ê) and cross-attention (i.e., E) are more important than others in information flow representation, and self-attention (i.e., those used for calculating M2) convey more matching signals. Note that these results are obtained with IoI (L = 7). We also check the ablation results of IoI (L = 1) and do not see much difference on overall trends and relative gaps among different ablated models."
    }, {
      "heading" : "7 Conclusions and Future Work",
      "text" : "We present an interaction-over-interaction network (IoI) that lets utterance-response interaction in context-response matching go deep. Depth of the model comes from stacking multiple interaction blocks that execute representationinteraction-representation in an iterative manner. Evaluation results on three benchmarks indicate that IoI can significantly outperform baseline methods with moderate depth. In the future, we plan to integrate our IoI model with models like ELMo (Peters et al., 2018) and BERT (Devlin et al., 2018) to study if the performance of IoI can be further improved."
    }, {
      "heading" : "Acknowledgement",
      "text" : "We would like to thank the anonymous reviewers for their constructive comments. This work was supported by the National Key Research and Development Program of China (No. 2017YFC0804001), the National Science Foundation of China (NSFC Nos. 61672058 and 61876196)."
    } ],
    "references" : [ {
      "title" : "Layer normalization",
      "author" : [ "Jimmy Lei Ba", "Jamie Ryan Kiros", "Geoffrey E Hinton." ],
      "venue" : "arXiv preprint arXiv:1607.06450.",
      "citeRegEx" : "Ba et al\\.,? 2016",
      "shortCiteRegEx" : "Ba et al\\.",
      "year" : 2016
    }, {
      "title" : "Empirical evaluation of gated recurrent neural networks on sequence modeling",
      "author" : [ "Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1412.3555.",
      "citeRegEx" : "Chung et al\\.,? 2014",
      "shortCiteRegEx" : "Chung et al\\.",
      "year" : 2014
    }, {
      "title" : "Very deep convolutional networks for text classification",
      "author" : [ "Alexis Conneau", "Holger Schwenk", "Loı̈c Barrault", "Yann Lecun" ],
      "venue" : "In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume",
      "citeRegEx" : "Conneau et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2017
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Deep residual learning for image recognition",
      "author" : [ "Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun." ],
      "venue" : "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770– 778.",
      "citeRegEx" : "He et al\\.,? 2016",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2016
    }, {
      "title" : "Convolutional neural network architectures for matching natural language sentences",
      "author" : [ "Baotian Hu", "Zhengdong Lu", "Hang Li", "Qingcai Chen." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 2042–2050.",
      "citeRegEx" : "Hu et al\\.,? 2014",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2014
    }, {
      "title" : "Densely connected convolutional networks",
      "author" : [ "Gao Huang", "Zhuang Liu", "Laurens Van Der Maaten", "Kilian Q Weinberger." ],
      "venue" : "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4700–4708.",
      "citeRegEx" : "Huang et al\\.,? 2017a",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2017
    }, {
      "title" : "FusionNet: Fusing via fullyaware attention with application to machine comprehension",
      "author" : [ "Hsin-Yuan Huang", "Chenguang Zhu", "Yelong Shen", "Weizhu Chen." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Huang et al\\.,? 2017b",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2017
    }, {
      "title" : "Improved deep learning baselines for ubuntu corpus dialogs",
      "author" : [ "Rudolf Kadlec", "Martin Schmid", "Jan Kleindienst." ],
      "venue" : "arXiv preprint arXiv:1510.03753.",
      "citeRegEx" : "Kadlec et al\\.,? 2015",
      "shortCiteRegEx" : "Kadlec et al\\.",
      "year" : 2015
    }, {
      "title" : "Semantic sentence matching with densely-connected recurrent and co-attentive information",
      "author" : [ "Seonhoon Kim", "Jin-Hyuk Hong", "Inho Kang", "Nojun Kwak." ],
      "venue" : "arXiv preprint arXiv:1805.11360.",
      "citeRegEx" : "Kim et al\\.,? 2018",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2018
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton." ],
      "venue" : "Advances in neural information processing systems, pages 1097–1105.",
      "citeRegEx" : "Krizhevsky et al\\.,? 2012",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "2017a. AliMe assist: An intelligent assistant for creating an innovative e-commerce experience",
      "author" : [ "Feng-Lin Li", "Minghui Qiu", "Haiqing Chen", "Xiongwei Wang", "Xing Gao", "Jun Huang", "Juwei Ren", "Zhongzhou Zhao", "Weipeng Zhao", "Lei Wang" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Li et al\\.,? 2015",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2015
    }, {
      "title" : "A persona-based neural conversation model",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Georgios Spithourakis", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Association for Computational Linguistics, pages 994– 1003.",
      "citeRegEx" : "Li et al\\.,? 2016a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep reinforcement learning for dialogue generation",
      "author" : [ "Jiwei Li", "Will Monroe", "Alan Ritter", "Dan Jurafsky", "Michel Galley", "Jianfeng Gao." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1192–",
      "citeRegEx" : "Li et al\\.,? 2016b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Adversarial learning for neural dialogue generation",
      "author" : [ "Jiwei Li", "Will Monroe", "Tianlin Shi", "Sėbastien Jean", "Alan Ritter", "Dan Jurafsky." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2157–2169.",
      "citeRegEx" : "Li et al\\.,? 2017b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems",
      "author" : [ "Ryan Lowe", "Nissan Pow", "Iulian Serban", "Joelle Pineau." ],
      "venue" : "Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse",
      "citeRegEx" : "Lowe et al\\.,? 2015",
      "shortCiteRegEx" : "Lowe et al\\.",
      "year" : 2015
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean." ],
      "venue" : "Advances in neural information processing systems, pages 3111–3119.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation",
      "author" : [ "Lili Mou", "Yiping Song", "Rui Yan", "Ge Li", "Lu Zhang", "Zhi Jin." ],
      "venue" : "Proceedings of COLING 2016, the 26th International Confer-",
      "citeRegEx" : "Mou et al\\.,? 2016",
      "shortCiteRegEx" : "Mou et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew E Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Associ-",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "End-to-end dialogue systems using generative hierarchical neural network models",
      "author" : [ "Iulian Vlad Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron C. Courville", "Joelle Pineau." ],
      "venue" : "AAAI, pages 3776–3784.",
      "citeRegEx" : "Serban et al\\.,? 2016",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural responding machine for short-text conversation",
      "author" : [ "Lifeng Shang", "Zhengdong Lu", "Hang Li." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural",
      "citeRegEx" : "Shang et al\\.,? 2015",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2015
    }, {
      "title" : "From Eliza to XiaoIce: Challenges and opportunities with social chatbots",
      "author" : [ "Heung-Yeung Shum", "Xiaodong He", "Di Li." ],
      "venue" : "Frontiers of IT & EE, 19(1):10–26.",
      "citeRegEx" : "Shum et al\\.,? 2018",
      "shortCiteRegEx" : "Shum et al\\.",
      "year" : 2018
    }, {
      "title" : "An ensemble of retrieval-based and generation-based humancomputer conversation systems",
      "author" : [ "Yiping Song", "Rui Yan", "Cheng-Te Li", "Jian-Yun Nie", "Ming Zhang", "Dongyan Zhao." ],
      "venue" : "IJCAI, pages 4382–4388.",
      "citeRegEx" : "Song et al\\.,? 2018",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2018
    }, {
      "title" : "Going deeper with convolutions",
      "author" : [ "Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich." ],
      "venue" : "Proceedings of the IEEE conference on computer vi-",
      "citeRegEx" : "Szegedy et al\\.,? 2015",
      "shortCiteRegEx" : "Szegedy et al\\.",
      "year" : 2015
    }, {
      "title" : "Get the point of my utterance! learning towards effective responses with multi-head attention mechanism",
      "author" : [ "Chongyang Tao", "Shen Gao", "Mingyue Shang", "Wei Wu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "IJCAI, pages 4418–4424.",
      "citeRegEx" : "Tao et al\\.,? 2018",
      "shortCiteRegEx" : "Tao et al\\.",
      "year" : 2018
    }, {
      "title" : "Co-stack residual affinity networks with multi-level attention refinement for matching text sequences",
      "author" : [ "Yi Tay", "Luu Anh Tuan", "Siu Cheung Hui." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Tay et al\\.,? 2018",
      "shortCiteRegEx" : "Tay et al\\.",
      "year" : 2018
    }, {
      "title" : "A neural conversational model",
      "author" : [ "Oriol Vinyals", "Quoc Le." ],
      "venue" : "arXiv preprint arXiv:1506.05869.",
      "citeRegEx" : "Vinyals and Le.,? 2015",
      "shortCiteRegEx" : "Vinyals and Le.",
      "year" : 2015
    }, {
      "title" : "Match-srnn: Modeling the recursive matching structure with spatial rnn",
      "author" : [ "Shengxian Wan", "Yanyan Lan", "Jun Xu", "Jiafeng Guo", "Liang Pang", "Xueqi Cheng." ],
      "venue" : "IJCAI, pages 2922–2928.",
      "citeRegEx" : "Wan et al\\.,? 2016",
      "shortCiteRegEx" : "Wan et al\\.",
      "year" : 2016
    }, {
      "title" : "A dataset for research on short-text conversations",
      "author" : [ "Hao Wang", "Zhengdong Lu", "Hang Li", "Enhong Chen." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 935–945.",
      "citeRegEx" : "Wang et al\\.,? 2013",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2013
    }, {
      "title" : "Syntax-based deep matching of short texts",
      "author" : [ "Mingxuan Wang", "Zhengdong Lu", "Hang Li", "Qun Liu." ],
      "venue" : "Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, pages 1354–1361.",
      "citeRegEx" : "Wang et al\\.,? 2015",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning natural language inference with LSTM",
      "author" : [ "Shuohang Wang", "Jing Jiang." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages",
      "citeRegEx" : "Wang and Jiang.,? 2016",
      "shortCiteRegEx" : "Wang and Jiang.",
      "year" : 2016
    }, {
      "title" : "Learning matching models with weak supervision for response selection in retrieval-based chatbots",
      "author" : [ "Yu Wu", "Wei Wu", "Zhoujun Li", "Ming Zhou." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2:",
      "citeRegEx" : "Wu et al\\.,? 2018a",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2018
    }, {
      "title" : "A sequential matching framework for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Yu Wu", "Wei Wu", "Chen Xing", "Can Xu", "Zhoujun Li", "Ming Zhou." ],
      "venue" : "Computational Linguistics, 45(1):163–197.",
      "citeRegEx" : "Wu et al\\.,? 2018b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2018
    }, {
      "title" : "Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Yu Wu", "Wei Wu", "Chen Xing", "Ming Zhou", "Zhoujun Li." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Wu et al\\.,? 2017",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2017
    }, {
      "title" : "Topic aware neural response generation",
      "author" : [ "Chen Xing", "Wei Wu", "Yu Wu", "Jie Liu", "Yalou Huang", "Ming Zhou", "Wei-Ying Ma." ],
      "venue" : "AAAI, pages 3351– 3357.",
      "citeRegEx" : "Xing et al\\.,? 2017",
      "shortCiteRegEx" : "Xing et al\\.",
      "year" : 2017
    }, {
      "title" : "Incorporating loosestructured knowledge into LSTM with recall gate for conversation modeling",
      "author" : [ "Zhen Xu", "Bingquan Liu", "Baoxun Wang", "Chengjie Sun", "Xiaolong Wang." ],
      "venue" : "Proceedings of the 2017 International Joint Conference on Neural Networks,",
      "citeRegEx" : "Xu et al\\.,? 2017",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2017
    }, {
      "title" : "Learning to respond with deep neural networks for retrievalbased human-computer conversation system",
      "author" : [ "Rui Yan", "Yiping Song", "Hua Wu." ],
      "venue" : "SIGIR, pages 55–64.",
      "citeRegEx" : "Yan et al\\.,? 2016",
      "shortCiteRegEx" : "Yan et al\\.",
      "year" : 2016
    }, {
      "title" : "Coupled context modeling for deep chit-chat: towards conversations between human and computer",
      "author" : [ "Rui Yan", "Dongyan Zhao." ],
      "venue" : "Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 2574–",
      "citeRegEx" : "Yan and Zhao.,? 2018",
      "shortCiteRegEx" : "Yan and Zhao.",
      "year" : 2018
    }, {
      "title" : "Personalizing dialogue agents: I have a dog, do you have pets too",
      "author" : [ "Saizheng Zhang", "Emily Dinan", "Jack Urbanek", "Arthur Szlam", "Douwe Kiela", "Jason Weston" ],
      "venue" : "In Proceedings of the 56th Annual Meeting of the Association",
      "citeRegEx" : "Zhang et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Modeling multiturn conversation with deep utterance aggregation",
      "author" : [ "Zhuosheng Zhang", "Jiangtong Li", "Pengfei Zhu", "Hai Zhao", "Gongshen Liu." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 3740–3752.",
      "citeRegEx" : "Zhang et al\\.,? 2018b",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning discourse-level diversity for neural dialog models using conditional variational autoencoders",
      "author" : [ "Tiancheng Zhao", "Ran Zhao", "Maxine Eskenazi." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Zhao et al\\.,? 2017",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2017
    }, {
      "title" : "Emotional chatting machine: Emotional conversation generation with internal and external memory",
      "author" : [ "Hao Zhou", "Minlie Huang", "Tianyang Zhang", "Xiaoyan Zhu", "Bing Liu." ],
      "venue" : "The Thirty-Second AAAI Conference on Artificial Intelligence, pages",
      "citeRegEx" : "Zhou et al\\.,? 2018a",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    }, {
      "title" : "Multi-view response selection for human-computer conversation",
      "author" : [ "Xiangyang Zhou", "Daxiang Dong", "Hua Wu", "Shiqi Zhao", "Dianhai Yu", "Hao Tian", "Xuan Liu", "Rui Yan." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Zhou et al\\.,? 2016",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2016
    }, {
      "title" : "Multi-turn response selection for chatbots with deep attention matching network",
      "author" : [ "Xiangyang Zhou", "Lu Li", "Daxiang Dong", "Yi Liu", "Ying Chen", "Wayne Xin Zhao", "Dianhai Yu", "Hua Wu." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association",
      "citeRegEx" : "Zhou et al\\.,? 2018b",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "The first approach leverages techniques of information retrieval (Lowe et al., 2015; Wu et al., 2017; Yan and Zhao, 2018), and selects a proper response from an index; while the second approach directly synthesizes a response with a natural lan-",
      "startOffset" : 65,
      "endOffset" : 121
    }, {
      "referenceID" : 35,
      "context" : "The first approach leverages techniques of information retrieval (Lowe et al., 2015; Wu et al., 2017; Yan and Zhao, 2018), and selects a proper response from an index; while the second approach directly synthesizes a response with a natural lan-",
      "startOffset" : 65,
      "endOffset" : 121
    }, {
      "referenceID" : 39,
      "context" : "The first approach leverages techniques of information retrieval (Lowe et al., 2015; Wu et al., 2017; Yan and Zhao, 2018), and selects a proper response from an index; while the second approach directly synthesizes a response with a natural lan-",
      "startOffset" : 65,
      "endOffset" : 121
    }, {
      "referenceID" : 21,
      "context" : "guage generation model estimated from a largescale conversation corpus (Serban et al., 2016; Li et al., 2017b).",
      "startOffset" : 71,
      "endOffset" : 110
    }, {
      "referenceID" : 16,
      "context" : "guage generation model estimated from a largescale conversation corpus (Serban et al., 2016; Li et al., 2017b).",
      "startOffset" : 71,
      "endOffset" : 110
    }, {
      "referenceID" : 23,
      "context" : "Compared with generation-based methods, retrieval-based methods are superior in terms of response fluency and diversity, and thus have been widely applied in commercial chatbots such as the social bot XiaoIce (Shum et al., 2018) from Microsoft, and the e-commerce assistant AliMe Assist from Alibaba Group (Li et al.",
      "startOffset" : 209,
      "endOffset" : 228
    }, {
      "referenceID" : 35,
      "context" : "Stateof-the-art methods (Wu et al., 2017; Zhou et al., 2018b) perform matching within a representationinteraction-aggregation framework (Wu et al.",
      "startOffset" : 24,
      "endOffset" : 61
    }, {
      "referenceID" : 45,
      "context" : "Stateof-the-art methods (Wu et al., 2017; Zhou et al., 2018b) perform matching within a representationinteraction-aggregation framework (Wu et al.",
      "startOffset" : 24,
      "endOffset" : 61
    }, {
      "referenceID" : 34,
      "context" : ", 2018b) perform matching within a representationinteraction-aggregation framework (Wu et al., 2018b) where matching signals in each utteranceresponse pair are distilled from their interaction based on their representations, and then are aggregated as a matching score.",
      "startOffset" : 83,
      "endOffset" : 101
    }, {
      "referenceID" : 35,
      "context" : "Although utteranceresponse interaction has proven to be crucial to the performance of the matching models (Wu et al., 2017), it is executed in a rather shallow manner where matching between an utterance and a response candidate is determined only by one step of interaction on each type or each layer of representations.",
      "startOffset" : 106,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "We conduct experiments on three benchmark data sets: the Ubuntu Dialogue Corpus (Lowe et al., 2015), the Douban Conversation Corpus (Wu et al.",
      "startOffset" : 80,
      "endOffset" : 99
    }, {
      "referenceID" : 35,
      "context" : ", 2015), the Douban Conversation Corpus (Wu et al., 2017), and the E-commerce Dialogue Corpus (Zhang et al.",
      "startOffset" : 40,
      "endOffset" : 57
    }, {
      "referenceID" : 41,
      "context" : ", 2017), and the E-commerce Dialogue Corpus (Zhang et al., 2018b).",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 28,
      "context" : "On top of the basic sequence-to-sequence with attention architecture (Vinyals and Le, 2015; Shang et al., 2015; Tao et al., 2018), various extensions have been made to tackle the “safe response” problem (Li et al.",
      "startOffset" : 69,
      "endOffset" : 129
    }, {
      "referenceID" : 22,
      "context" : "On top of the basic sequence-to-sequence with attention architecture (Vinyals and Le, 2015; Shang et al., 2015; Tao et al., 2018), various extensions have been made to tackle the “safe response” problem (Li et al.",
      "startOffset" : 69,
      "endOffset" : 129
    }, {
      "referenceID" : 26,
      "context" : "On top of the basic sequence-to-sequence with attention architecture (Vinyals and Le, 2015; Shang et al., 2015; Tao et al., 2018), various extensions have been made to tackle the “safe response” problem (Li et al.",
      "startOffset" : 69,
      "endOffset" : 129
    }, {
      "referenceID" : 13,
      "context" : ", 2018), various extensions have been made to tackle the “safe response” problem (Li et al., 2015; Mou et al., 2016; Xing et al., 2017; Zhao et al., 2017; Song et al., 2018); to generate responses with specific personas or emotions (Li et al.",
      "startOffset" : 81,
      "endOffset" : 173
    }, {
      "referenceID" : 19,
      "context" : ", 2018), various extensions have been made to tackle the “safe response” problem (Li et al., 2015; Mou et al., 2016; Xing et al., 2017; Zhao et al., 2017; Song et al., 2018); to generate responses with specific personas or emotions (Li et al.",
      "startOffset" : 81,
      "endOffset" : 173
    }, {
      "referenceID" : 36,
      "context" : ", 2018), various extensions have been made to tackle the “safe response” problem (Li et al., 2015; Mou et al., 2016; Xing et al., 2017; Zhao et al., 2017; Song et al., 2018); to generate responses with specific personas or emotions (Li et al.",
      "startOffset" : 81,
      "endOffset" : 173
    }, {
      "referenceID" : 42,
      "context" : ", 2018), various extensions have been made to tackle the “safe response” problem (Li et al., 2015; Mou et al., 2016; Xing et al., 2017; Zhao et al., 2017; Song et al., 2018); to generate responses with specific personas or emotions (Li et al.",
      "startOffset" : 81,
      "endOffset" : 173
    }, {
      "referenceID" : 24,
      "context" : ", 2018), various extensions have been made to tackle the “safe response” problem (Li et al., 2015; Mou et al., 2016; Xing et al., 2017; Zhao et al., 2017; Song et al., 2018); to generate responses with specific personas or emotions (Li et al.",
      "startOffset" : 81,
      "endOffset" : 173
    }, {
      "referenceID" : 14,
      "context" : ", 2018); to generate responses with specific personas or emotions (Li et al., 2016a; Zhang et al., 2018a; Zhou et al., 2018a); and to pursue better optimization strategies (Li et al.",
      "startOffset" : 66,
      "endOffset" : 125
    }, {
      "referenceID" : 43,
      "context" : ", 2018); to generate responses with specific personas or emotions (Li et al., 2016a; Zhang et al., 2018a; Zhou et al., 2018a); and to pursue better optimization strategies (Li et al.",
      "startOffset" : 66,
      "endOffset" : 125
    }, {
      "referenceID" : 30,
      "context" : "Along this line, the focus of research starts from single-turn response selection by setting the human input as a single message (Wang et al., 2013; Hu et al., 2014; Wang et al., 2015), and moves to context-response matching for multi-turn response selection recently.",
      "startOffset" : 129,
      "endOffset" : 184
    }, {
      "referenceID" : 5,
      "context" : "Along this line, the focus of research starts from single-turn response selection by setting the human input as a single message (Wang et al., 2013; Hu et al., 2014; Wang et al., 2015), and moves to context-response matching for multi-turn response selection recently.",
      "startOffset" : 129,
      "endOffset" : 184
    }, {
      "referenceID" : 31,
      "context" : "Along this line, the focus of research starts from single-turn response selection by setting the human input as a single message (Wang et al., 2013; Hu et al., 2014; Wang et al., 2015), and moves to context-response matching for multi-turn response selection recently.",
      "startOffset" : 129,
      "endOffset" : 184
    }, {
      "referenceID" : 17,
      "context" : "Representative methods include the dual LSTM model (Lowe et al., 2015), the deep learning to respond architecture (Yan et al.",
      "startOffset" : 51,
      "endOffset" : 70
    }, {
      "referenceID" : 38,
      "context" : ", 2015), the deep learning to respond architecture (Yan et al., 2016), the multi-view matching model (Zhou et al.",
      "startOffset" : 51,
      "endOffset" : 69
    }, {
      "referenceID" : 44,
      "context" : ", 2016), the multi-view matching model (Zhou et al., 2016), the sequential matching network (Wu et al.",
      "startOffset" : 39,
      "endOffset" : 58
    }, {
      "referenceID" : 45,
      "context" : ", 2017, 2018b), and the deep attention matching network (Zhou et al., 2018b).",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 33,
      "context" : "Besides model design, some attention is also paid to the learning problem of matching models (Wu et al., 2018a).",
      "startOffset" : 93,
      "endOffset" : 111
    }, {
      "referenceID" : 4,
      "context" : "Encouraged by the big success of deep neural architectures such as Resnet (He et al., 2016) and inception (Szegedy et al.",
      "startOffset" : 74,
      "endOffset" : 91
    }, {
      "referenceID" : 25,
      "context" : ", 2016) and inception (Szegedy et al., 2015) in computer vision, researchers have studied if they can achieve similar results with deep neural networks on NLP tasks.",
      "startOffset" : 22,
      "endOffset" : 44
    }, {
      "referenceID" : 2,
      "context" : "Although deep models have not yet brought breakthroughs to NLP as they do to computer vision, they have proven effective in a few tasks such as text classification (Conneau et al., 2017), natural language inference (Kim et al.",
      "startOffset" : 164,
      "endOffset" : 186
    }, {
      "referenceID" : 9,
      "context" : ", 2017), natural language inference (Kim et al., 2018; Tay et al., 2018), and question answering (Tay et al.",
      "startOffset" : 36,
      "endOffset" : 72
    }, {
      "referenceID" : 27,
      "context" : ", 2017), natural language inference (Kim et al., 2018; Tay et al., 2018), and question answering (Tay et al.",
      "startOffset" : 36,
      "endOffset" : 72
    }, {
      "referenceID" : 27,
      "context" : ", 2018), and question answering (Tay et al., 2018; Kim et al., 2018), etc.",
      "startOffset" : 32,
      "endOffset" : 68
    }, {
      "referenceID" : 9,
      "context" : ", 2018), and question answering (Tay et al., 2018; Kim et al., 2018), etc.",
      "startOffset" : 32,
      "endOffset" : 68
    }, {
      "referenceID" : 18,
      "context" : "4 are obtained by pre-training Word2vec (Mikolov et al., 2013) on D.",
      "startOffset" : 40,
      "endOffset" : 62
    }, {
      "referenceID" : 7,
      "context" : "Here, we exploit the symmetric function in (Huang et al., 2017b) as S(·, ·) which is given by:",
      "startOffset" : 43,
      "endOffset" : 64
    }, {
      "referenceID" : 4,
      "context" : "A residual connection (He et al., 2016) and a layer normalization (Ba et al.",
      "startOffset" : 22,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : ", 2016) and a layer normalization (Ba et al., 2016) are then applied to Q̂ as Q̃.",
      "startOffset" : 34,
      "endOffset" : 51
    }, {
      "referenceID" : 11,
      "context" : "We exploit a convolutional neural network (Krizhevsky et al., 2012) to extract matching features from Ti .",
      "startOffset" : 42,
      "endOffset" : 67
    }, {
      "referenceID" : 1,
      "context" : "(vk 1 , · · · ,vk l ) is then fed to a GRU (Chung et al., 2014) to capture temporal relationship among",
      "startOffset" : 43,
      "endOffset" : 63
    }, {
      "referenceID" : 10,
      "context" : "In both strategies, Θ are optimized using back-propagation with Adam algorithm (Kingma and Ba, 2015).",
      "startOffset" : 79,
      "endOffset" : 100
    }, {
      "referenceID" : 17,
      "context" : "The first data we use is the Ubuntu Dialogue Corpus (Lowe et al., 2015) which is a multi-turn English conversation data set constructed from chat logs of the Ubuntu forum.",
      "startOffset" : 52,
      "endOffset" : 71
    }, {
      "referenceID" : 35,
      "context" : "The second data set is the Douban Conversation Corpus (Wu et al., 2017) that consists of multiturn Chinese conversations collected from Douban group1.",
      "startOffset" : 54,
      "endOffset" : 71
    }, {
      "referenceID" : 41,
      "context" : "Finally, we choose the E-commerce Dialogue Corpus (Zhang et al., 2018b) as an experimental data set.",
      "startOffset" : 50,
      "endOffset" : 71
    }, {
      "referenceID" : 41,
      "context" : "Following (Zhang et al., 2018b), we employ R10@1, R10@2, and R10@5 as evaluation metrics.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 17,
      "context" : "Single-turn Matching Models: these models, including RNN (Lowe et al., 2015), CNN (Lowe et al.",
      "startOffset" : 57,
      "endOffset" : 76
    }, {
      "referenceID" : 17,
      "context" : ", 2015), LSTM (Lowe et al., 2015), BiLSTM (Kadlec et al.",
      "startOffset" : 14,
      "endOffset" : 33
    }, {
      "referenceID" : 8,
      "context" : ", 2015), BiLSTM (Kadlec et al., 2015), MV-LSTM (Wan et al.",
      "startOffset" : 16,
      "endOffset" : 37
    }, {
      "referenceID" : 29,
      "context" : ", 2015), MV-LSTM (Wan et al., 2016) and Match-LSTM (Wang and Jiang, 2016), perform context-response matching by concatenating all utterances in a context into a single long document and calculating a matching score between the document and a response candidate.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 32,
      "context" : ", 2016) and Match-LSTM (Wang and Jiang, 2016), perform context-response matching by concatenating all utterances in a context into a single long document and calculating a matching score between the document and a response candidate.",
      "startOffset" : 23,
      "endOffset" : 45
    }, {
      "referenceID" : 44,
      "context" : "Multi-View (Zhou et al., 2016): the model calculates matching degree between a context and a response candidate from both a word sequence view and an utterance sequence view.",
      "startOffset" : 11,
      "endOffset" : 30
    }, {
      "referenceID" : 38,
      "context" : "DL2R (Yan et al., 2016): the model first reformulates the last utterance with previous turns in a context with different approaches.",
      "startOffset" : 5,
      "endOffset" : 23
    }, {
      "referenceID" : 35,
      "context" : "SMN (Wu et al., 2017): the model lets each utterance in a context interact with a response candidate at the beginning, and then transforms interaction matrices into a matching vector with CNN.",
      "startOffset" : 4,
      "endOffset" : 21
    }, {
      "referenceID" : 41,
      "context" : "DUA (Zhang et al., 2018b): the model considers the relationship among utterances within a context by exploiting deep utterance aggregation to form a fine-grained context representation.",
      "startOffset" : 4,
      "endOffset" : 25
    }, {
      "referenceID" : 45,
      "context" : "DAM (Zhou et al., 2018b): the model lets each utterance in a context interact with a response candidate at different levels of representations obtained by a stacked self-attention module and a cross-attention module.",
      "startOffset" : 4,
      "endOffset" : 24
    }, {
      "referenceID" : 17,
      "context" : "7 Models Metrics Ubuntu Corpus Douban Corpus R2@1 R10@1 R10@2 R10@5 MAP MRR P@1 R10@1 R10@2 R10@5 RNN (Lowe et al., 2015) 0.",
      "startOffset" : 102,
      "endOffset" : 121
    }, {
      "referenceID" : 45,
      "context" : ", ≥ 8) is still challenging; (3) a deep form of our model is always better than its shallow form, no matter how we measure context length, and the gap between the two forms is bigger on short contexts than it is on long contexts, indicating that depth mainly improves matching accuracy on short contexts; and (4) trends of DAM in both charts are consistent with those reported in (Zhou et al., 2018b), and on both short contexts and long contexts, IoI is superior to DAM.",
      "startOffset" : 380,
      "endOffset" : 400
    }, {
      "referenceID" : 20,
      "context" : "In the future, we plan to integrate our IoI model with models like ELMo (Peters et al., 2018) and BERT (Devlin et al.",
      "startOffset" : 72,
      "endOffset" : 93
    }, {
      "referenceID" : 3,
      "context" : ", 2018) and BERT (Devlin et al., 2018) to study if the performance of IoI can be further improved.",
      "startOffset" : 17,
      "endOffset" : 38
    } ],
    "year" : 2019,
    "abstractText" : "Currently, researchers have paid great attention to retrieval-based dialogues in opendomain. In particular, people study the problem by investigating context-response matching for multi-turn response selection based on publicly recognized benchmark data sets. State-of-the-art methods require a response to interact with each utterance in a context from the beginning, but the interaction is performed in a shallow way. In this work, we let utterance-response interaction go deep by proposing an interaction-over-interaction network (IoI). The model performs matching by stacking multiple interaction blocks in which residual information from one time of interaction initiates the interaction process again. Thus, matching information within an utterance-response pair is extracted from the interaction of the pair in an iterative fashion, and the information flows along the chain of the blocks via representations. Evaluation results on three benchmark data sets indicate that IoI can significantly outperform state-of-theart methods in terms of various matching metrics. Through further analysis, we also unveil how the depth of interaction affects the performance of IoI.",
    "creator" : "LaTeX with hyperref package"
  }
}