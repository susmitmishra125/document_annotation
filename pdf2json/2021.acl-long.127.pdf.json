{
  "name" : "2021.acl-long.127.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Stance Detection in COVID-19 Tweets",
    "authors" : [ "Kyle Glandt", "Sarthak Khanal", "Yingjie Li", "Doina Caragea", "Cornelia Caragea" ],
    "emails" : [ "kglandt@ksu.edu", "sarthakk@ksu.edu", "dcaragea@ksu.edu", "yli300@uic.edu", "cornelia@uic.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1596–1611\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n1596"
    }, {
      "heading" : "1 Introduction",
      "text" : "We live in unprecedented times caused by a global COVID-19 pandemic, which has forced major changes in our daily lives. Given the developments concerning COVID-19, communities and governments need to take appropriate action to mitigate the effects of the novel coronavirus, which is at the root of the pandemic. For example, states in the United States that have imposed strict social distancing mandates were able to slow the growth of the virus within their communities (Courtemanche et al., 2020). For such measures to work, however, it is important that the public fully adhere to these guidelines and mandates. “Pandemic fatigue,” or when people become tired of pandemic mandates and begin to ease in adherence, can lead to\n1https://github.com/kglandt/ stance-detection-in-covid-19-tweets\nresurgences of the novel coronavirus (Feuer and Rattner, 2020). To reduce the spread of COVID-19, it is essential to understand the public’s opinion on the various initiatives, such as stay at home orders, wearing a face mask in public, school closures, etc. Understanding how the public feels about these mandates could help health officials better estimate the expected efficacy of their mandates, as well as detect pandemic fatigue before it leads to a serious resurgence of the virus.\nIn the era of Web 2.0, and especially during a pandemic in which people often resort to online communications, social media platforms provide an astounding amount of data relating to the stance and views held by various populations with respect to a variety of current and important topics. However, the total amount of data that is being generated each second makes it impossible for humans alone to fully make use of them. Fortunately, recent developments in deep learning have yielded stateof-the-art performance in text classification.This makes deep learning an ideal solution for extracting and making sense of the large amounts of data currently in circulation on social media sites.\nIn particular, given the current events, it is evident that automated approaches for detecting the stance of the population towards targets, such as health mandates related to COVID-19, using Twitter posts, or tweets, can help gauge the level of cooperation with the mandates. Stance detection is a natural language processing (NLP) task in which the goal is for a machine to learn how to automatically determine from text alone an author’s stance, or perspective/view, towards a controversial topic, or target. Research in the area of stance detection has yielded accurate results, especially in the United States politics (Mohammad et al., 2017; Ghosh et al., 2019; Xu et al., 2020). However, research on stance detection for targets relevant to COVID-19 health mandates lags behind, due to the\nrecency of the pandemic and a lack of benchmark datasets. We set out to address this problem by constructing a COVID-19 stance detection dataset (called COVID-19-Stance), which includes tweets that express views towards four targets, specifically “Anthony S. Fauci, M.D.”, “Keeping Schools Closed”, “Stay at Home Orders”, and “Wearing a Face Mask.” This is a challenging task, which is related but different from sentiment analysis. A tweet may express support for a target, while using a negative language, and expressing a negative sentiment overall. Furthermore, the opinion expressed in a tweet may not be explicitly towards the target of interest, while the stance can be implicitly inferred. Some examples of tweet/target pairs labeled with respect to stance, target of opinion and sentiment are shown in Table 1 to illustrate the above mentioned challenges.\nTo address the stance detection task, carefully designed approaches are needed to extract language patterns informative with respect to stance. We provide a comprehensive set of baseline results for the newly constructed COVID-19-Stance dataset, including results with established supervised baselines for stance detection tasks, and also baselines that employ approaches for handling small amounts of labeled data, including self-training and domain adaptation approaches. In summary, the contributions of this work are as follows:\n• We construct a COVID-19-Stance dataset that consists of 6,133 tweets covering user’s stance towards four targets relevant to COVID-19 health mandates. The tweets are manually annotated for stance according to three categories: in-favor, against, and neither.\n• We establish baseline results using state-ofthe-art supervised stance detection models, including transformer-based models.\n• We also establish baselines for self-training and domain adaptation approaches that use unlabeled data from the current task, or labeled data from a related task, to complement for limited labeled data for the current task."
    }, {
      "heading" : "2 Related Work",
      "text" : "We discuss related work in terms of existing datasets and approaches for stance detection."
    }, {
      "heading" : "2.1 Stance Detection Datasets",
      "text" : "Recent work on stance detection in social media data has been facilitated by Mohammad et al. (2016, 2017), who constructed a manually annotated stance detection dataset, shared publicly as SemEval2016 Task 6. The dataset was based on tweets about United States politics, collected during the lead up to the United States 2016 presidential election. Given a set of politics-relevant targets (e.g., politicians, feminism, climate change), the initial selection of tweets to be included in the dataset was done using “query hashtags”, which are Twitter hashtags within a manually curated shortlist that had been observed to correlate stances and targets on Twitter. Subsequently, tweet/target pairs were annotated by CrowdFlower2 workers, who were provided with a generic, but detailed questionnaire regarding the stance of a tweet’s author toward a target, as well as the sentiment of the tweet (Mohammad et al., 2016, 2017).\nSeveral other datasets for stance detection have become available in the last few years, including a large dataset (containing approximately 50,000 tweets) focused on the stance towards financial transactions that involve mergers and acquisition (Conforti et al., 2020), a dataset for identifying the stance in Twitter replies and quotes (Villa-Cox\n2http://www.crowdflower.com/\net al., 2020), datasets in languages different from English (Hercig et al., 2017; Vychegzhanin and Kotelnikov, 2019; Evrard et al., 2020), and multilingual datasets (Zotova et al., 2020; Vamvas and Sennrich, 2020; Lai et al., 2020).\nFurthermore, the global prevalence and impact of the COVID-19 pandemic has led to the quick development, concurrently with our work, of several COVID-19 stance-related Twitter datasets (Mutlu et al., 2020; Miao et al., 2020; Hossain et al., 2020). Mutlu et al. (2020) published a dataset of approximately 14,000 tweets (called COVID-CQ), which were manually annotated with respect to the author’s stance regarding the use of hydroxychloroquine in the treatment of COVID-19 patients. Miao et al. (2020) constructed a dataset focused on author’s stance towards lockdown regulations in New York City. The authors used keywords related to “lockdown” and “New York City” and extracted approximately 31,000 relevant tweets from a large COVID-19 tweet dataset published by Chen et al. (2020). They manually annotated 1629 tweet with respect to stance, while the remaining tweets were used as unlabeled.\nOur dataset construction procedure is similar to the one followed by Miao et al. (2020), but we label data for four targets using global English tweets, as opposed to Miao et al. (2020) who label data for just one target (“lockdown”) in one location (“New York City”)."
    }, {
      "heading" : "2.2 Stance Detection Approaches",
      "text" : "In terms of approaches used for stance detection, strong baseline results based on support vector machines (SVM) with manually engineered features were provided for the SemEval2016 Task 6 by Mohammad et al. (2016, 2017). Deep learning approaches used in SemEval2016 Task 6 included recurrent neural networks (RNNs) (Zarrella and Marsh, 2016) and convolutional neural networks (CNNs) (Vijayaraghavan et al., 2016; Wei et al., 2016). Such approaches used the tweets as input, but did not use any target-specific information, and did not outperform the SVM baselines. Later approaches were provided with both target and tweet representations as input, and employed RNNs and/or CNNs, together with the attention mechanism (Augenstein et al., 2016; Du et al., 2017; Zhou and Cristea, 2017; Sun et al., 2018; Siddiqua et al., 2019) to improve the performance of the SVM baselines.\nGiven the dominance of transformers (Vaswani et al., 2017), especially bidirectional encoder representations from transformers (BERT) (Devlin et al., 2019), in NLP tasks, some recent works (Slovikovskaya and Attardi, 2020; Li and Caragea, 2021; Ghosh et al., 2019) have focused on investigating the use of BERT models for stance detection. For example, Ghosh et al. (2019) explored the reproducibility of approaches for stance detection and compared them to BERT. They found BERT to be the best model overall for stance detection on the SemEval2016 Task 6. Li and Caragea (2021) also explored BERT based models with data augmentation and found BERT to be a powerful model for stance detection. Thus, we have selected BERT as a strong baseline for our paper.\nSeveral works have shown that auxiliary information, such as sentiment and emotion information, or the subjective/objective nature of a text (provided as additional inputs or presented in the form of auxiliary tasks in a multi-task framework), can help improve the performance obtained from the tweet/target information alone (Mohammad et al., 2017; Sun et al., 2019; Li and Caragea, 2019; Hosseinia et al., 2020; Xu et al., 2020). Other approaches to improve the performance, especially when the amount of labeled data for the task of interest is small, include weak supervision (Wei et al., 2019) and knowledge distillation (Miao et al., 2020); transfer learning through distant supervision (Zarrella and Marsh, 2016) or pre-trained models (Ebner et al., 2019; Hosseinia et al., 2020); and domain adaptation from a source task to the target task (Xu et al., 2018, 2020).\nIn particular, the Dual-view Adaptation Network (DAN) (Xu et al., 2020) learns to predict the stance of a tweet by combining the subjective and objective views/representations of the tweet, while also learning to adapt them across domains. We use an adaptation of the DAN model as a strong baseline in this work. Most relevant to our work on COVID-19-Stance, Miao et al. (2020) compared a supervised in-domain BERT model trained and tested on “lockdown” tweets, with cross-domain models, and knowledge distillation variants. The results showed significantly improved performance for the knowledge distillation variants, and emphasized the importance of having a small amount of data for the task of interest (as a better alternative to zero-shot learning). Similar to Miao et al. (2020), we also use BERT together with knowledge distillation/self-training as a strong baseline."
    }, {
      "heading" : "3 COVID-19-Stance Dataset",
      "text" : "The recency of the COVID-19 pandemic means there was no established stance detection dataset for this broader topic, when we began our research. Therefore, we set out to construct our own dataset, called COVID-19-Stance, by following the methodology introduced by Mohammad et al. (2016, 2017), which is generic and applicable for any controversial topic discussed on Twitter.\nData collection. We began crawling Twitter, using the Twitter Streaming API, on February 27th, 2020. We collected tweets that contained general keywords pertaining to the novel coronavirus (e.g. “coronavirus”, “covid-19”, “corona virus”, “#covid19”, etc.). As new hashtags emerged, we iteratively added additional, more specific keywords to the search (e.g., “#lockdown”, “stay at home”, “#socialdistancing”, “#washhands”, etc.). We continued crawling until August 20th, 2020. The full list of keywords that was used over this time period is provided in Appendix A. We only stored original tweets (not a retweet or quoted tweet) that contained no hyperlinks, and ended up collecting a grant total of 30,331,993 tweets.\nTarget selection. After being able to analyze the initial tweets, and following the developments of the COVID-19 events, we began to identify controversial topics that arose as the virus continued its spread in the United States (US). Four topics that we found to be among the most prevalent in our collection of tweets, and are understood by a large number of people in the US, were “Stay at Home Orders”, “Wearing a Face Mask”, “Keeping Schools Closed”, and “Anthony S. Fauci, M.D.”.\nData selection. Similar to Mohammad et al. (2016), we identified query hashtags to encompass\nthe four main targets/topics selected, and began to collect and organize the tweets according to topic and likely labels. For example, if “#FireFauci” is contained within a tweet, it is likely that the author of that tweet is posting information indicating they do not support the current director of the National Institute of Allergy and Infectious Diseases (NIAID), Anthony S. Fauci, M.D. For each of the four selected targets, we identified two types of query hashtags, specifically, “in-favor” hashtags and “against” hashtags (stance-neutral hashtags were very rare). The exact query hashtags identified for each target are shown in Table 2. Using the “in-favor” and “against” query hashtags, we selected a “noisy stance set” of tweets for each target, as shown in Table 3. Out of the total number of tweets corresponding to a target, we further selected a relatively balanced (in terms of in-favor and against noisy labels) dataset to be manually labeled, and another relatively balanced dataset of tweets to be used as unlabeled in the self-training approach. The exact number of tweets to-label and to be used unlabeled are shown in Table 4.\nData Annotation. Although query hashtags are great for selecting likely relevant tweets, they are noisy and not reliable enough to accurately identify the stance towards a target for a tweet (see Table 5 for some examples illustrating this point). There-\nfore we used Amazon Mechanical Turk (AMT) to enlist the help of gig workers to analyze and label our collection of 7,122 tweets selected to be labeled (the exact number of tweets for each target is shown in Table 4). We removed the hashtags that appeared at the end of a tweet to exclude obvious cues, without making the tweet syntactically ambiguous. This increases the chance that our collection contains tweets that do not explicitly mention the target, and potentially some tweets with neutral stance towards the target. Each tweet was labeled by three annotators. At one time, each annotator was shown a page with a tweet and a target, and asked to answer a questionnaire designed and detailed by Mohammad et al. (2017). The questionnaire, shown in Appendix B, contains detailed questions and multi-choice answers that allow us to annotate each tweet with respect to three criteria:\n1. the stance of the tweet’s author/user towards the given target: in favor, against or neither;\n2. the way the opinion is expressed, which captures whether the text of the tweet reveals the stance explicitly, implicitly, or neither;\n3. the sentiment of the tweet, which essentially captures the language used in the tweet: positive, negative, both, sarcasm, or neither.\nOur final COVID-19-Stance dataset contains only tweets for which at least two out of the three annotators agreed on the stance category. The Cohen’s Kappa scores that we obtained for interannotator agreement for the final dataset were 0.82 for stance, 0.83 for target of opinion, and 0.60 for sentiment. According to (Cohen, 1960), the scores for stance and target of represent almost perfect agreement, while the score for sentiment shows substantial agreement. Table 1 shows several examples of annotated tweets in our dataset.\nDataset statistics. The number of tweets for each target and the stance distribution for each target are shown in Table 6. The number of tweets for\neach target over the months when data was crawled is graphically displayed in Figure 1, which shows that a large number of the tweets in our dataset were posted in July 2020. The distribution of the type of opinion is shown in Tables 7 and 8, for each target and each stance, respectively. Similarly, the distribution of the sentiment (or tweet language) is shown in Tables 9 and 10, for each target and each stance, respectively. As can be seen from these tables, our dataset contains a good mix of in-favor, against and neutral categories, and also a good mix of tweets with implicit and explicit opinion towards the target. However, the sentiment is generally negative or in the other category (which includes both positive and negative, sarcastic language and neither). Together, these characteristics make our task both realistic and challenging. While we only use the stance label in this work, the other labels will be explored in future works, as auxiliary information potentially useful for stance detection.\nBenchmark subsets. To enable progress on COVID-19 stance detection, and facilitate comparisons between models developed for this task, we randomly split our COVID-19-Stance dataset (using stratified sampling) into training (Train), development (Val) and test (Test) subsets, respectively. We used the training subset to train our models, the development to select hyperparameters and the test to evaluate the final performance of the models. Statistics for the dataset in terms of number of tweets in the Train, Test and Val subsets, respectively, are shown in Table 11."
    }, {
      "heading" : "4 Baseline Models",
      "text" : "Having described our COVID-19-Stance dataset, we now briefly review several models that we use to establish baseline results on this dataset."
    }, {
      "heading" : "4.1 Supervised Baseline Models",
      "text" : "To get a baseline understanding of how established stance detection networks perform on our dataset, we used the following models:\n• BiLSTM: Bi-Directional Long Short Term Memory Networks (Schuster and Paliwal, 1997) take tweets as input, and are trained to predict the stance towards a target, without explicitly using the target information.\n• Kim-CNN: Convolutional Neural Networks for text, proposed by Kim (2014), are also provided with tweets as input, and trained to predict the stance towards a target, without explicitly using the target information.\n• TAN: Target-specific Attention Networks (Du et al., 2017) represent an attention-based BiLSTM model that identifies features specific to the target of interest, by explicitly incorporating the target information.\n• ATGRU: The Bi-Directional Gated Recurrent Unit Network with Token-Level Attention Mechanism (Zhou and Cristea, 2017) is an attention-based Bi-GRU model that also uses\nthe target information explicitly, and identifies specific target features using the attention.\n• GCAE: The Gated Convolutional Network with Aspect Embedding (Xue and Li, 2018) is based on a CNN model. In addition to tweets, it also has information about the target, and uses a gating mechanism to block target-unrelated information.\n• BERT: Bidirectional Encoder Representations from Transformers (Devlin et al., 2019) represent language models that are pre-trained on a large unlabeled corpus to encode sentences and their tokens into dense vector representations. We used the pre-trained COVIDTwitter-BERT model3 (Müller et al., 2020)."
    }, {
      "heading" : "4.2 Self-training Baseline",
      "text" : "Given that a large amount of unlabeled data is available for each target included in our COVID19-Stance dataset, we explored the use of a selftraining approach that can make use of unlabeled data, as described below:\n3https://huggingface.com/ digitalepidemiologylab/ covid-twitter-bert\n• BERT-NS: Self-training with Noisy Student (Xie et al., 2020) is a semi-supervised learning approach that employs self-training and knowledge distillation (Hinton et al., 2015) to improve the performance of a teacher model using unlabeled data. More specifically, a teacher is originally trained from the available labeled data, and is used to predict pseudolabels for the unlabeled data. Subsequently, a noisy student model is trained using the labeled and pseudo-labeled data. By replacing the teacher with the student, the process can be iterated several times. In our work, we performed just one iteration. Both the teacher and the student models were COVID-TwitterBERT, with a softmax layer at the top."
    }, {
      "heading" : "4.3 Domain Adaptation Baseline",
      "text" : "To understand the benefits of using a prior stance detection dataset, in addition to the dataset we constructed, we experimented with a domain adaptation model, as described below:\n• BERT-DAN: Dual-view Attention Networks (Xu et al., 2020) capture explicitly subjective and objective information contained in tweets, and also enable the use of labeled data for a prior, related task to train a model for a current task of interest. The original DAN model proposed by Xu et al. (2020) makes use of BiLSTM networks and domain adversarial networks to learn the subjective and objective representations and make them domain invariant. At the same time, DAN learns to predict the stance using labeled data from the prior task (under the assumption that no labeled data is available for the task of interest). Compared to the original DAN model, we re-\nplaced the BiLSTM networks with pre-trained COVID-Twitter-BERT models, and trained the network to predict the stance using both labeled data from the prior task and from the current task. The prior data was the whole SemEval2016 Task 6 data."
    }, {
      "heading" : "5 Experimental Setup",
      "text" : ""
    }, {
      "heading" : "5.1 Implementation Details",
      "text" : "Data Pre-processing Before the tweets in our dataset were used for training, they were preprocessed and transformed to embedded tensors. For every tweet in the dataset, we removed any emojis, URLs, and reserved words. We then used the pre-trained COVID-Twitter-BERT to tokenize and embed each tweet, truncating the sequence length to 128 as needed. Hyperparameters. The validation set was used to determine generally good hyperparameters for the models. For each non-BERT supervised model, Adam optimizer was used with a learning rate of 1e−5, weight decay of 4e−5, and gradient clipping with a max norm of 4.0. Each model was trained for 120 epochs, with a mini-batch size of 16 in each iteration. A dropout of 0.5 was used for each network. Other specific hyper-parameters for each network are shown below:\n• RNN Networks: BiLSTM, ATGRU, and TAN each had a hidden LSTM dimension of 512 with a dropout of 0.2.\n• CNN Networks: GCAE and Kim-CNN both used filters of width 2, 3, 4, and 5. For each filter width, there were 25 feature maps. Following the convolutional layers was a linear classifier with a hidden dimension of 128.\n• BERT: This model was initialized with the pre-trained COVID-Twitter-BERT model. It was optimized with AdamW with a learning rate of 1e−5 over the course of 10 epochs, with 15 warmup steps.\n• BERT-NS: The implementation of the student model is exactly the same as that of the supervised BERT. The teacher and the student models are set up in the same manner, except that the teacher has no dropout.\n• BERT-DAN: The formation functions are the same as those of the supervised BERT model,\nexcept that there is no softmax layer on top. The discriminators and classifiers were all two layer neural nets with a hidden dimension of 1024. A dropout of 0.15 was used throughout the network. Optimization was performed by AdamW with a learning rate of 3e−6 for first 7 epochs, and 3e−7 for the final 3 epochs. The following weights were assigned to this network’s loss functions: 0.1 for the domain discriminators, 0.05 for the objective and subjective classifiers, and 0.4 for the source stance classifier. A mini-batch size of 4 was used due to GPU memory limitations."
    }, {
      "heading" : "5.2 Evaluation Metrics",
      "text" : "To evaluate the performance of the baseline models on our dataset, we used the following standard metrics: accuracy, (macro average) precision, recall, and F1 score4. We report the performance on the test set at the epoch in which the model recorded the highest F1 score on the validation data. We performed 3 independent runs for each model to account for variability, and report average results over the three runs.\n4Precision, recall and F1 scores for each stance category are also reported in Appendix C"
    }, {
      "heading" : "6 Results and Discussion",
      "text" : "The results of the experiments are shown in Table 12 for the four targets in the COVID-19-Stance dataset, respectively. Between the two supervised baselines that do not explicitly use the target information, Bi-LSTM and Kim-CNN, the Bi-LSTM gives better results overall, in all metrics, except for the “Wearing a Face Mask” target. When comparing Kim-CNN with GCAE (a CNN-based models that explicitly uses the target), Kim-CNN gives better accuracy and F1 scores for two targets (“Anthony S. Fauci, M.D.” and “Stay At Home Orders”), while the GCAE model gives better results for the other two targets (“Keeping Schools Closed” and “Wearing a Face Mask”). Similarly, when comparing the two recurrent models with attention, TAN and ATGRU, TAN performs better on two targets, “Keeping Schools Closed” and “Stay At Home Orders”, while ATGRU performs better on “Anthony S. Fauci, M.D.” and “Wearing a Face Mask”. Surprisingly, these two models, which explicitly use the target information, perform worse than the BiLSTM model overall. Finally, we can see that among the supervised baselines, the BERT model performs significantly better than all the other models, a result that is in agreement with prior works (Ghosh et al., 2019; Miao et al., 2020).\nWhen comparing BERT with BERT-NS with BERT-DAN (models that use unlabeled data and SemEval2016 Task 6 data, respectively), we see that BERT performs better than the models that use additional information on the “Stay At Home Orders” target and comparable to the BERT-NS on the “Keeping Schools Closed” target - specifically, the targets with smaller labeled datasets. On the other hand, BERT-DAN performs the best on the “Anthony S. Fauci, M.D.” target, and comparable to BERT-NS on the “Wearing a Face Mask” target, i.e., the targets with larger labeled datasets. This result suggests that a larger amount of labeled data is useful for the domain adaptation approach. However, when only a small amount of labeled data is available, BERT is better than the noisy student which may not start with a very good teacher.\nError Analysis. To better understand how two of our best models would perform in the wild, we have included some of their predictions on examples from the Wearing A Face Mask test set, along with the gold-standard label in Table 13. As we can see, both models perform well on examples where the stance is presented explicitly, such as in tweets 1 and 2. However, the models generally struggle with sarcasm and humor as seen in tweets 3, 5, and 6. They also both demonstrate a strong bias towards certain phrases such as “form of government control” which is a common phrase in AGAINST tweets for Wearing A Face Mask. Interestingly, the noisy student model seems to be more likely\nto incorrectly predict a FAVOR stance when the sentiment of the tweet is positive compared to the DAN model, as seen in tweets 7 and 8."
    }, {
      "heading" : "7 Conclusions and Future Work",
      "text" : "In this work, we have constructed a COVID-19Stance dataset that can be used to further the research on stance detection, especially in the context of COVID-19 pandemic. In addition to the dataset, we have established baselines using several supervised models used in prior works on stance detection, and also two models that can make use of unlabeled data and data from a prior stance detection task, respectively. Our results show the pre-trained COVID-Twitter-BERT model constitutes a strong baseline. When a larger amount of labeled data is available for a target, the BERT-NS and BERT-DAN can help further improve the performance. As part of future work, we plan to study the benefits of the opinion and sentiment data that we annotated towards the stance detection. We also plan to study the usefulness of multi-task learning, where we train models for all our targets concurrently. Other transfer learning approaches that can leverage existing datasets will also be explored."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank the National Science Foundation and Amazon Web Services for support from grants IIS-1741345, IIS-1802284, IIS-1912887, and IIS1903963 which supported the research and the computation in this study.\nEthics and Impact Statement\nOur dataset does not provide any personally identifiable information as only the tweet IDs and human annotated stance labels will be shared. Thus, our dataset complies with Twitter’s information privacy policy. The research enabled by this dataset has the potential to help officials and health organizations understand the public’s opinion on various initiatives, estimate the efficacy of their mandates and prevent serious resurgence of the novel coronavirus."
    }, {
      "heading" : "A Keywords Used for Twitter Crawler",
      "text" : "#coronavirus, corona virus, #Coronavid19, #coronavirususa, #coronavirusaustralia, #covid19, covid-19, #covid-19, coronavirus, #coronapocalypse, #quarantinelife, #socialdistancing, SocialDistancing, StayHome, StayAtHome, lockdown, StayHomeSaveLives, Quarantine, socialdistancing, confinement, FlattenTheCurve, StayHomeStaySafe, stayhome, QuarantineLife, 5G, TrumpVirus, StaySafe, Coronavirustruth, WashYourHands, ChineseVirus, TrumpLiedPeopleDied, stayhome, Lockdown, TrumpLiesAboutCoronavirus, ChinaVirus, COVIDIOTS, COVIDIOT, quarantinelife, StaySafeStayHome, hoax, TrumpVirusCoverup, panicbuying, Hydroxychloroquine, TheLockdown, lockdowneffect, toiletpaper, StayAtHomeAndStaySafe, StayTheFHome, SelfIsolation, QuarantineAndChill, stayathome, TrumpPandemic, SocialDistanacing, ChinaLiedPeopleDied, QuaratineLife, lockdownextension, Trumpdemic, TrumpLiedPeopleDied, WorkFromHome, TrumpLiesPeopleDie, QuarentineLife, TrumpLiesAmericansDie, Lockdown21, workingfromhome, TrumpOwnsEveryDeath, TrumpPlague, LockdownExtended, CoronavirusLockdown, TrumpGenocide, SocialDistancingNow, CCPVirus, SocialDistance, ChineseVirus19, ShelterInPlace, StayAtHomeSaveLives, PhysicalDistancing, Resist, Isolation, ChinaCoronaVirus, toiletpapercrisis, lockdownuk, chloroquine, WFH, ChinaLiedAndPeopleDied, LockdownNow, selfisolating, Lockdownextention, CloseTheSchools, Pencedemic, SupportLockdownStaySafe, toiletpaperpanic, schoolclosure, ToiletPaperApocalypse, selfquarantine, masks, handwashing, WearAMask, SafeHands, handsanitizer, LockDown, mask, isolation, flattenthecurve, washyourhands, panicbuyers, panickbuying, Social Distancing, ChinaMustExplain, Masks4All, WashYourHandsChallenge, BloodOnTrumpsHands, IsolationLife, Hoax, ToiletPaperPanic, toiletpapergate, homeschooling, panicshopping, 5GKILLS, hydroxychloroquine, LockdownHouseParty, trumpvirus, StayHomeSaveLifes, homeoffice, PencePandemic, FamiliesFirst, StayHomeCanada, facemasks, selfisolation, flatteningthecurve, QuaratineAndChill, HerdImmunity, AloneTogether, Hydroxycloroquine, workfromhome, remotework, Masks, FlattenTheCuve, COVIDIDIOT, Socialdistancing, hydroxychloriquine, day8oflockdown, wfh, stayHome, herdimmunity, CoronavirusLockdownUK, TrumpVirus2020, TrumpBurialPits, ShutItDown, 5GCoronavirus, Homeoffice, Resistance, ChineseVirusCorona, chinesevirus, panicbuyinguk, KungFlu, NYCLockdown, facemask, trumpandemic, CoronaHoax, HomeOffice, ChineseCoronavirus, Pandumbic, CoronaLockdown, OPENAMERICANOW, TogetherAtHome, testing, FeverDetectionCamera, WhereAreTheTests, vaccines, Plandemic, Scamdemic, FireFauci, StudentLivesMatter, StayatHome, endthelockdown, ReopenAmerica, lockdown2020, CancelAPExamsPromoteStudents, schoolreopening, HealthOverExams, PromoteStudentsSaveFuture, TestingTestingTesting, schools, lockdownUKnow, SaferAtHome, ContactTracing, FreeThemAll, TrumpCoronavirusTestFailure, TrumpLiedAmericansDied, Handwashing, ChinaLiedPeopleDie, StayAtHomeOrder, OpenAmerica, Vaccine, remoteworking, californialockdown, TestTraceIsolate, EndTheShutdown, WHOLiedPeopleDied, curfew, Curfew, ReOpenAmerica, Testing, TESTVIRUSNOW, socialdistance, plandemic, FakePandemic, stayhomestaysafe, TrumpPandemicFailure, BackToWork, BackToWork, chinavirus, ReopenAmericaNow, MakeChinaPay, TestAndTrace,#MasksOff, MasksOff, SayNoToMasks, #SayNoToMasks, ConstitutionOverCoronavirus, #ConstitutionOverCoronavirus, endthelockdownuk, #endthelockdownuk, #studentban, #StudentBan, SchoolsMustOpeninFall, SchoolReopening, ReopeningSchools, #SchoolsMustOpeninFall, #SchoolReopening, #ReopeningSchools, #Hydroxychloroquine, Hydroxychloroquine"
    }, {
      "heading" : "B Questionnaire Used For Amazon Mechanical Turk Workers",
      "text" : "Q1: From reading the tweet, which of the options below is most likely to be true about the tweeter’s stance or outlook towards stance to prevent the spread of Covid-19: 1. We can infer from the tweet that the tweeter supports the target. This could be because of any of reasons shown below: • The tweet is explicitly in support for the target. • The tweet is in support of something/someone aligned with the target,\nfrom which we can infer that the tweeter supports the target.\n• The tweet is against something/someone other than the target, from which we can infer that the tweeter supports the target.\n• The tweet is NOT in support of or against anything, but it has some information, from which we can infer that the tweeter supports the target.\n• We cannot infer the tweeter’s stance toward the target, but the tweet is echoing somebody else’s favorable stance towards the target (this could be a news story, quote, retweet, etc).\n2. We can infer from the tweet that the tweeter is against the target. This could be because of any of the following:\n• The tweet is explicitly against the target. • The tweet is against someone/something\naligned with the target entity, from which we can infer that the tweeter is against the target.\n• the tweet is in support of someone/something other than the target, from which we can infer that the tweeter is against the target.\n• The tweet is NOT in support of or against anything, but it has some information, from which we can infer that the tweeter is against the target.\n• We cannot infer the tweeter’s stance toward the target, but the tweet is echoing somebody else’s negative stance towards the target entity (this could be a news story, quote, retweet, etc).\n3. We can infer from the tweet that the tweeter has a neutral stance towards the target.\n• The tweet must provide some information that suggests that the tweeter is neutral towards the target - the tweet being neither favorable nor against the target is not sufficient reason for choosing this option. One reason for choosing this option is that the tweeter supports the target entity to some extent, but is also against it to some extent.\n4. There is no clue in the tweet to reveal the stance of the tweeter towards the target (support/against/neutral).\nQ2: From reading the tweet, which of the options below is most likely to be true about the focus of opinion/sentiment in the tweet:\n1. The tweet explicitly expresses opinion/sentiment about the target.\n2. The tweet expresses opinion/sentiment about something/someone other than the target.\n3. The tweet is not expressing opinion/sentiment about anything.\nQ3: What kind of language is the speaker using?\n1. The speaker is using positive language, for example, expressions of support, admiration, positive attitude, forgiveness, fostering, success, positive emotional state (happiness, optimism, pride, etc.).\n2. The speaker is using negative language, for example, expressions of criticism, judgment, negative attitude, questioning validity/competence, failure, negative emotional state (anger, frustration, sadness, anxiety, etc.).\n3. The speaker is using expressions of sarcasm, ridicule, or mockery.\n4. The speaker is using positive language in part and negative language in part.\n5. The speaker is neither using positive language nor using negative language."
    }, {
      "heading" : "C Comprehensive Results by Class",
      "text" : "The average results for stance detection over all three classes, as well as detailed results per class are shown for the four targets in Tables 14, 15, 16, and 17, respectively."
    } ],
    "references" : [ {
      "title" : "Stance detection with bidirectional conditional encoding",
      "author" : [ "Isabelle Augenstein", "Tim Rocktäschel", "Andreas Vlachos", "Kalina Bontcheva." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 876–885,",
      "citeRegEx" : "Augenstein et al\\.,? 2016",
      "shortCiteRegEx" : "Augenstein et al\\.",
      "year" : 2016
    }, {
      "title" : "Tracking social media discourse about the covid-19 pandemic: Development of a public coronavirus twitter data set",
      "author" : [ "Emily Chen", "Kristina Lerman", "Emilio Ferrara." ],
      "venue" : "JMIR Public Health and Surveillance, 6(2):e19273.",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "A coefficient of agreement for nominal scales",
      "author" : [ "Jacob Cohen." ],
      "venue" : "Educational and Psychological Measurement, 20(1):37–46.",
      "citeRegEx" : "Cohen.,? 1960",
      "shortCiteRegEx" : "Cohen.",
      "year" : 1960
    }, {
      "title" : "Will-they-won’t-they: A very large dataset for stance detection on Twitter",
      "author" : [ "Costanza Conforti", "Jakob Berndt", "Mohammad Taher Pilehvar", "Chryssi Giannitsarou", "Flavio Toxvaerd", "Nigel Collier." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Asso-",
      "citeRegEx" : "Conforti et al\\.,? 2020",
      "shortCiteRegEx" : "Conforti et al\\.",
      "year" : 2020
    }, {
      "title" : "Strong social distancing measures in the united states reduced the covid-19 growth rate: Study evaluates the impact of social distancing measures on the growth rate",
      "author" : [ "Charles Courtemanche", "Joseph Garuccio", "Anh Le", "Pinkston J", "Aaron Yelowitz" ],
      "venue" : null,
      "citeRegEx" : "Courtemanche et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Courtemanche et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Stance classification with target-specific neural attention",
      "author" : [ "Jiachen Du", "Ruifeng Xu", "Yulan He", "Lin Gui." ],
      "venue" : "Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17, pages 3988–3994.",
      "citeRegEx" : "Du et al\\.,? 2017",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2017
    }, {
      "title" : "Bag-of-words transfer: Non-contextual techniques for multi-task learning",
      "author" : [ "Seth Ebner", "Felicity Wang", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 40–46,",
      "citeRegEx" : "Ebner et al\\.,? 2019",
      "shortCiteRegEx" : "Ebner et al\\.",
      "year" : 2019
    }, {
      "title" : "French tweet corpus for automatic stance detection",
      "author" : [ "Marc Evrard", "Rémi Uro", "Nicolas Hervé", "Béatrice Mazoyer." ],
      "venue" : "Proceedings of The 12th Language Resources and Evaluation Conference, pages 6317–6322.",
      "citeRegEx" : "Evrard et al\\.,? 2020",
      "shortCiteRegEx" : "Evrard et al\\.",
      "year" : 2020
    }, {
      "title" : "Pandemic fatigue” leads to resurgence of coronavirus in europe where cases hit fresh records in france and spain",
      "author" : [ "Will Feuer", "Nate Rattner." ],
      "venue" : "CNBC.",
      "citeRegEx" : "Feuer and Rattner.,? 2020",
      "shortCiteRegEx" : "Feuer and Rattner.",
      "year" : 2020
    }, {
      "title" : "Stance detection in web and social media: A comparative study",
      "author" : [ "Shalmoli Ghosh", "Prajwal Singhania", "Siddharth Singh", "Koustav Rudra", "Saptarshi Ghosh." ],
      "venue" : "Experimental IR Meets Multilinguality, Multimodality, and Interaction, 11696:75–87.",
      "citeRegEx" : "Ghosh et al\\.,? 2019",
      "shortCiteRegEx" : "Ghosh et al\\.",
      "year" : 2019
    }, {
      "title" : "Detecting stance in czech news commentaries",
      "author" : [ "Tomás Hercig", "Peter Krejzl", "Barbora Hourová", "Josef Steinberger", "Ladislav Lenc." ],
      "venue" : "ITAT, pages 176–180.",
      "citeRegEx" : "Hercig et al\\.,? 2017",
      "shortCiteRegEx" : "Hercig et al\\.",
      "year" : 2017
    }, {
      "title" : "Distilling the knowledge in a neural network",
      "author" : [ "Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean." ],
      "venue" : "arXiv preprint arXiv:1503.02531.",
      "citeRegEx" : "Hinton et al\\.,? 2015",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2015
    }, {
      "title" : "Covidlies: Detecting covid-19 misinformation on social media",
      "author" : [ "Tamanna Hossain", "Robert L Logan IV", "Arjuna Ugarte", "Yoshitomo Matsubara", "Sean Young", "Sameer Singh." ],
      "venue" : "Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP",
      "citeRegEx" : "Hossain et al\\.,? 2020",
      "shortCiteRegEx" : "Hossain et al\\.",
      "year" : 2020
    }, {
      "title" : "Stance prediction for contemporary issues: Data and experiments",
      "author" : [ "Marjan Hosseinia", "Eduard Dragut", "Arjun Mukherjee." ],
      "venue" : "Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media, pages 32–40,",
      "citeRegEx" : "Hosseinia et al\\.,? 2020",
      "shortCiteRegEx" : "Hosseinia et al\\.",
      "year" : 2020
    }, {
      "title" : "Convolutional neural networks for sentence classification",
      "author" : [ "Yoon Kim." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751, Doha, Qatar. Association for Computational Lin-",
      "citeRegEx" : "Kim.,? 2014",
      "shortCiteRegEx" : "Kim.",
      "year" : 2014
    }, {
      "title" : "Multilingual stance detection in social media political debates",
      "author" : [ "Mirko Lai", "Alessandra Teresa Cignarella", "Delia Irazú Hernández Farı́as", "Cristina Bosco", "Viviana Patti", "Paolo Rosso" ],
      "venue" : "Computer Speech & Language,",
      "citeRegEx" : "Lai et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 2020
    }, {
      "title" : "Multi-task stance detection with sentiment and stance lexicons",
      "author" : [ "Yingjie Li", "Cornelia Caragea." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan-",
      "citeRegEx" : "Li and Caragea.,? 2019",
      "shortCiteRegEx" : "Li and Caragea.",
      "year" : 2019
    }, {
      "title" : "Target-aware data augmentation for stance detection",
      "author" : [ "Yingjie Li", "Cornelia Caragea." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages",
      "citeRegEx" : "Li and Caragea.,? 2021",
      "shortCiteRegEx" : "Li and Caragea.",
      "year" : 2021
    }, {
      "title" : "Twitter data augmentation for monitoring public opinion on COVID-19 intervention measures",
      "author" : [ "Lin Miao", "Mark Last", "Marina Litvak." ],
      "venue" : "Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP 2020, Online. Association for Computa-",
      "citeRegEx" : "Miao et al\\.,? 2020",
      "shortCiteRegEx" : "Miao et al\\.",
      "year" : 2020
    }, {
      "title" : "Semeval-2016 task 6: Detecting stance in tweets",
      "author" : [ "Saif M Mohammad", "Svetlana Kiritchenko", "Parinaz Sobhani", "Xiaodan Zhu", "Colin Cherry." ],
      "venue" : "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), pages 31–",
      "citeRegEx" : "Mohammad et al\\.,? 2016",
      "shortCiteRegEx" : "Mohammad et al\\.",
      "year" : 2016
    }, {
      "title" : "Stance and sentiment in tweets",
      "author" : [ "Saif M. Mohammad", "Parinaz Sobhani", "Svetlana Kiritchenko." ],
      "venue" : "ACM Trans. Internet Technol., 17(3).",
      "citeRegEx" : "Mohammad et al\\.,? 2017",
      "shortCiteRegEx" : "Mohammad et al\\.",
      "year" : 2017
    }, {
      "title" : "A stance data set on polarized conversations on twitter about the efficacy of hydroxychloroquine as a treatment for covid-19",
      "author" : [ "Ece C Mutlu", "Toktam Oghaz", "Jasser Jasser", "Ege Tutunculer", "Amirarsalan Rajabi", "Aida Tayebi", "Ozlem Ozmen", "Ivan Garibay" ],
      "venue" : null,
      "citeRegEx" : "Mutlu et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Mutlu et al\\.",
      "year" : 2020
    }, {
      "title" : "Covid-twitter-bert: A natural language processing model to analyse covid-19 content on twitter",
      "author" : [ "Martin Müller", "Marcel Salathé", "Per E Kummervold" ],
      "venue" : null,
      "citeRegEx" : "Müller et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Müller et al\\.",
      "year" : 2020
    }, {
      "title" : "Bidirectional recurrent neural networks",
      "author" : [ "Mike Schuster", "Kuldip Paliwal." ],
      "venue" : "Signal Processing, IEEE Transactions on, 45:2673 – 2681.",
      "citeRegEx" : "Schuster and Paliwal.,? 1997",
      "shortCiteRegEx" : "Schuster and Paliwal.",
      "year" : 1997
    }, {
      "title" : "Tweet stance detection using an attention based neural ensemble model",
      "author" : [ "Umme Aymun Siddiqua", "Abu Nowshed Chy", "Masaki Aono." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Siddiqua et al\\.,? 2019",
      "shortCiteRegEx" : "Siddiqua et al\\.",
      "year" : 2019
    }, {
      "title" : "Transfer learning from transformers to fake news",
      "author" : [ "Valeriya Slovikovskaya", "Giuseppe Attardi" ],
      "venue" : null,
      "citeRegEx" : "Slovikovskaya and Attardi.,? \\Q2020\\E",
      "shortCiteRegEx" : "Slovikovskaya and Attardi.",
      "year" : 2020
    }, {
      "title" : "Stance detection via sentiment information and neural network model",
      "author" : [ "Qingying Sun", "Zhongqing Wang", "Shoushan Li", "Qiaoming Zhu", "Guodong Zhou." ],
      "venue" : "Frontiers of Computer Science, 13(1):127–138.",
      "citeRegEx" : "Sun et al\\.,? 2019",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Stance detection with hierarchical attention network",
      "author" : [ "Qingying Sun", "Zhongqing Wang", "Qiaoming Zhu", "Guodong Zhou." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 2399–2409, Santa Fe, New Mexico, USA.",
      "citeRegEx" : "Sun et al\\.,? 2018",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2018
    }, {
      "title" : "X-stance: A multilingual multi-target dataset for stance detection",
      "author" : [ "Jannis Vamvas", "Rico Sennrich" ],
      "venue" : null,
      "citeRegEx" : "Vamvas and Sennrich.,? \\Q2020\\E",
      "shortCiteRegEx" : "Vamvas and Sennrich.",
      "year" : 2020
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "undefinedukasz Kaiser", "Illia Polosukhin" ],
      "venue" : "In Proceedings of the 31st International Conference on Neural Information Processing",
      "citeRegEx" : "Vaswani et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "DeepStance at SemEval-2016 task 6: Detecting stance in tweets using character and word-level CNNs",
      "author" : [ "Prashanth Vijayaraghavan", "Ivan Sysoev", "Soroush Vosoughi", "Deb Roy." ],
      "venue" : "Proceedings of the 10th International Workshop on Seman-",
      "citeRegEx" : "Vijayaraghavan et al\\.,? 2016",
      "shortCiteRegEx" : "Vijayaraghavan et al\\.",
      "year" : 2016
    }, {
      "title" : "Stance in replies and quotes (srq): A new dataset for learning stance in Twitter conversations",
      "author" : [ "Ramon Villa-Cox", "Sumeet Kumar", "Matthew Babcock", "Kathleen M Carley." ],
      "venue" : "arXiv preprint arXiv:2006.00691.",
      "citeRegEx" : "Villa.Cox et al\\.,? 2020",
      "shortCiteRegEx" : "Villa.Cox et al\\.",
      "year" : 2020
    }, {
      "title" : "Stance detection based on ensembles of classifiers",
      "author" : [ "Sergey V Vychegzhanin", "Evgeny V Kotelnikov." ],
      "venue" : "Programming and Computer Software, 45(5):228–240.",
      "citeRegEx" : "Vychegzhanin and Kotelnikov.,? 2019",
      "shortCiteRegEx" : "Vychegzhanin and Kotelnikov.",
      "year" : 2019
    }, {
      "title" : "A topic-aware reinforced model for weakly supervised stance detection",
      "author" : [ "Penghui Wei", "Wenji Mao", "Guandan Chen." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 7249–7256.",
      "citeRegEx" : "Wei et al\\.,? 2019",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2019
    }, {
      "title" : "pkudblab at SemEval-2016 task 6 : A specific convolutional neural network system for effective stance detection",
      "author" : [ "Wan Wei", "Xiao Zhang", "Xuqin Liu", "Wei Chen", "Tengjiao Wang." ],
      "venue" : "Proceedings of the 10th International Workshop on Semantic Eval-",
      "citeRegEx" : "Wei et al\\.,? 2016",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2016
    }, {
      "title" : "Self-training with noisy student improves imagenet classification",
      "author" : [ "Qizhe Xie", "Minh-Thang Luong", "Eduard Hovy", "Quoc V Le." ],
      "venue" : "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10687–10698.",
      "citeRegEx" : "Xie et al\\.,? 2020",
      "shortCiteRegEx" : "Xie et al\\.",
      "year" : 2020
    }, {
      "title" : "Cross-target stance classification with selfattention networks",
      "author" : [ "Chang Xu", "Cécile Paris", "Surya Nepal", "Ross Sparks." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 778–",
      "citeRegEx" : "Xu et al\\.,? 2018",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2018
    }, {
      "title" : "Dan: dualview representation learning for adapting stance classifiers to new domains",
      "author" : [ "Chang Xu", "Cecile Paris", "Surya Nepal", "Ross Sparks", "Chong Long", "Yafang Wang." ],
      "venue" : "Proceedings of the 24th European Conference on Artificial Intelligence, vol-",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Aspect based sentiment analysis with gated convolutional networks",
      "author" : [ "Wei Xue", "Tao Li." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2514–2523, Melbourne, Australia.",
      "citeRegEx" : "Xue and Li.,? 2018",
      "shortCiteRegEx" : "Xue and Li.",
      "year" : 2018
    }, {
      "title" : "MITRE at SemEval-2016 task 6: Transfer learning for stance detection",
      "author" : [ "Guido Zarrella", "Amy Marsh." ],
      "venue" : "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), pages 458–463, San Diego, California. Association",
      "citeRegEx" : "Zarrella and Marsh.,? 2016",
      "shortCiteRegEx" : "Zarrella and Marsh.",
      "year" : 2016
    }, {
      "title" : "Connecting targets to tweets: semantic attention-based model for target-specific stance detection",
      "author" : [ "Yiwei Zhou", "A.I. Cristea." ],
      "venue" : "Athman Bouguettaya, Yunjun Gao, Andrey Klimenko, Lu Chen, Xiangliang Zhang, Fedor Dzerzhinskiy, Weijia Jia,",
      "citeRegEx" : "Zhou and Cristea.,? 2017",
      "shortCiteRegEx" : "Zhou and Cristea.",
      "year" : 2017
    }, {
      "title" : "Multilingual stance detection in tweets: The Catalonia independence corpus",
      "author" : [ "Elena Zotova", "Rodrigo Agerri", "Manuel Nuñez", "German Rigau." ],
      "venue" : "Proceedings of the 12th Language Resources and Evaluation Conference, pages 1368–1375, Mar-",
      "citeRegEx" : "Zotova et al\\.,? 2020",
      "shortCiteRegEx" : "Zotova et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "For example, states in the United States that have imposed strict social distancing mandates were able to slow the growth of the virus within their communities (Courtemanche et al., 2020).",
      "startOffset" : 160,
      "endOffset" : 187
    }, {
      "referenceID" : 9,
      "context" : "stance-detection-in-covid-19-tweets resurgences of the novel coronavirus (Feuer and Rattner, 2020).",
      "startOffset" : 73,
      "endOffset" : 98
    }, {
      "referenceID" : 21,
      "context" : "Research in the area of stance detection has yielded accurate results, especially in the United States politics (Mohammad et al., 2017; Ghosh et al., 2019; Xu et al., 2020).",
      "startOffset" : 112,
      "endOffset" : 172
    }, {
      "referenceID" : 10,
      "context" : "Research in the area of stance detection has yielded accurate results, especially in the United States politics (Mohammad et al., 2017; Ghosh et al., 2019; Xu et al., 2020).",
      "startOffset" : 112,
      "endOffset" : 172
    }, {
      "referenceID" : 38,
      "context" : "Research in the area of stance detection has yielded accurate results, especially in the United States politics (Mohammad et al., 2017; Ghosh et al., 2019; Xu et al., 2020).",
      "startOffset" : 112,
      "endOffset" : 172
    }, {
      "referenceID" : 3,
      "context" : "become available in the last few years, including a large dataset (containing approximately 50,000 tweets) focused on the stance towards financial transactions that involve mergers and acquisition (Conforti et al., 2020), a dataset for identifying the stance in Twitter replies and quotes (Villa-Cox",
      "startOffset" : 197,
      "endOffset" : 220
    }, {
      "referenceID" : 11,
      "context" : "English (Hercig et al., 2017; Vychegzhanin and Kotelnikov, 2019; Evrard et al., 2020), and multilingual datasets (Zotova et al.",
      "startOffset" : 8,
      "endOffset" : 85
    }, {
      "referenceID" : 33,
      "context" : "English (Hercig et al., 2017; Vychegzhanin and Kotelnikov, 2019; Evrard et al., 2020), and multilingual datasets (Zotova et al.",
      "startOffset" : 8,
      "endOffset" : 85
    }, {
      "referenceID" : 8,
      "context" : "English (Hercig et al., 2017; Vychegzhanin and Kotelnikov, 2019; Evrard et al., 2020), and multilingual datasets (Zotova et al.",
      "startOffset" : 8,
      "endOffset" : 85
    }, {
      "referenceID" : 42,
      "context" : ", 2020), and multilingual datasets (Zotova et al., 2020; Vamvas and Sennrich, 2020; Lai et al., 2020).",
      "startOffset" : 35,
      "endOffset" : 101
    }, {
      "referenceID" : 29,
      "context" : ", 2020), and multilingual datasets (Zotova et al., 2020; Vamvas and Sennrich, 2020; Lai et al., 2020).",
      "startOffset" : 35,
      "endOffset" : 101
    }, {
      "referenceID" : 16,
      "context" : ", 2020), and multilingual datasets (Zotova et al., 2020; Vamvas and Sennrich, 2020; Lai et al., 2020).",
      "startOffset" : 35,
      "endOffset" : 101
    }, {
      "referenceID" : 22,
      "context" : "Furthermore, the global prevalence and impact of the COVID-19 pandemic has led to the quick development, concurrently with our work, of several COVID-19 stance-related Twitter datasets (Mutlu et al., 2020; Miao et al., 2020; Hossain et al., 2020).",
      "startOffset" : 185,
      "endOffset" : 246
    }, {
      "referenceID" : 19,
      "context" : "Furthermore, the global prevalence and impact of the COVID-19 pandemic has led to the quick development, concurrently with our work, of several COVID-19 stance-related Twitter datasets (Mutlu et al., 2020; Miao et al., 2020; Hossain et al., 2020).",
      "startOffset" : 185,
      "endOffset" : 246
    }, {
      "referenceID" : 13,
      "context" : "Furthermore, the global prevalence and impact of the COVID-19 pandemic has led to the quick development, concurrently with our work, of several COVID-19 stance-related Twitter datasets (Mutlu et al., 2020; Miao et al., 2020; Hossain et al., 2020).",
      "startOffset" : 185,
      "endOffset" : 246
    }, {
      "referenceID" : 31,
      "context" : "Marsh, 2016) and convolutional neural networks (CNNs) (Vijayaraghavan et al., 2016; Wei et al., 2016).",
      "startOffset" : 54,
      "endOffset" : 101
    }, {
      "referenceID" : 35,
      "context" : "Marsh, 2016) and convolutional neural networks (CNNs) (Vijayaraghavan et al., 2016; Wei et al., 2016).",
      "startOffset" : 54,
      "endOffset" : 101
    }, {
      "referenceID" : 0,
      "context" : "Later approaches were provided with both target and tweet representations as input, and employed RNNs and/or CNNs, together with the attention mechanism (Augenstein et al., 2016; Du et al., 2017; Zhou and Cristea, 2017; Sun et al., 2018; Siddiqua et al., 2019) to improve the performance of the SVM baselines.",
      "startOffset" : 153,
      "endOffset" : 260
    }, {
      "referenceID" : 6,
      "context" : "Later approaches were provided with both target and tweet representations as input, and employed RNNs and/or CNNs, together with the attention mechanism (Augenstein et al., 2016; Du et al., 2017; Zhou and Cristea, 2017; Sun et al., 2018; Siddiqua et al., 2019) to improve the performance of the SVM baselines.",
      "startOffset" : 153,
      "endOffset" : 260
    }, {
      "referenceID" : 41,
      "context" : "Later approaches were provided with both target and tweet representations as input, and employed RNNs and/or CNNs, together with the attention mechanism (Augenstein et al., 2016; Du et al., 2017; Zhou and Cristea, 2017; Sun et al., 2018; Siddiqua et al., 2019) to improve the performance of the SVM baselines.",
      "startOffset" : 153,
      "endOffset" : 260
    }, {
      "referenceID" : 28,
      "context" : "Later approaches were provided with both target and tweet representations as input, and employed RNNs and/or CNNs, together with the attention mechanism (Augenstein et al., 2016; Du et al., 2017; Zhou and Cristea, 2017; Sun et al., 2018; Siddiqua et al., 2019) to improve the performance of the SVM baselines.",
      "startOffset" : 153,
      "endOffset" : 260
    }, {
      "referenceID" : 25,
      "context" : "Later approaches were provided with both target and tweet representations as input, and employed RNNs and/or CNNs, together with the attention mechanism (Augenstein et al., 2016; Du et al., 2017; Zhou and Cristea, 2017; Sun et al., 2018; Siddiqua et al., 2019) to improve the performance of the SVM baselines.",
      "startOffset" : 153,
      "endOffset" : 260
    }, {
      "referenceID" : 5,
      "context" : ", 2017), especially bidirectional encoder representations from transformers (BERT) (Devlin et al., 2019), in NLP tasks, some recent works (Slovikovskaya and Attardi, 2020; Li and Caragea, 2021; Ghosh et al.",
      "startOffset" : 83,
      "endOffset" : 104
    }, {
      "referenceID" : 26,
      "context" : ", 2019), in NLP tasks, some recent works (Slovikovskaya and Attardi, 2020; Li and Caragea, 2021; Ghosh et al., 2019) have focused on investigating the use of BERT models for stance detection.",
      "startOffset" : 41,
      "endOffset" : 116
    }, {
      "referenceID" : 18,
      "context" : ", 2019), in NLP tasks, some recent works (Slovikovskaya and Attardi, 2020; Li and Caragea, 2021; Ghosh et al., 2019) have focused on investigating the use of BERT models for stance detection.",
      "startOffset" : 41,
      "endOffset" : 116
    }, {
      "referenceID" : 10,
      "context" : ", 2019), in NLP tasks, some recent works (Slovikovskaya and Attardi, 2020; Li and Caragea, 2021; Ghosh et al., 2019) have focused on investigating the use of BERT models for stance detection.",
      "startOffset" : 41,
      "endOffset" : 116
    }, {
      "referenceID" : 21,
      "context" : "form of auxiliary tasks in a multi-task framework), can help improve the performance obtained from the tweet/target information alone (Mohammad et al., 2017; Sun et al., 2019; Li and Caragea, 2019; Hosseinia et al., 2020; Xu et al., 2020).",
      "startOffset" : 134,
      "endOffset" : 238
    }, {
      "referenceID" : 27,
      "context" : "form of auxiliary tasks in a multi-task framework), can help improve the performance obtained from the tweet/target information alone (Mohammad et al., 2017; Sun et al., 2019; Li and Caragea, 2019; Hosseinia et al., 2020; Xu et al., 2020).",
      "startOffset" : 134,
      "endOffset" : 238
    }, {
      "referenceID" : 17,
      "context" : "form of auxiliary tasks in a multi-task framework), can help improve the performance obtained from the tweet/target information alone (Mohammad et al., 2017; Sun et al., 2019; Li and Caragea, 2019; Hosseinia et al., 2020; Xu et al., 2020).",
      "startOffset" : 134,
      "endOffset" : 238
    }, {
      "referenceID" : 14,
      "context" : "form of auxiliary tasks in a multi-task framework), can help improve the performance obtained from the tweet/target information alone (Mohammad et al., 2017; Sun et al., 2019; Li and Caragea, 2019; Hosseinia et al., 2020; Xu et al., 2020).",
      "startOffset" : 134,
      "endOffset" : 238
    }, {
      "referenceID" : 38,
      "context" : "form of auxiliary tasks in a multi-task framework), can help improve the performance obtained from the tweet/target information alone (Mohammad et al., 2017; Sun et al., 2019; Li and Caragea, 2019; Hosseinia et al., 2020; Xu et al., 2020).",
      "startOffset" : 134,
      "endOffset" : 238
    }, {
      "referenceID" : 34,
      "context" : "proaches to improve the performance, especially when the amount of labeled data for the task of interest is small, include weak supervision (Wei et al., 2019) and knowledge distillation (Miao et al.",
      "startOffset" : 140,
      "endOffset" : 158
    }, {
      "referenceID" : 19,
      "context" : ", 2019) and knowledge distillation (Miao et al., 2020); transfer learning through distant supervision",
      "startOffset" : 35,
      "endOffset" : 54
    }, {
      "referenceID" : 40,
      "context" : "(Zarrella and Marsh, 2016) or pre-trained models (Ebner et al.",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 7,
      "context" : "(Zarrella and Marsh, 2016) or pre-trained models (Ebner et al., 2019; Hosseinia et al., 2020); and domain adaptation from a source task to the target task (Xu et al.",
      "startOffset" : 49,
      "endOffset" : 93
    }, {
      "referenceID" : 14,
      "context" : "(Zarrella and Marsh, 2016) or pre-trained models (Ebner et al., 2019; Hosseinia et al., 2020); and domain adaptation from a source task to the target task (Xu et al.",
      "startOffset" : 49,
      "endOffset" : 93
    }, {
      "referenceID" : 38,
      "context" : "In particular, the Dual-view Adaptation Network (DAN) (Xu et al., 2020) learns to predict the stance of a tweet by combining the subjective and objective views/representations of the tweet, while also learning to adapt them across domains.",
      "startOffset" : 54,
      "endOffset" : 71
    }, {
      "referenceID" : 2,
      "context" : "According to (Cohen, 1960), the scores for stance and target of represent almost perfect agreement, while the score for sentiment shows substantial agreement.",
      "startOffset" : 13,
      "endOffset" : 26
    }, {
      "referenceID" : 24,
      "context" : "• BiLSTM: Bi-Directional Long Short Term Memory Networks (Schuster and Paliwal, 1997) take tweets as input, and are trained",
      "startOffset" : 57,
      "endOffset" : 85
    }, {
      "referenceID" : 6,
      "context" : "• TAN: Target-specific Attention Networks (Du et al., 2017) represent an attention-based BiL-",
      "startOffset" : 42,
      "endOffset" : 59
    }, {
      "referenceID" : 41,
      "context" : "• ATGRU: The Bi-Directional Gated Recurrent Unit Network with Token-Level Attention Mechanism (Zhou and Cristea, 2017) is an attention-based Bi-GRU model that also uses Opinion Towards Target (%) Stance Explicit Implicit Neither Favor 81.",
      "startOffset" : 94,
      "endOffset" : 118
    }, {
      "referenceID" : 39,
      "context" : "with Aspect Embedding (Xue and Li, 2018) is based on a CNN model.",
      "startOffset" : 22,
      "endOffset" : 40
    }, {
      "referenceID" : 5,
      "context" : "• BERT: Bidirectional Encoder Representations from Transformers (Devlin et al., 2019) represent language models that are pre-trained",
      "startOffset" : 64,
      "endOffset" : 85
    }, {
      "referenceID" : 23,
      "context" : "We used the pre-trained COVIDTwitter-BERT model3 (Müller et al., 2020).",
      "startOffset" : 49,
      "endOffset" : 70
    }, {
      "referenceID" : 36,
      "context" : "• BERT-NS: Self-training with Noisy Student (Xie et al., 2020) is a semi-supervised learning approach that employs self-training and knowledge distillation (Hinton et al.",
      "startOffset" : 44,
      "endOffset" : 62
    }, {
      "referenceID" : 12,
      "context" : ", 2020) is a semi-supervised learning approach that employs self-training and knowledge distillation (Hinton et al., 2015) to improve the performance of a teacher model using unlabeled data.",
      "startOffset" : 101,
      "endOffset" : 122
    }, {
      "referenceID" : 38,
      "context" : "• BERT-DAN: Dual-view Attention Networks (Xu et al., 2020) capture explicitly subjective and objective information contained in tweets,",
      "startOffset" : 41,
      "endOffset" : 58
    }, {
      "referenceID" : 10,
      "context" : "Finally, we can see that among the supervised baselines, the BERT model performs significantly better than all the other models, a result that is in agreement with prior works (Ghosh et al., 2019; Miao et al., 2020).",
      "startOffset" : 176,
      "endOffset" : 215
    }, {
      "referenceID" : 19,
      "context" : "Finally, we can see that among the supervised baselines, the BERT model performs significantly better than all the other models, a result that is in agreement with prior works (Ghosh et al., 2019; Miao et al., 2020).",
      "startOffset" : 176,
      "endOffset" : 215
    } ],
    "year" : 2021,
    "abstractText" : "The prevalence of the COVID-19 pandemic in day-to-day life has yielded large amounts of stance detection data on social media sites, as users turn to social media to share their views regarding various issues related to the pandemic, e.g. stay at home mandates and wearing face masks when out in public. We set out to make use of this data by collecting the stance expressed by Twitter users, with respect to topics revolving around the pandemic. We annotate a new stance detection dataset, called COVID-19-Stance. Using this newly annotated dataset, we train several established stance detection models to ascertain a baseline performance for this specific task. To further improve the performance, we employ self-training and domain adaptation approaches to take advantage of large amounts of unlabeled data and existing stance detection datasets. The dataset, code, and other resources are available on GitHub.1",
    "creator" : "LaTeX with hyperref"
  }
}