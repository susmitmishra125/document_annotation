{
  "name" : "2021.acl-long.257.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Probabilistic, Structure-Aware Algorithms for Improved Variety, Accuracy, and Coverage of AMR Alignments",
    "authors" : [ "Austin Blodgett", "Nathan Schneider" ],
    "emails" : [ "nathan.schneider}@georgetown.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3310–3321\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3310"
    }, {
      "heading" : "1 Introduction",
      "text" : "Research with the Abstract Meaning Representation (AMR; Banarescu et al., 2013), a broadcoverage semantic annotation framework in which sentences are paired with directed acyclic graphs, must contend with the lack of gold-standard alignments between words and semantic units in the English data. A variety of rule-based and statistical algorithms have sought to fill this void, with improvements in alignment accuracy often translating into improvements in AMR parsing accuracy (Pourdamghani et al., 2014; Naseem et al., 2019; Liu et al., 2018). Yet current alignment algorithms still suffer from limited coverage and less-than-ideal accuracy, constraining the design and accuracy of parsing algorithms. Where parsers use latent alignments (e.g., Lyu and Titov, 2018; Cai and Lam, 2020), explicit alignments can still facilitate evaluation and error analysis. Moreover, AMR-to-text generation research and applications using AMR stand to benefit from accurate, human-interpretable alignments.\nWe present Linguistically Enriched AMR (LEAMR) alignment, which achieves full graph cov-\nerage via four distinct types of aligned structures: subgraphs, relations, reentrancies, and duplicate subgraphs arising from ellipsis. This formulation lends itself to unsupervised learning of alignment models. Advantages of our algorithm and released alignments include: (1) much improved coverage over previous datasets, (2) increased variety of the substructures aligned, including alignments for all relations, and alignments for diagnosing reentrancies, (3) alignments are made between spans and connected substructures of an AMR, (4) broader identification of spans including named entities and verbal and prepositional multiword expressions.\nContributions are as follows: • A novel all-inclusive formulation of AMR\nalignment in terms of mappings between spans and connected subgraphs, including spans aligned to multiple subgraphs; mappings between spans and inter-subgraph edges; and characterization of reentrancies. Together these alignments fully cover the nodes and edges of the AMR graph (§3). • An algorithm combining rules and EM to align English sentences to AMRs without supervision (§5), achieving higher coverage and quality than existing AMR aligners (§7). • A corpus with automatic alignments for LDC2020 and Little Prince data as well as a few hundred manually annotated sentences for tuning and evaluation (§4).\nWe release this dataset of alignments for over 60,000 sentences along with our aligner code to facilitate more accurate models and greater interpretability in future AMR research."
    }, {
      "heading" : "2 Related Work",
      "text" : "The main difficulty presented by AMR alignment is that it is a many-to-many mapping problem, with gold alignments often mapping multiple tokens to\nmultiple nodes while preserving AMR structure. Previous systems use various strategies for aligning. They also have differing approaches to what types of substructures of AMR are aligned—whether they are nodes, subgraphs, or relations—and what they are aligned to—whether individual tokens, token spans, or syntactic parses. Two main alignment strategies remain dominant, though they may be combined or extended in various ways: rule-based strategies as in Flanigan et al. (2014), Flanigan et al. (2016), Liu et al. (2018), and Szubert et al. (2018), and statistical strategies using ExpectationMaximization as in Pourdamghani et al. (2014). JAMR. The JAMR system (Flanigan et al., 2014, 2016) aligns token spans to subgraphs using iterative application of an ordered list of 14 rules which include exact and fuzzy matching. JAMR alignments form a connected subgraph of the AMR by the nature of the rules being applied. A disadvantage of JAMR is that it lacks a method for resolving ambiguities, such as repeated tokens, or of learning novel alignment patterns. ISI. The ISI system (Pourdamghani et al., 2014) produces alignments between tokens and nodes and between tokens and relations via an ExpectationMaximization (EM) algorithm in the style of IBM Model 2 (Brown et al., 1988). First, the AMR is linearized; then EM is applied using a symmetrized scoring function of the form P(a ∣ t) + P(t ∣ a), where a is any node or edge in the linearized AMR and t is any token in the sentence. Graph connectedness is not enforced for the elements aligning to a given token. Compared to JAMR, ISI produces more novel alignment patterns, but also struggles with rare strings such as dates and names, where a rule-based approach is more appropriate. Extensions and Combinations. TAMR (Tuned Abstract Meaning Representation; Liu et al., 2018) uses the JAMR alignment rules, along with two others, to produce a set of candidate alignments for the sentence. Then, the alignments are “tuned” with a parser oracle to select the candidates that correspond to the oracle parse that is most similar to the gold AMR.\nSome AMR parsers (Naseem et al., 2019; Fernandez Astudillo et al., 2020) use alignments which are a union of alignments produced by the JAMR and ISI systems. The unioned alignments achieve greater coverage, improving parser performance. Syntax-based. Several alignment systems attempt to incorporate syntax into AMR alignments.\nChen and Palmer (2017) perform unsupervised EM alignment between AMR nodes and tokens, taking advantage of a Universal Dependencies (UD) syntactic parse as well as named entity and semantic role features. Szubert et al. (2018) and Chu and Kurohashi (2016) both produce hierachical (nested) alignments between AMR and a syntactic parse. Szubert et al. use a rule-based algorithm to align AMR subgraphs with UD subtrees. Chu and Kurohashi use a supervised algorithm to align AMR subgraphs with constituency parse subtrees. Word Embeddings. Additionally, Anchiêta and Pardo (2020) use an alignment method designed to work well in low-resource settings using pretrained word embeddings for tokens and nodes. Graph Distance. Wang and Xue (2017) use an HMM-based aligner to align tokens and nodes. They include in their aligner a calculation of graph distance as a locality constraint on predicted alignments. This is similar to our use of projection distance as described in §5. Drawbacks of Current Alignments. Alignment methods vary in terms of components of the AMR that are candidates for alignment. Most systems either align nodes (e.g., ISI) or connected subgraphs (e.g., JAMR), with incomplete coverage. Most current systems do not align relations to tokens or spans, and those that do (such as ISI) do so with low coverage and performance. None of the current systems align reentrancies, although Szubert et al. (2020) developed a rule-based set of heuristics for identifying reentrancy types. Table 1 summarizes the coverage and variety of prominent alignment systems."
    }, {
      "heading" : "3 An All-Inclusive Formulation of AMR Alignment",
      "text" : "Aligning AMRs to English sentences is a vexing problem not only because the English training data lacks gold alignments, but also because AMRs— unlike many semantic representations—are not designed with a derivational process of form–function subunits in mind. Rather, each AMR graph represents the full-sentence meaning, and AMR anno-\ntation conventions can be opaque with respect to the words or surface structure of the sentence, e.g., by unifying coreferent mentions and making explicit certain elided or pragmatically inferable concepts and relations. Previous efforts toward general tools for AMR alignment have considered mapping tokens, spans, or syntactic units to nodes, edges, or subgraphs (§2). Other approaches to AMR alignment have targeted specific compositional formalisms (Groschwitz et al., 2018; Beschke, 2019; Blodgett and Schneider, 2019).\nWe advocate here for a definition of alignment that is principled—achieving full coverage of the graph structure—while being framework-neutral and easy-to-understand, by aligning graph substructures to shallow token spans on the form side, rather than using syntactic parses. We do use structural considerations to constrain alignments on the meaning side, but by using spans on the form side, we ensure the definition of the alignment search space is not at the mercy of error-prone parsers.\nDefinitions. Given a tokenized sentence w and its corresponding AMR graph G, a complete alignment assumes a segmentation of w into spans s, each containing one or more contiguous tokens; and puts each of the nodes and edges of G in correspondence with some span in s. A span may be aligned to one or more parts of the AMR, or else is null-aligned. Individual alignments for a sentence are grouped into four layers: subgraph alignments, duplicate subgraph alignments, relation alignments, and reentrancy alignments. These are given for an example in figure 1.\nAll alignments are between a single span and a substructure of the AMR. A span may be aligned\nin multiple layers which are designed to capture different information. Within the subgraph layer, alignments are mutually exclusive with respect to both spans and AMR components. The same holds true within the relation layer. Every node will be aligned exactly once between the subgraph and duplicate subgraph layers. Every edge will be aligned exactly once between the subgraph and relation layers, and may additionally have a secondary alignment in the reentrancy layer."
    }, {
      "heading" : "3.1 Subgraph Layer",
      "text" : "Alignments in this layer generally reflect the lexical semantic content of words in terms of connected,1 directed acyclic subgraphs of the corresponding AMR. Alignments are mutually exclusive (disjoint) on both the form and meaning sides."
    }, {
      "heading" : "3.2 Duplicate Subgraph Layer",
      "text" : "A span may be aligned to multiple subgraphs if one is a duplicate of the others, with a matching concept. This is often necessary when dealing with ellipsis constructions, where there is more semantic content in the AMR than is pronounced in the sentence and thus several identical parts of the AMR must be aligned to the same span. In this case, a single subgraph is chosen as the primary alignment (whichever is first based on depth-first order) and is aligned in the subgraph alignment layer, and any others are represented in the duplicates alignment\n1Nodes aligned to a span must form a connected subgraph with two exceptions: (1) duplicate alignments are allowed and are separated into subgraph and duplicate layers; (2) a span may be aligned to two terminal nodes that have the same parent. For example, never aligns to :polarity - :time ever, two nodes and two edges which share the same parent.\nlayer. For example, verb phrase ellipsis, as in I swim and so do you, would involve duplication of the predicate swim, with distinct ARG0s. Similarly, in figure 1, Most of the students involves a subsetsuperset structure where the subset and superset correspond to separate nodes. Because student is represented in AMR like person who studies, there are two 2-node subgraphs aligned to student, one with the variables p and s, and the duplicate with p2 and s2. The difficulty that duplicate subgraphs pose for parsing and generation makes it convenient to put these alignments in a separate layer."
    }, {
      "heading" : "3.3 Relation Layer",
      "text" : "This layer includes alignments between a span and a single relation—such as when → :time— and alignments mapping a span to its argument structure—such as give → :ARG0 :ARG1 :ARG2. All edges in an AMR that are not contained in a subgraph fit into one of these two categories.\nEnglish function words such as prepositions and subordinators typically function as connectives between two semantically related words or phrases, and can often be identified with the semantics of AMR relations. But many of these function words are highly ambiguous. Relation alignments make their contribution explicit. For example, when in figure 1 aligns to a :time relation.\nFor spans that are aligned to a subgraph, incoming or outgoing edges attached to that subgraph may also be aligned to the span in the relation layer. These can include core or non-core roles as long as they are evoked by the token span. For example, figure 1 contains visit → :ARG0 :ARG1."
    }, {
      "heading" : "3.4 Reentrancy Layer",
      "text" : "A reentrant node is one with multiple incoming edges. In figure 1, for example, p appears three times: once as the ARG0 of w (the wanter), once as the ARG0 of v (the visitor), and once as the ARG0 of g (the graduate). The p node is labeled with the concept person—in the PENMAN notation used by annotators, each variable’s concept is only designated on one occurrence of the variable, the choice of occurrence being, in principle, arbitrary. These three ARG0 relations are aligned to their respective predicates in the relation layer. But there are many different causes of reentrancy, and AMR parsers stand to benefit from additional information about the nature of each reentrant edge, such as the fact that the pronoun they is associated with one of the ARG0 relations.\nThe reentrancy layer “explains” the cause of each reentrancy as follows: for the incoming edges of a reentrant node, one of these edges is designated as PRIMARY—this is usually the first mention of the entity in a local surface syntactic attachment, e.g. the argument of a control predicate like want doubles as an argument of an embedded clause predicate. The remaining incoming edges to a reentrant node are aligned to a reentrancy trigger and labeled with one of 8 reentrancy types: coref, repetition, coordination, control, adjunct control, unmarked adjunct control, comparative control, and pragmatic. These are illustrated in table 2. These types, adapted from Szubert et al.’s (2020) classification, correspond to different linguistic phenomena leading to AMR reentrancies—anaphoric and non-anaphoric coreference, coordination, control, etc. The trigger is the word that most directly signals the reentrancy phenomenon in question. For the example in figure 1, the control verb want is aligned to the embedded predicate–argument relation and typed as CONTROL, while the pronoun they serves as the trigger for the third instance of p in when they graduate."
    }, {
      "heading" : "3.5 Validation",
      "text" : "To validate the annotation scheme we elicited two gold-standard annotations for 40 of the test sentences described in §4 and measured interannotator agreement.2 Interannotator exact-match F1 scores were 94.54 for subgraphs, 90.73 for relations, 76.92 for reentrancies, and 66.67 for duplicate subgraphs (details in appendix A)."
    }, {
      "heading" : "4 Released Data",
      "text" : "We release a dataset3 of the four alignment layers reflecting correpondences between English text and various linguistic phenomena in gold AMR graphs—subgraphs, relations (including argument structures), reentrancies (including coreference, control, etc.), and duplicate subgraphs.\nAutomatic alignments cover the ≈60,000 sentences of the LDC2020T02 dataset (Knight et al., 2020) and ≈1,500 sentences of The Little Prince.\nWe manually created gold alignments for evaluating our automatic aligner, split into a development set (150 sentences) and a test set (200 sen-\n2Both annotators are Ph.D. students with backgrounds in linguistics. One annotator aligned all development and test sentences; the other aligned a subset of 40 test sentences.\n3https://github.com/ablodge/leamr\n(h / have-degree-91 :ARG1 (h2 / house :location (l / left)) :ARG2 (b / big) :ARG3 (m / more) :ARG4 (h3 / house :location (r / right)))\nFigure 2: AMR for the sentence “The house1 on the left is bigger than the house2 on the right.”\ntences).4 The test sentences were annotated from scratch; the development sentences were first automatically aligned and then hand-corrected. We stress that no preprocessing apart from tokenization is required to prepare the test sentences and AMRs for human annotation. We also release our annotation guidelines as a part of our data release."
    }, {
      "heading" : "5 LEAMR Aligner",
      "text" : "We formulate statistical models for the alignment layers described above—subgraphs, duplicate subgraphs, relations, and reentrancies—and use the Expectation-Maximization (EM) algorithm to estimate probability distributions without supervision, with a decoding procedure that constrains aligned units to obey structural requirements. In line with Flanigan et al. (2014, 2016), we use rulebased preprocessing to align some substructures using string-matching, morphological features, etc.\nBefore delving into the models and algorithm, we motivate two important characteristics: Structure-Preserving. Constraints on legal candidates during alignment ensure that at any point\n4Our test set consists of sentences from the test set of Szubert et al. (2018) but with AMRs updated to the latest release version. This test set contains a mix of English sentences drawn from the LDC data and The Little Prince—some sampled randomly, others hand-selected—as well as several sentences constructed to illustrate particular phenomena.\nonly connected substructures may be aligned to a span. Thus, while our aligner is probabilistic like the ISI aligner, it has the advantage of preserving the AMR graph structure. Projection Distance. The scores calculated for an alignment take into account a distance metric designed to encourage locality—tokens that are close together in a sentence are aligned to subtructures that are close together in the AMR graph. We define the projection distance dist(n1,n2) between two neighboring nodes n1 and n2 to be the signed distance in the corresponding sentence between the span aligned to n1 and the span aligned to n2. This motivates the model to prefer alignments whose spans are close together when aligning nodes which are close together—particularly useful when a word occurs twice with identical subgraphs. Thus, our aligner relies on more information from the AMR graph structure than other aligners (note that the ISI system linearizes the graph). Further details are given in §5.2."
    }, {
      "heading" : "5.1 Overview",
      "text" : "Algorithm 1 illustrates our base algorithm in pseudocode. The likelihood for a sentence can be expressed as a sum of per-span alignment scores: we write the score of a full set of a sentence’s subgraph alignments A as\nScore(A ∣ G,w) = N\n∏ i=1 score(⟨gi,si⟩ ∣ G,w) (1)\nwhere s are N aligned spans in the sentence w, and g are sets of subgraphs of the AMR graph G aligned to each span. For relations model and the reentrancies model, each gi consists of relations rather than\nsubgraphs. Henceforth we assume all alignment scores are conditioned on the sentence and graph and omit w and G for brevity. The score(⋅) component of eq. (1) is calculated differently for each of the three models detailed below.\nAlignment Pipeline. Alignment proceeds in the following phases, with each phase depending on the output of the previous phase: 1. Preprocessing: Using external tools we extract lemmas, parts of speech, and coreference. 2. Span Segmentation: Tokens are grouped into spans using a rule-based procedure (appendix B). 3. Align Subgraphs & Duplicate Subgraphs: We greedily identify subgraph and duplicate subgraph alignments in the same alignment phase (§5.2). 4. Align Relations: Relations not belonging to a subgraph are greedily aligned in this phase, using POS criteria to identify legal candidates (§5.3). 5. Align Reentrancies: Reentrancies are aligned in this phase, using POS and coreference in criteria for identifying legal candidates (§5.4).\nThe three main alignment phases use different models with different parameters; they also have their own preprocessing rules used to identify some alignments heuristically (appendices C to E).5 In training, parameters for each phase are iteratively learned and used to align the entire training set by running EM to convergence before moving on to the next phase. At test time, the pipeline can be run sentence-by-sentence.\nDecoding. The three main alignment phases all use essentially the same greedy, substructure-aware search procedure. This searches over node–span candidate pairs based on the scoring function modeling the compatibility between a subgraph (or relation) g and span s, which we denote score(⟨g,s⟩). For each unaligned node (or edge), we identify a set of legal candidate alignments using phase-specific criteria. The incremental score improvement of adding each candidate—either extending a subgraph/set of relations already aligned to the span, or adding a completely new alignment—is calculated as as ∆score = score(⟨g0∪{n},s⟩)−score(⟨g0,s⟩), where g0 is the current aligned subgraph, s is the span, and n is an AMR component being considered. Of the candidates for all unaligned nodes, the node–span pair giving the best score improvement is then greedily selected to add to the alignment.\n579% of nodes and 89% of edges are aligned by rules. We believe this is why in practice, EM performs well without random restarts.\nThis is repeated until all nodes have been aligned (even if the last ones decrease the score). The procedure is detailed in algorithm 1 for subgraphs; the relations phase and the reentrancies phase use different candidates (respectively: unaligned edges; reentrant edges), different criteria for legal candidates, and different scoring functions."
    }, {
      "heading" : "5.2 Aligning Subgraphs",
      "text" : "The score assigned to an alignment between a span and subgraph is calculated as score(⟨g,s⟩) =\nPalign(g ∣ s;θ1) ⋅∏ di∈D\nPdist(di;θ2) 1 ∣D∣ ⋅ IB(g,s) (2)\nwhere g is a subgraph, s is a span, di is the projection distance of g with its ith neighboring node, and θ1 and θ2 are model parameters which are updated after each iteration. The subgraph g is represented in the model as a bag of concept labels and (parent concept, relation, child concept) triples.\nThe distributions Palign and Pdist are inspired by IBM Model 2 (Brown et al., 1988), and can be thought of as graph-theoretic extensions of translation (align) and alignment (dist) probabilities. IB stands for inductive bias, explained below. Legal Candidates. For each unaligned node n, the model calculates a score for spans of three possible categories: 1) unaligned spans; 2) spans aligned to a neighboring node (in this case, the aligner considers adding n to an existing subgraph if the resulting subgraph would be connected); 3) spans aligned to a node with the same concept as n (this allows the aligner to identify duplicate subgraphs— candidates in this category receive a score penalty because duplicates are quite rare, so they are generally the option of last resort).\nLimiting the candidate spans in this way ensures only connected, plausible substructures of the AMR are aligned. To form a multinode subgraph alignment t1 → n1 :rel n2, the aligner could first align n1 to an unaligned span t1, then add n2, which is a legal candidate because t1 is aligned to a neighboring node of n2 (ensuring a connected subgraph). Distance. We model the probability of the projection distance Pdist(d;θ2) using a Skellam distribution, which is the difference of two Poisson distributed random variables D=N1−N2 and can be positive or negative valued. Parameters are updated based on alignments in the previous iteration. For each aligned neighbor ni of a subgraph g, we calculate Pdist(dist(g,ni);θ2) and take the geometric mean of probabilities as Pdist.\nAlgorithm 1 Procedure for greedily aligning all nodes to spans using a scoring function that decomposes over (span, subgraph) pairs. (Scores are expressed in real space but the implementation is in log space.) 1: function ALIGNSUBGRAPHS(spans, amr) 2: alignments← dict() ▷map from span to an ordered list of aligned subgraphs 3: unaligned_nodes← get_unaligned_nodes(amr, alignments) 4: while ∣unaligned_nodes∣ > 0 do 5: ∆scores← [] 6: candidate_s_g_pairs← [] 7: for n ∈ unaligned_nodes do 8: candidate_spans← get_legal_alignments(n, alignments) 9: for span, i_subgraph ∈ candidate_spans do ▷either there is an edge between n and the indicated subgraph\nalready aligned to span, or i_subgraph would be a new subgraph consisting of n 10: current_aligned_nodes← alignments[span][i_subgraph] ▷∅ if this would be a new subgraph 11: new_aligned_nodes← current_aligned_nodes ∪ {n} 12: ∆score← get_score(span, new_aligned_nodes, alignments) 13: − get_score(span, current_aligned_nodes, alignments) ▷change from adding n into a subgraph\naligned to span; get_score queries score(⟨g,s⟩) and multiplies λdup if i_subgraph > 1 14: ∆scores.add(∆score) 15: candidate_s_g_pairs.add((span, new_aligned_nodes, i_subgraph)) 16: span∗, subgraph∗, i_subgraph∗ ← candidate_s_g_pairs[argmax(∆scores)] ▷update having the best impact on score\n(equivalently, maximizing sum of scores across individual aligned spans) 17: alignments[span∗][i_subgraph∗]← subgraph∗ 18: unaligned_nodes← get_unaligned_nodes(amr, alignments) 19: return alignments\nNull alignment. The aligner models the possibility of a span being unaligned using a fixed heuristic:\nPalign(∅ ∣ s) =max{rank(s)− 1 2 ,0.01} (3)\nwhere rank assigns 1 to the most frequent word, 2 to the 2nd most frequent, etc. Thus, the model expects that very common words are more likely to be null-aligned and rare words should almost always be aligned.6 Factorized Backoff. So that the aligner generalizes to unseen subgraph–span pairs, where Palign(g ∣ s) = 0, we use a backoff factorization into components of the subgraph. In particular, the factors are empirical probabilities of (i) an AMR concept given a span string in the sentence, and (ii) a relation and child node concept given the parent node concept and span string. These cooccurrence probabilities p̂ are estimated directly from the training sentence/AMR pairs (irrespective of latent alignments). The product is scaled by a factor λ . E.g., for a subgraph n1 :rel1 n2 :rel2 n3, where cn is the concept of node n, we have\nPfactorized(g ∣ s) = λ ⋅ p̂(cn1 ∣ s) ⋅ p̂(:rel1,cn2 ∣ cn1,s) ⋅ p̂(:rel2,cn3 ∣ cn1,s) (4)\nInductive bias. Lastly, to encourage good initialization, the score function includes an inductive\n6We allow several exceptions. For punctuation, words in parentheses, and spans that are coreferent to another span, the probability is 0.5. For repeated spans, the probability is 0.1.\nbias which does not depend on EM-trained parameters. This inductive bias is based on the empirical probability of a node occurring in the same AMR with a span in the training data. We calculate inductive bias as an average of exponentiated PMIs 1 N ∑i exp(PMI(ni,s)), where N is the number of nodes in g, ni is the ith node contained in the subgraph, and PMI is the PMI of ni and s. Aligning Duplicate Subgraphs. On rare occasion a span should be aligned to multiple subgraphs (§3.2). To encourage the model to align a different span where possible, there is a constant penalty λdup for each additional subgraph aligned to a span beyond the first. Thus the score for a span and its subgraphs is computed as:\nscore(⟨g,s⟩) = λ ∣g∣−1dup ∏ g∈g score(⟨g,s⟩) (5)"
    }, {
      "heading" : "5.3 Aligning Relations",
      "text" : "For a given relation alignment between a span and a collection of edges, we calculate a score as follows:\nscore(⟨a,s⟩) = Palign(a ∣ s;θ3) ⋅ ∏ di∈D1\nPdist(di;θ4) 1 ∣D1 ∣\n⋅ ∏ d j∈D2\nPdist(d j;θ5) 1 ∣D2 ∣ (6)\nwhere a is the argument structure (the collection of aligned edges), s is a span, D1 is the projection distances of each edge and its parent, and D2 is\nthe projection distances of each edge and its child. The collection of edges a is given a normalized label which represents the relations contained in the alignment (distinguishing incoming versus outgoing relations, and normalizing inverse edges).\nLegal Candidates. There are two kinds of candidate spans for relation alignment. First, previously unaligned spans7 (with no relation or subgraph alignments), e.g. prepositions and subordinating conjunctions such as in → :location or when → :time. Second, any spans aligned to the relation’s parent or child in the subgraph layer: this facilitates alignment of argument structures such as give → :ARG0 :ARG1 :ARG2. Additionally, we constrain certain types of edges to only align with the parent and others to only align with the child.\nDistance. For relations there are potentially two distances of interest—the projected distance of the relation from its parent and the projected distance of the relation from its child. We model these separately as parent distance and child distance with distinct parameters. To see why this is useful, consider the sentence “Should we meet at the restaurant or at the office?”, where each at token should be aligned to a :location edge. In English, prepositions like at precede an object and follow a governor. Thus parent distance tends to be to the left (negative valued) while child distance tends to be to the right (positive valued).\n7We constrain these to particular parts of speech: prepositions (IN), infinitival to (TO), possessives (POS), and possessive pronouns (PRP$). Additionally, only spans that are between the spans aligned to the parent and any descendent of child nodes of the relation (and are not between the child’s aligned span and any of its descendants’ spans) are allowed. This works well in practice for English."
    }, {
      "heading" : "5.4 Aligning Reentrancies",
      "text" : "The probability of a reentrancy alignment is similar to eq. (6), but with an extra variable for the reentrancy type: score(⟨r,s, type⟩) =\nPalign(r, type ∣ s;θ6) ⋅Pdist(d1;θ7) ⋅Pdist(d2;θ8) (7)\nwhere r is the role label of the reentrant edge.\nLegal Candidates. There are 8 reentrancy types (§3.4). For each type, a rule-based test determines if a span and edge are permitted to be aligned. The 8 tests use part of speech, the structure of the AMR, and subgraph and relation alignments. A span may be aligned (rarely) to multiple reentrancies, but these alignments are scored separately."
    }, {
      "heading" : "6 Experimental Setup",
      "text" : "Sentences are preprocessed with the Stanza library (Qi et al., 2020) to obtain lemmas, part-of-speech tags, and named entities. We identify token spans using a combination of named entities and a fixed list of multiword expressions (details are given in appendix B). Coreference information, which is used to identify legal candidates in the reentrancy alignment phase, is obtained using NeuralCoref.8 Lemmas are used in each alignment phase to normalize representation of spans, while parts of speech and coreference are used to restrict legal candidates in the relation and reentrancy alignment phases. We tune hyperparameters, including penalties for duplicate alignments and our factorized backoff probability, on the development set.\n8https://github.com/huggingface/neuralcoref"
    }, {
      "heading" : "7 Results",
      "text" : "Table 3 describes our main results on the 200- sentence test set (§4), reporting exact-match and partial-match alignment scores as well as span identification F1 and coverage.9 The partial alignment evaluation metric is designed to be more forgiving of arbitrary or slight differences between alignment systems. We argue that this metric is more comparable across alignment systems. It assigns partial credit equal to the product of Jaccard indices ∣N1∩N2∣ ∣N1∪N2∣ ⋅ ∣T1∩T2∣ ∣T1∪T2∣ for nodes (or edges) and tokens respectively. This partial credit is calculated for each gold alignment and the closest matching predicted alignment with nodes (or edges) N1 and N2 and tokens T1 and T2. Coverage is the percentage of relevant AMR components that are aligned.\nOur aligner shows improvements over previous aligners in terms of coverage and accuracy even when using a partial credit metric for evaluation. We demonstrate greater coverage, including coverage of phenomena not aligned by previous systems.\nTable 4 shows detailed results for relation subtypes and reentrancy subtypes. Here, we see room for improvement. In particular, ISI outperforms our system at aligning single relations. Our reentrancy aligner lacks a baseline to compare to, but the breakdown of results by type suggest there are several categories of reentrancies where scores could be improved. Qualitative Analysis. A number of errors from our subgraph aligner resulted from unseen mul-\n9A previous draft of this work reported lower scores on relations before a constraint was added to improve the legal candidates for relation alignment.\ntiword expressions in our test data that our span preprocessing failed to recognize and our aligner failed to align. For example, the expression “on the one hand” appears in test and should be aligned to contrast-01. The JAMR aligner suffers without a locality bias; we notice several cases where it misaligns words that are repeated in the sentence. The ISI aligner generally does not align very frequent nodes such as person, thing, country, or name, resulting in generally lower coverage. It also frequently aligns disconnected nodes with the same concept to one token instead of separate tokens. While our relation aligner yields significantly higher coverage, we do observe that the model is overeager to align relations to extremely frequent prepositions (such as to and of ), resulting in lower precision of single relations in particular. Ablations. Table 5 shows that projection distance is valuable, adding 1.20 points (exact align F1) for subgraph alignment and 0.57 points for relation alignment. Despite showing anecdotal benefits in early experiments, the inductive bias does not aid the model in a statistically significant way. Using gold subgraphs for relation alignment produces an improvement of over 5 points, indicating the scope of error propagation for the relation aligner."
    }, {
      "heading" : "8 Conclusions",
      "text" : "We demonstrate structure-aware AMR aligners that combine the best parts of rule-based and statistical methods for AMR alignment. We improve on previous systems in terms of accuracy and particularly in terms of alignment coverage and variety of AMR components to be aligned."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank reviewers for their thoughtful feedback, Jakob Prange for assisting with annotation, and members of the NERT lab for their support."
    }, {
      "heading" : "C Rule-based Subgraph Alignment Preprocessing",
      "text" : "C.1 Token matching\nWe use three phases of rule-based alignment which attempt to align particular spans to particular AMR subgraphs: 1. Exact token matching: If there is a unique full string correspondence between a span and a name or number in the AMR, they are aligned. 2. Exact lemma matching: If there is a unique correspondence between an AMR concept and the lemma of a span (which in the case of a multiword span is the sequence of lemmas of the tokens joined by hyphens), they are aligned. 3. Prefix token matching: A span with a prefix match of length 6, 5, or 4 is aligned if it uniquely corresponds to an AMR named entity. 4. Prefix lemma matching: A span with a prefix match of length 6, 5, or 4 of its lemma is aligned if it uniquely corresponds to an concept. 5. English rules: Several hand-written rules for matching English strings to specific subgraphs are used to match constructions such as dates, currency, and some frequent AMR concepts with many different ways of being expressed, such as and and -.\n• Parsing dates and times • Numbers written out (e.g., one, two, thousand,\netc.) • Currencies (e.g., $, C, etc.) • Decades (e.g., twenties, nineties) • and (matching and, additionally, as well, etc.) • multi-sentence (matching punctuation) • :polarity - (matching not, none, never,\netc.) • cause-01 (matching thus, since, because,\netc.) • amr-unknown (matching ?, who, when, etc.) • person (matching people) • rate-entity-91 (matching daily, weekly,\netc.) • \"United\" \"States\" (matching US, U.S.,\nAmerican, etc.) • include-91 (matching out of, include, etc.) • instead-of-91 (matching instead, etc.) • have-03 (matching have, ’s, etc.) • mean-01 (matching : and ,) • how (matching :manner thing or :degree so) • as. . . as (matching equal)\nC.2 Graph rules\nWe also perform preprocessing to expand a subgraph alignment to include some neighboring nodes. These fall into two main categories: 1. Some AMR concepts are primarily notational rather than linguistic and should be aligned together with a neighboring node. For example named entities (e.g., (country :name (n/name :op1 :United\" :op2 \"Kingdom\"))) are aligned as a unit rather than one node at a time. Likewise, date entities, and subgraphs matching (x/X-quantity :unit X :quant X) or (x/X-entity :value X) are also aligned as a unit. 2. Neighboring nodes which are associated with morphological information of the aligned span (e.g., biggest → (have-degree-91 :ARG1 big :ARG2 most)) are added to the alignment using a series of rules for identifying comparatives, superlatives, polarity, and suffixes such as -er or -able, etc."
    }, {
      "heading" : "D Rule-based Relation Alignment Preprocessing",
      "text" : "Many of the relations are forced to be aligned in a particular way as a matter of convention. We use a similar approach to that of (Groschwitz et al.,\n2018). 1. :ARGX edges are automatically aligned to the same span as the parent (:ARGX-of edges are automatically aligned to the child). 2. :opX edges are automatically aligned with the parent. 3. :sntX edges are automatically aligned with the parent. 4. :domain edges are automatically aligned with the parent. (We don’t align these edges to copula. Instead, a concept with a :domain edge is thought of as a predicate which takes one argument.) 5. :name, :polarity, and :li edges are automatically aligned with the child.\nD.1 Token matching Some relations take the form :prep-X or :conj-X where X is a preposition or conjunction in the sentence. We use exact match to align these relations as a preprocessing step. The relations :poss and :part may be automatically aligned to ’s or of if the correspondence is unique within a sentence."
    }, {
      "heading" : "E Rule-based Reentrancy Alignment Preprocessing",
      "text" : "Primary edges are identified as a preprocessing step before aligning reentrancies with the following rules: Any relation which is aligned to the same span as its token (any incoming edge which is a part of a span’s argument structure) is automatically made the primary edge. Otherwise, for each edge pointing to a node, we identify the spans aligned to the parent and child nodes in the subgraph layer. Whichever edge has the shortest distance between the span aligned to the parent and the span aligned to the child is identified as the primary edge. In the event of a tie, the edge whose parent is aligned to the leftmost span is identified as the primary edge. Primary reentrancy edges are always aligned to the same span the edge is aligned to in the relation layer of alignments."
    } ],
    "references" : [ {
      "title" : "Semantically inspired AMR alignment for the Portuguese language",
      "author" : [ "Rafael Anchiêta", "Thiago Pardo." ],
      "venue" : "Proc. of EMNLP, pages 1595–1600, Online.",
      "citeRegEx" : "Anchiêta and Pardo.,? 2020",
      "shortCiteRegEx" : "Anchiêta and Pardo.",
      "year" : 2020
    }, {
      "title" : "Abstract Meaning Representation for sembanking",
      "author" : [ "Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider." ],
      "venue" : "Proc. of the 7th Linguistic An-",
      "citeRegEx" : "Banarescu et al\\.,? 2013",
      "shortCiteRegEx" : "Banarescu et al\\.",
      "year" : 2013
    }, {
      "title" : "Exploring graph-algebraic CCG combinators for syntactic-semantic AMR parsing",
      "author" : [ "Sebastian Beschke." ],
      "venue" : "Proc. of RANLP, pages 112–121, Varna, Bulgaria.",
      "citeRegEx" : "Beschke.,? 2019",
      "shortCiteRegEx" : "Beschke.",
      "year" : 2019
    }, {
      "title" : "An improved approach for semantic graph composition with CCG",
      "author" : [ "Austin Blodgett", "Nathan Schneider." ],
      "venue" : "Proc. of the 13th International Conference on Computational Semantics - Long Papers, pages 55–70, Gothenburg, Sweden.",
      "citeRegEx" : "Blodgett and Schneider.,? 2019",
      "shortCiteRegEx" : "Blodgett and Schneider.",
      "year" : 2019
    }, {
      "title" : "A statistical approach to language translation",
      "author" : [ "P. Brown", "J. Cocke", "S. Della Pietra", "V. Della Pietra", "F. Jelinek", "R. Mercer", "P. Roossin." ],
      "venue" : "Proc. of COLING, pages 71–76, Budapest, Hungary.",
      "citeRegEx" : "Brown et al\\.,? 1988",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 1988
    }, {
      "title" : "AMR parsing via graphsequence iterative inference",
      "author" : [ "Deng Cai", "Wai Lam." ],
      "venue" : "Proc. of ACL, pages 1290–1301, Online.",
      "citeRegEx" : "Cai and Lam.,? 2020",
      "shortCiteRegEx" : "Cai and Lam.",
      "year" : 2020
    }, {
      "title" : "Unsupervised AMR-dependency parse alignment",
      "author" : [ "Wei-Te Chen", "Martha Palmer." ],
      "venue" : "Proc. of EACL, pages 558–567, Valencia, Spain.",
      "citeRegEx" : "Chen and Palmer.,? 2017",
      "shortCiteRegEx" : "Chen and Palmer.",
      "year" : 2017
    }, {
      "title" : "Supervised syntax-based alignment between English sentences and Abstract Meaning Representation graphs",
      "author" : [ "Chenhui Chu", "Sadao Kurohashi." ],
      "venue" : "arXiv:1606.02126 [cs].",
      "citeRegEx" : "Chu and Kurohashi.,? 2016",
      "shortCiteRegEx" : "Chu and Kurohashi.",
      "year" : 2016
    }, {
      "title" : "Transition-based parsing with stackTransformers",
      "author" : [ "Ramón Fernandez Astudillo", "Miguel Ballesteros", "Tahira Naseem", "Austin Blodgett", "Radu Florian." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages",
      "citeRegEx" : "Astudillo et al\\.,? 2020",
      "shortCiteRegEx" : "Astudillo et al\\.",
      "year" : 2020
    }, {
      "title" : "CMU at SemEval-2016 Task 8: Graph-based AMR parsing with infinite ramp loss",
      "author" : [ "Jeffrey Flanigan", "Chris Dyer", "Noah A. Smith", "Jaime Carbonell." ],
      "venue" : "Proc. of SemEval, pages 1202–1206, San Diego, California.",
      "citeRegEx" : "Flanigan et al\\.,? 2016",
      "shortCiteRegEx" : "Flanigan et al\\.",
      "year" : 2016
    }, {
      "title" : "A discriminative graph-based parser for the Abstract Meaning Representation",
      "author" : [ "Jeffrey Flanigan", "Sam Thomson", "Jaime Carbonell", "Chris Dyer", "Noah A. Smith." ],
      "venue" : "Proc. of ACL, pages 1426–1436, Baltimore, Maryland, USA.",
      "citeRegEx" : "Flanigan et al\\.,? 2014",
      "shortCiteRegEx" : "Flanigan et al\\.",
      "year" : 2014
    }, {
      "title" : "Abstract Meaning Representation (AMR) Annotation",
      "author" : [ "Kevin Knight", "Bianca Badarau", "Laura Baranescu", "Claire Bonial", "Kira Griffitt", "Ulf Hermjakob", "Daniel Marcu", "Tim O’Gorman", "Martha Palmer", "Nathan Schneider", "Madalina Bardocz" ],
      "venue" : null,
      "citeRegEx" : "Knight et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Knight et al\\.",
      "year" : 2020
    }, {
      "title" : "An AMR aligner tuned by transition-based parser",
      "author" : [ "Yijia Liu", "Wanxiang Che", "Bo Zheng", "Bing Qin", "Ting Liu." ],
      "venue" : "Proc. of EMNLP, pages 2422–2430, Brussels, Belgium.",
      "citeRegEx" : "Liu et al\\.,? 2018",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2018
    }, {
      "title" : "AMR parsing as graph prediction with latent alignment",
      "author" : [ "Chunchuan Lyu", "Ivan Titov." ],
      "venue" : "Proc. of ACL, pages 397–407, Melbourne, Australia.",
      "citeRegEx" : "Lyu and Titov.,? 2018",
      "shortCiteRegEx" : "Lyu and Titov.",
      "year" : 2018
    }, {
      "title" : "Rewarding smatch: transition-based AMR parsing with reinforcement learning",
      "author" : [ "Tahira Naseem", "Abhishek Shah", "Hui Wan", "Radu Florian", "Salim Roukos", "Miguel Ballesteros." ],
      "venue" : "Proc. of ACL, pages 4586–4592, Florence, Italy.",
      "citeRegEx" : "Naseem et al\\.,? 2019",
      "shortCiteRegEx" : "Naseem et al\\.",
      "year" : 2019
    }, {
      "title" : "Aligning English strings with Abstract Meaning Representation graphs",
      "author" : [ "Nima Pourdamghani", "Yang Gao", "Ulf Hermjakob", "Kevin Knight." ],
      "venue" : "Proc. of EMNLP, pages 425–429, Doha, Qatar.",
      "citeRegEx" : "Pourdamghani et al\\.,? 2014",
      "shortCiteRegEx" : "Pourdamghani et al\\.",
      "year" : 2014
    }, {
      "title" : "Stanza: A Python natural language processing toolkit for many human languages",
      "author" : [ "Peng Qi", "Yuhao Zhang", "Yuhui Zhang", "Jason Bolton", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Qi et al\\.,? 2020",
      "shortCiteRegEx" : "Qi et al\\.",
      "year" : 2020
    }, {
      "title" : "Comprehensive supersense disambiguation of English prepositions and possessives",
      "author" : [ "Nathan Schneider", "Jena D. Hwang", "Vivek Srikumar", "Jakob Prange", "Austin Blodgett", "Sarah R. Moeller", "Aviram Stern", "Adi Bitan", "Omri Abend." ],
      "venue" : "Proc. of ACL,",
      "citeRegEx" : "Schneider et al\\.,? 2018",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2018
    }, {
      "title" : "A corpus and model integrating multiword expressions and supersenses",
      "author" : [ "Nathan Schneider", "Noah A. Smith." ],
      "venue" : "Proc. of NAACL-HLT, pages 1537– 1547, Denver, Colorado.",
      "citeRegEx" : "Schneider and Smith.,? 2015",
      "shortCiteRegEx" : "Schneider and Smith.",
      "year" : 2015
    }, {
      "title" : "The role of reentrancies in Abstract Meaning Representation parsing",
      "author" : [ "Ida Szubert", "Marco Damonte", "Shay B. Cohen", "Mark Steedman." ],
      "venue" : "Proc. of Findings of EMNLP, pages 2198–2207, Online.",
      "citeRegEx" : "Szubert et al\\.,? 2020",
      "shortCiteRegEx" : "Szubert et al\\.",
      "year" : 2020
    }, {
      "title" : "A structured syntax-semantics interface for EnglishAMR alignment",
      "author" : [ "Ida Szubert", "Adam Lopez", "Nathan Schneider." ],
      "venue" : "Proc. of NAACL-HLT, pages 1169–1180, New Orleans, Louisiana.",
      "citeRegEx" : "Szubert et al\\.,? 2018",
      "shortCiteRegEx" : "Szubert et al\\.",
      "year" : 2018
    }, {
      "title" : "Getting the most out of AMR Parsing",
      "author" : [ "Chuan Wang", "Nianwen Xue." ],
      "venue" : "Proc. of EMNLP, pages 1257–1268, Copenhagen, Denmark.",
      "citeRegEx" : "Wang and Xue.,? 2017",
      "shortCiteRegEx" : "Wang and Xue.",
      "year" : 2017
    }, {
      "title" : "2018) (b) 348 verbal MWEs from STREUSLE (c) 1095 MWEs taken from gold AMRs in LDC",
      "author" : [ "Schneider", "Smith" ],
      "venue" : null,
      "citeRegEx" : "Schneider et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "tation (AMR; Banarescu et al., 2013), a broadcoverage semantic annotation framework in which sentences are paired with directed acyclic graphs, must contend with the lack of gold-standard alignments between words and semantic units in the English data.",
      "startOffset" : 7,
      "endOffset" : 36
    }, {
      "referenceID" : 5,
      "context" : "Where parsers use latent alignments (e.g., Lyu and Titov, 2018; Cai and Lam, 2020), explicit alignments can still facilitate evaluation and error analysis.",
      "startOffset" : 36,
      "endOffset" : 82
    }, {
      "referenceID" : 9,
      "context" : "Two main alignment strategies remain dominant, though they may be combined or extended in various ways: rule-based strategies as in Flanigan et al. (2014), Flanigan et al.",
      "startOffset" : 132,
      "endOffset" : 155
    }, {
      "referenceID" : 9,
      "context" : "Two main alignment strategies remain dominant, though they may be combined or extended in various ways: rule-based strategies as in Flanigan et al. (2014), Flanigan et al. (2016), Liu et al.",
      "startOffset" : 132,
      "endOffset" : 179
    }, {
      "referenceID" : 9,
      "context" : "Two main alignment strategies remain dominant, though they may be combined or extended in various ways: rule-based strategies as in Flanigan et al. (2014), Flanigan et al. (2016), Liu et al. (2018), and Szubert et al.",
      "startOffset" : 132,
      "endOffset" : 198
    }, {
      "referenceID" : 9,
      "context" : "Two main alignment strategies remain dominant, though they may be combined or extended in various ways: rule-based strategies as in Flanigan et al. (2014), Flanigan et al. (2016), Liu et al. (2018), and Szubert et al. (2018), and statistical strategies using ExpectationMaximization as in Pourdamghani et al.",
      "startOffset" : 132,
      "endOffset" : 225
    }, {
      "referenceID" : 9,
      "context" : "Two main alignment strategies remain dominant, though they may be combined or extended in various ways: rule-based strategies as in Flanigan et al. (2014), Flanigan et al. (2016), Liu et al. (2018), and Szubert et al. (2018), and statistical strategies using ExpectationMaximization as in Pourdamghani et al. (2014).",
      "startOffset" : 132,
      "endOffset" : 316
    }, {
      "referenceID" : 15,
      "context" : "The ISI system (Pourdamghani et al., 2014) produces alignments between tokens and nodes and between tokens and relations via an Expectation-",
      "startOffset" : 15,
      "endOffset" : 42
    }, {
      "referenceID" : 4,
      "context" : "Maximization (EM) algorithm in the style of IBM Model 2 (Brown et al., 1988).",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 12,
      "context" : "TAMR (Tuned Abstract Meaning Representation; Liu et al., 2018) uses the JAMR alignment rules, along with two others, to produce a set of candidate alignments for the sentence.",
      "startOffset" : 5,
      "endOffset" : 62
    }, {
      "referenceID" : 14,
      "context" : "Some AMR parsers (Naseem et al., 2019; Fernandez Astudillo et al., 2020) use alignments which are a union of alignments produced by the JAMR and ISI systems.",
      "startOffset" : 17,
      "endOffset" : 72
    }, {
      "referenceID" : 0,
      "context" : "Additionally, Anchiêta and Pardo (2020) use an alignment method designed to",
      "startOffset" : 14,
      "endOffset" : 40
    }, {
      "referenceID" : 21,
      "context" : "Wang and Xue (2017) use an HMM-based aligner to align tokens and nodes.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 19,
      "context" : "None of the current systems align reentrancies, although Szubert et al. (2020) developed a rule-based set of heuristics for identifying reentrancy types.",
      "startOffset" : 57,
      "endOffset" : 79
    }, {
      "referenceID" : 19,
      "context" : "These types, adapted from Szubert et al.’s (2020) classification, correspond to different linguistic phenomena leading to AMR reentrancies—anaphoric and non-anaphoric coreference, coordination, control,",
      "startOffset" : 26,
      "endOffset" : 50
    }, {
      "referenceID" : 11,
      "context" : "Automatic alignments cover the ≈60,000 sentences of the LDC2020T02 dataset (Knight et al., 2020) and ≈1,500 sentences of The Little Prince.",
      "startOffset" : 75,
      "endOffset" : 96
    }, {
      "referenceID" : 19,
      "context" : "4Our test set consists of sentences from the test set of Szubert et al. (2018) but with AMRs updated to the latest release version.",
      "startOffset" : 57,
      "endOffset" : 79
    }, {
      "referenceID" : 4,
      "context" : "The distributions Palign and Pdist are inspired by IBM Model 2 (Brown et al., 1988), and can be",
      "startOffset" : 63,
      "endOffset" : 83
    }, {
      "referenceID" : 16,
      "context" : "Sentences are preprocessed with the Stanza library (Qi et al., 2020) to obtain lemmas, part-of-speech tags, and named entities.",
      "startOffset" : 51,
      "endOffset" : 68
    } ],
    "year" : 2021,
    "abstractText" : "We present algorithms for aligning components of Abstract Meaning Representation (AMR) graphs to spans in English sentences. We leverage unsupervised learning in combination with heuristics, taking the best of both worlds from previous AMR aligners. Our unsupervised models, however, are more sensitive to graph substructures, without requiring a separate syntactic parse. Our approach covers a wider variety of AMR substructures than previously considered, achieves higher coverage of nodes and edges, and does so with higher accuracy. We will release our LEAMR datasets and aligner for use in research on AMR parsing, generation, and evaluation.",
    "creator" : "LaTeX with hyperref"
  }
}