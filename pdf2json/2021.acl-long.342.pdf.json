{
  "name" : "2021.acl-long.342.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Semantic Representation for Dialogue Modeling",
    "authors" : [ "Xuefeng Bai", "Yulong Chen", "Linfeng Song", "Yue Zhang" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4430–4445\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4430"
    }, {
      "heading" : "1 Introduction",
      "text" : "Dialogue systems have received increasing research attention (Wen et al., 2015; Serban et al., 2017; Bao et al., 2020), with much recent work focusing on social chats (Ritter et al., 2011; Li et al., 2017) and task-oriented dialogues (Wen et al., 2017; Dinan et al., 2019). There are two salient subtasks in dialogue modeling, namely dialogue understanding (Choi et al., 2018; Reddy et al., 2019; Yu et al., 2020) and response generation (Li et al., 2017; Budzianowski et al., 2018). The former refers to understanding of semantic and discourse details in a dialogue history, and the latter concerns making a fluent, novel and coherent utterance.\nThe current state-of-the-art methods employ neural networks and end-to-end training (Sutskever et al., 2014; Bahdanau et al., 2015) for dialogue modeling. For instance, sequence-to-sequence models have been used to encode a dialogue history, before directly synthesizing the next utterance (Vinyals and Le, 2015; Wen et al., 2017; Bao et al.,\n2020). Despite giving strong empirical results, neural models can suffer from spurious feature associations in their neural semantic representation (Poliak et al., 2018; Kaushik et al., 2020), which can lead to weak robustness, inducing irrelevant dialogue states (Xu and Sarikaya, 2014; Sharma et al., 2019; Rastogi et al., 2019) and generating unfaithful or irrelevant text (Maynez et al., 2020; Niu and Bansal, 2020). As shown in Figure 1, the baseline Transformer model pays attention to the word “lamb” but ignores its surrounding context, which has important contents (marked with squares) that indicate its true meaning, thereby giving an irrelevant response that is related to food. Intuitively, such issues can be alleviated by having a structural representation of semantic information, which treats entities as nodes and builds structural relations between nodes, making it easy to find the most salient context. Explicit structures are also more interpretable compared to\nneural representation and have been shown useful for information extraction (Strubell et al., 2018; Sun et al., 2019; Li et al., 2020; Bai et al., 2021; Sachan et al., 2021), summarization (Liu et al., 2015; Hardy and Vlachos, 2018; Liao et al., 2018) and machine translation (Marcheggiani et al., 2018; Song et al., 2019a).\nWe explore AMR (Banarescu et al., 2013) as a semantic representation for dialogue histories in order to better represent conversations. As shown in the central block of Figure 2, AMR is one type of sentential semantic representations, which models a sentence using a rooted directed acyclic graph, highlighting its main concepts (e.g. “mistake”) and semantic relations (e.g., “ARG0”1), while abstracting away function words. It can thus potentially offer core concepts and explicit structures needed for aggregating the main content in dialogue. In addition, AMR can also be useful for reducing the negative influence of variances in surface forms with the same meaning, which adds to data sparsity.\nExisting work on AMR parsing focuses on the sentence level. However, as the left block of Figure 2 shows, the semantic structure of a dialogue history can consist of rich cross-utterance coreference links (marked with squares) and multiple speaker interactions. To this end, we propose an algorithm to automatically derive dialogue-level AMRs from utterance-level AMRs, by adding cross-utterance links that indicate speakers, identical mentions and co-reference links. One example is shown in the right block of Figure 2, where newly added edges are in color. We consider two main approaches of making use of such dialogue-level AMR structures. For the first method, we merge an AMR with tokens in its corresponding sentence via AMR-to-text alignments, before encoding the resulting structure using a graph Transformer (Zhu et al., 2019). For the second method, we separately encode an AMR and its corresponding sentence, before leveraging both representations via feature fusion (Mangai et al., 2010) or dual attention (Calixto et al., 2017).\nWe verify the effectiveness of the proposed framework on a dialogue relation extraction task (Yu et al., 2020) and a response generation task (Li et al., 2017). Experimental results show that the proposed framework outperforms previous\n1Please refer to PropBank (Kingsbury and Palmer, 2002; Palmer et al., 2005) for more details.\nmethods (Vaswani et al., 2017; Bao et al., 2020; Yu et al., 2020), achieving the new state-of-the-art results on both benchmarks. Deep analysis and human evaluation suggest that semantic information introduced by AMR can help our model to better understand long dialogues and improve the coherence of dialogue generation. One more advantage is that AMR is helpful to enhance the robustness and has a potential to improve the interpretability of neural models. To our knowledge, this is the first attempt to leverage the AMR semantic representation into neural networks for dialogue understanding and generation. Our code is available at https://github.com/muyeby/AMR-Dialogue."
    }, {
      "heading" : "2 Constructing Dialogue AMRs",
      "text" : "Figure 2 illustrates our method for constructing a dialogue-level AMR graph from multiple utterancelevel AMRs. Given a dialogue consisting multiple utterances, we adopt a pretrained AMR parser (Cai and Lam, 2020) to obtain an AMR graph for each utterance. For utterances containing multiple sentences, we parse them into multiple AMR graphs, and mark them belonging to the same utterance. We construct each dialogue AMR graph by making connections between utterance AMRs. In particular, we take three strategies according to speaker, identical concept and co-reference information.\nSpeaker We add a dummy node and connect it to all root nodes of utterance AMRs. We add speaker tags (e.g., SPEAKER1 and SPEAKER2) to the edges to distinguish different speakers. The dummy node ensures that all utterance AMRs are connected so that information can be exchanged during graph encoding. Besides, it serves as the global root node to represent the whole dialogue.\nIdentical Concept There can be identical mentions in different utterances (e.g. “possible” in the first and the forth utterances in Figure 2), resulting in repeated concept nodes in utterance AMRs. We connect nodes corresponding to the same nonpronoun concepts by edges labeled with SAME2. This type of connection can further enhance crosssentence information exchange.\nInter-sentence Co-reference A major challenge for dialogues understanding is posed by pronouns,\n2Compared with co-reference, identical concept relations can connect different words which share the same meaning e.g.〈could,might〉 , 〈fear, afraid〉.\nwhich are frequent in conversations (Grosz et al., 1995; Newman et al., 2008; Quan et al., 2019). We conduct co-reference resolution on dialogue text using an off-to-shelf model3 in order to identify concept nodes in utterance AMRs that refer to the same entity. For example, in Figure 2, “I” in the first utterance, and “sir” in the second utterance refer to the same entity, SPEAKR1. We add edges labeled with COREF between them, starting from later nodes to earlier nodes (later and earlier here refer to the temporal order of ongoing conversation), to indicate their relation4."
    }, {
      "heading" : "3 Baseline System",
      "text" : "We adopt a standard Transformer (Vaswani et al., 2017) for dialogue history encoding. Typically, a Transformer encoder consists of L layers, taking a sequence of tokens (i.e., dialogue history) S = {w1, w2, ..., wN}, where wi is the i-th token and N is the sequence length, as input and produces vectorized word representations {hl1, hl2, ..., hlN} iteratively, l ∈ [1, ..., L]. Overall, a Transformer encoder can be written as:\nH = SeqEncoder(emb(S)), (1)\nwhere H = {hL1 , hL2 , ..., hLn}, and emb denotes a function that maps a sequence of tokens into the corresponding embeddings. Each Transformer layer consists of two sub-layers: a self-attention sub-layer and a position-wise feed forward network. The former calculates a set of attention scores:\nαij = Attn(hi, hj). (2)\n3https://github.com/huggingface/neuralcoref 4For simplicity, we omit the coreference links between the\nsecond and third utterance for display.\nwhich are used to update the hidden state of wi:\nhli = ∑N\nj=1 αij(W\nV hl−1j ), (3)\nwhere W V is a parameter matrix. The position-wise feed-forward (FFN) layer consists of two linear transformations:\nFFN(h) =W2ReLU(W1h+ b1) + b2, (4)\nwhere W1,W2, b1, b2 are model parameters."
    }, {
      "heading" : "3.1 Dialogue Understanding Task",
      "text" : "We take the dialogue relation extraction task (Yu et al., 2020) as an example. Given a dialogue history S and an argument (or entity) pair (a1, a2), the goal is to predict the corresponding relation type r ∈ R between a1 and a2.\nWe follow a previous dialogue relation extraction model (Chen et al., 2020) to feed the hidden states of a1 and a2 (denoted as ha1 , ha2) into a classifier to obtain the probability of each relation types:\nPrel = softmax(W3[ha1 ;ha2 ] + b3), (5)\nwhere W3 and b3 are model parameters. The k-th value of Prel is the conditional probability of k-th relation inR.\nGiven a training instance 〈S, a1, a2, r〉, the local loss is:\n` = −logP (r|S, a1, a2; θ), (6)\nwhere θ denotes the set of model parameters. In practice, we use BERT (Devlin et al., 2019) for calculating ha1 and ha2 , which can be regarded as pre-trained initialization of the Transformer encoder.\n\uD835\uDC64\uD835\uDC641 \uD835\uDC64\uD835\uDC642 \uD835\uDC64\uD835\uDC643 \uD835\uDC64\uD835\uDC644 \uD835\uDC64\uD835\uDC645\nTransformer\nGraph Transformer\n\uD835\uDC52\uD835\uDC521 \uD835\uDC52\uD835\uDC523 \uD835\uDC52\uD835\uDC522Projected AMR edges\nText\nℎ1\uD835̂\uDC60\uD835\uDC60 ℎ2\uD835̂\uDC60\uD835\uDC60 ℎ3 \uD835̂\uDC60\uD835\uDC60 ℎ4\uD835̂\uDC60\uD835\uDC60 ℎ5\uD835̂\uDC60\uD835\uDC60\nℎ1\uD835\uDC46\uD835\uDC46 ℎ2\uD835\uDC46\uD835\uDC46 ℎ3\uD835\uDC46\uD835\uDC46 ℎ4\uD835\uDC46\uD835\uDC46 ℎ5\uD835\uDC46\uD835\uDC46\n(a)\n\uD835\uDC5B\uD835\uDC5B1 \uD835\uDC5B\uD835\uDC5B2 \uD835\uDC5B\uD835\uDC5B3 \uD835\uDC5B\uD835\uDC5B4 \uD835\uDC52\uD835\uDC523\uD835\uDC52\uD835\uDC521\n\uD835\uDC52\uD835\uDC522\nGraph Encoder Sequence Encoder\n\uD835\uDC64\uD835\uDC641 \uD835\uDC64\uD835\uDC642 \uD835\uDC64\uD835\uDC643 \uD835\uDC64\uD835\uDC644 \uD835\uDC64\uD835\uDC645\nFeature Fusion\n�ℎ1 �ℎ2 �ℎ3 �ℎ4 �ℎ5\n(b)\n\uD835\uDC5B\uD835\uDC5B1 \uD835\uDC5B\uD835\uDC5B2 \uD835\uDC5B\uD835\uDC5B3 \uD835\uDC5B\uD835\uDC5B4 \uD835\uDC52\uD835\uDC523\uD835\uDC52\uD835\uDC521\n\uD835\uDC52\uD835\uDC522\nGraph Encoder Sequence Encoder\n\uD835\uDC64\uD835\uDC641 \uD835\uDC64\uD835\uDC642 \uD835\uDC64\uD835\uDC643 \uD835\uDC64\uD835\uDC644 \uD835\uDC64\uD835\uDC645\nDual Attention\n\uD835\uDC66\uD835\uDC66\uD835\uDC61\uD835\uDC61\n\uD835\uDC60\uD835\uDC60\uD835\uDC61\uD835\uDC61 \uD835\uDC50\uD835\uDC50\uD835\uDC61\uD835\uDC61\n\uD835\uDC66\uD835\uDC66\uD835\uDC61\uD835\uDC61+1\n\uD835\uDC60\uD835\uDC60\uD835\uDC61\uD835\uDC61+1 … …\n(c)\nFigure 3: AMR for dialogue modeling. (a) Using AMR to enrich text representation. (b,c) Using AMR independently."
    }, {
      "heading" : "3.2 Dialogue Response Generation Task",
      "text" : "Given a dialogue history S , we use a standard autoregressive Transformer decoder (Vaswani et al., 2017) to generate a response Y = {y1, y2, ..., y|Y|}. At time step t, the previous output word yt−1 is firstly transformed into a hidden state st by a selfattention layer as Equations 2 and 3. Then an encoder-decoder attention mechanism is applied to obtain a context vector from encoder output hidden states{hL1 , hL2 , . . . , hLN}:\nα̂ti = Attn(st, h L i ), ct = ∑N\ni=1 α̂tih\nL i ,\n(7)\nThe obtained context vector ct is then used to calculate the output probability distribution for the next word yt over the target vocabulary5:\nPvoc = softmax(W4ct + b4), (8)\nwhere W4, b4 are trainable model parameters. The k-th value of Pvoc is the conditional probability of k-th word in vocabulary given a dialogue.\nGiven a dialogue history-response pair {S,Y}, the model minimizes a cross-entropy loss:\n` = − |Y |∑ t=1 logPvoc(yt|yt−1, ..., y1,S; θ), (9)\nwhere θ denotes all model parameters."
    }, {
      "heading" : "4 Proposed Model",
      "text" : "Our model takes a dialogue history S and the corresponding dialogue AMR as input. Formally,\n5Similar to the encoder, there is also multi-head attention, a position-wise feed-forward layer and residual connections, which we omit in the equations.\nan AMR is a directed acyclic graph G = 〈V, E〉, where V denotes a set of nodes (i.e. AMR concepts) and E (i.e. AMR relations) denotes a set of labeled edges. An edge can be further represented by a triple 〈ni, rij , nj〉, meaning that the edge is from node ni to nj with label rij .\nWe consider two main ways of making use of dialogue-level AMRs. The first method (Figure 3(a)) uses AMR semantic relations to enrich a textual representation of the dialogue history. We project AMR nodes onto the corresponding tokens, extending Transformer by encoding semantic relations between words. For the second approach, we separately encode an AMR and its sentence, and use either feature fusion (Figure 3(b)) or dual attention (Figure 3(c)) to incorporate their embeddings."
    }, {
      "heading" : "4.1 Graph Encoding",
      "text" : "We adopt a Graph Transformer (Zhu et al., 2019) to encode an AMR graph, which extends the standard Transformer (Vaswani et al., 2017) for modeling structural input. AL-layer graph Transformer takes a set of node embeddings {n1,n2, ...,nM} and a set of edge embeddings {rij |i ∈ [1, ...,M ], j ∈ [1, ...,M ]} as input6 and produces more abstract node features {hl1, hl2, ..., hlM} iteratively, where l ∈ [1, ..., L]. The key difference between a graph Transformer and a standard Transformer is the graph attention layer. Compared with selfattention layer (Equation 2), the graph attention layer explicitly considers graph edges when updating node hidden states. For example, give an edge 〈ni, rij , nj〉, the attention score α̂ij is calculated\n6If there is no relation between ni and nj , rij=“None”\nas:\nα̂ij = exp(êij)∑M\nm=1 exp (êim) ,\nêij = (WQhl−1i ) T (WKhl−1j +W Rrij)√\nd ,\n(10)\nwhere WR is a transformation matrix, rij is the embedding of relation rij , d is hidden state size, and {h01, h02, ..., h0M} = {n1,n2, ...,nM}. The hidden state of ni is then updated as:\nhli = ∑M\nj=1 αij(W\nV hl−1j +W Rrij), (11)\nwhere W V is a parameter matrix. Overall, given an input AMR graph G = 〈V, E〉, the graph Transformer encoder can be written as\nH = GraphEncoder(emb(V),emb(E)), (12) where H = {hL1 , hL2 , ..., hLM} denotes top-layer graph encoder hidden states."
    }, {
      "heading" : "4.2 Enriching Text Representation",
      "text" : "We first use the JAMR aligner (Flanigan et al., 2014) to obtain a node-to-word alignment, then adopt the alignment to project the AMR edges onto text with following rules:\nr̂ij =  ri′j′ , if A(ni′) = wi,A(nj′) = wj , Self, if i = j,\nNone, otherwise, (13)\nwhere A is a one-to-K alignment (K ∈ [0, . . . , N ]). In this way, we obtain a projected graph G′ = 〈V ′, E ′〉, where V ′ represents the set of input words {w1, w2, ..., wN} and E ′ denotes a set of word-to-word semantic relations.\nInspired by previous work on AMR graph modeling (Guo et al., 2019; Song et al., 2019b; Sun et al., 2019), we adopt a hierarchical encoder that stacks a sequence encoder and a graph encoder. A sequence encoder (SeqEncoder) transforms a dialogue history into a set of hidden states:\nHS = SeqEncoder(emb(S)). (14)\nA graph encoder incorporates the projected relations features into HS :\nH Ŝ = GraphEncoder(HS ,emb(E ′)), (15)\nIn addition, we add a residual connection between graph adapter and sequence encoder to fuse\nword representations before and after refinement (as shown in Figure 3(b)):\nHF = LayerNorm(HS +H Ŝ). (16)\nwhere LayerNorm denotes the layer normalization (Ba et al., 2016). We name the hierarchical encoder as Hier, which can be used for both dialogue understanding and dialogue response generation."
    }, {
      "heading" : "4.3 Leveraging both Text and Structure Cues",
      "text" : "We consider integrating both text cues and AMR structure cues for dialogue understanding and response generation, using a dual-encoder network. First, a sequence encoder is used to transform a dialogue history S into a text memory (denoted as HS = {hS1 , hS2 , ..., hSN}) using Equation 1. Second, the AMR graph G is encoded into graph memory (denoted as HG = {hG1 , hG2 , ..., hGM}) by a graph Transformer encoder using Equation 12.\nFor dialogue understanding (Figure 3(b)) and dialogue response generation (Figure 3(c)), slightly different methods of feature integration are used due to their different nature of outputs. Dialogue Understanding. Similar to Section 4.2, we first use the JAMR aligner to obtain a node-toword alignment A. Then we fuse the word and AMR node representations as follows:\nĥi =\n{ f(hSi , h G j ), if ∃j, A(nj) = wi,\nf(hSi , h∅), otherwise, (17)\nwhere h∅ is the vector representation of the dummy node (see Figure 2), f is defined as:\nh = LayerNorm(h1 + h2). (18)\nThe fused word representations are then fed into a classifier for relation prediction (Equation 5). Dialogue Response Generation. We replace the standard encoder-decoder attention (Equation 7) with a dual-attention mechanism (Song et al., 2019a). In particular, given a decoder hidden state st at time step t, the dual-attention mechanism calculates a graph context vector cSt and a text context vector cGt , simultaneously:\nα̂ti = Attn(st, h S i ), α̂tj = Attn(st, h G j ),\ncSt = ∑N\ni=1 α̂tih\nS i , cGt = ∑M\nj=1 α̂tjh\nG j ,\n(19)\nModel data-v1 data-v2\ndev test dev test F1(δ) F1c(δ) F1(δ) F1c(δ) F1(δ) F1c(δ) F1(δ) F1c(δ)\nand the final context vector ĉt is calculated as:\nct =W c[cSt ; c G t ] + b c, (20)\nwhere W c and bc are model parameters. We name the dual-encoder model as Dual."
    }, {
      "heading" : "5 Dialogue Understanding Experiments",
      "text" : "We evaluate our model on DialogRE (Yu et al., 2020), which contains totally 1,788 dialogues, 10,168 relational triples and 36 relation types in total. On average, a dialogue in DialogRE contains 4.5 relational triples and 12.9 turns. We report experimental results on both original (v1) and updated (v2) English version.7"
    }, {
      "heading" : "5.1 Settings",
      "text" : "We adopt the same input format and hyperparameter settings as Yu et al. (2020) for the proposed model and baselines. In particular, the input sequence is constructed as [CLS]d[SEP]a1[SEP]a2[SEP], where d denotes the dialogue, and a1 and a2 are the two associated arguments. In the BERT model of Yu et al. (2020), only the hidden state of the [CLS] token is fed into a classifier for prediction, while our baseline (BERTc) additionally takes the hidden states of a1 and a2. All hyperparameters are selected by prediction accuracy on validation dataset (See Table 6 for detailed hyperparameters). Metrics Following previous work on DialogRE, we report macro F1 score on relations in both the standard (F1) and conversational settings (F1c; Yu et al., 2020). F1c is computed over the first few turns of a dialogue where two arguments are first mentioned.\n7https://dataset.org/dialogre/"
    }, {
      "heading" : "5.2 Main Results",
      "text" : "Table 1 shows the results of different systems on DialogRE. We compare the proposed model with two BERT-based approches, BERT and BERTs. Based on BERT, BERTs (Yu et al., 2020) highlights speaker information by replacing speaker arguments with special tokens. For completeness, we also include recent methods, such as AGGCN (Guo et al., 2019), LSR (Nan et al., 2020) and DHGAT (Chen et al., 2020). BERTc and Hier, Dual represent our baseline and the proposed models, respectively.\nBy incorporating speaker information, BERTs gives the best performance among the previous system. Our BERTc baseline outperforms BERTs by a large margin, as BERTc additionally considers argument representations for classification. Hier significantly (p < 0.01)8 outperforms BERTc in all settings, with 1.4 points of improvement in terms of F1 score on average. A similar trend is observed under F1c. This shows that semantic information in AMR is beneficial to dialogue relation extraction, since AMR highlights core entities and semantic relations between them. Dual obtains slightly better results than Hier, which shows effect of separately encoding a semantic structure.\nFinally, the standard deviation values of both Dual and Hier are lower than the baselines. This indicates that our approaches are more robust regarding model initialization."
    }, {
      "heading" : "5.3 Impact of Argument Distance",
      "text" : "We split the dialogues of the DialogRE (v2) devset into five groups by the utterance-based distance between two arguments. As shown in Figure 4, Dual gives better results than BERTc except when\n8We use pair-wised t-test.\nthe argument distance is less than 5. In particular, Dual surpasses BERTc by a large margin when the arguments distance is greater than 20. The comparison indicates that AMR can help a model to better handle long-term dependencies by improving the entity recall. In addition to utterance distance, we also consider word distance and observe a similar trend (as shown in Appendix 7)."
    }, {
      "heading" : "5.4 Case Study",
      "text" : "Figure 5 shows a conversation between a manager and an employee who might have taken a leave. The baseline model incorrectly predicts that the relation between two interlocutors is parent and child. It might be influenced by the last sentence in the conversation, assuming that it is a dialogue between family members. However, the proposed model successful predicts the interlocutors’ relation, suggesting it can extract global semantic information in the dialogue from a comprehensive perspective."
    }, {
      "heading" : "6 Response Generation Experiments",
      "text" : "We conduct experiments on the DailyDialog benchmark (Li et al., 2017), which contains 13,119 daily multi-turn conversations. On average, the number of turns for each dialogue is 7.9, and each utterance has 14.6 tokens."
    }, {
      "heading" : "6.1 Settings",
      "text" : "We take Transformer as a baseline. Our hyperparameters are selected by word prediction accuracy on validation dataset. The detailed hyperparameters are given in Appendix (See Table 6). Metric We set the decoding beam size as 5 and adopt BLEU-1/2/3/4 (Papineni et al., 2002) and Distinct-1/2 (Li et al., 2016) as automatic evaluation metrics. The former measures the ngram overlap between generated response and\nModel BLEU-1/2/3/4 Distinct-1/2\nSeq2Seq† 33.6/26.8/-/- 3.0/12.8 iVAEMI 30.9/24.9/-/- 2.9/25.0 PLATO w/o L†[ 40.5/32.2/-/- 4.6/24.6 PLATO†[ 39.7/31.1/-/- 5.3/29.1\nthe target response while the latter assesses the generation diversity, which is defined as the number of distinct uni- or bi-grams divided by the total amount of generated words. In addition, we also conduct human evaluation. Following Bao et al. (2020), we ask annotators who study linguistics to evaluate model outputs from four aspects, which are fluency, coherence, informativeness and overall performance. The scores are in a scale of {0, 1, 2}. The higher, the better."
    }, {
      "heading" : "6.2 Automatic Evaluation Results",
      "text" : "Table 2 reports the performances of the previous state-of-the-art methods and proposed models on the DailyDialog testset. For the previous methods, PLATO and PLATO w/o L are both Transformer models pre-trained on large-scale conversational data (8.3 million samples) and finetuned on DailyDialog. For completeness, we also report other systems including Seq2Seq (Vinyals and Le, 2015) and iVAEMI (Fang et al., 2019).\nAmong the previous systems, PLATO and PLATO w/o L report the best performances. Our Transformer baseline is highly competitive in terms of BLEU and Distinct scores. Compared with the Transformer baseline, both Dual and Hier show better numbers regarding BLEU and Distinct, and the gains of both models are significant (p < 0.01). This indicates that semantic information in AMR graphs is useful for dialogue response generation. In particular, the gains come from better recall of the important entities and their relations in a dialogue history, which can leads to generating a more detailed response."
    }, {
      "heading" : "6.3 Human Evaluation Results",
      "text" : "We conduct human evaluation on randomly selected 50 dialogues and corresponding generated responses of the baseline and our models. As shown in Table 3, the Transformer baseline gives the lowest scores, while Dual sees the highest scores from all aspects. Our main advantage is on the Coherence, meaning that AMRs are effective on recalling important concepts and relations. As the result, it makes it easier for our models to generate coherent replies. Examples are shown in Figure 8 in Appendix. Comparatively, all systems achieve high scores regarding Fluency, suggesting that this aspect is not the current bottleneck for response generation."
    }, {
      "heading" : "7 Analysis",
      "text" : "This section contains analysis concerning the effects of graph features, dialogue length and model robustness. We use Dual model for experiments since it gives slightly better results than Hier."
    }, {
      "heading" : "7.1 Ablation on AMR graph",
      "text" : "Table 4 shows the results of our best performing models on the two datasets regarding different configurations on the dialogue AMR graphs. We report the average F1 score for DialogRE and the BLEU1/Distinct-1 score for DailyDialog. First, using utterance-level AMR improves the text baseline by 1.2 points and 1.5 points with regard to F1 and\nBLEU-1 scores, respectively. This indicates that the semantic knowledge in formal AMR is helpful for dialogue modeling.\nSecond, our manually added relations (in Section 2) also leads to improvements, ranging from 0.5 to 1.0 in BLEU-1 score. The speaker relation is the most important for dialogue relation extraction, a possible reason is that DialogRE dataset mainly focus on person entities. Also, co-reference relations help the most in dialogue response generation. The identical concept relations give least improvements among three relations. Finally, combining all relations to build a Dialog-AMR graph achieves best performance on both datasets."
    }, {
      "heading" : "7.2 Impact of Dialogue Length",
      "text" : "We group the devset of DialogRE (v2) and DailyDialog into five groups according to the number of utterances in a dialogue. Figure 6 summarizes the performance of the baseline and the proposed model on dialogue understanding (DU) and response generation (RG) tasks. In dialogue understanding, our model gives slightly better F1 scores than the baseline when a dialogue has smaller than 12 utterance. The performance improvement is more significant when modeling a long dialogue. This confirms our motivation that AMR can help to understand long dialogues. In dialogue response generation, our model consistently outperforms the Transformer baseline by a large margin on\ndialogues of different lengths, still with more improvements on larger dialogues. Overall, these results are consistent with Table 1 and 2, showing that AMR can provide useful semantic information and alleviate the issue of long-range dependency."
    }, {
      "heading" : "7.3 Robustness Against Input",
      "text" : "Recent studies show that neural network-based dialog models lack robustness (Shalyminov and Lee, 2018; Einolghozati et al., 2019). We select 100 instances from the testset of DialogRE (v2) where both baseline and our model gives true prediction, before paraphrasing the source dialogues manually (see appendix B.3 for paraphrasing guidelines.).\nResults on the paraphrased dataset are given in Table 5. The performance of baseline model drop from 100 to 94.5 on paraphrased dataset. By contrast, the result of our model reaches 98.5, 4 points higher than baseline. This confirms our assumption that AMR can reduce data sparsity, thus improve the robustness of neural models."
    }, {
      "heading" : "8 Related Work",
      "text" : "Semantic Parsing for Dialogue Some previous work builds domain-specified semantic schema for task-oriented dialogues. For example, in the PEGASUS (Zue et al., 1994) system, a sentence is first transformed into a semantic frame and then used for travel planing. Wirsching et al. (2012) use semantic features to help a dialogue system perform certain database operations. Gupta et al. (2018) represent task-oriented conversations as semantic trees where intents and slots are tree nodes. They solve intent classification and slot-filling task via semantic parsing. Cheng et al. (2020) design a rooted semantic graph that integrates domains, verbs, operators and slots in order to perform dialogue state tracking. All these structures are designed for specified task only. In contrast, we investigate a general semantic representation for the modeling of everyday conversations.\nConstructing AMRs beyond Sentence Level There are a few attempts to construct AMRs beyond the sentence level. Liu et al. (2015) construct document-level AMRs by merging identical\nconcepts of sentence-level AMRs for abstractive summerization, and Liao et al. (2018) further extend this approach to multi-document summerization. O’Gorman et al. (2018) manually annotate co-reference information across sentence AMRs. We focus on creating conversation-level AMRs to facilitate information exchange more effectively for dialogue modeling.\nBonial et al. (2020) adapt AMRs on dialogues by enriching the standard AMR schema with dialogue acts, tense and aspect, and they construct a dataset consisting of 340 dialogue AMRs. However, they propose theoretical changes in the schema for annotating AMRs, while we explore empirical solutions that leverage existing AMRs of the standard schema on dialogues.\nAMR Parsing and Encoding Our work is also related to AMR parsing (Flanigan et al., 2014; Konstas et al., 2017a; Lyu and Titov, 2018; Guo and Lu, 2018; Zhang et al., 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al., 2017b; Song et al., 2018; Zhu et al., 2019; Song et al., 2020; Zhao et al., 2020; Bai et al., 2020). The former task makes it possible to use automatically-generated AMRs for downstream applications, while the latter helps to effectively exploit structural information in AMRs. In this work, we investigate AMRs for dialogue representation and combine AMRs with text for dialogue modeling."
    }, {
      "heading" : "9 Conclusion",
      "text" : "We investigated the feasibility of using AMRs for dialogue modeling, describing an algorithm to construct dialogue-level AMRs automatically and exploiting two ways to incorporate AMRs into neural dialogue systems. Experiments on two benchmarks show advantages of using AMR semantic representations model on both dialogue understanding and dialogue response generation."
    }, {
      "heading" : "Acknowledgments",
      "text" : "Yue Zhang is the corresponding author. We would like to thank the anonymous reviewers for their insightful comments and Jinhao Jiang for his help for data preparation. This work has been supported by Tencent AI Lab Rhino-Bird Focused Research Program. It also receives support from the Westlake University and Bright Dream Joint Institute for Intelligent Robotics, and a research grant from Rxhui Inc."
    }, {
      "heading" : "A Model parameters",
      "text" : "Table 6 lists all model hyperparameters used for experiments. In particular, we share the word vocabulary of encoder and decoder for response generation. We implement our baselines and proposed model based on Pytorch. The preprocessed data and source code will be released at https: //github.com/muyeby/AMR-Dialogue."
    }, {
      "heading" : "B More Experimental Results",
      "text" : "B.1 Impact of Argument Distance\nIn addition to utterance distance used in Figure 4, we also consider word-based distance as a metric to measure argument distance. Figure 7 shows F1 scores of baseline and our model on 5 groups of test instances. It can be seen that our model gives better results than baseline system among all distances longer than 30. In particular, our model surpass baseline by 8 points when argument distance is longer than 120.\nB.2 Case Study for Dialogue Response Generation\nFigure 8 represents a conversation between a hotel service and a guest who wants to book a room, along with its ground-truth response and model-generated responses. We can observe that Transformer’s output is general and not consistent with dialogue history. While proposed models’ outputs can capture the core information “room” from the history, and are more relevant to the topic. Besides, the output given by proposed model is semantically similar to the ground-truth output, but using novel words to response, indicating that the model not only captures the simple dependency between input and output sentences, but also learns deep semantic information of the dialogue history.\nB.3 Paraphrasing Guidelines We ask annotators to paraphrase the dialogues following 3 guidelines:\n• do not change the original meaning. • paraphrase the sentence by using different lexicon and syntax structures. • paraphrase the dialogue as much as they can. We also ask a judge to evaluate whether the paraphrased dialogue (sentences) convey the same meaning of the original ones."
    } ],
    "references" : [ {
      "title" : "Layer normalization",
      "author" : [ "Lei Jimmy Ba", "Jamie Ryan Kiros", "Geoffrey E. Hinton." ],
      "venue" : "CoRR, abs/1607.06450.",
      "citeRegEx" : "Ba et al\\.,? 2016",
      "shortCiteRegEx" : "Ba et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015,",
      "citeRegEx" : "Bahdanau et al\\.,? 2015",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2015
    }, {
      "title" : "Investigating typed syntactic dependencies for targeted sentiment classification using graph attention neural network",
      "author" : [ "Xuefeng Bai", "Pengbo Liu", "Yue Zhang." ],
      "venue" : "IEEE/ACM Transactions on Audio, Speech, and Language Processing, 29:503–514.",
      "citeRegEx" : "Bai et al\\.,? 2021",
      "shortCiteRegEx" : "Bai et al\\.",
      "year" : 2021
    }, {
      "title" : "Online back-parsing for AMR-to-text generation",
      "author" : [ "Xuefeng Bai", "Linfeng Song", "Yue Zhang." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1206–1219, Online. Association for Computa-",
      "citeRegEx" : "Bai et al\\.,? 2020",
      "shortCiteRegEx" : "Bai et al\\.",
      "year" : 2020
    }, {
      "title" : "Abstract meaning representation for sembanking",
      "author" : [ "Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider." ],
      "venue" : "Proceedings of the 7th Linguis-",
      "citeRegEx" : "Banarescu et al\\.,? 2013",
      "shortCiteRegEx" : "Banarescu et al\\.",
      "year" : 2013
    }, {
      "title" : "PLATO: Pre-trained dialogue generation model with discrete latent variable",
      "author" : [ "Siqi Bao", "Huang He", "Fan Wang", "Hua Wu", "Haifeng Wang." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 85–96, Online.",
      "citeRegEx" : "Bao et al\\.,? 2020",
      "shortCiteRegEx" : "Bao et al\\.",
      "year" : 2020
    }, {
      "title" : "Dialogue-AMR: Abstract Meaning Representation for dialogue",
      "author" : [ "Claire Bonial", "Lucia Donatelli", "Mitchell Abrams", "Stephanie M. Lukin", "Stephen Tratz", "Matthew Marge", "Ron Artstein", "David Traum", "Clare Voss." ],
      "venue" : "Proceedings of the 12th Language",
      "citeRegEx" : "Bonial et al\\.,? 2020",
      "shortCiteRegEx" : "Bonial et al\\.",
      "year" : 2020
    }, {
      "title" : "MultiWOZ - a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling",
      "author" : [ "Paweł Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "Iñigo Casanueva", "Stefan Ultes", "Osman Ramadan", "Milica Gašić." ],
      "venue" : "Proceedings",
      "citeRegEx" : "Budzianowski et al\\.,? 2018",
      "shortCiteRegEx" : "Budzianowski et al\\.",
      "year" : 2018
    }, {
      "title" : "AMR parsing via graph-sequence iterative inference",
      "author" : [ "Deng Cai", "Wai Lam." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1290–1301, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Cai and Lam.,? 2020",
      "shortCiteRegEx" : "Cai and Lam.",
      "year" : 2020
    }, {
      "title" : "Doubly-attentive decoder for multi-modal neural machine translation",
      "author" : [ "Iacer Calixto", "Qun Liu", "Nick Campbell." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1913–",
      "citeRegEx" : "Calixto et al\\.,? 2017",
      "shortCiteRegEx" : "Calixto et al\\.",
      "year" : 2017
    }, {
      "title" : "Dialogue relation extraction with document-level heterogeneous graph attention networks",
      "author" : [ "Hui Chen", "Pengfei Hong", "Wei Han", "Navonil Majumder", "Soujanya Poria." ],
      "venue" : "CoRR, abs/2009.05092.",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "Conversational semantic parsing for dialog state tracking",
      "author" : [ "Johannsen." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8107–8117, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Johannsen.,? 2020",
      "shortCiteRegEx" : "Johannsen.",
      "year" : 2020
    }, {
      "title" : "QuAC: Question answering in context",
      "author" : [ "Eunsol Choi", "He He", "Mohit Iyyer", "Mark Yatskar", "Wen-tau Yih", "Yejin Choi", "Percy Liang", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Choi et al\\.,? 2018",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2018
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Wizard of wikipedia: Knowledge-powered conversational agents",
      "author" : [ "Emily Dinan", "Stephen Roller", "Kurt Shuster", "Angela Fan", "Michael Auli", "Jason Weston." ],
      "venue" : "7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA,",
      "citeRegEx" : "Dinan et al\\.,? 2019",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2019
    }, {
      "title" : "Improving robustness of task oriented dialog systems",
      "author" : [ "Arash Einolghozati", "Sonal Gupta", "Mrinal Mohit", "Rushin Shah." ],
      "venue" : "CoRR, abs/1911.05153.",
      "citeRegEx" : "Einolghozati et al\\.,? 2019",
      "shortCiteRegEx" : "Einolghozati et al\\.",
      "year" : 2019
    }, {
      "title" : "Implicit deep latent variable models for text generation",
      "author" : [ "Le Fang", "Chunyuan Li", "Jianfeng Gao", "Wen Dong", "Changyou Chen." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Fang et al\\.,? 2019",
      "shortCiteRegEx" : "Fang et al\\.",
      "year" : 2019
    }, {
      "title" : "A discriminative graph-based parser for the Abstract Meaning",
      "author" : [ "Jeffrey Flanigan", "Sam Thomson", "Jaime Carbonell", "Chris Dyer", "Noah A. Smith" ],
      "venue" : null,
      "citeRegEx" : "Flanigan et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Flanigan et al\\.",
      "year" : 2014
    }, {
      "title" : "Centering: A framework for modeling the local coherence of discourse",
      "author" : [ "Barbara J. Grosz", "Aravind K. Joshi", "Scott Weinstein." ],
      "venue" : "Computational Linguistics, 21(2):203–225.",
      "citeRegEx" : "Grosz et al\\.,? 1995",
      "shortCiteRegEx" : "Grosz et al\\.",
      "year" : 1995
    }, {
      "title" : "Better transitionbased AMR parsing with a refined search space",
      "author" : [ "Zhijiang Guo", "Wei Lu." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1712–1722, Brussels, Belgium. Association",
      "citeRegEx" : "Guo and Lu.,? 2018",
      "shortCiteRegEx" : "Guo and Lu.",
      "year" : 2018
    }, {
      "title" : "Attention guided graph convolutional networks for relation extraction",
      "author" : [ "Zhijiang Guo", "Yan Zhang", "Wei Lu." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 241–251, Florence, Italy. Association",
      "citeRegEx" : "Guo et al\\.,? 2019",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2019
    }, {
      "title" : "Semantic parsing for task oriented dialog using hierarchical representations",
      "author" : [ "Sonal Gupta", "Rushin Shah", "Mrinal Mohit", "Anuj Kumar", "Mike Lewis." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Gupta et al\\.,? 2018",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2018
    }, {
      "title" : "Guided neural language generation for abstractive summarization using Abstract Meaning Representation",
      "author" : [ "Hardy Hardy", "Andreas Vlachos." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Hardy and Vlachos.,? 2018",
      "shortCiteRegEx" : "Hardy and Vlachos.",
      "year" : 2018
    }, {
      "title" : "Learning the difference that makes A difference with counterfactually-augmented data",
      "author" : [ "Divyansh Kaushik", "Eduard H. Hovy", "Zachary Chase Lipton." ],
      "venue" : "8th International Conference on Learning",
      "citeRegEx" : "Kaushik et al\\.,? 2020",
      "shortCiteRegEx" : "Kaushik et al\\.",
      "year" : 2020
    }, {
      "title" : "From treebank to propbank",
      "author" : [ "Paul R. Kingsbury", "Martha Palmer." ],
      "venue" : "Proceedings of the Third International Conference on Language Resources and Evaluation, LREC 2002, May 29-31, 2002, Las Palmas, Canary Islands, Spain. European Language",
      "citeRegEx" : "Kingsbury and Palmer.,? 2002",
      "shortCiteRegEx" : "Kingsbury and Palmer.",
      "year" : 2002
    }, {
      "title" : "Neural AMR: sequence-to-sequence models for parsing and generation",
      "author" : [ "Ioannis Konstas", "Srinivasan Iyer", "Mark Yatskar", "Yejin Choi", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Konstas et al\\.,? 2017a",
      "shortCiteRegEx" : "Konstas et al\\.",
      "year" : 2017
    }, {
      "title" : "Neural AMR: Sequence-to-sequence models for parsing and generation",
      "author" : [ "Ioannis Konstas", "Srinivasan Iyer", "Mark Yatskar", "Yejin Choi", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Vol-",
      "citeRegEx" : "Konstas et al\\.,? 2017b",
      "shortCiteRegEx" : "Konstas et al\\.",
      "year" : 2017
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "DailyDialog: A manually labelled multi-turn dialogue dataset",
      "author" : [ "Yanran Li", "Hui Su", "Xiaoyu Shen", "Wenjie Li", "Ziqiang Cao", "Shuzi Niu." ],
      "venue" : "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "Improving BERT with syntax-aware local attention",
      "author" : [ "Zhongli Li", "Qingyu Zhou", "Chao Li", "Ke Xu", "Yunbo Cao." ],
      "venue" : "CoRR, abs/2012.15150.",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Abstract Meaning Representation for multi-document summarization",
      "author" : [ "Kexin Liao", "Logan Lebanoff", "Fei Liu." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 1178–1190, Santa Fe, New Mexico, USA.",
      "citeRegEx" : "Liao et al\\.,? 2018",
      "shortCiteRegEx" : "Liao et al\\.",
      "year" : 2018
    }, {
      "title" : "Toward abstractive summarization using semantic representations",
      "author" : [ "Fei Liu", "Jeffrey Flanigan", "Sam Thomson", "Norman Sadeh", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Liu et al\\.,? 2015",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "AMR parsing as graph prediction with latent alignment",
      "author" : [ "Chunchuan Lyu", "Ivan Titov." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume",
      "citeRegEx" : "Lyu and Titov.,? 2018",
      "shortCiteRegEx" : "Lyu and Titov.",
      "year" : 2018
    }, {
      "title" : "A survey of decision fusion and feature fusion strategies for pattern classification",
      "author" : [ "Utthara Gosa Mangai", "Suranjana Samanta", "Sukhendu Das", "Pinaki Roy Chowdhury." ],
      "venue" : "IETE Technical Review, 27(4):293–307.",
      "citeRegEx" : "Mangai et al\\.,? 2010",
      "shortCiteRegEx" : "Mangai et al\\.",
      "year" : 2010
    }, {
      "title" : "Exploiting semantics in neural machine translation with graph convolutional networks",
      "author" : [ "Diego Marcheggiani", "Jasmijn Bastings", "Ivan Titov." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Compu-",
      "citeRegEx" : "Marcheggiani et al\\.,? 2018",
      "shortCiteRegEx" : "Marcheggiani et al\\.",
      "year" : 2018
    }, {
      "title" : "On faithfulness and factuality in abstractive summarization",
      "author" : [ "Joshua Maynez", "Shashi Narayan", "Bernd Bohnet", "Ryan McDonald." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1906–1919, On-",
      "citeRegEx" : "Maynez et al\\.,? 2020",
      "shortCiteRegEx" : "Maynez et al\\.",
      "year" : 2020
    }, {
      "title" : "Reasoning with latent structure refinement for document-level relation extraction",
      "author" : [ "Guoshun Nan", "Zhijiang Guo", "Ivan Sekulic", "Wei Lu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1546–1557, On-",
      "citeRegEx" : "Nan et al\\.,? 2020",
      "shortCiteRegEx" : "Nan et al\\.",
      "year" : 2020
    }, {
      "title" : "Gender differences in language use: An analysis of 14,000 text samples",
      "author" : [ "Matthew L Newman", "Carla J Groom", "Lori D Handelman", "James W Pennebaker." ],
      "venue" : "Discourse Processes: A Multidisciplinary Journal, 45(3):211–236.",
      "citeRegEx" : "Newman et al\\.,? 2008",
      "shortCiteRegEx" : "Newman et al\\.",
      "year" : 2008
    }, {
      "title" : "Avgout: A simple output-probability measure to eliminate dull responses",
      "author" : [ "Tong Niu", "Mohit Bansal." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, pages 8560–8567.",
      "citeRegEx" : "Niu and Bansal.,? 2020",
      "shortCiteRegEx" : "Niu and Bansal.",
      "year" : 2020
    }, {
      "title" : "2018. AMR beyond the sentence: the multi-sentence AMR corpus",
      "author" : [ "Tim O’Gorman", "Michael Regan", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Martha Palmer" ],
      "venue" : "In Proceedings of the 27th International Conference on Computational Linguistics,",
      "citeRegEx" : "O.Gorman et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "O.Gorman et al\\.",
      "year" : 2018
    }, {
      "title" : "The proposition bank: An annotated corpus of semantic roles",
      "author" : [ "Martha Palmer", "Paul R. Kingsbury", "Daniel Gildea." ],
      "venue" : "Comput. Linguistics, 31(1):71–106.",
      "citeRegEx" : "Palmer et al\\.,? 2005",
      "shortCiteRegEx" : "Palmer et al\\.",
      "year" : 2005
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia,",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Hypothesis only baselines in natural language inference",
      "author" : [ "Adam Poliak", "Jason Naradowsky", "Aparajita Haldar", "Rachel Rudinger", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics,",
      "citeRegEx" : "Poliak et al\\.,? 2018",
      "shortCiteRegEx" : "Poliak et al\\.",
      "year" : 2018
    }, {
      "title" : "GECOR: An end-to-end generative ellipsis and co-reference resolution model for taskoriented dialogue",
      "author" : [ "Jun Quan", "Deyi Xiong", "Bonnie Webber", "Changjian Hu." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Quan et al\\.,? 2019",
      "shortCiteRegEx" : "Quan et al\\.",
      "year" : 2019
    }, {
      "title" : "Scaling multi-domain dialogue state tracking via query reformulation",
      "author" : [ "Pushpendre Rastogi", "Arpit Gupta", "Tongfei Chen", "Mathias Lambert." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Rastogi et al\\.,? 2019",
      "shortCiteRegEx" : "Rastogi et al\\.",
      "year" : 2019
    }, {
      "title" : "CoQA: A conversational question answering challenge",
      "author" : [ "Siva Reddy", "Danqi Chen", "Christopher D. Manning." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 7:249–266.",
      "citeRegEx" : "Reddy et al\\.,? 2019",
      "shortCiteRegEx" : "Reddy et al\\.",
      "year" : 2019
    }, {
      "title" : "Data-driven response generation in social media",
      "author" : [ "Alan Ritter", "Colin Cherry", "William B. Dolan." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 583–593, Edinburgh, Scotland, UK. Association for",
      "citeRegEx" : "Ritter et al\\.,? 2011",
      "shortCiteRegEx" : "Ritter et al\\.",
      "year" : 2011
    }, {
      "title" : "Do syntax trees help pre-trained transformers extract information",
      "author" : [ "Devendra Singh Sachan", "Yuhao Zhang", "Peng Qi", "William L. Hamilton" ],
      "venue" : "In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Lin-",
      "citeRegEx" : "Sachan et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Sachan et al\\.",
      "year" : 2021
    }, {
      "title" : "A hierarchical latent variable encoder-decoder model for generating dialogues",
      "author" : [ "Iulian Vlad Serban", "Alessandro Sordoni", "Ryan Lowe", "Laurent Charlin", "Joelle Pineau", "Aaron C. Courville", "Yoshua Bengio." ],
      "venue" : "Proceedings of the Thirty-First AAAI",
      "citeRegEx" : "Serban et al\\.,? 2017",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2017
    }, {
      "title" : "Improving robustness of neural dialog systems in a data-efficient way with turn dropout",
      "author" : [ "Igor Shalyminov", "Sungjin Lee." ],
      "venue" : "The Thirty-second Annual Conference on Neural Information Processing Systems (NIPS) 2018, workshop on Conversational AI:",
      "citeRegEx" : "Shalyminov and Lee.,? 2018",
      "shortCiteRegEx" : "Shalyminov and Lee.",
      "year" : 2018
    }, {
      "title" : "Improving dialogue state tracking by discerning the relevant context",
      "author" : [ "Sanuj Sharma", "Prafulla Kumar Choubey", "Ruihong Huang." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:",
      "citeRegEx" : "Sharma et al\\.,? 2019",
      "shortCiteRegEx" : "Sharma et al\\.",
      "year" : 2019
    }, {
      "title" : "Semantic neural machine translation using AMR",
      "author" : [ "Linfeng Song", "Daniel Gildea", "Yue Zhang", "Zhiguo Wang", "Jinsong Su." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 7:19–31.",
      "citeRegEx" : "Song et al\\.,? 2019a",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2019
    }, {
      "title" : "Structural information preserving for graph-to-text generation",
      "author" : [ "Linfeng Song", "Ante Wang", "Jinsong Su", "Yue Zhang", "Kun Xu", "Yubin Ge", "Dong Yu" ],
      "venue" : null,
      "citeRegEx" : "Song et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2020
    }, {
      "title" : "Leveraging dependency forest for neural medical relation extraction",
      "author" : [ "Linfeng Song", "Yue Zhang", "Daniel Gildea", "Mo Yu", "Zhiguo Wang", "Jinsong Su." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Process-",
      "citeRegEx" : "Song et al\\.,? 2019b",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2019
    }, {
      "title" : "A graph-to-sequence model for AMRto-text generation",
      "author" : [ "Linfeng Song", "Yue Zhang", "Zhiguo Wang", "Daniel Gildea." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1616–",
      "citeRegEx" : "Song et al\\.,? 2018",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2018
    }, {
      "title" : "Linguistically-informed self-attention for semantic role labeling",
      "author" : [ "Emma Strubell", "Patrick Verga", "Daniel Andor", "David Weiss", "Andrew McCallum." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural",
      "citeRegEx" : "Strubell et al\\.,? 2018",
      "shortCiteRegEx" : "Strubell et al\\.",
      "year" : 2018
    }, {
      "title" : "Aspect-level sentiment analysis via convolution over dependency tree",
      "author" : [ "Kai Sun", "Richong Zhang", "Samuel Mensah", "Yongyi Mao", "Xudong Liu." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
      "citeRegEx" : "Sun et al\\.,? 2019",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Sequence to sequence learning with neural networks",
      "author" : [ "Ilya Sutskever", "Oriol Vinyals", "Quoc V. Le." ],
      "venue" : "Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014,",
      "citeRegEx" : "Sutskever et al\\.,? 2014",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2014
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "A neural conversational model",
      "author" : [ "Oriol Vinyals", "Quoc V. Le." ],
      "venue" : "CoRR, abs/1506.05869.",
      "citeRegEx" : "Vinyals and Le.,? 2015",
      "shortCiteRegEx" : "Vinyals and Le.",
      "year" : 2015
    }, {
      "title" : "Semantically conditioned LSTM-based natural language generation for spoken dialogue systems",
      "author" : [ "Tsung-Hsien Wen", "Milica Gašić", "Nikola Mrkšić", "PeiHao Su", "David Vandyke", "Steve Young." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical",
      "citeRegEx" : "Wen et al\\.,? 2015",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2015
    }, {
      "title" : "A networkbased end-to-end trainable task-oriented dialogue system",
      "author" : [ "Tsung-Hsien Wen", "David Vandyke", "Nikola Mrkšić", "Milica Gašić", "Lina M. Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "Steve Young." ],
      "venue" : "Proceedings of the 15th Conference",
      "citeRegEx" : "Wen et al\\.,? 2017",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2017
    }, {
      "title" : "Semantic dialogue modeling",
      "author" : [ "Günther Wirsching", "Markus Huber", "Christian Kölbl", "Robert Lorenz", "Ronald Römer." ],
      "venue" : "Anna Esposito, Antonietta M. Esposito, Alessandro Vinciarelli, Rüdiger Hoffmann, and Vincent C. Müller, editors, Cogni-",
      "citeRegEx" : "Wirsching et al\\.,? 2012",
      "shortCiteRegEx" : "Wirsching et al\\.",
      "year" : 2012
    }, {
      "title" : "Contextual domain classification in spoken language understanding systems using recurrent neural network",
      "author" : [ "P. Xu", "R. Sarikaya." ],
      "venue" : "2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 136–140.",
      "citeRegEx" : "Xu and Sarikaya.,? 2014",
      "shortCiteRegEx" : "Xu and Sarikaya.",
      "year" : 2014
    }, {
      "title" : "Dialogue-based relation extraction",
      "author" : [ "Dian Yu", "Kai Sun", "Claire Cardie", "Dong Yu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4927–4940, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Yu et al\\.,? 2020",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2020
    }, {
      "title" : "AMR parsing as sequence-tograph transduction",
      "author" : [ "Sheng Zhang", "Xutai Ma", "Kevin Duh", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 80–94, Florence, Italy. Associa-",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Line graph enhanced AMR-to-text generation with mix-order graph attention networks",
      "author" : [ "Yanbin Zhao", "Lu Chen", "Zhi Chen", "Ruisheng Cao", "Su Zhu", "Kai Yu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Zhao et al\\.,? 2020",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Modeling graph structure in transformer for better AMR-to-text generation",
      "author" : [ "Jie Zhu", "Junhui Li", "Muhua Zhu", "Longhua Qian", "Min Zhang", "Guodong Zhou." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Zhu et al\\.,? 2019",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2019
    }, {
      "title" : "PEGASUS: A spoken language interface for on-line air travel",
      "author" : [ "Victor Zue", "Stephanie Seneff", "Joseph Polifroni", "Michael Phillips", "Christine Pao", "David Goddeau", "James Glass", "Eric Brill" ],
      "venue" : null,
      "citeRegEx" : "Zue et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Zue et al\\.",
      "year" : 1994
    } ],
    "referenceMentions" : [ {
      "referenceID" : 60,
      "context" : "Dialogue systems have received increasing research attention (Wen et al., 2015; Serban et al., 2017; Bao et al., 2020), with much recent work focusing on social chats (Ritter et al.",
      "startOffset" : 61,
      "endOffset" : 118
    }, {
      "referenceID" : 48,
      "context" : "Dialogue systems have received increasing research attention (Wen et al., 2015; Serban et al., 2017; Bao et al., 2020), with much recent work focusing on social chats (Ritter et al.",
      "startOffset" : 61,
      "endOffset" : 118
    }, {
      "referenceID" : 5,
      "context" : "Dialogue systems have received increasing research attention (Wen et al., 2015; Serban et al., 2017; Bao et al., 2020), with much recent work focusing on social chats (Ritter et al.",
      "startOffset" : 61,
      "endOffset" : 118
    }, {
      "referenceID" : 46,
      "context" : ", 2020), with much recent work focusing on social chats (Ritter et al., 2011; Li et al., 2017) and task-oriented dialogues (Wen et al.",
      "startOffset" : 56,
      "endOffset" : 94
    }, {
      "referenceID" : 28,
      "context" : ", 2020), with much recent work focusing on social chats (Ritter et al., 2011; Li et al., 2017) and task-oriented dialogues (Wen et al.",
      "startOffset" : 56,
      "endOffset" : 94
    }, {
      "referenceID" : 61,
      "context" : ", 2017) and task-oriented dialogues (Wen et al., 2017; Dinan et al., 2019).",
      "startOffset" : 36,
      "endOffset" : 74
    }, {
      "referenceID" : 14,
      "context" : ", 2017) and task-oriented dialogues (Wen et al., 2017; Dinan et al., 2019).",
      "startOffset" : 36,
      "endOffset" : 74
    }, {
      "referenceID" : 12,
      "context" : "There are two salient subtasks in dialogue modeling, namely dialogue understanding (Choi et al., 2018; Reddy et al., 2019; Yu et al., 2020) and response generation (Li et al.",
      "startOffset" : 83,
      "endOffset" : 139
    }, {
      "referenceID" : 45,
      "context" : "There are two salient subtasks in dialogue modeling, namely dialogue understanding (Choi et al., 2018; Reddy et al., 2019; Yu et al., 2020) and response generation (Li et al.",
      "startOffset" : 83,
      "endOffset" : 139
    }, {
      "referenceID" : 64,
      "context" : "There are two salient subtasks in dialogue modeling, namely dialogue understanding (Choi et al., 2018; Reddy et al., 2019; Yu et al., 2020) and response generation (Li et al.",
      "startOffset" : 83,
      "endOffset" : 139
    }, {
      "referenceID" : 57,
      "context" : "The current state-of-the-art methods employ neural networks and end-to-end training (Sutskever et al., 2014; Bahdanau et al., 2015) for dialogue modeling.",
      "startOffset" : 84,
      "endOffset" : 131
    }, {
      "referenceID" : 1,
      "context" : "The current state-of-the-art methods employ neural networks and end-to-end training (Sutskever et al., 2014; Bahdanau et al., 2015) for dialogue modeling.",
      "startOffset" : 84,
      "endOffset" : 131
    }, {
      "referenceID" : 42,
      "context" : "Despite giving strong empirical results, neural models can suffer from spurious feature associations in their neural semantic representation (Poliak et al., 2018; Kaushik et al., 2020), which can lead to weak robustness, inducing irrelevant dialogue states (Xu and Sarikaya, 2014; Sharma et al.",
      "startOffset" : 141,
      "endOffset" : 184
    }, {
      "referenceID" : 23,
      "context" : "Despite giving strong empirical results, neural models can suffer from spurious feature associations in their neural semantic representation (Poliak et al., 2018; Kaushik et al., 2020), which can lead to weak robustness, inducing irrelevant dialogue states (Xu and Sarikaya, 2014; Sharma et al.",
      "startOffset" : 141,
      "endOffset" : 184
    }, {
      "referenceID" : 63,
      "context" : ", 2020), which can lead to weak robustness, inducing irrelevant dialogue states (Xu and Sarikaya, 2014; Sharma et al., 2019; Rastogi et al., 2019) and generating unfaithful or irrelevant text (Maynez et al.",
      "startOffset" : 80,
      "endOffset" : 146
    }, {
      "referenceID" : 50,
      "context" : ", 2020), which can lead to weak robustness, inducing irrelevant dialogue states (Xu and Sarikaya, 2014; Sharma et al., 2019; Rastogi et al., 2019) and generating unfaithful or irrelevant text (Maynez et al.",
      "startOffset" : 80,
      "endOffset" : 146
    }, {
      "referenceID" : 44,
      "context" : ", 2020), which can lead to weak robustness, inducing irrelevant dialogue states (Xu and Sarikaya, 2014; Sharma et al., 2019; Rastogi et al., 2019) and generating unfaithful or irrelevant text (Maynez et al.",
      "startOffset" : 80,
      "endOffset" : 146
    }, {
      "referenceID" : 35,
      "context" : ", 2019) and generating unfaithful or irrelevant text (Maynez et al., 2020; Niu and Bansal, 2020).",
      "startOffset" : 53,
      "endOffset" : 96
    }, {
      "referenceID" : 38,
      "context" : ", 2019) and generating unfaithful or irrelevant text (Maynez et al., 2020; Niu and Bansal, 2020).",
      "startOffset" : 53,
      "endOffset" : 96
    }, {
      "referenceID" : 55,
      "context" : "4431 neural representation and have been shown useful for information extraction (Strubell et al., 2018; Sun et al., 2019; Li et al., 2020; Bai et al., 2021; Sachan et al., 2021), summarization (Liu et al.",
      "startOffset" : 81,
      "endOffset" : 178
    }, {
      "referenceID" : 56,
      "context" : "4431 neural representation and have been shown useful for information extraction (Strubell et al., 2018; Sun et al., 2019; Li et al., 2020; Bai et al., 2021; Sachan et al., 2021), summarization (Liu et al.",
      "startOffset" : 81,
      "endOffset" : 178
    }, {
      "referenceID" : 29,
      "context" : "4431 neural representation and have been shown useful for information extraction (Strubell et al., 2018; Sun et al., 2019; Li et al., 2020; Bai et al., 2021; Sachan et al., 2021), summarization (Liu et al.",
      "startOffset" : 81,
      "endOffset" : 178
    }, {
      "referenceID" : 2,
      "context" : "4431 neural representation and have been shown useful for information extraction (Strubell et al., 2018; Sun et al., 2019; Li et al., 2020; Bai et al., 2021; Sachan et al., 2021), summarization (Liu et al.",
      "startOffset" : 81,
      "endOffset" : 178
    }, {
      "referenceID" : 47,
      "context" : "4431 neural representation and have been shown useful for information extraction (Strubell et al., 2018; Sun et al., 2019; Li et al., 2020; Bai et al., 2021; Sachan et al., 2021), summarization (Liu et al.",
      "startOffset" : 81,
      "endOffset" : 178
    }, {
      "referenceID" : 31,
      "context" : ", 2021), summarization (Liu et al., 2015; Hardy and Vlachos, 2018; Liao et al., 2018) and machine translation (Marcheggiani et al.",
      "startOffset" : 23,
      "endOffset" : 85
    }, {
      "referenceID" : 22,
      "context" : ", 2021), summarization (Liu et al., 2015; Hardy and Vlachos, 2018; Liao et al., 2018) and machine translation (Marcheggiani et al.",
      "startOffset" : 23,
      "endOffset" : 85
    }, {
      "referenceID" : 30,
      "context" : ", 2021), summarization (Liu et al., 2015; Hardy and Vlachos, 2018; Liao et al., 2018) and machine translation (Marcheggiani et al.",
      "startOffset" : 23,
      "endOffset" : 85
    }, {
      "referenceID" : 4,
      "context" : "We explore AMR (Banarescu et al., 2013) as a semantic representation for dialogue histories in order to better represent conversations.",
      "startOffset" : 15,
      "endOffset" : 39
    }, {
      "referenceID" : 67,
      "context" : "For the first method, we merge an AMR with tokens in its corresponding sentence via AMR-to-text alignments, before encoding the resulting structure using a graph Transformer (Zhu et al., 2019).",
      "startOffset" : 174,
      "endOffset" : 192
    }, {
      "referenceID" : 33,
      "context" : "For the second method, we separately encode an AMR and its corresponding sentence, before leveraging both representations via feature fusion (Mangai et al., 2010) or dual attention (Calixto et al.",
      "startOffset" : 141,
      "endOffset" : 162
    }, {
      "referenceID" : 64,
      "context" : "We verify the effectiveness of the proposed framework on a dialogue relation extraction task (Yu et al., 2020) and a response generation task (Li et al.",
      "startOffset" : 93,
      "endOffset" : 110
    }, {
      "referenceID" : 28,
      "context" : ", 2020) and a response generation task (Li et al., 2017).",
      "startOffset" : 39,
      "endOffset" : 56
    }, {
      "referenceID" : 24,
      "context" : "Please refer to PropBank (Kingsbury and Palmer, 2002; Palmer et al., 2005) for more details.",
      "startOffset" : 25,
      "endOffset" : 74
    }, {
      "referenceID" : 40,
      "context" : "Please refer to PropBank (Kingsbury and Palmer, 2002; Palmer et al., 2005) for more details.",
      "startOffset" : 25,
      "endOffset" : 74
    }, {
      "referenceID" : 58,
      "context" : "methods (Vaswani et al., 2017; Bao et al., 2020; Yu et al., 2020), achieving the new state-of-the-art results on both benchmarks.",
      "startOffset" : 8,
      "endOffset" : 65
    }, {
      "referenceID" : 5,
      "context" : "methods (Vaswani et al., 2017; Bao et al., 2020; Yu et al., 2020), achieving the new state-of-the-art results on both benchmarks.",
      "startOffset" : 8,
      "endOffset" : 65
    }, {
      "referenceID" : 64,
      "context" : "methods (Vaswani et al., 2017; Bao et al., 2020; Yu et al., 2020), achieving the new state-of-the-art results on both benchmarks.",
      "startOffset" : 8,
      "endOffset" : 65
    }, {
      "referenceID" : 8,
      "context" : "Given a dialogue consisting multiple utterances, we adopt a pretrained AMR parser (Cai and Lam, 2020) to obtain an AMR graph for each utterance.",
      "startOffset" : 82,
      "endOffset" : 101
    }, {
      "referenceID" : 18,
      "context" : "which are frequent in conversations (Grosz et al., 1995; Newman et al., 2008; Quan et al., 2019).",
      "startOffset" : 36,
      "endOffset" : 96
    }, {
      "referenceID" : 37,
      "context" : "which are frequent in conversations (Grosz et al., 1995; Newman et al., 2008; Quan et al., 2019).",
      "startOffset" : 36,
      "endOffset" : 96
    }, {
      "referenceID" : 43,
      "context" : "which are frequent in conversations (Grosz et al., 1995; Newman et al., 2008; Quan et al., 2019).",
      "startOffset" : 36,
      "endOffset" : 96
    }, {
      "referenceID" : 58,
      "context" : "We adopt a standard Transformer (Vaswani et al., 2017) for dialogue history encoding.",
      "startOffset" : 32,
      "endOffset" : 54
    }, {
      "referenceID" : 64,
      "context" : "We take the dialogue relation extraction task (Yu et al., 2020) as an example.",
      "startOffset" : 46,
      "endOffset" : 63
    }, {
      "referenceID" : 10,
      "context" : "We follow a previous dialogue relation extraction model (Chen et al., 2020) to feed the hidden states of a1 and a2 (denoted as ha1 , ha2) into a classifier to obtain the probability of each relation types:",
      "startOffset" : 56,
      "endOffset" : 75
    }, {
      "referenceID" : 13,
      "context" : "In practice, we use BERT (Devlin et al., 2019) for calculating ha1 and ha2 , which can be regarded as pre-trained initialization of the Transformer encoder.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 58,
      "context" : "Given a dialogue history S , we use a standard autoregressive Transformer decoder (Vaswani et al., 2017) to generate a response Y = {y1, y2, .",
      "startOffset" : 82,
      "endOffset" : 104
    }, {
      "referenceID" : 67,
      "context" : "We adopt a Graph Transformer (Zhu et al., 2019) to encode an AMR graph, which extends the standard Transformer (Vaswani et al.",
      "startOffset" : 29,
      "endOffset" : 47
    }, {
      "referenceID" : 58,
      "context" : ", 2019) to encode an AMR graph, which extends the standard Transformer (Vaswani et al., 2017) for modeling structural input.",
      "startOffset" : 71,
      "endOffset" : 93
    }, {
      "referenceID" : 17,
      "context" : "We first use the JAMR aligner (Flanigan et al., 2014) to obtain a node-to-word alignment, then adopt the alignment to project the AMR edges onto text with following rules:",
      "startOffset" : 30,
      "endOffset" : 53
    }, {
      "referenceID" : 20,
      "context" : "Inspired by previous work on AMR graph modeling (Guo et al., 2019; Song et al., 2019b; Sun et al., 2019), we adopt a hierarchical encoder that stacks a sequence encoder and a graph encoder.",
      "startOffset" : 48,
      "endOffset" : 104
    }, {
      "referenceID" : 53,
      "context" : "Inspired by previous work on AMR graph modeling (Guo et al., 2019; Song et al., 2019b; Sun et al., 2019), we adopt a hierarchical encoder that stacks a sequence encoder and a graph encoder.",
      "startOffset" : 48,
      "endOffset" : 104
    }, {
      "referenceID" : 56,
      "context" : "Inspired by previous work on AMR graph modeling (Guo et al., 2019; Song et al., 2019b; Sun et al., 2019), we adopt a hierarchical encoder that stacks a sequence encoder and a graph encoder.",
      "startOffset" : 48,
      "endOffset" : 104
    }, {
      "referenceID" : 0,
      "context" : "where LayerNorm denotes the layer normalization (Ba et al., 2016).",
      "startOffset" : 48,
      "endOffset" : 65
    }, {
      "referenceID" : 51,
      "context" : "We replace the standard encoder-decoder attention (Equation 7) with a dual-attention mechanism (Song et al., 2019a).",
      "startOffset" : 95,
      "endOffset" : 115
    }, {
      "referenceID" : 64,
      "context" : "We evaluate our model on DialogRE (Yu et al., 2020), which contains totally 1,788 dialogues, 10,168 relational triples and 36 relation types in total.",
      "startOffset" : 34,
      "endOffset" : 51
    }, {
      "referenceID" : 64,
      "context" : "Metrics Following previous work on DialogRE, we report macro F1 score on relations in both the standard (F1) and conversational settings (F1c; Yu et al., 2020).",
      "startOffset" : 137,
      "endOffset" : 159
    }, {
      "referenceID" : 64,
      "context" : "Based on BERT, BERTs (Yu et al., 2020) highlights speaker information by replacing speaker arguments with special tokens.",
      "startOffset" : 21,
      "endOffset" : 38
    }, {
      "referenceID" : 20,
      "context" : "For completeness, we also include recent methods, such as AGGCN (Guo et al., 2019), LSR (Nan et al.",
      "startOffset" : 64,
      "endOffset" : 82
    }, {
      "referenceID" : 36,
      "context" : ", 2019), LSR (Nan et al., 2020) and DHGAT (Chen et al.",
      "startOffset" : 13,
      "endOffset" : 31
    }, {
      "referenceID" : 28,
      "context" : "We conduct experiments on the DailyDialog benchmark (Li et al., 2017), which contains 13,119 daily multi-turn conversations.",
      "startOffset" : 52,
      "endOffset" : 69
    }, {
      "referenceID" : 41,
      "context" : "Metric We set the decoding beam size as 5 and adopt BLEU-1/2/3/4 (Papineni et al., 2002) and Distinct-1/2 (Li et al.",
      "startOffset" : 65,
      "endOffset" : 88
    }, {
      "referenceID" : 27,
      "context" : ", 2002) and Distinct-1/2 (Li et al., 2016) as automatic evaluation metrics.",
      "startOffset" : 25,
      "endOffset" : 42
    }, {
      "referenceID" : 59,
      "context" : "For completeness, we also report other systems including Seq2Seq (Vinyals and Le, 2015) and iVAEMI (Fang et al.",
      "startOffset" : 65,
      "endOffset" : 87
    }, {
      "referenceID" : 16,
      "context" : "For completeness, we also report other systems including Seq2Seq (Vinyals and Le, 2015) and iVAEMI (Fang et al., 2019).",
      "startOffset" : 99,
      "endOffset" : 118
    }, {
      "referenceID" : 49,
      "context" : "Recent studies show that neural network-based dialog models lack robustness (Shalyminov and Lee, 2018; Einolghozati et al., 2019).",
      "startOffset" : 76,
      "endOffset" : 129
    }, {
      "referenceID" : 15,
      "context" : "Recent studies show that neural network-based dialog models lack robustness (Shalyminov and Lee, 2018; Einolghozati et al., 2019).",
      "startOffset" : 76,
      "endOffset" : 129
    }, {
      "referenceID" : 68,
      "context" : "For example, in the PEGASUS (Zue et al., 1994) system, a sentence is first transformed into a semantic frame and then used for travel planing.",
      "startOffset" : 28,
      "endOffset" : 46
    }, {
      "referenceID" : 17,
      "context" : "AMR Parsing and Encoding Our work is also related to AMR parsing (Flanigan et al., 2014; Konstas et al., 2017a; Lyu and Titov, 2018; Guo and Lu, 2018; Zhang et al., 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al.",
      "startOffset" : 65,
      "endOffset" : 189
    }, {
      "referenceID" : 25,
      "context" : "AMR Parsing and Encoding Our work is also related to AMR parsing (Flanigan et al., 2014; Konstas et al., 2017a; Lyu and Titov, 2018; Guo and Lu, 2018; Zhang et al., 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al.",
      "startOffset" : 65,
      "endOffset" : 189
    }, {
      "referenceID" : 32,
      "context" : "AMR Parsing and Encoding Our work is also related to AMR parsing (Flanigan et al., 2014; Konstas et al., 2017a; Lyu and Titov, 2018; Guo and Lu, 2018; Zhang et al., 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al.",
      "startOffset" : 65,
      "endOffset" : 189
    }, {
      "referenceID" : 19,
      "context" : "AMR Parsing and Encoding Our work is also related to AMR parsing (Flanigan et al., 2014; Konstas et al., 2017a; Lyu and Titov, 2018; Guo and Lu, 2018; Zhang et al., 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al.",
      "startOffset" : 65,
      "endOffset" : 189
    }, {
      "referenceID" : 65,
      "context" : "AMR Parsing and Encoding Our work is also related to AMR parsing (Flanigan et al., 2014; Konstas et al., 2017a; Lyu and Titov, 2018; Guo and Lu, 2018; Zhang et al., 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al.",
      "startOffset" : 65,
      "endOffset" : 189
    }, {
      "referenceID" : 8,
      "context" : "AMR Parsing and Encoding Our work is also related to AMR parsing (Flanigan et al., 2014; Konstas et al., 2017a; Lyu and Titov, 2018; Guo and Lu, 2018; Zhang et al., 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al.",
      "startOffset" : 65,
      "endOffset" : 189
    }, {
      "referenceID" : 26,
      "context" : ", 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al., 2017b; Song et al., 2018; Zhu et al., 2019; Song et al., 2020; Zhao et al., 2020; Bai et al., 2020).",
      "startOffset" : 44,
      "endOffset" : 160
    }, {
      "referenceID" : 54,
      "context" : ", 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al., 2017b; Song et al., 2018; Zhu et al., 2019; Song et al., 2020; Zhao et al., 2020; Bai et al., 2020).",
      "startOffset" : 44,
      "endOffset" : 160
    }, {
      "referenceID" : 67,
      "context" : ", 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al., 2017b; Song et al., 2018; Zhu et al., 2019; Song et al., 2020; Zhao et al., 2020; Bai et al., 2020).",
      "startOffset" : 44,
      "endOffset" : 160
    }, {
      "referenceID" : 52,
      "context" : ", 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al., 2017b; Song et al., 2018; Zhu et al., 2019; Song et al., 2020; Zhao et al., 2020; Bai et al., 2020).",
      "startOffset" : 44,
      "endOffset" : 160
    }, {
      "referenceID" : 66,
      "context" : ", 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al., 2017b; Song et al., 2018; Zhu et al., 2019; Song et al., 2020; Zhao et al., 2020; Bai et al., 2020).",
      "startOffset" : 44,
      "endOffset" : 160
    }, {
      "referenceID" : 3,
      "context" : ", 2019; Cai and Lam, 2020) and AMR encoding (Konstas et al., 2017b; Song et al., 2018; Zhu et al., 2019; Song et al., 2020; Zhao et al., 2020; Bai et al., 2020).",
      "startOffset" : 44,
      "endOffset" : 160
    } ],
    "year" : 2021,
    "abstractText" : "Although neural models have achieved competitive results in dialogue systems, they have shown limited ability in representing core semantics, such as ignoring important entities. To this end, we exploit Abstract Meaning Representation (AMR) to help dialogue modeling. Compared with the textual input, AMR explicitly provides core semantic knowledge and reduces data sparsity. We develop an algorithm to construct dialogue-level AMR graphs from sentence-level AMRs and explore two ways to incorporate AMRs into dialogue systems. Experimental results on both dialogue understanding and response generation tasks show the superiority of our model. To our knowledge, we are the first to leverage a formal semantic representation into neural dialogue modeling.",
    "creator" : "LaTeX with hyperref"
  }
}