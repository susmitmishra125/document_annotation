{
  "name" : "2021.acl-long.486.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction",
    "authors" : [ "Hengyi Zheng", "Rui Wen", "Xi Chen", "Yifan Yang", "Yunyan Zhang", "Ziheng Zhang", "Ningyu Zhang", "Bin Qin", "Ming Xu", "Yefeng Zheng" ],
    "emails" : [ "zhenghengyi2019@email.szu.edu.cn,", "qinbin@szu.edu.cn", "xuming@szu.edu.cn", "ruiwen@tencent.com", "jasonxchen@tencent.com", "tobyfyang@tencent.com", "yunyanzhang@tencent.com", "zihengzhang@tencent.com", "yefengzheng@tencent.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6225–6235\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n6225"
    }, {
      "heading" : "1 Introduction",
      "text" : "Identifying entity mentions and their relations which are in the form of a triple (subject, relation, object) from unstructured texts is an important task in information extraction. Some previous works proposed to address the task with pipelined approaches which include two steps: named entity recognition (Tjong Kim Sang and De Meulder, 2003; Ratinov and Roth, 2009) and relation prediction (Zelenko et al., 2002; Bunescu and Mooney,\n*Corresponding author. 1The source code and data are released at\nhttps://github.com/hy-struggle/PRGC.\n2005; Pawar et al., 2017; Wang et al., 2020b). Recent end-to-end methods, which are based on either multi-task learning (Wei et al., 2020) or singlestage framework (Wang et al., 2020a), achieved promising performance and proved their effectiveness, but lacked in-depth study of the task.\nTo better comprehend the task and advance the state of the art, we propose a novel perspective to decompose the task into three subtasks: i) Relation Judgement which aims to identify relations in a sentence, ii) Entity Extraction which aims to extract all subjects and objects in the sentence and iii) Subject-object Alignment which aims to align the subject-object pair into a triple. On the basis, we review two end-to-end methods in Table 1. For the multi-task method named CasRel (Wei et al., 2020), the relational triple extraction is performed in two stages which applies object extraction to all relations. Obviously, the way to identify relations is redundant which contains numerous invalid operations, and the span-based extraction scheme which just pays attention to start/end position of an entity leads to poor generalization. Meanwhile, it is restricted to process one subject at a time due to its subject-object alignment mechanism, which is inefficient and difficult to deploy. For the single-stage\nframework named TPLinker (Wang et al., 2020a), in order to avoid the exposure bias in subject-object alignment, it exploits a rather complicated decoder which leads to sparse label and low convergence rate while the problems of relation redundancy and poor generalization of span-based extraction are still unsolved.\nTo address aforementioned issues, we propose an end-to-end framework which consists of three components: Potential Relation Prediction, Relation-Specific Sequence Tagging and Global Correspondence, which fulfill the three subtasks accordingly as shown in Table 1.\nFor Relation Judgement, we predict potential relations by the Potential Relation Prediction component rather than preserve all redundant relations, which reduces computational complexity and achieves better performance, especially when there are many relations in the dataset.2 For Entity Extraction, we use a more robust RelationSpecific Sequence Tagging component (Rel-Spec Sequence Tagging for short) to extract subjects and objects separately, to naturally handle overlapping between subjects and objects. For Subjectobject Alignment, unlike TPLinker which uses a relation-based token-pair matrix, we design a relation-independent Global Correspondence matrix to determine whether a specific subject-object pair is valid in a triple.\nGiven a sentence, PRGC first predicts a subset of potential relations and a global matrix which contains the correspondence score between all subjects and objects; then performs sequence tagging to extract subjects and objects for each potential relation in parallel; finally enumerates all predicted entity pairs, which are then pruned by the global correspondence matrix. It is worth to note that the experiment (described in Section 5.2.1) shows that the Potential Relation Prediction component of PRGC is overall beneficial, even though it introduces the exposure bias that is usually mentioned in prior single-stage methods to prove their advantages.\nExperimental results show that PRGC outperforms the state-of-the-art methods on public benchmarks with higher efficiency and fewer parameters. Detailed experiments on complex scenarios such as various overlapping patterns, which contain the Single Entity Overlap (SEO), Entity Pair Overlap\n2For example, the WebNLG dataset (Gardent et al., 2017) has hundreds of relations but only seven valid relations for one sentence mostly.\n(EPO) and Subject Object Overlap (SOO) types3 show that our method owns consistent advantages. The main contributions of this paper are as follows:\n1. We tackle the relational triple extraction task from a novel perspective which decomposes the task into three subtasks: Relation Judgement, Entity Extraction and Subject-object Alignment, and previous works are compared on the basis of the proposed paradigm as shown in Table 1.\n2. Following our perspective, we propose a novel end-to-end framework and design three components with respect to the subtasks which greatly alleviate the problems of redundant relation judgement, poor generalization of spanbased extraction and inefficient subject-object alignment, respectively.\n3. We conduct extensive experiments on several public benchmarks, which indicate that our method achieves state-of-the-art performance, especially for complex scenarios of overlapping triples. Further ablation studies and analyses confirm the effectiveness of each component in our model.\n4. In addition to higher accuracy, experiments show that our method owns significant advantages in complexity, number of parameters, floating point operations (FLOPs) and inference time compared with previous works."
    }, {
      "heading" : "2 Related Work",
      "text" : "Traditionally, relational triple extraction has been studied as two separated tasks: entity extraction and relation prediction. Early works (Zelenko et al., 2002; Chan and Roth, 2011) apply the pipelined methods to perform relation classification between entity pairs after extracting all the entities. To establish the correlation between these two tasks, joint models have attracted much attention. Prior featurebased joint models (Yu and Lam, 2010; Li and Ji, 2014; Miwa and Sasaki, 2014; Ren et al., 2017) require a complicated process of feature engineering and rely on various NLP tools with cumbersome manual operations.\nRecently, the neural network model which reduces manual involvement occupies the main part of the research. Zheng et al. (2017) proposed a\n3More details about overlapping patterns are shown in Appendix A.\nnovel tagging scheme that unified the role of the entity and the relation between entities in the annotations, thus the joint extraction task was converted to a sequence labeling task but it failed to solve the overlapping problems. Bekoulis et al. (2018) proposed to first extract all candidate entities, then predict the relation of every entity pair as a multihead selection problem, which shared parameters but did not decode jointly. Nayak and Ng (2020) employed an encoder-decoder architecture and a pointer network based decoding approach where an entire triple was generated at each time step.\nTo handle the problems mentioned above, Wei et al. (2020) presented a cascade framework, which first identified all possible subjects in a sentence, then for each subject, applied span-based taggers to identify the corresponding objects based on each relation. This method leads to redundancy on relation judgement, and is not robust due to the span-based scheme on entity extraction. Meanwhile, the alignment scheme of subjects and objects limits its parallelization. In order to represent the relation of triple explicitly, Yuan et al. (2020) presented a relationspecific attention to assign different weights to the words in context under each relation, but it applied a naive heuristic nearest neighbor principle to combine the entity pairs which means the nearest subject and object entities will be combined into a triple. This is obviously not in accordance with intuition and fact. Meanwhile, it is also redundant\non relation judgement. The state-of-the-art method named TPLinker (Wang et al., 2020a) employs a token pair linking scheme which performs twoO(n2) matrix operations for extracting entities and aligning subjects with objects under each relation of a sentence, causing extreme redundancy on relation judgement and complexity on subject-object alignment, respectively. And it also suffers from the disadvantage of span-based extraction scheme."
    }, {
      "heading" : "3 Method",
      "text" : "In this section, we first introduce our perspective of relational triple extraction task with a principled problem definition, then elaborate each component of the PRGC model. An overview illustration of PRGC is shown in Figure 1."
    }, {
      "heading" : "3.1 Problem Definition",
      "text" : "The input is a sentence S = {x1, x2, ..., xn} with n tokens. The desired outputs are relational triples as T (S) = {(s, r, o)|s, o ∈ E, r ∈ R}, where E and R are the entity and relation sets, respectively. In this paper, the problem is decomposed into three subtasks:\nRelation Judgement For the given sentence S, this subtask predicts potential relations it contains. The output of this task is Yr(S) = {r1, r2, ..., rm|ri ∈ R}, where m is the size of potential relation subset.\nEntity Extraction For the given sentence S and a predicted potential relation ri, this subtask identifies the tag of each token with BIO (i.e., Begin, Inside and Outside) tag scheme (Tjong Kim Sang and Veenstra, 1999; Ratinov and Roth, 2009). Let tj denote the tag. The output of this task is Ye(S, ri|ri ∈ R) = {t1, t2, ..., tn}.\nSubject-object Alignment For the given sentence S, this subtask predicts the correspondence score between the start tokens of subjects and objects. That means only the pair of start tokens of a true triple has a high score, while the other token pairs have a low score. Let M denote the global correspondence matrix. The output of this task is Ys(S) = M ∈ Rn×n."
    }, {
      "heading" : "3.2 PRGC Encoder",
      "text" : "The output of PRGC Encoder is Yenc(S) = {h1, h2, ..., hn|hi ∈ Rd×1}, where d is the embedding dimension, and n is the number of tokens. We use a pre-trained BERT model4 (Devlin et al., 2019) to encode the input sentence for a fair comparison, but theoretically it can be extended to other encoders, such as Glove (Pennington et al., 2014) and RoBERTa (Liu et al., 2019)."
    }, {
      "heading" : "3.3 PRGC Decoder",
      "text" : "In this section, we describe the instantiation of PRGC decoder that consists of three components."
    }, {
      "heading" : "3.3.1 Potential Relation Prediction",
      "text" : "This component is shown as the orange box in Figure 1 where Rpot is the potential relations. Different from previous works (Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a) which redundantly perform entity extraction to every relation, given a sentence, we first predict a subset of potential relations that possibly exist in the sentence, and then the entity extraction only needs to be applied to these potential relations. Given the embedding h ∈ Rn×d of a sentence with n tokens, each element of this component is obtained as:\nhavg = Avgpool(h) ∈ Rd×1\nPrel = σ(Wrh avg + br)\n(1)\nwhere Avgpool is the average pooling operation (Lin et al., 2014), Wr ∈ Rd×1 is a trainable weight and σ denotes the sigmoid function.\n4Please refer to the original paper (Devlin et al., 2019) for detailed descriptions.\nWe model it as a multi-label binary classification task, and the corresponding relation will be assigned with tag 1 if the probability exceeds a certain threshold λ1 or with tag 0 otherwise (as shown in Figure 1), so next we just need to apply the relation-specific sequence tagging to the predicted relations rather than all relations."
    }, {
      "heading" : "3.3.2 Relation-Specific Sequence Tagging",
      "text" : "As shown in Figure 1, we obtain several relationspecific sentence representations of potential relations described in Section 3.3.1. Then, we perform two sequence tagging operations to extract subjects and objects, respectively. The reason why we extract subjects and objects separately is to handle the special overlapping pattern named Subject Object Overlap (SOO). We can also simplify it to one sequence tagging operation with two types of entities if there are no SOO patterns in the dataset.5\nFor the sake of simplicity and fairness, we abandon the traditional LSTM-CRF (Panchendrarajan and Amaresan, 2018) network but adopt the simple fully connected neural network. Detailed operations of this component on each token are as follows:\nPsubi,j = Softmax(Wsub(hi + uj) + bsub)\nPobji,j = Softmax(Wobj(hi + uj) + bobj) (2)\nwhere uj ∈ Rd×1 is the j-th relation representation in a trainable embedding matrix U ∈ Rd×nr where nr is the size of full relation set, hi ∈ Rd×1 is the encoded representation of the i-th token, and Wsub,Wobj ∈ Rd×3 are trainable weights where the size of tag set {B, I, O} is 3."
    }, {
      "heading" : "3.3.3 Global Correspondence",
      "text" : "After sequence tagging, we acquire all possible subjects and objects with respect to a relation of the sentence, then we use a global correspondence matrix to determine the correct pairs of the subjects and objects. It should be noted that the global correspondence matrix can be learned simultaneously with potential relation prediction since it is independent of relations. The detailed process is as follows: first we enumerate all the possible subjectobject pairs; then we check the corresponding score in the global matrix for each pair, retain it if the value exceeds a certain threshold λ2 or filter it out otherwise.\n5For example, the SOO pattern is rare in the NYT (Riedel et al., 2010) dataset.\nAs shown in the green matrix M in Figure 1, given a sentence with n tokens, the shape of global correspondence matrix will be Rn×n. Each element of this matrix is about the start position of a paired subject and object, which represents the confidence level of a subject-object pair, the higher the value, the higher the confidence level that the pair belongs to a triple. For example, the value about “Tom” and “Jerry” at row 1, column 3 will be high if they are in a correct triple such as “(Tom, like, Jerry)”. The value of each element in the matrix is obtained as follows:\nPisub,jobj = σ(Wg[h sub i ;h obj j ] + bg) (3)\nwhere hsubi ,h obj j ∈ Rd×1 are the encoded representation of the i-th token and j-th token in the input sentence forming a potential pair of subject and object, Wg ∈ R2d×1 is a trainable weight, and σ is the sigmoid function."
    }, {
      "heading" : "3.4 Training Strategy",
      "text" : "We train the model jointly, optimize the combined objective function during training time and share the parameters of the PRGC encoder. The total loss can be divided into three parts as follows:\nLrel = − 1\nnr nr∑ i=1 (yi logPrel + (1− yi) log (1− Prel))\n(4)\nLseq = − 1\n2× n× npotr ∑ t∈{sub,obj} npotr∑ j=1 n∑ i=1 yti,j logP t i,j\n(5)\nLglobal =− 1\nn2 n∑ i=1 n∑ j=1 (yi,j logPisub,jobj\n+ (1− yi,j) log (1− Pisub,jobj )) (6)\nwhere nr is the size of full relation set and n pot r is the size of potential relation subset of the sentence. The total loss is the sum of these three parts,\nLtotal = αLrel + βLseq + γLglobal. (7)\nPerformance might be better by carefully tuning the weight of each sub-loss, but we just assign equal weights for simplicity (i.e., α = β = γ = 1)."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets and Experimental Settings",
      "text" : "For fair and comprehensive comparison, we follow Yu et al. (2019) and Wang et al. (2020a) to evaluate our model on two public datasets NYT (Riedel et al., 2010) and WebNLG (Gardent et al., 2017), both of which have two versions, respectively. We denote the different versions as NYT*, NYT and WebNLG*, WebNLG. Note that NYT* and WebNLG* annotate the last word of entities, while NYT and WebNLG annotate the whole entity span. The statistics of the datasets are described in Table 2. Following Wei et al. (2020), we further characterize the test set w.r.t. the overlapping patterns and the number of triples per sentence.\nFollowing prior works mentioned above, an extracted relational triple is regarded as correct only if it is an exact match with ground truth, which means the last word of entities or the whole entity span (depending on the annotation protocol) of both subject and object and the relation are all correct. Meanwhile, we report the standard micro Precision (Prec.), Recall (Rec.) and F1-score for all the baselines. The implementation details are shown in Appendix B.\nWe compare PRGC with eight strong baseline models and the state-of-the-art models CasRel (Wei et al., 2020) and TPLinker (Wang et al., 2020a). All the experimental results of the baseline models are directly taken from Wang et al. (2020a) unless specified."
    }, {
      "heading" : "4.2 Experimental Results",
      "text" : "In this section, we present the overall results and the results of complex scenarios, while the results on different subtasks corresponding to different\ncomponents in our model are described in Appendix C."
    }, {
      "heading" : "4.2.1 Overall Results",
      "text" : "Table 3 shows the results of our model against other baseline methods on four datasets. Our PRGC method outperforms them in respect of almost all evaluation metrics even if compared with the recent strongest baseline (Wang et al., 2020a) which is quite complicated.\nAt the same time, we implement PRGCRandom to validate the utility of our PRGC decoder, where all parameters of the encoder BERT are randomly initialized. The performance of PRGCRandom demonstrates that our decoder framework (which obtains 7% improvements than CasRelRandom) is still more competitive and robust than others even\nwithout taking advantage of the pre-trained BERT language model.\nIt is important to note that even though TPLinkerBERT has more parameters than CasRelBERT , it only obtains 0.1% improvements on the WebNLG* dataset, and the authors attributed this to problems with the dataset itself. However, our model achieves a 10× improvements than TPLinker on the WebNLG* dataset and a significant promotion on the WebNLG dataset. The reason behind this is that the relation judgement component of our model greatly reduces redundant relations particularly in the versions of WebNLG which contain hundreds of relations. In other words, the reduction in negative relations provides an additional boost compared to the models that perform entity extraction under every relation."
    }, {
      "heading" : "4.2.2 Detailed Results on Complex Scenarios",
      "text" : "Following previous works (Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a), to verify the capability of our model in handling different overlapping patterns and sentences with different numbers of triples, we conduct further experiments on NYT* and WebNLG* datasets.\nAs shown in Table 4, our model exceeds all the baselines in all overlapping patterns in both datasets except the SOO pattern in the NYT* dataset. Actually, the observation on the latter scenario is not reliable due to the very low percentage of SOO in NYT* (i.e., 45 out of 8,110 as shown in Table 2). As shown in Table 5, the performance of our model is better than others almost in every subset regardless of the number of triples. In general, these two further experiments adequately show the advantages of our model in complex scenarios."
    }, {
      "heading" : "5 Analysis",
      "text" : ""
    }, {
      "heading" : "5.1 Model Efficiency",
      "text" : "As shown in Table 6, we evaluate the model ef-\nficiency with respect to Complexity, floating point operations (FLOPs) (Molchanov et al., 2017), parameters of the decoder (Paramsdecoder) and Inference Time6 of CasRel, TPLinker and PRGC in two datasets which have quite different characteristics in the size of relation set, the average number of relations per sentence and the average number of subjects per sentence. All experiments are conducted with the same hardware configuration. Because the number of subjects in a sentence varies, it is difficult for CasRel to predict objects in a heterogeneous batch, and it is restricted to set batch size to 1 in the official implementation (Wang et al., 2020a). For the sake of fair comparison, we set batch size to 1 and 24 to verify the single-thread decoding speed and parallel processing capability, respectively.\nThe results indicate that the single-thread decoding speed of PRGC is 2× as CasRel and 3× as TPLinker, and our model is significantly better than TPLinker in terms of parallel processing. Note that the model efficiency of CasRel and TPLinker decreases as the size of relation set increases but our model is not affected by the size of relation set, thus PRGC overwhelmingly outperforms both models in terms of all the indicators of efficiency in the WebNLG* dataset. Compared with the stateof-the-art model TPLinker, PRGC is an order of magnitude lower in Complexity and the FLOPs is even 200 times lower, thus PRGC has fewer parameters and obtains 3× speedup in the inference phase while the F1-score is improved by 1.1%. Even though CasRel has lower Complexity and FLOPs in the NYT* dataset, PRGC still has significant advantages and obtains a 5× speedup in the inference time and 3% improvements in F1-score. Meanwhile, Figure 2 proves our advantage in convergence rate. These all confirm the efficiency of\n6The FLOPs and Paramsdecoder are calculated via: https://github.com/sovrasov/flops-counter.pytorch.\nour model."
    }, {
      "heading" : "5.2 Ablation Study",
      "text" : "In this section, we conduct ablation experiments to demonstrate the effectiveness of each component in PRGC with results reported in Table 7."
    }, {
      "heading" : "5.2.1 Effect of Potential Relation Prediction",
      "text" : "We use each relation in the relation set to perform sequence tagging when we remove the Potential Relation Prediction component to avoid the exposure bias. As shown in Table 7, the precision significantly decreases without this component, because the number of predicted triples increases due to relations not presented in the sentences, especially in the WebNLG* dataset where the size of relation set is much bigger and brings tremendous relation redundancy. Meanwhile, with the increase of relation number in sentences, the training and inference time increases three to four times. Through this experiment, the validity of this component that aims to predict a potential relation subset is proved, which is not only beneficial to model accuracy, but also to efficiency."
    }, {
      "heading" : "5.2.2 Effect of Rel-Spec Sequence Tagging",
      "text" : "As a comparison for sequence tagging scheme, following Wei et al. (2020) and Wang et al. (2020a), we perform binary classification to detect start\nand end positions of an entity with the span-based scheme. As shown in Table 7, span-based scheme brings significant decline of performance.\nThrough the case study shown in Figure 3, we observe that the span-based scheme tends to extract long entities and identify the correct subject-object pairs but ignore their relation. That is because the model is inclined to remember the position of an entity rather than understand the underlying semantics. However, the sequence tagging scheme used by PRGC performs well in both cases, and experimental results prove that our tagging scheme is more robust and generalizable."
    }, {
      "heading" : "5.2.3 Effect of Global Correspondence",
      "text" : "For comparison, we exploit the heuristic nearest neighbor principle to combine the subject-object pairs which was used by Zheng et al. (2017) and Yuan et al. (2020). As shown in Table 7, the precision also significantly decreases without Global Correspondence, because the number of predicted triples increases with many mismatched pairs when the model loses the constraint imposed by this component. This experiment proves that the Global Correspondence component is effective and greatly outperforms the heuristic nearest neighbor principle in the subject-object alignment task."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we presented a brand-new perspective and introduced a novel joint relational extraction framework based on Potential Relation and Global Correspondence, which greatly alleviates the problems of redundant relation judgement, poor generalization of span-based extraction and inefficient subject-object alignment. Experimental results showed that our model achieved the stateof-the-art performance in the public datasets and successfully handled many complex scenarios with higher efficiency."
    }, {
      "heading" : "A Overlapping Patterns",
      "text" : "As shown in Figure 4, the Normal, SEO and EPO patterns are usually mentioned in prior works (Nayak and Ng, 2020; Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a), and SOO is a special pattern we identified and addressed.\nB Implementation Details\nWe implement our model with PyTorch and optimize the parameters by Adam (Kingma and Ba, 2015) with batch size of 64/6 for NYT/WebNLG. The encoder learning rate for BERT is set as 5 × 10−5, and the decoder learning rate is set as 0.001 in order to converge rapidly. We also conduct weight decay (Loshchilov and Hutter, 2017) with a rate of 0.01.\nFor fair comparison, we use the BERT-BaseCased English model7 as our encoder, and set the max length of an input sentence to 100, which is the same as previous works (Wei et al., 2020; Wang et al., 2020a). Our experiments are conducted on the workstation with an Intel Xeon E5 2.40 GHz CPU, 128 GB memory, an NVIDIA Tesla V100 GPU, and CentOS 7.2. We train the model for 100 epochs and choose the last model. The performance will be better if the higher the threshold of Potential Relation Prediction (λ1), but tuning the threshold of Global Correspondence (λ2) will not help which is consistent with the analysis in Appendix C.\n7Available at https://huggingface.co/bert-base-cased."
    }, {
      "heading" : "C Results on Different Subtasks",
      "text" : "To further verify the results of the three subtasks in our new perspective and the performance of each component in our model, we present more detailed evaluations on NYT* and WebNLG* datasets in Table 8.\nRelation Judgement We evaluate outputs of the Potential Relation Prediction component which are potential relations contained in a sentence. Recall is more important for this task because if a true relation is missed, it will not be recovered in the following steps. We get high recall in this task and the results show that effectiveness of Potential Relation Prediction component is not affected by the size of relation set.\nEntity Extraction This task is related to the Relation-Specific Sequence Tagging component, and we evaluate it as a Named Entity Recognition (NER) task with two types of entities: subjects and objects. The predicted entities are from all potential relations of a sentence, and recall is more important for this task because most false negatives can be filtered out by Subject-object Alignment. Experimental results show that we extract almost all correct entities, and it further proves that the influence of the exposure bias is negligible.\nSubject-object Alignment This task is related to the Global Correspondence component, and we just evaluate the entity pair in a triple and ignore the relation. Both recall and precision are important for this component, experimental results indicate that our alignment scheme is useful but still can be further improved, especially in the recall.\nOverall, the combination of three components in our model accomplishes the relational triple extraction task with a fine-grained perspective, and achieves better and solid results."
    } ],
    "references" : [ {
      "title" : "Joint entity recognition and relation extraction as a multi-head selection problem",
      "author" : [ "Giannis Bekoulis", "Johannes Deleu", "Thomas Demeester", "Chris Develder." ],
      "venue" : "Expert Systems with Applications, 114:34–45.",
      "citeRegEx" : "Bekoulis et al\\.,? 2018",
      "shortCiteRegEx" : "Bekoulis et al\\.",
      "year" : 2018
    }, {
      "title" : "A shortest path dependency kernel for relation extraction",
      "author" : [ "Razvan C. Bunescu", "Raymond J. Mooney." ],
      "venue" : "Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Bunescu and Mooney.,? 2005",
      "shortCiteRegEx" : "Bunescu and Mooney.",
      "year" : 2005
    }, {
      "title" : "Exploiting syntactico-semantic structures for relation extraction",
      "author" : [ "Yee Seng Chan", "Dan Roth." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 551–560.",
      "citeRegEx" : "Chan and Roth.,? 2011",
      "shortCiteRegEx" : "Chan and Roth.",
      "year" : 2011
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "J. Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Annual Conference of the North American Chapter of the Association for Computational Linguistics.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "GraphRel: Modeling text as relational graphs for joint entity and relation extraction",
      "author" : [ "Tsu-Jui Fu", "Peng-Hsuan Li", "Wei-Yun Ma." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1409–1418, Flo-",
      "citeRegEx" : "Fu et al\\.,? 2019",
      "shortCiteRegEx" : "Fu et al\\.",
      "year" : 2019
    }, {
      "title" : "Creating training corpora for NLG micro-planners",
      "author" : [ "Claire Gardent", "Anastasia Shimorina", "Shashi Narayan", "Laura Perez-Beltrachini." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa-",
      "citeRegEx" : "Gardent et al\\.,? 2017",
      "shortCiteRegEx" : "Gardent et al\\.",
      "year" : 2017
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "3rd International Conference on Learning Representations, San Diego, CA, USA, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Incremental joint extraction of entity mentions and relations",
      "author" : [ "Qi Li", "Heng Ji." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 402–412, Baltimore, Maryland. Association",
      "citeRegEx" : "Li and Ji.,? 2014",
      "shortCiteRegEx" : "Li and Ji.",
      "year" : 2014
    }, {
      "title" : "Network in network",
      "author" : [ "Min Lin", "Qiang Chen", "Shuicheng Yan." ],
      "venue" : "2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings.",
      "citeRegEx" : "Lin et al\\.,? 2014",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2014
    }, {
      "title" : "Roberta: A robustly optimized BERT pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "CoRR, abs/1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Fixing weight decay regularization in Adam",
      "author" : [ "Ilya Loshchilov", "Frank Hutter." ],
      "venue" : "CoRR, abs/1711.05101.",
      "citeRegEx" : "Loshchilov and Hutter.,? 2017",
      "shortCiteRegEx" : "Loshchilov and Hutter.",
      "year" : 2017
    }, {
      "title" : "Modeling joint entity and relation extraction with table representation",
      "author" : [ "Makoto Miwa", "Yutaka Sasaki." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1858–1869, Doha, Qatar. Association for",
      "citeRegEx" : "Miwa and Sasaki.,? 2014",
      "shortCiteRegEx" : "Miwa and Sasaki.",
      "year" : 2014
    }, {
      "title" : "Pruning convolutional neural networks for resource efficient inference",
      "author" : [ "P Molchanov", "S Tyree", "T Karras", "T Aila", "J Kautz." ],
      "venue" : "5th International Conference on Learning Representations, ICLR 2017Conference Track Proceedings.",
      "citeRegEx" : "Molchanov et al\\.,? 2017",
      "shortCiteRegEx" : "Molchanov et al\\.",
      "year" : 2017
    }, {
      "title" : "Effective modeling of encoder-decoder architecture for joint entity and relation extraction",
      "author" : [ "Tapas Nayak", "Hwee Tou Ng." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, pages 8528– 8535.",
      "citeRegEx" : "Nayak and Ng.,? 2020",
      "shortCiteRegEx" : "Nayak and Ng.",
      "year" : 2020
    }, {
      "title" : "Bidirectional LSTM-CRF for named entity recognition",
      "author" : [ "Rrubaa Panchendrarajan", "Aravindh Amaresan." ],
      "venue" : "Proceedings of the 32nd Pacific Asia Conference on Language, Information and Computation, Hong Kong. Association for Computational",
      "citeRegEx" : "Panchendrarajan and Amaresan.,? 2018",
      "shortCiteRegEx" : "Panchendrarajan and Amaresan.",
      "year" : 2018
    }, {
      "title" : "Relation extraction : A survey",
      "author" : [ "Sachin Pawar", "Girish K. Palshikar", "Pushpak Bhattacharyya." ],
      "venue" : "CoRR, abs/1712.05191.",
      "citeRegEx" : "Pawar et al\\.,? 2017",
      "shortCiteRegEx" : "Pawar et al\\.",
      "year" : 2017
    }, {
      "title" : "GloVe: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher Manning." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, Doha,",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Design challenges and misconceptions in named entity recognition",
      "author" : [ "Lev Ratinov", "Dan Roth." ],
      "venue" : "Proceedings of the Thirteenth Conference on Computational Natural Language Learning, pages 147– 155, Boulder, Colorado. Association for Computa-",
      "citeRegEx" : "Ratinov and Roth.,? 2009",
      "shortCiteRegEx" : "Ratinov and Roth.",
      "year" : 2009
    }, {
      "title" : "Cotype: Joint extraction of typed entities and relations with knowledge bases",
      "author" : [ "Xiang Ren", "Zeqiu Wu", "Wenqi He", "Meng Qu", "Clare R Voss", "Heng Ji", "Tarek F Abdelzaher", "Jiawei Han." ],
      "venue" : "Proceedings of the 26th International Conference on World Wide",
      "citeRegEx" : "Ren et al\\.,? 2017",
      "shortCiteRegEx" : "Ren et al\\.",
      "year" : 2017
    }, {
      "title" : "Modeling relations and their mentions without labeled text",
      "author" : [ "S. Riedel", "Limin Yao", "A. McCallum." ],
      "venue" : "Proceedings of Joint European Conference on Machine Learning and Knowledge Discovery in Databases.",
      "citeRegEx" : "Riedel et al\\.,? 2010",
      "shortCiteRegEx" : "Riedel et al\\.",
      "year" : 2010
    }, {
      "title" : "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
      "author" : [ "Erik F. Tjong Kim Sang", "Fien De Meulder." ],
      "venue" : "Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, pages",
      "citeRegEx" : "Sang and Meulder.,? 2003",
      "shortCiteRegEx" : "Sang and Meulder.",
      "year" : 2003
    }, {
      "title" : "Representing text chunks",
      "author" : [ "Erik F. Tjong Kim Sang", "Jorn Veenstra." ],
      "venue" : "Conference of the European Chapter of the Association for Computational Linguistics, pages 173–179, Bergen, Norway. Association for Computational Linguistics.",
      "citeRegEx" : "Sang and Veenstra.,? 1999",
      "shortCiteRegEx" : "Sang and Veenstra.",
      "year" : 1999
    }, {
      "title" : "TPLinker: Single-stage joint extraction of entities and relations through token pair linking",
      "author" : [ "Yucheng Wang", "Bowen Yu", "Yueyang Zhang", "Tingwen Liu", "Hongsong Zhu", "Limin Sun." ],
      "venue" : "Proceedings of the 28th International Conference on Com-",
      "citeRegEx" : "Wang et al\\.,? 2020a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Finding influential instances for distantly supervised relation extraction",
      "author" : [ "Zifeng Wang", "Rui Wen", "Xi Chen", "Shao-Lun Huang", "Ningyu Zhang", "Yefeng Zheng." ],
      "venue" : "CoRR, abs/2009.09841.",
      "citeRegEx" : "Wang et al\\.,? 2020b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "A novel cascade binary tagging framework for relational triple extraction",
      "author" : [ "Zhepei Wei", "Jianlin Su", "Yue Wang", "Yuan Tian", "Yi Chang." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1476–",
      "citeRegEx" : "Wei et al\\.,? 2020",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2020
    }, {
      "title" : "Joint extraction of entities and relations based on a novel decomposition strategy",
      "author" : [ "Bowen Yu", "Zhenyu Zhang", "Jianlin Su", "Yubin Wang", "Tingwen Liu", "Bin Wang", "Sujian Li." ],
      "venue" : "24th European Conference on Artificial Intelligence - ECAI 2020.",
      "citeRegEx" : "Yu et al\\.,? 2019",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2019
    }, {
      "title" : "Jointly identifying entities and extracting relations in encyclopedia text via a graphical model approach",
      "author" : [ "Xiaofeng Yu", "Wai Lam." ],
      "venue" : "The 28th International Conference on Computational Linguistics, pages 1399–1407, Beijing, China.",
      "citeRegEx" : "Yu and Lam.,? 2010",
      "shortCiteRegEx" : "Yu and Lam.",
      "year" : 2010
    }, {
      "title" : "A relation-specific attention network for joint entity and relation extraction",
      "author" : [ "Yue Yuan", "Xiaofei Zhou", "Shirui Pan", "Qiannan Zhu", "Zeliang Song", "Li Guo." ],
      "venue" : "International Joint Conference on Artificial Intelligence, pages 4054–4060. Association for the",
      "citeRegEx" : "Yuan et al\\.,? 2020",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2020
    }, {
      "title" : "Kernel methods for relation extraction",
      "author" : [ "Dmitry Zelenko", "Chinatsu Aone", "Anthony Richardella." ],
      "venue" : "Proceedings of the Conference on Empirical Methods in Natural Language Processing Volume 10, page 71–78, USA. Association for Com-",
      "citeRegEx" : "Zelenko et al\\.,? 2002",
      "shortCiteRegEx" : "Zelenko et al\\.",
      "year" : 2002
    }, {
      "title" : "Learning the extraction order of multiple relational facts in a sentence with reinforcement learning",
      "author" : [ "Xiangrong Zeng", "Shizhu He", "Daojian Zeng", "Kang Liu", "Shengping Liu", "Jun Zhao." ],
      "venue" : "Proceedings of the Conference on Empirical Methods in Natural",
      "citeRegEx" : "Zeng et al\\.,? 2019",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2019
    }, {
      "title" : "Extracting relational facts",
      "author" : [ "Xiangrong Zeng", "Daojian Zeng", "Shizhu He", "Kang Liu", "Jun Zhao" ],
      "venue" : null,
      "citeRegEx" : "Zeng et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2018
    }, {
      "title" : "Joint extraction of entities and relations based on a novel tagging scheme",
      "author" : [ "Suncong Zheng", "Feng Wang", "Hongyun Bao", "Yuexing Hao", "Peng Zhou", "Bo Xu." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Zheng et al\\.,? 2017",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "Some previous works proposed to address the task with pipelined approaches which include two steps: named entity recognition (Tjong Kim Sang and De Meulder, 2003; Ratinov and Roth, 2009) and relation prediction (Zelenko et al.",
      "startOffset" : 125,
      "endOffset" : 186
    }, {
      "referenceID" : 24,
      "context" : "Recent end-to-end methods, which are based on either multi-task learning (Wei et al., 2020) or singlestage framework (Wang et al.",
      "startOffset" : 73,
      "endOffset" : 91
    }, {
      "referenceID" : 22,
      "context" : ", 2020) or singlestage framework (Wang et al., 2020a), achieved promising performance and proved their effectiveness, but lacked in-depth study of the task.",
      "startOffset" : 33,
      "endOffset" : 53
    }, {
      "referenceID" : 24,
      "context" : "For the multi-task method named CasRel (Wei et al., 2020), the relational triple extraction is performed in two stages which applies object extraction to all relations.",
      "startOffset" : 39,
      "endOffset" : 57
    }, {
      "referenceID" : 22,
      "context" : "6226 framework named TPLinker (Wang et al., 2020a), in order to avoid the exposure bias in subject-object alignment, it exploits a rather complicated decoder which leads to sparse label and low convergence rate while the problems of relation redundancy and poor generalization of span-based extraction are still unsolved.",
      "startOffset" : 30,
      "endOffset" : 50
    }, {
      "referenceID" : 5,
      "context" : "For example, the WebNLG dataset (Gardent et al., 2017) has hundreds of relations but only seven valid relations for one sentence mostly.",
      "startOffset" : 32,
      "endOffset" : 54
    }, {
      "referenceID" : 28,
      "context" : "Early works (Zelenko et al., 2002; Chan and Roth, 2011) apply the pipelined methods to perform relation classification between entity pairs after extracting all the entities.",
      "startOffset" : 12,
      "endOffset" : 55
    }, {
      "referenceID" : 2,
      "context" : "Early works (Zelenko et al., 2002; Chan and Roth, 2011) apply the pipelined methods to perform relation classification between entity pairs after extracting all the entities.",
      "startOffset" : 12,
      "endOffset" : 55
    }, {
      "referenceID" : 26,
      "context" : "Prior featurebased joint models (Yu and Lam, 2010; Li and Ji, 2014; Miwa and Sasaki, 2014; Ren et al., 2017) require a complicated process of feature engineering and rely on various NLP tools with cumbersome manual operations.",
      "startOffset" : 32,
      "endOffset" : 108
    }, {
      "referenceID" : 7,
      "context" : "Prior featurebased joint models (Yu and Lam, 2010; Li and Ji, 2014; Miwa and Sasaki, 2014; Ren et al., 2017) require a complicated process of feature engineering and rely on various NLP tools with cumbersome manual operations.",
      "startOffset" : 32,
      "endOffset" : 108
    }, {
      "referenceID" : 11,
      "context" : "Prior featurebased joint models (Yu and Lam, 2010; Li and Ji, 2014; Miwa and Sasaki, 2014; Ren et al., 2017) require a complicated process of feature engineering and rely on various NLP tools with cumbersome manual operations.",
      "startOffset" : 32,
      "endOffset" : 108
    }, {
      "referenceID" : 18,
      "context" : "Prior featurebased joint models (Yu and Lam, 2010; Li and Ji, 2014; Miwa and Sasaki, 2014; Ren et al., 2017) require a complicated process of feature engineering and rely on various NLP tools with cumbersome manual operations.",
      "startOffset" : 32,
      "endOffset" : 108
    }, {
      "referenceID" : 22,
      "context" : "The state-of-the-art method named TPLinker (Wang et al., 2020a) employs a token pair linking scheme which performs twoO(n2) matrix operations for extracting entities and aligning subjects with objects under each relation of a sentence, causing extreme redundancy on relation judgement and complexity on subject-object alignment, respectively.",
      "startOffset" : 43,
      "endOffset" : 63
    }, {
      "referenceID" : 17,
      "context" : ", Begin, Inside and Outside) tag scheme (Tjong Kim Sang and Veenstra, 1999; Ratinov and Roth, 2009).",
      "startOffset" : 40,
      "endOffset" : 99
    }, {
      "referenceID" : 3,
      "context" : "We use a pre-trained BERT model4 (Devlin et al., 2019) to encode the input sentence for a fair comparison, but theoretically it can be extended to other encoders, such as Glove (Pennington et al.",
      "startOffset" : 33,
      "endOffset" : 54
    }, {
      "referenceID" : 16,
      "context" : ", 2019) to encode the input sentence for a fair comparison, but theoretically it can be extended to other encoders, such as Glove (Pennington et al., 2014) and RoBERTa (Liu et al.",
      "startOffset" : 130,
      "endOffset" : 155
    }, {
      "referenceID" : 24,
      "context" : "Different from previous works (Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a) which redundantly perform entity extraction to every relation, given a sentence, we first predict a subset of potential relations that possibly exist in the sentence, and then the entity extraction only needs to be applied to these potential relations.",
      "startOffset" : 30,
      "endOffset" : 87
    }, {
      "referenceID" : 27,
      "context" : "Different from previous works (Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a) which redundantly perform entity extraction to every relation, given a sentence, we first predict a subset of potential relations that possibly exist in the sentence, and then the entity extraction only needs to be applied to these potential relations.",
      "startOffset" : 30,
      "endOffset" : 87
    }, {
      "referenceID" : 22,
      "context" : "Different from previous works (Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a) which redundantly perform entity extraction to every relation, given a sentence, we first predict a subset of potential relations that possibly exist in the sentence, and then the entity extraction only needs to be applied to these potential relations.",
      "startOffset" : 30,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "where Avgpool is the average pooling operation (Lin et al., 2014), Wr ∈ Rd×1 is a trainable weight and σ denotes the sigmoid function.",
      "startOffset" : 47,
      "endOffset" : 65
    }, {
      "referenceID" : 3,
      "context" : "Please refer to the original paper (Devlin et al., 2019) for detailed descriptions.",
      "startOffset" : 35,
      "endOffset" : 56
    }, {
      "referenceID" : 14,
      "context" : "5 For the sake of simplicity and fairness, we abandon the traditional LSTM-CRF (Panchendrarajan and Amaresan, 2018) network but adopt the simple fully connected neural network.",
      "startOffset" : 79,
      "endOffset" : 115
    }, {
      "referenceID" : 19,
      "context" : "For example, the SOO pattern is rare in the NYT (Riedel et al., 2010) dataset.",
      "startOffset" : 48,
      "endOffset" : 69
    }, {
      "referenceID" : 19,
      "context" : "(2020a) to evaluate our model on two public datasets NYT (Riedel et al., 2010) and WebNLG (Gardent et al.",
      "startOffset" : 57,
      "endOffset" : 78
    }, {
      "referenceID" : 5,
      "context" : ", 2010) and WebNLG (Gardent et al., 2017), both of which have two versions, respectively.",
      "startOffset" : 19,
      "endOffset" : 41
    }, {
      "referenceID" : 24,
      "context" : "We compare PRGC with eight strong baseline models and the state-of-the-art models CasRel (Wei et al., 2020) and TPLinker (Wang et al.",
      "startOffset" : 89,
      "endOffset" : 107
    }, {
      "referenceID" : 27,
      "context" : "4 - - - - - - - - RSAN‡ (Yuan et al., 2020) - - - - - - 85.",
      "startOffset" : 24,
      "endOffset" : 43
    }, {
      "referenceID" : 22,
      "context" : "Our PRGC method outperforms them in respect of almost all evaluation metrics even if compared with the recent strongest baseline (Wang et al., 2020a) which is quite complicated.",
      "startOffset" : 129,
      "endOffset" : 149
    }, {
      "referenceID" : 24,
      "context" : "Following previous works (Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a), to verify the capability of our model in handling different overlapping patterns and sentences with different numbers of triples, we conduct further experiments on NYT* and WebNLG* datasets.",
      "startOffset" : 25,
      "endOffset" : 82
    }, {
      "referenceID" : 27,
      "context" : "Following previous works (Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a), to verify the capability of our model in handling different overlapping patterns and sentences with different numbers of triples, we conduct further experiments on NYT* and WebNLG* datasets.",
      "startOffset" : 25,
      "endOffset" : 82
    }, {
      "referenceID" : 22,
      "context" : "Following previous works (Wei et al., 2020; Yuan et al., 2020; Wang et al., 2020a), to verify the capability of our model in handling different overlapping patterns and sentences with different numbers of triples, we conduct further experiments on NYT* and WebNLG* datasets.",
      "startOffset" : 25,
      "endOffset" : 82
    }, {
      "referenceID" : 12,
      "context" : "As shown in Table 6, we evaluate the model efficiency with respect to Complexity, floating point operations (FLOPs) (Molchanov et al., 2017), parameters of the decoder (Paramsdecoder) and Inference Time6 of CasRel, TPLinker and PRGC in two datasets which have quite different characteristics in the size of relation set, the average number of relations per sentence and the average number of subjects per sentence.",
      "startOffset" : 116,
      "endOffset" : 140
    }, {
      "referenceID" : 22,
      "context" : "Because the number of subjects in a sentence varies, it is difficult for CasRel to predict objects in a heterogeneous batch, and it is restricted to set batch size to 1 in the official implementation (Wang et al., 2020a).",
      "startOffset" : 200,
      "endOffset" : 220
    } ],
    "year" : 2021,
    "abstractText" : "Joint extraction of entities and relations from unstructured texts is a crucial task in information extraction. Recent methods achieve considerable performance but still suffer from some inherent limitations, such as redundancy of relation prediction, poor generalization of span-based extraction and inefficiency. In this paper, we decompose this task into three subtasks, Relation Judgement, Entity Extraction and Subject-object Alignment from a novel perspective and then propose a joint relational triple extraction framework based on Potential Relation and Global Correspondence (PRGC). Specifically, we design a component to predict potential relations, which constrains the following entity extraction to the predicted relation subset rather than all relations; then a relation-specific sequence tagging component is applied to handle the overlapping problem between subjects and objects; finally, a global correspondence component is designed to align the subject and object into a triple with low-complexity. Extensive experiments show that PRGC achieves state-of-the-art performance on public benchmarks with higher efficiency and delivers consistent performance gain on complex scenarios of overlapping triples.1",
    "creator" : "LaTeX with hyperref"
  }
}