{
  "name" : "2021.acl-long.340.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Intent Classification and Slot Filling for Privacy Policies",
    "authors" : [ "Wasi Uddin Ahmad", "Jianfeng Chi", "Tu Le", "Thomas Norton", "Yuan Tian", "Kai-Wei Chang" ],
    "emails" : [ "kwchang}@cs.ucla.edu", "jc6ub@virginia.edu", "tnl6wk@virginia.edu", "yuant@virginia.edu", "tnorton1@law.fordham.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4402–4417\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4402"
    }, {
      "heading" : "1 Introduction",
      "text" : "Privacy policies inform users about how a service provider collects, uses, and maintains the users’ information. The service providers collect the users’ data via their websites or mobile applications and analyze them for various purposes. The users’ data often contain sensitive information; therefore, the users must know how their information will be used, maintained, and protected from unauthorized and unlawful use. Privacy policies are meant to explain all these use cases in detail. This makes\n∗Equal contribution. Listed by alphabetical order.\nprivacy policies often very long, complicated, and confusing (McDonald and Cranor, 2008; Reidenberg et al., 2016). As a result, users do not tend to read privacy policies (Commission et al., 2012; Gluck et al.; Marotta-Wurgler, 2015), leading to undesirable consequences. For example, users might not be aware of their data being sold to third-party advertisers even if they have given their consent to the service providers to use their services in return. Therefore, automating information extraction from verbose privacy policies can help users understand their rights and make informed decisions.\nIn recent years, we have seen substantial efforts to utilize natural language processing (NLP) techniques to automate privacy policy analysis. In literature, information extraction from policy documents is formulated as text classification (Wilson et al., 2016a; Harkous et al., 2018; Zimmeck et al., 2019), text alignment (Liu et al., 2014; Ramanath et al., 2014), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020). Although these approaches effectively identify the sentences or segments in a policy document relevant to a privacy practice, they lack in extracting fine-grained structured information. As shown in the first example in Table 1, the privacy practice label “Data Collection/Usage” informs the user how, why, and what types of user information will be collected by the service provider. The policy also specifies that users’ “username” and “icon or profile photo” will be used for “marketing purposes”. This informs the user precisely what and why the service provider will use users’ information.\nThe challenge in training models to extract finegrained information is the lack of labeled examples. Annotating privacy policy documents is expensive as they can be thousands of words long and requires domain experts (e.g., law students). Therefore, prior works annotate privacy policies at the\nsentence level, without further utilizing the constituent text spans to convey specific information. Sentences written in a policy document explain privacy practices, which we refer to as intent classification and identifying the constituent text spans that share further specific information as slot filling. Table 1 shows a couple of examples. This formulation of information extraction lifts users’ burden to comprehend relevant segments in a policy document and identify the details, such as how and why users’ data are collected and shared with others.\nTo facilitate fine-grained information extraction, we present PolicyIE, an English corpus consisting of 5,250 intent and 11,788 slot annotations over 31 privacy policies of websites and mobile applications. We perform experiments using sequence tagging and sequence-to-sequence (Seq2Seq) learning models to jointly model intent classification and slot filling. The results show that both modeling approaches perform comparably in intent classification, while Seq2Seq models outperform the sequence tagging models in slot filling by a large margin. We conduct a thorough error analysis and categorize the errors into seven types. We observe that sequence tagging approaches miss more slots while Seq2Seq models predict more spurious slots. We further discuss the error cases by considering other factors to help guide future work. We release the code and data to facilitate research.1"
    }, {
      "heading" : "2 Construction of PolicyIE Corpus",
      "text" : ""
    }, {
      "heading" : "2.1 Privacy Policies Selection",
      "text" : "The scope of privacy policies primarily depends on how service providers function. For example, service providers primarily relying on mobile applications (e.g., Viber, Whatsapp) or websites and applications (e.g., Amazon, Walmart) have different privacy practices detailed in their privacy policies.\n1https://github.com/wasiahmad/ PolicyIE\nIn PolicyIE, we want to achieve broad coverage across privacy practices exercised by the service providers such that the corpus can serve a wide variety of use cases. Therefore, we go through the following steps to select the policy documents.\nInitial Collection Ramanath et al. (2014) introduced a corpus of 1,010 privacy policies of the top websites ranked on Alexa.com. We crawled those websites’ privacy policies in November 2019 since the released privacy policies are outdated. For mobile application privacy policies, we scrape application information from Google Play Store using play-scraper public API2 and crawl their privacy policy. We ended up with 7,500 mobile applications’ privacy policies.\nFiltering First, we filter out the privacy policies written in a non-English language and the mobile applications’ privacy policies with the app review rating of less than 4.5. Then we filter out privacy policies that are too short (< 2,500 words) or too long (> 6,000 words). Finally, we randomly select 200 websites and mobile application privacy policies each (400 documents in total).3\nPost-processing We ask a domain expert (working in the security and privacy domain for more than three years) to examine the selected 400 privacy policies. The goal for the examination is to ensure the policy documents cover the four privacy practices: (1) Data Collection/Usage, (2) Data Sharing/Disclosure, (3) Data Storage/Retention, and (4) Data Security/Protection. These four practices cover how a service provider processes users’ data in general and are included in the General Data Protection Regulation (GDPR). Finally, we shortlist 50 policy documents for annotation, 25 in each category (websites and mobile applications).\n2https://github.com/danieliu/ play-scraper\n3We ensure the mobile applications span different application categories on the Play Store."
    }, {
      "heading" : "2.2 Data Annotation",
      "text" : "Annotation Schema To annotate sentences in a policy document, we consider the first four privacy practices from the annotation schema suggested by Wilson et al. (2016a). Therefore, we perform sentence categorization under five intent classes that are described below. (1) Data Collection/Usage: What, why and how\nuser information is collected; (2) Data Sharing/Disclosure: What, why and how\nuser information is shared with or collected by third parties; (3) Data Storage/Retention: How long and where user information will be stored; (4) Data Security/Protection: Protection measures for user information; (5) Other: Other privacy practices that do not fall into the above four categories.\nApart from annotating sentences with privacy practices, we aim to identify the text spans in sentences that explain specific details about the practices. For example, in the sentence “we collect personal information in order to provide users with a personalized experience”, the underlined text span conveys the purpose of data collection. In our annotation schema, we refer to the identification of such text spans as slot filling. There are 18 slot labels in our annotation schema (provided in Appendix). We group the slots into two categories: type-I and typeII based on their role in privacy practices. While the type-I slots include participants of privacy practices, such as Data Provider, Data Receiver, type-II slots include purposes, conditions that characterize more details of privacy practices. Note that type-I and type-II slots may overlap, e.g., in the previous example, the underlined text span is the purpose of data collection, and the span “user” is the Data Provider (whose data is collected). In general, typeII slots are longer (consisting of more words) and less frequent than type-I slots.\nIn total, there are 14 type-I and 4 type-II slots in our annotation schema. These slots are associated with a list of attributes, e.g., Data Collected and Data Shared have the attributes Contact Data, Location Data, Demographic Data, etc. Table 1 illustrates a couple of examples. We detail the slots and their attributes in the Appendix.\nAnnotation Procedure General crowdworkers such as Amazon Mechanical Turkers are not suitable to annotate policy documents as it requires specialized domain knowledge (McDonald and Cra-\nnor, 2008; Reidenberg et al., 2016). We hire two law students to perform the annotation. We use the web-based annotation tool, BRAT (Stenetorp et al., 2012) to conduct the annotation. We write a detailed annotation guideline and pretest them through multiple rounds of pilot studies. The guideline is further updated with notes to resolve complex or corner cases during the annotation process.4 The annotation process is closely monitored by a domain expert and a legal scholar and is granted IRB exempt by the Institutional Review Board (IRB). The annotators are presented with one segment from a policy document at a time and asked to perform annotation following the guideline. We manually segment the policy documents such that a segment discusses similar issues to reduce ambiguity at the annotator end. The annotators worked 10 weeks, with an average of 10 hours per week, and completed annotations for 31 policy documents. Each annotator is paid $15 per hour.\nPost-editing and Quality Control We compute an inter-annotator agreement for each annotated segment of policy documents using Krippendorff’s Alpha (αK) (Klaus, 1980). The annotators are asked to discuss their annotations and re-annotate those sections with token-level αK falling below 0.75. An αK value within the range of 0.67 to 0.8 is allowed for tentative conclusions (Artstein and Poesio, 2008; Reidsma and Carletta, 2008). After the re-annotation process, we calculate the agreement for the two categories of slots individually. The inter-annotator agreement is 0.87 and 0.84 for type-I and type-II slots, respectively. Then the adjudicators discuss and finalize the annotations. The adjudication process involves one of the annotators, the legal scholar, and the domain expert.\n4We release the guideline as supplementary material.\nData Statistics & Format Table 2 presents the statistics of the PolicyIE corpus. The corpus consists of 15 and 16 privacy policies of websites and mobile applications, respectively. We release the annotated policy documents split into sentences.5 Each sentence is associated with an intent label, and the constituent words are associated with a slot label (following the BIO tagging scheme)."
    }, {
      "heading" : "3 Model & Setup",
      "text" : "PolicyIE provides annotations of privacy practices and corresponding text spans in privacy policies. We refer to privacy practice prediction for a sentence as intent classification and identifying the text spans as slot filling. We present two alternative approaches; the first approach jointly models intent classification and slot tagging (Chen et al., 2019), and the second modeling approach casts the problem as a sequence-to-sequence learning task (Rongali et al., 2020; Li et al., 2021)."
    }, {
      "heading" : "3.1 Sequence Tagging",
      "text" : "Following Chen et al. (2019), given a sentence s = w1, . . . , wl from a privacy policy document D, a special token (w0 = [CLS]) is prepended to form the input sequence that is fed to an encoder. The encoder produces contextual representations of the input tokens h0, h1, . . . , hl where h0 and h1, . . . , hl are fed to separate softmax classifiers\n5We split the policy documents into sentences using UDPipe (Straka et al., 2016).\nto predict the target intent and slot labels.\ny i = softmax(W Ti h0 + bi), y s n = softmax(W Ts hn + bs), n ∈ 1, . . . l,\nwhere Wi ∈ R d×I ,Ws ∈ R d×S , br ∈ R I and bi ∈ R I , bs ∈ R\nS are parameters, and I, S are the total number of intent and slot types, respectively. The sequence tagging model (composed of an encoder and a classifier) learns to maximize the following conditional probability to perform intent classification and slot filling jointly.\nP (yi, ys∣s) = p(yi∣s) l\n∏ n=1 p(ysn∣s).\nWe train the models end-to-end by minimizing the cross-entropy loss. Table 3 shows an example of input and output to train the joint intent and slot tagging models. Since type-I and type-II slots have different characteristics as discussed in § 2.2 and overlap, we train two separate sequential tagging models for type-I and type-II slots to keep the baseline models simple.6 We use BiLSTM (Liu and Lane, 2016; Zhang and Wang, 2016), Transformer (Vaswani et al., 2017), BERT (Vaswani et al., 2017), and RoBERTa (Liu et al., 2019) as encoder to form the sequence tagging models.\nBesides, we consider an embedding based baseline where the input word embeddings are fed to the softmax classifiers. The special token (w0 =\n6Span enumeration based techniques (Wadden et al., 2019; Luan et al., 2019) can be utilized to perform tagging both types of slots jointly, and we leave this as future work.\n[CLS]) embedding is formed by applying average pooling over the input word embeddings. We train WordPiece embeddings with a 30,000 token vocabulary (Devlin et al., 2019) using fastText (Bojanowski et al., 2017) based on a corpus of 130,000 privacy policies collected from apps on the Google Play Store (Harkous et al., 2018). We use the hidden state corresponding to the first WordPiece of a token to predict the target slot labels.\nConditional Random Field (CRF) helps structure prediction tasks, such as semantic role labeling (Zhou and Xu, 2015) and named entity recognition (Cotterell and Duh, 2017). Therefore, we model slot labeling jointly using a conditional random field (CRF) (Lafferty et al., 2001) (only interactions between two successive labels are considered). We refer the readers to Ma and Hovy (2016) for details."
    }, {
      "heading" : "3.2 Sequence-to-Sequence Learning",
      "text" : "Recent works in semantic parsing (Rongali et al., 2020; Zhu et al., 2020; Li et al., 2021) formulate the task as sequence-to-sequence (Seq2Seq) learning. Taking this as a motivation, we investigate the scope of Seq2Seq learning for joint intent classification and slot filling for privacy policy sentences. In Table 3, we show an example of encoder input and decoder output used in Seq2Seq learning. We form the target sequences by following the template: [IN:LABEL [SL:LABEL w1, . . . , wm] . . . ]. During inference, we use greedy decoding and parse the decoded sequence to extract intent and slot labels. Note that we only consider text spans in the decoded sequences that are surrounded by “[]”; the rest are discarded. Since our proposed PolicyIE\ncorpus consists of a few thousand examples, instead of training Seq2Seq models from scratch, we finetune pre-trained models as the baselines. Specifically, we consider five state-of-the-art models: MiniLM (Wang et al., 2020), UniLM (Dong et al., 2019), UniLMv2 (Bao et al., 2020), MASS (Song et al.), and BART (Lewis et al., 2020)."
    }, {
      "heading" : "3.3 Setup",
      "text" : "Implementation We use the implementation of BERT and RoBERTa from transformers API (Wolf et al., 2020). For the Seq2Seq learning baselines, we use their public implementations.7,8,9 We train BiLSTM, Transformer baseline models and fine-tune all the other baselines for 20 epochs and choose the best checkpoint based on validation performance. From 4,209 training examples, we use 4,000 examples for training (∼95%) and 209 examples for validation (∼5%). We tune the learning rate in [1e-3, 5e-4, 1e-4, 5e-5, 1e-5] and set the batch size to 16 in all our experiments (to fit in one GeForce GTX 1080 GPU with 11gb memory). We train (or fine-tune) all the models five times with different seeds and report average performances.\nEvaluation Metrics To evaluate the baseline approaches, we compute the F1 score for intent classification and slot filling tasks.10 We also compute an exact match (EM) accuracy (if the predicted intent matches the reference intent and slot F1 = 1.0).\n7https://github.com/microsoft/unilm 8https://github.com/microsoft/MASS 9https://github.com/pytorch/fairseq/\ntree/master/examples/bart 10We use a micro average for intent classification.\nHuman Performance is computed by considering each annotator’s annotations as predictions and the adjudicated annotations as the reference. The final score is an average across all annotators."
    }, {
      "heading" : "4 Experiment Results & Analysis",
      "text" : "We aim to address the following questions. 1. How do the two modeling approaches perform\non our proposed dataset (§ 4.1)? 2. How do they perform on different intent and\nslot types (§ 4.2)? 3. What type of errors do the best performing\nmodels make (§ 4.3)?"
    }, {
      "heading" : "4.1 Main Results",
      "text" : "Sequence Tagging The overall performances of the sequence tagging models are presented in Table 4. The pre-trained models, BERT and RoBERTa, outperform other baselines by a large margin. Using conditional random field (CRF), the models boost the slot tagging performance with a slight degradation in intent classification performance. For example, RoBERTa + CRF model improves over RoBERTa by 2.8% and 3.9% in terms of typeI slot F1 and EM with a 0.5% drop in intent F1 score. The results indicate that predicting type-II slots is difficult compared to type-I slots as they differ in length (type-I slots are mostly phrases, while type-II slots are clauses) and are less frequent in the training examples. However, the EM accuracy for type-I slots is lower than type-II slots due to more type-I slots (∼4.75) than type-II slots (∼1.38) on average per sentence. Note that if models fail to predict one of the slots, EM will be zero.\nSeq2Seq Learning Seq2Seq models predict the intent and slots by generating the labels and spans following a template. Then we extract the intent and slot labels from the generated sequences. The experiment results are presented in Table 5. To our\nsurprise, we observe that all the models perform well in predicting intent and slot labels. The best performing model is BART (according to slot F1 score) with 400 million parameters, outperforming its smaller variant by 10.1% and 2.8% in terms of slot F1 for type-I and type-II slots, respectively.\nSequence Tagging vs. Seq2Seq Learning It is evident from the experiment results that Seq2Seq models outperform the sequence tagging models in slot filling by a large margin, while in intent classification, they are competitive. However, both the modeling approaches perform poorly in predicting all the slots in a sentence correctly, resulting in a lower EM score. One interesting factor is, the Seq2Seq models significantly outperform sequence tagging models in predicting type-II slots. Note that type-II slots are longer and less frequent, and we suspect conditional text generation helps Seq2Seq models predict them accurately. In comparison, we suspect that due to fewer labeled examples of type-II slots, the sequence tagging models perform poorly on that category (as noted before, we train the sequence tagging models for the type-I and type-II slots individually).\nNext, we break down RoBERTa (w/ CRF) and BART’s performances, the best performing models in their respective model categories, followed by an error analysis to shed light on the error types."
    }, {
      "heading" : "4.2 Performance Breakdown",
      "text" : "Intent Classification In the PolicyIE corpus, 38% of the sentences fall into the first four categories: Data Collection, Data Sharing, Data Storage, Data Security, and the remaining belong to the Other category. Therefore, we investigate how much the models are confused in predicting the accurate intent label. We provide the confusion matrix of the models in Appendix. Due to an imbalanced distribution of labels, BART makes many\nincorrect predictions. We notice that BART is confused most between Data Collection and Data Storage labels. Our manual analysis reveals that BART is confused between slot labels {“Data Collector”, “Data Holder”} and {“Data Retained”, “Data Collected”} as they are often associated with the same text span. We suspect this leads to BART’s confusion. Table 6 presents the performance breakdown across intent labels.\nSlot Filling We breakdown the models’ performances in slot filling under two settings. First, Table 6 shows slot filling performance under different intent categories. Among the four classes, the models perform worst on slots associated with the “Data Security” intent class as PolicyIE has the lowest amount of annotations for that intent category. Second, we demonstrate the models’ performances on different slot types in Figure 1. RoBERTa’s recall score for “polarity”, “protectagainst”, “protection-method” and “storage-place” slot types is zero. This is because these slot types have the lowest amount of training examples in PolicyIE. On the other hand, BART achieves a higher recall score, specially for the “polarity” label as their corresponding spans are short.\nWe also study the models’ performances on slots of different lengths. The results show that BART outperforms RoBERTa by a larger margin on longer slots (see Figure 2), corroborating our hypothesis that conditional text generation results in more accurate predictions for longer spans."
    }, {
      "heading" : "4.3 Error Analysis",
      "text" : "We analyze the incorrect intent and slot predictions by RoBERTa and BART. We categorize the errors\ninto seven types. Note that a predicted slot is considered correct if its’ label and span both match (exact match) one of the references. We characterize the error types as follows.\n1. Wrong Intent (WI): The predicted intent label does not match the reference intent label. 2. Missing Slot (MS): None of the predicted slots exactly match a reference slot. 3. Spurious Slot (SS): Label of a predicted slot does not match any of the references. 4. Wrong Split (WSp): Two or more predicted slot spans with the same label could be merged to match one of the reference slots. A merged span and a reference span may only differ in punctuations or stopwords (e.g., and). 5. Wrong Boundary (WB): A predicted slot span is a sub-string of the reference span or vice versa. The slot label must exactly match.\n6. Wrong Label (WL): A predicted slot span matches a reference, but the label does not. 7. Wrong Slot (WS): All other types of errors fall into this category.\nWe provide one example of each error type in Table 7. In Table 8, we present the counts for each error type made by RoBERTa and BART models. The two most frequent error types are SS and MS. While BART makes more SS errors, RoBERTa suffers from MS errors. While both the models are similar in terms of total errors, BART makes more correct predictions resulting in a higher Recall score, as discussed before. One possible way to reduce SS errors is by penalizing more on wrong slot label prediction than slot span. On the other hand, reducing MS errors is more challenging as many missing slots have fewer annotations than\nothers. We provide more qualitative examples in Appendix (see Table 11 and 12) .\nIn the error analysis, we exclude the test examples (sentences) with the intent label “Other” and no slots. Out of 1,041 test instances in PolicyIE, there are 682 instances with the intent label “Other”. We analyze RoBERTa and BART’s predictions on those examples separately to check if the models predict slots as we consider them as spurious slots. While RoBERTa meets our expectation of performing highly accurate (correct prediction for 621 out of 682), BART also correctly predicts 594 out of 682 by precisely generating “[IN:Other]”. Overall the error analysis aligns with our anticipation that the Seq2Seq modeling technique has promise and should be further explored in future works."
    }, {
      "heading" : "5 Related Work",
      "text" : "Automated Privacy Policy Analysis Automating privacy policy analysis has drawn researchers’ attention as it enables the users to know their rights and act accordingly. Therefore, significant research efforts have been devoted to understanding privacy policies. Earlier approaches (Costante et al., 2012) designed rule-based pattern matching techniques to extract specific types of information. Under the Usable Privacy Project (Sadeh et al., 2013), several works have been done (Bhatia and Breaux, 2015; Wilson et al., 2016a,b; Sathyendra et al., 2016; Bhatia et al., 2016; Hosseini et al., 2016; Mysore Sathyendra et al., 2017; Zimmeck et al., 2019; Bannihatti Kumar et al., 2020). No-\ntable works leveraging NLP techniques include text alignment (Liu et al., 2014; Ramanath et al., 2014), text classification (Wilson et al., 2016a; Harkous et al., 2018; Zimmeck et al., 2019), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020). Bokaie Hosseini et al. (2020) is the most closest to our work that used named entity recognition (NER) modeling technique to extract third party entities mentioned in policy documents.\nOur proposed PolicyIE corpus is distinct from the previous privacy policies benchmarks: OPP115 (Wilson et al., 2016a) uses a hierarchical annotation scheme to annotate text segments with a set of data practices and it has been used for multilabel classification (Wilson et al., 2016a; Harkous et al., 2018) and question answering (Harkous et al., 2018; Ahmad et al., 2020); PrivacyQA (Ravichander et al., 2019) frame the QA task as identifying a list of relevant sentences from policy documents. Recently, Bui et al. (2021) created a dataset by tagging documents from OPP-115 for privacy practices and uses NER models to extract them. In contrast, PolicyIE is developed by following semantic parsing benchmarks, and we model the task following the NLP literature.\nIntent Classification and Slot Filling Voice assistants and chat-bots frame the task of natural language understanding via classifying intents and filling slots given user utterances. Several benchmarks have been proposed in literature covering several domains, and languages (Hemphill et al., 1990; Coucke et al., 2018; Gupta et al., 2018; Upadhyay et al., 2018; Schuster et al., 2019; Xu et al., 2020; Li et al., 2021). Our proposed PolicyIE corpus is a new addition to the literature within the security and privacy domain. PolicyIE enables us to build conversational solutions that users can interact with and learn about privacy policies."
    }, {
      "heading" : "6 Conclusion",
      "text" : "This work aims to stimulate research on automating information extraction from privacy policies and reconcile it with users’ understanding of their rights. We present PolicyIE, an intent classification and slot filling benchmark on privacy policies with two alternative neural approaches as baselines. We perform a thorough error analysis to shed light on the limitations of the two baseline approaches. We hope this contribution would call for research efforts in the specialized privacy domain from both\nprivacy and NLP communities."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The authors acknowledge the law students Michael Rasmussen and Martyna Glaz at Fordham University who worked as annotators to make the development of this corpus possible. This work was supported in part by National Science Foundation Grant OAC 1920462. Any opinions, findings, conclusions, or recommendations expressed herein are those of the authors, and do not necessarily reflect those of the US Government or NSF.\nBroader Impact\nPrivacy and data breaches have a significant impact on individuals. In general, security breaches expose the users to different risks such as financial loss (due to losing employment or business opportunities), physical risks to safety, and identity theft. Identity theft is among the most severe and fastest-growing crimes. However, the risks due to data breaches can be minimized if the users know their rights and how they can exercise them to protect their privacy. This requires the users to read the privacy policies of websites they visit or the mobile applications they use. As reading privacy policies is a tedious task, automating privacy policy analysis reduces the burden of users. Automating information extraction from privacy policies empowers users to be aware of their data collected and analyzed by service providers for different purposes. Service providers collect consumer data at a massive scale and often fail to protect them, resulting in data breaches that have led to increased attention towards data privacy and related risks. Reading privacy policies to understand users’ rights can help take informed and timely decisions on safeguarding data privacy to mitigate the risks. Developing an automated solution to facilitate policy document analysis requires labeled examples, and the PolicyIE corpus adds a new dimension to the available datasets in the security and privacy domain. While PolicyIE enables us to train models to extract fine-grained information from privacy policies, the corpus can be coupled with other existing benchmarks to build a comprehensive system. For example, PrivacyQA corpus (Ravichander et al., 2019) combined with PolicyIE can facilitate building QA systems that can answer questions with fine-grained details. We believe our experiments and analysis will help direct future research."
    } ],
    "references" : [ {
      "title" : "PolicyQA: A reading comprehension dataset for privacy policies",
      "author" : [ "Wasi Ahmad", "Jianfeng Chi", "Yuan Tian", "Kai-Wei Chang." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 743–749, Online. Association for Com-",
      "citeRegEx" : "Ahmad et al\\.,? 2020",
      "shortCiteRegEx" : "Ahmad et al\\.",
      "year" : 2020
    }, {
      "title" : "Survey article: Inter-coder agreement for computational linguistics",
      "author" : [ "Ron Artstein", "Massimo Poesio." ],
      "venue" : "Computational Linguistics, 34(4):555– 596.",
      "citeRegEx" : "Artstein and Poesio.,? 2008",
      "shortCiteRegEx" : "Artstein and Poesio.",
      "year" : 2008
    }, {
      "title" : "Finding a choice in a haystack: Automatic extraction of opt",
      "author" : [ "Vinayshekhar Bannihatti Kumar", "Roger Iyengar", "Namita Nisal", "Yuanyuan Feng", "Hana Habib", "Peter Story", "Sushain Cherivirala", "Margaret Hagan", "Lorrie Cranor", "Shomir Wilson" ],
      "venue" : null,
      "citeRegEx" : "Kumar et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2020
    }, {
      "title" : "Unilmv2: Pseudomasked language models for unified language model pre-training",
      "author" : [ "Hangbo Bao", "Li Dong", "Furu Wei", "Wenhui Wang", "Nan Yang", "Xiaodong Liu", "Yu Wang", "Jianfeng Gao", "Songhao Piao", "Ming Zhou" ],
      "venue" : null,
      "citeRegEx" : "Bao et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Bao et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards an information type lexicon for privacy policies",
      "author" : [ "Jaspreet Bhatia", "Travis D Breaux." ],
      "venue" : "2015 IEEE eighth international workshop on requirements engineering and law (RELAW), pages 19–24. IEEE.",
      "citeRegEx" : "Bhatia and Breaux.,? 2015",
      "shortCiteRegEx" : "Bhatia and Breaux.",
      "year" : 2015
    }, {
      "title" : "Automated extraction of regulated information types using hyponymy relations",
      "author" : [ "Jaspreet Bhatia", "Morgan C Evans", "Sudarshan Wadkar", "Travis D Breaux." ],
      "venue" : "2016 IEEE 24th International Requirements Engineering Conference Workshops (REW),",
      "citeRegEx" : "Bhatia et al\\.,? 2016",
      "shortCiteRegEx" : "Bhatia et al\\.",
      "year" : 2016
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 5:135–146.",
      "citeRegEx" : "Bojanowski et al\\.,? 2017",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2017
    }, {
      "title" : "Identifying and classifying third-party entities in natural language privacy policies",
      "author" : [ "Mitra Bokaie Hosseini", "Pragyan K C", "Irwin Reyes", "Serge Egelman." ],
      "venue" : "Proceedings of the Second Workshop on Privacy in NLP, pages 18–27, Online. Association for",
      "citeRegEx" : "Hosseini et al\\.,? 2020",
      "shortCiteRegEx" : "Hosseini et al\\.",
      "year" : 2020
    }, {
      "title" : "Automated extraction and presentation of data practices in privacy policies",
      "author" : [ "Duc Bui", "Kang G Shin", "Jong-Min Choi", "Junbum Shin." ],
      "venue" : "Proceedings on Privacy Enhancing Technologies, 2021(2):88–110.",
      "citeRegEx" : "Bui et al\\.,? 2021",
      "shortCiteRegEx" : "Bui et al\\.",
      "year" : 2021
    }, {
      "title" : "Bert for joint intent classification and slot filling",
      "author" : [ "Qian Chen", "Zhu Zhuo", "Wen Wang." ],
      "venue" : "arXiv preprint arXiv:1902.10909.",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Protecting consumer privacy in an era of rapid change",
      "author" : [ "Federal Trade Commission" ],
      "venue" : "FTC report.",
      "citeRegEx" : "Commission,? 2012",
      "shortCiteRegEx" : "Commission",
      "year" : 2012
    }, {
      "title" : "What websites know about you",
      "author" : [ "Elisa Costante", "Jerry den Hartog", "Milan Petković." ],
      "venue" : "Data Privacy Management and Autonomous Spontaneous Security, pages 146–159. Springer.",
      "citeRegEx" : "Costante et al\\.,? 2012",
      "shortCiteRegEx" : "Costante et al\\.",
      "year" : 2012
    }, {
      "title" : "Lowresource named entity recognition with crosslingual, character-level neural conditional random fields",
      "author" : [ "Ryan Cotterell", "Kevin Duh." ],
      "venue" : "Proceedings of the Eighth International Joint Conference on Natural Language Processing",
      "citeRegEx" : "Cotterell and Duh.,? 2017",
      "shortCiteRegEx" : "Cotterell and Duh.",
      "year" : 2017
    }, {
      "title" : "Snips voice platform: an embedded spoken language understanding",
      "author" : [ "Alice Coucke", "Alaa Saade", "Adrien Ball", "Théodore Bluche", "Alexandre Caulier", "David Leroy", "Clément Doumouro", "Thibault Gisselbrecht", "Francesco Caltagirone", "Thibaut Lavril" ],
      "venue" : null,
      "citeRegEx" : "Coucke et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Coucke et al\\.",
      "year" : 2018
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Unified language model pre-training for natural language understanding and generation",
      "author" : [ "Li Dong", "Nan Yang", "Wenhui Wang", "Furu Wei", "Xiaodong Liu", "Yu Wang", "Jianfeng Gao", "Ming Zhou", "Hsiao-Wuen Hon." ],
      "venue" : "Advances in Neural Informa-",
      "citeRegEx" : "Dong et al\\.,? 2019",
      "shortCiteRegEx" : "Dong et al\\.",
      "year" : 2019
    }, {
      "title" : "Semantic parsing for technical support questions",
      "author" : [ "Abhirut Gupta", "Anupama Ray", "Gargi Dasgupta", "Gautam Singh", "Pooja Aggarwal", "Prateeti Mohapatra." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 3251–",
      "citeRegEx" : "Gupta et al\\.,? 2018",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2018
    }, {
      "title" : "Polisis: Automated analysis and presentation of privacy policies using deep learning",
      "author" : [ "Hamza Harkous", "Kassem Fawaz", "Rémi Lebret", "Florian Schaub", "Kang G Shin", "Karl Aberer." ],
      "venue" : "27th {USENIX} Security Symposium ({USENIX} Security 18), pages",
      "citeRegEx" : "Harkous et al\\.,? 2018",
      "shortCiteRegEx" : "Harkous et al\\.",
      "year" : 2018
    }, {
      "title" : "The atis spoken language systems pilot corpus",
      "author" : [ "Charles T Hemphill", "John J Godfrey", "George R Doddington." ],
      "venue" : "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, Pennsylvania, June 24-27, 1990.",
      "citeRegEx" : "Hemphill et al\\.,? 1990",
      "shortCiteRegEx" : "Hemphill et al\\.",
      "year" : 1990
    }, {
      "title" : "Lexical similarity of information type hypernyms, meronyms and synonyms in privacy policies",
      "author" : [ "Mitra Bokaei Hosseini", "Sudarshan Wadkar", "Travis D Breaux", "Jianwei Niu." ],
      "venue" : "2016 AAAI Fall Symposium Series.",
      "citeRegEx" : "Hosseini et al\\.,? 2016",
      "shortCiteRegEx" : "Hosseini et al\\.",
      "year" : 2016
    }, {
      "title" : "Content analysis: An introduction to its methodology",
      "author" : [ "Krippendorff Klaus" ],
      "venue" : null,
      "citeRegEx" : "Klaus.,? \\Q1980\\E",
      "shortCiteRegEx" : "Klaus.",
      "year" : 1980
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "John Lafferty", "Andrew McCallum", "Fernando CN Pereira" ],
      "venue" : null,
      "citeRegEx" : "Lafferty et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "BART: Denoising sequence-to-sequence pretraining for natural language",
      "author" : [ "Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "MTOP: A comprehensive multilingual task-oriented semantic parsing benchmark",
      "author" : [ "Haoran Li", "Abhinav Arora", "Shuohui Chen", "Anchit Gupta", "Sonal Gupta", "Yashar Mehdad." ],
      "venue" : "Proceedings of the 16th Conference of the European Chapter of the",
      "citeRegEx" : "Li et al\\.,? 2021",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2021
    }, {
      "title" : "Attention-based recurrent neural network models for joint intent detection and slot filling",
      "author" : [ "Bing Liu", "Ian Lane." ],
      "venue" : "Interspeech 2016, 17th Annual Conference of the International Speech Communication Association, pages 685–689.",
      "citeRegEx" : "Liu and Lane.,? 2016",
      "shortCiteRegEx" : "Liu and Lane.",
      "year" : 2016
    }, {
      "title" : "A step towards usable privacy policy: Automatic alignment of privacy statements",
      "author" : [ "Fei Liu", "Rohan Ramanath", "Norman Sadeh", "Noah A. Smith." ],
      "venue" : "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Techni-",
      "citeRegEx" : "Liu et al\\.,? 2014",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2014
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "A general framework for information extraction using dynamic span graphs",
      "author" : [ "Yi Luan", "Dave Wadden", "Luheng He", "Amy Shah", "Mari Ostendorf", "Hannaneh Hajishirzi." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the",
      "citeRegEx" : "Luan et al\\.,? 2019",
      "shortCiteRegEx" : "Luan et al\\.",
      "year" : 2019
    }, {
      "title" : "End-to-end sequence labeling via bi-directional LSTM-CNNsCRF",
      "author" : [ "Xuezhe Ma", "Eduard Hovy." ],
      "venue" : "Proceedings of the 54th Annual Meeting of",
      "citeRegEx" : "Ma and Hovy.,? 2016",
      "shortCiteRegEx" : "Ma and Hovy.",
      "year" : 2016
    }, {
      "title" : "Does “notice and choice” disclosure regulation work? an empirical study of privacy policies,",
      "author" : [ "Florencia Marotta-Wurgler." ],
      "venue" : "Michigan Law: Law and Economics Workshop.",
      "citeRegEx" : "Marotta.Wurgler.,? 2015",
      "shortCiteRegEx" : "Marotta.Wurgler.",
      "year" : 2015
    }, {
      "title" : "The cost of reading privacy policies",
      "author" : [ "Aleecia M McDonald", "Lorrie Faith Cranor." ],
      "venue" : "Isjlp, 4:543.",
      "citeRegEx" : "McDonald and Cranor.,? 2008",
      "shortCiteRegEx" : "McDonald and Cranor.",
      "year" : 2008
    }, {
      "title" : "Identifying the provision of choices in privacy policy text",
      "author" : [ "Kanthashree Mysore Sathyendra", "Shomir Wilson", "Florian Schaub", "Sebastian Zimmeck", "Norman Sadeh." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Sathyendra et al\\.,? 2017",
      "shortCiteRegEx" : "Sathyendra et al\\.",
      "year" : 2017
    }, {
      "title" : "Unsupervised alignment of privacy policies using hidden markov models",
      "author" : [ "Rohan Ramanath", "Fei Liu", "Norman Sadeh", "Noah A Smith." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Pa-",
      "citeRegEx" : "Ramanath et al\\.,? 2014",
      "shortCiteRegEx" : "Ramanath et al\\.",
      "year" : 2014
    }, {
      "title" : "Question answering for privacy policies: Combining computational and legal perspectives",
      "author" : [ "Abhilasha Ravichander", "Alan W Black", "Shomir Wilson", "Thomas Norton", "Norman Sadeh." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Nat-",
      "citeRegEx" : "Ravichander et al\\.,? 2019",
      "shortCiteRegEx" : "Ravichander et al\\.",
      "year" : 2019
    }, {
      "title" : "Ambiguity in privacy policies and the impact of regulation",
      "author" : [ "Joel R Reidenberg", "Jaspreet Bhatia", "Travis D Breaux", "Thomas B Norton." ],
      "venue" : "The Journal of Legal Studies, 45(S2):S163–S190.",
      "citeRegEx" : "Reidenberg et al\\.,? 2016",
      "shortCiteRegEx" : "Reidenberg et al\\.",
      "year" : 2016
    }, {
      "title" : "Reliability measurement without limits",
      "author" : [ "Dennis Reidsma", "Jean Carletta." ],
      "venue" : "Computational Linguistics, 34(3):319–326.",
      "citeRegEx" : "Reidsma and Carletta.,? 2008",
      "shortCiteRegEx" : "Reidsma and Carletta.",
      "year" : 2008
    }, {
      "title" : "Don’t parse, generate! a sequence to sequence architecture for task-oriented semantic parsing",
      "author" : [ "Subendhu Rongali", "Luca Soldaini", "Emilio Monti", "Wael Hamza." ],
      "venue" : "Proceedings of The Web Conference 2020, pages 2962–2968.",
      "citeRegEx" : "Rongali et al\\.,? 2020",
      "shortCiteRegEx" : "Rongali et al\\.",
      "year" : 2020
    }, {
      "title" : "Automatic extraction of opt-out choices from privacy policies",
      "author" : [ "Kanthashree Mysore Sathyendra", "Florian Schaub", "Shomir Wilson", "Norman Sadeh." ],
      "venue" : "2016 AAAI Fall Symposium Series.",
      "citeRegEx" : "Sathyendra et al\\.,? 2016",
      "shortCiteRegEx" : "Sathyendra et al\\.",
      "year" : 2016
    }, {
      "title" : "Cross-lingual transfer learning for multilingual task oriented dialog",
      "author" : [ "Sebastian Schuster", "Sonal Gupta", "Rushin Shah", "Mike Lewis." ],
      "venue" : "Proceedings of the 2019 Conference of the North American",
      "citeRegEx" : "Schuster et al\\.,? 2019",
      "shortCiteRegEx" : "Schuster et al\\.",
      "year" : 2019
    }, {
      "title" : "RECIPE: Applying open domain question answering to privacy policies",
      "author" : [ "Yan Shvartzshanider", "Ananth Balashankar", "Thomas Wies", "Lakshminarayanan Subramanian." ],
      "venue" : "Proceedings of the Workshop on Machine Reading for Question Answering,",
      "citeRegEx" : "Shvartzshanider et al\\.,? 2018",
      "shortCiteRegEx" : "Shvartzshanider et al\\.",
      "year" : 2018
    }, {
      "title" : "Brat: a web-based tool for nlp-assisted text annotation",
      "author" : [ "Pontus Stenetorp", "Sampo Pyysalo", "Goran Topić", "Tomoko Ohta", "Sophia Ananiadou", "Jun’ichi Tsujii" ],
      "venue" : "In Proceedings of the Demonstrations at the 13th Conference of the European Chap-",
      "citeRegEx" : "Stenetorp et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Stenetorp et al\\.",
      "year" : 2012
    }, {
      "title" : "Udpipe: trainable pipeline for processing conll-u files performing tokenization, morphological analysis, pos tagging and parsing",
      "author" : [ "Milan Straka", "Jan Hajic", "Jana Straková." ],
      "venue" : "Proceedings of the Tenth International Conference on Language Re-",
      "citeRegEx" : "Straka et al\\.,? 2016",
      "shortCiteRegEx" : "Straka et al\\.",
      "year" : 2016
    }, {
      "title" : "almost) zero-shot cross-lingual spoken language understanding",
      "author" : [ "Shyam Upadhyay", "Manaal Faruqui", "Gokhan Tür", "Hakkani-Tür Dilek", "Larry Heck." ],
      "venue" : "2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),",
      "citeRegEx" : "Upadhyay et al\\.,? 2018",
      "shortCiteRegEx" : "Upadhyay et al\\.",
      "year" : 2018
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Ł ukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems 30, pages 5998–6008. Curran Asso-",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Entity, relation, and event extraction with contextualized span representations",
      "author" : [ "David Wadden", "Ulme Wennberg", "Yi Luan", "Hannaneh Hajishirzi." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
      "citeRegEx" : "Wadden et al\\.,? 2019",
      "shortCiteRegEx" : "Wadden et al\\.",
      "year" : 2019
    }, {
      "title" : "Minilm: Deep selfattention distillation for task-agnostic compression of pre-trained transformers",
      "author" : [ "Wenhui Wang", "Furu Wei", "Li Dong", "Hangbo Bao", "Nan Yang", "Ming Zhou." ],
      "venue" : "Advances in Neural Information Processing Systems.",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "The creation and analysis of a website privacy",
      "author" : [ "Giovanni Leon", "Mads Schaarup Andersen", "Sebastian Zimmeck", "Kanthashree Mysore Sathyendra", "N. Cameron Russell", "Thomas B. Norton", "Eduard Hovy", "Joel Reidenberg", "Norman Sadeh" ],
      "venue" : null,
      "citeRegEx" : "Leon et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Leon et al\\.",
      "year" : 2016
    }, {
      "title" : "Crowdsourcing annotations for websites’ privacy policies: Can it really work",
      "author" : [ "Shomir Wilson", "Florian Schaub", "Rohan Ramanath", "Norman Sadeh", "Fei Liu", "Noah A Smith", "Frederick Liu" ],
      "venue" : "In Proceedings of the 25th International Conference",
      "citeRegEx" : "Wilson et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Wilson et al\\.",
      "year" : 2016
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander M. Rush." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    }, {
      "title" : "End-to-end slot alignment and recognition for crosslingual NLU",
      "author" : [ "Weijia Xu", "Batool Haider", "Saab Mansour." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5052–5063, Online. As-",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "A joint model of intent determination and slot filling for spoken language understanding",
      "author" : [ "Xiaodong Zhang", "Houfeng Wang." ],
      "venue" : "IJCAI, volume 16, pages 2993–2999.",
      "citeRegEx" : "Zhang and Wang.,? 2016",
      "shortCiteRegEx" : "Zhang and Wang.",
      "year" : 2016
    }, {
      "title" : "End-to-end learning of semantic role labeling using recurrent neural networks",
      "author" : [ "Jie Zhou", "Wei Xu." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan-",
      "citeRegEx" : "Zhou and Xu.,? 2015",
      "shortCiteRegEx" : "Zhou and Xu.",
      "year" : 2015
    }, {
      "title" : "Don’t parse, insert: Multilingual semantic parsing with insertion based decoding",
      "author" : [ "Qile Zhu", "Haidar Khan", "Saleh Soltan", "Stephen Rawls", "Wael Hamza." ],
      "venue" : "Proceedings of the 24th Conference on Computational Natural Language Learning, pages 496–",
      "citeRegEx" : "Zhu et al\\.,? 2020",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2020
    }, {
      "title" : "Maps: Scaling privacy compliance analysis to a million apps",
      "author" : [ "Sebastian Zimmeck", "Peter Story", "Daniel Smullen", "Abhilasha Ravichander", "Ziqi Wang", "Joel Reidenberg", "N Cameron Russell", "Norman Sadeh." ],
      "venue" : "Proceedings on Privacy Enhancing Tech-",
      "citeRegEx" : "Zimmeck et al\\.,? 2019",
      "shortCiteRegEx" : "Zimmeck et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 30,
      "context" : "privacy policies often very long, complicated, and confusing (McDonald and Cranor, 2008; Reidenberg et al., 2016).",
      "startOffset" : 61,
      "endOffset" : 113
    }, {
      "referenceID" : 34,
      "context" : "privacy policies often very long, complicated, and confusing (McDonald and Cranor, 2008; Reidenberg et al., 2016).",
      "startOffset" : 61,
      "endOffset" : 113
    }, {
      "referenceID" : 29,
      "context" : "As a result, users do not tend to read privacy policies (Commission et al., 2012; Gluck et al.; Marotta-Wurgler, 2015), leading to undesirable consequences.",
      "startOffset" : 56,
      "endOffset" : 118
    }, {
      "referenceID" : 17,
      "context" : "In literature, information extraction from policy documents is formulated as text classification (Wilson et al., 2016a; Harkous et al., 2018; Zimmeck et al., 2019), text alignment (Liu et al.",
      "startOffset" : 97,
      "endOffset" : 163
    }, {
      "referenceID" : 53,
      "context" : "In literature, information extraction from policy documents is formulated as text classification (Wilson et al., 2016a; Harkous et al., 2018; Zimmeck et al., 2019), text alignment (Liu et al.",
      "startOffset" : 97,
      "endOffset" : 163
    }, {
      "referenceID" : 25,
      "context" : ", 2019), text alignment (Liu et al., 2014; Ramanath et al., 2014), and question answering (QA) (Shvartzshanider et al.",
      "startOffset" : 24,
      "endOffset" : 65
    }, {
      "referenceID" : 32,
      "context" : ", 2019), text alignment (Liu et al., 2014; Ramanath et al., 2014), and question answering (QA) (Shvartzshanider et al.",
      "startOffset" : 24,
      "endOffset" : 65
    }, {
      "referenceID" : 39,
      "context" : ", 2014), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 135
    }, {
      "referenceID" : 17,
      "context" : ", 2014), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 135
    }, {
      "referenceID" : 33,
      "context" : ", 2014), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 135
    }, {
      "referenceID" : 0,
      "context" : ", 2014), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 135
    }, {
      "referenceID" : 40,
      "context" : "We use the web-based annotation tool, BRAT (Stenetorp et al., 2012) to conduct the annotation.",
      "startOffset" : 43,
      "endOffset" : 67
    }, {
      "referenceID" : 20,
      "context" : "Post-editing and Quality Control We compute an inter-annotator agreement for each annotated segment of policy documents using Krippendorff’s Alpha (αK) (Klaus, 1980).",
      "startOffset" : 152,
      "endOffset" : 165
    }, {
      "referenceID" : 1,
      "context" : "8 is allowed for tentative conclusions (Artstein and Poesio, 2008; Reidsma and Carletta, 2008).",
      "startOffset" : 39,
      "endOffset" : 94
    }, {
      "referenceID" : 35,
      "context" : "8 is allowed for tentative conclusions (Artstein and Poesio, 2008; Reidsma and Carletta, 2008).",
      "startOffset" : 39,
      "endOffset" : 94
    }, {
      "referenceID" : 9,
      "context" : "We present two alternative approaches; the first approach jointly models intent classification and slot tagging (Chen et al., 2019), and the second modeling approach casts the problem as a sequence-to-sequence learning task (Rongali et al.",
      "startOffset" : 112,
      "endOffset" : 131
    }, {
      "referenceID" : 36,
      "context" : ", 2019), and the second modeling approach casts the problem as a sequence-to-sequence learning task (Rongali et al., 2020; Li et al., 2021).",
      "startOffset" : 100,
      "endOffset" : 139
    }, {
      "referenceID" : 23,
      "context" : ", 2019), and the second modeling approach casts the problem as a sequence-to-sequence learning task (Rongali et al., 2020; Li et al., 2021).",
      "startOffset" : 100,
      "endOffset" : 139
    }, {
      "referenceID" : 41,
      "context" : "We split the policy documents into sentences using UDPipe (Straka et al., 2016).",
      "startOffset" : 58,
      "endOffset" : 79
    }, {
      "referenceID" : 24,
      "context" : "We use BiLSTM (Liu and Lane, 2016; Zhang and Wang, 2016), Transformer (Vaswani et al.",
      "startOffset" : 14,
      "endOffset" : 56
    }, {
      "referenceID" : 50,
      "context" : "We use BiLSTM (Liu and Lane, 2016; Zhang and Wang, 2016), Transformer (Vaswani et al.",
      "startOffset" : 14,
      "endOffset" : 56
    }, {
      "referenceID" : 43,
      "context" : "We use BiLSTM (Liu and Lane, 2016; Zhang and Wang, 2016), Transformer (Vaswani et al., 2017), BERT (Vaswani et al.",
      "startOffset" : 70,
      "endOffset" : 92
    }, {
      "referenceID" : 43,
      "context" : ", 2017), BERT (Vaswani et al., 2017), and RoBERTa (Liu et al.",
      "startOffset" : 14,
      "endOffset" : 36
    }, {
      "referenceID" : 26,
      "context" : ", 2017), and RoBERTa (Liu et al., 2019) as encoder to form the sequence tagging models.",
      "startOffset" : 21,
      "endOffset" : 39
    }, {
      "referenceID" : 44,
      "context" : "Span enumeration based techniques (Wadden et al., 2019; Luan et al., 2019) can be utilized to perform tagging both types of slots jointly, and we leave this as future work.",
      "startOffset" : 34,
      "endOffset" : 74
    }, {
      "referenceID" : 27,
      "context" : "Span enumeration based techniques (Wadden et al., 2019; Luan et al., 2019) can be utilized to perform tagging both types of slots jointly, and we leave this as future work.",
      "startOffset" : 34,
      "endOffset" : 74
    }, {
      "referenceID" : 14,
      "context" : "We train WordPiece embeddings with a 30,000 token vocabulary (Devlin et al., 2019) using fastText (Bojanowski et al.",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 6,
      "context" : ", 2019) using fastText (Bojanowski et al., 2017) based on a corpus of 130,000 privacy policies collected from apps on the Google Play Store (Harkous et al.",
      "startOffset" : 23,
      "endOffset" : 48
    }, {
      "referenceID" : 17,
      "context" : ", 2017) based on a corpus of 130,000 privacy policies collected from apps on the Google Play Store (Harkous et al., 2018).",
      "startOffset" : 99,
      "endOffset" : 121
    }, {
      "referenceID" : 51,
      "context" : "Conditional Random Field (CRF) helps structure prediction tasks, such as semantic role labeling (Zhou and Xu, 2015) and named entity recognition (Cotterell and Duh, 2017).",
      "startOffset" : 96,
      "endOffset" : 115
    }, {
      "referenceID" : 12,
      "context" : "Conditional Random Field (CRF) helps structure prediction tasks, such as semantic role labeling (Zhou and Xu, 2015) and named entity recognition (Cotterell and Duh, 2017).",
      "startOffset" : 145,
      "endOffset" : 170
    }, {
      "referenceID" : 21,
      "context" : "Therefore, we model slot labeling jointly using a conditional random field (CRF) (Lafferty et al., 2001) (only interactions between two successive labels are considered).",
      "startOffset" : 81,
      "endOffset" : 104
    }, {
      "referenceID" : 36,
      "context" : "Recent works in semantic parsing (Rongali et al., 2020; Zhu et al., 2020; Li et al., 2021) formulate the task as sequence-to-sequence (Seq2Seq) learning.",
      "startOffset" : 33,
      "endOffset" : 90
    }, {
      "referenceID" : 52,
      "context" : "Recent works in semantic parsing (Rongali et al., 2020; Zhu et al., 2020; Li et al., 2021) formulate the task as sequence-to-sequence (Seq2Seq) learning.",
      "startOffset" : 33,
      "endOffset" : 90
    }, {
      "referenceID" : 23,
      "context" : "Recent works in semantic parsing (Rongali et al., 2020; Zhu et al., 2020; Li et al., 2021) formulate the task as sequence-to-sequence (Seq2Seq) learning.",
      "startOffset" : 33,
      "endOffset" : 90
    }, {
      "referenceID" : 45,
      "context" : "Specifically, we consider five state-of-the-art models: MiniLM (Wang et al., 2020), UniLM (Dong et al.",
      "startOffset" : 63,
      "endOffset" : 82
    }, {
      "referenceID" : 15,
      "context" : ", 2020), UniLM (Dong et al., 2019), UniLMv2 (Bao et al.",
      "startOffset" : 15,
      "endOffset" : 34
    }, {
      "referenceID" : 3,
      "context" : ", 2019), UniLMv2 (Bao et al., 2020), MASS (Song et al.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 11,
      "context" : "Earlier approaches (Costante et al., 2012) designed rule-based pattern matching techniques to extract specific types of information.",
      "startOffset" : 19,
      "endOffset" : 42
    }, {
      "referenceID" : 4,
      "context" : ", 2013), several works have been done (Bhatia and Breaux, 2015; Wilson et al., 2016a,b; Sathyendra et al., 2016; Bhatia et al., 2016; Hosseini et al., 2016; Mysore Sathyendra et al., 2017; Zimmeck et al., 2019; Bannihatti Kumar et al., 2020).",
      "startOffset" : 38,
      "endOffset" : 241
    }, {
      "referenceID" : 37,
      "context" : ", 2013), several works have been done (Bhatia and Breaux, 2015; Wilson et al., 2016a,b; Sathyendra et al., 2016; Bhatia et al., 2016; Hosseini et al., 2016; Mysore Sathyendra et al., 2017; Zimmeck et al., 2019; Bannihatti Kumar et al., 2020).",
      "startOffset" : 38,
      "endOffset" : 241
    }, {
      "referenceID" : 5,
      "context" : ", 2013), several works have been done (Bhatia and Breaux, 2015; Wilson et al., 2016a,b; Sathyendra et al., 2016; Bhatia et al., 2016; Hosseini et al., 2016; Mysore Sathyendra et al., 2017; Zimmeck et al., 2019; Bannihatti Kumar et al., 2020).",
      "startOffset" : 38,
      "endOffset" : 241
    }, {
      "referenceID" : 19,
      "context" : ", 2013), several works have been done (Bhatia and Breaux, 2015; Wilson et al., 2016a,b; Sathyendra et al., 2016; Bhatia et al., 2016; Hosseini et al., 2016; Mysore Sathyendra et al., 2017; Zimmeck et al., 2019; Bannihatti Kumar et al., 2020).",
      "startOffset" : 38,
      "endOffset" : 241
    }, {
      "referenceID" : 53,
      "context" : ", 2013), several works have been done (Bhatia and Breaux, 2015; Wilson et al., 2016a,b; Sathyendra et al., 2016; Bhatia et al., 2016; Hosseini et al., 2016; Mysore Sathyendra et al., 2017; Zimmeck et al., 2019; Bannihatti Kumar et al., 2020).",
      "startOffset" : 38,
      "endOffset" : 241
    }, {
      "referenceID" : 25,
      "context" : "4410 table works leveraging NLP techniques include text alignment (Liu et al., 2014; Ramanath et al., 2014), text classification (Wilson et al.",
      "startOffset" : 66,
      "endOffset" : 107
    }, {
      "referenceID" : 32,
      "context" : "4410 table works leveraging NLP techniques include text alignment (Liu et al., 2014; Ramanath et al., 2014), text classification (Wilson et al.",
      "startOffset" : 66,
      "endOffset" : 107
    }, {
      "referenceID" : 17,
      "context" : ", 2014), text classification (Wilson et al., 2016a; Harkous et al., 2018; Zimmeck et al., 2019), and question answering (QA) (Shvartzshanider et al.",
      "startOffset" : 29,
      "endOffset" : 95
    }, {
      "referenceID" : 53,
      "context" : ", 2014), text classification (Wilson et al., 2016a; Harkous et al., 2018; Zimmeck et al., 2019), and question answering (QA) (Shvartzshanider et al.",
      "startOffset" : 29,
      "endOffset" : 95
    }, {
      "referenceID" : 39,
      "context" : ", 2019), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 135
    }, {
      "referenceID" : 17,
      "context" : ", 2019), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 135
    }, {
      "referenceID" : 33,
      "context" : ", 2019), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 135
    }, {
      "referenceID" : 0,
      "context" : ", 2019), and question answering (QA) (Shvartzshanider et al., 2018; Harkous et al., 2018; Ravichander et al., 2019; Ahmad et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 135
    }, {
      "referenceID" : 17,
      "context" : ", 2016a) uses a hierarchical annotation scheme to annotate text segments with a set of data practices and it has been used for multilabel classification (Wilson et al., 2016a; Harkous et al., 2018) and question answering (Harkous et al.",
      "startOffset" : 153,
      "endOffset" : 197
    }, {
      "referenceID" : 17,
      "context" : ", 2018) and question answering (Harkous et al., 2018; Ahmad et al., 2020); PrivacyQA (Ravichander et al.",
      "startOffset" : 31,
      "endOffset" : 73
    }, {
      "referenceID" : 0,
      "context" : ", 2018) and question answering (Harkous et al., 2018; Ahmad et al., 2020); PrivacyQA (Ravichander et al.",
      "startOffset" : 31,
      "endOffset" : 73
    }, {
      "referenceID" : 33,
      "context" : ", 2020); PrivacyQA (Ravichander et al., 2019) frame the QA task as identifying a list of relevant sentences from policy documents.",
      "startOffset" : 19,
      "endOffset" : 45
    }, {
      "referenceID" : 18,
      "context" : "Several benchmarks have been proposed in literature covering several domains, and languages (Hemphill et al., 1990; Coucke et al., 2018; Gupta et al., 2018; Upadhyay et al., 2018; Schuster et al., 2019; Xu et al., 2020; Li et al., 2021).",
      "startOffset" : 92,
      "endOffset" : 236
    }, {
      "referenceID" : 13,
      "context" : "Several benchmarks have been proposed in literature covering several domains, and languages (Hemphill et al., 1990; Coucke et al., 2018; Gupta et al., 2018; Upadhyay et al., 2018; Schuster et al., 2019; Xu et al., 2020; Li et al., 2021).",
      "startOffset" : 92,
      "endOffset" : 236
    }, {
      "referenceID" : 16,
      "context" : "Several benchmarks have been proposed in literature covering several domains, and languages (Hemphill et al., 1990; Coucke et al., 2018; Gupta et al., 2018; Upadhyay et al., 2018; Schuster et al., 2019; Xu et al., 2020; Li et al., 2021).",
      "startOffset" : 92,
      "endOffset" : 236
    }, {
      "referenceID" : 42,
      "context" : "Several benchmarks have been proposed in literature covering several domains, and languages (Hemphill et al., 1990; Coucke et al., 2018; Gupta et al., 2018; Upadhyay et al., 2018; Schuster et al., 2019; Xu et al., 2020; Li et al., 2021).",
      "startOffset" : 92,
      "endOffset" : 236
    }, {
      "referenceID" : 38,
      "context" : "Several benchmarks have been proposed in literature covering several domains, and languages (Hemphill et al., 1990; Coucke et al., 2018; Gupta et al., 2018; Upadhyay et al., 2018; Schuster et al., 2019; Xu et al., 2020; Li et al., 2021).",
      "startOffset" : 92,
      "endOffset" : 236
    }, {
      "referenceID" : 49,
      "context" : "Several benchmarks have been proposed in literature covering several domains, and languages (Hemphill et al., 1990; Coucke et al., 2018; Gupta et al., 2018; Upadhyay et al., 2018; Schuster et al., 2019; Xu et al., 2020; Li et al., 2021).",
      "startOffset" : 92,
      "endOffset" : 236
    }, {
      "referenceID" : 23,
      "context" : "Several benchmarks have been proposed in literature covering several domains, and languages (Hemphill et al., 1990; Coucke et al., 2018; Gupta et al., 2018; Upadhyay et al., 2018; Schuster et al., 2019; Xu et al., 2020; Li et al., 2021).",
      "startOffset" : 92,
      "endOffset" : 236
    }, {
      "referenceID" : 33,
      "context" : "For example, PrivacyQA corpus (Ravichander et al., 2019) combined with PolicyIE can facilitate building QA systems that can answer questions with fine-grained details.",
      "startOffset" : 30,
      "endOffset" : 56
    } ],
    "year" : 2021,
    "abstractText" : "Understanding privacy policies is crucial for users as it empowers them to learn about the information that matters to them. Sentences written in a privacy policy document explain privacy practices, and the constituent text spans convey further specific information about that practice. We refer to predicting the privacy practice explained in a sentence as intent classification and identifying the text spans sharing specific information as slot filling. In this work, we propose PolicyIE, an English corpus consisting of 5,250 intent and 11,788 slot annotations spanning 31 privacy policies of websites and mobile applications. PolicyIE corpus is a challenging real-world benchmark with limited labeled examples reflecting the cost of collecting large-scale annotations from domain experts. We present two alternative neural approaches as baselines, (1) intent classification and slot filling as a joint sequence tagging and (2) modeling them as a sequence-tosequence (Seq2Seq) learning task. The experiment results show that both approaches perform comparably in intent classification, while the Seq2Seq method outperforms the sequence tagging approach in slot filling by a large margin. We perform a detailed error analysis to reveal the challenges of the proposed corpus.",
    "creator" : "LaTeX with hyperref"
  }
}