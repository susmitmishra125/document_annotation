{
  "name" : "2021.acl-long.546.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Space Efficient Context Encoding for Non-Task-Oriented Dialogue Generation with Graph Attention Transformer",
    "authors" : [ "Fabian Galetzka", "Jewgeni Rose", "David Schlangen", "Jens Lehmann" ],
    "emails" : [ "jewgeni.rose@volkswagen.de", "fabian.galetzka@volkswagen.de", "jens.lehmann@iais.fraunhofer.de", "david.schlangen@uni-potsdam.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 7028–7041\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n7028"
    }, {
      "heading" : "1 Introduction",
      "text" : "Building on the idea of attention-based seq2seq models (Vaswani et al., 2017), recent language models such as BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019) enable neural conversational models to generate responses that appear human-like and engaging (Yu et al., 2019). A closer look, however, reveals that the lack of long-term memory to represent consistent (world) knowledge and personality over multiple speaker turns can lead to incoherent content being generated (Li et al., 2016; Serban et al., 2017). Initiated by the Conversational Intelligence Challenge (Burtsev et al., 2018; Dinan et al., 2020), the research focus therefore shifted towards knowledge-grounded dialogue\n∗The first two authors contributed equally to this paper. †Corresponding author\ngeneration, resulting in first promising approaches using Transformer-based architectures (Dinan et al., 2019; Ghazvininejad et al., 2018; Galetzka et al., 2020).\nThe basic idea of these approaches is to provide the required background knowledge together with the current dialogue context when decoding the next system utterance. As the underlying language model’s input sequence length is limited – for instance, to 1024 tokens in the case of GTP-2 – the presentation of the background knowledge to the model highly impacts the amount of context information that can be fed into a Transformer network. In these earlier attempts, the knowledge was paraphrased into pseudo-utterances, on a par with the utterances from the dialogue history. In this paper, we show that a structured knowledge representation offers advantages over unstructured text: facts and complex relationships between different entities can be encoded concisely without performance drop in key indicators, such as knowledge correctness, consistency, and interestingness. Chaudhuri et al. (2019) showed the general feasibility of integrating knowledge graphs into domain-specific dialogues. With this work, we integrate arbitrary knowledge graphs into open-domain knowledgegrounded dialogues, preserving the information encoded in their structure.\nSpace Efficient Context Encoding For our proposed encoding, we generate dialogue-specific local knowledge graphs (subgraphs of a background knowledge graph) that capture the information relevant to the dialogue (similar to (Chaudhuri et al., 2021)). We transform these subgraphs into a concise representation that fits the input sequence encoding for the underlying language model (GPT-2): Labels of the distinct nodes and edges (entities and corresponding relations) are concatenated with the dialogue history. To preserve the graph structure,\nwe fit the attention mask to force the self-attention layers for each node to attend to only connected nodes in the original graph (if there is a connection, attention weight is set to 1, otherwise to 0). This resembles the message-passing approach of graph neural networks (Gilmer et al., 2017).\nNaive concatenation of graph triples has a space complexity of O(n · k), with n being the number of triples and k the number of word tokens per verbalized triple. Paraphrasing these triples into pseudo-utterances results in even larger space complexity. Our proposed encoding has a space complexity of O(l), with l being the number of distinct node and edge labels (entities and relations). This reduces the required context space compared to triple concatenation or paraphrasing if entities are repeated in the triples (and hence l < n · k), which can be assumed to be the case in knowledge graphs (see discussion below). The space savings grow with the size and average degree (connectedness) of the graph. Empirical results with two different knowledge-grounded dialogue datasets confirm our theoretical considerations and show that we can reduce the required space by a factor of up to 3.6. These results imply that we can feed more context information into the model, which should result in higher accuracy. We discuss these results in detail in Section 4.3.\nContributions We propose an approach to integrate a concise encoding of knowledge graphs into a Transformer-based decoder architecture for knowledge-grounded dialogue generation. Transformers for natural language generation can be viewed as graph neural networks which use selfattention (Veličković et al., 2018) for neighborhood aggregation on fully-connected word graphs (Xu et al., 2019). We utilize this relationship and restrict the self-attention weights to match the underlying graph structure. Our comprehensive human evaluation with models trained with the publicly available datasets KOMODIS (Galetzka et al., 2020) and OPENDIALKG (Moon et al., 2019), both providing dialogues enriched with structured knowledge, shows that we can reduce the space requirement for context without negative effects on the precision of reproduction of knowledge and perceived consistency. Moreover, our models generate dialogues that are judged to be more detailed and interesting. For reproducibility, we publish all necessary source code and data (https://github.com/fabiangal/ space-efficient-context-encoding-acl21)."
    }, {
      "heading" : "2 Knowledge-Augmented Neural Conversational Models",
      "text" : "Neural conversational models can be categorized into retrieval-based approaches (Lowe et al., 2015; Wu et al., 2017) that choose a next utterance from a set of suitable candidates, and generative approaches (Serban et al., 2016; Wolf et al., 2019; Chaudhuri et al., 2019; Roller et al., 2021) which decode the next utterance token by token out of a fixed vocabulary. The architectures are based on recurrent neural networks such as LSTM (Hochreiter and Schmidhuber, 1997) or GRU (Cho et al., 2014) cells or self-attention layers (Vaswani et al., 2017) in sequence-to-sequence structures. To integrate knowledge in addition to the dialogue history these models can be augmented by additional recurrent cells to encode the knowledge into a fixedsized vector representation (Young et al., 2018; Parthasarathi and Pineau, 2020; Ghazvininejad et al., 2018). This can be traced back to first endto-end approaches reading documents for questionanswering (Miller et al., 2016) or more general sequential data (Sukhbaatar et al., 2015). He et al. (2017) embedded knowledge graphs (stored as triples) with LSTM cells and message-passing, and then used a decoder LSTM to generate a suitable answer. Long et al. (2017) used a CNN architecture to encode external knowledge instead.\nThe recent success of unsupervised pre-trained language generation models such as GPT-2 yielded a variety of conversational models using selfattention based on the idea of fine-tuning the models with specific knowledge-grounded dialogue datasets (which we will discuss in Section 3). These models concatenate the additional context information as plain text to the input sequence (Zhang et al., 2018; Dinan et al., 2019; Galetzka et al., 2020). To differentiate context from dialogue, additional tokens are learned during fine-tuning and added to the word tokens. For bigger knowledge graphs, the limitation of the input sequence length of these models makes an information retrieval system necessary to estimate a small subset of relevant information that can be fed into the model."
    }, {
      "heading" : "3 Knowledge-Grounded Dialogue Datasets",
      "text" : "The increasing availability of conversational content on social media platforms such as Twitter or Reddit led to the construction of many dia-\nlogue datasets, with Open-Subtitles (Vinyals and Le, 2015) and Twitter-Corpus (Sordoni et al., 2015) being some popular examples (see also (Ritter et al., 2010; Duplessis et al., 2016)).\nSome recently published datasets emphasize knowledgeable dialogues by integrating external information sources. The objective is to create models that generate consistent dialogues with a high knowledge retrieval accuracy (utilizing information from user profiles or knowledge graphs). Dinan et al. (2019) released the Wizard of Wikipedia dataset with over 22k open-domain dialogues. In each dialogue, one participant is playing the “wizard”, i.e. an expert who is presented with potentially interesting and relevant Wikipedia article excerpts, while the chat partner is the curious apprentice. The textual knowledge passages that were shown to the wizard are part of the dataset. The PERSONA-CHAT dataset (Zhang et al., 2018) contains over 10k dialogues that are conditioned on profile information (personas), which ranges from hobbies or favorite food to family background. The information is shown to the participants as a set of sentences and they are tasked to integrate them into the dialogues. In addition, the dataset contains revised personas, which are rephrased, generalized, or specialized versions of the original personas."
    }, {
      "heading" : "3.1 Dialogue Datasets with Knowledge Graphs",
      "text" : "We use two publicly available human/human multiturn dialogue datasets that use structured background knowledge.\nKOMODIS (Galetzka et al., 2020) is a closeddomain dataset with dialogues between human participants that were tasked to chit-chat about one given movie and use provided information about it. This information includes facts about the film, such as release year or shot location (“Movie was shot in Canada.” or “The release year is 1995.”), free text containing plot or trivia related to the film crew and cast, and opinions towards the facts and entities (“I agree with the age restriction.” or “I don’t like Bruce Willis.”). The dataset contains over 7,500 conversations with an average of 13.8 utterances per dialogue.\nOpenDialKG (Moon et al., 2019) is an opendomain dataset containing 15K dialogues, which were collected in a Wizard-of-Oz setup, by connecting two human participants that were tasked to have an engaging dialogue about a given topic. Each dialogue is paired with its corresponding “KG paths” from Freebase (Bollacker et al., 2007) (connecting entities and relations mentioned in the dialogue)."
    }, {
      "heading" : "3.2 Subgraph Generation",
      "text" : "For our experiments with different encoding strategies, we restructure the context information provided by both datasets into dialogue-specific subgraphs. Figure 1 illustrates an example of an (incomplete) subgraph that belongs to a dialogue from KOMODIS. The inner subgraph containing the two green entity nodes ’Pulp Fiction’ and ’Bruce Willis’, and corresponding attribute nodes (blue), marked as depth 0, represents the information on which one particular dialogue was based.\nTo test the limits of the capacity for representing knowledge, we also experiment with expanded subgraphs—depths 1 and depths 2 in the figure— by including information from external knowledge sources (IMDb for KOMODIS, and Freebase for OPENDIALKG). For instance, Pulp Fiction also has Samuel L. Jackson as an actor (depth 1) who also stars in Goodfellas (depth 2). This way, the subgraph depth directly reflects the hop distance from the entities in the core subgraph.\nFor subgraphs of depth 2, we restrict some attributes and entities to prevent the subgraphs to explode in size, thus unlikely to fit in GPT-2. For example, we don’t add trivia information that isn’t already in the dialogues or limit additional actors per movie to three. In contrast to OPENDIALKG, the dialogues in KOMODIS are about one main entity (here, the movie) each. To better compare the experiments across datasets, we create two versions of depth 1 for KOMODIS, where depth 1b includes a second movie that is related to the first movie (e.g. by an actor). This version is then used to create the subgraph of depth 2."
    }, {
      "heading" : "4 Graph Attention Transformer",
      "text" : ""
    }, {
      "heading" : "4.1 Model Overview",
      "text" : "For all experiments, we use the GPT-2 model proposed by Radford et al. (2019), which is commonly used in Transformer-based dialogue generation for English. The authors published four different sized variations. We use the model with 117 million parameters, 12 self-attention layers, and 768-dimensional word embeddings. The model has 12 heads per attention layer and 3072 nodes in all feed-forward layers. Our architecture is visualized in Figure 3. A knowledge estimator creates a subgraph from the available knowledge graphs for both datasets based on the dialogue history and converts it using our encoding. Then, the dialogue history and encoded context sequences are concatenated and fed into the GPT-2 model. For training, we optimize model weights from GPT-2 by minimizing the negative log-likelihood for next-token prediction. Training details are listed in Appendix B."
    }, {
      "heading" : "4.2 Concise Graph Encoding",
      "text" : "Figure 2 shows the general encoding strategy that we propose. Similar to our previous approach (Galetzka et al., 2020) and Wolf et al. (2019), we use three layers of input embeddings for words, segments and positions. But instead of concatenating paraphrased triples (e.g. 〈‘Pulp Fiction’, ‘is a’, ‘movie’〉, 〈‘Pulp Fiction’, ‘release year’, ‘1994’〉), we convert the graph into unique entity-relation pairs (e.g. 〈‘Pulp Fiction’, ‘movie’〉, 〈‘1994’, ‘release year’〉 in the leftmost part of the figure) and concatenate them with the dialogue history (middle part in figure). In previous work, the segments layer distinguished context and different speakers. We experiment with two different encoding strategies, utilizing the segments layer in other ways. Figure 4 illustrates both encoding strategies. In the series encoding (upper half of the figure), relation and entity tokens are sequenced in a se-\nries and added to the words layer. Two new tokens (〈entity〉 and 〈relation〉) differentiate between relations and entities in the segments layer. In the parallel encoding, entity tokens are added to the words layer and according relations to the segments layer—thus in parallel. Padding tokens are used to align the length between the two layers.\nThis encoding via a segments layer reduces the space requirements compared to paraphrasing, as repeating tokens occur only once, but on its own loses information encoded in the graph structure (node-edge connections). To preserve this structure information, we create and add a per-graph attention mask to all hidden layers. Given an input sequence S, the hidden state hli of the i’th token at layer l in the GPT-2 model can be computed by:\nhli = ∑ j∈S wij(V l−1hl−1j ), (1)\nwhere\nwij = softmaxj(mj +Ql−1hl−1i ·K l−1hl−1j ),\n(2) with learnable weights K, Q, and V . Equation 1 is similar to message-passing algorithms (Duvenaud et al., 2015; Li et al., 2016; Gilmer et al., 2017), where a new hidden state for a graph node is computed by an arbitrary function of all previous hidden states of connected nodes. Our attention masks mj are added as shown in Equation 2 so that entity and relation tokens can only attend to tokens from their neighboring nodes. This attention masking was originally used for mask out future tokens (setting mi,j for all j > i to the masking value).\nFigure 5 illustrates the concept with an attention mask of the graph example from Figure 1. Here, the node ‘Bruce Willis’ (blue) is not connected with the release year ‘1994’. Thus, the attention weights are masked out with zeros. But, it is connected with the trivia information ‘Worked on the movie for only 18 days’ and these attentions are not masked (ones).\nAlthough entities and relations from the knowledge graph are position invariant within S, the word order still matters. Therefore, we keep the positional encoding of the model but shuffle the knowledge graph nodes and relations for each training sample to facilitate order invariance of the graph encoding."
    }, {
      "heading" : "4.3 Context Length Requirement",
      "text" : "Figure 6 shows the growth of the number of required context tokens when the graph size is increased (and hence, more knowledge is provided to the model), for different encoding types. The baselines are paraphrased-based encodings, where base-triples are the concatenated triples (“Pulp Fiction release year 1994”) and base-paraphrased the verbalized paraphrase (“The movie Pulp Fiction was released in 1994”). For OPENDIALKG, no paraphrased version is available. For both datasets, the average number of tokens increases with the graph depth and the average number of nodes and relations for all encodings, as expected. However, it grows much slower in the case of our proposed encodings.\nThe increase of required tokens for OPENDIALKG is steeper than for KOMODIS, due to the different structure of the dialogue context and the underlying knowledge graphs. The context graph for OPENDIALKG is initially rather small\nand increases very fast with more hops. Further, the KOMODIS context graph contains information about plot and trivia, which are normally longer strings that belong to one entity, thus the benefit of series-encoding (series-enc) and parallel-encoding (parallel-enc) regarding this information is rather small compared to the baselines. Concluding, the sequence length reduction correlates with the average number of edges per node. The series-enc is between 14% and 30% longer than the parallelenc, due to representing relation labels within the segments instead of word embeddings (as shown in Figure 4)."
    }, {
      "heading" : "5 Automated Evaluation, And Its Limits",
      "text" : "We trained 25 models with both datasets with series-encoding, parallel-encoding, base-triples and base-paraphrased (only KOMODIS) and with graph depths d0, d1 and d2. As we were also interested to investigate the effect of different decoding strategies, we used beam-search and topk-sampling when generating the dialogues. These were created by four colleagues (who were not involved in the creation of the models and did not know what the innovation was) interacting with the models. In sum, we created 500 dialogues.\nAt training time, we use perplexity on the validation subset as the stopping criterion. Table 3 lists the results for all models estimated on the test set. Base-triples (baselines) models reach the lowest perplexity and an increasing graph depth increases perplexity, which is reasonable since the format of the baseline encodings resembles the pre-training\ndata of the GPT-2 model the most. This correlation is stronger for OPENDIALKG models. In our experiments, perplexity does not correlate with naturalness (estimated by the human evaluators), indicating that this metric is insufficient to evaluate the overall dialogue quality, in particular across models trained on different datasets.\nIn information retrieval, precision/recall and F1 score are typically chosen as automated metrics to evaluate the retrieval capabilities of a system. In our case, we are interested in the ability of reproducing entities and relations from the knowledge graph. Commonly used word-overlap metrics, such as ROUGE-N/ROUGE-L (Lin, 2004), or BLEU (Papineni et al., 2001), aren’t capable of measuring these. Evaluating precision and recall requires precise co-reference resolution, parse tree annotation and question labelling (e.g. entities, relations, intent). Assume following background facts and generated utterance:\n• 〈‘Pulp Fiction’, ‘has genre’, ‘crime’〉\n• 〈‘comedy’, ‘bot opinion’, ‘I like’〉\n• “It is a crime movie, but I am more interested in comedy films.”\nWithout knowing the intent (asking for the genre of ’Pulp Fiction’ vs. asking for the preferred genre) of the previous utterance, we cannot determine if the occurrences of crime and comedy are true or false positives concerning the underlying knowledge graph. Moreover, in a conversation knowledge is not only used when answering a question\nbut also proactively (“Did you know that Bruce Willis worked on the movie only for 18 days?”). However, the resources that we use offer no such annotations and to the best of our knowledge, no published dataset does. Without it, automated metrics don’t work well. To tackle these challenges, we put our effort into a comprehensive human evaluation and annotation, which is described in the next section."
    }, {
      "heading" : "6 Human Evaluation",
      "text" : ""
    }, {
      "heading" : "6.1 Method",
      "text" : "Participants The evaluation study was managed by researchers not involved in setting up the models and experiments. They recruited 20 participants not familiar with our research and the goals of the study. Demographic data is given in Appendix A. Participants were paid for their effort.\nMaterials To keep the number of assessed dialogues manageable, we limited the number of experiments and did not test all possible variations of the factors described in Section 5. We prepared three series of experiments, aimed at evaluating the influence of decoding algorithms, encoding strategies and graph depths. Early samples indicated that beam-search generates more precise dialogues regarding context. We, therefore, decided to evaluate the decoding algorithm series beforehand. As shown in Section 6.2 our hypothesis proved to be correct, so that the other two series of experiments were done with beam-search only.\nProcedure All participants were instructed before and supervised during the study by a supervisor to ensure their understanding of the metrics. They were given a participant-specific questionnaire with the human/chatbot dialogues and had to perform three tasks. First, mark utterances that either entail (correct use) or contradict (wrong use) the dialogue context. Based on these annotations we measure the model’s knowledge retrieval ability as the ratio between entailing utterances and the sum of entailing and contradicting utterances (precision). Second, rate the dialogues with the following statements for agreement on a 7-point Likert scale: (1) Person B sounds natural. (2) Person B sounds consistent. (3) Person B sounds interesting. Person B is always a model, Person A a human. Last, choose between two dialogues, by answering: “To which Person B would you prefer to talk?”. Additionally, the participants could briefly reason their decision. An example questionnaire can be found in Appendix A."
    }, {
      "heading" : "6.2 Results and Discussion",
      "text" : "Decoding Table 2 shows the results for beamsearch and top-k-sampling decoding. Knowledge precision is better with beam-search for all models, while dialogues generated with top-k-sampling are considered more natural, less self-contradicting, and less repetitive. N-gram filtering reduces repetition through beam-search, but could not be avoided completely. Decoding with top-k-sampling includes more often wrong entity nouns when es-\ntimating the best next tokens, which are then selected by the algorithm. In this work, we emphasize the model’s ability to integrate additional dialogue context correctly. Here, models with beam-search perform significantly better. Thus, our further evaluation focuses on beam-search.\nGraph Encoding The results with series and parallel graph encodings are shown in Table 3 and compared against the baselines. Within each dataset, all models perform similar regarding knowledge precision. Due to the high standard deviation on the agreements, the difference between the models is statistically insignificant. Our graph encoding approach reduces the required input sequence length by a factor of up to 3.6 and still achieves the same quality of knowledge reproduction, consistency, and naturalness as the baselines. Further, the direct dialogue comparison (win ratio) indicates more comprehensive and interesting utterances for KOMODIS. Dialogue preference correlates highest with interestingness and non-existence of con-\ntradicting statements. The most common reasons from participants in no specific order are “longer and more comprehensive utterances”, “more interesting”, “asks counter questions” and “more pleasant”. The OPENDIALKG models perform worse in general but show similar results between the different encodings. Both datasets have similar sizes but OPENDIALKG is not limited to the movie domain, which makes it harder to train compared to KOMODIS.\nSeries vs. Parallel Encoding A quick summary: the segments layer encodes the typing of the word tokens (from the words layer). The intuition behind it is that the model learns the meaning of the words instead of the word distribution alone. For the series encoding, we encode the types generically as either entity or relation. For the parallel encoding, we use the actual typing from the underlying knowledge graph, such as movie, actor, or release year (Section 4.2). We had two objectives. First, reducing the required context space even fur-\nther (which we achieved, see Figure 6). Second, analyzing if this improves the accuracy. The results show, that parallel encoding performs slightly worse compared to series encoding. We assume that this is the case due to the lack of training data, which is, in particular, evident for OPENDIALKG that has much more entity and relation types than KOMODIS, i.e. fewer samples per type.\nGraph Depth Results for training with different context lengths with KOMODIS are shown in Table 4. All metrics (one outlier for opinion precision with d = 1) correlate with increasing graph depth. Results for d = 2, however, are statistically not significantly higher than for d = 1. A bigger subgraph leads to more difficult training data, as the model has more options to choose from. The same results couldn’t be reproduced for OPENDIALKG. This dataset was created for graph generation based on dialogues. However, the dialogue structure is different due to the recommendation task of the data collection. Most entities in these dialogues (e.g. persons, books, movies) are exchangeable (“Can you recommend me a crime book similar to X?”, “Can you recommend me a crime movie similar to Y?”) and therefore not mandatory for a correct and consistent dialogue. Adding more of these entities did not help to determine a correct next entity, as all entities of the same type could be used correctly by the model.\nEffectiveness of Graph Attention Masking Graph masking encodes the relationships between the entities. We hypothesize that dropping these relationships will lead to an information gap, particularly for bigger subgraphs due to more entities that are not represented (well) in the training data. Table 5 shows the results from an early evaluation phase for KOMODIS and OPENDIALKG with graph depth 1 and 2 without graph masking. The dialogues are significantly worse, in particular in terms of reproducing entities correctly for graph depth 2 – which validates our hypothesis. As our resources were limited, we had to reduce the number of models for a thorough human evaluation and thus decided to not pursue this approach any longer."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We proposed a new and concise encoding for knowledge triples from a knowledge graph, which can be integrated into a Transformer architecture\nfor consistent non-goal-driven dialogue generation. In our encoding, we reduce the context length by avoiding repetition by concatenating the whole triples with the dialogue history. By manipulating self-attention layers to reflect connections between nodes in the graphs, we preserve the graph structure. The evaluation results prove that our encoding reduces space requirements without negative effects on the precision of reproduction of knowledge and perceived consistency. For reproducibility, we publish the source code and data."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank our colleagues from the Digital Assistant for Mobility team at the Volkswagen Group Innovation Europe for their support in preparing the human evaluation."
    }, {
      "heading" : "A Human Evaluation",
      "text" : "Demographic data 45% of the 20 participants are women. 75% of the participants stated that they already have experience with various forms of chatbots. Due to data privacy reasons, age information is classified into three different categories. 65% of the participants are 18–35 years old, 20% 36–50 years, and three participants are older than 50 years.\nQuestionnaire The questionnaire contains a survey guide and a set of dialogue pairs to evaluate. An example dialogue pair is shown in Figure 7. Labels were added by the authors. The survey guide consists of four pages with examples and explanations for the participants. The following excerpts are from the guide.\nGeneral instructions: Following, you are presented with two dialogues between Person A and Person B with according background information. The dialogues are completely independent of each other. You must read both dialogues carefully. Please take time for this task.\nInstructions for evaluating the knowledge and opinion precision: Please remember that the evaluation is for Person B only! Please add ‘entailment’ to the fields, when the utterance entails a specific fact or opinion. Please add ‘contradiction’ if an utterance contradicts a specific fact or opinion. Please leave all other fields empty.\nInstructions for rating the dialogues on the 7- point Likert scale: Please rate the three statements for each dialogue on a scale from 1 to 7, where 1 means that you strongly disagree with it and 7 that you strongly agree with it. Please rate all statements independently from the given facts and opinions. For instance, if a dialogue contains wrong facts, it still can sound very natural.\nInstructions for deciding between two dialogues: Please rate intuitively with which Person B you would prefer to talk. Please reason your decision briefly.\nAll instructions are provided with examples."
    }, {
      "heading" : "B Training Details",
      "text" : "For fine-tuning GPT-2, we reused most training parameters from the generative pre-training (Radford et al., 2019). The learning rate linearly decreases to zero with an initial value of lr = 6.25e−6 with max-norm gradient clipping. The language modeling loss is multiplied by 2 before summed up\nwith the next sentence classifier loss. Each minibatch consists of 32 sequences of up to 256 tokens (padded to maximum length). If dialogue history exceeds maximum sequence length, the first utterances are cut off. For each sample, only the tokens from the last utterance are considered for the language modeling loss. Encoded nodes and edges are shuffled randomly for each sample, not for each dialogue. We used a cluster of 4 GeForce RTX 2080 Titan to train our models with batch distribution and gradient accumulation to handle the mini-batch size. Based on graph depth an epoch took up to 4 hours. We trained the models for 7 to 10 epochs. Our graph encoding approaches took longer to converge, compared to the baselines."
    }, {
      "heading" : "C Dialogue Examples",
      "text" : "We show three additional typical dialogue examples for both models in Tables 6, 7 and 8. They contain entailing and contradicting statements regarding the context. The inconsistent opinion in Table 8 (correct in line 4, but incorrect in line 6) was observed more often. For both datasets, we sometimes observe slight misspellings of entities (see Table 8, line 6, ‘Charlie Chaplin’ and ‘Charles Chaplin’). We left the decision, whether this is a contradiction (a wrong entity) or not (a misspelling) to the participants. Another issue that occurred multiple times, is the wrong use of repeated entities (see Figure 7 with ‘Julia Roberts’ in line 6). Models trained with OPENDIALKG also sometimes use entities that are not in the knowledge graph (see Table 7, line 4 ‘The Player’).\nD ia\nlo gu\ne Sa\nrf ar\nos h\nis of\ng en\nre A\nct io\nn.\nSm ita\nJa yk\nar h\nas tr\niv ia : O ft en p la ys th e ro le o f th e m ot he r i n Bo lly w oo d m ov ie\ns. So\nna li\nBe nd\nre is\na n\nac to\nr i n\nSa rf\nar os\nh. Sa\nrf ar\nos h\nw as\nre le\nas ed\nin\n19 99\n. Ac\ntio n\nis no\nt a\ngo od\ng en\nre .\nSo na\nli Be\nnd re\nis\nve ry\ng oo\nd. I l\nik e\nSa rf\nar os h ve ry m uc h.\nW ith\nw hi\nch P\ner so n B w ou ld y ou p re fe r to ta lk ? W\nhy ?\nPe rs\non B\nso\nun ds\nn at\nur al\nPe rs\non B\nso\nun ds\nco\nns is\nte nt\nPe rs\non B\nso\nun ds\nin\nte re\nst in\ng\n1\nA he\ny, h\now a\nre y\nou ?\nI w at\nch ed\nS ar\nfa ro\nsh ye\nst er\nda y.\nco nt\nra di\nct io\nn\n2 It\nw ou\nld b e m or e\nin te\nre st\nin g\nto\nta lk\nto th e se co nd P er\nso n.\n5 3\n4\nB i'm\ngo od\nth an\nks ...\ny ou\nrs el\nf? . i\ndo n'\nt k no\nw th\nat m\nov ie\na ct\nua lly\n... w\nha t's\nit a\nbo ut\n?\nA I a\nm g\noo d!\nIt 's\nan a\nct io\nn m\nov ie\nw ith\nso na\nli be\nnd re\n. en\nta ilm\nen t\nen ta\nilm en\nt\nB oh\no ka\ny co\nol ...\nso un\nds li\nke it\nm ig\nht b\ne a\ngo od\no ne\nto w\nat ch\nw ith\ny ou\nr k id\ns.\nA w\nhy d\no yo\nu th\nin k\nso ?\nen ta\nilm en\nt en\nta ilm\nen t\nco nt\nra di\nct io\nn\nB id\non 't\nre al\nly c\nar e\nfo r a\nct io\nn m\nov ie\ns. ..\nso m\nay be\nth at\n's w\nhy i\ndi dn\n't ca\nre fo\nr t hi\ns o ne . A w ha t d o yo u lik e?\nen ta\nilm en\nt\nB ij\nus t d\non 't\nth in\nk it'\ns a g\noo d\nge nr\ne to\nb e\na pa\nrt o\nf.. . i\ndo n'\nt l ik\ne ac\ntio n\nm ov\nie s e\nith er\n.\nBi ll\nRa ym\non d\nis an\na ct\nor in\nTw\nel ve\nM on\nke ys\n. Tw\nel ve\nM on\nke ys\nis o f ge nr e Sc i-F\ni. Tw\nel ve\nM on\nke ys\nw as\nre le\nas ed\nin\n1 99\n5. Tw\nel ve\nM on\nke ys\nis o\nf g en\nre\nM ys\nte ry\n. Ag\ne re\nst ric\ntio n: I ag re e.\nI l ik\ne Bi\nll Ra\nym on d ve ry m uc h.\n'T w\nel ve\nM on\nke ys ' is go od .\n2\nA he\ny, h\now a\nre y\nou ?\n6 4\n6\nB i'm\ngo od\n. i ju\nst w\nat ch\ned a\nm ov\nie c\nal le\nd \"t\nw el\nve m\non ke\nys \".\nh av\ne yo\nu se\nen it ? A ye s, b ut I di dn 't lik e\nit. en\nta ilm\nen t\nB re\nal ly\n? it\nho ug\nht it\nw as\np re\ntt y\ngo od . A Bi ll Ra ym on d is su ch a g oo d ac to r!\nen ta\nilm en\nt co\nnt ra\ndi ct\nio n\nB id\non 't\nre al\nly li\nke b\nill ra\nym on\nd, b\nut h\ne di\nd a\ngo od\njo b\nin th\nis m\nov ie . A Do y ou k no w th e re le as e ye ar\n? en\nta ilm\nen t\nB ib\nel ie\nve it\nw as\n1 99\n5. d\no yo\nu kn\now w\nha t t\nhe b\nud ge\nt w as\nfo r t\nhi s m\nov ie\nb y\nan y\nch an\nce ?\nFi gu\nre 7:\nE xa\nm pl\ne of\non e\ndi al\nog ue\npa ir\nfr om\nth e\nqu es\ntio nn\nai re\n."
    } ],
    "references" : [ {
      "title" : "Freebase: A shared database of structured general human knowledge",
      "author" : [ "Kurt Bollacker", "Robert Cook", "Patrick Tufts." ],
      "venue" : "Proceedings of the national conference on Artificial Intelligence, 22(2):1962.",
      "citeRegEx" : "Bollacker et al\\.,? 2007",
      "shortCiteRegEx" : "Bollacker et al\\.",
      "year" : 2007
    }, {
      "title" : "The first conversational intelligence challenge",
      "author" : [ "Yoshua Bengio." ],
      "venue" : "The NIPS’17 Competition: Building Intelligent Systems, pages 25–46. Springer.",
      "citeRegEx" : "Bengio.,? 2018",
      "shortCiteRegEx" : "Bengio.",
      "year" : 2018
    }, {
      "title" : "Using a KGCopy Network for Non-goal Oriented Dialogues",
      "author" : [ "Debanjan Chaudhuri", "Md Rashad Al Hasan Rony", "Simon Jordan", "Jens Lehmann." ],
      "venue" : "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and",
      "citeRegEx" : "Chaudhuri et al\\.,? 2019",
      "shortCiteRegEx" : "Chaudhuri et al\\.",
      "year" : 2019
    }, {
      "title" : "Grounding Dialogue Systems via Knowledge Graph Aware Decoding with Pretrained Transformers",
      "author" : [ "Debanjan Chaudhuri", "Md Rashad Al Hasan Rony", "Jens Lehmann." ],
      "venue" : "pages 1–16.",
      "citeRegEx" : "Chaudhuri et al\\.,? 2021",
      "shortCiteRegEx" : "Chaudhuri et al\\.",
      "year" : 2021
    }, {
      "title" : "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
      "author" : [ "Kyunghyun Cho", "Bart Van Merriënboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio." ],
      "venue" : "EMNLP 2014",
      "citeRegEx" : "Cho et al\\.,? 2014",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2014
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "NAACL HLT 2019 - 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "The second conversational intelligence challenge (convai2)",
      "author" : [ "Mikhail Burtsev", "Jason Weston", "Others." ],
      "venue" : "The NeurIPS’18 Competition, pages 187–208. Springer.",
      "citeRegEx" : "Burtsev et al\\.,? 2020",
      "shortCiteRegEx" : "Burtsev et al\\.",
      "year" : 2020
    }, {
      "title" : "Of Wikipedia: Knowledge-powered conversational agents",
      "author" : [ "Emily Dinan", "Stephen Roller", "Kurt Shuster", "Angela Fan", "Michael Auli", "Jason Weston." ],
      "venue" : "7th International Conference on Learning Representations, ICLR 2019, pages 1–18.",
      "citeRegEx" : "Dinan et al\\.,? 2019",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2019
    }, {
      "title" : "Purely corpus-based automatic conversation authoring",
      "author" : [ "Guillaume Dubuisson Duplessis", "Vincent Letard", "Anne Laure Ligozat", "Sophie Rosset." ],
      "venue" : "Proceedings of the 10th International Conference on Language Resources and Evaluation, LREC",
      "citeRegEx" : "Duplessis et al\\.,? 2016",
      "shortCiteRegEx" : "Duplessis et al\\.",
      "year" : 2016
    }, {
      "title" : "Convolutional networks on graphs for learning molecular fingerprints",
      "author" : [ "David Duvenaud", "Dougal Maclaurin", "Jorge AguileraIparraguirre", "Rafael Gómez-Bombarelli", "Timothy Hirzel", "Alán Aspuru-Guzik", "Ryan P. Adams." ],
      "venue" : "Advances in Neural",
      "citeRegEx" : "Duvenaud et al\\.,? 2015",
      "shortCiteRegEx" : "Duvenaud et al\\.",
      "year" : 2015
    }, {
      "title" : "A Corpus of Controlled Opinionated and Knowledgeable Movie Discussions for Training Neural Conversation Models",
      "author" : [ "Fabian Galetzka", "Chukwuemeka Uchenna Eneh", "David Schlangen." ],
      "venue" : "Proceedings of The 12th Language Resources and Evalua-",
      "citeRegEx" : "Galetzka et al\\.,? 2020",
      "shortCiteRegEx" : "Galetzka et al\\.",
      "year" : 2020
    }, {
      "title" : "A knowledge-grounded neural conversation model",
      "author" : [ "Marjan Ghazvininejad", "Chris Brockett", "Ming Wei Chang", "Bill Dolan", "Jianfeng Gao", "Wen Tau Yih", "Michel Galley." ],
      "venue" : "32nd AAAI Conference on Artificial Intelligence, AAAI 2018, pages 5110–5117.",
      "citeRegEx" : "Ghazvininejad et al\\.,? 2018",
      "shortCiteRegEx" : "Ghazvininejad et al\\.",
      "year" : 2018
    }, {
      "title" : "Neural message passing for quantum chemistry",
      "author" : [ "Justin Gilmer", "Samuel S. Schoenholz", "Patrick F. Riley", "Oriol Vinyals", "George E. Dahl." ],
      "venue" : "34th International Conference on Machine Learning, ICML 2017, 3:2053–2070.",
      "citeRegEx" : "Gilmer et al\\.,? 2017",
      "shortCiteRegEx" : "Gilmer et al\\.",
      "year" : 2017
    }, {
      "title" : "Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings",
      "author" : [ "He He", "Anusha Balakrishnan", "Mihail Eric", "Percy Liang." ],
      "venue" : "ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings",
      "citeRegEx" : "He et al\\.,? 2017",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2017
    }, {
      "title" : "Long Short-Term Memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural Computation, 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Gated graph sequence neural networks",
      "author" : [ "Yujia Li", "Richard Zemel", "Marc Brockschmidt", "Daniel Tarlow." ],
      "venue" : "4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings, (1):1–20.",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Rouge: A package for automatic evaluation of summaries",
      "author" : [ "C Y Lin." ],
      "venue" : "Proceedings of the workshop on text summarization branches out (WAS 2004).",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "A Knowledge Enhanced Generative Conversational Service Agent",
      "author" : [ "Yinong Long", "Jianan Wang", "Zhen Xu", "Zongsheng Wang", "Baoxun Wang", "Zhuoran Wang." ],
      "venue" : "DSTC6 Conference, pages 1–5.",
      "citeRegEx" : "Long et al\\.,? 2017",
      "shortCiteRegEx" : "Long et al\\.",
      "year" : 2017
    }, {
      "title" : "The Ubuntu Dialogue Corpus: A large dataset for research in unstructured multi-turn Dialogue systems",
      "author" : [ "Ryan Lowe", "Nissan Pow", "Iulian V. Serban", "Joelle Pineau." ],
      "venue" : "SIGDIAL 2015 - 16th Annual Meeting of the Special Interest Group on Discourse",
      "citeRegEx" : "Lowe et al\\.,? 2015",
      "shortCiteRegEx" : "Lowe et al\\.",
      "year" : 2015
    }, {
      "title" : "Key-value memory networks for directly reading documents",
      "author" : [ "Alexander H. Miller", "Adam Fisch", "Jesse Dodge", "Amir Hossein Karimi", "Antoine Bordes", "Jason Weston." ],
      "venue" : "EMNLP 2016 - Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Miller et al\\.,? 2016",
      "shortCiteRegEx" : "Miller et al\\.",
      "year" : 2016
    }, {
      "title" : "OpenDialKG: Explainable conversational reasoning with attention-based walks over knowledge graphs",
      "author" : [ "Seungwhan Moon", "Pararth Shah", "Anuj Kumar", "Rajen Subba." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Moon et al\\.,? 2019",
      "shortCiteRegEx" : "Moon et al\\.",
      "year" : 2019
    }, {
      "title" : "BLEU: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Acl, volume 371, pages 311–318, Morristown, NJ, USA. Association for Computational Linguistics.",
      "citeRegEx" : "Papineni et al\\.,? 2001",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2001
    }, {
      "title" : "Extending neural generative conversational model using external knowledge sources",
      "author" : [ "Prasanna Parthasarathi", "Joelle Pineau." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018, pages 690–",
      "citeRegEx" : "Parthasarathi and Pineau.,? 2020",
      "shortCiteRegEx" : "Parthasarathi and Pineau.",
      "year" : 2020
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "OpenAI Blog, 1(8):9.",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Unsupervised modeling of twitter conversations",
      "author" : [ "Alan Ritter", "Colin Cherry", "Bill Dolan." ],
      "venue" : "NAACL HLT 2010 - Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Ritter et al\\.,? 2010",
      "shortCiteRegEx" : "Ritter et al\\.",
      "year" : 2010
    }, {
      "title" : "Recipes for Building an Open-Domain Chatbot",
      "author" : [ "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Eric Michael Smith", "Y-Lan Boureau", "Jason Weston." ],
      "venue" : "Proceedings of the 16th Conference of",
      "citeRegEx" : "Roller et al\\.,? 2021",
      "shortCiteRegEx" : "Roller et al\\.",
      "year" : 2021
    }, {
      "title" : "Building end-To-end dialogue systems using generative hierarchical neural network models",
      "author" : [ "Iulian V. Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau." ],
      "venue" : "30th AAAI Conference on Artificial Intelligence, AAAI 2016, pages",
      "citeRegEx" : "Serban et al\\.,? 2016",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2016
    }, {
      "title" : "A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues",
      "author" : [ "Iulian Vlad Serban", "Alessandro Sordoni", "Laurent Charlin", "Joelle Pineau", "Aaron Courville", "Yoshua Bengio." ],
      "venue" : "Aaai2017, pages 3295–3301.",
      "citeRegEx" : "Serban et al\\.,? 2017",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2017
    }, {
      "title" : "A neural network approach to context-sensitive generation of conversational responses",
      "author" : [ "Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian Yun Nie", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "NAACL HLT 2015",
      "citeRegEx" : "Sordoni et al\\.,? 2015",
      "shortCiteRegEx" : "Sordoni et al\\.",
      "year" : 2015
    }, {
      "title" : "End-to-end memory networks",
      "author" : [ "Sainbayar Sukhbaatar", "Arthur Szlam", "Jason Weston", "Rob Fergus." ],
      "venue" : "Advances in Neural Information Processing Systems, 2015-Janua:2440–2448.",
      "citeRegEx" : "Sukhbaatar et al\\.,? 2015",
      "shortCiteRegEx" : "Sukhbaatar et al\\.",
      "year" : 2015
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems, 2017-Decem(Nips):5999–6009.",
      "citeRegEx" : "Kaiser and Polosukhin.,? 2017",
      "shortCiteRegEx" : "Kaiser and Polosukhin.",
      "year" : 2017
    }, {
      "title" : "Graph attention networks",
      "author" : [ "Petar Veličković", "Arantxa Casanova", "Pietro Liò", "Guillem Cucurull", "Adriana Romero", "Yoshua Bengio." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings, pages",
      "citeRegEx" : "Veličković et al\\.,? 2018",
      "shortCiteRegEx" : "Veličković et al\\.",
      "year" : 2018
    }, {
      "title" : "A Neural Conversational Model",
      "author" : [ "Oriol Vinyals", "Quoc Le." ],
      "venue" : "37.",
      "citeRegEx" : "Vinyals and Le.,? 2015",
      "shortCiteRegEx" : "Vinyals and Le.",
      "year" : 2015
    }, {
      "title" : "TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents",
      "author" : [ "Thomas Wolf", "Victor Sanh", "Julien Chaumond", "Clement Delangue." ],
      "venue" : "(ii).",
      "citeRegEx" : "Wolf et al\\.,? 2019",
      "shortCiteRegEx" : "Wolf et al\\.",
      "year" : 2019
    }, {
      "title" : "Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Yu Wu", "Wei Wu", "Chen Xing", "Zhoujun Li", "Ming Zhou." ],
      "venue" : "ACL 2017 - 55th Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Wu et al\\.,? 2017",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2017
    }, {
      "title" : "Multi-Graph Transformer for Free-Hand Sketch Recognition",
      "author" : [ "Peng Xu", "Chaitanya K. Joshi", "Xavier Bresson" ],
      "venue" : null,
      "citeRegEx" : "Xu et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2019
    }, {
      "title" : "Augmenting end-to-end dialogue systems with commonsense knowledge",
      "author" : [ "Tom Young", "Erik Cambria", "Iti Chaturvedi", "Hao Zhou", "Subham Biswas", "Minlie Huang." ],
      "venue" : "32nd AAAI Conference on Artificial Intelligence, AAAI 2018, pages 4970–4977.",
      "citeRegEx" : "Young et al\\.,? 2018",
      "shortCiteRegEx" : "Young et al\\.",
      "year" : 2018
    }, {
      "title" : "Personalizing dialogue agents: I have a dog, do you have pets too? ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics",
      "author" : [ "Saizheng Zhang", "Emily Dinan", "Jack Urbanek", "Arthur Szlam", "Douwe Kiela", "Jason Weston" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Table 8: Example of a dialogue from the series-enc-d1 model trained on KOMODIS",
      "author" : [ "Co-founded the ... in" ],
      "venue" : "Relevant utterance-context pairs are shown with gathered labels from our human evaluation.",
      "citeRegEx" : "in,? 1919",
      "shortCiteRegEx" : "in",
      "year" : 1919
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : ", 2017), recent language models such as BERT (Devlin et al., 2019) and GPT-2 (Radford et al.",
      "startOffset" : 45,
      "endOffset" : 66
    }, {
      "referenceID" : 23,
      "context" : ", 2019) and GPT-2 (Radford et al., 2019) enable neural conversational models to generate responses that appear human-like and engaging (Yu et al.",
      "startOffset" : 18,
      "endOffset" : 40
    }, {
      "referenceID" : 15,
      "context" : "A closer look, however, reveals that the lack of long-term memory to represent consistent (world) knowledge and personality over multiple speaker turns can lead to incoherent content being generated (Li et al., 2016; Serban et al., 2017).",
      "startOffset" : 199,
      "endOffset" : 237
    }, {
      "referenceID" : 27,
      "context" : "A closer look, however, reveals that the lack of long-term memory to represent consistent (world) knowledge and personality over multiple speaker turns can lead to incoherent content being generated (Li et al., 2016; Serban et al., 2017).",
      "startOffset" : 199,
      "endOffset" : 237
    }, {
      "referenceID" : 7,
      "context" : "†Corresponding author generation, resulting in first promising approaches using Transformer-based architectures (Dinan et al., 2019; Ghazvininejad et al., 2018; Galetzka et al., 2020).",
      "startOffset" : 112,
      "endOffset" : 183
    }, {
      "referenceID" : 11,
      "context" : "†Corresponding author generation, resulting in first promising approaches using Transformer-based architectures (Dinan et al., 2019; Ghazvininejad et al., 2018; Galetzka et al., 2020).",
      "startOffset" : 112,
      "endOffset" : 183
    }, {
      "referenceID" : 10,
      "context" : "†Corresponding author generation, resulting in first promising approaches using Transformer-based architectures (Dinan et al., 2019; Ghazvininejad et al., 2018; Galetzka et al., 2020).",
      "startOffset" : 112,
      "endOffset" : 183
    }, {
      "referenceID" : 3,
      "context" : "Space Efficient Context Encoding For our proposed encoding, we generate dialogue-specific local knowledge graphs (subgraphs of a background knowledge graph) that capture the information relevant to the dialogue (similar to (Chaudhuri et al., 2021)).",
      "startOffset" : 223,
      "endOffset" : 247
    }, {
      "referenceID" : 12,
      "context" : "This resembles the message-passing approach of graph neural networks (Gilmer et al., 2017).",
      "startOffset" : 69,
      "endOffset" : 90
    }, {
      "referenceID" : 31,
      "context" : "Transformers for natural language generation can be viewed as graph neural networks which use selfattention (Veličković et al., 2018) for neighborhood aggregation on fully-connected word graphs (Xu et al.",
      "startOffset" : 108,
      "endOffset" : 133
    }, {
      "referenceID" : 35,
      "context" : ", 2018) for neighborhood aggregation on fully-connected word graphs (Xu et al., 2019).",
      "startOffset" : 68,
      "endOffset" : 85
    }, {
      "referenceID" : 10,
      "context" : "Our comprehensive human evaluation with models trained with the publicly available datasets KOMODIS (Galetzka et al., 2020) and OPENDIALKG (Moon et al.",
      "startOffset" : 100,
      "endOffset" : 123
    }, {
      "referenceID" : 20,
      "context" : ", 2020) and OPENDIALKG (Moon et al., 2019), both providing dialogues enriched with structured knowledge, shows that we can reduce the space requirement for context without negative effects on the precision of reproduction of knowledge and perceived consistency.",
      "startOffset" : 23,
      "endOffset" : 42
    }, {
      "referenceID" : 18,
      "context" : "Neural conversational models can be categorized into retrieval-based approaches (Lowe et al., 2015; Wu et al., 2017) that choose a next utterance from a set of suitable candidates, and generative approaches (Serban et al.",
      "startOffset" : 80,
      "endOffset" : 116
    }, {
      "referenceID" : 34,
      "context" : "Neural conversational models can be categorized into retrieval-based approaches (Lowe et al., 2015; Wu et al., 2017) that choose a next utterance from a set of suitable candidates, and generative approaches (Serban et al.",
      "startOffset" : 80,
      "endOffset" : 116
    }, {
      "referenceID" : 26,
      "context" : ", 2017) that choose a next utterance from a set of suitable candidates, and generative approaches (Serban et al., 2016; Wolf et al., 2019; Chaudhuri et al., 2019; Roller et al., 2021) which decode the next utterance token by token out of a fixed vocabulary.",
      "startOffset" : 98,
      "endOffset" : 183
    }, {
      "referenceID" : 33,
      "context" : ", 2017) that choose a next utterance from a set of suitable candidates, and generative approaches (Serban et al., 2016; Wolf et al., 2019; Chaudhuri et al., 2019; Roller et al., 2021) which decode the next utterance token by token out of a fixed vocabulary.",
      "startOffset" : 98,
      "endOffset" : 183
    }, {
      "referenceID" : 2,
      "context" : ", 2017) that choose a next utterance from a set of suitable candidates, and generative approaches (Serban et al., 2016; Wolf et al., 2019; Chaudhuri et al., 2019; Roller et al., 2021) which decode the next utterance token by token out of a fixed vocabulary.",
      "startOffset" : 98,
      "endOffset" : 183
    }, {
      "referenceID" : 25,
      "context" : ", 2017) that choose a next utterance from a set of suitable candidates, and generative approaches (Serban et al., 2016; Wolf et al., 2019; Chaudhuri et al., 2019; Roller et al., 2021) which decode the next utterance token by token out of a fixed vocabulary.",
      "startOffset" : 98,
      "endOffset" : 183
    }, {
      "referenceID" : 14,
      "context" : "The architectures are based on recurrent neural networks such as LSTM (Hochreiter and Schmidhuber, 1997) or GRU (Cho et al.",
      "startOffset" : 70,
      "endOffset" : 104
    }, {
      "referenceID" : 4,
      "context" : "The architectures are based on recurrent neural networks such as LSTM (Hochreiter and Schmidhuber, 1997) or GRU (Cho et al., 2014) cells or self-attention layers (Vaswani et al.",
      "startOffset" : 112,
      "endOffset" : 130
    }, {
      "referenceID" : 36,
      "context" : "To integrate knowledge in addition to the dialogue history these models can be augmented by additional recurrent cells to encode the knowledge into a fixedsized vector representation (Young et al., 2018; Parthasarathi and Pineau, 2020; Ghazvininejad et al., 2018).",
      "startOffset" : 183,
      "endOffset" : 263
    }, {
      "referenceID" : 22,
      "context" : "To integrate knowledge in addition to the dialogue history these models can be augmented by additional recurrent cells to encode the knowledge into a fixedsized vector representation (Young et al., 2018; Parthasarathi and Pineau, 2020; Ghazvininejad et al., 2018).",
      "startOffset" : 183,
      "endOffset" : 263
    }, {
      "referenceID" : 11,
      "context" : "To integrate knowledge in addition to the dialogue history these models can be augmented by additional recurrent cells to encode the knowledge into a fixedsized vector representation (Young et al., 2018; Parthasarathi and Pineau, 2020; Ghazvininejad et al., 2018).",
      "startOffset" : 183,
      "endOffset" : 263
    }, {
      "referenceID" : 19,
      "context" : "This can be traced back to first endto-end approaches reading documents for questionanswering (Miller et al., 2016) or more general sequential data (Sukhbaatar et al.",
      "startOffset" : 94,
      "endOffset" : 115
    }, {
      "referenceID" : 29,
      "context" : ", 2016) or more general sequential data (Sukhbaatar et al., 2015).",
      "startOffset" : 40,
      "endOffset" : 65
    }, {
      "referenceID" : 37,
      "context" : "These models concatenate the additional context information as plain text to the input sequence (Zhang et al., 2018; Dinan et al., 2019; Galetzka et al., 2020).",
      "startOffset" : 96,
      "endOffset" : 159
    }, {
      "referenceID" : 7,
      "context" : "These models concatenate the additional context information as plain text to the input sequence (Zhang et al., 2018; Dinan et al., 2019; Galetzka et al., 2020).",
      "startOffset" : 96,
      "endOffset" : 159
    }, {
      "referenceID" : 10,
      "context" : "These models concatenate the additional context information as plain text to the input sequence (Zhang et al., 2018; Dinan et al., 2019; Galetzka et al., 2020).",
      "startOffset" : 96,
      "endOffset" : 159
    }, {
      "referenceID" : 32,
      "context" : "logue datasets, with Open-Subtitles (Vinyals and Le, 2015) and Twitter-Corpus (Sordoni et al.",
      "startOffset" : 36,
      "endOffset" : 58
    }, {
      "referenceID" : 28,
      "context" : "logue datasets, with Open-Subtitles (Vinyals and Le, 2015) and Twitter-Corpus (Sordoni et al., 2015) being some popular examples (see also (Ritter et al.",
      "startOffset" : 78,
      "endOffset" : 100
    }, {
      "referenceID" : 24,
      "context" : ", 2015) being some popular examples (see also (Ritter et al., 2010; Duplessis et al., 2016)).",
      "startOffset" : 46,
      "endOffset" : 91
    }, {
      "referenceID" : 8,
      "context" : ", 2015) being some popular examples (see also (Ritter et al., 2010; Duplessis et al., 2016)).",
      "startOffset" : 46,
      "endOffset" : 91
    }, {
      "referenceID" : 37,
      "context" : "The PERSONA-CHAT dataset (Zhang et al., 2018) contains over 10k dialogues that are conditioned on profile information (personas), which ranges from hobbies or favorite food to family background.",
      "startOffset" : 25,
      "endOffset" : 45
    }, {
      "referenceID" : 10,
      "context" : "KOMODIS (Galetzka et al., 2020) is a closeddomain dataset with dialogues between human participants that were tasked to chit-chat about one given movie and use provided information about it.",
      "startOffset" : 8,
      "endOffset" : 31
    }, {
      "referenceID" : 20,
      "context" : "OpenDialKG (Moon et al., 2019) is an opendomain dataset containing 15K dialogues, which were collected in a Wizard-of-Oz setup, by connecting two human participants that were tasked to have an engaging dialogue about a given topic.",
      "startOffset" : 11,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : "Each dialogue is paired with its corresponding “KG paths” from Freebase (Bollacker et al., 2007) (connecting entities and relations mentioned in the dialogue).",
      "startOffset" : 72,
      "endOffset" : 96
    }, {
      "referenceID" : 10,
      "context" : "Similar to our previous approach (Galetzka et al., 2020) and Wolf et al.",
      "startOffset" : 33,
      "endOffset" : 56
    }, {
      "referenceID" : 9,
      "context" : "Equation 1 is similar to message-passing algorithms (Duvenaud et al., 2015; Li et al., 2016; Gilmer et al., 2017), where a new hidden state for a graph node is computed by an arbitrary function of all previous hidden states of connected nodes.",
      "startOffset" : 52,
      "endOffset" : 113
    }, {
      "referenceID" : 15,
      "context" : "Equation 1 is similar to message-passing algorithms (Duvenaud et al., 2015; Li et al., 2016; Gilmer et al., 2017), where a new hidden state for a graph node is computed by an arbitrary function of all previous hidden states of connected nodes.",
      "startOffset" : 52,
      "endOffset" : 113
    }, {
      "referenceID" : 12,
      "context" : "Equation 1 is similar to message-passing algorithms (Duvenaud et al., 2015; Li et al., 2016; Gilmer et al., 2017), where a new hidden state for a graph node is computed by an arbitrary function of all previous hidden states of connected nodes.",
      "startOffset" : 52,
      "endOffset" : 113
    }, {
      "referenceID" : 16,
      "context" : "Commonly used word-overlap metrics, such as ROUGE-N/ROUGE-L (Lin, 2004), or BLEU (Papineni et al.",
      "startOffset" : 60,
      "endOffset" : 71
    }, {
      "referenceID" : 21,
      "context" : "Commonly used word-overlap metrics, such as ROUGE-N/ROUGE-L (Lin, 2004), or BLEU (Papineni et al., 2001), aren’t capable of measuring these.",
      "startOffset" : 81,
      "endOffset" : 104
    } ],
    "year" : 2021,
    "abstractText" : "To improve the coherence and knowledge retrieval capabilities of non-task-oriented dialogue systems, recent Transformer-based models aim to integrate fixed background context. This often comes in the form of knowledge graphs, and the integration is done by creating pseudo utterances through paraphrasing knowledge triples, added into the accumulated dialogue context. However, the context length is fixed in these architectures, which restricts how much background or dialogue context can be kept. In this work, we propose a more concise encoding for background context structured in the form of knowledge graphs, by expressing the graph connections through restrictions on the attention weights. The results of our human evaluation show that this encoding reduces space requirements without negative effects on the precision of reproduction of knowledge and perceived consistency. Further, models trained with our proposed context encoding generate dialogues that are judged to be more comprehensive and interesting.",
    "creator" : "LaTeX with hyperref"
  }
}