{
  "name" : "2021.acl-long.464.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "PHMOSpell: Phonological and Morphological Knowledge Guided Chinese Spelling Check",
    "authors" : [ "Li Huang", "Junjie Li", "Weiwei Jiang", "Zhiyu Zhang", "Minchuan Chen", "Shaojun Wang", "Jing Xiao" ],
    "emails" : [ "lhuang9703@gmail.com,", "junjielee815@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5958–5967\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n5958"
    }, {
      "heading" : "1 Introduction",
      "text" : "Chinese Spelling Check (CSC) is a fundamental task in Chinese Natural Language Processing (NLP), which aims to automatically detect and correct spelling errors in Chinese sentences. These errors typically consist of human writing errors and machine recognition errors by automatic speech recognition (ASR) or optical character recognition (OCR) systems (Yu et al., 2014). CSC serves as a preliminary component for other downstream tasks like information retrieval (IR) in search engine, thus significantly affects the final performance of these tasks.\nChinese is an ideograph language which contains numerous characters and has no between-word delimiters. These characteristics make its spelling check more difficult than other alphabetical languages such as English. Specifically, for error\ndetection, Chinese words usually consist of several characters and have no clear word boundaries, which makes it impossible to detect spelling errors just using individual word or character. They must be put in a specific sentence to capture contextual semantic information. For error correction, how to select correct candidates from tremendous character sets remains a great challenge. In contrast to English words that are composed of a small set of alphabet letters, there are more than 10k Chinese characters, and 3.5k of them are frequently used (Wang et al., 2019b). Besides, unlike English, almost all Chinese spelling errors are real-word errors which means the misspelling one is also a valid character in the vocabulary. (Kukich, 1992; Jia et al., 2013; Yu and Li, 2014).\nSince a great number of Chinese characters are similar either in phonology or morphology, they are easily misused with each other. According to (Liu et al., 2011), 76% of Chinese spelling errors belong to phonological similarity error and 46% belong to visual similarity error. Table 1 presents examples of these two common errors. The pronunciation and the shape of Chinese characters can be characterized by pinyin1 and radicals2, respectively.\n1pinyin is the official phonetic system of Mandarin Chinese, which usually consists of three parts: initials, finals and tones.\n2radical is the basic building blocks of all Chinese charac-\nPrevious methods have made attempts to fuse these two information into the process of CSC (Jin et al., 2014; Han et al., 2019; Hong et al., 2019; Nguyen et al., 2020). However, pinyin or radicals in these methods were used as external resources or heuristic filters and can not be trained with the model in an end-to-end style. More recently, Cheng et al. (2020) proposed SpellGCN, which incorporated phonological and morphological similarities into a pre-trained language model by graph convolutional network (GCN). However, their similarity graphs relied on specific confusion sets. Since confusion sets are unable to cover all characters, SpellGCN can only fuse limited information. Furthermore, they just used a simple aggregate strategy for feature fusion.\nTo tackle the above issues, we propose a novel framework called PHMOSpell. PHMOSpell incorporates pinyin and glyph features into a pre-trained language model via an adaptive gating module for CSC. These features are derived from intermediate representations of dominant Tacotron2 (Shen et al., 2018) in text-to-speech (TTS) task and VGG19 (Simonyan and Zisserman, 2014) in computer vision (CV) task. We combine them with semantic representation from a pre-trained language model by the proposed adaptive gating module, enabling the model to be trained end-to-end. Comprehensive experiments are conducted on three shared benchmarks to prove that latent representations in our method can capture not only semantic but also phonological and morphological information. Experimental results demonstrate that our method outperforms all baseline methods on three benchmarks.\nThe contributions of this paper are in three folds: 1) We derive both phonological and morphological knowledge of Chinese characters from multimodality and apply them to CSC. 2) We design a novel adaptive gating mechanism, which effectively incorporates the multi-modal information into a pre-trained language model in an end-to-end trainable way. 3) We achieve state-of-the-art performance on three benchmark datasets using the proposed model."
    }, {
      "heading" : "2 Related Work",
      "text" : "CSC has received active research in recent years. Previous studies on CSC can be divided into three categories: rule based methods, statistical based\nters, there are about 216 different radicals in Chinese.\nmethods and deep learning based methods. Mangu and Brill (1997) proposed a rule based approach for automatically acquiring linguistic knowledge from a small set of easily understood rules. Jiang et al. (2012) arranged a new grammar system of rules to solve both Chinese grammar errors and spelling errors. Xiong et al. (2015)’s HANSpeller was based on an extended HMM, ranker based models and a rule based model. For statistical based methods, Noisy Channel Model (Brill and Moore, 2000, 2008; Chiu et al., 2014; Noaman et al., 2016; Bao et al., 2020) is the most widely used model. Statistical based methods usually narrowed the candidates choice by utilizing a predefined confusion set (Chen et al., 2013; Hsieh et al., 2013; Wang et al., 2019a), which contains a set of similar character pairs. These similar characters were used to replace each other and language models were leveraged to measure the quality of the modified sentences (Liu et al., 2013; Yu and Li, 2014; Xie et al., 2015). More recently, deep learning has achieved excellent results on many NLP tasks, including CSC. Wang et al. (2019a) proposed an end-toend confusionset-guided encoder-decoder model, which treated CSC as a sequence-to-sequence task and infused confusion sets information by copy mechanism. FASpell (Hong et al., 2019) employed BERT (Devlin et al., 2019) as a denoising autoencoder (DAE) for CSC. SpellGCN (Cheng et al., 2020) constructed two similarity graphs over the characters in confusion sets and employed graph convolutional network on these two graphs to capture the pronunciation/shape similarities between characters. Soft-Masked BERT (Zhang et al., 2020) was proposed to combine a Bi-GRU based detection network and a BERT based correction network, where the former passed its prediction results to the latter using soft masking mechanism. Nguyen et al. (2020) applied TreeLSTM (Tai et al., 2015; Zhu et al., 2015) on the tree structure of the character radicals to get hierarchical character embeddings, which was used as an adaptable filtering component for candidates selection."
    }, {
      "heading" : "3 Approach",
      "text" : ""
    }, {
      "heading" : "3.1 Problem Formulation",
      "text" : "Generally, CSC can be regarded as a revision task on Chinese sentences. Given a Chinese sentence X = {x1, x2, ..., xn} of length n, the model needs to detect spelling errors on character level and output its correct corresponding sentence Y =\n{y1, y2, ..., yn}. Although CSC can be viewed as a kind of sequence-to-sequence (Seq2Seq) task, it is different from other Seq2Seq tasks (e.g., Text Summarization, Machine Translation): the input and output sequences of the former are equal in length. Most or even all of the characters in the input sequence remain unchanged, only a few of them need to be corrected."
    }, {
      "heading" : "3.2 Model",
      "text" : "Our model consists of three feature extractor modules and an adaptive gating module used to fuse kinds of features. Figure 1 illustrates the architecture of our model. Given a sentence, our model firstly extracts pinyin feature, glyph feature and context-sensitive semantic feature for every character, then integrates three features by the adaptive gating module. Finally, the integrated representation of each character is fed into a fully-connected layer to calculate the probabilities over the whole vocabulary, where the character with the highest probability is picked as the substitute.\nIn the following subsections, we will elaborate the implementation of each module."
    }, {
      "heading" : "3.3 Pinyin Feature Extractor",
      "text" : "Neural TTS models, like Tacotron2 (Shen et al., 2018), have achieved high-quality performance in producing natural-sounding synthetic speech. We propose to generate the phonological representations of Chinese characters through a TTS model\nso that CSC can benefit from realistic pronunciation similarities between characters. In this paper, we leverage Tacotron2, a recurrent sequenceto-sequence mel spectrograms prediction network, to help modeling the phonological representations since its location-sensitive attention can create effective time alignment between the character sequence and the acoustic sequence. When training a Chinese TTS system with Tacotron2, characters are first converted to pinyin sequence as phoneme form. Then the sequence is represented by the encoder using an embedding layer and the hidden representations are consumed by the decoder to predict a corresponding mel spectrogram one frame at a time. Motivated by this, we train Tacotron2 separately using public Chinese female voice datasets 3 with teacher forcing. During training, we utilize pinyin transcription and mel spectrograms as input to help modeling pinyin representations. Then we extract pinyin embedding layer of the encoder as our pinyin feature extractor to generate the phonological representations for CSC. When given a Chinese sentence X, our model first converts it to a pinyin sequence using pypinyin4. Then dense feature for pinyin sequence Fp = {fp1 , f p 2 , ..., f p n} can be obtained by using pinyin feature extractor as a lookup table, where fpi ∈ Rdp and dp is the dimen-\n3https://test.data-baker.com/#/data/ index/source\n4https://github.com/mozillazg/ python-pinyin\nsion of the pinyin feature."
    }, {
      "heading" : "3.4 Glyph Feature Extractor",
      "text" : "As Chinese characters are composed of graphical components, it is intuitive that the representations for Chinese characters could benefit from the spatial layout of these components. Motivated by Meng et al. (2019) and Sehanobish and Song (2019)’s exploration on using glyph images for Chinese named entity recognition (NER) and Chinese word segmentation (CWS), we employ a glyph feature extractor to extract glyph features for Chinese characters. We make use of 8106 Chinese glyph images released by (Sehanobish and Song, 2019). To take advantage of powerful pre-trained models and avoid training from scratch, VGG19 (Simonyan and Zisserman, 2014) pretrained on ImageNet is adopted as the backbone of the glyph feature extractor. Following (Meng et al., 2019), we further finetune it with the objective of recovering the identifiers from glyph images to solve the problem of domain adaptation. After that, we drop the last classification layer and use the outputs of VGG19’s last max pooling layer as glyph features. For a given sentence X, our glyph feature extractor is able to first retrieve images for its characters and then generate glyph features: Fg = {fg1 , f g 2 , ..., f g n}, where fgi ∈ Rdg is the glyph feature of the ith character xi and dg is the dimension of the glyph feature."
    }, {
      "heading" : "3.5 Semantic Feature Extractor",
      "text" : "Beyond the phonological and the morphological information, we adopt empirically dominant pretrained language model to capture semantic information from context. Following (Hong et al., 2019; Cheng et al., 2020; Zhang et al., 2020), BERT is employed as the backbone of our semantic feature extractor. Given an input sentence X, the extractor outputs hidden states Fs = {f s1 , f s2 , ..., f sn} at the final layer of BERT as semantic features, where f si ∈ Rds and ds is the dimension of the semantic feature."
    }, {
      "heading" : "3.6 Adaptive Gating",
      "text" : "Most previous methods for CSC simply used addition or concatenation to fuse different features. However, these fusion strategies ignore the relationship between the features. To tackle this issue, we propose an innovative adaptive gating mechanism served like a gate to finely control the fusion of\nfeatures. It is defined as follows:\nAG(Fp,Fs) = σ(FpWp + bp) · Fs (1)\nAG(Fg,Fs) = σ(FgWg + bg) · Fs (2)\nwhere Wp ∈ Rdp×ds ,bp ∈ Rn×ds ,Wg ∈ Rdg×ds ,bg ∈ Rn×ds are parameters to be learned. σ is a nonlinear activation function, which is a ReLU function in our implementation. “·” represents element-wise multiplication. We employ the proposed gating mechanism to control how much information in pinyin and glyph features is fused with semantic feature and transferred to the next classifier module. The enriched feature Fe ∈ Rn×ds is calculated as follows:\nFe = λp ·AG(Fp,Fs) + λg ·AG(Fg,Fs) (3)\nwhere λp + λg = 1 are coefficients. Finally, we add residual connection to Fe and Fs by linear combination:\nFes = Fe + Fs (4)"
    }, {
      "heading" : "3.7 Training",
      "text" : "During the training process, the representation Fes is fed into a fully-connected layer for the final classification, which is defined as follows:\nP (Yp|X) = softmax(FesWfc + bfc) (5)\nwhere Wfc ∈ Rds×V ,bfc ∈ Rn×V are learnable parameters for the fully-connected layer, V is the size of the vocabulary and Yp is the predicted sentence given the erroneous sentence X.\nThe goal of training the model is to match the predicted sequence Yp and the ground truth sequence Yg. Overall, the learning process is driven by minimizing negative log-likelihood of the characters:\nL = − n∑\ni=1\nlogP (ŷi = yi|X) (6)\nwhere ŷi, yi are the ith characters of Yp and Yg, respectively."
    }, {
      "heading" : "3.8 Inference",
      "text" : "At inference time, we select candidates with the highest probability given by the model for each character’s correction. As for detection task, it is accomplished by checking whether the picked candidate is different with the input character."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "To investigate the effectiveness of our proposed method, we conduct extensive experiments on three shared benchmark datasets for CSC task. Specifically, we make use of training datasets from SIGHAN13 (Wu et al., 2013), SIGHAN14 (Yu et al., 2014) and SIGHAN15 (Tseng et al., 2015). We also include 271K training samples automatically generated by OCR-based and ASRbased methods (Wang et al., 2018) as in (Cheng et al., 2020; Nguyen et al., 2020). We employ test datasets of SIGHAN13, SIGHAN14, SIGHAN15 for evaluation. Following the same data preprocessing procedure with (Cheng et al., 2020; Nguyen et al., 2020), characters in all SIGHAN datasets are converted to simplified form using OpenCC5. We adopt SIGHAN’s standard split of training and test data. The detailed statistic of the data is presented in Table 2."
    }, {
      "heading" : "4.2 Baseline Methods",
      "text" : "We compare our method against several advanced methods proposed recently to investigate the potential of our framework. They are listed below:\n• FASPell (Hong et al., 2019): This method employs BERT as a denoising autoencoder to generate candidates for wrong characters and filters the visually/phonologically irrelevant candidates by a confidence-similarity decoder.\n• SpellGCN (Cheng et al., 2020): This method learns the pronunciation/shape relationship between the characters by applying graph convolutional network on two similarity graphs. It predicts candidates for corrections by combining graph representations with semantic representations from BERT.\n5https://github.com/BYVoid/OpenCC\n• HeadFilt (Nguyen et al., 2020): This method uses adaptable filter learned from hierarchical character embeddings to estimate the similarity between characters and filter candidates produced by BERT.\n• BERT: This method finetunes BERT with the training data and selects the character with the highest probability for correction."
    }, {
      "heading" : "4.3 Evaluation Metrics",
      "text" : "We adopt sentence-level metrics for evaluation, which are widely used in previous methods for CSC task. Sentence-level metrics are stricter than character-level metrics since all errors in a sentence need to be detected and corrected. Metrics including accuracy, precision, recall and F1 score are calculated for errors detection and correction, respectively."
    }, {
      "heading" : "4.4 Experimental Setup",
      "text" : "Our model is implemented based on huggingface’s pytorch implementation of transformers6. We initialize weights of the semantic feature extractor using bert-base-chinese and weights of the glyph feature extractor using pretrained VGG19 from torchvision library7. Weights of the adaptive gating are randomly initialized. We train our model using AdamW optimizer for 5 epochs with learning rate 1e−4. Batch size is 64 for training and 32 for evaluation. Best λp, λg are 0.6, 0.4 for SIGHAN13, 0.8, 0.2 for SIGHAN14 and SIGHAN15. We train Tacotron2 using its open-source implementation8 for 130k steps with default parameters, except the decay step is set to 15000. The number of our pinyin is 1920 and the dimension of the pinyin feature is 512. Characters are written using Hei Ti font9 in 8106 glyph images. We finetune VGG19 on glyph images for 50 epochs with a batch size 32 and a learning rate 5e−4. The dimension of the glyph feature is 25088. All experiments are conducted on 2 Tesla V100 with 16G memory."
    }, {
      "heading" : "4.5 Main Results",
      "text" : "Table 3 presents the results of all methods on three test datasets. Our method outperforms all previous\n6https://github.com/huggingface/ transformers\n7https://github.com/pytorch/vision 8https://github.com/Rayhane-mamah/\nTacotron-2 9Hei Ti font is a very formal sans serif font for Chinese writing.\nmethods and achieves new state-of-the-art performance on all three datasets. Compared with the best baseline method (HeadFilt), the improvements of our method are 1.0%, 5.0%, 2.9% on detectionlevel F1 and 0.5%, 3.7%, 1.6% on correction-level F1 respectively, which verifies the effectiveness of our method.\nWe observe that our method substantially outperforms SpellGCN on the precision and F1 scores, which indicates that our method is superior to SpellGCN in fusing similarity knowledge. Although SpellGCN incorporates such knowledge, it relies on a predefined confusion set, which limits its generalization. Firstly, similarity knowledge cannot be obtained adequately since the confusion set is limited and unable to cover all characters. Secondly, the confusion set is manually constructed and has no golden-standard, which may bring about cascading errors. Our method achieves better F1 scores than HeadFilt, apparently because HeadFilt only leverages morphological knowledge in its post-filtering component. Finally, our method consistently beats vanilla BERT on all three datasets in terms of all metrics, which demonstrates the importance of incorporating the phonological and morphological knowledge into the semantic space for the CSC task."
    }, {
      "heading" : "4.6 Ablation Study",
      "text" : "To study the effectiveness of each component in our method, we carry out ablation tests on three datasets. All ablation experiments with pinyin and\nglyph features are conducted using equal weights for pinyin feature and glyph feature (λp = λg) to avoid unnecessary biases they bring. Table 4 presents the results. First, replacing adaptive gating with a simple aggregate strategy leads to worse performance for both detection and correction, which demonstrates the benefit of using adaptive gating. We then remove pinyin feature extractor or glyph feature extractor from the model. The performance degrades more when removing pinyin feature compared with removing glyph feature, which implies that phonological information is more crucial for CSC. This is consistent with the finding that most Chinese spelling errors are caused by phonological similarity (Liu et al., 2011). The result further degrades when removing both features and adaptive gating module, and this trend intuitively indicates that both phonological and morphological information contribute to the final performance."
    }, {
      "heading" : "4.7 Effect of Hyper Parameters",
      "text" : "In this subsection, we conduct experiments to analyze the effect of weights of features and the dimension of the pinyin feature.\nFigure 2 shows how different weights influence the performance of the model. In this comparison, the value of λp (λg) changes from 0.0 (1.0) to 1.0 (0.0) with the gap of 0.2. We plot the detection-level and correction-level F1 scores on three datasets in Figure 2. The results consistently show that our model performs better when λp is set larger (e.g., 0.6 for SIGHAN13, 0.8 for\nSIGHAN14, SIGHAN15), which means a higher weight on pinyin feature. Moreover, all of them outperform the model without any features.\nPrevious ablation tests show that the pinyin feature has more influence on the performance than the glyph feature. We further perform experiments by varying the dimension of the pinyin feature since it directly impacts the quality of the feature. Figure 3 shows larger dimensions perform better. However, it should be noted that the performance degrades when the dimension is larger than 512. This is reasonable due to the bias-variance phenomenon explained in (Yin and Shen, 2018). Feature with a small dimensionality can not capture all possible pinyin relations (high bias). On the other hand, fea-\nture with a large dimensionality includes too much noise (high variance). One must make a trade-off in dimensionality selection for high-quality features."
    }, {
      "heading" : "4.8 Features Visualization",
      "text" : "To understand the effectiveness of our features more intuitively, we reduce features from highdimensional space to low-dimensional space and visualize some of them using t-SNE (Van der Maaten and Hinton, 2008).\nFigure 4 illustrates the embeddings of pinyin whose initial begins with “d”, “f”, “h” and “j”. One can find from the figure that embeddings form several clusters based on their pronunciations. Pinyin embeddings with more similar pronunciations (eg. “fu4” and “hu2”) are closer in distance than dissim-\nilar ones (eg. “hu2” and “dao4”). This suggests that the model has learned alignment between the pinyin feature and the realistic acoustic feature. We also plot glyph embeddings of characters with radical “口”, “土” at left side and characters with radical “口” at outside in Figure 5. They show the same trends as that of pinyin embeddings. Above all, this further verifies the effectiveness of both phonological and morphological knowledge derived from multi-modality."
    }, {
      "heading" : "4.9 Discussion",
      "text" : "To demonstrate how our model can handle phonological and visual errors, we showcase some representative cases from the test datasets. For instance, for the erroneous sentence “...不惜娱(pinyin: yu2) 弄大臣...”, vanilla BERT corrects “娱弄” as “玩(pinyin: wan2) 弄 (play)” without considering phonological information, which is only semantically reasonable. Our model, however, takes both semantic and phonological knowledge into consideration and successfully generates a more proper correction “...不惜愚(pinyin: yu2) 弄大 臣... (...Not hesitate to fool the minister...)”. Another case is “...那别人的欢(radicals: 又,欠) 说\n是没办法改变你的...”. Our model is capable of modifying it into correct sentence “...那 别人的劝(radicals: 又,力) 说是没办法改变 你的...(...The persuasion of others can’t change you...)” under morphological constraint, whereas vanilla BERT produces an inferior correction “小(radicals: 小)说 (fiction)”.\nWe also manually analyze the error cases of our model on the test datasets and find there are two common types of errors. One type is continuous errors, where several continuous characters in a sentence are wrong. For example, in sentence “...他 们有时候，有一点捞到...”, “捞到(Caught)” are continuous errors, which should be “唠叨” (The correct sentence means ’Sometimes they are a little nagging’). The model fails to correct such continuous errors since the meaning of the whole sentence is more disturbed. Correcting another type of errors requires strong external knowledge. For instance, “心智 (mind)” in poem “...天将降大任于 斯人也，必先苦其心智，劳其筋骨... (...When Heaven is going to give a great responsibility to someone, it will first fill his mind with suffering, toil his sinews and bones...)” is erroneous but semantic plausible in Chinese. The model is still unable to correct it into “心志 (mind)” since the model lacks knowledge of poem."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this research, we propose a novel end-to-end trainable model called PHMOSpell for CSC, which incorporates both phonological and morphological knowledge from two feature extractors into a pretrained language model by an effective adaptive gating mechanism. Extensive experiments and empirical comparisons show that PHMOSpell achieves state-of-the-art results on three widely used benchmarks for CSC, demonstrating the effectiveness of the proposed method.\nWe remain extending the multi-modal knowledge to other NLP tasks (e.g., grammar error correction) as our future work. Another fruitful future work is exploring the integration of external knowledge so that the model can deal with errors in poems, proverbs, etc."
    } ],
    "references" : [ {
      "title" : "Chunk-based chinese spelling check with global optimization",
      "author" : [ "Zuyi Bao", "Chen Li", "Rui Wang." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical",
      "citeRegEx" : "Bao et al\\.,? 2020",
      "shortCiteRegEx" : "Bao et al\\.",
      "year" : 2020
    }, {
      "title" : "Spell checker with arbitrary length string-to-string transformations to improve noisy channel spelling correction",
      "author" : [ "Eric Brill", "Robert Moore." ],
      "venue" : "US Patent 7,366,983.",
      "citeRegEx" : "Brill and Moore.,? 2008",
      "shortCiteRegEx" : "Brill and Moore.",
      "year" : 2008
    }, {
      "title" : "An improved error model for noisy channel spelling correction",
      "author" : [ "Eric Brill", "Robert C Moore." ],
      "venue" : "Proceedings of the 38th annual meeting of the association for computational linguistics, pages 286– 293.",
      "citeRegEx" : "Brill and Moore.,? 2000",
      "shortCiteRegEx" : "Brill and Moore.",
      "year" : 2000
    }, {
      "title" : "A study of language modeling for chinese spelling check",
      "author" : [ "Kuan-Yu Chen", "Hung-Shin Lee", "Chung-Han Lee", "HsinMin Wang", "Hsin-Hsi Chen." ],
      "venue" : "Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 79–83.",
      "citeRegEx" : "Chen et al\\.,? 2013",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2013
    }, {
      "title" : "Spellgcn: Incorporating phonological and visual similarities into language models for chinese spelling check",
      "author" : [ "Xingyi Cheng", "Weidi Xu", "Kunlong Chen", "Shaohua Jiang", "Feng Wang", "Taifeng Wang", "Wei Chu", "Yuan Qi." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Cheng et al\\.,? 2020",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 2020
    }, {
      "title" : "Chinese spell checking based on noisy channel model",
      "author" : [ "Hsun-Wen Chiu", "Jian-Cheng Wu", "Jason S Chang." ],
      "venue" : "Proceedings of The Third CIPSSIGHAN Joint Conference on Chinese Language Processing, pages 202–209.",
      "citeRegEx" : "Chiu et al\\.,? 2014",
      "shortCiteRegEx" : "Chiu et al\\.",
      "year" : 2014
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Chinese spelling check based on sequence labeling",
      "author" : [ "Zijia Han", "Chengguo Lv", "Qiansheng Wang", "Guohong Fu." ],
      "venue" : "2019 International Conference on Asian Language Processing (IALP), pages 373– 378. IEEE.",
      "citeRegEx" : "Han et al\\.,? 2019",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2019
    }, {
      "title" : "Faspell: A fast, adaptable, simple, powerful chinese spell checker based on daedecoder paradigm",
      "author" : [ "Yuzhong Hong", "Xianguo Yu", "Neng He", "Nan Liu", "Junhui Liu." ],
      "venue" : "Proceedings of the 5th Workshop on Noisy User-generated Text (W-NUT 2019),",
      "citeRegEx" : "Hong et al\\.,? 2019",
      "shortCiteRegEx" : "Hong et al\\.",
      "year" : 2019
    }, {
      "title" : "Introduction to ckip chinese spelling check system for sighan bakeoff 2013 evaluation",
      "author" : [ "Yu-Ming Hsieh", "Ming-Hong Bai", "Keh-Jiann Chen." ],
      "venue" : "Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 59–63.",
      "citeRegEx" : "Hsieh et al\\.,? 2013",
      "shortCiteRegEx" : "Hsieh et al\\.",
      "year" : 2013
    }, {
      "title" : "Graph model for chinese spell checking",
      "author" : [ "Zhongye Jia", "Peilu Wang", "Hai Zhao." ],
      "venue" : "Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 88–92.",
      "citeRegEx" : "Jia et al\\.,? 2013",
      "shortCiteRegEx" : "Jia et al\\.",
      "year" : 2013
    }, {
      "title" : "A rule based chinese spelling and grammar detection system utility",
      "author" : [ "Ying Jiang", "Tong Wang", "Tao Lin", "Fangjie Wang", "Wenting Cheng", "Xiaofei Liu", "Chenghui Wang", "Weijian Zhang." ],
      "venue" : "2012 International Conference on System Science and Engineer-",
      "citeRegEx" : "Jiang et al\\.,? 2012",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2012
    }, {
      "title" : "Integrating pinyin to improve spelling errors detection for chinese language",
      "author" : [ "Peng Jin", "Xingyuan Chen", "Zhaoyi Guo", "Pengyuan Liu." ],
      "venue" : "2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Tech-",
      "citeRegEx" : "Jin et al\\.,? 2014",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2014
    }, {
      "title" : "Techniques for automatically correcting words in text",
      "author" : [ "Karen Kukich." ],
      "venue" : "Acm Computing Surveys (CSUR), 24(4):377–439.",
      "citeRegEx" : "Kukich.,? 1992",
      "shortCiteRegEx" : "Kukich.",
      "year" : 1992
    }, {
      "title" : "Visually and phonologically similar characters in incorrect chinese words: Analyses, identification, and applications",
      "author" : [ "C-L Liu", "M-H Lai", "K-W Tien", "Y-H Chuang", "S-H Wu", "C-Y Lee." ],
      "venue" : "ACM Transactions on Asian Language Information Processing",
      "citeRegEx" : "Liu et al\\.,? 2011",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2011
    }, {
      "title" : "A hybrid chinese spelling correction using language model and statistical machine translation with reranking",
      "author" : [ "Xiaodong Liu", "Kevin Cheng", "Yanyan Luo", "Kevin Duh", "Yuji Matsumoto." ],
      "venue" : "Proceedings of the Seventh SIGHAN Workshop on Chinese",
      "citeRegEx" : "Liu et al\\.,? 2013",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2013
    }, {
      "title" : "Visualizing data using t-sne",
      "author" : [ "Laurens Van der Maaten", "Geoffrey Hinton." ],
      "venue" : "Journal of machine learning research, 9(11).",
      "citeRegEx" : "Maaten and Hinton.,? 2008",
      "shortCiteRegEx" : "Maaten and Hinton.",
      "year" : 2008
    }, {
      "title" : "Automatic rule acquisition for spelling correction",
      "author" : [ "Lidia Mangu", "Eric Brill." ],
      "venue" : "ICML, volume 97, pages 187–194. Citeseer.",
      "citeRegEx" : "Mangu and Brill.,? 1997",
      "shortCiteRegEx" : "Mangu and Brill.",
      "year" : 1997
    }, {
      "title" : "Glyce: Glyph-vectors for chinese character representations",
      "author" : [ "Yuxian Meng", "Wei Wu", "Fei Wang", "Xiaoya Li", "Ping Nie", "Fan Yin", "Muyu Li", "Qinghong Han", "Xiaofei Sun", "Jiwei Li." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 2746–2757.",
      "citeRegEx" : "Meng et al\\.,? 2019",
      "shortCiteRegEx" : "Meng et al\\.",
      "year" : 2019
    }, {
      "title" : "Adaptable filtering using hierarchical embeddings for chinese spell check",
      "author" : [ "Minh Nguyen", "Gia H Ngo", "Nancy F Chen." ],
      "venue" : "arXiv preprint arXiv:2008.12281.",
      "citeRegEx" : "Nguyen et al\\.,? 2020",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2020
    }, {
      "title" : "Automatic arabic spelling errors detection and correction based on confusion matrixnoisy channel hybrid system",
      "author" : [ "Hatem M Noaman", "Shahenda S Sarhan", "M Rashwan." ],
      "venue" : "Egypt Comput Sci J, 40(2):2016.",
      "citeRegEx" : "Noaman et al\\.,? 2016",
      "shortCiteRegEx" : "Noaman et al\\.",
      "year" : 2016
    }, {
      "title" : "Using chinese glyphs for named entity recognition",
      "author" : [ "Arijit Sehanobish", "Chan Hee Song." ],
      "venue" : "arXiv preprint arXiv:1909.09922.",
      "citeRegEx" : "Sehanobish and Song.,? 2019",
      "shortCiteRegEx" : "Sehanobish and Song.",
      "year" : 2019
    }, {
      "title" : "Natural tts synthesis by conditioning wavenet on mel spectrogram predictions",
      "author" : [ "Jonathan Shen", "Ruoming Pang", "Ron J Weiss", "Mike Schuster", "Navdeep Jaitly", "Zongheng Yang", "Zhifeng Chen", "Yu Zhang", "Yuxuan Wang", "Rj Skerrv-Ryan" ],
      "venue" : null,
      "citeRegEx" : "Shen et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2018
    }, {
      "title" : "Very deep convolutional networks for large-scale image recognition",
      "author" : [ "Karen Simonyan", "Andrew Zisserman." ],
      "venue" : "arXiv preprint arXiv:1409.1556.",
      "citeRegEx" : "Simonyan and Zisserman.,? 2014",
      "shortCiteRegEx" : "Simonyan and Zisserman.",
      "year" : 2014
    }, {
      "title" : "Improved semantic representations from tree-structured long short-term memory networks",
      "author" : [ "Kai Sheng Tai", "Richard Socher", "Christopher D Manning." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Tai et al\\.,? 2015",
      "shortCiteRegEx" : "Tai et al\\.",
      "year" : 2015
    }, {
      "title" : "Introduction to sighan 2015 bake-off for chinese spelling check",
      "author" : [ "Yuen-Hsien Tseng", "Lung-Hao Lee", "Li-Ping Chang", "Hsin-Hsi Chen." ],
      "venue" : "Proceedings of the Eighth SIGHAN Workshop on Chinese Language Processing, pages 32–37.",
      "citeRegEx" : "Tseng et al\\.,? 2015",
      "shortCiteRegEx" : "Tseng et al\\.",
      "year" : 2015
    }, {
      "title" : "A hybrid approach to automatic corpus generation for chinese spelling check",
      "author" : [ "Dingmin Wang", "Yan Song", "Jing Li", "Jialong Han", "Haisong Zhang." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Confusionset-guided pointer networks for chinese spelling check",
      "author" : [ "Dingmin Wang", "Yi Tay", "Li Zhong." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5780–5785.",
      "citeRegEx" : "Wang et al\\.,? 2019a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Chinese spelling error detection using a fusion lattice lstm",
      "author" : [ "Hao Wang", "Bing Wang", "Jianyong Duan", "Jiajun Zhang." ],
      "venue" : "arXiv preprint arXiv:1911.10750.",
      "citeRegEx" : "Wang et al\\.,? 2019b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Chinese spelling check evaluation at sighan bake-off 2013",
      "author" : [ "Shih-Hung Wu", "Chao-Lin Liu", "Lung-Hao Lee." ],
      "venue" : "Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 35–42.",
      "citeRegEx" : "Wu et al\\.,? 2013",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2013
    }, {
      "title" : "Chinese spelling check system based on n-gram model",
      "author" : [ "Weijian Xie", "Peijie Huang", "Xinrui Zhang", "Kaiduo Hong", "Qiang Huang", "Bingzhou Chen", "Lei Huang." ],
      "venue" : "Proceedings of the Eighth SIGHAN Workshop on Chinese Language Process-",
      "citeRegEx" : "Xie et al\\.,? 2015",
      "shortCiteRegEx" : "Xie et al\\.",
      "year" : 2015
    }, {
      "title" : "Hanspeller: a unified framework for chinese spelling correction",
      "author" : [ "Jinhua Xiong", "Qiao Zhang", "Shuiyuan Zhang", "Jianpeng Hou", "Xueqi Cheng." ],
      "venue" : "International Journal of Computational Linguistics & Chinese Language Processing, Volume 20, Num-",
      "citeRegEx" : "Xiong et al\\.,? 2015",
      "shortCiteRegEx" : "Xiong et al\\.",
      "year" : 2015
    }, {
      "title" : "On the dimensionality of word embedding",
      "author" : [ "Zi Yin", "Yuanyuan Shen." ],
      "venue" : "Proceedings of the 32nd International Conference on Neural Information Processing Systems, pages 895–906.",
      "citeRegEx" : "Yin and Shen.,? 2018",
      "shortCiteRegEx" : "Yin and Shen.",
      "year" : 2018
    }, {
      "title" : "Chinese spelling error detection and correction based on language model, pronunciation, and shape",
      "author" : [ "Junjie Yu", "Zhenghua Li." ],
      "venue" : "Proceedings of The Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 220–223.",
      "citeRegEx" : "Yu and Li.,? 2014",
      "shortCiteRegEx" : "Yu and Li.",
      "year" : 2014
    }, {
      "title" : "Overview of sighan 2014 bake-off for chinese spelling check",
      "author" : [ "Liang-Chih Yu", "Lung-Hao Lee", "Yuen-Hsien Tseng", "Hsin-Hsi Chen." ],
      "venue" : "Proceedings of The Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 126–132.",
      "citeRegEx" : "Yu et al\\.,? 2014",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2014
    }, {
      "title" : "Spelling error correction with soft-masked bert",
      "author" : [ "Shaohua Zhang", "Haoran Huang", "Jicong Liu", "Hang Li." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 882–890.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Long short-term memory over recursive structures",
      "author" : [ "Xiaodan Zhu", "Parinaz Sobihani", "Hongyu Guo." ],
      "venue" : "International Conference on Machine Learning, pages 1604–1612.",
      "citeRegEx" : "Zhu et al\\.,? 2015",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 34,
      "context" : "These errors typically consist of human writing errors and machine recognition errors by automatic speech recognition (ASR) or optical character recognition (OCR) systems (Yu et al., 2014).",
      "startOffset" : 171,
      "endOffset" : 188
    }, {
      "referenceID" : 29,
      "context" : "Table 1: Examples of p-s (phonological similarity) error and v-s (visual similarity) error from SIGHAN13 (Wu et al., 2013).",
      "startOffset" : 105,
      "endOffset" : 122
    }, {
      "referenceID" : 14,
      "context" : "According to (Liu et al., 2011), 76% of Chinese spelling errors belong to phonological similarity error and 46% belong to visual similarity error.",
      "startOffset" : 13,
      "endOffset" : 31
    }, {
      "referenceID" : 12,
      "context" : "5959 Previous methods have made attempts to fuse these two information into the process of CSC (Jin et al., 2014; Han et al., 2019; Hong et al., 2019; Nguyen et al., 2020).",
      "startOffset" : 95,
      "endOffset" : 171
    }, {
      "referenceID" : 7,
      "context" : "5959 Previous methods have made attempts to fuse these two information into the process of CSC (Jin et al., 2014; Han et al., 2019; Hong et al., 2019; Nguyen et al., 2020).",
      "startOffset" : 95,
      "endOffset" : 171
    }, {
      "referenceID" : 8,
      "context" : "5959 Previous methods have made attempts to fuse these two information into the process of CSC (Jin et al., 2014; Han et al., 2019; Hong et al., 2019; Nguyen et al., 2020).",
      "startOffset" : 95,
      "endOffset" : 171
    }, {
      "referenceID" : 19,
      "context" : "5959 Previous methods have made attempts to fuse these two information into the process of CSC (Jin et al., 2014; Han et al., 2019; Hong et al., 2019; Nguyen et al., 2020).",
      "startOffset" : 95,
      "endOffset" : 171
    }, {
      "referenceID" : 22,
      "context" : "These features are derived from intermediate representations of dominant Tacotron2 (Shen et al., 2018) in text-to-speech (TTS) task and VGG19 (Simonyan and Zisserman, 2014) in computer vision (CV) task.",
      "startOffset" : 83,
      "endOffset" : 102
    }, {
      "referenceID" : 23,
      "context" : ", 2018) in text-to-speech (TTS) task and VGG19 (Simonyan and Zisserman, 2014) in computer vision (CV) task.",
      "startOffset" : 47,
      "endOffset" : 77
    }, {
      "referenceID" : 5,
      "context" : "For statistical based methods, Noisy Channel Model (Brill and Moore, 2000, 2008; Chiu et al., 2014; Noaman et al., 2016; Bao et al., 2020) is the most widely used model.",
      "startOffset" : 51,
      "endOffset" : 138
    }, {
      "referenceID" : 20,
      "context" : "For statistical based methods, Noisy Channel Model (Brill and Moore, 2000, 2008; Chiu et al., 2014; Noaman et al., 2016; Bao et al., 2020) is the most widely used model.",
      "startOffset" : 51,
      "endOffset" : 138
    }, {
      "referenceID" : 0,
      "context" : "For statistical based methods, Noisy Channel Model (Brill and Moore, 2000, 2008; Chiu et al., 2014; Noaman et al., 2016; Bao et al., 2020) is the most widely used model.",
      "startOffset" : 51,
      "endOffset" : 138
    }, {
      "referenceID" : 3,
      "context" : "Statistical based methods usually narrowed the candidates choice by utilizing a predefined confusion set (Chen et al., 2013; Hsieh et al., 2013; Wang et al., 2019a), which contains a set of similar character pairs.",
      "startOffset" : 105,
      "endOffset" : 164
    }, {
      "referenceID" : 9,
      "context" : "Statistical based methods usually narrowed the candidates choice by utilizing a predefined confusion set (Chen et al., 2013; Hsieh et al., 2013; Wang et al., 2019a), which contains a set of similar character pairs.",
      "startOffset" : 105,
      "endOffset" : 164
    }, {
      "referenceID" : 27,
      "context" : "Statistical based methods usually narrowed the candidates choice by utilizing a predefined confusion set (Chen et al., 2013; Hsieh et al., 2013; Wang et al., 2019a), which contains a set of similar character pairs.",
      "startOffset" : 105,
      "endOffset" : 164
    }, {
      "referenceID" : 15,
      "context" : "These similar characters were used to replace each other and language models were leveraged to measure the quality of the modified sentences (Liu et al., 2013; Yu and Li, 2014; Xie et al., 2015).",
      "startOffset" : 141,
      "endOffset" : 194
    }, {
      "referenceID" : 33,
      "context" : "These similar characters were used to replace each other and language models were leveraged to measure the quality of the modified sentences (Liu et al., 2013; Yu and Li, 2014; Xie et al., 2015).",
      "startOffset" : 141,
      "endOffset" : 194
    }, {
      "referenceID" : 30,
      "context" : "These similar characters were used to replace each other and language models were leveraged to measure the quality of the modified sentences (Liu et al., 2013; Yu and Li, 2014; Xie et al., 2015).",
      "startOffset" : 141,
      "endOffset" : 194
    }, {
      "referenceID" : 8,
      "context" : "FASpell (Hong et al., 2019) employed BERT (Devlin et al.",
      "startOffset" : 8,
      "endOffset" : 27
    }, {
      "referenceID" : 6,
      "context" : ", 2019) employed BERT (Devlin et al., 2019) as a denoising autoencoder (DAE) for CSC.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 4,
      "context" : "SpellGCN (Cheng et al., 2020) constructed two similarity graphs over the characters in confusion sets and employed graph convolutional network on these two graphs to capture the pronunciation/shape similarities between characters.",
      "startOffset" : 9,
      "endOffset" : 29
    }, {
      "referenceID" : 35,
      "context" : "Soft-Masked BERT (Zhang et al., 2020) was proposed to combine a Bi-GRU based detection network and a BERT based correction network, where the former passed its prediction results to the latter using soft masking mechanism.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 24,
      "context" : "(2020) applied TreeLSTM (Tai et al., 2015; Zhu et al., 2015) on the tree structure of the character radicals to get hierarchical character embeddings, which was used as an adaptable filtering component for candidates selection.",
      "startOffset" : 24,
      "endOffset" : 60
    }, {
      "referenceID" : 36,
      "context" : "(2020) applied TreeLSTM (Tai et al., 2015; Zhu et al., 2015) on the tree structure of the character radicals to get hierarchical character embeddings, which was used as an adaptable filtering component for candidates selection.",
      "startOffset" : 24,
      "endOffset" : 60
    }, {
      "referenceID" : 22,
      "context" : "Neural TTS models, like Tacotron2 (Shen et al., 2018), have achieved high-quality performance in producing natural-sounding synthetic speech.",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 21,
      "context" : "We make use of 8106 Chinese glyph images released by (Sehanobish and Song, 2019).",
      "startOffset" : 53,
      "endOffset" : 80
    }, {
      "referenceID" : 23,
      "context" : "To take advantage of powerful pre-trained models and avoid training from scratch, VGG19 (Simonyan and Zisserman, 2014) pretrained on ImageNet is adopted as the backbone of the glyph feature extractor.",
      "startOffset" : 88,
      "endOffset" : 118
    }, {
      "referenceID" : 18,
      "context" : "Following (Meng et al., 2019), we further finetune it with the objective of recovering the identifiers from glyph images to solve the problem of domain adaptation.",
      "startOffset" : 10,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "Following (Hong et al., 2019; Cheng et al., 2020; Zhang et al., 2020), BERT is employed as the backbone of our semantic feature extractor.",
      "startOffset" : 10,
      "endOffset" : 69
    }, {
      "referenceID" : 4,
      "context" : "Following (Hong et al., 2019; Cheng et al., 2020; Zhang et al., 2020), BERT is employed as the backbone of our semantic feature extractor.",
      "startOffset" : 10,
      "endOffset" : 69
    }, {
      "referenceID" : 35,
      "context" : "Following (Hong et al., 2019; Cheng et al., 2020; Zhang et al., 2020), BERT is employed as the backbone of our semantic feature extractor.",
      "startOffset" : 10,
      "endOffset" : 69
    }, {
      "referenceID" : 29,
      "context" : "Specifically, we make use of training datasets from SIGHAN13 (Wu et al., 2013), SIGHAN14 (Yu et al.",
      "startOffset" : 61,
      "endOffset" : 78
    }, {
      "referenceID" : 34,
      "context" : ", 2013), SIGHAN14 (Yu et al., 2014) and SIGHAN15 (Tseng et al.",
      "startOffset" : 18,
      "endOffset" : 35
    }, {
      "referenceID" : 26,
      "context" : "We also include 271K training samples automatically generated by OCR-based and ASRbased methods (Wang et al., 2018) as in (Cheng et al.",
      "startOffset" : 96,
      "endOffset" : 115
    }, {
      "referenceID" : 4,
      "context" : "Following the same data preprocessing procedure with (Cheng et al., 2020; Nguyen et al., 2020), characters in all SIGHAN datasets are converted to simplified form using OpenCC5.",
      "startOffset" : 53,
      "endOffset" : 94
    }, {
      "referenceID" : 19,
      "context" : "Following the same data preprocessing procedure with (Cheng et al., 2020; Nguyen et al., 2020), characters in all SIGHAN datasets are converted to simplified form using OpenCC5.",
      "startOffset" : 53,
      "endOffset" : 94
    }, {
      "referenceID" : 8,
      "context" : "• FASPell (Hong et al., 2019): This method employs BERT as a denoising autoencoder to generate candidates for wrong characters and filters the visually/phonologically irrelevant candidates by a confidence-similarity decoder.",
      "startOffset" : 10,
      "endOffset" : 29
    }, {
      "referenceID" : 4,
      "context" : "• SpellGCN (Cheng et al., 2020): This method learns the pronunciation/shape relationship between the characters by applying graph convolutional network on two similarity graphs.",
      "startOffset" : 11,
      "endOffset" : 31
    }, {
      "referenceID" : 19,
      "context" : "com/BYVoid/OpenCC • HeadFilt (Nguyen et al., 2020): This method uses adaptable filter learned from hierarchical character embeddings to estimate the similarity between characters and filter candidates produced by BERT.",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 14,
      "context" : "This is consistent with the finding that most Chinese spelling errors are caused by phonological similarity (Liu et al., 2011).",
      "startOffset" : 108,
      "endOffset" : 126
    }, {
      "referenceID" : 32,
      "context" : "This is reasonable due to the bias-variance phenomenon explained in (Yin and Shen, 2018).",
      "startOffset" : 68,
      "endOffset" : 88
    } ],
    "year" : 2021,
    "abstractText" : "Chinese Spelling Check (CSC) is a challenging task due to the complex characteristics of Chinese characters. Statistics reveal that most Chinese spelling errors belong to phonological or visual errors. However, previous methods rarely utilize phonological and morphological knowledge of Chinese characters or heavily rely on external resources to model their similarities. To address the above issues, we propose a novel end-to-end trainable model called PHMOSpell, which promotes the performance of CSC with multi-modal information. Specifically, we derive pinyin and glyph representations for Chinese characters from audio and visual modalities respectively, which are integrated into a pre-trained language model by a well-designed adaptive gating mechanism. To verify its effectiveness, we conduct comprehensive experiments and ablation tests. Experimental results on three shared benchmarks demonstrate that our model consistently outperforms previous state-of-the-art models.",
    "creator" : "LaTeX with hyperref"
  }
}