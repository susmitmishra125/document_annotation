{
  "name" : "2021.acl-long.75.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?",
    "authors" : [ "Peter Shaw", "Ming-Wei Chang", "Panupong Pasupat", "Kristina Toutanova" ],
    "emails" : [ "petershaw@google.com", "mingweichang@google.com", "ppasupat@google.com", "kristout@google.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 922–938\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n922"
    }, {
      "heading" : "1 Introduction",
      "text" : "Sequence-to-sequence (seq2seq) models have been widely used in semantic parsing (Dong and Lapata, 2016; Jia and Liang, 2016) and excel at handling the natural language variation1 of humangenerated queries. However, evaluations on synthetic2 tasks such as SCAN (Lake and Baroni,\n1We use the term natural language variation in a broad sense to refer to the many different ways humans can express the same meaning in natural language, including differences in word choice and syntactic constructions.\n2We make a coarse distinction between synthetic datasets, where natural language utterances are generated by a program,\n2018) have shown that seq2seq models often generalize poorly to out-of-distribution compositional utterances, such as “jump twice” when only “jump”, “walk”, and “walk twice” are seen during training. This ability to generalize to novel combinations of the elements observed during training is referred to as compositional generalization.\nThis has motivated many specialized architectures that improve peformance on SCAN (Li et al., 2019; Russin et al., 2019; Gordon et al., 2019; Lake, 2019; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020). However, most approaches have only been evaluated on synthetic datasets. While synthetic datasets enable precise, interpretable evaluation of specific phenomena, they are less representative of the natural language variation that a real-world semantic parsing system must handle.\nIn this paper, we ask: can we develop a semantic parsing approach that handles both natural language variation and compositional generalization?\nand non-synthetic datasets, where natural language utterances are collected from humans.\nSurprisingly, this question is understudied. As visualized in Figure 1, most prior work evaluates either out-of-distribution compositional generalization on synthetic datasets, or in-distribution performance on non-synthetic datasets. Notably, designing approaches that can handle both compositional generalization and the natural language variation of non-synthetic datasets is difficult. For example, large pre-trained seq2seq models that perform well on in-distribution evaluations do not address most of the compositional generalization challenges proposed in SCAN (Furrer et al., 2020).\nOur research question has two important motivations. First, humans have been shown to be adept compositional learners (Lake et al., 2019). Several authors have argued that a greater focus on compositional generalization is an important path to more human-like generalization and NLU (Lake et al., 2017; Battaglia et al., 2018). Second, it is practically important to assess performance on non-synthetic data and out-of-distribution examples, as random train and test splits can overestimate real-world performance and miss important error cases (Ribeiro et al., 2020). Therefore, we are interested in approaches that do well not only on controlled synthetic challenges of compositionality or in-distribution natural utterances, but across all of the diverse set of evaluations shown in Figure 2.\nOur contributions are two-fold. First, on the evaluation front, we show that performance on SCAN is not well-correlated with performance on non-synthetic tasks. In addition, strong existing approaches do not perform well across all evaluations in Figure 2. We also propose new Target Maximum Compound Divergence (TMCD) train and test splits, extending the methodology of Keysers et al. (2020) to create challenging evaluations of compositional generalization for non-synthetic datasets. We show that TMCD splits complement existing evaluations by focusing on different aspects of the problem.\nSecond, on the modeling front, we propose NQG, a simple and general grammar-based approach that solves SCAN and also scales to natural utterances, obtaining high precision for non-synthetic data. In addition, we introduce and evaluate NQG-T5, a hybrid model that combines NQG with T5 (Raffel et al., 2020), leading to improvements across several compositional generalization evaluations while also being competitive on the standard splits of GEOQUERY (Zelle and Mooney, 1996) and SPI-\nDER (Yu et al., 2018). Our results indicate that NQG-T5 is a strong baseline for our challenge of developing approaches that perform well across a diverse set of evaluations focusing on either natural language variation, compositional generalization, or both. Comparing five approaches across eight evaluations on SCAN and GEOQUERY, its average rank is 1, with the rank of the best previous approach (T5) being 2.9; performance is also competitive across several evaluations on SPIDER.\nWhile still far from affirmatively answering our research question, our study highlights the importance of a diverse set of evaluations and the open challenge of handling both compositional generalization and natural language variation.3"
    }, {
      "heading" : "2 Background and Related Work",
      "text" : "In this section, we survey recent work related to compositional generalization in semantic parsing.\nEvaluations To evaluate a model’s ability to generalize to novel compositions, previous work has proposed several methods for generating train and test splits, as well as several synthetic datasets.\nA widely used synthetic dataset for assessing compositional generalization is SCAN (Lake and Baroni, 2018), which consists of natural language commands (e.g., “jump twice”) mapping to action sequences (e.g., “I_JUMP I_JUMP”). One split for SCAN is the length split, where examples are separated by length such that the test set contains longer\n3Our code and data splits are available at https://github.com/google-research/ language/tree/master/language/nqg.\nexamples than the training set. Another is the primitive split, where a given primitive (e.g., “jump”) is seen by itself during training, but the test set consists of the primitive recombined with other elements observed during training (e.g., “jump twice”). Other synthetic datasets have been developed to evaluate aspects of compositional generalization beyond SCAN, including NACS (Bastings et al., 2018), CFQ (Keysers et al., 2020), and COGS (Kim and Linzen, 2020).\nIn addition to introducing the CFQ dataset, Keysers et al. (2020) propose Maximum Compound Divergence (MCD) splits based on the notion of a compound distribution. Their algorithm generates train and test splits that maximize the divergence of their respective compound distributions while bounding the divergence of their respective atom distributions. We extend their methodology to create new TMCD splits for non-synthetic datasets.\nAnother method for generating train and test splits is the template4 split (Finegan-Dollak et al., 2018). Unlike the aforementioned evaluations, template splits have been applied to non-synthetic datasets, primarily for text-to-SQL. In template splits, any parse template (defined as the target SQL query with entities anonymized) appearing in the training set cannot appear in the test set. We analyze and discuss template splits in § 6.1.\nFinally, Herzig and Berant (2019) studies biases resulting from methods for efficiently collecting human-labeled data, providing further motivation for out-of-distribution evaluations.\nApproaches Many specialized architectures have been developed to address the compositional generalization challenges of SCAN. Several of them have recently reached 100% accuracy across multiple SCAN challenges (Liu et al., 2020; Nye et al., 2020; Chen et al., 2020). Similarly to the NQG-T5 approach we propose in § 4, all of these models incorporate discrete structure. However, unlike NQG-T5, they have only been evaluated on synthetic parsing tasks.\nRecently, Herzig and Berant (2020) also begins to address our research question, proposing an approach that not only solves several SCAN challenges but also achieves strong performance on the standard and template splits of the non-synthetic dataset GEOQUERY. However, their approach requires some manual task-specific engineering. We compare NQG-T5 with this approach and other\n4Also referred to as a query split.\nSCAN-inspired architectures. Oren et al. (2020) and Zheng and Lapata (2020) also explored compositional generalization on non-synthetic datasets by focusing on the template splits proposed by Finegan-Dollak et al. (2018), demonstrating improvements over standard seq2seq models.\nThe effect of large-scale pre-training on compositional generalization ability has also been studied. Furrer et al. (2020) finds that pre-training alone cannot solve several compositional generalization challenges, despite its effectiveness across NLP tasks such as question answering (Raffel et al., 2020).\nWhile our work focuses on modeling approaches, compositional data augmentation techniques have also been proposed (Jia and Liang, 2016; Andreas, 2020). NQG-T5 outperforms previously reported results for these methods, but more in-depth analysis is needed."
    }, {
      "heading" : "3 Target Maximum Compound Divergence (TMCD) Splits",
      "text" : "The existing evaluations targeting compositional generalization for non-synthetic tasks are template splits and length splits. Here we propose an additional method which expands the set of available evaluations by generating data splits that maximize compound divergence over non-synthetic datasets, termed Target Maximum Compound Divergence (TMCD) splits. As we show in § 6, it results in a generalization problem with different characteristics that can be much more challenging than template splits, and contributes to the comprehensiveness of evaluation.\nIn standard MCD splits (Keysers et al., 2020), the notion of compounds requires that both source and target are generated by a rule-based procedure, and therefore cannot be applied to existing non-synthetic datasets where natural language utterances are collected from humans. For TMCD, we propose a new notion of compounds based only on the target representations. We leverage their known syntactic structure to define atoms and compounds. For instance, example atoms in FunQL are longest and river, and an example compound is longest(river). Detailed definitions of atoms and compounds for each dataset we study can be found in Appendix B.3.\nGiven this definition of compounds, our definition of compound divergence, DC , is the same as that of Keysers et al. (2020). Specifically,\nDC = 1 − C0.1(FTRAIN ‖FTEST),\nwhereFTRAIN andFTEST are the weighted frequency distributions of compounds in the training and test sets, respectively. The Chernoff coefficient Cα(P‖Q) = ∑ k p α k q 1−α k (Chung et al., 1989) is used with α = 0.1. For TMCD, we constrain atom divergence by requiring that every atom appear at least once in the training set. An atom constraint is desirable so that the model knows the possible target atoms to generate. A greedy algorithm similar to the one of Keysers et al. (2020) is used to generate splits that approximately maximize compound divergence. First, we randomly split the dataset. Then, we swap examples until the atom constraint is satisfied. Finally, we sequentially identify example pairs that can be swapped between the train and test sets to increase compound divergence without violating the atom constraint, breaking when a swap can no longer be identified."
    }, {
      "heading" : "4 Proposed Approach: NQG-T5",
      "text" : "We propose NQG-T5, a hybrid semantic parser that combines a grammar-based approach with a seq2seq model. The two components are motivated by prior work focusing on compositional generalization and natural language variation, respectively, and we show in § 5 that their combination sets a strong baseline for our challenge.\nThe grammar-based component, NQG, consists of a discriminative Neural parsing model and a flexible Quasi-synchronous Grammar induction algorithm which can operate over arbitrary pairs of strings. Like other grammar-based approaches, NQG can fail to produce an output for certain inputs. As visualized in Figure 3, in cases where NQG fails to produce an output, we return the output from T5 (Raffel et al., 2020), a pre-trained seq2seq model. This simple combination can work well because NQG often has higher precision than T5 for cases where it produces an output, especially in out-of-distribution settings.\nWe train NQG and T5 separately. Training data for both components consists of pairs of source and target strings, referred to as x and y, respectively."
    }, {
      "heading" : "4.1 NQG Component",
      "text" : "NQG is inspired by more traditional approaches to semantic parsing based on grammar formalisms such as CCG (Zettlemoyer and Collins, 2005, 2007; Kwiatkowski et al., 2010, 2013) and SCFG (Wong and Mooney, 2006, 2007; Andreas et al., 2013; Li\net al., 2015). NQG combines a QCFG induction algorithm with a neural parsing model. Training is a two-stage process. First, we employ a compressionbased grammar induction technique to construct our grammar. Second, based on the induced grammar, we build the NQG semantic parsing model via a discriminative latent variable model, using a powerful neural encoder to score grammar rule applications anchored in the source string x."
    }, {
      "heading" : "4.1.1 NQG Grammar Induction",
      "text" : "Grammar Formalism Synchronous contextfree grammars (SCFGs) synchronously generate strings in both a source and target language. Compared to related work based on SCFGs for machine translation (Chiang, 2007) and semantic parsing, NQG uses a slightly more general grammar formalism that allows repetition of a non-terminal with the same index on the target side. Therefore, we adopt the terminology of quasi-synchronous context-free grammars (Smith and Eisner, 2006), or QCFGs, to refer to our induced grammar G.5 Our grammar G contains a single non-terminal symbol, NT . We restrict source rules to ones containing at most 2 non-terminal symbols, and do not allow unary productions as source rules. This enables efficient parsing using an algorithm similar to CKY (Cocke, 1969; Kasami, 1965; Younger, 1967) that does not require binarization of the grammar.\nInduction Procedure To induce G from the training data, we propose a QCFG induction algorithm that does not rely on task-specific heuristics or pre-computed word alignments. Notably, our approach makes no explicit assumptions about the source or target languages, beyond those implicit in the QCFG formalism. Table 1 shows examples of induced rules.\nOur grammar induction algorithm is guided by the principle of Occam’s razor, which leads us to\n5See Appendix A.1 for additional background on QCFGs.\nseek the smallest, simplest grammar that explains the data well. We follow the Minimum Description Length (MDL) principle (Rissanen, 1978; Grunwald, 2004) as a way to formalize this intuition. Specifically, we use standard two-part codes to compute description length, where we are interested in an encoding of targets y given the inputs x, across a dataset D consisting of these pairs. A two-part code encodes the model and the targets encoded using the model; the two parts measure the simplicity of the model and the extent to which it can explain the data, respectively.\nFor grammar induction, our model is simply our grammar, G. The codelength can therefore be expressed as H(G) − ∑ x,y∈D log2 PG(y|x) where H(G) corresponds to the codelength of some encoding of G. We approximate H(G) by counting terminal (CT ) and non-terminal (CN ) symbols in the grammar’s rules, R. For PG , we assume a uniform distribution over the set of possible derivations.6 As the only mutable aspect of the grammar during induction is the set of rules R, we abuse notation slightly and write our approximate codelength objective as a function ofR only:\nL(R) = lNCN (R) + lTCT (R)−∑ (x,y)∈D log2 |ZGx,y| |ZGx,∗| ,\nwhere ZGx,y is the set of all derivations in G that yield the pair of strings x and y, whileZGx,∗ ⊃ ZGx,y\n6This can be viewed as a conservative choice, as in practice we expect our neural parser to learn a better model for P (y|x) than a naive uniform distribution over derivations.\nis the set of derivations that yield source string x and any target string. The constants lN and lT can be interpreted as the average bitlength for encoding non-terminal and terminal symbols, respectively. In practice, these are treated as hyperparameters.\nWe use a greedy search algorithm to find a grammar that approximately minimizes this codelength objective. We initialize G by creating a rule NT → 〈x,y〉 for every training example (x,y). By construction, the initial grammar perfectly fits the training data, but is also very large. Our algorithm iteratively identifies a rule that can be added to G that decreases our codelength objective by enabling ≥ 1 rule(s) to be removed, under the invariant constraint that G can still derive all training examples. The search completes when no rule that decreases the objective can be identified. In practice, we use several approximations to efficiently select a rule at each iteration. Additional details regarding the grammar induction algorithm are described in Appendix A.2."
    }, {
      "heading" : "4.1.2 NQG Semantic Parsing Model",
      "text" : "Based on the induced grammar G, we train a discriminative latent variable parsing model, using a method similar to that of Blunsom et al. (2008). We define p(y | x) as:\np(y | x) = ∑\nz∈ZGx,y\np(z | x),\nwhere ZGx,y is the set of derivations of x and y in G. We define p(z | x) as:\np(z | x) = exp(s(z,x))∑ z′∈ZGx,∗ exp(s(z′,x)) ,\nwhere s(z,x) is a derivation score and the denominator is a global partition function. Similarly to the Neural CRF model of Durrett and Klein (2015), the scores decompose over anchored rules. Unlike Durrett and Klein (2015), we compute these scores based on contextualized representations from a BERT (Devlin et al., 2019) encoder. Additional details regarding the model architecture can be found in Appendix A.3.\nAt training time, we use a Maximum Marginal Likelihood (MML) objective. We preprocess each example to produce parse forest representations for both ZGx,y and Z G x,∗, which correspond to the numerator and denominator of our MML objective, respectively. By using dynamic programming to\nefficiently sum derivation scores inside the training loop, we can efficiently compute the exact MML objective without requiring approximations such as beam search.\nAt inference time, we select the highest scoring derivation using an algorithm similar to CKY that considers anchored rule scores generated by the neural parsing model. We output the corresponding target if it can be derived by a CFG defining valid target constructions for the given task."
    }, {
      "heading" : "4.1.3 NQG Discussion",
      "text" : "We note that NQG is closely related to work that uses synchronous grammars for hierarchical statistical machine translation, such as Hiero (Chiang, 2007). Unlike Hiero, NQG does not rely on an additional word alignment component. Moreover, Hiero simply uses relative frequency to learn rule weights. Additionally, in contract with traditional SCFG models for machine translation applied to semantic parsing (Wong and Mooney, 2006; Andreas et al., 2013), our neural model conditions on global context from the source x via contextual word embeddings, and our grammar’s rules do not need to carry source context to aid disambiguation."
    }, {
      "heading" : "4.2 T5 Component",
      "text" : "T5 (Raffel et al., 2020) is a pre-trained sequence-tosequence Transformer model (Vaswani et al., 2017). We fine-tune T5 for each task."
    }, {
      "heading" : "5 Experiments",
      "text" : "We evaluate existing approaches and the newly proposed NQG-T5 across a diverse set of evaluations to assess compositional generalization and handling of natural language variation. We aim to understand how the approaches compare to each other for each type of evaluation and in aggregate, and how the performance of a single approach may vary across different evaluation types."
    }, {
      "heading" : "5.1 Experiments on SCAN and GEOQUERY",
      "text" : "For our main experiments, we focus on evaluation across multiple splits of two datasets with compositional queries: SCAN (Lake and Baroni, 2018) and GEOQUERY (Zelle and Mooney, 1996; Tang and Mooney, 2001). The two datasets have been widely used to study compositional generalization and robustness to natural language variation, respectively. Both datasets are closed-domain and have outputs with straightforward syntax, enabling\nus to make clear comparisons between synthetic vs. non-synthetic setups.\nApproaches For NQG-T5, to assess the effect of model size, we compare two sizes of the underlying T5 model: Base (220 million parameters) and 3B (3 billion parameters). To evaluate NQG individually, we treat any example where no output is provided as incorrect when computing accuracy.\nWe select strong approaches from prior work that have performed well in at least one setting. We group them into two families of approaches described in Figure 1. First, for general-purpose models that have shown strong ability to handle natural language variation, we consider T5, a pretrained seq2seq model, in both Base and 3B sizes.\nSecond, for specialized methods with strong compositional biases, we consider approaches that have been developed for SCAN. Some previous approaches for SCAN require task-specific information such as the mapping of atoms (Lake, 2019; Gordon et al., 2019) or a grammar mimicking the training data (Nye et al., 2020), and as such are difficult to adapt to non-synthetic datasets. Among the approaches that do not need task-specific resources, we evaluate two models with publicly available code: Syntactic Attention (Russin et al., 2019) and CGPS (Li et al., 2019). We report results on SCAN from the original papers as well as new results on our proposed data splits.\nDatasets For the SCAN dataset, we evaluate using the length split and two primitive splits, jump and turn left, included in the original dataset (Lake and Baroni, 2018). We also evaluate using the SCAN MCD splits from Keysers et al. (2020).\nGEOQUERY (Zelle and Mooney, 1996) contains natural language questions about US geography. Similarly to prior work (Dong and Lapata, 2016, 2018), we replace entity mentions with placeholders. We use a variant of Functional Query Language (FunQL) as the target representation (Kate et al., 2005). In addition to the standard split of Zettlemoyer and Collins (2005), we generate multiple splits focusing on compositional generalization: a new split based on query length and a TMCD split, each consisting of 440 train and 440 test examples. We also generate a new template split consisting of 441 train and 439 test examples.7\n7We generate a new template split rather than use the GEOQUERY template split of Finegan-Dollak et al. (2018) to avoid overlapping templates between the train and test sets when mapping from SQL to FunQL.\nWe report exact-match accuracy for both datasets.8 Hyperparameters and pre-processing details can be found in Appendix B.\nResults The results are presented in Table 2. The results for T5 on SCAN are from Furrer et al. (2020). Additionally, we include results for GECA9 (Andreas, 2020), a data augmentation method, as well as LANE (Liu et al., 2020) and NSSM (Chen et al., 2020)10. We also compare with SpanBasedSP11 (Herzig and Berant, 2020).\nFrom the results, we first note that the relative performance of approaches on compositional splits of SCAN is not very predictive of their relative performance on compositional splits of GEOQUERY. For example, GGPS is better than T5 on the length split of SCAN but is significantly worse than T5 on the length split of GEOQUERY. Similarly, the ranking of most methods is different\n8For GEOQUERY we report the mean of 3 runs for NQG, with standard deviations reported in Appendix B.5\n9GECA reports GEOQUERY results on a setting with Prolog logical forms and without anonymization of entities. Note that the performance of GECA depends on both the quality of the generated data and the underlying parser (Jia and Liang, 2016), which can complicate the analysis.\n10These SCAN-motivated approaches both include aspects of discrete search and curriculum learning, and have not been demonstrated to scale effectively to non-synthetic parsing tasks. Moreover, the code is either not yet released (NSSM) or specialized to SCAN (LANE).\n11SpanBasedSP preprocesses SCAN to add program-level supervision. For GEOQUERY, they similarly use FunQL, but uses slightly different data preprocessing and report denotation accuracy. We computed NQG-T5’s denotation accuracy to be 2.1 points higher than exact-match accuracy on the standard split of GeoQuery.\non the (T)MCD splits of the two datasets. Second, the proposed NQG-T5 approach combines the strengths of T5 and NQG to achieve superior results across all evaluations. It improves over T5 on compositional generalization for both synthetic and non-synthetic data while maintaining T5’s performance on handling in-distribution natural language variation, leading to an average rank of 1.0 compared to 2.9 for T5. (To the best of our knowledge, both T5 and NQG-T5 achieve new state-of-the-art accuracy on the standard split of GEOQUERY.)\nFinally, we note that there is substantial room for improvement on handling both compositional generalization and natural language variation."
    }, {
      "heading" : "5.2 Experiments on SPIDER",
      "text" : "We now compare the approaches on SPIDER (Yu et al., 2018), a non-synthetic text-to-SQL dataset that includes the further challenges of schema linking and modeling complex SQL syntax.\nSPIDER contains 10,181 questions and 5,693 unique SQL queries across 138 domains. The primary evaluation is in the cross-database setting, where models are evaluated on examples for databases not seen during training. The primary challenge in this setting is generalization to new database schemas, which is not our focus. Therefore, we use a setting where the databases are shared between train and test examples.12 We gen-\n12This is similar to the “example split” discussed in Yu et al. (2018). However, we only consider examples in the original training set for databases with more than 50 examples to ensure sufficient coverage over table and column names in\nerate 3 new splits consisting of 3,282 train and 1,094 test examples each: a random split, a split based on source length, and a TMCD split. We also generate a template split by anonymizing integers and quoted strings, consisting of 3,280 train and 1,096 test examples. We adopt the terminology of Suhr et al. (2020) and use SPIDER-SSP to refer to these same-database splits, and use SPIDERXSP to refer to the standard cross-database setting.\nWe prepend the name of the target database to the source sequence. For T5, we also serialize the database schema as a string and append it to the source sequence similarly to Suhr et al. (2020). We report exact set match without values, the standard Spider evaluation metric (Yu et al., 2018).\nResults Table 3 shows the results of T5 and NQG-T5 on different splits of SPIDER-SSP. We also show T5-Base performance without the schema string appended. The text-to-SQL mapping is not well modeled by NQG. Nevertheless, the performance of NQG-T5 is competitive with T5, indicating a strength of the hybrid approach.\nTable 4 shows the results on SPIDER-XSP, which focuses on handling unseen schema rather than compositional generalization. To our surprise, T5-3B proves to be competitive with the state-ofthe-art (Choi et al., 2020) for approaches without access to database contents beyond the table and column names. As NQG-T5 simply uses T5’s output when the induced grammar lacks coverage, it too is competitive."
    }, {
      "heading" : "6 Analysis",
      "text" : ""
    }, {
      "heading" : "6.1 Comparison of Data Splits",
      "text" : "Table 6 compares the compound divergence, the number of test examples with unseen atoms, and\nthe training data. This includes 51 databases.\nthe accuracy of T5-Base across various splits. For GEOQUERY, the TMCD split is significantly more challenging than the template split. However, for SPIDER, the template and TMCD splits are similarly challenging. Notably, template splits do not have an explicit atom constraint. We find that for the SPIDER template split, T5-Base accuracy is 53.9% for the 30.3% of test set examples that contain an atom not seen during training, and 61.6% on the remainder, indicating that generalization to unseen atoms can contribute to the difficulty of template splits.13 Length splits are also very challenging, but they lead to a more predictable error pattern for seq2seq models, as discussed next."
    }, {
      "heading" : "6.2 T5 Analysis",
      "text" : "We analyze NQG-T5’s components, starting with T5. On length splits, there is a consistent pattern to the errors. T5’s outputs on the test set are not significantly longer than the maximum length observed during training, leading to poor performance. This phenomenon was explored by Newman et al. (2020).\nDiagnosing the large generalization gap on the (T)MCD splits is more challenging, but we noticed several error patterns. For T5-Base on the GEOQUERY TMCD split, in 52 of the 201 incorrect predictions (26%), the first incorrectly predicted symbol occurs when the gold symbol has 0 probability under a trigram language model fit to the training data. This suggests that the decoder’s implicit target language model might have over-fitted to the distribution of target sequences in the training data, hampering its ability to generate novel compositions. Non-exclusively with these errors, 53% of the incorrect predictions occur when the gold target contains an atom that is seen in only 1\n13Future work could explore different choices for constructing template and TMCD splits, such as alternative compound definitions and atom constraints.\nexample during training, suggesting that T5 struggles with single-shot learning of new atoms. In other cases, the errors appear to reflect over-fitting to spurious correlations between inputs and outputs. Some error examples are shown in Appendix B.6."
    }, {
      "heading" : "6.3 NQG Analysis",
      "text" : "To analyze NQG, we compute its coverage (fraction of examples where NQG produces an output) and precision (fraction of examples with a correct output among ones where an output is produced) on different data splits. The results in Table 5 show that NQG has high precision but struggles at coverage on some data splits.\nThere is a significant difference in the effectiveness of the grammar induction procedure among the three datasets. Induction is particularly unsuccessful for SPIDER, as SQL has complicated syntax and often requires complex coordination across discontinuous clauses. Most of the induced rules are limited to simply replacing table and column names or value literals with non-terminals, such as the rule shown in Table 1, rather than representing nested sub-structures. The degree of span-to-span correspondence between natural language and SQL is seemingly lower than for other formalisms such as FunQL, which limits the effectiveness of grammar induction. Intermediate representations for SQL such as SemQL (Guo et al., 2019) may help\nincrease the correspondence between source and target syntax.\nFor both GEOQUERY and SPIDER, NQG is limited by the expressiveness of QCFGs and the simple greedy search procedure used for grammar induction, which can lead to sub-optimal approximations of the induction objective. Notably, QCFGs cannot directly represent relations between source strings, such as semantic similarity, or relations between target strings, such as logical equivalence (e.g. intersect(a,b)⇔ intersect(b,a)), that could enable greater generalization. However, such extensions pose additional scalability challenges, requiring new research in more flexible approaches for both learning and inference."
    }, {
      "heading" : "7 Conclusions",
      "text" : "Our experiments and analysis demonstrate that NQG and T5 offer different strengths. NQG generally has higher precision for out-of-distribution examples, but is limited by the syntactic constraints of the grammar formalism and by requiring exact lexical overlap with induced rules in order to provide a derivation at inference time. T5’s coverage is not limited by such constraints, but precision can be significantly lower for out-of-distribution examples. With NQG-T5, we offer a simple combination of these strengths. While accuracy is still limited for out-of-distribution examples where NQG lacks coverage, we believe it sets a strong and simple baseline for future work.\nMore broadly, our work highlights that evaluating on a diverse set of benchmarks is important, and that handling both out-of-distribution compositional generalization and natural language variation remains an open challenge for semantic parsing."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank Kenton Lee, William Cohen, Jeremy Cole, and Luheng He for helpful discussions. Thanks also to Emily Pitler, Jonathan Herzig, and the anonymous reviewers for their comments and suggestions."
    }, {
      "heading" : "Ethical Considerations",
      "text" : "This paper proposed to expand the set of benchmarks used to evaluate compositional generalization in semantic parsing. While we hope that ensuring semantic parsing approaches perform well across a diverse set of evaluations, including ones that test out-of-distribution compositional generalization, would lead to systems that generalize better to languages not well represented in small training sets, we have only evaluated our methods on semantic parsing datasets in English.\nOur NQG-T5 method uses a pre-trained T5 model, which is computationally expensive in finetuning and inference, especially for larger models (see Appendix B.1 for details on running time and compute architecture). Our method does not require pre-training of large models, as it uses pre-existing model releases. NQG-T5-base outperforms or is comparable in accuracy to T5-3B on the non-SQL datasets, leading to relative savings of computational resources."
    }, {
      "heading" : "Appendix",
      "text" : "We organize the appendix into two sections:\n• Additional details for NQG in Appendix A.\n• Additional experimental details and analysis in Appendix B."
    }, {
      "heading" : "A NQG Details",
      "text" : "In this section we describe the NQG grammar induction algorithm and parsing model in detail, starting with relevant background and notation for QCFGs."
    }, {
      "heading" : "A.1 Background: SCFGs and QCFGs",
      "text" : "Synchronous Context-Free Grammars (SCFGs) have been used to model the hierarchical mapping between pairs of strings in areas such as compiler theory (Aho and Ullman, 1972) and natural language processing.\nInformally, SCFGs can be viewed as an extension of Context-Free Grammars (CFGs) that synchronously generate strings in both a source and target language. We write SCFG rules as:\nS → 〈α, β〉\nWhere S is a non-terminal symbol, and α and β are strings of non-terminal and terminal symbols. An SCFG rule can be viewed as two CFG rules, S → α and S → β with a pairing between the occurrences of non-terminal symbols in α and β. This pairing is indicated by assigning each nonterminal in α and β an index ∈ N. Non-terminals sharing the same index are called linked. Following convention, we denote the index for a non-terminal using a boxed subscript, e.g. NT[1]. A complete SCFG derivation is a pair of parse trees, one for the source language and one for the target language. An example derivation is shown in Figure 4.\nThe ⇒r operator refers to a derives relation, such that 〈α1, β1〉 ⇒r 〈α2, β2〉 states that the string pair 〈α2, β2〉 can be generated from 〈α1, β1〉 by applying the rule r. We write ⇒ to leave the rule unspecified, assuming the set of possible rules is clear from context. We write⇒⇒ to indicate a chain of 2 rule applications, omitting the intermediate string pair. Finally, we write ∗⇒ to denote the reflexive transitive closure of⇒.\nQuasi-Synchronous Context-Free Grammars (QCFGs) QCFGs generalize SCFGs in various ways, notably relaxing the restriction on a strict\none-to-one alignment between source and target non-terminals (Smith and Eisner, 2006).\nCompositionality Notably, grammar formalisms such SCFGs and QCFGs capture the formal notion of the principle of compositionality as a homomorphism between source and target structures (Montague, 1970; Janssen and Partee, 1997)."
    }, {
      "heading" : "A.2 NQG Grammar Induction Details",
      "text" : "Having defined the codelength scoring function that we use to compare grammars in section 4.1.1, we describe our greedy search algorithm that finds a grammar that approximately minimizes this objective.14\nInitialization We initialize R to be {NT → 〈x,y〉 | x,y ∈ D}. We also add identity rules for substrings that exactly match between source and target examples, e.g. NT → 〈k, k〉 where k is a substring of both x and y for some x,y ∈ D.15\nOptimization Algorithm Our algorithm was designed with simplicity in mind, and therefore uses a simple greedy search process that could likely be significantly improved upon by future work. At a high level, our greedy algorithm iteratively identifies a rule to be added to R that decreases the codelength by enabling ≥ 1 rules in R to be removed while maintaining the invariant that G allows for deriving all of the training examples, i.e. 〈NT,NT 〉 ∗⇒ 〈x,y〉 for every x,y ∈ D. The search completes when no rule that decreases L(R) can be identified.\nTo describe the implementation, first let us define several operations over rules and sets of rules. We define the set of rules that can be derived from a given set of rules,R:\nd(R) = {NT → 〈α, β〉 | 〈NT,NT 〉 ∗⇒ 〈α, β〉}\nWe define an operation SPLIT that generates possible choices for splitting a rule into 2 rules:\nSPLIT(NT → 〈α, β〉) = {g, h | 〈NT,NT 〉 ⇒g⇒h 〈α, β〉 ∨ 〈NT,NT 〉 ⇒h⇒g 〈α, β〉},\n14The induction objective contains hyperparameters representing the bitlength of terminal and non-terminal symbols. For all experiments we use lN = 1. For GEOQUERY and SPIDER we use lT = 8, and use lT = 32 for SCAN.\n15These initialization rules are used for GEOQUERY and SPIDER, but SCAN does not contain any exact token overlap between source and target languages.\nNT → 〈how many NT[1] pass through NT[2], answer ( count ( intersection ( NT[1] , loc_1 ( NT[2] ) ) ) )〉 NT → 〈rivers, river〉 NT → 〈the largest NT[1], largest ( NT[1] )〉 NT → 〈state, state〉\nwhere g and h is a pair of new rules that would maintain the invariant that 〈NT,NT 〉 ∗⇒ 〈x,y〉 for every x,y ∈ D, even if the provided rule is eliminated.16\nSPLIT can be implemented by considering pairs of sub-strings in α and β to replace with a new indexed non-terminal symbol. For example, the rule “NT → 〈largest state, largest ( state )〉” can be split into the rules “NT → 〈largest NT[1], largest ( NT[1] )〉” and “NT → 〈state, state〉”. This step can require re-indexing of non-terminals.\nDuring our greedy search, we only split rules when one of the two resulting rules can already be derived given R. Therefore, we define a function NEW that returns a set of candidate rules to consider:\nNEW(R) = {g | g, h ∈ SPLIT(f) ∧ f ∈ R ∧ h ∈ d(R)}\nSimilarly, we can compute the set of rules that are made redundant and can be eliminated by introducing one these candidate rules, f :\nELIM(R, f) = {h | f, g ∈ SPLIT(h) ∧ g ∈ d(R) ∧ h ∈ R} 16We optionally allow SPLIT to introduce repeated target non-terminals when the target string has repeated substrings. Otherwise, we do not allow SPLIT to replace a repeated substring with a non-terminal, as this can lead to an ambiguous choice. We enable this option for SCAN and SPIDER but not for GEOQUERY, as FunQL does not require such repetitions.\nWe can then define the codelength reduction of adding a particular rule, −∆L(R, f) = L(R) − L(R′) whereR′ = (R ∪ f) \\ELIM(R, f).17 Finally, we can select the rule with the largest −∆L:\nMAX(R) = argmax f∈NEW(R) −∆L(R, f)\nConceptually, after initialization, the algorithm then proceeds as:\nwhile |NEW(R)| > 0 do r ← MAX(R) if −∆L(R, r) < 0 then\nbreak end if R ← (R ∪ r) \\ ELIM(R, r)\nend while\nFor efficiency, we select the shortest N examples from the training dataset, and only consider these during the induction procedure. Avoiding longer examples is helpful as the number of candidates returned by SPLIT is polynomial with respect to source and target length. Once induction\n17The last term of the codelength objective described in section 4.1.1 is related to the increase in the proportion of incorrect derivations due to introducing f . Rather than computing this exactly, we estimate this quantity by sampling up to k examples from D that contain all of the sub-strings of source terminal symbols in f such that f could be used in a derivation, and estimating the increase in incorrect derivations over this sample only. We sample k = 10 examples for all experiments.\nhas completed, we then determine which of the longer examples cannot be derived based on the set of induced rules, and add rules for these examples.18\nOur algorithm maintains a significant amount of state between iterations to cache computations that are not affected by particular rule changes, based on overlap in terminal symbols. We developed the algorithm and selected some hyperparameters by assessing the size of the induced grammars over the training sets of SCAN and GEOQUERY.\nOur grammar induction algorithm is similar to the transduction grammar induction method for machine translation by Saers et al. (2013). More broadly, compression-based criteria have been successfully used by a variety of models for language (Grünwald, 1995; Tang and Mooney, 2001; Ravi and Knight, 2009; Poon et al., 2009)."
    }, {
      "heading" : "A.3 NQG Parsing Model Details",
      "text" : "In this section we provide details on how we generate derivation scores, s(z,x), using a neural model, as introduced in § 4.1. The derivation scores decompose over anchored rules from our grammar:\ns(z,x) = ∑\n(r,i,j)∈z\nφ(r, i, j,x),\nwhere r is an index for a rule in G and i and j are indices defining the anchoring in x. The anchored rule scores, φ(r, i, j,x), are based on contextualized representations from a BERT (Devlin et al., 2019) encoder:\nφ(r, i, j,x) = fs([wi, wj ]) + e ᵀ rfr([wi, wj ]),\nwhere [wi, wj ] is the concatenation of the BERT representations for the first and last wordpiece in the anchored span, fr is a feed-forward network with hidden size d that outputs a vector ∈ Rd, fs is a feed-forward network with hidden size d that outputs a scalar, and er is an embedding ∈ Rd for the rule index r. Our formulation for encoding spans is similar to that used in other neural span-factored models (Stern et al., 2017; Lee et al., 2017)."
    }, {
      "heading" : "B Experimental Details",
      "text" : ""
    }, {
      "heading" : "B.1 Model Hyperparameters and Runtime",
      "text" : "We selected reasonable hyperparameter values and performed some minimal hyperparameter tuning\n18We use N = 500 for SCAN and N = 1000 for SPIDER. As the GEOQUERY training set contains < 500 unique examples, we use the entire training set.\nfor T5 and NQG based on random splits of the training sets for GEOQUERY and SPIDER. We used the same hyperparameters for all splits of a given dataset.\nFor T5, we selected a learning rate of 1e−4 from [1e−3, 1e−4, 1e−5], which we used for all experiments. Otherwise, we used the default hyperparameters for fine-tuning. We fine-tune for 3, 000 steps for GEOQUERY and 10, 000 for SPIDER. T5-Base trained with a learning rate of 1e−4 reached 94.2% accuracy at 3, 000 steps on a random split of the standard GeoQuery training set into 500 training and 100 validation examples.\nFor the NQG neural model, we use the pretrained BERT Tiny model of Turc et al. (2019) (4.4M parameters) for SCAN and SPIDER, and BERT Base (110.1M parameters) for GEOQUERY, where there is more headroom for improved scoring. We do not freeze pre-trained BERT parameters during training. For all experiments, we use d = 256 dimensions for computing anchored rule scores. We fine-tune for 256 steps and use a learning rate of 1e−4. We use a batch size of 256.\nWe train NQG on 8 V100 GPUs. Training NQG takes < 5 minutes for SCAN and SPIDER (BERT Tiny), and up to 90 minutes for GEOQUERY (BERT Base). We fine-tune T5 on 32 Cloud TPU v3 cores.19 For GEOQUERY, fine-tuning T5 takes approximately 5 and 37 hours for Base and 3B, respectively. For SPIDER, fine-tuning T5 takes approximately 5 and 77 hours for Base and 3B, respectively."
    }, {
      "heading" : "B.2 Dataset Preprocessing",
      "text" : "For GEOQUERY, we use the version of the dataset with variable-free FunQL logical forms (Kate et al., 2005), and expand certain functions based on their logical definitions, such that state(next_to_1(state(all))) becomes the more conventional intersection(state, next_to_1(state)). We replace entity mentions with placeholders (e.g. “m0”, “m1”) in both the source and target.\nFor SPIDER, we prepend the name of the target database to the source sequence. For T5, we also serialize the database schema as a string and append it to the source sequence similarly to Suhr et al. (2020). This schema string contains the names of all tables in the database, and the names of the columns for each table. As we use a maximum\n19https://cloud.google.com/tpu/\nsource sequence length of 512 for T5, this leads to some schema strings being truncated (affecting about 5% of training examples).\nSCAN did not require any dataset-specific preprocessing."
    }, {
      "heading" : "B.3 Atom and Compound Definitions",
      "text" : "For GEOQUERY, the tree structure of FunQL is given by explicit bracketing. We define atoms as individual FunQL symbols, and compounds as combinations between parent and child symbols in the FunQL tree. Example atoms are longest, river, and exclude and example compounds are longest(river) and exclude(longest(_), _).\nFor SPIDER, we tokenize the SQL string and define atoms as individual tokens. To define compounds, we parse the SQL string using an unambiguous CFG, and define compounds from the resulting parse tree. We define compounds over both first and second order edges in the resulting parse tree."
    }, {
      "heading" : "B.4 Grammar Sizes",
      "text" : "Induced grammar sizes for a selected split of each dataset are shown in Table 8. For SPIDER, the number of induced rules is larger than the original dataset due to the identity rules added during initialization."
    }, {
      "heading" : "B.5 GEOQUERY Variance",
      "text" : "In tables 2 and 5 we report the mean of 3 runs for NQG for GEOQUERY. The standard deviations for these runs are reported in Table 9. The reported standard deviations for NQG-T5 use the same finetuned T5 checkpoint, so they do not reflect any additional variance from different fine-tuned T5 checkpoints."
    }, {
      "heading" : "B.6 T5 GEOQUERY Errors",
      "text" : "We include several example T5-Base errors on the GEOQUERY TMCD split in Table 7."
    } ],
    "references" : [ {
      "title" : "The theory of parsing, translation, and compiling, volume 1",
      "author" : [ "Alfred V Aho", "Jeffrey D Ullman." ],
      "venue" : "Prentice-Hall Englewood Cliffs, NJ.",
      "citeRegEx" : "Aho and Ullman.,? 1972",
      "shortCiteRegEx" : "Aho and Ullman.",
      "year" : 1972
    }, {
      "title" : "Good-enough compositional data augmentation",
      "author" : [ "Jacob Andreas." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7556–7566, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Andreas.,? 2020",
      "shortCiteRegEx" : "Andreas.",
      "year" : 2020
    }, {
      "title" : "Semantic parsing as machine translation",
      "author" : [ "Jacob Andreas", "Andreas Vlachos", "Stephen Clark." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 47–52, Sofia, Bulgaria. Associ-",
      "citeRegEx" : "Andreas et al\\.,? 2013",
      "shortCiteRegEx" : "Andreas et al\\.",
      "year" : 2013
    }, {
      "title" : "Jump to better conclusions: Scan both left and right",
      "author" : [ "Jasmijn Bastings", "Marco Baroni", "Jason Weston", "Kyunghyun Cho", "Douwe Kiela." ],
      "venue" : "Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Net-",
      "citeRegEx" : "Bastings et al\\.,? 2018",
      "shortCiteRegEx" : "Bastings et al\\.",
      "year" : 2018
    }, {
      "title" : "A discriminative latent variable model for statistical machine translation",
      "author" : [ "Phil Blunsom", "Trevor Cohn", "Miles Osborne." ],
      "venue" : "Proceedings of ACL-08:",
      "citeRegEx" : "Blunsom et al\\.,? 2008",
      "shortCiteRegEx" : "Blunsom et al\\.",
      "year" : 2008
    }, {
      "title" : "Compositional generalization via neural-symbolic stack machines",
      "author" : [ "Xinyun Chen", "Chen Liang", "Adams Wei Yu", "Dawn Song", "Denny Zhou." ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "Hierarchical phrase-based translation",
      "author" : [ "David Chiang." ],
      "venue" : "computational linguistics, 33(2):201–228.",
      "citeRegEx" : "Chiang.,? 2007",
      "shortCiteRegEx" : "Chiang.",
      "year" : 2007
    }, {
      "title" : "RYANSQL: recursively applying sketch-based slot fillings for complex text-to-sql in cross-domain databases",
      "author" : [ "DongHyun Choi", "Myeongcheol Shin", "EungGyun Kim", "Dong Ryeol Shin." ],
      "venue" : "arXiv preprint arXiv:2004.03125.",
      "citeRegEx" : "Choi et al\\.,? 2020",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2020
    }, {
      "title" : "Measures of distance between probability distributions",
      "author" : [ "JK Chung", "PL Kannappan", "CT Ng", "PK Sahoo." ],
      "venue" : "Journal of mathematical analysis and applications, 138(1):280–292.",
      "citeRegEx" : "Chung et al\\.,? 1989",
      "shortCiteRegEx" : "Chung et al\\.",
      "year" : 1989
    }, {
      "title" : "Programming languages and their compilers: Preliminary notes",
      "author" : [ "John Cocke." ],
      "venue" : "New York University.",
      "citeRegEx" : "Cocke.,? 1969",
      "shortCiteRegEx" : "Cocke.",
      "year" : 1969
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Language to logical form with neural attention",
      "author" : [ "Li Dong", "Mirella Lapata." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 33–43.",
      "citeRegEx" : "Dong and Lapata.,? 2016",
      "shortCiteRegEx" : "Dong and Lapata.",
      "year" : 2016
    }, {
      "title" : "Coarse-to-fine decoding for neural semantic parsing",
      "author" : [ "Li Dong", "Mirella Lapata." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 731–742, Melbourne, Australia. Association",
      "citeRegEx" : "Dong and Lapata.,? 2018",
      "shortCiteRegEx" : "Dong and Lapata.",
      "year" : 2018
    }, {
      "title" : "Neural crf parsing",
      "author" : [ "Greg Durrett", "Dan Klein." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages",
      "citeRegEx" : "Durrett and Klein.,? 2015",
      "shortCiteRegEx" : "Durrett and Klein.",
      "year" : 2015
    }, {
      "title" : "Improving text-to-SQL evaluation methodology",
      "author" : [ "Catherine Finegan-Dollak", "Jonathan K. Kummerfeld", "Li Zhang", "Karthik Ramanathan", "Sesh Sadasivam", "Rui Zhang", "Dragomir Radev." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association",
      "citeRegEx" : "Finegan.Dollak et al\\.,? 2018",
      "shortCiteRegEx" : "Finegan.Dollak et al\\.",
      "year" : 2018
    }, {
      "title" : "Compositional generalization in semantic parsing: Pre-training vs",
      "author" : [ "Daniel Furrer", "Marc van Zee", "Nathan Scales", "Nathanael Schärli." ],
      "venue" : "specialized architectures. arXiv preprint arXiv:2007.08970.",
      "citeRegEx" : "Furrer et al\\.,? 2020",
      "shortCiteRegEx" : "Furrer et al\\.",
      "year" : 2020
    }, {
      "title" : "Permutation equivariant models for compositional generalization in language",
      "author" : [ "Jonathan Gordon", "David Lopez-Paz", "Marco Baroni", "Diane Bouchacourt." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Gordon et al\\.,? 2019",
      "shortCiteRegEx" : "Gordon et al\\.",
      "year" : 2019
    }, {
      "title" : "A minimum description length approach to grammar inference",
      "author" : [ "Peter Grünwald." ],
      "venue" : "International Joint Conference on Artificial Intelligence, pages 203–216. Springer.",
      "citeRegEx" : "Grünwald.,? 1995",
      "shortCiteRegEx" : "Grünwald.",
      "year" : 1995
    }, {
      "title" : "A tutorial introduction to the minimum description length principle",
      "author" : [ "Peter Grunwald." ],
      "venue" : "arXiv preprint math/0406077.",
      "citeRegEx" : "Grunwald.,? 2004",
      "shortCiteRegEx" : "Grunwald.",
      "year" : 2004
    }, {
      "title" : "Towards complex text-to-sql in cross-domain database with intermediate representation",
      "author" : [ "Jiaqi Guo", "Zecheng Zhan", "Yan Gao", "Yan Xiao", "Jian-Guang Lou", "Ting Liu", "Dongmei Zhang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Asso-",
      "citeRegEx" : "Guo et al\\.,? 2019",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2019
    }, {
      "title" : "Don’t paraphrase, detect! rapid and effective data collection for semantic parsing",
      "author" : [ "Jonathan Herzig", "Jonathan Berant." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Herzig and Berant.,? 2019",
      "shortCiteRegEx" : "Herzig and Berant.",
      "year" : 2019
    }, {
      "title" : "Spanbased semantic parsing for compositional generalization",
      "author" : [ "Jonathan Herzig", "Jonathan Berant." ],
      "venue" : "arXiv preprint arXiv:2009.06040.",
      "citeRegEx" : "Herzig and Berant.,? 2020",
      "shortCiteRegEx" : "Herzig and Berant.",
      "year" : 2020
    }, {
      "title" : "Compositionality",
      "author" : [ "Theo MV Janssen", "Barbara H Partee." ],
      "venue" : "Handbook of logic and language, pages 417–473. Elsevier.",
      "citeRegEx" : "Janssen and Partee.,? 1997",
      "shortCiteRegEx" : "Janssen and Partee.",
      "year" : 1997
    }, {
      "title" : "Data recombination for neural semantic parsing",
      "author" : [ "Robin Jia", "Percy Liang." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 12–22.",
      "citeRegEx" : "Jia and Liang.,? 2016",
      "shortCiteRegEx" : "Jia and Liang.",
      "year" : 2016
    }, {
      "title" : "An efficient recognition and syntax analysis algorithm for context-free languages",
      "author" : [ "T. Kasami." ],
      "venue" : "Technical Report AFCRL-65-758, Air Force Cambridge Research Laboratory, Bedford, MA.",
      "citeRegEx" : "Kasami.,? 1965",
      "shortCiteRegEx" : "Kasami.",
      "year" : 1965
    }, {
      "title" : "Learning to transform natural to formal languages",
      "author" : [ "Rohit J Kate", "Yuk Wah Wong", "Raymond J Mooney." ],
      "venue" : "Proceedings of the National Conference on Artificial Intelligence, volume 20, page 1062. Menlo Park, CA; Cambridge, MA; London; AAAI",
      "citeRegEx" : "Kate et al\\.,? 2005",
      "shortCiteRegEx" : "Kate et al\\.",
      "year" : 2005
    }, {
      "title" : "Measuring compositional generalization: A comprehensive method on realistic data",
      "author" : [ "Marc van Zee", "Olivier Bousquet." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Zee and Bousquet.,? 2020",
      "shortCiteRegEx" : "Zee and Bousquet.",
      "year" : 2020
    }, {
      "title" : "COGS: A compositional generalization challenge based on semantic interpretation",
      "author" : [ "Najoung Kim", "Tal Linzen." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 9087–9105, Online. As-",
      "citeRegEx" : "Kim and Linzen.,? 2020",
      "shortCiteRegEx" : "Kim and Linzen.",
      "year" : 2020
    }, {
      "title" : "Scaling semantic parsers with on-the-fly ontology matching",
      "author" : [ "Tom Kwiatkowski", "Eunsol Choi", "Yoav Artzi", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2013 conference on empirical methods in natural language processing, pages 1545–1556.",
      "citeRegEx" : "Kwiatkowski et al\\.,? 2013",
      "shortCiteRegEx" : "Kwiatkowski et al\\.",
      "year" : 2013
    }, {
      "title" : "Inducing probabilistic ccg grammars from logical form with higherorder unification",
      "author" : [ "Tom Kwiatkowski", "Luke Zettlemoyer", "Sharon Goldwater", "Mark Steedman." ],
      "venue" : "Proceedings of the 2010 conference on empirical methods in natural language",
      "citeRegEx" : "Kwiatkowski et al\\.,? 2010",
      "shortCiteRegEx" : "Kwiatkowski et al\\.",
      "year" : 2010
    }, {
      "title" : "Human few-shot learning of compositional instructions",
      "author" : [ "B.M. Lake", "T. Linzen", "M. Baroni." ],
      "venue" : "Proceedings of the 41st Annual Conference of the Cognitive Science Society.",
      "citeRegEx" : "Lake et al\\.,? 2019",
      "shortCiteRegEx" : "Lake et al\\.",
      "year" : 2019
    }, {
      "title" : "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
      "author" : [ "Brenden Lake", "Marco Baroni." ],
      "venue" : "International Conference on Machine Learning, pages 2873–2882.",
      "citeRegEx" : "Lake and Baroni.,? 2018",
      "shortCiteRegEx" : "Lake and Baroni.",
      "year" : 2018
    }, {
      "title" : "Compositional generalization through meta sequence-to-sequence learning",
      "author" : [ "Brenden M Lake." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 9788–9798.",
      "citeRegEx" : "Lake.,? 2019",
      "shortCiteRegEx" : "Lake.",
      "year" : 2019
    }, {
      "title" : "Building machines that learn and think like people",
      "author" : [ "Brenden M Lake", "Tomer D Ullman", "Joshua B Tenenbaum", "Samuel J Gershman." ],
      "venue" : "Behavioral and brain sciences, 40.",
      "citeRegEx" : "Lake et al\\.,? 2017",
      "shortCiteRegEx" : "Lake et al\\.",
      "year" : 2017
    }, {
      "title" : "End-to-end neural coreference resolution",
      "author" : [ "Kenton Lee", "Luheng He", "Mike Lewis", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 188–197.",
      "citeRegEx" : "Lee et al\\.,? 2017",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2017
    }, {
      "title" : "Improving semantic parsing with enriched synchronous context-free grammar",
      "author" : [ "Junhui Li", "Muhua Zhu", "Wei Lu", "Guodong Zhou." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1455–",
      "citeRegEx" : "Li et al\\.,? 2015",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2015
    }, {
      "title" : "Compositional generalization for primitive substitutions",
      "author" : [ "Yuanpeng Li", "Liang Zhao", "Jianyu Wang", "Joel Hestness." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Compositional generalization by learning analytical expressions",
      "author" : [ "Qian Liu", "Shengnan An", "Jian-Guang Lou", "Bei Chen", "Zeqi Lin", "Yan Gao", "Bin Zhou", "Nanning Zheng", "Dongmei Zhang." ],
      "venue" : "Advances in Neural Information Processing Systems, 33.",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Universal grammar",
      "author" : [ "Richard Montague." ],
      "venue" : "Theoria, 36(3):373–398.",
      "citeRegEx" : "Montague.,? 1970",
      "shortCiteRegEx" : "Montague.",
      "year" : 1970
    }, {
      "title" : "The EOS decision and length extrapolation",
      "author" : [ "Benjamin Newman", "John Hewitt", "Percy Liang", "Christopher D. Manning." ],
      "venue" : "Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 276–291,",
      "citeRegEx" : "Newman et al\\.,? 2020",
      "shortCiteRegEx" : "Newman et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning compositional rules via neural program synthesis",
      "author" : [ "Maxwell I Nye", "Armando Solar-Lezama", "Joshua B Tenenbaum", "Brenden M Lake." ],
      "venue" : "arXiv preprint arXiv:2003.05562.",
      "citeRegEx" : "Nye et al\\.,? 2020",
      "shortCiteRegEx" : "Nye et al\\.",
      "year" : 2020
    }, {
      "title" : "Improving compositional generalization in semantic parsing",
      "author" : [ "Inbar Oren", "Jonathan Herzig", "Nitish Gupta", "Matt Gardner", "Jonathan Berant." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings,",
      "citeRegEx" : "Oren et al\\.,? 2020",
      "shortCiteRegEx" : "Oren et al\\.",
      "year" : 2020
    }, {
      "title" : "Unsupervised morphological segmentation with log-linear models",
      "author" : [ "Hoifung Poon", "Colin Cherry", "Kristina Toutanova." ],
      "venue" : "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Associa-",
      "citeRegEx" : "Poon et al\\.,? 2009",
      "shortCiteRegEx" : "Poon et al\\.",
      "year" : 2009
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J Liu." ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Raffel et al\\.,? 2020",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2020
    }, {
      "title" : "Minimized models for unsupervised part-of-speech tagging",
      "author" : [ "Sujith Ravi", "Kevin Knight." ],
      "venue" : "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the",
      "citeRegEx" : "Ravi and Knight.,? 2009",
      "shortCiteRegEx" : "Ravi and Knight.",
      "year" : 2009
    }, {
      "title" : "Beyond accuracy: Behavioral testing of NLP models with CheckList",
      "author" : [ "Marco Tulio Ribeiro", "Tongshuang Wu", "Carlos Guestrin", "Sameer Singh." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4902–",
      "citeRegEx" : "Ribeiro et al\\.,? 2020",
      "shortCiteRegEx" : "Ribeiro et al\\.",
      "year" : 2020
    }, {
      "title" : "Modeling by shortest data description",
      "author" : [ "Jorma Rissanen." ],
      "venue" : "Automatica, 14(5):465–471.",
      "citeRegEx" : "Rissanen.,? 1978",
      "shortCiteRegEx" : "Rissanen.",
      "year" : 1978
    }, {
      "title" : "Compositional generalization in a deep seq2seq model by separating syntax and semantics. arXiv preprint arXiv:1904.09708",
      "author" : [ "Jake Russin", "Jason Jo", "Randall C O’Reilly", "Yoshua Bengio" ],
      "venue" : null,
      "citeRegEx" : "Russin et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Russin et al\\.",
      "year" : 2019
    }, {
      "title" : "Unsupervised transduction grammar induction via minimum description length",
      "author" : [ "Markus Saers", "Karteek Addanki", "Dekai Wu." ],
      "venue" : "Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 67–73, Sofia, Bulgaria. Association for",
      "citeRegEx" : "Saers et al\\.,? 2013",
      "shortCiteRegEx" : "Saers et al\\.",
      "year" : 2013
    }, {
      "title" : "Quasisynchronous grammars: Alignment by soft projection of syntactic dependencies",
      "author" : [ "David A Smith", "Jason Eisner." ],
      "venue" : "Proceedings on the Workshop on Statistical Machine Translation, pages 23–30.",
      "citeRegEx" : "Smith and Eisner.,? 2006",
      "shortCiteRegEx" : "Smith and Eisner.",
      "year" : 2006
    }, {
      "title" : "A minimal span-based neural constituency parser",
      "author" : [ "Mitchell Stern", "Jacob Andreas", "Dan Klein." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 818–827, Vancouver, Canada.",
      "citeRegEx" : "Stern et al\\.,? 2017",
      "shortCiteRegEx" : "Stern et al\\.",
      "year" : 2017
    }, {
      "title" : "Exploring unexplored generalization challenges for cross-database semantic parsing",
      "author" : [ "Alane Suhr", "Ming-Wei Chang", "Peter Shaw", "Kenton Lee." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8372–",
      "citeRegEx" : "Suhr et al\\.,? 2020",
      "shortCiteRegEx" : "Suhr et al\\.",
      "year" : 2020
    }, {
      "title" : "Using multiple clause constructors in inductive logic programming for semantic parsing",
      "author" : [ "Lappoon R Tang", "Raymond J Mooney." ],
      "venue" : "European Conference on Machine Learning, pages 466–477. Springer.",
      "citeRegEx" : "Tang and Mooney.,? 2001",
      "shortCiteRegEx" : "Tang and Mooney.",
      "year" : 2001
    }, {
      "title" : "Well-read students learn better: On the importance of pre-training compact models",
      "author" : [ "Iulia Turc", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1908.08962.",
      "citeRegEx" : "Turc et al\\.,? 2019",
      "shortCiteRegEx" : "Turc et al\\.",
      "year" : 2019
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in neural information processing systems, pages 5998–6008.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Learning synchronous grammars for semantic parsing with lambda calculus",
      "author" : [ "Yuk Wah Wong", "Raymond Mooney." ],
      "venue" : "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 960–967.",
      "citeRegEx" : "Wong and Mooney.,? 2007",
      "shortCiteRegEx" : "Wong and Mooney.",
      "year" : 2007
    }, {
      "title" : "Learning for semantic parsing with statistical machine translation",
      "author" : [ "Yuk Wah Wong", "Raymond J Mooney." ],
      "venue" : "Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Com-",
      "citeRegEx" : "Wong and Mooney.,? 2006",
      "shortCiteRegEx" : "Wong and Mooney.",
      "year" : 2006
    }, {
      "title" : "Recognition and parsing of context-free languages in time n3",
      "author" : [ "Daniel H Younger." ],
      "venue" : "Information and control, 10(2):189–208.",
      "citeRegEx" : "Younger.,? 1967",
      "shortCiteRegEx" : "Younger.",
      "year" : 1967
    }, {
      "title" : "Spider: A largescale human-labeled dataset for complex and cross",
      "author" : [ "Tao Yu", "Rui Zhang", "Kai Yang", "Michihiro Yasunaga", "Dongxu Wang", "Zifan Li", "James Ma", "Irene Li", "Qingning Yao", "Shanelle Roman", "Zilin Zhang", "Dragomir Radev" ],
      "venue" : null,
      "citeRegEx" : "Yu et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning to parse database queries using inductive logic programming",
      "author" : [ "John M Zelle", "Raymond J Mooney." ],
      "venue" : "Proceedings of the thirteenth national conference on Artificial intelligence-Volume 2, pages 1050–1055.",
      "citeRegEx" : "Zelle and Mooney.,? 1996",
      "shortCiteRegEx" : "Zelle and Mooney.",
      "year" : 1996
    }, {
      "title" : "Online learning of relaxed ccg grammars for parsing to logical form",
      "author" : [ "Luke Zettlemoyer", "Michael Collins." ],
      "venue" : "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language",
      "citeRegEx" : "Zettlemoyer and Collins.,? 2007",
      "shortCiteRegEx" : "Zettlemoyer and Collins.",
      "year" : 2007
    }, {
      "title" : "Learning to map sentences to logical form: structured classification with probabilistic categorial grammars",
      "author" : [ "Luke S Zettlemoyer", "Michael Collins." ],
      "venue" : "Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence, pages 658–666.",
      "citeRegEx" : "Zettlemoyer and Collins.,? 2005",
      "shortCiteRegEx" : "Zettlemoyer and Collins.",
      "year" : 2005
    }, {
      "title" : "Compositional generalization via semantic tagging",
      "author" : [ "Hao Zheng", "Mirella Lapata." ],
      "venue" : "arXiv preprint arXiv:2010.11818.",
      "citeRegEx" : "Zheng and Lapata.,? 2020",
      "shortCiteRegEx" : "Zheng and Lapata.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "Sequence-to-sequence (seq2seq) models have been widely used in semantic parsing (Dong and Lapata, 2016; Jia and Liang, 2016) and excel at handling the natural language variation1 of humangenerated queries.",
      "startOffset" : 80,
      "endOffset" : 124
    }, {
      "referenceID" : 23,
      "context" : "Sequence-to-sequence (seq2seq) models have been widely used in semantic parsing (Dong and Lapata, 2016; Jia and Liang, 2016) and excel at handling the natural language variation1 of humangenerated queries.",
      "startOffset" : 80,
      "endOffset" : 124
    }, {
      "referenceID" : 36,
      "context" : "This has motivated many specialized architectures that improve peformance on SCAN (Li et al., 2019; Russin et al., 2019; Gordon et al., 2019; Lake, 2019; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 82,
      "endOffset" : 208
    }, {
      "referenceID" : 47,
      "context" : "This has motivated many specialized architectures that improve peformance on SCAN (Li et al., 2019; Russin et al., 2019; Gordon et al., 2019; Lake, 2019; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 82,
      "endOffset" : 208
    }, {
      "referenceID" : 16,
      "context" : "This has motivated many specialized architectures that improve peformance on SCAN (Li et al., 2019; Russin et al., 2019; Gordon et al., 2019; Lake, 2019; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 82,
      "endOffset" : 208
    }, {
      "referenceID" : 32,
      "context" : "This has motivated many specialized architectures that improve peformance on SCAN (Li et al., 2019; Russin et al., 2019; Gordon et al., 2019; Lake, 2019; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 82,
      "endOffset" : 208
    }, {
      "referenceID" : 37,
      "context" : "This has motivated many specialized architectures that improve peformance on SCAN (Li et al., 2019; Russin et al., 2019; Gordon et al., 2019; Lake, 2019; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 82,
      "endOffset" : 208
    }, {
      "referenceID" : 40,
      "context" : "This has motivated many specialized architectures that improve peformance on SCAN (Li et al., 2019; Russin et al., 2019; Gordon et al., 2019; Lake, 2019; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 82,
      "endOffset" : 208
    }, {
      "referenceID" : 5,
      "context" : "This has motivated many specialized architectures that improve peformance on SCAN (Li et al., 2019; Russin et al., 2019; Gordon et al., 2019; Lake, 2019; Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 82,
      "endOffset" : 208
    }, {
      "referenceID" : 15,
      "context" : "For example, large pre-trained seq2seq models that perform well on in-distribution evaluations do not address most of the compositional generalization challenges proposed in SCAN (Furrer et al., 2020).",
      "startOffset" : 179,
      "endOffset" : 200
    }, {
      "referenceID" : 30,
      "context" : "First, humans have been shown to be adept compositional learners (Lake et al., 2019).",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 33,
      "context" : "Several authors have argued that a greater focus on compositional generalization is an important path to more human-like generalization and NLU (Lake et al., 2017; Battaglia et al., 2018).",
      "startOffset" : 144,
      "endOffset" : 187
    }, {
      "referenceID" : 45,
      "context" : "Second, it is practically important to assess performance on non-synthetic data and out-of-distribution examples, as random train and test splits can overestimate real-world performance and miss important error cases (Ribeiro et al., 2020).",
      "startOffset" : 217,
      "endOffset" : 239
    }, {
      "referenceID" : 43,
      "context" : "In addition, we introduce and evaluate NQG-T5, a hybrid model that combines NQG with T5 (Raffel et al., 2020), leading to improvements across several compositional generalization evaluations while also being competitive on the standard splits of GEOQUERY (Zelle and Mooney, 1996) and SPITRAIN AND TEST SPLITS",
      "startOffset" : 88,
      "endOffset" : 109
    }, {
      "referenceID" : 59,
      "context" : ", 2020), leading to improvements across several compositional generalization evaluations while also being competitive on the standard splits of GEOQUERY (Zelle and Mooney, 1996) and SPITRAIN AND TEST SPLITS",
      "startOffset" : 153,
      "endOffset" : 177
    }, {
      "referenceID" : 31,
      "context" : "A widely used synthetic dataset for assessing compositional generalization is SCAN (Lake and Baroni, 2018), which consists of natural language commands (e.",
      "startOffset" : 83,
      "endOffset" : 106
    }, {
      "referenceID" : 3,
      "context" : "Other synthetic datasets have been developed to evaluate aspects of compositional generalization beyond SCAN, including NACS (Bastings et al., 2018), CFQ (Keysers et al.",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 14,
      "context" : "Another method for generating train and test splits is the template4 split (Finegan-Dollak et al., 2018).",
      "startOffset" : 75,
      "endOffset" : 104
    }, {
      "referenceID" : 37,
      "context" : "Several of them have recently reached 100% accuracy across multiple SCAN challenges (Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 84,
      "endOffset" : 139
    }, {
      "referenceID" : 40,
      "context" : "Several of them have recently reached 100% accuracy across multiple SCAN challenges (Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 84,
      "endOffset" : 139
    }, {
      "referenceID" : 5,
      "context" : "Several of them have recently reached 100% accuracy across multiple SCAN challenges (Liu et al., 2020; Nye et al., 2020; Chen et al., 2020).",
      "startOffset" : 84,
      "endOffset" : 139
    }, {
      "referenceID" : 43,
      "context" : "(2020) finds that pre-training alone cannot solve several compositional generalization challenges, despite its effectiveness across NLP tasks such as question answering (Raffel et al., 2020).",
      "startOffset" : 169,
      "endOffset" : 190
    }, {
      "referenceID" : 23,
      "context" : "While our work focuses on modeling approaches, compositional data augmentation techniques have also been proposed (Jia and Liang, 2016; Andreas, 2020).",
      "startOffset" : 114,
      "endOffset" : 150
    }, {
      "referenceID" : 1,
      "context" : "While our work focuses on modeling approaches, compositional data augmentation techniques have also been proposed (Jia and Liang, 2016; Andreas, 2020).",
      "startOffset" : 114,
      "endOffset" : 150
    }, {
      "referenceID" : 8,
      "context" : "The Chernoff coefficient Cα(P‖Q) = ∑ k p α k q 1−α k (Chung et al., 1989) is used with α = 0.",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 43,
      "context" : "As visualized in Figure 3, in cases where NQG fails to produce an output, we return the output from T5 (Raffel et al., 2020), a pre-trained seq2seq model.",
      "startOffset" : 103,
      "endOffset" : 124
    }, {
      "referenceID" : 43,
      "context" : "Figure 3: Overview of how predictions are generated by NQG-T5, a simple yet effective combination of T5 (Raffel et al., 2020) with a high-precision grammarbased approach, NQG.",
      "startOffset" : 104,
      "endOffset" : 125
    }, {
      "referenceID" : 6,
      "context" : "Compared to related work based on SCFGs for machine translation (Chiang, 2007) and semantic parsing, NQG uses a slightly more general grammar formal-",
      "startOffset" : 64,
      "endOffset" : 78
    }, {
      "referenceID" : 49,
      "context" : "Therefore, we adopt the terminology of quasi-synchronous context-free grammars (Smith and Eisner, 2006), or QCFGs, to refer to our induced grammar G.",
      "startOffset" : 79,
      "endOffset" : 103
    }, {
      "referenceID" : 9,
      "context" : "This enables efficient parsing using an algorithm similar to CKY (Cocke, 1969; Kasami, 1965; Younger, 1967) that does not require binarization of the grammar.",
      "startOffset" : 65,
      "endOffset" : 107
    }, {
      "referenceID" : 24,
      "context" : "This enables efficient parsing using an algorithm similar to CKY (Cocke, 1969; Kasami, 1965; Younger, 1967) that does not require binarization of the grammar.",
      "startOffset" : 65,
      "endOffset" : 107
    }, {
      "referenceID" : 57,
      "context" : "This enables efficient parsing using an algorithm similar to CKY (Cocke, 1969; Kasami, 1965; Younger, 1967) that does not require binarization of the grammar.",
      "startOffset" : 65,
      "endOffset" : 107
    }, {
      "referenceID" : 46,
      "context" : "We follow the Minimum Description Length (MDL) principle (Rissanen, 1978; Grunwald, 2004) as a way to formalize this intuition.",
      "startOffset" : 57,
      "endOffset" : 89
    }, {
      "referenceID" : 18,
      "context" : "We follow the Minimum Description Length (MDL) principle (Rissanen, 1978; Grunwald, 2004) as a way to formalize this intuition.",
      "startOffset" : 57,
      "endOffset" : 89
    }, {
      "referenceID" : 10,
      "context" : "Unlike Durrett and Klein (2015), we compute these scores based on contextualized representations from a BERT (Devlin et al., 2019) encoder.",
      "startOffset" : 109,
      "endOffset" : 130
    }, {
      "referenceID" : 6,
      "context" : "We note that NQG is closely related to work that uses synchronous grammars for hierarchical statistical machine translation, such as Hiero (Chiang, 2007).",
      "startOffset" : 139,
      "endOffset" : 153
    }, {
      "referenceID" : 56,
      "context" : "SCFG models for machine translation applied to semantic parsing (Wong and Mooney, 2006; Andreas et al., 2013), our neural model conditions on global context from the source x via contextual word embeddings, and our grammar’s rules do not need to carry source context to aid disambiguation.",
      "startOffset" : 64,
      "endOffset" : 109
    }, {
      "referenceID" : 2,
      "context" : "SCFG models for machine translation applied to semantic parsing (Wong and Mooney, 2006; Andreas et al., 2013), our neural model conditions on global context from the source x via contextual word embeddings, and our grammar’s rules do not need to carry source context to aid disambiguation.",
      "startOffset" : 64,
      "endOffset" : 109
    }, {
      "referenceID" : 43,
      "context" : "T5 (Raffel et al., 2020) is a pre-trained sequence-tosequence Transformer model (Vaswani et al.",
      "startOffset" : 3,
      "endOffset" : 24
    }, {
      "referenceID" : 54,
      "context" : ", 2020) is a pre-trained sequence-tosequence Transformer model (Vaswani et al., 2017).",
      "startOffset" : 63,
      "endOffset" : 85
    }, {
      "referenceID" : 31,
      "context" : "For our main experiments, we focus on evaluation across multiple splits of two datasets with compositional queries: SCAN (Lake and Baroni, 2018) and GEOQUERY (Zelle and Mooney, 1996; Tang and Mooney, 2001).",
      "startOffset" : 121,
      "endOffset" : 144
    }, {
      "referenceID" : 59,
      "context" : "For our main experiments, we focus on evaluation across multiple splits of two datasets with compositional queries: SCAN (Lake and Baroni, 2018) and GEOQUERY (Zelle and Mooney, 1996; Tang and Mooney, 2001).",
      "startOffset" : 158,
      "endOffset" : 205
    }, {
      "referenceID" : 52,
      "context" : "For our main experiments, we focus on evaluation across multiple splits of two datasets with compositional queries: SCAN (Lake and Baroni, 2018) and GEOQUERY (Zelle and Mooney, 1996; Tang and Mooney, 2001).",
      "startOffset" : 158,
      "endOffset" : 205
    }, {
      "referenceID" : 32,
      "context" : "Some previous approaches for SCAN require task-specific information such as the mapping of atoms (Lake, 2019; Gordon et al., 2019) or a grammar mimicking the training data (Nye et al.",
      "startOffset" : 97,
      "endOffset" : 130
    }, {
      "referenceID" : 16,
      "context" : "Some previous approaches for SCAN require task-specific information such as the mapping of atoms (Lake, 2019; Gordon et al., 2019) or a grammar mimicking the training data (Nye et al.",
      "startOffset" : 97,
      "endOffset" : 130
    }, {
      "referenceID" : 40,
      "context" : ", 2019) or a grammar mimicking the training data (Nye et al., 2020), and as such are difficult to adapt to non-synthetic datasets.",
      "startOffset" : 49,
      "endOffset" : 67
    }, {
      "referenceID" : 47,
      "context" : "approaches that do not need task-specific resources, we evaluate two models with publicly available code: Syntactic Attention (Russin et al., 2019) and CGPS (Li et al.",
      "startOffset" : 126,
      "endOffset" : 147
    }, {
      "referenceID" : 31,
      "context" : "Datasets For the SCAN dataset, we evaluate using the length split and two primitive splits, jump and turn left, included in the original dataset (Lake and Baroni, 2018).",
      "startOffset" : 145,
      "endOffset" : 168
    }, {
      "referenceID" : 59,
      "context" : "GEOQUERY (Zelle and Mooney, 1996) contains natural language questions about US geography.",
      "startOffset" : 9,
      "endOffset" : 33
    }, {
      "referenceID" : 25,
      "context" : "We use a variant of Functional Query Language (FunQL) as the target representation (Kate et al., 2005).",
      "startOffset" : 83,
      "endOffset" : 102
    }, {
      "referenceID" : 37,
      "context" : "LANE (Liu et al., 2020) 100 — 100 100 — — — — — NSSM (Chen et al.",
      "startOffset" : 5,
      "endOffset" : 23
    }, {
      "referenceID" : 5,
      "context" : ", 2020) 100 — 100 100 — — — — — NSSM (Chen et al., 2020) 100 — 100 — — — — — — Syntactic Attn.",
      "startOffset" : 37,
      "endOffset" : 56
    }, {
      "referenceID" : 21,
      "context" : "0† — — — — SBSP (Herzig and Berant, 2020) 100 100 100 100 86.",
      "startOffset" : 16,
      "endOffset" : 41
    }, {
      "referenceID" : 1,
      "context" : "Additionally, we include results for GECA9 (Andreas, 2020), a data augmentation method, as well as LANE (Liu et al.",
      "startOffset" : 43,
      "endOffset" : 58
    }, {
      "referenceID" : 37,
      "context" : "Additionally, we include results for GECA9 (Andreas, 2020), a data augmentation method, as well as LANE (Liu et al., 2020) and NSSM (Chen et al.",
      "startOffset" : 104,
      "endOffset" : 122
    }, {
      "referenceID" : 21,
      "context" : "We also compare with SpanBasedSP11 (Herzig and Berant, 2020).",
      "startOffset" : 35,
      "endOffset" : 60
    }, {
      "referenceID" : 23,
      "context" : "Note that the performance of GECA depends on both the quality of the generated data and the underlying parser (Jia and Liang, 2016), which can complicate the analysis.",
      "startOffset" : 110,
      "endOffset" : 131
    }, {
      "referenceID" : 58,
      "context" : "We now compare the approaches on SPIDER (Yu et al., 2018), a non-synthetic text-to-SQL dataset that includes the further challenges of schema linking and modeling complex SQL syntax.",
      "startOffset" : 40,
      "endOffset" : 57
    }, {
      "referenceID" : 58,
      "context" : "We report exact set match without values, the standard Spider evaluation metric (Yu et al., 2018).",
      "startOffset" : 80,
      "endOffset" : 97
    }, {
      "referenceID" : 7,
      "context" : "To our surprise, T5-3B proves to be competitive with the state-ofthe-art (Choi et al., 2020) for approaches without access to database contents beyond the table and column names.",
      "startOffset" : 73,
      "endOffset" : 92
    }, {
      "referenceID" : 19,
      "context" : "Intermediate representations for SQL such as SemQL (Guo et al., 2019) may help increase the correspondence between source and target syntax.",
      "startOffset" : 51,
      "endOffset" : 69
    } ],
    "year" : 2021,
    "abstractText" : "Sequence-to-sequence models excel at handling natural language variation, but have been shown to struggle with out-of-distribution compositional generalization. This has motivated new specialized architectures with stronger compositional biases, but most of these approaches have only been evaluated on synthetically-generated datasets, which are not representative of natural language variation. In this work we ask: can we develop a semantic parsing approach that handles both natural language variation and compositional generalization? To better assess this capability, we propose new train and test splits of non-synthetic datasets. We demonstrate that strong existing approaches do not perform well across a broad set of evaluations. We also propose NQG-T5, a hybrid model that combines a highprecision grammar-based approach with a pretrained sequence-to-sequence model. It outperforms existing approaches across several compositional generalization challenges on nonsynthetic data, while also being competitive with the state-of-the-art on standard evaluations. While still far from solving this problem, our study highlights the importance of diverse evaluations and the open challenge of handling both compositional generalization and natural language variation in semantic parsing.",
    "creator" : "LaTeX with hyperref"
  }
}