{
  "name" : "2021.acl-long.190.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Enhancing the generalization for Intent Classification and Out-of-Domain Detection in SLU",
    "authors" : [ "Yilin Shen", "Yen-Chang Hsu", "Avik Ray", "Hongxia Jin" ],
    "emails" : [ "yilin.shen@samsung.com", "yenchang.hsu@samsung.com", "avik.r@samsung.com", "hongxia.jin@samsung.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2443–2453\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n2443"
    }, {
      "heading" : "1 Introduction",
      "text" : "Spoken language understanding (SLU) systems play a crucial role in ubiquitous artificially intelligent voice-enabled personal assistants (PA). SLU needs to process a wide variety of user utterances and carry out user’s intents, a.k.a. intent classification. Many deep neural network-based SLU models have recently been proposed and have demonstrated significant progress (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Chen et al., 2019) in classification accuracy. These models usually apply the closed-world assumption, in which the SLU model is trained with predefined domains, and the model expects to see the same data distribution\nduring both training and testing. However, such an assumption is not held in the practical use case of PA systems, where the system is used under a dynamic and open environment with personal expressions, new vocabulary, and unknown intents that are out of the design scope.\nTo address the challenges in open-world settings, previous works adopt varied strategies. Shen et al. (2018a, 2019c) use a cold-start algorithm to generate additional training data to cover a larger variety of utterances. This strategy relies on the software developers to pre-build all possible skills. Shen et al. (2019b,a) introduce a SkillBot that allows users to build up their own skills. Recently, Ray et al. (2018, 2019); Shen et al. (2018b, 2019d) enables an SLU model to incorporate user personalization over time. However, the above approaches do not explicitly address unsupported user utterances/intents, leading to catastrophic failures illustrated in Figure 1. Thus, it is critically desirable for an SLU system to classify the supported intents (in-domain (IND)) and reject unsupported ones (out-of-domain (OOD)) correctly.\nA straightforward solution is to collect OOD data and train a supervised binary classifier on both IND data and OOD data (Hendrycks et al., 2018). However, collecting a representative set of OOD data could be impractical due to the infinite\ncompositionality of language. Arbitrarily selecting a subset could incur the selection bias, causing the learned model might not generalize to unseen OOD data. Ryu et al. (2017, 2018) avoid learning with OOD data by using generative models (e.g., autoencoder and GAN) to capture the IND data distribution, then judge IND/OOD based on the reconstruction error or likelihood. Recently, Tan et al. (2019) utilizes a large training data to enable the meta-learning for OOD detection. Zheng et al. (2020) generates pseudo OOD data to learn the OOD detector. The above-discussed approaches require additional data or training procedures beyond the intent classification task, introducing significant data collection effort or inference overhead.\nThis paper proposes a strategy based on neural networks to use only IND utterances and their labels to learn both the intent classifier and OOD detector. Our strategy modifies the structure of the classifier, introducing an extra branch as a regularization target. We call the structure a DomainRegularized Module (DRM). This structure is probabilistically motivated and empirically leads to a better generalization in both intent classification and OOD detection. Our analysis focuses more on the latter task, finding that DRM not only outputs a class probability that is a better indicator for judging IND/OOD, but also leads to a feature representation with a less distribution overlap between IND and OOD data. More importantly, DRM is a simple drop-in replacement of the last linear layer, making it easy to plug into any off-the-shelf pretrained models (e.g. BERT (Devlin et al., 2019)) to fine-tune for a target task. The evaluation on four datasets shows that DRM can consistently improve upon previous state-of-the-art methods."
    }, {
      "heading" : "2 Problem Definition & Background",
      "text" : ""
    }, {
      "heading" : "2.1 Problem Definition",
      "text" : "In the application of intent classification, a user utterance will be either an in-domain (IND) utterance (supported by the system) or an out-of-domain (OOD) utterance (not supported by the system). The classifier is expected to correctly (1) predict the intent of supported IND utterances; and (2) detect to reject the unsupported OOD utterances.\nThe task is formally defined below. We are given a closed world IND training set DIND = {x, y} = {(xi, yi)}Ni=1. Each sample (xi, yi), an utterance xi and its intent class label yi ∈ {1 . . . C} for C predefined in-domain classes, is drawn from a\nfixed but unknown IND distribution PIND(x, y). We aim to train an intent classifier model only on IND training data DIND such that the model can perform: (1) Intent Classification: classify the intent class label y of an utterance x if x is drawn from the same distribution PIND as the training set DIND; (2) OOD Detection: detect an utterance x to be an abnormal/unsupported sample if x is drawn from a different distribution POOD."
    }, {
      "heading" : "2.2 Related Work",
      "text" : "Intent Classification is one of the major SLU components (Haffner et al., 2003; Wang et al., 2005; Tur and De Mori, 2011). Various models have been proposed to encode the user utterance for intent classification, including RNN (Ravuri and Stoicke, 2015; Zhang and Wang, 2016; Liu and Lane, 2016; Kim et al., 2017; Wang et al., 2018; Goo et al., 2018), Recursive autoencoders (Kato et al., 2017), or enriched word embeddings (Kim et al., 2016). Recently, the BERT model (Devlin et al., 2019) was explored by (Chen et al., 2019) for SLU. Our work also leverages the representation learned in BERT.\nOOD Detection has been studied for many years (Hellman, 1970). Tur et al. (2014) explores its combination with intent classification by learning an SVM classifier on the IND data and randomly sampled OOD data. Ryu et al. (2017) detects OOD by using reconstruction criteria with an autoencoder. Ryu et al. (2018) learns an intent classifier with GAN and uses the discriminator as the classifier for OOD detection. Zheng et al. (2020) leverages extra unlabeled data to generate pseudoOOD samples using GAN via auxiliary classifier regularization. Tan et al. (2019) further incorporates the few-shot setting, learning the encoding of sentences with a prototypical network that is regularized with the OOD data outside a learning episode. Other researchers developed methods in computer vision based on the rescaling of the predicted class probabilities (ODIN) (Liang et al., 2017) or building the Gaussian model with the features extracted from the hidden layers of neural networks (Mahalanobis) (Lee et al., 2018). Recently, (Hsu et al., 2020) proposed GeneralizedODIN with decomposed confidence scores. However, both approaches also heavily depend on the image input perturbation to achieve good performance. Unfortunately, such perturbation cannot be applied to discrete utterance data in SLU."
    }, {
      "heading" : "3 Our Method",
      "text" : "Our method is inspired by the decomposed confidence of Generalized-ODIN (Hsu et al., 2020), but we leverage the fact that the training data are all from IND to introduce an extra regularization. This regularization leads to a better generalization (lower classification error) on the intent classification. The improvement is in contrast to the original Generalized-ODIN, which has its classification error slightly increased. Since the improved generalization is likely due to a more generalizable feature representation, we leverage this observation, providing a modified Mahalanobis (Lee et al., 2018), which we called L-Mahalanobis, for a transformerbased model to detect OOD data. In the following sections, we first describe the DRM and then elaborate on using the outputs of a DRM-equipped model to detect OOD data."
    }, {
      "heading" : "3.1 Domain-Regularized Module (DRM)",
      "text" : "The motivation begins with introducing the domain variable d (d = 1 means IND, while d = 0 means OOD) following the intuition in (Hsu et al., 2020), then rewrite the posterior of class y given x with domain d as follows:\np̂(y|d = 1,x) = p̂(y, d = 1|x) p̂(d = 1|x)\n= p̂(y|x) p̂(d = 1|x) − p̂(y, d = 0|x) p̂(d = 1|x) ≈ p̂(y|x) p̂(d = 1|x) (1)\nwhere the last step holds since p̂(y, d = 0|x) is close to 0 with the intrinsic conflict between IND classes y and random variable d = 0 for OOD."
    }, {
      "heading" : "3.1.1 DRM Design",
      "text" : "Motivated by the above Equation 1, we design the DRM to mitigate overconfidence by decomposing the final logits f into two branches. Figure 2 illustrates the architecture. Domain Logits fd models p̂(d = 1|x) before normalization. It projects from hidden state h to a scalar w.r.t. d:\nfd = Wdh + bd (2)\nwhere Wd ∈ R|h|×1. Since p̂(d = 1|x) is a probability between 0 and 1, Section 3.1.2 will describe the training details of domain loss via the sigmoid function.\nClassification Logits fc models the probability posterior p̂(y|x) before normalization. It follows the conventional linear projection from hidden state h to the number of classes:\nfc = Wch + bc (3)\nwhere Wd ∈ R|h|×C with C classes. At the end, we obtain the final logits f to represent p̂(y|d = 1,x) by putting fd and fc together following the dividend-divisor structure of Equation 1:\nf = fc/fd (4)\nwhere each element of fc is divided by the same scalar fd."
    }, {
      "heading" : "3.1.2 DRM Training",
      "text" : "We propose two training loss functions to train a model with DRM. The first training loss aims to minimize a cross-entropy between the predicted intent class and ground truth IND class labels.\nLclassification , − C∑ i=1 yi log p̂(f)i (5)\nwhere p̂(f) is the softmax of logits f :\np̂(f) = softmax(f)\nThe second training loss aims to ensure that the domain component fd is close to 1 since all utterances in the training set are IND.\nLdomain , (1− sigmoid(fd))2 (6)\nWe first restrict fd between 0 and 1 by using sigmoid activation function. Then, this loss function encourages sigmoid(fd) close to 1 for training on IND utterances. In order to avoid fd to be very large values and affect the training convergence,\nwe further apply clamp function on fd before it feeds to Equation 4:\nfd = { fd if − δ < fd < δ δ if fd <= −δ or fd >= δ\nThus, we sum them up to optimize the model:\nL = Lclassification + Ldomain (7)\nRemarks: It is important to note that the design of Ldomain is to introduce extra regularization to mitigate the overconfidence in standard posterior probability p̂(f). sigmoid(fd) is not used to directly predict if an utterance is IND or OOD."
    }, {
      "heading" : "3.2 IND Intent Classification Method",
      "text" : "Following Equation 1 and our DRM design, it is straightforward to use the confidence score of softmax(f) to predict the IND intent class."
    }, {
      "heading" : "3.3 OOD Detection Methods",
      "text" : "There are two types of strategies to utilize the outputs of a classifier to perform OOD detection. One is based on the confidence which is computed from logits, the other is based on the features. In the below, we describe how to compute different OOD scores with our DRM."
    }, {
      "heading" : "3.3.1 Confidence-based Methods",
      "text" : "Recent works (Liang et al., 2017) has shown that the softmax outputs provide a good scoring for detecting OOD data. In our DRM model, we use the decomposed softmax outputs for the score. The logits fc w.r.t. the true posterior distribution in openworld can be combined with varied approaches:\nDRM Confidence Score:\nConfDRM = softmax(fc) (8)\nDRM ODIN Confidence Score:\nODINDRM = softmax(fc/T ) (9)\nwith large T = 1000 (Liang et al., 2017). DRM Entropy Confidence Score:\nENTDRM = Entropy[softmax(fc)] (10)\nThe OOD utterances have low ConfDRM , ODINDRM scores and high ENTDRM score."
    }, {
      "heading" : "3.3.2 Feature-based Method",
      "text" : "While our DRM confidence already outperforms many existing methods (later shown in experiments), we further design the feature-based Mahalanobis distance score, inspired by the recent work (Lee et al., 2018) for detecting OOD images.\nWe first recap the approach in (Lee et al., 2018) which consists of two parts: Mahalanobis distance calculation and input preprocessing. Mahalanobis distance score models the class conditional Gaussian distributions w.r.t. Gaussian discriminant analysis based on both low- and upper-level features of the deep classifier models. The score on layer ` is computed as follows:\nS`Maha(x) = maxi−(f `(x)− µ`c)TΣ −1 ` (f `(x)− µ`c)\nwhere f `(x) represents the output features at the `th-layer of neural networks; µi and Σ are the class mean representation and the covariance matrix. Thus, the overall score is their summation:\nSMaha(x) = ∑ ` SMaha(f `(x))\nIn addition, the input preprocessing adds a small controlled noise to the test samples to enhance the performance.\nAlthough Mahalanobis distance score can be applied only to the last feature layer without input preprocessing SlastMaha(x), the analysis (Table 2 in (Lee et al., 2018)) shows that either input preprocessing or multi-layer scoring mechanism is required to achieve decent OOD detection performance. Unfortunately, neither of the above two mechanisms is applicable in the intent classifier for SLU. First, unlike image data, noise injection into discrete natural language utterances has been shown not to perform well. Second, in most cutting-edge intent classifier models, low- and upper-level network layers are quite different. The direct application of multilayer Mahalanobis distance leads to much worse OOD detection performance.\nSince BERT-based models showed significant performance improvement for intent classification in SLU (Chen et al., 2019), we focus on designing the multi-layer Mahalanobis score for BERT-based classifier models. In existing BERT-based text classification models, such as BERT, RoBERTa, DistilBERT, ALBERT, etc., there are different designs between the last transformer layer and the classification layer. Figure 3 shows our generic design of\nTable 1: SLU Benchmark and In-House Dataset Statistics\nDataset Domain #Intents #Train #Dev #Test\nCLINC (Larson et al., 2019) various domains in voice assistants 150 15,000 3,000 4,500other out-of-scope domains - 100 100 1,000\nATIS (Hemphill et al., 1990) airline travel information domain 18 4,478 500 893\nSnips (Coucke et al., 2018) music, book, and weather domains 7 13,084 700 700\nMovie (in-house) movie QA domain 38 39,558 4,897 4,926\nMahalanobis score computation (blue) for various BERT-based models.\nOur design is based on our extensive experiments and understanding of the common insights in different BERT-based models. Specifically, we use the features from different layers between the last transformer layer and the classification layer. We empirically found that the nonlinear tanh layer plays an important role. Thus, to map the features of each transformer layer and last layer into the same semantic space, we pass the features of each layer through tanh function and sum them up to compute our Mahalanobis score:\nSL−Maha(x) = SMaha(f n(x)) + ∑\n1≤`<n SMaha(tanh(f `(x))) (11)\nwhere f ` and fn are the features of each layer ` and last layer n in a BERT-based intent classifier model. We refer to our proposed approach as LMahalanobis."
    }, {
      "heading" : "4 Experimental Evaluation",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We evaluate our proposed approach on three benchmark SLU datasets and one in-house SLU dataset. Table 1 provides an overview of all datasets.\nAmong all these datasets, the recently released CLINC dataset serves as a benchmark for OOD detection in SLU. For the other three datasets, we treat them mutually OOD due to non-overlapping domains.\nWe crowdsourced the in-house Movie dataset containing common questions that users may ask regarding movies. This dataset mainly consists of queries a user may ask in the movie domain. The dataset consists of 38 different intents (e.g. rating information, genre information, award information, show trailer) and 20 slots or entities (e.g., director, award, release year). This dataset was collected using crowdsourcing as follows. At first, some example template queries were generated by linguistic experts for each intent, along with intent and slot descriptions. Next, a generation crowdsourcing job was launched where a crowd worker was assigned a random intent, a combination of entities, and few slots generally associated with the intent. To better understand the intent and slots, the worker was asked to review the intent and slot descriptions, and example template utterances. The first task of the worker was to provide 3 different queries corresponding to the given intent, which also contains the provided entities. The second task of the worker was to provide additional entities corresponding to the same slot type. A subsequent validation crowdsourcing job was launched where these crowdsourced queries were rated by validation workers in terms of their accuracy with the provided intent and entities. Each query was rated by 5 different validation workers, and the final validated dataset contains a subset of crowdsourced queries with high accuracy score and high interrater agreement."
    }, {
      "heading" : "4.2 Implementation and Training Details",
      "text" : "We implemented our method using PyTorch on top of the Hugging Face transformer library (Wolf et al., 2019). We follow the hyperparameters in the original models. For the only hyperparameter δ, we experimented only on CLINC dataset\nfrom 2.2 to 4 with uniform interval 0.2 (we try 10 values of δ) based on sigmoid(2.2) ≈ 0.9 and sigmoid(4) ≈ 0.982. We used δ = 3 which gives the best performance in our experiment for all datasets. We train each model with 3 epochs using 4 NVIDIA Tesla V100 GPUs (16GB) for each training. We conducted experiments on two transformer-based models, BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019).\nRemarks: All experiments only use IND data for both training and validation. We use the same hyperparameters in all datasets and validate the generalizability of our method."
    }, {
      "heading" : "4.3 Baselines",
      "text" : ""
    }, {
      "heading" : "4.3.1 IND Intent Classification Baselines",
      "text" : "We consider the strongest baseline BERT-Linear (the last layer is linear) fine-tuned on the pre-trained BERT-based models (Chen et al., 2019)."
    }, {
      "heading" : "4.3.2 OOD Detection Baselines",
      "text" : "We consider the existing OOD detection methods:\nConGAN (Ryu et al., 2018): a GAN-based model based on given sentence representations to generate OOD features with additional feature matching loss. OOD utterances are expected to have low discriminator confidence scores.\nAutoencoder (AE) (Ryu et al., 2017): first uses an LSTM based classifier model to train sentence representations; then train an autoencoder on the above sentence embeddings. OOD utterances are expected to have high reconstruction error.\nODIN (Liang et al., 2017): we only use the temperature scaling on logits. OOD utterances are expected to have a low scaled confidence score.\nGeneralized-ODIN (G-ODIN) (Hsu et al., 2020): we fine-tune on pre-trained BERT models with replaced last layer and only use the decomposed confidence. We evaluate all three variations proposed in the paper hI , hE and hC and report the best one. OOD utterances are expected to have low scaled confidence score.\nMahalanobis (Lee et al., 2018): we only use the feature of BERT’s last layer to compute Mahalanobis distance score. OOD utterances are expected to have a low scaled confidence score.\nFor ConGAN and AE, we evaluate the model in the original paper as well as customized BERTbased backbone models as strong baselines. Specifically, we customize En-ConGAN and En-AE as follows: En-ConGAN uses BERT sentence representation as input; En-AE applies a BERT classi-\nfier model to train the sentence representation and then use them to further train an autoencoder. Thus, En-ConGAN and En-AE are not existing baselines.\nNote that ERAEPOG (Zheng et al., 2020) and O-Proto (Tan et al., 2019) are not comparable since they require additional unlabeled data and labels. We only put the ERAEPOG results on CLINC dataset (from the original paper) for reference."
    }, {
      "heading" : "4.4 Evaluation Metrics",
      "text" : ""
    }, {
      "heading" : "4.4.1 IND Intent Classification Metrics",
      "text" : "We evaluate IND performance using the classification accuracy metric as in literature (Liu and Lane, 2016; Wang et al., 2018; Chen et al., 2019)."
    }, {
      "heading" : "4.4.2 OOD Detection Metrics",
      "text" : "we follow the evaluation metrics in literature (Ryu et al., 2018) and (Liang et al., 2017; Lee et al., 2018). Let TP, TN, FP, and FN denote true positive, true negative, false positive, and false negative. We use the following OOD evaluation metrics:\nEER (lower is better): (Equal Error Rate) measures the error rate when false positive rate (FPR) is equal to the false negative rate (FNR). Here, FPR=FP/(FP+TN) and FNR=FN/(TP+FN).\nFPR95 (lower is better): (False Positive Rate (FPR) at 95% True Positive Rate (TPR)) can be interpreted as the probability that an OOD utterance is misclassified as IND when the true positive rate (TPR) is as high as 95%. Here, TPR=TP/(TP+FN).\nDetection Error (lower is better): measures the misclassification probability when TPR is 95%. Detection error is defined as follows:\nmin δ {PIND(s ≤ δ)p(x ∈ PIND)\n+POOD(s > δ)p(x ∈ POOD)}\nwhere s is a confidence score. We follow the same assumption that both IND and OOD examples have an equal probability of appearing in the testing set.\nAUROC (higher is better): (Area under the Receiver Operating Characteristic Curve) The ROC curve is a graph plotting TPR against the FPR=FP/(FP+TN) by varying a threshold.\nAUPR (higher is better): (Area under the Precision-Recall Curve (AUPR)) The PR curve is a graph plotting the precision against recall by varying a threshold. Here, precision=TP/(TP+FP) and recall=TP/(TP+FN). AUPR-IN and AUPR-OUT is AUPR where IND and OOD distribution samples are specified as positive, respectively.\nNote that EER, detection error, AUROC, and AUPR are threshold-independent metrics."
    }, {
      "heading" : "4.4.3 Statistical Significance",
      "text" : "We also evaluate the statistical significance between all baselines and our best result (DRM + L-Mahalanobis) on all the above metrics. We train each model 10 times with different PyTorch random seeds. We report the average results and t-test statistical significance results."
    }, {
      "heading" : "4.5 Results",
      "text" : ""
    }, {
      "heading" : "4.5.1 IND Classification Results",
      "text" : "Table 3 reports the IND intent classification results on each dataset finetuned using BERT and RoBERTa pre-trained models. It is interesting to observe that all DRM combined models consistently achieve better classification accuracy with up to 0.8% improvement (reproduced ”No joint” row in Table 3 in (Chen et al., 2019) on Snips dataset). This is because the domain loss forces sigmoid(fd) close to 1 and therefore also slightly mitigates its impact to IND classification. Thus, the true posterior distribution of IND data is also modeled more precisely. For both BERT and RoBERTa\nbackbones, DRM models are significantly better than conventional BERT-linear classification models with p-value < 0.05."
    }, {
      "heading" : "4.5.2 OOD Detection Results",
      "text" : "Results on CLINC Dataset: Table 2 reports the OOD detection results on CLINC dataset. This result covers all existing work and our enhanced baselines. We focus on analyzing the contribution by each of our proposed techniques, DRM and L-Mahalanobis. The first three rows report the performance of existing approaches based on the original designs in their papers (ERAEPOG in grey uses additional unlabeled data). Unfortunately, we observe that their performance is even worse than the simple confidence-based approach via BERT\nfinetuning baseline (row 5). Thus, we mainly focus on comparing our method with strong baselines with BERT and RoBERTa models.\nFor a given OOD detection method, we find that their combinations with DRM consistently perform better than those with standard models. The improvement is at least 1-2% for all metrics against our enhanced baselines. Among all OOD detection approaches, our proposed L-Mahalanobis OOD detection approach achieves the best performance for both linear and DRM combined BERT and RoBERTa models. It is not surprising to observe that our DRM method combined with a better pretrained RoBERTa model achieves larger OOD detection performance improvement. Note that our customized En-AE performs much better than most other methods since we incorporated the enhanced reconstruction capability with pre-trained BERT models. However, En-AE cannot utilize all BERT layers as our proposed L-Mahalanobis method, resulting in worse performance.\nIn addition, DRM+L-Mahalanobis models are significantly better than existing methods and enhanced baselines with p-value < 0.01 on most metrics for both BERT and RoBERTa backbones.\nAblation Study on CLINC Dataset: We analyze how our two novel components, DRM model and L-Mahalanobis, impact the performance.\nThe rows with “DRM” in “Last Layer” column of Table 2 show the performance of DRM model. As one can see, for all OOD methods, DRM consistently performs better than the conventional “Linear” last layer. Specifically, the DRM and Confidence combo also outperforms its closest baseline G-ODIN. This validates the effectiveness of our disentangled logits design in DRM based on the mathematical analysis of overconfidence. It also shows that our new domain loss can indeed enhance the model awareness that all training data is IND.\nThe rows with “L-Mahalanobis” in “OOD Method” column of Table 2 outperform other OOD methods with the same model and last layer. Compared with its closest baseline Mahalanobis, the better performance of L-Mahalanobis validates the usefulness of all layers’ features in various models. Results on ATIS/Snips/Movie Datasets: Since our strong baselines on pre-trained RoBERTa model showed better results on CLINC, we next evaluate other results finetuned on RoBERTa\nmodel. When taking each dataset as IND, we use the other two mutually exclusive datasets and CLINC OOD as OOD datasets for evaluating OOD detection performance. As one can see in Table 4, our method outperforms other approaches on both Snips and movie IND datasets. For ATIS IND dataset, En-AE for Snips OOD dataset achieves almost perfect performance. This is because ATIS and Snips are almost completely non-overlapping and ATIS is well designed with carefully selected varieties and entities in the airline travel domain. When taking Snip as IND and ATIS as OOD, it is interesting to see that our method achieves better performance than En-AE. This is because that Snips contains a large number of entities such that the reconstruction error will be lower and become less separable than that in ATIS OOD utterances.\nFor both Snips and Movie IND datasets, DRM+L-Mahalanobis are significantly better than baseline methods with p-value < 0.01 in most cases for all OOD datasets. For ATIS IND dataset, DRM+L-Mahalanobis shows similar behavior except En-AE since it is easier to train an autoencoder model for ATIS IND dataset due to its carefully collected clean training utterances."
    }, {
      "heading" : "4.6 Qualitative Analysis",
      "text" : "We provide a quantitative analysis by visualizing our two methods, DRM and L-Mahalanobis."
    }, {
      "heading" : "4.6.1 Detection Score Distribution",
      "text" : "Figure 4 plots the histograms of detection scores for OOD and IND data. Compared with Figure 4(a), DRM significantly reduces the overlap between OOD and IND in Figure 4(b). L-Mahalanobis utilizes features from all layers to further reduce the overlap in Figure 4(c). Moreover, the score distributions from left to right in Figure 4, imply that a larger entropy of all score reflects a better uncertainty modeling."
    }, {
      "heading" : "4.6.2 Feature Distribution Visualization",
      "text" : "Figure 5 visualizes the utterance representations learned with or without DRM. The red IND data are tightly clustered within classes (totally 150 CLINC IND classes), while the blue OOD data spread arbitrarily. As one can see, the blue dots in Figure 5(b) have less overlap with red dots, indicating the DRM helps to learn the utterance representation to better disentangle IND and OOD data."
    }, {
      "heading" : "5 Conclusion",
      "text" : "This paper proposes using only IND utterances to conduct intent classification and OOD detection for SLU in an open-world setting. The proposed DRM has a structure of two branches to avoid overconfidence and achieves a better generalization. The evaluation shows that our method can achieve stateof-the-art performance on various SLU benchmark and in-house datasets for both IND intent classification and OOD detection. In addition, thanks to the generic of our DRM design and with the recent extensive use of BERT on different data modalities, our work can contribute to improving both in-domain classification robustness and outof-domain detection robustness for various classification models such as image classification, sound classification, vision-language classifications.\nImpact Statement\nOur proposed method in this paper has been deployed in the domain classification SLU model for Samsung Bixby voice assistant. In addition to SLU, our work could have a broader impact on other applications, which can be benefited from having a more robust classification system. For example, our method can help the robot to detect objects more accurately or stop safely by correctly identifying unknown objects, classify environmental sounds or detect anomaly sounds, and so on. Moreover, by better detecting the OOD samples that are different from the training data distribution, our method can facilitate to handle distributional shifts between training data and practical usage data."
    } ],
    "references" : [ {
      "title" : "BERT for joint intent classification and slot filling",
      "author" : [ "Qian Chen", "Zhu Zhuo", "Wen Wang." ],
      "venue" : "CoRR, abs/1902.10909.",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Snips voice platform: an embedded",
      "author" : [ "Alice Coucke", "Alaa Saade", "Adrien Ball", "Théodore Bluche", "Alexandre Caulier", "David Leroy", "Clément Doumouro", "Thibault Gisselbrecht", "Francesco Caltagirone", "Thibaut Lavril", "Maël Primet", "Joseph Dureau" ],
      "venue" : null,
      "citeRegEx" : "Coucke et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Coucke et al\\.",
      "year" : 2018
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "NAACL-HLT, pages 4171–4186.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Slot-gated modeling for joint slot filling and intent prediction",
      "author" : [ "Chih-Wen Goo", "Guang Gao", "Yun-Kai Hsu", "Chih-Li Huo", "Tsung-Chieh Chen", "Keng-Wei Hsu", "YunNung Chen." ],
      "venue" : "NAACL-HLT, pages 753–757.",
      "citeRegEx" : "Goo et al\\.,? 2018",
      "shortCiteRegEx" : "Goo et al\\.",
      "year" : 2018
    }, {
      "title" : "Joint semantic utterance classification and slot filling with recursive neural networks",
      "author" : [ "Daniel Guo", "Gokhan Tur", "Wen-tau Yih", "Geoffrey Zweig." ],
      "venue" : "SLT, pages 554–559.",
      "citeRegEx" : "Guo et al\\.,? 2014",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2014
    }, {
      "title" : "Optimizing svms for complex call classification",
      "author" : [ "Patrick Haffner", "Gokhan Tur", "Jerry H Wright." ],
      "venue" : "ICASSP, volume 1.",
      "citeRegEx" : "Haffner et al\\.,? 2003",
      "shortCiteRegEx" : "Haffner et al\\.",
      "year" : 2003
    }, {
      "title" : "The nearest neighbor classification rule with a reject option",
      "author" : [ "Martin E Hellman." ],
      "venue" : "IEEE Transactions on Systems Science and Cybernetics, 6(3):179–185.",
      "citeRegEx" : "Hellman.,? 1970",
      "shortCiteRegEx" : "Hellman.",
      "year" : 1970
    }, {
      "title" : "The atis spoken language systems pilot corpus",
      "author" : [ "Charles T Hemphill", "John J Godfrey", "George R Doddington" ],
      "venue" : "In Proceedings of the DARPA speech and natural language workshop,",
      "citeRegEx" : "Hemphill et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Hemphill et al\\.",
      "year" : 1990
    }, {
      "title" : "Deep anomaly detection with outlier exposure",
      "author" : [ "Dan Hendrycks", "Mantas Mazeika", "Thomas G Dietterich." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Hendrycks et al\\.,? 2018",
      "shortCiteRegEx" : "Hendrycks et al\\.",
      "year" : 2018
    }, {
      "title" : "Generalized ODIN: detecting out-ofdistribution image without learning from out-ofdistribution data",
      "author" : [ "Yen-Chang Hsu", "Yilin Shen", "Hongxia Jin", "Zsolt Kira." ],
      "venue" : "CVPR, pages 10948–10957.",
      "citeRegEx" : "Hsu et al\\.,? 2020",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2020
    }, {
      "title" : "Utterance intent classification of a spoken dialogue system with efficiently untied recursive autoencoders",
      "author" : [ "Tsuneo Kato", "Atsushi Nagai", "Naoki Noda", "Ryosuke Sumitomo", "Jianming Wu", "Seiichi Yamamoto." ],
      "venue" : "SIGDIAL, pages 60–64.",
      "citeRegEx" : "Kato et al\\.,? 2017",
      "shortCiteRegEx" : "Kato et al\\.",
      "year" : 2017
    }, {
      "title" : "Intent detection using semantically enriched word embeddings",
      "author" : [ "Joo-Kyung Kim", "Gokhan Tur", "Asli Celikyilmaz", "Bin Cao", "Ye-Yi Wang." ],
      "venue" : "SLT, pages 414–419.",
      "citeRegEx" : "Kim et al\\.,? 2016",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2016
    }, {
      "title" : "ONENET: joint domain, intent, slot prediction for spoken language understanding",
      "author" : [ "Young-Bum Kim", "Sungjin Lee", "Karl Stratos." ],
      "venue" : "2017 IEEE Automatic Speech Recognition and Understanding Workshop, pages 547–553.",
      "citeRegEx" : "Kim et al\\.,? 2017",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2017
    }, {
      "title" : "An evaluation dataset for intent classification",
      "author" : [ "Stefan Larson", "Anish Mahendran", "Joseph J. Peper", "Christopher Clarke", "Andrew Lee", "Parker Hill", "Jonathan K. Kummerfeld", "Kevin Leach", "Michael A. Laurenzano", "Lingjia Tang", "Jason mars" ],
      "venue" : null,
      "citeRegEx" : "Larson et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Larson et al\\.",
      "year" : 2019
    }, {
      "title" : "A simple unified framework for detecting outof-distribution samples and adversarial attacks",
      "author" : [ "Kimin Lee", "Kibok Lee", "Honglak Lee", "Jinwoo Shin." ],
      "venue" : "NeurIPS, pages 7167–7177.",
      "citeRegEx" : "Lee et al\\.,? 2018",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2018
    }, {
      "title" : "Enhancing the reliability of out-of-distribution image detection in neural networks",
      "author" : [ "Shiyu Liang", "Yixuan Li", "R Srikant." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Liang et al\\.,? 2017",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2017
    }, {
      "title" : "Attention-based recurrent neural network models for joint intent detection and slot filling",
      "author" : [ "Bing Liu", "Ian Lane." ],
      "venue" : "INTERSPEECH, pages 685–689.",
      "citeRegEx" : "Liu and Lane.,? 2016",
      "shortCiteRegEx" : "Liu and Lane.",
      "year" : 2016
    }, {
      "title" : "Roberta: A robustly optimized BERT pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "CoRR, abs/1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "A comparative study of neural network models for lexical intent classification",
      "author" : [ "Suman Ravuri", "Andreas Stoicke." ],
      "venue" : "ASRU, pages 368–374.",
      "citeRegEx" : "Ravuri and Stoicke.,? 2015",
      "shortCiteRegEx" : "Ravuri and Stoicke.",
      "year" : 2015
    }, {
      "title" : "Learning out-of-vocabulary words in intelligent personal agents",
      "author" : [ "Avik Ray", "Yilin Shen", "Hongxia Jin." ],
      "venue" : "IJCAI, pages 4309–4315.",
      "citeRegEx" : "Ray et al\\.,? 2018",
      "shortCiteRegEx" : "Ray et al\\.",
      "year" : 2018
    }, {
      "title" : "Fast domain adaptation of semantic parsers via paraphrase attention",
      "author" : [ "Avik Ray", "Yilin Shen", "Hongxia Jin." ],
      "venue" : "DeepLo@EMNLP-IJCNLP, pages 94– 103.",
      "citeRegEx" : "Ray et al\\.,? 2019",
      "shortCiteRegEx" : "Ray et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural sentence embedding using only in-domain sentences for outof-domain sentence detection in dialog systems",
      "author" : [ "Seonghan Ryu", "Seokhwan Kim", "Junhwi Choi", "Hwanjo Yu", "Gary Geunbae Lee." ],
      "venue" : "Pattern Recogn. Lett., 88(C):26–32.",
      "citeRegEx" : "Ryu et al\\.,? 2017",
      "shortCiteRegEx" : "Ryu et al\\.",
      "year" : 2017
    }, {
      "title" : "Out-of-domain detection based on generative adversarial network",
      "author" : [ "Seonghan Ryu", "Sangjun Koo", "Hwanjo Yu", "Gary Geunbae Lee." ],
      "venue" : "EMNLP, pages 714–718.",
      "citeRegEx" : "Ryu et al\\.,? 2018",
      "shortCiteRegEx" : "Ryu et al\\.",
      "year" : 2018
    }, {
      "title" : "Teach once and use everywhere – building ai assistant eco-skills via user instruction and demonstration (poster)",
      "author" : [ "Yilin Shen", "Sandeep Nama", "Hongxia Jin." ],
      "venue" : "MobiSys, pages 606–607.",
      "citeRegEx" : "Shen et al\\.,? 2019a",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2019
    }, {
      "title" : "SkillBot: Towards automatic skill development via user demonstration",
      "author" : [ "Yilin Shen", "Avik Ray", "Hongxia Jin", "Sandeep Nama." ],
      "venue" : "NAACL-HLT, System Demonstrations, pages 105–109.",
      "citeRegEx" : "Shen et al\\.,? 2019b",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2019
    }, {
      "title" : "CRUISE: cold-start new skill development via iterative utterance generation",
      "author" : [ "Yilin Shen", "Avik Ray", "Abhishek Patel", "Hongxia Jin." ],
      "venue" : "ACL, System Demonstrations, pages 105–110.",
      "citeRegEx" : "Shen et al\\.,? 2018a",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2018
    }, {
      "title" : "Sliqa-i: Towards cold-start development of end-to-end spoken language interface for question answering",
      "author" : [ "Yilin Shen", "Yu Wang", "Abhishek Patel", "Hongxia Jin." ],
      "venue" : "ICASSP, pages 7195–7199.",
      "citeRegEx" : "Shen et al\\.,? 2019c",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2019
    }, {
      "title" : "A progressive model to enable continual learning for semantic slot filling",
      "author" : [ "Yilin Shen", "Xiangyu Zeng", "Hongxia Jin." ],
      "venue" : "EMNLP-IJCNLP, pages 1279–1284.",
      "citeRegEx" : "Shen et al\\.,? 2019d",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2019
    }, {
      "title" : "User information augmented semantic frame parsing using progressive neural networks",
      "author" : [ "Yilin Shen", "Xiangyu Zeng", "Yu Wang", "Hongxia Jin." ],
      "venue" : "INTERSPEECH, pages 3464–3468.",
      "citeRegEx" : "Shen et al\\.,? 2018b",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2018
    }, {
      "title" : "Out-ofdomain detection for low-resource text classification tasks",
      "author" : [ "Ming Tan", "Yang Yu", "Haoyu Wang", "Dakuo Wang", "Saloni Potdar", "Shiyu Chang", "Mo Yu." ],
      "venue" : "EMNLP-IJCNLP, pages 3564–3570.",
      "citeRegEx" : "Tan et al\\.,? 2019",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2019
    }, {
      "title" : "Spoken Language Understanding: Systems for Extracting Semantic Information from Speech",
      "author" : [ "G. Tur", "R. De Mori." ],
      "venue" : "Wiley.",
      "citeRegEx" : "Tur and Mori.,? 2011",
      "shortCiteRegEx" : "Tur and Mori.",
      "year" : 2011
    }, {
      "title" : "Detecting out-of-domain utterances addressed to a virtual personal assistant",
      "author" : [ "Gokhan Tur", "Anoop Deoras", "Dilek HakkaniTür." ],
      "venue" : "Fifteenth Annual Conference of the International Speech Communication Association.",
      "citeRegEx" : "Tur et al\\.,? 2014",
      "shortCiteRegEx" : "Tur et al\\.",
      "year" : 2014
    }, {
      "title" : "Spoken language understanding",
      "author" : [ "Ye-Yi Wang", "Li Deng", "Alex Acero." ],
      "venue" : "IEEE Signal Processing Magazine, 22(5):16–31.",
      "citeRegEx" : "Wang et al\\.,? 2005",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2005
    }, {
      "title" : "A bimodel based rnn semantic frame parsing model for intent detection and slot filling",
      "author" : [ "Yu Wang", "Yilin Shen", "Hongxia Jin." ],
      "venue" : "NAACL-HLT, pages 309–314.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Huggingface’s transformers: State-of-the-art natural language",
      "author" : [ "Thomas Wolf", "Lysandre Debut", "Victor Sanh", "Julien Chaumond", "Clement Delangue", "Anthony Moi", "Pierric Cistac", "Tim Rault", "Rémi Louf", "Morgan Funtowicz", "Jamie Brew" ],
      "venue" : null,
      "citeRegEx" : "Wolf et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Wolf et al\\.",
      "year" : 2019
    }, {
      "title" : "A joint model of intent determination and slot filling for spoken language understanding",
      "author" : [ "Xiaodong Zhang", "Houfeng Wang." ],
      "venue" : "IJCAI, pages 2993– 2999.",
      "citeRegEx" : "Zhang and Wang.,? 2016",
      "shortCiteRegEx" : "Zhang and Wang.",
      "year" : 2016
    }, {
      "title" : "Out-of-domain detection for natural language understanding in dialog systems",
      "author" : [ "Yinhe Zheng", "Guanyi Chen", "Minlie Huang." ],
      "venue" : "IEEE ACM Trans. Audio Speech Lang. Process., 28:1198–1209.",
      "citeRegEx" : "Zheng et al\\.,? 2020",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Many deep neural network-based SLU models have recently been proposed and have demonstrated significant progress (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Chen et al., 2019) in classification accuracy.",
      "startOffset" : 113,
      "endOffset" : 229
    }, {
      "referenceID" : 16,
      "context" : "Many deep neural network-based SLU models have recently been proposed and have demonstrated significant progress (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Chen et al., 2019) in classification accuracy.",
      "startOffset" : 113,
      "endOffset" : 229
    }, {
      "referenceID" : 35,
      "context" : "Many deep neural network-based SLU models have recently been proposed and have demonstrated significant progress (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Chen et al., 2019) in classification accuracy.",
      "startOffset" : 113,
      "endOffset" : 229
    }, {
      "referenceID" : 33,
      "context" : "Many deep neural network-based SLU models have recently been proposed and have demonstrated significant progress (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Chen et al., 2019) in classification accuracy.",
      "startOffset" : 113,
      "endOffset" : 229
    }, {
      "referenceID" : 3,
      "context" : "Many deep neural network-based SLU models have recently been proposed and have demonstrated significant progress (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Chen et al., 2019) in classification accuracy.",
      "startOffset" : 113,
      "endOffset" : 229
    }, {
      "referenceID" : 0,
      "context" : "Many deep neural network-based SLU models have recently been proposed and have demonstrated significant progress (Guo et al., 2014; Liu and Lane, 2016; Zhang and Wang, 2016; Wang et al., 2018; Goo et al., 2018; Chen et al., 2019) in classification accuracy.",
      "startOffset" : 113,
      "endOffset" : 229
    }, {
      "referenceID" : 8,
      "context" : "A straightforward solution is to collect OOD data and train a supervised binary classifier on both IND data and OOD data (Hendrycks et al., 2018).",
      "startOffset" : 121,
      "endOffset" : 145
    }, {
      "referenceID" : 2,
      "context" : "BERT (Devlin et al., 2019)) to fine-tune for a target task.",
      "startOffset" : 5,
      "endOffset" : 26
    }, {
      "referenceID" : 5,
      "context" : "Intent Classification is one of the major SLU components (Haffner et al., 2003; Wang et al., 2005; Tur and De Mori, 2011).",
      "startOffset" : 57,
      "endOffset" : 121
    }, {
      "referenceID" : 32,
      "context" : "Intent Classification is one of the major SLU components (Haffner et al., 2003; Wang et al., 2005; Tur and De Mori, 2011).",
      "startOffset" : 57,
      "endOffset" : 121
    }, {
      "referenceID" : 18,
      "context" : "Various models have been proposed to encode the user utterance for intent classification, including RNN (Ravuri and Stoicke, 2015; Zhang and Wang, 2016; Liu and Lane, 2016; Kim et al., 2017; Wang et al., 2018; Goo et al., 2018), Recursive autoencoders (Kato et al.",
      "startOffset" : 104,
      "endOffset" : 227
    }, {
      "referenceID" : 35,
      "context" : "Various models have been proposed to encode the user utterance for intent classification, including RNN (Ravuri and Stoicke, 2015; Zhang and Wang, 2016; Liu and Lane, 2016; Kim et al., 2017; Wang et al., 2018; Goo et al., 2018), Recursive autoencoders (Kato et al.",
      "startOffset" : 104,
      "endOffset" : 227
    }, {
      "referenceID" : 16,
      "context" : "Various models have been proposed to encode the user utterance for intent classification, including RNN (Ravuri and Stoicke, 2015; Zhang and Wang, 2016; Liu and Lane, 2016; Kim et al., 2017; Wang et al., 2018; Goo et al., 2018), Recursive autoencoders (Kato et al.",
      "startOffset" : 104,
      "endOffset" : 227
    }, {
      "referenceID" : 12,
      "context" : "Various models have been proposed to encode the user utterance for intent classification, including RNN (Ravuri and Stoicke, 2015; Zhang and Wang, 2016; Liu and Lane, 2016; Kim et al., 2017; Wang et al., 2018; Goo et al., 2018), Recursive autoencoders (Kato et al.",
      "startOffset" : 104,
      "endOffset" : 227
    }, {
      "referenceID" : 33,
      "context" : "Various models have been proposed to encode the user utterance for intent classification, including RNN (Ravuri and Stoicke, 2015; Zhang and Wang, 2016; Liu and Lane, 2016; Kim et al., 2017; Wang et al., 2018; Goo et al., 2018), Recursive autoencoders (Kato et al.",
      "startOffset" : 104,
      "endOffset" : 227
    }, {
      "referenceID" : 3,
      "context" : "Various models have been proposed to encode the user utterance for intent classification, including RNN (Ravuri and Stoicke, 2015; Zhang and Wang, 2016; Liu and Lane, 2016; Kim et al., 2017; Wang et al., 2018; Goo et al., 2018), Recursive autoencoders (Kato et al.",
      "startOffset" : 104,
      "endOffset" : 227
    }, {
      "referenceID" : 10,
      "context" : ", 2018), Recursive autoencoders (Kato et al., 2017), or enriched word embeddings (Kim et al.",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 11,
      "context" : ", 2017), or enriched word embeddings (Kim et al., 2016).",
      "startOffset" : 37,
      "endOffset" : 55
    }, {
      "referenceID" : 2,
      "context" : "Recently, the BERT model (Devlin et al., 2019) was explored by (Chen et al.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 6,
      "context" : "OOD Detection has been studied for many years (Hellman, 1970).",
      "startOffset" : 46,
      "endOffset" : 61
    }, {
      "referenceID" : 15,
      "context" : "Other researchers developed methods in computer vision based on the rescaling of the predicted class probabilities (ODIN) (Liang et al., 2017) or building the Gaussian model with the features extracted from the hidden layers of neural networks (Mahalanobis) (Lee et al.",
      "startOffset" : 122,
      "endOffset" : 142
    }, {
      "referenceID" : 14,
      "context" : ", 2017) or building the Gaussian model with the features extracted from the hidden layers of neural networks (Mahalanobis) (Lee et al., 2018).",
      "startOffset" : 123,
      "endOffset" : 141
    }, {
      "referenceID" : 9,
      "context" : "Recently, (Hsu et al., 2020) proposed GeneralizedODIN with decomposed confidence scores.",
      "startOffset" : 10,
      "endOffset" : 28
    }, {
      "referenceID" : 9,
      "context" : "Our method is inspired by the decomposed confidence of Generalized-ODIN (Hsu et al., 2020), but we leverage the fact that the training data are all from IND to introduce an extra regularization.",
      "startOffset" : 72,
      "endOffset" : 90
    }, {
      "referenceID" : 14,
      "context" : "Since the improved generalization is likely due to a more generalizable feature representation, we leverage this observation, providing a modified Mahalanobis (Lee et al., 2018), which we called L-Mahalanobis, for a transformerbased model to detect OOD data.",
      "startOffset" : 159,
      "endOffset" : 177
    }, {
      "referenceID" : 9,
      "context" : "The motivation begins with introducing the domain variable d (d = 1 means IND, while d = 0 means OOD) following the intuition in (Hsu et al., 2020), then rewrite the posterior of class y given x with domain d as follows:",
      "startOffset" : 129,
      "endOffset" : 147
    }, {
      "referenceID" : 15,
      "context" : "Recent works (Liang et al., 2017) has shown that the softmax outputs provide a good scoring for detecting OOD data.",
      "startOffset" : 13,
      "endOffset" : 33
    }, {
      "referenceID" : 14,
      "context" : "While our DRM confidence already outperforms many existing methods (later shown in experiments), we further design the feature-based Mahalanobis distance score, inspired by the recent work (Lee et al., 2018) for detecting OOD images.",
      "startOffset" : 189,
      "endOffset" : 207
    }, {
      "referenceID" : 14,
      "context" : "We first recap the approach in (Lee et al., 2018) which consists of two parts: Mahalanobis distance calculation and input preprocessing.",
      "startOffset" : 31,
      "endOffset" : 49
    }, {
      "referenceID" : 14,
      "context" : "Although Mahalanobis distance score can be applied only to the last feature layer without input preprocessing Slast Maha(x), the analysis (Table 2 in (Lee et al., 2018)) shows that either input preprocessing or multi-layer scoring mechanism is required to achieve decent OOD detection performance.",
      "startOffset" : 150,
      "endOffset" : 168
    }, {
      "referenceID" : 0,
      "context" : "Since BERT-based models showed significant performance improvement for intent classification in SLU (Chen et al., 2019), we focus on designing the multi-layer Mahalanobis score for BERT-based classifier models.",
      "startOffset" : 100,
      "endOffset" : 119
    }, {
      "referenceID" : 13,
      "context" : "CLINC (Larson et al., 2019) various domains in voice assistants 150 15,000 3,000 4,500 other out-of-scope domains 100 100 1,000",
      "startOffset" : 6,
      "endOffset" : 27
    }, {
      "referenceID" : 7,
      "context" : "ATIS (Hemphill et al., 1990) airline travel information domain 18 4,478 500 893",
      "startOffset" : 5,
      "endOffset" : 28
    }, {
      "referenceID" : 1,
      "context" : "Snips (Coucke et al., 2018) music, book, and weather domains 7 13,084 700 700",
      "startOffset" : 6,
      "endOffset" : 27
    }, {
      "referenceID" : 34,
      "context" : "We implemented our method using PyTorch on top of the Hugging Face transformer library (Wolf et al., 2019).",
      "startOffset" : 87,
      "endOffset" : 106
    }, {
      "referenceID" : 2,
      "context" : "We conducted experiments on two transformer-based models, BERT (Devlin et al., 2019) and RoBERTa (Liu et al.",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 0,
      "context" : "We consider the strongest baseline BERT-Linear (the last layer is linear) fine-tuned on the pre-trained BERT-based models (Chen et al., 2019).",
      "startOffset" : 122,
      "endOffset" : 141
    }, {
      "referenceID" : 22,
      "context" : "We consider the existing OOD detection methods: ConGAN (Ryu et al., 2018): a GAN-based model based on given sentence representations to generate OOD features with additional feature matching loss.",
      "startOffset" : 55,
      "endOffset" : 73
    }, {
      "referenceID" : 21,
      "context" : "Autoencoder (AE) (Ryu et al., 2017): first uses an LSTM based classifier model to train sentence representations; then train an autoencoder on the above sentence embeddings.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 15,
      "context" : "ODIN (Liang et al., 2017): we only use the temperature scaling on logits.",
      "startOffset" : 5,
      "endOffset" : 25
    }, {
      "referenceID" : 9,
      "context" : "Generalized-ODIN (G-ODIN) (Hsu et al., 2020): we fine-tune on pre-trained BERT models with replaced last layer and only use the decomposed confidence.",
      "startOffset" : 26,
      "endOffset" : 44
    }, {
      "referenceID" : 14,
      "context" : "Mahalanobis (Lee et al., 2018): we only use the feature of BERT’s last layer to compute Mahalanobis distance score.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 36,
      "context" : "Note that ERAEPOG (Zheng et al., 2020) and O-Proto (Tan et al.",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 29,
      "context" : ", 2020) and O-Proto (Tan et al., 2019) are not comparable since they require additional unlabeled data and labels.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 16,
      "context" : "We evaluate IND performance using the classification accuracy metric as in literature (Liu and Lane, 2016; Wang et al., 2018; Chen et al., 2019).",
      "startOffset" : 86,
      "endOffset" : 144
    }, {
      "referenceID" : 33,
      "context" : "We evaluate IND performance using the classification accuracy metric as in literature (Liu and Lane, 2016; Wang et al., 2018; Chen et al., 2019).",
      "startOffset" : 86,
      "endOffset" : 144
    }, {
      "referenceID" : 0,
      "context" : "We evaluate IND performance using the classification accuracy metric as in literature (Liu and Lane, 2016; Wang et al., 2018; Chen et al., 2019).",
      "startOffset" : 86,
      "endOffset" : 144
    }, {
      "referenceID" : 22,
      "context" : "we follow the evaluation metrics in literature (Ryu et al., 2018) and (Liang et al.",
      "startOffset" : 47,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "8% improvement (reproduced ”No joint” row in Table 3 in (Chen et al., 2019) on Snips dataset).",
      "startOffset" : 56,
      "endOffset" : 75
    } ],
    "year" : 2021,
    "abstractText" : "Intent classification is a major task in spoken language understanding (SLU). Since most models are built with pre-collected in-domain (IND) training utterances, their ability to detect unsupported out-of-domain (OOD) utterances has a critical effect in practical use. Recent works have shown that using extra data and labels can improve the OOD detection performance, yet it could be costly to collect such data. This paper proposes to train a model with only IND data while supporting both IND intent classification and OOD detection. Our method designs a novel domain-regularized module (DRM) to reduce the overconfident phenomenon of a vanilla classifier, achieving a better generalization in both cases. Besides, DRM can be used as a drop-in replacement for the last layer in any neural network-based intent classifier, providing a low-cost strategy for a significant improvement. The evaluation on four datasets shows that our method built on BERT and RoBERTa models achieves state-of-the-art performance against existing approaches and the strong baselines we created for the comparisons.",
    "creator" : "LaTeX with hyperref"
  }
}