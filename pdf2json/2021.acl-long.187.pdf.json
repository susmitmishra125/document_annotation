{
  "name" : "2021.acl-long.187.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "A Hierarchical VAE for Calibrating Attributes while Generating Text using Normalizing Flow",
    "authors" : [ "Bidisha Samanta", "Mohit Agrawal", "Niloy Ganguly" ],
    "emails" : [ "bidisha@iitkgp.ac.in", "mohit@iitkgp.ac.in", "niloy@cse.iitkgp.ac.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2405–2415\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n2405"
    }, {
      "heading" : "1 Introduction",
      "text" : "The ubiquity of online social networks and world wide web has brought in diverse and often conflicting groups of users consuming similar information but from different perspectives. So the onus falls on the content producer to cater customized content based on the users’ profile. Consider an example related to a Spanish football (soccer) league. Say the news is “Barcelona has defeated Real Madrid”. This news needs to be presented in different tones to a Barcelona Fan - “Barcelona smashed Real-Madrid”, a Real-Madrid Fan - “Real Madrid lost the epic battle” and a (say) Villarreal Fan - “Barcelona wins three points against Real-Madrid”. Automatic generation of content with fine regulation of attributes like sentiment and style is extremely beneficial in this context. There are several related works in similar space of text-style-transfer techniques (Hu et al., 2017; Logeswaran et al.,\n2018; Shen et al., 2017; Singh and Palod, 2018) which attempt to switch polarity of a text from, e.g., formal to casual, or positive to negative sentiment. However, none of the work focuses on more involved problem of fine-grained regulation of attributes to generate multiple variants of a sentence.\nSeveral of the existing style-transfer methods (Fu et al., 2018; John et al., 2018) convert a continuous entangled generative representation space obtained using variational auto-encoder (Bowman et al., 2015) into disentangled attribute and content space. It facilitates attribute polarity switch by perturbing attribute representation without interfering with context. However, a disentangled generative representation may result in a loss of information about complex inter-dependency of content and attributes otherwise captured in an unmodified entangled generative space. Hence, trivial extension of the variational inference (encoding) mechanism for finer attribute control by allowing incremental perturbation of the attribute representation in the disentangled generative space often leads to generation of ‘not-so-natural’ sentence mostly unrelated to the original content.\nMore specifically, there are two design challenges which need to be tackled to achieve fine grained attribute control (a) smooth regulation of attributes via disentangled attribute space perturbation and (b) natural sentence generation preserving the content. This paper builds up a layered VAE to tackle these problems simultaneously. Specifically, we propose the model Control Text VAE (CTVAE), that transforms a derived representation of entangled and enriched text embedding (obtained using the BERT encoder) into a disentangled representation of attribute and context using a transformation module followed by a factored prior imposition to ensure independence between context and attribute dimensions. Further using attribute supervision on the dimension designated for a given attribute,\nwe establish a correlation between the continuous representation to the discrete attribute value facilitating smooth interpolation as intended in (a). It preserves both the disentangled and entangled representations in different hierarchy of inference module. Designing the transformation network as reversible, it restores the original entangled sentence representation which is our generative space, from the disentangled space to achieve (b).\nWe demonstrate the effectiveness of CTVAE to generate controlled text by fine tuning two different attributes namely sentiment and formality. Using five publicly available datasets, we show that CTVAE improves the performance significantly over previous controlled text generative models while performing content preserving style transfer and fine tuning of the target attribute. With human evaluation on generated sentences, for three different metrics - meaning preservation, degree of target attribute transfer and naturalness - we show that CTVAE can generate attribute regulated content preserving natural sentences. 1"
    }, {
      "heading" : "2 Related Work",
      "text" : "Unlike style-transfer, fine grained attribute regulated text generation is less explored yet extremely necessary. State-of-the-art methods for style transfer are categorized as supervised and unsupervised techniques. If parallel examples are available for any attribute, i.e., training data consisting of original and corresponding attribute flipped sentences, then supervised techniques (Bahdanau et al., 2014; Vaswani et al., 2017) could be used to perform style transfer. The papers (Xu et al., 2012; Jhamtani et al., 2017; Rao and Tetreault, 2018) introduced parallel corpora consisting of formal and corresponding informal sentences and showed that coarse-grained formality transfer is possible and benchmarked various neural frameworks for the same. Generating parallel training corpus for fine grained attribute transfer is expensive and impractical as for one sentence we need to generate multiple style transferred text bearing fine-grained attribute.\nSome recent works focus on semi-supervised approaches incorporating attribute informations with non-parallel datasets. These techniques mainly focus on disentangling the attribute and content representation in the latent space (Fu et al., 2018; John et al., 2018; Logeswaran et al., 2018; Shen et al.,\n1https://github.com/bidishasamantakgp/ CTVAE\n2017; Singh and Palod, 2018) by using different encoding modules along with feature supervision. A recent work (John et al., 2018) uses adversarial setup in a multitasking setting to achieve attribute representation independent of the content. As this work disentangles context and attribute in multidimensional spaces it limits interpolation of the attribute space to desired degree. Moreover, the disentangled generative space causes loss in important context. Similarly, the paper (Hu et al., 2017) uses attribute information as a structured or one-hot vector, which is not continuous restricting interpolation. They replace the attribute representation to a desired value (corresponding to opposite polarity) and generate sentences from this disentangled space. However, a naive extension for fine grained control by perturbing the attribute space by a small amount is difficult as the representation is multidimensional moreover, leads to unnatural, poorly readable sentence.\nFrom a different perspective, a recent work (He et al., 2020) proposed an unsupervised framework to achieve style transfer. They propose a generative probabilistic model that assumes non-parallel corpus as partially observed parallel corpus. They do not infer posterior distribution of the observed data, hence fine grained attribute transfer is difficult.\nAs the extensions of current style transfer methods are non-trivial, a recent work (Wang et al., 2019) has proposed fine grained sentiment regulation keeping the content intact. It gradually updates the entangled latent representation using costly fastgradient-iterative modification until it can generate a sentence entailing target attribute from that . However, overemphasis on content preservation often results in generation of the original unmodified sentence followed by new phrases bearing target attribute. This is not ideal to extend them for more difficult attributes like casual to formal transformation. Understanding the criticality of fine grained attribute transfer, we propose a new framework towards this direction, which does not only facilitate fine-grained control even for complex attributes, but is also able to mitigate the existing problems of disentangled generative space."
    }, {
      "heading" : "3 CTVAE for Fine Grained Control",
      "text" : "We propose a hierarchical model using Variational Autoencoders (Kingma and Welling, 2013) to achieve fine grained control over attribute space while maintaining the quality of the generated sen-\ntences. We provide a high level overview of CTVAE along with key technical aspects of the individual components followed by training procedure."
    }, {
      "heading" : "3.1 Model overview",
      "text" : "We consider an input set X = {x0, · · · ,xM−1} of M observed sentences sampled from some underlying unknown data distribution pD. Along with the sentences, we observe ground truth attribute, F = {f0, · · · , fM−1} where fi is associated to sentence xi. For ease of reference, we will henceforth denote a training instance xi and fi by x and f respectively. Detailed architectural overview of CTVAE is depicted in Figure 1, which can be divided into two modules consisting of a hierarchical encoder and a corresponding hierarchical decoder. We start by describing the inference model (encoder) followed by the generation model (decoder)."
    }, {
      "heading" : "3.2 Inference model",
      "text" : "The inference model is designed as a bottom-up hierarchical encoder with two distinct layers for modelling word sequence representation zs, and feature representation zf . We model an enriched sentence representation zs ∈ Rd with latent dimension size d from word sequence x as follows. We first obtain the contextual word embeddings for each word w in x from the BERT pre-trained model (Turc et al., 2019). Then, we generate an aggregated encoding Es by taking an average of them. Finally, we transform it into a continuous d dimensional Gaussian space using a fully connected neural network gφ by the following two steps.\n[µs, σs] = gφ(Es) (1) qφ(zs|x) = N (µs, diag(σ2s)), (2)\nThe sentence representation zs is sampled from this posterior distribution qφ(zs|x). It is an entangled complex manifold of different salient features present in multiple dimensions. This enriched representation is the generative representation as we decode sentences from zs for better quality.\nNext, we transform the sentence representation zs into another representation zf on which we impose disentanglement constraints followed by attribute supervision such that zf could be decomposed into independent space of context and attribute. We need an efficient transformation to maintain the inherent dependencies between the context and attribute during this process. Also it is important to restore enriched zs from decomposed zf i.e. to capture the reverse dependency. Instead of modeling two different transformation networks to capture the dependency in both ways, we design a single reversible transformation module. It guarantees that given a zf , we getback an appropriate entangled zs useful for natural sentence generation.\nHence, we build our transformation network extending R-NVP (Dinh et al., 2016) which is a reversible auto-regressive normalizing flow to achieve mentioned interdependency and inversion. Specifically, we split zs into two parts. The first d− 1 dimensions of the zs is dedicated to model latent factors important for context modelling. The rest of the (last) dimension is used to derive a representation for the specified attribute. The detailed interconnection between them in one transformation step is depicted in Figure 1(B). We obtain zf by T transformation steps, where T is a hyper parameter. In a transformation step t we obtain a representation distribution qt(zt|zt−1), which is characterized as the ordered set of following opera-\ntions:\n[µt1, σ t 1] = Ψ 1 t (zt−1(1:d−1)) (3) zt(d) = zt−1(d) · σ t 1 + µ t 1 (4) [µt2, σ t 2] = Ψ 2 t (zt(d)) (5) zt(1:d−1) = zt−1(1:d−1).σ t 2 + µ t 2, (6)\nThe Eq. (4) describes intuitively that the attribute representation field is dependent on first d− 1 dimensions or context. The Eq. (6) encodes how context is influenced by the attribute. Here, Ψ1t and Ψ2t are designed as multilayer fully connected feed-forward networks which are not invertible. However, a careful inspection of Eqs. (4) and (6) reveals that given a zt, the input zt−1 can be fully recovered. We provide the reverse transformations in the next subsection. Thus, we can get qφ(zf |zs) := qφ(zT |zs) and we assign zf := zT . We pick the dth (last) dimension of zf to model specified attribute representation za. To facilitate smooth interpolation in this attribute space, we keep za as unidimensional. We further use attribute supervision to establish the correlation with categorical values of the attribute. We will discuss the process in the next subsection. The rest of the dimensions of zf are kept for other contextual features zu. We discuss about disentanglement of zf in Sec. 3.4. The overall posterior distribution achieved by the hierarchical inference mechanism:\nqφ(z|x) = qφ(zs|x)︸ ︷︷ ︸ Entangled qφ(zf |zs)︸ ︷︷ ︸ Disentangled\n(7)"
    }, {
      "heading" : "3.3 Generative model",
      "text" : "We design our generative model pθ using a topdown hierarchy, with two different variables zs and zf . The overall distribution of the latent variables for the generation is defined as:\npθ(z) = pπ(zf )︸ ︷︷ ︸ Disentangled pθ(zs|zf )︸ ︷︷ ︸ Entangled\n(8)\nHere pπ(zf ) is a factored prior of the feature representation zf , which can be expressed as pπ(zf ) =∏d i=1 pπ(z i f ). We use a standard normal distribution, which is a factored isotropic distribution, as prior, i.e., pπ(zf ) = N (0, I). Imposing this factored prior enforces disentanglement (Kim and Mnih, 2018) on the derived space qφ(zf |zs). As discussed in the previous section, we have designated the last dimension of the zf to capture any\nattribute of interest, and remaining dimensions for other contextual features. Henceforth, attribute representation prior can be sampled from pπ(zdf ) and other contextual features prior representations can be sampled from ∏d−1 i=1 pπ(z i f ). We use feature supervision on za to increase the correlation between the representation and the attribute value as follows. Given za, we decode the categorical attribute value of the given sentence x and back propagate the loss of prediction to modify the network parameters. More specifically, the decoding distribution for the ground truth attribute is\npθ(f |za) = Categorical(ξ(za)) (9)\nHere ξ is a scaling network to convert the singular value za into a logit vector corresponding to categorical values of ground-truth attribute. Next, the network tries to decode the entangled distribution zs from the disentangled distribution zf . We apply the reverse transformation flow to recover zs using T inverse transformations. Starting from zf (zT ), we recover zs by reverse transformation steps pt(zt−1|zt), as a set of ordered operations:\n[µt2, σ t 2] = Ψ 2 t (zt(d)) (10) zt−1(1:d−1) = zt(1:d−1) − µt2\nσt2 , (11)\n[µt1, σ t 1] = Ψ 1 t (zt−1(1:d−1)) (12)\nzt−1(d) = zt(d) − µt1\nσt1 (13)\nThe Eq. (11) is the reverse transformation corresponding to the Eq. (6). Similarly Eq. (13) defines the reverse flow of Eq. (4). It may be noted that µ1t , µ 2 t and σ 1 t , σ 2 t are derived from the same neural network Ψ1t ,Ψ 2 t as Eqs. (3), (5). Hence, given a zt we can easily get back zt−1 without any loss of information. Thus we get zs := z1. Following the density estimation theory (Dinh et al., 2016), the log probability density of pθ(zs|zf ), i.e., log pT (zs|zf ) denoted as:\nlog pπ(zf )− T∑ t=1 log det dft dft−1\n(14)\nwhere ft denotes transformation function at step t described in Eqs. (3)- (6). Finally, with the decoded zs, we sample the word sequence x(j) using a recurrent unit as follows:\nx(j) ∼ Softmax(mθ(h(j))) (15)\nhere h(j) = rθ(x(j − 1), zs) is the hidden state of gated recurrent unit rθ which takes the previously generated token x(j − 1) and the sentence representation zs. Then we pass this hidden state information to a feedforward network mθ to generate logits. Subsequently, we sample words based on the softmax distribution of the generated logits. The joint likelihood of the sentence, features, and the latent variables pθ(x,f , zs, zf ):\n= pθ(x|zs)pθ(f |za)pθ(zs|zf )pπ(zf ) (16)"
    }, {
      "heading" : "3.4 Training",
      "text" : "We can learn the model parameters by optimizing the joint likelihood given in Eq.(16). To learn the complex transformation of disentangled attribute and context in zf from entangled zs precisely, we need to first estimate the approximate posterior qφ(zs|x) accurately. However, in the initial iterations of training the encoder fails to approximate the posterior distribution (He et al., 2019). Hence, we first train the lower layer by maximizing ELBO (Kingma and Welling, 2013) :\nEqφ(zs|x)log pθ(x|zs)− KL(qφ(zs|x)||pθ(zs|zf )) (17)\nThis is an unsupervised training as we are not using any attribute information and this objective helps to update encoder parameters to generate entangled zs. Once the lower layer is trained, we update the transformation parameters (Eq.(14)) and impose feature supervision by maximizing the marginal likelihood of zf given below:\nEqφ(zf |zs) [ βlog pθ(f |za) + log pπ(zf )− (18) T∑ t=1 log det dft dft−1 ] − αKL(qφ(zf |zs)||pπ(zf ))\nwhere α and β are regularizing parameters to enforce disentanglement of zf and emphasize on attribute supervision respectively. If we breakdown the KL term of the above objective function as Ez∼qφ(zs)I(zs, zf )+ KL(qφ(zf )||pπ(zf )), we get total correlation loss KL(qφ(zf )||pπ(zf )), minimizing which the model achieves disentanglement on zf along the dimensions (Higgins et al., 2017). Also, the mutual information I(f, za) between specified attribute and za can be computed using entropy functionH(.) asH(f)−H(f |za) ≥\nEx∼pD [Eqφ(zs|x)qφ(za|zs)log pθ(f |za)], is lower bounded by the likelihood pθ(f |za), hence, we emphasise on the likelihood term in the objective function using β to maintain higher correlation between za and f . Thus we update the network parameters phase by phase using Eqs.(17) and(18)."
    }, {
      "heading" : "4 Experiments",
      "text" : "We broadly looked into two evaluation criteria to compare the performance of different generative models (a) Attribute control: efficiency in generating sentences entailing target attribute of interest (b) Fine-grained transfer: efficiency of content preserving fine-grained attribute regulated text generation. In this section we discuss datasets, baselines followed by the performance across datasets."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We focused on two attributes of varied complexity, namely, (a) sentiment and (b) formality. In Table 1 we describe the datasets in detail. For sentiment we include two review datasets and one hate-speech dataset. The Gab dataset is designed for counterhatespeech learning and every hateful sentence has a candidate counter hate-speech. We consider them as non-hateful (NH) class of content. Thus we have training examples with hateful (H) and non-hateful (NH) contents. The formality datasets have formal (F) and corresponding casual (C) instances. We report all the results on the test data provided."
    }, {
      "heading" : "4.2 Baseline methods",
      "text" : "We compare CTVAE performance with semisupervised method - (a) ctrlGen (Hu et al., 2017), supervised method -(b) DAE (John et al., 2018) that focus on text-style-transfer using disentanglement, and unsupervised method (c) ProbStyleTransfer (He et al., 2020). We also compare with (d) entangleGen (Wang et al., 2019) which focuses on fine-grained style transfer using entangled representation. Apart from these state-of-the-art baselines, we inspect (e) CTVAE-NR (CTVAE NonReversible transformation) where we replace the invertible transformations of CTVAE with two separate transformation networks responsible to capture qφ(zf |zs) and pθ(zs|zf ). For different evaluation\ncriteria we compare CTVAE with different subsets of these methods described in relevant sections."
    }, {
      "heading" : "4.3 Performance on attribute control",
      "text" : "Experimental setup: We estimate the average representation value of za corresponding to each categorical (binary) value for an attribute of interest as zmax and zmin from training data. We generate attribute controlled sentences in two ways. First we sample a generative representation vector from the prior distribution (i.e., pθ(zs|zf ∼ N (0, I)) and assign either zmax or zmin to za. We sample 10 sentences from a representation and select the one which bears the target attribute. If there is no such sample generated we consider it as a failure case. Similarly, we assign zmax or zmin to za depending on the target attribute to posterior representation of a given sentence x. We sample 10 sentences from that and select the one most similar with x (BERT embeddings having cosine similarity greater than τ = 0.71) and entails the target attribute. If we fail to find any candidate following both the criteria we consider that a miss. We identify the generated sentences with target attribute using a classifier build by extending BERT and train on different datasets.\nWe investigate multiple cosine similarity thresholds τ (0.65 to 0.75 with granularity 0.01). We observe the generated sentences having cosine similarity with original sentence less than 0.7, don’t contain important context words. On contrary, we observe all methods except CTVAE and entangledGen were able to generate only a very small number of candidates with high similarity scores (>0.73). To provide a fair comparison we keep τ at 0.71 for all datasets across all methods. Metrics: We report controlled generation accuracy, i.e., percentage of generated sentences from prior bearing target attribute and style inversion accuracy, i.e., the percentage of generated sentences from posterior bearing target attribute and related content. We also report percentages of related content generation for style inversion. We report mean performance of each model trained with three ran-\ndom initialization. Baselines: We report ctrlGen and DAE for both metrics as they can sample generative representation from both prior and posterior. Whereas entangleGen and probTrans can only generate sentences corresponding to a given posterior, we compare them only for style inversion."
    }, {
      "heading" : "4.3.1 Sentiment control",
      "text" : "We report controlled generation accuracy and style inversion accuracy for Yelp, Amazon and GAB in Table 2. It can be observed that CTVAE outperforms all competing methods across three datasets for controlled generation. The superior performance of CTVAE stems from the fact that attribute supervision on disentangled representation helps to achieve better control of attributes than the semi supervised ctrlGen. DAE which is also an attribute supervised technique performs exactly same like ours. CTVAE effectively generates more related content than others and achieves best accuracy for style inversion in Amazon and both hateful to nonhateful (H-NH) and non-hateful to hateful (NH-H) transitions for GAB. It is the second best in Yelp. DAE, along with ctrlGen, uses disentangled generative space which often causes content information loss. Hence, they generate less related content with respect to other methods which leads to a drop in accuracy for style inversion. entangleGen performs best for style inversion for Yelp and second best in other datasets. It achieves relatively low accuracy even after producing larger amount of related content. It uses BERT embedding space to search for a candidate embedding closest to the original sentence for style inversion. As Yelp contains shorter coherent sentences it is easy to find related yet opposite polarity sentence embedding whereas for GAB the H and NH sets are quite different and their representation spaces are far from each other causing poor performance. The unsupervised method probTrans performs well in relatively simpler dataset Yelp and Amazon however, fails to generate related content for complex GAB\nand scores the lowest. As converting a counterhatespeech to hateful content is difficult, all methods perform poorly. The performance of CTVAENR is significantly inferior compared to CTVAE. Close inspection reveals that even though at training we achieve very low KL between qφ(zf |zs) and pθ(zs|zf ), the decoded zs is not exactly the same as the encoded distribution. Thus, it performs poorly in style inversion."
    }, {
      "heading" : "4.3.2 Formality control",
      "text" : "From the Table 2, we can see that CTVAE performs best in bothMusic and Family datasets for all metrics. Conversion of a casual sentence into formal (C-F) is more difficult as it would require some structural change of the sentence, whereas the reverse transformation (F-C) is easy. Though the disentangled based methods perform better for C-F relatively than F-C conversion, overall they perform poorly as they are unable to generate related content after perturbing disentangled generative space for the same. entangleGen also performs poorly in both the datasets for both C-F and F-C. As a pair of formal and corresponding informal sentences have very high content overlap, only structure, capitalization etc are different, in the BERT representation space they become very close. The generative model for entangleGen generates sentences from this representation space, hence it cannot distinguish much on smaller change of representation. It confuses the generative model and it generates the original sentence as it is very often. Unlike GAB, probTrans performs better than all semi-supervised methods along with entangleGen even though formality is a difficult attribute like\nhatred. As the formality datasets are parallel data, probTrans can accurately estimate the latent variables for them which otherwise is difficult. Hence, they learn to successfully generate style inverted text given parallel sentence."
    }, {
      "heading" : "4.4 Significance test",
      "text" : "We perform student t-test with significance level 0.05 and report expected p-values with closest baseline following Reimers et al. (Reimers and Gurevych, 2018) for two tasks i.e controlled generation and style inversion.\nFor controlled generation we find the p-values per dataset as follows. For Yelp the p-value is 0.009 compared against ctrlGen, for Amazon 0.019 with respect to ctrlGen, GAB 0.015 with ctrlGen, Music 0.012 against DAE and for Family the p-value is 0.008 compared with DAE. In first three datasets, DAE and CTVAE performs exactly same. Similarly, for style transfer we obtain the p-values as follows. For Amazon it is 0.028 in comparison to entangleGen, in GAB for (H-NHS) we get 0.028 compared against entangleGen and for (NHS-HS) it is 0.032 in comparison to ctrlGen. Music (CF) yields 0.002 and (F-C) yields 0.017 with probTrans, for Family (C-F) for 0.024 against ctrlGen and for (F-C) 0.030 compared against probTrans."
    }, {
      "heading" : "4.5 Fine grained attribute control",
      "text" : "Experimental Setup: We evaluate the performance of fine grained attribute control as follows. We create a set with n equidistant values between zmin to zero denoted as {−fi} and another n values between zero to zmax denoted as {fi}. The\nunion set F represents attribute control grades. Greater indices indicate higher perturbation in the attribute representation space and the sign denotes the direction. Given a posterior representation zf of a sentence x, we assign za to a value from F keeping zu fixed and decode a zs from that. We generate 10 sentences from it and select the sentence whose BERT embedding is closest to the original sentence as well as bears target attribute value. We repeat this for all values in F . We consider equivalent set F with n values for entangleGen with different increasing modification weights w which they used for fine grained attribute control in the original paper and generate sentences corresponding to that. Though ctrlGen does not support fine-grained transfer, we extended it by interpolating between two structured attribute representation vector [0,1] and [1, 0] and generating real valued vectors inF where each vector summed to one. For each attribute representation vector, we generate sentences from them similar to CTVAE. As, other models cannot be extended for the same, we do not compare their performance here. Metrics: We report attribute polarity score AP which estimates degree of attribute polarity of a generated sentence and a relatedness scoreR capturing the relatedness with the original sentence.\nFor review datasets Yelp and Amazon, AP is obtained from a pre-trained Stanford regressor model (Socher et al., 2013) normalized between 0 (most negative) and 1 (most positive). A pilot study on randomly picked 25 sentences shows that the pre-trained regression score is highly corelated (Spearman’s rank correlation 0.68) with human judgements. We reportR as Jaccard overlap (Tustison and Gee, 2009) of unigrams between original and generated sentence excluding stop words\nfor these datasets. However, for other three datasets the correlation observed is low. Hence, we resort to human evaluation via crowdflower platform 2.\nGiven a test sentence, we generate n sentences corresponding to n different grades in the set F and ask three annotators to rank these sentences from 1 to n. We get the average rank for this instance and repeat for all test sentences to obtain average ranks as AP corresponding to each of the n values. We ask them to provide an absolute score for relatedness (R) of the generated sentences with respect to the original sentence in a scale of 1 to 10, 1 being least related, we rescale it and present the result in the scale of 0 to 1. A coherent scheme would see monotonic change in value of AP with attribute control grades varying from −fn to fn and the value ofR staying close to one throughout."
    }, {
      "heading" : "4.5.1 Fine-grained sentiment control",
      "text" : "We demonstrate the performance of generative models on one review dataset Yelp and hatespeech dataset GAB in Figure 2(a), (b) respectively. We show the variation of attribute polarity AP and relatedness scoreR with n = 4. We can observe that there is a smooth increase in AP as we move from f1 to f4 (denoting greater shift from original za values towards zmax ) while achieving consistently high R for CTVAE in both the datasets. Similarly as we move from −f1 to −f4 CTVAE shows monotonic decrease in AP still achieving highest R. Though a similar pattern is observed in ctrlGen in Yelp, it has extremely poorR score which denotes that it generates unrelated sentences in the process of fine-grained attribute regulation. Moreover, it shows minimum variation in sentiment score thoughout the process. In contrast, entan-\n2www.appen.com\ngleGen achieves highestR score as they focus on content preservation, however, the sentiment score transition is uneven and doesn’t follow the desired coherency. ctrlGen shows minimum variation in sentiment score thoughout the process. In contrast, CTVAE successfully maintains a balance for relatedness and attribute control. It can be observed that CTVAE shows a monotonic transition as we move from left to right denoting higher degree of attribute representation change for Amazon while other methods show haphazard changes.\nIn GAB ctrlGen shows abrupt change in AP and lowest score for R which demonstrates very less control towards fine-tuned attribute regulation for hatred filtering. Though entangleGen achieved lowest score in AP , signifying it can more accurately remove hateful content than CTVAE, the variation is not monotonic. Further inspection reveals that entangleGen mostly generates counter hate-speech as BERT representation clusters H and NH for GAB locate in two distant spaces. Hence, the relatednessR of the generated sentences is low. In contrast, CTVAE successfully maintains a balance for relatedness and attribute control in both."
    }, {
      "heading" : "4.5.2 Fine-grained formality control",
      "text" : "We experiment with n = 3 equidistant values in each direction in F and report the performance on Music and Family dataset in Figure 2 (d,e). It can be observed from the figure that all the methods received a similar AP score, around 2.0, for C-F transformation from f1 to f3. Also, as we move to right after f1, the changes in AP are inconsistent for CTVAE and entangleGen. However CTVAE achieves relatively better formality score thoughout. entangleGen achieves bestR and low AP due to generation of original content verbatim very often. ctrlGen shows lowest relatedness and achieves a transfer score AP = 1.5 on average, that is, overall it fails to generate formal sentences. Moving towards casual transition, i.e., from −f1 to −f3 we observe a similar trend for CTVAE and entangleGen. Though the variation with respect to attribute control grades in F is abrupt, we achieve the lowest AP , i.e., most informal sentences. ctrlGen performs very poor with respect to all the methods. for Family there is no trend in AP found. CTVAE maintains highR, whereas ctrlGen was able to achieve lowest relatedness score."
    }, {
      "heading" : "4.6 Fluency",
      "text" : "We also investigate the fluency of these methods across datasets reported in Table 4 and found that CTVAE produces very high percentage fluent sentences similar to entangleGen. As we have observed, entangleGen tends to copy the content for formality datasets because the formal and casual sentences lie close in the representation space, the fluency is high. Similarly for GAB dataset, as it tends to generate counter-hatespeech the fluency remains high.\nFinally, Table 3 provides examples of fine grained sentiment and hatred regulated sentences generated by CTVAE, entangleGen, and ctrlGen. We observe that entangleGen generally produces long sentences, sometimes copies the original content. It produces same sentence multiple times. On the other hand, ctrlGen mostly generates sentences hardly related with the original content. In contrast, CTVAE can generate related sentences and provides finer attribute variation, controlled by fi."
    }, {
      "heading" : "5 Conclusion",
      "text" : "The major contribution of this paper is to propose CTVAE which consists of a carefully designed hierarchical architecture facilitating disentangled representation to control attribute without affecting context as well as enriched entangled generative representation for meaningful sentence generation. The invertible normalizing flow as a transformation module between the two representation of CTVAE enables learning of complex interdependency between attribute and context without the loss of information. Such a design choice is key to achieving accurate fine tuning of attributes (be it sentiment or formality) while keeping the content intact. This is a key achievement considering the difficulty of the problem and modest performance of state-of-the-art techniques. Extensive experiments on real-world datasets emphatically establish the well-rounded performance of CTVAE and its superiority over the baselines."
    }, {
      "heading" : "A Analysis of attribute supervision",
      "text" : "Here we perform an ablation study by demonstrating the importance of the last dimension za of the representation zf in capturing sentiment. As we ensure independence of every dimension, we calculate the correlation of every dimension of zf with the sentiment labels in the test data. We observe that za achieves the highest correlation of 0.72 in Yelp and 0.42 in Amazon. We further train a logistic regression classifier with za of training data as a feature to predict sentiment labels, and we achieve a high accuracy of 0.85 and 0.64 on test data in Yelp and Amazon respectively. While training with the most correlated dimension of zf other than za, with a correlation of 0.12 for Yelp and 0.14 for Amazon, we achieve an accuracy of only 0.52 and 0.58 respectively. This implies that za is the most expressive dimension for capturing sentiment in comparison to any other dimension."
    }, {
      "heading" : "B Parameter Setting",
      "text" : "The sentence encoder is designed using pre-trained BERT-base-uncased model (embedding dim = 768) followed by 2-layer feed-forward network with hidden dim 200. The output of the same is the sentence embedding which is of dimension 256 for every dataset. The flow network is designed as RNVP with T = 3 and each ψt is designed as three layer feed forward network with tanh activation function for the initial two layers and hidden dimension is 100 for the intermediate layers. The scaling network for sentiment classification is designed as a two dimensional vector [−1, 1]. The sentence decoder is designed as a gated recurrent unit where output of each step is passed through a fully connected feed-forward network to convert it to a logit of length of the vocabulary size. The weighing parameters β and γ are set to 10 for feature supervision and disentanglement."
    }, {
      "heading" : "C Qualitative Examples",
      "text" : "In Table 5 we provide some examples of Casual to Formal conversion. We can see with increase of the perturbation CTVAE introduces more formal notions to the sentences as proper capitalization or not using any abbreviation etc. Whereas entangleGen fails to introduce such changes to keep content intact and ctrlGen generates unrelated content."
    }, {
      "heading" : "D Training time comparison",
      "text" : "In this section we provide a comparative analysis of training time and sampling time of CTVAE with entangleGen. Fig 3 shows that CTVAE is much faster than that of entangleGen for both cases."
    } ],
    "references" : [ {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1409.0473.",
      "citeRegEx" : "Bahdanau et al\\.,? 2014",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "Generating sentences from a continuous space",
      "author" : [ "Samuel R Bowman", "Luke Vilnis", "Oriol Vinyals", "Dai." ],
      "venue" : "arXiv preprint arXiv:1511.06349.",
      "citeRegEx" : "Bowman et al\\.,? 2015",
      "shortCiteRegEx" : "Bowman et al\\.",
      "year" : 2015
    }, {
      "title" : "Density estimation using real nvp",
      "author" : [ "Laurent Dinh", "Jascha Sohl-Dickstein", "Samy Bengio." ],
      "venue" : "arXiv preprint arXiv:1605.08803.",
      "citeRegEx" : "Dinh et al\\.,? 2016",
      "shortCiteRegEx" : "Dinh et al\\.",
      "year" : 2016
    }, {
      "title" : "Style transfer in text: Exploration and evaluation",
      "author" : [ "Zhenxin Fu", "Xiaoye Tan", "Nanyun Peng", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Thirty-Second AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Fu et al\\.,? 2018",
      "shortCiteRegEx" : "Fu et al\\.",
      "year" : 2018
    }, {
      "title" : "Lagging inference networks and posterior collapse in variational autoencoders",
      "author" : [ "Junxian He", "Daniel Spokoyny", "Graham Neubig", "Taylor Berg-Kirkpatrick." ],
      "venue" : "arXiv preprint arXiv:1901.05534.",
      "citeRegEx" : "He et al\\.,? 2019",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2019
    }, {
      "title" : "A probabilistic formulation of unsupervised text style transfer",
      "author" : [ "Junxian He", "Xinyi Wang", "Graham Neubig", "Taylor Berg-Kirkpatrick." ],
      "venue" : "arXiv preprint arXiv:2002.03912.",
      "citeRegEx" : "He et al\\.,? 2020",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2020
    }, {
      "title" : "beta-vae: Learning basic visual concepts with a constrained variational framework",
      "author" : [ "Irina Higgins", "Loic Matthey", "Arka Pal", "Christopher Burgess", "Xavier Glorot", "Matthew Botvinick", "Shakir Mohamed", "Alexander Lerchner." ],
      "venue" : "ICLR, 2(5):6.",
      "citeRegEx" : "Higgins et al\\.,? 2017",
      "shortCiteRegEx" : "Higgins et al\\.",
      "year" : 2017
    }, {
      "title" : "Toward controlled generation of text",
      "author" : [ "Zhiting Hu", "Zichao Yang", "Xiaodan Liang", "Ruslan Salakhutdinov", "Eric P Xing." ],
      "venue" : "Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1587–1596. JMLR. org.",
      "citeRegEx" : "Hu et al\\.,? 2017",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2017
    }, {
      "title" : "Shakespearizing modern language using copy-enriched sequence-to-sequence models",
      "author" : [ "Harsh Jhamtani", "Varun Gangal", "Eduard Hovy", "Eric Nyberg." ],
      "venue" : "arXiv preprint arXiv:1707.01161.",
      "citeRegEx" : "Jhamtani et al\\.,? 2017",
      "shortCiteRegEx" : "Jhamtani et al\\.",
      "year" : 2017
    }, {
      "title" : "Disentangled representation learning for non-parallel text style transfer",
      "author" : [ "Vineet John", "Lili Mou", "Hareesh Bahuleyan", "Olga Vechtomova." ],
      "venue" : "arXiv preprint arXiv:1808.04339.",
      "citeRegEx" : "John et al\\.,? 2018",
      "shortCiteRegEx" : "John et al\\.",
      "year" : 2018
    }, {
      "title" : "Disentangling by factorising",
      "author" : [ "Hyunjik Kim", "Andriy Mnih." ],
      "venue" : "arXiv preprint arXiv:1802.05983.",
      "citeRegEx" : "Kim and Mnih.,? 2018",
      "shortCiteRegEx" : "Kim and Mnih.",
      "year" : 2018
    }, {
      "title" : "Autoencoding variational bayes",
      "author" : [ "Diederik P Kingma", "Max Welling." ],
      "venue" : "arXiv preprint arXiv:1312.6114.",
      "citeRegEx" : "Kingma and Welling.,? 2013",
      "shortCiteRegEx" : "Kingma and Welling.",
      "year" : 2013
    }, {
      "title" : "Content preserving text generation with attribute controls",
      "author" : [ "Lajanugen Logeswaran", "Honglak Lee", "Samy Bengio." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 5103–5113.",
      "citeRegEx" : "Logeswaran et al\\.,? 2018",
      "shortCiteRegEx" : "Logeswaran et al\\.",
      "year" : 2018
    }, {
      "title" : "A benchmark dataset for learning to intervene in online hate speech",
      "author" : [ "Jing Qian", "Anna Bethke", "Yinyin Liu", "Elizabeth Belding", "William Yang Wang." ],
      "venue" : "arXiv preprint arXiv:1909.04251.",
      "citeRegEx" : "Qian et al\\.,? 2019",
      "shortCiteRegEx" : "Qian et al\\.",
      "year" : 2019
    }, {
      "title" : "Dear sir or madam, may i introduce the gyafc dataset: Corpus, benchmarks and metrics for formality style transfer",
      "author" : [ "Sudha Rao", "Joel Tetreault." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Rao and Tetreault.,? 2018",
      "shortCiteRegEx" : "Rao and Tetreault.",
      "year" : 2018
    }, {
      "title" : "Why comparing single performance scores does not allow to draw conclusions about machine learning approaches",
      "author" : [ "Nils Reimers", "Iryna Gurevych." ],
      "venue" : "arXiv preprint arXiv:1803.09578.",
      "citeRegEx" : "Reimers and Gurevych.,? 2018",
      "shortCiteRegEx" : "Reimers and Gurevych.",
      "year" : 2018
    }, {
      "title" : "Style transfer from non-parallel text by cross-alignment",
      "author" : [ "Tianxiao Shen", "Tao Lei", "Regina Barzilay", "Tommi Jaakkola." ],
      "venue" : "Advances in neural information processing systems, pages 6830–6841.",
      "citeRegEx" : "Shen et al\\.,? 2017",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2017
    }, {
      "title" : "Sentiment transfer using seq2seq adversarial autoencoders",
      "author" : [ "Ayush Singh", "Ritu Palod." ],
      "venue" : "arXiv preprint arXiv:1804.04003.",
      "citeRegEx" : "Singh and Palod.,? 2018",
      "shortCiteRegEx" : "Singh and Palod.",
      "year" : 2018
    }, {
      "title" : "Recursive deep models for semantic compositionality over a sentiment treebank",
      "author" : [ "Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D Manning", "Andrew Ng", "Christopher Potts." ],
      "venue" : "Proceedings of the 2013 conference on",
      "citeRegEx" : "Socher et al\\.,? 2013",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Well-read students learn better: On the importance of pre-training compact models",
      "author" : [ "Iulia Turc", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1908.08962v2.",
      "citeRegEx" : "Turc et al\\.,? 2019",
      "shortCiteRegEx" : "Turc et al\\.",
      "year" : 2019
    }, {
      "title" : "Introducing dice, jaccard, and other label overlap measures to itk",
      "author" : [ "NJ Tustison", "JC Gee." ],
      "venue" : "Insight J, 2.",
      "citeRegEx" : "Tustison and Gee.,? 2009",
      "shortCiteRegEx" : "Tustison and Gee.",
      "year" : 2009
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in neural information processing systems, pages 5998–6008.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Controllable unsupervised text attribute transfer via editing entangled latent representation",
      "author" : [ "Ke Wang", "Hang Hua", "Xiaojun Wan." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 11034– 11044.",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Paraphrasing for style",
      "author" : [ "Wei Xu", "Alan Ritter", "Bill Dolan", "Ralph Grishman", "Colin Cherry." ],
      "venue" : "Proceedings of COLING 2012, pages 2899–2914.",
      "citeRegEx" : "Xu et al\\.,? 2012",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "There are several related works in similar space of text-style-transfer techniques (Hu et al., 2017; Logeswaran et al., 2018; Shen et al., 2017; Singh and Palod, 2018) which attempt to switch polarity of a text from, e.",
      "startOffset" : 83,
      "endOffset" : 167
    }, {
      "referenceID" : 12,
      "context" : "There are several related works in similar space of text-style-transfer techniques (Hu et al., 2017; Logeswaran et al., 2018; Shen et al., 2017; Singh and Palod, 2018) which attempt to switch polarity of a text from, e.",
      "startOffset" : 83,
      "endOffset" : 167
    }, {
      "referenceID" : 16,
      "context" : "There are several related works in similar space of text-style-transfer techniques (Hu et al., 2017; Logeswaran et al., 2018; Shen et al., 2017; Singh and Palod, 2018) which attempt to switch polarity of a text from, e.",
      "startOffset" : 83,
      "endOffset" : 167
    }, {
      "referenceID" : 17,
      "context" : "There are several related works in similar space of text-style-transfer techniques (Hu et al., 2017; Logeswaran et al., 2018; Shen et al., 2017; Singh and Palod, 2018) which attempt to switch polarity of a text from, e.",
      "startOffset" : 83,
      "endOffset" : 167
    }, {
      "referenceID" : 3,
      "context" : "Several of the existing style-transfer methods (Fu et al., 2018; John et al., 2018) convert a continuous entangled generative representation space obtained using variational auto-encoder (Bowman et al.",
      "startOffset" : 47,
      "endOffset" : 83
    }, {
      "referenceID" : 9,
      "context" : "Several of the existing style-transfer methods (Fu et al., 2018; John et al., 2018) convert a continuous entangled generative representation space obtained using variational auto-encoder (Bowman et al.",
      "startOffset" : 47,
      "endOffset" : 83
    }, {
      "referenceID" : 1,
      "context" : ", 2018) convert a continuous entangled generative representation space obtained using variational auto-encoder (Bowman et al., 2015) into disentangled attribute and content",
      "startOffset" : 111,
      "endOffset" : 132
    }, {
      "referenceID" : 0,
      "context" : ", training data consisting of original and corresponding attribute flipped sentences, then supervised techniques (Bahdanau et al., 2014; Vaswani et al., 2017) could be used to perform style transfer.",
      "startOffset" : 113,
      "endOffset" : 158
    }, {
      "referenceID" : 21,
      "context" : ", training data consisting of original and corresponding attribute flipped sentences, then supervised techniques (Bahdanau et al., 2014; Vaswani et al., 2017) could be used to perform style transfer.",
      "startOffset" : 113,
      "endOffset" : 158
    }, {
      "referenceID" : 23,
      "context" : "The papers (Xu et al., 2012; Jhamtani et al., 2017; Rao and Tetreault, 2018) introduced parallel corpora consisting of formal and corresponding informal sentences and showed that coarse-grained formality transfer is possible and benchmarked various neural frameworks for the same.",
      "startOffset" : 11,
      "endOffset" : 76
    }, {
      "referenceID" : 8,
      "context" : "The papers (Xu et al., 2012; Jhamtani et al., 2017; Rao and Tetreault, 2018) introduced parallel corpora consisting of formal and corresponding informal sentences and showed that coarse-grained formality transfer is possible and benchmarked various neural frameworks for the same.",
      "startOffset" : 11,
      "endOffset" : 76
    }, {
      "referenceID" : 14,
      "context" : "The papers (Xu et al., 2012; Jhamtani et al., 2017; Rao and Tetreault, 2018) introduced parallel corpora consisting of formal and corresponding informal sentences and showed that coarse-grained formality transfer is possible and benchmarked various neural frameworks for the same.",
      "startOffset" : 11,
      "endOffset" : 76
    }, {
      "referenceID" : 9,
      "context" : "A recent work (John et al., 2018) uses adversarial setup in a multitasking setting to achieve attribute representation independent of the content.",
      "startOffset" : 14,
      "endOffset" : 33
    }, {
      "referenceID" : 7,
      "context" : "Similarly, the paper (Hu et al., 2017) uses attribute information as a structured or one-hot vector, which is not continuous restricting interpolation.",
      "startOffset" : 21,
      "endOffset" : 38
    }, {
      "referenceID" : 5,
      "context" : "From a different perspective, a recent work (He et al., 2020) proposed an unsupervised framework to achieve style transfer.",
      "startOffset" : 44,
      "endOffset" : 61
    }, {
      "referenceID" : 22,
      "context" : "As the extensions of current style transfer methods are non-trivial, a recent work (Wang et al., 2019) has proposed fine grained sentiment regulation keeping the content intact.",
      "startOffset" : 83,
      "endOffset" : 102
    }, {
      "referenceID" : 11,
      "context" : "We propose a hierarchical model using Variational Autoencoders (Kingma and Welling, 2013) to achieve fine grained control over attribute space while maintaining the quality of the generated sen-",
      "startOffset" : 63,
      "endOffset" : 89
    }, {
      "referenceID" : 19,
      "context" : "We first obtain the contextual word embeddings for each word w in x from the BERT pre-trained model (Turc et al., 2019).",
      "startOffset" : 100,
      "endOffset" : 119
    }, {
      "referenceID" : 2,
      "context" : "Hence, we build our transformation network extending R-NVP (Dinh et al., 2016) which is a reversible auto-regressive normalizing flow to achieve mentioned interdependency and inversion.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 10,
      "context" : "Imposing this factored prior enforces disentanglement (Kim and Mnih, 2018) on the derived space qφ(zf |zs).",
      "startOffset" : 54,
      "endOffset" : 74
    }, {
      "referenceID" : 2,
      "context" : "Following the density estimation theory (Dinh et al., 2016), the log probability density of pθ(zs|zf ), i.",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 4,
      "context" : "However, in the initial iterations of training the encoder fails to approximate the posterior distribution (He et al., 2019).",
      "startOffset" : 107,
      "endOffset" : 124
    }, {
      "referenceID" : 11,
      "context" : "Hence, we first train the lower layer by maximizing ELBO (Kingma and Welling, 2013) :",
      "startOffset" : 57,
      "endOffset" : 83
    }, {
      "referenceID" : 6,
      "context" : "If we breakdown the KL term of the above objective function as Ez∼qφ(zs)I(zs, zf )+ KL(qφ(zf )||pπ(zf )), we get total correlation loss KL(qφ(zf )||pπ(zf )), minimizing which the model achieves disentanglement on zf along the dimensions (Higgins et al., 2017).",
      "startOffset" : 237,
      "endOffset" : 259
    }, {
      "referenceID" : 22,
      "context" : "len Vocab Sentiment Yelp (Wang et al., 2019) 443K 15 16K Sentiment Amazon (Wang et al.",
      "startOffset" : 25,
      "endOffset" : 44
    }, {
      "referenceID" : 22,
      "context" : ", 2019) 443K 15 16K Sentiment Amazon (Wang et al., 2019) 554K 35 18K Sentiment Gab (Qian et al.",
      "startOffset" : 37,
      "endOffset" : 56
    }, {
      "referenceID" : 13,
      "context" : ", 2019) 554K 35 18K Sentiment Gab (Qian et al., 2019) 36K 35 29K Formality Family (Rao and Tetreault, 2018) 1M 25 41K Formality Music (Rao and Tetreault, 2018) 1M 25 35K",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 14,
      "context" : ", 2019) 36K 35 29K Formality Family (Rao and Tetreault, 2018) 1M 25 41K Formality Music (Rao and Tetreault, 2018) 1M 25 35K",
      "startOffset" : 36,
      "endOffset" : 61
    }, {
      "referenceID" : 14,
      "context" : ", 2019) 36K 35 29K Formality Family (Rao and Tetreault, 2018) 1M 25 41K Formality Music (Rao and Tetreault, 2018) 1M 25 35K",
      "startOffset" : 88,
      "endOffset" : 113
    }, {
      "referenceID" : 7,
      "context" : "We compare CTVAE performance with semisupervised method - (a) ctrlGen (Hu et al., 2017), supervised method -(b) DAE (John et al.",
      "startOffset" : 70,
      "endOffset" : 87
    }, {
      "referenceID" : 9,
      "context" : ", 2017), supervised method -(b) DAE (John et al., 2018) that focus on text-style-transfer using disentanglement, and unsupervised method (c) ProbStyleTransfer (He et al.",
      "startOffset" : 36,
      "endOffset" : 55
    }, {
      "referenceID" : 5,
      "context" : ", 2018) that focus on text-style-transfer using disentanglement, and unsupervised method (c) ProbStyleTransfer (He et al., 2020).",
      "startOffset" : 111,
      "endOffset" : 128
    }, {
      "referenceID" : 22,
      "context" : "We also compare with (d) entangleGen (Wang et al., 2019) which focuses on fine-grained style transfer using entangled representation.",
      "startOffset" : 37,
      "endOffset" : 56
    }, {
      "referenceID" : 18,
      "context" : "For review datasets Yelp and Amazon, AP is obtained from a pre-trained Stanford regressor model (Socher et al., 2013) normalized between 0 (most negative) and 1 (most positive).",
      "startOffset" : 96,
      "endOffset" : 117
    }, {
      "referenceID" : 20,
      "context" : "We reportR as Jaccard overlap (Tustison and Gee, 2009) of unigrams between original and generated sentence excluding stop words for these datasets.",
      "startOffset" : 30,
      "endOffset" : 54
    } ],
    "year" : 2021,
    "abstractText" : "In this digital age, online users expect personalized content. To cater to diverse group of audiences across online platforms it is necessary to generate multiple variants of same content with differing degree of characteristics (sentiment, style, formality, etc.). Though text-style transfer is a well explored related area, it focuses on flipping the style attribute polarity instead of regulating a fine-grained attribute transfer. In this paper we propose a hierarchical architecture for finer control over the attribute, preserving content using attribute disentanglement. We demonstrate the effectiveness of the generative process for two different attributes with varied complexity, namely sentiment and formality. With extensive experiments and human evaluation on five real-world datasets, we show that the framework can generate natural looking sentences with finer degree of control of intensity of a given attribute.",
    "creator" : "LaTeX with hyperref"
  }
}