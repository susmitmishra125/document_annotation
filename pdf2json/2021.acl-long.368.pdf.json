{
  "name" : "2021.acl-long.368.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "On Compositional Generalization of Neural Machine Translation",
    "authors" : [ "Yafu Li", "Yongjing Yin", "Yulong Chen", "Yue Zhang" ],
    "emails" : [ "yafuly@gmail.com", "yinyongjing@westlake.edu.cn", "yulongchen1010@gmail.com", "yue.zhang@wias.org.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4767–4780\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4767"
    }, {
      "heading" : "1 Introduction",
      "text" : "Neural machine translation (NMT) has shown competitive performance on benchmark datasets such as IWSLT and WMT (Vaswani et al., 2017; Edunov et al., 2018a; Liu et al., 2020a), and even achieves parity with professional human translation under certain evaluation settings (Hassan et al., 2018). However, the performance can be relatively low in out-of-domain and low-resource conditions. In addition, NMT systems show poor robustness and vulnerability to input perturbations (Belinkov and Bisk, 2018a; Cheng et al., 2019). One example is shown in Table 1, where simple substitution of a word yields translation with completely different semantics. Many of these issues origin from the fact that NMT models are trained end-to-end over large parallel data, where new test sentences can be sparse.\nDisregarding out-of-vocabulary words, a main cause of sparsity is semantic composition: given a limited vocabulary, the number of possible compositions grows exponentially with respect to the composite length. The ability to understand and\nproduce a potentially infinite number of novel combinations of known components, namely compositional generalization (Chomsky; Montague; Lake and Baroni, 2018; Keysers et al., 2020), has been demonstrated deficient in many machine learning (ML) methods (Johnson et al., 2017a; Lake and Baroni, 2018; Bastings et al., 2018; Loula et al., 2018; Russin et al., 2019a).\nIn this paper, we study compositional generalization in the context of machine translation. For example, if “red cars” and “blue balls” are seen in training, a competent algorithm is expected to translate “red balls” correctly, even if the phrase has not been seen in training data. Intuitively, the challenge increases as the composite length grows. Recently, several studies have taken steps towards this specific problem. They either use a few dedicated samples (i.e., 8 test sentences) for evaluation (Lake and Baroni, 2018; Li et al., 2019b; Chen et al., 2020), or make simple modifications in sampled source sentences such as removing or adding adverbs, and concatenating two sentences (Raunak et al., 2019; Fadaee and Monz, 2020a). Such experimental data is limited in size, scope and specificity, and the forms of composition are coarse-grained and non-systematic. As a result, no qualitative conclusions have been drawn on the prevalence and characteristics of this problem in modern NMT.\nWe make a first large-scale general domain investigation, constructing the CoGnition dataset (Compositional Generalization Machine Translation Dataset), a clean and consistent paral-\nlel dataset in English-Chinese, along with a synthetic test set to quantify and analyze the compositional generalization of NMT models. In particular, we define frequent syntactic constituents as compounds, and basic semantic components in constituents as atoms. In addition to the standard training, validation and test sets, the CoGnition dataset contains a compositional generalization test set, which contains novel compounds in each sentence, so that both the generalization error rate can be evaluated, and its influence on BLEU (Papineni et al., 2002) can be quantified. Our compositional generalization test set consists of 2,160 novel compounds, with up to 5 atoms and 7 words. In this way, generalization ability can be evaluated based on compound translation error rate.\nEmpirical results show that the dominant Transformer (Vaswani et al., 2017) NMT model faces challenges in translating novel compounds, despite its competitive performance under traditional evaluation metrics such as BLEU. In addition, we observe that various factors exert salient effects on model’s ability of compositional generalization, such as compound frequency, compound length, atom co-occurrence, linguistic patterns, and context complexity. The CoGnition dataset along with the automatic evaluation tool are realesed on https://github.com/yafuly/CoGnition."
    }, {
      "heading" : "2 Related Work",
      "text" : "Analysis of NMT. Our work is related to research analyzing NMT from various perspectives. There has been much linguistic analysis of NMT representations (Shi et al., 2016; Belinkov et al., 2017; Bisazza and Tump, 2018), interpretability (Ding et al., 2017; He et al., 2019; Voita et al., 2019a), and attention weights (Voita et al., 2019b; Michel et al., 2019). Robustness is also an important research direction. Work has shown that NMT models are prone to be negatively affected by both synthetic and natural noise (Belinkov and Bisk,\n2018b; Cheng et al., 2018; Ebrahimi et al., 2018). For better exploration of robust NMT, Michel and Neubig (2018) propose an MTNT dataset containing several types of noise. Wang et al. (2020) provide in-depth analyses of inference miscalibration of NMT resulting from the discrepancy between training and inference. Our work is in line but we discuss robustness from the perspective of compositional generalization.\nIn this respect, Lake and Baroni (2018) propose a simple experiment to analyze compositionality in MT, followed by Chen et al. (2020) and Li et al. (2019b). Specifically, they introduce a novel word “dax”, and their training data contains a single pattern of sentence pairs (e.g. “I am daxy”, “je suis daxiste”) while the test set contains different patterns. However, their work is limited in that there are only 8 sentences in the test set. Raunak et al. (2019) observe a performance drop on a dataset of concatenated source sentences. Fadaee and Monz (2020b) modify source sentences by removing adverbs, substituting numbers, inserting words that tend to keep syntax correct (e.g. “very”), and changing the gender, and find unexpected changes in the translation. In contrast to these studies, we quantitatively measure compositionality of NMT under compound translation error rate.\nTranslation involves various challenges such as low-frequency words, polysemy and compositional complexity. In this work, we focus on how the NMT model generalizes to complex compositions in a controllable setting and minimize the effects of the other factors.\nCompositional Generalization. Neural networks have been shown sample-inefficient, requiring large-scale training data, which suggests that they may lack compositionality (Lake and Baroni, 2018). Lake and Baroni (2018) introduce the SCAN dataset to help study compositional generalization of neural networks, which has received increasing interests (Russin et al., 2019b;\nDessı̀ and Baroni, 2019; Li et al., 2019c; Lake, 2019; Andreas, 2020; Gordon et al., 2020). Various benchmarks have been proposed including in the area of visual reasoning (Johnson et al., 2017b; Hudson and Manning, 2019), mathematics (Saxton et al., 2019), and semantic parsing (CFQ) (Keysers et al., 2020). However, no benchmark has been dedicated to machine translation in practice. We fill this gap by introducing a dataset with 216,000 instances and an average sentence length of 9.7 tokens."
    }, {
      "heading" : "3 Problem Definition",
      "text" : "Following Keysers et al. (2020), compositional generalization is defined as the capacity to systematically generalize to novel combinations of components which are learned sufficiently during training. Key elements to measure compositional generalization include atoms and compounds. Specifically, atoms are primitive elements in the train set whereas compounds are obtained by composing these atoms. The research question is whether neural models perform well on unseen compounds. Take Table 2 for example, in the SCAN dataset, the atoms are simple commands such as “jump” and the composite command “jump twice” is a compound. In the CFQ, the compounds are questions such as “Who directed Elysium”, and the atoms correspond to the primitive elements in the questions such as the predicate “directed”, the question patterns “Who [predicate] [entity]” and the entities “Elysium”.\nIn theory, compounds in MT can be defined as phrases, sentences or even document. In practice, however, we want to control the number of atoms in a novel compound for quantitative evaluation. In addition, it can be highly difficult to construct a large-scale dataset where novel compounds are sentences of practical sizes (the number of synthesized sentences increases exponentially with their length) while ensuring their grammatical correctness. Therefore, we constrain compounds to syntactic constituents, and define atoms as basic semantic components in constituents according to syntactic and semantic rules for forming constituents (Partee, 1995). As a result, we randomly assign multiple sentential contexts for investigating each novel compound. Table 2 shows a contrast between our dataset and existing datasets for compositional generalization in semantics.\nMistakes caused by weakness in computational\ngeneralization can be easily found in state-ofthe-art NMT models. In particular, we train a Transformer-based model (Vaswani et al., 2017) on WMT17 En-Zh Dataset 1. One sentence in the standard test set, “but the problem is , with the arrival of durant , thompson ’s appearance rate will surely decline , which is bound to affect his play”, is translated into “FÓò/,è@\\py Ñ0e, dnÓÑ hØö⇢↵M, Ÿ ö⇢ qÕ0÷Ñh” (English: but the problem is , with the arrival of durant , thompson ’s will surely look worse , which is bound to affect his play). The novel compound “appearance rate” is composed of two atoms (i.e., “appearance” and “rate”), both with a high frequency of more than 27,000 times in the training set. However, the sentence semantics is completely distorted due to the failure of semantic composition, which is possibly influenced by the context word “play”. More importantly, as the overall translation highly overlaps with the reference, the model achieves a high score in similarity-based metrics such as BLEU, demonstrating that fatal translation errors can be overlooked under traditional evaluation metrics."
    }, {
      "heading" : "4 Dataset",
      "text" : "Figure 1 gives an overview of our data construction process. We first source monolingual data (Section 4.1), and then build parallel data based by translation (Section 4.2). Then we synthesize a test set of novel compounds (Section 4.3), and offer an automatic evaluation method (Section 4.4)."
    }, {
      "heading" : "4.1 Monolingual Data Source",
      "text" : "Our goal is to focus on compositional generalization and minimize the influence of additional factors such as polysemy (Berard et al., 2019), misalignment (Munteanu and Marcu, 2005), and stylistic problems (Hovy et al., 2020). The dataset should ideally have following characteristics. First, the vocabulary size should be small and contain only words of high-frequency in order to avoid problems caused by rare words. In other words, variety of composition should come from combining different frequent words instead of word diversity, as suggested in (Keysers et al., 2020). Metaphorical words, which can increase the translation difficulty, should be excluded. Second, source sentences should not be too long or have complex syntactic structures. As a result, a sentence can be\n1http://www.statmt.org/wmt17/\ntranslated literally, directly, and without rhetoric. Third, the corpus size should be large enough for training an NMT model sufficiently.\nWidely-adopted corpora such as parallel data released on WMT and IWSLT2 have large vocabularies and also contain noisy sentences and rich morphology (Li et al., 2019a), which do not fully meet our goal. We choose Story Cloze Test and ROCStories Corpora (Mostafazadeh et al., 2016, 2017) as our data source. The dataset is created for commonsense story understanding and generation, and consists of 101903 5-sentence stories. These stories are rather simple in items of vocabulary and syntax, but still contain rich phrases. In addition, the topic is constrained to daily life.\nSince the vocabulary size of 42, 458 is large, we select the top 2, 000 frequent words as our vocabulary and extract sentences where the words are exclusively from the restricted vocab. Moreover, sentences that are longer than 20 words are removed. In this way, we finally obtain 216, 246\n2https://wit3.fbk.eu/\nsentences for parallel data construction. More detailed statistics including comparison to WMT and IWSLT data are shown in Appendix B."
    }, {
      "heading" : "4.2 Parallel Data Construction",
      "text" : "We take an MT post-editing method to construct parallel data, first using a public translation engine to obtain model-generated translations, and then requesting expert translators to post-edit them. The following aspects are highlighted:\n• Ensure the fluency of translations.\n• Ensure word-level matching between translated sentences and source sentences. Typically, every word should be correctly translated, without omission for legibility.\nFinally, we obtain a parallel dataset of 216, 246 sentences in CoGnition, and randomly split it into three subsets: 196, 246 sentence pairs for training, 10, 000 sentence pairs for validation, and 10, 000 sentence pairs as the random test set. In addition\nto the above split, we additionally make a compositional generalization test set, which is described in the next section."
    }, {
      "heading" : "4.3 Compositional Generalization Test Set",
      "text" : "We manually construct a special test set dedicated for evaluation of compositional generalization, by synthesizing new source sentences based on novel compounds and known contexts.\nDesigning Compound Patterns We use Berkeley Parser to obtain constituent trees (Kitaev and Klein, 2018). In CoGnition, noun phrases (NP), verb phrases (VP) and positional phrases (PP) are three most frequent constituents, accounting for 85.1% of all constituents, and thus we construct compounds based on them. According to syntactic and semantic rules (Partee, 1995), we choose basic semantic components as our atoms including determiners (DET), nouns (N), verbs (V), prepositions (P), adjectives (ADJ), and postpositive modifiers (MOD). Specifically, postpositive modifiers include prepositional phrases and relative clauses, and can contain multiple words. We consider them as a single atom due to their semantic inseparability. In this way, we generate 4 compound patterns for NP, VP, and PP, respectively, which are listed in Table 3 with corresponding examples.\nMaking Novel Compounds We use Stanza (Qi et al., 2020) to obtain POS tagging for each word in training sentences. We construct novel compounds by first selecting atom candidates with relatively consistent translation in the training set. The frequency of candidate atoms covers a wide range from 34 to 73518. We list full set of atom candidates in Table 4. For constructing compounds, we enumerate all possible combinations of atoms according to the patterns in Table 3, and then remove those that are ungrammatical or likely to cause ethic issues, obtaining 2,160 compounds finally. We do not deliberately make all compounds unseen, yet only 0.93% of them appear in the training data.\nSynthesizing Source Sentences We embed the compounds in specific context to form complete source sentences. Concretely, we first apply Berkeley Parser on the training sentences to obtain sentence templates, where certain constituents are replaced by placeholders according to their constituent types, e.g., “NP-placeholder spent a lot of time to set up a wedding .”. Then we select 5\nsentence templates for each constructed compound accordingly, so that every compound can be evaluated under 5 different contexts. To distinguish from VP and PP, we put NP compounds only in sentences with the placeholder outside VP and PP.\nMaking Reference To maintain statistical consistency, target translations of synthetic sentences are also obtained using the same MT post-edit approach. In addition to the annotation principles listed in 4.2, we set several additional rules:\n• Filter sentences with ethical issues and replace them with other synthetic ones.\n• Ensure the accuracy of compound translation.\nFinally, we obtain a compositional generalization test set (CG test set) of 10, 800 parallel sentences. The final dataset statistics is shown in table 5."
    }, {
      "heading" : "4.4 Automatic Evaluation",
      "text" : "We mainly adopt human evaluation for the experiments of this paper (Section 5) for ensuring reliability of findings. Despite its accuracy, human evaluation can be expensive. To facilitate fast evaluation in future research, we introduce an automatic evaluation approach to quantify a model’s generalization ability on our CG test set.\nIn particular, we manually construct a dictionary for all the atoms based on the training set (See Appendix C). The prerequisite of correctly translating one compound is that all of the atom translations should be contained. Besides, in most cases the translation of nouns should be placed after that of other atoms. Based on this, we design a heuristic algorithm to determine whether compounds are translated correctly. With the human annotation as ground truth, our automatic evaluation tool achieves a precision of 94.80% and a recall of 87.05%, demonstrating it can serve as an approximate alternative to human evaluation."
    }, {
      "heading" : "5 Experiments",
      "text" : "We conduct experiments on CoGnition dataset and perform human evaluation on the model results."
    }, {
      "heading" : "5.1 Settings",
      "text" : "We tokenize the English side using Moses tokenizer and do not apply byte pair encoding (BPE) (Sennrich et al., 2016) due to the small vocabulary (i.e., 2000). The Chinese sentences are segmented by\njieba segmenter3. We employ BPE with 3,000 merge operations, generating a vocabulary of 5,500 subwords.\nWe focus on Transformer (Vaswani et al., 2017) because of its state-of-the-art performance on machine translation (Edunov et al., 2018b; Takase and Kiyono, 2021; Raffel et al., 2020; Zhu et al., 2020; Liu et al., 2020b) and better performance on existing compositional generalization dataset (Daniel et al., 2019). We implement our model using BASE configuration provided by Fairseq (Ott et al., 2019). The model consists of a 6-layer encoder and a 6-layer decoder with the hidden size 512. We tie input and output embeddings on the target side. The model parameters are optimized by Adam (Kingma and Ba, 2015), with 1 = 0.1, 2 = 0.98 and ✏ = 10 9. The model is trained for 100,000 steps and we choose the best checkpoint on validation set for evaluation.\nWe report character-level BLEU scores using SacreBLEU (Post, 2018) to measure the overall translation performance. In addition, we request expert translators to annotate the correctness of compound translation. Translators are asked to only focus on examining whether the compound itself is translated correctly or not, disregarding errors in context. Specifically, a compound is correct only if its translation contains semantic meaning of all atoms and is fluent in human language. Since each of the 2,160 compounds is provided with 5 contexts, we can compute the translation error-rate for each compound.\n3https://github.com/fxsjy/jieba"
    }, {
      "heading" : "5.2 Main Results",
      "text" : "Table 6 shows the results. Besides the CG test set, we also list results on three of its subsets, which only contain NP, VP or PP compounds respectively. The model achieves a 69.58 BLEU score on the random test set, which partly indicates distributional consistency and quality of the dataset. In comparison, the performance on the CG test set drops dramatically by more than 20 BLEU points. Given that the only difference between synthetic sentences and training sentences is the unseen compounds (i.e., contexts are seen in training), the decrease of 20 BLEU points indicates that unseen compounds pose a significant challenge, which is however easy to be overlooked in traditional evaluation metrics. For example, the model mis-translates “alas , he became sick from eating all of the peanut butter on the ball” into “ ÷‡:⇤âÜ⇤:⌦@ Ñ ± q ≈Ü” (English: alas , he became sick from eating all of the peanut butter on the field). With a minor mistake on the compound “on the ball”, the model achieves a sentence-level BLEU of 61.4, despite that the full sentence meaning is largely affected. In other words, the BLEU score of 69.58 can be misleading since novel compounds can be rare in the random test set. Such mistakes in generalizing new compounds can severely hinder overall performance of translation engines in practice, as shown earlier in Table 1. Also, we calculate BLEU for the original training sentences that provide contexts for the CG test set (row 3). The model achieves 99.74 BLEU, further demonstrating that the performance degradation is mainly caused by the unseen compounds.\nInstance-wise, 27.31% compounds are translated incorrectly. However, when aggregating all 5 contexts, 61.62% compounds suffer at least one incorrect translation. This suggests that a well-trained NMT model is not robust in translating compounds, though all atoms within them are highly frequent in\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\nZero-shot Few-shot Many-shot\nEr ro\nr R at\ne\nCompound Frequency\nFigure 2: Effect of compound frequency on compound translation error rate.\nthe training set. We also observe that the error rate of PP compounds, 37.72%, is much higher than the other two, 21.94% and 22.25%, which we will discuss in detail in the following section."
    }, {
      "heading" : "6 Analysis",
      "text" : "We conduct experiments to explore in what situations the model is error-prone by considering compound frequency, compound length, compound structure, atom frequency, atom co-occurrence, and the complexity of external context."
    }, {
      "heading" : "6.1 Compound Frequency",
      "text" : "Intuitively, compounds with higher frequencies in the training set are easier to infer. We classify compounds according to their frequency levels, including many-shots (frequency higher than 10), fewshots (frequency from 1 to 10) and zero-shot, and show the error rate for each bucket in Figure 2. The model translates all the many-shots compounds correctly. For few-shot compounds, translation error rate increases to 5.00%, but is still much lower than zero-shot compounds with an error rate of 27.53%. The result suggests the model is good at memorizing correspondence between sentence segments. However, the model deteriorates severely when test samples are unseen in the training set, which further confirms model’s weakness in compositional generalization (Lake and Baroni, 2018)."
    }, {
      "heading" : "6.2 Compound Length",
      "text" : "As shown in Figure 3, the error rate grows with the increase of compound length (i.e., the number of atoms in a compound). Only 4.50% of the shortest compounds are translated incorrectly, each of which consists of a determiner and a noun. The error rate increases to 13.72% when the compound length grows to 3 atoms (e.g., “the smart lawyer”). The longest compounds contain a determiner, a noun, an adjective, a modifier and a preposition or verb in each of them, e.g., “taking every special chair he liked”. The error rate increases to 36.63%, demonstrating that it is more difficult to generalize in longer compounds, which contain richer semantic information. We conjecture that if the range of compound is further expanded, the error rate will be much higher."
    }, {
      "heading" : "6.3 Atom Frequency",
      "text" : "We empirically divide compounds into multiple groups according to the minimum frequency of their atoms, where each group consists of similar numbers of compounds. The intuition is that the atom with low frequency might be difficult to translate and therefore hinders the whole compound translation. We fix the compound length to 3 in order to reduce effects of compound length.\nAs shown in Figure 4, the error rate has no strong\ncorrelation with the atom frequency. This can be because all atoms in our corpus are simple and relatively frequent and thus it is easy for the NMT model to memorize the semantics of most atoms. Therefore, simply increasing atom frequency does not enhance model’s generalization ability of novel compounds. We observe similar patterns for compounds of other lengths (Appendix A)."
    }, {
      "heading" : "6.4 Atom Co-occurrence",
      "text" : "Although the NMT model may never see a compound, there can exist many local segments where atoms co-occur. For example, in the unseen compound “the smart lawyer”, “smart” and “lawyer” may occur within some training sentences. Intuitively, the compounds of which atoms co-occur more frequently may be translated better. We calculate pointwise mutual information (PMI) and compare error rates of compounds with positive or negative mean PMI scores (MPMI):\nMPMI(C) = 1\nM\nN 1X\ni=1\nNX\nj=i+1\nPMI(ai, aj), (1)\nwhere ai is the i-th atom in the compound C, N is the compound length, M is the number of possible combinations of two atoms, and PMI score is computed as:\nPMI(x, y) = log p(ai, aj)\np(ai)p(aj) , (2)\nwhere the probabilities p(ai) and p(ai, aj) are obtained by dividing the number of n-grams in which one word or both words occur by the total number of n-grams4.\nWe divide compounds into 4 groups by their length and compare error rates within each group. As shown in Figure 5, across all groups, the error rates with positive mean PMI scores are lower than those with negative ones, verifying our hypotheses.\n4We use 5-gram here"
    }, {
      "heading" : "6.5 Linguistic Factors",
      "text" : "Figure 6 shows the error rates of all compound patterns in Table 3. The MOD atom exerts salient influence on translation error rate. The error rate of compounds with MOD is 19.78% higher than those without on average. In contrast, adding ADJ into compounds only increases error rate by 2.66%. The major difficulty caused by MOD is word reordering. One can translate “the small dog” monotonically without adjusting word order. However, compounds like “the dog he liked” require the model to recognize “he liked” as MOD and put its translation before that of “the dog” in Chinese. We find many cases where the model translates such compounds without reordering or breaking the connection between nouns and modifiers.\nAcross these groups, we can see that the error rate of NP (Pattern 1.*) is generally lower than that of VP (Pattern 2.*) and PP (Pattern 3.*). Such phenomenon is more obvious for the patterns without MOD. The reason is that compounds in Pattern 1.* are generally shorter and contain less semantic and syntactic information. However, the error rates of Pattern 2.3 and 2.4 are lower than other patterns with MOD (i.e., Pattern 1.3, 1.4, 3.3 and 3.4), indicating the model performs better in “V+DET(+ADJ)+NN+MOD”. This can be because under certain situations the MOD can be useful for correctly translating verbs, which are more commonly seen in the training set, e.g., “found the chair on the floor”.\nWe also observe that compounds of PP (Pattern 3.*) are more difficult to translate compared with VP (Pattern 2.*), although both types of compounds share the same compound length. In the training set, verbs typically have consistent translations, whereas the meanings of prepositions vary with contexts. Therefore prepositional compounds are more difficult to translate as more context infor-\nmation is required to ground their meanings."
    }, {
      "heading" : "6.6 Effect of External Context",
      "text" : "Due to the nature of NMT, the semantic representation of each compound is context-aware. Intuitively, translation of compounds is also influenced by external context, which is sentential in our case but can also be document-level in practice. We investigate effects of context lengths and sentence comprehension difficulty. In particular, the context length is calculated by subtracting the sentence length by the number of words in the compound. Comprehension difficulty of the training sentences which provide contexts, is quantified by the dependency distance (Liu, 2008): MMD(x) = 1N 1 PN i Di, where N is the number of words in the sentence and Di is the dependency distance of the i-th syntactic link of the sentence.\nThe results are shown in Figure 7. The translation error rate increases stably with the context length as well as the dependency distance. These observations demonstrate that the generalization for novel compounds correlates strongly with context complexity. Sentences with higher dependency distances are harder for model to comprehend during training. Given that our test sentences are restricted to 20 words, compositional generalization can be more challenging in practice where average sentence lengths can be much longer."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We proposed a dedicated parallel dataset for measuring compositional generalization of NMT and quantitatively analyzed a Transformer-based NMT model manually. Results show that the model exhibits poor performance on novel compound translation, which demonstrates that the NMT model suffers from fragile compositionality, and it can be easily overlooked under transitional metrics. To the best of our knowledge, we are the first one to\npropose a practical benchmark for compositionality of NMT, which can be a testbed for models tailored for this specific problem."
    }, {
      "heading" : "8 Ethics Consideration",
      "text" : "As mentioned, we collected our data from Story Cloze Test and ROCStories Corpora that all are public to academic use, and they contain no sensitive information (Mostafazadeh et al., 2016, 2017). The legal advisor of our institute confirms that the sources of our data are freely accessible online without copyright constraint to academic use. Our data construction involves manual annotation. Annotators were asked to post-edit machine translation and filter out samples that may cause ethic issues, which do not involve any personal sensitive information.\nWe hired 4 annotators who have degrees in English Linguistics or Applied Linguistics. Before formal annotation, annotators were asked to annotate 100 samples randomly extracted from the dataset, and based on average annotation time we set a fair salary (i.e., 32 dollars per hour) for them. During their training annotation process, they were paid as well."
    }, {
      "heading" : "Acknowledgment",
      "text" : "Yue Zhang is the corresponding author. We thank all reviewers for their insightful comments. This work is supported by National Natural Science Foundation of China (NSFC) under grant No.61976180 and a grant from Lan-bridge Information Technology Co., Ltd. We thank colleagues from Lan-bridge for examining data and evaluating results. Major contributors include Xianchao Zhu, Guohui Chen, Jing Yang, Jing Li, Feng Chen, Jun Deng and Jiaxiang Xiang."
    }, {
      "heading" : "A Atom Frequency",
      "text" : "For compounds of other lengths, we also compute their error rates with respect to minimum atom frequency. As shown in Figure 8, 9 and 10, the error rate does not correlates with atom frequency across all compound lengths.\n0.00\n0.02\n0.04\n0.06\n0.08\n0.10\n0.12\n0.14\n49 67 73 135 207 316 671 911 1066 1099 1992 2698\nEr ro\nr R at\ne\nAtom Frequency\nAtom Frequency\n34 59 61 71 79 84 89 91 174 183 188 189\nAtom Frequency\nFigure 10: Effect of atom frequency with compound length fixed to 5."
    }, {
      "heading" : "B Data Statistics",
      "text" : "Table 7 and Table 8 lists statistics of several monolingual data sources, compared with the data source (ROC-Filter) used in constructing the CoGnition dataset. We can see that our dataset has both shorter sentences and vocabulary made up of more frequent words."
    }, {
      "heading" : "C Lexicon",
      "text" : "Part of the lexicon for automatic evaluation is shown in Table 9."
    } ],
    "references" : [ {
      "title" : "Good-enough compositional data augmentation",
      "author" : [ "Jacob Andreas." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7556–7566, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Andreas.,? 2020",
      "shortCiteRegEx" : "Andreas.",
      "year" : 2020
    }, {
      "title" : "Jump to better conclusions: SCAN both left and right",
      "author" : [ "Jasmijn Bastings", "Marco Baroni", "Jason Weston", "Kyunghyun Cho", "Douwe Kiela." ],
      "venue" : "Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Net-",
      "citeRegEx" : "Bastings et al\\.,? 2018",
      "shortCiteRegEx" : "Bastings et al\\.",
      "year" : 2018
    }, {
      "title" : "Synthetic and natural noise both break neural machine translation",
      "author" : [ "Yonatan Belinkov", "Yonatan Bisk." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track",
      "citeRegEx" : "Belinkov and Bisk.,? 2018a",
      "shortCiteRegEx" : "Belinkov and Bisk.",
      "year" : 2018
    }, {
      "title" : "Synthetic and natural noise both break neural machine translation",
      "author" : [ "Yonatan Belinkov", "Yonatan Bisk." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track",
      "citeRegEx" : "Belinkov and Bisk.,? 2018b",
      "shortCiteRegEx" : "Belinkov and Bisk.",
      "year" : 2018
    }, {
      "title" : "Evaluating layers of representation in neural machine translation on part-of-speech and semantic tagging tasks",
      "author" : [ "Yonatan Belinkov", "Lluı́s Màrquez", "Hassan Sajjad", "Nadir Durrani", "Fahim Dalvi", "James Glass" ],
      "venue" : "In Proceedings of the Eighth In-",
      "citeRegEx" : "Belinkov et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Belinkov et al\\.",
      "year" : 2017
    }, {
      "title" : "Machine translation of restaurant reviews: New corpus for domain adaptation and robustness",
      "author" : [ "Alexandre Berard", "Ioan Calapodescu", "Marc Dymetman", "Claude Roux", "Jean-Luc Meunier", "Vassilina Nikoulina." ],
      "venue" : "Proceedings of the 3rd Workshop on",
      "citeRegEx" : "Berard et al\\.,? 2019",
      "shortCiteRegEx" : "Berard et al\\.",
      "year" : 2019
    }, {
      "title" : "The lazy encoder: A fine-grained analysis of the role of morphology in neural machine translation",
      "author" : [ "Arianna Bisazza", "Clara Tump." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2871–2876,",
      "citeRegEx" : "Bisazza and Tump.,? 2018",
      "shortCiteRegEx" : "Bisazza and Tump.",
      "year" : 2018
    }, {
      "title" : "Compositional generalization via neural-symbolic stack machines",
      "author" : [ "Xinyun Chen", "Chen Liang", "Adams Wei Yu", "Dawn Song", "Denny Zhou." ],
      "venue" : "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Pro-",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "Robust neural machine translation with doubly adversarial inputs",
      "author" : [ "Yong Cheng", "Lu Jiang", "Wolfgang Macherey." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4324–4333, Florence, Italy. Associa-",
      "citeRegEx" : "Cheng et al\\.,? 2019",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 2019
    }, {
      "title" : "Towards robust neural machine translation",
      "author" : [ "Yong Cheng", "Zhaopeng Tu", "Fandong Meng", "Junjie Zhai", "Yang Liu." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1756–",
      "citeRegEx" : "Cheng et al\\.,? 2018",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 2018
    }, {
      "title" : "Towards automating healthcare question answering in a noisy multilingual lowresource setting",
      "author" : [ "Jeanne E. Daniel", "Willie Brink", "Ryan Eloff", "Charles Copley." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Daniel et al\\.,? 2019",
      "shortCiteRegEx" : "Daniel et al\\.",
      "year" : 2019
    }, {
      "title" : "CNNs found to jump around more skillfully than RNNs: Compositional generalization in seq2seq convolutional networks",
      "author" : [ "Roberto Dessı", "Marco Baroni" ],
      "venue" : "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguis-",
      "citeRegEx" : "Dessı̀ and Baroni.,? \\Q2019\\E",
      "shortCiteRegEx" : "Dessı̀ and Baroni.",
      "year" : 2019
    }, {
      "title" : "Visualizing and understanding neural machine translation",
      "author" : [ "Yanzhuo Ding", "Yang Liu", "Huanbo Luan", "Maosong Sun." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1150–",
      "citeRegEx" : "Ding et al\\.,? 2017",
      "shortCiteRegEx" : "Ding et al\\.",
      "year" : 2017
    }, {
      "title" : "On adversarial examples for character-level neural machine translation",
      "author" : [ "Javid Ebrahimi", "Daniel Lowd", "Dejing Dou." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 653–663, Santa Fe, New Mexico, USA.",
      "citeRegEx" : "Ebrahimi et al\\.,? 2018",
      "shortCiteRegEx" : "Ebrahimi et al\\.",
      "year" : 2018
    }, {
      "title" : "Understanding back-translation at scale",
      "author" : [ "Sergey Edunov", "Myle Ott", "Michael Auli", "David Grangier." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 489–500, Brussels, Belgium. Association for",
      "citeRegEx" : "Edunov et al\\.,? 2018a",
      "shortCiteRegEx" : "Edunov et al\\.",
      "year" : 2018
    }, {
      "title" : "Understanding back-translation at scale",
      "author" : [ "Sergey Edunov", "Myle Ott", "Michael Auli", "David Grangier." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 489–500, Brussels, Belgium. Association for",
      "citeRegEx" : "Edunov et al\\.,? 2018b",
      "shortCiteRegEx" : "Edunov et al\\.",
      "year" : 2018
    }, {
      "title" : "The unreasonable volatility of neural machine translation models",
      "author" : [ "Marzieh Fadaee", "Christof Monz." ],
      "venue" : "Proceedings of the Fourth Workshop on Neural Generation and Translation, pages 88–96, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Fadaee and Monz.,? 2020a",
      "shortCiteRegEx" : "Fadaee and Monz.",
      "year" : 2020
    }, {
      "title" : "The unreasonable volatility of neural machine translation models",
      "author" : [ "Marzieh Fadaee", "Christof Monz." ],
      "venue" : "Proceedings of the Fourth Workshop on Neural Generation and Translation, pages 88–96, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Fadaee and Monz.,? 2020b",
      "shortCiteRegEx" : "Fadaee and Monz.",
      "year" : 2020
    }, {
      "title" : "Permutation equivariant models for compositional generalization in language",
      "author" : [ "Jonathan Gordon", "David Lopez-Paz", "Marco Baroni", "Diane Bouchacourt." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa,",
      "citeRegEx" : "Gordon et al\\.,? 2020",
      "shortCiteRegEx" : "Gordon et al\\.",
      "year" : 2020
    }, {
      "title" : "Achieving human parity on automatic chinese to english news translation",
      "author" : [ "Xu Tan", "Fei Tian", "Lijun Wu", "Shuangzhi Wu", "Yingce Xia", "Dongdong Zhang", "Zhirui Zhang", "Ming Zhou." ],
      "venue" : "CoRR, abs/1803.05567.",
      "citeRegEx" : "Tan et al\\.,? 2018",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2018
    }, {
      "title" : "Towards understanding neural machine translation with word importance",
      "author" : [ "Shilin He", "Zhaopeng Tu", "Xing Wang", "Longyue Wang", "Michael Lyu", "Shuming Shi." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "He et al\\.,? 2019",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2019
    }, {
      "title" : "Can you translate that into man? commercial machine translation systems include stylistic biases",
      "author" : [ "Dirk Hovy", "Federico Bianchi", "Tommaso Fornaciari." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Seattle,",
      "citeRegEx" : "Hovy et al\\.,? 2020",
      "shortCiteRegEx" : "Hovy et al\\.",
      "year" : 2020
    }, {
      "title" : "GQA: A new dataset for real-world visual reasoning and compositional question answering",
      "author" : [ "Drew A. Hudson", "Christopher D. Manning." ],
      "venue" : "IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-",
      "citeRegEx" : "Hudson and Manning.,? 2019",
      "shortCiteRegEx" : "Hudson and Manning.",
      "year" : 2019
    }, {
      "title" : "CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning",
      "author" : [ "Justin Johnson", "Bharath Hariharan", "Laurens van der Maaten", "Li Fei-Fei", "C. Lawrence Zitnick", "Ross B. Girshick." ],
      "venue" : "2017 IEEE Conference on Com-",
      "citeRegEx" : "Johnson et al\\.,? 2017a",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2017
    }, {
      "title" : "CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning",
      "author" : [ "Justin Johnson", "Bharath Hariharan", "Laurens van der Maaten", "Li Fei-Fei", "C. Lawrence Zitnick", "Ross B. Girshick." ],
      "venue" : "2017 IEEE Conference on Com-",
      "citeRegEx" : "Johnson et al\\.,? 2017b",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2017
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Constituency parsing with a self-attentive encoder",
      "author" : [ "Nikita Kitaev", "Dan Klein." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2676–2686, Melbourne, Australia. Associa-",
      "citeRegEx" : "Kitaev and Klein.,? 2018",
      "shortCiteRegEx" : "Kitaev and Klein.",
      "year" : 2018
    }, {
      "title" : "Compositional generalization through meta sequence-to-sequence learning",
      "author" : [ "Brenden M. Lake." ],
      "venue" : "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December",
      "citeRegEx" : "Lake.,? 2019",
      "shortCiteRegEx" : "Lake.",
      "year" : 2019
    }, {
      "title" : "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
      "author" : [ "Brenden M. Lake", "Marco Baroni." ],
      "venue" : "Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stock-",
      "citeRegEx" : "Lake and Baroni.,? 2018",
      "shortCiteRegEx" : "Lake and Baroni.",
      "year" : 2018
    }, {
      "title" : "The NiuTrans machine translation",
      "author" : [ "Bei Li", "Yinqiao Li", "Chen Xu", "Ye Lin", "Jiqiang Liu", "Hui Liu", "Ziyang Wang", "Yuhao Zhang", "Nuo Xu", "Zeyang Wang", "Kai Feng", "Hexuan Chen", "Tengbo Liu", "Yanyang Li", "Qiang Wang", "Tong Xiao", "Jingbo Zhu" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Compositional generalization for primitive substitutions",
      "author" : [ "Yuanpeng Li", "Liang Zhao", "Jianyu Wang", "Joel Hestness." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer-",
      "citeRegEx" : "Li et al\\.,? 2019b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Compositional generalization for primitive substitutions",
      "author" : [ "Yuanpeng Li", "Liang Zhao", "Jianyu Wang", "Joel Hestness." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer-",
      "citeRegEx" : "Li et al\\.,? 2019c",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Dependency distance as a metric of language comprehension difficulty",
      "author" : [ "Haitao Liu." ],
      "venue" : "Journal of Cognitive Science, 9(2):159–191.",
      "citeRegEx" : "Liu.,? 2008",
      "shortCiteRegEx" : "Liu.",
      "year" : 2008
    }, {
      "title" : "Very deep transformers for neural machine translation",
      "author" : [ "Xiaodong Liu", "Kevin Duh", "Liyuan Liu", "Jianfeng Gao." ],
      "venue" : "CoRR, abs/2008.07772.",
      "citeRegEx" : "Liu et al\\.,? 2020a",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Very deep transformers for neural machine translation",
      "author" : [ "Xiaodong Liu", "Kevin Duh", "Liyuan Liu", "Jianfeng Gao." ],
      "venue" : "CoRR, abs/2008.07772.",
      "citeRegEx" : "Liu et al\\.,? 2020b",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Rearranging the familiar: Testing compositional generalization in recurrent networks",
      "author" : [ "João Loula", "Marco Baroni", "Brenden Lake." ],
      "venue" : "Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for",
      "citeRegEx" : "Loula et al\\.,? 2018",
      "shortCiteRegEx" : "Loula et al\\.",
      "year" : 2018
    }, {
      "title" : "Are sixteen heads really better than one? In Advances in Neural Information Processing Systems",
      "author" : [ "Paul Michel", "Omer Levy", "Graham Neubig" ],
      "venue" : "Annual Conference on Neural Information Processing Systems",
      "citeRegEx" : "Michel et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Michel et al\\.",
      "year" : 2019
    }, {
      "title" : "MTNT: A testbed for machine translation of noisy text",
      "author" : [ "Paul Michel", "Graham Neubig." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 543– 553, Brussels, Belgium. Association for Computa-",
      "citeRegEx" : "Michel and Neubig.,? 2018",
      "shortCiteRegEx" : "Michel and Neubig.",
      "year" : 2018
    }, {
      "title" : "A corpus and cloze evaluation for deeper understanding of commonsense stories",
      "author" : [ "Nasrin Mostafazadeh", "Nathanael Chambers", "Xiaodong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen." ],
      "venue" : "Proceedings of the 2016",
      "citeRegEx" : "Mostafazadeh et al\\.,? 2016",
      "shortCiteRegEx" : "Mostafazadeh et al\\.",
      "year" : 2016
    }, {
      "title" : "LSDSem 2017 shared task: The story cloze test",
      "author" : [ "Nasrin Mostafazadeh", "Michael Roth", "Annie Louis", "Nathanael Chambers", "James Allen." ],
      "venue" : "Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Seman-",
      "citeRegEx" : "Mostafazadeh et al\\.,? 2017",
      "shortCiteRegEx" : "Mostafazadeh et al\\.",
      "year" : 2017
    }, {
      "title" : "Improving machine translation performance by exploiting non-parallel corpora",
      "author" : [ "Dragos Stefan Munteanu", "Daniel Marcu." ],
      "venue" : "Computational Linguistics, 31(4):477–504.",
      "citeRegEx" : "Munteanu and Marcu.,? 2005",
      "shortCiteRegEx" : "Munteanu and Marcu.",
      "year" : 2005
    }, {
      "title" : "fairseq: A fast, extensible toolkit for sequence modeling",
      "author" : [ "Myle Ott", "Sergey Edunov", "Alexei Baevski", "Angela Fan", "Sam Gross", "Nathan Ng", "David Grangier", "Michael Auli." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chap-",
      "citeRegEx" : "Ott et al\\.,? 2019",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2019
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia,",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Lexical semantics and compositionality",
      "author" : [ "Barbara Partee." ],
      "venue" : "An invitation to cognitive science: Language, 1:311–360.",
      "citeRegEx" : "Partee.,? 1995",
      "shortCiteRegEx" : "Partee.",
      "year" : 1995
    }, {
      "title" : "A call for clarity in reporting BLEU scores",
      "author" : [ "Matt Post." ],
      "venue" : "Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186– 191, Brussels, Belgium. Association for Computational Linguistics.",
      "citeRegEx" : "Post.,? 2018",
      "shortCiteRegEx" : "Post.",
      "year" : 2018
    }, {
      "title" : "Stanza: A python natural language processing toolkit for many human languages",
      "author" : [ "Peng Qi", "Yuhao Zhang", "Yuhui Zhang", "Jason Bolton", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Qi et al\\.,? 2020",
      "shortCiteRegEx" : "Qi et al\\.",
      "year" : 2020
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J. Liu." ],
      "venue" : "J. Mach. Learn. Res., 21:140:1–140:67.",
      "citeRegEx" : "Raffel et al\\.,? 2020",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2020
    }, {
      "title" : "On compositionality in neural machine translation",
      "author" : [ "Vikas Raunak", "Vaibhav Kumar", "Florian Metze." ],
      "venue" : "CoRR, abs/1911.01497.",
      "citeRegEx" : "Raunak et al\\.,? 2019",
      "shortCiteRegEx" : "Raunak et al\\.",
      "year" : 2019
    }, {
      "title" : "Compositional generalization in a deep seq2seq model by separating syntax and semantics. CoRR, abs/1904.09708",
      "author" : [ "Jake Russin", "Jason Jo", "Randall C. O’Reilly", "Yoshua Bengio" ],
      "venue" : null,
      "citeRegEx" : "Russin et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Russin et al\\.",
      "year" : 2019
    }, {
      "title" : "Compositional generalization in a deep seq2seq model by separating syntax and semantics. CoRR, abs/1904.09708",
      "author" : [ "Jake Russin", "Jason Jo", "Randall C. O’Reilly", "Yoshua Bengio" ],
      "venue" : null,
      "citeRegEx" : "Russin et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Russin et al\\.",
      "year" : 2019
    }, {
      "title" : "Analysing mathematical reasoning abilities of neural models",
      "author" : [ "David Saxton", "Edward Grefenstette", "Felix Hill", "Pushmeet Kohli." ],
      "venue" : "7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.",
      "citeRegEx" : "Saxton et al\\.,? 2019",
      "shortCiteRegEx" : "Saxton et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural machine translation of rare words with subword units",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715–",
      "citeRegEx" : "Sennrich et al\\.,? 2016",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2016
    }, {
      "title" : "Does string-based neural MT learn source syntax",
      "author" : [ "Xing Shi", "Inkit Padhi", "Kevin Knight" ],
      "venue" : "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Shi et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2016
    }, {
      "title" : "Lessons on parameter sharing across layers in transformers",
      "author" : [ "Sho Takase", "Shun Kiyono." ],
      "venue" : "CoRR, abs/2104.06022.",
      "citeRegEx" : "Takase and Kiyono.,? 2021",
      "shortCiteRegEx" : "Takase and Kiyono.",
      "year" : 2021
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "The bottom-up evolution of representations in the transformer: A study with machine translation and language modeling objectives",
      "author" : [ "Elena Voita", "Rico Sennrich", "Ivan Titov." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natu-",
      "citeRegEx" : "Voita et al\\.,? 2019a",
      "shortCiteRegEx" : "Voita et al\\.",
      "year" : 2019
    }, {
      "title" : "Analyzing multi-head self-attention: Specialized heads do the heavy lifting, the rest can be pruned",
      "author" : [ "Elena Voita", "David Talbot", "Fedor Moiseev", "Rico Sennrich", "Ivan Titov." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Com-",
      "citeRegEx" : "Voita et al\\.,? 2019b",
      "shortCiteRegEx" : "Voita et al\\.",
      "year" : 2019
    }, {
      "title" : "On the inference calibration of neural machine translation",
      "author" : [ "Shuo Wang", "Zhaopeng Tu", "Shuming Shi", "Yang Liu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3070–3079, Online. Association for",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Incorporating BERT into neural machine translation",
      "author" : [ "Jinhua Zhu", "Yingce Xia", "Lijun Wu", "Di He", "Tao Qin", "Wengang Zhou", "Houqiang Li", "Tie-Yan Liu." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa,",
      "citeRegEx" : "Zhu et al\\.,? 2020",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 54,
      "context" : "Neural machine translation (NMT) has shown competitive performance on benchmark datasets such as IWSLT and WMT (Vaswani et al., 2017; Edunov et al., 2018a; Liu et al., 2020a), and even achieves parity with professional human translation under certain evaluation settings (Hassan et al.",
      "startOffset" : 111,
      "endOffset" : 174
    }, {
      "referenceID" : 14,
      "context" : "Neural machine translation (NMT) has shown competitive performance on benchmark datasets such as IWSLT and WMT (Vaswani et al., 2017; Edunov et al., 2018a; Liu et al., 2020a), and even achieves parity with professional human translation under certain evaluation settings (Hassan et al.",
      "startOffset" : 111,
      "endOffset" : 174
    }, {
      "referenceID" : 33,
      "context" : "Neural machine translation (NMT) has shown competitive performance on benchmark datasets such as IWSLT and WMT (Vaswani et al., 2017; Edunov et al., 2018a; Liu et al., 2020a), and even achieves parity with professional human translation under certain evaluation settings (Hassan et al.",
      "startOffset" : 111,
      "endOffset" : 174
    }, {
      "referenceID" : 2,
      "context" : "In addition, NMT systems show poor robustness and vulnerability to input perturbations (Belinkov and Bisk, 2018a; Cheng et al., 2019).",
      "startOffset" : 87,
      "endOffset" : 133
    }, {
      "referenceID" : 8,
      "context" : "In addition, NMT systems show poor robustness and vulnerability to input perturbations (Belinkov and Bisk, 2018a; Cheng et al., 2019).",
      "startOffset" : 87,
      "endOffset" : 133
    }, {
      "referenceID" : 28,
      "context" : "produce a potentially infinite number of novel combinations of known components, namely compositional generalization (Chomsky; Montague; Lake and Baroni, 2018; Keysers et al., 2020), has been demonstrated deficient in many machine learning (ML) methods (Johnson et al.",
      "startOffset" : 117,
      "endOffset" : 181
    }, {
      "referenceID" : 23,
      "context" : ", 2020), has been demonstrated deficient in many machine learning (ML) methods (Johnson et al., 2017a; Lake and Baroni, 2018; Bastings et al., 2018; Loula et al., 2018; Russin et al., 2019a).",
      "startOffset" : 79,
      "endOffset" : 190
    }, {
      "referenceID" : 28,
      "context" : ", 2020), has been demonstrated deficient in many machine learning (ML) methods (Johnson et al., 2017a; Lake and Baroni, 2018; Bastings et al., 2018; Loula et al., 2018; Russin et al., 2019a).",
      "startOffset" : 79,
      "endOffset" : 190
    }, {
      "referenceID" : 1,
      "context" : ", 2020), has been demonstrated deficient in many machine learning (ML) methods (Johnson et al., 2017a; Lake and Baroni, 2018; Bastings et al., 2018; Loula et al., 2018; Russin et al., 2019a).",
      "startOffset" : 79,
      "endOffset" : 190
    }, {
      "referenceID" : 35,
      "context" : ", 2020), has been demonstrated deficient in many machine learning (ML) methods (Johnson et al., 2017a; Lake and Baroni, 2018; Bastings et al., 2018; Loula et al., 2018; Russin et al., 2019a).",
      "startOffset" : 79,
      "endOffset" : 190
    }, {
      "referenceID" : 28,
      "context" : ", 8 test sentences) for evaluation (Lake and Baroni, 2018; Li et al., 2019b; Chen et al., 2020), or make simple modifications in sampled source sentences such as removing or adding adverbs, and concatenating two sentences (Raunak et al.",
      "startOffset" : 35,
      "endOffset" : 95
    }, {
      "referenceID" : 30,
      "context" : ", 8 test sentences) for evaluation (Lake and Baroni, 2018; Li et al., 2019b; Chen et al., 2020), or make simple modifications in sampled source sentences such as removing or adding adverbs, and concatenating two sentences (Raunak et al.",
      "startOffset" : 35,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : ", 8 test sentences) for evaluation (Lake and Baroni, 2018; Li et al., 2019b; Chen et al., 2020), or make simple modifications in sampled source sentences such as removing or adding adverbs, and concatenating two sentences (Raunak et al.",
      "startOffset" : 35,
      "endOffset" : 95
    }, {
      "referenceID" : 47,
      "context" : ", 2020), or make simple modifications in sampled source sentences such as removing or adding adverbs, and concatenating two sentences (Raunak et al., 2019; Fadaee and Monz, 2020a).",
      "startOffset" : 134,
      "endOffset" : 179
    }, {
      "referenceID" : 16,
      "context" : ", 2020), or make simple modifications in sampled source sentences such as removing or adding adverbs, and concatenating two sentences (Raunak et al., 2019; Fadaee and Monz, 2020a).",
      "startOffset" : 134,
      "endOffset" : 179
    }, {
      "referenceID" : 42,
      "context" : "In addition to the standard training, validation and test sets, the CoGnition dataset contains a compositional generalization test set, which contains novel compounds in each sentence, so that both the generalization error rate can be evaluated, and its influence on BLEU (Papineni et al., 2002) can be quantified.",
      "startOffset" : 272,
      "endOffset" : 295
    }, {
      "referenceID" : 54,
      "context" : "Empirical results show that the dominant Transformer (Vaswani et al., 2017) NMT model faces challenges in translating novel compounds, despite its competitive performance under traditional evaluation metrics such as BLEU.",
      "startOffset" : 53,
      "endOffset" : 75
    }, {
      "referenceID" : 52,
      "context" : "There has been much linguistic analysis of NMT representations (Shi et al., 2016; Belinkov et al., 2017; Bisazza and Tump, 2018), interpretability (Ding et al.",
      "startOffset" : 63,
      "endOffset" : 128
    }, {
      "referenceID" : 4,
      "context" : "There has been much linguistic analysis of NMT representations (Shi et al., 2016; Belinkov et al., 2017; Bisazza and Tump, 2018), interpretability (Ding et al.",
      "startOffset" : 63,
      "endOffset" : 128
    }, {
      "referenceID" : 6,
      "context" : "There has been much linguistic analysis of NMT representations (Shi et al., 2016; Belinkov et al., 2017; Bisazza and Tump, 2018), interpretability (Ding et al.",
      "startOffset" : 63,
      "endOffset" : 128
    }, {
      "referenceID" : 12,
      "context" : ", 2017; Bisazza and Tump, 2018), interpretability (Ding et al., 2017; He et al., 2019; Voita et al., 2019a), and attention weights (Voita et al.",
      "startOffset" : 50,
      "endOffset" : 107
    }, {
      "referenceID" : 20,
      "context" : ", 2017; Bisazza and Tump, 2018), interpretability (Ding et al., 2017; He et al., 2019; Voita et al., 2019a), and attention weights (Voita et al.",
      "startOffset" : 50,
      "endOffset" : 107
    }, {
      "referenceID" : 55,
      "context" : ", 2017; Bisazza and Tump, 2018), interpretability (Ding et al., 2017; He et al., 2019; Voita et al., 2019a), and attention weights (Voita et al.",
      "startOffset" : 50,
      "endOffset" : 107
    }, {
      "referenceID" : 3,
      "context" : "Work has shown that NMT models are prone to be negatively affected by both synthetic and natural noise (Belinkov and Bisk, 2018b; Cheng et al., 2018; Ebrahimi et al., 2018).",
      "startOffset" : 103,
      "endOffset" : 172
    }, {
      "referenceID" : 9,
      "context" : "Work has shown that NMT models are prone to be negatively affected by both synthetic and natural noise (Belinkov and Bisk, 2018b; Cheng et al., 2018; Ebrahimi et al., 2018).",
      "startOffset" : 103,
      "endOffset" : 172
    }, {
      "referenceID" : 13,
      "context" : "Work has shown that NMT models are prone to be negatively affected by both synthetic and natural noise (Belinkov and Bisk, 2018b; Cheng et al., 2018; Ebrahimi et al., 2018).",
      "startOffset" : 103,
      "endOffset" : 172
    }, {
      "referenceID" : 28,
      "context" : "Neural networks have been shown sample-inefficient, requiring large-scale training data, which suggests that they may lack compositionality (Lake and Baroni, 2018).",
      "startOffset" : 140,
      "endOffset" : 163
    }, {
      "referenceID" : 24,
      "context" : "Various benchmarks have been proposed including in the area of visual reasoning (Johnson et al., 2017b; Hudson and Manning, 2019), mathematics (Saxton et al.",
      "startOffset" : 80,
      "endOffset" : 129
    }, {
      "referenceID" : 22,
      "context" : "Various benchmarks have been proposed including in the area of visual reasoning (Johnson et al., 2017b; Hudson and Manning, 2019), mathematics (Saxton et al.",
      "startOffset" : 80,
      "endOffset" : 129
    }, {
      "referenceID" : 50,
      "context" : ", 2017b; Hudson and Manning, 2019), mathematics (Saxton et al., 2019), and semantic parsing (CFQ) (Keysers et al.",
      "startOffset" : 48,
      "endOffset" : 69
    }, {
      "referenceID" : 43,
      "context" : "Therefore, we constrain compounds to syntactic constituents, and define atoms as basic semantic components in constituents according to syntactic and semantic rules for forming constituents (Partee, 1995).",
      "startOffset" : 190,
      "endOffset" : 204
    }, {
      "referenceID" : 54,
      "context" : "In particular, we train a Transformer-based model (Vaswani et al., 2017) on WMT17 En-Zh Dataset 1.",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 5,
      "context" : "Our goal is to focus on compositional generalization and minimize the influence of additional factors such as polysemy (Berard et al., 2019), misalignment (Munteanu and Marcu, 2005), and stylistic problems (Hovy et al.",
      "startOffset" : 119,
      "endOffset" : 140
    }, {
      "referenceID" : 40,
      "context" : ", 2019), misalignment (Munteanu and Marcu, 2005), and stylistic problems (Hovy et al.",
      "startOffset" : 22,
      "endOffset" : 48
    }, {
      "referenceID" : 21,
      "context" : ", 2019), misalignment (Munteanu and Marcu, 2005), and stylistic problems (Hovy et al., 2020).",
      "startOffset" : 73,
      "endOffset" : 92
    }, {
      "referenceID" : 26,
      "context" : "Designing Compound Patterns We use Berkeley Parser to obtain constituent trees (Kitaev and Klein, 2018).",
      "startOffset" : 79,
      "endOffset" : 103
    }, {
      "referenceID" : 43,
      "context" : "According to syntactic and semantic rules (Partee, 1995), we choose basic semantic components as our atoms including determiners (DET), nouns (N), verbs (V), prepositions (P), adjectives (ADJ), and postpositive modifiers (MOD).",
      "startOffset" : 42,
      "endOffset" : 56
    }, {
      "referenceID" : 45,
      "context" : "Making Novel Compounds We use Stanza (Qi et al., 2020) to obtain POS tagging for each word in training sentences.",
      "startOffset" : 37,
      "endOffset" : 54
    }, {
      "referenceID" : 51,
      "context" : "We tokenize the English side using Moses tokenizer and do not apply byte pair encoding (BPE) (Sennrich et al., 2016) due to the small vocabulary (i.",
      "startOffset" : 93,
      "endOffset" : 116
    }, {
      "referenceID" : 54,
      "context" : "We focus on Transformer (Vaswani et al., 2017) because of its state-of-the-art performance on machine translation (Edunov et al.",
      "startOffset" : 24,
      "endOffset" : 46
    }, {
      "referenceID" : 15,
      "context" : ", 2017) because of its state-of-the-art performance on machine translation (Edunov et al., 2018b; Takase and Kiyono, 2021; Raffel et al., 2020; Zhu et al., 2020; Liu et al., 2020b) and better performance on existing compositional generalization dataset (Daniel et al.",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 53,
      "context" : ", 2017) because of its state-of-the-art performance on machine translation (Edunov et al., 2018b; Takase and Kiyono, 2021; Raffel et al., 2020; Zhu et al., 2020; Liu et al., 2020b) and better performance on existing compositional generalization dataset (Daniel et al.",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 46,
      "context" : ", 2017) because of its state-of-the-art performance on machine translation (Edunov et al., 2018b; Takase and Kiyono, 2021; Raffel et al., 2020; Zhu et al., 2020; Liu et al., 2020b) and better performance on existing compositional generalization dataset (Daniel et al.",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 58,
      "context" : ", 2017) because of its state-of-the-art performance on machine translation (Edunov et al., 2018b; Takase and Kiyono, 2021; Raffel et al., 2020; Zhu et al., 2020; Liu et al., 2020b) and better performance on existing compositional generalization dataset (Daniel et al.",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 34,
      "context" : ", 2017) because of its state-of-the-art performance on machine translation (Edunov et al., 2018b; Takase and Kiyono, 2021; Raffel et al., 2020; Zhu et al., 2020; Liu et al., 2020b) and better performance on existing compositional generalization dataset (Daniel et al.",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 10,
      "context" : ", 2020b) and better performance on existing compositional generalization dataset (Daniel et al., 2019).",
      "startOffset" : 81,
      "endOffset" : 102
    }, {
      "referenceID" : 41,
      "context" : "We implement our model using BASE configuration provided by Fairseq (Ott et al., 2019).",
      "startOffset" : 68,
      "endOffset" : 86
    }, {
      "referenceID" : 25,
      "context" : "The model parameters are optimized by Adam (Kingma and Ba, 2015), with 1 = 0.",
      "startOffset" : 43,
      "endOffset" : 64
    }, {
      "referenceID" : 44,
      "context" : "We report character-level BLEU scores using SacreBLEU (Post, 2018) to measure the overall translation performance.",
      "startOffset" : 54,
      "endOffset" : 66
    }, {
      "referenceID" : 28,
      "context" : "However, the model deteriorates severely when test samples are unseen in the training set, which further confirms model’s weakness in compositional generalization (Lake and Baroni, 2018).",
      "startOffset" : 163,
      "endOffset" : 186
    }, {
      "referenceID" : 32,
      "context" : "Comprehension difficulty of the training sentences which provide contexts, is quantified by the dependency distance (Liu, 2008): MMD(x) = 1 N 1 PN i Di, where N is the number of words in the sentence and Di is the dependency distance of the i-th syntactic link of the sentence.",
      "startOffset" : 116,
      "endOffset" : 127
    } ],
    "year" : 2021,
    "abstractText" : "Modern neural machine translation (NMT) models have achieved competitive performance in standard benchmarks such as WMT. However, there still exist significant issues such as robustness, domain generalization, etc. In this paper, we study NMT models from the perspective of compositional generalization by building a benchmark dataset, CoGnition, consisting of 216k clean and consistent sentence pairs. We quantitatively analyze effects of various factors using compound translation error rate, then demonstrate that the NMT model fails badly on compositional generalization, although it performs remarkably well under traditional metrics.",
    "creator" : "预览"
  }
}