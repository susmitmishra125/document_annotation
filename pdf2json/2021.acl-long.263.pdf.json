{
  "name" : "2021.acl-long.263.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Structured Sentiment Analysis as Dependency Graph Parsing",
    "authors" : [ "Jeremy Barnes", "Robin Kurtz", "Stephan Oepen", "Lilja Øvrelid", "Erik Velldal" ],
    "emails" : [ "}@ifi.uio.no", "robin.kurtz@kb.se" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3387–3402\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3387"
    }, {
      "heading" : "1 Introduction",
      "text" : "Structured1 sentiment analysis, i.e., the task of predicting a structured sentiment graph like the ones in Figure 1, can be theoretically cast as an information extraction problem in which one attempts to find all of the opinion tuples O = Oi, . . . , On in a text. Each opinion Oi is a tuple (h, t, e, p) where h is a holder who expresses a polarity p towards a target t through a sentiment expression e, implicitly defining pairwise relationships between elements of the same tuple. Liu (2012) argues that all of these elements2 are essential to fully resolve the sentiment analysis problem.\n1We use the term ‘structured sentiment’ distinctly from Almars et al. (2017), who use it to refer to the latent hierarchical structure of sentiment aspects. We instead use ‘structured’ to refer to predicting sentiment graphs as a structured prediction task, as opposed to the many text classification task that are found in sentiment analysis.\n2Liu (2012)’s definition replaces sentiment expression with the time when the opinion was expressed.\nHowever, most research on sentiment analysis focuses either on a variety of sub-tasks, which avoids performing the full task, or on simplified and idealized tasks, e.g., sentence-level binary polarity classification.\nWe argue that the division of structured sentiment into these sub-tasks has become counterproductive, as reported experiments are often not sensitive to whether a given addition to the pipeline improves the overall resolution of sentiment, or do not take into account the inter-dependencies of the various sub-tasks. As such, we propose a unified approach to structured sentiment which jointly predicts all elements of an opinion tuple and their relations. Moreover, we cast sentiment analysis as a dependency graph parsing problem, where the sentiment expression is the root node, and the other elements have arcs which model the relationships between them. This methodology also enables us to take advantage of recent improvements in semantic dependency parsing (Dozat and Manning, 2018; Oepen et al., 2020; Kurtz et al., 2020) to efficiently learn a sentiment graph parser.\nThis perspective also allows us to unify a number of approaches, including targeted, and opinion tuple mining. We aim to answer RQ1: whether graph-based approaches to structured sentiment outperform state-of-the-art sequence labeling approaches, and RQ2: how to best encode structured sentiment as parsing graphs. We perform experiments on five standard datasets in four languages (English, Norwegian, Basque, Catalan) and show that graph-based approaches outperform state-ofthe-art baselines on all datasets on several standard metrics, as well as our proposed novel (unlabeled and labeled) sentiment graph metrics. We further propose methods to inject linguistic structure into the sentiment graphs using syntactic dependencies. Our main contributions are therefore 1) proposing a holistic approach to structured sentiment through\nsentiment graph parsing, 2) introducing new evaluation metrics for measuring model performance, and 3) extensive experimental results that outperform state-of-the-art baselines. Finally, we release the code and datasets3 to enable future work on this problem."
    }, {
      "heading" : "2 Related Work",
      "text" : "Structured sentiment analysis can be broken down into five sub-tasks: i) sentiment expression extraction, ii) sentiment target extraction, iii) sentiment holder extraction, iv) defining the relationship between these elements, and v) assigning polarity. Previous work on information extraction has used pipeline methods which first extract the holders, targets, and expressions (tasks i - iii) and subsequently predict their relations (task iv), mostly on the MPQA dataset (Wiebe et al., 2005). CRFs and a number of external resources (sentiment lexicons, dependency parsers, named-entity taggers) (Choi et al., 2006; Yang and Cardie, 2012) are strong baselines. Given the small size of the training data and the complicated task, these techniques often still outperform neural models, such as BiLSTMs (Katiyar and Cardie, 2016). Transition-based end-toend approaches have shown some potential (Zhang et al., 2019). However, all of this work ignores the polarity classification subtask.\nTargeted sentiment analysis only concentrates on extracting sentiment targets (task ii) and classifying the polarity directed towards them (task iv) (Jiang et al., 2011; Mitchell et al., 2013). Recent shared tasks on Aspect-Based Sentiment Analysis (ABSA) (Pontiki et al., 2014, 2015, 2016) also include target extraction and polarity classification subtasks. Joint approaches perform on par with pipeline methods (Li et al., 2019a) and multitask models can perform even better (He et al., 2019). Finally, pretrained language models (Devlin et al.,\n3Code and datasets available at https://github. com/jerbarnes/sentiment_graphs.\n2019) can also lead to improvements on the ABSA data (Li et al., 2019b).\nEnd2End sentiment analysis is a recently proposed subtask which combines targeted sentiment (tasks ii and v) and sentiment expression extraction (task i), without requiring the resolution of relationships between targets and expressions. Wang et al. (2016) augment the ABSA datasets with sentiment expressions, but provide no details on the annotation process or any inter-annotator agreement. He et al. (2019) make use of this data and propose a multi-layer CNN (IMN) to create hidden representations h which are then fed to a target and opinion extraction module (AE), which is also a multi-layer CNN. This module predicts ŷae, a sequence of BIO tags4 that predict the presence or absence of targets and expressions. After jointly predicting the targets and expressions, a second multi-layer CNN with a final self-attention network is used to classify the polarity, again as sequence labeling task (AS). This second module combines the information from h and ŷae by incorporating the predicted probability of a token to be a target in the formulation of self-attention. Finally, an iterative message-passing algorithm updates h using the predictions from all the modules at the previous timestep.\nChen and Qian (2020) instead propose RelationAware Collaborative Learning (RACL). This model creates task specific representations by first embedding a sentence, passing through a shared feed-forward network and finally a task-specific CNN. This approach then models interactions between each pair of sub-tasks (target extraction, expression extraction, sentiment classification) by creating pairwise weighted attention representations. These are then concatenated and used to create the task-specific predictions. The authors finally stack several RACL layers, using the output from the previous layer as input for the next.\n4The tags include {BIO}-{target,expression}\nBoth models perform well on the augmented SemEval data, but it is unlikely that these annotations are adequate for full structured sentiment, as Wang et al. (2016) only provide expression annotations for sentences that have targets, generally only include sentiment-bearing words (not phrases), and do not specify the relationship between target and expression.\nFinally, the recently proposed aspect sentiment triplet extraction (Peng et al., 2019; ?) attempts to extract targets, expressions and their polarity. However, the datasets used are unlikely to be adequate, as they augment available targeted datasets, but do not report annotation guidelines, procedure, or inter-annotator agreement.\nGraph parsing: Syntactic dependency graphs are regularly used in applications, supplying them with necessary grammatical information (Mintz et al., 2009; Cui et al., 2005; Björne et al., 2009; Johansson and Moschitti, 2012; Lapponi et al., 2012). The dependency graph structures used in these systems are predominantly restricted to trees. While trees are sufficient to encode syntactic dependencies, they are not expressive enough to handle meaning representations, that require nodes to have multiple incoming arcs, or having no incoming arcs at all (Kuhlmann and Oepen, 2016). While much of the early research on parsing these new structures (Oepen et al., 2014, 2015) focused on specialized decoding algorithms, Dozat and Manning (2018) presented a neural dependency parser that essentially relies only on its neural network structure to predict any type of dependency graph without restrictions to certain structures. Using the parser’s ability to learn arbitrary dependency graphs, Kurtz et al. (2020) phrased the task of negation resolution (Morante and Blanco, 2012; Morante and Daelemans, 2012) as a graph parsing task. This transformed the otherwise flat representations to dependency structures that directly encode the often overlapping relations between the building blocks of multiple negation instances at the same time. In a simpler fashion, Yu et al. (2020) exploit the parser of Dozat and Manning (2018) to predict spans of named entities."
    }, {
      "heading" : "3 Datasets",
      "text" : "We here focus on datasets that annotate the full task of structured sentiment as described initially. We perform experiments on five structured sentiment datasets in four languages, the statistics of which\nare shown in Table 1. The largest available structured sentiment dataset is the NoReCFine dataset (Øvrelid et al., 2020), a multi-domain dataset of professional reviews in Norwegian, annotated for structured sentiment. MultiBEU and MultiBCA (Barnes et al., 2018) are hotel reviews in Basque and Catalan, respectively. MPQA (Wiebe et al., 2005) annotates news wire text in English. Finally, DSUnis (Toprak et al., 2010) annotate English reviews of online universities and e-commerce. In our experiments, we use only the university reviews, as the e-commerce reviews have a large number of ‘polar targets’, i.e., targets with a polarity, but no accompanying sentiment expression.\nWhile all the datasets annotate holders, targets, and expressions, the frequency and distribution of these vary. Regarding holders, MPQA has the most (2,054) and DSUnis has the fewest (94), whereas NoReCFine has the largest proportion of targets (8,923) and expressions (11,115). The average length of holders (2.6 tokens) and targets (6.1 tokens) in MPQA is also considerably higher than the others.\nIt is also worth pointing out that MPQA and DSUnis additionally include neutral polarity. In the case of MPQA the neutral class refers to verbs which are subjective but do not convey polarity, e.g., ‘say’, ‘opt for’. In DSUnis, however, the neutral label tends to indicate expressions that could entail mixed polarity or are polar under the right conditions, e.g., ‘the classes were not easy’ is considered neutral, as it is possible for difficult classes to be desirable at a university. MultiBEU, and MultiBCA also have labels for strong positive and strong negative, which we map to positive and negative, respectively. Finally, NoReCFine includes intensity annotations (strong, normal, slight), which we disregard for the purposes of these experiments."
    }, {
      "heading" : "4 Modeling",
      "text" : "This section describes how we define and encode sentiment graphs, detail the neural dependency graph models, as well as two state-of-the-art baselines for end-to-end sentiment analysis (target and expression extraction, plus polarity classification)."
    }, {
      "heading" : "4.1 Graph Representations",
      "text" : "Structured sentiment graphs as in Figure 1 are directed graphs, that are made up of a set of labeled nodes and a set of unlabeled edges connecting pairs of nodes. Nodes in the structured sentiment graphs\ncan span over multiple tokens and may have multiple incoming edges. The resulting graphs can have multiple entry points (roots), are not necessarily connected, and not every token is a node in the graph. The sentence’s sentiment expressions correspond to the roots of the graphs, connecting explicitly to their respective holders and targets. In order to apply the algorithm of Dozat and Manning (2018), we simplify these structures into bi-lexical dependency graphs visualized in Figure 2. Here, nodes correspond one-to-one to the tokens of the sequence and follow the same linear order. The edges are drawn as arcs in the half-plane above the sentence, connecting heads to dependents. Similarly to the source structures, the graphs can have multiple roots and nodes can have multiple or no incoming arcs. For some rare instances of structured sentiment graphs, the reduction to dependency graphs is lossy, as they do not allow multiple arcs to share the same head and dependent. This results in a slight mismatch of the learned and aimed-for representations.\nThe choice of how to encode the sentiment graphs as parsing graphs opens for several alternate representations depending on the choice of head/dependent status of individual tokens in the target/holder/expression spans of the sentiment graph. We here propose two simple parsing graph representations: head-first and head-final, which\nare shown in Figure 2. For head-first, we set the first token of the sentiment expression as a root node, and similarly set the first token in each holder and token span as the head of the span with all other tokens within that span as dependents. The labels simply denote the type of relation (target/holder) and for sentiment expressions, additionally encode the polarity. Head-final is similar, but instead sets the final token of spans as the heads, and the final token of the sentiment expression as the root node."
    }, {
      "heading" : "4.2 Proposed model",
      "text" : "The neural graph parsing model used in this work is a reimplementation of the neural parser by Dozat and Manning (2018) which was used by Kurtz et al. (2020) for negation resolution. The parser learns to score each possible arc to then finally predict the output structure simply as a collection of all positively scored arcs. The base of the network structure is a bidirectional LSTM (BiLSTM), that processes the input sentence both from left-toright and right-to-left, to create contextualized representations c1, . . . , cn = BiLSTM(w1, . . . , wn) where wi is the concatenation of a word embedding, POS tag embedding, lemma embedding, and character embedding created by a character-based LSTM for the ith token. In our experiments, we further augment the token representations with pretrained contextualized embeddings from multilingual BERT (Xu et al., 2019). We use multilingual BERT as several languages did not have available monolingual BERT models at the time of the experiments (Catalan, Norwegian).\nThe contextualized embeddings are then processed by two feedforward neural networks (FNN), creating specialized representations for potential heads and dependents, hi = FNNhead(ci) and di = FNNdep(ci). The scores for each possible arclabel combination are computed by a final bilinear transformation using the tensor U . Its inner dimension corresponds to the number of sentiment graph labels plus a special NONE label, indicating the ab-\nsence of an arc, which allows the model to predict arcs and labels jointly, score(hi, dj) = h>i Udj ."
    }, {
      "heading" : "4.3 Baselines",
      "text" : "We compare our proposed graph prediction approach with three state-of-the-art baselines5 for extracting targets and expressions and predicting the polarity: IMN6, RACL7, as well as RACLBERT, which also incorporates contextualized embeddings. Instead of using BERTLarge, we use the cased BERT-multilingual-base in order to fairly compare with our own models. Note, however, that our model does not update the mBERT representations, putting it at a disadvantage to RACL-BERT. We also compare with previously reported extraction results from Barnes et al. (2018) and Øvrelid et al. (2020)."
    }, {
      "heading" : "5 Evaluation",
      "text" : "As we are interested not only in extraction or classification, but rather in the full structured sentiment task, we propose metrics that capture the relations between all predicted elements, while enabling comparison with previous state-of-the-art models on different subtasks. The main metrics we use to rank models are Targeted F1 and Sentiment Graph F1.\n5Despite having state-of-the-art results on MPQA, we do not compare with Katiyar and Cardie (2016) as they use different dataset splits, 10-fold cross-validation, and their code is not available.\n6IMN code available at https://github.com/ ruidan/IMN-E2E-ABSA.\n7https://github.com/NLPWM-WHU/RACL.\nToken-level F1 for Holders, Targets, and Expressions To easily compare our models to pipeline models, we evaluate how well these models are able to identify the elements of a sentiment graph with token-level F1.\nTargeted F1 This is a common metric in targeted sentiment analysis (also referred to as F1-i (He et al., 2019) or ABSA F1 (Chen and Qian, 2020)). A true positive requires the combination of exact extraction of the sentiment target, and the correct polarity.\nParsing graph metrics We additionally compute graph-level metrics to determine how well the models predict the unlabeled and labeled arcs of the parsing graphs: Unlabeled F1 (UF1), Labeled F1 (LF1). These measure the amount of (in)correctly predicted arcs and labels, as the harmonic mean of precision and recall (Oepen et al., 2014). These\nmetrics inform us of the local properties of the graph, and do not overly penalize a model if a few edges of a graph are incorrect.\nSentiment graph metrics The two metrics that measure how well a model is able to capture the full sentiment graph (see Figure 1) are Non-polar Sentiment Graph F1 (NSF1) and Sentiment Graph F1 (SF1). For NSF1, each sentiment graph is a tuple of (holder, target, expression), while for SF1 we include polarity (holder, target, expression, polarity). A true positive is defined as an exact match at graph-level, weighting the overlap in predicted and gold spans for each element, averaged across all three spans. For precision we weight the number of correctly predicted tokens divided by the total number of predicted tokens (for recall, we divide instead by the number of gold tokens). We allow for empty holders and targets."
    }, {
      "heading" : "6 Experiments",
      "text" : "All sentiment graph models use token-level mBERT representations in addition to word2vec skip-gram embeddings openly available from the NLPL vector repository8 (Fares et al., 2017). We train all models for 100 epochs and keep the model that performs best regarding LF1 on the dev set (Targeted F1 for the baselines). We use default hyperparameters from Kurtz et al. (2020) (see Appendix) and run all of our models five times with different random seeds and report the mean (standard deviation shown as well in Table 8 in the Appendix). We calculate statistical difference between the best and second best models through a bootstrap with replacement test (Berg-Kirkpatrick et al., 2012). As there are 5 runs, we require that 3 of 5 be statistically significant at p < 0.05. Table 3 shows the results for all datasets.\nOn NoReCFine, the baselines IMN, RACL, and RACL-BERT perform well at extracting targets (35.9, 45.6, and 47.2 F1, respectively) and expressions (48.7/55.4/56.3), but struggle with the full targeted sentiment task (18.0/20.1/30.3). The graphbased models extract targets better (50.1/54.8) and have comparable scores for expressions (54.4/55.5). The holder extraction scores have a similar range (51.1/60.4). These patterns hold throughout the other datasets, where the proposed graph models nearly always perform best on extracting spans, although RACL-BERT achieves the best score on extracting targets on DSUnis (44.6 vs. 42.1). The graph models also outperform the strongest baseline (RACL-BERT) on targeted sentiment on all 5 datasets, although this difference is often not statistically significant (NoReCFine Head-first, MultiBEU Head-final) and RACL-BERT is better than Head-first on DSUnis.\nRegarding the Graph metrics, the results depend highly on the dataset, with UF1 and LF1 ranging from 35.3/31.4 (DSUnis Head-first) to 66.8/62.1 (MultiBCA Head-first). Sentiment Graph metrics NSF1 and SF1 have a similar, though slightly lower range (24.5/17.7 – 62.0/56.8). The graph and sentiment graph metrics do not correlate perfectly, however, as UF1 and LF1 on MPQA are relatively good\n8Nordic Language Processing Laboratory vector repo.: http://vectors.nlpl.eu/repository/. We used 300-dimensional embeddings trained on English Wikipedia and Gigaword for English (model id 18 in the repo.), and 100- dimensional embeddings trained on the 2017 CoNLL corpora for all others; Basque (id 32), Catalan (id 34), and Norwegian Bokmål (id 58).\n(40.0/36.9 and 41.4/38.0 for Head-first and Headfinal, respectively), but the NSF1 and SF1 are poor (24.5/17.4 and 26.1/18.8).\nOn average IMN is the weakest baseline, followed by RACL and then RACL-BERT. The main improvement that RACL-BERT gives over RACL on these datasets is seen in the Targeted metric, i.e., the contextualized representations improve the polarity classification more than the extraction task. The proposed graph-based models are consistently the best models across the metrics and datasets.\nRegarding graph representations, the differences between Head-first and Head-final are generally quite small. Head-first performs better on MultiBCA and slightly better on MultiBEU, while for the others (NoReCFine, MPQA, and DSUnis) Head-final is better. This suggests that the main benefit is the joint prediction of all spans and relationships, and that the specific graph representation matters less."
    }, {
      "heading" : "7 Analysis",
      "text" : "In this section we perform a deeper analysis of the models in order to answer the research questions."
    }, {
      "heading" : "7.1 Do syntactically informed sentiment graphs improve results?",
      "text" : "Our two baseline graph representations, Head-first and Head-final, are crude approximations of linguistic structure. In syntactic and semantic dependency graphs, heads are often neither the first or last word, but rather the most salient word according to various linguistic criteria. First, we enrich the dependency labels to distinguish edges that are internal to a holder/target/expression span from those that are external and perform experiments by adding an ‘in label’ to non-head nodes within the graph, which we call +inlabel. We further inform the head selection of the parsing graphs with syntactic information in the Dep. edges parsing\ngraphs, where we compute the dependency graph for each sentence9 and set the head of each span to be the node that has an outgoing edge in the corresponding syntactic graph. As there can be more than one such edge, we default to the first. A manual inspection showed that this approach sometimes set unlikely dependency label types as heads, e.g., punct, obl. Therefore, we suggest a final approach, Dep. labels, which filters out these unlikely heads. The full results are shown in Table 8 in the Appendix. The implementation of the graph structure has a large effect on all metrics, although the specific results depend on the dataset. We plot the average effect of each implementation across all datasets in Figure 3, as well as each individual dataset (Figures 4–8 in the Appendix). +inlabel tends to improve results on the non-English datasets, consistently increasing target and expression extraction and targeted sentiment. It also generally improves the graph scores UF1 and LF1 on the non-English datasets.\n9We use SpaCy (Honnibal et al., 2020) for English, Stanza (Qi et al., 2020) for Basque and Catalan and UDPipe (Straka and Straková, 2017) for Norwegian.\nDep. edges has the strongest positive effect on the NSF1 and SF1 (an avg. 2.52 and 2.22 percentage point (pp) over Head-final, respectively). However, this average is pulled down by poorer performance on the English datasets. Removing these two, the average benefit is 5.2 and 4.2 for NSF1 and SF1, respectively. On span extraction and targeted sentiment, however, Dep. edges leads to poorer scores overall. Dep. labels does not lead to any consistent improvements. These results indicate that incorporating syntactic dependency information is particularly helpful for the full structured sentiment task, but that these benefits do not always show at a more local level, i.e., span extraction."
    }, {
      "heading" : "7.2 Do graph models perform better on sentences with multiple targets?",
      "text" : "We hypothesize that predicting the full sentiment graph may have a larger effect on sentences with multiple targets. Therefore, we create a subset of the test data containing sentences with multiple targets and reevaluate Head-first, Head-final, and RACL-BERT on the target extraction task. Table 4 shows the number of sentences with multiple targets and the Target span extraction score for each model. On this subset, Head-first and Head-final outperform RACL-BERT on 9 of 10 experiments, confirming the hypothesis that the graph models improve on examples with multiple targets."
    }, {
      "heading" : "7.3 How much does mBERT contribute?",
      "text" : "We also perform experiments without mBERT (shown in Table 7 in the Appendix) and show the average gains (over all 6 graph setups) of including it in Table 5. Adding the mBERT features leads to average improvements in all experiments: for extracting spans an average gain of 4.1 pp for holders, 3.4 for targets, and 3.1 for expressions. For targeted sentiment there is a larger gain of 4.2 pp, while for the parsing graph metrics UF1 and lF1 the gains are more limited (3.3 pp/ 3.8 pp) and similarly for NSF1 and SF1 (3.6 pp/ 3.9 pp). The gains are\nlargest for the English datasets (MPQA, DSUnis) followed by NoReCFine, and finally MultiBCA and MultiBEU. This corroborates the bias towards English and similar languages that has been found in multilingual language models (Artetxe et al., 2020; Conneau et al., 2020) and motivates the need for language-specific contextualized embeddings."
    }, {
      "heading" : "7.4 Analysis of polarity predictions",
      "text" : "In this section we zoom in on polarity, in order to quantify how well models perform at predicting only polarity. As the polarity annotations are bound to the expressions, we consider true positives to be any expression that overlaps the gold expression and has the same polarity. Table 6 shows that the polarity predictions are best on and MultiBCA, followed by NoReCFine and DSUnis, and finally MPQA. This is likely due to the number of domains and characteristics of the data. NoReCFine contains many domains and has longer expressions, while MPQA contains many highly ambiguous polar expressions, e.g., ‘said’, ‘asked’, which have different polarity depending on the context."
    }, {
      "heading" : "8 Conclusion",
      "text" : "In this paper, we have proposed a dependency graph parsing approach to structured sentiment analysis and shown that these models outperform state-of-the-art sequence labeling models on five benchmark datasets.\nUsing parse trees as input has shown promise for sentiment analysis in the past, either to guide a tree-based algorithm (Socher et al., 2013; Tai et al., 2015) or to create features for sentiment models (Nakagawa et al., 2010; Almeida et al., 2015). However, to the authors’ knowledge, this is the first attempt to directly predict dependencybased sentiment graphs.\nIn the future, we would like to better exploit the similarities between dependency parsing and\nsentiment graph parsing, either by augmenting the token-level representations with contextualized vectors from their heads in a dependency tree (Kurtz et al., 2020) or by multi-task learning to dependency parse. We would also like to explore different graph parsing approaches, e.g., PERIN (Samuel and Straka, 2020)."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work has been carried out as part of the SANT project (Sentiment Analysis for Norwegian Text), funded by the Research Council of Norway (grant number 270908).\nThe computations were performed on resources provided by UNINETT Sigma2 - the National Infrastructure for High Performance Computing and Data Storage in Norway."
    }, {
      "heading" : "A Appendix",
      "text" : "GPU Infrastructure NVIDIA P100, 16 GiB RAM CPU Infrastructure Intel Xeon-Gold 6138 2.0 GHz Training duration 00:31:43 (MultiBEU) – 07:40:54 (NoReCFine) Model implementation https://github.com/jerbarnes/sentiment_graphs/src Hyperparameter Best assignment embedding Word2Vec SkipGram 100D contexualized embedding mBERT embeddings trainable False number of epochs 100 batch size 50 beta1 0 beta2 0.95 l2 3e-09 hidden lstm 200 hidden char lstm 100 layers lstm 3 dim mlp 200 dim embedding 100 dim char embedding 80 early stopping 0 pos style xpos attention bilinear model interpolation 0.5 loss interpolation 0.025 lstm implementation drop connect char implementation convolved emb dropout type replace bridge dpa+ dropout embedding 0.2 dropout edge 0.2 dropout label 0.3 dropout main recurrent 0.2 dropout recurrent char 0.3 dropout main ff 0.4 dropout char ff 0.3 dropout char linear 0.3"
    } ],
    "references" : [ {
      "title" : "Structured sentiment analysis",
      "author" : [ "Abdulqader Almars", "Xue Li", "Xin Zhao", "Ibrahim A. Ibrahim", "Weiwei Yuan", "Bohan Li." ],
      "venue" : "Advanced Data Mining and Applications, pages 695–707, Cham. Springer International Publishing.",
      "citeRegEx" : "Almars et al\\.,? 2017",
      "shortCiteRegEx" : "Almars et al\\.",
      "year" : 2017
    }, {
      "title" : "Aligning opinions: Cross-lingual opinion mining with dependencies",
      "author" : [ "Mariana S.C. Almeida", "Cláudia Pinto", "Helena Figueira", "Pedro Mendes", "André F.T. Martins." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational",
      "citeRegEx" : "Almeida et al\\.,? 2015",
      "shortCiteRegEx" : "Almeida et al\\.",
      "year" : 2015
    }, {
      "title" : "On the cross-lingual transferability of monolingual representations",
      "author" : [ "Mikel Artetxe", "Sebastian Ruder", "Dani Yogatama." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4623–4637, Online. Asso-",
      "citeRegEx" : "Artetxe et al\\.,? 2020",
      "shortCiteRegEx" : "Artetxe et al\\.",
      "year" : 2020
    }, {
      "title" : "MultiBooked: A corpus of basque and Catalan hotel reviews annotated for aspect-level sentiment classification",
      "author" : [ "Jeremy Barnes", "Toni Badia", "Patrik Lambert." ],
      "venue" : "Proceedings of the Eleventh International Conference on Language Resources and Eval-",
      "citeRegEx" : "Barnes et al\\.,? 2018",
      "shortCiteRegEx" : "Barnes et al\\.",
      "year" : 2018
    }, {
      "title" : "An Empirical Investigation of Statistical Significance in NLP",
      "author" : [ "Taylor Berg-Kirkpatrick", "David Burkett", "Dan Klein." ],
      "venue" : "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Nat-",
      "citeRegEx" : "Berg.Kirkpatrick et al\\.,? 2012",
      "shortCiteRegEx" : "Berg.Kirkpatrick et al\\.",
      "year" : 2012
    }, {
      "title" : "Extracting Complex Biological Events with Rich Graph-based Feature Sets",
      "author" : [ "Jari Björne", "Juho Heimonen", "Filip Ginter", "Antti Airola", "Tapio Pahikkala", "Tapio Salakoski." ],
      "venue" : "Proceedings of the Workshop on Current Trends in Biomedical Natural",
      "citeRegEx" : "Björne et al\\.,? 2009",
      "shortCiteRegEx" : "Björne et al\\.",
      "year" : 2009
    }, {
      "title" : "Relation-aware collaborative learning for unified aspect-based sentiment analysis",
      "author" : [ "Zhuang Chen", "Tieyun Qian." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3685–3694, Online. Association for",
      "citeRegEx" : "Chen and Qian.,? 2020",
      "shortCiteRegEx" : "Chen and Qian.",
      "year" : 2020
    }, {
      "title" : "Joint extraction of entities and relations for opinion recognition",
      "author" : [ "Yejin Choi", "Eric Breck", "Claire Cardie." ],
      "venue" : "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 431–439, Sydney, Australia. Association for",
      "citeRegEx" : "Choi et al\\.,? 2006",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2006
    }, {
      "title" : "Unsupervised cross-lingual representation learning at scale",
      "author" : [ "Alexis Conneau", "Kartikay Khandelwal", "Naman Goyal", "Vishrav Chaudhary", "Guillaume Wenzek", "Francisco Guzmán", "Edouard Grave", "Myle Ott", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "In",
      "citeRegEx" : "Conneau et al\\.,? 2020",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2020
    }, {
      "title" : "Question answering passage retrieval using dependency relations",
      "author" : [ "Hang Cui", "Renxu Sun", "Keya Li", "Min-Yen Kan", "TatSeng Chua." ],
      "venue" : "Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Informa-",
      "citeRegEx" : "Cui et al\\.,? 2005",
      "shortCiteRegEx" : "Cui et al\\.",
      "year" : 2005
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Simpler but more accurate semantic dependency parsing",
      "author" : [ "Timothy Dozat", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 484–490, Mel-",
      "citeRegEx" : "Dozat and Manning.,? 2018",
      "shortCiteRegEx" : "Dozat and Manning.",
      "year" : 2018
    }, {
      "title" : "Word vectors, reuse, and replicability: Towards a community repository of large-text resources",
      "author" : [ "Murhaf Fares", "Andrey Kutuzov", "Stephan Oepen", "Erik Velldal." ],
      "venue" : "Proceedings of the 21st Nordic Conference on Computational Linguistics, pages 271–",
      "citeRegEx" : "Fares et al\\.,? 2017",
      "shortCiteRegEx" : "Fares et al\\.",
      "year" : 2017
    }, {
      "title" : "An interactive multi-task learning network for end-to-end aspect-based sentiment analysis",
      "author" : [ "Ruidan He", "Wee Sun Lee", "Hwee Tou Ng", "Daniel Dahlmeier." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguis-",
      "citeRegEx" : "He et al\\.,? 2019",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2019
    }, {
      "title" : "spaCy: Industrial-strength Natural Language Processing in Python",
      "author" : [ "Matthew Honnibal", "Ines Montani", "Sofie Van Landeghem", "Adriane Boyd" ],
      "venue" : null,
      "citeRegEx" : "Honnibal et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Honnibal et al\\.",
      "year" : 2020
    }, {
      "title" : "Target-dependent twitter sentiment classification",
      "author" : [ "Long Jiang", "Mo Yu", "Ming Zhou", "Xiaohua Liu", "Tiejun Zhao." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages",
      "citeRegEx" : "Jiang et al\\.,? 2011",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2011
    }, {
      "title" : "Relational Features in Fine-Grained Opinion Analysis",
      "author" : [ "Richard Johansson", "Alessandro Moschitti." ],
      "venue" : "Computational Linguistics, 39(3):473–509.",
      "citeRegEx" : "Johansson and Moschitti.,? 2012",
      "shortCiteRegEx" : "Johansson and Moschitti.",
      "year" : 2012
    }, {
      "title" : "Investigating LSTMs for joint extraction of opinion entities and relations",
      "author" : [ "Arzoo Katiyar", "Claire Cardie." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 919–929, Berlin,",
      "citeRegEx" : "Katiyar and Cardie.,? 2016",
      "shortCiteRegEx" : "Katiyar and Cardie.",
      "year" : 2016
    }, {
      "title" : "Towards a Catalogue of Linguistic Graph Banks",
      "author" : [ "Marco Kuhlmann", "Stephan Oepen." ],
      "venue" : "Computational Linguistics, 42(4):819–827.",
      "citeRegEx" : "Kuhlmann and Oepen.,? 2016",
      "shortCiteRegEx" : "Kuhlmann and Oepen.",
      "year" : 2016
    }, {
      "title" : "End-to-end negation resolution as graph parsing",
      "author" : [ "Robin Kurtz", "Stephan Oepen", "Marco Kuhlmann." ],
      "venue" : "Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal De-",
      "citeRegEx" : "Kurtz et al\\.,? 2020",
      "shortCiteRegEx" : "Kurtz et al\\.",
      "year" : 2020
    }, {
      "title" : "UiO2: Sequence-labeling Negation Using Dependency Features",
      "author" : [ "Emanuele Lapponi", "Erik Velldal", "Lilja Øvrelid", "Jonathon Read." ],
      "venue" : "Proceedings of the First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings",
      "citeRegEx" : "Lapponi et al\\.,? 2012",
      "shortCiteRegEx" : "Lapponi et al\\.",
      "year" : 2012
    }, {
      "title" : "A unified model for opinion target extraction and target sentiment prediction",
      "author" : [ "Xin Li", "Lidong Bing", "Piji Li", "Wai Lam." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, pages 6714– 6721.",
      "citeRegEx" : "Li et al\\.,? 2019a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploiting BERT for end-to-end aspectbased sentiment analysis",
      "author" : [ "Xin Li", "Lidong Bing", "Wenxuan Zhang", "Wai Lam." ],
      "venue" : "Proceedings of the 5th",
      "citeRegEx" : "Li et al\\.,? 2019b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Association for Computational Linguistics",
      "author" : [ "Hong Kong", "China" ],
      "venue" : "Workshop on Noisy User-generated Text (W-NUT",
      "citeRegEx" : "Kong and China.,? \\Q2019\\E",
      "shortCiteRegEx" : "Kong and China.",
      "year" : 2019
    }, {
      "title" : "Sentiment Analysis and Opinion Mining",
      "author" : [ "Bing Liu." ],
      "venue" : "Morgan & Claypool Publishers.",
      "citeRegEx" : "Liu.,? 2012",
      "shortCiteRegEx" : "Liu.",
      "year" : 2012
    }, {
      "title" : "Distant supervision for relation extraction without labeled data",
      "author" : [ "Mike Mintz", "Steven Bills", "Rion Snow", "Daniel Jurafsky." ],
      "venue" : "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference",
      "citeRegEx" : "Mintz et al\\.,? 2009",
      "shortCiteRegEx" : "Mintz et al\\.",
      "year" : 2009
    }, {
      "title" : "Open domain targeted sentiment",
      "author" : [ "Margaret Mitchell", "Jacqui Aguilar", "Theresa Wilson", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1643–1654, Seattle, Washington,",
      "citeRegEx" : "Mitchell et al\\.,? 2013",
      "shortCiteRegEx" : "Mitchell et al\\.",
      "year" : 2013
    }, {
      "title" : "SEM 2012 Shared Task: Resolving the Scope and Focus of Negation",
      "author" : [ "Roser Morante", "Eduardo Blanco." ],
      "venue" : "*SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the Main Conference and the",
      "citeRegEx" : "Morante and Blanco.,? 2012",
      "shortCiteRegEx" : "Morante and Blanco.",
      "year" : 2012
    }, {
      "title" : "ConanDoyle-neg: Annotation of negation cues and their scope in Conan Doyle stories",
      "author" : [ "Roser Morante", "Walter Daelemans." ],
      "venue" : "Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC’12),",
      "citeRegEx" : "Morante and Daelemans.,? 2012",
      "shortCiteRegEx" : "Morante and Daelemans.",
      "year" : 2012
    }, {
      "title" : "Dependency tree-based sentiment classification using CRFs with hidden variables",
      "author" : [ "Tetsuji Nakagawa", "Kentaro Inui", "Sadao Kurohashi." ],
      "venue" : "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Associa-",
      "citeRegEx" : "Nakagawa et al\\.,? 2010",
      "shortCiteRegEx" : "Nakagawa et al\\.",
      "year" : 2010
    }, {
      "title" : "MRP 2020: The Second Shared Task on Cross-Framework and Cross-Lingual Meaning Rep",
      "author" : [ "Stephan Oepen", "Omri Abend", "Lasha Abzianidze", "Johan Bos", "Jan Hajic", "Daniel Hershcovich", "Bin Li", "Tim O’Gorman", "Nianwen Xue", "Daniel Zeman" ],
      "venue" : null,
      "citeRegEx" : "Oepen et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2020
    }, {
      "title" : "Broad-Coverage Semantic Dependency",
      "author" : [ "Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Silvie Cinkova", "Dan Flickinger", "Jan Hajic", "Zdenka Uresova" ],
      "venue" : "SemEval",
      "citeRegEx" : "Oepen et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2015
    }, {
      "title" : "SemEval 2014 Task 8: Broad-Coverage Semantic Dependency Parsing",
      "author" : [ "Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Dan Flickinger", "Jan Hajic", "Angelina Ivanova", "Yi Zhang." ],
      "venue" : "Proceedings of the 8th International Workshop on",
      "citeRegEx" : "Oepen et al\\.,? 2014",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2014
    }, {
      "title" : "A fine-grained sentiment dataset for Norwegian",
      "author" : [ "Lilja Øvrelid", "Petter Mæhlum", "Jeremy Barnes", "Erik Velldal." ],
      "venue" : "Proceedings of the 12th Language Resources and Evaluation Conference, pages 5025– 5033, Marseille, France. European Language Re-",
      "citeRegEx" : "Øvrelid et al\\.,? 2020",
      "shortCiteRegEx" : "Øvrelid et al\\.",
      "year" : 2020
    }, {
      "title" : "Knowing what, how and why: A near complete solution for aspect-based sentiment analysis",
      "author" : [ "Haiyun Peng", "Lu Xu", "Lidong Bing", "Fei Huang", "Wei Lu", "Luo Si" ],
      "venue" : null,
      "citeRegEx" : "Peng et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2019
    }, {
      "title" : "SemEval-2016 task 5: Aspect based sentiment analysis",
      "author" : [ "talia Loukachevitch", "Evgeniy Kotelnikov", "Nuria Bel", "Salud Marı́a Jiménez-Zafra", "Gülşen Eryiğit" ],
      "venue" : "In Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-",
      "citeRegEx" : "Loukachevitch et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Loukachevitch et al\\.",
      "year" : 2016
    }, {
      "title" : "SemEval-2015 task 12: Aspect based sentiment analysis",
      "author" : [ "Maria Pontiki", "Dimitris Galanis", "Haris Papageorgiou", "Suresh Manandhar", "Ion Androutsopoulos." ],
      "venue" : "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015),",
      "citeRegEx" : "Pontiki et al\\.,? 2015",
      "shortCiteRegEx" : "Pontiki et al\\.",
      "year" : 2015
    }, {
      "title" : "SemEval-2014 task 4: Aspect based sentiment analysis",
      "author" : [ "Maria Pontiki", "Dimitris Galanis", "John Pavlopoulos", "Harris Papageorgiou", "Ion Androutsopoulos", "Suresh Manandhar." ],
      "venue" : "Proceedings of the 8th International Workshop on Semantic Evaluation",
      "citeRegEx" : "Pontiki et al\\.,? 2014",
      "shortCiteRegEx" : "Pontiki et al\\.",
      "year" : 2014
    }, {
      "title" : "Stanza: A python natural language processing toolkit for many human languages",
      "author" : [ "Peng Qi", "Yuhao Zhang", "Yuhui Zhang", "Jason Bolton", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Qi et al\\.,? 2020",
      "shortCiteRegEx" : "Qi et al\\.",
      "year" : 2020
    }, {
      "title" : "ÚFAL at MRP 2020: Permutation-invariant semantic parsing in PERIN",
      "author" : [ "David Samuel", "Milan Straka." ],
      "venue" : "Proceedings of the CoNLL 2020",
      "citeRegEx" : "Samuel and Straka.,? 2020",
      "shortCiteRegEx" : "Samuel and Straka.",
      "year" : 2020
    }, {
      "title" : "Recursive deep models for semantic compositionality over a sentiment treebank",
      "author" : [ "Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Ng", "Christopher Potts." ],
      "venue" : "Proceedings of the 2013 Conference on",
      "citeRegEx" : "Socher et al\\.,? 2013",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Tokenizing, pos tagging, lemmatizing and parsing ud 2.0 with udpipe",
      "author" : [ "Milan Straka", "Jana Straková" ],
      "venue" : "In Proceedings of the CoNLL",
      "citeRegEx" : "Straka and Straková.,? \\Q2017\\E",
      "shortCiteRegEx" : "Straka and Straková.",
      "year" : 2017
    }, {
      "title" : "Improved semantic representations from tree-structured long short-term memory networks",
      "author" : [ "Kai Sheng Tai", "Richard Socher", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Tai et al\\.,? 2015",
      "shortCiteRegEx" : "Tai et al\\.",
      "year" : 2015
    }, {
      "title" : "Sentence and expression level annotation of opinions in user-generated discourse",
      "author" : [ "Cigdem Toprak", "Niklas Jakob", "Iryna Gurevych." ],
      "venue" : "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 575–584, Up-",
      "citeRegEx" : "Toprak et al\\.,? 2010",
      "shortCiteRegEx" : "Toprak et al\\.",
      "year" : 2010
    }, {
      "title" : "Recursive neural conditional random fields for aspect-based sentiment analysis",
      "author" : [ "Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier", "Xiaokui Xiao." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Wang et al\\.,? 2016",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2016
    }, {
      "title" : "Annotating expressions of opinions and emotions in language",
      "author" : [ "Janyce Wiebe", "Theresa Wilson", "Claire Cardie." ],
      "venue" : "Language Resources and Evaluation, 39(2-3):165–210.",
      "citeRegEx" : "Wiebe et al\\.,? 2005",
      "shortCiteRegEx" : "Wiebe et al\\.",
      "year" : 2005
    }, {
      "title" : "BERT post-training for review reading comprehension and aspect-based sentiment analysis",
      "author" : [ "Hu Xu", "Bing Liu", "Lei Shu", "Philip Yu." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:",
      "citeRegEx" : "Xu et al\\.,? 2019",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2019
    }, {
      "title" : "Extracting opinion expressions with semi-Markov conditional random fields",
      "author" : [ "Bishan Yang", "Claire Cardie." ],
      "venue" : "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Yang and Cardie.,? 2012",
      "shortCiteRegEx" : "Yang and Cardie.",
      "year" : 2012
    }, {
      "title" : "Named Entity Recognition as Dependency Parsing",
      "author" : [ "Juntao Yu", "Bernd Bohnet", "Massimo Poesio." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6470–6476, Online. Association for Computational",
      "citeRegEx" : "Yu et al\\.,? 2020",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2020
    }, {
      "title" : "End-to-end neural opinion extraction with a transition-based model",
      "author" : [ "Meishan Zhang", "Qiansheng Wang", "Guohong Fu." ],
      "venue" : "Information Systems, 80:56 – 63.",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "This methodology also enables us to take advantage of recent improvements in semantic dependency parsing (Dozat and Manning, 2018; Oepen et al., 2020; Kurtz et al., 2020) to efficiently learn a sentiment graph parser.",
      "startOffset" : 105,
      "endOffset" : 170
    }, {
      "referenceID" : 30,
      "context" : "This methodology also enables us to take advantage of recent improvements in semantic dependency parsing (Dozat and Manning, 2018; Oepen et al., 2020; Kurtz et al., 2020) to efficiently learn a sentiment graph parser.",
      "startOffset" : 105,
      "endOffset" : 170
    }, {
      "referenceID" : 19,
      "context" : "This methodology also enables us to take advantage of recent improvements in semantic dependency parsing (Dozat and Manning, 2018; Oepen et al., 2020; Kurtz et al., 2020) to efficiently learn a sentiment graph parser.",
      "startOffset" : 105,
      "endOffset" : 170
    }, {
      "referenceID" : 45,
      "context" : "Previous work on information extraction has used pipeline methods which first extract the holders, targets, and expressions (tasks i - iii) and subsequently predict their relations (task iv), mostly on the MPQA dataset (Wiebe et al., 2005).",
      "startOffset" : 219,
      "endOffset" : 239
    }, {
      "referenceID" : 7,
      "context" : "CRFs and a number of external resources (sentiment lexicons, dependency parsers, named-entity taggers) (Choi et al., 2006; Yang and Cardie, 2012) are strong baselines.",
      "startOffset" : 103,
      "endOffset" : 145
    }, {
      "referenceID" : 47,
      "context" : "CRFs and a number of external resources (sentiment lexicons, dependency parsers, named-entity taggers) (Choi et al., 2006; Yang and Cardie, 2012) are strong baselines.",
      "startOffset" : 103,
      "endOffset" : 145
    }, {
      "referenceID" : 17,
      "context" : "Given the small size of the training data and the complicated task, these techniques often still outperform neural models, such as BiLSTMs (Katiyar and Cardie, 2016).",
      "startOffset" : 139,
      "endOffset" : 165
    }, {
      "referenceID" : 49,
      "context" : "Transition-based end-toend approaches have shown some potential (Zhang et al., 2019).",
      "startOffset" : 64,
      "endOffset" : 84
    }, {
      "referenceID" : 15,
      "context" : "Targeted sentiment analysis only concentrates on extracting sentiment targets (task ii) and classifying the polarity directed towards them (task iv) (Jiang et al., 2011; Mitchell et al., 2013).",
      "startOffset" : 149,
      "endOffset" : 192
    }, {
      "referenceID" : 26,
      "context" : "Targeted sentiment analysis only concentrates on extracting sentiment targets (task ii) and classifying the polarity directed towards them (task iv) (Jiang et al., 2011; Mitchell et al., 2013).",
      "startOffset" : 149,
      "endOffset" : 192
    }, {
      "referenceID" : 21,
      "context" : "Joint approaches perform on par with pipeline methods (Li et al., 2019a) and multitask models can perform even better (He et al.",
      "startOffset" : 54,
      "endOffset" : 72
    }, {
      "referenceID" : 13,
      "context" : ", 2019a) and multitask models can perform even better (He et al., 2019).",
      "startOffset" : 54,
      "endOffset" : 71
    }, {
      "referenceID" : 22,
      "context" : "2019) can also lead to improvements on the ABSA data (Li et al., 2019b).",
      "startOffset" : 53,
      "endOffset" : 71
    }, {
      "referenceID" : 25,
      "context" : "Graph parsing: Syntactic dependency graphs are regularly used in applications, supplying them with necessary grammatical information (Mintz et al., 2009; Cui et al., 2005; Björne et al., 2009; Johansson and Moschitti, 2012; Lapponi et al., 2012).",
      "startOffset" : 133,
      "endOffset" : 245
    }, {
      "referenceID" : 9,
      "context" : "Graph parsing: Syntactic dependency graphs are regularly used in applications, supplying them with necessary grammatical information (Mintz et al., 2009; Cui et al., 2005; Björne et al., 2009; Johansson and Moschitti, 2012; Lapponi et al., 2012).",
      "startOffset" : 133,
      "endOffset" : 245
    }, {
      "referenceID" : 5,
      "context" : "Graph parsing: Syntactic dependency graphs are regularly used in applications, supplying them with necessary grammatical information (Mintz et al., 2009; Cui et al., 2005; Björne et al., 2009; Johansson and Moschitti, 2012; Lapponi et al., 2012).",
      "startOffset" : 133,
      "endOffset" : 245
    }, {
      "referenceID" : 16,
      "context" : "Graph parsing: Syntactic dependency graphs are regularly used in applications, supplying them with necessary grammatical information (Mintz et al., 2009; Cui et al., 2005; Björne et al., 2009; Johansson and Moschitti, 2012; Lapponi et al., 2012).",
      "startOffset" : 133,
      "endOffset" : 245
    }, {
      "referenceID" : 20,
      "context" : "Graph parsing: Syntactic dependency graphs are regularly used in applications, supplying them with necessary grammatical information (Mintz et al., 2009; Cui et al., 2005; Björne et al., 2009; Johansson and Moschitti, 2012; Lapponi et al., 2012).",
      "startOffset" : 133,
      "endOffset" : 245
    }, {
      "referenceID" : 18,
      "context" : "While trees are sufficient to encode syntactic dependencies, they are not expressive enough to handle meaning representations, that require nodes to have multiple incoming arcs, or having no incoming arcs at all (Kuhlmann and Oepen, 2016).",
      "startOffset" : 212,
      "endOffset" : 238
    }, {
      "referenceID" : 27,
      "context" : "(2020) phrased the task of negation resolution (Morante and Blanco, 2012; Morante and Daelemans, 2012) as a graph parsing task.",
      "startOffset" : 47,
      "endOffset" : 102
    }, {
      "referenceID" : 28,
      "context" : "(2020) phrased the task of negation resolution (Morante and Blanco, 2012; Morante and Daelemans, 2012) as a graph parsing task.",
      "startOffset" : 47,
      "endOffset" : 102
    }, {
      "referenceID" : 33,
      "context" : "The largest available structured sentiment dataset is the NoReCFine dataset (Øvrelid et al., 2020), a multi-domain dataset of professional reviews in Norwegian, annotated for structured sentiment.",
      "startOffset" : 76,
      "endOffset" : 98
    }, {
      "referenceID" : 3,
      "context" : "MultiBEU and MultiBCA (Barnes et al., 2018) are hotel reviews in Basque and Catalan, respectively.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 45,
      "context" : "MPQA (Wiebe et al., 2005) annotates news wire text in English.",
      "startOffset" : 5,
      "endOffset" : 25
    }, {
      "referenceID" : 43,
      "context" : "Finally, DSUnis (Toprak et al., 2010) annotate English reviews of online universities and e-commerce.",
      "startOffset" : 16,
      "endOffset" : 37
    }, {
      "referenceID" : 46,
      "context" : "In our experiments, we further augment the token representations with pretrained contextualized embeddings from multilingual BERT (Xu et al., 2019).",
      "startOffset" : 130,
      "endOffset" : 147
    }, {
      "referenceID" : 13,
      "context" : "Targeted F1 This is a common metric in targeted sentiment analysis (also referred to as F1-i (He et al., 2019) or ABSA F1 (Chen and Qian, 2020)).",
      "startOffset" : 93,
      "endOffset" : 110
    }, {
      "referenceID" : 32,
      "context" : "These measure the amount of (in)correctly predicted arcs and labels, as the harmonic mean of precision and recall (Oepen et al., 2014).",
      "startOffset" : 114,
      "endOffset" : 134
    }, {
      "referenceID" : 12,
      "context" : "All sentiment graph models use token-level mBERT representations in addition to word2vec skip-gram embeddings openly available from the NLPL vector repository8 (Fares et al., 2017).",
      "startOffset" : 160,
      "endOffset" : 180
    }, {
      "referenceID" : 4,
      "context" : "We calculate statistical difference between the best and second best models through a bootstrap with replacement test (Berg-Kirkpatrick et al., 2012).",
      "startOffset" : 118,
      "endOffset" : 149
    }, {
      "referenceID" : 14,
      "context" : "We use SpaCy (Honnibal et al., 2020) for English, Stanza (Qi et al.",
      "startOffset" : 13,
      "endOffset" : 36
    }, {
      "referenceID" : 38,
      "context" : ", 2020) for English, Stanza (Qi et al., 2020) for Basque and Catalan and UDPipe (Straka and Straková, 2017) for Norwegian.",
      "startOffset" : 28,
      "endOffset" : 45
    }, {
      "referenceID" : 41,
      "context" : ", 2020) for Basque and Catalan and UDPipe (Straka and Straková, 2017) for Norwegian.",
      "startOffset" : 42,
      "endOffset" : 69
    }, {
      "referenceID" : 2,
      "context" : "This corroborates the bias towards English and similar languages that has been found in multilingual language models (Artetxe et al., 2020; Conneau et al., 2020) and motivates the need for language-specific contextualized embeddings.",
      "startOffset" : 117,
      "endOffset" : 161
    }, {
      "referenceID" : 8,
      "context" : "This corroborates the bias towards English and similar languages that has been found in multilingual language models (Artetxe et al., 2020; Conneau et al., 2020) and motivates the need for language-specific contextualized embeddings.",
      "startOffset" : 117,
      "endOffset" : 161
    }, {
      "referenceID" : 40,
      "context" : "Using parse trees as input has shown promise for sentiment analysis in the past, either to guide a tree-based algorithm (Socher et al., 2013; Tai et al., 2015) or to create features for sentiment models (Nakagawa et al.",
      "startOffset" : 120,
      "endOffset" : 159
    }, {
      "referenceID" : 42,
      "context" : "Using parse trees as input has shown promise for sentiment analysis in the past, either to guide a tree-based algorithm (Socher et al., 2013; Tai et al., 2015) or to create features for sentiment models (Nakagawa et al.",
      "startOffset" : 120,
      "endOffset" : 159
    }, {
      "referenceID" : 29,
      "context" : ", 2015) or to create features for sentiment models (Nakagawa et al., 2010; Almeida et al., 2015).",
      "startOffset" : 51,
      "endOffset" : 96
    }, {
      "referenceID" : 1,
      "context" : ", 2015) or to create features for sentiment models (Nakagawa et al., 2010; Almeida et al., 2015).",
      "startOffset" : 51,
      "endOffset" : 96
    }, {
      "referenceID" : 19,
      "context" : "In the future, we would like to better exploit the similarities between dependency parsing and sentiment graph parsing, either by augmenting the token-level representations with contextualized vectors from their heads in a dependency tree (Kurtz et al., 2020) or by multi-task learning to dependency parse.",
      "startOffset" : 239,
      "endOffset" : 259
    } ],
    "year" : 2021,
    "abstractText" : "Structured sentiment analysis attempts to extract full opinion tuples from a text, but over time this task has been subdivided into smaller and smaller sub-tasks, e.g., target extraction or targeted polarity classification. We argue that this division has become counterproductive and propose a new unified framework to remedy the situation. We cast the structured sentiment problem as dependency graph parsing, where the nodes are spans of sentiment holders, targets and expressions, and the arcs are the relations between them. We perform experiments on five datasets in four languages (English, Norwegian, Basque, and Catalan) and show that this approach leads to strong improvements over state-of-the-art baselines. Our analysis shows that refining the sentiment graphs with syntactic dependency information further improves results.",
    "creator" : "LaTeX with hyperref"
  }
}