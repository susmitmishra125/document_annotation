{
  "name" : "2021.acl-long.142.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning",
    "authors" : [ "Xinyu Wang", "Yong Jiang", "Nguyen Bach", "Tao Wang", "Zhongqiang Huang", "Fei Huang", "Kewei Tu" ],
    "emails" : [ "wangxy1@shanghaitech.edu.cn,", "tukw@shanghaitech.edu.cn,", "yongjiang.jy@alibaba-inc.com", "nguyen.bach@alibaba-inc.com", "leeo.wangt@alibaba-inc.com", "z.huang@alibaba-inc.com", "f.huang@alibaba-inc.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1800–1812\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n1800"
    }, {
      "heading" : "1 Introduction",
      "text" : "Pretrained contextual embeddings such as ELMo (Peters et al., 2018), Flair (Akbik et al., 2018) and BERT (Devlin et al., 2019) have significantly improved the accuracy of Named Entity Recognition (NER) models. Recent work (Devlin et al., 2019; Yu et al., 2020; Yamada et al., 2020) found that including document-level contexts of the target sentence in the input of contextual embeddings methods can further boost the accuracy of NER models. However, there are a lot of application scenarios\n∗Yong Jiang and Kewei Tu are the corresponding authors. ‡: This work was conducted when Xinyu Wang was interning at Alibaba DAMO Academy.\n1Our code is publicly available at https://github. com/Alibaba-NLP/CLNER.\nin which document-level contexts are unavailable in practice. For example, there are sometimes no available contexts in users’ search queries, tweets and short comments in various domains such as social media and E-commerce domains. When professional annotators annotate ambiguous named entities in such cases, they usually rely on domain knowledge for disambiguation. This kind of knowledge can often be found through a search engine. Moreover, when the annotators are not sure about a certain entity, they are usually encouraged to find related knowledge through a search engine (Wang et al., 2019). Therefore, we believe that NER models can benefit from such a process as well.\nIn this paper, we propose to improve NER models by retrieving texts related to the input sentence by an off-the-shelf search engine. We re-rank the retrieved texts according to their semantic relevance to the input sentence and select several top-ranking texts as the external contexts. Consequently, we concatenate the input sentence and external contexts together as a new retrieval-based input view and feed it to the pretrained contextual embedding\nmodule, so that the resulting semantic representations of the input tokens can be improved. The token representations are then fed into a CRF layer for named entity prediction. A motivating example is shown in Figure 1.\nMoreover, we consider utilizing the new input view to improve model performance with the original input view that does not have external contexts. This can be useful in application scenarios when external contexts are unavailable or undesirable (e.g., in time-critical scenarios). To this end, we propose Cooperative Learning (CL) that encourages the two input views to produce similar predictions. We propose two approaches to CL which minimize either the L2 distances between the token representations of the two input views or the Kullback–Leibler (KL) divergence between the prediction distributions of the two input views during training.\nOur experiments show that including the retrieved external contexts can significantly improve the accuracy of NER models on 8 NER datasets from 5 domains. With CL, the accuracy of the NER models with both input views can be further improved. Our approaches outperform previous state-of-the-art approaches in each domain.\nThe contributions of this paper are:\n1. We propose a simple and straight-forward way to improve the contextual representation of an input sentence through retrieving related texts using a search engine. We take the retrieved texts together with the input sentence as a new retrieval-based view.\n2. We propose Cooperative Learning to jointly improve the accuracy of both input views in a unified model. We propose two approaches in CL based on the L2 norm and KL divergence respectively. CL can utilize unlabeled data for further improvement.\n3. We show the effectiveness of our approaches in several NER datasets across 5 domains and our approaches achieve state-of-the-art accuracy. By leveraging a large amount of unlabeled data, the performance can be further improved."
    }, {
      "heading" : "2 Framework",
      "text" : "Given a sentence of n tokens x = {x1, · · · , xn}, the input sentence is fed into a search engine as a query. The search engine returns the top k relevant texts {x̂1, · · · , x̂k}. Our framework feeds these\ntexts into a re-ranking model. We concatenate l top-ranking texts output from the re-ranking model as the external contexts. The NER model is fed with either an input view with the input sentence (original input view) or a concatenation of the input sentence and external contexts (retrieval-based input view) as input. The model outputs the predictions of labels y = {y1, · · · , yn} at each position based on the CRF layer. To further improve the model, we use Cooperative Learning to train a unified model that is strong in both input views. With CL, the model is additionally constrained to be consistent in the internal representations or the output distributions of both input views. The architecture of our framework is shown in Figure 2."
    }, {
      "heading" : "2.1 Re-ranking",
      "text" : "Given an input sentence as a search query, the search engine returns ranked relevant texts. However, the off-the-shelf search engine is highly optimized for a fast speed over a large set of documents, so it may sometimes produce semantically irrelevant results or rank the results using inaccurate relevance scores. Since the NER task targets at semantically recognizing named entities, it is more helpful if the relevant texts are semantically similar to the input sentence. Therefore, we need to re-rank the retrieved texts so that the most semantically relevant texts are chosen. We propose to apply BERTScore (Zhang et al., 2020) to score the relatedness of each retrieved text to the input sentence. BERTScore is a language generation metric that calculates a sum of cosine similarity between token representations of two sentences. Therefore, it is more likely that the search query and the retrieved texts have strong semantic relations when BERTScore is large. The token representations are generated from pretrained contextual embeddings such as BERT. Given the corresponding prenormalized token representations {r1, · · · , rn} of the input sentence x and the pre-normalized token representations {r̂1, · · · , r̂m} of a certain retrieved text x̂ with m words, the Precision (P), Recall (R) of BERTScore measure the semantic similarities from one to another:\nR = 1\nn ∑ xi∈x max x̂j∈x̂ r>i r̂j ; P = 1 m ∑ x̂j∈x̂ max xi∈x r>i r̂j\nWe re-rank the retrieved texts by the F1 scores F1=2 P·RP+R and concatenate l top-ranking texts {x̂1, · · · , x̂l} with F1 scores together as the ex-\nternal contexts:\nx̃ = [sep_token; x̂1; · · · ; x̂l]\nwhere sep_token is a special token representing a separate of sentences in the transformer-based pretrained contextual embeddings (for example, “[SEP]” in BERT)."
    }, {
      "heading" : "2.2 NER Model",
      "text" : "We solve the NER task as a sequence labeling problem. We apply a neural model with a CRF layer, which is one of the most popular state-of-the-art approaches to the task (Lample et al., 2016; Ma and Hovy, 2016; Akbik et al., 2019). In the sequence labeling model, the input sentence x is fed into a transformer-based pretrained contextual embeddings model to get the token representations {v1, · · · ,vn} by vi=embedi(x). The token representations are fed into a CRF layer to get the conditional probability pθ(y|x):\nψ(y′, y,vi) = exp(W T y vi + by′,y) (1)\npθ(y|x) =\nn∏ i=1\nψ(yi−1, yi,vi)∑ y′∈Y(x) n∏ i=1 ψ(y′i−1, y ′ i,vi)\nwhere ψ is the potential function and θ represents the model parameters. Y(x) denotes the set of all possible label sequences given x. y0 is defined to be a special start symbol. WT ∈ Rt×d and b ∈ Rt×t are parameters computing emission and transition scores respectively. d is the hidden size of v and t is the size of the label set. During training, the negative log-likelihood loss for the input sequence with gold labels y∗ is defined by:\nLNLL(θ) = − log pθ(y∗|x) (2)\nIn our approach, we concatenate the external contexts x̃ at the end of the input sentence x to form the retrieval-based input view. The token representations are now given by:\n{v′1, · · · ,v′n, · · · } = embed([x; x̃])\nThe architecture of our NER model is shown in Figure 3. Now the conditional probability pθ(y|x) becomes pθ(y|x, x̃). The loss function in Eq. 2 becomes:\nLNLL-EXT(θ) = − log pθ(y∗|x, x̃) (3)"
    }, {
      "heading" : "2.3 Cooperative Learning",
      "text" : "In practice, there are two application scenarios for the NER model: 1) offline prediction, which re-\nquires high accuracy of the prediction but the prediction speed is less emphasized; 2) online serving, which requires a faster prediction speed. The retrieval-based input view meets the requirement of the first scenario for its strong token representations. However, it does not meet the requirement of the second scenario. The external contexts are usually significantly longer than the input sentence and a search engine may not meet the latency requirements. These two issues significantly slow down the prediction speed of the model. Therefore, it is essential to improve the accuracy of the original input views in a unified model to meet these two scenarios.\nCooperative Learning targets at using the retrieval-based input view to help improve the accuracy of the model when there are no external contexts available. CL adds constraints between the internal representations or the output distributions between two input views to enforce that the predictions of both views should be near. The objective function of CL is calculated by:\nLCL(θ) = D(h([x; x̃]), h([x])) (4)\nwhere D is a distance function between a function hwith different inputs. Because the representations or the distributions with retrieval-based input view are usually informative, we do not backpropagate the gradient through h([x; x̃]). We propose two approaches for CL.\nToken Representations: Stronger token representations usually lead to better accuracy on the task. Therefore, CL constrains the token representations of two input views to be similar. This helps\nthe model learn to predict the token representations with external contexts even if the contexts are not available. In this approach, D is the L2 norm to represent the distances of the token representations:\nLCL-L2(θ) = n∑ i=1 ||v′i − vi||22 (5)\nLabel Distributions: Since CL enforces the label predictions of both input views to be similar, a straight-forward approach is constraining the label distributions predicted by the model to be similar with the two input views. In this approach, we use the KL divergence as the function D. Then objective function in Eq. 4 becomes the KL divergence between pθ(y|x, x̃) and pθ(y|x):\nLCL-KL(θ)= ∑\ny∈Y(x)\nKL(pθ(y|x, x̃)||pθ(y|x)) (6)\nWith the CRF layer, the loss function is difficult to calculate because the output space of pθ(y|•) is exponential in size. To alleviate this issue, we calculate the KL divergence between the marginal distributions qθ(yi|x, x̃) and qθ(yi|x) at each position of the sentence to approximate Eq. 6. The marginal distributions can be obtained using the forward-backward algorithm:\nα(yk) = ∑\n{y0,...,yk−1}\nk∏ i=1 ψ(yi−1, yi,vi)\nβ(yk) = ∑\n{yk+1,...,yn}\nn∏ i=k+1 ψ(yi−1, yi,vi)\nqθ(yk|x) ∝ α(yk)× β(yk) (7)\nAs mentioned earlier, we do not back-propagate the gradient through pθ(y|x, x̃). Therefore calculating the KL divergence is equivalent to calculating the cross-entropy loss between q(y|x, x̃) and q(y|x):\nLCL-KL(θ)=− n∑ i=1 t∑ yi=1 qθ(yi|x, x̃)logqθ(yi|x) (8)\nTogether with the negative log-likelihood losses in Eq. 2, 3, the total loss in training is a summation of label losses and a CL loss:\nL(θ) = LNLL(θ) + LNLL-EXT(θ) + LCL(θ) (9)\nwhere LCL(θ) can be one of the CL loss in Eq. 5, 8 or a summation of both of them."
    }, {
      "heading" : "3 Experiments",
      "text" : ""
    }, {
      "heading" : "3.1 Settings",
      "text" : "Datasets To show the effectiveness of our approach, we experiment on 8 NER datasets across 5 domains:\n• Social Media: We use WNUT-16 (Strauss et al., 2016) and WNUT-17 (Derczynski et al., 2017) datasets collected from social media. We use the standard split for these datasets.\n• News: We use CoNLL-03 English (Tjong Kim Sang and De Meulder, 2003) dataset and CoNLL++ (Wang et al., 2019) dataset. The CoNLL-03 dataset is the most popular dataset for NER. CoNLL++ is a revision of the CoNLL-03 datasets. Wang et al. (2019) fixed annotation errors on the test set by professional annotators and improved the quality of the training data through their CrossWeigh approach. We use the standard dataset split for these datasets.\n• Biomedical: We use BC5CDR (Li et al., 2016) and NCBI-disease (Doğan et al., 2014) datasets, which are two popular biomedical NER datasets. We merge the training and development data as training set following Nooralahzadeh et al. (2019).\n• Science and Technology: We use CBS SciTech News dataset collected by Jia et al. (2019). The dataset only contains the test set with the same label set as the CoNLL-03 dataset. We use the dataset to evaluate the effectiveness of crossdomain transferability from the news domain.\n• E-commerce: We collect and annotate an internal dataset from one anonymous E-commerce website. The dataset contains 25 named entity labels for goods in short texts. We also collect 300,000 unlabeled sentences for semi-supervised training.\nWe show the statistics of the datasets in Table 1.\nAnnotations of the E-commerce dataset We manually labeled the user queries through crowdsourcing from www.aliexpress.com, which is a real-world E-commerce website. For each query, we asked one annotator to label the entities and ask another annotator to check the quality. After that, we randomly select 10% of the dataset and ask the third annotator to check the accuracy. As a result, the overall averaged query-level accuracy2 is 95%. The dataset will not be released due to user privacy.\nRetrieving and Ranking We use an internal E-commerce search engine for the E-commerce dataset. For the other datasets, we use Google Search as the search engine. Google Search is an off-the-shelf search engine and can simulate the offline search over various domains. We use summarized descriptions from the search results as the retrieved texts3. As Google Search limits the maximal length of searching queries to 32 words, we chunk a sentence into multiple sub-sentences based on punctuation if the sentence is longer than 30, feed each sub-sentence to the search engine, and retrieve up to 20 results. We filter the retrieved texts that contain any part of the datasets. Our reranking module selects top 6 relevant texts4 as the external contexts of the input sentence and chunk the external contexts if the total sub-token lengths of the input sentence and external contexts exceeds 510.\nModel Configurations For the re-ranking module, we use Roberta-Large (Liu et al., 2019) for token representations which is the default configuration in the code5 of BERTScore (Zhang et al., 2020). For token representations in the NER model,\n2the accuracy of a query counts 1.0 if all the entities in the query are correctly recognized and 0.0 otherwise.\n3If the descriptions are not available, we use the titles of the results instead.\n4We determined that 6 is a reasonable number based on preliminary experiments.\n5https://github.com/Tiiiger/bert_score\nwe use pretrained Bio-BERT (Lee et al., 2020) for datasets from the biomedical domain and use XLMRoBERTa (Conneau et al., 2020) for datasets from other domains.\nTraining During training, we fine-tune the pretrained contextual embeddings by AdamW (Loshchilov and Hutter, 2018) optimizer with a batch size of 4. We use a learning rate of 5× 10−6 to update the parameters in the pretrained contextual embeddings. For the CRF layer parameters, we use a learning rate of 0.05. We train the NER models for 10 epochs for the datasets in Social Media and Biomedical domains while we train the NER models for 5 epochs for other datasets for efficiency as these datasets have more training sentences."
    }, {
      "heading" : "3.2 Results",
      "text" : "We experiment on the following approaches:\n• LUKE is a very recent state-of-the art model on CoNLL-03 NER dataset proposed by Yamada et al. (2020). We use the same parameter setting as Yamada et al. (2020) and use a single sentence as the input instead of taking document-level contexts in the dataset as in Yamada et al. (2020) for fair comparison.\n• W/O CONTEXT represents training the NER model without external contexts (Eq. 2), which is the baseline of our approaches.\n• W/ CONTEXT represents training the NER model with external contexts (Eq. 3).\n• CL-L2 represents minimizing the L2 distance between token representations (Eq. 5).\n• CL-KL represents minimizing the KL divergence (Eq. 8) between CRF output distributions.\nBesides, we also compare our approaches with previous state-of-the-art approaches over entity-level F1 scores6. During the evaluation, our approaches are evaluated using inputs without external contexts (W/O CONTEXT) and inputs with them (W/ CONTEXT). We report the results averaged over 5 runs in our experiments. The results are listed in\n6We do not compare the results from previous work such as Yu et al. (2020); Luoma and Pyysalo (2020); Yamada et al. (2020) that utilizes the document-level contexts in CoNLL-03 NER here. We conduct a comparison with these approaches in Appendix A.\nTable 27. With the external contexts, our models with CL outperform previous state-of-the-art approaches on most of the datasets. Our approaches significantly outperform the baseline that is trained without external contexts with only one exception. Comparing with LUKE, our approaches and our baseline outperform LUKE in all the cases. The possible reason is that LUKE is pretrained only using long word sequences, which makes the model prone to fail to capture the information of entities based on short sentences8. For our approaches, with CL, the accuracy can be improved on both input views comparing with W/O CONTEXT and W/ CONTEXT, which shows adding constraints between the two views during training helps the model better utilize the original text information. For the two constraints in CL, we find that CL-KL is relatively stronger than CL-L2 in a majority of the cases."
    }, {
      "heading" : "3.3 Cross-Domain Transfer",
      "text" : "For cross-domain transfer, we train the models on the CoNLL-03 datasets, evaluate the accuracy on the CBS SciTech News dataset, and compare the results with those in Jia et al. (2019). We evaluate our approaches with each input view and the results are shown in Table 3. Our approaches can improve the accuracy in cross-domain evaluation. The external contexts during evaluation can help to improve the accuracy of W/ CONTEXT. However, the gap between the two input views for the CL approaches is diminished. The observation shows that CL is able to improve the accuracy in crossdomain transfer for both views and eliminate the gap between the two views."
    }, {
      "heading" : "3.4 Semi-supervised Cooperative Learning",
      "text" : "Cooperative learning can take advantage of large amounts of unlabeled text for further improvement. We jointly train on the labeled data and unlabeled data in training to form a semi-supervised training manner. During training, we alternate between minimizing the loss (Eq. 9) for labeled data and the CL loss for unlabeled data (Eq. 4). We conduct the experiment on the E-commerce dataset as an exam-\n7For the result of Bio-BERT (Lee et al., 2020) on NCBIdisease dataset, we report the results reported in official code (https://github.com/dmis-lab/biobert). The results (89.71 in NCBI-disease) reported in the paper used token-level F1 score instead of entity-level F1 score.\n8We have confirmed with the authors of LUKE (Yamada et al., 2020) that the accuracy on the CoNLL-03 dataset is consistent with their experimental results.\nple. Results in Table 4 show that the accuracy of both input views can be improved especially for the input without external contexts, which shows the effectiveness of CL in semi-supervised learning."
    }, {
      "heading" : "4 Analysis",
      "text" : "We use the WNUT-17 dataset in the analysis."
    }, {
      "heading" : "4.1 Comparison of Re-ranking Approaches",
      "text" : "Various re-ranking approaches may affect the token representations of the model. We compare our approach with three other re-ranking approaches. The first is the ranking from the search engine without any re-ranking approaches. The second is reranking through a fuzzy match score. The approach has been widely applied in a lot of previous work (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020). The third is BERTScore with tf-idf importance weighting which makes rare words more indicative than common words in scoring. We train our models (W/ CONTEXT) with external contexts from these re-ranking approaches and report the averaged and best results on WNUT17 in Table 5. Our results show that re-ranking with BERTScore performs the best, which shows the semantic relevance is helpful for the performance. However, for BERTScore with the tf-idf weighting, the accuracy of the model drops significantly (with p < 0.05). The possible reason might be that the tf-idf weighting gives high weights to irrelevant texts with rare words during re-ranking."
    }, {
      "heading" : "4.2 How the Context Quality Affects Accuracy",
      "text" : "We analyze how the NER model will perform when the quality of external contexts varies. We train and evaluate the NER model in four conditions with various contexts. The first one takes each dataset split as a document and encodes each sentence with document-level contexts. In this case, we encode the document-level contexts following the approach of Yamada et al. (2020). The second one uses GPT-2 (Radford et al., 2019) to generate 6 relevant sentences as external contexts. The other two conditions randomly select from the retrieved texts or the dataset as external contexts. Results in Table 6 show that all these conditions result in inferior accuracy comparing with the model without any external context. However, our external contexts are more semantically relevant to the input sentence and helpful for prediction."
    }, {
      "heading" : "4.3 Ablation Study",
      "text" : "To show the effectiveness of CL, we conduct three ablation studies for our approach. The first one is training the NER model based on one view and predict on the other. The second is jointly training both views without the CL loss term (removing LCL(θ) in Eq. 9). The final one is using both CL losses to train the model (LCL(θ) = LCL-L2(θ)+LCL-KL(θ) in Eq. 9). Results in Table 7 show that the external context can help to improve the accuracy even when the NER model is trained without the contexts. However, when the model is trained with the external contexts, the accuracy of the model\ndrops when predicting the inputs without external contexts. In joint training without CL, the accuracy of the model over inputs without contexts can be slightly improved but the accuracy over inputs with contexts drops, which shows the benefit of adding CL. For the model trained with both CL losses, we find no improvement over the models trained with a single CL loss."
    }, {
      "heading" : "5 Related Work",
      "text" : "Named Entity Recognition Named Entity Recognition (Sundheim, 1995) has been studied for decades. Most of the work takes NER as a sequence labeling problem and applies the linear-chain CRF (Lafferty et al., 2001) to achieve state-of-the-art accuracy (Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018, 2019; Wang et al., 2020b). Recently, the improvement of accuracy mainly benefits from stronger token representations such as pretrained contextual embeddings such as BERT (Devlin et al., 2019), Flair (Akbik et al., 2018) and LUKE (Yamada et al., 2020). Very recent work (Yu et al., 2020; Yamada et al., 2020) utilizes the strength of pretrained contextual embeddings over long-range dependency and encodes the document-level contexts for token representations to achieve state-of-the-art accuracy on CoNLL 2002/2003 NER datasets (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003).\nImproving Models through Retrieval Retrieving related texts from a certain database (such as the training set) has been widely applied in tasks such as neural machine translation (Gu et al., 2018; Zhang et al., 2018; Xu et al., 2020), text generation (Weston et al., 2018; Kim et al., 2020), semantic parsing (Hashimoto et al., 2018; Guo et al., 2019). Most of the work uses the retrieved texts to guide the generation or refine the retrieved texts through the neural model, while we take the retrieved texts as the contexts of the input sentence to improve the semantic representations of the input tokens. For the re-ranking models, fuzzy match score (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020), attention mechanisms (Cao et al., 2018; Cai et al., 2019), and dot products between sentence representations (Lewis et al., 2020; Xu et al., 2020) are usual scoring functions to re-rank the retrieved texts. Instead, we use BERTScore to re-rank the retrieved texts instead as BERTScore evaluates semantic correlations between the texts\nbased on pretrained contextual embeddings.\nMulti-View Learning Multi-View Learning is a technique applied to inputs that can be split into multiple subsets. Co-training (Blum and Mitchell, 1998) and co-regularization (Sindhwani and Niyogi, 2005) train a separate model for each view. These approaches are semi-supervised learning techniques that require two independent views of the data. The model with higher confidence is applied to construct additional labeled data by predicting on unlabeled data. Sun (2013) and Xu et al. (2013) have extensively studied various multiview learning approaches. Hu et al. (2021) shows the effectiveness of multi-view learning on crosslingual structured prediction tasks. Recently, Clark et al. (2018) proposed Cross-View Training (CVT), which trains a unified model instead of multiple models and targets at minimizing the KL divergence between the probability distributions of the model and auxiliary prediction modules. Comparing with CVT, CL targets at improving the accuracy of two kinds of inputs rather than only one of them. We also propose to minimize the distance of token representations between different views in addition to KL-divergence. Besides, CL utilizes the external contexts and therefore we do not need to construct auxiliary prediction modules in the model. Moreover, CVT cannot be directly applied to our transformer-based embeddings. Finally, our decoding layer in the model uses the CRF layer instead of the simple Softmax layer as in CVT. The CRF layer is stronger but more difficult for KLdivergence computation.\nKnowledge Distillation Knowledge distillation (Buciluǎ et al., 2006; Hinton et al., 2015) transfers the knowledge of “teacher” models to smaller “student” models through minimizing the KL divergence of prediction probability distribution between the models. In speech recognition (Huang et al., 2018) and natural language processing (Wang et al., 2020a, 2021b), the marginal probability distribution of the linear-chain CRF layer has been applied to distill the knowledge between teacher models and student models. Comparing with these approaches, our approaches train a single unified model instead of transferring the knowledge between two models. We also show that the accuracy of both views can be improved with our approaches, unlike in knowledge distillation only the student model is updated and improved."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we propose to improve the NER model’s accuracy by retrieving related contexts from a search engine as external contexts of the inputs. To improve the robustness of the models when no external contexts are available, we propose Cooperative Learning. Cooperative Learning adds constraints between two input views over either the token representations or label distributions of both input views to be consistent. Empirical results show that our approach significantly outperforms the baseline models and previous state-of-the-art approaches on the datasets over 5 domains. We also show the effectiveness of Cooperative Learning in a semi-supervised training manner."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported by the National Natural Science Foundation of China (61976139) and by Alibaba Group through Alibaba Innovative Research Program. We thank Kaibo Zhang for his help in crawling related texts from Google Search and thank Jiong Cai and Zhuo Chen for their comments and suggestions on writing."
    }, {
      "heading" : "A Retrieved Contexts Versus Document-level contexts on CoNLL-03",
      "text" : "We conduct a comparison between our retrieved contexts and the document-level contexts on CoNLL-03 datasets. In Table 8, we report the best model on development set following Yamada et al. (2020). Comparing with previous state-of-the-art approaches with encoding document-level contexts, our approaches are competitive and even stronger than some of the previous approaches utilizing maximal document-level contexts. Comparing with our model trained on document-level contexts (W/ DOC CONTEXT), we find that there is still a gap between the document-level contexts and retrieved contexts but our CL approaches can reduce the gap between these two contexts."
    } ],
    "references" : [ {
      "title" : "Pooled contextualized embeddings for named entity recognition",
      "author" : [ "Alan Akbik", "Tanja Bergmann", "Roland Vollgraf." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Akbik et al\\.,? 2019",
      "shortCiteRegEx" : "Akbik et al\\.",
      "year" : 2019
    }, {
      "title" : "Contextual string embeddings for sequence labeling",
      "author" : [ "Alan Akbik", "Duncan Blythe", "Roland Vollgraf." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 1638–1649, Santa Fe, New Mexico, USA. Associ-",
      "citeRegEx" : "Akbik et al\\.,? 2018",
      "shortCiteRegEx" : "Akbik et al\\.",
      "year" : 2018
    }, {
      "title" : "Cloze-driven pretraining of self-attention networks",
      "author" : [ "Alexei Baevski", "Sergey Edunov", "Yinhan Liu", "Luke Zettlemoyer", "Michael Auli." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th Inter-",
      "citeRegEx" : "Baevski et al\\.,? 2019",
      "shortCiteRegEx" : "Baevski et al\\.",
      "year" : 2019
    }, {
      "title" : "Combining labeled and unlabeled data with co-training",
      "author" : [ "Avrim Blum", "Tom Mitchell." ],
      "venue" : "Proceedings of the eleventh annual conference on Computational learning theory, pages 92–100.",
      "citeRegEx" : "Blum and Mitchell.,? 1998",
      "shortCiteRegEx" : "Blum and Mitchell.",
      "year" : 1998
    }, {
      "title" : "Model compression",
      "author" : [ "Cristian Buciluǎ", "Rich Caruana", "Alexandru Niculescu-Mizil." ],
      "venue" : "Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’06, pages 535–541, New York, NY, USA.",
      "citeRegEx" : "Buciluǎ et al\\.,? 2006",
      "shortCiteRegEx" : "Buciluǎ et al\\.",
      "year" : 2006
    }, {
      "title" : "Retrievalguided dialogue response generation via a matchingto-generation framework",
      "author" : [ "Deng Cai", "Yan Wang", "Wei Bi", "Zhaopeng Tu", "Xiaojiang Liu", "Shuming Shi." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natu-",
      "citeRegEx" : "Cai et al\\.,? 2019",
      "shortCiteRegEx" : "Cai et al\\.",
      "year" : 2019
    }, {
      "title" : "Retrieve, rerank and rewrite: Soft template based neural summarization",
      "author" : [ "Ziqiang Cao", "Wenjie Li", "Sujian Li", "Furu Wei." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
      "citeRegEx" : "Cao et al\\.,? 2018",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2018
    }, {
      "title" : "Semi-supervised sequence modeling with cross-view training",
      "author" : [ "Kevin Clark", "Minh-Thang Luong", "Christopher D. Manning", "Quoc Le." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1914–",
      "citeRegEx" : "Clark et al\\.,? 2018",
      "shortCiteRegEx" : "Clark et al\\.",
      "year" : 2018
    }, {
      "title" : "Unsupervised cross-lingual representation learning at scale",
      "author" : [ "Alexis Conneau", "Kartikay Khandelwal", "Naman Goyal", "Vishrav Chaudhary", "Guillaume Wenzek", "Francisco Guzmán", "Edouard Grave", "Myle Ott", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "In",
      "citeRegEx" : "Conneau et al\\.,? 2020",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2020
    }, {
      "title" : "Results of the WNUT2017 shared task on novel and emerging entity recognition",
      "author" : [ "Leon Derczynski", "Eric Nichols", "Marieke van Erp", "Nut Limsopatham." ],
      "venue" : "Proceedings of the 3rd Workshop on Noisy User-generated Text, pages 140–147, Copenhagen,",
      "citeRegEx" : "Derczynski et al\\.,? 2017",
      "shortCiteRegEx" : "Derczynski et al\\.",
      "year" : 2017
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Ncbi disease corpus: a resource for disease name recognition and concept normalization",
      "author" : [ "Rezarta Islamaj Doğan", "Robert Leaman", "Zhiyong Lu." ],
      "venue" : "Journal of biomedical informatics, 47:1–10.",
      "citeRegEx" : "Doğan et al\\.,? 2014",
      "shortCiteRegEx" : "Doğan et al\\.",
      "year" : 2014
    }, {
      "title" : "Search engine guided neural machine translation",
      "author" : [ "Jiatao Gu", "Yong Wang", "Kyunghyun Cho", "Victor OK Li." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.",
      "citeRegEx" : "Gu et al\\.,? 2018",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2018
    }, {
      "title" : "Coupling retrieval and metalearning for context-dependent semantic parsing",
      "author" : [ "Daya Guo", "Duyu Tang", "Nan Duan", "Ming Zhou", "Jian Yin." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 855–",
      "citeRegEx" : "Guo et al\\.,? 2019",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2019
    }, {
      "title" : "A retrieve-and-edit framework for predicting structured outputs",
      "author" : [ "Tatsunori B Hashimoto", "Kelvin Guu", "Yonatan Oren", "Percy Liang." ],
      "venue" : "Proceedings of the 32nd International Conference on Neural Information Processing Systems, pages 10073–",
      "citeRegEx" : "Hashimoto et al\\.,? 2018",
      "shortCiteRegEx" : "Hashimoto et al\\.",
      "year" : 2018
    }, {
      "title" : "Retrieval-based neural code generation",
      "author" : [ "Shirley Anugrah Hayati", "Raphael Olivier", "Pravalika Avvaru", "Pengcheng Yin", "Anthony Tomasic", "Graham Neubig." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Hayati et al\\.,? 2018",
      "shortCiteRegEx" : "Hayati et al\\.",
      "year" : 2018
    }, {
      "title" : "Distilling the knowledge in a neural network",
      "author" : [ "Geoffrey Hinton", "Oriol Vinyals", "Jeffrey Dean." ],
      "venue" : "NIPS Deep Learning and Representation Learning Workshop.",
      "citeRegEx" : "Hinton et al\\.,? 2015",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2015
    }, {
      "title" : "Multi-View Cross-Lingual Structured Prediction with Minimum Supervision",
      "author" : [ "zechuan Hu", "Yong Jiang", "Nguyen Bach", "Tao Wang", "Zhongqiang Huang", "Fei Huang", "Kewei Tu" ],
      "venue" : "In the Joint Conference of the 59th Annual Meeting of the Associa-",
      "citeRegEx" : "Hu et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2021
    }, {
      "title" : "Knowledge distillation for sequence model",
      "author" : [ "Mingkun Huang", "Yongbin You", "Zhehuai Chen", "Yanmin Qian", "Kai Yu." ],
      "venue" : "Proc. Interspeech 2018, pages 3703–3707.",
      "citeRegEx" : "Huang et al\\.,? 2018",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2018
    }, {
      "title" : "Crossdomain NER using cross-domain language modeling",
      "author" : [ "Chen Jia", "Xiaobo Liang", "Yue Zhang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2464–2474, Florence, Italy. Association for",
      "citeRegEx" : "Jia et al\\.,? 2019",
      "shortCiteRegEx" : "Jia et al\\.",
      "year" : 2019
    }, {
      "title" : "Retrieval-augmented controllable review generation",
      "author" : [ "Jihyeok Kim", "Seungtaek Choi", "Reinald Kim Amplayo", "Seung-won Hwang." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 2284–2295, Barcelona,",
      "citeRegEx" : "Kim et al\\.,? 2020",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2020
    }, {
      "title" : "Conditional random fields",
      "author" : [ "John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira" ],
      "venue" : null,
      "citeRegEx" : "Lafferty et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "Neural architectures for named entity recognition",
      "author" : [ "Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Lample et al\\.,? 2016",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2016
    }, {
      "title" : "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
      "author" : [ "Jinhyuk Lee", "Wonjin Yoon", "Sungdong Kim", "Donghyeon Kim", "Sunkyu Kim", "Chan Ho So", "Jaewoo Kang." ],
      "venue" : "Bioinformatics, 36(4):1234–1240.",
      "citeRegEx" : "Lee et al\\.,? 2020",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2020
    }, {
      "title" : "Retrieval-augmented generation for knowledge-intensive nlp tasks",
      "author" : [ "Patrick Lewis", "Ethan Perez", "Aleksandara Piktus", "Fabio Petroni", "Vladimir Karpukhin", "Naman Goyal", "Heinrich Küttler", "Mike Lewis", "Wen-tau Yih", "Tim Rocktäschel" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "Biocreative v cdr task corpus: a resource for chemical disease relation extraction",
      "author" : [ "Jiao Li", "Yueping Sun", "Robin J Johnson", "Daniela Sciaky", "Chih-Hsuan Wei", "Robert Leaman", "Allan Peter Davis", "Carolyn J Mattingly", "Thomas C Wiegers", "Zhiyong Lu" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Dice loss for dataimbalanced NLP tasks",
      "author" : [ "Xiaoya Li", "Xiaofei Sun", "Yuxian Meng", "Junjun Liang", "Fei Wu", "Jiwei Li." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 465–476, Online. Associ-",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Decoupled weight decay regularization",
      "author" : [ "Ilya Loshchilov", "Frank Hutter." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Loshchilov and Hutter.,? 2018",
      "shortCiteRegEx" : "Loshchilov and Hutter.",
      "year" : 2018
    }, {
      "title" : "Exploring cross-sentence contexts for named entity recognition with BERT",
      "author" : [ "Jouni Luoma", "Sampo Pyysalo." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 904–914, Barcelona, Spain (Online). Interna-",
      "citeRegEx" : "Luoma and Pyysalo.,? 2020",
      "shortCiteRegEx" : "Luoma and Pyysalo.",
      "year" : 2020
    }, {
      "title" : "End-to-end sequence labeling via bi-directional LSTM-CNNsCRF",
      "author" : [ "Xuezhe Ma", "Eduard Hovy." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1064–1074, Berlin, Ger-",
      "citeRegEx" : "Ma and Hovy.,? 2016",
      "shortCiteRegEx" : "Ma and Hovy.",
      "year" : 2016
    }, {
      "title" : "BERTweet: A pre-trained language model for English tweets",
      "author" : [ "Dat Quoc Nguyen", "Thanh Vu", "Anh Tuan Nguyen." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 9–",
      "citeRegEx" : "Nguyen et al\\.,? 2020",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2020
    }, {
      "title" : "Named entity recognition for social media texts with semantic augmentation",
      "author" : [ "Yuyang Nie", "Yuanhe Tian", "Xiang Wan", "Yan Song", "Bo Dai." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Nie et al\\.,? 2020",
      "shortCiteRegEx" : "Nie et al\\.",
      "year" : 2020
    }, {
      "title" : "Reinforcement-based denoising of distantly supervised NER with partial annotation",
      "author" : [ "Farhad Nooralahzadeh", "Jan Tore Lønning", "Lilja Øvrelid." ],
      "venue" : "Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019),",
      "citeRegEx" : "Nooralahzadeh et al\\.,? 2019",
      "shortCiteRegEx" : "Nooralahzadeh et al\\.",
      "year" : 2019
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Associ-",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "OpenAI blog, 1(8):9.",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Bioflair: Pretrained pooled contextualized embeddings for biomedical sequence labeling tasks",
      "author" : [ "Shreyas Sharma", "Ron Daniel Jr." ],
      "venue" : "arXiv preprint arXiv:1908.05760.",
      "citeRegEx" : "Sharma and Jr.,? 2019",
      "shortCiteRegEx" : "Sharma and Jr.",
      "year" : 2019
    }, {
      "title" : "A coregularized approach to semi-supervised learning with multiple views",
      "author" : [ "Vikas Sindhwani", "Partha Niyogi." ],
      "venue" : "Proceedings of the ICML Workshop on Learning with Multiple Views. Citeseer.",
      "citeRegEx" : "Sindhwani and Niyogi.,? 2005",
      "shortCiteRegEx" : "Sindhwani and Niyogi.",
      "year" : 2005
    }, {
      "title" : "Results of the WNUT16 named entity recognition shared task",
      "author" : [ "Benjamin Strauss", "Bethany Toma", "Alan Ritter", "MarieCatherine de Marneffe", "Wei Xu." ],
      "venue" : "Proceedings of the 2nd Workshop on Noisy User-generated Text (WNUT), pages 138–144, Os-",
      "citeRegEx" : "Strauss et al\\.,? 2016",
      "shortCiteRegEx" : "Strauss et al\\.",
      "year" : 2016
    }, {
      "title" : "A survey of multi-view machine learning",
      "author" : [ "Shiliang Sun." ],
      "venue" : "Neural computing and applications, 23(78):2031–2038.",
      "citeRegEx" : "Sun.,? 2013",
      "shortCiteRegEx" : "Sun.",
      "year" : 2013
    }, {
      "title" : "Named entity task definition, version 2.1",
      "author" : [ "Beth M. Sundheim" ],
      "venue" : "In Proceedings of the Sixth Message Understanding Conference,",
      "citeRegEx" : "Sundheim.,? \\Q1995\\E",
      "shortCiteRegEx" : "Sundheim.",
      "year" : 1995
    }, {
      "title" : "Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition",
      "author" : [ "Erik F. Tjong Kim Sang." ],
      "venue" : "COLING-02: The 6th Conference on Natural Language Learning 2002 (CoNLL-2002).",
      "citeRegEx" : "Sang.,? 2002",
      "shortCiteRegEx" : "Sang.",
      "year" : 2002
    }, {
      "title" : "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
      "author" : [ "Erik F. Tjong Kim Sang", "Fien De Meulder." ],
      "venue" : "Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, pages",
      "citeRegEx" : "Sang and Meulder.,? 2003",
      "shortCiteRegEx" : "Sang and Meulder.",
      "year" : 2003
    }, {
      "title" : "Structure-level knowledge distillation for multilingual sequence labeling",
      "author" : [ "Xinyu Wang", "Yong Jiang", "Nguyen Bach", "Tao Wang", "Fei Huang", "Kewei Tu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Wang et al\\.,? 2020a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Automated Concatenation of Embeddings for Structured Prediction",
      "author" : [ "Xinyu Wang", "Yong Jiang", "Nguyen Bach", "Tao Wang", "Zhongqiang Huang", "Fei Huang", "Kewei Tu." ],
      "venue" : "the Joint Conference of the 59th Annual Meeting of the Association",
      "citeRegEx" : "Wang et al\\.,? 2021a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2021
    }, {
      "title" : "2020b. More embeddings, better sequence labelers",
      "author" : [ "Xinyu Wang", "Yong Jiang", "Nguyen Bach", "Tao Wang", "Huang Zhongqiang", "Fei Huang", "Kewei Tu" ],
      "venue" : "In Findings of EMNLP, Online",
      "citeRegEx" : "Wang et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Structural Knowledge Distillation: Tractably Distilling Information for Structured Predictor",
      "author" : [ "Xinyu Wang", "Yong Jiang", "Zhaohui Yan", "Zixia Jia", "Nguyen Bach", "Tao Wang", "Zhongqiang Huang", "Fei Huang", "Kewei Tu." ],
      "venue" : "the Joint Conference",
      "citeRegEx" : "Wang et al\\.,? 2021b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2021
    }, {
      "title" : "CrossWeigh: Training named entity tagger from imperfect annotations",
      "author" : [ "Zihan Wang", "Jingbo Shang", "Liyuan Liu", "Lihao Lu", "Jiacheng Liu", "Jiawei Han." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Retrieve and refine: Improved sequence generation models for dialogue",
      "author" : [ "Jason Weston", "Emily Dinan", "Alexander Miller." ],
      "venue" : "Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented Conversational",
      "citeRegEx" : "Weston et al\\.,? 2018",
      "shortCiteRegEx" : "Weston et al\\.",
      "year" : 2018
    }, {
      "title" : "A survey on multi-view learning",
      "author" : [ "Chang Xu", "Dacheng Tao", "Chao Xu." ],
      "venue" : "arXiv preprint arXiv:1304.5634.",
      "citeRegEx" : "Xu et al\\.,? 2013",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2013
    }, {
      "title" : "Boosting neural machine translation with similar translations",
      "author" : [ "Jitao Xu", "Josep Crego", "Jean Senellart." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1580–1590, Online. Association for Computa-",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "LUKE: Deep contextualized entity representations with entityaware self-attention",
      "author" : [ "Ikuya Yamada", "Akari Asai", "Hiroyuki Shindo", "Hideaki Takeda", "Yuji Matsumoto." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Lan-",
      "citeRegEx" : "Yamada et al\\.,? 2020",
      "shortCiteRegEx" : "Yamada et al\\.",
      "year" : 2020
    }, {
      "title" : "Named entity recognition as dependency parsing",
      "author" : [ "Juntao Yu", "Bernd Bohnet", "Massimo Poesio." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6470– 6476, Online. Association for Computational Lin-",
      "citeRegEx" : "Yu et al\\.,? 2020",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2020
    }, {
      "title" : "Guiding neural machine translation with retrieved translation pieces",
      "author" : [ "Jingyi Zhang", "Masao Utiyama", "Eiichro Sumita", "Graham Neubig", "Satoshi Nakamura." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Bertscore: Evaluating text generation with bert",
      "author" : [ "Tianyi Zhang", "Varsha Kishore", "Felix Wu", "Kilian Q. Weinberger", "Yoav Artzi." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Dual adversarial neural transfer for low-resource named entity recognition",
      "author" : [ "Joey Tianyi Zhou", "Hao Zhang", "Di Jin", "Hongyuan Zhu", "Meng Fang", "Rick Siow Mong Goh", "Kenneth Kwok." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association",
      "citeRegEx" : "Zhou et al\\.,? 2019",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 34,
      "context" : "Pretrained contextual embeddings such as ELMo (Peters et al., 2018), Flair (Akbik et al.",
      "startOffset" : 46,
      "endOffset" : 67
    }, {
      "referenceID" : 1,
      "context" : ", 2018), Flair (Akbik et al., 2018) and BERT (Devlin et al.",
      "startOffset" : 15,
      "endOffset" : 35
    }, {
      "referenceID" : 10,
      "context" : ", 2018) and BERT (Devlin et al., 2019) have significantly improved the accuracy of Named Entity Recognition (NER) models.",
      "startOffset" : 17,
      "endOffset" : 38
    }, {
      "referenceID" : 10,
      "context" : "Recent work (Devlin et al., 2019; Yu et al., 2020; Yamada et al., 2020) found that including document-level contexts of the target sentence in the input of contextual embeddings methods can further boost the accuracy of NER models.",
      "startOffset" : 12,
      "endOffset" : 71
    }, {
      "referenceID" : 52,
      "context" : "Recent work (Devlin et al., 2019; Yu et al., 2020; Yamada et al., 2020) found that including document-level contexts of the target sentence in the input of contextual embeddings methods can further boost the accuracy of NER models.",
      "startOffset" : 12,
      "endOffset" : 71
    }, {
      "referenceID" : 51,
      "context" : "Recent work (Devlin et al., 2019; Yu et al., 2020; Yamada et al., 2020) found that including document-level contexts of the target sentence in the input of contextual embeddings methods can further boost the accuracy of NER models.",
      "startOffset" : 12,
      "endOffset" : 71
    }, {
      "referenceID" : 47,
      "context" : "Moreover, when the annotators are not sure about a certain entity, they are usually encouraged to find related knowledge through a search engine (Wang et al., 2019).",
      "startOffset" : 145,
      "endOffset" : 164
    }, {
      "referenceID" : 54,
      "context" : "apply BERTScore (Zhang et al., 2020) to score the relatedness of each retrieved text to the input sentence.",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 22,
      "context" : "We apply a neural model with a CRF layer, which is one of the most popular state-of-the-art approaches to the task (Lample et al., 2016; Ma and Hovy, 2016; Akbik et al., 2019).",
      "startOffset" : 115,
      "endOffset" : 175
    }, {
      "referenceID" : 30,
      "context" : "We apply a neural model with a CRF layer, which is one of the most popular state-of-the-art approaches to the task (Lample et al., 2016; Ma and Hovy, 2016; Akbik et al., 2019).",
      "startOffset" : 115,
      "endOffset" : 175
    }, {
      "referenceID" : 0,
      "context" : "We apply a neural model with a CRF layer, which is one of the most popular state-of-the-art approaches to the task (Lample et al., 2016; Ma and Hovy, 2016; Akbik et al., 2019).",
      "startOffset" : 115,
      "endOffset" : 175
    }, {
      "referenceID" : 38,
      "context" : "• Social Media: We use WNUT-16 (Strauss et al., 2016) and WNUT-17 (Derczynski et al.",
      "startOffset" : 31,
      "endOffset" : 53
    }, {
      "referenceID" : 25,
      "context" : "• Biomedical: We use BC5CDR (Li et al., 2016) and NCBI-disease (Doğan et al.",
      "startOffset" : 28,
      "endOffset" : 45
    }, {
      "referenceID" : 11,
      "context" : ", 2016) and NCBI-disease (Doğan et al., 2014) datasets, which are two popular biomedical NER datasets.",
      "startOffset" : 25,
      "endOffset" : 45
    }, {
      "referenceID" : 27,
      "context" : "Model Configurations For the re-ranking module, we use Roberta-Large (Liu et al., 2019) for token representations which is the default configuration in the code5 of BERTScore (Zhang et al.",
      "startOffset" : 69,
      "endOffset" : 87
    }, {
      "referenceID" : 54,
      "context" : ", 2019) for token representations which is the default configuration in the code5 of BERTScore (Zhang et al., 2020).",
      "startOffset" : 95,
      "endOffset" : 115
    }, {
      "referenceID" : 23,
      "context" : "1805 we use pretrained Bio-BERT (Lee et al., 2020) for datasets from the biomedical domain and use XLMRoBERTa (Conneau et al.",
      "startOffset" : 32,
      "endOffset" : 50
    }, {
      "referenceID" : 8,
      "context" : ", 2020) for datasets from the biomedical domain and use XLMRoBERTa (Conneau et al., 2020) for datasets from other domains.",
      "startOffset" : 67,
      "endOffset" : 89
    }, {
      "referenceID" : 28,
      "context" : "Training During training, we fine-tune the pretrained contextual embeddings by AdamW (Loshchilov and Hutter, 2018) optimizer with a batch size of 4.",
      "startOffset" : 85,
      "endOffset" : 114
    }, {
      "referenceID" : 23,
      "context" : "For the result of Bio-BERT (Lee et al., 2020) on NCBIdisease dataset, we report the results reported in official code (https://github.",
      "startOffset" : 27,
      "endOffset" : 45
    }, {
      "referenceID" : 51,
      "context" : "(8)We have confirmed with the authors of LUKE (Yamada et al., 2020) that the accuracy on the CoNLL-03 dataset is consistent with their experimental results.",
      "startOffset" : 46,
      "endOffset" : 67
    }, {
      "referenceID" : 12,
      "context" : "The approach has been widely applied in a lot of previous work (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020).",
      "startOffset" : 63,
      "endOffset" : 138
    }, {
      "referenceID" : 53,
      "context" : "The approach has been widely applied in a lot of previous work (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020).",
      "startOffset" : 63,
      "endOffset" : 138
    }, {
      "referenceID" : 15,
      "context" : "The approach has been widely applied in a lot of previous work (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020).",
      "startOffset" : 63,
      "endOffset" : 138
    }, {
      "referenceID" : 50,
      "context" : "The approach has been widely applied in a lot of previous work (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020).",
      "startOffset" : 63,
      "endOffset" : 138
    }, {
      "referenceID" : 35,
      "context" : "The second one uses GPT-2 (Radford et al., 2019) to generate 6 relevant sentences as external contexts.",
      "startOffset" : 26,
      "endOffset" : 48
    }, {
      "referenceID" : 40,
      "context" : "Named Entity Recognition Named Entity Recognition (Sundheim, 1995) has been studied for decades.",
      "startOffset" : 50,
      "endOffset" : 66
    }, {
      "referenceID" : 21,
      "context" : "Most of the work takes NER as a sequence labeling problem and applies the linear-chain CRF (Lafferty et al., 2001) to achieve",
      "startOffset" : 91,
      "endOffset" : 114
    }, {
      "referenceID" : 10,
      "context" : "embeddings such as BERT (Devlin et al., 2019), Flair (Akbik et al.",
      "startOffset" : 24,
      "endOffset" : 45
    }, {
      "referenceID" : 1,
      "context" : ", 2019), Flair (Akbik et al., 2018) and LUKE (Yamada et al.",
      "startOffset" : 15,
      "endOffset" : 35
    }, {
      "referenceID" : 52,
      "context" : "Very recent work (Yu et al., 2020; Yamada et al., 2020) utilizes the strength of pretrained contextual embeddings over long-range",
      "startOffset" : 17,
      "endOffset" : 55
    }, {
      "referenceID" : 51,
      "context" : "Very recent work (Yu et al., 2020; Yamada et al., 2020) utilizes the strength of pretrained contextual embeddings over long-range",
      "startOffset" : 17,
      "endOffset" : 55
    }, {
      "referenceID" : 12,
      "context" : "Improving Models through Retrieval Retrieving related texts from a certain database (such as the training set) has been widely applied in tasks such as neural machine translation (Gu et al., 2018; Zhang et al., 2018; Xu et al., 2020), text generation (Weston et al.",
      "startOffset" : 179,
      "endOffset" : 233
    }, {
      "referenceID" : 53,
      "context" : "Improving Models through Retrieval Retrieving related texts from a certain database (such as the training set) has been widely applied in tasks such as neural machine translation (Gu et al., 2018; Zhang et al., 2018; Xu et al., 2020), text generation (Weston et al.",
      "startOffset" : 179,
      "endOffset" : 233
    }, {
      "referenceID" : 50,
      "context" : "Improving Models through Retrieval Retrieving related texts from a certain database (such as the training set) has been widely applied in tasks such as neural machine translation (Gu et al., 2018; Zhang et al., 2018; Xu et al., 2020), text generation (Weston et al.",
      "startOffset" : 179,
      "endOffset" : 233
    }, {
      "referenceID" : 48,
      "context" : ", 2020), text generation (Weston et al., 2018; Kim et al., 2020), semantic parsing (Hashimoto et al.",
      "startOffset" : 25,
      "endOffset" : 64
    }, {
      "referenceID" : 20,
      "context" : ", 2020), text generation (Weston et al., 2018; Kim et al., 2020), semantic parsing (Hashimoto et al.",
      "startOffset" : 25,
      "endOffset" : 64
    }, {
      "referenceID" : 12,
      "context" : "For the re-ranking models, fuzzy match score (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020), attention mechanisms (Cao et al.",
      "startOffset" : 45,
      "endOffset" : 120
    }, {
      "referenceID" : 53,
      "context" : "For the re-ranking models, fuzzy match score (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020), attention mechanisms (Cao et al.",
      "startOffset" : 45,
      "endOffset" : 120
    }, {
      "referenceID" : 15,
      "context" : "For the re-ranking models, fuzzy match score (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020), attention mechanisms (Cao et al.",
      "startOffset" : 45,
      "endOffset" : 120
    }, {
      "referenceID" : 50,
      "context" : "For the re-ranking models, fuzzy match score (Gu et al., 2018; Zhang et al., 2018; Hayati et al., 2018; Xu et al., 2020), attention mechanisms (Cao et al.",
      "startOffset" : 45,
      "endOffset" : 120
    }, {
      "referenceID" : 6,
      "context" : ", 2020), attention mechanisms (Cao et al., 2018; Cai et al., 2019), and dot products between sentence representations (Lewis et al.",
      "startOffset" : 30,
      "endOffset" : 66
    }, {
      "referenceID" : 5,
      "context" : ", 2020), attention mechanisms (Cao et al., 2018; Cai et al., 2019), and dot products between sentence representations (Lewis et al.",
      "startOffset" : 30,
      "endOffset" : 66
    }, {
      "referenceID" : 24,
      "context" : ", 2019), and dot products between sentence representations (Lewis et al., 2020; Xu et al., 2020) are usual scoring functions to re-rank the retrieved texts.",
      "startOffset" : 59,
      "endOffset" : 96
    }, {
      "referenceID" : 50,
      "context" : ", 2019), and dot products between sentence representations (Lewis et al., 2020; Xu et al., 2020) are usual scoring functions to re-rank the retrieved texts.",
      "startOffset" : 59,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "Co-training (Blum and Mitchell, 1998) and co-regularization (Sindhwani and Niyogi, 2005) train a separate model for each view.",
      "startOffset" : 12,
      "endOffset" : 37
    }, {
      "referenceID" : 37,
      "context" : "Co-training (Blum and Mitchell, 1998) and co-regularization (Sindhwani and Niyogi, 2005) train a separate model for each view.",
      "startOffset" : 60,
      "endOffset" : 88
    }, {
      "referenceID" : 4,
      "context" : "Knowledge Distillation Knowledge distillation (Buciluǎ et al., 2006; Hinton et al., 2015) transfers the knowledge of “teacher” models to smaller “student” models through minimizing the KL divergence of prediction probability distribution between the models.",
      "startOffset" : 46,
      "endOffset" : 89
    }, {
      "referenceID" : 16,
      "context" : "Knowledge Distillation Knowledge distillation (Buciluǎ et al., 2006; Hinton et al., 2015) transfers the knowledge of “teacher” models to smaller “student” models through minimizing the KL divergence of prediction probability distribution between the models.",
      "startOffset" : 46,
      "endOffset" : 89
    }, {
      "referenceID" : 18,
      "context" : "In speech recognition (Huang et al., 2018) and natural language processing (Wang et al.",
      "startOffset" : 22,
      "endOffset" : 42
    } ],
    "year" : 2021,
    "abstractText" : "Recent advances in Named Entity Recognition (NER) show that document-level contexts can significantly improve model performance. In many application scenarios, however, such contexts are not available. In this paper, we propose to find external contexts of a sentence by retrieving and selecting a set of semantically relevant texts through a search engine, with the original sentence as the query. We find empirically that the contextual representations computed on the retrieval-based input view, constructed through the concatenation of a sentence and its external contexts, can achieve significantly improved performance compared to the original input view based only on the sentence. Furthermore, we can improve the model performance of both input views by Cooperative Learning, a training method that encourages the two input views to produce similar contextual representations or output label distributions. Experiments show that our approach can achieve new state-of-the-art performance on 8 NER data sets across 5 domains.1",
    "creator" : "LaTeX with hyperref"
  }
}