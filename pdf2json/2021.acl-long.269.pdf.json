{
  "name" : "2021.acl-long.269.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Towards Emotional Support Dialog Systems",
    "authors" : [ "Siyang Liu", "Chujie Zheng", "Orianna Demasi", "Sahand Sabour", "Yu Li", "Zhou Yu", "Yong Jiang", "Minlie Huang" ],
    "emails" : [ "siyang-l18@mails.tsinghua.edu.cn,", "chujiezhengchn@gmail.com,", "aihuang@tsinghua.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3469–3483\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3469"
    }, {
      "heading" : "1 Introduction",
      "text" : "Emotional support (ES) aims at reducing individuals’ emotional distress and helping them understand and work through the challenges that they face (Burleson, 2003; Langford et al., 1997; Heaney and Israel, 2008). It is a critical capacity to train into dialog systems that interact with users\n∗Equal Contribution. †Corresponding author.\n1Our data and codes are available at https://github.com/thu-coai/ Emotional-Support-Conversation.\non daily basis (Van der Zwaan et al., 2012; Zhou et al., 2020), particularly for settings that include social interactions (accompanying and cheering up the user), mental health support (comforting a frustrated help-seeker and helping identify the problem), customer service chats (appeasing an angry customer and providing solutions), etc. Recent research has also shown that people prefer dialog systems that can provide more supportive responses (Rains et al., 2020).\nResearch has shown that providing emotional support is not intuitive (Burleson, 2003), so procedures and conversational skills have been suggested (Hill, 2009) to help provide better support through conversation. Such skills can be seen in the example conversation that we collected and is shown in Figure 1. To identify the causes of the help-\nseeker’s distress, the supporter first explores the help-seeker’s problems. Without exploration, the support is unlikely to understand the help-seeker’s experiences and feelings, and thus it may be offensive or even harmful if the supporter would give irrelevant advice, like ‘You could go for a walk to relax’. While learning about the help-seeker’s situation, the supporter may express understanding and empathy to relieve the help-seeker’s frustration by using various skills (e.g., Self-disclosure, Reflection of Feelings, etc.). After understanding the help-seeker’s problem, the supporter may offer suggestions to help the help-seeker cope with the problem. If the supporter only comforts the help-seeker without any inspiration for action to change, the supporter may not effectively help the help-seeker’s emotions improve. Finally, during the data collection of this example conversation, the help-seeker reported that their emotion intensity decreased from 5 to 2 (emotion intensity is labeled in our corpus, we give detailed annotations of this conversation example in Appendix A), which indicates the effectiveness of the ES provided by the supporter.\nDespite the importance and complexity of ES, research on data-driven ES dialog systems is limited due to a lack of both task design and relevant corpora of conversations that demonstrate diverse ES skills in use. First, existing research systems that relate to emotional chatting (Zhou et al., 2018) or empathetic responding (Rashkin et al., 2019) return messages that are examples of emotion or empathy and are thus limited in functionality, as they are not capable of many other skills that are often used to provide effective ES (Hill, 2009). Figure 2 illustrates the relationship between the three tasks and we provide further discussion in Section 2.1. Second, people are not naturally good at being supportive, so guidelines have been developed to train humans how to be more supportive. Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations. As a result, data-driven models that leverage such corpora (Radford et al., 2019; Zhang et al., 2020; Roller et al., 2020) are limited in their ability to explicitly learn how to utilize support skills and thus provide effective ES.\nIn this paper, we define the task of Emotional Support Conversation (ESC), aiming to provide\nsupport through social interactions (like the interactions between peers, friends, or families) rather than professional counseling, and propose an ESC Framework, which is grounded on the Helping Skills Theory (Hill, 2009) and tailored to be appropriate for a dialog system setting (Figure 3). We carefully design the ESC Framework for a dialog system setting by adapting relevant components of Hill’s Helping Skills model of conversational support. The ESC Framework proposes three stages (Exploration, Comforting and Action), where each stage contains several support strategies (or skills). To facilitate the research of emotional support conversation, we then construct an Emotional Support Conversation dataset, ESConv, and take multiple efforts to ensure rich annotation and that all conversations are quality examples for this particularly complex dialog task. ESConv is collected with crowdworkers chatting in help-seeker and supporter roles. We design tutorials based on the ESC framework and train all the supporters and devise multiple manual and automatic mechanisms to ensure effectiveness of emotional support in conversations. Finally, we evaluate the state-of-the-art models and observe significant improvement in the emotional support provided when various support strategies are utilized. Further analysis of the interactive evaluation results shows the Joint model can mimic human supporters’ behaviors in strategy utilization. We believe our work will facilitate research on more data-driven approaches to build dialog systems capable of providing effective emotional support."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Emotional & Empathetic Conversation",
      "text" : "Figure 2 intuitively shows the relationships among ESC, emotional conversation, and empathetic conversation. Emotion has been shown to be impor-\ntant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020). As a notable work of emotional conversation, Zhou et al. (2018) propose Emotional Chatting Machine (ECM) to generate emotional responses given a pre-specified emotion. This task is required to accurately express (designated or not) emotions in generated responses. While ES may include expressing emotions, such as happiness or sadness, it has a broader aim of reducing the user’s emotional distress through the utilization of proper support skills, which is fundamentally different from emotional chatting. Emotional chatting is merely a basic quality of dialog systems, while ES is a more high-level and complex ability that dialog systems are expected to be equipped with. Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accordingly. For instance, Rashkin et al. (2019) argued that dialog models can generate more empathetic responses by recognizing the interlocutor’s feelings. Effective ES naturally requires expressing empathy according to the help-seeker’s experiences and feelings, as shown in our proposed Emotional Support Framework (Section 3.2, Figure 3). Hence, empathetic responding is only one of the necessary components of emotional support. In addition to empathetic responding, an emotional support conversation needs to explore the users’ problems and help them cope with difficulty."
    }, {
      "heading" : "2.2 Related Datasets for Emotional Support",
      "text" : "Various works have considered conversations of emotional support in a social context, such as on social media or online forums (Medeiros and Bosse, 2018; Sharma et al., 2020b; Hosseini and Caragea, 2021). Medeiros and Bosse (2018) collected stressrelated posts and response pairs from Twitter and classified replies into supportive categories. In (Sharma et al., 2020b), the post-response pairs from TalkLife and mental health subreddits are annotated with the communication mechanisms of text-based empathy expression (only the data of the Reddit part is publicly available). Hosseini and Caragea (2021) also collected such post-response pairs from online support groups, which have been annotated as needing or expressing support. The dialogues in these corpora are either single-turn interactions\n(post-response pair) or very short conversations, which limits the potential for effective ES, as ES often requires many turns of interaction (Hill, 2009)."
    }, {
      "heading" : "2.3 Emotional Support Dialog Systems",
      "text" : "Some traditional dialog systems have applied human-crafted rules to provide emotional support responses (Van der Zwaan et al., 2012; van der Zwaan et al., 2012). A recent system has considered a rule-based algorithm that determines the supportive act used in the response and then selects proper replies from the pre-defined list of candidates (Medeiros and Bosse, 2018). Another conversational system designed to provide support for coping with COVID-19 was implemented by identifying topics that users mentioned and then responding with a reflection from a template or a message from a pre-defined lexicon (Welch et al., 2020). Few studies have focused on generating supportive responses, and those that have have been limited in scope. For example, Shen et al. (2020) explored how to generate supportive responses via reflecting on user input."
    }, {
      "heading" : "3 Emotional Support Conversation",
      "text" : ""
    }, {
      "heading" : "3.1 Task Definition",
      "text" : "When a user is in a bad emotional state, perhaps due to a particular problem, they may seek help to improve their emotional state. In this setting, the user can be tagged with a negative emotion label e, a emotion intensity level l (e.g., ranging from 1 to 5), and an underlying challenge that the user is going through. The supporter (or the system) needs to comfort the user in a conversation with support skills to lower their intensity level. Note that the user’s state is unknown to the supporter prior to the conversation. During the conversation, the supporter needs to identify the problem that the user is facing, comfort the user, and then provide some suggestions or information to help the user take action to cope with their problem. An emotional support conversation is effective if the intensity level of the user is lowered at the end of the conversation, or more concretely, if the supporter can effectively identify the problem, comfort the user, and provide solutions or suggestions.\nThe ESC task has several sub-problems: (1) Support strategy selection and strategy-constrained response generation. As shown in our later experiments (Section 6.4), the timing of applying strategies is relevant to the effectiveness of ES. It is thus important that a generated response conforms to a\nspecified strategy. (2) Emotion state modeling. It is important to model and track the user’s emotion state dynamically, both for dynamic strategy selection and for measuring the effectiveness of ESC. (3) Evaluation of support effectiveness. In addition to the traditional dimension of evaluating a conversation’s relevance, coherence, and user engagement, ESC raises a new dimension of evaluating the effectiveness of ES."
    }, {
      "heading" : "3.2 ESC Framework",
      "text" : "We present an ESC Framework, which characterizes the procedure of emotional support into three stages, each with several suggested support strategies. We ground the ESC Framework on Hill’s Helping Skills Theory (Hill, 2009) and adapt it more appropriate for a dialog system setting, aiming to provide support through social interactions (like the interactions between peers, friends, or families) rather than merely professional counseling. An overview of the conversational stages and strategies in the ESC Framework is shown in Figure 3. Stages Hill (2009) proposes three stages of supporting people: exploration (exploring to help the help-seeker identify the problems), insight (helping the help-seeker move to new depths of selfunderstanding), and action (helping the help-seeker make decisions on actions to cope with the problems). However, we note that insight usually requires re-interpreting users’ behaviors and feelings, which is both difficult and risky for the supporters without sufficient support experience. We thus adapt insight to comforting (defined as provid-\ning support through empathy and understanding). While it is suggested that emotional support conversations target these three ordered stages, in practice conversations cannot follow a fixed or linear order and must adapt appropriately. As suggested in (Hill, 2009), the three stages can be flexibly adjusted to meet the help-seeker’s needs. Strategies Hill (2009) also provides several recommended conversational skills for each stage. Some of the described skills are not appropriate2 in a dialog system setting without professional supervision and experience. To adapt these skills appropriate to the dialog system setting, we extract seven methods from these skills (along with an “Others” one), which we called strategies in our task and hereafter. We provide a detailed definition of each strategy in Appendix B."
    }, {
      "heading" : "4 Data Collection",
      "text" : "To facilitate the research of emotional support skills in dialog systems, we introduce an Emotional Support Conversation Dataset, ESConv, which is collected in a help-seeker and supporter mode with crowdworkers. As high-quality conversation examples are needed for this complex task, we took tremendous effort to try to ensure the effectiveness of ES in conversations. Our efforts included the following major aspects: (1) Because providing conversational support is a skill that must be trained\n2For instance, one skill named challenging refers to pointing out the discrepancies or irrational beliefs that the helpseeker is unaware of or unwilling to change. Such skills usually require professional experience, which is too difficult for an average person.\nfor supporters to be effective (Burleson, 2003), we design a tutorial with the ESC Framework and train crowdworkers to be supporters. Only those who pass the examination are admitted to the task. (2) We require help-seekers to complete a pre-chat survey on their problems and emotions and to provide feedback during and after the conversations. (3) We devise and use multiple manual or automatic mechanisms to filter out the low-quality conversations after collecting raw dialog data."
    }, {
      "heading" : "4.1 Supporter-specific Tasks",
      "text" : "Training and Examination To teach crowdworkers how to provide effective emotional support, we designed a tutorial with the ESC Framework. Inspired by 7cups (7cups.com) (Baumel, 2015), we developed eleven sub-tasks (3 + 8) to help workers to learn the definitions of the three stages and the eight support strategies. Each sub-task includes an example conversation excerpt and a corresponding quiz question. As noted in Section 3.2, we also informed participants that following a fixed order may not be possible and that they may need to be flexible with adjusting the stage transitions. Strategy Annotation To encourage supporters to use the ESC support strategies during the conversation and to structure the resulting dataset, we ask the supporter to first select a proper strategy that they would like to use according to the dialog context. They are then able to write an utterance reflecting their selected strategy. We encourage supporters to send multiple messages if they would like to use multiple strategies to provide support. Post-chat Survey After each conversation, the supporter is asked to rate the extent that the seeker goes into detail about their problems on five-point Likert scales."
    }, {
      "heading" : "4.2 Seeker-specific Tasks",
      "text" : "Pre-chat Survey Before each conversation, the help-seeker was asked to complete the following survey: (1) Problem & emotion category: the helpseeker should select one problem from 5 options and one emotion from 7 options (the options were based on conversations collected in pilot data collection trials). (2) Emotion intensity: a score from 1 to 5 (the larger number indicates a more intense emotion). (3) Situation: open text describing the causes of the emotional problem. (4) Experience origin: whether the described situation was the current experience of the help-seeker or based on prior life circumstances. We found that 75.2% of conver-\nsations originated from the help-seekers’ current experiences. Feedback During the conversation, the helpseeker was asked to give feedback after every two new utterances they received from the supporter. Their feedback scored the helpfulness of the supporter messages on a 5-star scale. We divided each conversation into three phases and calculated the average feedback score for each phase. The scores in the three phases are 4.03, 4.30, and 4.44 respectively, indicating that the supporters were sufficiently trained to effectively help the help-seekers feel better. Post-chat Survey After each conversation, the help-seeker is asked to rate their emotion and the performance of the supporter on the following fivepoint Likert scales: (1) Their emotion intensity after the emotional support conversation (a decrease from the intensity before the conversation reflects emotion improvement), (2) the supporter’s empathy and understanding of the help-seeker’s experiences and feelings, and (3) the relevance of the supporter’s responses to the conversation topic."
    }, {
      "heading" : "4.3 Quality Control",
      "text" : "We use multiple methods to ensure that the corpus contains high-quality examples of effective emotional support conversations. Preliminary Filtering Mechanisms When recruiting participants for the supporter role, we initially received 5,449 applicants, but only 425 (7.8%) passed the training tutorial. From the 2,472 conversations that we initially collected, we filtered out those that were not finished by the help-seekers or that had fewer than 16 utterances. This filtering\nleft 1,342 conversations (54.3%) for consideration. Auto-approval Program for Qualified Conversations We carefully designed the auto-approval program, which is the most important part of data quality control. This program uses criteria based on the post-chat survey responses from both roles and the length of utterances, which are summarized in Table 1. These criteria are based on initial human reviewing results. We show how to choose these auto-approval criteria in Appendix D. The computed average emotion intensity before conversations is 4.04 and 2.14 after. Such improvement demonstrates the effectiveness of the emotional support provided by the supporters. In a small number of conversations, the help-seeker did not finish the post-chat surveys, so we added another criterion for these conversations requiring that the last two feedback scores from the help-seekers are both greater than 4. Thus, among all the conversations without post-chat surveys, only those who met both (2) and (3) were qualified. Using these quality criteria, 1,053 (78.5% of 1,342) of collected conversations were qualified. Annotation Correction To further ensure data quality, we reviewed and revised incorrect annotations of support strategy and seeker’s emotion intensity. (1) For strategy annotation correction, we asked new qualified supporters to review and revise annotations on previously collected conversations as necessary, which led to 2,545 utterances (17.1%) being reviewed. We manually reviewed annotations where more than 75% of reviewers disagreed and revised 139 of them. (2) According to the auto-approval criteria (Table 7), a conversation can be qualified when the score of the seeker’s emotion improvement is less than one, but the other three criteria are satisfied. Upon review, we found this to most often result from seekers mistaking negative emotion intensity as the positiveness of their emotion. We manually re-checked and revised the emotion intensity of these conversations by using other helpful information, such as the responses to the post-chat survey open question and the seekers’ feedback scores during the chat. Of 130 such conversations, 92% were revised and included in the corpus."
    }, {
      "heading" : "5 Data Characteristics",
      "text" : ""
    }, {
      "heading" : "5.1 Statistics",
      "text" : "The overall statistics of the 1,053 ESConv examples are shown in table 2. Relatively long conversations (avg. 29.8 utterances) indicate that providing\neffective ES usually requires many turns of interaction and considerably more turns than typical for previous emotional chatting (Zhou et al., 2018) or empathetic dialog (Rashkin et al., 2019) datasets.\nWe also present the statistics of other annotations in Table 3. Perhaps due to the current outbreak of COVID-19, ongoing depression and job crisis are the most commonly stated problems for the help-seekers and depression and anxiety are the most commonly noted emotions. From the helpseekers’ feedback, we found that they are usually highly satisfied with the emotional support, which further indicates that the training tutorial based on the ESC Framework indeed helps supporters learn to provide effective ES. We release all these annotations to facilitate further research."
    }, {
      "heading" : "5.2 Strategy Analysis",
      "text" : "Lexical Features We extracted lexical features of each strategy by calculating the log odds ratio, informative Dirichlet prior (Monroe et al., 2008) of all the unigrams and bigrams for each strategy contrasting to all other strategies. We list the top 5 phrases for each strategy in Figure 3. Those strategies are all significantly (z-score > 3) associated with certain phrases (e.g., Question with “are you”, Self-disclosure with “me”). Strategy Distribution We computed the distribution of strategies at different phases of the conversation. For a conversation with L utterances in total, the k-th (1 ≤ k ≤ L) utterance is from the supporter and adopts the strategy st, we say that it locates at the conversation progress k/L. Specifically, we split the conversation progress into six intervals: [0, 1] = ⋃4 i=0[i/5, (i+1)/5) ⋃ {1}. Then, for all the conversations in ESConv, we counted the proportions of different strategies in the six intervals. We split the conversation progress into six intervals: [0, 1] = ⋃4 i=0[i/5, (i + 1)/5) ⋃ {1} and drew the distributions on the six intervals at six points i/5(i = 0, . . . , 5) respectively and connected them, finally obtaining Figure 4.\nThe supporters generally follow the stage order suggested by the ESC Framework (Figure 3), but there is also flexible adjustment of stages and adoption of strategies. For instance, at the early phase of conversation, the supporters usually adopt exploratory strategies such as Question. After knowing help-seekers’ situations, the supporters tend to provide their opinions (such as Providing Suggestions). Throughout the entire conversation, the comforting strategies (such as Affirmation and Reassurance) are used and label a relatively constant proportion of messages. Strategy Transition We present the top-5 most frequent strategy transitions with 3 / 4 hops in Appendix (Table 6). These transitions indicate that,\nas the tutorial of ESC framework trains, supporters usually ask questions and explore the help-seekers’ situations before comforting the help-seekers."
    }, {
      "heading" : "6 Experiments",
      "text" : "Our experiments focus on two key questions: (1) How much can ESConv with strategy annotation improve state-of-the-art generative dialog models? (2) Can these models learn to provide effective emotional support from ESConv?"
    }, {
      "heading" : "6.1 Backbone Models",
      "text" : "We used two state-of-the-art pre-trained models as the backbones of the compared variant models: BlenderBot BlenderBot (Roller et al., 2020) is an open-domain conversational agent trained with multiple communication skills, including empathetic responding. As such, BlenderBot should be capable of providing ES for users to some extent. We used the small version3 of BlenderBot in experiments, because the larger versions have the limitation of maximum context length 128, which we found harms the model performance and response coherence. DialoGPT We additionally evaluated DialoGPT (Zhang et al., 2020), which is a GPT-2-based model pre-trained on large-scale dialog corpora. We used the small version4."
    }, {
      "heading" : "6.2 Variant Models",
      "text" : "Taking each of the above pre-trained models as the backbone, we built the following variant models: Vanilla Directly fine-tuning the backbone model on ESConv with no access to strategy annotations. Formally, suppose the flattened dialog history is x and the response to be generated is y, we maximize the conditional probability: P(y|x) =∏|y|\ni=1 P (yi|x,y≤i). Variants with strategy To incorporate the strategy annotation into the backbone model, we used a special token to represent each strategy. For each utterance y from the supporters, we appended the corresponding strategy token before this utterance: ỹ = [st] ⊕ y, where [st] denotes the special token of the used strategy. Then, taking the flattened dialog history x as input, the model generates the response conditioned on the first predicted (or designated) strategy token: P(ỹ|x) = P([st]|x) ∏|y| i=1 P (yi|x, [st],y<i).\n3https://huggingface.co/facebook/ BlenderBotbot_small-90M\n4https://huggingface.co/microsoft/ DialoGPT-small\nWe studied three variants that use strategy annotation in the later experiments. (1) Oracle: responses are generated conditioned on the gold reference strategy tokens. (2) Joint: responses are generated conditioned on predicted (sampled) strategy tokens. (3) Random: responses are generated conditioned on randomly selected strategies. Implementation details are in Appendix C."
    }, {
      "heading" : "6.3 Automatic Evaluation",
      "text" : "To investigate the impact of utilizing support strategies on the model performance with either BlenderBot or DialoGPT as the backbone, we compared the performance of the Vanilla, Joint, and Oracle variants described above. The automatic metrics we adopted include perplexity (PPL), BLEU-2 (B2) (Papineni et al., 2002), ROUGE-L (R-L) (Lin, 2004), and the BOW Embedding-based (Liu et al., 2016) Extrema matching score. The metrics except PPL were calculated with an NLG evaluation toolkit5 (Sharma et al., 2017) with responses tokenized by NLTK6 (Loper and Bird, 2002).\nThere are three major findings from the experiments (Table 4). (1) The Oracle models are significantly superior to the Vanilla models on all the metrics, indicating the great utility of support strategies. (2) The Joint models obtain sightly lower scores than the Vanilla models, as, if the predicted strategy is different from the ground truth, the generated response will be much different from the reference response. However, learning to predict strategies is important when there are no ground truth labels provided, and we will further investigate the performance of the Joint model in human interactive evaluation (Section 6.4). (3) The BlenderBot variants consistently perform better than the DialoGPT ones, indicating that BlenderBot is more suitable for the ESC task. Thus, in the subsequent human evaluation, we will focus evaluation on the Blender-\n5https://github.com/Maluuba/nlg-eval 6https://www.nltk.org/\nBot variants."
    }, {
      "heading" : "6.4 Human Interactive Evaluation",
      "text" : "We recruited participants from Amazon Mechanical Turk to chat with the models. The online tests were conducted on the same platform as our data collection, but with the role of supporter taken by a model. Each participant chatted with two different models that were randomly ordered to avoid exposure bias. Participants were asked to compare the two models based on the following questions: (1) Fluency: which bot’s responses were more fluent and understandable? (2) Identification: which bot explored your situation more in depth and was more helpful in identifying your problems? (3) Comforting: which bot was more skillful in comforting you? (4) Suggestion: which bot gave you more helpful suggestions for your problems? (5) Overall: generally, which bot’s emotional support do you prefer? The metrics in (2), (3), and (4) correspond to the three stages in the ESC Framework.\nWe compare three pairs of models: (a) Joint vs. BlenderBot (without fine-tuning on ESConv), (b) Joint vs. Vanilla, and (c) Joint vs. Random (using randomly selected strategies). To better simulate the real strategy occurrence, the Random model randomly selects a strategy following the strategy distribution in ESConv (Table 3).\nEach pair of models was compared by 100 conversations with human participants (Table 5). The results of comparison (a) show that BlenderBot’s capability of providing ES is significantly improved on all the metrics after being fine-tuned on ESConv. From comparison (b), we found that utilizing strategies can better comfort the users. The results of comparison (c) also demonstrate that the proper timing of strategies is critical to help users identify their problems and to provide effective suggestions. In general, through being fine-tuned with the su-\npervision of strategy prediction on ESConv, the pre-trained models become preferred by the users, which proves the high-quality and utility of ESConv."
    }, {
      "heading" : "6.5 Further Analysis of Human Interactive Evaluation",
      "text" : "In this section, we explore what the dialog models learned from ESConv. Firstly, we analyzed the strategy distribution based on the 300 dialogs between users and the Joint model in human interactive experiments. We can see in Figure 5 (the calculation was consistent with Figure 4), the strategies that the Joint model adopted have a very similar distribution compared with the truth distribution in ESConv (Figure 4). It provides important evidence that models mimic strategy selection and utilization as human supporters do to achieve more effective ES. Secondly, we present a case study in Figure 7. We see in cases that the Joint model provides more supportive responses and uses more skills in conversation, while BlenderBot without fine-tuning seems not to understand the user’s distress very well and prefers to talk more about itself. This may imply that having more supportive responses and a diverse set of support strategies are crucial to effective emotional support."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this work, we define the task of Emotional Support Conversation and present an ESC Framework. The ESC Framework is adapted from the Helping Skills Theory into a dialog system setting, which characterizes three stages with corresponding support strategies useful at each stage. We then construct an Emotional Support Conversation dataset, ESConv. We carefully design the process of data collection and devise multiple mechanisms to ensure the effectiveness of ES in conversations. Finally, we evaluate the ES ability with state-of-theart dialog models. Experimental results show the\npotential utility of ESConv in terms of improving dialog systems’ ability to provide effective ES. Our work can facilitate future research of ES dialog systems, as well as improve models for other conversation scenarios where emotional support plays an important role. Strategy selection and realization, user state modeling, and task evaluation are important directions for further research."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported by the NSFC projects (Key project with No. 61936010 and regular project with No. 61876096). This work was also supported by the Guoqiang Institute of Tsinghua University, with Grant No. 2019GQG1 and 2020GQG0005.\nEthical Considerations There are many types and levels of support that humans can seek to provide, e.g., professional versus peer support, and some of these levels may be inappropriate, unrealistic, and too risky for systems to deliver. However, as dialog systems become more common in daily use, opportunities will arise when at least some basic level of supportive statements may be required. In developing the ESC Framework, we have carefully considered which elements of conversational support may be relevant for a dialog system and omitted elements that are clear oversteps. Considerable additional work is needed to determine what are appropriate levels of support for systems to provide or that can be expected from systems, but our work provides a cautious, yet concrete, step towards developing systems capable of reasonably modest levels of support. The corpus we construct can also provide examples to enable future work that probes the ethical extent to which systems can or should provide support. In addition to these broader ethical considerations, we have sought to ethically conduct this study, including by transparently communicating with crowdworkers about data use and study intent, compensating workers at a reasonable hourly wage, and obtaining study approval from the Institutional Review Board."
    }, {
      "heading" : "A Data Example from ESConv",
      "text" : "Here we detail the conversation that Figure 1 demonstrates to show the annotations that our dataset contains. The detailed example can be seen in Figure 6. Each pre-chat survey of conversation is labeled its problem category, emotion category, emotion intensity, and a brief of the situation of the seeker. In the context of each conversation, the strategies used by supporters are labeled and the seeker’s feedback score per two utterances of the supporter’s responses are also given in our dataset. Note that not all conversations have the label of emotion intensity after the conversation. It is because some seekers don’t finish the post-chat survey but we still include such conversations into our dataset due to their high quality that meets our criteria."
    }, {
      "heading" : "B Definitions of Strategies",
      "text" : "Question Asking for information related to the problem to help the help-seeker articulate the issues that they face. Open-ended questions are best,\nand closed questions can be used to get specific information. Restatement or Paraphrasing A simple, more concise rephrasing of the help-seeker’s statements that could help them see their situation more clearly. Reflection of Feelings Articulate and describe the help-seeker’s feelings. Self-disclosure Divulge similar experiences that you have had or emotions that you share with the help-seeker to express your empathy. Affirmation and Reassurance Affirm the helpseeker’s strengths, motivation, and capabilities and provide reassurance and encouragement. Providing Suggestions Provide suggestions about how to change, but be careful to not overstep and tell them what to do. Information Provide useful information to the help-seeker, for example with data, facts, opinions, resources, or by answering questions. Others Exchange pleasantries and use other support strategies that do not fall into the above categories.\nC Implementation Details\nThe implementation of all models was based on Transformer library7 (Wolf et al., 2020). We split ESConv into the sets of training / validation / test with the proportions of 6:2:2. since the conversations in ESConv usually have long turns, we cut each dialog into conversation pieces with 5 utterances, which contain one supporter’s response and the preceding 4 utterances. During training, we trained all the models with Adam (Kingma and Ba, 2014) optimizer with learning rate 5e−5. All the models were trained for 5 epochs, and the check-\n7https://github.com/huggingface/ transformers\npoints with the lowest perplexity scores on the validation set were selected for evaluation. During inference, we masked other tokens and sampled a strategy token at the first position of the response. For the Random variant models, we sampled strategies randomly following the strategy distribution in ESConv, which is reported in Table 3. The response were decoded by Top-k and Top-p sampling with p = 0.9 (Holtzman et al., 2019), k = 30, temperature τ = 0.7, and the repetition penalty 1.03."
    }, {
      "heading" : "D Auto-Approval Criteria",
      "text" : "To establish each criterion of the auto-approval program as shown in the main paper (Section 3.4), we searched the most suitable thresholds for each filtering rule. We recruited three well-trained human annotators, who have also received the same training procedures as the supporter applicants did. We then randomly sampled 100 conversations from our dataset and asked the three annotators to judge whether the conversations are qualified for providing effective emotional support. Next, we utilized the post-survey results and the lengths of speaker utterances to choose suitable thresholds for filtering rules. We then treated each auto-filtering rule as a rule annotator and computed the Cohen’s Kappa (Cohen, 1960) score between the rule annotator and each human annotator.\nThe agreement scores in Table 7 are Cohen’s Kappa consistency among the agreement scores between each rule annotator and the three human annotators. We selected the thresholds that lead to the second-highest agreement score with human annotators and used these thresholds in the filtering rules. We didn’t use the set of thresholds that has the highest agreement score because the rule based on these thresholds is stricter so that many conversations would be filtered out. However, the second-highest score is only slightly lower than the highest so the rule based on the thresholds of second-highest score can remain more qualified conversations with little accepted cost. As a result, a qualified conversation requires that the supporter must meet at least three of all the four criteria, and the help-seeker must satisfy both of the two corresponding criteria. The final ’rule’ annotator combines the two conditions, and the averaged agreement score between the final rule annotator and the three human annotators is 0.576, indicating significant agreement.\nE Interface of Data Collection Platform\nTo facilitate readers to have an intuitive understanding of our data collection process, we present an interface diagram of some important steps in the data collection process in Figure 8, which contains the surfaces of support strategy training, supporter’s chatting, help-seeker’s pre-chat survey, help-seeker’s chatting, and post-survey.\nGreen background : utterances that corresponding to the used strategies. Yellow background : utterances where the model talks about itself and is not user-centered."
    } ],
    "references" : [ {
      "title" : "Online emotional support delivered by trained volunteers: users’ satisfaction and their perception of the service compared to psychotherapy",
      "author" : [ "Amit Baumel." ],
      "venue" : "Journal of Mental Health, 24(5):313– 320.",
      "citeRegEx" : "Baumel.,? 2015",
      "shortCiteRegEx" : "Baumel.",
      "year" : 2015
    }, {
      "title" : "Emotional support skill",
      "author" : [ "Brant R Burleson." ],
      "venue" : "HANDBOOK OF COMMUNICATION AND SOCIAL INTERACTION SKILLS, page 551.",
      "citeRegEx" : "Burleson.,? 2003",
      "shortCiteRegEx" : "Burleson.",
      "year" : 2003
    }, {
      "title" : "A coefficient of agreement for nominal scales",
      "author" : [ "Jacob Cohen." ],
      "venue" : "Educational and psychological measurement, 20(1):37–46.",
      "citeRegEx" : "Cohen.,? 1960",
      "shortCiteRegEx" : "Cohen.",
      "year" : 1960
    }, {
      "title" : "Social networks and social support",
      "author" : [ "Catherine A Heaney", "Barbara A Israel." ],
      "venue" : "Health behavior and health education: Theory, research, and practice, 4:189–210.",
      "citeRegEx" : "Heaney and Israel.,? 2008",
      "shortCiteRegEx" : "Heaney and Israel.",
      "year" : 2008
    }, {
      "title" : "Helping skills: Facilitating, exploration, insight, and action",
      "author" : [ "Clara E Hill." ],
      "venue" : "American Psychological Association.",
      "citeRegEx" : "Hill.,? 2009",
      "shortCiteRegEx" : "Hill.",
      "year" : 2009
    }, {
      "title" : "The curious case of neural text degeneration",
      "author" : [ "Ari Holtzman", "Jan Buys", "Li Du", "Maxwell Forbes", "Yejin Choi." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Holtzman et al\\.,? 2019",
      "shortCiteRegEx" : "Holtzman et al\\.",
      "year" : 2019
    }, {
      "title" : "It takes two to empathize: One to seek and one to provide",
      "author" : [ "Mahshid Hosseini", "Cornelia Caragea." ],
      "venue" : "Proceedings of the 35th American Association for Artificial Intelligence (AAAI 2021).",
      "citeRegEx" : "Hosseini and Caragea.,? 2021",
      "shortCiteRegEx" : "Hosseini and Caragea.",
      "year" : 2021
    }, {
      "title" : "Challenges in building intelligent open-domain dialog systems",
      "author" : [ "Minlie Huang", "Xiaoyan Zhu", "Jianfeng Gao." ],
      "venue" : "ACM Transactions on Information Systems (TOIS), 38(3):1–32.",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "Emotional dialogue generation using image-grounded language models",
      "author" : [ "Bernd Huber", "Daniel McDuff", "Chris Brockett", "Michel Galley", "Bill Dolan." ],
      "venue" : "Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, pages 1–12.",
      "citeRegEx" : "Huber et al\\.,? 2018",
      "shortCiteRegEx" : "Huber et al\\.",
      "year" : 2018
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "arXiv preprint arXiv:1412.6980.",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Social support: a conceptual analysis",
      "author" : [ "Catherine Penny Hinson Langford", "Juanita Bowsher", "Joseph P Maloney", "Patricia P Lillis." ],
      "venue" : "Journal of advanced nursing, 25(1):95–100.",
      "citeRegEx" : "Langford et al\\.,? 1997",
      "shortCiteRegEx" : "Langford et al\\.",
      "year" : 1997
    }, {
      "title" : "DailyDialog: A manually labelled multi-turn dialogue dataset",
      "author" : [ "Yanran Li", "Hui Su", "Xiaoyu Shen", "Wenjie Li", "Ziqiang Cao", "Shuzi Niu." ],
      "venue" : "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Pa-",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "ROUGE: A package for automatic evaluation of summaries",
      "author" : [ "Chin-Yew Lin." ],
      "venue" : "Text Summarization Branches Out, pages 74–81, Barcelona, Spain. Association for Computational Linguistics.",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "MoEL: Mixture of empathetic listeners",
      "author" : [ "Zhaojiang Lin", "Andrea Madotto", "Jamin Shin", "Peng Xu", "Pascale Fung." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Lin et al\\.,? 2019",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2019
    }, {
      "title" : "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
      "author" : [ "Chia-Wei Liu", "Ryan Lowe", "Iulian Serban", "Mike Noseworthy", "Laurent Charlin", "Joelle Pineau." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Liu et al\\.,? 2016",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2016
    }, {
      "title" : "Nltk: the natural language toolkit",
      "author" : [ "Edward Loper", "Steven Bird." ],
      "venue" : "arXiv preprint cs/0205028.",
      "citeRegEx" : "Loper and Bird.,? 2002",
      "shortCiteRegEx" : "Loper and Bird.",
      "year" : 2002
    }, {
      "title" : "MIME: MIMicking emotions for empathetic response generation",
      "author" : [ "Navonil Majumder", "Pengfei Hong", "Shanshan Peng", "Jiankun Lu", "Deepanway Ghosal", "Alexander Gelbukh", "Rada Mihalcea", "Soujanya Poria." ],
      "venue" : "Proceedings of the 2020 Con-",
      "citeRegEx" : "Majumder et al\\.,? 2020",
      "shortCiteRegEx" : "Majumder et al\\.",
      "year" : 2020
    }, {
      "title" : "Using crowdsourcing for the development of online emotional support agents",
      "author" : [ "Lenin Medeiros", "Tibor Bosse." ],
      "venue" : "International Conference on Practical Applications of Agents and Multi-Agent Systems, pages 196–209. Springer.",
      "citeRegEx" : "Medeiros and Bosse.,? 2018",
      "shortCiteRegEx" : "Medeiros and Bosse.",
      "year" : 2018
    }, {
      "title" : "Fightin’words: Lexical feature selection and evaluation for identifying the content of political conflict",
      "author" : [ "Burt L Monroe", "Michael P Colaresi", "Kevin M Quinn." ],
      "venue" : "Political Analysis, 16(4):372–403.",
      "citeRegEx" : "Monroe et al\\.,? 2008",
      "shortCiteRegEx" : "Monroe et al\\.",
      "year" : 2008
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia,",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "OpenAI blog, 1(8):9.",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Support seeker expectations, support message quality, and supportive interaction processes and outcomes: The case of the comforting computer program revis",
      "author" : [ "Stephen A Rains", "Corey A Pavlich", "Bethany Lutovsky", "Eric Tsetsi", "Anjali Ashtaputre" ],
      "venue" : null,
      "citeRegEx" : "Rains et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Rains et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards empathetic opendomain conversation models: A new benchmark and dataset",
      "author" : [ "Hannah Rashkin", "Eric Michael Smith", "Margaret Li", "Y-Lan Boureau." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguis-",
      "citeRegEx" : "Rashkin et al\\.,? 2019",
      "shortCiteRegEx" : "Rashkin et al\\.",
      "year" : 2019
    }, {
      "title" : "Recipes for building an open-domain chatbot",
      "author" : [ "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Eric M Smith" ],
      "venue" : "arXiv preprint arXiv:2004.13637",
      "citeRegEx" : "Roller et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Roller et al\\.",
      "year" : 2020
    }, {
      "title" : "A computational approach to understanding empathy expressed in text-based mental health support",
      "author" : [ "Ashish Sharma", "Adam Miner", "David Atkins", "Tim Althoff." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Sharma et al\\.,? 2020a",
      "shortCiteRegEx" : "Sharma et al\\.",
      "year" : 2020
    }, {
      "title" : "A computational approach to understanding empathy expressed in text-based mental health support",
      "author" : [ "Ashish Sharma", "Adam S Miner", "David C Atkins", "Tim Althoff." ],
      "venue" : "arXiv preprint arXiv:2009.08441.",
      "citeRegEx" : "Sharma et al\\.,? 2020b",
      "shortCiteRegEx" : "Sharma et al\\.",
      "year" : 2020
    }, {
      "title" : "Relevance of unsupervised metrics in task-oriented dialogue for evaluating natural language generation",
      "author" : [ "Shikhar Sharma", "Layla El Asri", "Hannes Schulz", "Jeremie Zumer." ],
      "venue" : "arXiv preprint arXiv:1706.09799.",
      "citeRegEx" : "Sharma et al\\.,? 2017",
      "shortCiteRegEx" : "Sharma et al\\.",
      "year" : 2017
    }, {
      "title" : "Counseling-style reflection generation using generative pretrained transformers with augmented context",
      "author" : [ "Siqi Shen", "Charles Welch", "Rada Mihalcea", "Verónica Pérez-Rosas." ],
      "venue" : "Proceedings of the 21th Annual Meeting of the Special Interest",
      "citeRegEx" : "Shen et al\\.,? 2020",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2020
    }, {
      "title" : "Psyqa: A chinese dataset for generating long counseling text for mental health support",
      "author" : [ "Hao Sun", "Zhenru Lin", "Chujie Zheng", "Siyang Liu", "Minlie Huang." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL 2021.",
      "citeRegEx" : "Sun et al\\.,? 2021",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2021
    }, {
      "title" : "A conversation model enabling intelligent agents to give emotional support",
      "author" : [ "Janneke M van der Zwaan", "Virginia Dignum", "Catholijn M Jonker." ],
      "venue" : "Modern Advances in Intelligent Systems and Tools, pages 47–52. Springer.",
      "citeRegEx" : "Zwaan et al\\.,? 2012",
      "shortCiteRegEx" : "Zwaan et al\\.",
      "year" : 2012
    }, {
      "title" : "A bdi dialogue agent for social support: Specification and evaluation method",
      "author" : [ "JM Van der Zwaan", "V Dignum", "CM Jonker." ],
      "venue" : "AAMAS 2012: Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems, Workshop",
      "citeRegEx" : "Zwaan et al\\.,? 2012",
      "shortCiteRegEx" : "Zwaan et al\\.",
      "year" : 2012
    }, {
      "title" : "Expressive interviewing: A conversational system for coping with COVID-19",
      "author" : [ "Charles Welch", "Allison Lahnala", "Veronica Perez-Rosas", "Siqi Shen", "Sarah Seraj", "Larry An", "Kenneth Resnicow", "James Pennebaker", "Rada Mihalcea." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Welch et al\\.,? 2020",
      "shortCiteRegEx" : "Welch et al\\.",
      "year" : 2020
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander Rush." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    }, {
      "title" : "Emptransfo: A multi-head transformer architecture for creating empathetic dialog systems",
      "author" : [ "Rohola Zandie", "Mohammad H Mahoor." ],
      "venue" : "arXiv preprint arXiv:2003.02958.",
      "citeRegEx" : "Zandie and Mahoor.,? 2020",
      "shortCiteRegEx" : "Zandie and Mahoor.",
      "year" : 2020
    }, {
      "title" : "DIALOGPT : Largescale generative pre-training for conversational response generation",
      "author" : [ "Yizhe Zhang", "Siqi Sun", "Michel Galley", "Yen-Chun Chen", "Chris Brockett", "Xiang Gao", "Jianfeng Gao", "Jingjing Liu", "Bill Dolan." ],
      "venue" : "Proceedings of the 58th An-",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Comae: A multi-factor hierarchical framework for empathetic response generation",
      "author" : [ "Chujie Zheng", "Yong Liu", "Wei Chen", "Yongcai Leng", "Minlie Huang." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL 2021.",
      "citeRegEx" : "Zheng et al\\.,? 2021",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2021
    }, {
      "title" : "Towards persona-based empathetic conversational models",
      "author" : [ "Peixiang Zhong", "Chen Zhang", "Hao Wang", "Yong Liu", "Chunyan Miao." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages",
      "citeRegEx" : "Zhong et al\\.,? 2020",
      "shortCiteRegEx" : "Zhong et al\\.",
      "year" : 2020
    }, {
      "title" : "Emotional chatting machine: Emotional conversation generation with internal and external memory",
      "author" : [ "Hao Zhou", "Minlie Huang", "Tianyang Zhang", "Xiaoyan Zhu", "Bing Liu." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Zhou et al\\.,? 2018",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    }, {
      "title" : "The design and implementation of xiaoice, an empathetic social chatbot",
      "author" : [ "Li Zhou", "Jianfeng Gao", "Di Li", "Heung-Yeung Shum." ],
      "venue" : "Computational Linguistics, 46(1):53–93.",
      "citeRegEx" : "Zhou et al\\.,? 2020",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2020
    }, {
      "title" : "MojiTalk: Generating emotional responses at scale",
      "author" : [ "Xianda Zhou", "William Yang Wang." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1128–1137, Melbourne, Aus-",
      "citeRegEx" : "Zhou and Wang.,? 2018",
      "shortCiteRegEx" : "Zhou and Wang.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "In this paper, we define the Emotional Support Conversation (ESC) task and propose an ESC Framework, which is grounded on the Helping Skills Theory (Hill, 2009).",
      "startOffset" : 148,
      "endOffset" : 160
    }, {
      "referenceID" : 1,
      "context" : "Emotional support (ES) aims at reducing individuals’ emotional distress and helping them understand and work through the challenges that they face (Burleson, 2003; Langford et al., 1997; Heaney and Israel, 2008).",
      "startOffset" : 147,
      "endOffset" : 211
    }, {
      "referenceID" : 10,
      "context" : "Emotional support (ES) aims at reducing individuals’ emotional distress and helping them understand and work through the challenges that they face (Burleson, 2003; Langford et al., 1997; Heaney and Israel, 2008).",
      "startOffset" : 147,
      "endOffset" : 211
    }, {
      "referenceID" : 3,
      "context" : "Emotional support (ES) aims at reducing individuals’ emotional distress and helping them understand and work through the challenges that they face (Burleson, 2003; Langford et al., 1997; Heaney and Israel, 2008).",
      "startOffset" : 147,
      "endOffset" : 211
    }, {
      "referenceID" : 38,
      "context" : "on daily basis (Van der Zwaan et al., 2012; Zhou et al., 2020), particularly for settings that include social interactions (accompanying and cheering up the user), mental health support (comforting a frustrated help-seeker and helping identify the problem), customer service chats (appeasing an angry customer and providing solutions), etc.",
      "startOffset" : 15,
      "endOffset" : 62
    }, {
      "referenceID" : 21,
      "context" : "Recent research has also shown that people prefer dialog systems that can provide more supportive responses (Rains et al., 2020).",
      "startOffset" : 108,
      "endOffset" : 128
    }, {
      "referenceID" : 1,
      "context" : "Research has shown that providing emotional support is not intuitive (Burleson, 2003), so procedures and conversational skills have been suggested (Hill, 2009) to help provide better support through conversation.",
      "startOffset" : 69,
      "endOffset" : 85
    }, {
      "referenceID" : 4,
      "context" : "Research has shown that providing emotional support is not intuitive (Burleson, 2003), so procedures and conversational skills have been suggested (Hill, 2009) to help provide better support through conversation.",
      "startOffset" : 147,
      "endOffset" : 159
    }, {
      "referenceID" : 37,
      "context" : "First, existing research systems that relate to emotional chatting (Zhou et al., 2018)",
      "startOffset" : 67,
      "endOffset" : 86
    }, {
      "referenceID" : 22,
      "context" : "or empathetic responding (Rashkin et al., 2019) return messages that are examples of emotion or empathy and are thus limited in functionality, as they are not capable of many other skills that are often used to provide effective ES (Hill, 2009).",
      "startOffset" : 25,
      "endOffset" : 47
    }, {
      "referenceID" : 4,
      "context" : ", 2019) return messages that are examples of emotion or empathy and are thus limited in functionality, as they are not capable of many other skills that are often used to provide effective ES (Hill, 2009).",
      "startOffset" : 192,
      "endOffset" : 204
    }, {
      "referenceID" : 24,
      "context" : "Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations.",
      "startOffset" : 66,
      "endOffset" : 148
    }, {
      "referenceID" : 22,
      "context" : "Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations.",
      "startOffset" : 66,
      "endOffset" : 148
    }, {
      "referenceID" : 36,
      "context" : "Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations.",
      "startOffset" : 66,
      "endOffset" : 148
    }, {
      "referenceID" : 28,
      "context" : "Without trained individuals, existing online conversation datasets(Sharma et al., 2020a; Rashkin et al., 2019; Zhong et al., 2020; Sun et al., 2021) do not naturally exhibit examples or elements of supportive conversations.",
      "startOffset" : 66,
      "endOffset" : 148
    }, {
      "referenceID" : 20,
      "context" : "As a result, data-driven models that leverage such corpora (Radford et al., 2019; Zhang et al., 2020; Roller et al., 2020) are limited in their ability to explicitly learn how to utilize support skills and thus provide effective ES.",
      "startOffset" : 59,
      "endOffset" : 122
    }, {
      "referenceID" : 34,
      "context" : "As a result, data-driven models that leverage such corpora (Radford et al., 2019; Zhang et al., 2020; Roller et al., 2020) are limited in their ability to explicitly learn how to utilize support skills and thus provide effective ES.",
      "startOffset" : 59,
      "endOffset" : 122
    }, {
      "referenceID" : 23,
      "context" : "As a result, data-driven models that leverage such corpora (Radford et al., 2019; Zhang et al., 2020; Roller et al., 2020) are limited in their ability to explicitly learn how to utilize support skills and thus provide effective ES.",
      "startOffset" : 59,
      "endOffset" : 122
    }, {
      "referenceID" : 37,
      "context" : "Figure 2: Emotional support conversations (our work) can include elements of emotional chatting (Zhou et al., 2018) and empathetic responding(Rashkin et al.",
      "startOffset" : 96,
      "endOffset" : 115
    }, {
      "referenceID" : 4,
      "context" : "support through social interactions (like the interactions between peers, friends, or families) rather than professional counseling, and propose an ESC Framework, which is grounded on the Helping Skills Theory (Hill, 2009) and tailored to be appropriate for a dialog system setting (Figure 3).",
      "startOffset" : 210,
      "endOffset" : 222
    }, {
      "referenceID" : 37,
      "context" : "3471 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 149
    }, {
      "referenceID" : 11,
      "context" : "3471 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 149
    }, {
      "referenceID" : 39,
      "context" : "3471 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 149
    }, {
      "referenceID" : 8,
      "context" : "3471 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 149
    }, {
      "referenceID" : 7,
      "context" : "3471 tant for building more engaging dialog systems (Zhou et al., 2018; Li et al., 2017; Zhou and Wang, 2018; Huber et al., 2018; Huang et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 149
    }, {
      "referenceID" : 22,
      "context" : "Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accord-",
      "startOffset" : 46,
      "endOffset" : 196
    }, {
      "referenceID" : 13,
      "context" : "Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accord-",
      "startOffset" : 46,
      "endOffset" : 196
    }, {
      "referenceID" : 16,
      "context" : "Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accord-",
      "startOffset" : 46,
      "endOffset" : 196
    }, {
      "referenceID" : 33,
      "context" : "Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accord-",
      "startOffset" : 46,
      "endOffset" : 196
    }, {
      "referenceID" : 24,
      "context" : "Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accord-",
      "startOffset" : 46,
      "endOffset" : 196
    }, {
      "referenceID" : 36,
      "context" : "Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accord-",
      "startOffset" : 46,
      "endOffset" : 196
    }, {
      "referenceID" : 35,
      "context" : "Another related task is empathetic responding (Rashkin et al., 2019; Lin et al., 2019; Majumder et al., 2020; Zandie and Mahoor, 2020; Sharma et al., 2020a; Zhong et al., 2020; Zheng et al., 2021), which aims at understanding users’ feelings and then replying accord-",
      "startOffset" : 46,
      "endOffset" : 196
    }, {
      "referenceID" : 17,
      "context" : "Various works have considered conversations of emotional support in a social context, such as on social media or online forums (Medeiros and Bosse, 2018; Sharma et al., 2020b; Hosseini and Caragea, 2021).",
      "startOffset" : 127,
      "endOffset" : 203
    }, {
      "referenceID" : 25,
      "context" : "Various works have considered conversations of emotional support in a social context, such as on social media or online forums (Medeiros and Bosse, 2018; Sharma et al., 2020b; Hosseini and Caragea, 2021).",
      "startOffset" : 127,
      "endOffset" : 203
    }, {
      "referenceID" : 6,
      "context" : "Various works have considered conversations of emotional support in a social context, such as on social media or online forums (Medeiros and Bosse, 2018; Sharma et al., 2020b; Hosseini and Caragea, 2021).",
      "startOffset" : 127,
      "endOffset" : 203
    }, {
      "referenceID" : 25,
      "context" : "In (Sharma et al., 2020b), the post-response pairs from TalkLife and mental health subreddits are annotated with the communication mechanisms of text-based empathy expression (only the data of the Reddit part is publicly available).",
      "startOffset" : 3,
      "endOffset" : 25
    }, {
      "referenceID" : 4,
      "context" : "The dialogues in these corpora are either single-turn interactions (post-response pair) or very short conversations, which limits the potential for effective ES, as ES often requires many turns of interaction (Hill, 2009).",
      "startOffset" : 209,
      "endOffset" : 221
    }, {
      "referenceID" : 17,
      "context" : "A recent system has considered a rule-based algorithm that determines the supportive act used in the response and then selects proper replies from the pre-defined list of candidates (Medeiros and Bosse, 2018).",
      "startOffset" : 182,
      "endOffset" : 208
    }, {
      "referenceID" : 31,
      "context" : "Another conversational system designed to provide support for coping with COVID-19 was implemented by identifying topics that users mentioned and then responding with a reflection from a template or a message from a pre-defined lexicon (Welch et al., 2020).",
      "startOffset" : 236,
      "endOffset" : 256
    }, {
      "referenceID" : 18,
      "context" : "Each feature is ranked by the rounded z-scored log odds ratios (Monroe et al., 2008) in the parentheses.",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 4,
      "context" : "We ground the ESC Framework on Hill’s Helping Skills Theory (Hill, 2009) and adapt it more appropriate for a dialog system setting, aiming to provide support through social interactions (like the interactions between peers, friends, or families) rather than merely professional counseling.",
      "startOffset" : 60,
      "endOffset" : 72
    }, {
      "referenceID" : 4,
      "context" : "As suggested in (Hill, 2009), the three stages can be flexibly adjusted to meet the help-seeker’s needs.",
      "startOffset" : 16,
      "endOffset" : 28
    }, {
      "referenceID" : 1,
      "context" : "3473 for supporters to be effective (Burleson, 2003), we design a tutorial with the ESC Framework and train crowdworkers to be supporters.",
      "startOffset" : 36,
      "endOffset" : 52
    }, {
      "referenceID" : 0,
      "context" : "com) (Baumel, 2015), we developed eleven sub-tasks (3 + 8) to help workers to learn the definitions of the three stages and the eight support strategies.",
      "startOffset" : 5,
      "endOffset" : 19
    }, {
      "referenceID" : 37,
      "context" : "effective ES usually requires many turns of interaction and considerably more turns than typical for previous emotional chatting (Zhou et al., 2018) or empathetic dialog (Rashkin et al.",
      "startOffset" : 129,
      "endOffset" : 148
    }, {
      "referenceID" : 22,
      "context" : ", 2018) or empathetic dialog (Rashkin et al., 2019) datasets.",
      "startOffset" : 29,
      "endOffset" : 51
    }, {
      "referenceID" : 18,
      "context" : "Lexical Features We extracted lexical features of each strategy by calculating the log odds ratio, informative Dirichlet prior (Monroe et al., 2008) of all the unigrams and bigrams for each strategy contrasting to all other strategies.",
      "startOffset" : 127,
      "endOffset" : 148
    }, {
      "referenceID" : 23,
      "context" : "We used two state-of-the-art pre-trained models as the backbones of the compared variant models: BlenderBot BlenderBot (Roller et al., 2020) is an open-domain conversational agent trained with multiple communication skills, including empathetic responding.",
      "startOffset" : 119,
      "endOffset" : 140
    }, {
      "referenceID" : 34,
      "context" : "DialoGPT We additionally evaluated DialoGPT (Zhang et al., 2020), which is a GPT-2-based model pre-trained on large-scale dialog corpora.",
      "startOffset" : 44,
      "endOffset" : 64
    }, {
      "referenceID" : 19,
      "context" : "The automatic metrics we adopted include perplexity (PPL), BLEU-2 (B2) (Papineni et al., 2002), ROUGE-L (R-L) (Lin, 2004), and the BOW Embedding-based (Liu et al.",
      "startOffset" : 71,
      "endOffset" : 94
    }, {
      "referenceID" : 12,
      "context" : ", 2002), ROUGE-L (R-L) (Lin, 2004), and the BOW Embedding-based (Liu et al.",
      "startOffset" : 23,
      "endOffset" : 34
    }, {
      "referenceID" : 14,
      "context" : ", 2002), ROUGE-L (R-L) (Lin, 2004), and the BOW Embedding-based (Liu et al., 2016) Extrema matching score.",
      "startOffset" : 64,
      "endOffset" : 82
    }, {
      "referenceID" : 26,
      "context" : "The metrics except PPL were calculated with an NLG evaluation toolkit5 (Sharma et al., 2017) with responses tokenized by NLTK6 (Loper and Bird, 2002).",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 15,
      "context" : ", 2017) with responses tokenized by NLTK6 (Loper and Bird, 2002).",
      "startOffset" : 42,
      "endOffset" : 64
    } ],
    "year" : 2021,
    "abstractText" : "Emotional support is a crucial ability for many conversation scenarios, including social interactions, mental health support, and customer service chats. Following reasonable procedures and using various support skills can help to effectively provide support. However, due to the lack of a well-designed task and corpora of effective emotional support conversations, research on building emotional support into dialog systems remains untouched. In this paper, we define the Emotional Support Conversation (ESC) task and propose an ESC Framework, which is grounded on the Helping Skills Theory (Hill, 2009). We construct an Emotion Support Conversation dataset (ESConv) with rich annotation (especially support strategy) in a help-seeker and supporter mode. To ensure a corpus of high-quality conversations that provide examples of effective emotional support, we take extensive effort to design training tutorials for supporters and several mechanisms for quality control during data collection. Finally, we evaluate state-of-the-art dialog models with respect to the ability to provide emotional support. Our results show the importance of support strategies in providing effective emotional support and the utility of ESConv in training more emotional support systems 1.",
    "creator" : "LaTeX with hyperref"
  }
}