{
  "name" : "2021.acl-long.129.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Changes in European Solidarity Before and During COVID-19: Evidence from a Large Crowd- and Expert-Annotated Twitter Dataset",
    "authors" : [ "Alexandra Ils", "Dan Liu", "Daniela Grunow", "Steffen Eger" ],
    "emails" : [ "ils@soz.uni-frankfurt.de,", "grunow@soz.uni-frankfurt.de,", "dan.liu.19@stud.tu-darmstadt.de,", "eger@aiphes.tu-darmstadt.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1623–1637\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n1623"
    }, {
      "heading" : "1 Introduction",
      "text" : "Social solidarity statements and other forms of collective pro-social behavior expressed in online media have been argued to affect public opinion and political mobilization (Fenton, 2008; Margolin and Liao, 2018; Santhanam et al., 2019; Tufekci, 2014). The ubiquity of social media enables individuals to feel and relate to real-world problems through\nsolidarity statements expressed online and to act accordingly (Fenton, 2008). Social solidarity is a key feature that keeps modern societies integrated, functioning and cohesive. It constitutes a moral and normative bond between individuals and society, affecting people’s willingness to help others and share own resources beyond immediate rational individually-, group- or class-based interests (Silver, 1994). National and international crises intensify the need for social solidarity, as crises diminish the resources available, raise demand for new and additional resources, and/or require readjustment of established collective redistributive patterns, e.g. inclusion of new groups. Because principles of inclusion and redistribution are contested in modern societies and related opinions fragmented (Fenton, 2008; Sunstein, 2018), collective expressions of social solidarity online are likely contested. Such statements, which we refer to as anti-solidarity, question calls for social solidarity and its framing, i.e. towards whom individuals should show solidarity, and in what ways (Wallaschek, 2019).\nFor a long time, social solidarity was considered to be confined to local, national or cultural groups. The concept of a European society and European solidarity (Gerhards et al., 2019), a form of solidarity that goes beyond the nation state, is rather new. European solidarity gained relevance with the rise and expansion of the European Union (EU) and its legislative and administrative power vis-à-vis the EU member states since the 1950s (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018). After decades of increasing European integration and institutionalization, the EU entered into a continued succession of deep crises, beginning with the European Financial Crisis in 2010 (Gerhards et al., 2019). Experiences of recurring European crises raise concerns regarding the future of European society and its foundation, European solidarity. Eurosceptics\nand right-wing populists claim that social solidarity is, and should be, confined within the nation state, whereas supporters of the European project see European solidarity as a means to overcome the great challenges imposed on EU countries and its citizens today (Gerhards et al., 2019). To date, it is an open empirical question how strong and contested social solidarity really is in Europe, and how it has changed since the onset of the COVID19 pandemic. Against this background, we ask whether we can detect changes in the debates on European solidarity before and after the outbreak of COVID-19. Our contributions are:\n(i) We provide a novel Twitter corpus annotated for expressions of social solidarity and antisolidarity. Our corpus contains 2.3k humanlabeled tweets from two annotation strategies (experts vs. crowds). Moreover, we provide over 270k automatically labeled tweets based on an ensemble of BERT classifiers trained on the expert and crowd annotations.\n(ii) We train BERT on crowd- and expert annotations using multiple data augmentation and transfer learning approaches, achieving over 25 points improvement over BERT trained on expert annotations alone.\n(iii) We present novel empirical evidence regarding changes in European solidarity debates before and after the outbreak of the COVID-19 pandemic. Our findings show that both expressed solidarity and anti-solidarity escalated with the occurrence of incisive political events, such as the onset of the first European lockdowns.\nOur data and code are available from https://github.com/lalashiwoya/ socialsolidarityCOVID19."
    }, {
      "heading" : "2 Related work",
      "text" : "Social Solidarity in the Social Sciences. In the social sciences, social solidarity has always been a key topic of intellectual thought and empirical investigation, dating back to seminal thinkers such as Rousseau and Durkheim (Silver, 1994). Whereas earlier empirical research was mostly confined to survey-based (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018) or qualitative approaches (Franceschelli, 2019; Gómez Garrido et al., 2018; Heimann et al., 2019), computational social science just started tackling concepts as complex as solidarity as part\nof natural language processing (NLP) approaches (Santhanam et al., 2019).\nIn (computational) social science, several studies investigated the European Migration Crisis and/or the Financial Crisis as displayed in media discourses. These studies focused on differences in perspectives and narratives between mainstream media and Twitter, using topic models (Nerghes and Lee, 2019), and the coverage and kinds of solidarity addressed in leftist and conservative newspaper media (Wallaschek, 2019, 2020a), as well as relevant actors in discourses on solidarity, using discourse network measures (Wallaschek, 2020b). While these studies offer insight into solidarity discourses during crises, they all share a strong focus on mainstream media, which is unlikely to publicly reject solidarity claims (Wallaschek, 2019). Social media, in contrast, allows its users to perpetuate, challenge and open new perspectives on mainstream narratives (Nerghes and Lee, 2019). A first attempt to study solidarity expressed by social media users during crises has been presented by Santhanam et al. (2019). They assessed how emojis are used in tweets expressing solidarity relating to two crises through hashtag-based manual annotation— ignoring actual content of the tweets—and utilizing a LSTM network for automatic classification. Their approach, while insightful, provides a rather simple operationalization of solidarity, which neglects its contested, consequential and obligatory aspects vis-à-vis other social groups.\nThe current state of social science research on European social solidarity poses a puzzle. On the one hand, most survey research paints a rather optimistic view regarding social solidarity in the EU, despite marked cross-national variation (Binner and Scherschel, 2019; Dragolov et al., 2016; Gerhards et al., 2019; Lahusen and Grasso, 2018). On the other hand, the rise of political polarization and Eurosceptic political parties (Baker et al., 2020; Nicoli, 2017) suggests that the opinions, orientations and fears of a potentially growing political minority is underrepresented in this research. People holding extreme opinions have been found to be reluctant to participate in surveys and adopt their survey-responses to social norms (social desirability bias) (Bazo Vienrich and Creighton, 2017; Heerwegh, 2009; Janus, 2010). Research indicates that such minorities may grow in times of crises, with both short-term and long-term effects for public opinion and political trust (Gangl and Giustozzi,\n2018; Nicoli, 2017). Our paper addresses these problems by drawing on large volumes of longitudinal social media data that reflect potential fragmentation of political opinion (Sunstein, 2018) and its change over time. Our approach will thus uncover how contested European solidarity is and how it developed since the onset of COVID-19.\nEmotion and Sentiment Classification in NLP. In NLP, annotating and classifying text (in social media) for sentiment or emotions is a wellestablished task (Demszky et al., 2020; Ding et al., 2020; Haider et al., 2020; Hutto and Gilbert, 2014; Oberländer and Klinger, 2018). Importantly, our approach focuses on expressions of (anti)solidarity: For example, texts containing a positive sentiment towards persons, groups or organizations which are at their core anti-European, nationalistic and excluding reflect anti-solidarity and are annotated as such. Our annotations therefore go beyond superficial assessment of sentiment. In fact, the correlation between sentiment labels—e.g., as obtained from Vader (Hutto and Gilbert, 2014)—and our annotations in §3 is only ∼0.2. Specifically, many tweets labeled as solidarity use negatively connoted emotion words."
    }, {
      "heading" : "3 Data and Annotations",
      "text" : "We use the unforeseen onset of the COVID-19 crisis, beginning with the first European lockdown, enacted late February to early March 2020, to analyze and compare social solidarity data before and during the COVID-19 crisis as if it were a natural experiment (Creighton et al., 2015; Kuntz et al., 2017). In order to utilize this strategy and keep the baseline solidarity debate comparable before and after the onset of the COVID-19 crisis, we confined our sample to tweets with hashtags predominantly relating to two previous European crises whose effects continue to concern Europe, its member states and citizens: (i) Migration and the distribution of refugees among European member states, and (ii) Financial solidarity, i.e. financial support for indebted EU countries. The former solidarity debate predominantly refers to the Refugee Crisis since 2015 and the living situation of migrants, the latter mostly relates to the Financial Crisis, followed by the Euro Crisis, and concerns the excessive indebtedness of some EU countries since 2010.1\n1Further analyses (not shown) revealed that around 20 percent of the tweets in our sample relate to solidarity regarding other issues.\nData. We crawled 271,930 tweets between 01.09.2019 and 31.12.2020, written in English or German and geographically restricted to Europe, to obtain setups comparable to the survey-based social science literature on European solidarity. We only crawled tweets that contained specific hashtags, to filter for our two topics, i.e. refugee and financial solidarity. We started with an initial list of hashtags (e.g., “#refugeecrisis”, “#eurobonds”), which we then expanded via co-occurrence statistics. We manually evaluated 456 co-occurring hashtags with at least 100 occurrences to see if they represented the topics we are interested in. Ultimately, we selected 45 hashtags (see appendix) to capture a wide range of the discourse on migration and financial solidarity. Importantly, we keep the hashtag list associated with our 270k tweets constant over time.2\nDefinition of Social Solidarity. In line with social scientific concepts of social solidarity, we define social solidarity as expressed and/or called for in online media as “the preparedness to share one’s own resources with others, be that directly by donating money or time in support of others or indirectly by supporting the state to reallocate and redistribute some of the funds gathered through taxes or contributions” (Lahusen and Grasso, 2018, p. 4). We define anti-solidarity as expressions that contest this type of social solidarity and/or deny solidarity towards vulnerable social groups and other European states, e.g. by promoting nationalism or the closure of national borders (Burgoon and Rooduijn, 2021; Cinalli et al., 2020; Finseraas, 2008; Wallaschek, 2017).\nExpert Annotations. After crawling and preparing the data, we set up guidelines for annotating tweets. Overall, we set four categories to annotate, with solidarity and anti-solidarity being the most important ones. A tweet indicating support for people in need, the willingness and/or gratitude towards others to share resources and/or help them is considered expressing solidarity. The same applies to tweets criticizing the EU in terms of not doing enough to share resources and/or help socially vulnerable groups as well as advocating for the EU as a solidarity union. A tweet is considered to be expressing anti-solidarity statements\n2We follow a purposeful sampling frame, but this necessarily introduces a bias in our data. While we took care of including a variety of hashtags, we do not claim to have captured the full extent of discourse concerning the topics migration and financial solidarity.\nif the above-mentioned criteria are reversed, and/or, the tweet contains tendencies of nationalism or advocates for closed borders. Not all tweets fit into these classes, thus we introduce two additional categories: ambivalent and not applicable. While the ambivalent category refers to tweets that could be interpreted as both expressing solidarity and anti-solidarity statements, the second category is reserved for tweets that do not contain the topic of (anti-)solidarity at all or refer to topics that are not concerned with discourses on refugee or financial solidarity. Table 1 contains example tweets for all categories. Full guidelines for the annotation of tweets are given in the appendix.\nWe divided the annotation process into six working stages (I-VI) to refine our data set and annotation standards over time and strengthen interannotator reliability through subsequent discussions among annotators and social science experts. Our annotators included four university students majoring in computer science, one computer science faculty member as well as two social science experts (one PhD student and one professor). We started the training of seven annotators with a small dataset that they annotated independently and refined the guidelines during the annotation process. In the training period, which lasted three iterations (I-III), we achieved Cohen’s kappa values of 0.51 among seven annotators. In working stage IV, two groups of two annotators annotated 339 tweets with hashtags not included before. Across the four annotators, Cohen’s kappa values of 0.49 were reached. In working stages V and VI, one group of two students annotated overall 588 tweets, with a resulting kappa value of 0.79 and 0.77 respectively.\nWhile the kappa value was low in the first stages, we managed to raise the inter-annotator reliability over time through discussions with the social science experts and extension of the guidelines. We also introduced a gold-standard for annotations from stage II onward which served as orientation. This was determined by majority voting and discussions among the annotators. For cases where a decision on the gold-standard label could not be reached, a social science expert decided on the gold-standard label; some hard cases were left undecided (not included in the dataset).\nThe gold-standard additionally served as human reference performance which we compared the model against. On average across all stages, our kappa agreement is 0.64 for four and 0.69 for\nthree classes (collapsing ambivalent and not applicable), while the macro F1-score is 69% for four and 78.5% for three classes. However, in the final stages, the agreement is considerably higher: above 80% macro-F1 for four and between 85.4% and 89.7% macro-F1 for three classes.\nCrowd annotations. We also conducted a ‘crowd experiment’ with students in an introductory course to NLP. We provided students with the guidelines and 100 expert annotated tweets as illustrations. We trained crowd annotators in three iterations. 1) They were assigned reading the guidelines and looking at 30 random expert annotations. Then they were asked to annotate 20 tweets themselves and self-report their kappa agreement with the experts (we provided the labels separately so that they could further use the 20 tweets to understand the annotation task). 2) We repeated this with another 30 tweets for annotator training and 20 tweets for annotator testing. 3) They received 30 expert-annotated tweets for which we did not give them access to expert labels, and 30 entirely novel tweets, that had not been annotated before. These 60 final tweets were presented in random order to each student. 50% of the 30 novel tweets were taken from before September 2020 and the other 50% were taken from after September 2020.\n125 students participated in the annotation task. The annotation experiment was part of a bonus the students could achieve for the course (counted 12.5% of the overall bonus for the class). Each novel tweet was annotated by up to 3 students (2.7 on average). To obtain a unique label for each crowd-annotated tweet, we used the following simple strategy: we either chose the majority label among the three annotators or the annotation of the most reliable annotator in case there was no unique majority label. The annotator that had the highest agreement with the expert annotators was taken as most reliable annotator.\nKappa agreements of students with the experts are shown in Figure 1. The majority of students has a kappa agreement with the gold-standard of between 0.6-0.7 when three classes are taken into account and between 0.5-0.6 for four classes.\nIn Table 2, we further show statistics on our annotated datasets: we have 2299 annotated tweets in total, about 60% of which have been annotated by crowd-workers. About 50% of all tweets are annotated as solidarity, 20% as anti-solidarity, and 30% as either not-applicable or ambivalent. In our annotations, 1196 tweets are English and 1103 are German.3 Finally, we note that the distribution of labels for expert and crowd annotations are different, i.e., the crowd annotations cover more solidarity tweets. The reason is twofold: (a) for the experts, we oversampled hashtags that we believed to be associated more often with anti-solidarity tweets as the initial annotations indicated that these would be in the minority, which we feared to be problematic for the automatic classifiers. (b) The time periods in which the tweets for the experts and crowd annotators fall differ."
    }, {
      "heading" : "4 Methods",
      "text" : "We use multilingual BERT (Devlin et al., 2019) / XLM-R (Conneau et al., 2020) to\n3In our automatically labeled data, the majority of tweets is German. We assumed all German tweets to come from within the EU, while the English tweets would be geofiltered more aggressively.\nclassify our tweets in a 3-way classification problem (solidarity, anti-solidarity, other), not differentiating between the classes ambivalent and non-applicable since our main focus is on the analysis of changes in (anti)solidarity. We use the baseline MBERT model: bert-base-multilingual-cased and the base XLM-R model: xlm-roberta-base. We implemented several data augmentation/transfer learning techniques to improve model performance:\n• Oversampling of minority classes: We randomly duplicate (expert and crowd annotated) tweets from minority classes until all classes have the same number of tweets as the majority class solidarity.\n• Back-translation: We use the Google Translate API to translate English tweets into a pivot language (we used German), and pivot language tweets back into English (for expert and crowdannotated tweets).\n• Fine-tuning: We fine-tune MBERT / XLM-R with masked language model and next sentence prediction tasks on domain-specific data, i.e., our crawled unlabeled tweets.\n• Auto-labeled data: As a form of self-learning, we train 9 different models (including oversampling, back-translation, etc.) on the expert and crowd-annotated data, then apply them to our full dataset (of 270k tweets, see below). We only retain tweets where 7 of 9 models agree and select 35k such tweets for each label (solidarity, anti-solidarity, other) into an augmented training set, thus increasing training data by 105k auto-labeled tweets.\n• Ensembling: We take the majority vote of 15 different models to leverage heterogeneous information. The k = 15 models, like the k = 9 models above, were determined as the top-k models by their dev set performance.\nWe also experimented with re-mapping multilin-\ngual BERT and XLM-R (Cao et al., 2020; Zhao et al., 2020a,b) as they have not seen parallel data during training, but found only minor effects in initial experiments."
    }, {
      "heading" : "5 Experiments",
      "text" : "In §5.1, we describe our experimental setup. In §5.2, we show the classification results of our baseline models on the annotated data and the effects of our various data augmentation and transfer learning strategies. In §5.3, we analyze performances of our best-performing models. In §5.4, we automatically label our whole dataset of 270k tweets and analyze changes in solidarity over time."
    }, {
      "heading" : "5.1 Experimental Setup",
      "text" : "To examine the effects of various factors, we design several experimental conditions. These involve (i) using only hashtags for classification, ignoring the actual tweet text, (ii) using only text, without the hashtags, (iii) combining expert and crowd annotations for training, (iv) examining the augmentation and transfer learning strategies, (v) ensembling various models using majority voting.\nAll models are evaluated on randomly sampled test and dev sets of size 170 each. Both dev and test set are taken from the expert annotations. We use the dev set for early stopping. To make sure our results are not an artefact of unlucky choices of test and dev sets, we report averages of 3 random splits where test and dev set contain 170 instances in each case (for reasons of computational costs, we do so only for selected experimental conditions).\nWe report the macro-F1 score to evaluate the performance of different models. Hyperparameters of our models can be found in our github."
    }, {
      "heading" : "5.2 Results",
      "text" : "The main results are reported in Table 3. Using only hashtags and expert annotated data yields a macroF1 score of below 50% for MBERT and XLMR. Including the full texts improves this by over 8 points (almost 20 points for XLM-R). Adding crowd-annotations yields another substantial boost of more than 6 points for MBERT. Removing hashtags in this situation decreases the performance between 5 and 6 points. This means that the hashtags indeed contain import information, but the texts are more important than the hashtags: with hashtags only, we observe macro-F1 scores between 42 and 49%, whereas with text only the performances are\nsubstantially higher, between 58 and 60%. While using hashtags only means less data since not all of our tweets have hashtags, the performance with only hashtags on the test sets stays below 50%, both with 572 and more than 1500 tweets for training.\nNext, we analyze the data augmentation and transfer learning techniques. Including autolabeled data drastically increases the train set, from below 2k instances to over 100k. Even though these instances are self-labeled, performance increases by over 13 points to about 78% macro-F1. Additionally oversampling or backtranslating the data does not yield further benefits, but pretraining on unlabeled tweets is effective even here and boosts performance to over 78%. Combining all strategies yields scores of up to almost 80%. Finally, when we consider our ensemble of 15 models, we achieve a best performance of 84.5% macro-F1 on the test set, close to the human macro-F1 agreement for the experts in the last rounds of annotation.\nTo sum up, we note: (i) adding crowd annotated data clearly helps, despite the crowd annotated data having a different label distribution; (ii) including text is important for classification as the classification with hashtags only performs considerably worse; (iii) data augmentation (especially self-labeling), combining models and transfer learning strategies has a further clearly positive effect."
    }, {
      "heading" : "5.3 Model Analysis",
      "text" : "Our most accurate ensemble models perform best for the majority class solidarity with an F1score of almost 90%, about 10 points better than for anti-solidarity and over 5 points better than for the other class. A confusion matrix for this best performing model is shown in Table 4. Here, anti-solidarity is disproportionately misclassified as either solidarity or the other class.\nTable 5 shows selected misclassifications for our ensemble model with performance of about 84.5% macro-F1. This reveals that the models sometimes leverage superficial lexical cues (e.g., the German political party ‘AfD’ is typically associated with anti-solidarity towards EU and refugees), including hashtags (‘Remigration’); see Figure 2, where we used LIME (Ribeiro et al., 2016) to highlight words the model pays attention to. To further gain insight into the misclassifications, we had one social science expert reannotate all misclassifications. From\nthe 25 errors that our best model makes in the test set of 170 instances, the expert thinks that 12 times the gold standard is correct, 7 times the model prediction is correct, and in further 6 cases neither the model nor the gold standard are correct. This hints at some level of errors in our annotated data; it further supports the conclusion that our model is close to the human upper bound."
    }, {
      "heading" : "5.4 Temporal Analysis",
      "text" : "Throughout the period observed in our data, discourses relating to migration were much more frequent than financial solidarity discourses. We crawled an average of 2526 tweets per week relating to migration (anti-)solidarity and an average of 174 financial (anti-)solidarity tweets, judging from the associated hashtags.\nWe used our best performing model to automatically label all our 270k tweets between September 2019 and December 2020. Solidarity tweets were about twice as frequent compared to anti-solidarity tweets, reflecting a polarized discourse in which solidarity statements clearly dominated. Figure\n3 shows the frequency curves for solidarity, anti-solidarity and other tweets over time in our sample. The figure also gives the ratio\nS/A := #Solidarity tweets\n#Anti-Solidarity tweets\nthat shows the frequency of solidarity tweets relative to anti-solidarity tweets. Values above one indicate that more solidarity than anti-solidarity statements were tweeted that day.\nFigure 3 displays several short-term increases in solidarity statements in our window of observation. Further analysis shows that these peaks have been immediate responses to drastic politically relevant events in Europe, which were also prominently covered by mainstream media, i.e. COVID-19-related news, natural disasters, fires, major policy changes. We illustrate this in the following.\nOn March 11th 2020, the World Health Organization (WHO) declared the COVID-19 outbreak a global pandemic. Shortly before and after, European countries started to take a variety of countermeasures, including stay-at-home orders for the general population, private gathering restrictions, and the closure of educational and childcare institutions (ECDC, 2020a). With the onset of these interventions, both solidarity and anti-solidarity statements relating to refugees and financial solidarity increased dramatically. At its peak at the beginning of March, anti-solidarity statements markedly outnumbered solidarity statements (we recorded 2189 solidarity tweets vs. 2569 anti-solidarity tweets on march 3rd). In fact, the period in early March 2020 is the only extended period in our data where anti-\nsolidarity statements outweighed solidarity statements. The dominance of solidarity statements was reestablished after two weeks. Over the following months, anti-solidarity statements decreased again to pre-COVID-19 levels, whereas solidarity statements remained comparatively high, with several peaks between March and September 2020.\nSolidarity and anti-solidarity statements shot up again early-September 2020, with an unprecedented climax on September 9th. Introspection of our data shows that the trigger for this was the precarious situation of refugees after a fire destroyed the Mória Refugee Camp on the Greek island of Lesbos on the night of September 8th. Human Rights Watch had compared the camp to an open-air prison in which refugees lived under inhumane conditions, and the disaster spurred debates about the responsibilities of EU countries towards refugees and the countries hosting refugee hot spots (i.e. Greece and Italy). At that time, COVID-19 infection rates in the EU were increasing but still low, and national measures to prevent the spread of infections relaxed in some and tightened in other EU countries (ECDC, 2020a,b). Further analyses (not displayed) show that the dominance of solidarity over anti-solidarity statements at the time was driven by tweets using hashtags relating to migration. The contemporaneous discourse on financial solidarity between EU countries was much less pronounced. From September 2020 to Decem-\nber 2020, solidarity and (anti-)solidarity statements were about equal in frequency, which means that anti-solidarity was on average on a higher level compared to the earlier time points in our time frame. This period also corresponds to the highest COVID-19 infection rates witnessed in the EU, on average, during the year 2020. In fact, the Spearman correlation between the number of antisolidarity tweets in our data and infection rates is 0.45 and 0.47, respectively (infection rates within Germany and the EU); see Figure 4 in the appendix. Correlation with the number of solidarity tweets is, in contrast, non-significant.\nDiscussion Late February to mid-March 2020, EU governments began enacting lockdowns and other measures to contain COVID-19 infection rates, turning people’s everyday lives upside down. During this time frame, anti-solidarity statements peaked in our data, but solidarity statements quickly dominated thereafter again. During the summer of 2020, anti-solidarity tweets decreased whereas solidarity tweets continued to prevail on higher levels than before. A major peak on September 9th, in the aftermath of the destruction of the Mória Refugee Camp, signifies an intensification of the polarized solidarity discourse. From September to December 2020, anti-solidarity and solidarity statements were almost equal in number. Thus, the onset of the COVID-19 crisis as well as times of high infection rates concurred with disproportionately high levels of anti-solidarity, despite a dominance of solidarity overall. Whether the relationship between anti-solidarity and intensified strains during crises is indeed causal will be the scope of our future research.4"
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we contributed the first large-scale human and automatically annotated dataset labeled for solidarity and its contestation, anti-solidarity. The dataset uses the textual material in social media posts to determine whether a post shows (anti)solidarity with respect to relevant target groups. Our annotations, conducted by both trained experts and student crowd-workers, show overall good agreement levels for a challenging novel NLP task. We further trained augmented BERT models whose\n4We made sure that the substantial findings reported here are not driven by inherently German (anti-)solidarity discourses. Still, our results are bound to the opinions of people posting tweets in the English and German language.\nperformance is close to the agreement levels of the experts and which we used for large-scale trend analysis of over 270k media posts before and after the onset of the COVID-19 pandemic. Our findings show that (anti-)solidarity statements climaxed momentarily with the first lockdown, but the predominance of solidarity expressions was quickly restored at higher levels than before. Solidarity and anti-solidarity statements were balanced by the end of the year 2020, when infection rates were rising.\nThe COVID-19 pandemic constitutes a worldwide crisis, with profound economic and social consequences for contemporary societies. It manifests yet another challenge for European solidarity, by putting a severe strain on available resources, i.e. national economies, health systems, and individual freedom. While the EU, its member countries and residents continued to struggle with the consequences of the Financial Crisis and its aftermath, as well as migration, the COVID-19 pandemic has accelerated the problems related to these former crises. Our data suggests that the COVID-19 pandemic has not severely negatively impacted the willingness of European Twitter users to take responsibility for refugees, while financial solidarity with other EU countries remained low on the agenda. Over time, however, this form of expressed solidarity became more controversial. On one hand, these findings are in line with survey-based, quantitative research and its rather optimistic overall picture regarding social solidarity in the EU during earlier crises (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018); on the other hand, results from our correlation analysis suggests that severe strains during crises coincide with increased levels of antisolidarity statements. We conclude that a convergence of opinion (Santhanam et al., 2019) among the European Twitter-using public regarding the target audiences of solidarity, and the limits of European solidarity vs. national interests, is not in sight. Instead, our widened analytic focus has allowed us to examine pro-social online behavior during crises and its opposition, revealing that European Twitter users remain divided on issues of European solidarity."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank the anonymous reviewers whose comments greatly improved the final version of the paper.\nEthical considerations. We will release only tweet IDs in our final dataset. The presented tweets in our paper were paraphrased and/or translated and therefore cannot be traced back to the users. No user identities of any annotator (neither expert nor crowd worker) will ever be revealed or can be inferred from the dataset. Crowd workers were made aware that the annotations are going to be used in further downstream applications and they were free to choose to submit their annotations. While our trained model could potentially be misused, we do not foresee greater risks than with established NLP applications such as sentiment or emotion classification."
    }, {
      "heading" : "A Appendices",
      "text" : "Guidelines\nRead the guidelines for annotating solidarity carefully.\n• Definition of solidarity:\nThe preparedness to share one’s own resources with others, be that directly by donating money or time in support of others or indirectly by supporting the state to reallocate and redistribute some of the funds gathered through taxes or contributions (Lahusen and Grasso, 2018)\n• General rules\n1. Do not take links (urls) into account when annotating.\n2. Hashtags should be taken into account, especially if a tweet is otherwise neutral.\n3. Emojis, if easily interpretable, can be taken into account.\n4. If solidarity and anti-solidarity hashtags are used, code anti-solidarity.\n5. When annotating use the scheme: Solidarity: 0, Anti-Solidarity: 1, Ambivalent: 2, Not Applicable: 3.\n• Detailed rules for annotation.\n1. A tweet is annotated as showing solidarity, when: (a) It clearly indicates support people\nand the willingness to share resources and/or help.\n(b) Positive attitude and gratitude to those sharing resources and/or helping.\n(c) Advocacy of the European Union as a solidarity union.\n(d) Criticism of the EU in terms of not doing enough to share resources and/or help others.\n(e) Hashtags can be to be taken into account as to whether a tweet qualifies as showing solidarity (e.g. using hashtags like #refugeeswelcome).\n(f) Hashtags should be taken into account if the tweet points neither\ntowards solidarity or anti-solidarity itself.\n2. A tweet is annotated as showing antisolidarity, when: (a) It clearly indicates no willingness to\nsupport people and an unwillingness to share resources and/or help.\n(b) It suggests to exclude our target groups from resources they currently have access to.\n(c) Tendencies of nationalism and closing borders.\n(d) Irony/sarcasm in tweets need to be taken into account.\n(e) Hashtags can be taken into account as to whether a tweet qualifies as antisolidarity (e.g. using hashtags like #grexit).\n(f) Hashtags should be taken into account if the tweet points neither towards solidarity or anti-solidarity itself.\n3. A tweet is annotated ambivalent, when: (a) The tweet shows solidarity or anti-\nsolidarity sentiment, but it cannot be determined whether the tweet shows solidarity or anti-solidarity as there is additional info missing.\n(b) Even if taking hashtags into account, there is no clear indication as to whether the author shows solidarity or anti-solidarity.\n(c) If solidarity and anti-solidarity hashtags are used, code anti-solidarity.\n4. A tweet is annotated not applicable, when: (a) There is no indication of solidarity or\nanti-solidarity sentiment in the tweet. (b) Even when hashtags that usually\npoint towards solidarity or antisolidarity are taken into account the tweet does not indicate any connection to solidarity or anti-solidarity.\n(c) The tweet concerns completely different topics than solidarity or antisolidarity.\n(d) The tweet is not understandable (e.g.\ncontains only links).\nHashtags\nInfection numbers vs. anti-solidarity Tweets"
    } ],
    "references" : [ {
      "title" : "Brexit, division, and individual solidarity: What future for europe? Evidence from eight european countries",
      "author" : [ "Simone Baglioni", "Olga Biosca", "Tom Montgomery." ],
      "venue" : "American Behavioral Scientist, 63(4):538–550.",
      "citeRegEx" : "Baglioni et al\\.,? 2019",
      "shortCiteRegEx" : "Baglioni et al\\.",
      "year" : 2019
    }, {
      "title" : "Elections, political polarization, and economic uncertainty",
      "author" : [ "Scott R Baker", "Aniket Baksy", "Nicholas Bloom", "Steven J Davis", "Jonathan A Rodden." ],
      "venue" : "Working Paper 27961, National Bureau of Economic Research.",
      "citeRegEx" : "Baker et al\\.,? 2020",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 2020
    }, {
      "title" : "What’s left unsaid? In-group solidarity and ethnic and racial differences in opposition to immigration in the united states",
      "author" : [ "Alessandra Bazo Vienrich", "Mathew J. Creighton." ],
      "venue" : "Journal of Ethnic and Migration Studies, 44(13):2240–2255.",
      "citeRegEx" : "Vienrich and Creighton.,? 2017",
      "shortCiteRegEx" : "Vienrich and Creighton.",
      "year" : 2017
    }, {
      "title" : "Immigrationization’ of welfare politics? Antiimmigration and welfare attitudes in context",
      "author" : [ "Brian Burgoon", "Matthijs Rooduijn." ],
      "venue" : "West European Politics, 44(2):177–203.",
      "citeRegEx" : "Burgoon and Rooduijn.,? 2021",
      "shortCiteRegEx" : "Burgoon and Rooduijn.",
      "year" : 2021
    }, {
      "title" : "Multilingual alignment of contextual word representations",
      "author" : [ "Steven Cao", "Nikita Kitaev", "Dan Klein." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Cao et al\\.,? 2020",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2020
    }, {
      "title" : "Solidarity contestation in the public domain during the ‘refugee crisis",
      "author" : [ "Manlio Cinalli", "Olga Eisele", "Verena K. Brändle", "Hans-Jörg Trenz." ],
      "venue" : "Christian Lahusen, editor, Citizens’ Solidarity in Europe, pages 120–148.",
      "citeRegEx" : "Cinalli et al\\.,? 2020",
      "shortCiteRegEx" : "Cinalli et al\\.",
      "year" : 2020
    }, {
      "title" : "Unsupervised cross-lingual representation learning at scale",
      "author" : [ "Alexis Conneau", "Kartikay Khandelwal", "Naman Goyal", "Vishrav Chaudhary", "Guillaume Wenzek", "Francisco Guzmán", "Edouard Grave", "Myle Ott", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "In",
      "citeRegEx" : "Conneau et al\\.,? 2020",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2020
    }, {
      "title" : "Has opposition to immigration increased in the united states after the economic crisis? an experimental approach",
      "author" : [ "Mathew J. Creighton", "Amaney Jamal", "Natalia C. Malancu." ],
      "venue" : "International Migration Review, 49(3):727–756.",
      "citeRegEx" : "Creighton et al\\.,? 2015",
      "shortCiteRegEx" : "Creighton et al\\.",
      "year" : 2015
    }, {
      "title" : "GoEmotions: A dataset of fine-grained emotions",
      "author" : [ "Dorottya Demszky", "Dana Movshovitz-Attias", "Jeongwoo Ko", "Alan Cowen", "Gaurav Nemade", "Sujith Ravi." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Demszky et al\\.,? 2020",
      "shortCiteRegEx" : "Demszky et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Hashtags, emotions, and comments: A large-scale dataset to understand fine-grained social emotions to online topics",
      "author" : [ "Keyang Ding", "Jing Li", "Yuji Zhang." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process-",
      "citeRegEx" : "Ding et al\\.,? 2020",
      "shortCiteRegEx" : "Ding et al\\.",
      "year" : 2020
    }, {
      "title" : "Social cohesion in the western world: What holds societies together: Insights from the social cohesion radar",
      "author" : [ "Georgi Dragolov", "Zsófia S. Ignácz", "Jan Lorenz", "Jan Delhey", "Klaus Boehnke", "Kai Unzicker." ],
      "venue" : "Springer.",
      "citeRegEx" : "Dragolov et al\\.,? 2016",
      "shortCiteRegEx" : "Dragolov et al\\.",
      "year" : 2016
    }, {
      "title" : "Mediating solidarity",
      "author" : [ "Natalie Fenton." ],
      "venue" : "Global Media and Communication, 4(1):37–57.",
      "citeRegEx" : "Fenton.,? 2008",
      "shortCiteRegEx" : "Fenton.",
      "year" : 2008
    }, {
      "title" : "Immigration and preferences for redistribution: An empirical analysis of european survey data",
      "author" : [ "Henning Finseraas." ],
      "venue" : "Comparative European Politics, 6(4):407–431.",
      "citeRegEx" : "Finseraas.,? 2008",
      "shortCiteRegEx" : "Finseraas.",
      "year" : 2008
    }, {
      "title" : "Global migration, local communities and the absent state: Resentment and resignation on the italian island of lampedusa",
      "author" : [ "Michela Franceschelli." ],
      "venue" : "Sociology, 54(3):591–608.",
      "citeRegEx" : "Franceschelli.,? 2019",
      "shortCiteRegEx" : "Franceschelli.",
      "year" : 2019
    }, {
      "title" : "The erosion of political trust in the great recession",
      "author" : [ "Markus Gangl", "Carlotta Giustozzi." ],
      "venue" : "CORRODE Working Paper, (5).",
      "citeRegEx" : "Gangl and Giustozzi.,? 2018",
      "shortCiteRegEx" : "Gangl and Giustozzi.",
      "year" : 2018
    }, {
      "title" : "European solidarity in times of crisis: Insights from a thirteen-country survey",
      "author" : [ "Jürgen Gerhards", "Holger Lengfeld", "Zsófia S. Ignácz", "Florian K. Kley", "Maximilian Priem." ],
      "venue" : "Routledge.",
      "citeRegEx" : "Gerhards et al\\.,? 2019",
      "shortCiteRegEx" : "Gerhards et al\\.",
      "year" : 2019
    }, {
      "title" : "The role of grassroots food banks in building political solidarity with vulnerable people",
      "author" : [ "Marı́a Gómez Garrido", "M. Antònia Carbonero Gamundı", "Anahı́ Viladrich" ],
      "venue" : "European Societies,",
      "citeRegEx" : "Garrido et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Garrido et al\\.",
      "year" : 2018
    }, {
      "title" : "POEMO: Conceptualization, annotation, and modeling of aesthetic emotions in German and English poetry",
      "author" : [ "Thomas Haider", "Steffen Eger", "Evgeny Kim", "Roman Klinger", "Winfried Menninghaus." ],
      "venue" : "Proceedings of the 12th Language Resources",
      "citeRegEx" : "Haider et al\\.,? 2020",
      "shortCiteRegEx" : "Haider et al\\.",
      "year" : 2020
    }, {
      "title" : "Mode differences between faceto-face and web surveys: An experimental investigation of data quality and social desirability effects",
      "author" : [ "D. Heerwegh." ],
      "venue" : "International Journal of Public Opinion Research, 21(1):111–121.",
      "citeRegEx" : "Heerwegh.,? 2009",
      "shortCiteRegEx" : "Heerwegh.",
      "year" : 2009
    }, {
      "title" : "Challenging the nation-state from within: The emergence of transmunicipal solidarity in the course of the eu refugee controversy",
      "author" : [ "Christiane Heimann", "Sandra Müller", "Hannes Schammann", "Janina Stürner." ],
      "venue" : "Social Inclusion, 7(2):208–218.",
      "citeRegEx" : "Heimann et al\\.,? 2019",
      "shortCiteRegEx" : "Heimann et al\\.",
      "year" : 2019
    }, {
      "title" : "Vader: A parsimonious rule-based model for sentiment analysis of social media text",
      "author" : [ "C. Hutto", "Eric Gilbert." ],
      "venue" : "Proceedings of the International AAAI Conference on Web and Social Media, 8(1).",
      "citeRegEx" : "Hutto and Gilbert.,? 2014",
      "shortCiteRegEx" : "Hutto and Gilbert.",
      "year" : 2014
    }, {
      "title" : "The influence of social desirability pressures on expressed immigration attitudes",
      "author" : [ "Alexander L. Janus." ],
      "venue" : "Social Science Quarterly, 91(4):928–946.",
      "citeRegEx" : "Janus.,? 2010",
      "shortCiteRegEx" : "Janus.",
      "year" : 2010
    }, {
      "title" : "Solidarity with refugees across europe",
      "author" : [ "Sebastian Koos", "Verena Seibel." ],
      "venue" : "a comparative analysis of public support for helping forced migrants. European Societies, 21(5):704–728.",
      "citeRegEx" : "Koos and Seibel.,? 2019",
      "shortCiteRegEx" : "Koos and Seibel.",
      "year" : 2019
    }, {
      "title" : "The dynamic relations between economic conditions and anti-immigrant sentiment: A natural experiment in times of the european economic crisis",
      "author" : [ "Anabel Kuntz", "Eldad Davidov", "Moshe Semyonov." ],
      "venue" : "International Journal of Comparative Sociol-",
      "citeRegEx" : "Kuntz et al\\.,? 2017",
      "shortCiteRegEx" : "Kuntz et al\\.",
      "year" : 2017
    }, {
      "title" : "The emotional antecedents of solidarity in social media crowds",
      "author" : [ "Drew Margolin", "Wang Liao." ],
      "venue" : "New Media & Society, 20(10):3700–3719.",
      "citeRegEx" : "Margolin and Liao.,? 2018",
      "shortCiteRegEx" : "Margolin and Liao.",
      "year" : 2018
    }, {
      "title" : "Narratives of the refugee crisis: A comparative study of mainstream-media and twitter",
      "author" : [ "Adina Nerghes", "Ju-Sung Lee." ],
      "venue" : "Media and Communication, 7(2 Refugee Crises Disclosed):275–288.",
      "citeRegEx" : "Nerghes and Lee.,? 2019",
      "shortCiteRegEx" : "Nerghes and Lee.",
      "year" : 2019
    }, {
      "title" : "Hard-line euroscepticism and the eurocrisis: Evidence from a panel study of 108 elections across europe",
      "author" : [ "Francesco Nicoli." ],
      "venue" : "JCMS: Journal of Common Market Studies, 55(2):312–331.",
      "citeRegEx" : "Nicoli.,? 2017",
      "shortCiteRegEx" : "Nicoli.",
      "year" : 2017
    }, {
      "title" : "An analysis of annotated corpora for emotion classification in text",
      "author" : [ "Laura Ana Maria Oberländer", "Roman Klinger." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 2104–2119.",
      "citeRegEx" : "Oberländer and Klinger.,? 2018",
      "shortCiteRegEx" : "Oberländer and Klinger.",
      "year" : 2018
    }, {
      "title" : "Why should I trust you?”: Explaining the predictions of any classifier",
      "author" : [ "Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin." ],
      "venue" : "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages",
      "citeRegEx" : "Ribeiro et al\\.,? 2016",
      "shortCiteRegEx" : "Ribeiro et al\\.",
      "year" : 2016
    }, {
      "title" : "I stand with you: Using emojis to study solidarity in crisis events",
      "author" : [ "Sashank Santhanam", "Vidhushini Srinivasan", "Shaina Glass", "Samira Shaikh." ],
      "venue" : "arXiv preprint.",
      "citeRegEx" : "Santhanam et al\\.,? 2019",
      "shortCiteRegEx" : "Santhanam et al\\.",
      "year" : 2019
    }, {
      "title" : "Social exclusion and social solidarity: three paradigms",
      "author" : [ "Hilary Silver." ],
      "venue" : "International Labour Review, 133(5-6):531–578.",
      "citeRegEx" : "Silver.,? 1994",
      "shortCiteRegEx" : "Silver.",
      "year" : 1994
    }, {
      "title" : "Republic: Divided democracy in the age of social media",
      "author" : [ "Cass R. Sunstein." ],
      "venue" : "Princeton University Press.",
      "citeRegEx" : "Sunstein.,? 2018",
      "shortCiteRegEx" : "Sunstein.",
      "year" : 2018
    }, {
      "title" : "Social movements and governments in the digital age: Evaluating a complex landscape",
      "author" : [ "Zeynep Tufekci." ],
      "venue" : "Journal of International Affairs, 68(1):1–18.",
      "citeRegEx" : "Tufekci.,? 2014",
      "shortCiteRegEx" : "Tufekci.",
      "year" : 2014
    }, {
      "title" : "Notions of solidarity in europe’s migration crisis: The case of germany’s media discourse",
      "author" : [ "Stefan Wallaschek" ],
      "venue" : null,
      "citeRegEx" : "Wallaschek.,? \\Q2017\\E",
      "shortCiteRegEx" : "Wallaschek.",
      "year" : 2017
    }, {
      "title" : "Solidarity in europe in times of crisis",
      "author" : [ "Stefan Wallaschek." ],
      "venue" : "Journal of European Integration, 41(2):257–263.",
      "citeRegEx" : "Wallaschek.,? 2019",
      "shortCiteRegEx" : "Wallaschek.",
      "year" : 2019
    }, {
      "title" : "Contested solidarity in the euro crisis and europe’s migration crisis: A discourse network analysis",
      "author" : [ "Stefan Wallaschek." ],
      "venue" : "Journal of European Public Policy, 27(7):1034–1053.",
      "citeRegEx" : "Wallaschek.,? 2020a",
      "shortCiteRegEx" : "Wallaschek.",
      "year" : 2020
    }, {
      "title" : "The discursive construction of solidarity: Analysing public claims in europe’s migration crisis",
      "author" : [ "Stefan Wallaschek." ],
      "venue" : "Political Studies, 68(1):74–92.",
      "citeRegEx" : "Wallaschek.,? 2020b",
      "shortCiteRegEx" : "Wallaschek.",
      "year" : 2020
    }, {
      "title" : "Inducing languageagnostic multilingual representations",
      "author" : [ "Wei Zhao", "Steffen Eger", "Johannes Bjerva", "Isabelle Augenstein." ],
      "venue" : "arXiv preprint arXiv:2008.09112.",
      "citeRegEx" : "Zhao et al\\.,? 2020a",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "On the limitations of cross-lingual encoders as exposed by reference-free machine translation evaluation",
      "author" : [ "Wei Zhao", "Goran Glavaš", "Maxime Peyrard", "Yang Gao", "Robert West", "Steffen Eger." ],
      "venue" : "In",
      "citeRegEx" : "Zhao et al\\.,? 2020b",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "Social solidarity statements and other forms of collective pro-social behavior expressed in online media have been argued to affect public opinion and political mobilization (Fenton, 2008; Margolin and Liao, 2018; Santhanam et al., 2019; Tufekci, 2014).",
      "startOffset" : 174,
      "endOffset" : 252
    }, {
      "referenceID" : 25,
      "context" : "Social solidarity statements and other forms of collective pro-social behavior expressed in online media have been argued to affect public opinion and political mobilization (Fenton, 2008; Margolin and Liao, 2018; Santhanam et al., 2019; Tufekci, 2014).",
      "startOffset" : 174,
      "endOffset" : 252
    }, {
      "referenceID" : 30,
      "context" : "Social solidarity statements and other forms of collective pro-social behavior expressed in online media have been argued to affect public opinion and political mobilization (Fenton, 2008; Margolin and Liao, 2018; Santhanam et al., 2019; Tufekci, 2014).",
      "startOffset" : 174,
      "endOffset" : 252
    }, {
      "referenceID" : 33,
      "context" : "Social solidarity statements and other forms of collective pro-social behavior expressed in online media have been argued to affect public opinion and political mobilization (Fenton, 2008; Margolin and Liao, 2018; Santhanam et al., 2019; Tufekci, 2014).",
      "startOffset" : 174,
      "endOffset" : 252
    }, {
      "referenceID" : 12,
      "context" : "The ubiquity of social media enables individuals to feel and relate to real-world problems through solidarity statements expressed online and to act accordingly (Fenton, 2008).",
      "startOffset" : 161,
      "endOffset" : 175
    }, {
      "referenceID" : 31,
      "context" : "affecting people’s willingness to help others and share own resources beyond immediate rational individually-, group- or class-based interests (Silver, 1994).",
      "startOffset" : 143,
      "endOffset" : 157
    }, {
      "referenceID" : 12,
      "context" : "societies and related opinions fragmented (Fenton, 2008; Sunstein, 2018), collective expressions of social solidarity online are likely contested.",
      "startOffset" : 42,
      "endOffset" : 72
    }, {
      "referenceID" : 32,
      "context" : "societies and related opinions fragmented (Fenton, 2008; Sunstein, 2018), collective expressions of social solidarity online are likely contested.",
      "startOffset" : 42,
      "endOffset" : 72
    }, {
      "referenceID" : 35,
      "context" : "towards whom individuals should show solidarity, and in what ways (Wallaschek, 2019).",
      "startOffset" : 66,
      "endOffset" : 84
    }, {
      "referenceID" : 16,
      "context" : "The concept of a European society and European solidarity (Gerhards et al., 2019), a form of solidarity that goes beyond the nation state, is rather new.",
      "startOffset" : 58,
      "endOffset" : 81
    }, {
      "referenceID" : 0,
      "context" : "and expansion of the European Union (EU) and its legislative and administrative power vis-à-vis the EU member states since the 1950s (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018).",
      "startOffset" : 133,
      "endOffset" : 228
    }, {
      "referenceID" : 16,
      "context" : "and expansion of the European Union (EU) and its legislative and administrative power vis-à-vis the EU member states since the 1950s (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018).",
      "startOffset" : 133,
      "endOffset" : 228
    }, {
      "referenceID" : 23,
      "context" : "and expansion of the European Union (EU) and its legislative and administrative power vis-à-vis the EU member states since the 1950s (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018).",
      "startOffset" : 133,
      "endOffset" : 228
    }, {
      "referenceID" : 16,
      "context" : "After decades of increasing European integration and institutionalization, the EU entered into a continued succession of deep crises, beginning with the European Financial Crisis in 2010 (Gerhards et al., 2019).",
      "startOffset" : 187,
      "endOffset" : 210
    }, {
      "referenceID" : 16,
      "context" : "1624 and right-wing populists claim that social solidarity is, and should be, confined within the nation state, whereas supporters of the European project see European solidarity as a means to overcome the great challenges imposed on EU countries and its citizens today (Gerhards et al., 2019).",
      "startOffset" : 270,
      "endOffset" : 293
    }, {
      "referenceID" : 31,
      "context" : "In the social sciences, social solidarity has always been a key topic of intellectual thought and empirical investigation, dating back to seminal thinkers such as Rousseau and Durkheim (Silver, 1994).",
      "startOffset" : 185,
      "endOffset" : 199
    }, {
      "referenceID" : 0,
      "context" : "Whereas earlier empirical research was mostly confined to survey-based (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018) or qualitative approaches (Franceschelli, 2019; Gómez Garrido et al.",
      "startOffset" : 71,
      "endOffset" : 166
    }, {
      "referenceID" : 16,
      "context" : "Whereas earlier empirical research was mostly confined to survey-based (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018) or qualitative approaches (Franceschelli, 2019; Gómez Garrido et al.",
      "startOffset" : 71,
      "endOffset" : 166
    }, {
      "referenceID" : 23,
      "context" : "Whereas earlier empirical research was mostly confined to survey-based (Baglioni et al., 2019; Gerhards et al., 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018) or qualitative approaches (Franceschelli, 2019; Gómez Garrido et al.",
      "startOffset" : 71,
      "endOffset" : 166
    }, {
      "referenceID" : 14,
      "context" : ", 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018) or qualitative approaches (Franceschelli, 2019; Gómez Garrido et al., 2018; Heimann et al., 2019), computational social science just started tackling concepts as complex as solidarity as part of natural language processing (NLP) approaches (Santhanam et al.",
      "startOffset" : 83,
      "endOffset" : 154
    }, {
      "referenceID" : 20,
      "context" : ", 2019; Koos and Seibel, 2019; Lahusen and Grasso, 2018) or qualitative approaches (Franceschelli, 2019; Gómez Garrido et al., 2018; Heimann et al., 2019), computational social science just started tackling concepts as complex as solidarity as part of natural language processing (NLP) approaches (Santhanam et al.",
      "startOffset" : 83,
      "endOffset" : 154
    }, {
      "referenceID" : 30,
      "context" : ", 2019), computational social science just started tackling concepts as complex as solidarity as part of natural language processing (NLP) approaches (Santhanam et al., 2019).",
      "startOffset" : 150,
      "endOffset" : 174
    }, {
      "referenceID" : 26,
      "context" : "These studies focused on differences in perspectives and narratives between mainstream media and Twitter, using topic models (Nerghes and Lee, 2019), and the coverage and kinds of solidarity addressed in leftist and conservative newspaper media (Wallaschek, 2019, 2020a), as well as relevant actors in discourses on solidarity, using discourse network measures (Wallaschek, 2020b).",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 37,
      "context" : "These studies focused on differences in perspectives and narratives between mainstream media and Twitter, using topic models (Nerghes and Lee, 2019), and the coverage and kinds of solidarity addressed in leftist and conservative newspaper media (Wallaschek, 2019, 2020a), as well as relevant actors in discourses on solidarity, using discourse network measures (Wallaschek, 2020b).",
      "startOffset" : 361,
      "endOffset" : 380
    }, {
      "referenceID" : 35,
      "context" : "on mainstream media, which is unlikely to publicly reject solidarity claims (Wallaschek, 2019).",
      "startOffset" : 76,
      "endOffset" : 94
    }, {
      "referenceID" : 26,
      "context" : "Social media, in contrast, allows its users to perpetuate, challenge and open new perspectives on mainstream narratives (Nerghes and Lee, 2019).",
      "startOffset" : 120,
      "endOffset" : 143
    }, {
      "referenceID" : 11,
      "context" : "On the one hand, most survey research paints a rather optimistic view regarding social solidarity in the EU, despite marked cross-national variation (Binner and Scherschel, 2019; Dragolov et al., 2016; Gerhards et al., 2019; Lahusen and Grasso, 2018).",
      "startOffset" : 149,
      "endOffset" : 250
    }, {
      "referenceID" : 16,
      "context" : "On the one hand, most survey research paints a rather optimistic view regarding social solidarity in the EU, despite marked cross-national variation (Binner and Scherschel, 2019; Dragolov et al., 2016; Gerhards et al., 2019; Lahusen and Grasso, 2018).",
      "startOffset" : 149,
      "endOffset" : 250
    }, {
      "referenceID" : 1,
      "context" : "Eurosceptic political parties (Baker et al., 2020; Nicoli, 2017) suggests that the opinions, orientations and fears of a potentially growing political minority is underrepresented in this research.",
      "startOffset" : 30,
      "endOffset" : 64
    }, {
      "referenceID" : 27,
      "context" : "Eurosceptic political parties (Baker et al., 2020; Nicoli, 2017) suggests that the opinions, orientations and fears of a potentially growing political minority is underrepresented in this research.",
      "startOffset" : 30,
      "endOffset" : 64
    }, {
      "referenceID" : 19,
      "context" : "People holding extreme opinions have been found to be reluctant to participate in surveys and adopt their survey-responses to social norms (social desirability bias) (Bazo Vienrich and Creighton, 2017; Heerwegh, 2009; Janus, 2010).",
      "startOffset" : 166,
      "endOffset" : 230
    }, {
      "referenceID" : 22,
      "context" : "People holding extreme opinions have been found to be reluctant to participate in surveys and adopt their survey-responses to social norms (social desirability bias) (Bazo Vienrich and Creighton, 2017; Heerwegh, 2009; Janus, 2010).",
      "startOffset" : 166,
      "endOffset" : 230
    }, {
      "referenceID" : 32,
      "context" : "Our paper addresses these problems by drawing on large volumes of longitudinal social media data that reflect potential fragmentation of political opinion (Sunstein, 2018) and its change over time.",
      "startOffset" : 155,
      "endOffset" : 171
    }, {
      "referenceID" : 8,
      "context" : "In NLP, annotating and classifying text (in social media) for sentiment or emotions is a wellestablished task (Demszky et al., 2020; Ding et al., 2020; Haider et al., 2020; Hutto and Gilbert, 2014; Oberländer and Klinger, 2018).",
      "startOffset" : 110,
      "endOffset" : 227
    }, {
      "referenceID" : 10,
      "context" : "In NLP, annotating and classifying text (in social media) for sentiment or emotions is a wellestablished task (Demszky et al., 2020; Ding et al., 2020; Haider et al., 2020; Hutto and Gilbert, 2014; Oberländer and Klinger, 2018).",
      "startOffset" : 110,
      "endOffset" : 227
    }, {
      "referenceID" : 18,
      "context" : "In NLP, annotating and classifying text (in social media) for sentiment or emotions is a wellestablished task (Demszky et al., 2020; Ding et al., 2020; Haider et al., 2020; Hutto and Gilbert, 2014; Oberländer and Klinger, 2018).",
      "startOffset" : 110,
      "endOffset" : 227
    }, {
      "referenceID" : 21,
      "context" : "In NLP, annotating and classifying text (in social media) for sentiment or emotions is a wellestablished task (Demszky et al., 2020; Ding et al., 2020; Haider et al., 2020; Hutto and Gilbert, 2014; Oberländer and Klinger, 2018).",
      "startOffset" : 110,
      "endOffset" : 227
    }, {
      "referenceID" : 28,
      "context" : "In NLP, annotating and classifying text (in social media) for sentiment or emotions is a wellestablished task (Demszky et al., 2020; Ding et al., 2020; Haider et al., 2020; Hutto and Gilbert, 2014; Oberländer and Klinger, 2018).",
      "startOffset" : 110,
      "endOffset" : 227
    }, {
      "referenceID" : 21,
      "context" : "tained from Vader (Hutto and Gilbert, 2014)—and our annotations in §3 is only ∼0.",
      "startOffset" : 18,
      "endOffset" : 43
    }, {
      "referenceID" : 7,
      "context" : "lyze and compare social solidarity data before and during the COVID-19 crisis as if it were a natural experiment (Creighton et al., 2015; Kuntz et al., 2017).",
      "startOffset" : 113,
      "endOffset" : 157
    }, {
      "referenceID" : 24,
      "context" : "lyze and compare social solidarity data before and during the COVID-19 crisis as if it were a natural experiment (Creighton et al., 2015; Kuntz et al., 2017).",
      "startOffset" : 113,
      "endOffset" : 157
    }, {
      "referenceID" : 9,
      "context" : "We use multilingual BERT (Devlin et al., 2019) / XLM-R (Conneau et al.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 29,
      "context" : ", the German political party ‘AfD’ is typically associated with anti-solidarity towards EU and refugees), including hashtags (‘Remigration’); see Figure 2, where we used LIME (Ribeiro et al., 2016) to highlight words the model pays attention to.",
      "startOffset" : 175,
      "endOffset" : 197
    }, {
      "referenceID" : 30,
      "context" : "We conclude that a convergence of opinion (Santhanam et al., 2019) among the European Twitter-using public regarding the target audiences of solidarity, and the limits of European solidarity vs.",
      "startOffset" : 42,
      "endOffset" : 66
    } ],
    "year" : 2021,
    "abstractText" : "We introduce the well-established social scientific concept of social solidarity and its contestation, anti-solidarity, as a new problem setting to supervised machine learning in NLP to assess how European solidarity discourses changed before and after the COVID-19 outbreak was declared a global pandemic. To this end, we annotate 2.3k English and German tweets for (anti-)solidarity expressions, utilizing multiple human annotators and two annotation approaches (experts vs. crowds). We use these annotations to train a BERT model with multiple data augmentation strategies. Our augmented BERT model that combines both expert and crowd annotations outperforms the baseline BERT classifier trained with expert annotations only by over 25 points, from 58% macro-F1 to almost 85%. We use this highquality model to automatically label over 270k tweets between September 2019 and December 2020. We then assess the automatically labeled data for how statements related to European (anti-)solidarity discourses developed over time and in relation to one another, before and during the COVID-19 crisis. Our results show that solidarity became increasingly salient and contested during the crisis. While the number of solidarity tweets remained on a higher level and dominated the discourse in the scrutinized time frame, anti-solidarity tweets initially spiked, then decreased to (almost) pre-COVID-19 values before rising to a stable higher level until the end of 2020.",
    "creator" : "LaTeX with hyperref"
  }
}