{
  "name" : "2021.acl-long.137.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Dialogue Response Selection with Hierarchical Curriculum Learning",
    "authors" : [ "Yixuan Su", "Deng Cai", "Qingyu Zhou", "Zibo Lin", "Simon Baker", "Yunbo Cao", "Shuming Shi", "Nigel Collier", "Yan Wang" ],
    "emails" : [ "ys484@cam.ac.uk", "sb895@cam.ac.uk", "nhc30@cam.ac.uk", "thisisjcykcd@gmail.com", "qingyuzhou@tencent.com", "jimblin@tencent.com", "yunbocao@tencent.com", "shumingshi@tencent.com", "brandenwang@tencent.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1740–1751\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n1740"
    }, {
      "heading" : "1 Introduction",
      "text" : "Building intelligent conversation systems is a longstanding goal of artificial intelligence and has attracted much attention in recent years (Shum et al., 2018; Kollar et al., 2018). An important challenge for building such conversation systems is the response selection problem, that is, selecting the best response to a given dialogue context from a set of candidate responses (Ritter et al., 2011).\nTo tackle this problem, different matching models are developed to measure the matching degree between a dialogue context and a response candidate (Wu et al., 2017; Zhou et al., 2018; Lu et al., 2019; Gu et al., 2019). Despite their differences,\n∗The main body of this work was done during internship at Tencent Inc. The first two authors contributed equally. Yan Wang is the corresponding author.\nmost prior works train the model with data constructed by a simple heuristic. For each context, the human-written response is considered as positive (i.e., an appropriate response) and the responses from other dialogue contexts are considered as negatives (i.e., inappropriate responses). In practice, the negative responses are often randomly sampled and the training objective ensures that the positive response scores are higher than the negative ones.\nRecently, some researchers (Li et al., 2019; Lin et al., 2020) have raised the concern that randomly sampled negative responses are often too trivial (i.e., totally irrelevant to the dialogue context). Models trained with trivial negative responses may fail to handle strong distractors in real-world scenarios. Essentially, the problem stems from the ignorance of the diversity in context-response matching degree. In other words, all random responses are treated as equally negative regardless of their different distracting strengths. For example, Ta-\nble 1 shows a conversation between two speakers and two negative responses (N1, N2) are presented. For N1, one can easily dispel its appropriateness as it unnaturally diverges from the TV show topic. On the other hand, N2 is a strong distractor as it overlaps significantly with the context (e.g., fantasy series and Game of Thrones). Only with close observation we can find that N2 does not maintain the coherence of the discussion, i.e., it starts a parallel discussion about an actor in Game of Thrones rather than elaborating on the enjoyable properties of the TV series. In addition, we also observe a similar phenomenon on the positive side. For different training context-response pairs, their pairwise relevance also varies. In Table 1, two positive responses (P1, P2) are provided for the given context. For P1, one can easily confirm its validity as it naturally replies the context. As for P2, while it expatiates on the enjoyable properties of the TV series, it does not exhibit any obvious matching clues (e.g., lexical overlap with the context). Therefore, to correctly identify P2, its relationship with the context must be carefully reasoned by the model.\nInspired by the above observations, in this work, we propose to employ the idea of curriculum learning (CL) (Bengio et al., 2009). The key to applying CL is to specify a proper learning scheme under which all training examples are learned. By analyzing the characteristics of the concerned task, we tailor-design a hierarchical curriculum learning (HCL) framework. Specifically, our learning framework consists of two complementary curriculum strategies, corpus-level curriculum (CC) and instance-level curriculum (IC), covering the two distinct aspects of response selection. In CC, the model gradually increases its ability in finding matching clues through an easy-to-difficult arrangement of positive context-response pairs. In IC, we sort all negative responses according to their distracting strength such that the model’s capability of identifying the mismatching information can be progressively strengthened.\nNotably, our learning framework is independent to the choice of matching models. For a comprehensive evaluation, we evaluate our approach on three representative matching models, including the current state of the art. Results on three benchmark datasets demonstrate that the proposed learning framework leads to remarkable performance improvements across all evaluation metrics.\nIn a nutshell, our contributions can be summa-\nrized as: (1) We propose a hierarchical curriculum learning framework to tackle the task of dialogue response selection; and (2) Empirical results on three benchmark datasets show that our approach can significantly improve the performance of various strong matching models, including the current state of the art."
    }, {
      "heading" : "2 Background",
      "text" : "Given a dataset D = {(ci, ri)}|D|i=1, the learning of a matching model s(·, ·) is to correctly identify the positive response ri conditioned on the dialogue context ci from a set of negative responses R−i . The learning objective is typically defined as\nLs = m∑ j=1 max{0, 1−s(ci, ri)+s(ci,R−ij)}, (1)\nwhere m is the number of negative responses associated with each training context-response pair. In most existing studies (Wu et al., 2017; Zhou et al., 2018; Gu et al., 2019), the training negative responsesR−i are randomly selected from the dataset D. Recently, Li et al. (2019) and Lin et al. (2020) proposed different approaches to strengthen the training negatives. In testing, for any contextresponse (c, r), the models give a score s(c, r) that reflects their pairwise matching degree. Therefore, it allows the user to rank a set of response candidates according to the scores for response selection."
    }, {
      "heading" : "3 Methodology",
      "text" : ""
    }, {
      "heading" : "3.1 Overview",
      "text" : "We propose a hierarchical curriculum learning (HCL) framework for training neural matching models. It consists of two complementary curricula: (1) corpus-level curriculum (CC); and (2) instance-level curriculum (IC). Figure 1 illustrates the relationship between these two strategies. In CC (§3.2), the training context-response pairs with lower difficulty are presented to the model before harder pairs. This way, the model gradually increases its ability to find the matching clues contained in the response candidate. As for IC (§3.3), it controls the difficulty of negative responses that associated with each training context-response pair. Starting from easier negatives, the model progressively strengthens its ability to identify the mismatching information (e.g., semantic incoherence) in the response candidate. The following gives a detailed description of the proposed approach."
    }, {
      "heading" : "3.2 Corpus-Level Curriculum",
      "text" : "Given the dataset D = {(ci, ri)}|D|i=1, the corpuslevel curriculum (CC) arranges the ordering of different training context-response pairs. The model first learns to find easier matching clues from the pairs with lower difficulty. As the training progresses, harder cases are presented to the model to learn less obvious matching signals. Two examples are shown in the left part of Figure 1. For the easier pair, the context and the positive response are semantically coherent as well as lexically overlapped (e.g., TV series and Game of Thrones) with each other and such matching clues are simple for the model to learn. As for the harder case, the positive response can only be identified via numerical reasoning, which makes it harder to learn.\nDifficulty Function. To measure the difficulty of each training context-response pair (ci, ri), we adopt a pre-trained ranking model G(·, ·) (§3.4) to calculate its relevance score as G(ci, ri). Here, a higher score of G(ci, ri) corresponds to a higher relevance between ci and ri and vice versa. Then, for each pair (ci, ri) ∈ D, its corpus-level difficulty dcc(ci, ri) is defined as\ndcc(ci, ri) = 1.0− G(ci, ri)\nmax(ck,rk)∈DG(ck, rk) , (2)\nwhere dcc(ci, ri) is normalized to [0.0, 1.0]. Here, a lower difficulty score indicates the pair (ci, ri) is\neasier for the model to learn and vise versa.\nPacing Function. In training, to select the training context-response pairs with appropriate difficulty, we define a corpus-level pacing function, pcc(t), which controls the pace of learning from easy to hard instances. In other words, at time step t, pcc(t) represents the upper limit of difficulty and the model is only allowed to use the training instances (ci, ri) whose corpus-level difficulty score dcc(ci, ri) is lower than pcc(t). In this work, we propose a simple functional form for pcc(t)1 as\npcc(t) =\n{ 1.0−pcc(0)\nT · t+ pcc(0) if t ≤ T, 1.0 otherwise,\nwhere pcc(0) is a predefined initial value. At the training warm up stage (first T steps), we learn a basic matching model with a easy subset of the training data. In this subset, the difficulty of all samples are lower than pcc(t). After pcc(t) becomes 1.0 (at time step T ), the corpus-level curriculum is completed and the model can then freely access the entire dataset. In Figure 2(a), we give an illustration of the corpus-level curriculum."
    }, {
      "heading" : "3.3 Instance-Level Curriculum",
      "text" : "As a complement of CC, the instance-level curriculum (IC) controls the difficulty of negative responses. For an arbitrary training context-response 1More sophisticated designs for the function pcc(t) are possible, but we do not consider them in this work.\npair (ci, ri), while its associated negative responses can be any responses rj (s.t. j 6= i) in the training set, the difficulties of different rj are diverse. Some examples are presented in the right part of Figure 1. We see that the negative responses with lower difficulty are always simple to spot as they are often obviously off the topic. As for the harder negatives, the model need to identify the fine-grained semantic incoherence between them and the context.\nThe main purpose of IC is to select negative responses with appropriate difficulty based on the state of the learning process. At the beginning, the negative responses are randomly sampled from the entire training set, so that most of them are easy to distinguish. As the training evolves, IC gradually increases the difficulty of negative responses by sampling them from the responses with higher difficulty (i.e., from a harder subset of the training data). In this way, the model’s ability in finding the mismatching information is progressively strengthened and will be more robust when handling those strong distractors in real-world scenarios.\nDifficulty Function. Given a specific training instance (ci, ri), we define the difficulty of an arbitrary response rj (s.t. j 6= i) as its rank in a sorted list of relevance score in descending order,\ndic(ci, rj) = sortrj∈D,j 6=i(G(ci, rj)). (3)\nIn this formula, the response rh with the highest relevance score, i.e., rh = maxrj∈D,j 6=iG(ci, rj), has a rank of 1, thus dic(ci, rh) = 1. For the response rl with the lowest relevance score, i.e., rl = minrj∈D,j 6=iG(ci, rj), has a rank of |D|, thus dic(ci, rl) = |D|. Here, a smaller rank means the corresponding negative response is more relevant to the context ci, thus it is more difficult for the model to distinguish.\nPacing Function. Similar to CC, in IC, the pace of learning from easy to difficult negative responses is controlled by an instance-level pacing function, pic(t). It adjusts the size of the sampling space (in log scale) from which the negative responses are sampled from. Given a training instance (ci, ri), at time step t, the negative examples are sampled from the responses rj (s.t. j 6= i) whose rank is smaller than 10pic(t) (dic(ci, rj) ≤ 10pic(t)), i.e., the negative responses are sampled from a subset of the training data which consists of the top-10pic(t) relevant responses in relation to ci. The smaller the pic(t) is, the harder the sampled negatives will be. In this work, we define the function pic(t) as\npic(t) =\n{ (k0−kT )\nT · (T − t) + kT if t ≤ T, kT if t > T,\nwhere T is the same as the one in the corpus-level pacing function pcc(t). k0 = log |D| 10 , meaning that, at the start of training, the negative responses are sampled from the entire training set D. kT is a hyperparameter and it is smaller than k0. After pic(t) becomes kT (at step T ), the instance-level curriculum is completed. For the following training steps, the size of the sampling space is fixed at 10kT . An example of pic(t) is depicted in Figure 2(b)."
    }, {
      "heading" : "3.4 Hierarchical Curriculum Learning",
      "text" : "Model Training. Our learning framework jointly employs the corpus-level and instance-level curriculum. For each training step, we construct a batch of training data as follows: First, we select the positive context-response pairs according to the corpus-level pacing function pcc(t). Then, for each instance in the selected batch, we sample its associated negative examples according to the instance-\nAlgorithm 1: Hierarchical Curriculum Learning\nInput :Dataset, D = {(ci, ri)}|D|i=1; model trainer, T , that takes batches of training data as input to optimize the matching model; corpus-level difficulty and pacing function, dcc and pcc; instance-level difficulty and pacing function, dic and pic; number of negative responses, m;\n1 for train step t = 1, ... do 2 Uniformly sample one batch of context-response\npairs, Bt, from all (ci, ri) ∈ D, such that dcc(ci, ri) ≤ pcc(t), as shown in Figure 2(a).\n3 for (cj , rj) in Bt do 4 Sample m negative responses,R−j , from all\nresponses r, where r 6= rj , that satisfies the condition dic(cj , r) ≤ 10pic(t).\n5 end 6 Invoke the trainer, T , using {(ck, rk,R−k )} |Bt| k=1 as input to optimize the model using Eq. (1). 7 end\nOutput :Trained Matching Model\nlevel pacing function pic(t). Details of our learning framework are presented in Algorithm 1.\nFast Ranking Model. As described in Eq. (2) and (3), our framework requires a ranking model G(·, ·) that efficiently measures the pairwise relevance of millions of possible context-response combinations. In this work, we construct G(·, ·) as an non-interaction matching model with dualencoder structure such that we can precompute all contexts and responses offline and store them in cache. For any context-response pair (c, r), its pairwise relevance G(c, r) is defined as\nG(c, r) = Ec(c) TEr(r), (4)\nwhere Ec(c) and Er(r) are the dense context and response representations produced by a context encoder Ec(·) and a response encoder Er(·)2.\nOffline Index. After training the ranking model on the same response selection dataset D using the in-batch negative objective (Karpukhin et al., 2020), we compute the dense representations of all contexts and responses contained in D. Then, as described in Eq. (4), the relevance scores of all possible combinations of the contexts and responses in D can be easily computed through the dot product between their representations. After this step, we can compute the corpus-level and instance-level difficulty of all possible combinations and cache them in memory for a fast access in training.\n2The encoders can be any model, e.g., LSTM (Hochreiter and Schmidhuber, 1997) and Transformers (Vaswani et al., 2017)."
    }, {
      "heading" : "4 Related Work",
      "text" : "Dialogue Response Selection. Early studies in this area devoted to the response selection for single-turn conversations (Wang et al., 2013; Tan et al., 2016; Su et al., 2020). Recently, researchers turned to the scenario of multi-turn conversations and many sophisticated neural network architectures have been devised (Wu et al., 2017; Gu et al., 2019; Zhou et al., 2018; Gu et al., 2020).\nThere is an emerging line of research studying how to improve existing matching models with better learning algorithms. Wu et al. (2018) proposed to adopt a Seq2seq model as weak teacher to guide the training process. Feng et al. (2019) designed a co-teaching framework to eliminate the training noises. Similar to our work, Li et al. (2019) proposed to alleviate the problem of trivial negatives by sampling stronger negatives. Lin et al. (2020) attempted to create negative examples with a retrieval system and a pre-trained generation model. In contrast to their studies, we not only enlarge the set of negative examples but also arrange the negative examples in an easy-to-diffuclt fashion.\nCurriculum Learning. Curriculum Learning (Bengio et al., 2009) is reminiscent of the cognitive process of human being. Its core idea is first learning easier concepts and then gradually transitioning to more complex concepts based on some predefined learning schemes. Curriculum learning (CL) has demonstrated its benefits in various machine learning tasks (Spitkovsky et al., 2010; Ilg et al., 2017; Li et al., 2017; Svetlik et al., 2017; Liu et al., 2018; Platanios et al., 2019). Recently, Penha and Hauff (2020) employed the idea of CL to tackle the response selection task. However, they only apply curriculum learning for the positive-side response selection, while ignoring the diversity of the negative responses."
    }, {
      "heading" : "5 Experiment Setups",
      "text" : ""
    }, {
      "heading" : "5.1 Datasets and Evaluation Metrics",
      "text" : "We test our approach on three benchmark datasets.\nDouban Dataset. This dataset (Wu et al., 2017) consists of multi-turn Chinese conversation data crawled from Douban group3. The size of training, validation and test set are 500k, 25k and 1k. In the test set, each dialogue context is paired with 10 candidate responses. Following previous works, 3https://www.douban.com/group\nwe report the results of Mean Average Precision (MAP), Mean Reciprocal Rank (MRR) and Precision at Position 1 (P@1). In addition, we also report the results of R10@1, R10@2, R10@5, where Rn@k means recall at position k in n candidates.\nUbuntu Dataset. This dataset (Lowe et al., 2015) contains multi-turn dialogues collected from chat logs of the Ubuntu Forum. The training, validation and test size are 500k, 50k and 50k. Each dialogue context is paired with 10 response candidates. Following previous studies, we use R2@1, R10@1, R10@2 and R10@5 as evaluation metrics.\nE-Commerce Dataset. This dataset (Zhang et al., 2018) consists of Chinese conversations between customers and customer service staff from Taobao4. The size of training, validation and test set are 500k, 25k and 1k. In the test set, each dialogue context is paired with 10 candidate responses. Rn@k are employed as the evaluation metrics."
    }, {
      "heading" : "5.2 Baseline Models",
      "text" : "In the experiments, we compare our approach with the following models that can be summarized into three categories.\nSingle-turn Matching Models. This type of models treats all dialogue context as a single long utterance and then measures the relevance score between the context and response candidates, including RNN (Lowe et al., 2015), CNN (Lowe et al., 2015), LSTM (Lowe et al., 2015), Bi-LSTM\n4www.taobao.com\n(Kadlec et al., 2015), MV-LSTM (Wan et al., 2016) and Match-LSTM (Wang and Jiang, 2016).\nMulti-turn Matching Models. Instead of treating the dialogue context as one single utterance, these models aggregate information from different utterances in more sophisticated ways, including DL2R (Yan et al., 2016), Multi-View (Zhou et al., 2016), DUA (Zhang et al., 2018), DAM (Zhou et al., 2018), MRFN (Tao et al., 2019a), IOI (Tao et al., 2019b), SMN (Wu et al., 2017) and MSN (Yuan et al., 2019).\nBERT-based Matching Models. Given the recent advances of pre-trained language models (Devlin et al., 2019), Gu et al. (2020) proposed the SA-BERT model which adapts BERT for the task of response selection and it is the current state-ofthe-art model on the Douban and Ubuntu dataset."
    }, {
      "heading" : "5.3 Implementation Details",
      "text" : "For all experiments, we set the value of pcc(0) in the corpus-level pacing function pcc(t) as 0.3, meaning that all models start training with the context-response pairs whose corpus-level difficulty is lower than 0.3. For the instance-level pacing function pic(t), the value of kT is set as 3, meaning that, after IC is completed, the negative responses of each training instance are sampled from the top-103 relevant responses. In the experiments, each matching model is trained for 40, 000 steps with a batch size of 128, and we set the T in both pcc(t) and pic(t) as half of the total training steps, i.e., T = 20, 000. To build the context and\nresponse encoders in the ranking model G(·, ·), we use a 3-layer transformers with a hidden size of 256. We select two representative models (SMN and MSN) along with the state-of-the-art SA-BERT to test the proposed learning framework. To better simulate the true testing environment, the number of negative responses (m in Eq. (1)) is set to be 5."
    }, {
      "heading" : "6 Result and Analysis",
      "text" : ""
    }, {
      "heading" : "6.1 Main Results",
      "text" : "Table 2 shows the results on Douban, Ubuntu, and E-Commerce datasets, where X+HCL means training the model X with the proposed learning HCL. We can see that HCL significantly improves the performance of all three matching models in terms of all evaluation metrics, showing the robustness and universality of our approach. We also observe that, by training with HCL, a model (MSN) without using pre-trained language model can even surpass the state-of-the-art model using pre-trained language model (SA-BERT) on Douban dataset. These results suggest that, while the training strategy is under-explored in previous studies, it could be very decisive for building a competent response selection model."
    }, {
      "heading" : "6.2 Effect of CC and IC",
      "text" : "To reveal the individual effects of CC and IC, we train different models on Douban dataset by remov-\ning either CC or IC. The experimental results are shown in Table 3, from which we see that both CC and IC make positive contributions to the overall performance when used alone. Only utilizing IC leads to larger improvements than only using CC. This observation suggests that the ability of identifying the mismatching information is a more important factor for the model to achieve its optimal performance. However, the optimal performance is achieved when CC and IC are combined, indicating that CC and IC are complementary to each other."
    }, {
      "heading" : "6.3 Contrast to Existing Learning Strategies",
      "text" : "Next, we compare our approach with other learning strategies proposed recently (Li et al., 2019; Penha and Hauff, 2020; Lin et al., 2020). We use Semi, CIR, and Gray to denote the approaches in Li et al. (2019), Penha and Hauff (2020), and Lin et al. (2020) respectively, where Gray is the current state of the art. We conduct experiments on Douban and Ubuntu datasets and the experimental results of three matching models are listed in Table 4. From the results, we can see that our approach consistently outperforms other learning strategies in all settings. The performance gains of our approach are even more remarkable given its simplicity; it does not require running additional generation models (Lin et al., 2020) or re-scoring negative samples at different epochs (Li et al., 2019)."
    }, {
      "heading" : "6.4 Further Analysis on HCL",
      "text" : "In this part, we study how the key hyper-parameters affect the performance of HCL, including the initial difficulty of CC, pcc(0), and the curriculum length of IC, kT .5 In addition, we also investigate the effect of different ranking model choices.\nInitial Difficulty of CC. We run sensitivity analysis experiments on Douban dataset with the SMN model by tuning pcc(0) in the corpus-level pacing function pcc(t). The results of P@1 and R10@2 in terms of pcc(0) and kT are shown in Figure 3(a). We observe that when pcc(0) is small (i.e., pcc(0) ≤ 0.3), the model performances are relatively similar. When pcc(0) approaches to 1.0, the results drop significantly. It concurs with our expectation that, in CC, the model should start learning with training context-response pairs of lower difficulty. Once pcc(0) becomes 1.0, the CC is disabled, resulting the lowest model performances.\nCurriculum Length of IC. Similair to pcc(0), we also run sensitivity analysis experiments by tuning kT in the instance-level pacing function pic(t) and Figure 3(b) shows the results. We observe that\n5Our experiments show that other hyper-parameter settings have little impact on the model performance.\na too small or too large KT results in performance degradation. When kT is too small, after IC is completed, the negative examples are only sampled from a very small subset of the training data that consists of responses with high relevance. In this case, the sampled responses might be false negatives that should be deemed as positive cases. Thus, learning to treat those responses as true negatives could harm the model performance. On the other hand, as kT increases, the effect of IC becomes less obvious. When kT = log500k10 (|D|= 500k), IC is completely disabled, leading to the further decrease of model performances.\nRanking Model Architecture. Lastly, we examine the effect of the choice of the ranking model architecture. We build two ranking model variants by replacing the Transformers module Ec(·) and Er(·) in Eq. (4) with other modules. For the first case, we use 3-layer BiLSTM with a hidden size of 256. For the second one, we use BERT-base (Devlin et al., 2019) model. Then, we train the matching models using the proposed HCL but with different ranking models as the scoring basis.\nThe results on Douban dataset are shown in Table 5. We first compare the performance of different ranking models by directly using them to select the best response. The results are shown in the “Ranking Model” row of Table 5. Among all three variants, BERT performs the best but it is still less accurate than these sophisticated matching models. Second, we study the effect of different ranking models on the matching model performance. We see that, for different matching models, Transformers and BERT perform comparably but the results from BiLSTM are much worse. This further leads to a conclusion that, while the choice of ranking\nmodel does have impact on the overall results, the improvement of the ranking model does not necessarily lead to the improvement of matching models once the ranking model achieves certain accuracy."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this work, we propose a novel hierarchical curriculum learning framework for training response selection models for multi-turn conversations. During training, the proposed framework simultaneously employs corpus-level and instance-level curricula to dynamically select suitable training data based on the state of the learning process. Extensive experiments and analysis on two benchmark datasets show that our approach can significantly improve the performance of various strong matching models on all evaluation metrics."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The authors wish to thank Jialu Xu and Sihui Wang for their insightful discussions and support. Many thanks to our anonymous reviewers for their suggestions and comments.\nEthical Statement\nWe honor and support the ACL code of Ethics. Dialogue response selection aims to build a retrievalbased dialogue system which better interacts with users. The selection of the best response does not involve any bias towards to the participants. All datasets used in this work are from previously published works, and in our view, do not have any attached privacy or ethical issues."
    }, {
      "heading" : "A Ranking Model Training",
      "text" : "Here we provide more details on how to train the neural ranking model G(·, ·) that serves as the scoring basis in the proposed HCL framework.\nModelling. Given a dialogue context c and a response r, their context-response relevance score is defined as\nG(c, r) = Ec(c) TEr(r). (5)\nNote that, the context c is a long sequence which is acquired by concatenating all utterances in the dialogue context. The Ec(c) and Er(r) are the context and response encoder. The context encoder Ec(·) takes the token sequence c = c0, ..., c|c| and returns the context representation Ec(c) by taking the output state corresponds to the last token c|c|. The same operation is applied when computing the response representation Er(r). In practice, the choice of E(·) could be any sequence model, e.g., LSTM (Hochreiter and Schmidhuber, 1997), RNN (Elman, 1990), Transformers (Vaswani et al., 2017), and BERT (Devlin et al., 2019). In this work, we choose Transformers as our modelling basis.\nLearning. The goal of training the ranking model is to create a vector space such that similar pair of dialogue contexts and responses have higher relevance score than the dissimilar ones.\nWe train the ranking model with the same response selection data set D using the in-batch negative objective (Karpukhin et al., 2020). For a sampled batch of training data {(ck, rk)}bk=1, where b is the batch size, the sampled contexts and responses are separately encoded using Eq. (4) as Ec(C) ∈ Rb×n and Er(R) ∈ Rb×n, where n is the output size of encoder modules. Next, the score matrix S is computed as Ec(C)TEr(R) ∈ Rb×b. The in-batch negative objective (Karpukhin et al., 2020) is then defined as minimizing the negative log likelihood of positive responses\nLG = − 1\nb b∑ i=1 log exp(Sii) exp(Sii) + ∑ j 6=i exp(Sij) ,\n(6) where Sij = G(ci, rj).\nIn this work, we build the context and response encoder with a 3-layer Transformers and its output size is 256. For all considered datasets, we pre-train the ranking model with a batch size b = 128 for 20, 000 steps. For optimization, we use the Adam\noptimizer (Kingma and Ba, 2015) with a learning rate of 2e-5. For more details, we refer the readers to the original paper (Karpukhin et al., 2020)."
    }, {
      "heading" : "B Hyper-parameter Setup",
      "text" : "In the following, we provide details on the search space for the hyperparameters. For number of negative responses m in Eq. (1), the search space is {1, 5, 10, 15, 20}, where the underline indicates the number selected based on the model performance on the validation set. The search space for the pcc(0) in corpus-level pacing function pcc(t) is {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. For the kT in instance-level pacing function pic(t), the search space is {1, 2, 3, 4, 5, log500k10 }, where 500k is the size of the training set.\nEach matching model is optimized with Adam optimizer (Kingma and Ba, 2015) with a learning rate of 2e-5 and a batch size of 128. The total training step is set as 40, 000. T in the corpuslevel pacing fucntion pcc(t) and the instance-level pacing function pic(t) is set as the half of the total training steps (i.e., T = 20000)."
    } ],
    "references" : [ {
      "title" : "2019. BERT: pre-training",
      "author" : [ "Kristina Toutanova" ],
      "venue" : null,
      "citeRegEx" : "Toutanova.,? \\Q2019\\E",
      "shortCiteRegEx" : "Toutanova.",
      "year" : 2019
    }, {
      "title" : "Finding structure in time",
      "author" : [ "Jeffrey L. Elman." ],
      "venue" : "Cogn. Sci., 14(2):179–211.",
      "citeRegEx" : "Elman.,? 1990",
      "shortCiteRegEx" : "Elman.",
      "year" : 1990
    }, {
      "title" : "Learning a matching model with co-teaching for multi-turn response selection in retrieval-based dialogue systems",
      "author" : [ "Jiazhan Feng", "Chongyang Tao", "Wei Wu", "Yansong Feng", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Proceedings of the 57th Conference of the As-",
      "citeRegEx" : "Feng et al\\.,? 2019",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2019
    }, {
      "title" : "Speaker-aware BERT for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Jia-Chen Gu", "Tianda Li", "Quan Liu", "Zhen-Hua Ling", "Zhiming Su", "Si Wei", "Xiaodan Zhu." ],
      "venue" : "CIKM ’20: The 29th ACM International Conference on Information",
      "citeRegEx" : "Gu et al\\.,? 2020",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2020
    }, {
      "title" : "Interactive matching network for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Jia-Chen Gu", "Zhen-Hua Ling", "Quan Liu." ],
      "venue" : "Proceedings of the 28th ACM International Conference on Information and Knowledge Management, CIKM 2019,",
      "citeRegEx" : "Gu et al\\.,? 2019",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2019
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural Comput., 9(8):1735– 1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Flownet 2.0: Evolution of optical flow estimation with deep networks",
      "author" : [ "Eddy Ilg", "Nikolaus Mayer", "Tonmoy Saikia", "Margret Keuper", "Alexey Dosovitskiy", "Thomas Brox" ],
      "venue" : "IEEE Conference on Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Ilg et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Ilg et al\\.",
      "year" : 2017
    }, {
      "title" : "Improved deep learning baselines for ubuntu corpus dialogs",
      "author" : [ "Rudolf Kadlec", "Martin Schmid", "Jan Kleindienst." ],
      "venue" : "CoRR, abs/1510.03753.",
      "citeRegEx" : "Kadlec et al\\.,? 2015",
      "shortCiteRegEx" : "Kadlec et al\\.",
      "year" : 2015
    }, {
      "title" : "Dense passage retrieval for open-domain question answering",
      "author" : [ "Vladimir Karpukhin", "Barlas Oguz", "Sewon Min", "Patrick S.H. Lewis", "Ledell Wu", "Sergey Edunov", "Danqi Chen", "Wen-tau Yih." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Meth-",
      "citeRegEx" : "Karpukhin et al\\.,? 2020",
      "shortCiteRegEx" : "Karpukhin et al\\.",
      "year" : 2020
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "The alexa meaning representation language",
      "author" : [ "Thomas Kollar", "Danielle Berry", "Lauren Stuart", "Karolina Owczarzak", "Tagyoung Chung", "Lambert Mathias", "Michael Kayser", "Bradford Snow", "Spyros Matsoukas." ],
      "venue" : "Proceedings of the 2018 Confer-",
      "citeRegEx" : "Kollar et al\\.,? 2018",
      "shortCiteRegEx" : "Kollar et al\\.",
      "year" : 2018
    }, {
      "title" : "Sampling matters! an empirical study of negative sampling strategies for learning of matching models in retrievalbased dialogue systems",
      "author" : [ "Jia Li", "Chongyang Tao", "Wei Wu", "Yansong Feng", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Multiple instance curriculum learning for weakly supervised object detection",
      "author" : [ "Siyang Li", "Xiangxin Zhu", "Qin Huang", "Hao Xu", "C.-C. Jay Kuo." ],
      "venue" : "British Machine Vision Conference 2017, BMVC 2017, London, UK, September 4-7, 2017. BMVA",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "The world is not binary: Learning to rank with grayscale data for dialogue response selection",
      "author" : [ "Zibo Lin", "Deng Cai", "Yan Wang", "Xiaojiang Liu", "HaiTao Zheng", "Shuming Shi" ],
      "venue" : null,
      "citeRegEx" : "Lin et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "Curriculum learning for natural answer generation",
      "author" : [ "Cao Liu", "Shizhu He", "Kang Liu", "Jun Zhao." ],
      "venue" : "Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden, pages",
      "citeRegEx" : "Liu et al\\.,? 2018",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2018
    }, {
      "title" : "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems",
      "author" : [ "Ryan Lowe", "Nissan Pow", "Iulian Serban", "Joelle Pineau." ],
      "venue" : "Proceedings of the SIGDIAL 2015 Conference, The 16th Annual Meeting of the Spe-",
      "citeRegEx" : "Lowe et al\\.,? 2015",
      "shortCiteRegEx" : "Lowe et al\\.",
      "year" : 2015
    }, {
      "title" : "Constructing interpretive spatio-temporal features for multiturn responses selection",
      "author" : [ "Junyu Lu", "Chenbin Zhang", "Zeying Xie", "Guang Ling", "Tom Chao Zhou", "Zenglin Xu." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational",
      "citeRegEx" : "Lu et al\\.,? 2019",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2019
    }, {
      "title" : "Curriculum learning strategies for IR",
      "author" : [ "Gustavo Penha", "Claudia Hauff." ],
      "venue" : "Advances in Information Retrieval - 42nd European Conference on IR Research, ECIR 2020, Lisbon, Portugal, April 14-17, 2020, Proceedings, Part I, volume 12035 of",
      "citeRegEx" : "Penha and Hauff.,? 2020",
      "shortCiteRegEx" : "Penha and Hauff.",
      "year" : 2020
    }, {
      "title" : "Competence-based curriculum learning",
      "author" : [ "Emmanouil Antonios Platanios", "Otilia Stretcu", "Graham Neubig", "Barnabás Póczos", "Tom M. Mitchell" ],
      "venue" : null,
      "citeRegEx" : "Platanios et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Platanios et al\\.",
      "year" : 2019
    }, {
      "title" : "Data-driven response generation in social media",
      "author" : [ "Alan Ritter", "Colin Cherry", "William B. Dolan." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, 27-31 July 2011, John McIntyre Conference",
      "citeRegEx" : "Ritter et al\\.,? 2011",
      "shortCiteRegEx" : "Ritter et al\\.",
      "year" : 2011
    }, {
      "title" : "From eliza to xiaoice: Challenges and opportunities with social chatbots",
      "author" : [ "Heung-Yeung Shum", "Xiaodong He", "Di Li." ],
      "venue" : "CoRR, abs/1801.01957.",
      "citeRegEx" : "Shum et al\\.,? 2018",
      "shortCiteRegEx" : "Shum et al\\.",
      "year" : 2018
    }, {
      "title" : "From baby steps to leapfrog: How ”less is more” in unsupervised dependency parsing",
      "author" : [ "Valentin I. Spitkovsky", "Hiyan Alshawi", "Daniel Jurafsky." ],
      "venue" : "Human Language Technologies: Conference of the North American Chapter of the Association of",
      "citeRegEx" : "Spitkovsky et al\\.,? 2010",
      "shortCiteRegEx" : "Spitkovsky et al\\.",
      "year" : 2010
    }, {
      "title" : "Prototype-to-style: Dialogue generation with style-aware editing on retrieval memory",
      "author" : [ "Yixuan Su", "Yan Wang", "Simon Baker", "Deng Cai", "Xiaojiang Liu", "Anna Korhonen", "Nigel Collier." ],
      "venue" : "CoRR, abs/2004.02214.",
      "citeRegEx" : "Su et al\\.,? 2020",
      "shortCiteRegEx" : "Su et al\\.",
      "year" : 2020
    }, {
      "title" : "Automatic curriculum graph generation for reinforcement learning agents",
      "author" : [ "Maxwell Svetlik", "Matteo Leonetti", "Jivko Sinapov", "Rishi Shah", "Nick Walker", "Peter Stone." ],
      "venue" : "Proceedings of the ThirtyFirst AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Svetlik et al\\.,? 2017",
      "shortCiteRegEx" : "Svetlik et al\\.",
      "year" : 2017
    }, {
      "title" : "Lstm-based deep learning models for non-factoid answer selection",
      "author" : [ "Ming Tan", "Cicero dos Santos", "Bing Xiang", "Bowen Zhou" ],
      "venue" : null,
      "citeRegEx" : "Tan et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2016
    }, {
      "title" : "Multirepresentation fusion network for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Chongyang Tao", "Wei Wu", "Can Xu", "Wenpeng Hu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Proceedings of the Twelfth ACM International Con-",
      "citeRegEx" : "Tao et al\\.,? 2019a",
      "shortCiteRegEx" : "Tao et al\\.",
      "year" : 2019
    }, {
      "title" : "One time of interaction may not be enough: Go deep with an interaction-over-interaction network for response selection in dialogues",
      "author" : [ "Chongyang Tao", "Wei Wu", "Can Xu", "Wenpeng Hu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Proceedings of the 57th Con-",
      "citeRegEx" : "Tao et al\\.,? 2019b",
      "shortCiteRegEx" : "Tao et al\\.",
      "year" : 2019
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Match-srnn: Modeling the recursive matching structure with spatial RNN",
      "author" : [ "Shengxian Wan", "Yanyan Lan", "Jun Xu", "Jiafeng Guo", "Liang Pang", "Xueqi Cheng." ],
      "venue" : "Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Wan et al\\.,? 2016",
      "shortCiteRegEx" : "Wan et al\\.",
      "year" : 2016
    }, {
      "title" : "A dataset for research on short-text conversations",
      "author" : [ "Hao Wang", "Zhengdong Lu", "Hang Li", "Enhong Chen." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013, 18-21 October 2013, Grand Hy-",
      "citeRegEx" : "Wang et al\\.,? 2013",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning natural language inference with LSTM",
      "author" : [ "Shuohang Wang", "Jing Jiang." ],
      "venue" : "NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego",
      "citeRegEx" : "Wang and Jiang.,? 2016",
      "shortCiteRegEx" : "Wang and Jiang.",
      "year" : 2016
    }, {
      "title" : "Learning matching models with weak supervision for response selection in retrieval-based chatbots",
      "author" : [ "Yu Wu", "Wei Wu", "Zhoujun Li", "Ming Zhou." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018,",
      "citeRegEx" : "Wu et al\\.,? 2018",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2018
    }, {
      "title" : "Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Yu Wu", "Wei Wu", "Chen Xing", "Ming Zhou", "Zhoujun Li." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Wu et al\\.,? 2017",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2017
    }, {
      "title" : "Learning to respond with deep neural networks for retrievalbased human-computer conversation system",
      "author" : [ "Rui Yan", "Yiping Song", "Hua Wu." ],
      "venue" : "Proceedings of the 39th International ACM SIGIR conference on Research and Development in Informa-",
      "citeRegEx" : "Yan et al\\.,? 2016",
      "shortCiteRegEx" : "Yan et al\\.",
      "year" : 2016
    }, {
      "title" : "Multi-hop selector network for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Chunyuan Yuan", "Wei Zhou", "Mingming Li", "Shangwen Lv", "Fuqing Zhu", "Jizhong Han", "Songlin Hu." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in",
      "citeRegEx" : "Yuan et al\\.,? 2019",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2019
    }, {
      "title" : "Modeling multiturn conversation with deep utterance aggregation",
      "author" : [ "Zhuosheng Zhang", "Jiangtong Li", "Pengfei Zhu", "Hai Zhao", "Gongshen Liu." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018, Santa",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Multi-view response selection for humancomputer conversation",
      "author" : [ "Xiangyang Zhou", "Daxiang Dong", "Hua Wu", "Shiqi Zhao", "Dianhai Yu", "Hao Tian", "Xuan Liu", "Rui Yan." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Lan-",
      "citeRegEx" : "Zhou et al\\.,? 2016",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2016
    }, {
      "title" : "Multi-turn response selection for chatbots with deep attention matching network",
      "author" : [ "Xiangyang Zhou", "Lu Li", "Daxiang Dong", "Yi Liu", "Ying Chen", "Wayne Xin Zhao", "Dianhai Yu", "Hua Wu." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Associa-",
      "citeRegEx" : "Zhou et al\\.,? 2018",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    }, {
      "title" : "The in-batch negative objective (Karpukhin et al., 2020) is then defined as minimizing the negative log likelihood of positive responses",
      "author" : [ "∈ Rb×b" ],
      "venue" : null,
      "citeRegEx" : "Rb×b.,? \\Q2020\\E",
      "shortCiteRegEx" : "Rb×b.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 20,
      "context" : "Building intelligent conversation systems is a longstanding goal of artificial intelligence and has attracted much attention in recent years (Shum et al., 2018; Kollar et al., 2018).",
      "startOffset" : 141,
      "endOffset" : 181
    }, {
      "referenceID" : 10,
      "context" : "Building intelligent conversation systems is a longstanding goal of artificial intelligence and has attracted much attention in recent years (Shum et al., 2018; Kollar et al., 2018).",
      "startOffset" : 141,
      "endOffset" : 181
    }, {
      "referenceID" : 19,
      "context" : "An important challenge for building such conversation systems is the response selection problem, that is, selecting the best response to a given dialogue context from a set of candidate responses (Ritter et al., 2011).",
      "startOffset" : 196,
      "endOffset" : 217
    }, {
      "referenceID" : 32,
      "context" : "To tackle this problem, different matching models are developed to measure the matching degree between a dialogue context and a response candidate (Wu et al., 2017; Zhou et al., 2018; Lu et al., 2019; Gu et al., 2019).",
      "startOffset" : 147,
      "endOffset" : 217
    }, {
      "referenceID" : 37,
      "context" : "To tackle this problem, different matching models are developed to measure the matching degree between a dialogue context and a response candidate (Wu et al., 2017; Zhou et al., 2018; Lu et al., 2019; Gu et al., 2019).",
      "startOffset" : 147,
      "endOffset" : 217
    }, {
      "referenceID" : 16,
      "context" : "To tackle this problem, different matching models are developed to measure the matching degree between a dialogue context and a response candidate (Wu et al., 2017; Zhou et al., 2018; Lu et al., 2019; Gu et al., 2019).",
      "startOffset" : 147,
      "endOffset" : 217
    }, {
      "referenceID" : 4,
      "context" : "To tackle this problem, different matching models are developed to measure the matching degree between a dialogue context and a response candidate (Wu et al., 2017; Zhou et al., 2018; Lu et al., 2019; Gu et al., 2019).",
      "startOffset" : 147,
      "endOffset" : 217
    }, {
      "referenceID" : 11,
      "context" : "Recently, some researchers (Li et al., 2019; Lin et al., 2020) have raised the concern that randomly sampled negative responses are often too trivial (i.",
      "startOffset" : 27,
      "endOffset" : 62
    }, {
      "referenceID" : 13,
      "context" : "Recently, some researchers (Li et al., 2019; Lin et al., 2020) have raised the concern that randomly sampled negative responses are often too trivial (i.",
      "startOffset" : 27,
      "endOffset" : 62
    }, {
      "referenceID" : 32,
      "context" : "In most existing studies (Wu et al., 2017; Zhou et al., 2018; Gu et al., 2019), the training negative responsesRi are randomly selected from the dataset D.",
      "startOffset" : 25,
      "endOffset" : 78
    }, {
      "referenceID" : 37,
      "context" : "In most existing studies (Wu et al., 2017; Zhou et al., 2018; Gu et al., 2019), the training negative responsesRi are randomly selected from the dataset D.",
      "startOffset" : 25,
      "endOffset" : 78
    }, {
      "referenceID" : 4,
      "context" : "In most existing studies (Wu et al., 2017; Zhou et al., 2018; Gu et al., 2019), the training negative responsesRi are randomly selected from the dataset D.",
      "startOffset" : 25,
      "endOffset" : 78
    }, {
      "referenceID" : 8,
      "context" : "After training the ranking model on the same response selection dataset D using the in-batch negative objective (Karpukhin et al., 2020), we compute the dense representations of all contexts and responses contained in D.",
      "startOffset" : 112,
      "endOffset" : 136
    }, {
      "referenceID" : 5,
      "context" : ", LSTM (Hochreiter and Schmidhuber, 1997) and Transformers (Vaswani et al.",
      "startOffset" : 7,
      "endOffset" : 41
    }, {
      "referenceID" : 27,
      "context" : ", LSTM (Hochreiter and Schmidhuber, 1997) and Transformers (Vaswani et al., 2017).",
      "startOffset" : 59,
      "endOffset" : 81
    }, {
      "referenceID" : 29,
      "context" : "Early studies in this area devoted to the response selection for single-turn conversations (Wang et al., 2013; Tan et al., 2016; Su et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 145
    }, {
      "referenceID" : 24,
      "context" : "Early studies in this area devoted to the response selection for single-turn conversations (Wang et al., 2013; Tan et al., 2016; Su et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 145
    }, {
      "referenceID" : 22,
      "context" : "Early studies in this area devoted to the response selection for single-turn conversations (Wang et al., 2013; Tan et al., 2016; Su et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 145
    }, {
      "referenceID" : 32,
      "context" : "Recently, researchers turned to the scenario of multi-turn conversations and many sophisticated neural network architectures have been devised (Wu et al., 2017; Gu et al., 2019; Zhou et al., 2018; Gu et al., 2020).",
      "startOffset" : 143,
      "endOffset" : 213
    }, {
      "referenceID" : 4,
      "context" : "Recently, researchers turned to the scenario of multi-turn conversations and many sophisticated neural network architectures have been devised (Wu et al., 2017; Gu et al., 2019; Zhou et al., 2018; Gu et al., 2020).",
      "startOffset" : 143,
      "endOffset" : 213
    }, {
      "referenceID" : 37,
      "context" : "Recently, researchers turned to the scenario of multi-turn conversations and many sophisticated neural network architectures have been devised (Wu et al., 2017; Gu et al., 2019; Zhou et al., 2018; Gu et al., 2020).",
      "startOffset" : 143,
      "endOffset" : 213
    }, {
      "referenceID" : 3,
      "context" : "Recently, researchers turned to the scenario of multi-turn conversations and many sophisticated neural network architectures have been devised (Wu et al., 2017; Gu et al., 2019; Zhou et al., 2018; Gu et al., 2020).",
      "startOffset" : 143,
      "endOffset" : 213
    }, {
      "referenceID" : 32,
      "context" : "This dataset (Wu et al., 2017) consists of multi-turn Chinese conversation data crawled from Douban group3.",
      "startOffset" : 13,
      "endOffset" : 30
    }, {
      "referenceID" : 15,
      "context" : "This dataset (Lowe et al., 2015) contains multi-turn dialogues collected from chat",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 15,
      "context" : "This type of models treats all dialogue context as a single long utterance and then measures the relevance score between the context and response candidates, including RNN (Lowe et al., 2015), CNN (Lowe et al.",
      "startOffset" : 172,
      "endOffset" : 191
    }, {
      "referenceID" : 28,
      "context" : ", 2015), MV-LSTM (Wan et al., 2016) and Match-LSTM (Wang and Jiang, 2016).",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 33,
      "context" : "ing the dialogue context as one single utterance, these models aggregate information from different utterances in more sophisticated ways, including DL2R (Yan et al., 2016), Multi-View (Zhou et al.",
      "startOffset" : 154,
      "endOffset" : 172
    }, {
      "referenceID" : 36,
      "context" : ", 2016), Multi-View (Zhou et al., 2016), DUA (Zhang et al.",
      "startOffset" : 20,
      "endOffset" : 39
    }, {
      "referenceID" : 32,
      "context" : ", 2019b), SMN (Wu et al., 2017) and MSN (Yuan et al.",
      "startOffset" : 14,
      "endOffset" : 31
    }, {
      "referenceID" : 11,
      "context" : "Next, we compare our approach with other learning strategies proposed recently (Li et al., 2019; Penha and Hauff, 2020; Lin et al., 2020).",
      "startOffset" : 79,
      "endOffset" : 137
    }, {
      "referenceID" : 17,
      "context" : "Next, we compare our approach with other learning strategies proposed recently (Li et al., 2019; Penha and Hauff, 2020; Lin et al., 2020).",
      "startOffset" : 79,
      "endOffset" : 137
    }, {
      "referenceID" : 13,
      "context" : "Next, we compare our approach with other learning strategies proposed recently (Li et al., 2019; Penha and Hauff, 2020; Lin et al., 2020).",
      "startOffset" : 79,
      "endOffset" : 137
    }, {
      "referenceID" : 13,
      "context" : "The performance gains of our approach are even more remarkable given its simplicity; it does not require running additional generation models (Lin et al., 2020) or re-scoring negative samples at different epochs (Li et al.",
      "startOffset" : 142,
      "endOffset" : 160
    }, {
      "referenceID" : 11,
      "context" : ", 2020) or re-scoring negative samples at different epochs (Li et al., 2019).",
      "startOffset" : 59,
      "endOffset" : 76
    } ],
    "year" : 2021,
    "abstractText" : "We study the learning of a matching model for dialogue response selection. Motivated by the recent finding that models trained with random negative samples are not ideal in real-world scenarios, we propose a hierarchical curriculum learning framework that trains the matching model in an “easy-to-difficult” scheme. Our learning framework consists of two complementary curricula: (1) corpus-level curriculum (CC); and (2) instance-level curriculum (IC). In CC, the model gradually increases its ability in finding the matching clues between the dialogue context and a response candidate. As for IC, it progressively strengthens the model’s ability in identifying the mismatching information between the dialogue context and a response candidate. Empirical studies on three benchmark datasets with three state-of-the-art matching models demonstrate that the proposed learning framework significantly improves the model performance across various evaluation metrics.",
    "creator" : "LaTeX with hyperref"
  }
}