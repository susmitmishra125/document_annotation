{
  "name" : "2021.acl-long.394.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Exploring Dynamic Selection of Branch Expansion Orders for Code Generation",
    "authors" : [ "Hui Jiang", "Chulun Zhou", "Fandong Meng", "Biao Zhang", "Jie Zhou", "Degen Huang", "Qingqiang Wu", "Jinsong Su" ],
    "emails" : [ "hjiang@stu.xmu.edu.cn", "clzhou@stu.xmu.edu.cn", "fandongmeng@tencent.com", "withtomzhou@tencent.com", "B.Zhang@ed.ac.uk", "huangdg@dlut.edu.cn", "wuqq@xmu.edu.cn", "jssu@xmu.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5076–5085\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n5076\nDue to the great potential in facilitating software development, code generation has attracted increasing attention recently. Generally, dominant models are Seq2Tree models, which convert the input natural language description into a sequence of tree-construction actions corresponding to the pre-order traversal of an Abstract Syntax Tree (AST). However, such a traversal order may not be suitable for handling all multi-branch nodes. In this paper, we propose to equip the Seq2Tree model with a context-based Branch Selector, which is able to dynamically determine optimal expansion orders of branches for multibranch nodes. Particularly, since the selection of expansion orders is a non-differentiable multi-step operation, we optimize the selector through reinforcement learning, and formulate the reward function as the difference of model losses obtained through different expansion orders. Experimental results and in-depth analysis on several commonly-used datasets demonstrate the effectiveness and generality of our approach. We have released our code at https: //github.com/DeepLearnXMU/CG-RL."
    }, {
      "heading" : "1 Introduction",
      "text" : "Code generation aims at automatically generating a source code snippet given a natural language (NL) description, which has attracted increasing attention recently due to its potential value in simplifying programming. Instead of modeling the abstract syntax tree (AST) of code snippets directly, most of methods for code generation convert AST into a sequence of tree-construction actions. This allows for using natural language generation (NLG) models, such as the widely-used encoder-decoder\nJoint work with Pattern Recognition Center, WeChat AI, Tencent Inc, China.\n*Equal contribution †Corresponding author\nmodels, and obtains great success (Ling et al., 2016; Dong and Lapata, 2016, 2018; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018, 2019; Hayati et al., 2018; Sun et al., 2019, 2020; Wei et al., 2019; Shin et al., 2019; Xu et al., 2020; Xie et al., 2021). Specifically, an encoder is first used to learn word-level semantic representations of the input NL description. Then, a decoder outputs a sequence of tree-construction actions, with which the corresponding AST is generated through pre-order traversal. Finally, the generated AST is mapped into surface codes via certain deterministic functions.\nGenerally, during the generation of dominant Seq2Tree models based on pre-order traversal, branches of each multi-branch nodes are expanded in a left-to-right order. Figure 1 gives an example of the NL-to-Code conversion conducted by a Seq2Tree model. At the timestep t1, the model generates a multi-branch node using the action a1 with the grammar containing three fields: type, name, and body. Thus, during the subsequent generation process, the model expands the node of t1 to sequentially generate several branches in a left-toright order, corresponding to the three fields of a1. The left-to-right order is a conventional bias for most human-beings to handle multi-branch nodes, which, however, may not be optimal for expanding branches. Alternatively, if we first expand the field name to generate a branch, which can inform us the name ‘e’, it will be easier to expand the field type with a ‘Exception’ branch due to the high co-occurrence of ‘e’ and ‘Exception’.\nTo verify this conjecture, we choose TRANX (Yin and Neubig, 2018) to construct a variant: TRANX-R2L, which conducts depth-first generation in a right-to-left manner, and then compare their performance on the DJANGO dataset. We find that about 93.4% of ASTs contain multi-branch nodes, and 17.38% of AST nodes are multi-branch\nones. Table 1 reports the experimental results. We can observe that 8.47% and 7.66% of multi-branch nodes can only be correctly handled by TRANX and TRANX-R2L, respectively. Therefore, we conclude that different multi-branch nodes have different optimal branch expansion orders, which can be dynamically selected based on context to improve the performance of conventional Seq2Tree models.\nIn this paper, we explore dynamic selection of branch expansion orders for code generation. Specifically, we propose to equip the conventional Seq2Tree model with a context-based Branch Selector, which dynamically quantifies the priorities of expanding different branches for multi-branch nodes during AST generations. However, such a non-differentiable multi-step operation poses a challenge to the model training. To deal with this issue, we apply reinforcement learning to train the extended Seq2Tree model. Particularly, we augment the conventional training objective with a reward function, which is based on the model training loss between different expansion orders of branches. In this way, the model is trained to determine optimal expansion orders of branches for multi-branch nodes, which will contribute to AST generations.\nTo summarize, the major contributions of our work are three-fold:\n• Through in-depth analysis, we point out that different orders of branch expansion are suitable for handling different multi-branch AST nodes, and thus dynamic selection of branch expansion orders has the potential to improve conventional Seq2Tree models. • We propose to incorporate a contextbased Branch Selector into the conventional Seq2Tree model and then employ reinforcement learning to train the extended model. To the best of our knowledge, our work is the first attempt to explore dynamic selection of branch expansion orders for code generation. • Experimental results and in-depth analyses\nDescription: if Exception , renamed to e , exception is caught\nCode: except Exception as e:\nAST\nAction Sequence:\n\uD835\uDC4E : excepthandler -> ExceptHandler(expr? type, expr? name, stmt* body)\n\uD835\uDC4E : expr -> Name(identifier id) \uD835\uDC4E : GenToken[Exception] \uD835\uDC4E : expr -> Name(identifier id) \uD835\uDC4E : GenToken[e]\n\uD835\uDC4E : Reduce\uD835\uDC4E\n\uD835\uDC61\n\uD835\uDC61\n\uD835\uDC61\n\uD835\uDC4E\n\uD835\uDC4E\n\uD835\uDC4E \uD835\uDC61\n\uD835\uDC61 \uD835\uDC4E\n\uD835\uDC4E \uD835\uDC61\nApplyConstr Reduce GenToken\ntoken\nconstructor\n\uD835\uDC4E\n\uD835\uDC61\n\uD835\uDC61\n\uD835\uDC61\n\uD835\uDC4E\n\uD835\uDC4E\n\uD835\uDC4E\n\uD835\uDC4E \uD835\uDC61 \uD835\uDC61 \uD835\uDC4E\n\uD835\uDC61 \uD835\uDC4E\nName (empty) type bodyname\nid\nException\nName\ne id\nExceptHandler"
    }, {
      "heading" : "2 Background",
      "text" : "As shown in Figure 1, the procedure of code generation can be decomposed into three stages. Based on the learned semantic representations of the input NL utterance, the dominant Seq2Tree model (Yin and Neubig, 2018) first outputs a sequence of abstract syntax description language (ASDL) grammar-based actions. These actions can then be used to construct an AST following the preorder traversal. Finally, the generated AST is mapped into surface code via a user-specified function AST to MR(∗).\nIn the following subsections, we first describe the basic ASDL grammars of Seq2Tree models. Then, we introduce the details of TRANX (Yin and Neubig, 2018), which is selected as our basic model due to its extensive applications and competitive performance (Yin and Neubig, 2019; Shin et al., 2019; Xu et al., 2020). 1\n1Please note that our approach is also applicable to other Seq2Tree models."
    }, {
      "heading" : "2.1 ASDL Grammar",
      "text" : "Formally, an ASDL grammar contains two components: type and constructors. The value of type can be composite or primitive. As shown in the ‘ActionSequence’ and ‘ASTz’ parts of Figure 1, a constructor specifies a language component of a particular type using its fields, e.g., ExceptHandler (expr? type, expr? name, stmt∗ body). Each field specifies the type of its child node and contains a cardinality (single, optional ? and sequential ∗) indicating the number of child nodes it holds. For instance, expr? name denotes the field name has optional child node. The field with composite type (e.g. expr) can be instantiated by constructors of corresponding type, while the field with primitive type (e.g. identifier) directly stores token.\nThere are three kinds of ASDL grammar-based actions that can be used to generate the action sequence: 1) APPLYCONSTR[c]. Using this action, a constructor c is applied to the composite field of the parent node with the same type as c, expanding the field to generate a branch ending with an AST node. Here we denote the field of the parent node as frontier field. 2) REDUCE. It indicates the completion of generating branches for a field with optional or multiple cardinalities. 3) GENTOKEN[v]. It expands a primitive frontier field to generate a token v.\nObviously, a constructor with multiple fields can produce multiple AST branches2, of which generation order has important effect on the model performance, as previously mentioned."
    }, {
      "heading" : "2.2 Seq2Tree Model",
      "text" : "Similar to other NLG models, TRANX is trained to minimize the following objective function:\nLmle(x,a) = − T∑ t=1 log p(at|a<t,x), (1)\nwhere at is the t-th action, and p(at|a<t,x) is modeled by an attentional encoder-decoder network (Yin and Neubig, 2018).\nFor an NL description x=x1, x2, ..., xN , we use a BiLSTM encoder to learn its word-level hidden states. Likewise, the decoder is also an LSTM network. Formally, at the timestep t, the temporary hidden state ht is updated as\nht = fLSTM ([E(at−1) : st−1 : pt] ,ht−1) , (2) 2We also note that the field with sequential cardinality will be expanded to multiple branches. However, in this work, we do not consider this scenario, which is left as future work.\nwhere E(at−1) is the embedding of the previous action at−1, st−1 is the previous decoder hidden state, and pt is a concatenated vector involving the embedding of the frontier field and the decoder hidden state for the parent node. Furthermore, the decoder hidden state st is defined as\nst = tanh (W [ht : ct]) , (3)\nwhere ct is the context vector produced from the encoder hidden states and W is a parameter matrix.\nHere, we calculate the probability of action at according to the type of its frontier field:\n• Composite. We adopt an APPLYCONSTR action to expand the field or a REDUCE action to complete the field.3 The probability of using APPLYCONSTR[c] is defined as follows:\np (at=APPLYCONSTR[c]|a<t,x) = softmax ( E(c)>Wst ) (4) where E(c) denotes the embedding of the constructor c. • Primitive. We apply a GENTOKEN action to produce a token v, which is either generated from the vocabulary or copied from the input NL description. Formally, the probability of using GENTOKEN[v] can be decomposed into two parts:\np (at=GENTOKEN[v]|a<t,x) = p (gen |a<t,x) pgen (v|a<t,x)+\n(1− p (gen |a<t,x))pcopy (v|a<t,x) , (5)\nwhere p (gen |a<t,x) is modeled as sigmoid (Wst).\nPlease note that our proposed dynamic selection of branch expansion orders does not affect other aspects of the model."
    }, {
      "heading" : "3 Dynamic Selection of Branch Expansion Orders",
      "text" : "In this section, we extend the conventional Seq2Tree model with a context-based branch selector, which dynamically determines optimal expansion orders of branches for multi-branch AST nodes. In the following subsections, we first illustrate the elaborately-designed branch selector module and then introduce how to train the extended Seq2Tree model via reinforcement learning in detail.\n3REDUCE action can be considered as a special APPLYCONSTR action"
    }, {
      "heading" : "3.1 Branch Selector",
      "text" : "As described in Section 2.2, the action prediction at each timestep is mainly affected by its previous action, frontier field and the action of its parent node. Thus, it is reasonable to construct the branch selector determining optimal expansion orders of branches according to these three kinds of information.\nSpecifically, given a multi-branch node nt at timestep t, where the ASDL grammar of action at containsm fields [f1, f2, ...fm], we feed the branch selector with three vectors: 1) E(fi): the embedding of field fi, 2) E(at): the embedding of action at, 3) st: the decoder hidden state, and then calculate the priority score of expanding fields as follows:\nScore(fi) = W2(tanh(W1[st : E(at) : E(fi)])), (6) where W1∈Rd1×d2 and W2∈Rd2×1 are learnable parameters.4\nAfterwards, we normalize priority scores of expanding all fields into a probability distribution:\npnt = softmax([Score(f1) : · · · : Score(fm)]). (7)\nBased on the above probability distribution, we can sample m times to form a branch expansion order o = [fo1 , ..., fom ], of which the policy probability is computed as\nπ(o) = m∏ i=1 pnt(foi |fo<i). (8)\n4We omit the bias term for clarity.\nIt is notable that during the sampling of foi , we mask previously sampled fields fo<i to ensure that duplicate fields will not be sampled."
    }, {
      "heading" : "3.2 Training with Reinforcement Learning",
      "text" : "During the generation of ASTs, with the above context-based branch selector, we deal with multibranch nodes according to the dynamically determined order instead of the standard left-to-right order. However, the non-differentiability of multistep expansion order selection and how to determine the optimal expansion order lead to challenges for the model training. To deal with these issues, we introduce reinforcement learning to train the extended Seq2Tree model in an end-to-end way.\nConcretely, we first pre-train a conventional Seq2Tree model. Then, we employ self-critical training with a reward function that measures loss difference between different branch expansion orders to train the extended Seq2Tree model."
    }, {
      "heading" : "3.2.1 Pre-training",
      "text" : "It is known that a well-initialized network is very important for applying reinforcement learning (Kang et al., 2020). In this work, we require the model to automatically quantify effects of different branch expansion orders on the quality of the generated action sequences. Therefore, we expect that the model has the basic ability to generate action sequences in random order at the beginning. To do this, instead of using the pre-order traversal based action sequences, we use the randomly-organized action sequences to pre-train the Seq2Tree model.\nConcretely, for each multi-branch node in an AST, we sample a branch expansion order from a\nuniform distribution, and then reorganize the corresponding actions according to the sampled order. We conduct the same operations to all multi-branch nodes of the AST, forming a new training instance. Finally, we use the regenerated training instances to pre-train our model.\nIn this way, the pre-trained Seq2Tree model acquires the preliminary capability to make predictions in any order."
    }, {
      "heading" : "3.2.2 Self-Critical Training",
      "text" : "With the above initialized parameters, we then perform self-critical training (Rennie et al., 2017; Kang et al., 2020) to update the Seq2Tree model with branch selector.\nSpecifically, we train the extended Seq2Tree model by combining the MLE objective and RL objective together. Formally, given the training instance (x,a), we first apply the sampling method described in section 3.1 to all multi-branch nodes, reorganizing the initial action sequence a to form a new action sequence ao, and then define the model training objective as\nL = Lmle(ao|x; θ) + λ |Nmb| ∑\nn∈Nmb\nLrl(o; θ),\n(9) where Lmle(∗) denotes the conventional training objective defined in Equation 1, Lrl(∗) is the negative expected reward of branch expansion order o for the multi-branch node n, λ is a balancing hyperparameter, Nmb denotes the set of multi-branch nodes in the training instance, and θ denotes the parameter set of our enhanced model.\nMore specifically, Lrl(∗) is defined as\nLrl(o; θ) = −Eo∼π[r(o)] ≈ −r(o), o ∼ π,\n(10)\nwhere we approximate the expected reward with the loss of an order o sampled from the policy π.\nInspired by successful applications of selfcritical training in previous studies (Rennie et al., 2017; Kang et al., 2020), we propose the reward r(∗) to accurately measure the effect of any order on the model performance. As shown in Figure 2, we calculate the reward using two expansion orders of branches: one is o sampled from the policy π, and the other is ô inferred from the policy π with the maximal generation probability:\nr(o) = (Lmle(ô)− Lmle(o)) ∗ (max(η − p(o), 0)). (11)\nPlease note that we extend the standard reward function by setting a threshold η to clip the reward, which can prevent the network from being overconfident in current expansion order of branches.\nFinally, we apply the REINFORCE algorithm (Williams, 1992) to compute the gradient:\n∇θLrl ≈ −r (o)∇θ log pθ (o) . (12)"
    }, {
      "heading" : "4 Experiments",
      "text" : "To investigate the effectiveness and generalizability of our model, we carry out experiments on several commonly-used datasets."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "Following previous studies (Yin and Neubig, 2018, 2019; Xu et al., 2020), we use the following four datasets:\n• DJANGO (Oda et al., 2015). This dataset totally contains 18,805 lines of Python source code, which are extracted from the Django Web framework, and each line is paired with an NL description. • ATIS. This dataset is a set of 5,410 inquiries of flight information, where the input of each example is an NL description and its corresponding output is a short piece of code in lambda calculus. • GEO. It is a collection of 880 U.S. geographical questions, with meaning representations defined in lambda logical forms like ATIS. • CONALA (Yin et al., 2018). It totally consists of 2,879 examples of manually annotated NL questions and their Python solutions on STACK OVERFLOW. Compared with DJANGO, the examples of CONALA cover real-world NL queries issued by programmers with diverse intents, and are significantly more difficult due to its broad coverage and high compositionality of target meaning representations."
    }, {
      "heading" : "4.2 Baselines",
      "text" : "To facilitate the descriptions of experimental results, we refer to the enhanced TRANX model as TRANX-RL. In addition to TRANX, we compare our enhanced model with several competitive models:\n• TRANX (w/ pre-train). It is an enhanced version of TRANX with pre-training. We\ncompare with it because our model involves a pre-training stage. • COARSE2FINE (Dong and Lapata, 2018). This model adopts a two-stage decoding strategy to produce the action sequence. It first generates a rough sketch of its meaning, and then fills in missing detail. • TREEGEN (Sun et al., 2020). It introduces the attention mechanism of Transformer (Vaswani et al., 2017), and a novel AST reader to incorporate grammar and AST structures into the network. • TRANX-R2L. It is a variant of the conventional TRANX model, which deals with multibranch AST nodes in a right-to-left manner. • TRANX-RAND. It is also a variant of the conventional TRANX model dealing with multibranch AST nodes in a random order. • TRANX-RL (w/o pre-train). In this variant of TRANX-RL, we train our model from scratch. By doing so, we can discuss the effect of pre-training on our model training.\nTo ensure fair comparisons, we use the same experimental setup as TRANX (Yin and Neubig, 2018). Concretely, the sizes of action embedding, field embedding and hidden states are set to 128, 128 and 256, respectively. For decoding, the beam sizes for GEO, ATIS, DJANGO and CONALA are 5, 5, 15 and 15, respectively. We pre-train models in 10 epochs for all datasets. we determine the λs as 1.0 according to the model performance on validation sets. As in previous studies (Alvarez-Melis and Jaakkola, 2017; Yin and Neubig, 2018, 2019), we use the exact matching accuracy (Acc) as the\nevaluation metric for all datasets. For CONALA, we use the corpus-level BLEU (Yin et al., 2018) as a complementary metric."
    }, {
      "heading" : "4.3 Main Results",
      "text" : "Table 2 reports the main experimental results. Overall, our enhanced model outperforms baselines across all datasets. Moreover, we can draw the following conclusions:\nFirst, our reimplemented TRANX model achieves comparable performance to previously reported results (Yin and Neubig, 2019) (TRANX). Therefore, we confirm that our reimplemented TRANX model are convincing.\nSecond, compared with TRANX, TRANX-R2L and TRANX-RAND, our TRANX-RL exhibits better performance. This result demonstrates the advantage of dynamically determining branch expansion orders on dealing with multi-branch AST nodes.\nThird, the TRANX model with pre-training does not gain a better performance. In contrast, removing the model pre-training leads to the performance degradation of our TRANX-RL model. This result is consistent with the conclusion of previous studies (Wang et al., 2018; Kang et al., 2020) that the pre-training is very important for the applying reinforcement learning."
    }, {
      "heading" : "4.4 Effects of the Number of Multi-branch Nodes",
      "text" : "As implemented in related studies on other NLG tasks, such as machine translation (Bahdanau et al., 2015), we individually split two relatively large\ndatasets (DJANGO and ATIS) into different groups according to the number of multi-branch AST nodes, and report the performance of various models on these groups of datasets.\nTables 4 and 5 show the experimental results. On most groups, TRANX-RL achieves better or equal performance than other models. Therefore, we confirm that our model is general to datasets with different numbers of multi-branch nodes."
    }, {
      "heading" : "4.5 Accuracy of Action Predictions for the",
      "text" : "Child Nodes\nGiven a multi-branch node, its child nodes have an important influence in the subtree. Therefore, we focus on the accuracy of action predictions for the child nodes.\nFor fair comparison, we predict actions with pre-\nvious ground-truth history actions as inputs. Table 3 reports the experimental results. We observe that TRANX-RL still achieves higher prediction accuracy than other baselines on most groups, which proves the effectiveness of our model again."
    }, {
      "heading" : "4.6 Case Study",
      "text" : "Figure 3 shows two examples from DJANGO. In the first example, TRANX first generates the leftmost child node at the timestep t2, incorrectly predicting GENTOKEN[‘gzip’] as REDUCE action. By contrast, TRANX-RL puts this child node in the last position and successfully predict its action, since our model benefits from the previously generated token ‘GzipFile’ of the sibling node, which frequently occurs with ‘gzip’.\nIn the second example, TRANX incorrectly predicts the second child node at the t10-th timestep, while TRANX-RL firstly predicts it at the timestep t6. We think this error results from the sequentially generated nodes and the errors in early timesteps would accumulatively harm the predictions of later sibling nodes. By comparison, our model can flexibly generate subtrees with shorter lengths, alleviating error accumulation."
    }, {
      "heading" : "5 Related Work",
      "text" : "With the prosperity of deep learning, researchers introduce neural networks into code generation. In this aspect, Ling et al. (2016) first explore a Seq2Seq model for code generation. Then, due to the advantage of tree structure, many attempts resort to Seq2Tree models, which represent codes as trees of meaning representations (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018; Sun et al., 2019, 2020).\nTypically, Yin and Neubig (2018) propose TRANX, which introduces ASTs as intermediate representations of codes and has become the most influential Seq2Tree model. Then, Sun et al. (2019, 2020) respectively explore CNN and Transformer\narchitectures to model code generation. Unlike these work, Shin et al. (2019) present a Seq2Tree model to generate program fragments or tokens interchangeably at each generation step. From another perspective, Xu et al. (2020) exploit external knowledge to enhance neural code generation model. Generally, all these Seq2Tree models generate ASTs in pre-order traversal, which, how-\never, is not suitable to handle all multi-branch AST nodes. Different from the above studies that deal with multi-branch nodes in left-to-right order, our model determines the optimal expansion orders of branches for multi-branch nodes.\nSome researchers have also noticed that the selection of decoding order has an important impact on the performance of neural code generation models. For example, Alvarez-Melis and Jaakkola (2017) introduce a doubly RNN model that combines width and depth recurrences to traverse each node. Dong and Lapata (2018) firstly generate a rough code sketch, and then fill in missing details by considering the input NL description and the sketch. Gu et al. (2019a) present an insertionbased Seq2Seq model that can flexibly generate a sequence in an arbitrary order. In general, these researches still deal with multi-branch AST nodes in a left-to-right manner. Thus, these models are theoretically compatible with our proposed branch selector.\nFinally, it should be noted that have been many NLP studies on exploring other decoding methods to improve other NLG tasks (Zhang et al., 2018; Su et al., 2019; Zhang et al., 2019; Welleck et al., 2019; Stern et al., 2019; Gu et al., 2019a,b). However, to the best of our knowledge, our work is the first attempt to explore dynamic selection of branch expansion orders for tree-structured decoding."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "In this work, we first point out that the generation of domainant Seq2Tree models based on pre-order traversal is not optimal for handling all multi-branch nodes. Then we propose an extended Seq2Tree model equipped with a context-based branch selector, which is capable of dynamically determining optimal branch expansion orders for multi-branch nodes. Particularly, we adopt reinforcement learning to train the whole model with an elaborate reward that measures the model loss difference between different branch expansion orders. Extensive experiment results and in-depth analyses demonstrate the effectiveness and generality of our proposed model on several commonlyused datasets.\nIn the future, we will study how to extend our branch selector to deal with indefinite branches caused by sequential field."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The project was supported by National Key Research and Development Program of China (Grant No. 2020AAA0108004), National Natural Science Foundation of China (Grant No. 61672440), Natural Science Foundation of Fujian Province of China (Grant No. 2020J06001), Youth Innovation Fund of Xiamen (Grant No. 3502Z20206059), and the Fundamental Research Funds for the Central Universities (Grant No. ZK20720200077). We also thank the reviewers for their insightful comments."
    } ],
    "references" : [ {
      "title" : "Tree-structured decoding with doubly-recurrent neural networks",
      "author" : [ "David Alvarez-Melis", "Tommi S. Jaakkola." ],
      "venue" : "Proceedings of ICLR.",
      "citeRegEx" : "Alvarez.Melis and Jaakkola.,? 2017",
      "shortCiteRegEx" : "Alvarez.Melis and Jaakkola.",
      "year" : 2017
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "Proceedings of ICLR.",
      "citeRegEx" : "Bahdanau et al\\.,? 2015",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2015
    }, {
      "title" : "Language to logical form with neural attention",
      "author" : [ "Li Dong", "Mirella Lapata." ],
      "venue" : "Proceedings of ACL, pages 33–43.",
      "citeRegEx" : "Dong and Lapata.,? 2016",
      "shortCiteRegEx" : "Dong and Lapata.",
      "year" : 2016
    }, {
      "title" : "Coarse-to-fine decoding for neural semantic parsing",
      "author" : [ "Li Dong", "Mirella Lapata." ],
      "venue" : "Proceedings of ACL, pages 6559–6569.",
      "citeRegEx" : "Dong and Lapata.,? 2018",
      "shortCiteRegEx" : "Dong and Lapata.",
      "year" : 2018
    }, {
      "title" : "Insertion-based decoding with automatically inferred generation order",
      "author" : [ "Jiatao Gu", "Qi Liu", "Kyunghyun Cho." ],
      "venue" : "Trans. Assoc. Comput. Linguistics, pages 661–676.",
      "citeRegEx" : "Gu et al\\.,? 2019a",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2019
    }, {
      "title" : "Levenshtein transformer",
      "author" : [ "Jiatao Gu", "Changhan Wang", "Junbo Zhao." ],
      "venue" : "Proceedings of NIPS, pages 11179–11189.",
      "citeRegEx" : "Gu et al\\.,? 2019b",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2019
    }, {
      "title" : "Retrieval-based neural code generation",
      "author" : [ "Shirley Anugrah Hayati", "Raphael Olivier", "Pravalika Avvaru", "Pengcheng Yin", "Anthony Tomasic", "Graham Neubig." ],
      "venue" : "Proceedings of EMNLP, pages 925–930.",
      "citeRegEx" : "Hayati et al\\.,? 2018",
      "shortCiteRegEx" : "Hayati et al\\.",
      "year" : 2018
    }, {
      "title" : "Dynamic context selection for document-level neural machine translation via reinforcement learning",
      "author" : [ "Xiaomian Kang", "Yang Zhao", "Jiajun Zhang", "Chengqing Zong." ],
      "venue" : "Proceedings of EMNLP, pages 2242–2254.",
      "citeRegEx" : "Kang et al\\.,? 2020",
      "shortCiteRegEx" : "Kang et al\\.",
      "year" : 2020
    }, {
      "title" : "Latent predictor networks for code generation",
      "author" : [ "Wang Ling", "Phil Blunsom", "Edward Grefenstette", "Karl Moritz Hermann", "Andrew Senior." ],
      "venue" : "Proceedings of ACL, pages 599–609.",
      "citeRegEx" : "Ling et al\\.,? 2016",
      "shortCiteRegEx" : "Ling et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning to generate pseudo-code from source code using statistical machine translation",
      "author" : [ "Yusuke Oda", "Hiroyuki Fudaba", "Graham Neubig", "Hideaki Hata", "Sakriani Sakti", "Tomoki Toda", "Satoshi Nakamura." ],
      "venue" : "Proceedings of ASE, pages 574–",
      "citeRegEx" : "Oda et al\\.,? 2015",
      "shortCiteRegEx" : "Oda et al\\.",
      "year" : 2015
    }, {
      "title" : "Abstract syntax networks for code generation and semantic parsing",
      "author" : [ "Maxim Rabinovich", "Mitchell Stern", "Dan Klein." ],
      "venue" : "Proceedings of ACL, pages 1139–1149.",
      "citeRegEx" : "Rabinovich et al\\.,? 2017",
      "shortCiteRegEx" : "Rabinovich et al\\.",
      "year" : 2017
    }, {
      "title" : "Self-critical sequence training for image captioning",
      "author" : [ "Steven J. Rennie", "Etienne Marcheret", "Youssef Mroueh", "Jerret Ross", "Vaibhava Goel." ],
      "venue" : "Proceedings of CVPR, pages 1179–1195.",
      "citeRegEx" : "Rennie et al\\.,? 2017",
      "shortCiteRegEx" : "Rennie et al\\.",
      "year" : 2017
    }, {
      "title" : "Program synthesis and semantic parsing with learned code idioms",
      "author" : [ "Eui Chul Shin", "Miltiadis Allamanis", "Marc Brockschmidt", "Alex Polozov." ],
      "venue" : "Proceedings of NIPS, pages 10825–10835.",
      "citeRegEx" : "Shin et al\\.,? 2019",
      "shortCiteRegEx" : "Shin et al\\.",
      "year" : 2019
    }, {
      "title" : "Insertion transformer: Flexible sequence generation via insertion operations",
      "author" : [ "Mitchell Stern", "William Chan", "Jamie Kiros", "Jakob Uszkoreit." ],
      "venue" : "Proceedings of ICML, pages 5976–5985.",
      "citeRegEx" : "Stern et al\\.,? 2019",
      "shortCiteRegEx" : "Stern et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploiting reverse target-side contexts for neural machine translation via asynchronous bidirectional decoding",
      "author" : [ "Jinsong Su", "Xiangwen Zhang", "Qian Lin", "Yue Qin", "Junfeng Yao", "Yang Liu." ],
      "venue" : "Artificial Intelligence, 277.",
      "citeRegEx" : "Su et al\\.,? 2019",
      "shortCiteRegEx" : "Su et al\\.",
      "year" : 2019
    }, {
      "title" : "A grammar-based structural cnn decoder for code generation",
      "author" : [ "Zeyu Sun", "Qihao Zhu", "Lili Mou", "Yingfei Xiong", "Ge Li", "Lu Zhang." ],
      "venue" : "Proceedings of AAAI, pages 7055–7062.",
      "citeRegEx" : "Sun et al\\.,? 2019",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Treegen: A tree-based transformer architecture for code generation",
      "author" : [ "Zeyu Sun", "Qihao Zhu", "Yingfei Xiong", "Yican Sun", "Lili Mou", "Lu Zhang." ],
      "venue" : "Proceedings of AAAI, pages 8984–8991.",
      "citeRegEx" : "Sun et al\\.,? 2020",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2020
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Ł ukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Proceedings of NIPS, pages 5998–6008.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Skipnet: Learning dynamic routing in convolutional networks",
      "author" : [ "Xin Wang", "Fisher Yu", "Zi-Yi Dou", "Trevor Darrell", "Joseph E. Gonzalez." ],
      "venue" : "Proceedings of ECCV, pages 420–436.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Code generation as a dual task of code summarization",
      "author" : [ "Bolin Wei", "Ge Li", "Xin Xia", "Zhiyi Fu", "Zhi Jin." ],
      "venue" : "Proceedings of NIPS, pages 6563–6573.",
      "citeRegEx" : "Wei et al\\.,? 2019",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2019
    }, {
      "title" : "Non-monotonic sequential text generation",
      "author" : [ "Sean Welleck", "Kianté Brantley", "Hal Daumé III", "Kyunghyun Cho." ],
      "venue" : "Proceedings of ICML, pages 6716– 6726.",
      "citeRegEx" : "Welleck et al\\.,? 2019",
      "shortCiteRegEx" : "Welleck et al\\.",
      "year" : 2019
    }, {
      "title" : "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning",
      "author" : [ "Ronald J. Williams." ],
      "venue" : "Machine Learning, 8:229–256.",
      "citeRegEx" : "Williams.,? 1992",
      "shortCiteRegEx" : "Williams.",
      "year" : 1992
    }, {
      "title" : "Improving tree-structured decoder training for code generation via mutual learning",
      "author" : [ "Binbin Xie", "Xiang Li", "Yubin Ge", "Jianwei Cui", "Junfeng Yao", "Bin Wang", "Jinsong Su." ],
      "venue" : "Proceedings of AAAI.",
      "citeRegEx" : "Xie et al\\.,? 2021",
      "shortCiteRegEx" : "Xie et al\\.",
      "year" : 2021
    }, {
      "title" : "Incorporating external knowledge through pre-training for natural language to code generation",
      "author" : [ "Frank F. Xu", "Zhengbao Jiang", "Pengcheng Yin", "Bogdan Vasilescu", "Graham Neubig." ],
      "venue" : "Proceedings of ACL, pages 6045–6052.",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning to mine aligned code and natural language pairs from stack overflow",
      "author" : [ "Pengcheng Yin", "Bowen Deng", "Edgar Chen", "Bogdan Vasilescu", "Graham Neubig." ],
      "venue" : "Proceedings of MSR, pages 476– 486.",
      "citeRegEx" : "Yin et al\\.,? 2018",
      "shortCiteRegEx" : "Yin et al\\.",
      "year" : 2018
    }, {
      "title" : "A syntactic neural model for general-purpose code generation",
      "author" : [ "Pengcheng Yin", "Graham Neubig." ],
      "venue" : "Proceedings of ACL, pages 440–450.",
      "citeRegEx" : "Yin and Neubig.,? 2017",
      "shortCiteRegEx" : "Yin and Neubig.",
      "year" : 2017
    }, {
      "title" : "Tranx: A transition-based neural abstract syntax parser for semantic parsing and code generation",
      "author" : [ "Pengcheng Yin", "Graham Neubig." ],
      "venue" : "Proceedings of EMNLP, pages 7–12.",
      "citeRegEx" : "Yin and Neubig.,? 2018",
      "shortCiteRegEx" : "Yin and Neubig.",
      "year" : 2018
    }, {
      "title" : "Reranking for neural semantic parsing",
      "author" : [ "Pengcheng Yin", "Graham Neubig." ],
      "venue" : "Proceedings of ACL, pages 4553–4559.",
      "citeRegEx" : "Yin and Neubig.,? 2019",
      "shortCiteRegEx" : "Yin and Neubig.",
      "year" : 2019
    }, {
      "title" : "Future-aware knowledge distillation for neural machine translation",
      "author" : [ "Biao Zhang", "Deyi Xiong", "Jinsong Su", "Jiebo Luo." ],
      "venue" : "IEEE ACM Trans. Audio Speech Lang. Process., pages 2278–2287.",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Asynchronous bidirectional decoding for neural machine translation",
      "author" : [ "Xiangwen Zhang", "Jinsong Su", "Yue Qin", "Yang Liu", "Rongrong Ji", "Hongji Wang." ],
      "venue" : "Proceedings of AAAI, pages 5698–5705.",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "*Equal contribution Corresponding author models, and obtains great success (Ling et al., 2016; Dong and Lapata, 2016, 2018; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018, 2019; Hayati et al., 2018; Sun et al., 2019, 2020; Wei et al., 2019; Shin et al., 2019; Xu et al., 2020; Xie et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 299
    }, {
      "referenceID" : 10,
      "context" : "*Equal contribution Corresponding author models, and obtains great success (Ling et al., 2016; Dong and Lapata, 2016, 2018; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018, 2019; Hayati et al., 2018; Sun et al., 2019, 2020; Wei et al., 2019; Shin et al., 2019; Xu et al., 2020; Xie et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 299
    }, {
      "referenceID" : 6,
      "context" : "*Equal contribution Corresponding author models, and obtains great success (Ling et al., 2016; Dong and Lapata, 2016, 2018; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018, 2019; Hayati et al., 2018; Sun et al., 2019, 2020; Wei et al., 2019; Shin et al., 2019; Xu et al., 2020; Xie et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 299
    }, {
      "referenceID" : 19,
      "context" : "*Equal contribution Corresponding author models, and obtains great success (Ling et al., 2016; Dong and Lapata, 2016, 2018; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018, 2019; Hayati et al., 2018; Sun et al., 2019, 2020; Wei et al., 2019; Shin et al., 2019; Xu et al., 2020; Xie et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 299
    }, {
      "referenceID" : 12,
      "context" : "*Equal contribution Corresponding author models, and obtains great success (Ling et al., 2016; Dong and Lapata, 2016, 2018; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018, 2019; Hayati et al., 2018; Sun et al., 2019, 2020; Wei et al., 2019; Shin et al., 2019; Xu et al., 2020; Xie et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 299
    }, {
      "referenceID" : 23,
      "context" : "*Equal contribution Corresponding author models, and obtains great success (Ling et al., 2016; Dong and Lapata, 2016, 2018; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018, 2019; Hayati et al., 2018; Sun et al., 2019, 2020; Wei et al., 2019; Shin et al., 2019; Xu et al., 2020; Xie et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 299
    }, {
      "referenceID" : 22,
      "context" : "*Equal contribution Corresponding author models, and obtains great success (Ling et al., 2016; Dong and Lapata, 2016, 2018; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018, 2019; Hayati et al., 2018; Sun et al., 2019, 2020; Wei et al., 2019; Shin et al., 2019; Xu et al., 2020; Xie et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 299
    }, {
      "referenceID" : 26,
      "context" : "To verify this conjecture, we choose TRANX (Yin and Neubig, 2018) to construct a variant: TRANX-R2L, which conducts depth-first generation in a right-to-left manner, and then compare their performance on the DJANGO dataset.",
      "startOffset" : 43,
      "endOffset" : 65
    }, {
      "referenceID" : 26,
      "context" : "TRANX-R2L is a variant of TRANX (Yin and Neubig, 2018), which handles multi-branch nodes in a right-toleft order.",
      "startOffset" : 32,
      "endOffset" : 54
    }, {
      "referenceID" : 26,
      "context" : "Based on the learned semantic representations of the input NL utterance, the dominant Seq2Tree model (Yin and Neubig, 2018) first outputs a sequence of abstract syntax description language (ASDL) grammar-based actions.",
      "startOffset" : 101,
      "endOffset" : 123
    }, {
      "referenceID" : 26,
      "context" : "Then, we introduce the details of TRANX (Yin and Neubig, 2018), which is selected as our basic model due to its extensive applications and competitive performance (Yin and Neubig, 2019; Shin et al.",
      "startOffset" : 40,
      "endOffset" : 62
    }, {
      "referenceID" : 27,
      "context" : "Then, we introduce the details of TRANX (Yin and Neubig, 2018), which is selected as our basic model due to its extensive applications and competitive performance (Yin and Neubig, 2019; Shin et al., 2019; Xu et al., 2020).",
      "startOffset" : 163,
      "endOffset" : 221
    }, {
      "referenceID" : 12,
      "context" : "Then, we introduce the details of TRANX (Yin and Neubig, 2018), which is selected as our basic model due to its extensive applications and competitive performance (Yin and Neubig, 2019; Shin et al., 2019; Xu et al., 2020).",
      "startOffset" : 163,
      "endOffset" : 221
    }, {
      "referenceID" : 23,
      "context" : "Then, we introduce the details of TRANX (Yin and Neubig, 2018), which is selected as our basic model due to its extensive applications and competitive performance (Yin and Neubig, 2019; Shin et al., 2019; Xu et al., 2020).",
      "startOffset" : 163,
      "endOffset" : 221
    }, {
      "referenceID" : 26,
      "context" : "where at is the t-th action, and p(at|a<t,x) is modeled by an attentional encoder-decoder network (Yin and Neubig, 2018).",
      "startOffset" : 98,
      "endOffset" : 120
    }, {
      "referenceID" : 7,
      "context" : "It is known that a well-initialized network is very important for applying reinforcement learning (Kang et al., 2020).",
      "startOffset" : 98,
      "endOffset" : 117
    }, {
      "referenceID" : 11,
      "context" : "With the above initialized parameters, we then perform self-critical training (Rennie et al., 2017; Kang et al., 2020) to update the Seq2Tree model with branch selector.",
      "startOffset" : 78,
      "endOffset" : 118
    }, {
      "referenceID" : 7,
      "context" : "With the above initialized parameters, we then perform self-critical training (Rennie et al., 2017; Kang et al., 2020) to update the Seq2Tree model with branch selector.",
      "startOffset" : 78,
      "endOffset" : 118
    }, {
      "referenceID" : 11,
      "context" : "Inspired by successful applications of selfcritical training in previous studies (Rennie et al., 2017; Kang et al., 2020), we propose the reward r(∗) to accurately measure the effect of any order on the model performance.",
      "startOffset" : 81,
      "endOffset" : 121
    }, {
      "referenceID" : 7,
      "context" : "Inspired by successful applications of selfcritical training in previous studies (Rennie et al., 2017; Kang et al., 2020), we propose the reward r(∗) to accurately measure the effect of any order on the model performance.",
      "startOffset" : 81,
      "endOffset" : 121
    }, {
      "referenceID" : 21,
      "context" : "Finally, we apply the REINFORCE algorithm (Williams, 1992) to compute the gradient:",
      "startOffset" : 42,
      "endOffset" : 58
    }, {
      "referenceID" : 23,
      "context" : "Following previous studies (Yin and Neubig, 2018, 2019; Xu et al., 2020), we use the following four datasets:",
      "startOffset" : 27,
      "endOffset" : 72
    }, {
      "referenceID" : 17,
      "context" : "It introduces the attention mechanism of Transformer (Vaswani et al., 2017), and a novel AST reader to incorporate grammar and AST structures into the network.",
      "startOffset" : 53,
      "endOffset" : 75
    }, {
      "referenceID" : 26,
      "context" : "To ensure fair comparisons, we use the same experimental setup as TRANX (Yin and Neubig, 2018).",
      "startOffset" : 72,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "As in previous studies (Alvarez-Melis and Jaakkola, 2017; Yin and Neubig, 2018, 2019), we use the exact matching accuracy (Acc) as the evaluation metric for all datasets.",
      "startOffset" : 23,
      "endOffset" : 85
    }, {
      "referenceID" : 24,
      "context" : "For CONALA, we use the corpus-level BLEU (Yin et al., 2018) as a complementary metric.",
      "startOffset" : 41,
      "endOffset" : 59
    }, {
      "referenceID" : 27,
      "context" : "Moreover, we can draw the following conclusions: First, our reimplemented TRANX model achieves comparable performance to previously reported results (Yin and Neubig, 2019) (TRANX).",
      "startOffset" : 149,
      "endOffset" : 171
    }, {
      "referenceID" : 18,
      "context" : "This result is consistent with the conclusion of previous studies (Wang et al., 2018; Kang et al., 2020) that the pre-training is very important for the applying reinforcement learning.",
      "startOffset" : 66,
      "endOffset" : 104
    }, {
      "referenceID" : 7,
      "context" : "This result is consistent with the conclusion of previous studies (Wang et al., 2018; Kang et al., 2020) that the pre-training is very important for the applying reinforcement learning.",
      "startOffset" : 66,
      "endOffset" : 104
    }, {
      "referenceID" : 1,
      "context" : "As implemented in related studies on other NLG tasks, such as machine translation (Bahdanau et al., 2015), we individually split two relatively large",
      "startOffset" : 82,
      "endOffset" : 105
    }, {
      "referenceID" : 2,
      "context" : "Then, due to the advantage of tree structure, many attempts resort to Seq2Tree models, which represent codes as trees of meaning representations (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018; Sun et al., 2019, 2020).",
      "startOffset" : 145,
      "endOffset" : 279
    }, {
      "referenceID" : 0,
      "context" : "Then, due to the advantage of tree structure, many attempts resort to Seq2Tree models, which represent codes as trees of meaning representations (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018; Sun et al., 2019, 2020).",
      "startOffset" : 145,
      "endOffset" : 279
    }, {
      "referenceID" : 10,
      "context" : "Then, due to the advantage of tree structure, many attempts resort to Seq2Tree models, which represent codes as trees of meaning representations (Dong and Lapata, 2016; Alvarez-Melis and Jaakkola, 2017; Rabinovich et al., 2017; Yin and Neubig, 2017, 2018; Sun et al., 2019, 2020).",
      "startOffset" : 145,
      "endOffset" : 279
    } ],
    "year" : 2021,
    "abstractText" : "Due to the great potential in facilitating software development, code generation has attracted increasing attention recently. Generally, dominant models are Seq2Tree models, which convert the input natural language description into a sequence of tree-construction actions corresponding to the pre-order traversal of an Abstract Syntax Tree (AST). However, such a traversal order may not be suitable for handling all multi-branch nodes. In this paper, we propose to equip the Seq2Tree model with a context-based Branch Selector, which is able to dynamically determine optimal expansion orders of branches for multibranch nodes. Particularly, since the selection of expansion orders is a non-differentiable multi-step operation, we optimize the selector through reinforcement learning, and formulate the reward function as the difference of model losses obtained through different expansion orders. Experimental results and in-depth analysis on several commonly-used datasets demonstrate the effectiveness and generality of our approach. We have released our code at https: //github.com/DeepLearnXMU/CG-RL.",
    "creator" : "LaTeX with hyperref"
  }
}