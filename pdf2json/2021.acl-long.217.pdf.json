{
  "name" : "2021.acl-long.217.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "TEXT2EVENT: Controllable Sequence-to-Structure Generation for End-to-end Event Extraction",
    "authors" : [ "Yaojie Lu", "Hongyu Lin", "Jin Xu", "Xianpei Han", "Jialong Tang", "Annan Li", "Le Sun", "Meng Liao", "Shaoyi Chen" ],
    "emails" : [ "yaojie2017@iscas.ac.cn", "jialong2019@iscas.ac.cn", "liannan2019@iscas.ac.cn", "hongyu@iscas.ac.cn", "xianpei@iscas.ac.cn", "sunle@iscas.ac.cn", "jinxxu@tencent.com", "maricoliao@tencent.com", "shaoyichen@tencent.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2795–2806\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n2795"
    }, {
      "heading" : "1 Introduction",
      "text" : "Event extraction is an essential task for natural language understanding, aiming to transform the text into event records (Doddington et al., 2004; Ahn, 2006). For example, in Figure 1, mapping “The man returned to Los Angeles from Mexico following his capture Tuesday by bounty hunters.” into two event records {Type: Transport, Trigger: returned, Arg1 Role: Artifact, Arg1: The man, Arg2 Role: Destination, Arg2: Los Angeles, ... } and {Type: Arrest-Jail, Trigger: capture, Arg1 Role: Person, Arg1: The man, Arg2 Role: Agent, Arg2: bounty hunters, ... }.\nEvent extraction is challenging due to the complex structure of event records and the semantic gap between text and event. First, an event record contains event type, trigger, and arguments, which\n∗Corresponding authors.\nform a table-like structure. And different event types have different structures. For example, in Figure 1, Transport and Arrest-Jail have entirely different structures. Second, an event can be expressed using very different utterances, such as diversified trigger words and heterogeneous syntactic structures. For example, both “the dismission of the man” and “the man departed his job” express the same event record {Type: End-Position, Arg1 Role: PERSON, Arg1: the man}.\nCurrently, most event extraction methods employ the decomposition strategy (Chen et al., 2015; Nguyen and Nguyen, 2019; Wadden et al., 2019; Zhang et al., 2019b; Du and Cardie, 2020; Li et al., 2020; Paolini et al., 2021), i.e., decomposing the prediction of complex event structures into multiple separated subtasks (mostly including entity recognition, trigger detection, argument classifica-\ntion), and then compose the components of different subtasks for predicting the whole event structure (e.g., pipeline modeling, joint modeling or joint inference). The main drawbacks of these decomposition-based methods are: (1) They need massive and fine-grained annotations for different subtasks, often resulting in the data inefficiency problem. For example, they need different finegrained annotations for Transport trigger detection, for Person entity recognition, for Transport.Artifact argument classification, etc. (2) It is very challenging to design the optimal composition architecture of different subtasks manually. For instance, the pipeline models often lead to error propagation. And the joint models need to heuristically predefine the information sharing and decision dependence between trigger detection, argument classification, and entity recognition, often resulting in suboptimal and inflexible architectures.\nIn this paper, we propose a sequence-tostructure generation paradigm for event extraction – TEXT2EVENT, which can directly extract events from the text in an end-to-end manner. Specifically, instead of decomposing event structure prediction into different subtasks and predicting labels, we uniformly model the whole event extraction process in a neural network-based sequence-tostructure architecture, and all triggers, arguments, and their labels are universally generated as natural language words. For example, we generate a subsequence “Attack fire” for trigger extraction, where both “Attack” and “fire” are treated as natural language words. Compared with previous methods, our method is more data-efficient: it can be learned using only coarse parallel text-record annotations, i.e., pairs of 〈sentence, event records〉, rather than fine-grained token-level annotations. Besides, the uniform architecture makes it easy to model, learn and exploit the interactions between different underlying predictions, and the knowledge can be seamlessly shared and transferred between different components.\nFurthermore, we design two algorithms for effective sequence-to-structure event extraction. First, we propose a constrained decoding algorithm, which can guide the generation process using event schemas. In this way, the event knowledge can be injected and exploited during inference on-thefly. Second, we design a curriculum learning algorithm, which starts with current pre-trained language models (PLMs), then trains them on simple\nevent substructure generation tasks such as trigger generation and independent argument generation, finally trains the model on the full event structure generation task.\nWe conducted experiments1 on ACE and ERE datasets, and the results verified the effectiveness of TEXT2EVENT in both supervised learning and transfer learning settings. In summary, the contributions are as follows:\n1. We propose a new paradigm for event extraction -– sequence-to-structure generation, which can directly extract events from the text in an end-to-end manner. By uniformly modeling all tasks in a single model and universally predicting different labels, our method is effective, data-efficient, and easy to implement.\n2. We design an effective sequence-to-structure architecture, which is enhanced with a constrained decoding algorithm for event knowledge injection during inference and a curriculum learning algorithm for efficient model learning.\n3. Many information extraction tasks can be formulated as structure prediction tasks. Our sequence-to-structure method can motivate the learning of other information extraction models."
    }, {
      "heading" : "2 TEXT2EVENT: End-to-end Event Extraction as Controllable Generation",
      "text" : "Given the token sequence x = x1, ..., x|x| of the input text, TEXT2EVENT directly generate the event structures E = e1, ..., e|E| via an encoderdecoder architecture. For example, in Figure 1, TEXT2EVENT take the raw text as input and output two event records including {Type: Transport, Trigger: returned, Arg1 Role: Artifact, Arg1: The man, ...} and {Type: Arrest-Jail, Trigger: capture, ..., Arg2 Role: Agent, Arg2: bounty hunters, ...}.\nFor end-to-end event extraction, TEXT2EVENT first encodes input text, then generates the linearized structure using the constrained decoding algorithm. In the following, we first introduce how to reformulate event extraction as structure generation via structure linearization, then describe the sequence-to-structure model and the constrained decoding algorithm.\n1Our source codes are openly available at https://github.com/luyaojie/text2event"
    }, {
      "heading" : "2.1 Event Extraction as Structure Generation",
      "text" : "This section describes how to linearize event structure so that events can be generated in an end-toend manner. Specifically, the linearized event representations should: (1) be able to express multiple event records in a text as one expression; (2) be easy to reversibly converted to event records in a deterministic way; (3) be similar to the token sequence of general text generation tasks so that text generation models can be leveraged and transferred easily.\nConcretely, the process of converting from record format to linearized format is shown in Figure 2. We first convert event records (Figure 2a) into a labeled tree (Figure 2b) by: 1) first labeling the root of the tree with the type of event (Root - Transport, Root - Arrest-Jail), 2) then connecting multiple event argument role types with event types (Transport - Artifact, Transport - Origin, etc.), and 3) finally linking the text spans from the raw text to the corresponding nodes as leaves (Transport - returned, Transport - Origin - Mexico, Transport - Artifact - The man, etc.). Given the converted event tree, we linearize it into a token sequence (Figure 2c) via depth-first traversal (Vinyals et al., 2015), where “(” and “)” are structure indicators used to represent the semantic structure of linear expressions. The traversal order of the same depth is the order in which the text spans appear in the text, e.g., first “return” then “capture” in Figure 2b. Noted that each linearized form has a virtual root – Root. For a sentence that contains multiple event records, each event links to Root directly. For a sentence that doesn’t express any event, its tree format will be linearized as “()”."
    }, {
      "heading" : "2.2 Sequence-to-Structure Network",
      "text" : "Based on the above linearization strategy, TEXT2EVENT generates the event structure via\na transformer-based encoder-decoder architecture (Vaswani et al., 2017). Given the token sequence x = x1, ..., x|x| as input, TEXT2EVENT outputs the linearized event representation y = y1, ..., y|y|. To this end, TEXT2EVENT first computes the hidden vector representation H = h1, ...,h|x| of the input via a multi-layer transformer encoder:\nH = Encoder(x1, ..., x|x|) (1)\nwhere each layer of Encoder(·) is a transformer block with the multi-head attention mechanism.\nAfter the input token sequence is encoded, the decoder predicts the output structure token-bytoken with the sequential input tokens’ hidden vectors. At the step i of generation, the self-attention decoder predicts the i-th token yi in the linearized form and decoder state hdi as:\nyi,h d i = Decoder([H;h d 1, ...,h d i−1], yi−1) (2)\nwhere each layer of Decoder(·) is a transformer block that contains self-attention with decoder state hdi and cross-attention with encoder state H.\nThe generated output structured sequence starts from the start token “〈bos〉” and ends with the end token “〈eos〉”. The conditional probability of the whole output sequence p(y|x) is progressively combined by the probability of each step p(yi|y<i, x):\np(y|x) = |y|∏ i p(yi|y<i, x) (3)\nwhere y<i = y1...yi−1, and p(yi|y<i, x) is the probability over the target vocabulary V normalized by softmax(·) .\nBecause all tokens in linearized event representations are also natural language words, we adopt the pre-trained language model T5 (Raffel et al., 2020) as our transformer-based encoder-decoder architecture. In this way, the general text generation knowledge can be directly reused."
    }, {
      "heading" : "2.3 Constrained Decoding",
      "text" : "Given the hidden sequence H, the sequence-tostructure network needs to generate the linearized event representations token-by-token. One straightforward solution is to use a greedy decoding algorithm, which selects the token with the highest predicted probability p(yi|y<i, x) at each decoding step i. Unfortunately, this greedy decoding algorithm cannot guarantee the generation of valid event structures. In other words, it could end up with invalid event types, mismatch of argumenttype, and incomplete structure. Furthermore, the greedy decoding algorithm ignores the useful event schema knowledge, which can be used to guide the decoding effectively. For example, we can constrain the model to only generate event type tokens in the type position.\nTo exploit the event schema knowledge, we propose to employ a trie-based constrained decoding algorithm (Chen et al., 2020a; Cao et al., 2021) for event generation. During constrained decoding, the event schema knowledge is injected as the prompt of the decoder and ensures the generation of valid event structures.\nConcretely, unlike the greedy decoding algorithm that selects the token from the whole target vocabulary V at each step, our trie-based constrained decoding method dynamically chooses and prunes a candidate vocabulary V ′ based on the current generated state. A complete linearized form decoding process can be represented by executing a trie tree search, as shown in Figure 3a. Specifically, each generation step of TEXT2EVENT has three kinds of candidate vocabulary V ′:\n• Event schema: label names of event types T and argument rolesR;\n• Mention strings: event trigger word and argument mention S , which is the text span in the raw input;\n• Structure indicator: “(” and “)” which are used to combine event schemas and mention strings.\nThe decoding starts from the root “〈bos〉” and ends at the terminator “〈eos〉”. At the generation step i, the candidate vocabulary V ′ is the children nodes of the last generated node. For instance, at the generation step with the generated string “〈bos〉 (”, the candidate vocabulary V ′ is {“(”, “)”} in Figure 3a. When generating the event type name\nT , argument role name R and text span S, the decoding process can be considered as executing search on a subtree of the trie tree. For example, in Figure 3b, the candidate vocabulary V ′ for “( Transfer” is {“Ownership”, “Money”}.\nFinally, the decoder’s output will be transformed to event records and used as final extraction results."
    }, {
      "heading" : "3 Learning",
      "text" : "This section describes how to learn the TEXT2EVENT neural network in an end-toend manner. Our method can be learned using only the coarse parallel text-record annotations, i.e., pairs of 〈sentence, event records〉, with no need for fine-grained token-level annotation used in traditional methods. Given a training dataset D = {(x1, y1), ...(x|D|, y|D|)} where each instance is a 〈sentence, event records〉 pair, the learning objective is the negative log-likelihood function as:\nL = − ∑\n(x,y)∈D\nlog p(y|x, θ) (4)\nwhere θ is model parameters. Unfortunately, unlike general text-to-text generation models, the learning of sequence-to-structure generation models is more challenging: 1) There is an output gap between the event generation model and the text-to-text generation model. Compared with natural word sequences, the linearized event structure contains many non-semantic indicators\nsuch as “(” and “)”, and they don’t follow the syntax constraints of natural language sentences. 2) The non-semantic indicators “(” and “)” appear very frequently but contain little semantic information, which will mislead the learning process.\nTo address the above challenges, we employ a curriculum learning (Bengio et al., 2009; Xu et al., 2020) strategy. Specifically, we first train PLMs using simple event substructure generation tasks so that they would not overfit in non-semantic indicators; then we train the model on the full event structure generation task.\nSubstructure Learning. Because event representations often have complex structures and their token sequences are different from natural language word sequences, it is challenging to train them with the full sequence generation task directly. Therefore, we first train TEXT2EVENT on simple event substructures.\nSpecifically, we learn our model by starting from generating only “(label, span)” substructures, including “(type, trigger words)” and “(role, argument words)” substructures. For example, we will extract substructure tasks in Figure 2c in this stage as: (Transport returned) (Artifact The man) (Arrest-Jail capture), etc. We construct a 〈sentence, substructures〉 pair for each extracted substructures, then train our model using the loss in equation 4.\nFull Structure Learning. After the substructure learning stage, we further train our model for the full structure generation task using the loss in equation 4. We found the curriculum learning strategy uses data annotation more efficiently and makes the learning process more smooth."
    }, {
      "heading" : "4 Experiments",
      "text" : "This section evaluates the proposed TEXT2EVENT model by conducting experiments in both supervised learning and transfer learning settings."
    }, {
      "heading" : "4.1 Experimental Settings",
      "text" : "Datasets. We conducted experiments on the event extraction benchmark – ACE2005 (Walker et al., 2006), which has 599 English annotated documents and 33 event types. We used the same split and preprocessing step as the previous work (Zhang et al., 2019b; Wadden et al., 2019; Du and Cardie, 2020), and we denote it as ACE05-EN.\nIn addition to ACE05-EN, we also conducted experiments on two other benchmarks: ACE05-EN+ and ERE-EN, using the same split and preprocessing step in the previous work (Lin et al., 2020). Compared to ACE05-EN, ACE05-EN+ and EREEN further consider pronoun roles and multi-token event triggers. ERE-EN contains 38 event categories and 458 documents.\nStatistics of all datasets are shown in Table 1. For evaluation, we used the same criteria in previous work (Zhang et al., 2019b; Wadden et al., 2019; Lin et al., 2020). Since TEXT2EVENT is a text generation model, we reconstructed the offset of predicted trigger mentions by finding the matched utterance in the input sequence one by one. For argument mentions, we found the nearest matched utterance to the predicted trigger mention as the predicted offset.\nBaselines. Currently, event extraction supervision can be conducted at two different levels: 1) Token-level annotation, which labels each token in a sentence with event labels, e.g., “The/O dismission/B-End-Position of/O ..”; 2) Parallel textrecord annotation, which only gives 〈sentence, event〉 pairs but without expensive token-level annotations, e.g., 〈The dismission of ..., {Type: EndPosition, Trigger: dismission, ...}〉. Furthermore, some previous works also leverage golden entity annotation for model training, which marks all entity mentions with their golden types, to facilitate event extraction. Introducing more supervision knowledge will benefit the event extraction but is more label-intensive. The proposed Text2Event only uses parallel text-record annotation, which makes it more practical in a real-world application.\nTo verify TEXT2EVENT, we compare our method with the following groups of baselines:\n1. Baselines using token annotation: TANL is the\nSOTA sequence generation-based method that models event extraction as a trigger-argument pipeline manner (Paolini et al., 2021); Multi-task TANL extends TANL by transferring structure knowledge from other tasks; EEQA (Du and Cardie, 2020) and MQAEE (Li et al., 2020) are QA-based models which use machine reading comprehension model for trigger detection and argument extraction.\n2. Baselines using both token annotation and entity annotation: Joint3EE is a joint entity, trigger, argument extraction model based on the shared hidden representations (Nguyen and Nguyen, 2019); DYGIE++ is a BERT-based model which captures both within-sentence and cross-sentence context (Wadden et al., 2019); GAIL is an inverse reinforcement learning-based joint entity and event extraction model (Zhang et al., 2019b); OneIE is an end-to-end IE system which employs global feature and beam search to extract globally optimal event structures (Lin et al., 2020).\nImplementations. We optimized our model using label smoothing (Szegedy et al., 2016; Müller et al., 2019) and AdamW (Loshchilov and Hutter, 2019) with learning rate=5e-5 for T5-large, 1e-4 for T5-base. For curriculum learning, the epoch of substructure learning is 5, and full structure learn-\ning is 30. We conducted each experiment on a single NVIDIA GeForce RTX 3090 24GB. Due to GPU memory limitation, we used different batch sizes for different models: 8 for T5-large and 16 for T5-base; and truncated the max length of raw text to 256 and linearized form to 128 during training. We added the task name as the prefix for the T5 default setup."
    }, {
      "heading" : "4.2 Results in Supervised Learning Setting",
      "text" : "Table 2 presents the performance of all baselines and TEXT2EVENT on ACE05-EN. And Table 3 shows the performance of SOTA and TEXT2EVENT on ACE05-EN+ and ERE-EN. We can see that:\n1) By uniformly modeling all tasks in a single model and predicting labels universally, TEXT2EVENT can achieve competitive performance with weaker supervision and simpler architecture. Our method, only using the weak parallel text-record annotations, surpasses most of the baselines using token and entity annotations and achieves competitive performance with SOTA. Furthermore, using the simple encoder-decoder architecture, TEXT2EVENT outperforms most of the counterparts with complicated architectures.\n2) By directly generating event structure from the text, TEXT2EVENT can significantly outperform sequence generation-based methods. Our method improves Arg-C F1 by 4.6% and 2.7% over the SOTA generation baseline and its extended multitask TANL. Compared with sequence generation, structure generation can be effectively guided using event schema knowledge during inference, and there is no need to generate irrelevant information.\n3) By uniformly modeling and sharing information between different tasks and labels, the sequence-to-structure framework can achieve robust performance. From Table 2 and Table 3, we can see that the performance of OneIE decreases on the harder dataset ACE05-EN+, which has more pronoun roles and multi-token triggers. By contrast, the performance of TEXT2EVENT remains nearly the same on ACE05-EN. We believe this may be because the proposed sequence-to-structure model is a universal model that doesn’t specialize in labels and can better share information between different labels."
    }, {
      "heading" : "4.3 Results in Transfer Learning Setting",
      "text" : "TEXT2EVENT is a universal model, therefore can facilitate the knowledge transfer between different labels. To verify the transfer ability of TEXT2EVENT, we conducted experiments in the transfer learning setting, and the results are shown in Table 4. Specifically, we first randomly split the sentences which length larger than 8 in ACE05EN+ into two equal-sized subsets src and tgt: src only retains the annotations of the top 10 frequent event types, and tgt only retains the annotations of the remaining 23 event types. For both src and tgt, we use 80% of the dataset for model training and\n20% for evaluation. For transfer learning, We first pre-trained an event extraction model on the src dataset, then fine-tuned the pre-trained model for extracting the new event types in tgt. From Table 4, we can see that:\n1) Data-efficient TEXT2EVENT can make better use of supervision signals. Even training on tgt from scratch, the proposed method also outperforms strong baselines. We believe that this may because baselines using token and entity annotation require massive fine-grained data for model learning. Different from baselines, TEXT2EVENT uniformly models all subtasks, thus the knowledge can be seamlessly transferred, which is more dataefficient.\n2) TEXT2EVENT can effectively transfer knowledge between different labels. Compared with the non-transfer setting, which is directly trained on tgt training set, the transfer setting of TEXT2EVENT can achieve significant F1 improvements of 3.7 and 3.2 on Trig-C and Arg-C, respectively. By contrast, the other two baselines cannot obtain significant F1 improvements of both Trig-C and Arg-C via transfer learning. Note that the information of entity annotation is shared across src and tgt. As a result, OneIE can leverage such information to better argument prediction even with worse trigger prediction. However, even without using entity annotation, the proposed method can still achieve a similar improvement in the transfer learning setting. This is because the labels are provided universally in TEXT2EVENT, so the parameters are not labelspecific."
    }, {
      "heading" : "4.4 Detailed Analysis",
      "text" : "This section analyzes the effects of event schema knowledge, constrained decoding, and curriculum learning algorithm in TEXT2EVENT. We designed four ablated variants based on T5-base:\n• “TEXT2EVENT” is the base model that is directly trained with the full structure learning.\n• “+ CL” indicates training TEXT2EVENT with the proposed curriculum learning algorithm.\n• “w/o CD” discards the constrained decoding during inference and generates event structures as an unconstrained generation model.\n• “w/o ES” replaces the names of event types and roles with meaningless symbols, which is used to verify the effect of event schema knowledge.\nTable 5 shows the results on the development set of ACE05-EN using different training data sizes. We can see that: 1) Constrained decoding can effectively guide the generation with event schemas, especially in low-resource settings. Comparing to “w/o CD”, constrained decoding improves the performance of TEXT2EVENT, especially in lowresource scenarios, e.g., using 1%, 5% training set. 2) Curriculum learning is useful for model learning. Substructure learning improves 4.7% Trig-C F1 and 5.8% Arg-C F1 on average. 3) It is crucial to encode and generate event labels as words, rather than meaningless symbols. Because by encoding labels as natural language words, our method can effectively transfer knowledge from pre-trained language models."
    }, {
      "heading" : "5 Related Work",
      "text" : "Our work is a synthesis of two research directions: event extraction and structure prediction via neural generation model.\nEvent extraction has received widespread attention in recent years, and mainstream methods usually use different strategies to obtain a complete event structure. These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al., 2011; Li et al., 2013, 2014; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2018; Zhang et al., 2019a; Zheng et al., 2019), 3) semantic structure grounding (Huang et al., 2016, 2018; Zhang et al., 2020a), and 4) question-answering (Chen et al., 2020b; Du and Cardie, 2020; Li et al., 2020; Liu et al., 2020).\nCompared with previous methods, we model all subtasks of event extraction in a uniform sequenceto-structure framework, which leads to better decision interactions and information sharing. The neural encoder-decoder generation architecture (Sutskever et al., 2014; Bahdanau et al., 2015) has shown its strong structure prediction ability and has been widely used in many NLP tasks, such as machine translation (Kalchbrenner and Blunsom, 2013), semantic parsing (Dong and Lapata, 2016; Song et al., 2020), entity extraction (Straková et al., 2019), relation extraction (Zeng et al., 2018; Zhang et al., 2020b), and aspect term extraction (Ma et al., 2019). Like TEXT2EVENT in this paper, TANL (Paolini et al., 2021) and GRIT (Du et al., 2021) also employ neural generation models for event extraction, but they focus on sequence generation, rather than structure generation. Different from previous works that extract text span via labeling (Straková et al., 2019) or copy/pointer mechanism (Zeng et al., 2018; Du et al., 2021), TEXT2EVENT directly generate event schemas and text spans to form event records via constrained decoding (Cao et al., 2021; Chen et al., 2020a), which allows TEXT2EVENT to handle various event types and transfer to new types easily."
    }, {
      "heading" : "6 Conclusions",
      "text" : "In this paper, we propose TEXT2EVENT, a sequence-to-structure generation paradigm for\nevent extraction. TEXT2EVENT directly learns from parallel text-record annotation and uniformly models all subtasks of event extraction in a sequence-to-structure framework. Concretely, we propose an effective sequence-to-structure network for event extraction, which is further enhanced by a constrained decoding algorithm for event knowledge injection during inference and a curriculum learning algorithm for efficient model learning. Experimental results in supervised learning and transfer learning settings show that TEXT2EVENT can achieve competitive performance with the previous SOTA using only coarse text-record annotation.\nFor future work, we plan to adapt our method to other information extraction tasks, such as N-ary relation extraction."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We sincerely thank the reviewers for their insightful comments and valuable suggestions. This work is supported by the National Natural Science Foundation of China under Grants no. U1936207 and 61772505, Beijing Academy of Artificial Intelligence (BAAI2019QN0502), and in part by the Youth Innovation Promotion Association CAS(2018141)."
    } ],
    "references" : [ {
      "title" : "The stages of event extraction",
      "author" : [ "David Ahn." ],
      "venue" : "Proceedings of the Workshop on Annotating and Reasoning about Time and Events, pages 1–8, Sydney, Australia. Association for Computational Linguistics.",
      "citeRegEx" : "Ahn.,? 2006",
      "shortCiteRegEx" : "Ahn.",
      "year" : 2006
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "The Third International Conference on Learning Representations.",
      "citeRegEx" : "Bahdanau et al\\.,? 2015",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2015
    }, {
      "title" : "Curriculum learning",
      "author" : [ "Yoshua Bengio", "Jérôme Louradour", "Ronan Collobert", "Jason Weston." ],
      "venue" : "Proceedings of the 26th International Conference on Machine Learning, pages 41–48, Montreal. Omnipress.",
      "citeRegEx" : "Bengio et al\\.,? 2009",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2009
    }, {
      "title" : "Autoregressive entity retrieval",
      "author" : [ "Nicola De Cao", "Gautier Izacard", "Sebastian Riedel", "Fabio Petroni." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Cao et al\\.,? 2021",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2021
    }, {
      "title" : "Parallel sentence mining by constrained decoding",
      "author" : [ "Pinzhen Chen", "Nikolay Bogoychev", "Kenneth Heafield", "Faheem Kirefu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1672–1678, Online. Association",
      "citeRegEx" : "Chen et al\\.,? 2020a",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "Event extraction via dynamic multipooling convolutional neural networks",
      "author" : [ "Yubo Chen", "Liheng Xu", "Kang Liu", "Daojian Zeng", "Jun Zhao." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Interna-",
      "citeRegEx" : "Chen et al\\.,? 2015",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2015
    }, {
      "title" : "Reading the manual: Event extraction as definition comprehension",
      "author" : [ "Yunmo Chen", "Tongfei Chen", "Seth Ebner", "Aaron Steven White", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the Fourth Workshop on Structured Prediction for NLP, pages 74–83, Online.",
      "citeRegEx" : "Chen et al\\.,? 2020b",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "The automatic content extraction (ACE) program – tasks, data, and evaluation",
      "author" : [ "George Doddington", "Alexis Mitchell", "Mark Przybocki", "Lance Ramshaw", "Stephanie Strassel", "Ralph Weischedel." ],
      "venue" : "Proceedings of the Fourth International Conference",
      "citeRegEx" : "Doddington et al\\.,? 2004",
      "shortCiteRegEx" : "Doddington et al\\.",
      "year" : 2004
    }, {
      "title" : "Language to logical form with neural attention",
      "author" : [ "Li Dong", "Mirella Lapata." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 33–43, Berlin, Germany. Association for Computa-",
      "citeRegEx" : "Dong and Lapata.,? 2016",
      "shortCiteRegEx" : "Dong and Lapata.",
      "year" : 2016
    }, {
      "title" : "Event extraction by answering (almost) natural questions",
      "author" : [ "Xinya Du", "Claire Cardie." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 671–683, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Du and Cardie.,? 2020",
      "shortCiteRegEx" : "Du and Cardie.",
      "year" : 2020
    }, {
      "title" : "GRIT: Generative role-filler transformers for document-level event entity extraction",
      "author" : [ "Xinya Du", "Alexander Rush", "Claire Cardie." ],
      "venue" : "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics:",
      "citeRegEx" : "Du et al\\.,? 2021",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2021
    }, {
      "title" : "Using cross-entity inference to improve event extraction",
      "author" : [ "Yu Hong", "Jianfeng Zhang", "Bin Ma", "Jianmin Yao", "Guodong Zhou", "Qiaoming Zhu." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human",
      "citeRegEx" : "Hong et al\\.,? 2011",
      "shortCiteRegEx" : "Hong et al\\.",
      "year" : 2011
    }, {
      "title" : "Self-regulation: Employing a generative adversarial network to improve event detection",
      "author" : [ "Yu Hong", "Wenxuan Zhou", "Jingli Zhang", "Guodong Zhou", "Qiaoming Zhu." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Vol-",
      "citeRegEx" : "Hong et al\\.,? 2018",
      "shortCiteRegEx" : "Hong et al\\.",
      "year" : 2018
    }, {
      "title" : "Zero-shot transfer learning for event extraction",
      "author" : [ "Lifu Huang", "Heng Ji", "Kyunghyun Cho", "Ido Dagan", "Sebastian Riedel", "Clare Voss." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
      "citeRegEx" : "Huang et al\\.,? 2018",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2018
    }, {
      "title" : "Modeling textual cohesion for event extraction",
      "author" : [ "Ruihong Huang", "Ellen Riloff." ],
      "venue" : "Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence, AAAI’12, page 1664–1670. AAAI Press.",
      "citeRegEx" : "Huang and Riloff.,? 2012",
      "shortCiteRegEx" : "Huang and Riloff.",
      "year" : 2012
    }, {
      "title" : "Refining event extraction through cross-document inference",
      "author" : [ "Heng Ji", "Ralph Grishman." ],
      "venue" : "Proceedings of ACL-08: HLT, pages 254–262. Association for Computational Linguistics.",
      "citeRegEx" : "Ji and Grishman.,? 2008",
      "shortCiteRegEx" : "Ji and Grishman.",
      "year" : 2008
    }, {
      "title" : "Recurrent continuous translation models",
      "author" : [ "Nal Kalchbrenner", "Phil Blunsom." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1700–1709, Seattle, Washington, USA. Association for Computational",
      "citeRegEx" : "Kalchbrenner and Blunsom.,? 2013",
      "shortCiteRegEx" : "Kalchbrenner and Blunsom.",
      "year" : 2013
    }, {
      "title" : "Event extraction as multi-turn question answering",
      "author" : [ "Fayuan Li", "Weihua Peng", "Yuguang Chen", "Quan Wang", "Lu Pan", "Yajuan Lyu", "Yong Zhu." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 829–838, Online. Association",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Constructing information networks using one single model",
      "author" : [ "Qi Li", "Heng Ji", "Yu Hong", "Sujian Li." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1846–1851, Doha, Qatar. Associa-",
      "citeRegEx" : "Li et al\\.,? 2014",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2014
    }, {
      "title" : "Joint event extraction via structured prediction with global features",
      "author" : [ "Qi Li", "Heng Ji", "Liang Huang." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 73–82, Sofia, Bulgaria.",
      "citeRegEx" : "Li et al\\.,? 2013",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2013
    }, {
      "title" : "Using document level cross-event inference to improve event extraction",
      "author" : [ "Shasha Liao", "Ralph Grishman." ],
      "venue" : "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 789–797, Uppsala, Sweden. Association for",
      "citeRegEx" : "Liao and Grishman.,? 2010",
      "shortCiteRegEx" : "Liao and Grishman.",
      "year" : 2010
    }, {
      "title" : "Nugget proposal networks for Chinese event detection",
      "author" : [ "Hongyu Lin", "Yaojie Lu", "Xianpei Han", "Le Sun." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1565–1574, Melbourne,",
      "citeRegEx" : "Lin et al\\.,? 2018",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2018
    }, {
      "title" : "A joint neural model for information extraction with global features",
      "author" : [ "Ying Lin", "Heng Ji", "Fei Huang", "Lingfei Wu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7999–8009, Online. Association for",
      "citeRegEx" : "Lin et al\\.,? 2020",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "Event extraction as machine reading comprehension",
      "author" : [ "Jian Liu", "Yubo Chen", "Kang Liu", "Wei Bi", "Xiaojiang Liu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1641–1651, Online. Association",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Jointly multiple events extraction via attention-based graph information aggregation",
      "author" : [ "Xiao Liu", "Zhunchen Luo", "Heyan Huang." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1247–1256, Brussels,",
      "citeRegEx" : "Liu et al\\.,? 2018",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2018
    }, {
      "title" : "Decoupled weight decay regularization",
      "author" : [ "Ilya Loshchilov", "Frank Hutter." ],
      "venue" : "Seventh International Conference on Learning Representations.",
      "citeRegEx" : "Loshchilov and Hutter.,? 2019",
      "shortCiteRegEx" : "Loshchilov and Hutter.",
      "year" : 2019
    }, {
      "title" : "Exploring sequence-tosequence learning in aspect term extraction",
      "author" : [ "Dehong Ma", "Sujian Li", "Fangzhao Wu", "Xing Xie", "Houfeng Wang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3538–",
      "citeRegEx" : "Ma et al\\.,? 2019",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2019
    }, {
      "title" : "Resourceenhanced neural model for event argument extraction",
      "author" : [ "Jie Ma", "Shuai Wang", "Rishita Anubhai", "Miguel Ballesteros", "Yaser Al-Onaizan." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3554–3559, Online.",
      "citeRegEx" : "Ma et al\\.,? 2020",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2020
    }, {
      "title" : "Event extraction as dependency parsing",
      "author" : [ "David McClosky", "Mihai Surdeanu", "Christopher Manning." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1626–1635,",
      "citeRegEx" : "McClosky et al\\.,? 2011",
      "shortCiteRegEx" : "McClosky et al\\.",
      "year" : 2011
    }, {
      "title" : "When does label smoothing help? In Advances in Neural Information Processing Systems, volume 32, pages 4694–4703",
      "author" : [ "Rafael Müller", "Simon Kornblith", "Geoffrey E Hinton." ],
      "venue" : "Curran Associates, Inc.",
      "citeRegEx" : "Müller et al\\.,? 2019",
      "shortCiteRegEx" : "Müller et al\\.",
      "year" : 2019
    }, {
      "title" : "Joint event extraction via recurrent neural networks",
      "author" : [ "Thien Huu Nguyen", "Kyunghyun Cho", "Ralph Grishman." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
      "citeRegEx" : "Nguyen et al\\.,? 2016",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2016
    }, {
      "title" : "One for all: Neural joint modeling of entities and events",
      "author" : [ "Trung Minh Nguyen", "Thien Huu Nguyen." ],
      "venue" : "The Thirty-Third AAAI Conference on",
      "citeRegEx" : "Nguyen and Nguyen.,? 2019",
      "shortCiteRegEx" : "Nguyen and Nguyen.",
      "year" : 2019
    }, {
      "title" : "Structured prediction as translation between augmented natural languages",
      "author" : [ "Giovanni Paolini", "Ben Athiwaratkun", "Jason Krone", "Jie Ma", "Alessandro Achille", "Rishita Anubhai", "Cicero Nogueira dos Santos", "Bing Xiang", "Stefano Soatto." ],
      "venue" : "The Ninth",
      "citeRegEx" : "Paolini et al\\.,? 2021",
      "shortCiteRegEx" : "Paolini et al\\.",
      "year" : 2021
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J. Liu." ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Raffel et al\\.,? 2020",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2020
    }, {
      "title" : "RBPB: Regularization-based pattern balancing method for event extraction",
      "author" : [ "Lei Sha", "Jing Liu", "Chin-Yew Lin", "Sujian Li", "Baobao Chang", "Zhifang Sui." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Sha et al\\.,? 2016",
      "shortCiteRegEx" : "Sha et al\\.",
      "year" : 2016
    }, {
      "title" : "Structural information preserving for graph-to-text generation",
      "author" : [ "Linfeng Song", "Ante Wang", "Jinsong Su", "Yue Zhang", "Kun Xu", "Yubin Ge", "Dong Yu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7987–",
      "citeRegEx" : "Song et al\\.,? 2020",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural architectures for nested NER through linearization",
      "author" : [ "Jana Straková", "Milan Straka", "Jan Hajic." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5326–5331, Florence, Italy. Association for Compu-",
      "citeRegEx" : "Straková et al\\.,? 2019",
      "shortCiteRegEx" : "Straková et al\\.",
      "year" : 2019
    }, {
      "title" : "Sequence to sequence learning with neural networks",
      "author" : [ "Ilya Sutskever", "Oriol Vinyals", "Quoc V Le." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 27, pages 3104–3112. Curran Associates, Inc.",
      "citeRegEx" : "Sutskever et al\\.,? 2014",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2014
    }, {
      "title" : "Rethinking the inception architecture for computer vision",
      "author" : [ "C. Szegedy", "V. Vanhoucke", "S. Ioffe", "J. Shlens", "Z. Wojna." ],
      "venue" : "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2818–2826.",
      "citeRegEx" : "Szegedy et al\\.,? 2016",
      "shortCiteRegEx" : "Szegedy et al\\.",
      "year" : 2016
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Ł ukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 30, pages 5998–6008. Cur-",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Grammar as a foreign language",
      "author" : [ "Oriol Vinyals", "Ł ukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 28, pages 2773–2781. Curran Associates, Inc.",
      "citeRegEx" : "Vinyals et al\\.,? 2015",
      "shortCiteRegEx" : "Vinyals et al\\.",
      "year" : 2015
    }, {
      "title" : "Entity, relation, and event extraction with contextualized span representations",
      "author" : [ "David Wadden", "Ulme Wennberg", "Yi Luan", "Hannaneh Hajishirzi." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
      "citeRegEx" : "Wadden et al\\.,? 2019",
      "shortCiteRegEx" : "Wadden et al\\.",
      "year" : 2019
    }, {
      "title" : "HMEAE: Hierarchical modular event argument extraction",
      "author" : [ "Xiaozhi Wang", "Ziqi Wang", "Xu Han", "Zhiyuan Liu", "Juanzi Li", "Peng Li", "Maosong Sun", "Jie Zhou", "Xiang Ren." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Pro-",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Curriculum learning for natural language understanding",
      "author" : [ "Benfeng Xu", "Licheng Zhang", "Zhendong Mao", "Quan Wang", "Hongtao Xie", "Yongdong Zhang." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Joint extraction of events and entities within a document context",
      "author" : [ "Bishan Yang", "Tom M. Mitchell." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
      "citeRegEx" : "Yang and Mitchell.,? 2016",
      "shortCiteRegEx" : "Yang and Mitchell.",
      "year" : 2016
    }, {
      "title" : "Exploring pre-trained language models for event extraction and generation",
      "author" : [ "Sen Yang", "Dawei Feng", "Linbo Qiao", "Zhigang Kan", "Dongsheng Li." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5284–",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Extracting relational facts by an end-to-end neural model with copy mechanism",
      "author" : [ "Xiangrong Zeng", "Daojian Zeng", "Shizhu He", "Kang Liu", "Jun Zhao." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1:",
      "citeRegEx" : "Zeng et al\\.,? 2018",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2018
    }, {
      "title" : "Unsupervised label-aware event trigger and argument classification",
      "author" : [ "Hongming Zhang", "Haoyu Wang", "Dan Roth" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Extracting entities and events as a single task using a transition-based neural model",
      "author" : [ "Junchi Zhang", "Yanxia Qin", "Yue Zhang", "Mengchi Liu", "Donghong Ji." ],
      "venue" : "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Zhang et al\\.,? 2019a",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Minimize exposure bias of Seq2Seq models in joint entity and relation extraction",
      "author" : [ "Ranran Haoran Zhang", "Qianying Liu", "Aysa Xuemo Fan", "Heng Ji", "Daojian Zeng", "Fei Cheng", "Daisuke Kawahara", "Sadao Kurohashi." ],
      "venue" : "Findings of the Association",
      "citeRegEx" : "Zhang et al\\.,? 2020b",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Joint entity and event extraction with generative adversarial imitation learning",
      "author" : [ "Tongtao Zhang", "Heng Ji", "Avirup Sil." ],
      "venue" : "Data Intelligence, 1(2):99– 120.",
      "citeRegEx" : "Zhang et al\\.,? 2019b",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "A two-step approach for implicit event argument detection",
      "author" : [ "Zhisong Zhang", "Xiang Kong", "Zhengzhong Liu", "Xuezhe Ma", "Eduard Hovy." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7479–7485, Online.",
      "citeRegEx" : "Zhang et al\\.,? 2020c",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Doc2EDAG: An end-to-end document-level framework for Chinese financial event extraction",
      "author" : [ "Shun Zheng", "Wei Cao", "Wei Xu", "Jiang Bian." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th In-",
      "citeRegEx" : "Zheng et al\\.,? 2019",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "Event extraction is an essential task for natural language understanding, aiming to transform the text into event records (Doddington et al., 2004; Ahn, 2006).",
      "startOffset" : 122,
      "endOffset" : 158
    }, {
      "referenceID" : 0,
      "context" : "Event extraction is an essential task for natural language understanding, aiming to transform the text into event records (Doddington et al., 2004; Ahn, 2006).",
      "startOffset" : 122,
      "endOffset" : 158
    }, {
      "referenceID" : 5,
      "context" : "Currently, most event extraction methods employ the decomposition strategy (Chen et al., 2015; Nguyen and Nguyen, 2019; Wadden et al., 2019; Zhang et al., 2019b; Du and Cardie, 2020; Li et al., 2020; Paolini et al., 2021), i.",
      "startOffset" : 75,
      "endOffset" : 221
    }, {
      "referenceID" : 31,
      "context" : "Currently, most event extraction methods employ the decomposition strategy (Chen et al., 2015; Nguyen and Nguyen, 2019; Wadden et al., 2019; Zhang et al., 2019b; Du and Cardie, 2020; Li et al., 2020; Paolini et al., 2021), i.",
      "startOffset" : 75,
      "endOffset" : 221
    }, {
      "referenceID" : 41,
      "context" : "Currently, most event extraction methods employ the decomposition strategy (Chen et al., 2015; Nguyen and Nguyen, 2019; Wadden et al., 2019; Zhang et al., 2019b; Du and Cardie, 2020; Li et al., 2020; Paolini et al., 2021), i.",
      "startOffset" : 75,
      "endOffset" : 221
    }, {
      "referenceID" : 50,
      "context" : "Currently, most event extraction methods employ the decomposition strategy (Chen et al., 2015; Nguyen and Nguyen, 2019; Wadden et al., 2019; Zhang et al., 2019b; Du and Cardie, 2020; Li et al., 2020; Paolini et al., 2021), i.",
      "startOffset" : 75,
      "endOffset" : 221
    }, {
      "referenceID" : 9,
      "context" : "Currently, most event extraction methods employ the decomposition strategy (Chen et al., 2015; Nguyen and Nguyen, 2019; Wadden et al., 2019; Zhang et al., 2019b; Du and Cardie, 2020; Li et al., 2020; Paolini et al., 2021), i.",
      "startOffset" : 75,
      "endOffset" : 221
    }, {
      "referenceID" : 17,
      "context" : "Currently, most event extraction methods employ the decomposition strategy (Chen et al., 2015; Nguyen and Nguyen, 2019; Wadden et al., 2019; Zhang et al., 2019b; Du and Cardie, 2020; Li et al., 2020; Paolini et al., 2021), i.",
      "startOffset" : 75,
      "endOffset" : 221
    }, {
      "referenceID" : 32,
      "context" : "Currently, most event extraction methods employ the decomposition strategy (Chen et al., 2015; Nguyen and Nguyen, 2019; Wadden et al., 2019; Zhang et al., 2019b; Du and Cardie, 2020; Li et al., 2020; Paolini et al., 2021), i.",
      "startOffset" : 75,
      "endOffset" : 221
    }, {
      "referenceID" : 40,
      "context" : "Given the converted event tree, we linearize it into a token sequence (Figure 2c) via depth-first traversal (Vinyals et al., 2015), where “(” and “)” are structure indicators used to represent the semantic structure of linear expressions.",
      "startOffset" : 108,
      "endOffset" : 130
    }, {
      "referenceID" : 39,
      "context" : "Based on the above linearization strategy, TEXT2EVENT generates the event structure via a transformer-based encoder-decoder architecture (Vaswani et al., 2017).",
      "startOffset" : 137,
      "endOffset" : 159
    }, {
      "referenceID" : 33,
      "context" : "Because all tokens in linearized event representations are also natural language words, we adopt the pre-trained language model T5 (Raffel et al., 2020) as our transformer-based encoder-decoder architecture.",
      "startOffset" : 131,
      "endOffset" : 152
    }, {
      "referenceID" : 4,
      "context" : "To exploit the event schema knowledge, we propose to employ a trie-based constrained decoding algorithm (Chen et al., 2020a; Cao et al., 2021) for event generation.",
      "startOffset" : 104,
      "endOffset" : 142
    }, {
      "referenceID" : 3,
      "context" : "To exploit the event schema knowledge, we propose to employ a trie-based constrained decoding algorithm (Chen et al., 2020a; Cao et al., 2021) for event generation.",
      "startOffset" : 104,
      "endOffset" : 142
    }, {
      "referenceID" : 2,
      "context" : "To address the above challenges, we employ a curriculum learning (Bengio et al., 2009; Xu et al., 2020) strategy.",
      "startOffset" : 65,
      "endOffset" : 103
    }, {
      "referenceID" : 43,
      "context" : "To address the above challenges, we employ a curriculum learning (Bengio et al., 2009; Xu et al., 2020) strategy.",
      "startOffset" : 65,
      "endOffset" : 103
    }, {
      "referenceID" : 50,
      "context" : "We used the same split and preprocessing step as the previous work (Zhang et al., 2019b; Wadden et al., 2019; Du and Cardie, 2020), and we denote it as ACE05-EN.",
      "startOffset" : 67,
      "endOffset" : 130
    }, {
      "referenceID" : 41,
      "context" : "We used the same split and preprocessing step as the previous work (Zhang et al., 2019b; Wadden et al., 2019; Du and Cardie, 2020), and we denote it as ACE05-EN.",
      "startOffset" : 67,
      "endOffset" : 130
    }, {
      "referenceID" : 9,
      "context" : "We used the same split and preprocessing step as the previous work (Zhang et al., 2019b; Wadden et al., 2019; Du and Cardie, 2020), and we denote it as ACE05-EN.",
      "startOffset" : 67,
      "endOffset" : 130
    }, {
      "referenceID" : 22,
      "context" : "In addition to ACE05-EN, we also conducted experiments on two other benchmarks: ACE05-EN+ and ERE-EN, using the same split and preprocessing step in the previous work (Lin et al., 2020).",
      "startOffset" : 167,
      "endOffset" : 185
    }, {
      "referenceID" : 50,
      "context" : "For evaluation, we used the same criteria in previous work (Zhang et al., 2019b; Wadden et al., 2019; Lin et al., 2020).",
      "startOffset" : 59,
      "endOffset" : 119
    }, {
      "referenceID" : 41,
      "context" : "For evaluation, we used the same criteria in previous work (Zhang et al., 2019b; Wadden et al., 2019; Lin et al., 2020).",
      "startOffset" : 59,
      "endOffset" : 119
    }, {
      "referenceID" : 22,
      "context" : "For evaluation, we used the same criteria in previous work (Zhang et al., 2019b; Wadden et al., 2019; Lin et al., 2020).",
      "startOffset" : 59,
      "endOffset" : 119
    }, {
      "referenceID" : 32,
      "context" : "SOTA sequence generation-based method that models event extraction as a trigger-argument pipeline manner (Paolini et al., 2021); Multi-task TANL extends TANL by transferring structure knowledge from other tasks; EEQA (Du and Cardie, 2020) and MQAEE (Li et al.",
      "startOffset" : 105,
      "endOffset" : 127
    }, {
      "referenceID" : 9,
      "context" : ", 2021); Multi-task TANL extends TANL by transferring structure knowledge from other tasks; EEQA (Du and Cardie, 2020) and MQAEE (Li et al.",
      "startOffset" : 97,
      "endOffset" : 118
    }, {
      "referenceID" : 17,
      "context" : ", 2021); Multi-task TANL extends TANL by transferring structure knowledge from other tasks; EEQA (Du and Cardie, 2020) and MQAEE (Li et al., 2020) are QA-based models which use machine reading comprehension model for trigger detection and argument extraction.",
      "startOffset" : 129,
      "endOffset" : 146
    }, {
      "referenceID" : 31,
      "context" : "Baselines using both token annotation and entity annotation: Joint3EE is a joint entity, trigger, argument extraction model based on the shared hidden representations (Nguyen and Nguyen, 2019); DYGIE++ is a BERT-based model which captures both within-sentence and cross-sentence context (Wadden et al.",
      "startOffset" : 167,
      "endOffset" : 192
    }, {
      "referenceID" : 41,
      "context" : "Baselines using both token annotation and entity annotation: Joint3EE is a joint entity, trigger, argument extraction model based on the shared hidden representations (Nguyen and Nguyen, 2019); DYGIE++ is a BERT-based model which captures both within-sentence and cross-sentence context (Wadden et al., 2019); GAIL is an inverse reinforcement learning-based joint entity and event extraction model (Zhang et al.",
      "startOffset" : 287,
      "endOffset" : 308
    }, {
      "referenceID" : 50,
      "context" : ", 2019); GAIL is an inverse reinforcement learning-based joint entity and event extraction model (Zhang et al., 2019b); OneIE is an end-to-end IE system which employs global feature and beam search to extract globally optimal event structures (Lin et al.",
      "startOffset" : 97,
      "endOffset" : 118
    }, {
      "referenceID" : 22,
      "context" : ", 2019b); OneIE is an end-to-end IE system which employs global feature and beam search to extract globally optimal event structures (Lin et al., 2020).",
      "startOffset" : 133,
      "endOffset" : 151
    }, {
      "referenceID" : 38,
      "context" : "We optimized our model using label smoothing (Szegedy et al., 2016; Müller et al., 2019) and AdamW (Loshchilov and Hutter, 2019) with learning rate=5e-5 for T5-large, 1e-4 for T5-base.",
      "startOffset" : 45,
      "endOffset" : 88
    }, {
      "referenceID" : 29,
      "context" : "We optimized our model using label smoothing (Szegedy et al., 2016; Müller et al., 2019) and AdamW (Loshchilov and Hutter, 2019) with learning rate=5e-5 for T5-large, 1e-4 for T5-base.",
      "startOffset" : 45,
      "endOffset" : 88
    }, {
      "referenceID" : 25,
      "context" : ", 2019) and AdamW (Loshchilov and Hutter, 2019) with learning rate=5e-5 for T5-large, 1e-4 for T5-base.",
      "startOffset" : 18,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 15,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 20,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 14,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 5,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 34,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 21,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 45,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 42,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 27,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 51,
      "context" : "These methods can be divided into: 1) pipeline classification (Ahn, 2006; Ji and Grishman, 2008; Liao and Grishman, 2010; Hong et al., 2011, 2018; Huang and Riloff, 2012; Chen et al., 2015; Sha et al., 2016; Lin et al., 2018; Yang et al., 2019; Wang et al., 2019; Ma et al., 2020; Zhang et al., 2020c), 2) multi-task joint models (McClosky et al.",
      "startOffset" : 62,
      "endOffset" : 301
    }, {
      "referenceID" : 28,
      "context" : ", 2020c), 2) multi-task joint models (McClosky et al., 2011; Li et al., 2013, 2014; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2018; Zhang et al., 2019a; Zheng et al., 2019), 3) semantic structure grounding (Huang et al.",
      "startOffset" : 37,
      "endOffset" : 188
    }, {
      "referenceID" : 44,
      "context" : ", 2020c), 2) multi-task joint models (McClosky et al., 2011; Li et al., 2013, 2014; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2018; Zhang et al., 2019a; Zheng et al., 2019), 3) semantic structure grounding (Huang et al.",
      "startOffset" : 37,
      "endOffset" : 188
    }, {
      "referenceID" : 30,
      "context" : ", 2020c), 2) multi-task joint models (McClosky et al., 2011; Li et al., 2013, 2014; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2018; Zhang et al., 2019a; Zheng et al., 2019), 3) semantic structure grounding (Huang et al.",
      "startOffset" : 37,
      "endOffset" : 188
    }, {
      "referenceID" : 24,
      "context" : ", 2020c), 2) multi-task joint models (McClosky et al., 2011; Li et al., 2013, 2014; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2018; Zhang et al., 2019a; Zheng et al., 2019), 3) semantic structure grounding (Huang et al.",
      "startOffset" : 37,
      "endOffset" : 188
    }, {
      "referenceID" : 48,
      "context" : ", 2020c), 2) multi-task joint models (McClosky et al., 2011; Li et al., 2013, 2014; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2018; Zhang et al., 2019a; Zheng et al., 2019), 3) semantic structure grounding (Huang et al.",
      "startOffset" : 37,
      "endOffset" : 188
    }, {
      "referenceID" : 52,
      "context" : ", 2020c), 2) multi-task joint models (McClosky et al., 2011; Li et al., 2013, 2014; Yang and Mitchell, 2016; Nguyen et al., 2016; Liu et al., 2018; Zhang et al., 2019a; Zheng et al., 2019), 3) semantic structure grounding (Huang et al.",
      "startOffset" : 37,
      "endOffset" : 188
    }, {
      "referenceID" : 6,
      "context" : ", 2020a), and 4) question-answering (Chen et al., 2020b; Du and Cardie, 2020; Li et al., 2020; Liu et al., 2020).",
      "startOffset" : 36,
      "endOffset" : 112
    }, {
      "referenceID" : 9,
      "context" : ", 2020a), and 4) question-answering (Chen et al., 2020b; Du and Cardie, 2020; Li et al., 2020; Liu et al., 2020).",
      "startOffset" : 36,
      "endOffset" : 112
    }, {
      "referenceID" : 17,
      "context" : ", 2020a), and 4) question-answering (Chen et al., 2020b; Du and Cardie, 2020; Li et al., 2020; Liu et al., 2020).",
      "startOffset" : 36,
      "endOffset" : 112
    }, {
      "referenceID" : 23,
      "context" : ", 2020a), and 4) question-answering (Chen et al., 2020b; Du and Cardie, 2020; Li et al., 2020; Liu et al., 2020).",
      "startOffset" : 36,
      "endOffset" : 112
    }, {
      "referenceID" : 37,
      "context" : "The neural encoder-decoder generation architecture (Sutskever et al., 2014; Bahdanau et al., 2015) has shown its strong structure prediction ability and has been widely used in many NLP tasks, such as machine translation (Kalchbrenner and Blunsom, 2013), semantic parsing (Dong and Lapata, 2016; Song et al.",
      "startOffset" : 51,
      "endOffset" : 98
    }, {
      "referenceID" : 1,
      "context" : "The neural encoder-decoder generation architecture (Sutskever et al., 2014; Bahdanau et al., 2015) has shown its strong structure prediction ability and has been widely used in many NLP tasks, such as machine translation (Kalchbrenner and Blunsom, 2013), semantic parsing (Dong and Lapata, 2016; Song et al.",
      "startOffset" : 51,
      "endOffset" : 98
    }, {
      "referenceID" : 16,
      "context" : ", 2015) has shown its strong structure prediction ability and has been widely used in many NLP tasks, such as machine translation (Kalchbrenner and Blunsom, 2013), semantic parsing (Dong and Lapata, 2016; Song et al.",
      "startOffset" : 130,
      "endOffset" : 162
    }, {
      "referenceID" : 8,
      "context" : ", 2015) has shown its strong structure prediction ability and has been widely used in many NLP tasks, such as machine translation (Kalchbrenner and Blunsom, 2013), semantic parsing (Dong and Lapata, 2016; Song et al., 2020), entity extraction (Straková et al.",
      "startOffset" : 181,
      "endOffset" : 223
    }, {
      "referenceID" : 35,
      "context" : ", 2015) has shown its strong structure prediction ability and has been widely used in many NLP tasks, such as machine translation (Kalchbrenner and Blunsom, 2013), semantic parsing (Dong and Lapata, 2016; Song et al., 2020), entity extraction (Straková et al.",
      "startOffset" : 181,
      "endOffset" : 223
    }, {
      "referenceID" : 36,
      "context" : ", 2020), entity extraction (Straková et al., 2019), relation extraction (Zeng et al.",
      "startOffset" : 27,
      "endOffset" : 50
    }, {
      "referenceID" : 46,
      "context" : ", 2019), relation extraction (Zeng et al., 2018; Zhang et al., 2020b), and aspect term extraction (Ma et al.",
      "startOffset" : 29,
      "endOffset" : 69
    }, {
      "referenceID" : 49,
      "context" : ", 2019), relation extraction (Zeng et al., 2018; Zhang et al., 2020b), and aspect term extraction (Ma et al.",
      "startOffset" : 29,
      "endOffset" : 69
    }, {
      "referenceID" : 26,
      "context" : ", 2020b), and aspect term extraction (Ma et al., 2019).",
      "startOffset" : 37,
      "endOffset" : 54
    }, {
      "referenceID" : 32,
      "context" : "Like TEXT2EVENT in this paper, TANL (Paolini et al., 2021) and GRIT (Du et al.",
      "startOffset" : 36,
      "endOffset" : 58
    }, {
      "referenceID" : 10,
      "context" : ", 2021) and GRIT (Du et al., 2021) also employ neural generation models for event extraction, but they focus on sequence generation, rather than structure generation.",
      "startOffset" : 17,
      "endOffset" : 34
    }, {
      "referenceID" : 36,
      "context" : "Different from previous works that extract text span via labeling (Straková et al., 2019) or copy/pointer mechanism (Zeng et al.",
      "startOffset" : 66,
      "endOffset" : 89
    }, {
      "referenceID" : 46,
      "context" : ", 2019) or copy/pointer mechanism (Zeng et al., 2018; Du et al., 2021), TEXT2EVENT directly generate event schemas and text spans to form event records via constrained decoding (Cao et al.",
      "startOffset" : 34,
      "endOffset" : 70
    }, {
      "referenceID" : 10,
      "context" : ", 2019) or copy/pointer mechanism (Zeng et al., 2018; Du et al., 2021), TEXT2EVENT directly generate event schemas and text spans to form event records via constrained decoding (Cao et al.",
      "startOffset" : 34,
      "endOffset" : 70
    }, {
      "referenceID" : 3,
      "context" : ", 2021), TEXT2EVENT directly generate event schemas and text spans to form event records via constrained decoding (Cao et al., 2021; Chen et al., 2020a), which allows TEXT2EVENT to handle various event types and transfer to new types easily.",
      "startOffset" : 114,
      "endOffset" : 152
    }, {
      "referenceID" : 4,
      "context" : ", 2021), TEXT2EVENT directly generate event schemas and text spans to form event records via constrained decoding (Cao et al., 2021; Chen et al., 2020a), which allows TEXT2EVENT to handle various event types and transfer to new types easily.",
      "startOffset" : 114,
      "endOffset" : 152
    } ],
    "year" : 2021,
    "abstractText" : "Event extraction is challenging due to the complex structure of event records and the semantic gap between text and event. Traditional methods usually extract event records by decomposing the complex structure prediction task into multiple subtasks. In this paper, we propose TEXT2EVENT, a sequence-to-structure generation paradigm that can directly extract events from the text in an end-to-end manner. Specifically, we design a sequence-to-structure network for unified event extraction, a constrained decoding algorithm for event knowledge injection during inference, and a curriculum learning algorithm for efficient model learning. Experimental results show that, by uniformly modeling all tasks in a single model and universally predicting different labels, our method can achieve competitive performance using only record-level annotations in both supervised learning and transfer learning settings.",
    "creator" : "LaTeX with hyperref"
  }
}