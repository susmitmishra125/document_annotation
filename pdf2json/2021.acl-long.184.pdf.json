{
  "name" : "2021.acl-long.184.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Distributed Representations of Emotion Categories in Emotion Space",
    "authors" : [ "Xiangyu Wang", "Chengqing Zong" ],
    "emails" : [ "cqzong}@nlpr.ia.ac.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2364–2375\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n2364\nEmotion category is usually divided into different ones by human beings, but it is indeed difficult to clearly distinguish and define the boundaries between different emotion categories. The existing studies working on emotion detection usually focus on how to improve the performance of model prediction, in which emotions are represented with one-hot vectors. However, emotion relations are ignored in onehot representations. In this article, we first propose a general framework to learn the distributed representations for emotion categories in emotion space from a given emotion classification dataset. Furthermore, based on the soft labels predicted by the pre-trained neural network model, we derive a simple and effective algorithm. Experiments have validated that the proposed representations in emotion space can express emotion relations much better than word vectors in semantic space."
    }, {
      "heading" : "1 Introduction",
      "text" : "In the past decades, a lot of tasks have been proposed in the field of text emotion analysis. The most primary one among them is emotion classification task (Alm et al., 2005). Based on emotion classification task, many new tasks have been proposed from different considerations. Lee et al. (2010) proposed the task of emotion cause extraction, which aims at predicting the reason of a given emotion in a document. Based on the emotion cause extraction task, Xia and Ding (2019) introduced the emotion-cause pair extraction task for the purpose of extracting the potential pairs of emotions and corresponding causes in a document. Jiang et al. (2011) proposed a target-dependent emotion recognition task, which aims at predicting the sentiment with the given query. To express the intensity of\n∗ Corresponding author.\na specific emotion in text, Mohammad and BravoMarquez (2017) proposed the emotion intensity detection task. However, all the above tasks treat emotions as independent ones and represent emotions with one-hot vectors, which definitely ignore the underlying emotion relations.\nBased on existing emotion detection tasks, many efforts have been made to achieve better performance (Danisman and Alpkocak, 2008; Xia et al., 2011; Kim, 2014; Xia et al., 2015; Li et al., 2018; Zong et al., 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al., 2015; Mohammad et al., 2018; Liu et al., 2019). The vast majority of existing emotion annotation work assumes that the emotions are orthogonal to each other and represent the emotion categories with one-hot vectors (Mohammad, 2012; Gui et al., 2016; Klinger et al., 2018). Actually, the boundaries as well as the relations among emotion categories are not clearly distinguished and defined.\nTypical word embedding learning algorithms only use the contexts but ignore the sentiment of texts (Turian et al., 2010; Mikolov et al., 2013). To encode emotional information into word embedding, sentiment embedding and emotion(al) embedding have been proposed (Tang et al., 2014; Yu et al., 2017; Xu et al., 2018). Tang et al. (2015) proposed a learning algorithm dubbed sentimentspecific word embedding (SSWE). Agrawal et al. (2018) proposed a method to learn emotionenriched word embedding (EWE). However, all the above algorithms represent emotions in semantic space rather than emotion space. As shown in Table 1, each emotion category represented in semantic space reflect a piece of semantic information rather than a specific emotional state. In this work, we regard each emotion category as a specific emotional state in emotion space and represent each emotion category with a point in emotion\nspace. The further experiments show that our representations in emotion space can express emotion relations much better than word vectors in semantic space.\nFrom the perspective of psychology, some studies have discussed the complexity of the human emotional state (Russell, 1980; Griffiths, 2002; Fontaine et al., 2007; Clark, 2010) and the shared psychological features across emotions (Fehr and Russell, 1984; Mauss and Robinson, 2009; Campos et al., 2013). However, psychological researches mainly focus on the human emotional state itself and do not pay attention to emotion relations hidden in the text. As there are lots of emotion detection tasks and corresponding datasets in NLP field, it is very meaningful to investigate what is the relations among emotion categories hidden in corpora. In this paper, we detect the underlying relations among emotion categories labeled in corpora from the perspective of NLP.\nDistributed representations of emotion categories in emotion space can also benefit NLP applications. Take depression recognition for example, depression is a serious mood disorder and manifested by a complex emotional state (Blatt, 2004; Beck et al., 2014). Most existing emotion taxonomies or datasets do not contain depression as a specific category. In this article, we generate the latent encoding for each emotion category. Based on the psychological researches (Rottenberg, 2005; Joormann and Stanton, 2016) on relations between depression and existing emotion categories, we can predict the distributed representations of depression in the text even if there are no samples annotated as depression.\nThe main contributions of this work are summarized as follows:\n• A general framework to learn distributed emotion representations from an emotion classification dataset is first proposed. Based on soft labels predicted by the pre-trained neural network model, a simple and effective approach\nis derived. As far as we know, this is the first work to learn the distributed representations for emotion categories in emotion space rather than semantic space.\n• Experiments have been conducted to validate the effectiveness of our emotion representations. The results have shown that our emotion representations in emotion space can express emotion relations much better than word vectors, and is competitive with human results.\n• Emotion similarities across datasets have been detected to validate the quality of our emotion representations across corpora. The results have shown the good consistency of our representations in emotion similarities across datasets although they are created for a variety of domains and applications."
    }, {
      "heading" : "2 Related Work",
      "text" : "Emotion Taxonomy: The existing studies on emotion taxonomy usually divide emotion space into specific emotion categories. Ekman (1992) classified emotions into six discrete states (anger, disgust, fear, joy, sadness and surprise), which are contained in vast majority of the existing emotion classification datasets. With the discrete emotion questionnaire method, Harmon-Jones et al. (2016) captured eight distinct state emotions in their study: anger, disgust, fear, anxiety, sadness, happiness, relaxation, and desire. Similarly, Cowen and Keltner (2017) introduced a conceptual framework to analyze reported emotional states and elicited 27 distinct varieties of reported emotional experience. However, above work only gives the basic emotions of human emotional state from a psychological perspective. The quantitative relations among basic emotions remain to be detected. In this work, emotion relations are quantitatively revealed based on our emotion representations.\nEmotion Datasets: Strapparava and Mihalcea (2007) introduced first emotion recognition dataset, Affective Text, in the domain of news headlines. After that, many emotion datasets that vary in domain, size and taxonomy have been developed. Wang et al. (2012) automatically created a large emotion-labeled dataset (of about 2.5 million tweets) by harnessing emotion-related hashtags available in the tweets. Abdul-Mageed and Ungar (2017) introduced a fine-grained dataset with up to 24 types of emotion categories with Twitter data. Li et al. (2017) developed a multi-turn dialog dataset, DailyDialog, for detecting the emotions in the field of dialog systems. Öhman et al. (2018) presented a multi-dimensional emotion dataset with annotations in movie subtitles for the purpose of creating a robust multilingual emotion detection tool. Demszky et al. (2020) built a manually dataset with up to 27 fine-grained emotion categories on Reddit comments for emotion prediction. However, all above datasets are annotated with discrete basic emotion categories, which means the emotion categories are represented with one-hot vectors. Onehot representations ignore the underlying relations among emotion categories. In this work, the underlying emotion relations contained in the datasets are revealed with our emotion representations.\nSoft Labels: Hinton et al. (2015) observed that it is easier to train classifier using the soft targets output by trained classifier as target values than using manual ground-truth labels. Phuong and Lampert (2019) provided their insights into the working mechanisms of distillation by studying the special case of linear and deep linear classifiers. Szegedy et al. (2016) proposed a label smoothing mechanism for the purpose of encouraging the model to be less confident by smoothing the initial one-hot labels. Imani and White (2018) investigated the reasons for the improvement of the model performance by converting hard targets to soft labels in supervised learning. Zhao et al. (2020) proposed a robust training method for machine reading comprehension by learning soft labels. In this work, soft labels output by the trained neural network model are used to generate distributed representations for emotion categories."
    }, {
      "heading" : "3 Methodology",
      "text" : "In this section, we describe how to learn the distributed representations for emotion categories. First, a general framework is proposed. Then, a\nsimple and effective algorithm is derived based on the soft labels from a pre-trained neural network model. After that, we extend our method to multilabel datasets. At last, detailed approaches of the algorithm are listed."
    }, {
      "heading" : "3.1 The General Framework",
      "text" : "As shown in Table 2, the four instances from dataset SemEval-2007 task 14 (Strapparava and Mihalcea, 2007) are annotated with both emotion categories and valence values. Although both instance 1 and instance 2 are labeled with joy category, their valence values are very different, which means there is a big difference between their emotional states. Actually, emotions in instance 1 seem to be more excited while emotions in instance 2 seem to be more hopeful. On the other hand, instances 3 and 4 are annotated with the same valence value while they are divided into different categories. Fontaine et al. (2007) also find that emotional state is high-dimensional and valencearousal-dominance representation model is not sufficient to describe the emotional state.\nThe above examples show emotional states contained in different documents, even if they are annotated with the same emotion category or valence value, are not exactly the same. In this work, we regard text emotional states as an emotion space. The emotion contained in a specific document corresponds to a specific emotional state, further corresponds to a point in the space. As a result, documents annotated with same emotion category probably correspond to different emotional states and points in the space, which means the emotion category is a random variable rather than a specific vector in the space.\nFor category K, we define x as the sample annotated with category K and V K as the specific distributed representations of category K. Let V(x) be the distributed representations of sample x and p(x) be the probability density of sample x. Let Ω be the integral domain of x. We further use L(V K ,V(x)) as the distance function between V K and V(x). In order to obtain a better distributed representation for category K, we must minimize the expectation of L. Thus, we obtain the calculation formula for specific distributed representation of category K as the following:\nV K = arg min V ∫ Ω L(V ,V(x))p(x)dx. (1)"
    }, {
      "heading" : "3.2 A Simple Method",
      "text" : "Although we can not directly obtain the strict probability distribution of each emotion category in emotion space, there are many available emotion classification dataset, in which the instances can be regarded as samples of the corresponding annotated emotion categories.\nFor emotion dataset D and emotion category K, we use all samples annotated as category K in the dataset to estimate the distribution of category K. Thus, we can rewrite formula 1 as:\nV K = arg min V ∑ x∈SK L(V ,V(x)), (2)\nwhere SK is the set of all instances labeled with category K in dataset D.\nIn this paper, we use squared Euclidean distance as the distance metric between two representations. Therefore, formula 2 can be simplified as follows:\nV K = arg min V ∑ x∈SK ||V − V(x)||22. (3)\nBy solving formula 3, we have:\nV K = ∑ x∈SK V(x) NK , (4)\nwhere NK is the size of SK . Since then we have derived that the distributed representation of emotion category K is exactly the average of the distributed representation of all instances labeled as category K in dataset D.\nNow, let’s discuss how to obtain the distributed representation for the instances in the dataset. As shown in Figure 1, the output of the neural network model is a soft label regardless of the specific architecture of the model. It has been verified that soft labels output by the trained model tend to have higher entropy and contain more information than manual one-hot labels (Hinton et al., 2015; Phuong and Lampert, 2019). Inspired by previous work on soft labels, we directly take the soft labels output by the trained neural network model as the distributed\nrepresentation of the input instance. As a result, the dimension of V K is equal to the number of categories annotated in dataset D.\nWe define soft labels output by the trained neural network model of the input instance x as f(x). Thus, we derive a simple method to calculate the specific distributed representation for category K:\nV K =\n∑ x∈SK f(x)\nNK . (5)"
    }, {
      "heading" : "3.3 How to Deal with Multilabel Data?",
      "text" : "In some corpora, instances are annotated with multiple emotion categories (Strapparava and Mihalcea, 2007; Demszky et al., 2020). To deal with multilabel instances, we regard each multilabel instance as multiple single label instances with weights summing to 1, and the weight of each single label data is set to the reciprocal of the number of the annotated labels. For example, suppose document D is labeled with category A and B. We regard D as two half instances, one half is labeled with category A and the other half is labeled with category B.\nLet Y(x) denote the set of the annotated labels of sample x and |Y(x)| denote the size of set Y(x). Take above document D as an example, then Y(D) is equal to {A,B} and |Y(D)| is equal to 2 as\nthere are two labels contained in Y(D). Therefore, we obtain the calculation formula of specific distributed representation for category K:\nV K =\n∑ x∈SK wK(x)f(x)∑\nx∈SK wK(x) , (6)\nwhere wK(x) is equal to 1/|Y(x)|, which is the weight of instance x in category K,"
    }, {
      "heading" : "3.4 Algorithm",
      "text" : "In this part, we describe the algorithm of learning the Distributed Representations for Emotion Categories (DREC). First, go through every instance in the dataset, and calculate the total weight and weighted sum of soft labels output by the trained model for each category. Then, the weighted sum is divided by the total weight to obtain the final distributed representation for each emotion category. The detailed approaches are stated in Algorithm 1.\nAlgorithm 1 DREC\nInput: D = {(T (n),Y(n))Nn=1} // dataset Output: V = {V 1,V 2, ...,V C}\n// distributed representations for emotions 01: f ← D // train a neural network model 02: V ← {0,0, ...,0} 03: {W1,W2, ...,WC} ← {0, 0, ..., 0} // weight 04: for n = 1 to N do 05: for each j ∈ Y(n) do 06: SL← f(T (n)) // soft labels 07: V j ← V j + SL/|Y(n)| 08: Wj ←Wj + 1/|Y(n)| 09: end for 10: end for 11: for i = 1 to C do 12: V i ← V i/Wi 13: end for"
    }, {
      "heading" : "4 Experiments",
      "text" : "In order to validate the intrinsic quality of our emotion representations, we conducted three experi-\nments in this section. First of all, arrangement experiment is conducted to show the emotion distribution. Then, relations between different emotion taxonomies are detected in mapping experiment. At last, the emotion representations extracted from various corpora are compared to show the consistency of our approach across corpora."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "There are four datasets we use to detect emotion relations. The detailed information of each dataset is described as follows:\nGoEmotions: GoEmotions is annotated of 58k English Reddit comments extracted from popular English subreddits (Demszky et al., 2020), multilabeled for 27 emotion categories, which is proposed by Cowen and Keltner (2017). GoEmotions is created for the purpose of building a large dataset with a large number of positive, negative, and ambiguous emotion categories. The detailed emotion categories are shown in Table 3.\nAffectiveText: AffectiveText consists of 1250 instances on the domain of news headlines (Strapparava and Mihalcea, 2007). The dataset is multilabel annotated. There are six emotion categories (anger, disgust, fear, joy, sadness and surprise) and valence contained in the dataset.\nISEAR: ISEAR is created from questionnaires by Scherer and Wallbott (1994). Each instance is annotated with only one label. There are seven emotion categories contained in ISEAR: anger, disgust, fear, guilt, joy, sadness, and shame.\nAffect in Tweets: “Affect in Tweets” is created from tweets (Mohammad et al., 2018). There are ten emotions contained in “Affect in Tweets”: anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, and trust.\nGoEmotions is used to conduct the first two experiments (arrangement and mapping), and the above four datasets are used to validate our representations across corpora in last experiment."
    }, {
      "heading" : "4.2 Model Settings",
      "text" : "Any model that outputs are soft labels can be employed to learn the distributed representations for emotion categories. In our experiments, TextCNN (Kim, 2014), BiLSTM (Schuster and Paliwal, 1997) and BERT (Devlin et al., 2019) are used as the training models. For comparison, experiments on word embedding learning algorithms are conducted to show emotion relations in semantic space. For a specific emotion category, we use its word embedding as its representations in semantic space. 100-dimensional GloVe (Pennington et al., 2014) is the word vectors used in TextCNN and BiLSTM. The detailed model settings are listed as follows:\nTextCNN: The height of convolutional kernel size is divided into three groups (3,4,5) and the width is 100, which is equal to the dimension of the word vectors. There are 32 channels in each group. Batch size and learning rate are set to 16 and 0.001.\nBiLSTM: There is only one layer in this model. Batch size and learning rate are set to 16 and 0.001 separately, which are the same as for TextCNN. There are 32 neurons in the hidden layer in each direction.\nBERT: BERT-based model is used in this experiment. A fully connected layer is added on top of the pre-trained model. Batch size and learning rate are separately set to 8 and 2e-5 for fine-tuning."
    }, {
      "heading" : "4.3 Arrangement",
      "text" : "As shown in Table 3, the emotion categories are divided into three groups corresponding to the positive, negative, and ambiguous emotions, which are divided by the creators of GoEmotions1 (Demszky et al., 2020).\nWe conduct the experiments 10 times with same model and different initial parameters, and the average representations are employed to show the following results. After final emotion representations obtained, to better understand the arrangement of emotion categories in emotion space, we reduce the dimension of the emotion representations to two with singular value decomposition (Wall et al., 2003). The two-dimensional average vectors are displayed as shown in Figure 2. Three color-shape pairs, red-circle, gray-square and black-triangle, correspond to positive, negative and ambiguous emotions respectively. Figure 2 (a)-(c) correspond\n1https://github.com/google-research/googleresearch/tree/master/goemotions/data/sentiment mapping.json\nto the results of word representations in semantic space. Figure 2 (d)-(f) show the results of TextCNN, BiLSTM and BERT in emotion space.\nAs shown in Figure 2 (a)-(c), the results of three word embedding algorithms (GloVe, SSWE and EWE) are displayed. We can find that the word vectors of emotion terms are displayed relatively random in semantic space and there are no clear linear boundaries among positive, negative and ambiguous emotions.\nAs shown in Figure 2 (d)-(f), it can be found that in emotion space, regardless of the constructed model, there are obvious boundaries among positive, negative and ambiguous emotions. The two blue dashed lines separate each type of emotion category from the others, which means that different types of emotion categories are linearly separable from each other in emotion space. The ambiguous emotions are just located between positive and negative emotions in Figure 2 (d)-(f), which shows our representations in emotion space can better describe the relative relation between ambiguous emotions and the others. In addition, the arrangement of emotions in Figure 2 (d) and (e) are very similar, which means TextCNN and BiLSTM have similar emotion relation extraction capabilities.\nFrom this experiment, we can conclude that similar emotions are more likely to get together in emotion space than in semantic space, which further demonstrates that our representations can express emotion relations much better than word vectors."
    }, {
      "heading" : "4.4 Mapping",
      "text" : "Demszky et al. (2020) manually mapped these 27 emotion categories to Ekman’s basic emotions (Ekman, 1992).2 In this experiment, we automatically generate these mapping relations based on the proposed distribution representations of emotion categories.\nIn this experiment, we take Ekman’s basic emotions as target emotions and the remaining 21 categories as source emotions. For each source emotion, we select the most similar one from the target emotions as its mapping result. The calculation formula is listed as follows:\ne = arg max et sim(es, et), (7)\nwhere et is the emotion category in target emotions, es is the emotion category in source emotions and\n2https://github.com/google-research/googleresearch/tree/master/goemotions/data/ekman mapping.json\ne is the mapping result of es. sim is the similarity function and the cosine similarity is selected here.\nThe emotion representations are calculated 10 times with same model and different initial parameters and the average results are employed to conduct this experiment. Table 4 shows the mapping results with different models. We also calculate the results of word vectors for comparison. Manual results are chosen as the gold answers. GloVe correctly maps 3 out of 21 emotions, which is comparable to a random result. By encoding emotional information into word representations, SSWE (Tang et al., 2015) maps 10 emotions correctly and EWE (Agrawal et al., 2018) maps 7 emotions correctly. The results indicate that although sentiment embedding (SSWE) and emotion embedding (EWE) map more emotions correctly than typical word embedding (GloVe), SSWE and EWE still mismatch more than half of the source emotions as they are constructed under semantic space.\nIn emotion space, our emotion representations correctly map 18 out of 21 emotions, which is much better than the result in semantic space. The scores undoubtedly show that our emotion representations can describe emotion relations much better than word vectors. Besides, detailed mapping results for each emotion can be seen in Table 4. Results\nof TextCNN and BiLSTM are exactly the same, which is consistent with their similar arrangement in emotion space in first experiment. BERT maps disapproval to disgust while the others map it to anger. The most confusing emotions are caring and embarrassment, human maps them to joy and sadness respectively, while our representations in emotion space map them to sadness and disgust.\nThe inconsistency of the two emotions (embarrassment and caring) in emotion space and in human results shows the complexity of emotion relations. Existing psychological study (Scherer, 2005) shows that embarrassment is close to both sadness and disgust, which means sadness and disgust can both be regarded as the mapping result for embarrassment. As for caring, it has been discussed (Scherer et al., 2013) that caring is a positive emotion in nature but accompanied by the occurrence of negative events.\nThe mapping results of the three models are roughly the same as human-provided mapping results, which shows our emotion representations are effective. However, when a certain emotion has high similarities to multiple emotions (such as embarrassment to disgust and sadness), there may exist some differences between different mapping results. In other words, there are no absolutely cor-\nrect mapping results for all emotions, which further indicates the relations among emotions are indeed complex."
    }, {
      "heading" : "4.5 Emotion Relations across Corpora",
      "text" : "Due to the deviations in different corpora (such as data source bias and annotation bias), there may exist some differences in emotion relations between different corpora. In this part, we analyze the difference in emotion relations across corpora. BERT is chosen as the training model here to eliminate the potential impact caused by models. For each dataset, the experiments are repeated 10 times with same model and different initial parameters, and the average results are reported here.\nThere are five emotion categories (anger, disgust, fear, joy and sadness) shared in the four datasets. The shared five emotions are basic emotion categories in many emotion taxonomy theories (Ekman, 1992; Harmon-Jones et al., 2016; Cowen and Keltner, 2017). As a result, the cosine similarities among these emotion categories as shown in Figure 3 are not high. For each dataset, all co-\nsine similarities are not greater than 0.3 except the similarity between anger and disgust.\nOn the other hand, the datasets are created based on different annotation standards from different domains. Thus, for specific emotion pair, the similarities across datasets may be quite different. However, the relative magnitude of similarities is consistent across datasets. For each dataset, there is a moderate similarity between anger and disgust (ranging from 0.52 to 0.65) while the similarities among remaining emotion pairs are relatively small (ranging from 0.04 to 0.30).\nIn order to quantitatively measure the consistency of emotion relations in different datasets, Pearson correlation coefficients between cosine similarities across datasets are calculated as shown in Table 5. The Pearson correlation coefficients among datasets are pretty high (ranging from 0.867 to 0.949), which indicates the underlying emotion relations are quite similar across datasets even if they are created in different domains.\nIn this experiment, we detect emotion relations across corpora. The results reveal that there is a"
    }, {
      "heading" : "G 0.949 1.000 0.873 0.926",
      "text" : ""
    }, {
      "heading" : "I 0.917 0.873 1.000 0.867",
      "text" : ""
    }, {
      "heading" : "T 0.936 0.926 0.867 1.000",
      "text" : "good consistency of our emotion representations across datasets even if they are created on the basis of different annotation standards from different domains."
    }, {
      "heading" : "5 Conclusion and Future Work",
      "text" : "In this paper, we argued that the emotion categories are not orthogonal to each other and the relations among emotion categories are very complex. We proposed a general framework to learn the distributed representation for each emotion category in emotion space from a given emotion dataset. Then, a simple and effective algorithm was also derived based on the soft labels predicted by the pre-trained neural network model. We conducted three experiments to validate the effectiveness of our emotion representations and the experimental results demonstrated that our representations in emotion space can express emotion relations much better than representations from word embeddings.\nThere are three avenues of future work we would like to explore. First, the distributed representations for emotion categories are derived from a specific emotion classification dataset. It would be interesting to build a universal emotion representation that is irrelevant to a specific corpus. Second, the computation of our emotion representations relies on the soft labels predicted by the neural network model, and we would like to investigate a more general method in the future. Finally, we would like to explore more NLP applications of our emotion rep-\nresentations, such as improving the performance of emotion classification models and studying emotion spaces across languages."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thank the anonymous reviewers for their helpful comments."
    } ],
    "references" : [ {
      "title" : "Emonet: Fine-grained emotion detection with gated recurrent neural networks",
      "author" : [ "Muhammad Abdul-Mageed", "Lyle Ungar." ],
      "venue" : "Proceedings of the 55th annual meeting of the association for computational linguistics (volume 1: Long papers), pages",
      "citeRegEx" : "Abdul.Mageed and Ungar.,? 2017",
      "shortCiteRegEx" : "Abdul.Mageed and Ungar.",
      "year" : 2017
    }, {
      "title" : "Learning emotion-enriched word representations",
      "author" : [ "Ameeta Agrawal", "Aijun An", "Manos Papagelis." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 950– 961.",
      "citeRegEx" : "Agrawal et al\\.,? 2018",
      "shortCiteRegEx" : "Agrawal et al\\.",
      "year" : 2018
    }, {
      "title" : "Emotions from text: machine learning for text-based emotion prediction",
      "author" : [ "Cecilia Ovesdotter Alm", "Dan Roth", "Richard Sproat." ],
      "venue" : "Proceedings of human language technology conference and conference on empirical methods in natural language pro-",
      "citeRegEx" : "Alm et al\\.,? 2005",
      "shortCiteRegEx" : "Alm et al\\.",
      "year" : 2005
    }, {
      "title" : "Depression",
      "author" : [ "Aaron T Beck", "Brad A Alford", "MD Aaron T Beck", "Ph D Brad A Alford." ],
      "venue" : "University of Pennsylvania Press.",
      "citeRegEx" : "Beck et al\\.,? 2014",
      "shortCiteRegEx" : "Beck et al\\.",
      "year" : 2014
    }, {
      "title" : "Experiences of depression: Theoretical, clinical, and research perspectives",
      "author" : [ "Sidney J Blatt." ],
      "venue" : "American Psychological Association.",
      "citeRegEx" : "Blatt.,? 2004",
      "shortCiteRegEx" : "Blatt.",
      "year" : 2004
    }, {
      "title" : "What is shared, what is different? core relational themes and expressive displays of eight positive emotions",
      "author" : [ "Belinda Campos", "Michelle N Shiota", "Dacher Keltner", "Gian C Gonzaga", "Jennifer L Goetz." ],
      "venue" : "Cognition & emotion, 27(1):37–52.",
      "citeRegEx" : "Campos et al\\.,? 2013",
      "shortCiteRegEx" : "Campos et al\\.",
      "year" : 2013
    }, {
      "title" : "Relations of homology between higher cognitive emotions and basic emotions",
      "author" : [ "Jason A Clark." ],
      "venue" : "Biology & Philosophy, 25(1):75–94.",
      "citeRegEx" : "Clark.,? 2010",
      "shortCiteRegEx" : "Clark.",
      "year" : 2010
    }, {
      "title" : "Self-report captures 27 distinct categories of emotion bridged by continuous gradients",
      "author" : [ "Alan S Cowen", "Dacher Keltner." ],
      "venue" : "Proceedings of the National Academy of Sciences, 114(38):E7900–E7909.",
      "citeRegEx" : "Cowen and Keltner.,? 2017",
      "shortCiteRegEx" : "Cowen and Keltner.",
      "year" : 2017
    }, {
      "title" : "Feeler: Emotion classification of text using vector space model",
      "author" : [ "Taner Danisman", "Adil Alpkocak." ],
      "venue" : "AISB 2008 Convention Communication, Interaction and Social Intelligence, volume 1, page 53.",
      "citeRegEx" : "Danisman and Alpkocak.,? 2008",
      "shortCiteRegEx" : "Danisman and Alpkocak.",
      "year" : 2008
    }, {
      "title" : "GoEmotions: A dataset of fine-grained emotions",
      "author" : [ "Dorottya Demszky", "Dana Movshovitz-Attias", "Jeongwoo Ko", "Alan Cowen", "Gaurav Nemade", "Sujith Ravi." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Demszky et al\\.,? 2020",
      "shortCiteRegEx" : "Demszky et al\\.",
      "year" : 2020
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "An argument for basic emotions",
      "author" : [ "Paul Ekman." ],
      "venue" : "Cognition & emotion, 6(3-4):169–200.",
      "citeRegEx" : "Ekman.,? 1992",
      "shortCiteRegEx" : "Ekman.",
      "year" : 1992
    }, {
      "title" : "Concept of emotion viewed from a prototype perspective",
      "author" : [ "Beverley Fehr", "James A Russell." ],
      "venue" : "Journal of experimental psychology: General, 113(3):464.",
      "citeRegEx" : "Fehr and Russell.,? 1984",
      "shortCiteRegEx" : "Fehr and Russell.",
      "year" : 1984
    }, {
      "title" : "The world of emotions is not two-dimensional",
      "author" : [ "Johnny RJ Fontaine", "Klaus R Scherer", "Etienne B Roesch", "Phoebe C Ellsworth." ],
      "venue" : "Psychological science, 18(12):1050–1057.",
      "citeRegEx" : "Fontaine et al\\.,? 2007",
      "shortCiteRegEx" : "Fontaine et al\\.",
      "year" : 2007
    }, {
      "title" : "Detecting emotion stimuli in emotion-bearing sentences",
      "author" : [ "Diman Ghazi", "Diana Inkpen", "Stan Szpakowicz." ],
      "venue" : "International Conference on Intelligent Text Processing and Computational Linguistics, pages 152–165. Springer.",
      "citeRegEx" : "Ghazi et al\\.,? 2015",
      "shortCiteRegEx" : "Ghazi et al\\.",
      "year" : 2015
    }, {
      "title" : "Basic emotions, complex emotions, machiavellian emotions",
      "author" : [ "Paul E Griffiths" ],
      "venue" : null,
      "citeRegEx" : "Griffiths.,? \\Q2002\\E",
      "shortCiteRegEx" : "Griffiths.",
      "year" : 2002
    }, {
      "title" : "Event-driven emotion cause extraction with corpus construction",
      "author" : [ "Lin Gui", "Dongyin Wu", "Ruifeng Xu", "Qin Lu", "Yu Zhou." ],
      "venue" : "EMNLP, pages 1639–1649. World Scientific.",
      "citeRegEx" : "Gui et al\\.,? 2016",
      "shortCiteRegEx" : "Gui et al\\.",
      "year" : 2016
    }, {
      "title" : "The discrete emotions questionnaire: A new tool for measuring state selfreported emotions",
      "author" : [ "Cindy Harmon-Jones", "Brock Bastian", "Eddie Harmon-Jones." ],
      "venue" : "PloS one, 11(8):e0159915.",
      "citeRegEx" : "Harmon.Jones et al\\.,? 2016",
      "shortCiteRegEx" : "Harmon.Jones et al\\.",
      "year" : 2016
    }, {
      "title" : "Distilling the knowledge in a neural network",
      "author" : [ "Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean." ],
      "venue" : "arXiv preprint arXiv:1503.02531.",
      "citeRegEx" : "Hinton et al\\.,? 2015",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2015
    }, {
      "title" : "Improving regression performance with distributional losses",
      "author" : [ "Ehsan Imani", "Martha White." ],
      "venue" : "International Conference on Machine Learning, pages 2157–2166. PMLR.",
      "citeRegEx" : "Imani and White.,? 2018",
      "shortCiteRegEx" : "Imani and White.",
      "year" : 2018
    }, {
      "title" : "Target-dependent twitter sentiment classification",
      "author" : [ "Long Jiang", "Mo Yu", "Ming Zhou", "Xiaohua Liu", "Tiejun Zhao." ],
      "venue" : "Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies, pages",
      "citeRegEx" : "Jiang et al\\.,? 2011",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2011
    }, {
      "title" : "Examining emotion regulation in depression: A review and future directions",
      "author" : [ "Jutta Joormann", "Colin H Stanton." ],
      "venue" : "Behaviour research and therapy, 86:35–49.",
      "citeRegEx" : "Joormann and Stanton.,? 2016",
      "shortCiteRegEx" : "Joormann and Stanton.",
      "year" : 2016
    }, {
      "title" : "Convolutional neural networks for sentence classification",
      "author" : [ "Yoon Kim." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751.",
      "citeRegEx" : "Kim.,? 2014",
      "shortCiteRegEx" : "Kim.",
      "year" : 2014
    }, {
      "title" : "An analysis of annotated corpora for emotion classification in text",
      "author" : [ "Roman Klinger" ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 2104–2119.",
      "citeRegEx" : "Klinger,? 2018",
      "shortCiteRegEx" : "Klinger",
      "year" : 2018
    }, {
      "title" : "A text-driven rule-based system for emotion cause detection",
      "author" : [ "Sophia Yat Mei Lee", "Ying Chen", "Chu-Ren Huang." ],
      "venue" : "Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages",
      "citeRegEx" : "Lee et al\\.,? 2010",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2010
    }, {
      "title" : "Document-level multi-aspect sentiment classification by jointly modeling users, aspects, and overall ratings",
      "author" : [ "Junjie Li", "Haitong Yang", "Chengqing Zong." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages",
      "citeRegEx" : "Li et al\\.,? 2018",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2018
    }, {
      "title" : "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "author" : [ "Yanran Li", "Hui Su", "Xiaoyu Shen", "Wenjie Li", "Ziqiang Cao", "Shuzi Niu." ],
      "venue" : "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "Dens: A dataset for multi-class emotion analysis",
      "author" : [ "Chen Liu", "Muhammad Osama", "Anderson De Andrade." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer-",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Measures of emotion: A review",
      "author" : [ "Iris B Mauss", "Michael D Robinson." ],
      "venue" : "Cognition and emotion, 23(2):209–237.",
      "citeRegEx" : "Mauss and Robinson.,? 2009",
      "shortCiteRegEx" : "Mauss and Robinson.",
      "year" : 2009
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "arXiv preprint arXiv:1301.3781.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : " emotional tweets",
      "author" : [ "Saif Mohammad." ],
      "venue" : "* SEM 2012: The First Joint Conference on Lexical and Computational Semantics–Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Work-",
      "citeRegEx" : "Mohammad.,? 2012",
      "shortCiteRegEx" : "Mohammad.",
      "year" : 2012
    }, {
      "title" : "Emotion intensities in tweets",
      "author" : [ "Saif Mohammad", "Felipe Bravo-Marquez." ],
      "venue" : "Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (* SEM 2017), pages 65–77.",
      "citeRegEx" : "Mohammad and Bravo.Marquez.,? 2017",
      "shortCiteRegEx" : "Mohammad and Bravo.Marquez.",
      "year" : 2017
    }, {
      "title" : "Semeval2018 task 1: Affect in tweets",
      "author" : [ "Saif Mohammad", "Felipe Bravo-Marquez", "Mohammad Salameh", "Svetlana Kiritchenko." ],
      "venue" : "Proceedings of the 12th international workshop on semantic evaluation, pages 1–17.",
      "citeRegEx" : "Mohammad et al\\.,? 2018",
      "shortCiteRegEx" : "Mohammad et al\\.",
      "year" : 2018
    }, {
      "title" : "Creating a dataset for multilingual fine-grained emotion-detection using gamification-based annotation",
      "author" : [ "Emily Öhman", "Kaisla Kajava", "Jörg Tiedemann", "Timo Honkela." ],
      "venue" : "Proceedings of the 9th Workshop on Computational Approaches to",
      "citeRegEx" : "Öhman et al\\.,? 2018",
      "shortCiteRegEx" : "Öhman et al\\.",
      "year" : 2018
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D Manning." ],
      "venue" : "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Towards understanding knowledge distillation",
      "author" : [ "Mary Phuong", "Christoph Lampert." ],
      "venue" : "International Conference on Machine Learning, pages 5142–5151.",
      "citeRegEx" : "Phuong and Lampert.,? 2019",
      "shortCiteRegEx" : "Phuong and Lampert.",
      "year" : 2019
    }, {
      "title" : "Mood and emotion in major depression",
      "author" : [ "Jonathan Rottenberg." ],
      "venue" : "Current Directions in Psychological Science, 14(3):167–170.",
      "citeRegEx" : "Rottenberg.,? 2005",
      "shortCiteRegEx" : "Rottenberg.",
      "year" : 2005
    }, {
      "title" : "A circumplex model of affect",
      "author" : [ "James A Russell." ],
      "venue" : "Journal of personality and social psychology, 39(6):1161.",
      "citeRegEx" : "Russell.,? 1980",
      "shortCiteRegEx" : "Russell.",
      "year" : 1980
    }, {
      "title" : "What are emotions? and how can they be measured",
      "author" : [ "Klaus R Scherer" ],
      "venue" : "Social science information,",
      "citeRegEx" : "Scherer.,? \\Q2005\\E",
      "shortCiteRegEx" : "Scherer.",
      "year" : 2005
    }, {
      "title" : "The grid meets the wheel: Assessing emotional feeling via self-report",
      "author" : [ "Klaus R Scherer", "Vera Shuman", "Johnny Fontaine", "Cristina Soriano Salinas." ],
      "venue" : "Components of emotional meaning: A sourcebook.",
      "citeRegEx" : "Scherer et al\\.,? 2013",
      "shortCiteRegEx" : "Scherer et al\\.",
      "year" : 2013
    }, {
      "title" : "Evidence for universality and cultural variation of differential emotion response patterning",
      "author" : [ "Klaus R Scherer", "Harald G Wallbott." ],
      "venue" : "Journal of personality and social psychology, 66(2):310.",
      "citeRegEx" : "Scherer and Wallbott.,? 1994",
      "shortCiteRegEx" : "Scherer and Wallbott.",
      "year" : 1994
    }, {
      "title" : "Bidirectional recurrent neural networks",
      "author" : [ "Mike Schuster", "Kuldip K Paliwal." ],
      "venue" : "IEEE transactions on Signal Processing, 45(11):2673–2681.",
      "citeRegEx" : "Schuster and Paliwal.,? 1997",
      "shortCiteRegEx" : "Schuster and Paliwal.",
      "year" : 1997
    }, {
      "title" : "Semeval2007 task 14: Affective text",
      "author" : [ "Carlo Strapparava", "Rada Mihalcea." ],
      "venue" : "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 70–74.",
      "citeRegEx" : "Strapparava and Mihalcea.,? 2007",
      "shortCiteRegEx" : "Strapparava and Mihalcea.",
      "year" : 2007
    }, {
      "title" : "Rethinking the inception architecture for computer vision",
      "author" : [ "Christian Szegedy", "Vincent Vanhoucke", "Sergey Ioffe", "Jon Shlens", "Zbigniew Wojna." ],
      "venue" : "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2818–2826.",
      "citeRegEx" : "Szegedy et al\\.,? 2016",
      "shortCiteRegEx" : "Szegedy et al\\.",
      "year" : 2016
    }, {
      "title" : "Sentiment embeddings with applications to sentiment analysis",
      "author" : [ "Duyu Tang", "Furu Wei", "Bing Qin", "Nan Yang", "Ting Liu", "Ming Zhou." ],
      "venue" : "IEEE transactions on knowledge and data Engineering, 28(2):496–509.",
      "citeRegEx" : "Tang et al\\.,? 2015",
      "shortCiteRegEx" : "Tang et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning sentiment-specific word embedding for twitter sentiment classification",
      "author" : [ "Duyu Tang", "Furu Wei", "Nan Yang", "Ming Zhou", "Ting Liu", "Bing Qin." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume",
      "citeRegEx" : "Tang et al\\.,? 2014",
      "shortCiteRegEx" : "Tang et al\\.",
      "year" : 2014
    }, {
      "title" : "Word representations: a simple and general method for semi-supervised learning",
      "author" : [ "Joseph Turian", "Lev Ratinov", "Yoshua Bengio." ],
      "venue" : "Proceedings of the 48th annual meeting of the association for computational linguistics, pages 384–394.",
      "citeRegEx" : "Turian et al\\.,? 2010",
      "shortCiteRegEx" : "Turian et al\\.",
      "year" : 2010
    }, {
      "title" : "Singular value decomposition and principal component analysis",
      "author" : [ "Michael E Wall", "Andreas Rechtsteiner", "Luis M Rocha." ],
      "venue" : "A practical approach to microarray data analysis, pages 91–109. Springer.",
      "citeRegEx" : "Wall et al\\.,? 2003",
      "shortCiteRegEx" : "Wall et al\\.",
      "year" : 2003
    }, {
      "title" : "Harnessing twitter” big data” for automatic emotion identification",
      "author" : [ "Wenbo Wang", "Lu Chen", "Krishnaprasad Thirunarayan", "Amit P Sheth." ],
      "venue" : "2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on So-",
      "citeRegEx" : "Wang et al\\.,? 2012",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2012
    }, {
      "title" : "Emotion-cause pair extraction: A new task to emotion analysis in texts",
      "author" : [ "Rui Xia", "Zixiang Ding." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1003–1012.",
      "citeRegEx" : "Xia and Ding.,? 2019",
      "shortCiteRegEx" : "Xia and Ding.",
      "year" : 2019
    }, {
      "title" : "Dual sentiment analysis: Considering two sides of one review",
      "author" : [ "Rui Xia", "Feng Xu", "Chengqing Zong", "Qianmu Li", "Yong Qi", "Tao Li." ],
      "venue" : "IEEE transactions on knowledge and data engineering, 27(8):2120– 2133.",
      "citeRegEx" : "Xia et al\\.,? 2015",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2015
    }, {
      "title" : "Ensemble of feature sets and classification algorithms for sentiment classification",
      "author" : [ "Rui Xia", "Chengqing Zong", "Shoushan Li." ],
      "venue" : "Information sciences, 181(6):1138–1152.",
      "citeRegEx" : "Xia et al\\.,? 2011",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2011
    }, {
      "title" : "Emo2vec: Learning generalized emotion representation by multitask training",
      "author" : [ "Peng Xu", "Andrea Madotto", "Chien-Sheng Wu", "Ji Ho Park", "Pascale Fung." ],
      "venue" : "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Senti-",
      "citeRegEx" : "Xu et al\\.,? 2018",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2018
    }, {
      "title" : "Refining word embeddings for sentiment analysis",
      "author" : [ "Liang-Chih Yu", "Jin Wang", "K Robert Lai", "Xuejie Zhang." ],
      "venue" : "Proceedings of the 2017 conference on empirical methods in natural language processing, pages 534–539.",
      "citeRegEx" : "Yu et al\\.,? 2017",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2017
    }, {
      "title" : "Robust machine reading comprehension by learning soft labels",
      "author" : [ "Zhenyu Zhao", "Shuangzhi Wu", "Muyun Yang", "Kehai Chen", "Tiejun Zhao." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 2754–2759.",
      "citeRegEx" : "Zhao et al\\.,? 2020",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Text Data Mining (in Chinese)",
      "author" : [ "Chengqing Zong", "Rui Xia", "Jiajun Zhang." ],
      "venue" : "Tsinghua University Press, Beijing.",
      "citeRegEx" : "Zong et al\\.,? 2019",
      "shortCiteRegEx" : "Zong et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "The most primary one among them is emotion classification task (Alm et al., 2005).",
      "startOffset" : 63,
      "endOffset" : 81
    }, {
      "referenceID" : 8,
      "context" : "Based on existing emotion detection tasks, many efforts have been made to achieve better performance (Danisman and Alpkocak, 2008; Xia et al., 2011; Kim, 2014; Xia et al., 2015; Li et al., 2018; Zong et al., 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al.",
      "startOffset" : 101,
      "endOffset" : 213
    }, {
      "referenceID" : 51,
      "context" : "Based on existing emotion detection tasks, many efforts have been made to achieve better performance (Danisman and Alpkocak, 2008; Xia et al., 2011; Kim, 2014; Xia et al., 2015; Li et al., 2018; Zong et al., 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al.",
      "startOffset" : 101,
      "endOffset" : 213
    }, {
      "referenceID" : 22,
      "context" : "Based on existing emotion detection tasks, many efforts have been made to achieve better performance (Danisman and Alpkocak, 2008; Xia et al., 2011; Kim, 2014; Xia et al., 2015; Li et al., 2018; Zong et al., 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al.",
      "startOffset" : 101,
      "endOffset" : 213
    }, {
      "referenceID" : 50,
      "context" : "Based on existing emotion detection tasks, many efforts have been made to achieve better performance (Danisman and Alpkocak, 2008; Xia et al., 2011; Kim, 2014; Xia et al., 2015; Li et al., 2018; Zong et al., 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al.",
      "startOffset" : 101,
      "endOffset" : 213
    }, {
      "referenceID" : 25,
      "context" : "Based on existing emotion detection tasks, many efforts have been made to achieve better performance (Danisman and Alpkocak, 2008; Xia et al., 2011; Kim, 2014; Xia et al., 2015; Li et al., 2018; Zong et al., 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al.",
      "startOffset" : 101,
      "endOffset" : 213
    }, {
      "referenceID" : 55,
      "context" : "Based on existing emotion detection tasks, many efforts have been made to achieve better performance (Danisman and Alpkocak, 2008; Xia et al., 2011; Kim, 2014; Xia et al., 2015; Li et al., 2018; Zong et al., 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al.",
      "startOffset" : 101,
      "endOffset" : 213
    }, {
      "referenceID" : 14,
      "context" : ", 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al., 2015; Mohammad et al., 2018; Liu et al., 2019).",
      "startOffset" : 94,
      "endOffset" : 155
    }, {
      "referenceID" : 32,
      "context" : ", 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al., 2015; Mohammad et al., 2018; Liu et al., 2019).",
      "startOffset" : 94,
      "endOffset" : 155
    }, {
      "referenceID" : 27,
      "context" : ", 2019) and many datasets have been introduced to train and evaluate the corresponding models (Ghazi et al., 2015; Mohammad et al., 2018; Liu et al., 2019).",
      "startOffset" : 94,
      "endOffset" : 155
    }, {
      "referenceID" : 30,
      "context" : "The vast majority of existing emotion annotation work assumes that the emotions are orthogonal to each other and represent the emotion categories with one-hot vectors (Mohammad, 2012; Gui et al., 2016; Klinger et al., 2018).",
      "startOffset" : 167,
      "endOffset" : 223
    }, {
      "referenceID" : 16,
      "context" : "The vast majority of existing emotion annotation work assumes that the emotions are orthogonal to each other and represent the emotion categories with one-hot vectors (Mohammad, 2012; Gui et al., 2016; Klinger et al., 2018).",
      "startOffset" : 167,
      "endOffset" : 223
    }, {
      "referenceID" : 46,
      "context" : "Typical word embedding learning algorithms only use the contexts but ignore the sentiment of texts (Turian et al., 2010; Mikolov et al., 2013).",
      "startOffset" : 99,
      "endOffset" : 142
    }, {
      "referenceID" : 29,
      "context" : "Typical word embedding learning algorithms only use the contexts but ignore the sentiment of texts (Turian et al., 2010; Mikolov et al., 2013).",
      "startOffset" : 99,
      "endOffset" : 142
    }, {
      "referenceID" : 45,
      "context" : "To encode emotional information into word embedding, sentiment embedding and emotion(al) embedding have been proposed (Tang et al., 2014; Yu et al., 2017; Xu et al., 2018).",
      "startOffset" : 118,
      "endOffset" : 171
    }, {
      "referenceID" : 53,
      "context" : "To encode emotional information into word embedding, sentiment embedding and emotion(al) embedding have been proposed (Tang et al., 2014; Yu et al., 2017; Xu et al., 2018).",
      "startOffset" : 118,
      "endOffset" : 171
    }, {
      "referenceID" : 52,
      "context" : "To encode emotional information into word embedding, sentiment embedding and emotion(al) embedding have been proposed (Tang et al., 2014; Yu et al., 2017; Xu et al., 2018).",
      "startOffset" : 118,
      "endOffset" : 171
    }, {
      "referenceID" : 37,
      "context" : "From the perspective of psychology, some studies have discussed the complexity of the human emotional state (Russell, 1980; Griffiths, 2002; Fontaine et al., 2007; Clark, 2010) and the shared psychological features across emotions (Fehr and Russell, 1984; Mauss and Robinson, 2009; Campos et al.",
      "startOffset" : 108,
      "endOffset" : 176
    }, {
      "referenceID" : 15,
      "context" : "From the perspective of psychology, some studies have discussed the complexity of the human emotional state (Russell, 1980; Griffiths, 2002; Fontaine et al., 2007; Clark, 2010) and the shared psychological features across emotions (Fehr and Russell, 1984; Mauss and Robinson, 2009; Campos et al.",
      "startOffset" : 108,
      "endOffset" : 176
    }, {
      "referenceID" : 13,
      "context" : "From the perspective of psychology, some studies have discussed the complexity of the human emotional state (Russell, 1980; Griffiths, 2002; Fontaine et al., 2007; Clark, 2010) and the shared psychological features across emotions (Fehr and Russell, 1984; Mauss and Robinson, 2009; Campos et al.",
      "startOffset" : 108,
      "endOffset" : 176
    }, {
      "referenceID" : 6,
      "context" : "From the perspective of psychology, some studies have discussed the complexity of the human emotional state (Russell, 1980; Griffiths, 2002; Fontaine et al., 2007; Clark, 2010) and the shared psychological features across emotions (Fehr and Russell, 1984; Mauss and Robinson, 2009; Campos et al.",
      "startOffset" : 108,
      "endOffset" : 176
    }, {
      "referenceID" : 12,
      "context" : ", 2007; Clark, 2010) and the shared psychological features across emotions (Fehr and Russell, 1984; Mauss and Robinson, 2009; Campos et al., 2013).",
      "startOffset" : 75,
      "endOffset" : 146
    }, {
      "referenceID" : 28,
      "context" : ", 2007; Clark, 2010) and the shared psychological features across emotions (Fehr and Russell, 1984; Mauss and Robinson, 2009; Campos et al., 2013).",
      "startOffset" : 75,
      "endOffset" : 146
    }, {
      "referenceID" : 5,
      "context" : ", 2007; Clark, 2010) and the shared psychological features across emotions (Fehr and Russell, 1984; Mauss and Robinson, 2009; Campos et al., 2013).",
      "startOffset" : 75,
      "endOffset" : 146
    }, {
      "referenceID" : 4,
      "context" : "depression is a serious mood disorder and manifested by a complex emotional state (Blatt, 2004; Beck et al., 2014).",
      "startOffset" : 82,
      "endOffset" : 114
    }, {
      "referenceID" : 3,
      "context" : "depression is a serious mood disorder and manifested by a complex emotional state (Blatt, 2004; Beck et al., 2014).",
      "startOffset" : 82,
      "endOffset" : 114
    }, {
      "referenceID" : 36,
      "context" : "Based on the psychological researches (Rottenberg, 2005; Joormann and Stanton, 2016) on relations between depression and existing emotion categories, we can predict the distributed representations of depression in the text even if there are no samples annotated as depression.",
      "startOffset" : 38,
      "endOffset" : 84
    }, {
      "referenceID" : 21,
      "context" : "Based on the psychological researches (Rottenberg, 2005; Joormann and Stanton, 2016) on relations between depression and existing emotion categories, we can predict the distributed representations of depression in the text even if there are no samples annotated as depression.",
      "startOffset" : 38,
      "endOffset" : 84
    }, {
      "referenceID" : 42,
      "context" : "As shown in Table 2, the four instances from dataset SemEval-2007 task 14 (Strapparava and Mihalcea, 2007) are annotated with both emotion categories and valence values.",
      "startOffset" : 74,
      "endOffset" : 106
    }, {
      "referenceID" : 18,
      "context" : "It has been verified that soft labels output by the trained model tend to have higher entropy and contain more information than manual one-hot labels (Hinton et al., 2015; Phuong and Lampert, 2019).",
      "startOffset" : 150,
      "endOffset" : 197
    }, {
      "referenceID" : 35,
      "context" : "It has been verified that soft labels output by the trained model tend to have higher entropy and contain more information than manual one-hot labels (Hinton et al., 2015; Phuong and Lampert, 2019).",
      "startOffset" : 150,
      "endOffset" : 197
    }, {
      "referenceID" : 42,
      "context" : "In some corpora, instances are annotated with multiple emotion categories (Strapparava and Mihalcea, 2007; Demszky et al., 2020).",
      "startOffset" : 74,
      "endOffset" : 128
    }, {
      "referenceID" : 9,
      "context" : "In some corpora, instances are annotated with multiple emotion categories (Strapparava and Mihalcea, 2007; Demszky et al., 2020).",
      "startOffset" : 74,
      "endOffset" : 128
    }, {
      "referenceID" : 9,
      "context" : "English Reddit comments extracted from popular English subreddits (Demszky et al., 2020), multilabeled for 27 emotion categories, which is proposed by Cowen and Keltner (2017).",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 32,
      "context" : "Affect in Tweets: “Affect in Tweets” is created from tweets (Mohammad et al., 2018).",
      "startOffset" : 60,
      "endOffset" : 83
    }, {
      "referenceID" : 22,
      "context" : "In our experiments, TextCNN (Kim, 2014), BiLSTM (Schuster and Paliwal, 1997) and BERT (Devlin et al.",
      "startOffset" : 28,
      "endOffset" : 39
    }, {
      "referenceID" : 41,
      "context" : "In our experiments, TextCNN (Kim, 2014), BiLSTM (Schuster and Paliwal, 1997) and BERT (Devlin et al.",
      "startOffset" : 48,
      "endOffset" : 76
    }, {
      "referenceID" : 10,
      "context" : "In our experiments, TextCNN (Kim, 2014), BiLSTM (Schuster and Paliwal, 1997) and BERT (Devlin et al., 2019) are used as the training models.",
      "startOffset" : 86,
      "endOffset" : 107
    }, {
      "referenceID" : 34,
      "context" : "100-dimensional GloVe (Pennington et al., 2014) is the word vectors used in TextCNN and BiLSTM.",
      "startOffset" : 22,
      "endOffset" : 47
    }, {
      "referenceID" : 9,
      "context" : "As shown in Table 3, the emotion categories are divided into three groups corresponding to the positive, negative, and ambiguous emotions, which are divided by the creators of GoEmotions1 (Demszky et al., 2020).",
      "startOffset" : 188,
      "endOffset" : 210
    }, {
      "referenceID" : 47,
      "context" : "After final emotion representations obtained, to better understand the arrangement of emotion categories in emotion space, we reduce the dimension of the emotion representations to two with singular value decomposition (Wall et al., 2003).",
      "startOffset" : 219,
      "endOffset" : 238
    }, {
      "referenceID" : 11,
      "context" : "(2020) manually mapped these 27 emotion categories to Ekman’s basic emotions (Ekman, 1992).",
      "startOffset" : 77,
      "endOffset" : 90
    }, {
      "referenceID" : 34,
      "context" : "(GloVe: global vectors for word representation (Pennington et al., 2014); SSWE: sentiment-specific word embedding (Tang et al.",
      "startOffset" : 47,
      "endOffset" : 72
    }, {
      "referenceID" : 44,
      "context" : ", 2014); SSWE: sentiment-specific word embedding (Tang et al., 2015); EWE: emotion-enriched word embedding (Agrawal et al.",
      "startOffset" : 49,
      "endOffset" : 68
    }, {
      "referenceID" : 1,
      "context" : ", 2015); EWE: emotion-enriched word embedding (Agrawal et al., 2018).",
      "startOffset" : 46,
      "endOffset" : 68
    }, {
      "referenceID" : 44,
      "context" : "By encoding emotional information into word representations, SSWE (Tang et al., 2015) maps 10 emotions correctly and EWE (Agrawal et al.",
      "startOffset" : 66,
      "endOffset" : 85
    }, {
      "referenceID" : 1,
      "context" : ", 2015) maps 10 emotions correctly and EWE (Agrawal et al., 2018) maps 7 emotions correctly.",
      "startOffset" : 43,
      "endOffset" : 65
    }, {
      "referenceID" : 38,
      "context" : "Existing psychological study (Scherer, 2005) shows that embarrassment is close to both sadness and disgust, which means sadness and disgust can both be regarded as the mapping result for embarrassment.",
      "startOffset" : 29,
      "endOffset" : 44
    }, {
      "referenceID" : 39,
      "context" : "As for caring, it has been discussed (Scherer et al., 2013) that caring is a positive emotion in nature but accompanied by the occurrence of negative events.",
      "startOffset" : 37,
      "endOffset" : 59
    }, {
      "referenceID" : 11,
      "context" : "The shared five emotions are basic emotion categories in many emotion taxonomy theories (Ekman, 1992; Harmon-Jones et al., 2016; Cowen and Keltner, 2017).",
      "startOffset" : 88,
      "endOffset" : 153
    }, {
      "referenceID" : 17,
      "context" : "The shared five emotions are basic emotion categories in many emotion taxonomy theories (Ekman, 1992; Harmon-Jones et al., 2016; Cowen and Keltner, 2017).",
      "startOffset" : 88,
      "endOffset" : 153
    }, {
      "referenceID" : 7,
      "context" : "The shared five emotions are basic emotion categories in many emotion taxonomy theories (Ekman, 1992; Harmon-Jones et al., 2016; Cowen and Keltner, 2017).",
      "startOffset" : 88,
      "endOffset" : 153
    } ],
    "year" : 2021,
    "abstractText" : "Emotion category is usually divided into different ones by human beings, but it is indeed difficult to clearly distinguish and define the boundaries between different emotion categories. The existing studies working on emotion detection usually focus on how to improve the performance of model prediction, in which emotions are represented with one-hot vectors. However, emotion relations are ignored in onehot representations. In this article, we first propose a general framework to learn the distributed representations for emotion categories in emotion space from a given emotion classification dataset. Furthermore, based on the soft labels predicted by the pre-trained neural network model, we derive a simple and effective algorithm. Experiments have validated that the proposed representations in emotion space can express emotion relations much better than word vectors in semantic space.",
    "creator" : "LaTeX with hyperref"
  }
}