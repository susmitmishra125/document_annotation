{
  "name" : "2021.acl-long.85.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Unsupervised Out-of-Domain Detection via Pre-trained Transformers",
    "authors" : [ "Keyang Xu", "Tongzheng Ren", "Shikun Zhang", "Yihao Feng", "Caiming Xiong" ],
    "emails" : [ "kx2155@columbia.edu", "shikunz@cs.cmu.edu", "yihao}@cs.utexas.edu", "cxiong@salesforce.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1052–1061\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n1052"
    }, {
      "heading" : "1 Introduction",
      "text" : "Deep neural networks, despite achieving good performance on many challenging tasks, can make overconfident predictions for completely irrelevant and out-of-domain (OOD) inputs, leading to significant AI safety issues (Hendrycks and Gimpel, 2017). Detecting out-of-domain inputs is a fundamental task for trustworthy AI applications in realworld use cases, because those applications are often subject to ill-defined queries or even potentially malicious inputs. Prior work on out-of-domain detection (e.g., Hendrycks and Gimpel, 2017; Lee et al., 2018; Liang et al., 2018; Hendrycks et al., 2019, 2020; Xu et al., 2020) mostly requires indomain task labels, limiting its usage to supervised classification. However, deployed applica-\n1Code is available at https://github.com/rivercold/ BERT-unsupervised-OOD.\ntions rarely receive controlled inputs and are susceptible to an ever-evolving set of user inputs that are scarcely labeled. For example, for many nonclassification tasks, such as summarization or topic modeling, there are no available classifiers or task labels, which limits the practical usage of recently proposed out-of-domain detection methods. Therefore, it is natural to ask the following question:\nCan we detect out-of-domain samples using only unsupervised data without any in-domain labels?\nWe regard the out-of-domain detection problem as checking whether the given test samples are drawn from the same distribution that generates the in-domain samples, which requires a weaker assumption than prior work (e.g., Lee et al., 2018; Hendrycks et al., 2020). We suppose that there are only in-domain samples, which allows us to understand the properties of data itself regardless of tasks. Therefore, methods developed for this problem are more applicable than task-specific ones and can be further adapted to tasks where no classification labels are present, such as active learning or transfer learning.\nTo solve the problem, we utilize the latent embeddings of pre-trained transformers (e.g., Vaswani et al., 2017; Devlin et al., 2019; Liu et al., 2019) to represent the input data, which allow us to apply classical OOD detection methods such as one-class support vector machines (Schölkopf et al., 2001) or support vector data description (Tax and Duin, 2004) on them.\nHowever, the best practice on how to extract features from BERT is usually task-specific. For supervised classification, we can represent the text sequence using the hidden state of [CLS] token from the top layer. Meanwhile BERT’s intermediate layers also capture rich linguistic information that may outperform the top layer for specific NLP tasks. By performing probing tasks on each layer, Jawahar et al. (2019) suggest bottom layers\nof BERT capture more surface features, middle layers focus more on syntax and semantic features are well represented by top ones.\nAs no prior knowledge about OOD samples is usually provided in practice, deciding which layer of features is the most effective for OOD detection is itself non-trivial. Some OOD samples may just contain a few out-of-vocabulary words; while others are OOD due to their syntax or semantics.\nBased on the observations above, this paper studies how to leverage all-layer features from a pretrained transformer for OOD detection in an unsupervised manner. Our contributions are three-fold:\n• By analyzing all layers of (Ro)BERT(a) models, we empirically validate that it is hard to extract features from a certain layer that work well for any OOD datasets.\n•We propose a computationally efficient way to transform all-layer features of a pre-trained transformer into a low-dimension one. We empirically validate that the proposed method outperforms baselines that use one-layer features or by simple aggregations of all layers.\n•We propose two different techniques for finetuning a pre-trained transformer to further improve its capability of detecting OOD data."
    }, {
      "heading" : "2 Problem Setup",
      "text" : "Assume that we have a collection of text inputs Dn := {xi}ni=1, we want to construct an out-ofdomain detector that takes an unseen new input u and determines whether u comes from the same distribution that generates Dn. We adopt a more practical setting where we have no prior knowledge of what out-of-domain inputs look like. In this case, training a domain classifier directly is not feasible. The out-of-domain detector can be described mathematically as:\ng(u, ) = { True if I(u) ≤ , False if I(u) > ,\nwhere I(·) denotes the anomaly score function, and is a chosen threshold to ensure that the true positive rate is at a certain level (e.g., 95%) (Hendrycks and Gimpel, 2017; Liang et al., 2018; Lee et al., 2018). The OOD detection problem boils down to designing I(·) such that it assigns in-domain inputs lower scores than out-of-domain inputs.\nThere are two different scenarios, considering if we have any in-domain labels for data xi ∈ Dn. Here we define in-domain labels as any specific supervised task labels, such as sentiments, intents or topics of the text.\nWith in-domain labels Suppose that we have multi-class label yi ∈ [K] and Dn = {(xi, yi)}ni=1. Given a classifier h trained with Dn, we can use maximum calibrated softmax probability with temperature scaling as the anomaly score (Liang et al., 2018; Hinton et al., 2015):\nI(x) := −max i∈[K] exp (hi(x)/T )∑K j=1 exp (hj(x)/T ) ,\nwhere hi(x) is the output logits of the multi-class classifier, and T is the temperature that is selected such that the true positive rate is at a given rate (e.g., 95% in Liang et al. (2018)). This method is known as Maximum Softmax Probability (MSP), which requires multi-class labels to train a classifier and thus limits its application in practice. We argue that requiring in-domain labels is a less practical scenario for OOD detection and will not be further discussed it in this paper.\nWithout in-domain labels The setting of no indomain labels is our major focus. Under this assumptin, the models we can obtain in hand are usually not classifiers, but feature extractors instead. Then it is natural to resort to classic outlier detection methods like one-class support vector machine (Schölkopf et al., 2001), support vector data description (Tax and Duin, 2004) or kernel density estimation (KDE) for estimating the support or the density of the in-domain data distribution.\nWhen applying such methods to text data, the major focus of prior work is to design a good network structure or learning objectives (Ruff et al., 2018). Instead, in this paper we mainly focus on how to obtain good representations from pre-trained transformers and design new anomaly scores without modifying its structure, while still obtaining good OOD detection performance."
    }, {
      "heading" : "3 Model and Feature Learning",
      "text" : "BERT and its variants such as RoBERTa (e.g., Devlin et al., 2019; Liu et al., 2019) are pre-trained on large-scale public data (denoted as Dpub) using self-supervised tasks, such as language model and next sentence prediction. These models show\npromising results when transferred to tasks in other domains. We aim to leverage features obtained from pre-trained transformers to construct OOD detectors in lieu of in-domain labels in Dn."
    }, {
      "heading" : "3.1 BERT features for OOD detection",
      "text" : "After pretraining, we can obtain a BERT/RoBERTa model f with L layers. We denote f`(x) ∈ Rd as the d-dimensional feature embeddings corresponding to the `-th layer for input x, and f(x) is the overall representation using all layers of f . We explore the following methods to extract BERT features to construct OOD detectors.\nFeatures from the `-th layer f` Options to extract fl(x) include using the hidden states of [CLS] token or averaging all contextualized token embeddings at the `-layer. Then we can directly construct an OOD detector based on features from f` of each input x in Dn using existing pure sample based methods, such as one-class support vector machine (OC-SVM).2\nFeatures from all layers Using BERT features from only one layer might not be sufficient, as prior work (Jawahar et al., 2019) has explored that different layers of BERT capture distinct linguistic properties, e.g., lower-level features capturing lexical properties, middle layers representing syntactic properties, and semantic properties surfacing in higher layers. The effects of BERT features from different layers on detecting OOD data are\n2It is also possible to use other related one-class classification methods, such as Isolation Forest. However, in practice we find OC-SVM works the best and we use it in our empirical evaluations.\nyet to be investigated. One straightforward way that leverages all L layers is to concatenate all layerwise features f`(x), which has no information loss. However, this solution is computationally expensive and thus hard to optimize OC-SVM or kernel based methods. Another solution is to perform aggregation likes max- or mean-pooling along the feature dimension across all layers, sacrificing some information in exchange for efficiency.\nIn this paper, we propose a simple yet effective method (described below) to use latent representations from all layers of a pre-trained transformer and can automatically decide features from which layers are important. Besides, this method is computationally efficient, only requiring us to solve a low-dimensional constrained convex optimization.\nMahalanobis distance as features (MDF) for all layers Support Vector Data Description (SVDD) (Tax and Duin, 2004) is a technique related to OC-SVM where a hypersphere is used to separate the data instead of a hyperplane. However, the features provided by deep models may not be separable by hyperspheres. We focus on a generalization of the hypersphere called hyper-ellipsoid to account for such surface shapes.\nSuppose that we use the concatenated features from all layers Φ(x) = [f1(x), . . . , fL(x)]> ∈ Rd·L and consider the following optimization problem to find the hyper-ellipsoid, which is similar to the optimization formula of SVDD:\nmin R,c,Σ,ξ\n1 2 ‖Σ‖2Fr +\n( R2 + 1\nνn ∑ i ξi\n) ,\ns.t. ‖Φ(xi)− c‖2Σ−1 ≤ R 2 + ξi , ξi ≥ 0 ,∀i , (1)\nwhere Φ is the feature map, c is the center of the hyper-ellipsoid, and Σ is a symmetric positive definite matrix that reflects the shape of the ellipsoid. And R reflects the volume of the hyper-ellipsoid.3 Here we also introduce a regularization term 12‖Σ‖ 2 Fr to constrain the complexity of Σ. If Σ = I, then the optimization problem is identical to one-class SVDD.\nSolving Eq (1) exactly can be difficult, since it involves finding the optimal Σ of shapeD×D, where D = d · L is the dimension of the features. For the concatenated features Φ(x), D can be tens of thousands or even hundreds of thousands, which makes the exact solution computationally intractable. To tackle the problem, we consider a simple and computationally efficient approximation of the solution, which can be useful in practice.\nFirst, we decompose the feature space into several subspaces, based on the features from different layers, i.e., assume Σ is a block diagonal matrix, and Σ` reflects the shape of feature distribution at layer `. By a straightforward calculation, we have:\n‖Φ(x)− c‖2Σ−1 = L∑\n`=1\n‖f`(x)− c`‖2Σ−1` ,\nwhere we decompose the center c to be the center of each layer c = [c1, . . . , cL]>. Still, optimizing c` and Σ` can be difficult since the dimension of f`(x) can be high. Based on the intuition that c` and Σ` should not deviate from the empirical mean and covariance estimation ĉ` and Σ̂` from the training data, we can replace c and Σ` with the following approximation:\nc` ≈ĉ` = 1\nn n∑ i=1 [f`(xi)] ,\nΣ` ≈ Σ̂` w` = 1 (n− 1)w` n∑ i=1 (f`(xi)− ĉ`)(f`(xi)− ĉ`)>,\nwhere w` is a layer-dependent constant. Now we only need to find proper {w`}L`=1 as well as the corresponding R and {ξi}ni=1, which is a low-dimension optimization problem that only scales linearly with the number of layer L. We further define:\nM`(xi) = (f`(xi)− ĉ`)>Σ̂−1` (f`(xi)− ĉ`) ,\n3We can further assume ‖Σ‖ = 1, where the norm can be the operator norm or Frobenius norm, which can give the definition of the hyper-ellipsoid with unique Σ and R.\nwhere the square root of M`(xi) is also referred to as the Mahalanobis distance of the features of data xi from layer `. Assume w = [w1, . . . , wL]> ∈ RL and M(x) = [M1(x), . . . ,ML(x)]> ∈ RL, then we have:\n‖Φ(x)− c‖2Σ−1 = 〈w,M(x)〉 .\nAs ‖Σ‖2Fr = ∑L\n`=1 ‖Σ̂l‖2Fr w2` is not convex w.r.t w,\nwe instead minimize −12‖w‖ 2 2, which has a similar regularization effect on Σ (as we don’t want ‖w‖2 to be small, which can make ‖Σ‖Fr very large). So the final optimization problem to solve is:\nmin R,w,ξ −1 2 ‖w‖22 +R2 + 1 νn ∑ i ξi,\ns.t. 〈w,M(xi)〉 ≤ R2 + ξi, ξi ≥ 0 , ∀i , (2)\nwhich in fact is a one-class SVM with a linear kernel, with Mahalanobis distance of each layers as features (MDF), and it can be simply solved with the standard convex optimization. We illustrate our proposed algorithm in Figure 1.\nRemark Note that the optimization in Eq (2) is not identical as that in Eq (1), since we are using empirical sample mean {ĉ`}L`=1 and covariance {Σ̂`/w`}L`=1 to replace the original parameters c and Σ in Eq (1), which are hard to optimize when the dimension of the concatenated features Φ(x) is high. Also, our approximation from Eq (1) to Eq (2) is different from the known result that when Φ(x) is the infinite-dimensional feature map of the widely used Gaussian RBF kernels, OC-SVM and SVDD are equivalent and asymptotically consistent density estimators (Tsybakov et al., 1997; Vert et al., 2006). In our case, Φ(x) is the concatenated features from all layers of pre-trained transformers, which makes our approximation fundamentally different from prior work."
    }, {
      "heading" : "3.2 Feature fine-tuning",
      "text" : "We can also fine-tune the pre-trained transformer f on the unsupervised in-domain dataset Dn so that f(x) can better represent the distribution of Dn. We explore two domain-specific fine-tuning approaches.\nIn-domain masked language modeling (IMLM) Gururangan et al. (2020) find that domain-adaptive masked language modeling (Devlin et al., 2019) would improve supervised classification capability of BERT when it is transferred to that domain.\nSimilarly, we can do MLM on Dn and argue this would make the features of Dn concentrate, bringing benefits to downstream OOD detection.\nBinary classification with auxiliary dataset (BCAD) Another way of fine-tuning the model f is to use the public dataset Dpub that pretrains it. We consider the training data in Dn as in-domain positive samples and data in the public dataset Dpub as OOD negative samples. We add a new classification layer on top of f and update this layer together with all parameters of f by performing a binary classification task. In practice, we only need a small subset of Dpub, denoted as D̃pub, for finetuning. Since D̃pub is publicly available and has no labels, we do not violate the unsupervised setting. D̃pub does not provide any information about the OOD samples at test time as well.\nBesides, the added classification layer can actually be applied for OOD detection using the MSP method, and this is exactly the setting of zero-shot classification, which we use as a baseline for comparison in our experiments."
    }, {
      "heading" : "4 Experiments",
      "text" : "Datasets We consider two distinct datasets for experiments, where one is to regard text from unseen corpora as OOD, and the other one is to detect class-level OOD samples within the same corpus.\n• Cross-corpus dataset (SST) We follow the experimental setting in Hendrycks et al. (2020),\nby providing in-domain Dn with the original training set of SST dataset (Socher et al., 2013) and considering samples from four other datasets (i.e., 20 Newsgroups (Lang, 1995), English-German Multi30K (Elliott et al., 2016), RTE (Dagan et al., 2005) and SNLI (Bowman et al., 2015)) as OOD data. For evaluation, we use the original test data of SST as in-domain positives and randomly pick 500 samples from each of the four datasets as OOD negatives. We do not include any sentiment labels from SST to Dn for training.\n• Cross-intent dataset (CLINIC150) This is a crowdsourced dialog dataset (Larson et al., 2019), including in-domain queries covering 150 intents and out-of-domain queries that do not fall within any of the 150 intents. We use all 15,000 queries that are originally in its training data as in-domain samples but discard their intent labels. For evaluation, we mix the 4,500 unseen in-domain test queries with 1,000 out-of-domain queries and wish to separate two sets by their anomaly scores.\nExamples taken from the two datasets can be found in Table 1. Note that for both datasets, only the in-domain samples are used for training, and the source/intent labels are not used in our experiments.\nEvaluation metrics We rank all test samples by their anomaly scores and follow Liang et al. (2018) to report four different metrics, namely, Area Under the Receiver Operating Characteristic Curve (AUROC), Detection Accuracy (DTACC), and\nArea under the Precision-Recall curve (AUPR) for in-domain and out-of-domain testing sentences respectively, denoted by AUIN and AUOUT.\nModel configurations We evaluate all methods with both BERT and RoBERTa (basemodels with 768 latent dimensions and 12 layers).\nChoice of D̃pub for BCAD We adopt the BooksCorpus (Zhu et al., 2015) and English Wikipedia, which are the sources used in common by BERT and RoBERTa for pre-training. We split paragraphs into sentences and sample D̃pub to have the same size as Dn for BCAD.\nBaselines To examine the effectiveness of our newly proposed anomaly score based on MDF that utilizes the representations of all layers, we compare it with the following baselines.\n• (Ro)BERT(a)-Single layer: It uses f`(x) mentioned above. We iterate all 12 layers and detailed results of each layer are discussed in Section 5.1.\n• (Ro)BERT(a)-Mean pooling: we construct alllayer representation by averaging all f`(x), which has 768 dimensions.\n• (Ro)BERT(a)-Max pooling: we aggregate all layers by picking largest values along each feature dimension and get a 768-dimension vector.\n• (Ro)BERT(a)-Euclidean distance as features (EDF): we replace Mahalanobis distance with Euclidean distance and still obtain a 12-dimension vector.\n• TF-IDF: we extract TF-IDF features and adopt SVD to reduce high-dimensional features to 100 dimensions for computational efficiency.\nAll of the above methods extract features as the input to OC-SVM to compute anomaly scores.\n• BCAD + MSP: It performs zero-shot classification after BCAD fine-tuning, as discussed in Section 3. The temperature scaling is tuned to achieve the best result. This method is not applicable when no D̃pub is provided."
    }, {
      "heading" : "5 Results and Discussions",
      "text" : "In this section, we present the results for our experiments and summarize our findings.\n5.1 Using single-layer feature f`(x)\nTable 2 shows results obtained from using the [CLS] embedding or averaging token embeddings"
    }, {
      "heading" : "11 88.8 66.3 88.8 68.8 57.3 59.0 51.6 55.5",
      "text" : ""
    }, {
      "heading" : "10 87.7 52.1 79.6 68.4 56.6 55.4 53.8 56.2",
      "text" : ""
    }, {
      "heading" : "9 85.5 50.7 84.2 67.2 56.8 56.5 58.3 56.5",
      "text" : ""
    }, {
      "heading" : "6 76.4 61.9 73.0 67.8 58.2 62.3 55.5 56.7",
      "text" : ""
    }, {
      "heading" : "5 74.2 58.2 63.5 67.2 56.3 62.8 56.2 57.1",
      "text" : ""
    }, {
      "heading" : "4 66.7 67.4 70.0 69.8 61.9 60.9 52.7 57.8",
      "text" : ""
    }, {
      "heading" : "3 65.8 67.5 62.9 69.3 54.3 59.4 51.0 58.5",
      "text" : "(AVG) at each layer of (Ro)BERT(a) models in the cross-corpus and the cross-intent dataset.\nWe observe that detecting cross-intent OOD samples in CLINIC150 is more challenging than that of cross-dataset OOD data in SST. This is mainly because the OOD samples in CLINIC150 are sorted by humans and the differences between intents can be subtle. We will further compare the performance of these two settings in Figure 2.\nThe best f`(x) for OOD is dataset-specific For the cross-corpus dataset (SST), we find that the best results come from the top layer of both (Ro)BERT(a). However, for the cross-intent dataset (CLINIC150), the middle layers perform the best when using [CLS], while the bottom layers achieve the best results with AVG. This indicates that OOD distributions are not simply based on certain types of linguistic features and the strategy of choosing f`(x) is dataset-specific; for some dataset, semantic features play a more important role, while sometimes we need to focus on syntactic or lexical features. This validates the assumption that it is beneficial to fully utilize all layers of the hidden representations from pre-trained transformers to detect OOD instances.\nWe find using f`(x) of BERT is generally better\nthan RoBERTa, especially with [CLS]. We guess next sentence prediction may cause this, which pretrains on [CLS] and is exclusive for BERT.\nIn later sections, (Ro)BERT(a)-Single layer will refer to the best one in Table 2."
    }, {
      "heading" : "5.2 Overall OOD detection performance",
      "text" : "We report the empirical results of OOD detection in Table 3 and the following observations.\nPre-trained transformers produce good feature representations Methods using single-layer feature f` outperforms frequency-based features (TFIDF) and zero-shot classification (MSP), which validates the strong representation capability granted by self-supervised pre-training.\nSimple aggregations of all layers are not so effective The results of max-pooling and meanpolling are not very promising. Even though we observe an absolute 0.5% boost in SST using maxpooling, using the best single layer actually outperforms those simple aggregations in CLINIC150.\nMDF is more effective MDF consistently outperforms methods that directly use features f`(x), simple aggregations of f`(x), or TF-IDF features on all four metrics. In terms of AUROC, MDF outperforms the best single-layer of (Ro)BERT(a) by absolute 7.1% on SST and 14.0% on CLINIC150.\nMDF also performs better than EDF. Note that Euclidean distance is a special case of Mahalanobis distance when the covariance is an identity matrix. Empirically, the features generated by neural models are not invariant across all dimensions; and the comparison between MDF and EDF validates SVDD with a hyper-ellipsoid is better than a hypersphere.\nMDF is more efficient in training OC-SVM Notice that our approach is also more computationally efficient when obtaining optimal w and R since the optimization is performed on a new transformed low dimensional data space (d = 12 is number of layers in f ). See column #feats in Table 3 for detailed comparisons.\nFine-tuning techniques improve performance From Table 3, we can see both MILM and BCAD improve OOD detection performance when incorporated with MDF separately. The overall best detecting performance is achieved by MILM + BCAD + MDF, combining both proposed fine-tuning methods with MDF.\nWe also find that RoBERTa outperforms BERT when using MDF, even though features from a single layer prefers BERT in Table 2."
    }, {
      "heading" : "5.3 Visualizations",
      "text" : "We plot the ROC curves of four different anomaly scores on SST in Figure 2 (a) and on CLINIC150 in Figure 2 (c), confirming that our proposed MDF and two fine-tuning techniques improve the ability in detecting OOD samples. We also present the distributions of anomaly scores I(x) generated by our best method in Figure 2 (b) for SST and in Figure 2 (d) for CLINIC150. For SST, the OOD detector can clearly separate I(x) of in-domain and out-domain samples, and the in-domain scores are densely concentrated on the low-score region. Although for CLINIC150, we do observe some OOD samples mixing with in-domain ones, accounting for the gap of metric scores between two datasets."
    }, {
      "heading" : "5.4 Case Studies",
      "text" : "We present some examples from CLINIC150 together with their corresponding predictions by TFIDF, BERT-single layer and MDF methods in Table 4. TF-IDF predicts false positives for examples (b) and (d) because most of the words in the exam-\nple test query are seen in the training set, like “i would like you to buy me some paper plates” (intent: order), “i need to know how long to cook chicken for” (intent: cooking time) and etc. BERTsingle layer learns the syntax of “can you tell me how to ...”, which is frequently seen in the training data, but it fails to discern that the semantic meaning is out-of-domain. For example (d), all models make the mistake, potentially associating it with the intent: recipe (“i need to find a good way to make chicken soup” or “what’s the best way to make chicken stir fry”)."
    }, {
      "heading" : "6 Related Work",
      "text" : "Out-of-domain detection is essentially an important component for trustworthy machine learning applications. There are two lines of work proposed to perform out-of-domain detection. One is to tackle the problem in specific multi-class classification tasks, where well-trained classifiers are utilized to design anomaly scores (e.g., Hendrycks and Gimpel, 2017; Liang et al., 2018; Lee et al., 2018; Card et al., 2019; Hendrycks et al., 2020; Xu et al., 2020), Those methods can only be useful when multi-class labels are available, which limits their application in more general domains. Our proposed work goes beyond this limitation and can utilize large amounts of unsupervised data.\nAnother line of work is based on support estimation or density estimation, which assumes that the in-domain data is in specific support or from the high density region (Schölkopf et al., 2001; Tax\nand Duin, 2004). In principle, our work is closely related to this line of work. Besides, Zhai et al. (2016); Ruff et al. (2018); Zong et al. (2018) also leverage the features of neural networks, though these methods require designing specific network structures for different data. Our work circumvents the issues of prior work by designing a computationally efficient method that leverages the powerful representations of pre-trained transformers.\nFinally, the fine-tuning techniques we use to improve the representation of data are closely related to unsupervised pre-training for transformers (Devlin et al., 2019; Yang et al., 2019), and recently proposed contrastive learning (e.g., He et al., 2020; Chen et al., 2020). Lately, Gururangan et al. (2020) discover that performing pre-training (MLM) on the target domain with unlabeled data can also help to improve downstream classification performance. To the best of our knowledge, our method is the first to incorporate transformers and pre-training techniques to improve out-of-domain detection."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We study the problem of detecting out-of-domain samples with unsupervised in-domain data, which is a more general setting for out-of-domain detection. We propose a simple yet effective method using Mahalanobis distance as features, which significantly improves the detection ability and reduces computational cost in learning the detector. Two domain-adaptive fine-tuning techniques are further explored to boost the detection performance.\nIn the future, we are interested in deploying our OOD method to real-world applications, such as detecting unseen new classes for incremental fewshot learning (Zhang et al., 2020; Xia et al., 2021) or filtering OOD samples in data augmentations."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thank the anonymous reviewers for their valuable feedback and comments."
    } ],
    "references" : [ {
      "title" : "A large annotated corpus for learning natural language inference",
      "author" : [ "Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP",
      "citeRegEx" : "Bowman et al\\.,? 2015",
      "shortCiteRegEx" : "Bowman et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep weighted averaging classifiers",
      "author" : [ "Dallas Card", "Michael Zhang", "Noah A Smith." ],
      "venue" : "Proceedings",
      "citeRegEx" : "Card et al\\.,? 2019",
      "shortCiteRegEx" : "Card et al\\.",
      "year" : 2019
    }, {
      "title" : "A simple framework for contrastive learning of visual representations",
      "author" : [ "Ting Chen", "Simon Kornblith", "Mohammad Norouzi", "Geoffrey Hinton." ],
      "venue" : "Proceedings of the 37th International Conference on Machine Learning, ICML 2020, pages 1597–1607.",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "The pascal recognising textual entailment challenge",
      "author" : [ "I. Dagan", "Oren Glickman", "B. Magnini." ],
      "venue" : "Machine Learning Challenges, Evaluating Predictive Uncertainty, Visual Object Classification and Recognizing Textual Entailment, First PASCAL Ma-",
      "citeRegEx" : "Dagan et al\\.,? 2005",
      "shortCiteRegEx" : "Dagan et al\\.",
      "year" : 2005
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Com-",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Multi30k: Multilingual english-german image descriptions",
      "author" : [ "Desmond Elliott", "S. Frank", "K. Sima’an", "Lucia Specia" ],
      "venue" : "In Proceedings of the 5th Workshop on Vision and Language",
      "citeRegEx" : "Elliott et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Elliott et al\\.",
      "year" : 2016
    }, {
      "title" : "Don’t stop pretraining: Adapt language models to domains and tasks",
      "author" : [ "Suchin Gururangan", "Ana Marasović", "Swabha Swayamdipta", "Kyle Lo", "Iz Beltagy", "Doug Downey", "Noah A Smith." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the",
      "citeRegEx" : "Gururangan et al\\.,? 2020",
      "shortCiteRegEx" : "Gururangan et al\\.",
      "year" : 2020
    }, {
      "title" : "Momentum contrast for unsupervised visual representation learning",
      "author" : [ "Kaiming He", "Haoqi Fan", "Yuxin Wu", "Saining Xie", "Ross Girshick." ],
      "venue" : "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, pages 9729–9738.",
      "citeRegEx" : "He et al\\.,? 2020",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2020
    }, {
      "title" : "A baseline for detecting misclassified and out-of-distribution examples in neural networks",
      "author" : [ "Dan Hendrycks", "Kevin Gimpel." ],
      "venue" : "5th International Conference on Learning Representations, ICLR 2017.",
      "citeRegEx" : "Hendrycks and Gimpel.,? 2017",
      "shortCiteRegEx" : "Hendrycks and Gimpel.",
      "year" : 2017
    }, {
      "title" : "Pretrained transformers improve out-of-distribution robustness",
      "author" : [ "Dan Hendrycks", "Xiaoyuan Liu", "Eric Wallace", "Adam Dziedzic", "Rishabh Krishnan", "Dawn Song." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Hendrycks et al\\.,? 2020",
      "shortCiteRegEx" : "Hendrycks et al\\.",
      "year" : 2020
    }, {
      "title" : "Deep anomaly detection with outlier exposure",
      "author" : [ "Dan Hendrycks", "Mantas Mazeika", "Thomas Dietterich." ],
      "venue" : "7th International Conference on Learning Representations, ICLR 2019.",
      "citeRegEx" : "Hendrycks et al\\.,? 2019",
      "shortCiteRegEx" : "Hendrycks et al\\.",
      "year" : 2019
    }, {
      "title" : "Distilling the knowledge in a neural network",
      "author" : [ "Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean." ],
      "venue" : "arXiv preprint arXiv:1503.02531.",
      "citeRegEx" : "Hinton et al\\.,? 2015",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2015
    }, {
      "title" : "What does bert learn about the structure of language",
      "author" : [ "Ganesh Jawahar", "Benoît Sagot", "Djamé Seddah" ],
      "venue" : "In Proceedings of the 57th Conference of the Association for Computational Linguistics,",
      "citeRegEx" : "Jawahar et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Jawahar et al\\.",
      "year" : 2019
    }, {
      "title" : "Newsweeder: Learning to filter netnews",
      "author" : [ "K. Lang." ],
      "venue" : "Machine Learning, Proceedings of the Twelfth International Conference on Machine Learning, pages 331–339.",
      "citeRegEx" : "Lang.,? 1995",
      "shortCiteRegEx" : "Lang.",
      "year" : 1995
    }, {
      "title" : "An evaluation dataset for intent classification",
      "author" : [ "Stefan Larson", "Anish Mahendran", "Joseph J. Peper", "Christopher Clarke", "Andrew Lee", "Parker Hill", "Jonathan K. Kummerfeld", "Kevin Leach", "Michael A. Laurenzano", "Lingjia Tang", "Jason Mars" ],
      "venue" : null,
      "citeRegEx" : "Larson et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Larson et al\\.",
      "year" : 2019
    }, {
      "title" : "A simple unified framework for detecting outof-distribution samples and adversarial attacks",
      "author" : [ "Kimin Lee", "Kibok Lee", "Honglak Lee", "Jinwoo Shin." ],
      "venue" : "Advances in Neural Information Processing Systems, NeurIPS 2018, pages 7167–7177.",
      "citeRegEx" : "Lee et al\\.,? 2018",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2018
    }, {
      "title" : "Enhancing the reliability of out-ofdistribution image detection in neural networks",
      "author" : [ "Shiyu Liang", "Yixuan Li", "Rayadurgam Srikant." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018.",
      "citeRegEx" : "Liang et al\\.,? 2018",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2018
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Deep one-class classification",
      "author" : [ "Lukas Ruff", "Robert Vandermeulen", "Nico Goernitz", "Lucas Deecke", "Shoaib Ahmed Siddiqui", "Alexander Binder", "Emmanuel Müller", "Marius Kloft." ],
      "venue" : "Proceedings of the 35th International Conference on Machine Learning,",
      "citeRegEx" : "Ruff et al\\.,? 2018",
      "shortCiteRegEx" : "Ruff et al\\.",
      "year" : 2018
    }, {
      "title" : "Estimating the support of a high-dimensional distribution",
      "author" : [ "Bernhard Schölkopf", "John C Platt", "John Shawe-Taylor", "Alex J Smola", "Robert C Williamson." ],
      "venue" : "Neural computation, 13(7):1443–1471.",
      "citeRegEx" : "Schölkopf et al\\.,? 2001",
      "shortCiteRegEx" : "Schölkopf et al\\.",
      "year" : 2001
    }, {
      "title" : "Recursive deep models for semantic compositionality over a sentiment treebank",
      "author" : [ "R. Socher", "Alex Perelygin", "J. Wu", "Jason Chuang", "Christopher D. Manning", "A. Ng", "Christopher Potts." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Meth-",
      "citeRegEx" : "Socher et al\\.,? 2013",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Support vector data description",
      "author" : [ "David MJ Tax", "Robert PW Duin." ],
      "venue" : "Machine learning, 54(1):45–66.",
      "citeRegEx" : "Tax and Duin.,? 2004",
      "shortCiteRegEx" : "Tax and Duin.",
      "year" : 2004
    }, {
      "title" : "On nonparametric estimation of density level sets",
      "author" : [ "Alexandre B Tsybakov" ],
      "venue" : "The Annals of Statistics, 25(3):948–969.",
      "citeRegEx" : "Tsybakov,? 1997",
      "shortCiteRegEx" : "Tsybakov",
      "year" : 1997
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in neural information processing systems, pages 5998–6008.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Consistency and convergence rates of one-class svms and related algorithms",
      "author" : [ "Régis Vert", "Jean-Philippe Vert", "Bernhard Schölkopf." ],
      "venue" : "Journal of Machine Learning Research, 7(5).",
      "citeRegEx" : "Vert et al\\.,? 2006",
      "shortCiteRegEx" : "Vert et al\\.",
      "year" : 2006
    }, {
      "title" : "Incremental few-shot text classification with multi-round new classes: Formulation, dataset and system",
      "author" : [ "Congying Xia", "Wenpeng Yin", "Yihao Feng", "Philip Yu." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Xia et al\\.,? 2021",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2021
    }, {
      "title" : "A deep generative distance-based classifier for out-of-domain detection with mahalanobis space",
      "author" : [ "Hong Xu", "Keqing He", "Yuanmeng Yan", "Sihong Liu", "Zijun Liu", "Weiran Xu." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguis-",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Xlnet: Generalized autoregressive pretraining for language understanding",
      "author" : [ "Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime Carbonell", "Russ R Salakhutdinov", "Quoc V Le." ],
      "venue" : "Advances in neural information processing systems, pages 5754–5764.",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Deep structured energy based models for anomaly detection",
      "author" : [ "Shuangfei Zhai", "Yu Cheng", "Weining Lu", "Zhongfei Zhang." ],
      "venue" : "Proceedings of The 33rd International Conference on Machine Learning, pages 1100–1109.",
      "citeRegEx" : "Zhai et al\\.,? 2016",
      "shortCiteRegEx" : "Zhai et al\\.",
      "year" : 2016
    }, {
      "title" : "Discriminative nearest neighbor few-shot intent detection by transferring natural language inference",
      "author" : [ "Jian-Guo Zhang", "Kazuma Hashimoto", "Wenhao Liu", "Chien-Sheng Wu", "Yao Wan", "Philip S Yu", "Richard Socher", "Caiming Xiong." ],
      "venue" : "Proceedings",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
      "author" : [ "Y. Zhu", "Ryan Kiros", "R. Zemel", "R. Salakhutdinov", "R. Urtasun", "A. Torralba", "S. Fidler." ],
      "venue" : "2015 IEEE International Conference on Computer",
      "citeRegEx" : "Zhu et al\\.,? 2015",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep autoencoding gaussian mixture model for unsupervised anomaly detection",
      "author" : [ "Bo Zong", "Qi Song", "Martin Renqiang Min", "Wei Cheng", "Cristian Lumezanu", "Daeki Cho", "Haifeng Chen." ],
      "venue" : "6th International Conference on Learning Representations.",
      "citeRegEx" : "Zong et al\\.,? 2018",
      "shortCiteRegEx" : "Zong et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "Deep neural networks, despite achieving good performance on many challenging tasks, can make overconfident predictions for completely irrelevant and out-of-domain (OOD) inputs, leading to significant AI safety issues (Hendrycks and Gimpel, 2017).",
      "startOffset" : 217,
      "endOffset" : 245
    }, {
      "referenceID" : 15,
      "context" : "Prior work on out-of-domain detection (e.g., Hendrycks and Gimpel, 2017; Lee et al., 2018; Liang et al., 2018; Hendrycks et al., 2019, 2020; Xu et al., 2020) mostly requires indomain task labels, limiting its usage to supervised classification.",
      "startOffset" : 38,
      "endOffset" : 157
    }, {
      "referenceID" : 16,
      "context" : "Prior work on out-of-domain detection (e.g., Hendrycks and Gimpel, 2017; Lee et al., 2018; Liang et al., 2018; Hendrycks et al., 2019, 2020; Xu et al., 2020) mostly requires indomain task labels, limiting its usage to supervised classification.",
      "startOffset" : 38,
      "endOffset" : 157
    }, {
      "referenceID" : 26,
      "context" : "Prior work on out-of-domain detection (e.g., Hendrycks and Gimpel, 2017; Lee et al., 2018; Liang et al., 2018; Hendrycks et al., 2019, 2020; Xu et al., 2020) mostly requires indomain task labels, limiting its usage to supervised classification.",
      "startOffset" : 38,
      "endOffset" : 157
    }, {
      "referenceID" : 9,
      "context" : "Therefore, it is natural to ask the following question: Can we detect out-of-domain samples using only unsupervised data without any in-domain labels? We regard the out-of-domain detection problem as checking whether the given test samples are drawn from the same distribution that generates the in-domain samples, which requires a weaker assumption than prior work (e.g., Lee et al., 2018; Hendrycks et al., 2020).",
      "startOffset" : 366,
      "endOffset" : 414
    }, {
      "referenceID" : 4,
      "context" : "To solve the problem, we utilize the latent embeddings of pre-trained transformers (e.g., Vaswani et al., 2017; Devlin et al., 2019; Liu et al., 2019) to represent the input data, which allow us to apply classical OOD detection methods such as one-class support vector machines (Schölkopf et al.",
      "startOffset" : 83,
      "endOffset" : 150
    }, {
      "referenceID" : 17,
      "context" : "To solve the problem, we utilize the latent embeddings of pre-trained transformers (e.g., Vaswani et al., 2017; Devlin et al., 2019; Liu et al., 2019) to represent the input data, which allow us to apply classical OOD detection methods such as one-class support vector machines (Schölkopf et al.",
      "startOffset" : 83,
      "endOffset" : 150
    }, {
      "referenceID" : 19,
      "context" : ", 2019) to represent the input data, which allow us to apply classical OOD detection methods such as one-class support vector machines (Schölkopf et al., 2001) or support vector data description (Tax and Duin, 2004) on them.",
      "startOffset" : 135,
      "endOffset" : 159
    }, {
      "referenceID" : 21,
      "context" : ", 2001) or support vector data description (Tax and Duin, 2004) on them.",
      "startOffset" : 43,
      "endOffset" : 63
    }, {
      "referenceID" : 16,
      "context" : "Given a classifier h trained with Dn, we can use maximum calibrated softmax probability with temperature scaling as the anomaly score (Liang et al., 2018; Hinton et al., 2015):",
      "startOffset" : 134,
      "endOffset" : 175
    }, {
      "referenceID" : 11,
      "context" : "Given a classifier h trained with Dn, we can use maximum calibrated softmax probability with temperature scaling as the anomaly score (Liang et al., 2018; Hinton et al., 2015):",
      "startOffset" : 134,
      "endOffset" : 175
    }, {
      "referenceID" : 19,
      "context" : "Then it is natural to resort to classic outlier detection methods like one-class support vector machine (Schölkopf et al., 2001), support vector data description (Tax and Duin, 2004) or kernel density estimation (KDE) for estimating the support or the density of the in-domain data distribution.",
      "startOffset" : 104,
      "endOffset" : 128
    }, {
      "referenceID" : 21,
      "context" : ", 2001), support vector data description (Tax and Duin, 2004) or kernel density estimation (KDE) for estimating the support or the density of the in-domain data distribution.",
      "startOffset" : 41,
      "endOffset" : 61
    }, {
      "referenceID" : 18,
      "context" : "When applying such methods to text data, the major focus of prior work is to design a good network structure or learning objectives (Ruff et al., 2018).",
      "startOffset" : 132,
      "endOffset" : 151
    }, {
      "referenceID" : 17,
      "context" : "BERT and its variants such as RoBERTa (e.g., Devlin et al., 2019; Liu et al., 2019) are pre-trained on large-scale public data (denoted as Dpub) using self-supervised tasks, such as language model and next sentence prediction.",
      "startOffset" : 38,
      "endOffset" : 83
    }, {
      "referenceID" : 12,
      "context" : "Features from all layers Using BERT features from only one layer might not be sufficient, as prior work (Jawahar et al., 2019) has explored that different layers of BERT capture distinct linguistic properties, e.",
      "startOffset" : 104,
      "endOffset" : 126
    }, {
      "referenceID" : 21,
      "context" : "Mahalanobis distance as features (MDF) for all layers Support Vector Data Description (SVDD) (Tax and Duin, 2004) is a technique related to OC-SVM where a hypersphere is used to separate the data instead of a hyperplane.",
      "startOffset" : 93,
      "endOffset" : 113
    }, {
      "referenceID" : 24,
      "context" : "Also, our approximation from Eq (1) to Eq (2) is different from the known result that when Φ(x) is the infinite-dimensional feature map of the widely used Gaussian RBF kernels, OC-SVM and SVDD are equivalent and asymptotically consistent density estimators (Tsybakov et al., 1997; Vert et al., 2006).",
      "startOffset" : 257,
      "endOffset" : 299
    }, {
      "referenceID" : 4,
      "context" : "(2020) find that domain-adaptive masked language modeling (Devlin et al., 2019) would improve supervised classification capability of BERT when it is transferred to that domain.",
      "startOffset" : 58,
      "endOffset" : 79
    }, {
      "referenceID" : 20,
      "context" : "(2020), by providing in-domain Dn with the original training set of SST dataset (Socher et al., 2013) and considering samples from four other datasets (i.",
      "startOffset" : 80,
      "endOffset" : 101
    }, {
      "referenceID" : 13,
      "context" : ", 20 Newsgroups (Lang, 1995), English-German Multi30K (Elliott et al.",
      "startOffset" : 16,
      "endOffset" : 28
    }, {
      "referenceID" : 5,
      "context" : ", 20 Newsgroups (Lang, 1995), English-German Multi30K (Elliott et al., 2016), RTE (Dagan et al.",
      "startOffset" : 54,
      "endOffset" : 76
    }, {
      "referenceID" : 3,
      "context" : ", 2016), RTE (Dagan et al., 2005) and SNLI (Bowman et al.",
      "startOffset" : 13,
      "endOffset" : 33
    }, {
      "referenceID" : 14,
      "context" : "• Cross-intent dataset (CLINIC150) This is a crowdsourced dialog dataset (Larson et al., 2019), including in-domain queries covering 150 intents and out-of-domain queries that do not fall within any of the 150 intents.",
      "startOffset" : 73,
      "endOffset" : 94
    }, {
      "referenceID" : 30,
      "context" : "Choice of D̃pub for BCAD We adopt the BooksCorpus (Zhu et al., 2015) and English Wikipedia, which are the sources used in common by BERT and RoBERTa for pre-training.",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 16,
      "context" : "One is to tackle the problem in specific multi-class classification tasks, where well-trained classifiers are utilized to design anomaly scores (e.g., Hendrycks and Gimpel, 2017; Liang et al., 2018; Lee et al., 2018; Card et al., 2019; Hendrycks et al., 2020; Xu et al., 2020), Those methods can only be useful when multi-class labels are available, which limits their application in more general domains.",
      "startOffset" : 144,
      "endOffset" : 276
    }, {
      "referenceID" : 15,
      "context" : "One is to tackle the problem in specific multi-class classification tasks, where well-trained classifiers are utilized to design anomaly scores (e.g., Hendrycks and Gimpel, 2017; Liang et al., 2018; Lee et al., 2018; Card et al., 2019; Hendrycks et al., 2020; Xu et al., 2020), Those methods can only be useful when multi-class labels are available, which limits their application in more general domains.",
      "startOffset" : 144,
      "endOffset" : 276
    }, {
      "referenceID" : 1,
      "context" : "One is to tackle the problem in specific multi-class classification tasks, where well-trained classifiers are utilized to design anomaly scores (e.g., Hendrycks and Gimpel, 2017; Liang et al., 2018; Lee et al., 2018; Card et al., 2019; Hendrycks et al., 2020; Xu et al., 2020), Those methods can only be useful when multi-class labels are available, which limits their application in more general domains.",
      "startOffset" : 144,
      "endOffset" : 276
    }, {
      "referenceID" : 9,
      "context" : "One is to tackle the problem in specific multi-class classification tasks, where well-trained classifiers are utilized to design anomaly scores (e.g., Hendrycks and Gimpel, 2017; Liang et al., 2018; Lee et al., 2018; Card et al., 2019; Hendrycks et al., 2020; Xu et al., 2020), Those methods can only be useful when multi-class labels are available, which limits their application in more general domains.",
      "startOffset" : 144,
      "endOffset" : 276
    }, {
      "referenceID" : 26,
      "context" : "One is to tackle the problem in specific multi-class classification tasks, where well-trained classifiers are utilized to design anomaly scores (e.g., Hendrycks and Gimpel, 2017; Liang et al., 2018; Lee et al., 2018; Card et al., 2019; Hendrycks et al., 2020; Xu et al., 2020), Those methods can only be useful when multi-class labels are available, which limits their application in more general domains.",
      "startOffset" : 144,
      "endOffset" : 276
    }, {
      "referenceID" : 4,
      "context" : "Finally, the fine-tuning techniques we use to improve the representation of data are closely related to unsupervised pre-training for transformers (Devlin et al., 2019; Yang et al., 2019), and recently proposed contrastive learning (e.",
      "startOffset" : 147,
      "endOffset" : 187
    }, {
      "referenceID" : 27,
      "context" : "Finally, the fine-tuning techniques we use to improve the representation of data are closely related to unsupervised pre-training for transformers (Devlin et al., 2019; Yang et al., 2019), and recently proposed contrastive learning (e.",
      "startOffset" : 147,
      "endOffset" : 187
    }, {
      "referenceID" : 2,
      "context" : ", 2019), and recently proposed contrastive learning (e.g., He et al., 2020; Chen et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 94
    }, {
      "referenceID" : 29,
      "context" : "In the future, we are interested in deploying our OOD method to real-world applications, such as detecting unseen new classes for incremental fewshot learning (Zhang et al., 2020; Xia et al., 2021) or filtering OOD samples in data augmentations.",
      "startOffset" : 159,
      "endOffset" : 197
    }, {
      "referenceID" : 25,
      "context" : "In the future, we are interested in deploying our OOD method to real-world applications, such as detecting unseen new classes for incremental fewshot learning (Zhang et al., 2020; Xia et al., 2021) or filtering OOD samples in data augmentations.",
      "startOffset" : 159,
      "endOffset" : 197
    } ],
    "year" : 2021,
    "abstractText" : "Deployed real-world machine learning applications are often subject to uncontrolled and even potentially malicious inputs. Those outof-domain inputs can lead to unpredictable outputs and sometimes catastrophic safety issues. Prior studies on out-of-domain detection require in-domain task labels and are limited to supervised classification scenarios. Our work tackles the problem of detecting out-ofdomain samples with only unsupervised indomain data. We utilize the latent representations of pre-trained transformers and propose a simple yet effective method to transform features across all layers to construct outof-domain detectors efficiently. Two domainspecific fine-tuning approaches are further proposed to boost detection accuracy. Our empirical evaluations of related methods on two datasets validate that our method greatly improves out-of-domain detection ability in a more general scenario.1",
    "creator" : "LaTeX with hyperref"
  }
}