{
  "name" : "2021.acl-long.325.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "How is BERT surprised? Layerwise detection of linguistic anomalies",
    "authors" : [ "Bai Li", "Zining Zhu", "Guillaume Thomas", "Yang Xu", "Frank Rudzicz" ],
    "emails" : [ "frank}@cs.toronto.edu", "guillaume.thomas@utoronto.ca" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4215–4228\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4215\nmarkable ability in detecting when a word is anomalous in context, but likelihood scores offer no information about the cause of the anomaly. In this work, we use Gaussian models for density estimation at intermediate layers of three language models (BERT, RoBERTa, and XLNet), and evaluate our method on BLiMP, a grammaticality judgement benchmark. In lower layers, surprisal is highly correlated to low token frequency, but this correlation diminishes in upper layers. Next, we gather datasets of morphosyntactic, semantic, and commonsense anomalies from psycholinguistic studies; we find that the best performing model RoBERTa exhibits surprisal in earlier layers when the anomaly is morphosyntactic than when it is semantic, while commonsense anomalies do not exhibit surprisal at any intermediate layer. These results suggest that language models employ separate mechanisms to detect different types of linguistic anomalies."
    }, {
      "heading" : "1 Introduction",
      "text" : "Transformer-based language models (LMs) have achieved remarkable success in numerous natural language processing tasks, prompting many probing studies to determine the extent of their linguistic knowledge. A popular approach is to formulate the problem as a multiple-choice task, where the LM is considered correct if it assigns higher likelihood to the appropriate word than an inappropriate one, given context (Gulordava et al., 2018; Ettinger, 2020; Warstadt et al., 2020). The likelihood score, however, only gives a scalar value of the degree that a word is anomalous in context, and cannot distinguish between different ways that a word might be anomalous.\nIt has been proposed that there are different types of linguistic anomalies. Chomsky\n(1957) distinguished semantic anomalies (“colorless green ideas sleep furiously”) from ungrammaticality (“furiously sleep ideas green colorless”). Psycholinguistic studies initially suggested that different event-related potentials (ERPs) are produced in the brain depending on the type of anomaly; e.g., semantic anomalies produce negative ERPs 400 ms after the stimulus, while syntactic anomalies produce positive ERPs 600 ms after (Kutas et al., 2006). Here, we ask whether Transformer LMs show different surprisals in their intermediate layers depending on the type of anomaly. However, LMs do not compute likelihoods at intermediate layers – only at the final layer.\nIn this paper, we introduce a new tool to probe for surprisal at intermediate layers of BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and XLNet (Yang et al., 2019), formulating the problem as density estimation. We train Gaussian models to fit distributions of embeddings at each layer of the LMs. Using BLiMP (Warstadt et al., 2020) for evaluation, we show that this model is effective at grammaticality judgement, requiring only a small amount of in-domain text for training. Figure 1 shows the method using the RoBERTa model on two example sentences.\nWe apply our model to test sentences drawn from BLiMP and 7 psycholinguistics studies, exhibiting morphosyntactic, semantic, and commonsense anomalies. We find that morphosyntactic anomalies produce out-of-domain embeddings at earlier layers, semantic anomalies at later layers, and no commonsense anomalies, even though the LM’s final accuracy is similar. We show that LMs are internally sensitive to the type of linguistic anomaly, which is not apparent if we only had access to their softmax probability outputs. Our source code and data are available at: https://github.com/SPOClab-ca/ layerwise-anomaly."
    }, {
      "heading" : "2 Related work",
      "text" : ""
    }, {
      "heading" : "2.1 Probing LMs for linguistic knowledge",
      "text" : "Soon after BERT’s release, many papers invented probing techniques to discover what linguistic knowledge it contains, and how this information is distributed between layers (e.g., Rogers et al. (2021) provides a comprehensive overview). Tenney et al. (2019) used “edge probing” to determine each layer’s contribution to a task’s performance, and discovered that the middle layers contributed more when the task was syntactic, and the upper layers more when the task was semantic.\nSeveral papers found that BERT’s middle layers contain the most syntactic information. Kelly et al. (2020) found that BERT’s middle layers are best at distinguishing between sentences with direct and indirect object constructions. Hewitt and Manning (2019) used a structural probe to recover syntax trees from contextual embeddings, and found the performance peaked in middle layers.\nProbing results are somewhat dependent on the choice of linguistic formalism used to annotate the data, as Kulmizev et al. (2020) found for syntax, and Kuznetsov and Gurevych (2020) found for se-\nmantic roles. Miaschi et al. (2020) examined the layerwise performance of BERT for a suite of linguistic features, before and after fine tuning. Our work further investigates what linguistic information is contained in different layers, with a focus on anomalous inputs."
    }, {
      "heading" : "2.2 Neural grammaticality judgements",
      "text" : "Many recent probing studies used grammaticality judgement tasks to test the knowledge of specific phenomena in LMs. Warstadt et al. (2019) gathered sentences from linguistic publications, and evaluated by Matthews Correlation with the ground truth. More commonly, the model is presented with a binary choice between an acceptable and unacceptable sentence: BLiMP (Warstadt et al., 2020) used templates to generate 67k such sentence pairs, covering 12 types of linguistic phenomena. Similarly, Hu et al. (2020) created syntactic tests using templates, but defined success criteria using inequalities of LM perplexities.\nIn contrast with artificial templates, Gulordava et al. (2018) generated test cases by perturbing natural corpus data to test long-distance dependencies. Most grammaticality studies focused on syntactic phenomena, but Rabinovich et al. (2019) tested LMs’ sensitivity to semantic infelicities involving indefinite pronouns."
    }, {
      "heading" : "2.3 Tests of selectional restrictions",
      "text" : "Violations of selectional restrictions are one type of linguistic unacceptability, defined as a semantic mismatch between a verb and an argument. Sasano and Korhonen (2020) examined the geometry of word classes (e.g., words that can be a direct object of the verb ‘play’) in word vector models; they compared single-class models against discriminative models for learning word class boundaries. Chersoni et al. (2018) tested distributional semantic models on their ability to identify selectional restriction violations using stimuli from two psycholinguistic datasets. Finally, Metheniti et al. (2020) tested how much BERT relies on selectional restriction information versus other contextual information for making masked word predictions."
    }, {
      "heading" : "2.4 Psycholinguistic tests for LMs",
      "text" : "The N400 response is a negative event-related potential that occurs roughly 400ms after a stimulus in human brains, and is generally associated with the stimulus being semantically anomalous with\nrespect to the preceding context (Kutas and Federmeier, 2011). Although many studies have been performed with a diverse range of linguistic stimuli, exactly what conditions trigger the N400 response is still an open question. Frank et al. (2015) found that the N400 response is correlated with surprisal, i.e., how unlikely an LM predicts a word given the preceding context.\nRecently, several studies have investigated relationships between surprisal in neural LMs and the N400 response. Michaelov and Bergen (2020) compared human N400 amplitudes with LSTM-based models using stimuli from several psycholinguistic studies. Ettinger (2020) used data from three psycholinguistic studies to probe BERT’s knowledge of commonsense and negation. Our work is similar to the latter – we leverage psycholinguistic studies for their stimuli, but we do not use the their N400 amplitude results."
    }, {
      "heading" : "3 Model",
      "text" : "We use the transformer language model as a contextual embedding extractor (we write this as BERT for convenience). Let L be the layer index, which ranges from 0 to 12 on all of our models. Using a training corpus {w1, · · · , wT }, we extract contextual embeddings at layer L for each token:\nx (L) 1 , · · · ,x (L) T = BERTL(w1, · · · , wT ). (1)\nNext, we fit a multivariate Gaussian on the extracted embeddings:\nx (L) 1 , · · · ,x (L) T ∼ N (µ̂L, Σ̂L). (2)\nFor evaluating the layerwise surprisal of a new sentence s = [t1, · · · , tn], we similarly extract contextual embeddings using the language model:\ny1, · · · ,yn = BERTL(t1, · · · , tn). (3)\nThe surprisal of each token is the negative log likelihood of the contextual vector according to the multivariate Gaussian:\nGi = − log p(yi | µ̂L, Σ̂L) for i = 1 . . . n. (4) Finally, we define the surprisal of sentence s as the sum of surprisals of all of its tokens, which is also the joint log likelihood of all of the embeddings:\nsurprisalL(t1, · · · , tn) = n∑\ni=1\nGi\n= − log p(y1, · · · ,yn | µ̂L, Σ̂L). (5)"
    }, {
      "heading" : "3.1 Connection to Mahalanobis distance",
      "text" : "The theoretical motivation for using the sum of log likelihoods is that when we fit a Gaussian model with full covariance matrix, low likelihood corresponds exactly to high Mahalanobis distance from the in-distribution points. The score given by the Gaussian model is:\nG = − log p(y | µ̂L, Σ̂L)\n= − log\n( 1\n(2π)D/2|Σ̂L|1/2 exp(−\n1 2 d2)\n) , (6)\nwhere D is the dimension of the vector space, and d is the Mahalanobis distance:\nd = √ (y − µ̂L) T Σ̂ −1 L (y − µ̂L). (7)\nRearranging, we get:\nd2 = 2G−D log(2π)− log |Σ̂L|, (8)\nthus the negative log likelihood is the squared Mahalanobis distance plus a constant.\nVarious methods based on Mahalanobis distance have been used for anomaly detection in neural networks; for example, Lee et al. (2018) proposed a similar method for out-of-domain detection in neural classification models, and Cao et al. (2020) found the Mahalanobis distance method to be competitive with more sophisticated methods on medical out-of-domain detection. In Transformer models, Podolskiy et al. (2021) used Mahalanobis distance for out-of-domain detection, outperforming methods based on softmax probability and likelihood ratios.\nGaussian assumptions. Our model assumes that the embeddings at every layer follow a multivariate Gaussian distribution. Since the Gaussian distribution is the maximum entropy distribution given a mean and covariance matrix, it makes the fewest assumptions and is therefore a reasonable default. Hennigen et al. (2020) found that embeddings sometimes do not follow a Gaussian distribution, but it is unclear what alternative distribution would be a better fit, so we will assume a Gaussian distribution in this work."
    }, {
      "heading" : "3.2 Training and evaluation",
      "text" : "For all of our experiments, we use the ‘base’ versions of pretrained language models BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and\nXLNet (Yang et al., 2019), provided by HuggingFace (Wolf et al., 2020). Each of these models have 12 contextual layers plus a 0th static layer, and each layer is 768-dimensional.\nWe train the Gaussian model on randomly selected sentences from the British National Corpus (Leech, 1992), representative of acceptable English text from various genres. We evaluate on BLiMP (Warstadt et al., 2020), a dataset of 67k minimal sentence pairs that test acceptability judgements across a variety of syntactic and semantic phenomena. In our case, a sentence pair is considered correct if the sentence-level surprisal of the unacceptable sentence is higher than that of the acceptable sentence.\nHow much training data is needed? We experiment with training data sizes ranging from 10 to 10,000 sentences (Figure 2a). Compared to the massive amount of data needed for pretraining the LMs, we find that a modest corpus suffices for training the Gaussian anomaly model, and a plateau is reached after 1000 sentences for all three models. Therefore, we use 1000 training sentences (unless otherwise noted) for all subsequent experiments in this paper.\nWhich layers are sensitive to anomaly? We vary L from 0 to 12 in all three models (Figure 2b). The layer with the highest accuracy differs between models: layer 9 has the highest accuracy for BERT, 11 for RoBERTa, and 6 for XLNet. All models experience a sharp drop in the last layer, likely because the last layer is specialized for the MLM pretraining objective.\nComparisons to other models. Our bestperforming model is RoBERTa, with an accuracy of 0.830. This is slightly higher the best model reported in BLiMP (GPT-2, with accuracy 0.801).\nWe do not claim to beat the state-of-the-art on BLiMP: Salazar et al. (2020) obtains a higher accuracy of 0.865 using RoBERTa-large. Even though the main goal of this paper is not to maximize accuracy on BLiMP, our Gaussian anomaly model is competitive with other transformer-based models on this task.\nIn Appendix A, we explore variations of the Gaussian anomaly model, such as varying the type of covariance matrix, Gaussian mixture models, and one-class SVMs (Schölkopf et al., 2000). However, none of these variants offer a significant improvement over a single Gaussian model with full covariance matrix."
    }, {
      "heading" : "3.3 Lower layers are sensitive to frequency",
      "text" : "We notice that surprisal scores in the lower layers are sensitive to token frequency: higher frequency tokens produce embeddings close to the center of the Gaussian distribution, while lower frequency tokens are at the periphery. The effect gradually diminishes towards the upper layers.\nTo quantify the sensitivity to frequency, we compute token-level surprisal scores for 5000 sentences from BNC that were not used in training. We then compute the Pearson correlation between the surprisal score and log frequency for each token (Figure 3). In all three models, there is a high correlation between the surprisal score and log frequency at the lower layers, which diminishes at the upper layers. A small positive correlation persists until the last layer, except for XLNet, in which the correlation eventually disappears.\nThere does not appear to be any reports of this phenomenon in previous work. For static word vectors, Gong et al. (2018) found that embeddings for low-frequency words lie in a different region of\nthe embedding space than high-frequency words. We find evidence that the same phenomenon occurs in contextual embeddings (Appendix B). In this scenario, the Gaussian model fits the highfrequency region and assigns lower likelihoods to the low-frequency region, explaining the positive correlation at all layers; however, it is still unclear why the correlation diminishes at upper layers."
    }, {
      "heading" : "4 Levels of linguistic anomalies",
      "text" : "We turn to the question of whether LMs exhibit different behaviour when given inputs with different types of linguistic anomalies. The task of partitioning linguistic anomalies into several distinct classes can be challenging. Syntax and semantics have a high degree of overlap – there is no widely accepted criterion for distinguishing between ungrammaticality and semantic anomaly (e.g., Abrusán (2019) gives a survey of current proposals), and Poulsen (2012) challenges this dichotomy entirely. Similarly, Warren et al. (2015) noted that semantic anomalies depend somewhat on world knowledge.\nWithin a class, the anomalies are also heterogeneous (e.g., ungrammaticality may be due to violations of agreement, wh-movement, negative polarity item licensing, etc), which might each affect the LMs differently. Thus, we define three classes of anomalies that do not attempt to cover all possible linguistic phenomena, but captures different levels of language processing while retaining internal uniformity:\n1. Morphosyntactic anomaly: an error in\nthe inflected form of a word, for example, subject-verb agreement (*the boy eat the\nsandwich), or incorrect verb tense or aspect inflection (*the boy eaten the sandwich). In each case, the sentence can be corrected by changing the inflectional form of one word.\n2. Semantic anomaly: a violation of a se-\nlectional restriction, such as animacy (#the house eats the sandwich). In these cases, the sentence can be corrected by replacing one of the verb’s arguments with another one in the same word class that satisfies the verb’s selectional restrictions.\n3. Commonsense anomaly: sentence describes\nan situation that is atypical or implausible in the real world but is otherwise acceptable (#the customer served the waitress)."
    }, {
      "heading" : "4.1 Summary of anomaly datasets",
      "text" : "We use two sources of data for experiments on linguistic anomalies: synthetic sentences generated from templates, and materials from psycholinguistic studies. Both have advantages and disadvantages – synthetic data can be easily generated in large quantities, but the resulting sentences may be odd in unintended ways. Psycholinguistic stimuli are designed to control for confounding factors (e.g., word frequency) and human-validated for acceptability, but are smaller (typically fewer than 100 sentence pairs).\nWe curate a set of 12 tasks from BLiMP and 7 psycholinguistic studies1. Each sentence pair consists of a control and an anomalous sentence, so that all sentences within a task differ in a consistent manner. Table 1 shows an example sentence pair from each task. We summarize each dataset:\n1. BLiMP (Warstadt et al., 2020): we use\nsubject-verb and determiner-noun agreement tests as morphosyntactic anomaly tasks. For simplicity, we only use the basic regular sentences, and exclude sentences involving irregular words or distractor items. We also use the two argument structure tests involving animacy as a semantic anomaly task. All three BLiMP tasks therefore have 2000 sentence pairs.\n1Several of these stimuli have been used in natural language processing research. Chersoni et al. (2018) used the data from Pylkkänen and McElree (2007) and Warren et al. (2015) to probe word vectors for knowledge of selectional restrictions. Ettinger (2020) used data from Federmeier and Kutas (1999) and Chow et al. (2016), which were referred to as CPRAG-102 and ROLE-88 respectively.\nType Task Correct Example Incorrect Example\nMorphosyntax\nBLiMP (Subject-Verb) These casseroles disgust Kayla. These casseroles disgusts Kayla.\nBLiMP (Det-Noun) Craig explored that grocery store. Craig explored that grocery stores.\nOsterhout and Nicol (1999)\nThe cats won’t eat the food that Mary gives them.\nThe cats won’t eating the food that Mary gives them.\nSemantic\nBLiMP (Animacy) Amanda was respected by some waitresses.\nAmanda was respected by some picture.\nPylkkänen and McElree (2007)\nThe pilot flew the airplane after the intense class.\nThe pilot amazed the airplane after the intense class.\nWarren et al. (2015) Corey’s hamster explored a nearby backpack and filled it with sawdust. Corey’s hamster entertained a nearby backpack and filled it with sawdust.\nOsterhout and Nicol (1999)\nThe cats won’t eat the food that Mary gives them.\nThe cats won’t bake the food that Mary gives them.\nOsterhout and Mobley (1995)\nThe plane sailed through the air and landed on the runway. The plane sailed through the air and laughed on the runway.\nCommonsense\nWarren et al. (2015) Corey’s hamster explored a nearby backpack and filled it with sawdust. Corey’s hamster lifted a nearby backpack and filled it with sawdust.\nFedermeier and Kutas (1999)\n“Checkmate,” Rosalie announced with glee. She was getting to be really good at chess.\n“Checkmate,” Rosalie announced with glee. She was getting to be really good at monopoly.\nChow et al. (2016) The restaurant owner forgot which customer the waitress had served.\nThe restaurant owner forgot which waitress the customer had served.\nUrbach and Kutas (2010) Prosecutors accuse defendants of committing a crime.\nProsecutors accuse sheriffs of committing a crime.\n5. Osterhout and Mobley (1995): we use data\nfrom experiment 2, containing 90 sentence pairs where the verb in the anomalous sentence is semantically inappropriate. The ex-"
    }, {
      "heading" : "4.2 Quantifying layerwise surprisal",
      "text" : "Let D = {(s1, s ′ 1), · · · , (sn, s ′ n)} be a dataset of sentence pairs, where si is a control sentence and s ′\ni is an anomalous sentence. For each layer L, we define the surprisal gap as the mean difference of surprisal scores between the control and anoma-\nlous sentences, scaled by the standard deviation:\nsurprisal gapL(D) =\nE{surprisalL(s ′ i)− surprisalL(si)} n i=1 σ{surprisalL(s ′ i)− surprisalL(si)} n i=1 (9)\nThe surprisal gap is a scale-invariant measure of sensitivity to anomaly, similar to a signal-tonoise ratio. While surprisal scores are unitless, the surprisal gap may be viewed as the number of standard deviations that anomalous sentences trigger surprisal above control sentences. This is advantageous over accuracy scores, which treats the sentence pair as correct when the anomalous sentence has higher surprisal by any margin; this hard cutoff masks differences in the magnitude of surprisal. The metric also allows for fair comparison of surprisal scores across datasets of vastly different sizes. Figure 4 shows the surprisal gap for all 12 tasks, using the RoBERTa model; the results for BERT and XLNet are in the Appendix C.\nNext, we compare the performance of the Gaussian model with the masked language model (MLM). We score each instance as correct if the masked probability of the correct word is higher than the anomalous word. One limitation of the MLM approach is that it requires the sentence pair to be identical in all places except for one token, since the LMs do not support modeling joint probabilities over multiple tokens. To ensure fair comparison between GM and MLM, we exclude instances where the differing token is outof-vocabulary in any of the LMs (this excludes approximately 30% of instances). For the Gaussian model, we compute accuracy using the bestperforming layer for each model (Section 3.2). The results are listed in Table 2."
    }, {
      "heading" : "5 Discussion",
      "text" : ""
    }, {
      "heading" : "5.1 Anomaly type and surprisal",
      "text" : "Morphosyntactic anomalies generally appear earlier than semantic anomalies (Figure 4). The surprisal gap plot exhibits different patterns depending on the type of linguistic anomaly: morphosyntactic anomalies produce high surprisal relatively early (layers 3-4), while semantic anomalies produce low surprisals until later (layers 9 and above). Commonsense anomalies do not result in surprisals at any layer: the surprisal gap is near zero for all of the commonsense tasks. The observed difference between morphosyntactic and semantic\nanomalies is consistent with previous work (Tenney et al., 2019), which found that syntactic information appeared earlier in BERT than semantic information.\nOne should be careful and avoid drawing conclusions from only a few experiments. A similar situation occurred in psycholinguistics research (Kutas et al., 2006): early results suggested that the N400 was triggered by semantic anomalies, while syntactic anomalies triggered the P600 – a different type of ERP. However, subsequent experiments found exceptions to this rule, and now it is believed that the N400 cannot be categorized by any standard dichotomy, like syntax versus semantics (Kutas and Federmeier, 2011). In our case, Pylkkänen and McElree (2007) is an exception: the task is a semantic anomaly, but produces surprisals in early layers, similar to the morphosyntactic tasks. Hence it is possible that the dichotomy is something other than syntax versus semantics; we leave to future work to determine more precisely what conditions trigger high surprisals in lower versus upper layers of LMs."
    }, {
      "heading" : "5.2 Comparing anomaly model with MLM",
      "text" : "The masked language model (MLM) usually outperforms the Gaussian anomaly model (GM), but the difference is uneven. MLM performs much better than GM on commonsense tasks, slightly better on semantic tasks, and about the same or slightly worse on morphosyntactic tasks. It is not obvious why MLM should perform better than GM, but we note two subtle differences between the MLM and GM setups that may be contributing\nfactors. First, the GM method adds up the surprisal scores for the whole sequence, while MLM only considers the softmax distribution at one token. Second, the input sequence for MLM always contains a [MASK] token, whereas GM takes the original unmasked sequences as input, so the representations are never identical between the two setups.\nMLM generally outperforms GM, but it does not solve every task: all three LMs fail to perform above chance on the data from Warren et al. (2015). This set of stimuli was designed so that both the control and impossible completions are not very likely or expected, which may have caused the difficulty for the LMs. We excluded the task of Chow et al. (2016) for MLM because the control and anomalous sentences differed by more than one token2."
    }, {
      "heading" : "5.3 Differences between LMs",
      "text" : "RoBERTa is the best-performing of the three LMs in both the GM and MLM settings: this is expected since it is trained with the most data and performs well on many natural language benchmarks. Surprisingly, XLNet is ill-suited for this task and performs worse than BERT, despite having a similar model capacity and training data.\nThe surprisal gap plots for BERT and XL-\n2Sentence pairs with multiple differing tokens are inconvenient for MLM to handle, but this is not a fundamental limitation. For example, Salazar et al. (2020) proposed a modification to MLM to handle such cases: they compute a pseudolog-likelihood score for a sequence by replacing one token at a time with a [MASK] token, applying MLM to each masked sequence, and summing up the log likelihood scores.\nNet (Appendix C) show some differences from RoBERTa: only morphosyntactic tasks produce out-of-domain embeddings in these two models, and not semantic or commonsense tasks. Evidently, how LMs behave when presented with anomalous inputs is dependent on model architecture and training data size; we leave exploration of this phenomenon to future work."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We use Gaussian models to characterize outof-domain embeddings at intermediate layers of Transformer language models. The model requires a relatively small amount of in-domain data. Our experiments reveal that out-of-domain points in lower layers correspond to low-frequency tokens, while grammatically anomalous inputs are out-of-domain in higher layers. Furthermore, morphosyntactic anomalies are recognized as out-ofdomain starting from lower layers compared to syntactic anomalies. Commonsense anomalies do not generate out-of-domain embeddings at any layer, even when the LM has a preference for the correct cloze completion. These results show that depending on the type of linguistic anomaly, LMs use different mechanisms to produce the output softmax distribution."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank Julian Salazar and our anonymous reviewers for their helpful suggestions. YX is funded through an NSERC Discovery Grant, a SSHRC Insight Grant, and an Ontario ERA award. FR is supported by a CIFAR Chair in Artificial Intelligence."
    }, {
      "heading" : "A Ablation experiments on Gaussian model",
      "text" : "We compare some variations to our methodology of training the Gaussian model. All of these variations are evaluated on the full BLiMP dataset. In each experiment, (unless otherwise noted) the language model is RoBERTa-base, using the secondto-last layer, and the Gaussian model has a full covariance matrix trained with 1000 sentences from the BNC corpus.\nCovariance matrix. We vary the type of covariance matrix (Table 3). Diagonal and spherical covariance matrices perform worse than with the full covariance matrix; this may be expected, as the full matrix has the most trainable parameters.\nGaussian mixture models. We try GMMs with up to 16 mixture components (Table 4). We observe a small increase in accuracy compared to a single Gaussian, but the difference is too small to justify the increased training time.\nGenre of training text. We sample from genres of BNC (each time with 1000 sentences) to train the Gaussian model (Table 5). The model performed worse when trained with the academic and spoken genres, and about the same with the fiction and news genres, perhaps because their vocabularies and grammars are more similar to those in the BLiMP sentences.\nOne-class SVM. We try replacing the Gaussian model with a one-class SVM (Schölkopf et al., 2000), another popular model for anomaly detection. We use the default settings from scikit-learn\nwith three kernels (Table 6), but it performs worse than the Gaussian model on all settings.\nSentence aggregation. Instead of Equation 5, we try defining sentence-level surprisal as the maximum surprisal among all tokens (Table 7):\nsurprisal(s1, · · · , sn) = max n i=1Gi; (10)\nhowever, this performs worse than using the sum of token surprisals."
    }, {
      "heading" : "B PCA plots of infrequent tokens",
      "text" : "We feed a random selection of BNC sentences into RoBERTa and use PCA to visualize the distribution of rare and frequent tokens at different layers (Figure 5). In all cases, we find that infrequent tokens occupy a different region of the embedding space from frequent tokens, similar to what Gong et al. (2018) observed for static word vectors. This is consistent with the correlation between tokenlevel surprisal and frequency (Figure 3), although the decrease in correlation towards upper layers is not apparent in the PCA plots."
    }, {
      "heading" : "C Surprisal gap for BERT and XLNet",
      "text" : "Figures 6 and 7 plot the surprisal gaps using the BERT and XLNet models; data and algorithms are identical to the RoBERTa model (Figure 4). The Gaussian model is only sensitive to morphosyntactic anomalies, and not to semantic and commonsense ones."
    } ],
    "references" : [ {
      "title" : "Semantic anomaly, pragmatic infelicity, and ungrammaticality",
      "author" : [ "Márta Abrusán." ],
      "venue" : "Annual Review of Linguistics, 5:329–351.",
      "citeRegEx" : "Abrusán.,? 2019",
      "shortCiteRegEx" : "Abrusán.",
      "year" : 2019
    }, {
      "title" : "A benchmark of medical out of distribution detection",
      "author" : [ "Tianshi Cao", "Chinwei Huang", "David Yu-Tung Hui", "Joseph Paul Cohen." ],
      "venue" : "arXiv preprint arXiv:2007.04250.",
      "citeRegEx" : "Cao et al\\.,? 2020",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2020
    }, {
      "title" : "Modeling violations of selectional restrictions with distributional semantics",
      "author" : [ "Emmanuele Chersoni", "Adrià Torrens Urrutia", "Philippe Blache", "Alessandro Lenci." ],
      "venue" : "Proceedings of the Workshop on Linguistic Complexity and Natural Language Process-",
      "citeRegEx" : "Chersoni et al\\.,? 2018",
      "shortCiteRegEx" : "Chersoni et al\\.",
      "year" : 2018
    }, {
      "title" : "Syntactic Structures",
      "author" : [ "Noam Chomsky." ],
      "venue" : "Mouton and Co.",
      "citeRegEx" : "Chomsky.,? 1957",
      "shortCiteRegEx" : "Chomsky.",
      "year" : 1957
    }, {
      "title" : "A “bag-of-arguments” mechanism for initial verb predictions",
      "author" : [ "Wing-Yee Chow", "Cybelle Smith", "Ellen Lau", "Colin Phillips." ],
      "venue" : "Language, Cognition and Neuroscience, 31(5):577–596.",
      "citeRegEx" : "Chow et al\\.,? 2016",
      "shortCiteRegEx" : "Chow et al\\.",
      "year" : 2016
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models",
      "author" : [ "Allyson Ettinger." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 8:34–48.",
      "citeRegEx" : "Ettinger.,? 2020",
      "shortCiteRegEx" : "Ettinger.",
      "year" : 2020
    }, {
      "title" : "A rose by any other name: Long-term memory structure and sentence processing",
      "author" : [ "Kara D Federmeier", "Marta Kutas." ],
      "venue" : "Journal of memory and Language, 41(4):469–495.",
      "citeRegEx" : "Federmeier and Kutas.,? 1999",
      "shortCiteRegEx" : "Federmeier and Kutas.",
      "year" : 1999
    }, {
      "title" : "The ERP response to the amount of information conveyed by words in sentences",
      "author" : [ "Stefan L Frank", "Leun J Otten", "Giulia Galli", "Gabriella Vigliocco." ],
      "venue" : "Brain and language, 140:1–11.",
      "citeRegEx" : "Frank et al\\.,? 2015",
      "shortCiteRegEx" : "Frank et al\\.",
      "year" : 2015
    }, {
      "title" : "FRAGE: Frequencyagnostic word representation",
      "author" : [ "Chengyue Gong", "Di He", "Xu Tan", "Tao Qin", "Liwei Wang", "Tie-Yan Liu." ],
      "venue" : "Advances in neural information processing systems, pages 1334–1345.",
      "citeRegEx" : "Gong et al\\.,? 2018",
      "shortCiteRegEx" : "Gong et al\\.",
      "year" : 2018
    }, {
      "title" : "Colorless green recurrent networks dream hierarchically",
      "author" : [ "Kristina Gulordava", "Piotr Bojanowski", "Édouard Grave", "Tal Linzen", "Marco Baroni." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Gulordava et al\\.,? 2018",
      "shortCiteRegEx" : "Gulordava et al\\.",
      "year" : 2018
    }, {
      "title" : "Intrinsic probing through dimension selection",
      "author" : [ "Lucas Torroba Hennigen", "Adina Williams", "Ryan Cotterell." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 197–216.",
      "citeRegEx" : "Hennigen et al\\.,? 2020",
      "shortCiteRegEx" : "Hennigen et al\\.",
      "year" : 2020
    }, {
      "title" : "A structural probe for finding syntax in word representations",
      "author" : [ "John Hewitt", "Christopher D Manning." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
      "citeRegEx" : "Hewitt and Manning.,? 2019",
      "shortCiteRegEx" : "Hewitt and Manning.",
      "year" : 2019
    }, {
      "title" : "A systematic assessment of syntactic generalization in neural language models",
      "author" : [ "Jennifer Hu", "Jon Gauthier", "Peng Qian", "Ethan Wilcox", "Roger Levy." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Hu et al\\.,? 2020",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2020
    }, {
      "title" : "Which sentence embeddings and which layers encode syntactic structure",
      "author" : [ "MA Kelly", "Yang Xu", "Jesús Calvillo", "David Reitter" ],
      "venue" : "In Cognitive Science,",
      "citeRegEx" : "Kelly et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Kelly et al\\.",
      "year" : 2020
    }, {
      "title" : "Do neural language models show preferences for syntactic formalisms",
      "author" : [ "Artur Kulmizev", "Vinit Ravishankar", "Mostafa Abdou", "Joakim Nivre" ],
      "venue" : "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Kulmizev et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Kulmizev et al\\.",
      "year" : 2020
    }, {
      "title" : "Thirty years and counting: finding meaning in the N400 component of the event-related brain potential (ERP)",
      "author" : [ "Marta Kutas", "Kara D Federmeier." ],
      "venue" : "Annual review of psychology, 62:621–647.",
      "citeRegEx" : "Kutas and Federmeier.,? 2011",
      "shortCiteRegEx" : "Kutas and Federmeier.",
      "year" : 2011
    }, {
      "title" : "Psycholinguistics electrified II (1994– 2005)",
      "author" : [ "Marta Kutas", "Cyma K Van Petten", "Robert Kluender." ],
      "venue" : "Handbook of psycholinguistics, pages 659–724. Elsevier.",
      "citeRegEx" : "Kutas et al\\.,? 2006",
      "shortCiteRegEx" : "Kutas et al\\.",
      "year" : 2006
    }, {
      "title" : "A matter of framing: The impact of linguistic formalism on probing results",
      "author" : [ "Ilia Kuznetsov", "Iryna Gurevych." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 171–182. Association",
      "citeRegEx" : "Kuznetsov and Gurevych.,? 2020",
      "shortCiteRegEx" : "Kuznetsov and Gurevych.",
      "year" : 2020
    }, {
      "title" : "A simple unified framework for detecting outof-distribution samples and adversarial attacks",
      "author" : [ "Kimin Lee", "Kibok Lee", "Honglak Lee", "Jinwoo Shin." ],
      "venue" : "Advances in Neural Information Processing Systems, 31:7167–7177.",
      "citeRegEx" : "Lee et al\\.,? 2018",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2018
    }, {
      "title" : "100 million words of English: the British National Corpus (BNC)",
      "author" : [ "Geoffrey Neil Leech." ],
      "venue" : "Language Research, 28:1–13.",
      "citeRegEx" : "Leech.,? 1992",
      "shortCiteRegEx" : "Leech.",
      "year" : 1992
    }, {
      "title" : "RoBERTa: A robustly optimized BERT pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "How relevant are selectional preferences for Transformer-based language models",
      "author" : [ "Eleni Metheniti", "Tim Van de Cruys", "Nabil Hathout" ],
      "venue" : "In Proceedings of the 28th International Conference on Computational Linguistics,",
      "citeRegEx" : "Metheniti et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Metheniti et al\\.",
      "year" : 2020
    }, {
      "title" : "Linguistic profiling of a neural language model",
      "author" : [ "Alessio Miaschi", "Dominique Brunato", "Felice Dell’Orletta", "Giulia Venturi" ],
      "venue" : "The 28th International Conference on Computational Linguistics,",
      "citeRegEx" : "Miaschi et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Miaschi et al\\.",
      "year" : 2020
    }, {
      "title" : "How well does surprisal explain N400 amplitude under different experimental conditions",
      "author" : [ "James Michaelov", "Benjamin Bergen" ],
      "venue" : "In Proceedings of the 24th Conference on Computational Natural Language Learning,",
      "citeRegEx" : "Michaelov and Bergen.,? \\Q2020\\E",
      "shortCiteRegEx" : "Michaelov and Bergen.",
      "year" : 2020
    }, {
      "title" : "Eventrelated brain potentials elicited by failure to agree",
      "author" : [ "Lee Osterhout", "Linda A Mobley." ],
      "venue" : "Journal of Memory and language, 34(6):739–773.",
      "citeRegEx" : "Osterhout and Mobley.,? 1995",
      "shortCiteRegEx" : "Osterhout and Mobley.",
      "year" : 1995
    }, {
      "title" : "On the distinctiveness, independence, and time course of the brain responses to syntactic and semantic anomalies",
      "author" : [ "Lee Osterhout", "Janet Nicol." ],
      "venue" : "Language and cognitive processes, 14(3):283–317.",
      "citeRegEx" : "Osterhout and Nicol.,? 1999",
      "shortCiteRegEx" : "Osterhout and Nicol.",
      "year" : 1999
    }, {
      "title" : "Revisiting Mahalanobis distance for Transformerbased out-of-domain detection",
      "author" : [ "Alexander Podolskiy", "Dmitry Lipin", "Andrey Bout", "Ekaterina Artemova", "Irina Piontkovskaya." ],
      "venue" : "35th AAAI Conference on Artificial Intelligence (AAAI 2021).",
      "citeRegEx" : "Podolskiy et al\\.,? 2021",
      "shortCiteRegEx" : "Podolskiy et al\\.",
      "year" : 2021
    }, {
      "title" : "The usefulness of the grammaticality–acceptability distinction in functional approaches to language",
      "author" : [ "Mads Poulsen." ],
      "venue" : "Acta Linguistica Hafniensia, 44(1):4–21.",
      "citeRegEx" : "Poulsen.,? 2012",
      "shortCiteRegEx" : "Poulsen.",
      "year" : 2012
    }, {
      "title" : "An MEG study of silent meaning",
      "author" : [ "Liina Pylkkänen", "Brian McElree." ],
      "venue" : "Journal of cognitive neuroscience, 19(11):1905–1921.",
      "citeRegEx" : "Pylkkänen and McElree.,? 2007",
      "shortCiteRegEx" : "Pylkkänen and McElree.",
      "year" : 2007
    }, {
      "title" : "Say anything: Automatic semantic infelicity detection in L2 English indefinite pronouns",
      "author" : [ "Ella Rabinovich", "Julia Watson", "Barend Beekhuizen", "Suzanne Stevenson." ],
      "venue" : "Proceedings of the 23rd Conference on Computational Natural Language Learn-",
      "citeRegEx" : "Rabinovich et al\\.,? 2019",
      "shortCiteRegEx" : "Rabinovich et al\\.",
      "year" : 2019
    }, {
      "title" : "A primer in BERTology: What we know about how BERT works",
      "author" : [ "Anna Rogers", "Olga Kovaleva", "Anna Rumshisky." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 8:842–866.",
      "citeRegEx" : "Rogers et al\\.,? 2021",
      "shortCiteRegEx" : "Rogers et al\\.",
      "year" : 2021
    }, {
      "title" : "Masked language model scoring",
      "author" : [ "Julian Salazar", "Davis Liang", "Toan Q. Nguyen", "Katrin Kirchhoff." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2699–2712. Association for Computa-",
      "citeRegEx" : "Salazar et al\\.,? 2020",
      "shortCiteRegEx" : "Salazar et al\\.",
      "year" : 2020
    }, {
      "title" : "Investigating word-class distributions in word vector spaces",
      "author" : [ "Ryohei Sasano", "Anna Korhonen." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3657–3666.",
      "citeRegEx" : "Sasano and Korhonen.,? 2020",
      "shortCiteRegEx" : "Sasano and Korhonen.",
      "year" : 2020
    }, {
      "title" : "Support vector method for novelty detection",
      "author" : [ "Bernhard Schölkopf", "Robert C Williamson", "Alex J Smola", "John Shawe-Taylor", "John C Platt." ],
      "venue" : "Advances in neural information processing systems, pages 582–588.",
      "citeRegEx" : "Schölkopf et al\\.,? 2000",
      "shortCiteRegEx" : "Schölkopf et al\\.",
      "year" : 2000
    }, {
      "title" : "BERT rediscovers the classical NLP pipeline",
      "author" : [ "Ian Tenney", "Dipanjan Das", "Ellie Pavlick." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4593– 4601.",
      "citeRegEx" : "Tenney et al\\.,? 2019",
      "shortCiteRegEx" : "Tenney et al\\.",
      "year" : 2019
    }, {
      "title" : "Quantifiers more or less quantify on-line: ERP evidence for partial incremental interpretation",
      "author" : [ "Thomas P Urbach", "Marta Kutas." ],
      "venue" : "Journal of Memory and Language, 63(2):158–179.",
      "citeRegEx" : "Urbach and Kutas.,? 2010",
      "shortCiteRegEx" : "Urbach and Kutas.",
      "year" : 2010
    }, {
      "title" : "Comprehending the impossible: what role do selectional restriction violations play? Language, cognition and neuroscience, 30(8):932–939",
      "author" : [ "Tessa Warren", "Evelyn Milburn", "Nikole D Patson", "Michael Walsh Dickey" ],
      "venue" : null,
      "citeRegEx" : "Warren et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Warren et al\\.",
      "year" : 2015
    }, {
      "title" : "BLiMP: The benchmark of linguistic minimal pairs for English",
      "author" : [ "Alex Warstadt", "Alicia Parrish", "Haokun Liu", "Anhad Mohananey", "Wei Peng", "Sheng-Fu Wang", "Samuel R Bowman." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 8:377–",
      "citeRegEx" : "Warstadt et al\\.,? 2020",
      "shortCiteRegEx" : "Warstadt et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural network acceptability judgments",
      "author" : [ "Alex Warstadt", "Amanpreet Singh", "Samuel R Bowman." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 7:625–641.",
      "citeRegEx" : "Warstadt et al\\.,? 2019",
      "shortCiteRegEx" : "Warstadt et al\\.",
      "year" : 2019
    }, {
      "title" : "Transformers: State-of-theart natural language processing",
      "author" : [ "Thomas Wolf", "Julien Chaumond", "Lysandre Debut", "Victor Sanh", "Clement Delangue", "Anthony Moi", "Pierric Cistac", "Morgan Funtowicz", "Joe Davison", "Sam Shleifer" ],
      "venue" : null,
      "citeRegEx" : "Wolf et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Wolf et al\\.",
      "year" : 2020
    }, {
      "title" : "XLNet: Generalized autoregressive pretraining for language understanding",
      "author" : [ "Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime Carbonell", "Russ R Salakhutdinov", "Quoc V Le." ],
      "venue" : "Advances in neural information processing systems, pages 5753–5763.",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "A popular approach is to formulate the problem as a multiple-choice task, where the LM is considered correct if it assigns higher likelihood to the appropriate word than an inappropriate one, given context (Gulordava et al., 2018; Ettinger, 2020; Warstadt et al., 2020).",
      "startOffset" : 206,
      "endOffset" : 269
    }, {
      "referenceID" : 6,
      "context" : "A popular approach is to formulate the problem as a multiple-choice task, where the LM is considered correct if it assigns higher likelihood to the appropriate word than an inappropriate one, given context (Gulordava et al., 2018; Ettinger, 2020; Warstadt et al., 2020).",
      "startOffset" : 206,
      "endOffset" : 269
    }, {
      "referenceID" : 38,
      "context" : "A popular approach is to formulate the problem as a multiple-choice task, where the LM is considered correct if it assigns higher likelihood to the appropriate word than an inappropriate one, given context (Gulordava et al., 2018; Ettinger, 2020; Warstadt et al., 2020).",
      "startOffset" : 206,
      "endOffset" : 269
    }, {
      "referenceID" : 17,
      "context" : ", semantic anomalies produce negative ERPs 400 ms after the stimulus, while syntactic anomalies produce positive ERPs 600 ms after (Kutas et al., 2006).",
      "startOffset" : 131,
      "endOffset" : 151
    }, {
      "referenceID" : 5,
      "context" : "4216 In this paper, we introduce a new tool to probe for surprisal at intermediate layers of BERT (Devlin et al., 2019), RoBERTa (Liu et al.",
      "startOffset" : 98,
      "endOffset" : 119
    }, {
      "referenceID" : 21,
      "context" : ", 2019), RoBERTa (Liu et al., 2019), and XLNet (Yang et al.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 41,
      "context" : ", 2019), and XLNet (Yang et al., 2019), formulating the problem as density estimation.",
      "startOffset" : 19,
      "endOffset" : 38
    }, {
      "referenceID" : 38,
      "context" : "Using BLiMP (Warstadt et al., 2020) for evaluation, we show that this model is effective at grammaticality judgement, requiring only a small amount of in-domain text for training.",
      "startOffset" : 12,
      "endOffset" : 35
    }, {
      "referenceID" : 31,
      "context" : ", Rogers et al. (2021) provides a comprehensive overview).",
      "startOffset" : 2,
      "endOffset" : 23
    }, {
      "referenceID" : 31,
      "context" : ", Rogers et al. (2021) provides a comprehensive overview). Tenney et al. (2019) used “edge probing” to determine each layer’s contribution to a task’s performance, and discovered that the middle layers contributed more when the task was syntactic, and the upper layers more when the task was semantic.",
      "startOffset" : 2,
      "endOffset" : 80
    }, {
      "referenceID" : 13,
      "context" : "Kelly et al. (2020) found that BERT’s middle layers are best at distinguishing between sentences with direct and indirect object constructions.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 12,
      "context" : "Hewitt and Manning (2019) used a structural probe to recover syntax trees from contextual embeddings, and found the performance peaked in middle layers.",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 12,
      "context" : "Hewitt and Manning (2019) used a structural probe to recover syntax trees from contextual embeddings, and found the performance peaked in middle layers. Probing results are somewhat dependent on the choice of linguistic formalism used to annotate the data, as Kulmizev et al. (2020) found for syntax, and Kuznetsov and Gurevych (2020) found for semantic roles.",
      "startOffset" : 0,
      "endOffset" : 283
    }, {
      "referenceID" : 12,
      "context" : "Hewitt and Manning (2019) used a structural probe to recover syntax trees from contextual embeddings, and found the performance peaked in middle layers. Probing results are somewhat dependent on the choice of linguistic formalism used to annotate the data, as Kulmizev et al. (2020) found for syntax, and Kuznetsov and Gurevych (2020) found for semantic roles. Miaschi et al. (2020) examined the layerwise performance of BERT for a suite of linguistic features, before and after fine tuning.",
      "startOffset" : 0,
      "endOffset" : 383
    }, {
      "referenceID" : 38,
      "context" : "More commonly, the model is presented with a binary choice between an acceptable and unacceptable sentence: BLiMP (Warstadt et al., 2020) used templates to generate 67k such sentence pairs, covering 12 types of linguistic phenomena.",
      "startOffset" : 114,
      "endOffset" : 137
    }, {
      "referenceID" : 35,
      "context" : "Warstadt et al. (2019) gathered sentences from linguistic publications, and evaluated by Matthews Correlation with the ground truth.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 12,
      "context" : "Similarly, Hu et al. (2020) created syntactic tests using templates, but defined success criteria using inequalities of LM perplexities.",
      "startOffset" : 11,
      "endOffset" : 28
    }, {
      "referenceID" : 10,
      "context" : "In contrast with artificial templates, Gulordava et al. (2018) generated test cases by perturbing natural corpus data to test long-distance dependencies.",
      "startOffset" : 39,
      "endOffset" : 63
    }, {
      "referenceID" : 10,
      "context" : "In contrast with artificial templates, Gulordava et al. (2018) generated test cases by perturbing natural corpus data to test long-distance dependencies. Most grammaticality studies focused on syntactic phenomena, but Rabinovich et al. (2019) tested LMs’ sensitivity to semantic infelicities involving indefinite pronouns.",
      "startOffset" : 39,
      "endOffset" : 243
    }, {
      "referenceID" : 31,
      "context" : "Sasano and Korhonen (2020) examined the geometry of word classes (e.",
      "startOffset" : 0,
      "endOffset" : 27
    }, {
      "referenceID" : 2,
      "context" : "Chersoni et al. (2018) tested distributional semantic models on their ability to identify selectional restriction violations using stimuli from two psycholinguistic datasets.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 2,
      "context" : "Chersoni et al. (2018) tested distributional semantic models on their ability to identify selectional restriction violations using stimuli from two psycholinguistic datasets. Finally, Metheniti et al. (2020) tested how much BERT relies on selectional restriction information versus other contextual information for making masked word predictions.",
      "startOffset" : 0,
      "endOffset" : 208
    }, {
      "referenceID" : 16,
      "context" : "4217 respect to the preceding context (Kutas and Federmeier, 2011).",
      "startOffset" : 38,
      "endOffset" : 66
    }, {
      "referenceID" : 7,
      "context" : "Frank et al. (2015) found that the N400 response is correlated with surprisal, i.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 7,
      "context" : "Frank et al. (2015) found that the N400 response is correlated with surprisal, i.e., how unlikely an LM predicts a word given the preceding context. Recently, several studies have investigated relationships between surprisal in neural LMs and the N400 response. Michaelov and Bergen (2020) compared human N400 amplitudes with LSTM-based models using stimuli from several psycholinguistic studies.",
      "startOffset" : 0,
      "endOffset" : 290
    }, {
      "referenceID" : 6,
      "context" : "Ettinger (2020) used data from three psycholinguistic studies to probe BERT’s knowledge of commonsense and negation.",
      "startOffset" : 0,
      "endOffset" : 16
    }, {
      "referenceID" : 17,
      "context" : "Various methods based on Mahalanobis distance have been used for anomaly detection in neural networks; for example, Lee et al. (2018) proposed a similar method for out-of-domain detection in neural classification models, and Cao et al.",
      "startOffset" : 116,
      "endOffset" : 134
    }, {
      "referenceID" : 1,
      "context" : "(2018) proposed a similar method for out-of-domain detection in neural classification models, and Cao et al. (2020) found the Mahalanobis distance method to be competitive with more sophisticated methods on medical out-of-domain detection.",
      "startOffset" : 98,
      "endOffset" : 116
    }, {
      "referenceID" : 1,
      "context" : "(2018) proposed a similar method for out-of-domain detection in neural classification models, and Cao et al. (2020) found the Mahalanobis distance method to be competitive with more sophisticated methods on medical out-of-domain detection. In Transformer models, Podolskiy et al. (2021) used Mahalanobis distance for out-of-domain detection, outperforming methods based on softmax probability and likelihood ratios.",
      "startOffset" : 98,
      "endOffset" : 287
    }, {
      "referenceID" : 1,
      "context" : "(2018) proposed a similar method for out-of-domain detection in neural classification models, and Cao et al. (2020) found the Mahalanobis distance method to be competitive with more sophisticated methods on medical out-of-domain detection. In Transformer models, Podolskiy et al. (2021) used Mahalanobis distance for out-of-domain detection, outperforming methods based on softmax probability and likelihood ratios. Gaussian assumptions. Our model assumes that the embeddings at every layer follow a multivariate Gaussian distribution. Since the Gaussian distribution is the maximum entropy distribution given a mean and covariance matrix, it makes the fewest assumptions and is therefore a reasonable default. Hennigen et al. (2020) found that embeddings sometimes do not follow a Gaussian distribution, but it is unclear what alternative distribution would be a better fit, so we will assume a Gaussian distribution in this work.",
      "startOffset" : 98,
      "endOffset" : 734
    }, {
      "referenceID" : 5,
      "context" : "For all of our experiments, we use the ‘base’ versions of pretrained language models BERT (Devlin et al., 2019), RoBERTa (Liu et al.",
      "startOffset" : 90,
      "endOffset" : 111
    }, {
      "referenceID" : 41,
      "context" : "XLNet (Yang et al., 2019), provided by HuggingFace (Wolf et al.",
      "startOffset" : 6,
      "endOffset" : 25
    }, {
      "referenceID" : 20,
      "context" : "We train the Gaussian model on randomly selected sentences from the British National Corpus (Leech, 1992), representative of acceptable English text from various genres.",
      "startOffset" : 92,
      "endOffset" : 105
    }, {
      "referenceID" : 38,
      "context" : "We evaluate on BLiMP (Warstadt et al., 2020), a dataset of 67k minimal sentence pairs that test acceptability judgements across a variety of syntactic and semantic phenomena.",
      "startOffset" : 21,
      "endOffset" : 44
    }, {
      "referenceID" : 34,
      "context" : "In Appendix A, we explore variations of the Gaussian anomaly model, such as varying the type of covariance matrix, Gaussian mixture models, and one-class SVMs (Schölkopf et al., 2000).",
      "startOffset" : 159,
      "endOffset" : 183
    }, {
      "referenceID" : 20,
      "context" : "We train the Gaussian model on randomly selected sentences from the British National Corpus (Leech, 1992), representative of acceptable English text from various genres. We evaluate on BLiMP (Warstadt et al., 2020), a dataset of 67k minimal sentence pairs that test acceptability judgements across a variety of syntactic and semantic phenomena. In our case, a sentence pair is considered correct if the sentence-level surprisal of the unacceptable sentence is higher than that of the acceptable sentence. How much training data is needed? We experiment with training data sizes ranging from 10 to 10,000 sentences (Figure 2a). Compared to the massive amount of data needed for pretraining the LMs, we find that a modest corpus suffices for training the Gaussian anomaly model, and a plateau is reached after 1000 sentences for all three models. Therefore, we use 1000 training sentences (unless otherwise noted) for all subsequent experiments in this paper. Which layers are sensitive to anomaly? We vary L from 0 to 12 in all three models (Figure 2b). The layer with the highest accuracy differs between models: layer 9 has the highest accuracy for BERT, 11 for RoBERTa, and 6 for XLNet. All models experience a sharp drop in the last layer, likely because the last layer is specialized for the MLM pretraining objective. Comparisons to other models. Our bestperforming model is RoBERTa, with an accuracy of 0.830. This is slightly higher the best model reported in BLiMP (GPT-2, with accuracy 0.801). We do not claim to beat the state-of-the-art on BLiMP: Salazar et al. (2020) obtains a higher accuracy of 0.",
      "startOffset" : 93,
      "endOffset" : 1580
    }, {
      "referenceID" : 9,
      "context" : "For static word vectors, Gong et al. (2018) found that embeddings for low-frequency words lie in a different region of",
      "startOffset" : 25,
      "endOffset" : 44
    }, {
      "referenceID" : 0,
      "context" : ", Abrusán (2019) gives a survey of current proposals), and Poulsen (2012) challenges this dichotomy entirely.",
      "startOffset" : 2,
      "endOffset" : 17
    }, {
      "referenceID" : 0,
      "context" : ", Abrusán (2019) gives a survey of current proposals), and Poulsen (2012) challenges this dichotomy entirely.",
      "startOffset" : 2,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : ", Abrusán (2019) gives a survey of current proposals), and Poulsen (2012) challenges this dichotomy entirely. Similarly, Warren et al. (2015) noted that semantic anomalies depend somewhat on world knowledge.",
      "startOffset" : 2,
      "endOffset" : 142
    }, {
      "referenceID" : 38,
      "context" : "BLiMP (Warstadt et al., 2020): we use subject-verb and determiner-noun agreement tests as morphosyntactic anomaly tasks.",
      "startOffset" : 6,
      "endOffset" : 29
    }, {
      "referenceID" : 2,
      "context" : "Chersoni et al. (2018) used the data from Pylkkänen and McElree (2007) and Warren et al.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 2,
      "context" : "Chersoni et al. (2018) used the data from Pylkkänen and McElree (2007) and Warren et al. (2015) to probe word vectors for knowledge of selectional restrictions.",
      "startOffset" : 0,
      "endOffset" : 96
    }, {
      "referenceID" : 2,
      "context" : "Chersoni et al. (2018) used the data from Pylkkänen and McElree (2007) and Warren et al. (2015) to probe word vectors for knowledge of selectional restrictions. Ettinger (2020) used data from Federmeier and Kutas (1999) and Chow et al.",
      "startOffset" : 0,
      "endOffset" : 177
    }, {
      "referenceID" : 2,
      "context" : "Chersoni et al. (2018) used the data from Pylkkänen and McElree (2007) and Warren et al. (2015) to probe word vectors for knowledge of selectional restrictions. Ettinger (2020) used data from Federmeier and Kutas (1999) and Chow et al. (2016), which were referred to as CPRAG-102 and ROLE-88 respectively.",
      "startOffset" : 0,
      "endOffset" : 243
    }, {
      "referenceID" : 37,
      "context" : "Commonsense Warren et al. (2015) Corey’s hamster explored a nearby backpack and filled it with sawdust.",
      "startOffset" : 12,
      "endOffset" : 33
    }, {
      "referenceID" : 26,
      "context" : "Osterhout and Nicol (1999): contains 90 sentence triplets containing a control, syntactic, and semantic anomaly.",
      "startOffset" : 0,
      "endOffset" : 27
    }, {
      "referenceID" : 29,
      "context" : "Pylkkänen and McElree (2007): contains 70 sentence pairs where the verb is replaced in the anomalous sentence with one that requires an animate object, thus violating the selectional restriction.",
      "startOffset" : 0,
      "endOffset" : 29
    }, {
      "referenceID" : 37,
      "context" : "Warren et al. (2015): contains 30 sentence triplets with a possible condition, a selectional restriction violation between the subject and verb, and an impossible condition where the subject cannot carry out the action, i.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 25,
      "context" : "Osterhout and Mobley (1995): we use data from experiment 2, containing 90 sentence pairs where the verb in the anomalous sentence is semantically inappropriate.",
      "startOffset" : 0,
      "endOffset" : 28
    }, {
      "referenceID" : 7,
      "context" : "Federmeier and Kutas (1999): contains 34 sentence pairs, where the final noun in each anomalous sentence is an inappropriate completion, but in the same semantic category as the expected completion.",
      "startOffset" : 0,
      "endOffset" : 28
    }, {
      "referenceID" : 4,
      "context" : "Chow et al. (2016): contains 44 sentence pairs, where two of the nouns in the anomalous sentence are swapped to reverse their roles.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 36,
      "context" : "Urbach and Kutas (2010): contains 120 sentence pairs, where the anomalous sentence replaces a patient of the verb with an atypical one.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 4,
      "context" : "The MLM results for Chow et al. (2016) are excluded because the control and anomalous sentences differ by more than one token.",
      "startOffset" : 20,
      "endOffset" : 39
    }, {
      "referenceID" : 35,
      "context" : "anomalies is consistent with previous work (Tenney et al., 2019), which found that syntactic information appeared earlier in BERT than semantic information.",
      "startOffset" : 43,
      "endOffset" : 64
    }, {
      "referenceID" : 17,
      "context" : "A similar situation occurred in psycholinguistics research (Kutas et al., 2006): early results suggested that the N400 was triggered by semantic anomalies, while syntactic anomalies triggered the P600 – a different type of ERP.",
      "startOffset" : 59,
      "endOffset" : 79
    }, {
      "referenceID" : 16,
      "context" : "However, subsequent experiments found exceptions to this rule, and now it is believed that the N400 cannot be categorized by any standard dichotomy, like syntax versus semantics (Kutas and Federmeier, 2011).",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 16,
      "context" : "However, subsequent experiments found exceptions to this rule, and now it is believed that the N400 cannot be categorized by any standard dichotomy, like syntax versus semantics (Kutas and Federmeier, 2011). In our case, Pylkkänen and McElree (2007) is an exception: the task is a semantic anomaly, but produces surprisals in early layers, similar to the morphosyntactic tasks.",
      "startOffset" : 179,
      "endOffset" : 250
    }, {
      "referenceID" : 36,
      "context" : "MLM generally outperforms GM, but it does not solve every task: all three LMs fail to perform above chance on the data from Warren et al. (2015). This set of stimuli was designed so that both the control and impossible completions are not very likely or expected, which may have caused the difficulty for the LMs.",
      "startOffset" : 124,
      "endOffset" : 145
    }, {
      "referenceID" : 4,
      "context" : "We excluded the task of Chow et al. (2016) for MLM because the control and anomalous sentences differed by more than one token(2).",
      "startOffset" : 24,
      "endOffset" : 43
    }, {
      "referenceID" : 32,
      "context" : "For example, Salazar et al. (2020) proposed a modification to MLM to handle such cases: they compute a pseudolog-likelihood score for a sequence by replacing one token at a time with a [MASK] token, applying MLM to each masked sequence, and summing up the log likelihood scores.",
      "startOffset" : 13,
      "endOffset" : 35
    } ],
    "year" : 2021,
    "abstractText" : "Transformer language models have shown remarkable ability in detecting when a word is anomalous in context, but likelihood scores offer no information about the cause of the anomaly. In this work, we use Gaussian models for density estimation at intermediate layers of three language models (BERT, RoBERTa, and XLNet), and evaluate our method on BLiMP, a grammaticality judgement benchmark. In lower layers, surprisal is highly correlated to low token frequency, but this correlation diminishes in upper layers. Next, we gather datasets of morphosyntactic, semantic, and commonsense anomalies from psycholinguistic studies; we find that the best performing model RoBERTa exhibits surprisal in earlier layers when the anomaly is morphosyntactic than when it is semantic, while commonsense anomalies do not exhibit surprisal at any intermediate layer. These results suggest that language models employ separate mechanisms to detect different types of linguistic anomalies.",
    "creator" : "LaTeX with hyperref"
  }
}