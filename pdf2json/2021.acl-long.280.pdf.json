{
  "name" : "2021.acl-long.280.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "BERT is to NLP what AlexNet is to CV: Can Pre-Trained Language Models Identify Analogies?",
    "authors" : [ "Asahi Ushio", "Luis Espinosa-Anke", "Steven Schockaert", "Jose Camacho-Collados" ],
    "emails" : [ "UshioA@cardiff.ac.uk", "Espinosa-AnkeL@cardiff.ac.uk", "SchockaertS1@cardiff.ac.uk", "CamachoColladosJ@cardiff.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3609–3624\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3609"
    }, {
      "heading" : "1 Introduction",
      "text" : "One of the most widely discussed properties of word embeddings has been their surprising ability to model certain types of relational similarities in terms of word vector differences (Mikolov\nWhile the title is probably self-explanatory, this is a small note explaining it. BERT is to NLP what AlexNet is to CV is making an analogy on what the BERT and AlexNet models represented for Natural Language Processing (NLP) and Computer Vision (CV), respectively. They both brought a paradigm shift in how research was undertaken in their corresponding disciplines and this is what the analogy refers to.\n1Source code and data to reproduce our experimental results are available in the following repository: https://github.com/asahi417/ analogy-language-model\net al., 2013a; Vylomova et al., 2016; Allen and Hospedales, 2019; Ethayarajh et al., 2019). The underlying assumption is that when “a is to b what c is to d” the word vector differences b − a and d− c are expected to be similar, where we write x for the embedding of a word x. While this assumption holds for some types of syntactic relations, for semantic relations this holds to a much more limited degree than was suggested in early work (Linzen, 2016; Schluter, 2018). Moreover, the most commonly used benchmarks have focused on specific and well-defined semantic relations such as “capital of”, rather than the more abstract notion of relational similarity that is often needed for solving the kind of psychometric analogy problems that can be found in IQ tests and educational settings. An example of such a problem is shown in Table 1.\nGiven the central role of analogy in human cognition, it is nonetheless important to understand the extent to which NLP models are able to solve these more abstract analogy problems. Besides its value as an intrinsic benchmark for lexical semantics, the ability to recognize analogies is indeed important in the contexts of human creativity (Holyoak et al., 1996), innovation (Hope et al., 2017), computational creativity (Goel, 2019) and education (Pardos and Nam, 2020). Analogies are also a prerequisite to build AI systems for the legal domain (Ashley, 1988; Walton, 2010) and are used in machine learning (Miclet et al., 2008; Hug et al.,\n2016; Hüllermeier, 2020) and for ontology alignment (Raad and Evermann, 2015), among others.\nWithin NLP, however, the task of recognizing analogies has received relatively little attention. To solve such problems, Turney (2005) proposed Latent Relational Analysis (LRA), which was essentially designed as a relational counterpart to Latent Semantic Analysis (Landauer and Dumais, 1997). Somewhat surprisingly, perhaps, despite the substantial progress that word embeddings and language models (LMs) have enabled in NLP, LRA still represents the current state-of-the-art in solving abstract word analogy problems. When going beyond a purely unsupervised setting, however, GPT-3 was recently found to obtain slightly better results (Brown et al., 2020).\nThe aim of this paper is to analyze the ability of pre-trained LMs to recognize analogies. Our focus is on the zero-shot setting, where LMs are used without fine-tuning. To predict whether two word pairs (a, b) and (c, d) are likely to be analogical, we need a prompt, i.e. a template that is used to construct the input to the LM, and a scoring function. We extensively analyze the impact of both of these choices, as well as the differences between different LMs. When the prompt and scoring function are carefully calibrated, we find that GPT-2 can outperform LRA, standard word embeddings as well as the published results for GPT-3 in the zero-shot setting. However, we also find that these results are highly sensitive to the choice of the prompt, as well as two hyperparameters in our scoring function, with the optimal choices not being consistent across different datasets. Moreover, using BERT leads to considerably weaker results, underperforming even standard word embeddings in all of the considered configurations. These findings suggest that while transformer-based LMs learn relational knowledge to a meaningful extent, more work is needed to understand how such knowledge is encoded, and how it can be exploited."
    }, {
      "heading" : "2 Related work",
      "text" : ""
    }, {
      "heading" : "2.1 Understanding Pre-trained LMs",
      "text" : "Since their recent dominance in standard NLP benchmarks (Peters et al., 2018a; Devlin et al., 2019; Liu et al., 2019), pre-trained language models have been extensively studied. This has mainly been done through probing tasks, which are aimed at understanding the knowledge that is implicitly captured by their parameters. After the initial focus\non understanding pre-trained LSTM-based LMs (Peters et al., 2018b), attention has now shifted toward transformer-based models. The main aspects that have been studied in recent years are syntax (Goldberg, 2019; Saphra and Lopez, 2019; Hewitt and Manning, 2019; van Schijndel et al., 2019; Jawahar et al., 2019; Tenney et al., 2019b) and semantics (Ettinger, 2019; Tenney et al., 2019a). For a more complete overview on analyses of the different properties of transformer-based LMs, we refer to Rogers et al. (2021).\nDespite the rise in probing analyses for LMs and the importance of analogical reasoning in human cognition, understanding the analogical capabilities of LMs remains understudied. The most similar works have focused on capturing relational knowledge from LMs (in particular the type of information available in knowledge graphs). For instance, Petroni et al. (2019) analyzed to what extent LMs could fill manually-defined templates such as “Dante was born in [MASK]”. Follow-up works extended this initial approach by automatically generating templates and fine-tuning LMs on them (Bouraoui et al., 2020; Jiang et al., 2020), showing an improved performance. In this paper, we focus on the analogical knowledge that is encoded in pre-trained LMs, without the extra step of fine-tuning on additional data."
    }, {
      "heading" : "2.2 Word Analogy Probing",
      "text" : "Word analogies have been used as a standard intrinsic evaluation task for measuring the quality of word embeddings. Mikolov et al. (2013b) showed that word embeddings, in particular Word2vec embeddings, were able to solve analogy problems by simple vector operations (e.g. king - man + woman = queen). The motivation for this task dates back to the connectionism theory (Feldman and Ballard, 1982) in cognitive science. In particular, neural networks were thought to be able to model emergent concepts (Hopfield, 1982; Hinton, 1986) by learning distributed representations across an embedding space (Hinton et al., 1986), similar to the properties that word embeddings displayed in the analogy task. More recent works have proposed new mathematical theories and experiments to understand the analogical capabilities of word embeddings, attempting to understand their linear algebraic structure (Arora et al., 2016; Gittens et al., 2017; Allen and Hospedales, 2019) or by explicitly studying their compositional nature (Levy and\nGoldberg, 2014; Paperno and Baroni, 2016; Ethayarajh et al., 2019; Chiang et al., 2020).\nHowever, recent works have questioned the impressive results displayed by word embeddings in this task. In many cases simple baselines excluding the input pair (or query) were competitive (Linzen, 2016). Simultaneously, some researchers have found that many relationships may not be retrieved in the embedding space by simple linear transformations (Drozd et al., 2016; Bouraoui et al., 2018) and others argued that the standard evaluation procedure has limitations (Schluter, 2018). New datasets and measures have also been introduced to address some of these issues (Gladkova et al., 2016; Fournier et al., 2020). Finally, in the context of bias detection, for which analogies have been used as a proxy (Bolukbasi et al., 2016), it has also been found that word analogies may misguide or hide the real relationships existing in the vector space (Gonen and Goldberg, 2019; Nissim et al., 2020).\nAs far as language models are concerned, word analogies have not been explored to the same extent as for word embeddings. Recently, Brown et al. (2020) evaluated the unsupervised capabilities of GPT-3 by evaluating it on the SAT analogies dataset (Turney et al., 2003), which we also include in our evaluation (see Section 3.2). However, the evaluation is limited to a single dataset (i.e., SAT) and model (i.e., GPT-3), and the general capabilities of language models were not investigated.\nDespite their limitations, analogy tests remain appealing for evaluating the ability of embeddings and language models to identify abstract relationships. To mitigate the aforementioned methodological issues, in this work we rely on analogy tests from educational resources, where the task is to complete analogical proportions, given only the first word pair. In contrast, word embedding models have mostly been evaluated using a predictive task, in which three of the four words are given. Moreover, the considered datasets are focused on abstract analogies, whereas the most commonly used datasets only include well-defined semantic relations such as “capital of”. For completeness, however, we also show results on these standard datasets. We furthermore experiment with several simple baselines to understand possible artifacts present in the different datasets."
    }, {
      "heading" : "3 Word Analogies",
      "text" : "In this section, we describe the word analogy formulation that is used for our experiments (Section 3.1). Subsequently, we provide an overview of the datasets used in our experiments (Section 3.2)."
    }, {
      "heading" : "3.1 Task Description",
      "text" : "We frame the analogy task in terms of analogical proportions (Prade and Richard, 2017). Given a query word pair (hq, tq) and a list of candidate answer pairs {(hi, ti)}ni=1, the goal is to find the candidate answer pair that has the most similar relation to the query pair. Table 1 shows a sample query and candidate answers drawn from one of the datasets used in our evaluation (see Section 3.2)."
    }, {
      "heading" : "3.2 Analogy Datasets",
      "text" : "We split analogy datasets in two types, based on how the analogy problems were constructed."
    }, {
      "heading" : "3.2.1 Psychometric Analogy Tests",
      "text" : "Word analogy tests are commonly used in assessments of linguistic and cognitive ability. For instance, in the past, such tests were included in the SAT exams, which are a US college admission test. Turney et al. (2003) collected a benchmark of 374 word analogy problems, consisting primarily of problems from these SAT tests. Aimed at college applicants, these problems are designed to be challenging for humans. A key challenge for NLP systems is that solving these problems often requires identifying fine-grained semantic differences between word pairs that belong to the same coarse-grained relation. For instance, in the case of Table 1, we could say that “a year consists of weeks” like “language consists of words”, but the week-year pair is nonetheless less similar to wordlanguage than note-music.\nAnother analogy benchmark was constructed by Boteanu and Chernova (2015), who used word analogy problems from an educational resource2. They used in particular UNIT 2 of the analogy problems from the educational site. These problems have the same form as those from the SAT benchmark, but rather than college applicants, they are aimed at children in grades 4 to 12 from the US school system (i.e. from age 9 onwards). In this paper, we will also include this UNIT 2 benchmark. Moreover, we have collected another benchmark from\n2https://www.englishforeveryone.org/ Topics/Analogies.html\nthe UNIT 4 problems on the same website. These UNIT 4 problems are organised in 5 difficulty levels: high-beginning, low-intermediate, highintermediate, low-advanced and high-advanced. The low-advanced level is stated to be at the level of the SAT tests, whereas the high-advanced level is stated to be at the level of the GRE test (which is used for admission into graduate schools)."
    }, {
      "heading" : "3.2.2 Lexical Semantics Benchmarks",
      "text" : "Since the introduction of Word2vec (Mikolov et al., 2013a), the problem of modelling analogies has been commonly used as an intrinsic benchmark for word embedding models. However, the datasets that have been used in that context are focused on well-defined and relatively coarse-grained relations. The Google analogy dataset (Mikolov et al., 2013b) has been one of the most commonly used benchmarks for intrinsic evaluation of word embeddings. This dataset contains a mix of semantic and morphological relations such as capital-of and singular-plural, respectively. However, its coverage has been shown to be limiting, and BATS (Gladkova et al., 2016) was developed in an attempt to address its main shortcomings. BATS includes a larger number of concepts and relations, which are split into four categories: lexicographic, encyclopedic, and derivational and inflectional morphology.\nAs pointed out above, these datasets were tailored to the evaluation of word embeddings in a predictive setting. To provide an evaluation setting which is comparable to the benchmarks obtained from human analogy tests, we constructed word analogy problems from the Google and BATS datasets, by choosing for each correct analogy pair a number of negative examples. The resulting benchmark thus follows the same format as described in Section 3.1. To obtain sufficiently challenging negative examples, for each query pair (e.g. Paris-France) we extracted three negative in-\nstances: (1) two random words from the head of the input relation type (e.g. Rome-Oslo); (2) two random words from the tail of the input relation type (e.g. Germany-Canada); (3) a random word pair from a relation type of the same high-level category as the input relation type (e.g. Argentina-peso).3"
    }, {
      "heading" : "3.2.3 Unification and Statistics",
      "text" : "Table 2 provides an overview of our datasets. The instances from each dataset are organised into groups. In the case of Google and BATS, these groups refer to the relation types (e.g. semantic or morphological in the case of Google). In the case of UNIT 2 and UNIT 4, the groups refer to the difficulty level. For the SAT dataset, we consider two groups, capturing whether the instances come from an actual SAT test or not. Finally, we randomly sample 10% of each group in each dataset to construct a validation set, and regard the remaining data as the test set."
    }, {
      "heading" : "4 Methodology",
      "text" : "In this section, we explain our strategy for using pretrained LMs to solve analogy problems without fine-tuning. First, in Section 4.1 we explain how each relation pair is converted into a natural sentence to be fed into the LM. In Section 4.2, we then discuss a number of scoring functions that can be used to select the most plausible answer candidate. Finally, we take advantage of the fact that analogical proportion is invariant to particular permutations, which allows for a natural extension of the proposed scoring functions (Section 4.3). Figure 1 shows a high-level overview of our methodology."
    }, {
      "heading" : "4.1 Relation Pair Prompting",
      "text" : "We define a prompting function Tt(w1, w2, w3, w4) that takes four placeholders and a template type t,\n3In order to avoid adding various correct answers to the query, we avoided adding negative pairs from all country-of type relations, and from similar lexicographic relations in the BATS dataset with more than one relation type, namely antonyms, synonyms, meronyms and hyponyms.\nand returns a sentence in which the placeholders were replaced by the words w1, w2, w3, and w4. For instance, given a query “word:language” and a candidate “note:music”, the prompting function produces\nTto-as(“word”, “language”, “note”, “music”) = “word is to language as note is to music”\nwhere we use the template type to-as here. Using manually specified template types can result in a sub-optimal textual representation. For this reason, recent studies have proposed autoprompting strategies, which optimize the template type on a training set (Shin et al., 2020), paraphrasing (Jiang et al., 2020), additional prompt generation model (Gao et al., 2020), and corpus-driven template mining (Bouraoui et al., 2020). However, none of these approaches can be applied to unsupervised settings. Thus, we do not explore auto-prompting methods in this work. Instead, we will consider a number of different template types in the experiments, and assess the sensitivity of the results to the choice of template type."
    }, {
      "heading" : "4.2 Scoring Function",
      "text" : "Perplexity. We first define perplexity, which is widely used as a sentence re-ranking metric (Chan et al., 2016; Gulcehre et al., 2015). Given a sentence x, for autoregressive LMs such as LSTM based models (Zaremba et al., 2014) and GPTs (Radford et al., 2018, 2019; Brown et al., 2020), perplexity can be computed as\nf(x) = exp − m∑ j=1 logPauto(xj |xj−1)  (1) where x is tokenized as [x1...xm] and Pauto(x|x) is the likelihood from an autoregressive LM’s next token prediction. For masked LMs such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019), we instead use pseudoperplexity, which is defined as in (1) but with Pmask(xj |x\\j) instead of Pauto(xj |xj−1), where x\\j = [x1 . . . xj1〈mask〉xj+1 . . . xm] and Pmask(xj |x\\j) is the pseudo-likelihood (Wang and Cho, 2019) that the masked token is xj . PMI. Although perplexity is well-suited to capture the fluency of a sentence, it may not be the best choice to test the plausibility of a given analogical proportion candidate. As an alternative, we propose a scoring function that focuses specifically\non words from the two given pairs. To this end, we propose to use an approximation of point-wise mutual information (PMI), based on perplexity.\nPMI is defined as the difference between a conditional and marginal log-likelihood. In our case, we consider the conditional likelihood of ti given hi and the query pair (recall from Section 3.1 that h and t represent the head and tail of a given word pair, respectively), i.e. P (ti|hq, tq, hi), and the marginal likelihood over hi, i.e. P (ti|hq, tq). Subsequently, the PMI-inspired scoring function is defined as\nr(ti|hi, hq, tq) = logP (ti|hi, hq, tq) − α · logP (ti|hq, tq) (2)\nwhere α is a hyperparameter to control the effect of the marginal likelihood. The PMI score corresponds to the specific case where α = 1. However, Davison et al. (2019) found that using a hyperparameter to balance the impact of the conditional and marginal probabilities can significantly improve the results. The probabilities in (2) are estimated by assuming that the answer candidates are the only possible word pairs that need to be considered. By relying on this closed-world assumption, we can estimate marginal probabilities based on perplexity, which we found to give better results than the masking based strategy from Davison et al. (2019). In particular, we estimate these probabilities as\nP (ti|hq, tq, hi) = − f (Tt(hq, tq, hi, ti)) n∑ k=1 f (Tt(hq, tq, hi, tk))\nP (ti|hq, tq) = −\nn∑ k=1 f (Tt(hq, tq, hk, ti))\nn∑ k=1 n∑ l=1 f (Tt(hq, tq, hk, tl))\nwhere n is the number of answer candidates for the given query. Equivalently, since PMI is symmetric, we can consider the difference between the logs of P (hi|hq, tq, ti) and P (hi|hq, tq). While this leads to the same PMI value in theory, due to the way in which we approximate the probabilities, this symmetric approach will lead to a different score. We thus combine both scores with an aggregation function Ag. This aggregation function takes a list of scores and outputs an aggregated value. As an example, given a list [1, 2, 3, 4], we write Amean([1, 2, 3, 4]) = 2.5 for the mean and Aval1([1, 2, 3, 4]) = 1 for the first element. Given such an aggregation function, we define the following PMI-based score\nsPMI(ti, hi|hq, tq) = Ag (r) (3)\nwhere we consider basic aggregation operations over the list r = [r(ti|hi, hq, tq), r(hi|ti, hq, tq)], such as the mean, max, and min value. The choice of using only one of the scores r(ti|hi, hq, tq), r(hi|ti, hq, tq) is viewed as a special case, in which the aggregation function g simply returns the first or the second item. mPPL. We also experiment with a third scoring function, which borrows ideas from both perplexity and PMI. In particular, we propose the marginal likelihood biased perplexity (mPPL) defined as\nsmPPL(ti, hi|hq, tq) = log sPPL(ti, hi|hq, tq) − αt · logP (ti|hq, tq) − αh · logP (hi|hq, tq)\nwhere αt and αh are hyperparameters, and sPPL is a normalized perplexity defined as\nsPPL(ti, hi|hq, tq) = − f (Tt(hq, tq, hi, ti)) n∑ k=1 f (Tt(hq, tq, hk, tk)) .\nThe mPPL score extends perplexity with two bias terms. It is motivated from the insight that treating α as a hyperparameter in (2) can lead to better results than fixing α = 1. By tuning αt and αh, we can essentially influence to what extent answer candidates involving semantically similar words to the query pair should be favored."
    }, {
      "heading" : "4.3 Permutation Invariance",
      "text" : "The formalization of analogical proportions dates back to Aristotle (Barbot et al., 2019). According\nto the standard axiomatic characterization, whenever we have an analogical proportion a : b :: c : d (meaning “a is to b what c is to d”), it also holds that c : d :: a : b and a : c :: b : d are analogical proportions. It follows from this that for any given analogical proportion a : b :: c : d there are eight permutations of the four elements a, b, c, d that form analogical proportions. These eight permutations, along with the 16 “negative permutations”, are shown in Figure 2.\nTo take advantage of the different permutations of analogical proportions, we propose the following Analogical Proportion (AP) score:\nAP(hq, tq, hi, ti) = Agpos(p)− β · Agneg(n) (4) p = [s(a, b|c, d)](a:b,c:d)∈P n = [s(a, b|c, d)](a:b,c:d)∈N\nwhere P and N correspond to the list of positive and negative permutations of the candidate analogical proportion hq : tq :: hi : ti in the order shown in Figure 2, β is a hyperparameter to control the impact of the negative permutations, and s(a, b|c, d) is a scoring function as described in Section 4.2. Here Agpos and Agneg refer to the aggregation functions that are used to combine the scores for the positive and negative permutations respectively, where these aggregation functions are defined as in Section 4.2. To solve an analogy problem, we simply choose the answer candidate that results in the highest value of AP(ti, hi, hq, tq)."
    }, {
      "heading" : "5 Evaluation",
      "text" : "In this section, we evaluate language models on the five analogy datasets presented in Section 3."
    }, {
      "heading" : "5.1 Experimental Setting",
      "text" : "We consider three transformer-based LMs of a different nature: two masked LMs, namely BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019), and GPT-2, as a prominent example of an autoregressive language model. Each pretrained model was fetched from the Huggingface transformers library (Wolf et al., 2019), from which we use bert-large-cased, roberta-large, and gpt2-xl respectively. For parameter selection, we run grid search on β, α, αh, αt, t, g, gpos, and gneg for each model and select the configuration which achieves the best accuracy on each validation set. We experiment with the three scoring functions presented in Section 4.2, i.e., sPPL (perplexity),\nsPMI and smPPL. Possible values for each hyperparameter (including the selection of six prompts and an ablation test on the scoring function) and the best configurations that were found by grid search are provided in the appendix.\nAs baseline methods, we also consider three pre-trained word embedding models, which have been shown to provide competitive results in analogy tasks, as explained in Section 2.2: Word2vec (Mikolov et al., 2013a), GloVe (Pennington et al., 2014), and FastText (Bojanowski et al., 2017). For the word embedding models, we simply represent word pairs by taking the difference between their embeddings4. We then choose the answer candidate with the highest cosine similarity to the query in terms of this vector difference. To put the results into context, we also include two simple statistical baselines. First, we report the expected random performance. Second, we use a method based on each word pair’s PMI in a given corpus. We then select the answer candidate with the highest\n4Vector differences have been found to be the most robust encoding method in the context of word analogies (Hakami and Bollegala, 2017).\nPMI as the prediction. Note that the query word pair is completely ignored in this case. This PMI score is the well-known word-pair association metric introduced by Church and Hanks (1990) for lexicographic purposes (specifically, collocation extraction), which compares the probability of observing two words together with the probabilities of observing them independently (chance). The PMI scores in our experiments were computed using the English Wikipedia with a fixed window size 10."
    }, {
      "heading" : "5.2 Results",
      "text" : "Table 3 shows our main results. As far as the comparison among LMs is concerned, RoBERTa and GPT-2 consistently outperform BERT. Among the AP variants, smPPL achieves substantially better results than sPMI or sPPL in most cases. We also observe that word embeddings perform surprisingly well, with FastText and GloVe outperforming BERT on most datasets, as well as GPT-2 and RoBERTa with default hyperparameters. FastText achieves the best overall accuracy on the Google dataset, confirming that this dataset is particularly well-suited to word embeddings (see Section 2.2).\nIn order to compare with published results from prior work, we carried out an additional experiment on the full SAT dataset (i.e., without splitting it into validation and test). Table 4 shows the results. GPT3 (Brown et al., 2020) and LRA (Turney, 2005) are added for comparison. Given the variability of the results depending on the tuning procedure, we have also reported results of configurations that were tuned on the entire set, to provide an upper bound on what is possible within the proposed unsupervised setting. This result shows that even with optimal hyperparameter values, LMs barely outperform the performance of the simpler LRA model. GPT-3 similarly fails to outperform LRA in the zero-shot setting."
    }, {
      "heading" : "6 Analysis",
      "text" : "We now take a closer look into our results to investigate parameter sensitivity, the correlation between model performance and human difficulty levels, and possible dataset artifacts. The following analysis focuses on smPPL as it achieved the best results among the LM based scoring functions.\nParameter Sensitivity We found that optimal values of the parameters α and β are highly dependent on the dataset, while other parameters such as the template type t vary across LMs. On the other hand, as shown in Figure 3, the optimal permutations of the templates are relatively consistent, with the original ordering a : b :: c : d typically achieving the best results. The results degrade most for permutations that mix the two word pairs (e.g. a : c :: b : d). In the appendix we include an ablation study for the sensitivity and relevance of other parameters and design choices.\nDifficulty Levels To increase our understanding of what makes an analogy problem difficult for LMs, we compare the results for each difficulty level.5 Recall from Section 3.2 that the U2 and U4 datasets come from educational resources and are split by difficulty level. Figure 4 shows the results of all LMs (tuned setting), FastText and the PMI baseline according to these difficulty levels. Broadly speaking, we can see that instances that are harder for humans are also harder for the considered models. The analogies in the most difficult levels are generally more abstract (e.g. witness : testimony :: generator : electricity), or contain obscure or infrequent words (e.g. grouch : cantakerous :: palace : ornate).6\n5For SAT, Google and BATS, there are no difficulty levels available, but we show the results split by high-level categories in the appendix. We also note that the number of candidates in U2 and U4 vary from three to five, so results per difficulty level are not fully comparable. However, they do reflect the actual difficulty of the educational tests.\n6In the appendix we include more examples with errors made by RoBERTa in easy instances.\nHypothesis Only Recently, several researchers have found that standard NLP benchmarks, such as SNLI (Bowman et al., 2015) for language inference, contain several annotation artifacts that makes the task simpler for automatic models (Poliak et al., 2018; Gururangan et al., 2018). One of their most relevant findings is that models which do not even consider the premise can reach high accuracy. More generally, these issues have been found to be problematic in NLP models (Linzen, 2020) and neural networks more generally (Geirhos et al., 2020). According to the results shown in Table 3, we already found that the PMI baseline achieved a non-trivial performance, even outperforming BERT in a few settings and datasets. This suggests that several implausible negative examples are included in the analogy datasets. As a further exploration of such artifacts, here we analyse the analogue of a hypothesis-only baseline. In particular, for this analysis, we masked the head or tail of the candidate answer in all evaluation instances. Then, we test the masked language models with the same AP con-\nfiguration and tuning on these artificially-modified datasets.As can be seen in Table 5, a non-trivial performance is achieved for all datasets, which suggests that the words from the answer pair tend to be more similar to the words from the query than the words from negative examples."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we have presented an extensive analysis of the ability of language models to identify analogies. To this end, we first compiled datasets with psychometric analogy problems from educational resources, covering a wide range of difficulty levels and topics. We also recast two standard benchmarks, the Google and BATS analogy datasets, into the same style of problems. Then, we proposed standard techniques to apply language models to the unsupervised task of solving these analogy problems. Our empirical results shed light on the strengths and limitations of various models. To directly answer the question posed in the title, our conclusion is that language models can identify analogies to a certain extent, but not all language models are able to achieve a meaningful improvement over word embeddings (whose limitations in analogy tasks are well documented). On the other hand, when carefully tuned, some language models are able to achieve state-of-the-art results. We emphasize that results are highly sensitive to the chosen hyperparameters (which define the scoring function and the prompt among others). Further research could focus on the selection of these optimal hyperparameters, including automatizing the search or generation of prompts, along the lines of Bouraoui et al. (2020) and Shin et al. (2020), respectively. Finally, clearly LMs might still be able to learn to solve analogy tasks when given appropriate training data, which is an aspect that we leave for future work."
    }, {
      "heading" : "A Experimental Details",
      "text" : "In our grid search to find the optimal configuration for each dataset and language model, each parameter was selected within the values shown in Table 6. As the coefficient of marginal likelihood α, αh, αt, we considered negative values as well as we hypothesized that the marginal likelihood could be beneficial for LMs as a way to leverage lexical knowledge of the head and tail words.\nAdditionally, Table 7 shows the set of custom templates (or prompts) used in our experiments. Finally, Tables 8, 9, and 10 include the best configuration based on each validation set in for sPMI, smPPL and the hypothesis-only baseline, respectively."
    }, {
      "heading" : "B Additional Ablation Results",
      "text" : "We show a few more complementary results to our main experiments.\nB.1 Alternative Scoring Functions\nAs alternative scoring functions for LM, we have tried two other scores: PMI score based on masked token prediction (Davison et al., 2019) (Mask PMI) and cosine similarity between the embedding difference of a relation pair similar to what used in word-embedding models. For embedding method, we give a prompted sentence to LM to get the last layer’s hidden state for each word in the given pair and we take the difference between them, which we regard as the embedding vector for the pair. Finally we pick up the most similar candidate in terms of the cosine similarity with the query embedding. Ta-\nble 11 shows the test accuracy on each dataset. As one can see, AP scores outperform other methods with a great margin.\nB.2 Parameter Sensitivity: template type t Figure 5 shows the box plot of relative improvement across all datasets grouped by t and the results indicate that there is a mild trend that certain templates tend to perform well, but not significant universal selectivity can be found across datasets.\nB.3 Parameter Sensitivity: aggregation method gneg\nFigure 6 shows the box plot of relative improvement across all datasets grouped by gneg. Unlike gpos we show in Figure 3, they do not give a strong signals over datasets.\nB.4 Relation Types in BATS/Google Figure 7 shows the results of different language models with the smPPL scoring function on the different categories of the BATS and Google datasets."
    }, {
      "heading" : "C Error Analysis",
      "text" : "Table 12 shows all examples from the U2 dataset of the easiest difficuly (i.e. grade 4), which were misclassified by RoBERTa, with smPPL tuned on the validation set. We can see a few typical issues with word embeddings and language models. For instance, in the first example, the model confuses the antonym pair right:wrong with synonymy. In the second example, we have that someone who is poor lacks money, while someone who is hungry lacks food. However, the selected candidate pair is hungy:water rather than hungry:food, which is\npresumably chosen because water is assumed to be a near-synonym of food. In the third example (wrench:tool), the hypnernymy relation is confused with a meronymy relation in the selected candidate tree:forest. In the last three examples, the model has selected answers which seem reasonable. In the fourth example, beautiful:pretty, terrible:bad and brave:valiant can all be considered to be synonym pairs. In the fifth example, vehicle:transport is clearly the correct answer, but the pair song:sing is nonetheless relationally similar to shield:protect. In the last example, we can think of being sad as an emotional state, like being sick is a health state, which provides some justification for the predicted answer. On the other hand, the gold answer is based on the argument that someone who is sick lacks health like someone who is scared lacks courage."
    } ],
    "references" : [ {
      "title" : "Analogies explained: Towards understanding word embeddings",
      "author" : [ "Carl Allen", "Timothy Hospedales." ],
      "venue" : "International Conference on Machine Learning, pages 223–231.",
      "citeRegEx" : "Allen and Hospedales.,? 2019",
      "shortCiteRegEx" : "Allen and Hospedales.",
      "year" : 2019
    }, {
      "title" : "A latent variable model approach to pmi-based word embeddings",
      "author" : [ "Sanjeev Arora", "Yuanzhi Li", "Yingyu Liang", "Tengyu Ma", "Andrej Risteski." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 4:385–399.",
      "citeRegEx" : "Arora et al\\.,? 2016",
      "shortCiteRegEx" : "Arora et al\\.",
      "year" : 2016
    }, {
      "title" : "Arguing by analogy in law: A case-based model",
      "author" : [ "Kevin D Ashley." ],
      "venue" : "Analogical reasoning, pages 205–224. Springer.",
      "citeRegEx" : "Ashley.,? 1988",
      "shortCiteRegEx" : "Ashley.",
      "year" : 1988
    }, {
      "title" : "Analogy between concepts",
      "author" : [ "Nelly Barbot", "Laurent Miclet", "Henri Prade." ],
      "venue" : "Artificial Intelligence, 275:487–539.",
      "citeRegEx" : "Barbot et al\\.,? 2019",
      "shortCiteRegEx" : "Barbot et al\\.",
      "year" : 2019
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "Transactions of the Association of Computational Linguistics, 5(1):135–146.",
      "citeRegEx" : "Bojanowski et al\\.,? 2017",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2017
    }, {
      "title" : "Man is to computer programmer as woman is to homemaker? debiasing word embeddings",
      "author" : [ "Tolga Bolukbasi", "Kai-Wei Chang", "James Y Zou", "Venkatesh Saligrama", "Adam T Kalai." ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Bolukbasi et al\\.,? 2016",
      "shortCiteRegEx" : "Bolukbasi et al\\.",
      "year" : 2016
    }, {
      "title" : "Solving and explaining analogy questions using semantic networks",
      "author" : [ "Adrian Boteanu", "Sonia Chernova." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Boteanu and Chernova.,? 2015",
      "shortCiteRegEx" : "Boteanu and Chernova.",
      "year" : 2015
    }, {
      "title" : "Inducing relational knowledge from bert",
      "author" : [ "Zied Bouraoui", "Jose Camacho-Collados", "Steven Schockaert." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 7456– 7463.",
      "citeRegEx" : "Bouraoui et al\\.,? 2020",
      "shortCiteRegEx" : "Bouraoui et al\\.",
      "year" : 2020
    }, {
      "title" : "Relation induction in word embeddings revisited",
      "author" : [ "Zied Bouraoui", "Shoaib Jameel", "Steven Schockaert." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 1627– 1637, Santa Fe, New Mexico, USA. Association for",
      "citeRegEx" : "Bouraoui et al\\.,? 2018",
      "shortCiteRegEx" : "Bouraoui et al\\.",
      "year" : 2018
    }, {
      "title" : "A large annotated corpus for learning natural language inference",
      "author" : [ "Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Bowman et al\\.,? 2015",
      "shortCiteRegEx" : "Bowman et al\\.",
      "year" : 2015
    }, {
      "title" : "Language models are few-shot learners",
      "author" : [ "Eric Sigler", "Mateusz Litwin", "Scott Gray", "Benjamin Chess", "Jack Clark", "Christopher Berner", "Sam McCandlish", "Alec Radford", "Ilya Sutskever", "Dario Amodei." ],
      "venue" : "Annual Conference on Neural Information",
      "citeRegEx" : "Sigler et al\\.,? 2020",
      "shortCiteRegEx" : "Sigler et al\\.",
      "year" : 2020
    }, {
      "title" : "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition",
      "author" : [ "William Chan", "Navdeep Jaitly", "Quoc Le", "Oriol Vinyals." ],
      "venue" : "2016 IEEE International Conference on Acoustics, Speech and Signal Processing",
      "citeRegEx" : "Chan et al\\.,? 2016",
      "shortCiteRegEx" : "Chan et al\\.",
      "year" : 2016
    }, {
      "title" : "Understanding the source of semantic regularities in word embeddings",
      "author" : [ "Hsiao-Yu Chiang", "Jose Camacho-Collados", "Zachary Pardos." ],
      "venue" : "Proceedings of the 24th Conference on Computational Natural Language Learning, pages 119–131, Online.",
      "citeRegEx" : "Chiang et al\\.,? 2020",
      "shortCiteRegEx" : "Chiang et al\\.",
      "year" : 2020
    }, {
      "title" : "Word association norms, mutual information, and lexicography",
      "author" : [ "Kenneth Church", "Patrick Hanks." ],
      "venue" : "Computational linguistics, 16(1):22–29.",
      "citeRegEx" : "Church and Hanks.,? 1990",
      "shortCiteRegEx" : "Church and Hanks.",
      "year" : 1990
    }, {
      "title" : "Commonsense knowledge mining from pretrained models",
      "author" : [ "Joe Davison", "Joshua Feldman", "Alexander M Rush." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer-",
      "citeRegEx" : "Davison et al\\.,? 2019",
      "shortCiteRegEx" : "Davison et al\\.",
      "year" : 2019
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Word embeddings, analogies, and machine learning: Beyond king-man+ woman= queen",
      "author" : [ "Aleksandr Drozd", "Anna Gladkova", "Satoshi Matsuoka." ],
      "venue" : "Proceedings of coling 2016, the 26th international conference on computational linguistics:",
      "citeRegEx" : "Drozd et al\\.,? 2016",
      "shortCiteRegEx" : "Drozd et al\\.",
      "year" : 2016
    }, {
      "title" : "Towards understanding linear word analogies",
      "author" : [ "Kawin Ethayarajh", "David Duvenaud", "Graeme Hirst." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3253–3262.",
      "citeRegEx" : "Ethayarajh et al\\.,? 2019",
      "shortCiteRegEx" : "Ethayarajh et al\\.",
      "year" : 2019
    }, {
      "title" : "What bert is not: Lessons from a new suite of psycholinguistic diagnostics for language models",
      "author" : [ "Allyson Ettinger." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 8:34–48.",
      "citeRegEx" : "Ettinger.,? 2019",
      "shortCiteRegEx" : "Ettinger.",
      "year" : 2019
    }, {
      "title" : "Connectionist models and their properties",
      "author" : [ "Jerome A. Feldman", "Dana H. Ballard." ],
      "venue" : "Cognitive Science, 6(3):205–254.",
      "citeRegEx" : "Feldman and Ballard.,? 1982",
      "shortCiteRegEx" : "Feldman and Ballard.",
      "year" : 1982
    }, {
      "title" : "Analogies minus analogy test: measuring regularities in word embeddings",
      "author" : [ "Louis Fournier", "Emmanuel Dupoux", "Ewan Dunbar." ],
      "venue" : "Proceedings of the 24th Conference on Computational Natural Language Learning, pages 365–375, Online. Asso-",
      "citeRegEx" : "Fournier et al\\.,? 2020",
      "shortCiteRegEx" : "Fournier et al\\.",
      "year" : 2020
    }, {
      "title" : "Making pre-trained language models better few-shot learners",
      "author" : [ "Tianyu Gao", "Adam Fisch", "Danqi Chen." ],
      "venue" : "arXiv preprint arXiv:2012.15723.",
      "citeRegEx" : "Gao et al\\.,? 2020",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2020
    }, {
      "title" : "Shortcut learning in deep neural networks",
      "author" : [ "Robert Geirhos", "Jörn-Henrik Jacobsen", "Claudio Michaelis", "Richard Zemel", "Wieland Brendel", "Matthias Bethge", "Felix A Wichmann." ],
      "venue" : "Nature Machine Intelligence, 2(11):665–673.",
      "citeRegEx" : "Geirhos et al\\.,? 2020",
      "shortCiteRegEx" : "Geirhos et al\\.",
      "year" : 2020
    }, {
      "title" : "Skip-gram- zipf+ uniform= vector additivity",
      "author" : [ "Alex Gittens", "Dimitris Achlioptas", "Michael W Mahoney." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 69–76.",
      "citeRegEx" : "Gittens et al\\.,? 2017",
      "shortCiteRegEx" : "Gittens et al\\.",
      "year" : 2017
    }, {
      "title" : "Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn’t",
      "author" : [ "Anna Gladkova", "Aleksandr Drozd", "Satoshi Matsuoka." ],
      "venue" : "Proceedings of the Student Research Workshop at NAACL, pages",
      "citeRegEx" : "Gladkova et al\\.,? 2016",
      "shortCiteRegEx" : "Gladkova et al\\.",
      "year" : 2016
    }, {
      "title" : "Computational design, analogy, and creativity",
      "author" : [ "Ashok Goel." ],
      "venue" : "Computational Creativity, pages 141–158. Springer.",
      "citeRegEx" : "Goel.,? 2019",
      "shortCiteRegEx" : "Goel.",
      "year" : 2019
    }, {
      "title" : "Assessing bert’s syntactic abilities",
      "author" : [ "Yoav Goldberg." ],
      "venue" : "arXiv preprint arXiv:1901.05287.",
      "citeRegEx" : "Goldberg.,? 2019",
      "shortCiteRegEx" : "Goldberg.",
      "year" : 2019
    }, {
      "title" : "Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them",
      "author" : [ "Hila Gonen", "Yoav Goldberg." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Gonen and Goldberg.,? 2019",
      "shortCiteRegEx" : "Gonen and Goldberg.",
      "year" : 2019
    }, {
      "title" : "On using monolingual corpora in neural machine translation",
      "author" : [ "Caglar Gulcehre", "Orhan Firat", "Kelvin Xu", "Kyunghyun Cho", "Loic Barrault", "Huei-Chi Lin", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1503.03535.",
      "citeRegEx" : "Gulcehre et al\\.,? 2015",
      "shortCiteRegEx" : "Gulcehre et al\\.",
      "year" : 2015
    }, {
      "title" : "Annotation artifacts in natural language inference data",
      "author" : [ "Suchin Gururangan", "Swabha Swayamdipta", "Omer Levy", "Roy Schwartz", "Samuel Bowman", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the",
      "citeRegEx" : "Gururangan et al\\.,? 2018",
      "shortCiteRegEx" : "Gururangan et al\\.",
      "year" : 2018
    }, {
      "title" : "Compositional approaches for representing relations between words: A comparative study",
      "author" : [ "Huda Hakami", "Danushka Bollegala." ],
      "venue" : "KnowledgeBased Systems, 136:172–182.",
      "citeRegEx" : "Hakami and Bollegala.,? 2017",
      "shortCiteRegEx" : "Hakami and Bollegala.",
      "year" : 2017
    }, {
      "title" : "A structural probe for finding syntax in word representations",
      "author" : [ "John Hewitt", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
      "citeRegEx" : "Hewitt and Manning.,? 2019",
      "shortCiteRegEx" : "Hewitt and Manning.",
      "year" : 2019
    }, {
      "title" : "Learning distributed representations of concepts",
      "author" : [ "Geoffrey E. Hinton." ],
      "venue" : "Proceedings of the eighth annual conference of the cognitive science society, volume 1, page 12. Amherst, MA.",
      "citeRegEx" : "Hinton.,? 1986",
      "shortCiteRegEx" : "Hinton.",
      "year" : 1986
    }, {
      "title" : "Distributed representations",
      "author" : [ "Geoffrey E. Hinton", "James L. McClelland", "David E. Rumelhart." ],
      "venue" : "Parallel distributed processing: explorations in the microstructure of cognition, vol. 1, pages 77–109.",
      "citeRegEx" : "Hinton et al\\.,? 1986",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 1986
    }, {
      "title" : "Mental leaps: Analogy in creative thought",
      "author" : [ "Keith J Holyoak", "Keith James Holyoak", "Paul Thagard." ],
      "venue" : "MIT press.",
      "citeRegEx" : "Holyoak et al\\.,? 1996",
      "shortCiteRegEx" : "Holyoak et al\\.",
      "year" : 1996
    }, {
      "title" : "Accelerating innovation through analogy mining",
      "author" : [ "Tom Hope", "Joel Chan", "Aniket Kittur", "Dafna Shahaf." ],
      "venue" : "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 235–243.",
      "citeRegEx" : "Hope et al\\.,? 2017",
      "shortCiteRegEx" : "Hope et al\\.",
      "year" : 2017
    }, {
      "title" : "Neural networks and physical systems with emergent collective computational abilities",
      "author" : [ "John J. Hopfield." ],
      "venue" : "Proceedings of the National Academy of Sciences, 79(8):2554–2558.",
      "citeRegEx" : "Hopfield.,? 1982",
      "shortCiteRegEx" : "Hopfield.",
      "year" : 1982
    }, {
      "title" : "Analogical classifiers: a theoretical perspective",
      "author" : [ "Nicolas Hug", "Henri Prade", "Gilles Richard", "Mathieu Serrurier." ],
      "venue" : "Proceedings of the Twentysecond European Conference on Artificial Intelligence, pages 689–697.",
      "citeRegEx" : "Hug et al\\.,? 2016",
      "shortCiteRegEx" : "Hug et al\\.",
      "year" : 2016
    }, {
      "title" : "Towards analogy-based explanations in machine learning",
      "author" : [ "Eyke Hüllermeier." ],
      "venue" : "International Conference on Modeling Decisions for Artificial Intelligence, pages 205–217.",
      "citeRegEx" : "Hüllermeier.,? 2020",
      "shortCiteRegEx" : "Hüllermeier.",
      "year" : 2020
    }, {
      "title" : "What does BERT learn about the structure of language",
      "author" : [ "Ganesh Jawahar", "Benoı̂t Sagot", "Djamé Seddah" ],
      "venue" : "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Jawahar et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Jawahar et al\\.",
      "year" : 2019
    }, {
      "title" : "How can we know what language models know? Transactions of the Association for Computational Linguistics, 8:423–438",
      "author" : [ "Zhengbao Jiang", "Frank F. Xu", "Jun Araki", "Graham Neubig" ],
      "venue" : null,
      "citeRegEx" : "Jiang et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2020
    }, {
      "title" : "A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge",
      "author" : [ "Thomas K. Landauer", "Susan T. Dumais." ],
      "venue" : "Psychological Review, 104(2):211.",
      "citeRegEx" : "Landauer and Dumais.,? 1997",
      "shortCiteRegEx" : "Landauer and Dumais.",
      "year" : 1997
    }, {
      "title" : "Linguistic regularities in sparse and explicit word representations",
      "author" : [ "Omer Levy", "Yoav Goldberg." ],
      "venue" : "Proceedings of the Eighteenth Conference on Computational Natural Language Learning,",
      "citeRegEx" : "Levy and Goldberg.,? 2014",
      "shortCiteRegEx" : "Levy and Goldberg.",
      "year" : 2014
    }, {
      "title" : "Issues in evaluating semantic spaces using word analogies",
      "author" : [ "Tal Linzen." ],
      "venue" : "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, pages 13–18.",
      "citeRegEx" : "Linzen.,? 2016",
      "shortCiteRegEx" : "Linzen.",
      "year" : 2016
    }, {
      "title" : "How can we accelerate progress towards human-like linguistic generalization? In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5210– 5217, Online",
      "author" : [ "Tal Linzen." ],
      "venue" : "Association for Computational Lin-",
      "citeRegEx" : "Linzen.,? 2020",
      "shortCiteRegEx" : "Linzen.",
      "year" : 2020
    }, {
      "title" : "Roberta: A robustly optimized BERT pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "CoRR, abs/1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Analogical dissimilarity: definition, algorithms and two experiments in machine learning",
      "author" : [ "Laurent Miclet", "Sabri Bayoudh", "Arnaud Delhay." ],
      "venue" : "Journal of Artificial Intelligence Research, 32:793– 824.",
      "citeRegEx" : "Miclet et al\\.,? 2008",
      "shortCiteRegEx" : "Miclet et al\\.",
      "year" : 2008
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean." ],
      "venue" : "Advances in neural information processing systems, pages 3111–3119.",
      "citeRegEx" : "Mikolov et al\\.,? 2013a",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Linguistic regularities in continuous space word representations",
      "author" : [ "Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig." ],
      "venue" : "Proceedings of HLTNAACL, pages 746–751.",
      "citeRegEx" : "Mikolov et al\\.,? 2013b",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Fair is better than sensational: Man is to doctor as woman is to doctor",
      "author" : [ "Malvina Nissim", "Rik van Noord", "Rob van der Goot." ],
      "venue" : "Computational Linguistics, 46(2):487–497.",
      "citeRegEx" : "Nissim et al\\.,? 2020",
      "shortCiteRegEx" : "Nissim et al\\.",
      "year" : 2020
    }, {
      "title" : "When the whole is less than the sum of its parts: How composition affects pmi values in distributional semantic vectors",
      "author" : [ "Denis Paperno", "Marco Baroni." ],
      "venue" : "Computational Linguistics, 42(2):345–350.",
      "citeRegEx" : "Paperno and Baroni.,? 2016",
      "shortCiteRegEx" : "Paperno and Baroni.",
      "year" : 2016
    }, {
      "title" : "A university map of course knowledge",
      "author" : [ "Zachary A. Pardos", "Andrew J.H. Nam." ],
      "venue" : "PLoS ONE, 15(9).",
      "citeRegEx" : "Pardos and Nam.,? 2020",
      "shortCiteRegEx" : "Pardos and Nam.",
      "year" : 2020
    }, {
      "title" : "GloVe: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D Manning." ],
      "venue" : "Proceedings of EMNLP, pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Associ-",
      "citeRegEx" : "Peters et al\\.,? 2018a",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Dissecting contextual word embeddings: Architecture and representation",
      "author" : [ "Matthew Peters", "Mark Neumann", "Luke Zettlemoyer", "Wen-tau Yih." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Peters et al\\.,? 2018b",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models as knowledge bases",
      "author" : [ "Fabio Petroni", "Tim Rocktäschel", "Sebastian Riedel", "Patrick Lewis", "Anton Bakhtin", "Yuxiang Wu", "Alexander Miller" ],
      "venue" : "In Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Petroni et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Petroni et al\\.",
      "year" : 2019
    }, {
      "title" : "Hypothesis only baselines in natural language inference",
      "author" : [ "Adam Poliak", "Jason Naradowsky", "Aparajita Haldar", "Rachel Rudinger", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics,",
      "citeRegEx" : "Poliak et al\\.,? 2018",
      "shortCiteRegEx" : "Poliak et al\\.",
      "year" : 2018
    }, {
      "title" : "Analogical proportions and analogical reasoning-an introduction",
      "author" : [ "Henri Prade", "Gilles Richard." ],
      "venue" : "International Conference on Case-Based Reasoning, pages 16–32. Springer.",
      "citeRegEx" : "Prade and Richard.,? 2017",
      "shortCiteRegEx" : "Prade and Richard.",
      "year" : 2017
    }, {
      "title" : "The role of analogy in ontology alignment: A study on lisa",
      "author" : [ "Elie Raad", "Joerg Evermann." ],
      "venue" : "Cognitive Systems Research, 33:1–16.",
      "citeRegEx" : "Raad and Evermann.,? 2015",
      "shortCiteRegEx" : "Raad and Evermann.",
      "year" : 2015
    }, {
      "title" : "Improving language understanding by generative pre-training",
      "author" : [ "Alec Radford", "Karthik Narasimhan", "Tim Salimans", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeff Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "A primer in bertology: What we know about how bert works",
      "author" : [ "Anna Rogers", "Olga Kovaleva", "Anna Rumshisky." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 8:842–866.",
      "citeRegEx" : "Rogers et al\\.,? 2021",
      "shortCiteRegEx" : "Rogers et al\\.",
      "year" : 2021
    }, {
      "title" : "Understanding learning dynamics of language models with SVCCA",
      "author" : [ "Naomi Saphra", "Adam Lopez." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
      "citeRegEx" : "Saphra and Lopez.,? 2019",
      "shortCiteRegEx" : "Saphra and Lopez.",
      "year" : 2019
    }, {
      "title" : "Quantity doesn’t buy quality syntax with neural language models",
      "author" : [ "Marten van Schijndel", "Aaron Mueller", "Tal Linzen." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Schijndel et al\\.,? 2019",
      "shortCiteRegEx" : "Schijndel et al\\.",
      "year" : 2019
    }, {
      "title" : "The word analogy testing caveat",
      "author" : [ "Natalie Schluter." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 242–246.",
      "citeRegEx" : "Schluter.,? 2018",
      "shortCiteRegEx" : "Schluter.",
      "year" : 2018
    }, {
      "title" : "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
      "author" : [ "Taylor Shin", "Yasaman Razeghi", "Robert L. Logan IV", "Eric Wallace", "Sameer Singh." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods",
      "citeRegEx" : "Shin et al\\.,? 2020",
      "shortCiteRegEx" : "Shin et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT rediscovers the classical NLP pipeline",
      "author" : [ "Ian Tenney", "Dipanjan Das", "Ellie Pavlick." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4593– 4601, Florence, Italy. Association for Computational",
      "citeRegEx" : "Tenney et al\\.,? 2019a",
      "shortCiteRegEx" : "Tenney et al\\.",
      "year" : 2019
    }, {
      "title" : "What do you learn from context? probing for sentence structure",
      "author" : [ "Ian Tenney", "Patrick Xia", "Berlin Chen", "Alex Wang", "Adam Poliak", "R. Thomas McCoy", "Najoung Kim", "Benjamin Van Durme", "Samuel R. Bowman", "Dipanjan Das", "Ellie Pavlick" ],
      "venue" : null,
      "citeRegEx" : "Tenney et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Tenney et al\\.",
      "year" : 2019
    }, {
      "title" : "Measuring semantic similarity by latent relational analysis",
      "author" : [ "Peter D. Turney." ],
      "venue" : "Proc. of IJCAI, pages 1136–1141.",
      "citeRegEx" : "Turney.,? 2005",
      "shortCiteRegEx" : "Turney.",
      "year" : 2005
    }, {
      "title" : "Combining independent modules in lexical multiple-choice problems",
      "author" : [ "Peter D. Turney", "Michael L. Littman", "Jeffrey Bigham", "Victor Shnayder." ],
      "venue" : "Recent Advances in Natural Language Processing III, pages 101–110.",
      "citeRegEx" : "Turney et al\\.,? 2003",
      "shortCiteRegEx" : "Turney et al\\.",
      "year" : 2003
    }, {
      "title" : "Take and took, gaggle and goose, book and read: Evaluating the utility of vector differences for lexical relation learning",
      "author" : [ "Ekaterina Vylomova", "Laura Rimell", "Trevor Cohn", "Timothy Baldwin." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Asso-",
      "citeRegEx" : "Vylomova et al\\.,? 2016",
      "shortCiteRegEx" : "Vylomova et al\\.",
      "year" : 2016
    }, {
      "title" : "Similarity, precedent and argument from analogy",
      "author" : [ "Douglas Walton." ],
      "venue" : "Artificial Intelligence and Law, 18(3):217–246.",
      "citeRegEx" : "Walton.,? 2010",
      "shortCiteRegEx" : "Walton.",
      "year" : 2010
    }, {
      "title" : "BERT has a mouth, and it must speak: BERT as a Markov random field language model",
      "author" : [ "Alex Wang", "Kyunghyun Cho." ],
      "venue" : "Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation, pages 30–36,",
      "citeRegEx" : "Wang and Cho.,? 2019",
      "shortCiteRegEx" : "Wang and Cho.",
      "year" : 2019
    }, {
      "title" : "Huggingface’s transformers: State-of-the-art natural language processing",
      "author" : [ "Clara Ma", "Yacine Jernite", "Julien Plu", "Canwen Xu", "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander M. Rush." ],
      "venue" : "ArXiv, abs/1910.03771.",
      "citeRegEx" : "Ma et al\\.,? 2019",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2019
    }, {
      "title" : "Recurrent neural network regularization",
      "author" : [ "Wojciech Zaremba", "Ilya Sutskever", "Oriol Vinyals." ],
      "venue" : "arXiv preprint arXiv:1409.2329.",
      "citeRegEx" : "Zaremba et al\\.,? 2014",
      "shortCiteRegEx" : "Zaremba et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 43,
      "context" : "tion holds for some types of syntactic relations, for semantic relations this holds to a much more limited degree than was suggested in early work (Linzen, 2016; Schluter, 2018).",
      "startOffset" : 147,
      "endOffset" : 177
    }, {
      "referenceID" : 64,
      "context" : "tion holds for some types of syntactic relations, for semantic relations this holds to a much more limited degree than was suggested in early work (Linzen, 2016; Schluter, 2018).",
      "startOffset" : 147,
      "endOffset" : 177
    }, {
      "referenceID" : 34,
      "context" : "Besides its value as an intrinsic benchmark for lexical semantics, the ability to recognize analogies is indeed important in the contexts of human creativity (Holyoak et al., 1996), innovation (Hope et al.",
      "startOffset" : 158,
      "endOffset" : 180
    }, {
      "referenceID" : 35,
      "context" : ", 1996), innovation (Hope et al., 2017), computational creativity (Goel, 2019) and education (Pardos and Nam, 2020).",
      "startOffset" : 20,
      "endOffset" : 39
    }, {
      "referenceID" : 25,
      "context" : ", 2017), computational creativity (Goel, 2019) and education (Pardos and Nam, 2020).",
      "startOffset" : 34,
      "endOffset" : 46
    }, {
      "referenceID" : 51,
      "context" : ", 2017), computational creativity (Goel, 2019) and education (Pardos and Nam, 2020).",
      "startOffset" : 61,
      "endOffset" : 83
    }, {
      "referenceID" : 2,
      "context" : "Analogies are also a prerequisite to build AI systems for the legal domain (Ashley, 1988; Walton, 2010) and are used in machine learning (Miclet et al.",
      "startOffset" : 75,
      "endOffset" : 103
    }, {
      "referenceID" : 71,
      "context" : "Analogies are also a prerequisite to build AI systems for the legal domain (Ashley, 1988; Walton, 2010) and are used in machine learning (Miclet et al.",
      "startOffset" : 75,
      "endOffset" : 103
    }, {
      "referenceID" : 58,
      "context" : "3610 2016; Hüllermeier, 2020) and for ontology alignment (Raad and Evermann, 2015), among others.",
      "startOffset" : 57,
      "endOffset" : 82
    }, {
      "referenceID" : 41,
      "context" : "To solve such problems, Turney (2005) proposed Latent Relational Analysis (LRA), which was essentially designed as a relational counterpart to Latent Semantic Analysis (Landauer and Dumais, 1997).",
      "startOffset" : 168,
      "endOffset" : 195
    }, {
      "referenceID" : 53,
      "context" : "Since their recent dominance in standard NLP benchmarks (Peters et al., 2018a; Devlin et al., 2019; Liu et al., 2019), pre-trained language models have been extensively studied.",
      "startOffset" : 56,
      "endOffset" : 117
    }, {
      "referenceID" : 15,
      "context" : "Since their recent dominance in standard NLP benchmarks (Peters et al., 2018a; Devlin et al., 2019; Liu et al., 2019), pre-trained language models have been extensively studied.",
      "startOffset" : 56,
      "endOffset" : 117
    }, {
      "referenceID" : 45,
      "context" : "Since their recent dominance in standard NLP benchmarks (Peters et al., 2018a; Devlin et al., 2019; Liu et al., 2019), pre-trained language models have been extensively studied.",
      "startOffset" : 56,
      "endOffset" : 117
    }, {
      "referenceID" : 54,
      "context" : "After the initial focus on understanding pre-trained LSTM-based LMs (Peters et al., 2018b), attention has now shifted toward transformer-based models.",
      "startOffset" : 68,
      "endOffset" : 90
    }, {
      "referenceID" : 26,
      "context" : "The main aspects that have been studied in recent years are syntax (Goldberg, 2019; Saphra and Lopez, 2019; Hewitt and Manning, 2019; van Schijndel et al., 2019; Jawahar et al., 2019; Tenney et al., 2019b) and semantics (Ettinger, 2019; Tenney et al.",
      "startOffset" : 67,
      "endOffset" : 205
    }, {
      "referenceID" : 62,
      "context" : "The main aspects that have been studied in recent years are syntax (Goldberg, 2019; Saphra and Lopez, 2019; Hewitt and Manning, 2019; van Schijndel et al., 2019; Jawahar et al., 2019; Tenney et al., 2019b) and semantics (Ettinger, 2019; Tenney et al.",
      "startOffset" : 67,
      "endOffset" : 205
    }, {
      "referenceID" : 31,
      "context" : "The main aspects that have been studied in recent years are syntax (Goldberg, 2019; Saphra and Lopez, 2019; Hewitt and Manning, 2019; van Schijndel et al., 2019; Jawahar et al., 2019; Tenney et al., 2019b) and semantics (Ettinger, 2019; Tenney et al.",
      "startOffset" : 67,
      "endOffset" : 205
    }, {
      "referenceID" : 39,
      "context" : "The main aspects that have been studied in recent years are syntax (Goldberg, 2019; Saphra and Lopez, 2019; Hewitt and Manning, 2019; van Schijndel et al., 2019; Jawahar et al., 2019; Tenney et al., 2019b) and semantics (Ettinger, 2019; Tenney et al.",
      "startOffset" : 67,
      "endOffset" : 205
    }, {
      "referenceID" : 7,
      "context" : "ically generating templates and fine-tuning LMs on them (Bouraoui et al., 2020; Jiang et al., 2020), showing an improved performance.",
      "startOffset" : 56,
      "endOffset" : 99
    }, {
      "referenceID" : 40,
      "context" : "ically generating templates and fine-tuning LMs on them (Bouraoui et al., 2020; Jiang et al., 2020), showing an improved performance.",
      "startOffset" : 56,
      "endOffset" : 99
    }, {
      "referenceID" : 19,
      "context" : "The motivation for this task dates back to the connectionism theory (Feldman and Ballard, 1982) in cognitive science.",
      "startOffset" : 68,
      "endOffset" : 95
    }, {
      "referenceID" : 36,
      "context" : "In particular, neural networks were thought to be able to model emergent concepts (Hopfield, 1982; Hinton, 1986) by learning distributed representations across an embedding space (Hinton et al.",
      "startOffset" : 82,
      "endOffset" : 112
    }, {
      "referenceID" : 32,
      "context" : "In particular, neural networks were thought to be able to model emergent concepts (Hopfield, 1982; Hinton, 1986) by learning distributed representations across an embedding space (Hinton et al.",
      "startOffset" : 82,
      "endOffset" : 112
    }, {
      "referenceID" : 33,
      "context" : "In particular, neural networks were thought to be able to model emergent concepts (Hopfield, 1982; Hinton, 1986) by learning distributed representations across an embedding space (Hinton et al., 1986), similar to the properties that word embeddings displayed in the analogy task.",
      "startOffset" : 179,
      "endOffset" : 200
    }, {
      "referenceID" : 1,
      "context" : "More recent works have proposed new mathematical theories and experiments to understand the analogical capabilities of word embeddings, attempting to understand their linear algebraic structure (Arora et al., 2016; Gittens et al., 2017; Allen and Hospedales, 2019) or by explicitly studying their compositional nature (Levy and",
      "startOffset" : 194,
      "endOffset" : 264
    }, {
      "referenceID" : 23,
      "context" : "More recent works have proposed new mathematical theories and experiments to understand the analogical capabilities of word embeddings, attempting to understand their linear algebraic structure (Arora et al., 2016; Gittens et al., 2017; Allen and Hospedales, 2019) or by explicitly studying their compositional nature (Levy and",
      "startOffset" : 194,
      "endOffset" : 264
    }, {
      "referenceID" : 0,
      "context" : "More recent works have proposed new mathematical theories and experiments to understand the analogical capabilities of word embeddings, attempting to understand their linear algebraic structure (Arora et al., 2016; Gittens et al., 2017; Allen and Hospedales, 2019) or by explicitly studying their compositional nature (Levy and",
      "startOffset" : 194,
      "endOffset" : 264
    }, {
      "referenceID" : 43,
      "context" : "In many cases simple baselines excluding the input pair (or query) were competitive (Linzen, 2016).",
      "startOffset" : 84,
      "endOffset" : 98
    }, {
      "referenceID" : 16,
      "context" : "Simultaneously, some researchers have found that many relationships may not be retrieved in the embedding space by simple linear transformations (Drozd et al., 2016; Bouraoui et al., 2018) and others argued that the standard evaluation procedure has limitations (Schluter, 2018).",
      "startOffset" : 145,
      "endOffset" : 188
    }, {
      "referenceID" : 8,
      "context" : "Simultaneously, some researchers have found that many relationships may not be retrieved in the embedding space by simple linear transformations (Drozd et al., 2016; Bouraoui et al., 2018) and others argued that the standard evaluation procedure has limitations (Schluter, 2018).",
      "startOffset" : 145,
      "endOffset" : 188
    }, {
      "referenceID" : 64,
      "context" : ", 2018) and others argued that the standard evaluation procedure has limitations (Schluter, 2018).",
      "startOffset" : 81,
      "endOffset" : 97
    }, {
      "referenceID" : 24,
      "context" : "New datasets and measures have also been introduced to address some of these issues (Gladkova et al., 2016; Fournier et al., 2020).",
      "startOffset" : 84,
      "endOffset" : 130
    }, {
      "referenceID" : 20,
      "context" : "New datasets and measures have also been introduced to address some of these issues (Gladkova et al., 2016; Fournier et al., 2020).",
      "startOffset" : 84,
      "endOffset" : 130
    }, {
      "referenceID" : 5,
      "context" : "Finally, in the context of bias detection, for which analogies have been used as a proxy (Bolukbasi et al., 2016), it has also been found that word analogies may misguide",
      "startOffset" : 89,
      "endOffset" : 113
    }, {
      "referenceID" : 27,
      "context" : "or hide the real relationships existing in the vector space (Gonen and Goldberg, 2019; Nissim et al., 2020).",
      "startOffset" : 60,
      "endOffset" : 107
    }, {
      "referenceID" : 49,
      "context" : "or hide the real relationships existing in the vector space (Gonen and Goldberg, 2019; Nissim et al., 2020).",
      "startOffset" : 60,
      "endOffset" : 107
    }, {
      "referenceID" : 69,
      "context" : "(2020) evaluated the unsupervised capabilities of GPT-3 by evaluating it on the SAT analogies dataset (Turney et al., 2003), which we also include in our evaluation (see Section 3.",
      "startOffset" : 102,
      "endOffset" : 123
    }, {
      "referenceID" : 57,
      "context" : "We frame the analogy task in terms of analogical proportions (Prade and Richard, 2017).",
      "startOffset" : 61,
      "endOffset" : 86
    }, {
      "referenceID" : 47,
      "context" : "Since the introduction of Word2vec (Mikolov et al., 2013a), the problem of modelling analogies has been commonly used as an intrinsic benchmark for word embedding models.",
      "startOffset" : 35,
      "endOffset" : 58
    }, {
      "referenceID" : 48,
      "context" : "The Google analogy dataset (Mikolov et al., 2013b) has been one of the most commonly used benchmarks for intrinsic evaluation of word embeddings.",
      "startOffset" : 27,
      "endOffset" : 50
    }, {
      "referenceID" : 24,
      "context" : "However, its coverage has been shown to be limiting, and BATS (Gladkova et al., 2016) was developed in an attempt to address its main shortcomings.",
      "startOffset" : 62,
      "endOffset" : 85
    }, {
      "referenceID" : 65,
      "context" : "For this reason, recent studies have proposed autoprompting strategies, which optimize the template type on a training set (Shin et al., 2020), paraphrasing (Jiang et al.",
      "startOffset" : 123,
      "endOffset" : 142
    }, {
      "referenceID" : 40,
      "context" : ", 2020), paraphrasing (Jiang et al., 2020), additional prompt generation model (Gao et al.",
      "startOffset" : 22,
      "endOffset" : 42
    }, {
      "referenceID" : 21,
      "context" : ", 2020), additional prompt generation model (Gao et al., 2020), and corpus-driven template mining (Bouraoui et al.",
      "startOffset" : 44,
      "endOffset" : 62
    }, {
      "referenceID" : 7,
      "context" : ", 2020), and corpus-driven template mining (Bouraoui et al., 2020).",
      "startOffset" : 43,
      "endOffset" : 66
    }, {
      "referenceID" : 11,
      "context" : "We first define perplexity, which is widely used as a sentence re-ranking metric (Chan et al., 2016; Gulcehre et al., 2015).",
      "startOffset" : 81,
      "endOffset" : 123
    }, {
      "referenceID" : 28,
      "context" : "We first define perplexity, which is widely used as a sentence re-ranking metric (Chan et al., 2016; Gulcehre et al., 2015).",
      "startOffset" : 81,
      "endOffset" : 123
    }, {
      "referenceID" : 74,
      "context" : "Given a sentence x, for autoregressive LMs such as LSTM based models (Zaremba et al., 2014) and GPTs (Radford et al.",
      "startOffset" : 69,
      "endOffset" : 91
    }, {
      "referenceID" : 15,
      "context" : "For masked LMs such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al.",
      "startOffset" : 28,
      "endOffset" : 49
    }, {
      "referenceID" : 45,
      "context" : ", 2019) and RoBERTa (Liu et al., 2019), we instead use pseudoperplexity, which is defined as in (1) but with Pmask(xj |x\\j) instead of Pauto(xj |xj−1), where x\\j = [x1 .",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 72,
      "context" : "xm] and Pmask(xj |x\\j) is the pseudo-likelihood (Wang and Cho, 2019) that the masked token is xj .",
      "startOffset" : 48,
      "endOffset" : 68
    }, {
      "referenceID" : 3,
      "context" : "The formalization of analogical proportions dates back to Aristotle (Barbot et al., 2019).",
      "startOffset" : 68,
      "endOffset" : 89
    }, {
      "referenceID" : 15,
      "context" : "We consider three transformer-based LMs of a different nature: two masked LMs, namely BERT (Devlin et al., 2019) and RoBERTa (Liu et al.",
      "startOffset" : 91,
      "endOffset" : 112
    }, {
      "referenceID" : 45,
      "context" : ", 2019) and RoBERTa (Liu et al., 2019), and GPT-2, as a prominent example of an autoregressive language model.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 47,
      "context" : "2: Word2vec (Mikolov et al., 2013a), GloVe (Pennington et al.",
      "startOffset" : 12,
      "endOffset" : 35
    }, {
      "referenceID" : 52,
      "context" : ", 2013a), GloVe (Pennington et al., 2014), and FastText (Bojanowski et al.",
      "startOffset" : 16,
      "endOffset" : 41
    }, {
      "referenceID" : 30,
      "context" : "Vector differences have been found to be the most robust encoding method in the context of word analogies (Hakami and Bollegala, 2017).",
      "startOffset" : 106,
      "endOffset" : 134
    }, {
      "referenceID" : 68,
      "context" : ", 2020) and LRA (Turney, 2005) are added for comparison.",
      "startOffset" : 16,
      "endOffset" : 30
    }, {
      "referenceID" : 9,
      "context" : "Hypothesis Only Recently, several researchers have found that standard NLP benchmarks, such as SNLI (Bowman et al., 2015) for language inference, contain several annotation artifacts that makes the task simpler for automatic models (Poliak et al.",
      "startOffset" : 100,
      "endOffset" : 121
    }, {
      "referenceID" : 56,
      "context" : ", 2015) for language inference, contain several annotation artifacts that makes the task simpler for automatic models (Poliak et al., 2018; Gururangan et al., 2018).",
      "startOffset" : 118,
      "endOffset" : 164
    }, {
      "referenceID" : 29,
      "context" : ", 2015) for language inference, contain several annotation artifacts that makes the task simpler for automatic models (Poliak et al., 2018; Gururangan et al., 2018).",
      "startOffset" : 118,
      "endOffset" : 164
    }, {
      "referenceID" : 44,
      "context" : "More generally, these issues have been found to be problematic in NLP models (Linzen, 2020) and neural networks more generally (Geirhos et al.",
      "startOffset" : 77,
      "endOffset" : 91
    }, {
      "referenceID" : 22,
      "context" : "More generally, these issues have been found to be problematic in NLP models (Linzen, 2020) and neural networks more generally (Geirhos et al., 2020).",
      "startOffset" : 127,
      "endOffset" : 149
    } ],
    "year" : 2021,
    "abstractText" : "Analogies play a central role in human commonsense reasoning. The ability to recognize analogies such as “eye is to seeing what ear is to hearing”, sometimes referred to as analogical proportions, shape how we structure knowledge and understand language. Surprisingly, however, the task of identifying such analogies has not yet received much attention in the language model era. In this paper, we analyze the capabilities of transformer-based language models on this unsupervised task, using benchmarks obtained from educational settings, as well as more commonly used datasets. We find that off-the-shelf language models can identify analogies to a certain extent, but struggle with abstract and complex relations, and results are highly sensitive to model architecture and hyperparameters. Overall the best results were obtained with GPT-2 and RoBERTa, while configurations using BERT were not able to outperform word embedding models. Our results raise important questions for future work about how, and to what extent, pre-trained language models capture knowledge about abstract semantic relations.1",
    "creator" : "LaTeX with hyperref"
  }
}