{
  "name" : "2021.acl-long.192.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Robustness Testing of Language Understanding in Task-Oriented Dialog",
    "authors" : [ "Jiexi Liu", "Ryuichi Takanobu", "Jiaxin Wen", "Dazhen Wan", "Hongguang Li", "Weiran Nie", "Cheng Li", "Wei Peng", "Minlie Huang" ],
    "emails" : [ "gxly19}@mails.tsinghua.edu.cn,", "aihuang@tsinghua.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2467–2480\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n2467"
    }, {
      "heading" : "1 Introduction",
      "text" : "Recently task-oriented dialog systems have been attracting more and more research efforts (Gao et al., 2019; Zhang et al., 2020b), where understanding user utterances is a critical precursor to the success of such dialog systems. While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use. ∗Equal contribution. †Corresponding author.\nReal dialogs between human participants involve language phenomena that do not contribute so much to the intent of communication. As shown in Fig. 1, user expressions can be of high lexical and syntactic diversity when a system is deployed to users; typed texts may differ significantly from those recognized from voice speech; interaction environments may be full of chaos and even users themselves may introduce irrelevant noises such that the system can hardly get clean user input.\nUnfortunately, neural LU models are vulnerable to these natural perturbations that are legitimate inputs but not observed in training data. For example, Bickmore et al. (2018) found that popular conversational assistants frequently failed to understand real health-related scenarios and were unable to deliver adequate responses on time. Although many studies have discussed the LU robustness (Ray et al., 2018; Zhu et al., 2018; Iyyer et al., 2018; Yoo et al., 2019; Ren et al., 2019; Jin et al., 2020; He et al., 2020), there is a lack of systematic studies for real-life robustness issues and corresponding benchmarks for evaluating task-oriented dialog systems.\nIn order to study the real-world robustness issues, we define the LU robustness from three aspects: language variety, speech characteristics and noise perturbation. While collecting dialogs from deployed systems could obtain realistic data distribution, it is quite costly and not scalable since a large number of conversational interactions with real users are required. Therefore, we propose an automatic method LAUG for Language understanding AUGmentation in this paper to approximate the natural perturbations to existing data. LAUG is a black-box testing toolkit on LU robustness composed of four data augmentation methods, including word perturbation, text paraphrasing, speech recognition, and speech disfluency.\nWe instantiate LAUG on two dialog corpora\nFrames (El Asri et al., 2017) and MultiWOZ (Budzianowski et al., 2018) to demonstrate the toolkit’s effectiveness. Quality evaluation by annotators indicates that the utterances augmented by LAUG are reasonable and appropriate with regards to each augmentation approach’s target. A number of LU models with different categories and training paradigms are tested as base models with in-depth analysis. Experiments indicate a sharp performance decline in most baselines in terms of each robustness aspect. Real user evaluation further verifies that LAUG well reflects real-world robustness issues. Since our toolkit is model-agnostic and does not require model parameters or gradients, the augmented data can be easily obtained for both training and testing to build a robust dialog system.\nOur contributions can be summarized as follows: (1) We classify the LU robustness systematically into three aspects that occur in real-world dialog, including linguistic variety, speech characteristics and noise perturbation; (2) We propose a general and model-agnostic toolkit, LAUG, which is an integration of four data augmentation methods on LU that covers the three aspects. (3) We conduct an in-depth analysis of LU robustness on two dialog corpora with a variety of baselines and standardized evaluation measures. (4) Quality and user evaluation results demonstrate that the augmented data are representative of real-world noisy data, therefore can be used for future research to test the LU robustness in task-oriented dialog1."
    }, {
      "heading" : "2 Robustness Type",
      "text" : "We summarize several common interleaved challenges in language understanding from three aspects, as shown in Fig. 1b:\nLanguage Variety A modern dialog system in a text form has to interact with a large variety of real users. The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020).\nSpeech Characteristics The dialog system can take voice input or typed text, but these two differ in many ways. For example, written language\n1The data, toolkit, and codes are available at https: //github.com/thu-coai/LAUG, and will be merged into https://github.com/thu-coai/ConvLab-2 (Zhu et al., 2020).\ntends to be more complex and intricate with longer sentences and many subordinate clauses, whereas spoken language can contain repetitions, incomplete sentences, self-corrections and interruptions (Wang et al., 2020a; Park et al., 2019; Wang et al., 2020b; Honal and Schultz, 2003; Zhu et al., 2018).\nNoise Perturbation Most dialog systems are trained only on noise-free interactions. However, there are various noises in the real world, including background noise, channel noise, misspelling, and grammar mistakes (Xu and Sarikaya, 2014; Li and Qiu, 2020; Yoo et al., 2019; Henderson et al., 2012; Ren et al., 2019)."
    }, {
      "heading" : "3 LAUG: Language Understanding Augmentation",
      "text" : "This section introduces commonly observed out-ofdistribution data in real-world dialog into existing corpora. We approximate natural perturbations in an automatic way instead of collecting real data by asking users to converse with a dialog system.\nTo achieve our goals, we propose a toolkit LAUG, for black-box evaluation of LU robustness. It is an ensemble of four data augmentation approaches, including Word Perturbation (WP), Text Paraphrasing (TP), Speech Recognition (SR), and Speech Disfluency (SD). Noting that LAUG is modelagnostic and can be applied to any LU dataset theoretically. Each augmentation approach tests\none or two proposed aspects of robustness as Table 1 shows. The intrinsic evaluation of the chosen approaches will be given in Sec. 4.\nTask Formulation Given the dialog context Xt = {x2t−m, . . . , x2t−1, x2t} at dialog turn t, where each x is an utterance and m is the size of sliding window that controls the length of utilizing dialog history, the model should recognize yt, the dialog act (DA) of x2t. Empirically, we set m = 2 in the experiment. Let U ,S denote the set of user/system utterances, respectively. Then, we have x2t−2i ∈ U and x2t−2i−1 ∈ S. The task of this paper is to examine different LU models whether they can predict yt correctly given a perturbed input X̃t. The perturbation is only performed on user utterances.\nWord Perturbation Inspired by EDA (Easy Data Augmentation) (Wei and Zou, 2019), we propose its semantically conditioned version, SC-EDA, which considers task-specific augmentation operations in LU. SC-EDA injects word-level perturbation into each utterance x′ and updates its corresponding semantic label y′.\nTable 2 shows an example of SC-EDA. Original EDA randomly performs one of the four operations, including synonym replacement, random insertion, random swap and random deletion2. Noting that, to keep the label unchanged, words related to slot\n2See the EDA paper for details of each operation.\nvalues of dialog acts are not modified in these four operations. Additionally, we design slot value replacement, which changes the utterance and label at the same time to test model’s generalization to unseen entities. Some randomly picked slot values are replaced by unseen values with the same slot name in the database or crawled from web sources. For example in Table 2, “Cambridge” is replaced by “Liverpool”, where both belong to the same slot name “dest” (destination).\nSynonym replacement and slot value replacement aim at increasing the language variety, while random word insertion/deletion/swap test the robustness of noise perturbation. From another perspective, four operations from EDA perform an Invariance test, while slot value replacement conducts a Directional Expectation test according to CheckList (Ribeiro et al., 2020).\nText Paraphrasing The target of text paraphrasing is to generate a new utterance x′ 6= x while maintaining its dialog act unchanged, i.e. y′ = y. We applied SC-GPT (Peng et al., 2020), a finetuned language model conditioned on the dialog acts, to paraphrase the sentences as data augmentation. Specifically, it characterizes the conditional probability pθ(x|y) = ∏K k=1 pθ(xk|x<k, y),where x<k denotes all the tokens before the k-th position. The model parameters θ are trained by maximizing the log-likelihood of pθ.\nWe observe that co-reference and ellipsis frequently occurs in user utterances. Therefore, we propose different encoding strategies during paraphrasing to further evaluate each model’s capacity for context resolution. In particular, if the user mentions a certain domain for the first time in a dialog, we will insert a “*” mark into the sequential dialog act y′ to indicate that the user tends to express without co-references or ellipsis, as shown in Table 3. Then SC-GPT is finetuned on the processed data so that it can be aware of dialog context when generating paraphrases. As a result, we find\nthat the average token length of generated utterances with/without “*” is 15.96/12.67 respectively after SC-GPT’s finetuning on MultiWOZ.\nIt should be noted that slot values of an utterance can be paraphrased by models, resulting in a different semantic meaning y′. To prevent generating irrelevant sentences, we apply automatic value detection in paraphrases with original slot values by fuzzy matching3 , and replace the detected values in bad paraphrases with original values. In addition, we filter out paraphrases that have missing or redundant information compared to the original utterance.\nSpeech Recognition We simulate the speech recognition (SR) process with a TTS-ASR pipeline (Park et al., 2019). First we transfer textual user utterance x to its audio form a using gTTS4 (Oord et al., 2016), a Text-to-Speech system. Then audio data is translated back into text x′ by DeepSpeech2 (Amodei et al., 2016), an Automatic Speech Recognition (ASR) system. We directly use the released models in the DeepSpeech2 repository5 with the original configuration, where the speech model is trained on Baidu Internal English Dataset, and the language model is trained on CommonCrawl Data.\nTable 4 shows some typical examples of our SR augmentation. ASR sometimes wrongly identifies one word as another with similar pronunciation. Liaison constantly occurs between successive words. Expressions with numbers including time and price are written in numerical form but different in spoken language.\nSince SR may modify the slot values in the translated utterances, fuzzy value detection is employed here to handle similar sounds and liaison problems when it extracts slot values to obtain a semantic label y′. However, we do not replace the noisy value with the original value as we encourage such misrecognition in SR, thus y′ 6= y is allowed. Moreover, numerical terms are normalized to deal with the spoken number problem. Most slot values could\n3https://pypi.org/project/fuzzywuzzy/ 4https://pypi.org/project/gTTS/ 5https://github.com/PaddlePaddle/\nDeepSpeech\nbe relocated by our automatic value detection rules. The remainder slot values which vary too much to recognize are discarded along with their corresponding labels.\nSpeech Disfluency Disfluency is a common feature of spoken language. We follow the categorization of disfluency in previous works (Lickley, 1995; Wang et al., 2020b): filled pauses, repeats, restarts, and repairs.\nWe present some examples of SD in Table 5. Filler words (“um”, “uh”) are injected into the sentence to present pauses. Repeats are inserted by repeating the previous word. In order to approximate the real distribution of disfluency, the interruption points of filled pauses and repeats are predicted by a Bi-LSTM+CRF model (Zayats et al., 2016) trained on an annotated dataset SwitchBoard (Godfrey et al., 1992), which was collected from real human talks. For restarts, we insert false start terms (“I just”) as a prefix of the utterance to simulate self-correction. In LU task, we apply repairs on slot values to fool the models to predict wrong labels. We take the original slot value as Repair (“Cambridge”) and take another value with the same slot name as Reparandum (“Liverpool”). An edit term (“sorry, I mean”) is inserted between Repair and Reparandum to construct a correction. The filler words, restart terms, and edit terms and their occurrence frequency are all sampled from their distribution in SwitchBoard.\nIn order to keep the spans of slot values intact, each span is regarded as one whole word. No insertions are allowed to operate inside the span. Therefore, SD augmentation do not change the original semantic and labels of the utterance, i.e. y′ = y."
    }, {
      "heading" : "4 Experimental Setup",
      "text" : ""
    }, {
      "heading" : "4.1 Data Preparation",
      "text" : "In our experiments we adopt Frames6 (El Asri et al., 2017) and MultiWOZ (Budzianowski et al., 2018), which are two task-oriented dialog datasets where\n6As data division was not defined in Frames, we split the data into training/validation/test set with a ratio of 8:1:1.\nsemantic labels of user utterances are annotated. In particular, MultiWOZ is one of the most challenging datasets due to its multi-domain setting and complex ontology, and we conduct our experiments on the latest annotation-enhanced version MultiWOZ 2.3 (Han et al., 2020), which provides cleaned annotations of user dialog acts (i.e. semantic labels). The dialog act consists of four parts: domain, intent, slot names, and slot values. The statistics of two datasets are shown in Table 6. Following Takanobu et al. (2020), we calculate overall F1 scores as evaluation metrics due to the multiintent setting in LU.\nThe data are augmented with the inclusion of its copies, leading to a composite of all 4 augmentation types with equal proportion. Other setups are described in each experiment7.\nTable 7 shows the change rates in different as7See appendix for the hyperparameter setting of LAUG.\npects by comparing our augmented utterances with the original counterparts. We could find each augmentation method has a distinct effect on the data. For instance, TP rewrites the text without changing the original meaning, thus lexical and syntactic representations dramatically change, while most slot values remain unchanged. In contrast, SR makes the lowest change rate in characters and words but modifies the most slot values due to the speech misrecognition."
    }, {
      "heading" : "4.2 Quality Evaluation",
      "text" : "To ensure the quality of our augmented test set, we conduct human annotation on 1,000 sampled utterances in each augmented test set of MultiWOZ. We ask annotators to check whether our augmented utterances are reasonable and our autodetected value annotations are correct (two true-orfalse questions). According to the feature of each augmentation method, different evaluation protocols are used. For TP and SD, annotators check whether the meaning of utterances and dialog acts are unchanged. For WP, changing slot values is allowed due to slot value replacement, but the slot name should be the same. For SR, annotators are asked to judge on the similarity of pronunciation rather than semantics. In summary, all the high scores in Table 7 demonstrate that LAUG makes reasonable augmented examples."
    }, {
      "heading" : "4.3 Baselines",
      "text" : "LU models roughly fall into two categories: classification-based and generation-based models. Classification based models (Hakkani-Tür et al., 2016; Goo et al., 2018) extract semantics by intent detection and slot tagging. Intent detection is commonly regarded as a multi-label classification task, and slot tagging is often treated as a sequence labeling task with BIO format (Ramshaw and Marcus, 1999), as shown in Fig. 2a. Generation-based mod-\nels (Liu and Lane, 2016; Zhao and Feng, 2018) generate a dialog act containing intent and slot values. They treat LU as a sequence-to-sequence problem and transform a dialog act into a sequential structure as shown in Fig. 2b. Five base models with different categories are used in the experiments, as shown in Table 9.\nTo support a multi-intent setting in classificationbased models, we decouple the LU process as follows: first perform domain classification and intent detection, then concatenate two special tokens which indicate the detected domain and intent (e.g. [restaurant][inform]) at the beginning of the input sequence, and last encode the new sequence to predict slot tags. In this way, the model can address overlapping slot values when values are shared in\ndifferent dialog acts."
    }, {
      "heading" : "5 Evaluation Results",
      "text" : ""
    }, {
      "heading" : "5.1 Main Results",
      "text" : "We conduct robustness testing on all three capacities for five base models using four augmentation methods in LAUG. All baselines are first trained on the original datasets, then finetuned on the augmented datasets. Overall F1-measure performance on Frames and MultiWOZ is shown in Table 8. All experiments are conducted over 5 runs, and averaged results are reported.\nRobustness for each capacity can be measured by performance drops on the corresponding augmented test sets. All models achieve some performance recovery on augmented test sets after trained on the augmented data, while keeping a comparable result on the original test set. This indicates the effectiveness of LAUG in improving the model’s robustness.\nWe observe that pre-trained models outperform non-pre-trained ones on both original and augmented test sets. Classification-based models have better performance and are more robust than generation-based models. ToD-BERT, the state-\nof-the-art model which was further pre-trained on task-oriented dialog data, has comparable performance with BERT. With most augmentation methods, ToD-BERT shows slightly better robustness than BERT.\nSince the data volume of Frames is far less than that of MultiWOZ, the performance improvement of pre-trained models on Frames is larger than that on MultiWOZ. Due to the same reason, augmented training data benefits the non-pre-trained models performance of on Ori. test set more remarkably in Frames where data is not sufficient.\nAmong the four augmentation methods, SR has the largest impact on the models’ performance, and SD comes the second. The dramatic performance drop when testing on SR and SD data indicates that robustness for speech characteristics may be the most challenging issue.\nFig. 3 shows how the performance of BERT and GPT-2 changes on MultiWOZ when the ratio of augmented training data to the original data varies from 0.1 to 4.0. F1 scores on augmented test sets increase when there are more augmented data for training. The performance of BERT on augmented test sets is improved when augmentation ratio is less than 0.5 but becomes almost unchanged after 0.5 while GPT-2 keeps increasing stably. This result shows the different characteristics between classification-based models and generation-based models when finetuned with augmented data."
    }, {
      "heading" : "5.2 Ablation Study",
      "text" : "Between augmentation approaches In order to study the influence of each augmentation approach\nin LAUG, we test the performance changes when one augmentation approach is removed from constructing augmented training data. Results on MultiWOZ are shown in Table 10.\nLarge performance decline on each augmented test set is observed when the corresponding augmentation approach is removed in constructing training data. The performance after removing an augmentation method is comparable to the one without augmented training data. Only slight changes are observed without other approaches. These results indicate that our four augmentation approaches are relatively orthogonal.\nWithin augmentation approach Our implementation of WP and SD consist of several func-\ntional components. Ablation experiments here show how much performance is affected by each component in augmented test sets.\nOriginal EDA consists of four functions as described in Table 2. Performance differences (Diff.) can reflect the influences of those components in Table 11a. The additional function of our SC-EDA is slot value replacement. We can also observe an increase in performance when it is removed, especially for MILU. This implies a lack of LU robustness in detecting unseen entities.\nTable 11b shows the results of ablation study on SD. Among the four types of disfluencies described in Table 5, repairs has the largest impact on models’ performance. The performance is also affected by pauses but to a less extent. The influences of repeats and restarts are small, which indicates that neural models are robust to handle these two problems."
    }, {
      "heading" : "5.3 User Evaluation",
      "text" : "In order to test whether the data automatically augmented by LAUG can reflect and alleviate practical robustness problems, we conduct a real user evaluation. We collected 240 speech utterances from real humans as follows: First, we sampled 120 combinations of DA from the test set of MultiWOZ. Given a combination, each user was asked to speak two utterances with different expressions, in their own language habits. Then the audio signals were recognized into text using DeepSpeech2, thereby\nconstructing a new test set in real scenarios8. Results on this real test set are shown in Table 12.\nThe performance on the real test set is substantially lower than that on Ori. and Avg., indicating that real user evaluation is much more challenging. This is because multiple robustness issues may be included in one real case, while each augmentation method in LAUG evaluates them separately. Despite the difference, model performance on the real data is remarkably improved after every model is finetuned on the augmented data, verifying that LAUG effectively enhances the model’s real-world robustness."
    }, {
      "heading" : "5.4 Error Analysis",
      "text" : "Table 13 investigates which error type the model has made on the real test set by manually checking all the error outputs of BERT Ori. “Others” are the error cases which are not caused by robustness issues, for example, because of the model’s poor performance. It can be observed that the model seriously suffers to LU robustness (over 70%), and that almost half of the error is due to Language Variety. We find that this is because there are more diverse expressions in real user evaluation than in the original data. After augmented training, we can observe that the number of error cases of Speech Characteristics and Noise Perturbation is relatively decreased. This shows that BERT Aug. can solve these two kinds of problems better. Noting that the sum of four percentages is over 100% since 25% error cases involve multiple robustness issues.\n8See appendix for details on real data collection.\nThis again demonstrates that real user evaluation is more challenging than the original test set9."
    }, {
      "heading" : "6 Related Work",
      "text" : "Robustness in LU has always been a challenge in task-oriented dialog. Several studies have investigated the model’s sensitivity to the collected data distribution, in order to prevent models from overfitting to the training data and improve robustness in the real world. Kang et al. (2018) collected dialogs with templates and paraphrased with crowdsourcing to achieve high coverage and diversity in training data. Dinan et al. (2019) proposed a training schema that involves human in the loop in dialog systems to enhance the model’s defense against human attack in an iterative way. Ganhotra et al. (2020) injected natural perturbation into the dialog history manually to refine over-controlled data generated through crowd-sourcing. All these methods require laborious human intervention. This paper aims to provide an automatic way to test the LU robustness in task-oriented dialog.\nVarious textual adversarial attacks (Zhang et al., 2020a) have been proposed and received increasing attentions these years to measure the robustness of a victim model. Most attack methods perform whitebox attacks (Papernot et al., 2016; Li et al., 2019; Ebrahimi et al., 2018) based on the model’s internal structure or gradient signals. Even some black-box attack models are not purely “black-box”, which require the prediction scores (classification probabilities) of the victim model (Jin et al., 2020; Ren et al., 2019; Alzantot et al., 2018). However, all these methods address random perturbation but do not consider linguistic phenomena to evaluate the real-life generalization of LU models.\nWhile data augmentation can be an efficient method to address data sparsity, it can improve the generalization abilities and measure the model robustness as well (Eshghi et al., 2017). Paraphrasing that rewrites the utterances in dialog has been used to get diverse representation and thus enhancing robustness (Ray et al., 2018; Zhao et al., 2019; Iyyer et al., 2018). Word-level operations (Kolomiyets et al., 2011; Li and Qiu, 2020; Wei and Zou, 2019) including replacement, insertion, and deletion were also proposed to increase language variety. Other studies (Shah et al., 2019; Xu and Sarikaya, 2014) worked on the out-of-vocabulary problem when facing unseen user expression. Some other research\n9See appendix for case study.\nfocused on building robust spoken language understanding (Zhu et al., 2018; Henderson et al., 2012; Huang and Chen, 2019) from audio signals beyond text transcripts. Simulating ASR errors (Schatzmann et al., 2007; Park et al., 2019; Wang et al., 2020a) and speaker disfluency (Wang et al., 2020b; Qader et al., 2018) can be promising solutions to enhance robustness to voice input when only textual data are provided. As most work tackles LU robustness from only one perspective, we present a comprehensive study to reveal three critical issues in this paper, and shed light on a thorough robustness evaluation of LU in dialog systems."
    }, {
      "heading" : "7 Conclusion and Discussion",
      "text" : "In this paper, we present a systematic robustness evaluation of language understanding (LU) in taskoriented dialog from three aspects: language variety, speech characteristics, and noise perturbation. Accordingly, we develop four data augmentation methods to approximate these language phenomena. In-depth experiments and analysis are conducted on MultiWOZ and Frames, with both classification- and generation-based LU models. The performance drop of all models on augmented test data indicates that these robustness issues are challenging and critical, while pre-trained models are relatively more robust to LU. Ablation studies are carried out to show the effect and orthogonality of each augmentation approach. We also conduct a real user evaluation and verifies that our augmentation methods can reflect and help alleviate real robustness problems.\nExisting and future dialog models can be evaluated in terms of robustness with our toolkit and data, as our augmentation model does not depend on any particular LU models. Moreover, our proposed robustness evaluation scheme is extensible. In addition to the four approaches in LAUG, more methods to evaluate LU robustness can be considered in the future."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was partly supported by the NSFC projects (Key project with No. 61936010 and regular project with No. 61876096). This work was also supported by the Guoqiang Institute of Tsinghua University, with Grant No. 2019GQG1 and 2020GQG0005. We would like to thank colleagues from HUAWEI for their constant support and valuable discussion."
    }, {
      "heading" : "A Experimental Setup",
      "text" : "A.1 Hyperparameters\nAs for hyperparameters in LAUG, we set the ratio of perturbation number to text length α = n/l = 0.1 in EDA . The learning rate used to finetune SC-GPT in TP is 1e-4, the number of training epoch is 5, and the beam size during inference is 5. In SR, the beam size of the language model in DeepSpeech2 is set to 50. The learning rate of Bi-LSTM+CRF in SD is 1e-3. The threshold of fuzzy matching in automatic value detection is set to 0.9 in TP and 0.7 in SR.\nFor hyperparameters of base models. The learning rate is set to 1e-4 for BERT, 1e-5 for GPT2, and 1e-3 for MILU and CopyNet. The beam-size of GPT2 and CopyNet is 5 during the decoding step.\nA.2 Real Data Collection\nAmong the 120 sampled DA combinations, each combination contains 1 to 3 DAs. Users can organize the DAs in any order provided that they describe DAs with the correct meaning so as to imitate diverse user expressions in real scenarios. Users are also asked to keep natural in both intonation and expression, and communication noise caused by users in speech and language is included during collection. The audios are recorded by users’ PCs under their real environmental noises. We use the same settings of DeepSpeech2 in SR to recognize the collected audios. After automatic span detection (also the same as SR’s) are applied, we conduct human check and annotation to ensure the quality of labels."
    }, {
      "heading" : "B Evaluation Results",
      "text" : "B.1 Prediction Schemes\nIn this section, we study the influence of training/prediction schemes on LU robustness. As described in Sec. 4.3 of the main paper, the process of classification-based LU models is decoupled into two steps to handle multiple labels: one for domain/intent classification and the other for slot tagging. Another strategy is to use the cartesian product of all the components of dialog acts, which yields a joint tagging scheme as presented in ConvLab (Lee et al., 2019). To give an intuitive illustration, the slot tag of the token “Los” becomes “Train-Inform-Depart-B” in the example described in Fig. 2 of the main paper. The classificationbased models can predict the dialog acts within a single step in this way.\nTable 14 shows that MILU and BERT gain from the decoupled scheme on the original test set. This indicates that the decoupled scheme decreases the model complexity by decomposing the output space. Interestingly, there is no consistency between two models in terms of robustness. MILU via the coupled scheme behaves more robustly than the decoupled counterpart (-2.61 vs. -7.05), while BERT with the decoupled scheme outperforms its coupled version in robustness (-6.45 vs. -8.61). Meanwhile, BERT benefits from the decoupled scheme and still achieves 86.95% accuracy, but BERT training with the coupled scheme seems more susceptible. In addition, both MILU and BERT recover more performance by the proposed decoupled scheme. All these results demonstrate the superiority of the decoupled scheme in classification-based LU models.\nB.2 Case Study\nIn Table 15, we present some examples of augmented utterances in MultiWOZ. In terms of model performance, MILU, BERT and GPT-2 perform well on WP and TP in the example while CopyNet misses some dialog acts. For the SR utterance, only BERT obtains all the correct labels. MILU and Copynet both fail to find the changed value spans “lester” and “thirteen forty five”. Copynet’s copy mechanism is fully confused by recognition error and even predicts discontinuous slot values. GPT-2 successfully finds the non-numerical time but misses “leseter”. In the SD utterance, the repair term fools all the models. Overall, in this example, BERT performs quite well while MILU and CopyNet expose some of their defects in robustness.\nTable 16 shows some examples from real user\nevaluation. In case-1, the user says “seventeen o’clock” while time is always represented in numeric formats (e.g. “17:00”) in the dataset, which is a typical Speech Characteristics problem. Case2 could be regarded as a Speech Characteristics or Noise Perturbation case because “please” is wrongly recognized as “police” by ASR models. Case-3 is an example of Language Variety, the user expresses the request of getting ticket price in a\ndifferent way comparing to the dataset. MILU and BERT failed in most of these cases but fixed some error after augmented training."
    } ],
    "references" : [ {
      "title" : "Generating natural language adversarial examples",
      "author" : [ "Moustafa Alzantot", "Yash Sharma", "Ahmed Elgohary", "Bo-Jhang Ho", "Mani Srivastava", "Kai-Wei Chang." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Alzantot et al\\.,? 2018",
      "shortCiteRegEx" : "Alzantot et al\\.",
      "year" : 2018
    }, {
      "title" : "Deep speech 2: End-to-end speech recognition in english and mandarin",
      "author" : [ "Dario Amodei", "Sundaram Ananthanarayanan", "Rishita Anubhai", "Jingliang Bai", "Eric Battenberg", "Carl Case", "Jared Casper", "Bryan Catanzaro", "Qiang Cheng", "Guoliang Chen" ],
      "venue" : null,
      "citeRegEx" : "Amodei et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Amodei et al\\.",
      "year" : 2016
    }, {
      "title" : "Patient and consumer safety risks when using conversational assistants for medical information: an observational study of siri",
      "author" : [ "Timothy W Bickmore", "Ha Trinh", "Stefan Olafsson", "Teresa K O’Leary", "Reza Asadi", "Nathaniel M Rickles", "Ricardo Cruz" ],
      "venue" : null,
      "citeRegEx" : "Bickmore et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Bickmore et al\\.",
      "year" : 2018
    }, {
      "title" : "Multiwoz-a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling",
      "author" : [ "Paweł Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "Iñigo Casanueva", "Stefan Ultes", "Osman Ramadan", "Milica Gasic." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Budzianowski et al\\.,? 2018",
      "shortCiteRegEx" : "Budzianowski et al\\.",
      "year" : 2018
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Build it break it fix it for dialogue safety: Robustness from adversarial human attack",
      "author" : [ "Emily Dinan", "Samuel Humeau", "Bharath Chintagunta", "Jason Weston." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Dinan et al\\.,? 2019",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2019
    }, {
      "title" : "Hotflip: White-box adversarial examples for text classification",
      "author" : [ "Javid Ebrahimi", "Anyi Rao", "Daniel Lowd", "Dejing Dou." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages",
      "citeRegEx" : "Ebrahimi et al\\.,? 2018",
      "shortCiteRegEx" : "Ebrahimi et al\\.",
      "year" : 2018
    }, {
      "title" : "Frames: a corpus for adding memory to goal-oriented dialogue systems",
      "author" : [ "Layla El Asri", "Hannes Schulz", "Shikhar Kr Sarma", "Jeremie Zumer", "Justin Harris", "Emery Fine", "Rahul Mehrotra", "Kaheer Suleman." ],
      "venue" : "Proceedings of the 18th Annual SIG-",
      "citeRegEx" : "Asri et al\\.,? 2017",
      "shortCiteRegEx" : "Asri et al\\.",
      "year" : 2017
    }, {
      "title" : "Bootstrapping incremental dialogue systems from minimal data: the generalisation power of dialogue grammars",
      "author" : [ "Arash Eshghi", "Igor Shalyminov", "Oliver Lemon." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Eshghi et al\\.,? 2017",
      "shortCiteRegEx" : "Eshghi et al\\.",
      "year" : 2017
    }, {
      "title" : "Effects of naturalistic variation in goal-oriented dialog",
      "author" : [ "Jatin Ganhotra", "Robert C Moore", "Sachindra Joshi", "Kahini Wadhawan." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, pages 4013–4020.",
      "citeRegEx" : "Ganhotra et al\\.,? 2020",
      "shortCiteRegEx" : "Ganhotra et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural approaches to conversational ai",
      "author" : [ "Jianfeng Gao", "Michel Galley", "Lihong Li." ],
      "venue" : "Foundations and Trends R",
      "citeRegEx" : "Gao et al\\.,? 2019",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Switchboard: Telephone speech corpus for research and development",
      "author" : [ "John J Godfrey", "Edward C Holliman", "Jane McDaniel." ],
      "venue" : "Acoustics, Speech, and Signal Processing, IEEE International Conference on, volume 1, pages 517–520. IEEE",
      "citeRegEx" : "Godfrey et al\\.,? 1992",
      "shortCiteRegEx" : "Godfrey et al\\.",
      "year" : 1992
    }, {
      "title" : "Slot-gated modeling for joint slot filling and intent prediction",
      "author" : [ "Chih-Wen Goo", "Guang Gao", "Yun-Kai Hsu", "Chih-Li Huo", "Tsung-Chieh Chen", "Keng-Wei Hsu", "YunNung Chen." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chap-",
      "citeRegEx" : "Goo et al\\.,? 2018",
      "shortCiteRegEx" : "Goo et al\\.",
      "year" : 2018
    }, {
      "title" : "Incorporating copying mechanism in sequence-to-sequence learning",
      "author" : [ "Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor OK Li." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
      "citeRegEx" : "Gu et al\\.,? 2016",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2016
    }, {
      "title" : "Multi-domain joint semantic frame parsing using bi-directional rnn-lstm",
      "author" : [ "Dilek Hakkani-Tür", "Gokhan Tur", "Asli Celikyilmaz", "Yun-Nung Chen", "Jianfeng Gao", "Li Deng", "YeYi Wang." ],
      "venue" : "Interspeech 2016, pages 715–719.",
      "citeRegEx" : "Hakkani.Tür et al\\.,? 2016",
      "shortCiteRegEx" : "Hakkani.Tür et al\\.",
      "year" : 2016
    }, {
      "title" : "Multiwoz 2.3: A multi-domain taskoriented dataset enhanced with annotation corrections and co-reference annotation",
      "author" : [ "Ting Han", "Ximing Liu", "Ryuichi Takanobu", "Yixin Lian", "Chongxuan Huang", "Wei Peng", "Minlie Huang" ],
      "venue" : null,
      "citeRegEx" : "Han et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning to tag oov tokens by integrating contextual representation and background knowledge",
      "author" : [ "Keqing He", "Yuanmeng Yan", "XU Weiran." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 619–624.",
      "citeRegEx" : "He et al\\.,? 2020",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2020
    }, {
      "title" : "Discriminative spoken language understanding using word confusion networks",
      "author" : [ "Matthew Henderson", "Milica Gašić", "Blaise Thomson", "Pirros Tsiakoulis", "Kai Yu", "Steve Young." ],
      "venue" : "2012 IEEE Spoken Language Technology Workshop (SLT), pages 176–",
      "citeRegEx" : "Henderson et al\\.,? 2012",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2012
    }, {
      "title" : "Correction of disfluencies in spontaneous speech using a noisychannel approach",
      "author" : [ "Matthias Honal", "Tanja Schultz." ],
      "venue" : "Eighth European Conference on Speech Communication and Technology, pages 2781–2784.",
      "citeRegEx" : "Honal and Schultz.,? 2003",
      "shortCiteRegEx" : "Honal and Schultz.",
      "year" : 2003
    }, {
      "title" : "Adapting pretrained transformer to lattices for spoken language understanding",
      "author" : [ "Chao-Wei Huang", "Yun-Nung Chen." ],
      "venue" : "2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), pages 845–852. IEEE.",
      "citeRegEx" : "Huang and Chen.,? 2019",
      "shortCiteRegEx" : "Huang and Chen.",
      "year" : 2019
    }, {
      "title" : "Adversarial example generation with syntactically controlled paraphrase networks",
      "author" : [ "Mohit Iyyer", "John Wieting", "Kevin Gimpel", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Iyyer et al\\.,? 2018",
      "shortCiteRegEx" : "Iyyer et al\\.",
      "year" : 2018
    }, {
      "title" : "Is bert really robust? a strong baseline for natural language attack on text classification and entailment",
      "author" : [ "Di Jin", "Zhijing Jin", "Joey Tianyi Zhou", "Peter Szolovits." ],
      "venue" : "Proceedings of the AAAI conference on artificial intelligence, volume 34, pages",
      "citeRegEx" : "Jin et al\\.,? 2020",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2020
    }, {
      "title" : "Data collection for dialogue system: A startup perspective",
      "author" : [ "Yiping Kang", "Yunqi Zhang", "Jonathan K Kummerfeld", "Lingjia Tang", "Jason Mars." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Kang et al\\.,? 2018",
      "shortCiteRegEx" : "Kang et al\\.",
      "year" : 2018
    }, {
      "title" : "Model-portability experiments for textual temporal analysis",
      "author" : [ "Oleksandr Kolomiyets", "Steven Bethard", "MarieFrancine Moens." ],
      "venue" : "Proceedings of the 49th annual meeting of the association for computational linguistics: human language tech-",
      "citeRegEx" : "Kolomiyets et al\\.,? 2011",
      "shortCiteRegEx" : "Kolomiyets et al\\.",
      "year" : 2011
    }, {
      "title" : "Convlab: Multi-domain end-to-end dialog system platform",
      "author" : [ "Sungjin Lee", "Qi Zhu", "Ryuichi Takanobu", "Zheng Zhang", "Yaoqin Zhang", "Xiang Li", "Jinchao Li", "Baolin Peng", "Xiujun Li", "Minlie Huang" ],
      "venue" : "In Proceedings of the 57th Annual Meeting",
      "citeRegEx" : "Lee et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2019
    }, {
      "title" : "Textbugger: Generating adversarial text against real-world applications",
      "author" : [ "Jinfeng Li", "Shouling Ji", "Tianyu Du", "Bo Li", "Ting Wang." ],
      "venue" : "26th Annual Network and Distributed System Security Symposium.",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Textat: Adversarial training for natural language understanding with token-level perturbation",
      "author" : [ "Linyang Li", "Xipeng Qiu." ],
      "venue" : "arXiv preprint arXiv:2004.14543.",
      "citeRegEx" : "Li and Qiu.,? 2020",
      "shortCiteRegEx" : "Li and Qiu.",
      "year" : 2020
    }, {
      "title" : "Missing disfluencies",
      "author" : [ "Robin J Lickley." ],
      "venue" : "Proceedings of the international congress of phonetic sciences, volume 4, pages 192–195.",
      "citeRegEx" : "Lickley.,? 1995",
      "shortCiteRegEx" : "Lickley.",
      "year" : 1995
    }, {
      "title" : "Attention-based recurrent neural network models for joint intent detection and slot filling",
      "author" : [ "Bing Liu", "Ian Lane." ],
      "venue" : "Interspeech 2016, pages 685–689.",
      "citeRegEx" : "Liu and Lane.,? 2016",
      "shortCiteRegEx" : "Liu and Lane.",
      "year" : 2016
    }, {
      "title" : "Cm-net: A novel collaborative memory network for spoken language understanding",
      "author" : [ "Yijin Liu", "Fandong Meng", "Jinchao Zhang", "Jie Zhou", "Yufeng Chen", "Jinan Xu." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Wavenet: A generative model for raw audio",
      "author" : [ "Aaron van den Oord", "Sander Dieleman", "Heiga Zen", "Karen Simonyan", "Oriol Vinyals", "Alex Graves", "Nal Kalchbrenner", "Andrew Senior", "Koray Kavukcuoglu." ],
      "venue" : "arXiv preprint arXiv:1609.03499.",
      "citeRegEx" : "Oord et al\\.,? 2016",
      "shortCiteRegEx" : "Oord et al\\.",
      "year" : 2016
    }, {
      "title" : "Crafting adversarial input sequences for recurrent neural networks",
      "author" : [ "Nicolas Papernot", "Patrick McDaniel", "Ananthram Swami", "Richard Harang." ],
      "venue" : "MILCOM 2016-2016 IEEE Military Communications Conference, pages 49–54. IEEE.",
      "citeRegEx" : "Papernot et al\\.,? 2016",
      "shortCiteRegEx" : "Papernot et al\\.",
      "year" : 2016
    }, {
      "title" : "Specaugment: A simple data augmentation method for automatic speech recognition",
      "author" : [ "Daniel S Park", "William Chan", "Yu Zhang", "Chung-Cheng Chiu", "Barret Zoph", "Ekin D Cubuk", "Quoc V Le." ],
      "venue" : "Interspeech 2019, pages 2613–2617.",
      "citeRegEx" : "Park et al\\.,? 2019",
      "shortCiteRegEx" : "Park et al\\.",
      "year" : 2019
    }, {
      "title" : "Few-shot natural language generation for task-oriented dialog",
      "author" : [ "Baolin Peng", "Chenguang Zhu", "Chunyuan Li", "Xiujun Li", "Jinchao Li", "Michael Zeng", "Jianfeng Gao." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Lan-",
      "citeRegEx" : "Peng et al\\.,? 2020",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2020
    }, {
      "title" : "Disfluency insertion for spontaneous tts: Formalization and proof of concept",
      "author" : [ "Raheel Qader", "Gwénolé Lecorvé", "Damien Lolive", "Pascale Sébillot." ],
      "venue" : "International Conference on Statistical Language and Speech Processing, pages 32–44. Springer.",
      "citeRegEx" : "Qader et al\\.,? 2018",
      "shortCiteRegEx" : "Qader et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "OpenAI Blog, 1(8):9.",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Text chunking using transformation-based learning",
      "author" : [ "Lance A Ramshaw", "Mitchell P Marcus." ],
      "venue" : "Natural language processing using very large corpora, pages 157–176. Springer.",
      "citeRegEx" : "Ramshaw and Marcus.,? 1999",
      "shortCiteRegEx" : "Ramshaw and Marcus.",
      "year" : 1999
    }, {
      "title" : "Robust spoken language understanding via paraphrasing",
      "author" : [ "Avik Ray", "Yilin Shen", "Hongxia Jin." ],
      "venue" : "Interspeech 2018, pages 3454–3458.",
      "citeRegEx" : "Ray et al\\.,? 2018",
      "shortCiteRegEx" : "Ray et al\\.",
      "year" : 2018
    }, {
      "title" : "Generating natural language adversarial examples through probability weighted word saliency",
      "author" : [ "Shuhuai Ren", "Yihe Deng", "Kun He", "Wanxiang Che." ],
      "venue" : "Proceedings of the 57th annual meeting of the association for computational linguistics, pages 1085–",
      "citeRegEx" : "Ren et al\\.,? 2019",
      "shortCiteRegEx" : "Ren et al\\.",
      "year" : 2019
    }, {
      "title" : "Beyond accuracy: Behavioral testing of nlp models with checklist",
      "author" : [ "Marco Tulio Ribeiro", "Tongshuang Wu", "Carlos Guestrin", "Sameer Singh." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4902–",
      "citeRegEx" : "Ribeiro et al\\.,? 2020",
      "shortCiteRegEx" : "Ribeiro et al\\.",
      "year" : 2020
    }, {
      "title" : "Error simulation for training statistical dialogue systems",
      "author" : [ "Jost Schatzmann", "Blaise Thomson", "Steve Young." ],
      "venue" : "2007 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), pages 526–531. IEEE.",
      "citeRegEx" : "Schatzmann et al\\.,? 2007",
      "shortCiteRegEx" : "Schatzmann et al\\.",
      "year" : 2007
    }, {
      "title" : "Robust zero-shot cross-domain slot filling with example values",
      "author" : [ "Darsh Shah", "Raghav Gupta", "Amir Fayazi", "Dilek Hakkani-Tur." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5484–5490.",
      "citeRegEx" : "Shah et al\\.,? 2019",
      "shortCiteRegEx" : "Shah et al\\.",
      "year" : 2019
    }, {
      "title" : "Is your goaloriented dialog model performing really well? empirical analysis of system-wise evaluation",
      "author" : [ "Ryuichi Takanobu", "Qi Zhu", "Jinchao Li", "Baolin Peng", "Jianfeng Gao", "Minlie Huang." ],
      "venue" : "Proceedings of the 21th Annual Meeting of the Special",
      "citeRegEx" : "Takanobu et al\\.,? 2020",
      "shortCiteRegEx" : "Takanobu et al\\.",
      "year" : 2020
    }, {
      "title" : "Data augmentation for training dialog models robust to speech recognition errors",
      "author" : [ "Longshaokan Wang", "Maryam Fazel-Zarandi", "Aditya Tiwari", "Spyros Matsoukas", "Lazaros Polymenakos." ],
      "venue" : "Proceedings of the 2nd Workshop on Natural Language Pro-",
      "citeRegEx" : "Wang et al\\.,? 2020a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Multitask self-supervised learning for disfluency detection",
      "author" : [ "Shaolei Wang", "Wangxiang Che", "Qi Liu", "Pengda Qin", "Ting Liu", "William Yang Wang." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9193–9200.",
      "citeRegEx" : "Wang et al\\.,? 2020b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "A bimodel based rnn semantic frame parsing model for intent detection and slot filling",
      "author" : [ "Yu Wang", "Yilin Shen", "Hongxia Jin." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics:",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Eda: Easy data augmentation techniques for boosting performance on text classification tasks",
      "author" : [ "Jason Wei", "Kai Zou." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer-",
      "citeRegEx" : "Wei and Zou.,? 2019",
      "shortCiteRegEx" : "Wei and Zou.",
      "year" : 2019
    }, {
      "title" : "Tod-bert: Pre-trained natural language understanding for task-oriented dialogue",
      "author" : [ "Chien-Sheng Wu", "Steven CH Hoi", "Richard Socher", "Caiming Xiong." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Wu et al\\.,? 2020",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Targeted feature dropout for robust slot filling in natural language understanding",
      "author" : [ "Puyang Xu", "Ruhi Sarikaya." ],
      "venue" : "Interspeech 2014, pages 258–262.",
      "citeRegEx" : "Xu and Sarikaya.,? 2014",
      "shortCiteRegEx" : "Xu and Sarikaya.",
      "year" : 2014
    }, {
      "title" : "Data augmentation for spoken language understanding via joint variational generation",
      "author" : [ "Kang Min Yoo", "Youhyun Shin", "Sang-goo Lee." ],
      "venue" : "Proceedings of the AAAI conference on artificial intelligence, volume 33, pages 7402–7409.",
      "citeRegEx" : "Yoo et al\\.,? 2019",
      "shortCiteRegEx" : "Yoo et al\\.",
      "year" : 2019
    }, {
      "title" : "Disfluency detection using a bidirectional lstm",
      "author" : [ "Vicky Zayats", "Mari Ostendorf", "Hannaneh Hajishirzi." ],
      "venue" : "Interspeech 2016, pages 2523–2527.",
      "citeRegEx" : "Zayats et al\\.,? 2016",
      "shortCiteRegEx" : "Zayats et al\\.",
      "year" : 2016
    }, {
      "title" : "Adversarial attacks on deep-learning models in natural language processing: A survey",
      "author" : [ "Wei Emma Zhang", "Quan Z Sheng", "Ahoud Alhazmi", "Chenliang Li." ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology (TIST), 11(3):1–41.",
      "citeRegEx" : "Zhang et al\\.,? 2020a",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Recent advances and challenges in task-oriented dialog systems",
      "author" : [ "Zheng Zhang", "Ryuichi Takanobu", "Qi Zhu", "Minlie Huang", "Xiaoyan Zhu." ],
      "venue" : "Science China Technological Sciences, pages 1–17.",
      "citeRegEx" : "Zhang et al\\.,? 2020b",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Improving slot filling in spoken language understanding with joint pointer and attention",
      "author" : [ "Lin Zhao", "Zhe Feng." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 426–431.",
      "citeRegEx" : "Zhao and Feng.,? 2018",
      "shortCiteRegEx" : "Zhao and Feng.",
      "year" : 2018
    }, {
      "title" : "Data augmentation with atomic templates for spoken language understanding",
      "author" : [ "Zijian Zhao", "Su Zhu", "Kai Yu." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer-",
      "citeRegEx" : "Zhao et al\\.,? 2019",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2019
    }, {
      "title" : "Convlab2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems",
      "author" : [ "Qi Zhu", "Zheng Zhang", "Yan Fang", "Xiang Li", "Ryuichi Takanobu", "Jinchao Li", "Baolin Peng", "Jianfeng Gao", "Xiaoyan Zhu", "Minlie Huang." ],
      "venue" : "Proceedings",
      "citeRegEx" : "Zhu et al\\.,? 2020",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2020
    }, {
      "title" : "Robust spoken language understanding with unsupervised asrerror adaptation",
      "author" : [ "Su Zhu", "Ouyu Lan", "Kai Yu." ],
      "venue" : "2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6179–6183. IEEE.",
      "citeRegEx" : "Zhu et al\\.,? 2018",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "Recently task-oriented dialog systems have been attracting more and more research efforts (Gao et al., 2019; Zhang et al., 2020b), where understanding user utterances is a critical precursor to the success of such dialog systems.",
      "startOffset" : 90,
      "endOffset" : 129
    }, {
      "referenceID" : 52,
      "context" : "Recently task-oriented dialog systems have been attracting more and more research efforts (Gao et al., 2019; Zhang et al., 2020b), where understanding user utterances is a critical precursor to the success of such dialog systems.",
      "startOffset" : 90,
      "endOffset" : 129
    }, {
      "referenceID" : 45,
      "context" : "While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use.",
      "startOffset" : 99,
      "endOffset" : 194
    }, {
      "referenceID" : 53,
      "context" : "While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use.",
      "startOffset" : 99,
      "endOffset" : 194
    }, {
      "referenceID" : 12,
      "context" : "While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use.",
      "startOffset" : 99,
      "endOffset" : 194
    }, {
      "referenceID" : 29,
      "context" : "While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use.",
      "startOffset" : 99,
      "endOffset" : 194
    }, {
      "referenceID" : 41,
      "context" : "While modern neural networks have achieved state-of-the-art results on language understanding (LU) (Wang et al., 2018; Zhao and Feng, 2018; Goo et al., 2018; Liu et al., 2019; Shah et al., 2019), their robustness to changes in the input distribution is still one of the biggest challenges in practical use.",
      "startOffset" : 99,
      "endOffset" : 194
    }, {
      "referenceID" : 3,
      "context" : ", 2017) and MultiWOZ (Budzianowski et al., 2018) to demonstrate the toolkit’s effectiveness.",
      "startOffset" : 21,
      "endOffset" : 48
    }, {
      "referenceID" : 37,
      "context" : "The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020).",
      "startOffset" : 177,
      "endOffset" : 272
    }, {
      "referenceID" : 21,
      "context" : "The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020).",
      "startOffset" : 177,
      "endOffset" : 272
    }, {
      "referenceID" : 16,
      "context" : "The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020).",
      "startOffset" : 177,
      "endOffset" : 272
    }, {
      "referenceID" : 54,
      "context" : "The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020).",
      "startOffset" : 177,
      "endOffset" : 272
    }, {
      "referenceID" : 9,
      "context" : "The user utterances can be characterized by a series of linguistic phenomena with a long tail of variations in terms of spelling, vocabulary, lexical/syntactic/pragmatic choice (Ray et al., 2018; Jin et al., 2020; He et al., 2020; Zhao et al., 2019; Ganhotra et al., 2020).",
      "startOffset" : 177,
      "endOffset" : 272
    }, {
      "referenceID" : 43,
      "context" : "sentences and many subordinate clauses, whereas spoken language can contain repetitions, incomplete sentences, self-corrections and interruptions (Wang et al., 2020a; Park et al., 2019; Wang et al., 2020b; Honal and Schultz, 2003; Zhu et al., 2018).",
      "startOffset" : 146,
      "endOffset" : 248
    }, {
      "referenceID" : 32,
      "context" : "sentences and many subordinate clauses, whereas spoken language can contain repetitions, incomplete sentences, self-corrections and interruptions (Wang et al., 2020a; Park et al., 2019; Wang et al., 2020b; Honal and Schultz, 2003; Zhu et al., 2018).",
      "startOffset" : 146,
      "endOffset" : 248
    }, {
      "referenceID" : 44,
      "context" : "sentences and many subordinate clauses, whereas spoken language can contain repetitions, incomplete sentences, self-corrections and interruptions (Wang et al., 2020a; Park et al., 2019; Wang et al., 2020b; Honal and Schultz, 2003; Zhu et al., 2018).",
      "startOffset" : 146,
      "endOffset" : 248
    }, {
      "referenceID" : 18,
      "context" : "sentences and many subordinate clauses, whereas spoken language can contain repetitions, incomplete sentences, self-corrections and interruptions (Wang et al., 2020a; Park et al., 2019; Wang et al., 2020b; Honal and Schultz, 2003; Zhu et al., 2018).",
      "startOffset" : 146,
      "endOffset" : 248
    }, {
      "referenceID" : 56,
      "context" : "sentences and many subordinate clauses, whereas spoken language can contain repetitions, incomplete sentences, self-corrections and interruptions (Wang et al., 2020a; Park et al., 2019; Wang et al., 2020b; Honal and Schultz, 2003; Zhu et al., 2018).",
      "startOffset" : 146,
      "endOffset" : 248
    }, {
      "referenceID" : 48,
      "context" : "However, there are various noises in the real world, including background noise, channel noise, misspelling, and grammar mistakes (Xu and Sarikaya, 2014; Li and Qiu, 2020; Yoo et al., 2019; Henderson et al., 2012; Ren et al., 2019).",
      "startOffset" : 130,
      "endOffset" : 231
    }, {
      "referenceID" : 26,
      "context" : "However, there are various noises in the real world, including background noise, channel noise, misspelling, and grammar mistakes (Xu and Sarikaya, 2014; Li and Qiu, 2020; Yoo et al., 2019; Henderson et al., 2012; Ren et al., 2019).",
      "startOffset" : 130,
      "endOffset" : 231
    }, {
      "referenceID" : 49,
      "context" : "However, there are various noises in the real world, including background noise, channel noise, misspelling, and grammar mistakes (Xu and Sarikaya, 2014; Li and Qiu, 2020; Yoo et al., 2019; Henderson et al., 2012; Ren et al., 2019).",
      "startOffset" : 130,
      "endOffset" : 231
    }, {
      "referenceID" : 17,
      "context" : "However, there are various noises in the real world, including background noise, channel noise, misspelling, and grammar mistakes (Xu and Sarikaya, 2014; Li and Qiu, 2020; Yoo et al., 2019; Henderson et al., 2012; Ren et al., 2019).",
      "startOffset" : 130,
      "endOffset" : 231
    }, {
      "referenceID" : 38,
      "context" : "However, there are various noises in the real world, including background noise, channel noise, misspelling, and grammar mistakes (Xu and Sarikaya, 2014; Li and Qiu, 2020; Yoo et al., 2019; Henderson et al., 2012; Ren et al., 2019).",
      "startOffset" : 130,
      "endOffset" : 231
    }, {
      "referenceID" : 46,
      "context" : "Word Perturbation Inspired by EDA (Easy Data Augmentation) (Wei and Zou, 2019), we propose its semantically conditioned version, SC-EDA, which considers task-specific augmentation operations in LU.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 39,
      "context" : "spective, four operations from EDA perform an Invariance test, while slot value replacement conducts a Directional Expectation test according to CheckList (Ribeiro et al., 2020).",
      "startOffset" : 155,
      "endOffset" : 177
    }, {
      "referenceID" : 33,
      "context" : "We applied SC-GPT (Peng et al., 2020), a finetuned language model conditioned on the dialog acts, to paraphrase the sentences as data augmentation.",
      "startOffset" : 18,
      "endOffset" : 37
    }, {
      "referenceID" : 32,
      "context" : "Speech Recognition We simulate the speech recognition (SR) process with a TTS-ASR pipeline (Park et al., 2019).",
      "startOffset" : 91,
      "endOffset" : 110
    }, {
      "referenceID" : 30,
      "context" : "First we transfer textual user utterance x to its audio form a using gTTS4 (Oord et al., 2016), a Text-to-Speech system.",
      "startOffset" : 75,
      "endOffset" : 94
    }, {
      "referenceID" : 1,
      "context" : "Then audio data is translated back into text x′ by DeepSpeech2 (Amodei et al., 2016), an Automatic Speech Recognition (ASR) system.",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 27,
      "context" : "rization of disfluency in previous works (Lickley, 1995; Wang et al., 2020b): filled pauses, repeats, restarts, and repairs.",
      "startOffset" : 41,
      "endOffset" : 76
    }, {
      "referenceID" : 44,
      "context" : "rization of disfluency in previous works (Lickley, 1995; Wang et al., 2020b): filled pauses, repeats, restarts, and repairs.",
      "startOffset" : 41,
      "endOffset" : 76
    }, {
      "referenceID" : 50,
      "context" : "In order to approximate the real distribution of disfluency, the interruption points of filled pauses and repeats are predicted by a Bi-LSTM+CRF model (Zayats et al., 2016) trained on an annotated dataset SwitchBoard (Godfrey et al.",
      "startOffset" : 151,
      "endOffset" : 172
    }, {
      "referenceID" : 11,
      "context" : ", 2016) trained on an annotated dataset SwitchBoard (Godfrey et al., 1992), which was collected from real human talks.",
      "startOffset" : 52,
      "endOffset" : 74
    }, {
      "referenceID" : 3,
      "context" : ", 2017) and MultiWOZ (Budzianowski et al., 2018), which are two task-oriented dialog datasets where",
      "startOffset" : 21,
      "endOffset" : 48
    }, {
      "referenceID" : 15,
      "context" : "3 (Han et al., 2020), which provides cleaned annotations of user dialog acts (i.",
      "startOffset" : 2,
      "endOffset" : 20
    }, {
      "referenceID" : 14,
      "context" : "Classification based models (Hakkani-Tür et al., 2016; Goo et al., 2018) extract semantics by intent detection and slot tagging.",
      "startOffset" : 28,
      "endOffset" : 72
    }, {
      "referenceID" : 12,
      "context" : "Classification based models (Hakkani-Tür et al., 2016; Goo et al., 2018) extract semantics by intent detection and slot tagging.",
      "startOffset" : 28,
      "endOffset" : 72
    }, {
      "referenceID" : 36,
      "context" : "Intent detection is commonly regarded as a multi-label classification task, and slot tagging is often treated as a sequence labeling task with BIO format (Ramshaw and Marcus, 1999), as shown in Fig.",
      "startOffset" : 154,
      "endOffset" : 180
    }, {
      "referenceID" : 28,
      "context" : "els (Liu and Lane, 2016; Zhao and Feng, 2018) generate a dialog act containing intent and slot values.",
      "startOffset" : 4,
      "endOffset" : 45
    }, {
      "referenceID" : 53,
      "context" : "els (Liu and Lane, 2016; Zhao and Feng, 2018) generate a dialog act containing intent and slot values.",
      "startOffset" : 4,
      "endOffset" : 45
    }, {
      "referenceID" : 51,
      "context" : "Various textual adversarial attacks (Zhang et al., 2020a) have been proposed and received increasing attentions these years to measure the robustness of a victim model.",
      "startOffset" : 36,
      "endOffset" : 57
    }, {
      "referenceID" : 31,
      "context" : "Most attack methods perform whitebox attacks (Papernot et al., 2016; Li et al., 2019; Ebrahimi et al., 2018) based on the model’s internal structure or gradient signals.",
      "startOffset" : 45,
      "endOffset" : 108
    }, {
      "referenceID" : 25,
      "context" : "Most attack methods perform whitebox attacks (Papernot et al., 2016; Li et al., 2019; Ebrahimi et al., 2018) based on the model’s internal structure or gradient signals.",
      "startOffset" : 45,
      "endOffset" : 108
    }, {
      "referenceID" : 6,
      "context" : "Most attack methods perform whitebox attacks (Papernot et al., 2016; Li et al., 2019; Ebrahimi et al., 2018) based on the model’s internal structure or gradient signals.",
      "startOffset" : 45,
      "endOffset" : 108
    }, {
      "referenceID" : 21,
      "context" : "Even some black-box attack models are not purely “black-box”, which require the prediction scores (classification probabilities) of the victim model (Jin et al., 2020; Ren et al., 2019; Alzantot et al., 2018).",
      "startOffset" : 149,
      "endOffset" : 208
    }, {
      "referenceID" : 38,
      "context" : "Even some black-box attack models are not purely “black-box”, which require the prediction scores (classification probabilities) of the victim model (Jin et al., 2020; Ren et al., 2019; Alzantot et al., 2018).",
      "startOffset" : 149,
      "endOffset" : 208
    }, {
      "referenceID" : 0,
      "context" : "Even some black-box attack models are not purely “black-box”, which require the prediction scores (classification probabilities) of the victim model (Jin et al., 2020; Ren et al., 2019; Alzantot et al., 2018).",
      "startOffset" : 149,
      "endOffset" : 208
    }, {
      "referenceID" : 8,
      "context" : "While data augmentation can be an efficient method to address data sparsity, it can improve the generalization abilities and measure the model robustness as well (Eshghi et al., 2017).",
      "startOffset" : 162,
      "endOffset" : 183
    }, {
      "referenceID" : 37,
      "context" : "Paraphrasing that rewrites the utterances in dialog has been used to get diverse representation and thus enhancing robustness (Ray et al., 2018; Zhao et al., 2019; Iyyer et al., 2018).",
      "startOffset" : 126,
      "endOffset" : 183
    }, {
      "referenceID" : 54,
      "context" : "Paraphrasing that rewrites the utterances in dialog has been used to get diverse representation and thus enhancing robustness (Ray et al., 2018; Zhao et al., 2019; Iyyer et al., 2018).",
      "startOffset" : 126,
      "endOffset" : 183
    }, {
      "referenceID" : 20,
      "context" : "Paraphrasing that rewrites the utterances in dialog has been used to get diverse representation and thus enhancing robustness (Ray et al., 2018; Zhao et al., 2019; Iyyer et al., 2018).",
      "startOffset" : 126,
      "endOffset" : 183
    }, {
      "referenceID" : 23,
      "context" : "Word-level operations (Kolomiyets et al., 2011; Li and Qiu, 2020; Wei and Zou, 2019) including replacement, insertion, and deletion were also proposed to increase language variety.",
      "startOffset" : 22,
      "endOffset" : 84
    }, {
      "referenceID" : 26,
      "context" : "Word-level operations (Kolomiyets et al., 2011; Li and Qiu, 2020; Wei and Zou, 2019) including replacement, insertion, and deletion were also proposed to increase language variety.",
      "startOffset" : 22,
      "endOffset" : 84
    }, {
      "referenceID" : 46,
      "context" : "Word-level operations (Kolomiyets et al., 2011; Li and Qiu, 2020; Wei and Zou, 2019) including replacement, insertion, and deletion were also proposed to increase language variety.",
      "startOffset" : 22,
      "endOffset" : 84
    }, {
      "referenceID" : 41,
      "context" : "Other studies (Shah et al., 2019; Xu and Sarikaya, 2014) worked on the out-of-vocabulary problem when facing unseen user expression.",
      "startOffset" : 14,
      "endOffset" : 56
    }, {
      "referenceID" : 48,
      "context" : "Other studies (Shah et al., 2019; Xu and Sarikaya, 2014) worked on the out-of-vocabulary problem when facing unseen user expression.",
      "startOffset" : 14,
      "endOffset" : 56
    }, {
      "referenceID" : 56,
      "context" : "focused on building robust spoken language understanding (Zhu et al., 2018; Henderson et al., 2012; Huang and Chen, 2019) from audio signals beyond text transcripts.",
      "startOffset" : 57,
      "endOffset" : 121
    }, {
      "referenceID" : 17,
      "context" : "focused on building robust spoken language understanding (Zhu et al., 2018; Henderson et al., 2012; Huang and Chen, 2019) from audio signals beyond text transcripts.",
      "startOffset" : 57,
      "endOffset" : 121
    }, {
      "referenceID" : 19,
      "context" : "focused on building robust spoken language understanding (Zhu et al., 2018; Henderson et al., 2012; Huang and Chen, 2019) from audio signals beyond text transcripts.",
      "startOffset" : 57,
      "endOffset" : 121
    }, {
      "referenceID" : 40,
      "context" : "Simulating ASR errors (Schatzmann et al., 2007; Park et al., 2019; Wang et al., 2020a) and speaker disfluency (Wang et al.",
      "startOffset" : 22,
      "endOffset" : 86
    }, {
      "referenceID" : 32,
      "context" : "Simulating ASR errors (Schatzmann et al., 2007; Park et al., 2019; Wang et al., 2020a) and speaker disfluency (Wang et al.",
      "startOffset" : 22,
      "endOffset" : 86
    }, {
      "referenceID" : 43,
      "context" : "Simulating ASR errors (Schatzmann et al., 2007; Park et al., 2019; Wang et al., 2020a) and speaker disfluency (Wang et al.",
      "startOffset" : 22,
      "endOffset" : 86
    }, {
      "referenceID" : 44,
      "context" : ", 2020a) and speaker disfluency (Wang et al., 2020b; Qader et al., 2018) can be promising solutions to enhance robustness to voice input when only textual data are provided.",
      "startOffset" : 32,
      "endOffset" : 72
    }, {
      "referenceID" : 34,
      "context" : ", 2020a) and speaker disfluency (Wang et al., 2020b; Qader et al., 2018) can be promising solutions to enhance robustness to voice input when only textual data are provided.",
      "startOffset" : 32,
      "endOffset" : 72
    } ],
    "year" : 2021,
    "abstractText" : "Most language understanding models in taskoriented dialog systems are trained on a small amount of annotated training data, and evaluated in a small set from the same distribution. However, these models can lead to system failure or undesirable output when being exposed to natural language perturbation or variation in practice. In this paper, we conduct comprehensive evaluation and analysis with respect to the robustness of natural language understanding models, and introduce three important aspects related to language understanding in realworld dialog systems, namely, language variety, speech characteristics, and noise perturbation. We propose a model-agnostic toolkit LAUG to approximate natural language perturbations for testing the robustness issues in taskoriented dialog. Four data augmentation approaches covering the three aspects are assembled in LAUG, which reveals critical robustness issues in state-of-the-art models. The augmented dataset through LAUG can be used to facilitate future research on the robustness testing of language understanding in task-oriented dialog.",
    "creator" : "LaTeX with hyperref"
  }
}