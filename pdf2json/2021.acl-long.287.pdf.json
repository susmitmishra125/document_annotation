{
  "name" : "2021.acl-long.287.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "NeuralWOZ: Learning to Collect Task-Oriented Dialogue via Model-Based Simulation",
    "authors" : [ "Sungdong Kim", "Minsuk Chang", "Sang-Woo Lee" ],
    "emails" : [ "sang.woo.lee}@navercorp.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3704–3717\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3704"
    }, {
      "heading" : "1 Introduction",
      "text" : "For a task-oriented dialogue system to be scalable, the dialogue system needs to be able to quickly adapt and expand to new scenarios and domains. However, the cost and effort in collecting and annotating an expanding dataset is not only laborintensive but also proportional to the size and variety of the unseen scenarios.\nThere are three types of dialogue system expansions. (1) The simplest expansion is the addition of new instances in the knowledge base (KB) under the identical schema. For example, the addition of newly opened restaurants in the KB of restaurant domain falls under this category. (2) A slightly more complicated expansion involves modifications to the KB schema, and possibly the related\n1The code is available at github.com/naver-ai/neuralwoz.\ninstances. For example, additions of new constraint types to access the KB due to the change in needs of the user often require a restructuring of the KB. If a dialogue system built with only restaurant search in mind observes user’s requests about not only “restaurant location” and but also “traffic information” for navigating, the system now needs a new knowledge base including the additional different domain. (3) The most complex expansion is the one that expands across multiple domains. For example, imagine an already built dialogue system\nsupported restaurant and hotel reservation domains, but now needs to expand to points of interest or other domains. It is difficult to expand to new domain without collecting new data instances and building a new knowledge base, if the schema between the source (restaurant and hotel in this case) and target domain (point of interest) look different.\nTo support development of scalable dialogue systems, we propose NeuralWOZ, a model-based dialogue collection framework. NeuralWOZ uses goal instructions and KB instances for synthetic dialogue generation. NeuralWOZ mimics the mechanism of a Wizard-of-Oz (Kelley, 1984; Dahlbäck et al., 1993) and Figure 1 illustrates our approach. NeuralWOZ has two neural components, Collector and Labeler. Collector generates a dialogue by using the given goal instruction and candidate relevant API call results from the KB as an input. Labeler annotates the generated dialogue with appropriate labels by using the schema structure of the dialogue domain as meta information. More specifically, Labeler selects the labels from candidate labels which can be obtained from the goal instruction and the API call results. As a result, NeuralWOZ is able to generate a dialogue corpus without training data of the target domain.\nWe evaluate our method for zero-shot domain transfer task (Wu et al., 2019; Campagna et al., 2020) to demonstrate the ability to generate corpus for unseen domains, when no prior training data exists. In dialogue state tracking (DST) task with MultiWOZ 2.1 (Eric et al., 2019), the synthetic data generated with NeuralWOZ achieves 4.4% point higher joint goal accuracy and 5.7% point higher zero-shot coverage than the existing baseline. Additionally, we examine few-shot and full data augmentation tasks using both training data and synthetic data. We also illustrate how to collect synthetic data beyond MultiWOZ domains, and discuss the effectiveness of the proposed approach as a data collection strategy.\nOur contributions are as follows:\n• NeuralWOZ, a novel method for generating dialogue corpus using goal instruction and knowledge base information\n• New state-of-the-art performance on the zeroshot domain transfer task\n• Analysis results highlighting the potential synergy of using the data generated from NeuralWOZ together with human-annotated data"
    }, {
      "heading" : "2 Related Works",
      "text" : ""
    }, {
      "heading" : "2.1 Wizard-of-Oz",
      "text" : "Wizard-of-Oz (WOZ) is a widely used approach for constructing dialogue data (Henderson et al., 2014a,b; El Asri et al., 2017; Eric and Manning, 2017; Budzianowski et al., 2018). It works by facilitating a role play between two people. “User” utilizes a goal instruction that describes the context of the task and details of request and “system” has access to a knowledge base, and query results from the knowledge base. They take turns to converse, while the user makes requests one by one following the instructions, the system responds according to the knowledge base, and labels user’s utterances."
    }, {
      "heading" : "2.2 Synthetic Dialogue Generation",
      "text" : "Other studies on dialogue datasets use the user simulator-based data collection approaches (Schatzmann et al., 2007; Li et al., 2017; Bordes et al., 2017; Shah et al., 2018; Zhao and Eskenazi, 2018; Shah et al., 2018; Campagna et al., 2020). They define domain schema, rules, and dialogue templates to simulate user behavior under certain goals. The ingredients to the simulation are designed by developers and the dialogues are realized by predefined mapping rules or paraphrasing by crowdworkers.\nIf a training corpus for the target domain exists, neural models that synthetically generates dialogues can augment the training corpus (Hou et al., 2018; Yoo et al., 2019). For example, Yoo et al. (2020) introduce Variational Hierarchical Dialog Autoencoder (VHDA), where hierarchical latent variables exist for speaker identity, user’s request, dialog state, and utterance. They show the effectiveness of their model on single-domain DST tasks. SimulatedChat (Mohapatra et al., 2020) also uses goal instruction for dialogue augmentation. Although it does not solve zero-shot learning task with domain expansion in mind, we run auxiliary experiments to compare with NeuralWOZ, and the results are in the Appendix D."
    }, {
      "heading" : "2.3 Zero-shot Domain Transfer",
      "text" : "In zero-shot domain transfer tasks, there is no data for target domain, but there exists plenty of data for other domains similar to target domain. Solving the problem of domain expansion of dialogue systems can be quite naturally reducted to solving zero-shot domain transfer. Wu et al. (2019) conduct a landmark study on the zero-shot DST. They\nsuggest a model, Transferable Dialogue State Generator (TRADE), which is robust to a new domain where few or no training data for the domain exists. Kumar et al. (2020) and Li et al. (2021) follow the same experimental setup, and we also compare NeuralWOZ in the same experiment setup. Abstract Transaction Dialogue Model (ATDM) (Campagna et al., 2020), another method for synthesizing dialogue data, is another baseline for zero-shot domain transfer tasks we adopt. They use rules, abstract state transition, and templates to synthesize the dialogue, which is then fed into a model-based zero-shot learner. They achieved state-of-the-art in the task using the synthetic data on SUMBT (Lee et al., 2019), a pretrained BERT (Devlin et al., 2019) based DST model."
    }, {
      "heading" : "3 NeuralWOZ",
      "text" : "In this section, we describe the components of NeuralWOZ in detail, and how they interact with each other. Figure 2 illustrates the input and output of two modules in NeuralWOZ. The synthetic corpus, which Collector and Labeler made, are used for\nthe training of the DST baselines, TRADE (Wu et al., 2019) and SUMBT (Lee et al., 2019) in our experiments."
    }, {
      "heading" : "3.1 Problem Statement",
      "text" : "Domain Schema In task-oriented dialogues, there are two slot types; informable and requestable slots (Henderson et al., 2014a; Budzianowski et al., 2018). The informable slots are the task constraints to find relevant information from user requests, for example, “restaurantpricerange”, “restaurant-food”, “restaurant-name”, and “restaurant-book people” in Figure 1. The requestable slots are the additional details of user requests, like “reference number” and “address” in Figure 1. Each slot S can have its corresponding value V in a scenario. In multi-domain scenarios, each domain has a knowledge base KB, which consists of slot-value pairs corresponding to its domain schema. The API call results in Figure 1 are the examples of the KB instances of the restaurant domain.\nGoal Instruction The goal instruction, G, is a natural language text describing constraints of user behavior in the dialogue D including informable and requestable slots. The paragraph consists of four sentences at the top of Figure 1 is an example. We define a set of informable slot-value pairs that explicitly expressed on the G as CG, which we formally define as CG = {(SGi , V Gi ) | 1 ≤ i ≤ |CG|, SGi ∈ informable}. (“restaurantpricerange”, “expensive”) and (“restaurant-food”, “british”) are examples of the elements of CG (Figure 1).\nAPI Call Results The API call results,A, are corresponding query results of the CG from KB. We formally define A = {ai | 1 ≤ i ≤ |A|, ai ∈ KB}. Each ai is associated with its domain, domainai , and with slot-value pairs, Cai = {(Saik , V ai k ) | 1 ≤ k ≤ |Cai |}. A slot Saik can be either informable or requestable slot. For example, the restaurant instance, “graffiti” in Figure 1, is a query result from (“restaurant-pricerange”, “expensive”) and (“restaurant-food”, “british”) described in the goal instruction.\nState Candidate We define informable slot-value pairs that are not explicit in G but accessible by A in D as CA = {(SAi , V Ai ) | 1 ≤ i ≤ |CA|, SAi ∈ informable}. It contains all informable slot-value pairs from Ca1 to Ca|A| . The elements of CA are\nlikely to be uttered by summaries of current states or recommendations of KB instances by the system side in D. The system utterance of the second turn in Figure 1 is an example (“I recommend graffiti.”). In this case, the slot-value pair (“restaurant-name”, “graffiti”) can be obtained from the A, not from the G. Finally, state candidate C is the union of CG and CA. It is a full set of the dialogue state for the dialogue D from given G and A. Thus, it can be used as label candidates of dialogue state tracking annotation."
    }, {
      "heading" : "3.2 Collector",
      "text" : "Collector is a sequence-to-sequence model, which takes a goal instruction G and API call results A as the input and generates dialogue DT . The generated dialogue DT = (r1, u1, ..., rT , uT ) is the sequence of system response r and user utterance u. They are represented by N tokens (w1, ..., wN )2.\np(DT |G,A) = N∏ i=1 p(wi|w<i, G,A)\nWe denote the input of Collector as <s> ⊕ G ⊕ </s> ⊕ A, where the ⊕ is concatenate operation. The <s> and </s> are special tokens to indicate start and seperator respectively. The tokenized natural language description of G is directly used as the tokens. The A takes concatenation of each ai (a1 ⊕ · · · ⊕ a|A|)3. For each ai, we flatten the result to the token sequence, <domain>⊕domainai⊕<slot>⊕S ai 1 ⊕V ai 1 ⊕ · · · ⊕ <slot>⊕Sai|Cai |⊕ V ai |Cai |. The <domain> and <slot> are other special tokens as separators. The objective function of Collector is\nLC = − 1\nMC MC∑ j=1 Nj∑ i=1 log p(wji |w j <i, G j , Aj).\nOur Collector model uses the transformer architecture (Vaswani et al., 2017) initialized with pretrained BART (Lewis et al., 2020). Collector is trained using negative log-likelihood loss, where MC is the number of training dataset for Collector and Nj is target length of the j-th instance. Following Lewis et al. (2020), label smoothing is used during the training with the smoothing parameter of 0.1.\n2Following Hosseini-Asl et al. (2020), we also utilize rolespecific special tokens <system> and <user> for the r and u respectively.\n3we limit the |A| to a maximum 3"
    }, {
      "heading" : "3.3 Labeler",
      "text" : "We formulate labeling as a multiple-choice problem. Specifically, Labeler takes a dialogue context Dt = (r1, u1, ..., rt, ut), question q, and a set of answer options O = {o1, o2, ..., o|O|}, and selects one answer õ ∈ O. Labeler encodes the inputs for each oi separately, and soi ∈ R1 is the corresponding logit score from the encoding. Finally, the logit score is normalized via softmax function over the answer option set O.\np(oi|Dt, q, O) = exp(soi)∑|O| j exp(soj ) ,\nsoi = Labeler(Dt, q, oi),∀i.\nThe input of Labeler is a concatenation of Dt, q, and oi, <s>⊕Dt⊕</s>⊕q⊕</s>⊕oi⊕</s>, with special tokens. For labeling dialogue states to Dt, we use the slot description for each corresponding slot type, Si, as the question, for example, “what is area or place of hotel?” for “hotel-area” in Figure 2. We populate corresponding answer options OSi = {Vj |(Sj , Vj) ∈ C, Sj = Si} from the state candidate set C. There are two special values, Dontcare to indicate the user has no preference and None to indicate the user is yet to specify a value for this slot (Henderson et al., 2014a; Budzianowski et al., 2018). We include these values in the OSi .\nFor labeling the active domain of Dt, which is the domain at t-th turn of Dt, we define domain question, for example “what is the domain or topic of current turn?”, for q and use predefined domain setOdomain as answer options. In MultiWOZ, Odomain = {“Attraction”, “Hotel”, “Restaurant”, “Taxi”, “Train”}.\nOur Labeler model employs a pretrained RoBERTa model (Liu et al., 2019) as the initial weight. Dialogue state and domain labeling are trained jointly based on the multiple choice setting. Preliminary result shows that the imbalanced class problem is significant in the dialogue state labels. Most of the ground-truth answers is None given question4. Therefore, we revise the negative loglikelihood objective to weight other (not-None) answers by multiplying a constant β to the loglikelihood when the answer of training instance is\n4The number of None in the training data is about 10 times more than the number of others\nnot None. The objective function of Labeler is\nLL = − 1\nML ML∑ j=1 T∑ t=1 Nq∑ i=1 Ljt,i\nLjt,i =\n{ β log p(õjt,i|D j t , q j i , O j i ), if õ j t,i 6= None\nlog p(õjt,i|D j t , q j i , O j i ), otherwise\n, where õjt,i denotes the answer of i-th question for j-th training dialogue at turn t, the Nq is the number of questions, and ML is the number of training dialogues for Labeler. We empirically set β to a constant 5."
    }, {
      "heading" : "3.4 Synthesizing a Dialogue",
      "text" : "We first define goal template G.5 G is a delexicalized version of G by changing each value V Gi expressed on the instruction to its slot SGi . For example, the “expensive” and “british” of goal instruction in Figure 1 are replaced with “restaurantpricerange” and “restaurant-food”, respectively. As a result, domain transitions in G becomes convenient.\nFirst, G is sampled from a pre-defined set of goal template. API call results A, which correspond to domain transitions in G, are randomly selected from the KB. Especially, we constrain the sampling space of A when the consecutive scenario among domains in G have shared slot values. For example, the sampled API call results for restaurant and hotel domain should share the value of “area” to support the following instruction “I am looking for a hotel nearby the restaurant”. G and A are aligned to become GA. In other words, each value for SGi in G is assigned using the corresponding values in A.6 Then, Collector generates dialogue D, of which the total turn number is T , given GA and A. More details are in Appendix A. Nucleus sampling (Holtzman et al., 2020) is used for the generation.\nWe denote dialogue state and active domain at turn t as Bt and domaint respectively. The Bt, {(Sj , Vj,t) | 1 ≤ j ≤ J}, has J number of predefined slots and their values at turn t. It means Labeler is asked J (from slot descriptions) + 1 (from domain question) questions regarding dialogue context Dt from Collector. Finally, the out-\n5In Budzianowski et al. (2018), they also use templates like ours when allocating goal instructions to the user in the Wizard-of-Oz setup.\n6Booking-related slots, e.g., the number of people, time, day, and etc., are randomly sampled for their values since they are independent of the A.\nput of Labeler is a set of dialogue context, dialogue state, and active domain at turn t triples {(D1, B1, domain1), ..., (DT , BT , domainT )}."
    }, {
      "heading" : "4 Experimental Setups",
      "text" : ""
    }, {
      "heading" : "4.1 Dataset",
      "text" : "We use MultiWOZ 2.1 (Eric et al., 2019) dataset7 for our experiments. It is one of the largest publicly available multi-domain dialogue data and it contains 7 domains related to travel (attraction, hotel, restaurant, taxi, train, police, hospital), including about 10,000 dialogues. The MultiWOZ data is created using WOZ so it includes goal instruction per each dialogue and domain-related knowledge base as well. We train our NeuralWOZ using the goal instructions and the knowledge bases first. Then we evaluate our method on dialogue state tracking with and without synthesized data from the NeuralWOZ using five domains (attraction, restaurant, hotel, taxi, train) in our baseline, and follow the same preprocessing steps of Wu et al. (2019); Campagna et al. (2020)."
    }, {
      "heading" : "4.2 Training NeuralWOZ",
      "text" : "We use the pretrained BART-Large (Lewis et al., 2020) for Collector and RoBERTa-Base (Liu et al., 2019) for Labeler. They share the same byte-level BPE vocab (Sennrich et al., 2016) introduced by Radford et al. (2019). We train the pipelined models using Adam optimizer (Kingma and Ba, 2017) with learning rate 1e-5, warming up steps 1,000, and batch size 32. The number of training epoch is set to 30 and 10 for Collector and Labeler respectively.\nFor the training phase of Labeler, we use a state candidate set from ground truth dialogue states B1:T for each dialogue, not like the synthesizing phase where the options are obtained from goal instruction and API call results. We also evaluate the performance of Labeler itself like the training phase with validation data (Table 5). Before training Labeler on the MultiWOZ 2.1 dataset, we pretrain Labeler on DREAM8 (Sun et al., 2019) to boost Labeler’s performance. This is similar to coarse-tuning in Jin et al. (2019). The same hyper parameter setting is used for the pretraining.\nFor the zero-shot domain transfer task, we exclude dialogues which contains target domain from\n7https://github.com/budzianowski/multiwoz 8The DREAM is a multiple-choice question answering dataset in dialogue and includes about 84% of non-extractive answers.\nthe training data for both Collector and Labeler. This means we train our pipelines for every target domain separately. We use the same seed data for training as Campagna et al. (2020) did in the fewshot setting. All our implementations are conducted on NAVER Smart Machine Learning (NSML) platform (Sung et al., 2017; Kim et al., 2018) using huggingface’s transformers library (Wolf et al., 2020). The best performing models, Collector and Labeler, are selected by evaluation results from the validation set."
    }, {
      "heading" : "4.3 Synthetic Data Generation",
      "text" : "We synthesize 5,000 dialogues for every target domain for both zero-shot and few-shot experiments9, and 1,000 dialogues for full data augmentation. For zero-shot experiment, since the training data are unavailable for a target domain, we only use goal templates that contain the target domain scenario in the validation set similar to Campagna et al. (2020). We use nucleus sampling in Collector with parameters top p ratio in the range {0.92, 0.98} and temperature in the range {0.7, 0.9, 1.0}. It takes about two hours to synthesize 5,000 dialogues using one V100 GPU. More statistics is in Appendix B."
    }, {
      "heading" : "4.4 Baselines",
      "text" : "We compare NeuralWOZ with baseline methods both zero-shot learning and data augmentation using MultiWOZ 2.1 in our experiments. We use a baseline zero-shot learning scheme which does not\n9In Campagna et al. (2020), the average number of synthesized dialogue over domains is 10,140.\nuse synthetic data (Wu et al., 2019). For data augmentation, we use ATDM and VHDA.\nATDM refers to a rule-based synthetic data augmentation method for zero-shot learning suggested by Campagna et al. (2020). It defines rules including state transitions and templates for simulating dialogues and creates about 10,000 synthetic dialogues per five domains in the MultiWOZ dataset. Campagna et al. (2020) feed the synthetic dialogues into zero-shot learner models to perform zero-shot transfer task for dialogue state tracking. We also employ TRADE (Wu et al., 2019) and SUMBT (Lee et al., 2019) as baseline zero-shot learners for fair comparisons with the ATDM.\nVHDA refers to model-based generation method using hierarchical variational autoencoder (Yoo et al., 2020). It generates dialogues incorporating information of speaker, goal of the speaker, turnlevel dialogue acts, and utterance sequentially. Yoo et al. (2020) augment about 1,000 dialogues for restaurant and hotel domains in the MultiWOZ dataset. For a fair comparison, we use TRADE as the baseline model for the full data augmentation experiments. Also, we compare ours with the VHDA on the single-domain augmentation setting following their report."
    }, {
      "heading" : "5 Experimental Results",
      "text" : "We use both joint goal accuracy (JGA) and slot accuracy (SA) as the performance measurement. The JGA is an accuracy which checks whether all slot values predicted at each turn exactly match the ground truth values, and the SA is the slotwise accuracy of partial match against the grouth\ntruth values. Especially for zero and few-shot setting, we follow the previous setup (Wu et al., 2019; Campagna et al., 2020). Following Campagna et al. (2020), the zero-shot learner model should be trained on data excluding the target domain, and tested on the target domain. We also add synthesized data from our NeuralWOZ which is trained in the same way, i.e., leave-one-out setup, to the training data in the experiment."
    }, {
      "heading" : "5.1 Zero-Shot Domain Transfer Learning",
      "text" : "Our method achieves new state-of-the-art of zeroshot domain transfer learning for dialogue state tracking on the MultiWOZ 2.1 dataset (Table 1). Except for the hotel domain, the performance over all target domains is significantly better than the previous sota method. We discuss the lower performance in hotel domain in the analysis section. Following the work of Campagna et al. (2020), we also measure zero-shot coverage, which refers to the accuracy ratio between zero-shot learning over target domain, and fully trained model including the target domain. Our NeuralWOZ achieves 66.9% and 79.2% zero-shot coverage on TRADE and SUMBT, respectively, outperforming previous state-of-the-art, ATDM, which achieves 61.2% and 73.5%, respectively."
    }, {
      "heading" : "5.2 Data Augmentation on Full Data Setting",
      "text" : "For full data augmentation, our synthesized data come from fully trained model including all five domains in this setting. Table 2 shows that our model still consistently outperforms in full data augmentation of multi-domain dialogue state tracking. Specifically, our NeuralWOZ performs 2.8% point better on the joint goal accuracy of TRADE than ATDM. Our augmentation improves the performance by a 1.6% point while ATDM degrades.\nWe also compare NeuralWOZ with VHDA, a previous model-based data augmentation method for dialogue state tracking (Yoo et al., 2020). Since the VHDA only considers single-domain simulation, we use single-domain dialogue in hotel\nand restaurant domains for the evaluation. Table 3 shows that our method still performs better than the VHDA in this setting. NeuralWOZ has more than twice better joint goal accuracy gain than that of VHDA."
    }, {
      "heading" : "5.3 Intrinsic Evaluation of NeuralWOZ",
      "text" : "Table 4 shows the intrinsic evaluation results from two components (Collector and Labeler) of the NeuralWOZ on the validation set of MultiWOZ 2.1. We evaluate each component using perplexity for Collector and joint goal accuracy for Labeler, respectively. Note that the joint goal accuracy is achieved by using state candidate set, prepopulated as the multiple-choice options from the ground truth, B1:T , as the training time of Labeler. It can be seen as using meta information since its purpose is accurate annotation but not the dialogue state tracking itself. We also report the results by excluding target domain from full dataset to simulate zero-shot environment. Surprisingly, synthesized data from ours performs effectively even though the annotation by Labeler is not perfect. We conduct further analysis, the responsibility of each model, in the following section."
    }, {
      "heading" : "6 Analysis",
      "text" : ""
    }, {
      "heading" : "6.1 Error Analysis",
      "text" : "Figure 3 shows the slot accuracy for each slot type in the hotel domain, which is the weakest domain from ours. Different from other four domains, only the hotel domain has two boolean type slots, “parking” and “internet”, which can have only “yes” or “no” as their value. Since they have abstract property for the tracking, Labeler’s labeling performance tends to be limited to this domain. However, it is noticeable that our accuracy of booking related slots (book stay, book people, book day) are much higher than the ATDM’s. Moreover, the model using synthetic data from the ATDM totally fails to track the “book stay” slot. In the synthesizing procedures of Campagna et al. (2020), they create the data with a simple substitution of a domain noun phrase when the two domains have similar slots. For example, “find me a restaurant in the city center” can be replaced with “find me a hotel in the city center” since the restaurant and hotel domains share “area” slot. We presume it is why they outperform over slots like “pricerange” and “area”."
    }, {
      "heading" : "6.2 Few-shot Learning",
      "text" : "We further investigate how our method is complementary with human-annotated data. Figure 4 illustrates our NeuralWOZ shows a consistent gain in the few-shot domain transfer setting. Unlike the performance with ATDM is saturated as few-shot ratio increases, the performance using our NeuralWOZ is improved continuously. We get about 5.8% point improvement from the case which does not use synthetic data when using 10% of humanannotated data for the target domain. It implies our method could be used more effectively with the\nhuman-annotated data in a real scenario."
    }, {
      "heading" : "6.3 Ablation Study",
      "text" : "We discover whether Collector and Labeler are more responsible for the quality of synthesizing. Table 5 shows ablation results where each model of NeuralWOZ is trained the data including or withholding the hotel domain. Except for the training data for each model, the pipelined models are trained and dialogues are synthesized in the same way. Then, we train TRADE model using the synthesized data and evaluate it on hotel domain like the zero-shot setting. The performance gain from Collector which is trained including the target domain is 4.3% point, whereas the gain from Labeler is only 0.8% point. It implies the generation quality from Collector is more responsible for the performance of the zero-shot learner than accurate annotation of Labeler."
    }, {
      "heading" : "6.4 Qualitative Analysis",
      "text" : "Figure 5 is an qualitative example generated by NeuralWOZ. It shows the NeuralWOZ can generate an unseen movie domain which has a different schema from the traveling, the meta domain of the MultiWOZ dataset, even if it is trained on only the\ndataset. It is harder to generalize when the schema structure of the target domain is different from the source domain. Other examples can be found in Appendix C. We would like to extend the NeuralWOZ to more challenging expansion scenario like these in future work."
    }, {
      "heading" : "6.5 Comparison on End-to-End Task",
      "text" : "To show that our framework can be used for other dialogue tasks, we test our data augmentation method on end-to-end task in MultiWOZ 2.1. We describe the result in Appendix D with discussion. In full data setting, Our method achieves 17.46 BLUE, 75.1 Inform rate, 64.6 Success rate, and 87.31 Combine rate, showing performance gain using the synthetic data. Appendix D also includes the comparison and discussion on SimulatedChat (Mohapatra et al., 2020)."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We propose NeuralWOZ, a novel dialogue collection framework, and we show our method achieves state-of-the-art performance on zero-shot domain transfer task. We find the dialogue corpus from NeuralWOZ is synergetic with human-annotated data. Finally, further analysis shows that NeuralWOZ can be applied for scaling dialogue system. We believe NeuralWOZ will spark further research into dialogue system environments where expansion target domains are distant from the source domains."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Sohee Yang, Gyuwan Kim, Jung-Woo Ha, and other members of NAVER AI for their valuable comments. We also thank participants who helped our preliminary experiments for building data collection protocol."
    }, {
      "heading" : "A Goal Instruction Sampling for Synthesizing in NeuralWOZ",
      "text" : "B Data Statistics\n# of Dialogues # of Turns\nDomain Slots Train Valid Test Train Valid Test\nAttraction area, name, type 2,717 401 395 8,073 1,220 1,256\nHotel price range, type, parking, book stay, book day, book people, area, stars, internet, name\n3,381 416 394 14,793 1,781 1,756\nRestaurant food, price range, area, name, book time, book day, book people\n3,813 438 437 15,367 1,708 1,726\nTaxi leave at, destination, departure, arrive by 1,654 207 195 4,618 690 654\nTrain destination, day, departure, arrive by, book people, leave at\n3,103 484 494 12,133 1,972 1,976\nTable 6: Data Statistics of MultiWOZ 2.1."
    }, {
      "heading" : "C Additional Qualitative Examples",
      "text" : "Figure 7 shows other examples from our NeuralWOZ. The left subfigure shows an example of synthesized dialogue from NeuralWOZ in a restaurant, which is seen domain and has the same schema from the\nrestaurant domain in MultiWOZ dataset. However, the “spicy club” is an unseen instance which is newly added to the schema for the synthesizing. The right subfigure shows other synthetic dialogue in restaurant, which is a seen domain but has different schema from restaurant domain in MultiWOZ dataset. It describes navigation in-car scenario which is borrowed from KVret dataset (Eric and Manning, 2017). It is a non-trivial problem to adapt to unseen scenario, even if it is in the same domain."
    }, {
      "heading" : "D Additional Explanation on Comparison in End-to-End Task",
      "text" : "To compare our model with the model of (Mohapatra et al., 2020), we conduct end-to-end task experiments the previous work did. Table 8 illustrates the result. Though the performance of baseline implementation\nis different, we can see that the trend of performance improvement is comparable to the report of SimulatedChat.\nTwo studies are also different in terms of modeling. In our method, all utterances in the dialogue are first collected based on goal instruction and KB information by Collector. After that, Labeler selects annotations from candidate labels, which can be inducted from goal instruction and KB information. On the other hand, SimulatedChat creates utterance and label sequentially with knowledge base access, for each turn. Thus, each generation of utterance is affected by the generated utterance of labels of the previous turn.\nIn detail, the two methods also differ in terms of complexity. SimulatedChat creates a model for each domain separately, and for each domain, it creates five neural modules: user response generation, user response selector, agent query generator, agent response generator, and agent response selector. This results 25 neural models for data augmentation in the MultiWOZ experiments. On the contrary, NeuralWOZ only needs two neural models for data augmentation: Collector and Labeler.\nAnother notable difference is that SimulatedChat does not generate multi-domain data in a natural way. The strategy of creating a model for each domain not only makes it difficult to transfer the knowledge to a new domain, but also makes it difficult to create multi-domain data. In SimulatedChat, the dialogue is created for each domain and then concatenated. Our model can properly reflect the information of all domains included in the goal instruction to generate synthetic dialogues, regardless of the number of domains."
    }, {
      "heading" : "E Other Experiment Details",
      "text" : "The number of parameters of our models is 406M for Collector and 124M for Labeler, respectively. Both models are trained on two V100 GPUs with mixed precision floating point arithmetic. It takes about 4 (10 epochs) and 24 hours (30 epochs) for the training, respectively. We optimize hyperparameters of each model, learning rate {1e-5, 2e-5, 3e-5} and batch size {16, 32, 64}, based on greedy search. We set the maximum sequence length of Collector to 768 and the Labeler to 512.\nFor the main experiments, we fix hyperparameter settings of TRADE (learning rate 1e-4 and batch size 32) and SUMBT (learning rate 5e-5 and batch size 4) same with previous works. We use the script of Campagna et al. (2020) for converting the TRADE’s data format to the SUMBT’s.\nFor GPT2 (Radford et al., 2019) based model for the end2end task, we re-implement the model similar with SimpleTOD (Hosseini-Asl et al., 2020) but not using action. Thus, it generates dialogue context, dialogue state, database results, and system response in an autoregressive manner. We also use special tokens in the SimpleTOD (without special tokens for the action). We follow preprocessing procedure for the end2end task, including delexicalization suggested by (Budzianowski et al., 2018). We use 8 for batch size and 5e-5 for learning rate. Note that we also train our NeuralWOZ using 30% of training data and synthesize 5000 dialogues for the end2end experiments. However, we could not find detailed experiments setup of Mohapatra et al. (2020) including hyperparameter, the seed of each portion of training data, and evaluation, so it is not a fair comparison."
    } ],
    "references" : [ {
      "title" : "Learning end-to-end goal-oriented dialog",
      "author" : [ "Antoine Bordes", "Y-Lan Boureau", "Jason Weston" ],
      "venue" : null,
      "citeRegEx" : "Bordes et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2017
    }, {
      "title" : "MultiWOZ - a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling",
      "author" : [ "Paweł Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "Iñigo Casanueva", "Stefan Ultes", "Osman Ramadan", "Milica Gašić." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Budzianowski et al\\.,? 2018",
      "shortCiteRegEx" : "Budzianowski et al\\.",
      "year" : 2018
    }, {
      "title" : "Zero-shot transfer learning with synthesized data for multi-domain dialogue state tracking",
      "author" : [ "Giovanni Campagna", "Agata Foryciarz", "Mehrad Moradshahi", "Monica Lam." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Campagna et al\\.,? 2020",
      "shortCiteRegEx" : "Campagna et al\\.",
      "year" : 2020
    }, {
      "title" : "Wizard of oz studies: why and how",
      "author" : [ "Nils Dahlbäck", "Arne Jönsson", "Lars Ahrenberg." ],
      "venue" : "Proceedings of the 1st international conference on Intelligent user interfaces, pages 193–200.",
      "citeRegEx" : "Dahlbäck et al\\.,? 1993",
      "shortCiteRegEx" : "Dahlbäck et al\\.",
      "year" : 1993
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Frames: a corpus for adding memory to goal-oriented dialogue systems",
      "author" : [ "Layla El Asri", "Hannes Schulz", "Shikhar Sharma", "Jeremie Zumer", "Justin Harris", "Emery Fine", "Rahul Mehrotra", "Kaheer Suleman." ],
      "venue" : "Proceedings of the 18th Annual SIG-",
      "citeRegEx" : "Asri et al\\.,? 2017",
      "shortCiteRegEx" : "Asri et al\\.",
      "year" : 2017
    }, {
      "title" : "Multiwoz 2.1: A consolidated multi-domain dialogue dataset with state correc",
      "author" : [ "Mihail Eric", "Rahul Goel", "Shachi Paul", "Adarsh Kumar", "Abhishek Sethi", "Peter Ku", "Anuj Kumar Goyal", "Sanchit Agarwal", "Shuyang Gao", "Dilek Hakkani-Tur" ],
      "venue" : null,
      "citeRegEx" : "Eric et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Eric et al\\.",
      "year" : 2019
    }, {
      "title" : "Keyvalue retrieval networks for task-oriented dialogue",
      "author" : [ "Mihail Eric", "Christopher D. Manning" ],
      "venue" : null,
      "citeRegEx" : "Eric and Manning.,? \\Q2017\\E",
      "shortCiteRegEx" : "Eric and Manning.",
      "year" : 2017
    }, {
      "title" : "The second dialog state tracking challenge",
      "author" : [ "Matthew Henderson", "Blaise Thomson", "Jason D. Williams." ],
      "venue" : "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 263–272, Philadelphia,",
      "citeRegEx" : "Henderson et al\\.,? 2014a",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2014
    }, {
      "title" : "The third dialog state tracking challenge",
      "author" : [ "Matthew Henderson", "Blaise Thomson", "Jason D Williams." ],
      "venue" : "2014 IEEE Spoken Language Technology Workshop (SLT), pages 324–329. IEEE.",
      "citeRegEx" : "Henderson et al\\.,? 2014b",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2014
    }, {
      "title" : "The curious case of neural text degeneration",
      "author" : [ "Ari Holtzman", "Jan Buys", "Li Du", "Maxwell Forbes", "Yejin Choi" ],
      "venue" : null,
      "citeRegEx" : "Holtzman et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Holtzman et al\\.",
      "year" : 2020
    }, {
      "title" : "A simple language model for task-oriented dialogue",
      "author" : [ "Ehsan Hosseini-Asl", "Bryan McCann", "Chien-Sheng Wu", "Semih Yavuz", "Richard Socher" ],
      "venue" : null,
      "citeRegEx" : "Hosseini.Asl et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Hosseini.Asl et al\\.",
      "year" : 2020
    }, {
      "title" : "Sequence-to-sequence data augmentation for dialogue language understanding",
      "author" : [ "Yutai Hou", "Yijia Liu", "Wanxiang Che", "Ting Liu." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 1234–1245, Santa Fe, New",
      "citeRegEx" : "Hou et al\\.,? 2018",
      "shortCiteRegEx" : "Hou et al\\.",
      "year" : 2018
    }, {
      "title" : "Mmm: Multi-stage multi-task learning for multi-choice reading comprehension",
      "author" : [ "Di Jin", "Shuyang Gao", "Jiun-Yu Kao", "Tagyoung Chung", "Dilek Hakkani-tur" ],
      "venue" : null,
      "citeRegEx" : "Jin et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2019
    }, {
      "title" : "An iterative design methodology for user-friendly natural language office information applications",
      "author" : [ "John F Kelley." ],
      "venue" : "ACM Transactions on Information Systems (TOIS), 2(1):26–41.",
      "citeRegEx" : "Kelley.,? 1984",
      "shortCiteRegEx" : "Kelley.",
      "year" : 1984
    }, {
      "title" : "Nsml: Meet the mlaas platform with a real-world case study",
      "author" : [ "Hanjoo Kim", "Minkyu Kim", "Dongjoo Seo", "Jinwoong Kim", "Heungseok Park", "Soeun Park", "Hyunwoo Jo", "KyungHyun Kim", "Youngil Yang", "Youngkwan Kim" ],
      "venue" : null,
      "citeRegEx" : "Kim et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2018
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba" ],
      "venue" : null,
      "citeRegEx" : "Kingma and Ba.,? \\Q2017\\E",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2017
    }, {
      "title" : "Ma-dst: Multi-attention based scalable dialog state tracking",
      "author" : [ "Adarsh Kumar", "Peter Ku", "Anuj Kumar Goyal", "Angeliki Metallinou", "Dilek Hakkani-Tur" ],
      "venue" : null,
      "citeRegEx" : "Kumar et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2020
    }, {
      "title" : "SUMBT: Slot-utterance matching for universal and scalable belief tracking",
      "author" : [ "Hwaran Lee", "Jinsik Lee", "Tae-Yoon Kim." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5478–5483, Florence, Italy.",
      "citeRegEx" : "Lee et al\\.,? 2019",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2019
    }, {
      "title" : "BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
      "author" : [ "Levy", "Veselin Stoyanov", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Levy et al\\.,? 2020",
      "shortCiteRegEx" : "Levy et al\\.",
      "year" : 2020
    }, {
      "title" : "Zero-shot generalization in dialog state tracking through generative question answering",
      "author" : [ "Shuyang Li", "Jin Cao", "Mukund Sridhar", "Henghui Zhu", "Shang-Wen Li", "Wael Hamza", "Julian McAuley." ],
      "venue" : "Proceedings of the 16th Conference of the European",
      "citeRegEx" : "Li et al\\.,? 2021",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2021
    }, {
      "title" : "A user simulator for task-completion dialogues",
      "author" : [ "Xiujun Li", "Zachary C. Lipton", "Bhuwan Dhingra", "Lihong Li", "Jianfeng Gao", "Yun-Nung Chen" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov" ],
      "venue" : null,
      "citeRegEx" : "Liu et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Simulated chats for task-oriented dialog: Learning to generate conversations from instructions",
      "author" : [ "Biswesh Mohapatra", "Gaurav Pandey", "Danish Contractor", "Sachindra Joshi." ],
      "venue" : "arXiv preprint arXiv:2010.10216.",
      "citeRegEx" : "Mohapatra et al\\.,? 2020",
      "shortCiteRegEx" : "Mohapatra et al\\.",
      "year" : 2020
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeff Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Agenda-based user simulation for bootstrapping a POMDP dialogue system",
      "author" : [ "Jost Schatzmann", "Blaise Thomson", "Karl Weilhammer", "Hui Ye", "Steve Young." ],
      "venue" : "Human Language Technologies 2007: The Conference of the North American Chap-",
      "citeRegEx" : "Schatzmann et al\\.,? 2007",
      "shortCiteRegEx" : "Schatzmann et al\\.",
      "year" : 2007
    }, {
      "title" : "Neural machine translation of rare words with subword units",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715–",
      "citeRegEx" : "Sennrich et al\\.,? 2016",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2016
    }, {
      "title" : "Building a conversational agent overnight with dialogue self-play",
      "author" : [ "Pararth Shah", "Dilek Hakkani-Tür", "Gokhan Tür", "Abhinav Rastogi", "Ankur Bapna", "Neha Nayak", "Larry Heck." ],
      "venue" : "arXiv preprint arXiv:1801.04871.",
      "citeRegEx" : "Shah et al\\.,? 2018",
      "shortCiteRegEx" : "Shah et al\\.",
      "year" : 2018
    }, {
      "title" : "Dream: A challenge dataset and models for dialogue-based reading comprehension",
      "author" : [ "Kai Sun", "Dian Yu", "Jianshu Chen", "Dong Yu", "Yejin Choi", "Claire Cardie" ],
      "venue" : null,
      "citeRegEx" : "Sun et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Nsml: A machine learning platform that enables you",
      "author" : [ "Nako Sung", "Minkyu Kim", "Hyunwoo Jo", "Youngil Yang", "Jingwoong Kim", "Leonard Lausen", "Youngkwan Kim", "Gayoung Lee", "Donghyun Kwak", "Jung-Woo Ha" ],
      "venue" : null,
      "citeRegEx" : "Sung et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Sung et al\\.",
      "year" : 2017
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander Rush." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    }, {
      "title" : "Transferable multi-domain state generator for task-oriented dialogue systems",
      "author" : [ "Chien-Sheng Wu", "Andrea Madotto", "Ehsan HosseiniAsl", "Caiming Xiong", "Richard Socher", "Pascale Fung." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association",
      "citeRegEx" : "Wu et al\\.,? 2019",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Variational hierarchical dialog autoencoder for dialog state tracking data augmentation",
      "author" : [ "Kang Min Yoo", "Hanbit Lee", "Franck Dernoncourt", "Trung Bui", "Walter Chang", "Sang-goo Lee." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods",
      "citeRegEx" : "Yoo et al\\.,? 2020",
      "shortCiteRegEx" : "Yoo et al\\.",
      "year" : 2020
    }, {
      "title" : "Data augmentation for spoken language understanding via joint variational generation",
      "author" : [ "Kang Min Yoo", "Youhyun Shin", "Sang-goo Lee." ],
      "venue" : "Proceedings of the AAAI conference on artificial intelligence, volume 33, pages 7402–7409.",
      "citeRegEx" : "Yoo et al\\.,? 2019",
      "shortCiteRegEx" : "Yoo et al\\.",
      "year" : 2019
    }, {
      "title" : "Taskoriented dialog systems that consider multiple appropriate responses under the same context",
      "author" : [ "Yichi Zhang", "Zhijian Ou", "Zhou Yu." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9604–9611.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Zeroshot dialog generation with cross-domain latent actions",
      "author" : [ "Tiancheng Zhao", "Maxine Eskenazi." ],
      "venue" : "Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue, pages 1–10.",
      "citeRegEx" : "Zhao and Eskenazi.,? 2018",
      "shortCiteRegEx" : "Zhao and Eskenazi.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "NeuralWOZ mimics the mechanism of a Wizard-of-Oz (Kelley, 1984; Dahlbäck et al., 1993) and Figure 1 illustrates our approach.",
      "startOffset" : 49,
      "endOffset" : 86
    }, {
      "referenceID" : 3,
      "context" : "NeuralWOZ mimics the mechanism of a Wizard-of-Oz (Kelley, 1984; Dahlbäck et al., 1993) and Figure 1 illustrates our approach.",
      "startOffset" : 49,
      "endOffset" : 86
    }, {
      "referenceID" : 31,
      "context" : "We evaluate our method for zero-shot domain transfer task (Wu et al., 2019; Campagna et al., 2020) to demonstrate the ability to generate corpus for unseen domains, when no prior training data",
      "startOffset" : 58,
      "endOffset" : 98
    }, {
      "referenceID" : 2,
      "context" : "We evaluate our method for zero-shot domain transfer task (Wu et al., 2019; Campagna et al., 2020) to demonstrate the ability to generate corpus for unseen domains, when no prior training data",
      "startOffset" : 58,
      "endOffset" : 98
    }, {
      "referenceID" : 6,
      "context" : "1 (Eric et al., 2019), the synthetic data generated with NeuralWOZ achieves 4.",
      "startOffset" : 2,
      "endOffset" : 21
    }, {
      "referenceID" : 7,
      "context" : "Wizard-of-Oz (WOZ) is a widely used approach for constructing dialogue data (Henderson et al., 2014a,b; El Asri et al., 2017; Eric and Manning, 2017; Budzianowski et al., 2018).",
      "startOffset" : 76,
      "endOffset" : 176
    }, {
      "referenceID" : 1,
      "context" : "Wizard-of-Oz (WOZ) is a widely used approach for constructing dialogue data (Henderson et al., 2014a,b; El Asri et al., 2017; Eric and Manning, 2017; Budzianowski et al., 2018).",
      "startOffset" : 76,
      "endOffset" : 176
    }, {
      "referenceID" : 25,
      "context" : "Other studies on dialogue datasets use the user simulator-based data collection approaches (Schatzmann et al., 2007; Li et al., 2017; Bordes et al., 2017; Shah et al., 2018; Zhao and Eskenazi, 2018; Shah et al., 2018; Campagna et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 240
    }, {
      "referenceID" : 21,
      "context" : "Other studies on dialogue datasets use the user simulator-based data collection approaches (Schatzmann et al., 2007; Li et al., 2017; Bordes et al., 2017; Shah et al., 2018; Zhao and Eskenazi, 2018; Shah et al., 2018; Campagna et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 240
    }, {
      "referenceID" : 0,
      "context" : "Other studies on dialogue datasets use the user simulator-based data collection approaches (Schatzmann et al., 2007; Li et al., 2017; Bordes et al., 2017; Shah et al., 2018; Zhao and Eskenazi, 2018; Shah et al., 2018; Campagna et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 240
    }, {
      "referenceID" : 27,
      "context" : "Other studies on dialogue datasets use the user simulator-based data collection approaches (Schatzmann et al., 2007; Li et al., 2017; Bordes et al., 2017; Shah et al., 2018; Zhao and Eskenazi, 2018; Shah et al., 2018; Campagna et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 240
    }, {
      "referenceID" : 35,
      "context" : "Other studies on dialogue datasets use the user simulator-based data collection approaches (Schatzmann et al., 2007; Li et al., 2017; Bordes et al., 2017; Shah et al., 2018; Zhao and Eskenazi, 2018; Shah et al., 2018; Campagna et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 240
    }, {
      "referenceID" : 27,
      "context" : "Other studies on dialogue datasets use the user simulator-based data collection approaches (Schatzmann et al., 2007; Li et al., 2017; Bordes et al., 2017; Shah et al., 2018; Zhao and Eskenazi, 2018; Shah et al., 2018; Campagna et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 240
    }, {
      "referenceID" : 2,
      "context" : "Other studies on dialogue datasets use the user simulator-based data collection approaches (Schatzmann et al., 2007; Li et al., 2017; Bordes et al., 2017; Shah et al., 2018; Zhao and Eskenazi, 2018; Shah et al., 2018; Campagna et al., 2020).",
      "startOffset" : 91,
      "endOffset" : 240
    }, {
      "referenceID" : 23,
      "context" : "SimulatedChat (Mohapatra et al., 2020) also uses goal instruction for dialogue augmentation.",
      "startOffset" : 14,
      "endOffset" : 38
    }, {
      "referenceID" : 2,
      "context" : "Abstract Transaction Dialogue Model (ATDM) (Campagna et al., 2020), another method for synthesizing dialogue data, is another baseline for zero-shot domain transfer tasks we adopt.",
      "startOffset" : 43,
      "endOffset" : 66
    }, {
      "referenceID" : 18,
      "context" : "They achieved state-of-the-art in the task using the synthetic data on SUMBT (Lee et al., 2019), a pretrained BERT (Devlin et al.",
      "startOffset" : 77,
      "endOffset" : 95
    }, {
      "referenceID" : 4,
      "context" : ", 2019), a pretrained BERT (Devlin et al., 2019) based DST model.",
      "startOffset" : 27,
      "endOffset" : 48
    }, {
      "referenceID" : 31,
      "context" : "The synthetic corpus, which Collector and Labeler made, are used for the training of the DST baselines, TRADE (Wu et al., 2019) and SUMBT (Lee et al.",
      "startOffset" : 110,
      "endOffset" : 127
    }, {
      "referenceID" : 18,
      "context" : ", 2019) and SUMBT (Lee et al., 2019) in our experiments.",
      "startOffset" : 18,
      "endOffset" : 36
    }, {
      "referenceID" : 8,
      "context" : "Domain Schema In task-oriented dialogues, there are two slot types; informable and requestable slots (Henderson et al., 2014a; Budzianowski et al., 2018).",
      "startOffset" : 101,
      "endOffset" : 153
    }, {
      "referenceID" : 1,
      "context" : "Domain Schema In task-oriented dialogues, there are two slot types; informable and requestable slots (Henderson et al., 2014a; Budzianowski et al., 2018).",
      "startOffset" : 101,
      "endOffset" : 153
    }, {
      "referenceID" : 8,
      "context" : "erence and None to indicate the user is yet to specify a value for this slot (Henderson et al., 2014a; Budzianowski et al., 2018).",
      "startOffset" : 77,
      "endOffset" : 129
    }, {
      "referenceID" : 1,
      "context" : "erence and None to indicate the user is yet to specify a value for this slot (Henderson et al., 2014a; Budzianowski et al., 2018).",
      "startOffset" : 77,
      "endOffset" : 129
    }, {
      "referenceID" : 22,
      "context" : "Our Labeler model employs a pretrained RoBERTa model (Liu et al., 2019) as the initial weight.",
      "startOffset" : 53,
      "endOffset" : 71
    }, {
      "referenceID" : 10,
      "context" : "Nucleus sampling (Holtzman et al., 2020) is used for the generation.",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 22,
      "context" : ", 2020) for Collector and RoBERTa-Base (Liu et al., 2019) for Labeler.",
      "startOffset" : 39,
      "endOffset" : 57
    }, {
      "referenceID" : 26,
      "context" : "They share the same byte-level BPE vocab (Sennrich et al., 2016) introduced by Radford et al.",
      "startOffset" : 41,
      "endOffset" : 64
    }, {
      "referenceID" : 16,
      "context" : "using Adam optimizer (Kingma and Ba, 2017) with learning rate 1e-5, warming up steps 1,000, and batch size 32.",
      "startOffset" : 21,
      "endOffset" : 42
    }, {
      "referenceID" : 28,
      "context" : "1 dataset, we pretrain Labeler on DREAM8 (Sun et al., 2019) to boost Labeler’s performance.",
      "startOffset" : 41,
      "endOffset" : 59
    }, {
      "referenceID" : 29,
      "context" : "All our implementations are conducted on NAVER Smart Machine Learning (NSML) platform (Sung et al., 2017; Kim et al., 2018) using hug-",
      "startOffset" : 86,
      "endOffset" : 123
    }, {
      "referenceID" : 15,
      "context" : "All our implementations are conducted on NAVER Smart Machine Learning (NSML) platform (Sung et al., 2017; Kim et al., 2018) using hug-",
      "startOffset" : 86,
      "endOffset" : 123
    }, {
      "referenceID" : 18,
      "context" : "(Lee et al., 2019) as baseline zero-shot learners for fair comparisons with the ATDM.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 32,
      "context" : "VHDA refers to model-based generation method using hierarchical variational autoencoder (Yoo et al., 2020).",
      "startOffset" : 88,
      "endOffset" : 106
    }, {
      "referenceID" : 31,
      "context" : "Especially for zero and few-shot setting, we follow the previous setup (Wu et al., 2019; Campagna et al., 2020).",
      "startOffset" : 71,
      "endOffset" : 111
    }, {
      "referenceID" : 2,
      "context" : "Especially for zero and few-shot setting, we follow the previous setup (Wu et al., 2019; Campagna et al., 2020).",
      "startOffset" : 71,
      "endOffset" : 111
    }, {
      "referenceID" : 32,
      "context" : "We also compare NeuralWOZ with VHDA, a previous model-based data augmentation method for dialogue state tracking (Yoo et al., 2020).",
      "startOffset" : 113,
      "endOffset" : 131
    }, {
      "referenceID" : 23,
      "context" : "Appendix D also includes the comparison and discussion on SimulatedChat (Mohapatra et al., 2020).",
      "startOffset" : 72,
      "endOffset" : 96
    } ],
    "year" : 2021,
    "abstractText" : "We propose NeuralWOZ, a novel dialogue collection framework that uses model-based dialogue simulation. NeuralWOZ has two pipelined models, Collector and Labeler. Collector generates dialogues from (1) user’s goal instructions, which are the user context and task constraints in natural language, and (2) system’s API call results, which is a list of possible query responses for user requests from the given knowledge base. Labeler annotates the generated dialogue by formulating the annotation as a multiple-choice problem, in which the candidate labels are extracted from goal instructions and API call results. We demonstrate the effectiveness of the proposed method in the zero-shot domain transfer learning for dialogue state tracking. In the evaluation, the synthetic dialogue corpus generated from NeuralWOZ achieves a new state-of-theart with improvements of 4.4% point joint goal accuracy on average across domains, and improvements of 5.7% point of zero-shot coverage against the MultiWOZ 2.1 dataset.1",
    "creator" : "LaTeX with hyperref"
  }
}