{
  "name" : "2021.acl-long.278.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Knowing the No-match: Entity Alignment with Dangling Cases",
    "authors" : [ "Zequn Sun", "Muhao Chen", "Wei Hu" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3582–3593\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3582"
    }, {
      "heading" : "1 Introduction",
      "text" : "Knowledge graphs (KGs) have evolved to be the building blocks of many intelligent systems (Ji et al., 2020). Despite the importance, KGs are usually costly to construct (Paulheim, 2018) and naturally suffer from incompleteness (Galárraga et al., 2017). Hence, merging multiple KGs through entity alignment can lead to mutual enrichment of their knowledge (Chen et al., 2020), and provide downstream applications with more comprehensive knowledge representations (Trivedi et al., 2018; Chen et al., 2020). Entity alignment seeks to discover identical entities in different KGs, such as English entity Thailand and its French counterpart\nThaı̈lande. To tackle this important problem, literature has attempted with the embedding-based entity alignment methods (Chen et al., 2017; Wang et al., 2018; Cao et al., 2019; Fey et al., 2020; Wu et al., 2020a; Liu et al., 2020; Sun et al., 2020a). These methods jointly embed different KGs and put similar entities at close positions in a vector space, where the nearest neighbor search can retrieve entity alignment. Due to its effectiveness, embedding-based entity alignment has drawn extensive attention in recent years (Sun et al., 2020c).\nNonetheless, to practically support the alignment of KGs as a real-world task, existing studies suffer one common problem of identifying entities without alignment across KGs (called dangling entities). Specifically, current methods are all built upon the assumption that any source entity has a counterpart in the target KG (Sun et al., 2020c), and are accordingly developed with learning resources that enforce the same assumption. Hence, given every entity in a source KG, a model always tends to predict a counterpart via the nearest neighbor search in the embedding space. However, since each KG may be independently created based on separate corpora (Lehmann et al., 2015) or contributed by different crowds (Speer et al., 2017; Carlson et al., 2010), it is natural for KGs to possess different sets\nof entities (Collarana et al., 2017), as illustrated in Fig. 1. Essentially, this problem overlooked in prior studies causes existing methods to fall short of distinguishing between matchable and dangling entities, hence hinders any of such methods to align KGs in a real-world scenario.\nTowards more practical solutions of entity alignment for KGs, we provide a redefinition of the task with the incorporation of dangling cases (§2.1), as the first contribution of this work. Given a source entity, our setting does not assume that it must have a counterpart in the target KG as what previous studies do. Instead, conducting entity alignment also involves identifying whether the counterpart of an entity actually exists in another KG. Hence, a system to tackle this realistic problem setting of entity alignment is also challenged by the requirement for justifying the validity of its prediction.\nTo facilitate the research towards the new problem, the second contribution of this work is to construct a new dataset DBP2.0 for entity alignment with dangling cases (§2.2). As being discussed, existing benchmarks for entity alignment, including DBP15K (Sun et al., 2017), WK3L (Chen et al., 2017) and the more recent OpenEA (Sun et al., 2020c), are set with the constraint that any entity to be aligned should have a valid counterpart. We use the full DBpedia (Lehmann et al., 2015) to build a new dataset and the key challenge lies in that we need to guarantee the selected dangling entities actually do not have counterparts. We first extract two subgraphs with one-to-one entity alignment (i.e., all entities have counterparts). Then, we randomly remove some entities to make their left counterparts in the peer KG dangling.\nAlthough embedding-based entity alignment has been investigated for several years, handling with dangling entities has not been studied yet. As the third contribution, we present a multi-task learning framework for the proposed task (§3). It consists of two jointly optimized modules for entity alignment and dangling entity detection, respectively. While the entity alignment module can basically incorporate any existing techniques from prior studies (Sun et al., 2020c), in this paper, we experiment with two representative techniques, i.e., relational embedding based (Chen et al., 2017) and neighborhood aggregation based (Sun et al., 2020b) methods. For dangling entity detection, our framework incorporates an auxiliary learning objective, which seeks to learn a confidence metric for the inferred\nentity alignment. The principle to realize such metric learning is that the embeddings of dangling entities should be isolated and are distant from others. According to this principle, we exploit several techniques to distinguish between matchable and dangling entities based on their distance distribution with their neighbors (§3), including nearest neighbor classification, marginal ranking and background ranking (Dhamija et al., 2018).\nWe conduct comprehensive experiments on the new DBP2.0 dataset, which demonstrate the proposed techniques to solve the dangling entity detection problem to different extents. Moreover, we observe that training the dangling detection model (marginal ranking) provides an effective indirect supervision that improves the detection of alignment for matchable entities. We hope our task, dataset and framework can foster further investigation of entity alignment techniques in the suggested real scenario, leading to more effective and practical solutions to this challenging but important problem."
    }, {
      "heading" : "2 Task and Dataset",
      "text" : "We hereby describe the problem setting of our task and introduce the new dataset."
    }, {
      "heading" : "2.1 Task Definition",
      "text" : "A KG is a set of relational triples T ⊆ E ×R× E , where E and R denote vocabularies of entities and relations, respectively. Without loss of generality, we consider entity alignment between two KGs, i.e., a source KG K1=(T1, E1,R1) and a target KG K2=(T2, E2,R2). Given a small set of seed entity alignment A12 = {(e1, e2) ∈ E1 × E2‖e1 ≡ e2} along with a small set of source entities D ⊂ E1 known to have no counterparts as training data, the task seeks to find the remaining entity alignment. Different from the conventional entity alignment setting (Sun et al., 2017), a portion (with an anticipated quantity) of entities in E1 and E2 may have no counterparts. Our training and inference stages take such dangling entities into consideration."
    }, {
      "heading" : "2.2 Dataset Construction",
      "text" : "As discussed, previous testbeds for entity alignment do not contain dangling entities (Sun et al., 2017; Chen et al., 2018; Sun et al., 2020c). Therefore, we first create a new dataset to support the study of the proposed problem setting. Same as the widely used existing benchmark DBP15K (Sun\net al., 2017), we choose DBpedia 2016-101 as the raw data source. Following DBP15K, we also use English (EN), French (FR), Japanese (JA) and Chinese (ZH) versions of DBpedia to build three entity alignment settings of ZH-EN, JA-EN and FR-EN. For each monolingual KG, the triples are extracted from the Infobox Data of DBpedia, where relations are not mapped to a unified ontology. The reference entity alignment data is from the inter-language links (ILLs) of DBpedia across these three bridges of languages. Such reference data is later used as alignment labels for training and testing, and also serves as references to recognize dangling entities.\nConstruction. The key challenge of building our dataset lies in that we need to ensure the selected dangling entities are indeed without counterparts. Specifcally, we cannot simply regard entities without ILLs as dangling ones, since the ILLs are also incomplete (Chen et al., 2017). Under this circumstance, we use a two-step dataset extraction process, which first samples two subgraphs whose entities all have counterparts based on ILLs, and randomly removes a disjoint set of entities in the source and target graphs to make their counterparts dangling. For the first step, we iteratively delete unlinked entities and their triples from the source and target KGs until the left two subgraphs are one-to-one aligned. In the second step for entity removal, while the removed entities are disjoint in two KGs, the proportion of the removed entities also complies with the proportion of unaligned entities in each KG.\nStatistics and evaluation. Tab. 1 lists the statistics our dataset. The three entity alignment settings have different data scales and each is much larger than the same setting in DBP15K, thus can benefit better scalability analysis of models. For dangling entity detection, we split 30% of dangling entities for training, 20% for validation and others for test-\n1Downloaded from https://wiki.dbpedia.org/ downloads-2016-10. The latest 2020 version has not provided updated data for some languages other than English when this study is conducted.\ning. The splits of reference alignment follow the same partition ratio, which is also consistent with that of DBP15K to simulate the weak alignment nature of KGs (Chen et al., 2017; Sun et al., 2017). We also compare the degree distribution of matchable and dangling entities in our dataset against DBP15K in Fig. 7 of Appx. §A. We find the matchable and unlabeled entities in DBP15K have biased degree distribution, which has an adverse effect on dangling entity detection and leads to unreal evaluation. By contrast, in DBP2.0, matchable and dangling entities have similar degree distribution."
    }, {
      "heading" : "3 Entity Alignment with Dangling Cases",
      "text" : "We propose a multi-task learning framework for entity alignment with dangling cases, as illustrated in Fig. 2. It has two jointly optimized modules, i.e., entity alignment and dangling entity detection. The entity alignment module takes as input relational triples of two KGs (for KG embedding) and seed entity alignment (for alignment learning). As for the detection of dangling entities, the module uses a small number of labeled dangling entities to jump-start the learning of a confidence metric for distinguishing between matchable and dangling entities. In the inference stage for entity alignment, our framework is able to first identify and remove dangling entities, then predict alignment for those that are decided to be matchable."
    }, {
      "heading" : "3.1 Entity Alignment",
      "text" : "Our framework can incorporate any entity alignment technique. For the sake of generality, we consider two representative techniques in our framework. One technique is based on MTransE (Chen et al., 2017), which is among the earliest studies for embedding-based entity alignment. It employs the translational model TransE (Bordes et al., 2013) to embed KGs in separate spaces, meanwhile jointly learns a linear transformation between the embedding spaces to match entity counterparts. Specifically, given an entity pair (x1, x2) ∈ A12, let x1 and x2 be their embeddings learned by the translational model. MTransE learns the linear transformation induced by a matrix M by minimizing ‖Mx1−x2‖, where ‖·‖ denotes the L1 or L2 norm.\nThe other technique is from AliNet (Sun et al., 2020b), which is one of the SOTA methods based on graph neural networks. AliNet encodes entities by performing a multi-hop neighborhood aggregation, seeking to cope with heteromorphism of\nalignment search\nsource KG\ntarget KG\nseed entity alignment\ndangling source entities\nentity alignment dangling entity detection\nInput\nLearning\nInference source entity verification remove dangling entities Output\ntraining data\nFigure 2: Framework of entity alignment w/ abstention.\ntheir neighborhood structures. For alignment learning, different from MTransE that only minimizes the transformed embedding distance, AliNet additionally optimizes a margin-based ranking loss for entity counterparts with negative samples. Specifically, let x be a matchable source entity in the seed entity alignment, and x′ is a randomly-sampled entity in the target KG, AliNet attempts to ensure ‖x−x′‖ > λ1 > 0, where λ1 is a distance margin."
    }, {
      "heading" : "3.2 Dangling Entity Detection",
      "text" : "We propose three techniques to implement the dangling detection module based on the distribution of the nearest neighbor distance in embedding space."
    }, {
      "heading" : "3.2.1 NN Classification",
      "text" : "This technique is to train a binary classifier to distinguish between dangling entities (labeled 1, i.e., y = 1) and matchable ones (y = 0). Specifically, we experiment with a feed-forward network (FFN) classifier. Given a source entity x, its input feature representation is the difference vector between its embedding x and its transformed NN embedding xnn in the target KG embedding space2. The confidence of x being a dangling entity is given by p(y = 1|x) = sigmoid(FFN(Mx − xnn)). Let D be the training set of dangling source entities and A denotes the set of matchable entities in the training alignment data. For every x ∈ D∪A, we minimize the cross-entropy loss:\nLx = − ( yx log(p(y = 1|x)) + (1− yx) log(1− p(y = 1|x)) ) , (1)\nwhere yx denotes the truth label for entity x. In a real-world entity alignment scenario, the dangling entities and matchable ones usually differ greatly in quantity, leading to unbalanced label distribution. In that case, we apply label weights (Huang et al., 2016) to balance between the losses for both labels.\n2We use transformed nearest neighbor (NN) to denote the the NN of a source KG entity after it is transformed to the target embedding space."
    }, {
      "heading" : "3.2.2 Marginal Ranking",
      "text" : "Considering that dangling entities are the noises for finding entity alignment based on embedding distance, we are motivated to let dangling entities have solitary representations in the embedding space, i.e., they should keep a distance away from their surrounding embeddings. Hence, we seek to put a distance margin between dangling entities and their sampled NNs. For every input dangling entity x ∈ D, we minimize the following loss:\nLx = max(0, λ− ‖Mx− xnn‖), (2)\nwhere λ is a distance margin. This loss and the entity alignment loss (e.g., that of MTransE) conduct joint learning-to-rank, i.e., the distance between unaligned entities should be larger than that of aligned entities while dangling entities should have a lower ranking in the candidate list of any source entity."
    }, {
      "heading" : "3.2.3 Background Ranking",
      "text" : "In the two aforementioned techniques, searching for the NN of an entity is time-consuming. Furthermore, selecting an appropriate value for the distance margin of the second technique is not trivial. Based on empirical studies, we find that the margin has a significant influence on the final performance. Hence, we would like to find a more efficient and self-driven technique. Inspired by the open-set classification approach (Dhamija et al., 2018) that lets a classifier equally penalize the output logits for samples of classes that are unknown to training (i.e. background classes), we follow a similar principle and let the model equally enlarge the distance of a dangling entity from any sampled target-space entities. This method is to treat all dangling entities as the “background” of the embedding space, since they should be distant from matchable ones. We also decrease the scale of the dangling entity embeddings to further provide a separation between the embeddings of matchable and dangling entities. For the dangling entity x ∈ D, let Xvx be the set of randomly-sampled target entities with size of v. The loss is defined as\nLx = ∑\nx′∈Xvx\n∣∣λx − ‖Mx− x′‖ ∣∣+ α‖x‖, (3)\nwhere | · | denotes the absolute value and α is a weight hyper-parameter for balance. λx is the average distance, i.e., λx = 1v ∑ x′∈Xvx ‖Mx − x\n′‖. This objective can push the relatively close entities away from the source entity without requiring a pre-defined distance margin."
    }, {
      "heading" : "3.3 Learning and Inference",
      "text" : "The overall learning objective of the proposed framework is a combination of the entity alignment loss (e.g., MTransE’s loss) and one of the dangling entity detection loss as mentioned above. The two losses are optimized in alternate batches. More training details are presented in §4.1.\nLike the training phase, the inference phase is also separated into dangling entity detection and entity alignment. The way of inference for dangling entities differs with the employed technique. The NN classification uses the jointly trained FFN classifier to estimate whether the input entity is a dangling one. The marginal ranking takes the preset margin value in training as a confidence threshold, and decides whether an entity is a dangling one based on if its transformed NN distance is higher than the threshold. The inference of background ranking is similar to that of marginal ranking, with only the difference, by its design, to be that the confidence threshold is set as the average NN distance of entities in the target embedding space. After detecting dangling entities, the framework finds alignment in the remaining entities based on the transformed NN search among the matchable entities in the embedding space of the target KG.\nAccelerated NN search. The first and second techniques need to search NNs. We can use an efficient similarity search library Faiss (Johnson et al., 2017) for fast NN retrieval in large embedding space. We also maintain a cache to store the NNs of entities backstage and update it every ten training epochs."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we report our experimental results. We start with describing the experimental setups (§4.1). Next, we separately present the experimentation under two different evaluation settings (§4.2- §4.3), followed by an analysis on the similarity score distribution of the obtained representations for matchable and dangling entities (§4.4). To faciliate the use of the contributed dataset and software, we have incorporated these resources into the OpenEA benchmark3 (Sun et al., 2020c)."
    }, {
      "heading" : "4.1 Experimental Settings",
      "text" : "We consider two evaluation settings. One setting is for the proposed problem setting with dangling entities, for which we refer as the consolidated\n3https://github.com/nju-websoft/OpenEA\nevaluation setting. We first detect and remove the dangling source entities and then search alignment for the left entities. For this evaluation setting, we also separately assess the performance of the dangling detection module. The other simplified setting follows that in previous studies (Sun et al., 2017, 2020c) where the source entities in test set all have counterparts in the target KG, so no dangling source entities are considered. In this relaxed evaluation setting, we seek to evaluate the effect of dangling entity detection on entity alignment and make our results comparable to previous work.\nEvaluation Protocol. For the relaxed evaluation setting, given each source entity, the candidate counterpart list is selected via NN search in the embedding space. The widely-used metrics on the ranking lists are Hits@k (k = 1, 10, H@k for short) and mean reciprocal rank (MRR). Higher H@k and MRR indicate better performance.\nFor the consolidated setting, we report precision, recall and F1 for dangling entity detection. As for assessing the eventual performance of realistic entity alignment, since the dangling entity detection may not be perfect. it is inevitable for some dangling entities to be incorrectly sent to the entity alignment module for aligning, while some matchable ones may be wrongly excluded. In this case, H@k and MRR are not applicable for the consolidated entity alignment evaluation. Following a relevant evaluation setting for entity resolution in database (Mudgal et al., 2018; Ebraheem et al., 2018), we also use precision, recall and F1 as metrics. More specifically, if a source entity is dangling and is not identified by the detection module, the prediction is always regarded as incorrect. Similarly, if a matchable entity is falsely excluded by the dangling detection module, this test case is also regarded as incorrect since the alignment model has no chance to search for alignment. Otherwise, the alignment module searches for the NN of a source entity in the target embedding space and assesses if the predicated counterpart is correct.\nModel Configuration. As described in §3.2, our dangling detection module has three variants, i.e.,\nNN classification (NNC), marginal ranking (MR), and background ranking (BR). We report the implementation details of the entity alignment module (w/ MTransE or AliNet) in Appendices B and C. We initialize KG embeddings and model parameters using the Xavier initializer (Glorot and Bengio, 2010), and use Adam (Kingma and Ba, 2015) to optimize the learning objectives with the learning rate 0.001 for MTransE and 0.0005 for AliNet. Note that we do not follow some methods to initialize with machine translated entity name embeddings (Wu et al., 2020a). As being pointed out by recent studies (Chen et al., 2021; Liu et al., 2021, 2020), this is necessary to prevent test data leakage. Entity similarity is measured by cross-domain similarity local scaling (Lample et al., 2018) for reduced hubness effects, as being consistent to recent studies (Sun et al., 2020b; Chen et al., 2021). We use a twolayer FFN in NNC. For MR, the margin is set as λ = 0.9 for MTransE and 0.2 for AliNet. BR randomly samples 20 target entities for each entity per epoch and α = 0.01. Training is terminated based on F1 results of entity alignment on validation data."
    }, {
      "heading" : "4.2 Relaxed Evaluation",
      "text" : "We first present the evaluation under the relaxed entity alignment setting based on Tab. 2. This setting only involves matchable source entities to test entity alignment, which is an ideal (but less realistic) scenario similar to prior studies (Sun et al., 2020c).\nWe also examine if jointly learning to detect dangling entities can indirectly improve alignment.\nAs observed, MTransE, even without dangling detection, can achieve promising performance on DBP2.0. The results are even better than those on DBP15K as reported by Sun et al. (2017). We attribute this phenomenon to the robustness of this simple embedding method and our improved implementation (e.g., more effective negative sampling). By contrast, although we have tried our best in tuning, the latest GNN-based AliNet falls behind MTransE. Unlike MTransE that learns entity embeddings from a first-order perspective (i.e., based on triple plausibility scores), AliNet represents an entity from a high-order perspective by aggregating its neighbor embeddings, and entities with similar neighborhood structures would have similar representations. However, the dangling entities in DBP2.0 inevitably become spread noises in entity neighborhoods. To further probe into this issue, we count the average neighbor overlap ratio of aligned entities in DBP15K and our DBP2.0. Given an entity alignment pair (x1, x2), let π(x1) and π(x2) be the sets of their neighboring entities respectively, where we also merge their aligned neighbors as one identity based on reference entity alignment. Then the neighbor overlap ratio of x1 and x2 is calculated as |π(x1)∩π(x2)|/|π(x1)∪π(x2)|. We average such a ratio for both DBP15K and DBP2.0 as given in Fig. 3. We can see that the three settings’\noverlap ratios in DBP2.0 are all much lower than those in DBP15K. Thus, DBP2.0 poses additional challenges, as compared to DBP15K, specifically for those methods relying on neighborhood aggregation. Based on results and analysis, we argue that methods performing well on the previous synthetic entity alignment dataset may not robustly generalize to the more realistic dataset with dangling cases. The performance of both MTransE and AliNet is relatively worse on FR-EN, which has more entities (i.e., larger candidate search space) and a low neighborhood overlap ratio (therefore, more difficult to match entities based on neighborhood similarity).\nMeanwhile, we find that the dangling detection module can affect the performance of entity alignment. In details, MR consistently leads to improvement to both MTransE and AliNet. BR can also noticeably boost entity alignment on most settings. This shows that learning to isolate dangling entities from matchable ones naturally provides indirect help to discriminate the counterpart of a matchable entity from irrelevant ones. On the other hand, such indirect supervision signals may be consumed by the additional trainable parameters in NNC, causing its effect on entity alignment to be negligible. Overall, the observation here calls for more robust entity alignment methods and dangling detection techniques, and lead to further analysis (§4.3)."
    }, {
      "heading" : "4.3 Consolidated Evaluation",
      "text" : "We now report the experiment on the more realistic consolidated evaluation setting. Tab. 3 gives the precision, recall and F1 results of dangling entity detection, and the final entity alignment performance is presented in Tab. 4. In addition, Fig. 4\nshows the accuracy of dangling entity detection. We analyze the results from the following aspects.\nDangling entity detection. Regardless of which alignment module is incorporated, NNC performs the worst (e.g., the low recall and accuracy around 0.5) among the dangling detection techniques, whereas BR generally performs the best. NNC determines whether an entity is dangling based on the difference vector of the entity embedding and its NN, instead of directly capturing the embedding distance which is observed to be more important based on the results by the other two techniques. By directly pushing dangling entities away from their NNs in the embedding space, both MR and BR offer much better performance. Besides, BR outperforms MR in most cases. By carefully checking their prediction results and the actual distance of NNs, we find that the induced distance margin in BR better discriminates dangling entities from matchable ones than the pre-defined margin.\nEfficiency. We compare the average epoch time of training the three dangling detection modules for MTransE in Fig. 5. We conduct the experiment using a workstation with an Intel Xeon E51620 3.50GHz CPU and a NVIDIA GeForce RTX 2080 Ti GPU. Since NNC and MR need to search for NNs of source entities, both techniques spend much more training time that is saved by random sampling in BR. Overall, BR is an effective and efficient technique for dangling entity detection.\nEntity alignment. Generally, for both MTransE and AliNet variants, MR and BR lead to better entity alignment results than NNC. MR and BR\nobtain higher precision and recall performance on detecting dangling entities as listed in Tab. 3, resulting in less noise that enters the entity alignment stage. By contrast, NNC has a low accuracy and thus introduces many noises. As BR outperforms MR in dangling detection, it also achieves higher entity alignment results than MR on most settings. We also notice that MR in a few settings, MR offer comparible or slightly better performance than BR. This is because MR can enhance the learning of alignment modules (see §4.2 for detailed analysis), thus delivering improvement to the final performance. MTransE variants generally excels AliNet variants in both entity alignment (see Tab. 2) and dangling entity detection (see Tab. 3) than AliNet, similar to the observation in §4.2.\nAlignment direction. We find that the alignment direction makes a difference in both dangling entity detection and entity alignment. Using EN KG as the source is coupled with easier dangling detection than in other languages, as the most populated EN KG contributes more dangling entities and triples to training than other KGs. As for entity alignment, we find the observation to be quite the opposite, as using the EN KG as a source leads to noticeable drops in results. For example, the precision of MTransE-BR is 0.312 on ZH-EN, but only 0.241 on EN-ZH. This is because the EN KG has a larger portion of dangling entities. Although the dangling detection module performs well on the EN KG than on others, there are still much more dangling entities entering the alignment search stage, thus reducing the entity alignment precision. This observation suggests that choosing the alignment direction from a less populated KG to the more populated EN KG can be a more effective solution."
    }, {
      "heading" : "4.4 Similarity Score Distribution",
      "text" : "To illustrate how well the BR technique distinguishes between matchable and dangling entities,\nwe plot in Fig. 6 the distribution of similarity scores of each test entity and its NN. The plot illustrates BR has the expected effect to isolate dangling entities from their NNs, whereas matchable entities are generally placed closer to their NNs. Yet, we can still see a modest overlap between the two NN similarity distributions of dangling and matchable entities, and a number of dangling entities still have a quite large NN similarity. This also reveals the fact that the proposed problem setting of entity alignment with dangling cases has many remaining challenges that await further investigation."
    }, {
      "heading" : "5 Related Work",
      "text" : "We discuss two topics of relevant work."
    }, {
      "heading" : "5.1 Entity Alignment",
      "text" : "Embedding-based entity alignment is first attempted in MTransE (Chen et al., 2017), which jointly learns a translational embedding model and a transform-based alignment model for two KGs. Later studies generally follow three lines of improvement. (i) The first line improves the embedding technique to better suit the alignment task, including contextual translation techniques (Sun et al., 2019), long-term dependency techniques (Guo et al., 2019) and neighborhood aggregation (or GNN-based) ones (Wang et al., 2018; Cao et al., 2019; Li et al., 2019; Sun et al., 2020b,a; Fey et al., 2020). (ii) The second line focuses on effective alignment learning with limited supervision. Some leverage semi-supervised learning techniques to resolve the training data insufficiency issue, including self-learning (Sun et al., 2018; Mao et al., 2020) and co-training (Chen et al., 2018). (iii) Another line of research seeks to retrieve auxiliary or indirect supervision signals from profile information or side features of entities, such as entity attributes (Sun et al., 2017; Trisedya et al., 2019; Zhang et al., 2019; Pei et al., 2019), literals (Wu et al., 2019, 2020b; Liu et al., 2020), free text (Chen et al., 2021), pre-trained language models (Yang et al., 2019; Tang et al., 2020) or visual modalities (Liu et al., 2021). Due to the large body of recent advances, we refer readers to a more comprehensive summarization in the survey (Sun et al., 2020c)."
    }, {
      "heading" : "5.2 Learning with Abstention",
      "text" : "Learning with abstention is a fundamental machine learning, where the learner can opt to abstain from making a prediction if without enough decisive\nconfidence (Cortes et al., 2016, 2018). Related techniques include thresholding softmax (Stefano et al., 2000), selective classification (Geifman and El-Yaniv, 2017), open-set classification with background classes (Dhamija et al., 2018) and out-ofdistribution detection (Liang et al., 2018; Vyas et al., 2018). The idea of learning with abstention also has applications in NLP, such as unanswerable QA, where correct answers of some questions are not stated in the given reference text (Rajpurkar et al., 2018; Zhu et al., 2019; Hu et al., 2019).\nTo the best of our knowledge, our task, dataset, and the proposed dangling detection techniques are the first contribution to support learning with abstention for entity alignment and structured representation learning."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "In this paper, we propose and study a new entity alignment task with dangling cases. We construct a dataset to support the study of the proposed problem setting, and design a multi-learning framework for both entity alignment and dangling entity detection. Three types of dangling detection techniques are studied, which are based on nearest neighbor classification, marginal ranking, and background ranking. Comprehensive experiments demonstrate the effectiveness of the method, and provide insights to foster further investigation on this new problem. We further find that dangling entity detection can, in turn, effectively provide auxiliary supervision signals to improve the performance of entity alignment.\nFor future work, we plan to extend the benchmarking on DBP2.0 with results from more base models of entity alignment as well as more abstention inference techniques. Extending our framework to support more prediction tasks with abstention, such as entity type inference (Hao et al., 2019) and relation extraction (Alt et al., 2020), is another direction with potentially broad impact."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank the anonymous reviewers for their insightful comments. This work is supported by the National Natural Science Foundation of China (No. 61872172), and the Collaborative Innovation Center of Novel Software Technology & Industrialization. Muhao Chen’s work is supported by the National Science Foundation of United States Grant IIS-2105329."
    }, {
      "heading" : "A Degree Distribution",
      "text" : "Fig. 7 shows the degree distribution of the matchable and dangling entities in our dataset against DBP15K. Although DBP15K contains some entities that are not labeled to have counterparts, by checking the ILLs in the recent update of DBpedia, we find many of these entities to have counterparts in the target KG. Hence, these entities in DBP15k cannot act as dangling entities that are key to the more realistic evaluation protocol being proposed in this work. From the comparison, we can see that these unlabeled entities in DBP15K have much fewer triples than matchable entities. This biased degree distribution will have an adverse effect on dangling entity detection and lead to unreal evaluation. By contrast, in our dataset, matchable and dangling entities have similar degree distribution."
    }, {
      "heading" : "B Configuration of MTransE and AliNet",
      "text" : "For entity alignment, we experiment with MTransE (Chen et al., 2017) and the SOTA method AliNet (Sun et al., 2020b). The implementation of our\nframework is extended based on OpenEA (Sun et al., 2020c). We adopt the truncated negative sampling method by BootEA (Sun et al., 2018) to generate negative triples for MTransE and negative alignment links for AliNet, which leads to improved performance. The embedding size is 128 for MTransE and 256 for AliNet. The batch size of MTransE is 20, 480 on ZH-EN and JA-EN, and 102, 400 on FR-EN. The batch size of AliNet is 8, 192 on ZH-EN and JA-EN, and 20, 480 on FREN. λ1 = 1.4 in AliNet."
    }, {
      "heading" : "C Hyper-parameter Settings",
      "text" : "We select each hyper-parameter setting within a wide range of values as follows:\n• Learning rate: {0.0001, 0.0002, 0.0005, 0.001} • Embedding dimension: {64, 128, 256, 512} • Batch size: {4096, 8192, 10240, 20480, 102400} • # FNN layers: {1, 2, 3, 4} • # Random targets: {1, 10, 20, 30, 40, 50} • λ: {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}"
    }, {
      "heading" : "D Recall@10 of Entity Alignment",
      "text" : "Fig. 8 gives the recall@10 results of the MTransE variants with dangling entity detection in the consolidated evaluation setting. We can see that the recall@10 results on FR-EN are lower than that on ZH-EN and JA-EN, which is similar to the observation in entity alignment §4.3. From the results, we think existing embedding-based entity alignment methods are still far from being usable in practice."
    } ],
    "references" : [ {
      "title" : "Tacred revisited: A thorough evaluation of the tacred relation extraction task",
      "author" : [ "Christoph Alt", "Aleksandra Gabryszak", "Leonhard Hennig." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), pages",
      "citeRegEx" : "Alt et al\\.,? 2020",
      "shortCiteRegEx" : "Alt et al\\.",
      "year" : 2020
    }, {
      "title" : "Translating embeddings for modeling multirelational data",
      "author" : [ "Antoine Bordes", "Nicolas Usunier", "Alberto Garcı́aDurán", "Jason Weston", "Oksana Yakhnenko" ],
      "venue" : "In Proceedings of the 27th Annual Conference on Neural Information Processing Sys-",
      "citeRegEx" : "Bordes et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2013
    }, {
      "title" : "Multi-channel graph neural network for entity alignment",
      "author" : [ "Yixin Cao", "Zhiyuan Liu", "Chengjiang Li", "Zhiyuan Liu", "Juanzi Li", "Tat-Seng Chua." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL), pages",
      "citeRegEx" : "Cao et al\\.,? 2019",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2019
    }, {
      "title" : "Toward an architecture for never-ending language learning",
      "author" : [ "Andrew Carlson", "Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam Hruschka", "Tom Mitchell." ],
      "venue" : "Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI).",
      "citeRegEx" : "Carlson et al\\.,? 2010",
      "shortCiteRegEx" : "Carlson et al\\.",
      "year" : 2010
    }, {
      "title" : "Cross-lingual Entity Alignment with Incidental Supervision",
      "author" : [ "Muhao Chen", "Weijia Shi", "Ben Zhou", "Dan Roth." ],
      "venue" : "Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL).",
      "citeRegEx" : "Chen et al\\.,? 2021",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2021
    }, {
      "title" : "Co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment",
      "author" : [ "Muhao Chen", "Yingtao Tian", "Kai-Wei Chang", "Steven Skiena", "Carlo Zaniolo." ],
      "venue" : "Proceedings of the 27th International Joint Conference on",
      "citeRegEx" : "Chen et al\\.,? 2018",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2018
    }, {
      "title" : "Multilingual knowledge graph embeddings for cross-lingual knowledge alignment",
      "author" : [ "Muhao Chen", "Yingtao Tian", "Mohan Yang", "Carlo Zaniolo." ],
      "venue" : "Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI), pages 1511–",
      "citeRegEx" : "Chen et al\\.,? 2017",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2017
    }, {
      "title" : "Multilingual knowledge graph completion via ensemble knowledge transfer",
      "author" : [ "Xuelu Chen", "Muhao Chen", "Changjun Fan", "Ankith Uppunda", "Yizhou Sun", "Carlo Zaniolo." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "Semantic data integration for knowledge graph construction at query time",
      "author" : [ "Diego Collarana", "Mikhail Galkin", "Ignacio Traverso Ribón", "Christoph Lange", "Maria-Esther Vidal", "Sören Auer." ],
      "venue" : "Proceedings of the 11th IEEE International Conference",
      "citeRegEx" : "Collarana et al\\.,? 2017",
      "shortCiteRegEx" : "Collarana et al\\.",
      "year" : 2017
    }, {
      "title" : "Online learning with abstention",
      "author" : [ "Corinna Cortes", "Giulia DeSalvo", "Claudio Gentile", "Mehryar Mohri", "Scott Yang." ],
      "venue" : "Proceedings of the 35th Inter-",
      "citeRegEx" : "Cortes et al\\.,? 2018",
      "shortCiteRegEx" : "Cortes et al\\.",
      "year" : 2018
    }, {
      "title" : "Boosting with abstention",
      "author" : [ "Corinna Cortes", "Giulia DeSalvo", "Mehryar Mohri." ],
      "venue" : "Proceedings of the 30th Annual Conference on Neural Information Processing Systems (NeurIPS), pages 1660–1668.",
      "citeRegEx" : "Cortes et al\\.,? 2016",
      "shortCiteRegEx" : "Cortes et al\\.",
      "year" : 2016
    }, {
      "title" : "Reducing network agnostophobia",
      "author" : [ "Akshay Raj Dhamija", "Manuel Günther", "Terrance E. Boult." ],
      "venue" : "Proceedings of the 32nd Annual Conference on Neural Information Processing Systems (NeurIPS), pages 9175–9186.",
      "citeRegEx" : "Dhamija et al\\.,? 2018",
      "shortCiteRegEx" : "Dhamija et al\\.",
      "year" : 2018
    }, {
      "title" : "Distributed representations of tuples for entity resolution",
      "author" : [ "Muhammad Ebraheem", "Saravanan Thirumuruganathan", "Shafiq R. Joty", "Mourad Ouzzani", "Nan Tang." ],
      "venue" : "Proceedings of the VLDB Endowment, 11(11):1454–1467.",
      "citeRegEx" : "Ebraheem et al\\.,? 2018",
      "shortCiteRegEx" : "Ebraheem et al\\.",
      "year" : 2018
    }, {
      "title" : "Deep graph matching consensus",
      "author" : [ "Matthias Fey", "Jan Eric Lenssen", "Christopher Morris", "Jonathan Masci", "Nils M. Kriege." ],
      "venue" : "Proceedings of the 8th International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Fey et al\\.,? 2020",
      "shortCiteRegEx" : "Fey et al\\.",
      "year" : 2020
    }, {
      "title" : "Predicting completeness in knowledge bases",
      "author" : [ "Luis Galárraga", "Simon Razniewski", "Antoine Amarilli", "Fabian M. Suchanek." ],
      "venue" : "Proceedings of the 10th ACM International Conference on Web Search and Data Mining (WSDM), pages 375–383.",
      "citeRegEx" : "Galárraga et al\\.,? 2017",
      "shortCiteRegEx" : "Galárraga et al\\.",
      "year" : 2017
    }, {
      "title" : "Selective classification for deep neural networks",
      "author" : [ "Yonatan Geifman", "Ran El-Yaniv." ],
      "venue" : "Proceedings of the 31st Annual Conference on Neural Information Processing Systems (NeurIPS), pages 4878– 4887.",
      "citeRegEx" : "Geifman and El.Yaniv.,? 2017",
      "shortCiteRegEx" : "Geifman and El.Yaniv.",
      "year" : 2017
    }, {
      "title" : "Understanding the difficulty of training deep feedforward neural networks",
      "author" : [ "Xavier Glorot", "Yoshua Bengio." ],
      "venue" : "Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS), pages 249–256.",
      "citeRegEx" : "Glorot and Bengio.,? 2010",
      "shortCiteRegEx" : "Glorot and Bengio.",
      "year" : 2010
    }, {
      "title" : "Learning to exploit long-term relational dependencies in knowledge graphs",
      "author" : [ "Lingbing Guo", "Zequn Sun", "Wei Hu." ],
      "venue" : "Proceedings of the 36th International Conference on Machine Learning (ICML), pages 2505–2514.",
      "citeRegEx" : "Guo et al\\.,? 2019",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2019
    }, {
      "title" : "Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts",
      "author" : [ "Junheng Hao", "Muhao Chen", "Wenchao Yu", "Yizhou Sun", "Wei Wang." ],
      "venue" : "Proceedings of the ACM SIGKDD International Conference",
      "citeRegEx" : "Hao et al\\.,? 2019",
      "shortCiteRegEx" : "Hao et al\\.",
      "year" : 2019
    }, {
      "title" : "Read + Verify: Machine reading comprehension with unanswerable questions",
      "author" : [ "Minghao Hu", "Furu Wei", "Yuxing Peng", "Zhen Huang", "Nan Yang", "Dongsheng Li." ],
      "venue" : "Proceedings of the 33rd AAAI Conference on Artificial Intelligence (AAAI), pages 6529–",
      "citeRegEx" : "Hu et al\\.,? 2019",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning deep representation for imbalanced classification",
      "author" : [ "Chen Huang", "Yining Li", "Chen Change Loy", "Xiaoou Tang." ],
      "venue" : "Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR), pages 5375–5384.",
      "citeRegEx" : "Huang et al\\.,? 2016",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2016
    }, {
      "title" : "A survey on knowledge graphs: Representation, acquisition and applications",
      "author" : [ "Shaoxiong Ji", "Shirui Pan", "Erik Cambria", "Pekka Marttinen", "Philip S. Yu." ],
      "venue" : "CoRR, abs/2002.00388.",
      "citeRegEx" : "Ji et al\\.,? 2020",
      "shortCiteRegEx" : "Ji et al\\.",
      "year" : 2020
    }, {
      "title" : "Billion-scale similarity search with gpus",
      "author" : [ "Jeff Johnson", "Matthijs Douze", "Hervé Jégou." ],
      "venue" : "CoRR, abs/1702.08734.",
      "citeRegEx" : "Johnson et al\\.,? 2017",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2017
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "Proceedings of the 3rd International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Word translation without parallel data",
      "author" : [ "Guillaume Lample", "Alexis Conneau", "Marc’Aurelio Ranzato", "Ludovic Denoyer", "Hervé Jégou" ],
      "venue" : "In Proceedings of the 6th International Conference on Learning Representations (ICLR)",
      "citeRegEx" : "Lample et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2018
    }, {
      "title" : "DBpedia - A large-scale, multilingual knowledge base extracted",
      "author" : [ "Jens Lehmann", "Robert Isele", "Max Jakob", "Anja Jentzsch", "Dimitris Kontokostas", "Pablo N. Mendes", "Sebastian Hellmann", "Mohamed Morsey", "Patrick van Kleef", "Sören Auer", "Christian Bizer" ],
      "venue" : null,
      "citeRegEx" : "Lehmann et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lehmann et al\\.",
      "year" : 2015
    }, {
      "title" : "Semi-supervised entity alignment via joint knowledge embedding model and cross-graph model",
      "author" : [ "Chengjiang Li", "Yixin Cao", "Lei Hou", "Jiaxin Shi", "Juanzi Li", "Tat-Seng Chua." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Nat-",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Enhancing the reliability of out-of-distribution image detection in neural networks",
      "author" : [ "Shiyu Liang", "Yixuan Li", "R Srikant." ],
      "venue" : "Proceedings of the 6th International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Liang et al\\.,? 2018",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2018
    }, {
      "title" : "Visual Pivoting for (Unsupervised) Entity Alignment",
      "author" : [ "Fangyu Liu", "Muhao Chen", "Dan Roth", "Nigel Collier." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence (AAAI).",
      "citeRegEx" : "Liu et al\\.,? 2021",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2021
    }, {
      "title" : "Exploring and evaluating attributes, values, and structures for entity alignment",
      "author" : [ "Zhiyuan Liu", "Yixin Cao", "Liangming Pan", "Juanzi Li", "Tat-Seng Chua." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Mraea: an efficient and robust entity alignment approach for cross-lingual knowledge graph",
      "author" : [ "Xin Mao", "Wenting Wang", "Huimin Xu", "Man Lan", "Yuanbin Wu." ],
      "venue" : "Proceedings of the 13th International Conference on Web Search and Data Mining",
      "citeRegEx" : "Mao et al\\.,? 2020",
      "shortCiteRegEx" : "Mao et al\\.",
      "year" : 2020
    }, {
      "title" : "Deep learning for entity matching: A design space exploration",
      "author" : [ "Sidharth Mudgal", "Han Li", "Theodoros Rekatsinas", "AnHai Doan", "Youngchoon Park", "Ganesh Krishnan", "Rohit Deep", "Esteban Arcaute", "Vijay Raghavendra." ],
      "venue" : "Proceedings of the 2018 Inter-",
      "citeRegEx" : "Mudgal et al\\.,? 2018",
      "shortCiteRegEx" : "Mudgal et al\\.",
      "year" : 2018
    }, {
      "title" : "How much is a triple? estimating the cost of knowledge graph creation",
      "author" : [ "Heiko Paulheim." ],
      "venue" : "Proceedings of the 17th International Semantic Web Conference (ISWC).",
      "citeRegEx" : "Paulheim.,? 2018",
      "shortCiteRegEx" : "Paulheim.",
      "year" : 2018
    }, {
      "title" : "Semi-supervised entity alignment via knowledge graph embedding with awareness of degree difference",
      "author" : [ "Shichao Pei", "Lu Yu", "Robert Hoehndorf", "Xiangliang Zhang." ],
      "venue" : "Proceedings of the World Wide Web Conference (WWW), pages 3130–3136.",
      "citeRegEx" : "Pei et al\\.,? 2019",
      "shortCiteRegEx" : "Pei et al\\.",
      "year" : 2019
    }, {
      "title" : "Know what you don’t know: Unanswerable questions for SQuAD",
      "author" : [ "Pranav Rajpurkar", "Robin Jia", "Percy Liang." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), pages 784–789.",
      "citeRegEx" : "Rajpurkar et al\\.,? 2018",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2018
    }, {
      "title" : "Conceptnet 5.5: An open multilingual graph of general knowledge",
      "author" : [ "Robyn Speer", "Joshua Chin", "Catherine Havasi" ],
      "venue" : "In Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI),",
      "citeRegEx" : "Speer et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Speer et al\\.",
      "year" : 2017
    }, {
      "title" : "To reject or not to reject: that is the questionan answer in case of neural classifiers",
      "author" : [ "Claudio De Stefano", "Carlo Sansone", "Mario Vento." ],
      "venue" : "IEEE Transactions on Systems, Man, and Cybernetics - Part C: Applications and Reviews, 30(1):84–94.",
      "citeRegEx" : "Stefano et al\\.,? 2000",
      "shortCiteRegEx" : "Stefano et al\\.",
      "year" : 2000
    }, {
      "title" : "Knowledge association with hyperbolic knowledge graph embeddings",
      "author" : [ "Zequn Sun", "Muhao Chen", "Wei Hu", "Chengming Wang", "Jian Dai", "Wei Zhang." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Sun et al\\.,? 2020a",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2020
    }, {
      "title" : "Cross-lingual entity alignment via joint attributepreserving embedding",
      "author" : [ "Zequn Sun", "Wei Hu", "Chengkai Li." ],
      "venue" : "Proceedings of the 16th International Semantic Web Conference (ISWC), pages 628–644.",
      "citeRegEx" : "Sun et al\\.,? 2017",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2017
    }, {
      "title" : "Bootstrapping entity alignment with knowledge graph embedding",
      "author" : [ "Zequn Sun", "Wei Hu", "Qingheng Zhang", "Yuzhong Qu." ],
      "venue" : "Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI), pages 4396–4402.",
      "citeRegEx" : "Sun et al\\.,? 2018",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2018
    }, {
      "title" : "Transedge: Translating relation-contextualized embeddings for knowledge graphs",
      "author" : [ "Zequn Sun", "JiaCheng Huang", "Wei Hu", "Muhao Chen", "Lingbing Guo", "Yuzhong Qu." ],
      "venue" : "Proceedings of the 18th International Semantic Web Conference (ISWC), pages",
      "citeRegEx" : "Sun et al\\.,? 2019",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Knowledge graph alignment network with gated",
      "author" : [ "Zequn Sun", "Chengming Wang", "Wei Hu", "Muhao Chen", "Jian Dai", "Wei Zhang", "Yuzhong Qu" ],
      "venue" : null,
      "citeRegEx" : "Sun et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2020
    }, {
      "title" : "A benchmarking study of embedding-based entity alignment for knowledge graphs",
      "author" : [ "Zequn Sun", "Qingheng Zhang", "Wei Hu", "Chengming Wang", "Muhao Chen", "Farahnaz Akrami", "Chengkai Li." ],
      "venue" : "Proceedings of the VLDB Endowment,",
      "citeRegEx" : "Sun et al\\.,? 2020c",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT-INT: A bertbased interaction model for knowledge graph alignment",
      "author" : [ "Xiaobin Tang", "Jing Zhang", "Bo Chen", "Yang Yang", "Hong Chen", "Cuiping Li." ],
      "venue" : "Proceedings of the 29th International Joint Conference on Artificial Intelligence (IJCAI), pages",
      "citeRegEx" : "Tang et al\\.,? 2020",
      "shortCiteRegEx" : "Tang et al\\.",
      "year" : 2020
    }, {
      "title" : "Entity alignment between knowledge graphs using attribute embeddings",
      "author" : [ "Bayu Distiawan Trisedya", "Jianzhong Qi", "Rui Zhang." ],
      "venue" : "Proceedings of the 33rd AAAI Conference on Artificial Intelligence (AAAI), pages 297–304.",
      "citeRegEx" : "Trisedya et al\\.,? 2019",
      "shortCiteRegEx" : "Trisedya et al\\.",
      "year" : 2019
    }, {
      "title" : "LinkNBed: Multi-graph representation learning with entity linkage",
      "author" : [ "Rakshit Trivedi", "Bunyamin Sisman", "Xin Luna Dong", "Christos Faloutsos", "Jun Ma", "Hongyuan Zha." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computa-",
      "citeRegEx" : "Trivedi et al\\.,? 2018",
      "shortCiteRegEx" : "Trivedi et al\\.",
      "year" : 2018
    }, {
      "title" : "Out-of-distribution detection using an ensemble of self supervised leave-out classifiers",
      "author" : [ "Apoorv Vyas", "Nataraj Jammalamadaka", "Xia Zhu", "Dipankar Das", "Bharat Kaul", "Theodore L Willke." ],
      "venue" : "Proceedings of the European Conference on Computer",
      "citeRegEx" : "Vyas et al\\.,? 2018",
      "shortCiteRegEx" : "Vyas et al\\.",
      "year" : 2018
    }, {
      "title" : "Cross-lingual knowledge graph alignment via graph convolutional networks",
      "author" : [ "Zhichun Wang", "Qingsong Lv", "Xiaohan Lan", "Yu Zhang." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Jointly learning entity and relation representations for entity alignment",
      "author" : [ "Yuting Wu", "Xiao Liu", "Yansong Feng", "Zheng Wang", "Dongyan Zhao." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th In-",
      "citeRegEx" : "Wu et al\\.,? 2019",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Neighborhood matching network for entity alignment",
      "author" : [ "Yuting Wu", "Xiao Liu", "Yansong Feng", "Zheng Wang", "Dongyan Zhao." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), pages 6477–6487.",
      "citeRegEx" : "Wu et al\\.,? 2020a",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Neighborhood matching network for entity alignment",
      "author" : [ "Yuting Wu", "Xiao Liu", "Yansong Feng", "Zheng Wang", "Dongyan Zhao." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), pages 6477–6487.",
      "citeRegEx" : "Wu et al\\.,? 2020b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Aligning cross-lingual entities with multi-aspect information",
      "author" : [ "Hsiu-Wei Yang", "Yanyan Zou", "Peng Shi", "Wei Lu", "Jimmy Lin", "Xu Sun." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th Interna-",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Multi-view knowledge graph embedding for entity alignment",
      "author" : [ "Qingheng Zhang", "Zequn Sun", "Wei Hu", "Muhao Chen", "Lingbing Guo", "Yuzhong Qu." ],
      "venue" : "Proceedings of the 28th International Joint Conference (IJCAI), pages 5429–5435.",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning to ask unanswerable questions for machine reading comprehension",
      "author" : [ "Haichao Zhu", "Li Dong", "Furu Wei", "Wenhui Wang", "Bing Qin", "Ting Liu." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL),",
      "citeRegEx" : "Zhu et al\\.,? 2019",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2019
    }, {
      "title" : "2017) and the SOTA method AliNet",
      "author" : [ "Chen" ],
      "venue" : null,
      "citeRegEx" : "Chen,? \\Q2017\\E",
      "shortCiteRegEx" : "Chen",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "building blocks of many intelligent systems (Ji et al., 2020).",
      "startOffset" : 44,
      "endOffset" : 61
    }, {
      "referenceID" : 32,
      "context" : "Despite the importance, KGs are usually costly to construct (Paulheim, 2018) and naturally suffer from incompleteness (Galárraga et al.",
      "startOffset" : 60,
      "endOffset" : 76
    }, {
      "referenceID" : 14,
      "context" : "Despite the importance, KGs are usually costly to construct (Paulheim, 2018) and naturally suffer from incompleteness (Galárraga et al., 2017).",
      "startOffset" : 118,
      "endOffset" : 142
    }, {
      "referenceID" : 7,
      "context" : "Hence, merging multiple KGs through entity alignment can lead to mutual enrichment of their knowledge (Chen et al., 2020), and provide downstream applications with more comprehensive knowledge representations (Trivedi et al.",
      "startOffset" : 102,
      "endOffset" : 121
    }, {
      "referenceID" : 6,
      "context" : "To tackle this important problem, literature has attempted with the embedding-based entity alignment methods (Chen et al., 2017; Wang et al., 2018; Cao et al., 2019; Fey et al., 2020; Wu et al., 2020a; Liu et al., 2020; Sun et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 238
    }, {
      "referenceID" : 47,
      "context" : "To tackle this important problem, literature has attempted with the embedding-based entity alignment methods (Chen et al., 2017; Wang et al., 2018; Cao et al., 2019; Fey et al., 2020; Wu et al., 2020a; Liu et al., 2020; Sun et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 238
    }, {
      "referenceID" : 2,
      "context" : "To tackle this important problem, literature has attempted with the embedding-based entity alignment methods (Chen et al., 2017; Wang et al., 2018; Cao et al., 2019; Fey et al., 2020; Wu et al., 2020a; Liu et al., 2020; Sun et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 238
    }, {
      "referenceID" : 13,
      "context" : "To tackle this important problem, literature has attempted with the embedding-based entity alignment methods (Chen et al., 2017; Wang et al., 2018; Cao et al., 2019; Fey et al., 2020; Wu et al., 2020a; Liu et al., 2020; Sun et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 238
    }, {
      "referenceID" : 49,
      "context" : "To tackle this important problem, literature has attempted with the embedding-based entity alignment methods (Chen et al., 2017; Wang et al., 2018; Cao et al., 2019; Fey et al., 2020; Wu et al., 2020a; Liu et al., 2020; Sun et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 238
    }, {
      "referenceID" : 29,
      "context" : "To tackle this important problem, literature has attempted with the embedding-based entity alignment methods (Chen et al., 2017; Wang et al., 2018; Cao et al., 2019; Fey et al., 2020; Wu et al., 2020a; Liu et al., 2020; Sun et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 238
    }, {
      "referenceID" : 37,
      "context" : "To tackle this important problem, literature has attempted with the embedding-based entity alignment methods (Chen et al., 2017; Wang et al., 2018; Cao et al., 2019; Fey et al., 2020; Wu et al., 2020a; Liu et al., 2020; Sun et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 238
    }, {
      "referenceID" : 42,
      "context" : "Due to its effectiveness, embedding-based entity alignment has drawn extensive attention in recent years (Sun et al., 2020c).",
      "startOffset" : 105,
      "endOffset" : 124
    }, {
      "referenceID" : 42,
      "context" : "Specifically, current methods are all built upon the assumption that any source entity has a counterpart in the target KG (Sun et al., 2020c), and are ac-",
      "startOffset" : 122,
      "endOffset" : 141
    }, {
      "referenceID" : 25,
      "context" : "corpora (Lehmann et al., 2015) or contributed by different crowds (Speer et al.",
      "startOffset" : 8,
      "endOffset" : 30
    }, {
      "referenceID" : 35,
      "context" : ", 2015) or contributed by different crowds (Speer et al., 2017; Carlson et al., 2010), it is natural for KGs to possess different sets",
      "startOffset" : 43,
      "endOffset" : 85
    }, {
      "referenceID" : 3,
      "context" : ", 2015) or contributed by different crowds (Speer et al., 2017; Carlson et al., 2010), it is natural for KGs to possess different sets",
      "startOffset" : 43,
      "endOffset" : 85
    }, {
      "referenceID" : 38,
      "context" : "As being discussed, existing benchmarks for entity alignment, including DBP15K (Sun et al., 2017), WK3L (Chen et al.",
      "startOffset" : 79,
      "endOffset" : 97
    }, {
      "referenceID" : 6,
      "context" : ", 2017), WK3L (Chen et al., 2017) and the more recent OpenEA (Sun et al.",
      "startOffset" : 14,
      "endOffset" : 33
    }, {
      "referenceID" : 42,
      "context" : ", 2017) and the more recent OpenEA (Sun et al., 2020c), are set with the constraint that any entity to be aligned should have a valid counterpart.",
      "startOffset" : 35,
      "endOffset" : 54
    }, {
      "referenceID" : 42,
      "context" : "ies (Sun et al., 2020c), in this paper, we experiment with two representative techniques, i.",
      "startOffset" : 4,
      "endOffset" : 23
    }, {
      "referenceID" : 6,
      "context" : ", relational embedding based (Chen et al., 2017) and neighborhood aggregation based (Sun et al.",
      "startOffset" : 29,
      "endOffset" : 48
    }, {
      "referenceID" : 11,
      "context" : "According to this principle, we exploit several techniques to distinguish between matchable and dangling entities based on their distance distribution with their neighbors (§3), including nearest neighbor classification, marginal ranking and background ranking (Dhamija et al., 2018).",
      "startOffset" : 261,
      "endOffset" : 283
    }, {
      "referenceID" : 38,
      "context" : "Different from the conventional entity alignment setting (Sun et al., 2017), a portion (with an anticipated quantity) of entities in E1 and E2 may have no counterparts.",
      "startOffset" : 57,
      "endOffset" : 75
    }, {
      "referenceID" : 38,
      "context" : "As discussed, previous testbeds for entity alignment do not contain dangling entities (Sun et al., 2017; Chen et al., 2018; Sun et al., 2020c).",
      "startOffset" : 86,
      "endOffset" : 142
    }, {
      "referenceID" : 5,
      "context" : "As discussed, previous testbeds for entity alignment do not contain dangling entities (Sun et al., 2017; Chen et al., 2018; Sun et al., 2020c).",
      "startOffset" : 86,
      "endOffset" : 142
    }, {
      "referenceID" : 42,
      "context" : "As discussed, previous testbeds for entity alignment do not contain dangling entities (Sun et al., 2017; Chen et al., 2018; Sun et al., 2020c).",
      "startOffset" : 86,
      "endOffset" : 142
    }, {
      "referenceID" : 6,
      "context" : "out ILLs as dangling ones, since the ILLs are also incomplete (Chen et al., 2017).",
      "startOffset" : 62,
      "endOffset" : 81
    }, {
      "referenceID" : 6,
      "context" : "The splits of reference alignment follow the same partition ratio, which is also consistent with that of DBP15K to simulate the weak alignment nature of KGs (Chen et al., 2017; Sun et al., 2017).",
      "startOffset" : 157,
      "endOffset" : 194
    }, {
      "referenceID" : 38,
      "context" : "The splits of reference alignment follow the same partition ratio, which is also consistent with that of DBP15K to simulate the weak alignment nature of KGs (Chen et al., 2017; Sun et al., 2017).",
      "startOffset" : 157,
      "endOffset" : 194
    }, {
      "referenceID" : 6,
      "context" : "One technique is based on MTransE (Chen et al., 2017), which is among the earliest studies for embedding-based entity alignment.",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 1,
      "context" : "It employs the translational model TransE (Bordes et al., 2013) to embed KGs in separate spaces, meanwhile jointly learns a linear transformation between the embedding spaces to match entity counterparts.",
      "startOffset" : 42,
      "endOffset" : 63
    }, {
      "referenceID" : 20,
      "context" : "In that case, we apply label weights (Huang et al., 2016) to balance between the losses for both labels.",
      "startOffset" : 37,
      "endOffset" : 57
    }, {
      "referenceID" : 11,
      "context" : "Inspired by the open-set classification approach (Dhamija et al., 2018) that lets a classifier equally penalize the output logits for samples of classes that are unknown to training (i.",
      "startOffset" : 49,
      "endOffset" : 71
    }, {
      "referenceID" : 22,
      "context" : "similarity search library Faiss (Johnson et al., 2017) for fast NN retrieval in large embedding space.",
      "startOffset" : 32,
      "endOffset" : 54
    }, {
      "referenceID" : 42,
      "context" : "To faciliate the use of the contributed dataset and software, we have incorporated these resources into the OpenEA benchmark3 (Sun et al., 2020c).",
      "startOffset" : 126,
      "endOffset" : 145
    }, {
      "referenceID" : 31,
      "context" : "Following a relevant evaluation setting for entity resolution in database (Mudgal et al., 2018; Ebraheem et al., 2018), we also use precision, recall and F1 as metrics.",
      "startOffset" : 74,
      "endOffset" : 118
    }, {
      "referenceID" : 12,
      "context" : "Following a relevant evaluation setting for entity resolution in database (Mudgal et al., 2018; Ebraheem et al., 2018), we also use precision, recall and F1 as metrics.",
      "startOffset" : 74,
      "endOffset" : 118
    }, {
      "referenceID" : 16,
      "context" : "We initialize KG embeddings and model parameters using the Xavier initializer (Glorot and Bengio, 2010), and use Adam (Kingma and Ba, 2015) to optimize the learning objectives with the learning rate 0.",
      "startOffset" : 78,
      "endOffset" : 103
    }, {
      "referenceID" : 23,
      "context" : "We initialize KG embeddings and model parameters using the Xavier initializer (Glorot and Bengio, 2010), and use Adam (Kingma and Ba, 2015) to optimize the learning objectives with the learning rate 0.",
      "startOffset" : 118,
      "endOffset" : 139
    }, {
      "referenceID" : 49,
      "context" : "with machine translated entity name embeddings (Wu et al., 2020a).",
      "startOffset" : 47,
      "endOffset" : 65
    }, {
      "referenceID" : 4,
      "context" : "As being pointed out by recent studies (Chen et al., 2021; Liu et al., 2021, 2020), this is necessary to prevent test data leakage.",
      "startOffset" : 39,
      "endOffset" : 82
    }, {
      "referenceID" : 24,
      "context" : "Entity similarity is measured by cross-domain similarity local scaling (Lample et al., 2018) for reduced hubness effects, as being consistent to recent studies (Sun et al.",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 4,
      "context" : ", 2018) for reduced hubness effects, as being consistent to recent studies (Sun et al., 2020b; Chen et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 113
    }, {
      "referenceID" : 42,
      "context" : "This setting only involves matchable source entities to test entity alignment, which is an ideal (but less realistic) scenario similar to prior studies (Sun et al., 2020c).",
      "startOffset" : 152,
      "endOffset" : 171
    }, {
      "referenceID" : 6,
      "context" : "tempted in MTransE (Chen et al., 2017), which jointly learns a translational embedding model and a transform-based alignment model for two KGs.",
      "startOffset" : 19,
      "endOffset" : 38
    }, {
      "referenceID" : 17,
      "context" : ", 2019), long-term dependency techniques (Guo et al., 2019) and neighborhood aggregation (or GNN-based) ones (Wang et al.",
      "startOffset" : 41,
      "endOffset" : 59
    }, {
      "referenceID" : 39,
      "context" : "ing self-learning (Sun et al., 2018; Mao et al., 2020) and co-training (Chen et al.",
      "startOffset" : 18,
      "endOffset" : 54
    }, {
      "referenceID" : 30,
      "context" : "ing self-learning (Sun et al., 2018; Mao et al., 2020) and co-training (Chen et al.",
      "startOffset" : 18,
      "endOffset" : 54
    }, {
      "referenceID" : 38,
      "context" : "(iii) Another line of research seeks to retrieve auxiliary or indirect supervision signals from profile information or side features of entities, such as entity attributes (Sun et al., 2017; Trisedya et al., 2019; Zhang et al., 2019; Pei et al., 2019), literals (Wu et al.",
      "startOffset" : 172,
      "endOffset" : 251
    }, {
      "referenceID" : 44,
      "context" : "(iii) Another line of research seeks to retrieve auxiliary or indirect supervision signals from profile information or side features of entities, such as entity attributes (Sun et al., 2017; Trisedya et al., 2019; Zhang et al., 2019; Pei et al., 2019), literals (Wu et al.",
      "startOffset" : 172,
      "endOffset" : 251
    }, {
      "referenceID" : 52,
      "context" : "(iii) Another line of research seeks to retrieve auxiliary or indirect supervision signals from profile information or side features of entities, such as entity attributes (Sun et al., 2017; Trisedya et al., 2019; Zhang et al., 2019; Pei et al., 2019), literals (Wu et al.",
      "startOffset" : 172,
      "endOffset" : 251
    }, {
      "referenceID" : 33,
      "context" : "(iii) Another line of research seeks to retrieve auxiliary or indirect supervision signals from profile information or side features of entities, such as entity attributes (Sun et al., 2017; Trisedya et al., 2019; Zhang et al., 2019; Pei et al., 2019), literals (Wu et al.",
      "startOffset" : 172,
      "endOffset" : 251
    }, {
      "referenceID" : 29,
      "context" : ", 2019), literals (Wu et al., 2019, 2020b; Liu et al., 2020), free text (Chen et al.",
      "startOffset" : 18,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : ", 2020), free text (Chen et al., 2021), pre-trained language models (Yang et al.",
      "startOffset" : 19,
      "endOffset" : 38
    }, {
      "referenceID" : 51,
      "context" : ", 2021), pre-trained language models (Yang et al., 2019; Tang et al., 2020) or visual modalities (Liu",
      "startOffset" : 37,
      "endOffset" : 75
    }, {
      "referenceID" : 43,
      "context" : ", 2021), pre-trained language models (Yang et al., 2019; Tang et al., 2020) or visual modalities (Liu",
      "startOffset" : 37,
      "endOffset" : 75
    }, {
      "referenceID" : 42,
      "context" : "Due to the large body of recent advances, we refer readers to a more comprehensive summarization in the survey (Sun et al., 2020c).",
      "startOffset" : 111,
      "endOffset" : 130
    }, {
      "referenceID" : 36,
      "context" : "Related techniques include thresholding softmax (Stefano et al., 2000), selective classification (Geifman and El-Yaniv, 2017), open-set classification with background classes (Dhamija et al.",
      "startOffset" : 48,
      "endOffset" : 70
    }, {
      "referenceID" : 15,
      "context" : ", 2000), selective classification (Geifman and El-Yaniv, 2017), open-set classification with background classes (Dhamija et al.",
      "startOffset" : 34,
      "endOffset" : 62
    }, {
      "referenceID" : 11,
      "context" : ", 2000), selective classification (Geifman and El-Yaniv, 2017), open-set classification with background classes (Dhamija et al., 2018) and out-ofdistribution detection (Liang et al.",
      "startOffset" : 112,
      "endOffset" : 134
    }, {
      "referenceID" : 27,
      "context" : ", 2018) and out-ofdistribution detection (Liang et al., 2018; Vyas et al., 2018).",
      "startOffset" : 41,
      "endOffset" : 80
    }, {
      "referenceID" : 46,
      "context" : ", 2018) and out-ofdistribution detection (Liang et al., 2018; Vyas et al., 2018).",
      "startOffset" : 41,
      "endOffset" : 80
    }, {
      "referenceID" : 34,
      "context" : "The idea of learning with abstention also has applications in NLP, such as unanswerable QA, where correct answers of some questions are not stated in the given reference text (Rajpurkar et al., 2018; Zhu et al., 2019; Hu et al., 2019).",
      "startOffset" : 175,
      "endOffset" : 234
    }, {
      "referenceID" : 53,
      "context" : "The idea of learning with abstention also has applications in NLP, such as unanswerable QA, where correct answers of some questions are not stated in the given reference text (Rajpurkar et al., 2018; Zhu et al., 2019; Hu et al., 2019).",
      "startOffset" : 175,
      "endOffset" : 234
    }, {
      "referenceID" : 19,
      "context" : "The idea of learning with abstention also has applications in NLP, such as unanswerable QA, where correct answers of some questions are not stated in the given reference text (Rajpurkar et al., 2018; Zhu et al., 2019; Hu et al., 2019).",
      "startOffset" : 175,
      "endOffset" : 234
    }, {
      "referenceID" : 18,
      "context" : "Extending our framework to support more prediction tasks with abstention, such as entity type inference (Hao et al., 2019) and relation extraction (Alt et al.",
      "startOffset" : 104,
      "endOffset" : 122
    }, {
      "referenceID" : 0,
      "context" : ", 2019) and relation extraction (Alt et al., 2020), is another direction with potentially broad impact.",
      "startOffset" : 32,
      "endOffset" : 50
    } ],
    "year" : 2021,
    "abstractText" : "This paper studies a new problem setting of entity alignment for knowledge graphs (KGs). Since KGs possess different sets of entities, there could be entities that cannot find alignment across them, leading to the problem of dangling entities. As the first attempt to this problem, we construct a new dataset and design a multi-task learning framework for both entity alignment and dangling entity detection. The framework can opt to abstain from predicting alignment for the detected dangling entities. We propose three techniques for dangling entity detection that are based on the distribution of nearest-neighbor distances, i.e., nearest neighbor classification, marginal ranking and background ranking. After detecting and removing dangling entities, an incorporated entity alignment model in our framework can provide more robust alignment for remaining entities. Comprehensive experiments and analyses demonstrate the effectiveness of our framework. We further discover that the dangling entity detection module can, in turn, improve alignment learning and the final performance. The contributed resource is publicly available to foster further research.",
    "creator" : "LaTeX with hyperref"
  }
}