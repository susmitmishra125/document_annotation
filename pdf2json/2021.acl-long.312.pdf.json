{
  "name" : "2021.acl-long.312.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Handling Extreme Class Imbalance in Technical Logbook Datasets",
    "authors" : [ "Farhad Akhbardeh", "Cecilia Ovesdotter Alm", "Marcos Zampieri", "Travis Desell" ],
    "emails" : [ "tjdvse}@rit.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4034–4045\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4034"
    }, {
      "heading" : "1 Introduction",
      "text" : "Predictive maintenance techniques are applied to engineering systems to estimate when maintenance should be performed to reduce costs and improve operational efficiency (Carvalho et al., 2019), as well as mitigate risk and increase safety. Maintenance records are an important source of information for predictive maintenance (McArthur et al., 2018). These records are often stored in the form of technical logbooks in which each entry contains fields that identify and describe a maintenance issue (Akhbardeh et al., 2020a). Being able to classify these technical events is an important step in the development of predictive maintenance systems.\nIn most technical logbooks, issues are manually\nlabeled by domain experts (e.g., mechanics) in free text fields. This text can then be used to classify or cluster events by semantic similarity. Classifying events in technical logbooks is a challenging problem for the NLP community for several reasons: (a) the technical logbooks are written by various domain experts and contain short text entries with nonstandard language including domain-specific abbreviated words (see Table 1 for examples), which makes them distinct from other short non-standard text corpora (e.g., social media); (b) off-the-shelf NLP tools struggle to perform well on this type of data as they tend to be trained on standard contemporary corpora such as newspaper texts; (c) outside of the clinical and biomedical sciences, there is a lack of domain-specific, expert-based datasets for studying expert-based event classification, and in particular few resources are available for technical problem domains; and (d) technical logbooks tend to be characterized by a large number of event classes that are highly imbalanced.\nWe address the aforementioned challenges with a special focus on exploring strategies to address class imbalance. There is wide variation in the number of instances among the technical event classes examined in this work, as shown in Figure 1 and Ta-\nble 3. This extreme class imbalance is an obstacle when processing logbooks as it causes most learning algorithms to become biased and mainly predict the large classes (Kim et al., 2019). To overcome this issue, we introduce a feedback loop strategy, which is a repurposing of a method used to address extreme class imbalance in computer vision (Bowley et al., 2019), and examine it for classification of textual technical event descriptions. This technique is applied in the training of a suite of common classification models on seven predictive maintenance datasets representing the aviation, automotive, and facility maintenance domains.\nThis paper addresses these research questions: RQ1: To which extent does the class granularity and class imbalance present in technical logbooks impact technical event classification performance, and can a feedback loop for training data selection effectively address this issue? RQ2: Which classification models are better suited to classify technical events for predictive maintenance across logbook datasets representing different technical domains? The main contributions of this work include:\n1. Experimental results showing strong performance of the feedback loop in addressing the class imbalance problem in technical event classification across all datasets and models; 2. A thorough empirical evaluation of the performance of the technical event classifier considering multiple models and seven logbook datasets from three different domains."
    }, {
      "heading" : "2 Related Work",
      "text" : "Most expert-domain datasets containing events have focused on healthcare. For instance, Altuncu et al. (2019) analyzed patient incidents in unstructured electronic health records provided by the U.K. National Health Service. They evaluated a deep artificial neural network model on the expertannotated textual dataset of a safety incident to identify similar events that occurred. Deléger et al. (2010) proposed a method to deal with unstructured clinical records, using rule-based techniques to extract names of medicines and related information such as prescribed dosage. Savova et al. (2010) considered free-text electronic medical records for information extraction purposes and developed a system to obtain clinical domain knowledge.\nPatrick and Li (2009) proposed the cascade methods of extracting the medication records such as treatment duration or reason, obtained from patient’s historical records. Their approach for event extraction includes text normalization, tokenization, and context identification. A system using multiple features outperformed a baseline method using a bag of words model. Yetisgen-Yildiz et al. (2013) proposed the lung disease phenotypes identification method to prevent the use of a handoperated identification strategy. They employed NLP pipelines including text pre-processing and further text classification on the textual reports to identify the patients with a positive diagnosis for the disease. Based on the outcome, they achieve\nnotable performance by using the n-gram features with the Maximum Entropy (MaxEnt) classifier.\nThere is also relevant research on event classification in social media. For example, Ritter et al. (2012) proposed an open-source event extraction and supervised tagger for noisy microblogs. Cherry and Guo (2015) applied word embedding-based modeling for information extraction on news-wire and tweets, comparing named entity taggers to improve their method. Hammar et al. (2018) performed experimental work on Instagram text using weakly supervised text classification to extracted clothing brand based on user descriptions in posts.\nThe problem of class imbalance has been studied in recent years for numerous natural language processing tasks. Tayyar Madabushi et al. (2019) studied automatic propaganda event detection from a news dataset using a pre-trained BERT model. They recognized that the BERT model had issues in generalizing. To overcome this issue, they proposed a cost-weighting method. Al-Azani and ElAlfy (2017) analyzed polarity measurement in imbalanced tweet datasets utilizing features learned with word embeddings. Li and Nenkova (2014) studied the class imbalance problem in the task of discourse relation identification by comparing the accuracy of multiple classifiers. They showed that utilizing a unified method and further downsampling the negative instances can significantly enhance the performance of the prediction model on unbalanced binary and multi-classes.\nDealing with unbalance classes is also studied well in the sentiment classification task. Li et al. (2012) introduced an active learning method that overcomes the problem of data class unbalance by choosing the significant sample of minority class\nfor manual annotation and majority class for automatic annotation to lower the amount of human annotation required. Furthermore, Damaschk et al. (2019) examined techniques to overcome the problem of dealing with high-class imbalance in classifying a collection of song lyrics. They employed neural network models including a multi-layer perceptron and a Doc2Vec model in their experiments where the finding was that undersampling the majority class can be a reasonable approach to remove the data sparsity and further improve the classification performance.\nLi et al. (2020) also explored the problem of high data imbalance using cross-entropy criteria as well as standard performance metrics. They proposed a loss function called Dice loss that assigns equal importance to the false negatives and the false positives. In computer vision, Bowley et al. (2019) developed an automated feedback loop method to identify and classify wildlife species from Unmanned Aerial Systems imagery, for training CNNs to overcome the unbalanced class issue. On their expert imagery dataset, the error rate decreased substantially from 0.88 to 0.05. This work adapts this feedback loop strategy to the NLP problem of classifying technical events."
    }, {
      "heading" : "3 Technical Event Datasets",
      "text" : "In this work, we used a set of 7 logbook datasets from the aviation, automotive, and facility domains available at MaintNet (Akhbardeh et al., 2020a). MaintNet is a collaborative open-source platform for predictive maintenance language resources featuring multiple technical logbook datasets and tools. These datasets include: 1) Avi-Main contains seven years of maintenance logbook reports collected by\nthe University of North Dakota aviation program on aircraft maintenance that were reported by the mechanic or pilot. 2) Avi-Acc contains four years of aviation accident and reported damages. 3) AviSafe contains eleven years of aviation safety and incident reports. Accidents were caused by foreign objects/birds during the flights which led to safety inspection and maintenance, where safety crews indicated the damage (safety) level for further analysis. 4) Auto-Main is a single year report with maintenance records for cars. 5) Auto-Acc contains twelve years of car accidents and crash reports describing the related car maintenance issue and property damaged in the accident. 6) Auto-Safe contains four years of noted hazards and incidents on the roadway from the driver. 7) Faci-Main contains six years of logbook reports collected for building maintenance.\nThese technical logbooks include short, compact, and descriptive domain-specific English texts single instances usually contain between 2 and 20 tokens on average including abbreviations and domain-specific words. An example instance from Table 2, r/h fwd upper baff seal needs to be resecured, shows how the instances for a specific issue class are comprised from specific vocabulary (less ambiguity), and therefore contain a high level of granularity (level of description for an event from multiple words) (Mulkar-Mehta et al., 2011). Table 3 presents statistics for each dataset, in terms of the number of instances, average instance length, number of classes, and the minimum, average, median and maximum class size to represent how imbalanced the datasets are.\nAn instance in the logbook can be formed as a complete description of the technical event (such as\na safety or maintenance inspection) like: #2 & #4 cyl rocker cover gsk are leaking, or it might contain an incomplete description by solely referring to the damaged part/section of machinery (hyd cap chck eng light on) using few domain words. In either form of the problem description, the given annotation (label) is at the issue type-level, e.g., baffle damage. Table 2 shows multiple examples with associated instances.\nFurther characteristics of these log entries include compound words (antifreeze, engine-holder, driftangle, dashboard). Many of these words (e.g., a compound word: dashboard) essentially represent the items, or domain-specific parts used in the descriptions. Additionally, function words (e.g., prepositions) are important and removing them could alter the meaning of the entry. The logbook datasets also have both the following shared and distinct characteristics:\nShared Characteristics: Each instance contains a descriptive observation of the issue and/or the suggested action that should be taken (eng inspection panel missing screw). Each instance also refers to maintaining a single event, which means the recognized problem applies to the only single-issue type. As an example, the instance cyl #1 baff cracked at screw support & forward baff below #1 includes a combination of sequences that refers to the location and/or specific part of the machinery.\nDistinct Characteristics: In each domain, terminologies, a list of terms, and abbreviations are distinct, and an abbreviation can have different expansion depending on the domain context (Sproat et al., 2001), e.g., a/c can mean aircraft in aviation and in the automotive domain air conditioner. However, the abbreviations and acronyms of the domain words (e.g. atc - air traffic control) in these technical datasets should not be approached as a word sense disambiguation problem as they require character level expansion."
    }, {
      "heading" : "4 Methods and Models",
      "text" : ""
    }, {
      "heading" : "4.1 Handling Class Imbalance",
      "text" : "Collecting additional data to augment datasets is a common approach for tackling the problem of skewed class distributions. However, as discussed earlier, technical logbooks are proprietary and very hard to obtain. In addition, each domain captures domain-specific lexical semantics, preventing the use of techniques such as domain adaption (Ma\nAlgorithm 1 Feedback Loop Pseudocode . GetsMCS random instances from each class function SAMPLERANDOM(C,MCS)\nArray A for i← 1 to SIZE(C) do\nSHUFFLE(Ci) A ← A∪ GETFIRSTN(MCS, Ci)\nreturn A\n. GetsMCS instances from each class with the worst error function RESAMPLE(C,M,MCS)\nArray A for i← 1 to SIZE(C) do\nCALCULATEERROR(Ci) SORTBYERROR(Ci) A ← A∪ GETFIRSTN(MCS, Ci)\nreturn A\nInput: Training Data D = Instance(1, 2, . . . , N ) Input: Feedback Loop Iterations FLI Input: Epochs Per Loop Iteration FLE Input: Minimum Class SizeMCS\n. Divide training data by class Array C ← SPLITBYCLASS(D)\n. Get initial active training data A randomly Array A ← SAMPLERANDOM(C,MCS) ModelM for l← 1 to FLI do\n. Train the model for the number of epochs per iteration M← TRAIN(M, FLE , A) . Update the active training data A ← RESAMPLE(D,M,MCS)\nOutput:M\net al., 2019) to apply a large class data from one technical domain to another. For example, instances that describe an engine failure in the aviation domain are distinct from engine failure instances reported in the automotive domain. In this paper we apply five different methods for selecting training data for the models to analyze their effects on classification performance: (1) under(down)and (2) over-sampling, (3) random down-sampling, (4) a feedback loop strategy, and (5) a baseline strategy which simply uses all available data.\nRe-sampling Under- and over-sampling are resampling techniques (Maragoudakis et al., 2006) that were used to create balanced class sizes for model training. For over-sampling, instances of the minority classes are randomly copied so that all classes would have the same number of instances as the largest class. For under-sampling, observations are randomly removed from the majority classes, so that all classes have the same number of instances as the smallest class. For both approaches, we first divided our datasets into test and\ntraining sets before performing over-sampling to prevent contamination of the test set by having the same observations in both the training and test data.\nFeedback Loop To address class imbalances in text classification, this work adapts the approach in Bowley et al. (2019) from the computer vision domain. The goal of this approach is not only to alleviate the bias towards majority classes but also to adjust the training data instances such that the models are always being trained on the instances that was performing the worst on. It should be noted that this approach is very similar to adaptive learning strategies which have been shown to aid in human learning (Kerr, 2015; Midgley, 2014).\nAlgorithm 1 presents pseudocode for the feedback loop. In this process, the active training data (the data used to actually train the models in each iteration of the loop) is continually resampled from the training data. The model is first initially trained with an undersampled number of random instances from each class, which becomes the initial active training data. The model M then performs inference over the entire training set, and then selects MCS instances from each class Ci which had the worst error during inference, where MCS is the minority (smallest) class size. The model is then retrained with this new active training data and the process of training, inference and selection of the MCS worst instances repeats for a fixed number of feedback loop iterations, FLI. In this way the model is always being trained on the instances it has classified the worst.\nTo measure the effect of resampling the worst performing instances, the feedback loop approach was also compared to a random downsampling (DS) loop, where instead of evaluating the model over each instance and selecting the worst performing instances, MCS instances from each class are instead randomly sampled. As performing inference over the entire training set adds overhead, a comparison to the random DS loop method would show if performing this inference is worth the performance cost over simple random resampling. This approach is the same as Algorithm 1 except that SampleRandom is used instead of Resample in the feedback loop. Section 4.3 describes how the number of training epochs and loop iterations were determined such that all the training data selection methods are given a fair evaluation with the same amount of computational time.\nEvaluation Metrics For imbalanced datasets, simply using precision, recall or F1 score metrics for the entire datasets would not accurately reflect how well a model or method performs, as they emphasize the majority classes. To overcome this, alternative evaluation metrics to handle the class imbalance problem were used, as recommended by Banerjee et al. (2019). Specifically, we report the models performance based on precision, recall, and F1 score by utilizing a macro-average over all classes, as this gives every class equal weight, and hence reveals how well the models and training data selection strategies perform."
    }, {
      "heading" : "4.2 Model Architecture and Training",
      "text" : "Different machine learning methods were considered for technical event/issue classification (e.g. engine failure, turbine failure). Each instance is an individual short logbook entry and contains approximately 2 to 20 tokens (12 words on average per instance including function words), as shown in Table 3.The methods used in this study were a Deep Neural Network (DNN) (Dernoncourt et al., 2017), a Long Short-Term Memory (LSTM) (Suzgun et al., 2019), recurrent neural network (RNN) (Pascanu et al., 2013), a Convolutional Neural Network (CNN) (Lin et al., 2018), and BERT (Devlin et al., 2019).\nDeep Neural Network A deep artificial neural network (DNN), as described by Dernoncourt et al. (2017), can learn abstract representation and features of the input instances that would help to achieve better performance on predicting the issue type in the logbook dataset. The DNN used was a 3 layer, fully connected feed forward neural network with an input embedding layer of dimension 300 and equal size number of words followed by 2 dense layers with 512 hidden units with ReLU activation functions followed by a dropout layer. Finally, we added a fully connected dense layer with size equal to the number of classes, with a SoftMax activation function.\nLong Short-Term Memory An LSTM RNN was also used to perform a sequence-to-label classification. As described by Suzgun et al. (2019) LSTM RNNs utilize several vector gates at each state to regulate the passing of data by the sequence which enhances the modeling of the long-term dependencies. We used a 3 layer LSTM model with a word embedding layer of dimension 300 and the equal size number of words followed by an LSTM\nlayer with setting the number of hidden units equal to the embedding dimension, followed by a dropout layer. Finally, we added a fully connected layer with size equal to the number of classes, with a SoftMax activation function.\nConvolutional Neural Network Convolutional neural networks (CNNs) have demonstrated exceptional success in NLP tasks such as document classification, language modeling, or machine translation (Lin et al., 2018). As Xu et al. (2020) described, CNN models can produce consistent performance when applied to the various text types such as short sequences. We evaluated a CNN architecture (Shen et al., 2018) with a convolutional layer, followed by batch normalization, ReLU, and a dropout layer, which was followed by a maxpooling layer. The model contained 300 convolutional filters with the size of 1 by n-gram length pooling with the size of 1 by the length of the input sequence, followed by concatenation layer, then finally connected to a fully connected dense layer, and an output layer equal to the size of the dataset class using a SoftMax activation function.\nBidirectional Encoder Representations We also evaluated using the pre-trained uncased Bidirectional Encoder Representations (BERT) for English (Devlin et al., 2019). We fine-tuned the model, and used a word piece based BERT tokenizer for the tokenization process and the RandomSampler and SequentialSampler for training and testing respectively. To better optimize this model, a schedule was created for the learning rate that decayed linearly from the initial learning rate we set in the optimizer to 0."
    }, {
      "heading" : "4.3 Experimental Settings",
      "text" : "Datasets and Baselines First, the technical text pre-processing pipeline developed by Akhbardeh et al. (2020b) was applied, which comprises domain-specific noise entity removal, dictionarybased standardization, lexical normalization, part of speech tagging, and domain-specific lemmatization. We divided the datasets selecting randomly from each class independently to maintain a similar class size distribution, using 80% of the instances for training and 20% of the instances for testing data. For feature extraction, two methods were considered: a bag-of-word model (n-grams:1) (Pedregosa et al., 2011) and pre-trained 300 dimensional GloVe word embeddings (Pennington et al., 2014).\nHyperparameter and Tuning The coarse to fine learning (CFL) approach (Lee et al., 2018) was used to set parameters and hyperparameters for the DNN, LSTM, and CNN models. Experiments considered batch sizes of 32, 64, and 128, an initial learning rate ranging from 0.01 to 0.001 with a learning decay rate of 0.9, and dropout regularization in the range from 0.2 to 0.5 in all models, as well as ReLU and SoftMax activation functions (Nair and Hinton, 2010), categorical cross-entropy (Zhang and Sabuncu, 2018) as the loss function, and the Adam optimizer (Kingma and Ba, 2015) in the DNN, LSTM, CNN and BERT models. Based on experiments and network training accuracy, a batch size of 64 and drop out regularization of 0.3 was selected for model training.\nEach model with each training data selection strategy was trained 20 times to generate results for each dataset. To ensure each training data selection strategy was fairly compared with a similar computational budget, the number of training epochs and loop iterations (if the strategy had a feedback or random downsampling loop) were adjusted so that the total number of training instances evaluations each model performed was the same. For each dataset, the number of forward and backward passes, ‘T’ for 100 epochs of the baseline strategy was used as the standard. As an example, Table 4 shows how many loop iterations, epochs per loop, and inference passes were done for each training data selection strategy on the Auto-Safe dataset. Given the differences between the min and max class sizes it was not possible to get exact matches but the strategies came as close as possible. We counted each inference pass for the feedback loop the same as a forward and backward training pass, which actually was a slight computational disadvantage for the feedback loop, as a forward and backward pass in training takes approximately 1x to 2x the time as an inference pass."
    }, {
      "heading" : "5 Results",
      "text" : "Table 5 shows a comparison between the baseline and the four different class balancing methods (over-sampling, under-sampling, the random downsampling (DS) loop and the feedback loop). Based on these outcomes, the feedback loop strategy almost entirely outperforms the other methods over all datasets and models, showing that performing inference over the training set and reselecting the training data from the worst performing instances\ndoes provide a benefit to the learning process. A plausible explanation is that this strategy does not introduce bias into the larger class and also does not effect the minority class size distribution. It also does not waste training time on instances the model has already well learned.\nTable 5 also shows the empirical analysis of the four classification models, with the model and training data selection strategy providing the overall best results shown in bold and italics. Using technical text pre-processing techniques described in Section 4.3, and the feedback loop strategy described in Section 4.1, the precision, recall, and F1 score improved compared to the baseline performance. The CNN model outperformed the other algorithms with improved precision, recall, and F1 score for almost all datasets except for Avi-Main, where BERT had the similar results, and Auto-Main where CNN and BERT tied. This is interesting, given the current popularity of the BERT model, however it may be due to the substantial lexical, topical, and structural linguistic differences between the technical logbook data and the English corpus that BERT was pre-trained on.\nFurthermore, we conducted the Mann-Whitney U-test of statistical significance by using the F1 scores of each of the 20 repeated experiments of the classification models, using the baseline and the feedback loop approach as the two different populations. The outcomes are shown in Table 6, with the differences being highly statistically significant."
    }, {
      "heading" : "6 Discussion",
      "text" : "To investigate the optimal strategies for dealing with these imbalanced technical datasets, we studied various methods on how to process the data, extract features, and classify the type of event. Re-\ngarding the discussion provided in Section 3 about the nature of such a dataset, there are key challenges that effect the performance of employed algorithms. As discussed in Section 1, the extreme class imbalance observed in these technical datasets substantially affects learning algorithms’ performance. To overcome this issue, we first explored oversampling and undersampling, which both result in balanced class sizes. Undersampling removed portions of dataset that could be important for certain technical events or issues, which resulted in underfitting and weak generalization for important classes. On the other hand, oversampling may introduce overfitting in the minority class, as some of the event types are very short tokens containing domain-specific words. Following this, to minimize the possibility of overfitting and underfitting, a random downsampling loop and a feedback loop were investigated to minimize bias in the training process. It was found that the added computational cost of the feedback loop inference was worth the reduction in training time it caused over the random downsampling loop.\nThe scarce data available in a dataset such as Auto-Main is certainly an issue for deep learning methods. Examining the accuracy improvement by using the proposed feedback loop strategy, requires incorporating more instances to the event classes.\nSimilar to any supervised learning models, we noticed some limitations that could be addressed in future work. As shown in the previous sections (such as Table 2), logbook instances contain short text (ranging from 2 to 20 tokens per instance), and utilizing recurrent deep learning algorithms such as LSTM RNNs which are heavily based on the context leads to weak performance compared to other algorithms. One possible explanation is that logbooks with short instances (sequences) are not providing sufficient context for the algorithm to make better predictions. Another could be that RNNs are notoriously difficult to train (Pascanu et al., 2013), and the LSTM models may simply require more training time to achieve similar results. There is some evidence for this, as the dataset with the most instances, which also had the second largest number of tokens per instance on average was FaciMain, which is the dataset which the LSTM model had the closest performance to the CNN and BERT models, and was also the only one which the LSTM model outperformed the DNN model.\nThe pre-trained BERT model provided a reasonable classification performance compared to the other deep learning models, however as BERT is pre-trained on standard language, the performance when applying to logbook data was not optimal. Training or fine-tunning BERT to technical logbook data is likely to improve performance as observed in the legal and scientific domains (Chalkidis et al., 2020; Beltagy et al., 2019). As training or finetuning BERT requires large amounts of data, a limitation for fine-tuning a domain-specific BERT is the amount of logbook data available."
    }, {
      "heading" : "7 Conclusion and Future Work",
      "text" : "This work focused on predictive maintenance and technical event/issue classification, with a special focus on addressing class imbalance. We acquired seven logbook datasets from three technical domains containing short instances with non-standard grammar and spelling, and many abbreviations. To address RQ1, we evaluated multiple strategies to address the extreme class imbalance in these datasets and we showed that the feedback loop strategy performs best, almost entirely providing the best results for the 7 different datasets and 4 different models investigated. To address RQ2, we empirically compared different classification algorithms (DNN, LSTM, CNN, and pre-tuned BERT). Results show that the CNN model outperforms the\nother classifiers. The methodology presented in this paper could be applied to other maintenance corpora from a variety of technical domains. The feedback loop approach for selecting training data is generic and could easily be applied to any learning problem with substantial class imbalances. This is useful as extreme class imbalance is a challenge at the heart of a number of natural language tasks.\nIn future work, we would like to fine-tune BERT using logbook data, as described in Section 6, and extend this work to datasets in other languages. The biggest challenge for these two research directions is the limited availability of logbook datasets. Furthermore, we are exploring various methods of domain adaptation and transfer learning on these datasets to further improve the performance of classification models."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We would like to thanks the University of North Dakota aviation program for providing the valuable aviation maintenance logbook datasets to the MaintNet research. We further thank the aviation domain expert Zechariah Morgan for evaluating the outcomes of the various algorithms and providing valuable feedback for the aviation domain dataset. We also would like to thank the anonymous ACL reviewers for providing us with helpful comments and feedback."
    } ],
    "references" : [ {
      "title" : "MaintNet: A collaborative opensource library for predictive maintenance language resources",
      "author" : [ "Farhad Akhbardeh", "Travis Desell", "Marcos Zampieri." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 7–",
      "citeRegEx" : "Akhbardeh et al\\.,? 2020a",
      "shortCiteRegEx" : "Akhbardeh et al\\.",
      "year" : 2020
    }, {
      "title" : "NLP tools for predictive maintenance records in MaintNet",
      "author" : [ "Farhad Akhbardeh", "Travis Desell", "Marcos Zampieri." ],
      "venue" : "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th In-",
      "citeRegEx" : "Akhbardeh et al\\.,? 2020b",
      "shortCiteRegEx" : "Akhbardeh et al\\.",
      "year" : 2020
    }, {
      "title" : "Using word embedding and ensemble learning for highly imbalanced data sentiment analysis in short arabic text",
      "author" : [ "Sadam Al-Azani", "El-Sayed El-Alfy." ],
      "venue" : "Procedia Computer Science, Vol 109:359–366.",
      "citeRegEx" : "Al.Azani and El.Alfy.,? 2017",
      "shortCiteRegEx" : "Al.Azani and El.Alfy.",
      "year" : 2017
    }, {
      "title" : "From free text to clusters of content in health records: an unsupervised graph partitioning approach",
      "author" : [ "M. Altuncu", "Erik Mayer", "Sophia Yaliraki", "Mauricio Barahona." ],
      "venue" : "Applied Network Science, Vol 4.",
      "citeRegEx" : "Altuncu et al\\.,? 2019",
      "shortCiteRegEx" : "Altuncu et al\\.",
      "year" : 2019
    }, {
      "title" : "Hierarchical transfer learning for multi-label text classification",
      "author" : [ "Siddhartha Banerjee", "Cem Akkaya", "Francisco PerezSorrosal", "Kostas Tsioutsiouliklis." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Banerjee et al\\.,? 2019",
      "shortCiteRegEx" : "Banerjee et al\\.",
      "year" : 2019
    }, {
      "title" : "SciBERT: A pretrained language model for scientific text",
      "author" : [ "Iz Beltagy", "Kyle Lo", "Arman Cohan." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan-",
      "citeRegEx" : "Beltagy et al\\.,? 2019",
      "shortCiteRegEx" : "Beltagy et al\\.",
      "year" : 2019
    }, {
      "title" : "An analysis of altitude, citizen science and a convolutional neural network feedback loop on object detection in unmanned aerial systems",
      "author" : [ "Connor Bowley", "Marshall Mattingly", "Andrew Barnas", "Susan Ellis-Felege", "Travis Desell." ],
      "venue" : "Journal of Compu-",
      "citeRegEx" : "Bowley et al\\.,? 2019",
      "shortCiteRegEx" : "Bowley et al\\.",
      "year" : 2019
    }, {
      "title" : "A systematic literature review of machine learning methods applied to predictive maintenance",
      "author" : [ "Thyago P. Carvalho", "Fabrı́zzio A.A.M.N. Soares", "Roberto Vita", "Roberto da P. Francisco", "João P. Basto", "Symone G.S. Alcalá" ],
      "venue" : "Computers and Industrial",
      "citeRegEx" : "Carvalho et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Carvalho et al\\.",
      "year" : 2019
    }, {
      "title" : "LEGAL-BERT: The muppets straight out of law school",
      "author" : [ "Ilias Chalkidis", "Manos Fergadiotis", "Prodromos Malakasiotis", "Nikolaos Aletras", "Ion Androutsopoulos." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 2898–",
      "citeRegEx" : "Chalkidis et al\\.,? 2020",
      "shortCiteRegEx" : "Chalkidis et al\\.",
      "year" : 2020
    }, {
      "title" : "The unreasonable effectiveness of word representations for Twitter named entity recognition",
      "author" : [ "Colin Cherry", "Hongyu Guo." ],
      "venue" : "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics:",
      "citeRegEx" : "Cherry and Guo.,? 2015",
      "shortCiteRegEx" : "Cherry and Guo.",
      "year" : 2015
    }, {
      "title" : "Multiclass text classification on unbalanced, sparse and noisy data",
      "author" : [ "Matthias Damaschk", "Tillmann Dönicke", "Florian Lux." ],
      "venue" : "Proceedings of the First NLPL Workshop on Deep Learning for Natural Language Processing, pages 58–65, Turku, Finland.",
      "citeRegEx" : "Damaschk et al\\.,? 2019",
      "shortCiteRegEx" : "Damaschk et al\\.",
      "year" : 2019
    }, {
      "title" : "Extracting medical information from narrative patient records: The case of medicationrelated information",
      "author" : [ "Louise Deléger", "Cyril Grouin", "Pierre Zweigenbaum." ],
      "venue" : "Journal of the American Medical Informatics Association, Vol 17:555 – 558.",
      "citeRegEx" : "Deléger et al\\.,? 2010",
      "shortCiteRegEx" : "Deléger et al\\.",
      "year" : 2010
    }, {
      "title" : "Neural networks for joint sentence classification in medical paper abstracts",
      "author" : [ "Franck Dernoncourt", "Ji Young Lee", "Peter Szolovits." ],
      "venue" : "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume",
      "citeRegEx" : "Dernoncourt et al\\.,? 2017",
      "shortCiteRegEx" : "Dernoncourt et al\\.",
      "year" : 2017
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Deep text mining of instagram data without strong supervision",
      "author" : [ "Kim Hammar", "Shatha Jaradat", "Nima Dokoohaki", "Mihhail Matskin." ],
      "venue" : "International Conference on Web Intelligence (WI), pages 158 – 165, Santiago, Chile.",
      "citeRegEx" : "Hammar et al\\.,? 2018",
      "shortCiteRegEx" : "Hammar et al\\.",
      "year" : 2018
    }, {
      "title" : "Adaptive learning",
      "author" : [ "Philip Kerr." ],
      "venue" : "English Language Teaching (ELT) Journal, 70(1):88–93.",
      "citeRegEx" : "Kerr.,? 2015",
      "shortCiteRegEx" : "Kerr.",
      "year" : 2015
    }, {
      "title" : "Multi-co-training for document classification using various document representations: TF-IDF, LDA, and Doc2Vec",
      "author" : [ "Donghwa Kim", "Deokseong Seo", "Suhyoun Cho", "Pilsung Kang." ],
      "venue" : "Information Sciences, Vol 477:15 – 29.",
      "citeRegEx" : "Kim et al\\.,? 2019",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2019
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Higher-order coreference resolution with coarse-tofine inference",
      "author" : [ "Kenton Lee", "Luheng He", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Lee et al\\.,? 2018",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2018
    }, {
      "title" : "Addressing class imbalance for improved recognition of implicit discourse relations",
      "author" : [ "Junyi Jessy Li", "Ani Nenkova." ],
      "venue" : "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 142–150,",
      "citeRegEx" : "Li and Nenkova.,? 2014",
      "shortCiteRegEx" : "Li and Nenkova.",
      "year" : 2014
    }, {
      "title" : "Active learning for imbalanced sentiment classification",
      "author" : [ "Shoushan Li", "Shengfeng Ju", "Guodong Zhou", "Xiaojun Li." ],
      "venue" : "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Lan-",
      "citeRegEx" : "Li et al\\.,? 2012",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2012
    }, {
      "title" : "Dice loss for dataimbalanced NLP tasks",
      "author" : [ "Xiaoya Li", "Xiaofei Sun", "Yuxian Meng", "Junjun Liang", "Fei Wu", "Jiwei Li." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 465–476, Online. Associ-",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Semantic-unit-based dilated convolution for multi-label text classification",
      "author" : [ "Junyang Lin", "Qi Su", "Pengcheng Yang", "Shuming Ma", "Xu Sun." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4554–",
      "citeRegEx" : "Lin et al\\.,? 2018",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2018
    }, {
      "title" : "Domain adaptation with BERT-based domain classification and data selection",
      "author" : [ "Xiaofei Ma", "Peng Xu", "Zhiguo Wang", "Ramesh Nallapati", "Bing Xiang." ],
      "venue" : "Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP",
      "citeRegEx" : "Ma et al\\.,? 2019",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2019
    }, {
      "title" : "Association for Computational Linguistics",
      "author" : [ "Hong Kong", "China" ],
      "venue" : "(DeepLo",
      "citeRegEx" : "Kong and China.,? \\Q2019\\E",
      "shortCiteRegEx" : "Kong and China.",
      "year" : 2019
    }, {
      "title" : "Dealing with imbalanced data using Bayesian techniques",
      "author" : [ "Manolis Maragoudakis", "Katia Kermanidis", "Aristogiannis Garbis", "Nikos Fakotakis." ],
      "venue" : "Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC’06),",
      "citeRegEx" : "Maragoudakis et al\\.,? 2006",
      "shortCiteRegEx" : "Maragoudakis et al\\.",
      "year" : 2006
    }, {
      "title" : "Machine learning and bim visualization for maintenance issue classification and enhanced data collection",
      "author" : [ "J.J. McArthur", "Nima Shahbazi", "Ricky Fok", "Christopher Raghubar", "Brandon Bortoluzzi", "Aijun An." ],
      "venue" : "Advanced Engineering Informatics, 38:101 –",
      "citeRegEx" : "McArthur et al\\.,? 2018",
      "shortCiteRegEx" : "McArthur et al\\.",
      "year" : 2018
    }, {
      "title" : "Goals, goal structures, and patterns of adaptive learning",
      "author" : [ "Carol Midgley." ],
      "venue" : "Routledge.",
      "citeRegEx" : "Midgley.,? 2014",
      "shortCiteRegEx" : "Midgley.",
      "year" : 2014
    }, {
      "title" : "Granularity in natural language discourse",
      "author" : [ "Rutu Mulkar-Mehta", "Jerry Hobbs", "Eduard Hovy." ],
      "venue" : "Proceedings of the Ninth International Conference on Computational Semantics, IWCS ’11, page 360–364, USA. Association for Computational Lin-",
      "citeRegEx" : "Mulkar.Mehta et al\\.,? 2011",
      "shortCiteRegEx" : "Mulkar.Mehta et al\\.",
      "year" : 2011
    }, {
      "title" : "Rectified linear units improve restricted Boltzmann Machines",
      "author" : [ "Vinod Nair", "Geoffrey E. Hinton." ],
      "venue" : "Proceedings of the 27 th International Conference on Machine Learning, Haifa, Israel. ICML.",
      "citeRegEx" : "Nair and Hinton.,? 2010",
      "shortCiteRegEx" : "Nair and Hinton.",
      "year" : 2010
    }, {
      "title" : "On the difficulty of training recurrent neural networks",
      "author" : [ "Razvan Pascanu", "Tomas Mikolov", "Yoshua Bengio." ],
      "venue" : "International conference on machine learning, pages 1310–1318. PMLR.",
      "citeRegEx" : "Pascanu et al\\.,? 2013",
      "shortCiteRegEx" : "Pascanu et al\\.",
      "year" : 2013
    }, {
      "title" : "A cascade approach to extracting medication events",
      "author" : [ "Jon Patrick", "Min Li." ],
      "venue" : "Proceedings of the Australasian Language Technology Association Workshop 2009, pages 99–103, Sydney, Australia.",
      "citeRegEx" : "Patrick and Li.,? 2009",
      "shortCiteRegEx" : "Patrick and Li.",
      "year" : 2009
    }, {
      "title" : "Scikit-learn: Machine learning",
      "author" : [ "F. Pedregosa", "G. Varoquaux", "A. Gramfort", "V. Michel", "B. Thirion", "O. Grisel", "M. Blondel", "P. Prettenhofer", "R. Weiss", "V. Dubourg", "J. Vanderplas", "A. Passos", "D. Cournapeau", "M. Brucher", "M. Perrot", "E. Duchesnay" ],
      "venue" : null,
      "citeRegEx" : "Pedregosa et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Pedregosa et al\\.",
      "year" : 2011
    }, {
      "title" : "GloVe: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher Manning." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, Doha,",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Open domain event extraction from twitter",
      "author" : [ "Alan Ritter", "Mausam Mausam", "Oren Etzioni", "Sam Clark." ],
      "venue" : "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1104-1112:1104 – 1112.",
      "citeRegEx" : "Ritter et al\\.,? 2012",
      "shortCiteRegEx" : "Ritter et al\\.",
      "year" : 2012
    }, {
      "title" : "Mayo clinical text analysis and knowledge extraction system (ctakes): architecture, component evaluation",
      "author" : [ "Guergana K. Savova", "James J. Masanz", "Philip V. Ogren", "Jiaping Zheng", "Sunghwan Sohn", "Karin Kipper Schuler", "Christopher G. Chute" ],
      "venue" : null,
      "citeRegEx" : "Savova et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Savova et al\\.",
      "year" : 2010
    }, {
      "title" : "Learning context-sensitive convolutional filters for text processing",
      "author" : [ "Dinghan Shen", "Martin Renqiang Min", "Yitong Li", "Lawrence Carin." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1839–1848,",
      "citeRegEx" : "Shen et al\\.,? 2018",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2018
    }, {
      "title" : "Normalization of non-standard words",
      "author" : [ "Richard Sproat", "Alan W. Black", "Stanley Chen", "Shankar Kumar", "Mari Ostendorf", "Christopher Richards." ],
      "venue" : "Computer Speech & Language, 15(3):287 – 333.",
      "citeRegEx" : "Sproat et al\\.,? 2001",
      "shortCiteRegEx" : "Sproat et al\\.",
      "year" : 2001
    }, {
      "title" : "On evaluating the generalization of LSTM models in formal languages",
      "author" : [ "Mirac Suzgun", "Yonatan Belinkov", "Stuart M. Shieber." ],
      "venue" : "Proceedings of the Society for Computation in Linguistics (SCiL) 2019, pages 277–286.",
      "citeRegEx" : "Suzgun et al\\.,? 2019",
      "shortCiteRegEx" : "Suzgun et al\\.",
      "year" : 2019
    }, {
      "title" : "Cost-sensitive BERT for generalisable sentence classification on imbalanced",
      "author" : [ "Harish Tayyar Madabushi", "Elena Kochkina", "Michael Castelle" ],
      "venue" : null,
      "citeRegEx" : "Madabushi et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Madabushi et al\\.",
      "year" : 2019
    }, {
      "title" : "Incorporating context-relevant concepts into convolutional neural networks for short text classification",
      "author" : [ "Jingyun Xu", "Yi Cai", "Xin Wu", "Xue Lei", "Qingbao Huang", "Ho fung Leung", "Qing Li." ],
      "venue" : "Neurocomputing, 386:42 – 53.",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Identification of patients with acute lung injury from free-text chest X-ray reports",
      "author" : [ "Meliha Yetisgen-Yildiz", "Cosmin Bejan", "Mark Wurfel." ],
      "venue" : "Proceedings of the 2013 Workshop on Biomedical Natural Language Processing, pages 10–17, Sofia, Bul-",
      "citeRegEx" : "Yetisgen.Yildiz et al\\.,? 2013",
      "shortCiteRegEx" : "Yetisgen.Yildiz et al\\.",
      "year" : 2013
    }, {
      "title" : "Generalized cross entropy loss for training deep neural networks with noisy labels",
      "author" : [ "Zhilu Zhang", "Mert R. Sabuncu." ],
      "venue" : "Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS’18, page 8792–8802, Red Hook,",
      "citeRegEx" : "Zhang and Sabuncu.,? 2018",
      "shortCiteRegEx" : "Zhang and Sabuncu.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "Predictive maintenance techniques are applied to engineering systems to estimate when maintenance should be performed to reduce costs and improve operational efficiency (Carvalho et al., 2019), as well as mitigate risk and increase safety.",
      "startOffset" : 169,
      "endOffset" : 192
    }, {
      "referenceID" : 26,
      "context" : "Maintenance records are an important source of information for predictive maintenance (McArthur et al., 2018).",
      "startOffset" : 86,
      "endOffset" : 109
    }, {
      "referenceID" : 0,
      "context" : "These records are often stored in the form of technical logbooks in which each entry contains fields that identify and describe a maintenance issue (Akhbardeh et al., 2020a).",
      "startOffset" : 148,
      "endOffset" : 173
    }, {
      "referenceID" : 16,
      "context" : "when processing logbooks as it causes most learning algorithms to become biased and mainly predict the large classes (Kim et al., 2019).",
      "startOffset" : 117,
      "endOffset" : 135
    }, {
      "referenceID" : 6,
      "context" : "extreme class imbalance in computer vision (Bowley et al., 2019), and examine it for classification of textual technical event descriptions.",
      "startOffset" : 43,
      "endOffset" : 64
    }, {
      "referenceID" : 0,
      "context" : "In this work, we used a set of 7 logbook datasets from the aviation, automotive, and facility domains available at MaintNet (Akhbardeh et al., 2020a).",
      "startOffset" : 124,
      "endOffset" : 149
    }, {
      "referenceID" : 28,
      "context" : "An example instance from Table 2, r/h fwd upper baff seal needs to be resecured, shows how the instances for a specific issue class are comprised from specific vocabulary (less ambiguity), and therefore contain a high level of granularity (level of description for an event from multiple words) (Mulkar-Mehta et al., 2011).",
      "startOffset" : 295,
      "endOffset" : 322
    }, {
      "referenceID" : 37,
      "context" : "pansion depending on the domain context (Sproat et al., 2001), e.",
      "startOffset" : 40,
      "endOffset" : 61
    }, {
      "referenceID" : 25,
      "context" : "Re-sampling Under- and over-sampling are resampling techniques (Maragoudakis et al., 2006) that were used to create balanced class sizes for model training.",
      "startOffset" : 63,
      "endOffset" : 90
    }, {
      "referenceID" : 15,
      "context" : "It should be noted that this approach is very similar to adaptive learning strategies which have been shown to aid in human learning (Kerr, 2015; Midgley, 2014).",
      "startOffset" : 133,
      "endOffset" : 160
    }, {
      "referenceID" : 27,
      "context" : "It should be noted that this approach is very similar to adaptive learning strategies which have been shown to aid in human learning (Kerr, 2015; Midgley, 2014).",
      "startOffset" : 133,
      "endOffset" : 160
    }, {
      "referenceID" : 12,
      "context" : "The methods used in this study were a Deep Neural Network (DNN) (Dernoncourt et al., 2017), a Long Short-Term Memory (LSTM) (Suz-",
      "startOffset" : 64,
      "endOffset" : 90
    }, {
      "referenceID" : 30,
      "context" : ", 2019), recurrent neural network (RNN) (Pascanu et al., 2013), a Convolutional Neural Network (CNN) (Lin et al.",
      "startOffset" : 40,
      "endOffset" : 62
    }, {
      "referenceID" : 22,
      "context" : ", 2013), a Convolutional Neural Network (CNN) (Lin et al., 2018), and BERT (Devlin et al.",
      "startOffset" : 46,
      "endOffset" : 64
    }, {
      "referenceID" : 22,
      "context" : "Convolutional Neural Network Convolutional neural networks (CNNs) have demonstrated exceptional success in NLP tasks such as document classification, language modeling, or machine translation (Lin et al., 2018).",
      "startOffset" : 192,
      "endOffset" : 210
    }, {
      "referenceID" : 36,
      "context" : "We evaluated a CNN architecture (Shen et al., 2018) with a convolutional layer, followed by batch normalization, ReLU, and a dropout layer, which was followed by a max-",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 32,
      "context" : "For feature extraction, two methods were considered: a bag-of-word model (n-grams:1) (Pedregosa et al., 2011) and pre-trained 300 dimensional GloVe word embeddings (Pennington et al.",
      "startOffset" : 85,
      "endOffset" : 109
    }, {
      "referenceID" : 33,
      "context" : ", 2011) and pre-trained 300 dimensional GloVe word embeddings (Pennington et al., 2014).",
      "startOffset" : 62,
      "endOffset" : 87
    }, {
      "referenceID" : 18,
      "context" : "4040 Hyperparameter and Tuning The coarse to fine learning (CFL) approach (Lee et al., 2018) was used to set parameters and hyperparameters for the DNN, LSTM, and CNN models.",
      "startOffset" : 74,
      "endOffset" : 92
    }, {
      "referenceID" : 29,
      "context" : "5 in all models, as well as ReLU and SoftMax activation functions (Nair and Hinton, 2010), categorical cross-entropy (Zhang and Sabuncu, 2018) as the loss function, and the Adam optimizer (Kingma and Ba, 2015) in the DNN, LSTM, CNN and BERT models.",
      "startOffset" : 66,
      "endOffset" : 89
    }, {
      "referenceID" : 42,
      "context" : "5 in all models, as well as ReLU and SoftMax activation functions (Nair and Hinton, 2010), categorical cross-entropy (Zhang and Sabuncu, 2018) as the loss function, and the Adam optimizer (Kingma and Ba, 2015) in the DNN, LSTM, CNN and BERT models.",
      "startOffset" : 117,
      "endOffset" : 142
    }, {
      "referenceID" : 17,
      "context" : "5 in all models, as well as ReLU and SoftMax activation functions (Nair and Hinton, 2010), categorical cross-entropy (Zhang and Sabuncu, 2018) as the loss function, and the Adam optimizer (Kingma and Ba, 2015) in the DNN, LSTM, CNN and BERT models.",
      "startOffset" : 188,
      "endOffset" : 209
    }, {
      "referenceID" : 30,
      "context" : "Another could be that RNNs are notoriously difficult to train (Pascanu et al., 2013), and the LSTM models may simply require more training time to achieve similar results.",
      "startOffset" : 62,
      "endOffset" : 84
    }, {
      "referenceID" : 8,
      "context" : "data is likely to improve performance as observed in the legal and scientific domains (Chalkidis et al., 2020; Beltagy et al., 2019).",
      "startOffset" : 86,
      "endOffset" : 132
    }, {
      "referenceID" : 5,
      "context" : "data is likely to improve performance as observed in the legal and scientific domains (Chalkidis et al., 2020; Beltagy et al., 2019).",
      "startOffset" : 86,
      "endOffset" : 132
    } ],
    "year" : 2021,
    "abstractText" : "Technical logbooks are a challenging and under-explored text type in automated event identification. These texts are typically short and written in non-standard yet technical language, posing challenges to off-the-shelf NLP pipelines. The granularity of issue types described in these datasets additionally leads to class imbalance, making it challenging for models to accurately predict which issue each logbook entry describes. In this paper we focus on the problem of technical issue classification by considering logbook datasets from the automotive, aviation, and facilities maintenance domains. We adapt a feedback strategy from computer vision for handling extreme class imbalance, which resamples the training data based on its error in the prediction process. Our experiments show that with statistical significance this feedback strategy provides the best results for four different neural network models trained across a suite of seven different technical logbook datasets from distinct technical domains. The feedback strategy is also generic and could be applied to any learning problem with substantial class imbalances.",
    "creator" : "LaTeX with hyperref"
  }
}