{
  "name" : "2021.acl-long.341.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "RADDLE: An Evaluation Benchmark and Analysis Platform for Robust Task-oriented Dialog Systems",
    "authors" : [ "Baolin Peng", "Chunyuan Li", "Zhu Zhang", "Chenguang Zhu", "Jinchao Li", "Jianfeng Gao" ],
    "emails" : [ "bapeng@microsoft.com", "chunyl@microsoft.com", "chezhu@microsoft.com", "jincli@microsoft.com", "jfgao@microsoft.com", "zhuzhang@iastate.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4418–4429\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4418"
    }, {
      "heading" : "1 Introduction",
      "text" : "Dialogs constitute a crucial communication channel in completing a broad range of tasks, such as weather query, flight and restaurant booking, movie booking, IT help desk, etc. Comparing to chitchat systems that are usually modeled with singleturn context-response pairs, task-oriented dialog systems involve retrieving information from knowledge bases and reasoning over multiple dialog turns. This makes it especially important for a system to\n†Work was done when Zhu Zhang was visiting MSR 1Robust tAsk-orienteD DiaLog systems Evaluation 2Benchmark link: http://aka.ms/raddle\nbe able to produce response that are grounded on tasks goals and user intents. In a bid to support human-computer interactions, task-oriented dialog systems have been built to allow users to converse with a computer system using natural language, such as Siri, Google Assistant, Amazon Alexa, Microsoft XiaoIce (Zhou et al., 2020). Traditionally, a task-oriented dialog system uses a modularized pipeline with four modules that execute sequentially (Gao et al., 2019). A natural language understanding (NLU) module identifies user intents and extracts associated information such as slots and corresponding values from user input. A dialog state tracker (DST) infers the belief state (or user goal) from dialog history. The belief state is often used to query a task-specific database (DB) to obtain the DB state, such as the number of entities that match the user goal. The dialog state and DB state are then passed to a dialog policy (POL) module to select the next system action. A natural language generation (NLG) module converts the action to a natural language response.\nThe human ability to converse is general, flexible, and robust. In contrast, most popular tools for dialog system development adopting the above modular systems are designed for specific tasks and struggle with out-of-scope data. If we aspire to develop models beyond extensively handcrafted rules and annotated data for each single domain/task, it is critical to develop a more unified, efficient and robust model that can more quickly learn to execute a range of tasks in different domains.\nTo fuel research in this direction, we present the RADDLE benchmark. It includes a collection of task-oriented dialog tasks in diverse domains (e.g. end-to-end modeling, dialog state tracking). The benchmark also has a companion online platform for model evaluation, comparison, and robustness analysis. Importantly, RADDLE exhibits two\nunique advantages that pave the way for building more pragmatic dialog systems: (i) Limited data setting is the major focus of RADDLE, to evaluate the generalization ability of models. It aims at simulating the real-world application scenarios where only very limited amount of labelled data is available for new domains. Given this focus, RADDLE is therefore a favorable benchmark to evaluate recent models in the pre-training and finetuning paradigm, which learn to represent linguistic knowledge in a way that facilitates sample-efficient learning and effective knowledge transfer. (ii) Robustness analysis is introduced to study model performance in various challenging scenarios, where models are evaluated with anomalous user input such as language variations, speech errors, unseen entities and out-of-domain utterances. Failing to handle these inputs often produce inappropriate responses leading to frustrating user experience. These scenarios are common for deployed systems in the real world, but are largely ignored in existing dialog benchmarks. To the best of our knowledge, RADDLE presents the first work to fill this gap.\nTo better understand the challenges posed by RADDLE, we conduct experiments with simple baselines and state-of-the-art task-oriented dialog models. We find that grounded pre-trained models with a unified multi-task learning objective outperform models separately trained on each domain. Moreover, even the best performing model (SOLOIST (Peng et al., 2020a)) in our evaluation achieves a fairly low score in robustness analysis. This suggests that our baseline models can handle common inputs with strong regularities, but struggle with anomalous inputs that require deeper reasoning.\nIn summary, our key contributions are: (i) A novel dialog benchmark with an emphasis on limited data and multiple domains/tasks, which formally creates a scenario to evaluate the grounding and generalization ability of pre-trained models. (ii) A crowd-sourced diagnostic evaluation dataset to cover a broad range of real-world sophistication to study model robustness. (iii) An online evaluation platform and leaderboard to track research progress, with human evaluation services to be granted to top-ranked submissions on a bi-monthly basis. (iv) Baseline results for major existing approaches to task-oriented dialogs are reported. An adversarially robust model is proposed to improve the generalization ability in noisy environments.\nStarter codes, pre-trained models, and scripts to reproduce the results will be provided together with the benchmark."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Dialog Benchmarks",
      "text" : "To drive the progress of building dialog systems using data-driven approaches, a number of conversational corpora have been released. They are roughly grouped into two categories: (i) Corpora with structured semantic labels (Wen et al., 2017; Shah et al., 2018). These datasets are often specifically annotated, and used to study an individual module in the dialog pipeline. For example, DialoGLUE (Mehri et al., 2020) is a recently proposed benchmark with a focus on NLU and DST tasks. (ii) Corpora with an implicit user goal (Lowe et al., 2015). These datasets are often without semantic labels but can be used in end-to-end (E2E) dialog modeling (Li et al., 2016; Zhu, 2020; Wu et al., 2019; Zhu et al., 2019a; Lee et al., 2019; Zhu et al., 2020).\nMultiWOZ (Budzianowski et al., 2018) is the most related work to RADDLE. It is a large-scale multi-turn conversational corpus across several domains. It can be used to develop individual dialog modules as separate tasks for existing modularbased methods, or serves as a benchmark for E2E dialog modeling methods. RADDLE inherits the advantages of MultiWOZ in its flexibility for separate/joint task modeling and its comprehensiveness in multi-domain data coverage, but differs significantly in two aspects: an emphasis on limited data settings and an unique robustness checklist. Both are essential qualities in building task bots at scale.\nFurther, RADDLE provides an online platform for model evaluation and fair comparison based on privately-held test data, inspired by GLUE (Wang et al., 2018). To the best of our knowledge, RADDLE is the first online platform for DST and E2E tasks in the dialog community. This can reduce the inconsistency caused by different researchers/teams using varying processing/evaluation scripts to dilute where the gain comes from."
    }, {
      "heading" : "2.2 Evaluation of Pre-Trained Models",
      "text" : "Pre-trained language models (PLMs) have substantially advanced the state of the art across a variety of language understanding and generation tasks (Peters et al., 2018; Devlin et al., 2019; Yang et al., 2019; Liu et al., 2019; Radford et al., 2019;\nKeskar et al., 2019; Dong et al., 2019; Peng et al., 2020b,c; Li et al., 2020a). PLMs are often trained to predict words based on their context on massive text data, and the learned models can be fine-tuned to quickly adapt to various downstream tasks, exhibiting strong generalization capacity even with just a few in-domain training examples. Building task bots at scale requires the model to deal with the limited data problem for each domain, which can be used as a testbed to evaluate the generalization ability of PLMs. To this end, we limit the number of task-specific training examples in RADDLE to evaluate the sample-efficiency of models.\nMeanwhile, task-oriented dialogs pose a unique set of challenges for PLMs (Gao et al., 2020): a dialog is intrinsically goal-driven, multi-turn and often informal/noisy. Indeed, dialog-specific PLMs are proposed (Wu et al., 2020a; Peng et al., 2020a). However, the robustness of PLMs to linguistic perturbations often occurring in dialog settings (See Section 4 for details) is largely unexplored. Note that our notion of robustness emphasizes natural language variations, which is different from adversarial examples/training that aim to fool a trained model (Nie et al., 2019). From this perspective, RADDLE provides an unique benchmark for assessing PLMs with a robustness orientation."
    }, {
      "heading" : "3 Tasks",
      "text" : "RADDLE is centered on five English dialog scenarios in daily life, which cover a broad range of data collection schemes, task types and complexities. As our first goal of RADDLE is to spur development of generalizable dialog systems, we design the benchmark such that a good performance requires a model to leverage substantial knowledge (e.g., pretrained parameters) learned from its previous life cycle, while still maintaining some task-specific components (Coope et al., 2020; Henderson et al., 2020; Peng et al., 2020a; Wu et al., 2020b). Specifi-\ncally, we deliberately keep a small number of training examples for each scenario. This is consistent with the common practice that only limited labelled data is provided when deploying a dialog system to new domains. Table 1 shows the data statistics. Four domains in the standard-setting are sampled from MultiWOZ 2.0 (Budzianowski et al., 2018). Reminder is intentionally only utilized for unseen entity tracking. Because it is a humanmachine corpus with a relatively smaller action space meaning that the impact of policy learning on models is largely alleviated. Therefore, the performance of models on this corpus will mostly reflect its capability of unseen entity tracking. Note that the number of training examples is limited to 50, an accepted scale that users can provide. Though it is possible to train a single model for each task from scratch without outside sources of knowledge, we expect that our focus on data-scarce settings will render this approach uncompetitive.\nFurthermore, a typical task-oriented dialog system uses a modularized pipeline that has four modules and executes sequentially. Recent research has shown promising results on parameterizing the modularized pipeline using a single neural autoregressive model, and training it in an end-to-end manner (Peng et al., 2020a; Ham et al., 2020; Hosseini-Asl et al., 2020). In fact, a single autoregressive model can significantly ease the workflow of training and deploying dialog systems for new tasks, compared to existing modularized tools and methods. Therefore, we design the benchmark to allow evaluations on end-to-end dialog modeling, in addition to the modularized evaluation on dialog state tracking. To reveal the gap between the complexity of dialogs in lab environments and that in real scenarios, we construct a suite of tasks to study the robustness of models. We describe these tasks below and in Table 1.\nOn the evaluation front, we concentrate on\nsimulation-based methodologies, in order to facilitate automation. Though we only offer human evaluations (Gao et al., 2019) to top-ranked submissions at this point, we emphasize realistic scenarios in pursuit of system robustness (see Section 4).\nTask 1: Dialog State Tracking A robust NLU and DST is the first step towards building a reliable dialog system. The dialog state is a summary of the entire conversation till the current turn. In a task-oriented system, it is represented in the form of slot-value pairs, where slot indicates the category/attribute of the user goal expressed in the utterance, and value is the corresponding information. For the evaluation metric, we report joint goal accuracy, which indicates the proportion of dialog turns where all the user’s search goal constraints are correctly identified (Mrksic et al., 2017). To specially study the NLU performance, we consider intent classification, which aims to automatically extract meaning from a natural language utterance in order to understand user’s goal (Hemphill et al., 1990; Zhu et al., 2019b).\nTask 2: End-to-End Modeling The end-to-end (E2E) dialog models consider dialog history as input, and produce the natural language response. It jointly implements the dialog management (including DST and POL) and response generation (i.e., NLG) components. Following Budzianowski et al. (2018), Inform, Success, and BLEU scores are reported. The first two metrics evaluate dialog task completion: Inform measures if the system provides a correct entity (inform rate), meanwhile Success measures the exact matching of answering all the requested information (success rate), and if the answered information matches users’ goal. BLEU evaluates how fluent the generated responses are compared to human-written responses. A combined score (Combined) is also reported using Combined = (Inform + Success) × 0.5 + BLEU as an overall quality measure, as suggested in (Budzianowski et al., 2018)."
    }, {
      "heading" : "4 Robustness Diagnostic Checklist",
      "text" : "Existing benchmarks assume a world of a “perfect” user who always provides precise, concise, and semantically unambiguous utterances. These goal-oriented dialog datasets are largely collected by crowd-sourcing, where a crowd-sourced worker enacts the part of a real user by following a set of template instructions provided for the task. This\nmethod results in a dataset where most user utterances are straight-forward, stick to the goal and tend to leave out the variation/errors commonly found in real-world conversational data. To this end, we collect a suite of language variations to reveal the dialog sophistication in the real world, and measure the robustness of dialog models."
    }, {
      "heading" : "4.1 Checklist Tasks",
      "text" : "Language Variations It is well-known that humans communicate using language with fairly large variations such as different ways of expressions or personalized styles (Sacks et al., 1978), while template-based crowd-sourcing fails in covering the linguistic variations (Schegloff et al., 1977; Moore and Arar, 2019). Specifically, we consider four types of variations in RADDLE: (i) Paraphrase widely exists among different users, who may present restatements of the meaning of a text or message using other words. (ii) Verbosity describes a quality that users may express their intents using more words than needed. (iii) Simplification is a quality that users express their intents using fewer words to be concise. (iv) Typos often result from mistakes made in the typing. In Figure 1(b)-(e), we provide examples to illustrate these language variations.\nSpeech Errors It is desirable that dialog systems can leverage automatic speech recognition (ASR) techniques to serve the speech modality, as in Amazon Alexa. However, almost all dialog systems have typically assumed that the user input is written text, and hoped that the system would seamlessly integrate with speech inputs. Recently, it has been empirically shown in Gopalakrishnan et al. (2020) that dialog systems trained on written data is very sensitive to various types of synthetic and actual ASR hypotheses in the dialog history. To bring attention to this gap, RADDLE promotes speech robustness as an evaluation criterion. For example in Figure 1(f), “what’s available” can be transcribed as “once available” due to ASR deficiency, and a robust dialog system is expected to still correctly perceive user intents.\nUnseen Entities Most existing DST methods are not designed to handle slot values that are not known to the tracker. The assumption that a predefined ontology exists for the dialog and one can enumerate all possible values for each slot is often not valid in real-world scenarios. Even if such lists or dictionaries exist, they can be very large in size\nUser : I want to tour a college in the center of town. what's available? System : I have several different options available . did you want one with free entrance ? User : Entrance fee is not an issue., System : Christ's College is free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, that's it. thanks. System : thank you , goodbye .\nUser : i want to tour college in the center of town once available System : I have several different options available . did you want one with free entrance ? User : entrance phi is not an issue. System : Christ's College is free to enter. User : Can i have the postcard and address for that college?, System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : i know that's it uh thanks System : thank you , goodbye .\nUser : I want to tour a park in the Bellevue downtown . what's available? System : I have several different options available . did you want one with free entrance ? User : Entrance fee is not an issue., System : Downtown Park is a nice one and it is free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at 10201 NE 4th St, postcode 98004. Is there any other information you need? User : no, that's it. thanks. System : thank you , goodbye .\nUser : I want to tour a college in the center of town . what's available? System : I have several different options available . did you want one with free entrance ? User : today is a sunny day we should go outside for a walk. System : Sorry I do not understand. Can you paraphrase? By the way, Christ's College is a good place and free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at 10201 NE 4th St, postcode 98004. Is there any other information you need? User : no, that's it. thanks. System : thank you , goodbye .\nParaphrase Verbose\nUser : I want to take a tour in a college which lies in the center of town. Any r comme dation? System : I have several diff rent options available . id you want one with fre entrance ? Us r : I don't have a problem paying the entrance fee. System : Christ's College is free to enter. Us r : Will you please give me postcode and address of that college? System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other informati n you need? Us r : no, perfect. I appreciate that. System : thank you , goodbye .\nUser : I want to tour a college. what do you have available? I know some college in the center area is awesome. System : I have several different options available . did you want one with free entrance ? User : I do not have any preference on the fee but does paying the fee give me something extra? System : Christ's College is free to enter. User : Okay, sounds good! I would like to visit that college to enjoy this afternoon, do you have its address and postcode? System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thanks. System : thank you , goodbye .\nUser : Any college available in the center of town? System : I have several diff rent options available . id you want one with fre entrance ? User : do not care about fee System : Christ's College is free to enter. User : Give m addres an postco e. System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thanks. System : thank you , goodbye .\nUser : want to tour a college in center. whats available System : I have several different options available . did you want one with free entrance ? User : I don't have a problem paying the entrance fee. System : Christ's College is free to enter. User : Plz tell me addr and postcode of that college. System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thats all. thx System : thank you , goodbye .\n(a) Standard dialog session (b) Paraphrase Paraphrase Verbose\nUser : I want to take a tour in a college which lies in the center of town. Any recommendation? System : I have several different options available . did you want one with free entrance ? User : I don't have a problem paying the entrance fee. System : Christ's College is free to enter. User : Will you please give me postcode and address of that college? System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, perfect. I appreciate that. System : thank you , goodbye .\nUser : I want to tour a college. what do you have available? I know some college in the center area is awesome. System : I have several different options available . did you want one with free entrance ? User : I do not have any preference on the fee but does paying the fee give me something extra? ste : Christ's C lleg is free to enter. Use : Okay, s nds good! I would like to visit that college to enjoy this afternoon, do you have its address and postcode? System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thanks. System : thank you , goodbye .\nUser : Any college available in the center of town? System : I have several different options available . did you want one with free entrance ? User : do not care about fee System : Christ's College is free to enter. User : Give me address and postcode. System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thanks. System : thank you , goodbye .\nUser : want to tour a college in center. whats available System : I have several different options available . did you want one with free entrance ? User : I don't have a problem paying the entrance fee. System : Christ's College is free to enter. User : Plz tell me addr and postcode of that college. System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thats all. thx System : thank you , goodbye .\nParaphrase Verbose\nUser : I want to take a tour in a college which lies in the center of town. Any recommendation? System : I have several different options available . did you want one with free entrance ?\nI don't hav proble paying th entr nce fee. Christ' College is free o ent r.\nUser : Will you please give me postcode and address of that college? System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, perfect. I appreciate that. System : thank you , goodbye .\nUser : I want to tour a college. what do you have available? I know some college in the center area is awesome. System : I have several different options available . did you want one with free entrance ? User : I do not have any preference on the fee but does paying the fee give me something extra? System : Christ's College is free to enter. User : Okay, sounds good! I would like to visit that college to enjoy this afternoon, do you have its address and postcode? System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thanks. System : thank you , goodbye .\nUser : Any college available in the center of town? System : I have several diff rent options available . did you want one with free entrance ? ser : do not care about fee Syste : Christ's College is free to enter. Use : G ve me ad ress and postcode. System : Yes, it' located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thanks. System : thank you , goodbye .\nUser : want to tour a college in center. whats available System : I have several different options available . did you want one with free entrance ? User : I don't have a problem paying the entrance fee. System : Christ's College is free to enter. User : Plz tell me addr and postcode of that college. System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thats all. thx System : thank you , goodbye .\n(c) Verbosity (d) Simplification\nParaphrase Verbose\nUser : I want to tak tour in a c llege which lies in the center of town. Any recommendation? System : I have several different options available . did you want one with free entrance ? User : I don't have a problem paying the entrance fee. System : Christ's College is free to enter. User : Will you please give me postcode and address of that college? System : Y s, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, perfect. I appreciate that. System : thank you , goodbye .\nUser : I want to tour a college. what do you have available? I know some coll ge in the center area is awesome. System : I have several different options available . did you want one with free entrance ? User : I do not have any pre er nce on the fee but d es paying the fee give me something extra? System : Christ's College is free to enter. User : Okay, sounds good! I would like to vi it that college to enjoy this afternoon, do you have its address and postcode? System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thanks. System : thank you , goodbye .\nUser : Any college available in the center of town? System : I have several different options available . did you want one with free entrance ? User : do not care about fee System : Christ's College is free to enter. User : Give me address and postcode. System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thanks. System : thank you , goodbye .\nUser : want to tour a college in center. whats available System : I have several different options available . did you want one with free entrance ? User : I don't have a problem paying the entrance fee. System : Christ's College is free to enter. User : Plz tell me addr and postcode of that college. System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : no, thats all. thx System : thank you , goodbye . User : I want to tour a college in the center of town. what's available? System : I have several different options available . did you want one with free entrance ? User : Entrance fee is not an issue., System : Christ's College is free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information need? User : no, that's it. thanks. System : thank you , goodbye .\nUser : i want to tour college in the center of town once available System : I have several different options available . did you want one with free entrance ? User : entrance phi is not an issue. System : Christ's College is free to enter. User : Can i have the postcard and address for that college?, System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : i know that's it uh thanks System : thank you , goodbye .\nUser : I want to tour a park in the Bellevue downtown . what's available? System : I have several different options available . did you want one with free entrance ? User : Entrance fee is not an issue., System : Downtown Park is a nice one and it is free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at 10201 NE 4th St, postcode 98004. Is there any other information you need? User : no, that's it. thanks. System : thank you , goodbye .\nUser : I want to tour a college in the center of town . what's available? System : I have several different options available . did you want one with free entrance ? User : today is a sunny day we should go outside for a walk. System : Sorry I do not understand. Can you paraphrase? By the way, Christ's College is a good place and free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at 10201 NE 4th St, postcode 98004. Is there any other information you need? User : no, that's it. thanks. System : thank you , goodbye .\n(e) Typos (f) Speech errors\nUser : I want to tour a college in the center of town. what's available? System : I have several differe t options available . did you want one with free entrance ? User : Entrance fee is not an issue., System : C ri t's College is free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other informa ion you eed? User : no, that's it. thanks. System : thank you , goodbye .\nUser : i want to tour college in th center of town once available System : I have several different ptions available . did you want one with free entrance ? User : entrance phi is n t an issue. System : Christ's C lleg is free to ent r. User : Can i have the postcard and address for that college?, System : Yes, it's located at saint andrew's street, postcode cb23bu. Is there any other information you need? User : i know that's it uh thanks System : thank you , goodbye .\nUser : I want to tour a park in the Bellevue downtown . what's available? System : I have several different options available . did you want one with free entrance ? User : Entrance fee is not an issue., System : Downtown Park is a nice one and it is free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at 10201 NE 4th St, postcode 98004. Is there any other information you need? User : no, that's it. thanks. System : thank you , goodbye .\nUser : I want to to r a college in the center of town . what's available? System : I have several different options available . did you want one with free entrance ? User : today is a sunny day we should go outside for a walk. System : Sorry I do not understand. Can you paraphrase? By the way, Christ's College is a good place and free to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at 10201 NE 4th St, postcode 98004. Is there any other information you need? User : no, that's it. thanks. System : thank you , goodbye . User : I want to tour a college in the center of town. what's available?, System : I have several different options available . did you want one with free entrance ? User : today is a sunny day we should go outside for a walk. System : Sorry I do not understand. Can you paraphrase? By the way, Christ’s College is a good place and fee to enter. User : Can i have the postcode and address for that college?, System : Yes, it's located at 10201 NE 4th St, postcode 98004. Is there any other information you need? User : no, that's it. thanks. System : thank you , goodbye .\n(g) Unseen entities (h) Out-of-domain utterance\nFigure 1: Illustration of different language perturbations in the robustness diagnostic checklist. The standard dialog\nexample is shown in (a). Based on it, (b)-(e) are four types of language variations , (f) shows speech error , (e) shows unseen entities , and (h) shows out-of-domain utterance . In each case, some representative examples are highlighted in red text.\nand highly dynamic (Xu and Hu, 2018). Therefore, unseen entities are common in dialogs, i.e., entities that are not observed during training, but appear in the testing stage. In Figure 1(g), the entity Bellevue downtown is in the knowledge base but never appears in model training, a robust DST should be able to recognize it as a city/place, via generalizing from other similar entities learned during training.\nOut-of-Domain Utterances Most deployed task-oriented dialog systems are built for a closed set of target domains. Thus, they are fragile when\ndealing with out-of-domain (OOD) utterances (Lee and Shalyminov, 2019). Failure to detect OOD utterances often prevents the model from responding with an appropriate fallback action, hence leading to frustrating user experience. Therefore, it is important to endow task bots with the ability to detect OOD utterances for special handling (Larson et al., 2019). For example, in Figure 1(h), the user suggests an excursion to a task bot trained in college consulting, which is out of the bot’s scope. The bot is expected to raise a flag to label the utterance as an outlier, and guides the user to focus on the\ncurrent domain."
    }, {
      "heading" : "4.2 Collection Protocols",
      "text" : "The standard setting is sampled from MultiWOZ 2.0 (Budzianowski et al., 2018) but re-purposed in a few-shot learning setting.\nThe language variations corpus is created by workers on Amazon Mechanical Turks based on the standard corpus. To maximize the quality, we require workers in US locale and have a minimal previous approval rate of 90%. Assignments are constructed at the turn level. Given a user utterance and associated dialog history, workers are required to answer four questions, what are the paraphrase, typos, verbose, and simplified versions of the user utterance. Moreover, in each assignment, the workers are instructed to exactly mention the slot values in the answers if the given user utterance has them. We pay Turks 0.5$ per assignment and each assignment can be finished in one to two minutes.\nFor the speech recognition errors setting, we employ the audio-level error simulation (Gopalakrishnan et al., 2020), which generates audio signals from texts, adds noise into the audio, and then decodes the audio with an ASR model to obtain hypotheses. In particular, we employ Microsoft Cognition text-to-speech service to synthesize audio signals. After injecting background noise into the audio signals, we use the speech recognition service to obtain a corpus of Word Error Rate (WER) of 30%.\nFor the reminder domain that is applied for unseen entity evaluation, we firstly simulate several dialogs as seed scenarios using an agenda-based simulator and then randomly replace the slots in the dialogs with new values. Similar to constructing the language variations corpus, we then hire workers to rewrite the corpus as diverse and realistic as possible. Finally, the out-of-domain corpus is developed following Lee and Shalyminov (2019). We randomly choose 50% utterances in DSTC (Henderson et al., 2014) for the Attraction domain as the training set. For the test set, besides utterance from DSTC, we also introduce utterance from a diverse set of domains like Stanford (Eric and Manning, 2017), Reddit, Twitter (Sordoni et al., 2015) to evaluate the capability of handling different out-of-domain utterances. A board of data researchers reviews all the collected data to ensure no ethical concerns in it."
    }, {
      "heading" : "5 Methods",
      "text" : ""
    }, {
      "heading" : "5.1 Competitive Baselines",
      "text" : "For baselines, we consider three representative methods, holding state-of-the-art positions on existing benchmarks such as MultiWoZ (Budzianowski et al., 2018).\nDAMD (Zhang et al., 2020) is a state-of-theart modular system, where each dialog module is implemented using a neural network, and the whole system is trained in an end-to-end manner.\nGPT-2 represents a single multi-task learning model with impressive results on general language understanding and generation tasks. GPT-2 is an auto-regressive language model that leverages 12-24 layers of masked, multi-head self-attention Transformers. GPT-2 is pre-trained on extremely massive text data OpenWebText (Radford et al., 2019). It has demonstrated superior performance on characterizing human language data distribution and knowledge transfer. Given text prompts, GPT-2 can often generate fluent sentences. Its ancestral work GPT (with a smaller model size and less training data) has shown impressive results on language understanding tasks. In this paper, we consider GPT-2FT as the approach of directly finetuning the pre-trained GPT-2 on a specific domain. Hence, GPT-2FT can be viewed as SOLOIST without grounded pre-training, and serve as a strong baseline for both DST and E2E task.\nSOLOIST represents recent model variants (Ham et al., 2020; Hosseini-Asl et al., 2020) to parameterize dialog system as a single auto-regressive model. SOLOIST subsumes different dialog modules (e.g. state tracker, dialog policy, response generator) into a single Transformer model. It has the similar capability with GPT-2 in understanding and generating natural language sentences but is pre-trained on large heterogeneous dialog corpora to gain additional capability of grounding text response in user goals and real-world knowledge for task completion (Peng et al., 2020a; Gao et al., 2020). For detailed description, please see Section A in Appendix."
    }, {
      "heading" : "5.2 Adversarially Robust SOLOIST",
      "text" : "It is known that adversarial training can improve a model’s adversarial robustness, which refers to a model’s invariance to small (often imperceptible) perturbations of its inputs (i.e., clean exam-\nples) (Madry et al., 2017; Miyato et al., 2018; Liu et al., 2020; Li et al., 2020b). Adversarial examples are produced by adding perturbations on clean examples to fool the predictions of a trained model the most. Though fundamentally different, one may view adversarial examples as resembling the variations in natural language to some extent. Inspired by this idea, we propose an adversarially robust SOLOIST model, denoted as SOLOISTAdv.\nSpecifically, for a dialog turn x drawn from the training dataset D, and a neural model SOLOIST parameterized by θ, the standard training minimizes the empirical risk: minθ Ex∼DLθ(x), where Lθ(x) is the SOLOIST learning objective defined in Appendix Section A. The key idea of adversarial training is to modify the objective by applying small perturbation δ to input word embeddings that maximize the adversarial loss: minθ Ex∼Dmaxδ Lθ(x+δ), where the inner maximization can be solved by running a number of projected gradient descent steps (Goodfellow et al., 2014; Bubeck, 2014). SOLOISTAdv is trained in a hybrid manner that combines standard training and adversarial training. It augments the training dataset with adversarial examples that add perturbations in the word embedding space of original dialog turns, which improve the model’s robustness against noisy inputs that arguably covers language variations. In our experiments, SOLOISTAdv employs adversarial training in both task-specific pre-training and fine-tuning stages."
    }, {
      "heading" : "5.3 Submission Details",
      "text" : "Training We leverage the pre-trained checkpoints from the corresponding work, and fine-tune them on RADDLE. For SOLOISTAdv, We apply 100k steps of adversarial training to the pre-trained checkpoints. Each domain is trained separately. We train our models with Adam with initial learning rate 5e-5 and batch size 1 for 20 epochs. We encourage subsequent submissions systems to devote\nthe same computation efforts in fine-tuning stage, e.g., up to one hour GPU time, for each model to ensure fair comparisons.\nEvaluation The RADDLE benchmark follows the same evaluation model as GLUE (Wang et al., 2018) or Kaggle3. To evaluate a system on the benchmark, one must run the system on the provided test data for the tasks, then upload the results to the website http://aka.ms/raddle for scoring. The benchmark site shows per-task scores and a macro-average of those scores to determine a system’s position on the leaderboard. The website also provides fine- and coarse-grained results on the robustness diagnostic datasets. We will provide human evaluation services for top-ranked submissions on a quarterly basis. The human evaluation protocol follows Peng et al. (2020a) and Li et al. (2020c)."
    }, {
      "heading" : "6 Benchmark Results",
      "text" : ""
    }, {
      "heading" : "6.1 Overall Results",
      "text" : "We first present the results of baseline methods across all tasks on the RADDLE benchmark in Table 2. As shown, GPT-2FT fine-tuned with domainspecific dialog corpora outperforms the strong modular-based method DAMD. This highlights the efficacy of pre-trained language models. SOLOIST improves upon GPT-2FT over 10 points in terms of average score, and consistently performs better than GPT-2FT across all the tasks. These strong results indicate that large-scale task-specific pretraining on dialog corpora is crucial for effective and robust task adaptation. However, the performance of SOLOIST drops on robust checklist tasks. Benefiting from adversarial training, SOLOISTAdv outperforms SOLOIST about 2 points.\n3https://www.kaggle.com/"
    }, {
      "heading" : "6.2 Robustness Diagnostic Checklist Results",
      "text" : "Table 2 shows the overall performance of DST and E2E modeling under different variation settings.\nLanguage Variations It is noticeable that all the models incur significant performance drops under each type of variation. Among all variation types, Typos has the most substantial impact on both JGA and Combined score resulting in 10 to 20 points of drop in performance. This is expected as misspelled keywords pose significant challenges for state tracking. The influence of other three types of variations are also prominent. The results reveal that existing SoTA dialog models trained on limited task-specific examples are not robust enough to handle various types of user utterances. Adversarial training improves robustness to language variations, boosting performance across all the language variations tasks.\nSpeech Errors We observe a clear degradation in all metrics for all models. This shows that during inference, models trained on textual data are sensitive and not robust to actual ASR hypotheses introduced in dialog history.\nUnseen Entities Without task-specific pretraining, GPT-2FT only achieves less than 30% of JGA and 51.20 of dialog act accuracy even on a simple domain with most of the common entity values. SOLOIST performs significantly better than GPT-2FT by achieving 69.05% JGA and 96.98 dialog act accuracy but remains imperfect. SOLOISTAdv performs similar to SOLOIST, which is expected as adversarial training does not provides additional knowledge. These results imply that task-specific pre-training can improve the generalization capability of models but is still far from enough for production environments.\nOut-of-Domain Utterances It is non-trivial for conventional modular-based dialog systems to handle OOD detection. It often requires an additional component to classify whether a user utterance as in-domain or not. As such, we omit the result of DAMD in our experiments. GPT-2FT achieves 83.96 F1 score while SOLOIST has 96.18 F1 score, which shows that task-specific pre-training can improve robustness of models to OOD utterances. It is interesting to observe that adversarial training hurts model’s performance on OOD detection. We conjecture that adversarial training enable models to tolerate disturbances on the inputs and thus yield\n0.6\n0.7\n0.8\n0.9\nSu cc\nes s R\nat e\nDSTC-8\nmore false positive predictions on this task. Finally, it is worth pointing out some important trends in the dialog research community, based on the DSTC challenge (Kim et al., 2019; Gunasekara et al., 2020) in the last 2 years (Figure 2). In DSTC8 (Kim et al., 2019), the winning submission by Team 5 is the only one that uses pretrained models (GPT-2). When moving from corpus evaluation to human evaluation, it exhibits the least performance drop relative to other submissions, which is strong evidence to demonstrate robustness of pre-trained models. By the time of DSTC9 (Gunasekara et al., 2020), the community have witnessed a general trend shift from modular systems to pre-trained end-to-end architectures. However, the significant performance gap between corpus evaluation and human evaluation indicates that pre-trained methods remain sensitive to noisy inputs. Such observations underscore the importance of robustness-oriented design and evaluation, for which RADDLE fills a major void."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We introduce RADDLE, a platform and collection of resources for evaluating and analyzing taskoriented dialog systems. We confirm (1) the utility of grounded pre-training and transfer learning methods in dialog systems: pre-training improves\ngeneralization in a limited data setting, and (2) adversarial training improves robustness, but still leaves room for improvement. When evaluating these models on our diagnostic dataset, we find that they fail (often spectacularly) on many robustness test cases, suggesting possible avenues for future work. In summary, the question of how to design unified, efficient, robust models remains largely unexplored, and we believe that RADDLE can provide fertile soil for addressing this challenge."
    }, {
      "heading" : "Acknowledgement",
      "text" : "We gratefully acknowledge the entire Project Philly team inside Microsoft, who provided the computing platform for our research. We also thank the anonymous reviewers whose suggestions helped clarify this work.\nEthical Considerations\nThe collection of our RADDLE dataset is consistent with the terms of use of any sources and the original authors’ intellectual property and privacy rights. The dataset is collected with Amazon mechanical Turks, and each HIT requires up to two minutes to complete. The requested inputs are general language variations, and no privacy-related information is collected during data collection. Each HIT was paid 0.5 USD, with the hourly pay being 15% higher than the minimum wage requirements in our area. A board of data researchers has reviewed all the collected data to ensure no ethical concerns e.g., toxic language and hate speech."
    }, {
      "heading" : "A Background on SOLOIST",
      "text" : "We review the SOLOIST (Peng et al., 2020a) for completeness. Each dialog turn is represented as:\nx = (s, b, c, r), (1)\nwhere s is the entire dialog history up to the current dialog turn, b is the dialog belief state acquired from human annotation, c is the DB state automatically retrieved from a database using b, and r is the delexicalized dialog response, from which the system response in natural language can be easily obtained with some automatic post-processing. In sum, each item in x is by itself a sequence of tokens, the entire dialog turn can be viewed as a long sequence.\nSOLOIST is a neural model parameterized by θ to characterize the sequence generation probability pθ(x). It is pre-trained using publicly available heterogeneous dialog corpora with labels of belief states and DB states. The pre-trained model can be fine-tuned to any new task to generate responses grounded in task-specific user goals and a database. The pre-training and fine-tuning share the same multi-task objective for learning θ:\nLθ = LB + LR + LC , (2)\nwhere each task is described as follows:\nTask 1: Belief Prediction For a belief state sequence of length Tb, we define the objective of predicting the belief state as:\nLB = log p(b|s) = Tb∑ t=1 log pθ(bt|b<t, s), (3)\nwhere b<t indicates all tokens before t.\nTask 2: Grounded Response Generation A delexicalized response of length Tr, r = [r1, · · · , rTr ], is generated by our model token-bytoken from left to right, grounded in dialog history c, belief state b and DB state s. The corresponding training objective is defined as\nLR = log p(r|c, b, s) (4)\n= Tr∑ t=1 log pθ(rt|r<t, c, b, s).\nTask 3: Contrastive Objective A contrastive objective is employed to promote the matched items (y = 1 for positive samples x) while driving\ndown the mismatched items (y = 0 for negative samples x′). Since the the special token [EOS] attends all tokens in the sequence, the output feature on [EOS] is the fused representation of all items. We apply a binary classifier on top of the feature\nLC=y log(pθ(x)) + (1−y) log(1− pθ(x′)). (5)\nPlease refer (Peng et al., 2020a) for more details."
    } ],
    "references" : [ {
      "title" : "Convex optimization: Algorithms and complexity",
      "author" : [ "Sébastien Bubeck." ],
      "venue" : "arXiv preprint arXiv:1405.4980.",
      "citeRegEx" : "Bubeck.,? 2014",
      "shortCiteRegEx" : "Bubeck.",
      "year" : 2014
    }, {
      "title" : "Multiwoz-a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling",
      "author" : [ "Paweł Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "Iñigo Casanueva", "Stefan Ultes", "Osman Ramadan", "Milica Gasic." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Budzianowski et al\\.,? 2018",
      "shortCiteRegEx" : "Budzianowski et al\\.",
      "year" : 2018
    }, {
      "title" : "Span-convert: Fewshot span extraction for dialog with pretrained conversational representations",
      "author" : [ "Sam Coope", "Tyler Farghly", "Daniela Gerz", "Ivan Vulic", "Matthew Henderson." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Com-",
      "citeRegEx" : "Coope et al\\.,? 2020",
      "shortCiteRegEx" : "Coope et al\\.",
      "year" : 2020
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Unified language model pre-training for natural language understanding and generation",
      "author" : [ "Li Dong", "Nan Yang", "Wenhui Wang", "Furu Wei", "Xiaodong Liu", "Yu Wang", "Jianfeng Gao", "Ming Zhou", "Hsiao-Wuen Hon." ],
      "venue" : "Advances in Neural Informa-",
      "citeRegEx" : "Dong et al\\.,? 2019",
      "shortCiteRegEx" : "Dong et al\\.",
      "year" : 2019
    }, {
      "title" : "Keyvalue retrieval networks for task-oriented dialogue",
      "author" : [ "Mihail Eric", "Christopher D Manning." ],
      "venue" : "arXiv preprint arXiv:1705.05414.",
      "citeRegEx" : "Eric and Manning.,? 2017",
      "shortCiteRegEx" : "Eric and Manning.",
      "year" : 2017
    }, {
      "title" : "Neural approaches to conversational ai",
      "author" : [ "Jianfeng Gao", "Michel Galley", "Lihong Li." ],
      "venue" : "Foundations and Trends R",
      "citeRegEx" : "Gao et al\\.,? 2019",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Robust conversational ai with grounded text generation",
      "author" : [ "Jianfeng Gao", "Baolin Peng", "Chunyuan Li", "Jinchao Li", "Shahin Shayandeh", "Lars Liden", "HeungYeung Shum." ],
      "venue" : "arXiv preprint arXiv:2009.03457.",
      "citeRegEx" : "Gao et al\\.,? 2020",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2020
    }, {
      "title" : "Explaining and harnessing adversarial examples",
      "author" : [ "Ian J Goodfellow", "Jonathon Shlens", "Christian Szegedy." ],
      "venue" : "arXiv preprint arXiv:1412.6572.",
      "citeRegEx" : "Goodfellow et al\\.,? 2014",
      "shortCiteRegEx" : "Goodfellow et al\\.",
      "year" : 2014
    }, {
      "title" : "Are neural open-domain dialog systems robust to speech recognition errors in the dialog history? an empirical study",
      "author" : [ "Karthik Gopalakrishnan", "Behnam Hedayatnia", "Longshaokan Wang", "Yang Liu", "Dilek HakkaniTur." ],
      "venue" : "arXiv preprint",
      "citeRegEx" : "Gopalakrishnan et al\\.,? 2020",
      "shortCiteRegEx" : "Gopalakrishnan et al\\.",
      "year" : 2020
    }, {
      "title" : "Overview of the ninth dialog system technology",
      "author" : [ "Chulaka Gunasekara", "Seokhwan Kim", "Luis Fernando D’Haro", "Abhinav Rastogi", "Yun-Nung Chen", "Mihail Eric", "Behnam Hedayatnia", "Karthik Gopalakrishnan", "Yang Liu", "Chao-Wei Huang" ],
      "venue" : null,
      "citeRegEx" : "Gunasekara et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Gunasekara et al\\.",
      "year" : 2020
    }, {
      "title" : "End-to-end neural pipeline for goal-oriented dialogue systems using gpt-2",
      "author" : [ "Donghoon Ham", "Jeong-Gwan Lee", "Youngsoo Jang", "Kee-Eung Kim." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Ham et al\\.,? 2020",
      "shortCiteRegEx" : "Ham et al\\.",
      "year" : 2020
    }, {
      "title" : "The ATIS spoken language systems pilot corpus",
      "author" : [ "Charles T. Hemphill", "John J. Godfrey", "George R. Doddington." ],
      "venue" : "Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, Pennsylvania, June 24-27,1990.",
      "citeRegEx" : "Hemphill et al\\.,? 1990",
      "shortCiteRegEx" : "Hemphill et al\\.",
      "year" : 1990
    }, {
      "title" : "The second dialog state tracking challenge",
      "author" : [ "Matthew Henderson", "Blaise Thomson", "Jason D Williams." ],
      "venue" : "Proceedings of the 15th annual meeting of the special interest group on discourse and dialogue (SIGDIAL), pages 263–272.",
      "citeRegEx" : "Henderson et al\\.,? 2014",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2014
    }, {
      "title" : "A simple language model for task-oriented dialogue",
      "author" : [ "Ehsan Hosseini-Asl", "Bryan McCann", "Chien-Sheng Wu", "Semih Yavuz", "Richard Socher." ],
      "venue" : "arXiv preprint arXiv:2005.00796.",
      "citeRegEx" : "Hosseini.Asl et al\\.,? 2020",
      "shortCiteRegEx" : "Hosseini.Asl et al\\.",
      "year" : 2020
    }, {
      "title" : "Ctrl: A conditional transformer language model for controllable generation",
      "author" : [ "Nitish Shirish Keskar", "Bryan McCann", "Lav R Varshney", "Caiming Xiong", "Richard Socher." ],
      "venue" : "arXiv preprint arXiv:1909.05858.",
      "citeRegEx" : "Keskar et al\\.,? 2019",
      "shortCiteRegEx" : "Keskar et al\\.",
      "year" : 2019
    }, {
      "title" : "The eighth dialog system technology challenge",
      "author" : [ "Seokhwan Kim", "Michel Galley", "Chulaka Gunasekara", "Sungjin Lee", "Adam Atkinson", "Baolin Peng", "Hannes Schulz", "Jianfeng Gao", "Jinchao Li", "Mahmoud Adada" ],
      "venue" : "arXiv preprint arXiv:1911.06394",
      "citeRegEx" : "Kim et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2019
    }, {
      "title" : "An evaluation dataset for intent classification",
      "author" : [ "Stefan Larson", "Anish Mahendran", "Joseph J. Peper", "Christopher Clarke", "Andrew Lee", "Parker Hill", "Jonathan K. Kummerfeld", "Kevin Leach", "Michael A. Laurenzano", "Lingjia Tang", "Jason Mars" ],
      "venue" : null,
      "citeRegEx" : "Larson et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Larson et al\\.",
      "year" : 2019
    }, {
      "title" : "Contextual out-of-domain utterance handling with counterfeit data augmentation",
      "author" : [ "Sungjin Lee", "Igor Shalyminov." ],
      "venue" : "ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7205–7209.",
      "citeRegEx" : "Lee and Shalyminov.,? 2019",
      "shortCiteRegEx" : "Lee and Shalyminov.",
      "year" : 2019
    }, {
      "title" : "Convlab: Multi-domain end-to-end dialog system platform",
      "author" : [ "Sungjin Lee", "Qi Zhu", "Ryuichi Takanobu", "Zheng Zhang", "Yaoqin Zhang", "Xiang Li", "Jinchao Li", "Baolin Peng", "Xiujun Li", "Minlie Huang" ],
      "venue" : "In Proceedings of the 57th Annual Meeting",
      "citeRegEx" : "Lee et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2019
    }, {
      "title" : "Optimus: Organizing sentences via pre-trained modeling of a latent space",
      "author" : [ "Chunyuan Li", "Xiang Gao", "Yuan Li", "Baolin Peng", "Xiujun Li", "Yizhe Zhang", "Jianfeng Gao." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Li et al\\.,? 2020a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Selfsupervised pre-training with hard examples improves visual representations",
      "author" : [ "Chunyuan Li", "Xiujun Li", "Lei Zhang", "Baolin Peng", "Mingyuan Zhou", "Jianfeng Gao." ],
      "venue" : "arXiv preprint arXiv:2012.13493.",
      "citeRegEx" : "Li et al\\.,? 2020b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Results of the multi-domain task-completion dialog challenge",
      "author" : [ "Jinchao Li", "Baolin Peng", "Sungjin Lee", "Jianfeng Gao", "Ryuichi Takanobu", "Qi Zhu", "Minlie Huang", "Hannes Schulz", "Adam Atkinson", "Mahmoud Adada." ],
      "venue" : "Proceedings of the 34th AAAI",
      "citeRegEx" : "Li et al\\.,? 2020c",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Adversarial training for large neural language models",
      "author" : [ "Xiaodong Liu", "Hao Cheng", "Pengcheng He", "Weizhu Chen", "Yu Wang", "Hoifung Poon", "Jianfeng Gao." ],
      "venue" : "arXiv preprint arXiv:2004.08994.",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems",
      "author" : [ "Ryan Lowe", "Nissan Pow", "Iulian Serban", "Joelle Pineau." ],
      "venue" : "arXiv preprint arXiv:1506.08909.",
      "citeRegEx" : "Lowe et al\\.,? 2015",
      "shortCiteRegEx" : "Lowe et al\\.",
      "year" : 2015
    }, {
      "title" : "Towards deep learning models resistant to adversarial attacks",
      "author" : [ "Aleksander Madry", "Aleksandar Makelov", "Ludwig Schmidt", "Dimitris Tsipras", "Adrian Vladu." ],
      "venue" : "arXiv preprint arXiv:1706.06083.",
      "citeRegEx" : "Madry et al\\.,? 2017",
      "shortCiteRegEx" : "Madry et al\\.",
      "year" : 2017
    }, {
      "title" : "DialoGLUE: A natural language understanding benchmark for task-oriented dialogue",
      "author" : [ "Shikib Mehri", "Mihail Eric", "Dilek Hakkani-Tur." ],
      "venue" : "arXiv preprint arXiv:2009.13570.",
      "citeRegEx" : "Mehri et al\\.,? 2020",
      "shortCiteRegEx" : "Mehri et al\\.",
      "year" : 2020
    }, {
      "title" : "Virtual adversarial training: a regularization method for supervised and semisupervised learning",
      "author" : [ "Takeru Miyato", "Shin-ichi Maeda", "Masanori Koyama", "Shin Ishii." ],
      "venue" : "T-PAMI.",
      "citeRegEx" : "Miyato et al\\.,? 2018",
      "shortCiteRegEx" : "Miyato et al\\.",
      "year" : 2018
    }, {
      "title" : "Conversational UX Design: A Practitioner’s Guide to the Natural Conversation Framework",
      "author" : [ "Robert J Moore", "Raphael Arar." ],
      "venue" : "ACM.",
      "citeRegEx" : "Moore and Arar.,? 2019",
      "shortCiteRegEx" : "Moore and Arar.",
      "year" : 2019
    }, {
      "title" : "Neural belief tracker: Data-driven dialogue state tracking",
      "author" : [ "Nikola Mrksic", "Diarmuid Ó Séaghdha", "Tsung-Hsien Wen", "Blaise Thomson", "Steve J Young." ],
      "venue" : "ACL (1).",
      "citeRegEx" : "Mrksic et al\\.,? 2017",
      "shortCiteRegEx" : "Mrksic et al\\.",
      "year" : 2017
    }, {
      "title" : "Adversarial NLI: A new benchmark for natural language understanding",
      "author" : [ "Yixin Nie", "Adina Williams", "Emily Dinan", "Mohit Bansal", "Jason Weston", "Douwe Kiela." ],
      "venue" : "arXiv preprint arXiv:1910.14599.",
      "citeRegEx" : "Nie et al\\.,? 2019",
      "shortCiteRegEx" : "Nie et al\\.",
      "year" : 2019
    }, {
      "title" : "SOLOIST: few-shot task-oriented dialog with A single pre-trained auto-regressive model",
      "author" : [ "Baolin Peng", "Chunyuan Li", "Jinchao Li", "Shahin Shayandeh", "Lars Liden", "Jianfeng Gao." ],
      "venue" : "CoRR, abs/2005.05298.",
      "citeRegEx" : "Peng et al\\.,? 2020a",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2020
    }, {
      "title" : "Few-shot natural language generation for task-oriented dialog",
      "author" : [ "Baolin Peng", "Chenguang Zhu", "Chunyuan Li", "Xiujun Li", "Jinchao Li", "Michael Zeng", "Jianfeng Gao." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020,",
      "citeRegEx" : "Peng et al\\.,? 2020b",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2020
    }, {
      "title" : "Data augmentation for spoken language understanding via pretrained models",
      "author" : [ "Baolin Peng", "Chenguang Zhu", "Michael Zeng", "Jianfeng Gao." ],
      "venue" : "arXiv preprint arXiv:2004.13952.",
      "citeRegEx" : "Peng et al\\.,? 2020c",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2020
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew E Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "arXiv preprint arXiv:1802.05365.",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "A simplest systematics for the organization of turn taking for conversation",
      "author" : [ "Harvey Sacks", "Emanuel A Schegloff", "Gail Jefferson." ],
      "venue" : "Studies in the organization of conversational interaction. Elsevier.",
      "citeRegEx" : "Sacks et al\\.,? 1978",
      "shortCiteRegEx" : "Sacks et al\\.",
      "year" : 1978
    }, {
      "title" : "The preference for self-correction in the organization of repair in conversation",
      "author" : [ "Emanuel A Schegloff", "Gail Jefferson", "Harvey Sacks." ],
      "venue" : "Language.",
      "citeRegEx" : "Schegloff et al\\.,? 1977",
      "shortCiteRegEx" : "Schegloff et al\\.",
      "year" : 1977
    }, {
      "title" : "Building a conversational agent overnight with dialogue self-play",
      "author" : [ "Pararth Shah", "Dilek Hakkani-Tür", "Gokhan Tür", "Abhinav Rastogi", "Ankur Bapna", "Neha Nayak", "Larry Heck." ],
      "venue" : "arXiv preprint arXiv:1801.04871.",
      "citeRegEx" : "Shah et al\\.,? 2018",
      "shortCiteRegEx" : "Shah et al\\.",
      "year" : 2018
    }, {
      "title" : "A neural network approach to context-sensitive generation of conversational responses",
      "author" : [ "Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "arXiv preprint",
      "citeRegEx" : "Sordoni et al\\.,? 2015",
      "shortCiteRegEx" : "Sordoni et al\\.",
      "year" : 2015
    }, {
      "title" : "Glue: A multi-task benchmark and analysis platform for natural language understanding",
      "author" : [ "Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R Bowman." ],
      "venue" : "arXiv preprint arXiv:1804.07461.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "A networkbased end-to-end trainable task-oriented dialogue system",
      "author" : [ "Tsung-Hsien Wen", "David Vandyke", "Nikola Mrkšić", "Milica Gasic", "Lina M Rojas Barahona", "Pei-Hao Su", "Stefan Ultes", "Steve Young." ],
      "venue" : "Proceedings of the 15th Conference of",
      "citeRegEx" : "Wen et al\\.,? 2017",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2017
    }, {
      "title" : "Tod-bert: Pre-trained natural language understanding for task-oriented dialogues",
      "author" : [ "Chien-Sheng Wu", "Steven Hoi", "Richard Socher", "Caiming Xiong." ],
      "venue" : "arXiv preprint arXiv:2004.06871.",
      "citeRegEx" : "Wu et al\\.,? 2020a",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Tod-bert: Pre-trained natural language understanding for task-oriented dialogue",
      "author" : [ "Chien-Sheng Wu", "Steven CH Hoi", "Richard Socher", "Caiming Xiong." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Wu et al\\.,? 2020b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Alternating recurrent dialog model with largescale pre-trained language models",
      "author" : [ "Qingyang Wu", "Yichi Zhang", "Yu Li", "Zhou Yu." ],
      "venue" : "arXiv preprint arXiv:1910.03756.",
      "citeRegEx" : "Wu et al\\.,? 2019",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "An end-to-end approach for handling unknown slot values in dialogue state tracking",
      "author" : [ "Puyang Xu", "Qi Hu." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1448–1457, Mel-",
      "citeRegEx" : "Xu and Hu.,? 2018",
      "shortCiteRegEx" : "Xu and Hu.",
      "year" : 2018
    }, {
      "title" : "XLNet: Generalized autoregressive pretraining for language understanding",
      "author" : [ "Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime Carbonell", "Ruslan Salakhutdinov", "Quoc V Le." ],
      "venue" : "NeurIPS.",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Taskoriented dialog systems that consider multiple appropriate responses under the same context",
      "author" : [ "Yichi Zhang", "Zhijian Ou", "Zhou Yu." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9604–9611.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "The design and implementation of xiaoice, an empathetic social chatbot",
      "author" : [ "Li Zhou", "Jianfeng Gao", "Di Li", "Heung-Yeung Shum." ],
      "venue" : "Computational Linguistics, 46(1):53–93.",
      "citeRegEx" : "Zhou et al\\.,? 2020",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2020
    }, {
      "title" : "Boosting naturalness of language in task-oriented dialogues via adversarial training",
      "author" : [ "Chenguang Zhu." ],
      "venue" : "arXiv preprint arXiv:2004.14565.",
      "citeRegEx" : "Zhu.,? 2020",
      "shortCiteRegEx" : "Zhu.",
      "year" : 2020
    }, {
      "title" : "Multi-task learning for natural language generation in task-oriented dialogue",
      "author" : [ "Chenguang Zhu", "Michael Zeng", "Xuedong Huang." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Zhu et al\\.,? 2019a",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2019
    }, {
      "title" : "Sim: A slot-independent neural model for dialogue state tracking",
      "author" : [ "Chenguang Zhu", "Michael Zeng", "Xuedong Huang." ],
      "venue" : "arXiv preprint arXiv:1909.11833.",
      "citeRegEx" : "Zhu et al\\.,? 2019b",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2019
    }, {
      "title" : "ConvLab2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems",
      "author" : [ "Qi Zhu", "Zheng Zhang", "Yan Fang", "Xiang Li", "Ryuichi Takanobu", "Jinchao Li", "Baolin Peng", "Jianfeng Gao", "Xiaoyan Zhu", "Minlie Huang." ],
      "venue" : "Proceedings",
      "citeRegEx" : "Zhu et al\\.,? 2020",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 50,
      "context" : "In a bid to support human-computer interactions, task-oriented dialog systems have been built to allow users to converse with a computer system using natural language, such as Siri, Google Assistant, Amazon Alexa, Microsoft XiaoIce (Zhou et al., 2020).",
      "startOffset" : 232,
      "endOffset" : 251
    }, {
      "referenceID" : 6,
      "context" : "Traditionally, a task-oriented dialog system uses a modularized pipeline with four modules that execute sequentially (Gao et al., 2019).",
      "startOffset" : 117,
      "endOffset" : 135
    }, {
      "referenceID" : 33,
      "context" : "Moreover, even the best performing model (SOLOIST (Peng et al., 2020a)) in our evaluation achieves a fairly low score in robustness analysis.",
      "startOffset" : 50,
      "endOffset" : 70
    }, {
      "referenceID" : 43,
      "context" : "They are roughly grouped into two categories: (i) Corpora with structured semantic labels (Wen et al., 2017; Shah et al., 2018).",
      "startOffset" : 90,
      "endOffset" : 127
    }, {
      "referenceID" : 40,
      "context" : "They are roughly grouped into two categories: (i) Corpora with structured semantic labels (Wen et al., 2017; Shah et al., 2018).",
      "startOffset" : 90,
      "endOffset" : 127
    }, {
      "referenceID" : 28,
      "context" : "For example, DialoGLUE (Mehri et al., 2020) is a recently proposed benchmark with a focus on NLU and DST tasks.",
      "startOffset" : 23,
      "endOffset" : 43
    }, {
      "referenceID" : 26,
      "context" : "(ii) Corpora with an implicit user goal (Lowe et al., 2015).",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 23,
      "context" : "These datasets are often without semantic labels but can be used in end-to-end (E2E) dialog modeling (Li et al., 2016; Zhu, 2020; Wu et al., 2019; Zhu et al., 2019a; Lee et al., 2019; Zhu et al., 2020).",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 51,
      "context" : "These datasets are often without semantic labels but can be used in end-to-end (E2E) dialog modeling (Li et al., 2016; Zhu, 2020; Wu et al., 2019; Zhu et al., 2019a; Lee et al., 2019; Zhu et al., 2020).",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 46,
      "context" : "These datasets are often without semantic labels but can be used in end-to-end (E2E) dialog modeling (Li et al., 2016; Zhu, 2020; Wu et al., 2019; Zhu et al., 2019a; Lee et al., 2019; Zhu et al., 2020).",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 52,
      "context" : "These datasets are often without semantic labels but can be used in end-to-end (E2E) dialog modeling (Li et al., 2016; Zhu, 2020; Wu et al., 2019; Zhu et al., 2019a; Lee et al., 2019; Zhu et al., 2020).",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 19,
      "context" : "These datasets are often without semantic labels but can be used in end-to-end (E2E) dialog modeling (Li et al., 2016; Zhu, 2020; Wu et al., 2019; Zhu et al., 2019a; Lee et al., 2019; Zhu et al., 2020).",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 54,
      "context" : "These datasets are often without semantic labels but can be used in end-to-end (E2E) dialog modeling (Li et al., 2016; Zhu, 2020; Wu et al., 2019; Zhu et al., 2019a; Lee et al., 2019; Zhu et al., 2020).",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 1,
      "context" : "MultiWOZ (Budzianowski et al., 2018) is the most related work to RADDLE.",
      "startOffset" : 9,
      "endOffset" : 36
    }, {
      "referenceID" : 42,
      "context" : "Further, RADDLE provides an online platform for model evaluation and fair comparison based on privately-held test data, inspired by GLUE (Wang et al., 2018).",
      "startOffset" : 137,
      "endOffset" : 156
    }, {
      "referenceID" : 7,
      "context" : "Meanwhile, task-oriented dialogs pose a unique set of challenges for PLMs (Gao et al., 2020): a dialog is intrinsically goal-driven, multi-turn and often informal/noisy.",
      "startOffset" : 74,
      "endOffset" : 92
    }, {
      "referenceID" : 44,
      "context" : "Indeed, dialog-specific PLMs are proposed (Wu et al., 2020a; Peng et al., 2020a).",
      "startOffset" : 42,
      "endOffset" : 80
    }, {
      "referenceID" : 33,
      "context" : "Indeed, dialog-specific PLMs are proposed (Wu et al., 2020a; Peng et al., 2020a).",
      "startOffset" : 42,
      "endOffset" : 80
    }, {
      "referenceID" : 32,
      "context" : "Note that our notion of robustness emphasizes natural language variations, which is different from adversarial examples/training that aim to fool a trained model (Nie et al., 2019).",
      "startOffset" : 162,
      "endOffset" : 180
    }, {
      "referenceID" : 2,
      "context" : ", pretrained parameters) learned from its previous life cycle, while still maintaining some task-specific components (Coope et al., 2020; Henderson et al., 2020; Peng et al., 2020a; Wu et al., 2020b).",
      "startOffset" : 117,
      "endOffset" : 199
    }, {
      "referenceID" : 33,
      "context" : ", pretrained parameters) learned from its previous life cycle, while still maintaining some task-specific components (Coope et al., 2020; Henderson et al., 2020; Peng et al., 2020a; Wu et al., 2020b).",
      "startOffset" : 117,
      "endOffset" : 199
    }, {
      "referenceID" : 45,
      "context" : ", pretrained parameters) learned from its previous life cycle, while still maintaining some task-specific components (Coope et al., 2020; Henderson et al., 2020; Peng et al., 2020a; Wu et al., 2020b).",
      "startOffset" : 117,
      "endOffset" : 199
    }, {
      "referenceID" : 33,
      "context" : "Recent research has shown promising results on parameterizing the modularized pipeline using a single neural autoregressive model, and training it in an end-to-end manner (Peng et al., 2020a; Ham et al., 2020; Hosseini-Asl et al., 2020).",
      "startOffset" : 171,
      "endOffset" : 236
    }, {
      "referenceID" : 11,
      "context" : "Recent research has shown promising results on parameterizing the modularized pipeline using a single neural autoregressive model, and training it in an end-to-end manner (Peng et al., 2020a; Ham et al., 2020; Hosseini-Asl et al., 2020).",
      "startOffset" : 171,
      "endOffset" : 236
    }, {
      "referenceID" : 14,
      "context" : "Recent research has shown promising results on parameterizing the modularized pipeline using a single neural autoregressive model, and training it in an end-to-end manner (Peng et al., 2020a; Ham et al., 2020; Hosseini-Asl et al., 2020).",
      "startOffset" : 171,
      "endOffset" : 236
    }, {
      "referenceID" : 6,
      "context" : "Though we only offer human evaluations (Gao et al., 2019) to top-ranked submissions at this point, we emphasize realistic scenarios in pursuit of system robustness (see Section 4).",
      "startOffset" : 39,
      "endOffset" : 57
    }, {
      "referenceID" : 31,
      "context" : "For the evaluation metric, we report joint goal accuracy, which indicates the proportion of dialog turns where all the user’s search goal constraints are correctly identified (Mrksic et al., 2017).",
      "startOffset" : 175,
      "endOffset" : 196
    }, {
      "referenceID" : 12,
      "context" : "To specially study the NLU performance, we consider intent classification, which aims to automatically extract meaning from a natural language utterance in order to understand user’s goal (Hemphill et al., 1990; Zhu et al., 2019b).",
      "startOffset" : 188,
      "endOffset" : 230
    }, {
      "referenceID" : 53,
      "context" : "To specially study the NLU performance, we consider intent classification, which aims to automatically extract meaning from a natural language utterance in order to understand user’s goal (Hemphill et al., 1990; Zhu et al., 2019b).",
      "startOffset" : 188,
      "endOffset" : 230
    }, {
      "referenceID" : 1,
      "context" : "5 + BLEU as an overall quality measure, as suggested in (Budzianowski et al., 2018).",
      "startOffset" : 56,
      "endOffset" : 83
    }, {
      "referenceID" : 38,
      "context" : "Language Variations It is well-known that humans communicate using language with fairly large variations such as different ways of expressions or personalized styles (Sacks et al., 1978), while template-based crowd-sourcing fails in covering the linguistic variations (Schegloff et al.",
      "startOffset" : 166,
      "endOffset" : 186
    }, {
      "referenceID" : 39,
      "context" : ", 1978), while template-based crowd-sourcing fails in covering the linguistic variations (Schegloff et al., 1977; Moore and Arar, 2019).",
      "startOffset" : 89,
      "endOffset" : 135
    }, {
      "referenceID" : 30,
      "context" : ", 1978), while template-based crowd-sourcing fails in covering the linguistic variations (Schegloff et al., 1977; Moore and Arar, 2019).",
      "startOffset" : 89,
      "endOffset" : 135
    }, {
      "referenceID" : 18,
      "context" : "Thus, they are fragile when dealing with out-of-domain (OOD) utterances (Lee and Shalyminov, 2019).",
      "startOffset" : 72,
      "endOffset" : 98
    }, {
      "referenceID" : 17,
      "context" : "Therefore, it is important to endow task bots with the ability to detect OOD utterances for special handling (Larson et al., 2019).",
      "startOffset" : 109,
      "endOffset" : 130
    }, {
      "referenceID" : 1,
      "context" : "0 (Budzianowski et al., 2018) but re-purposed in a few-shot learning setting.",
      "startOffset" : 2,
      "endOffset" : 29
    }, {
      "referenceID" : 9,
      "context" : "For the speech recognition errors setting, we employ the audio-level error simulation (Gopalakrishnan et al., 2020), which generates audio signals from texts, adds noise into the audio, and then decodes the audio with an ASR model to obtain hypotheses.",
      "startOffset" : 86,
      "endOffset" : 115
    }, {
      "referenceID" : 13,
      "context" : "We randomly choose 50% utterances in DSTC (Henderson et al., 2014) for the Attraction domain as the training set.",
      "startOffset" : 42,
      "endOffset" : 66
    }, {
      "referenceID" : 5,
      "context" : "For the test set, besides utterance from DSTC, we also introduce utterance from a diverse set of domains like Stanford (Eric and Manning, 2017), Reddit, Twitter (Sordoni et al.",
      "startOffset" : 119,
      "endOffset" : 143
    }, {
      "referenceID" : 41,
      "context" : "For the test set, besides utterance from DSTC, we also introduce utterance from a diverse set of domains like Stanford (Eric and Manning, 2017), Reddit, Twitter (Sordoni et al., 2015) to evaluate the capability of handling different out-of-domain utterances.",
      "startOffset" : 161,
      "endOffset" : 183
    }, {
      "referenceID" : 1,
      "context" : "For baselines, we consider three representative methods, holding state-of-the-art positions on existing benchmarks such as MultiWoZ (Budzianowski et al., 2018).",
      "startOffset" : 132,
      "endOffset" : 159
    }, {
      "referenceID" : 49,
      "context" : "DAMD (Zhang et al., 2020) is a state-of-theart modular system, where each dialog module is implemented using a neural network, and the whole system is trained in an end-to-end manner.",
      "startOffset" : 5,
      "endOffset" : 25
    }, {
      "referenceID" : 37,
      "context" : "GPT-2 is pre-trained on extremely massive text data OpenWebText (Radford et al., 2019).",
      "startOffset" : 64,
      "endOffset" : 86
    }, {
      "referenceID" : 11,
      "context" : "SOLOIST represents recent model variants (Ham et al., 2020; Hosseini-Asl et al., 2020) to parameterize dialog system as a single auto-regressive model.",
      "startOffset" : 41,
      "endOffset" : 86
    }, {
      "referenceID" : 14,
      "context" : "SOLOIST represents recent model variants (Ham et al., 2020; Hosseini-Asl et al., 2020) to parameterize dialog system as a single auto-regressive model.",
      "startOffset" : 41,
      "endOffset" : 86
    }, {
      "referenceID" : 33,
      "context" : "It has the similar capability with GPT-2 in understanding and generating natural language sentences but is pre-trained on large heterogeneous dialog corpora to gain additional capability of grounding text response in user goals and real-world knowledge for task completion (Peng et al., 2020a; Gao et al., 2020).",
      "startOffset" : 273,
      "endOffset" : 311
    }, {
      "referenceID" : 7,
      "context" : "It has the similar capability with GPT-2 in understanding and generating natural language sentences but is pre-trained on large heterogeneous dialog corpora to gain additional capability of grounding text response in user goals and real-world knowledge for task completion (Peng et al., 2020a; Gao et al., 2020).",
      "startOffset" : 273,
      "endOffset" : 311
    }, {
      "referenceID" : 8,
      "context" : "The key idea of adversarial training is to modify the objective by applying small perturbation δ to input word embeddings that maximize the adversarial loss: minθ Ex∼Dmaxδ Lθ(x+δ), where the inner maximization can be solved by running a number of projected gradient descent steps (Goodfellow et al., 2014; Bubeck, 2014).",
      "startOffset" : 280,
      "endOffset" : 319
    }, {
      "referenceID" : 0,
      "context" : "The key idea of adversarial training is to modify the objective by applying small perturbation δ to input word embeddings that maximize the adversarial loss: minθ Ex∼Dmaxδ Lθ(x+δ), where the inner maximization can be solved by running a number of projected gradient descent steps (Goodfellow et al., 2014; Bubeck, 2014).",
      "startOffset" : 280,
      "endOffset" : 319
    }, {
      "referenceID" : 42,
      "context" : "Evaluation The RADDLE benchmark follows the same evaluation model as GLUE (Wang et al., 2018) or Kaggle3.",
      "startOffset" : 74,
      "endOffset" : 93
    }, {
      "referenceID" : 16,
      "context" : "Finally, it is worth pointing out some important trends in the dialog research community, based on the DSTC challenge (Kim et al., 2019; Gunasekara et al., 2020) in the last 2 years (Figure 2).",
      "startOffset" : 118,
      "endOffset" : 161
    }, {
      "referenceID" : 10,
      "context" : "Finally, it is worth pointing out some important trends in the dialog research community, based on the DSTC challenge (Kim et al., 2019; Gunasekara et al., 2020) in the last 2 years (Figure 2).",
      "startOffset" : 118,
      "endOffset" : 161
    }, {
      "referenceID" : 16,
      "context" : "In DSTC8 (Kim et al., 2019), the winning submission by Team 5 is the only one that uses pretrained models (GPT-2).",
      "startOffset" : 9,
      "endOffset" : 27
    }, {
      "referenceID" : 10,
      "context" : "By the time of DSTC9 (Gunasekara et al., 2020), the community have witnessed a general trend shift from modular systems to pre-trained end-to-end architectures.",
      "startOffset" : 21,
      "endOffset" : 46
    } ],
    "year" : 2021,
    "abstractText" : "For task-oriented dialog systems to be maximally useful, it must be able to process conversations in a way that is (1) generalizable with a small number of training examples for new task domains, and (2) robust to user input in various styles, modalities, or domains. In pursuit of these goals, we introduce the RADDLE1 benchmark 2, a collection of corpora and tools for evaluating the performance of models across a diverse set of domains. By including tasks with limited training data, RADDLE is designed to favor and encourage models with a strong generalization ability. RADDLE also includes a diagnostic checklist that facilitates detailed robustness analysis in aspects such as language variations, speech errors, unseen entities, and out-of-domain utterances. We evaluate recent state-of-the-art systems based on pre-training and fine-tuning, and find that grounded pre-training on heterogeneous dialog corpora performs better than training a separate model per domain. Adversarial training is also proposed to improve model robustness against noisy inputs. Overall, existing models are less than satisfactory in robustness evaluation, which suggests opportunities for future improvement.",
    "creator" : "LaTeX with hyperref"
  }
}