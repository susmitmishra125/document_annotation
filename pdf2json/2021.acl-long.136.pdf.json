{
  "name" : "2021.acl-long.136.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Discovering Dialog Structure Graph for Coherent Dialog Generation",
    "authors" : [ "Jun Xu", "Zeyang Lei", "Haifeng Wang", "Zheng-Yu Niu", "Hua Wu", "Wanxiang Che" ],
    "emails" : [ "car}@ir.hit.edu.cn,", "hua}@baidu.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 1726–1739\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n1726"
    }, {
      "heading" : "1 Introduction",
      "text" : "With the aim of building a machine to converse with humans naturally, some work investigate neural generative models (Shang et al., 2015; Serban et al., 2017). While these models can generate locally relevant dialogs, they struggle to organize individual utterances into globally coherent flow (Yu et al., 2016; Xu et al., 2020b). The possible reason is that it is difficult to control the overall dialog flow without background knowledge about dialog structure.1 However, due to the complexity of opendomain conversation, it is laborious and costly to annotate dialog structure manually. Therefore, it is\n∗Equal contribution. †Corresponding author: Wanxiang Che.\n1Dialog structure means dialog states and their transitions.\nof great importance to discover open-domain dialog structure from corpus in an unsupervised way for coherent dialog generation.\nSome studies tried to discover dialog structure from task-oriented dialogs (Shi et al., 2019). However, the number of their dialog states is limited to only dozens or hundreds, which cannot cover finegrained semantics in open-domain dialogs. Furthermore, the dialog structures they discovered generally only contain utterance-level semantics (non-hierarchical), without session-level semantics (chatting topics) that are essential in open-domain dialogs (Wu et al., 2019; Kang et al., 2019; Xu et al., 2020c).2 Thus, in order to provide a full picture of open-domain dialog structure, it is desirable to discover a two-layer directed graph that contains session-level semantics in the upper-layer vertices, utterance-level semantics in the lower-layer vertices, and edges among these vertices.\nIn this paper, we propose a novel discrete variational auto-encoder with graph neural network (DVAE-GNN) to discover a two-layer dialog structure from chitchat corpus. Intuitively, since discrete dialog states are easier to capture transitions for dialog coherence, we use discrete variables to represent dialog states (or vertices in the graph) rather than dense continuous ones in most VAEbased dialog models (Serban et al., 2017; Zhao et al., 2017). Specifically, we employ an RNN Encoder with softmax function as vertex recognition module in DVAE, and an RNN decoder as reconstruction module in DVAE, as shown in Figure 3. Furthermore, we integrate GNN into DVAE to model complex relations among discrete variables for more effective discovery. The parameters of DVAE-GNN can be optimized by minimizing a reconstruction loss, without the requirement of any annotated datasets.\n2A session refers to a dialog fragment about one topic.\n1 3\n3 4\n6 7 2\n5 1\n2\n1 3\n3 4\n6 7 2\n5 1\n2\nSession-level semantic vertex Utterance-level semantic vertex\n(b) Map each dialog session to vertices (c) Collect co-occurrence statistics of mapped vertices for all dialog sessions\n(d) Build edges between vertices to form dialog structure graph (a) A set of dialog sessions\n1 3\n3 4\n6 7 2\n5 1\n2\n找到房子了么 Have you found a\nplace to live?\n1\n3 4\n7 2\n5 1\n2\nSession-level semantic vertex Utterance-level semantic vertex\n3\nSpeak 1:嗯，我 提前订好了酒店。 [Yes, I have booked a hotel in advance.] Speak 1: 假期准备去爬黄山[I’m going to climb Huangshan Mountain on holiday.] Speak 2:哇！准备在山上找房子过夜么？ [WOW! Are you going to find a house on the mountain for the night?]\nContext Response\n有时间找我玩 Visit me when\nyou are free\n好久没见你 Haven't seen you for a long time\n明天去长沙 Go to Changsha\ntomorrow\n预定了酒店 Have booked a hotel room\nOne co-occurrence of two vertices Edge\n6\n找到房子了么 Have you found a\nplace to live?\n预定了酒店 Have booked a\nhotel room\nPhrase associated with utterance-level vertex\n放假来找我玩啊 [Let’s take vacations together.]\n我明天准备去长沙上班 [I’ll go to Changsha tomorrow]\n好啊，好久没见面了 [Yep, long time no see]\n…\n…\n你租房子了么 [Oh, have you rent a room yet?]\n…\n…\nFigure 1: The procedure of dialog structure discovery. Figure (d) shows the discovered dialog structure graph.\n放假来找我玩啊 [Let’s take vacations together.]\n好啊，好久没见面了 [Yep, long time no see]\n我明天准备去长沙上班 [I’ll go to Changsha tomorrow]\n你租房子了么 [Oh, have you rent a room yet?]\n1 3\n3 4\n6 7 2\n5 1\n2\n… … 1 3\n3 4\n6 7 2\n5 1\n2\nSession-level semantic vertex Utterance-level semantic vertex\n… …\n(b) Map each dialog session to vertices (c) Collect co-occurrence statistics of\nmapped vertices for all dialog sessions\n(d) Build ges between vertic s\nto form dialog structure graph\n(a) A set of dialog sessions\n1 3\n3 4\n6 7 2\n5 1\n2\n找到房子了么 Have you found a\nplace to live?\n1\n3 4\n7 2\n5 1\n2\nSession-level semantic vertex Utterance-level semantic vertex\n3\nSpeak 1:嗯，我 提前订好了酒店。 [Yes, I have booked a hotel in advance.] Speak 1: 假期准备去爬黄山[I’m going to climb Huangshan Mountain on holiday.] Speak 2:哇！准备在山上找房子过夜么？ [WOW! Are you going to find a house on the mountain for the night?]\nContext Response\n有时间找我玩 Visit me when\nyou are free\n好久没见你 Haven't seen you for a long time\n明天去长沙 Go to Changsha\ntomorrow\n预定了酒店 Have booked a hotel room\nOne co-occurrence of two vertices Edge\n6\n找到房子了么 Have you found a\nplace to live?\n预定了酒店 Have booked a\nhotel room\nPhrase associated with utterance-level vertex\nFigure 2: Response generation grounded on a dialog structure graph.\nAs shown in Figure 1, with well-trained DVAEGNN, we build the dialog structure graph by three steps. First, we map all dialog sessions to utterance-level and session-level vertices, as shown in Figure 1 (b); Second, we calculate cooccurrence statistics of mapped vertices for all dialog sessions, as shown in Figure 1 (c).3 Finally, we build edges among vertices based on all collected co-occurrence statistics to form the dialog structure graph, as shown in Figure 1 (d).\nTo prove the effectiveness of the discovered structure, we propose a hierarchical reinforcement learning (RL) based graph grounded conversational system (GCS) to leverage it for conversation generation. As shown in Figure 2, given a dialog context, GCS first maps it to a utterance-level vertex, and then learns to walk over graph edges, and finally selects a contextual appropriate utterance-level vertex to guide response generation at each turn.\nOur contribution includes: (1) we identify the task of unsupervised dialog structure graph discovery in open-domain dialogs. (2) we propose a novel model, DVAE-GNN, for hierarchical dialog struc-\n3Co-occurrence means that two utterance-level vertices are mapped by two adjacent utterances in a session.\nture graph discovery. Experimental results on two benchmark corpora demonstrate that we can discover meaningful dialog structure, the use of GNN is crucial to dialog structure discovery, and the graph can improve dialog coherence significantly."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Dialog structure learning for task-oriented dialogs",
      "text" : "There are previous work on discovering humanreadable dialog structure for task-oriented dialogs via hidden Markov models (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014) or variational auto-encoder (Shi et al., 2019). However, the number of their dialog states is limited to only dozens or hundreds, which cannot cover fine-grained semantics in chitchat. Moreover, our method can discover a hierarchical dialog structure, which is different from the non-hierarchical dialog structures in most previous work."
    }, {
      "heading" : "2.2 Knowledge aware conversation generation",
      "text" : "There are growing interests in leveraging knowledge bases for generation of more informative responses (Moghe et al., 2018; Dinan et al., 2019; Liu et al., 2019; Xu et al., 2020c,a). In this work, we employ a dialog-modeling oriented graph built from dialog corpora, instead of a external knowledge base, in order to facilitate multi-turn dialog modeling."
    }, {
      "heading" : "2.3 Latent variable models for chitchat",
      "text" : "Recently, latent variables are utilized to improve diversity (Serban et al., 2017; Zhao et al., 2017; Gu et al., 2019; Gao et al., 2019; Ghandeharioun et al., 2019), control responding styles (Zhao et al., 2018; Li et al., 2020) and incorporate knowledge (Kim et al., 2020) in dialogs. Our work differs from\n4ai.baidu.com/tech/nlp basic/dependency parsing\nAlgorithm 1 Phrase extraction Input: An utterance U Output: A set of phrases E extracted from U 1: Obtain a dependency parse tree T for U ;4\n2: Get all the head words HED that are connected to ROOT node, and all the leaf nodes in T (denoted as L); 3: for each leaf node in |L| do 4: Extract a phrase consisting of words along the tree from HED to current leaf node, denoted as ei; 5: If ei is a verb phrase, then append it into E; 6: end for 7: return E\ntheirs in that: (1) we focus on open-domain dialog structure discovery. (2) we use discrete latent variables to model dialog states instead of dense continuous ones in most previous work."
    }, {
      "heading" : "3 Our Approach",
      "text" : ""
    }, {
      "heading" : "3.1 Problem Definition",
      "text" : "Given a corpus D that contains |D| dialog sessions {X1, X2, ..., X|D|}, where each dialog session X consists of a sequence of c utterances, and X = [x1, ..., xc]. The objective is to discover a two-layer dialog structure graph G = {V, E} from all dialog sessions inD, where V is the vertex set and E is the edge set. Specifically, V consists of two types, vsm (1 ≤ m ≤ M ) for session-level vertices (topics) and vun (1 ≤ n ≤ N ) for utterance-level vertices. E contains three types: edges between two sessionlevel vertices (denoted as Sess-Sess edges), edges between two utterance-level vertices (denoted as Utter-Utter edges), and edges between an utterancelevel vertex and its parent session-level vertices (denoted as Sess-Utter edges).\nFigure 3 shows the proposed DVAE-GNN framework. It contains two procedures, vertex recognition that maps utterances and sessions to vertices\n(as the role of recognition module in VAE (Kingma and Welling, 2014)), and utterance reconstruction that regenerates all utterances in sessions (as the role of decoding module in VAE)."
    }, {
      "heading" : "3.2 Graph Initialization",
      "text" : "Vertex Initialization. Theoretically, we can cold start the representation learning of vertices in dialog structure graph. In practice, to accelerate the learning procedure, we warm start each utterancelevel vertex representation with the combination of two parts: one discrete latent variable and one distinct phrase. The associated phrase with each utterance-level vertex provides prior semantic knowledge for utterance-level vertex representation, which is beneficial for reducing the learning difficulty. Specifically, we first extract distinct phrases from all dialog utterances with Algorithm 1. Then we choose the top-N most frequent extracted phrases (the same number as utterance-level vertices), and then randomly match utterance-level vertices and the phrases in pairs during initialization. Notice that the association relations are not changed afterwards.\nFormally, we use Λs and Λx to represent the hidden representation matrix of discrete sessionlevel and utterance-level vertices respectively. The calculation can be shown as follows:\nΛs[m] =W svsm (1)\nΛx[n] = [e(phn);W uvun], (2)\nwhere Λs[m] denotes the representation vector of m-th session-level vertex, Λx[n] denotes the representation vector of n-th utterance-level vertex, vsm and v u n are one-hot vectors of discrete vertices, e(phn) denotes the representation vector of the\nassociated phrase phn with vun, W u and W s are parameters, and “;” denotes concatenation operation. Specifically, for phrase representation, we first feed word sequence in the phrase to an RNN encoder and obtain their hidden vectors. Then we compute the average pooling value of these hidden vectors as e(phn). Edge Initialization We build an initial Utter-Utter edge between two utterance-level vertices when their associated phrases can be extracted sequentially from two adjacent utterances in the same dialog session."
    }, {
      "heading" : "3.3 Vertex Recognition",
      "text" : "Utterance-level Vertex Recognition. For each utterance xi in a dialog session, we map it to an utterance-level vertex. Specifically, we first encode the utterance xi with an RNN encoder to obtain its representation vector e(xi). Then, we calculate the posterior distribution of the mapped utterance-level vertex, zi, by a feed-forward neural network (FFN):\nzi ∼ q(z|xi) = softmax(Λxe(xi)). (3)\nFinally, we obtain the mapped utterance-level vertex, zi, by sampling from the posterior distribution with Gumbel-Softmax (Jang et al., 2017). Here, we can obtain an utterance-level vertex sequence after mapping each utterance in one dialog session, where the sequence is utilized for sessionlevel vertex recognition. Session-level Vertex Recognition. We assume that each session-level vertex corresponds to a group of similar utterance-level vertex sequences that are mapped by different dialog sessions. And these similar sequences might have overlapped utterance-level vertices. To leverage this locally overlapping vertex information for encouraging mapping similar utterance-level vertex sequences to similar session-level vertices, we employ graph neural network to model complex relations among vertices for session-level vertex recognition. Specifically, we utilize a three-layer graph convolution network (GCN) over Utter-Utter edges to calculate structure-aware utterance-level semantics. The calculation is defined by:\nhjvun = σ j(\n∑\nvu n′∈N (vun)\nhj−1vu n′ ), (4)\nwhere hjvun denotes the j-th layer structure-aware representation for the n-th utterance-level vertex\nvun. σ j is the sigmoid activation function for the j-th layer, and N (vun) is the set of utterancelevel neighbors of vun in the graph. Here, we can obtain a structure-aware semantic sequence [h3vuz1 ,h 3 vuzi , ...,h3vuzc ], where h3vuzi represents the final structure-aware representation of i-th mapped utterance-level vertex, vuzi .\nThen, we feed the structure-aware semantic sequence to an RNN encoder, denoted as the vertexsequence encoder, to obtain the structure-aware session representation e(z1,...,c). We calculate the posterior distribution of the mapped session-level vertex, g, as follows:\ng ∼ q(g|z1,...,c) = softmax(Λse(z1,...,c)). (5) Then, we obtain the mapped session-level vertex, g, by sampling from the session-level posterior distribution with Gumbel-Softmax."
    }, {
      "heading" : "3.4 Utterance Reconstruction",
      "text" : "We reconstruct all utterances in the dialog session by feeding these mapped vertices into an RNN decoder (denoted as the reconstruction decoder). Specifically, to regenerate utterance xi, we concatenate the representation vector of mapped utterancelevel vertex Λx[zi] and the representation vector of the mapped session-level vertex Λs[g], as the initial hidden state of the reconstruction decoder.\nFinally, we optimize the DVAE-GNN model by maximizing the variational lower-bound (ELBO) (Kingma and Welling, 2014). Please refer to Appendix D for more details."
    }, {
      "heading" : "3.5 Graph Construction",
      "text" : "After training DVAE-GNN, we construct the dialog structure graph with well-trained DVAE-GNN by three steps, as shown in Figure 1. Specifically, we first map all dialog sessions in corpus to vertices by Equation 3 and 5.\nThen, we collect co-occurrence statistics of these mapped vertices. Specifically, we count the total mapped times for each session-level vertex, denoted as #(vsi ), and those for each utterance-level vertex, denoted as #(vuj ). Furthermore, we collect the co-occurrence frequency of a session-level vertex and an utterance-level vertex that are mapped by a dialog session and an utterance in it respectively, denoted as #(vsi , v u j ). Moreover, we collect the co-occurrence frequency of two utterance-level vertices that are sequentially mapped by two adjacent utterances in a dialog session, denoted as #(vuj , v u k ).\nFinally, we build edges between vertices based on these co-occurrence statistics. We first build a directed Utter-Utter edge from vuj to v u k if the bi-gram transition probability #(vuj , v u k )/#(v u j ) is above a threshold αuu. Then, we build a bidirectional SessUtter edge between vuj and v s k if the probability #(vsi , v u j )/#(v u j ) is above a threshold α\nsu. Moreover, we build a directed Sess-Sess edge from vsi to vso, if #(v s i , v s o)/#(v s i ) is above a threshold α\nss, where the first item #(vsi , v s o) is the number of utterance-level vertices that are connected to both session-level vertices. Here, Sess-Sess edges are dependent on Sess-Utter edges."
    }, {
      "heading" : "3.6 Graph Grounded Dialog Generation",
      "text" : "To prove the effectiveness of the discovered structure for coherent dialog generation, we utilize a graph grounded conversation system (GCS) following (Xu et al., 2020a). Different from single-layer policy in Xu et al.(Xu et al., 2020a), we present a hierarchical policy for two-level vertex selection. The GCS contains three modules: (1) a dialog context understanding module that maps given dialog context (the previous two utterances) to an utterance-level vertex (called as hit utterance-level vertex) in the graph with well-trained DVAE-GNN, (2) a hierarchical policy that learns to walk over one-hop graph edges (for dialog coherence) to select an utterance-level vertex to serve as response content, and (3) a response generator that generate an appropriate response based on the selected utterance-level vertex. Specifically, a session-level sub-policy first selects a session-level vertex as current dialog topic. Then, an utterance-level subpolicy selects an utterance-level vertex from current dialog topic’s child utterance-level vertices.\nSession-level sub-policy Let Agsl denote the set of session-level candidate actions at time step l. It consists of all parent session-level vertices of the hit utterance-level vertex. Given current RL state sl at the time step l, the session-level sub-policy µg selects an appropriate session-level vertex from Agsl as the current dialog topic. Specifically, µg is formalized as follows:\nµg(sl, v s cgj ) =\nexp(esl TΛs[c g j ])\n∑Ngl k=1 exp(esl TΛs[c g k]) ,\nwhere esl is the aforementioned RL state representation, cgj the j-th session-level vertex in A g sl , and Ngl is the number of session-level vertices in A g sl .\nUtterance-level sub-policy Let Ausl denote the set of utterance-level candidate actions at time step\nl. It consists of utterance-level vertices that are connected to the vertex of current dialog topic. Given current state sl at the time step l, the utterancelevel sub-policy µu selects an optimal utterancelevel vertex from Ausl . Specifically, µu is defined as follows:\nµu(sl, v u cuj ) =\nexp(esl TΛx[c u j ])\n∑Nul k=1 exp(esl TΛx[cuk ]) .\nHere, esl is the aforementioned RL state representation, cuj is the j-th utterance-level vertex in Ausl , and Nul is the number of utterance-level candidate vertices in Ausl . With the distribution calculated by the above equation, we utilize GumbelSoftmax to sample an utterance-level vertex from Ausl , to provide response content for response generator, which is a Seq2Seq model with attention mechanism.\nTo train RL, we use a set of rewards including utterance relevance, utter-topic closeness, and repetition penalty. For the session-level sub-policy, its reward rg is the average rewards from the utterancelevel sub-policy during current dialog topic. The reward for the utterance-level sub-policy, ru, is a weighted sum of the below-mentioned factors. The default values of weights are set as [60, 0.5, -0.5]. 5\ni) Utterance relevance We choose the classical multi-turn response selection model, DAM in (Zhou et al., 2018), to calculate utterance relevance. We expect the generated response is coherent to dialog context.\nii) Utter-topic closeness The selected utterancelevel vertex vuj should be closely related to current topic vsi . And we use the #(v s i , v u j )/#(v u j ) in Section 3.5 as the utter-topic closeness score. iii) Repetition penalty This factor is 1 when the selected utterance-level vertex shares more than 60% words with one of contextual utterance, otherwise 0. We expect that the selected utterance-level vertices are not only coherent, but also diverse.\nFurther implementation details can be found in the Appendix C."
    }, {
      "heading" : "4 Experiments for Dialog Structure Graph Discovery",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets and Baselines",
      "text" : "We evaluate the quality of dialog structure graph discovered by our method and baselines on two\n5We optimize these weights by grid search.\nbenchmark datasets: (1) Weibo (Li and Yan, 2018): this is a Chinese multi-turn tweet-style corpora. After data cleaning, we obtain 3.1 million sessions for training, 10k sessions for validation and 10k sessions for testing. (2) Douban (Wu et al., 2017): we use the original multi-turn dialog corpus, and obtain 2.3 million sessions for training, 10k sessions for validation and 10k sessions for testing. For the Weibo or Douban corpus, each dialog session has 4 sentences on average, and each sentence contains about 7 or 14 words respectively. The discovered dialog structure graph on Weibo corpus contains 1,641,238 utterance-level vertices, 6000 session-level vertices and 11,561,007 edges. And the discovered dialog structure graph on Douban corpus contains 1,768,720 utterance-level vertices, 5500 session-level vertices and 6,117,159 edges. The number of utterance-level vertices is equal to the number of extracted phrase number in corpus and session-level vertices is determined by grid search based on the NLL metric in Section 4.2.\nIn this work, we select DVRNN (Shi et al., 2019) as a baseline, since there is few previous study on unsupervised open-domain dialog structure discovery. DVRNN is the SOTA unsupervised method in discovering dialog structure in task-oriented dialogs, which outperforms other hidden Markov based methods by a large margin (Shi et al., 2019). We rerun the original source codes.6 Notice that, to suite the setting of open-domain dialog and also consider the limit of our 16G GPU memory (we set batch size as 32 to ensure training efficiency), we\n6github.com/wyshi/Unsupervised-Structure-Learning\nset the number of dialog states as 50 (originally it is 10).7 We also evaluate the quality of the initialized graph (denoted as Phrase Graph) that consists of only phrases (as vertices) and initial edges (between phrases) in Section 3.2. For more details, please refer to Appendix A.1."
    }, {
      "heading" : "4.2 Evaluation Metrics",
      "text" : "We evaluate discovered dialog structure graph with both automatic evaluation and human evaluation. For automatic evaluation, we use two metrics to evaluate the performance of reconstruction: (1) NLL is the negative log likelihood of dialog utterances; (2) BLEU-1/2 measures how much that reconstructed sentences contains 1/2-gram overlaps with input sentences (Papineni et al., 2002). The two metrics indicate how well the learned dialog structure graph can capture important semantic information in dialog dataset.\nFurther, we manually evaluate the quality of edges and vertices in the graph. For edges, (1) S-U Appr. for multi-turn dialog coherence. It measures the appropriateness of Sess-Utter edges, where these edges provide crucial prior information to ensure multi-turn dialog coherence (see results in Section 5.4). “1” if an utterance-level vertex is relevant to its session-level vertex (topic), otherwise “0”. (2) U-U Appr. for single-turn dialog coherence: It measures the quality of Utter-Utter edges between two utterance-level vertices, where these edges provide crucial prior information to\n7We ever tried to modify their codes to support the learning of a large number of dialog states (up to 30k). But its performance is even worse than original code with 50 states.\nensure single-turn dialog coherence. It is “1” if an Utter-Utter edge is suitable for responding, otherwise “0”. Notice that we don’t evaluate the quality of Sess-Sess edges because Sess-Sess edges are dependent on the statistics of Sess-Utter edges.\nMeanwhile, for vertices, we evaluate Sessionlevel Vertex Quality (Sess.V.-Qual.). Ideally, a session-level vertex (topic) should be mapped by dialog sessions that share high similarity. In other words, we can measure the quality of a sessionlevel vertex by evaluating the similarity of semantics between two sessions that are mapped to it. It is “2” if the two sessions mapped to the same sessionlevel vertex are about the same or highly similar topic, ”0” if the two sessions contains different topic, otherwise “1”. Specifically, during evaluation, we provide typical words of each topic by calculating TF-IDF on utterances that are mapped to it. High “Sess.V.-Qual.” is beneficial to conduct topic management for coherent multi-turn dialogs. Note that we don’t evaluate utterance-level vertex quality since it is too fine-grained for annotators to determine whether two utterances that are mapped to a utterance-level vertex are “highly-similar”.\nFor human evaluation, we sample 300 cases and invite three annotators from a crowd-sourcing platform to evaluate each case.8 Notice that all system identifiers are masked during human evaluation."
    }, {
      "heading" : "4.3 Experiment Results",
      "text" : "As shown in Table 1, DVAE-GNN significantly outperforms DVRNN, in terms of all the metrics (sign test, p-value < 0.01) on the two datasets. It demonstrates that DVAE-GNN can better discover meaningful dialog structure graph. Specifically, DVAEGNN obtains the best results in terms of NLL and BLEU-1/2, which shows that DVAE-GNN can better capture important semantic information in comparison with DVRNN. Meanwhile, DVAE-GNN also surpasses all baselines in terms of “U-U Appr.” and “S-U Appr.”. It indicates that our discovered dialog structure graph has higher-quality edges and can better facilitate coherent dialog generation.\nFurthermore, we conduct ablation study. Specifically, to evaluate the contribution of GNN, we remove GNN from DVAE-GNN, denoted as DVAEGNN w/o GNN. We see that its performance drop sharply in terms of “S-U Appr.” and “Sess.V.Qual.”. It demonstrates that GNN can better incorporate the structure information (complex relations\n8test.baidu.com\namong vertices) into session-level vertex representation learning. Moreover, to evaluate the contribution of phrases to utterance-level vertex representation, we remove phrases, denoted as DVAE-GNN w/o phrase. We see that its scores in terms of all the metrics drops sharply, especially the three human evaluation metrics. The reason is that it’s difficult to learn high-quality utterance-level vertex representation from a large amount of fine-grained semantic content in open-domain dialogs without any prior information. The Kappa value is above 0.4, showing moderate agreement among annotators.\nTwo sample parts of the discovered dialog structure graph can be found in Appendix B."
    }, {
      "heading" : "5 Experiments for Graph Grounded Dialog Generation",
      "text" : "To confirm the benefits of discovered dialog structure graph for coherent conversation generation, we conduct experiments on the graph discovered from Weibo corpus. All the systems (including baselines) are trained on Weibo corpus."
    }, {
      "heading" : "5.1 Models",
      "text" : "We carefully select the following six baselines. MMPMS It is the multi-mapping based neural open-domain conversational model with posterior mapping selection mechanism (Chen et al., 2019), which is a SOTA model on the Weibo Corpus. MemGM It is the memory-augmented opendomain dialog model (Tian et al., 2019), which learns to cluster U-R pairs for response generation. HRED It is the hierarchical recurrent encoderdecoder model (Serban et al., 2016). CVAE It is the Conditional Variational AutoEncoder based neural open-domain conversational model (Zhao et al., 2017). VHCR-EI This variational hierarchical RNN model can learn hierarchical latent variables from open-domain dialogs (Ghandeharioun et al., 2019). It is a SOTA dialog model with hierarchical VAE. DVRNN-RL It discovers dialog structure graph for task-oriented dialog modeling (Shi et al., 2019). GCS It is our proposed dialog structure graph grounded dialog system with hierarchical RL. GCS w/ UtterG It is a simplified version of GCS that just uses the utterance-level graph and utterance-level sub-policy. GCS w/ Phrase Graph It is a simplified version of GCS that just uses the phrase graph and utterancelevel sub-policy.\nWe use the same user simulator for RL training of DVRNN-RL, GCS and GCS w/ UtterG. Here, we use the original MMPMS as user simulator because it achieves the best result on the Weibo Corpus. The user simulator is pre-trained on dialog corpus and not updated during policy training. We use the original source codes for all the baselines and the simulator. Further details about baselines and GCS can be found in Appendix A.2.\nWe conduct model-human dialogs for evaluation. Given a model, we first randomly select an utterance (the first utterance in a session) from test set for the model side to start the conversations with a human turker. Then the human is asked to converse with the selected model till 8 turns are reached. Finally, we obtain 50 model-human dialogs for multi-turn evaluation. Then we randomly sample 200 U-R pairs from the above dialogs for single-turn evaluation."
    }, {
      "heading" : "5.2 Evaluation Metrics",
      "text" : "Since the proposed system does not aim at predicting the highest-probability response at each turn, but rather the long-term success of a dialog (e.g., coherence), we do not employ BLEU (Papineni et al., 2002) or perplexity for evaluation. We use three multi-turn evaluation metrics and three singleturn metrics. For human evaluation, we invite three annotators to conduct evaluation on each case, and we ask them to provide 1/0 (Yes or No) scores for most of the metrics. Moreover, for multi-turn coherence, we first ask the annotators to manually segment a dialog by topics and then conduct evaluation on each session. A session refers to a dialog fragment about one topic. Notice that system identifiers are masked during human evaluation.\nMulti-turn Metrics. We use the following metrics: (1) Multi-turn Coherence (Multi.T.-Coh.) It measures the coherence within a session. Common incoherence errors in a session include amphora errors across utterances and information inconsistency. “0” means that there are more than two incoherence errors in a session. “1” means that there are only one error. “2” means that there are no errors. Finally, we compute the average score of all the sessions. (2) Dialog engagement (Enga.) This metric measures how interesting a dialogs is. It is “1” if a dialog is interesting and the human is willing to continue the conversation, otherwise “0”. (3) Length of high-quality dialog (Length) A high-quality dialog ends if the model tends to produce dull responses or two consecutive utterances are highly overlapping (Li et al., 2016b).\nSingle-turn Metrics. We use the following metrics: (1) Single-turn Coherence (Single.T.-Coh.) “0” if a response is inappropriate as an reply, otherwise “1”; (2) Informativeness (Info.) “0” if a response is a “safe” response, e.g. “I don’t know”, or it is highly overlapped with context, otherwise “1”; (3) Distinct (Dist.-i) It is an automatic metric for response diversity (Li et al., 2016a)."
    }, {
      "heading" : "5.3 Experiment Results",
      "text" : "As shown in Table 2, GCS significantly outperforms all the baselines in terms of all the metrics except “Length-of-dialog” (sign test, p-value < 0.01). It indicates that GCS can generate more coherent, informative and engaging dialogs. Specifically, our system’s two sub-policies strategy on the dialog structure graph enables more coherent dialog flow control than hierarchical latent variable based VHCR-EI model that performs the best among\nbaselines, as indicated by “Multi.T.-Coh.”. Moreover, our high-quality edges between utterancelevel vertices (measured by the metric “U-U Appr.” in Table 1) help GCS to achieve higher single-turn coherence score than DVRNN-RL, as indicated by “Single.T.-Coh.”. In addition, GCS, VHCR-EI, MMPMS and CVAE can obtain better performance in terms of “Info.”, indicating that latent variable can effectively improve response informativeness. The Kappa value is above 0.4, showing moderate agreement among annotators."
    }, {
      "heading" : "5.4 Case Study of Conversation Generation",
      "text" : "Figure 4 shows a sample dialog between our system “GCS” and a human. We see that our system can generate a coherent, engaging and informative multi-turn dialog. For an in-depth analysis, we manually segment the whole dialog into two sessions. It can be seen that the first session is about “meeting appointment”, and it contains a reasonable dialog logic, I will have a holiday → I will arrive→ wait for you at home→ look forward to a big meal. And the second session is about “joking between friends”, and it also contains a reasonable logic, you are beautiful → flattering me → I am sorry.\nAblation Study. In order to evaluate the contribution of session-level vertices, we run GCS with an utterance-level dialog structure graph, denoted as “GCS w/ UtterG”. Results in Table 2 show that its performance in terms of “Multi.T.-Coh.” and “Enga.” drops sharply. It demonstrates the contribution of our hierarchical dialog structure graph for enhancing dialog coherence and dialog engagement. The possible reason for the inferior performance of “GCS w/ UtterG” is that the removal of session-level vertices harms the capability of selecting coherent utterance-level vertex sequence."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we conduct unsupervised discovery of discrete dialog structure from chitchat corpora. Further, we try to formalize the structure as a twolayer directed graph. To discover the dialog structure, we present an unsupervised model, DVAEGNN, which integrates GNN into DVAE to model complex relations among dialog states for more effective dialog structure discovery. Experimental results demonstrate that DVAE-GNN can discover meaningful dialog structure, and the use of dialog structure as background knowledge can significantly improve multi-turn dialog coherence."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We are grateful for the support from Ying Yu. This work is supported by the National Key Research and Development Project of China (No.2018AAA0101900) and the National Natural Science Foundation of China (NSFC) via grant 61976072."
    }, {
      "heading" : "B Case Study of Dialog Structure Graph Discovery",
      "text" : "Figure 5 shows a part of the unified dialog structure graph that is discovered from the Weibo corpus. Each yellow-colored circle in this figure represents a session-level vertex with expert interpreted meanings based on the information of top words (from phrases of utterance-level vertices belonging to this session-level vertex) ranked by TF/IDF. Each green-colored rectangle represents an utterance-level vertex. The directed-arrows between utterance-level vertices represent dialog transitions between states, and the utterance-level vertices within blue dotted-lines are about the same session-level vertex (topic).\nWe observe reasonable dialog structures in Figure 5. It captures the major interaction logic in dialogs about the topic “go traveling”, traveling is really good→ you decide where to travel→ let’s\n11ai.baidu.com/tech/nlp basic/dependency parsing 12paddlepaddle.org.cn/\ngo to Huangshan→ comments about Huangshan. Furthermore, it also captures the major logic in dialogs about the topic “want a boyfriend”, need a boyfriend→ why? → he can accompany me to celebrate the festival. Moreover, it captures a dialog topic transition between the topic “go trveling” and another topic “want a boyfriend”.\nFigure 6 shows another part of the unified dialog structure graph that discovered from the Weibo corpus."
    }, {
      "heading" : "C GCS with RL",
      "text" : "In the following, we will elaborate the details of GCS.\nC.1 Dialog Context Understanding\nGiven a dialog context (the last two utterances), we first map it to the graph by recognizing the most related utterance-level vertex with the well-trained DVAE-GNN. Here, the recognized utterance-level vertex is denoted as the hit utterance-level vertex.\nFor policy learning, we build current RL state sl at time step l by collecting dialog context (the last two utterances), previously selected session-level vertex sequence, and previously selected utterancelevel vertex sequence. Here, we first utilize three independent RNN encoders to encode them respectively, and then concatenate these three obtained representation vectors, to obtain the representation of the RL state, esl .\nC.2 Response Generator\nThe response generator is a pre-trained Seq2Seq model with attention mechanism, whose parameters are not updated during RL training. Specifically, we take the last user utterance, and the associated phrase of the selected utterance-level vertex as input of the generator."
    }, {
      "heading" : "D Training Objective for DVAE-GNN",
      "text" : "The proposed DVAE-GNN model consists of two procedures. In the recognition procedure, for a dialog session X that consists of a sequence of c utterances, X = [x1, ..., xc], in recognition procedure, we first recognize an utterance-level vertex zi for each utterance xi, and then recognize a sessionlevel vertex g based on all recognized utterancelevel vertices, [z1, ..., zc]. In reconstruction procedure, we regenerate all the utterances in X with the predicted vertices Z = [z1, ..., zc, g]. Here,\nwe optimize the proposed DVAE-GNN model by maximizing the variational lower-bound:\nEq(Z|X)[log p(X|Z)]−KL(q(Z|X)‖p(Z)),\nwhere p(Z) is the prior uniform distribution of Z. Specifically, we approximate the first item in the above equation by sampling Z from q(Z|X) and calculate the the negative log-likelihood reconstruction loss. For the second item, we calculate it by:\nc∑\nj=1\nKL[q(zj |xj)‖p(zj)] +KL[q(g|z1,...,c)‖p(g)],\nwhere we can calculate each sub-item straightly since z1,...,c and g follow discrete distribution. Below, we provide the derivation of the second item.\n14\n1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349\n1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399\nACL-IJCNLP 2021 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE.\nKL[q(Z|X)‖p(Z)] = ∑\nZ\n[log q(Z|X)− log p(Z)]q(Z|X)\n= ∑\nz1,...,c,g\n{ c∑\nj=1\n[log q(zj |xj)− log p(zj)] + [log q(g|z1,...,c)−\nlog p(g)]} c∏\ni=1\nq(zi|xi)q(g|z1,...,c)\n= c∑\nj=1\n∑\nz1,...,c,g\n[log q(zj |xj)− log p(zj)]q(zj |xj) c∏\ni=1,i 6=j q(zi|xi)q(g|z1,...,c)\n+ ∑\nz1,...,c,g\n[log q(g|z1,...,c)− log p(g)]q(g|z1,...,c) c∏\ni=1\nq(zi|xi)\n=\nc∑\nj=1\n∑\nzj\n[log q(zj |xj)− log p(zj)] ∑\nz[1,...,c]−j ,g\nq(zj |xj) c∏\ni=1,i 6=j q(zi|xi)q(g|z1,...,c)\n+ ∑\ng\n[log q(g|z1,...,c)− log p(g)]q(g|z1,...,c) ∑\nz1,...,c\nc∏\ni=1\nq(zi|xi)\n= c∑\nj=1\nKL[q(zj |xj)‖p(zj)] ∑\nz[1,...,c]−j ,g\nc∏\ni=1,i 6=j q(zi|xi)q(g|z1,...,c)\n+KL[q(g|z1,...,c)‖p(g)] ∑\nz1,...,c\nc∏\ni=1\nq(zi|xi)\n= c∑\nj=1\nKL[q(zj |xj)‖p(zj)] +KL[q(g|z1,...,c)‖p(g)]"
    } ],
    "references" : [ {
      "title" : "Generating multiple diverse responses with multi-mapping and posterior mapping selection",
      "author" : [ "Chaotao Chen", "Jinhua Peng", "Fan Wang", "Jun Xu", "Hua Wu." ],
      "venue" : "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelli-",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning the structure of task-oriented conversations from the corpus of indomain dialogs",
      "author" : [ "Ananlada Chotimongkol." ],
      "venue" : "Ph.D. thesis, Carnegie Mellon University.",
      "citeRegEx" : "Chotimongkol.,? 2008",
      "shortCiteRegEx" : "Chotimongkol.",
      "year" : 2008
    }, {
      "title" : "Wizard of wikipedia: Knowledge-powered conversational",
      "author" : [ "Emily Dinan", "Stephen Roller", "Kurt Shuster", "Angela Fan", "Michael Auli", "Jason Weston" ],
      "venue" : null,
      "citeRegEx" : "Dinan et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2019
    }, {
      "title" : "A discrete CVAE for response generation on short-text conversation",
      "author" : [ "Jun Gao", "Wei Bi", "Xiaojiang Liu", "Junhui Li", "Guodong Zhou", "Shuming Shi." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
      "citeRegEx" : "Gao et al\\.,? 2019",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Approximating interactive human evaluation with self-play for open-domain dialog systems",
      "author" : [ "Asma Ghandeharioun", "Judy Hanwen Shen", "Natasha Jaques", "Craig Ferguson", "Noah Jones", "Àgata Lapedriza", "Rosalind W. Picard." ],
      "venue" : "Advances in",
      "citeRegEx" : "Ghandeharioun et al\\.,? 2019",
      "shortCiteRegEx" : "Ghandeharioun et al\\.",
      "year" : 2019
    }, {
      "title" : "Dialogwae: Multimodal response generation with conditional wasserstein autoencoder",
      "author" : [ "Xiaodong Gu", "Kyunghyun Cho", "Jung-Woo Ha", "Sunghun Kim." ],
      "venue" : "7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA,",
      "citeRegEx" : "Gu et al\\.,? 2019",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2019
    }, {
      "title" : "Categorical reparameterization with gumbel-softmax",
      "author" : [ "Eric Jang", "Shixiang Gu", "Ben Poole." ],
      "venue" : "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net.",
      "citeRegEx" : "Jang et al\\.,? 2017",
      "shortCiteRegEx" : "Jang et al\\.",
      "year" : 2017
    }, {
      "title" : "Recommendation as a communication game: Self-supervised bot-play for goal-oriented dialogue",
      "author" : [ "Dongyeop Kang", "Anusha Balakrishnan", "Pararth Shah", "Paul Crook", "Y-Lan Boureau", "Jason Weston." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical",
      "citeRegEx" : "Kang et al\\.,? 2019",
      "shortCiteRegEx" : "Kang et al\\.",
      "year" : 2019
    }, {
      "title" : "Sequential latent knowledge selection for knowledge-grounded dialogue",
      "author" : [ "Byeongchang Kim", "Jaewoo Ahn", "Gunhee Kim." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020.",
      "citeRegEx" : "Kim et al\\.,? 2020",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2020
    }, {
      "title" : "Autoencoding variational bayes",
      "author" : [ "Diederik P. Kingma", "Max Welling." ],
      "venue" : "2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Welling.,? 2014",
      "shortCiteRegEx" : "Kingma and Welling.",
      "year" : 2014
    }, {
      "title" : "Optimus: Organizing sentences via pre-trained modeling",
      "author" : [ "Chunyuan Li", "Xiang Gao", "Yuan Li", "Baolin Peng", "Xiujun Li", "Yizhe Zhang", "Jianfeng Gao" ],
      "venue" : null,
      "citeRegEx" : "Li et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Li et al\\.,? 2016a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep reinforcement learning for dialogue generation",
      "author" : [ "Jiwei Li", "Will Monroe", "Alan Ritter", "Dan Jurafsky", "Michel Galley", "Jianfeng Gao." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1192–",
      "citeRegEx" : "Li et al\\.,? 2016b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Overview of the nlpcc 2018 shared task: Multi-turn human-computer conversations",
      "author" : [ "Juntao Li", "Rui Yan." ],
      "venue" : "CCF International Conference on Natural Language Processing and Chinese Computing, pages 446–451. Springer.",
      "citeRegEx" : "Li and Yan.,? 2018",
      "shortCiteRegEx" : "Li and Yan.",
      "year" : 2018
    }, {
      "title" : "Knowledge aware conversation generation with explainable reasoning over augmented graphs",
      "author" : [ "Zhibin Liu", "Zheng-Yu Niu", "Hua Wu", "Haifeng Wang." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Towards exploiting background knowledge for building conversation systems",
      "author" : [ "Nikita Moghe", "Siddhartha Arora", "Suman Banerjee", "Mitesh M. Khapra." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Moghe et al\\.,? 2018",
      "shortCiteRegEx" : "Moghe et al\\.",
      "year" : 2018
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia,",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Unsupervised modeling of Twitter conversations",
      "author" : [ "Alan Ritter", "Colin Cherry", "Bill Dolan." ],
      "venue" : "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 172–180,",
      "citeRegEx" : "Ritter et al\\.,? 2010",
      "shortCiteRegEx" : "Ritter et al\\.",
      "year" : 2010
    }, {
      "title" : "The probabilistic relevance framework: BM25 and beyond",
      "author" : [ "Stephen Robertson", "Hugo Zaragoza." ],
      "venue" : "Now Publishers Inc.",
      "citeRegEx" : "Robertson and Zaragoza.,? 2009",
      "shortCiteRegEx" : "Robertson and Zaragoza.",
      "year" : 2009
    }, {
      "title" : "Building end-to-end dialogue systems using generative hierarchical neural network models",
      "author" : [ "Iulian Vlad Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron C. Courville", "Joelle Pineau." ],
      "venue" : "Proceedings of the Thirtieth AAAI Conference on Arti-",
      "citeRegEx" : "Serban et al\\.,? 2016",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2016
    }, {
      "title" : "A hierarchical latent variable encoder-decoder model for generating dialogues",
      "author" : [ "Iulian Vlad Serban", "Alessandro Sordoni", "Ryan Lowe", "Laurent Charlin", "Joelle Pineau", "Aaron C. Courville", "Yoshua Bengio." ],
      "venue" : "Proceedings of the Thirty-First AAAI",
      "citeRegEx" : "Serban et al\\.,? 2017",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2017
    }, {
      "title" : "Neural responding machine for short-text conversation",
      "author" : [ "Lifeng Shang", "Zhengdong Lu", "Hang Li." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan-",
      "citeRegEx" : "Shang et al\\.,? 2015",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2015
    }, {
      "title" : "Unsupervised dialog structure learning",
      "author" : [ "Weiyan Shi", "Tiancheng Zhao", "Zhou Yu." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1",
      "citeRegEx" : "Shi et al\\.,? 2019",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2019
    }, {
      "title" : "Reinforcement learning: An introduction",
      "author" : [ "Richard S Sutton", "Andrew G Barto." ],
      "venue" : "MIT Press.",
      "citeRegEx" : "Sutton and Barto.,? 2018",
      "shortCiteRegEx" : "Sutton and Barto.",
      "year" : 2018
    }, {
      "title" : "Learning to abstract for memoryaugmented conversational response generation",
      "author" : [ "Zhiliang Tian", "Wei Bi", "Xiaopeng Li", "Nevin L. Zhang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Tian et al\\.,? 2019",
      "shortCiteRegEx" : "Tian et al\\.",
      "year" : 2019
    }, {
      "title" : "Proactive human-machine conversation with explicit conversation goal",
      "author" : [ "Wenquan Wu", "Zhen Guo", "Xiangyang Zhou", "Hua Wu", "Xiyuan Zhang", "Rongzhong Lian", "Haifeng Wang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Com-",
      "citeRegEx" : "Wu et al\\.,? 2019",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots",
      "author" : [ "Yu Wu", "Wei Wu", "Chen Xing", "Ming Zhou", "Zhoujun Li." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Wu et al\\.,? 2017",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2017
    }, {
      "title" : "Enhancing dialog coherence with event graph grounded content",
      "author" : [ "Jun Xu", "Zeyang Lei", "Haifeng Wang", "Zheng-Yu Niu", "Hua Wu", "Wanxiang Che" ],
      "venue" : null,
      "citeRegEx" : "Xu et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Conversational graph grounded policy learning for open-domain conversation generation",
      "author" : [ "Jun Xu", "Haifeng Wang", "Zheng-Yu Niu", "Hua Wu", "Wanxiang Che", "Ting Liu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computa-",
      "citeRegEx" : "Xu et al\\.,? 2020b",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Knowledge graph grounded goal planning for open-domain conversation generation",
      "author" : [ "Jun Xu", "Haifeng Wang", "Zhengyu Niu", "Hua Wu", "Wanxiang Che." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9338–9345.",
      "citeRegEx" : "Xu et al\\.,? 2020c",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Strategy and policy learning for nontask-oriented conversational systems",
      "author" : [ "Zhou Yu", "Ziyu Xu", "Alan W Black", "Alexander Rudnicky." ],
      "venue" : "Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 404–",
      "citeRegEx" : "Yu et al\\.,? 2016",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2016
    }, {
      "title" : "Discovering latent structure in task-oriented dialogues",
      "author" : [ "Ke Zhai", "Jason D. Williams." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 36–46, Baltimore, Maryland. Associa-",
      "citeRegEx" : "Zhai and Williams.,? 2014",
      "shortCiteRegEx" : "Zhai and Williams.",
      "year" : 2014
    }, {
      "title" : "Unsupervised discrete sentence representation learning for interpretable neural dialog generation",
      "author" : [ "Tiancheng Zhao", "Kyusong Lee", "Maxine Eskenazi." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Vol-",
      "citeRegEx" : "Zhao et al\\.,? 2018",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning discourse-level diversity for neural dialog models using conditional variational autoencoders",
      "author" : [ "Tiancheng Zhao", "Ran Zhao", "Maxine Eskenazi." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Zhao et al\\.,? 2017",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2017
    }, {
      "title" : "Multi-turn response selection for chatbots with deep attention matching network",
      "author" : [ "Xiangyang Zhou", "Lu Li", "Daxiang Dong", "Yi Liu", "Ying Chen", "Wayne Xin Zhao", "Dianhai Yu", "Hua Wu." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association",
      "citeRegEx" : "Zhou et al\\.,? 2018",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "With the aim of building a machine to converse with humans naturally, some work investigate neural generative models (Shang et al., 2015; Serban et al., 2017).",
      "startOffset" : 117,
      "endOffset" : 158
    }, {
      "referenceID" : 20,
      "context" : "With the aim of building a machine to converse with humans naturally, some work investigate neural generative models (Shang et al., 2015; Serban et al., 2017).",
      "startOffset" : 117,
      "endOffset" : 158
    }, {
      "referenceID" : 30,
      "context" : "While these models can generate locally relevant dialogs, they struggle to organize individual utterances into globally coherent flow (Yu et al., 2016; Xu et al., 2020b).",
      "startOffset" : 134,
      "endOffset" : 169
    }, {
      "referenceID" : 28,
      "context" : "While these models can generate locally relevant dialogs, they struggle to organize individual utterances into globally coherent flow (Yu et al., 2016; Xu et al., 2020b).",
      "startOffset" : 134,
      "endOffset" : 169
    }, {
      "referenceID" : 22,
      "context" : "Some studies tried to discover dialog structure from task-oriented dialogs (Shi et al., 2019).",
      "startOffset" : 75,
      "endOffset" : 93
    }, {
      "referenceID" : 25,
      "context" : "Furthermore, the dialog structures they discovered generally only contain utterance-level semantics (non-hierarchical), without session-level semantics (chatting topics) that are essential in open-domain dialogs (Wu et al., 2019; Kang et al., 2019; Xu et al., 2020c).",
      "startOffset" : 212,
      "endOffset" : 266
    }, {
      "referenceID" : 7,
      "context" : "Furthermore, the dialog structures they discovered generally only contain utterance-level semantics (non-hierarchical), without session-level semantics (chatting topics) that are essential in open-domain dialogs (Wu et al., 2019; Kang et al., 2019; Xu et al., 2020c).",
      "startOffset" : 212,
      "endOffset" : 266
    }, {
      "referenceID" : 29,
      "context" : "Furthermore, the dialog structures they discovered generally only contain utterance-level semantics (non-hierarchical), without session-level semantics (chatting topics) that are essential in open-domain dialogs (Wu et al., 2019; Kang et al., 2019; Xu et al., 2020c).",
      "startOffset" : 212,
      "endOffset" : 266
    }, {
      "referenceID" : 20,
      "context" : "Intuitively, since discrete dialog states are easier to capture transitions for dialog coherence, we use discrete variables to represent dialog states (or vertices in the graph) rather than dense continuous ones in most VAEbased dialog models (Serban et al., 2017; Zhao et al., 2017).",
      "startOffset" : 243,
      "endOffset" : 283
    }, {
      "referenceID" : 33,
      "context" : "Intuitively, since discrete dialog states are easier to capture transitions for dialog coherence, we use discrete variables to represent dialog states (or vertices in the graph) rather than dense continuous ones in most VAEbased dialog models (Serban et al., 2017; Zhao et al., 2017).",
      "startOffset" : 243,
      "endOffset" : 283
    }, {
      "referenceID" : 1,
      "context" : "1 Dialog structure learning for task-oriented dialogs There are previous work on discovering humanreadable dialog structure for task-oriented dialogs via hidden Markov models (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014) or variational auto-encoder (Shi et al.",
      "startOffset" : 175,
      "endOffset" : 241
    }, {
      "referenceID" : 17,
      "context" : "1 Dialog structure learning for task-oriented dialogs There are previous work on discovering humanreadable dialog structure for task-oriented dialogs via hidden Markov models (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014) or variational auto-encoder (Shi et al.",
      "startOffset" : 175,
      "endOffset" : 241
    }, {
      "referenceID" : 31,
      "context" : "1 Dialog structure learning for task-oriented dialogs There are previous work on discovering humanreadable dialog structure for task-oriented dialogs via hidden Markov models (Chotimongkol, 2008; Ritter et al., 2010; Zhai and Williams, 2014) or variational auto-encoder (Shi et al.",
      "startOffset" : 175,
      "endOffset" : 241
    }, {
      "referenceID" : 22,
      "context" : ", 2010; Zhai and Williams, 2014) or variational auto-encoder (Shi et al., 2019).",
      "startOffset" : 61,
      "endOffset" : 79
    }, {
      "referenceID" : 20,
      "context" : "3 Latent variable models for chitchat Recently, latent variables are utilized to improve diversity (Serban et al., 2017; Zhao et al., 2017; Gu et al., 2019; Gao et al., 2019; Ghandeharioun et al., 2019), control responding styles (Zhao et al.",
      "startOffset" : 99,
      "endOffset" : 202
    }, {
      "referenceID" : 33,
      "context" : "3 Latent variable models for chitchat Recently, latent variables are utilized to improve diversity (Serban et al., 2017; Zhao et al., 2017; Gu et al., 2019; Gao et al., 2019; Ghandeharioun et al., 2019), control responding styles (Zhao et al.",
      "startOffset" : 99,
      "endOffset" : 202
    }, {
      "referenceID" : 5,
      "context" : "3 Latent variable models for chitchat Recently, latent variables are utilized to improve diversity (Serban et al., 2017; Zhao et al., 2017; Gu et al., 2019; Gao et al., 2019; Ghandeharioun et al., 2019), control responding styles (Zhao et al.",
      "startOffset" : 99,
      "endOffset" : 202
    }, {
      "referenceID" : 3,
      "context" : "3 Latent variable models for chitchat Recently, latent variables are utilized to improve diversity (Serban et al., 2017; Zhao et al., 2017; Gu et al., 2019; Gao et al., 2019; Ghandeharioun et al., 2019), control responding styles (Zhao et al.",
      "startOffset" : 99,
      "endOffset" : 202
    }, {
      "referenceID" : 4,
      "context" : "3 Latent variable models for chitchat Recently, latent variables are utilized to improve diversity (Serban et al., 2017; Zhao et al., 2017; Gu et al., 2019; Gao et al., 2019; Ghandeharioun et al., 2019), control responding styles (Zhao et al.",
      "startOffset" : 99,
      "endOffset" : 202
    }, {
      "referenceID" : 32,
      "context" : ", 2019), control responding styles (Zhao et al., 2018; Li et al., 2020) and incorporate knowledge (Kim et al.",
      "startOffset" : 35,
      "endOffset" : 71
    }, {
      "referenceID" : 10,
      "context" : ", 2019), control responding styles (Zhao et al., 2018; Li et al., 2020) and incorporate knowledge (Kim et al.",
      "startOffset" : 35,
      "endOffset" : 71
    }, {
      "referenceID" : 8,
      "context" : ", 2020) and incorporate knowledge (Kim et al., 2020) in dialogs.",
      "startOffset" : 34,
      "endOffset" : 52
    }, {
      "referenceID" : 9,
      "context" : "It contains two procedures, vertex recognition that maps utterances and sessions to vertices (as the role of recognition module in VAE (Kingma and Welling, 2014)), and utterance reconstruction that regenerates all utterances in sessions (as the role of decoding module in VAE).",
      "startOffset" : 135,
      "endOffset" : 161
    }, {
      "referenceID" : 6,
      "context" : "Finally, we obtain the mapped utterance-level vertex, zi, by sampling from the posterior distribution with Gumbel-Softmax (Jang et al., 2017).",
      "startOffset" : 122,
      "endOffset" : 141
    }, {
      "referenceID" : 9,
      "context" : "Finally, we optimize the DVAE-GNN model by maximizing the variational lower-bound (ELBO) (Kingma and Welling, 2014).",
      "startOffset" : 89,
      "endOffset" : 115
    }, {
      "referenceID" : 34,
      "context" : "i) Utterance relevance We choose the classical multi-turn response selection model, DAM in (Zhou et al., 2018), to calculate utterance relevance.",
      "startOffset" : 91,
      "endOffset" : 110
    }, {
      "referenceID" : 13,
      "context" : "benchmark datasets: (1) Weibo (Li and Yan, 2018): this is a Chinese multi-turn tweet-style corpora.",
      "startOffset" : 30,
      "endOffset" : 48
    }, {
      "referenceID" : 26,
      "context" : "(2) Douban (Wu et al., 2017): we use the original multi-turn dialog corpus, and obtain 2.",
      "startOffset" : 11,
      "endOffset" : 28
    }, {
      "referenceID" : 22,
      "context" : "In this work, we select DVRNN (Shi et al., 2019) as a baseline, since there is few previous study on unsupervised open-domain dialog structure discovery.",
      "startOffset" : 30,
      "endOffset" : 48
    }, {
      "referenceID" : 22,
      "context" : "DVRNN is the SOTA unsupervised method in discovering dialog structure in task-oriented dialogs, which outperforms other hidden Markov based methods by a large margin (Shi et al., 2019).",
      "startOffset" : 166,
      "endOffset" : 184
    }, {
      "referenceID" : 16,
      "context" : "For automatic evaluation, we use two metrics to evaluate the performance of reconstruction: (1) NLL is the negative log likelihood of dialog utterances; (2) BLEU-1/2 measures how much that reconstructed sentences contains 1/2-gram overlaps with input sentences (Papineni et al., 2002).",
      "startOffset" : 261,
      "endOffset" : 284
    }, {
      "referenceID" : 0,
      "context" : "MMPMS It is the multi-mapping based neural open-domain conversational model with posterior mapping selection mechanism (Chen et al., 2019), which is a SOTA model on the Weibo Corpus.",
      "startOffset" : 119,
      "endOffset" : 138
    }, {
      "referenceID" : 24,
      "context" : "MemGM It is the memory-augmented opendomain dialog model (Tian et al., 2019), which learns to cluster U-R pairs for response generation.",
      "startOffset" : 57,
      "endOffset" : 76
    }, {
      "referenceID" : 19,
      "context" : "HRED It is the hierarchical recurrent encoderdecoder model (Serban et al., 2016).",
      "startOffset" : 59,
      "endOffset" : 80
    }, {
      "referenceID" : 33,
      "context" : "CVAE It is the Conditional Variational AutoEncoder based neural open-domain conversational model (Zhao et al., 2017).",
      "startOffset" : 97,
      "endOffset" : 116
    }, {
      "referenceID" : 4,
      "context" : "VHCR-EI This variational hierarchical RNN model can learn hierarchical latent variables from open-domain dialogs (Ghandeharioun et al., 2019).",
      "startOffset" : 113,
      "endOffset" : 141
    }, {
      "referenceID" : 22,
      "context" : "DVRNN-RL It discovers dialog structure graph for task-oriented dialog modeling (Shi et al., 2019).",
      "startOffset" : 79,
      "endOffset" : 97
    }, {
      "referenceID" : 16,
      "context" : ", coherence), we do not employ BLEU (Papineni et al., 2002) or perplexity for evaluation.",
      "startOffset" : 36,
      "endOffset" : 59
    }, {
      "referenceID" : 12,
      "context" : "(3) Length of high-quality dialog (Length) A high-quality dialog ends if the model tends to produce dull responses or two consecutive utterances are highly overlapping (Li et al., 2016b).",
      "startOffset" : 168,
      "endOffset" : 186
    }, {
      "referenceID" : 11,
      "context" : "-i) It is an automatic metric for response diversity (Li et al., 2016a).",
      "startOffset" : 53,
      "endOffset" : 71
    } ],
    "year" : 2021,
    "abstractText" : "Learning discrete dialog structure graph from human-human dialogs yields basic insights into the structure of conversation, and also provides background knowledge to facilitate dialog generation. However, this problem is less studied in open-domain dialogue. In this paper, we conduct unsupervised discovery of discrete dialog structure from chitchat corpora, and then leverage it to facilitate coherent dialog generation in downstream systems. To this end, we present an unsupervised model, Discrete Variational Auto-Encoder with Graph Neural Network (DVAE-GNN), to discover discrete hierarchical latent dialog states (at the level of both session and utterance) and their transitions from corpus as a dialog structure graph. Then we leverage it as background knowledge to facilitate dialog management in a RL based dialog system. Experimental results on two benchmark corpora confirm that DVAE-GNN can discover meaningful dialog structure graph, and the use of dialog structure as background knowledge can significantly improve multi-turn coherence.",
    "creator" : "LaTeX with hyperref"
  }
}