{
  "name" : "2021.acl-long.64.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking",
    "authors" : [ "Hang Jiang", "Sairam Gurajada", "Qiuhao Lu", "Sumit Neelam", "Lucian Popa", "Prithviraj Sen", "Yunyao Li", "Alexander Gray" ],
    "emails" : [ "hjian42@mit.edu,", "alexander.gray}@ibm.com,", "luqh@cs.uoregon.edu,", "sumit.neelam@in.ibm.com,", "lpopa@us.ibm.com", "senp@us.ibm.com", "yunyaoli@us.ibm.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 775–787\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n775"
    }, {
      "heading" : "1 Introduction",
      "text" : "Entity Linking (EL) is the task of disambiguating textual mentions by linking them to canonical entities provided by a knowledge graph (KG) such as DBpedia, YAGO (Suchanek et al., 2007) or Wikidata (Vrandečić and Krötzsch, 2014). A large body of existing work deals with EL in the context of longer text (i.e., comprising of multiple sentences) (Bunescu and Pasca, 2006). The general\n∗Equal contribution; Author Hang Jiang did this work while interning at IBM.\napproach is: 1) extract features measuring some degree of similarity between the textual mention and any one of several candidate entities (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011), followed by 2) the disambiguation step, either heuristics-based (non-learning) (Hoffart et al., 2011; Sakor et al., 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011; Hoffart et al., 2012; Ganea and Hofmann, 2017), to link the mention to an actual entity.\nA particular type of entity linking, focused on short text (i.e., a single sentence or question), has attracted recent attention due to its relevance for downstream applications such as question answering (e.g., (Kapanipathi et al., 2021)) and conversational systems. Short-text EL is particularly challenging because the limited context surrounding mentions results in greater ambiguity (Sakor et al., 2019). To address this challenge, one needs to exploit as many features from as many sources of evidence as possible.\nConsider the question in Figure 1(a), containing mention1 (Cameron) and mention2 (Titanic).1 DBpedia contains several person entities whose last name matches Cameron. Two such entities are shown in Figure 3(b), James_Cameron and Roderick_Cameron, along with their string similarity scores (in this case, character-level Jaccard similarity) to mention1. In this case, the string similarities are quite close. In the absence of reliable discerning information, one can employ a prior such as using the more popular candidate entity, as measured by the in-degree of the entity in the KG (see Figure 3(b)). Given the higher in-degree, we can (correctly) link mention1 to James_Cameron. However, for mention2, the correct entry is Titanic_(1997_film) as opposed to\n1Note that we assume that mention extraction has already been applied and we are given the textual mentions.\nWho composed soundtrack of Cameron︸ ︷︷ ︸\nmention1 ’s Titanic︸ ︷︷ ︸ mention2 ?\nMention Entity Similarity In-degree mention1 James_Cameron 0.7 30 Roderick_Cameron 0.6 10 mention2 Titanic 1.0 44\nTitanic_(1997_film) 0.4 52\nJames_Cameron\nTitanic_(1997_film)Aliens_(film)\nTrue_Lies\nDirectorDirector\nDirector\nRoderick_Cameron\nRory_CameronOntario\nUpper_Canada\nRelativerestingPlace\nbirthPlace\n(a) (b) (c)\nFigure 1: (a) Question with 2 mentions that need to be disambiguated against DBpedia. (b) For each mentioncandidate entity pair, the character-level Jaccard similarity is shown along with the in-degree of the entity in the knowledge graph. (c) (Partial) Ego networks for entities James_Cameron and Roderick_Cameron.\nTitanic the ship, but it actually has a lower string similarity. To link to the correct entity, one needs to exploit the fact that James_Cameron has an edge connecting it to Titanic_(1997_film) in the KG (see ego network on the left in Figure 1(c)). Linking co-occurring mentions from text to connected entities in the KG is an instance of collective entity linking. This example provides some intuition as to how priors, local features (string similarity) and collective entity linking can be exploited to overcome the limited context in short-text EL.\nWhile the use of priors, local features and nonlocal features (for collective linking) has been proposed before (Ratinov et al., 2011), our goal in this paper is to provide an extensible framework that can combine any number of such features and more, including contextual embeddings such as BERT encodings (Devlin et al., 2019) and Query2box embeddings (Ren et al., 2020), and even the results of previously developed neural EL models (e.g., BLINK (Wu et al., 2020)). Additionally, such a framework must not only allow for easy inclusion of new sources of evidence but also for interpretability of the resulting model (Guidotti et al., 2018). An approach that combines disparate features should, at the very least, be able to state, post-training, which features are detrimental and which features aid EL performance and under what conditions, in order to enable actionable insights in the next iteration of model improvement. Our Approach. We propose to use rules in firstorder logic (FOL), an interpretable fragment of logic, as a glue to combine EL features into a coherent model. Each rule in itself is a disambiguation model capturing specific characteristics of the overall linking. While inductive logic programming (Muggleton, 1996) and statistical relational learning (Getoor and Taskar, 2007) have for long focused on learning FOL rules from labeled data, more recent approaches based on neuro-symbolic AI have led to impressive advances. In this work, we start with an input set of rule templates (given by an expert or available as a library), and learn the\nparameters of these rules (namely, the thresholds of the various similarity predicates as well as the weights of the predicates that appear in the rules), based on a labeled dataset. We use logical neural networks (LNN) (Riegel et al., 2020), a powerful neuro-symbolic AI approach based on real-valued logic that employs neural networks to learn the parameters of the rules. Learning of the rule templates themselves will be the focus of future work.\nSummary of contributions • We propose, to the best of our knowledge, the\nfirst neuro-symbolic method for entity linking (coined “LNN-EL\") that provides a principled approach to learning EL rules.\n• Our approach is extensible and can combine disparate types of local and global features as well as results of prior black-box neural methods, thus building on top of such approaches.\n• Our approach produces interpretable rules that humans can inspect toward actionable insights.\n• We evaluate our approach on three benchmark datasets and show competitive (or better) performance with SotA black-box neural approaches (e.g., BLINK (Wu et al., 2020)) even though we are constrained on using rules.\n• By leveraging rules, the learned model shows a desirable transferability property: it performs well not only on the dataset on which it was trained, but also on other datasets from the same domain without further training."
    }, {
      "heading" : "2 Related Work",
      "text" : "Entity Linking Models. Entity Linking is a wellstudied problem in NLP, especially for long text. Approaches such as (Bunescu and Pasca, 2006; Ratinov et al., 2011; Sil et al., 2012; Hoffart et al., 2011; Shen et al., 2015) use a myriad of classical ML and deep learning models to combine priors, local and global features. These techniques, in general, can be applied to short text, but the lack of sufficient context may render them ineffective. The recently proposed BLINK (Logeswaran et al., 2019;\nWu et al., 2020) uses powerful transformer-based encoder architectures trained on massive amounts of data (such as Wikipedia, Wikia) to achieve SotA performance on entity disambiguation tasks, and is shown to be especially effective in zero-shot settings. BLINK is quite effective on short text (as observed in our findings); in our approach, we use BLINK both as a baseline and as a component that is combined in larger rules.\nFor short-text EL, some prior works (Sakor et al., 2019; Ferragina and Scaiella, 2012; Mendes et al., 2011) address the joint problem of mention detection and linking, with primary focus on identifying mention spans, while linking is done via heuristic methods without learning. (Sakor et al., 2019) also jointly extracts relation spans which aide in overall linking performance. The recent ELQ (Li et al., 2020) extends BLINK to jointly learn mention detection and linking. In contrast, we focus solely on linking and take a different strategy based on combining logic rules with learning. This facilitates a principled way combining multiple types of EL features with interpretability and learning using promising gradient-based techniques.\nRule-based Learning. FOL rules and learning have been successfully applied in some NLP tasks and also other domains. Of these, the task that is closest to ours is entity resolution (ER), which is the task of linking two entities across two structured datasets. In this context, works like (Chaudhuri et al., 2007; Arasu et al., 2010; Wang et al., 2012; Hernández et al., 2013) use FOL rules for ER. Approaches such as (Singla and Domingos, 2006; Pujara and Getoor, 2016) induce probabilistic rules using MLNs (Richardson and Domingos, 2006) and PSL (Bach et al., 2017), respectively. None of these approaches use any recent advances in neural-based learning; moreover, they are focused on entity resolution, which is a related task but distinct from short-text EL."
    }, {
      "heading" : "3 Preliminaries",
      "text" : ""
    }, {
      "heading" : "3.1 Entity Linking.",
      "text" : "Given text T , a setM = {m1,m2, ...} of mentions, where each mi is contained in T , and a knowledge graph (KG) comprising of a set E of entities, entity linking is a many-to-one function that links each mention mi ∈ M to an entity eij ∈ Ci, where Ci ⊆ E is a subset of relevant candidates for mention mi. More generally, we formulate the problem as a ranking of the candidates in Ci so that the “cor-\nrect\" entity for mi is ranked highest. Following existing approaches(e.g. (Sakor et al., 2019; Wu et al., 2020), we use off-the-shelf lookup tools such as DBpedia lookup2 to retrieve top-100 candidates for each mention. While this service is specific to DBpedia, we assume that similar services exist or can be implemented on top of other KGs."
    }, {
      "heading" : "3.2 Logical Neural Networks",
      "text" : "Fueled by the rise in complexity of deep learning, recently there has been a push towards learning interpretable models (Guidotti et al., 2018; Danilevsky et al., 2020). While linear classifiers, decision lists/trees may also be considered interpretable, rules expressed in first-order logic (FOL) form a much more powerful, closed language that offer semantics clear enough for human interpretation and a larger range of operators facilitating the expression of richer models. To learn these rules, neuro-symbolic AI typically substitutes conjunctions (disjunctions) with differentiable t-norms (t-conorms) (Esteva and Godo, 2001). However, since these norms do not have any learnable parameters (more details in Appendix A.1), their behavior cannot be adjusted, thus limiting their ability to model well the data.\nIn contrast, logical neural networks (LNN) (Riegel et al., 2020) offer operators that include parameters, thus allowing to better learn from the data. To maintain the crisp semantics of FOL, LNNs enforce constraints when learning operators such as conjunction. Concretely, LNN-∧ is expressed as:\nmax(0,min(1, β − w1(1− x)− w2(1− y))) subject to: β − (1− α)(w1 + w2) ≥ α (1)\nβ − αw1 ≤ 1− α (2) β − αw2 ≤ 1− α (3) w1, w2 ≥ 0\nwhere β,w1, w2 are learnable parameters, x, y ∈ [0, 1] are inputs and α ∈ [12 , 1] is a hyperparameter. Note that max(0,min(1, ·)) clamps the output of LNN-∧ between 0 and 1 regardless of β,w1, w2, x, and y. The more interesting aspects are in the constraints. While Boolean conjunction only returns 1 or true when both inputs are 1, LNNs relax this condition by using α as a proxy for 1 (and conversely, 1 − α as a proxy for 0). In particular, Constraint (1) forces the output of LNN-∧ to be greater than α when both inputs are greater than α. Similarly, Constraints (2) and (3) constrain the\n2https://lookup.dbpedia.org/\nbehavior of LNN-∧ when one input is low and the other is high. For instance, Constraint (2) forces the output of LNN-∧ to be less than 1−α for y = 1 and x ≤ 1 − α. This formulation allows for unconstrained learning when x, y ∈ [1 − α, α]. By changing α a user can control how much learning to enable (increase to make region of unconstrained learning wider or decrease for the opposite). Figure 2 depicts product t-norm and LNN-∧ (α = 0.7). While the former increases slowly with increasing x, y, LNN-∧ produces a high output when both inputs are ≥ α and stays high thereafter, thus closely modeling Boolean conjunction semantics.\nIn case the application requires even more degrees of freedom, the hard constraints (1), (2) and (3) can be relaxed via the inclusion of slacks:\nmax(0,min(1, β − w1(1− x)− w2(1− y))) subject to: β − (1− α)(w1 + w2) + ∆ ≥ α\nβ − αw1 ≤ 1− α+ δ1 β − αw2 ≤ 1− α+ δ2 w1, w2, δ1, δ2,∆ ≥ 0\nLNN-∧(x, y) =\nwhere δ1, δ2, and ∆ denote slack variables. If any of Constraints (1), (2) and (3) in LNN-∧ are unsatisfied then slacks help correct the direction of the inequality without putting pressure on parameters w1, w2, and β during training. For the rest of the paper, by LNN-∧ we refer to the above formulation. LNN negation is a pass-through operator: LNN-¬(x) = 1− x, and LNN disjunction is defined in terms of LNN-∧:\nLNN-∨(x, y) = 1− LNN-∧(1− x, 1− y)\nWhile vanilla backpropagation cannot handle linear inequality constraints such as Constraint (1), specialized learning algorithms are available within the LNN framework. For more details, please check Riegel et al. (2020)"
    }, {
      "heading" : "4 LNN-EL",
      "text" : "An overview of our neuro-symbolic approach for entity linking is depicted in Figure 3. We next discuss the details about feature generation component that generates features using a catalogue\nof feature functions (Section 4.1) followed by proposed model that does neuro-symbolic learning over user provided EL algorithm in Section 4.2.\nGiven the input text T , together with labeled data in the form (mi, Ci, Li), where mi ∈ M is a mention in T , Ci is a list of candidate entities eij (drawn from lookup services3) for the mention mi, and where each lij ∈ Li denotes a link/notlink label for the pair (mi, eij). The first step is to generate a set Fij = {fk(mi, eij)} of features for each pair (mi, eij), where fk is a feature function drawn from a catalog F of user provided functions."
    }, {
      "heading" : "4.1 Feature Functions",
      "text" : "Our collection of feature functions include both non-embedding and embedding based functions.\nNon-embedding based. We include here a multitude of functions (see Table 1) that measure the similarity between the mention mi and the candidate entity eij based on multiple types of scores.\nName: a set of general purpose string similarity functions4 such as Jaccard, Jaro Winkler, Levenshtein, Partial Ratio, etc. are used to compute the similarity between mi and eij’s name.\nContext: aggregated similarity of mi’s context to the description of eij . Here, we consider the list of all other mentions mk ∈M (k 6= i) as mi’s context, together with eij’s textual description obtained using KG resources5. The exact formula we use is shown in Table 1, where Partial Ratio(pr) measures the similarity between each context mention and the description. (Partial Ratio computes the\n3https://lookup.dbpedia.org 4pypi.org/project/py-stringmatching 5dbpedia.org/sparql\nmaximum similarity between a short input string and substrings of a second, longer string.) For normalizing the final score, we apply a min-max rescaling over all entities eij ∈ Ci.\nType: the overlap similarity of mention mi’s type to eij’s domain (class) set, similar to the domain-entity coherence score proposed in (Nguyen et al., 2014). Unlike in (Nguyen et al., 2014), instead of using a single type for all mentions in M , we obtain type information for each mentionmi using a trained BERT-based entity type detection model. We use KG resources 5 to obtain eij’s domain set, similar to Context similarity.\nEntity Prominence: measure the prominence of entity eij as the number of entities that link to eij in target KG, i.e., indegree(eij). Similar to Context score normalization, we apply min-max rescaling over all entities eij ∈ Ci.\nEmbedding based. We also employ a suite of pretrained or custom trained neural language models to compute the similarity of mi and eij .\nPre-trained Embedding Models. These include SpaCy’s semantic similarity6 function that uses Glove (Pennington et al., 2014) trained on Common Crawl. In addition to SpaCy, we also use scores from an entity linking system such as BLINK (Wu et al., 2020) (a state-of-the-art entity linking model) as a feature function in our system.\nBERT Embeddings. To further explore the semantics of the context in T and the inherent structure of the target KG, we incorporate an embeddingbased similarity by training a mini entity linking model without any aforementioned prior information. We first tag the input text T with a special token [MENT] to indicate the position of mention mi, and then encode T with BERT, i.e., mi = BERT(mi, T ). Each candidate eij is encoded with\n6spacy.io/usage/vectors-similarity\na pre-trained graph embedding Wiki2Vec (Yamada et al., 2020), i.e., eij = Wiki2Vec(eij). The candidates are ranked in order of the cosine similarity to mi, i.e., Simcos(mi, eij). The mini EL model is optimized with margin ranking loss so that the correct candidate is ranked higher.\nBERT with Box Embeddings. While features such as Context (see Table 1) can exploit other mentions appearing within the same piece of text, they only do so via textual similarity. A more powerful method is to jointly disambiguate the mentions in text to the actual entities in the KG, thus exploiting the structural context in the KG. Intuitively, the simultaneous linking of co-occurring mentions in text to related entities in the KG is a way to reinforce the links for each individual mention. To this end, we adapt the recent Query2Box (Ren et al., 2020), whose goal is to answer FOL queries over a KG. The main idea there is to represent sets of entities (i.e., queries) as contiguous regions in embedded space (e.g., axis-parallel hyper-rectangles or boxes), thus reducing logical operations to geometric operations (e.g., intersection).\nSince Query2Box assumes a well-formed query as input, one complication in directly applying it to our setting is that we lack the information necessary to form such an FOL query. For instance, in the example from Section 1, while we may assume that the correct entities for our Cameron and Titanic mentions are connected in the KG, we do not know how these are connected, i.e., via which relation. To circumvent this challenge, we introduce a special neighborhood relation N , such that v ∈ N (u) whenever there is some KG relation from entity u\nto entity v. We next define two box operations:\nBox(Ci) = {v|min({eij|eij ∈ Ci}) v max({eij|eij ∈ Ci})} Box(N (Ci)) = Box(Ci) + BoxN\nThe first operation represents mention mi as a box, by taking the smallest box that contains the set Ci of candidate entities for mi. This can be achieved by computing the dimension-wise minimum (maximum) of all entity embeddings in Ci to obtain the lower-left (upper-right) corner of the resulting box. The second operation takesmi’s box and produces the box containing its neighbors in the KG. Query2Box achieves this by representing BoxN via a center vector ψ and offset vector ω, both of which are learned parameters. The box of neighbors is then obtained by translating the center of mi’s box by ψ and adding the offset ω to its side.\nFigure 4 shows how these operations are used to disambiguate Titanic while exploiting the cooccurring mention Cameron and the KG structure. We take the box for Cameron, compute its neighborhood box, then intersect with the Titanic box. This intersection contains valid entities that can disambiguate Titanic and are connected to the entity for Cameron. For the actual score of each such entity, we take its distance to the center of the intersection box and convert it to a similarity score Simbox(mi, eij). We then linearly combine this with the BERT-based similarity measure: βboxSimbox(mi, eij) +Simcos(mi, eij), where βbox is a hyper-parameter that adjusts the importance of the two scores. The approach described can be easily extended to more than two mentions."
    }, {
      "heading" : "4.2 Model",
      "text" : "In this section, we describe how an EL algorithm composed of a disjunctive set of rules is reformulated into LNN representation for learning. Entity Linking Rules are a restricted form of FOL rules comprising of a set of Boolean predicates connected via logical operators: conjunction (∧) and disjunction (∨). A Boolean predicate has the form fk > θ, where fk ∈ F is one of the feature functions, and θ can be either a user provided or a learned threshold in [0, 1]. Figure 5(a) shows two example rules R1 and R2, where, for instance, R1(mi, eij) evaluates to True if both the predicate jacc(mi, eij) > θ1 and Ctx(mi, eij) > θ2 are True. Rules can be disjuncted together to form a larger EL algorithm, as the one shown in Figure 5(b), which states that Links(mi, eij) evalu-\nates to True if any one of its rules evaluates to True. The Links predicate is meant to store high-quality links between mention and candidate entities that pass the conditions of at least one rule. The EL algorithm also acts as a scoring mechanism. In general, there are many ways in which scores can computed. In a baseline implementation (no learning), we use the scoring function in Figure 5(c), where rwi denote manually assigned rule weights, while fwi are manually assigned feature weights.\nAn EL algorithm is an explicit and extensible description of the entity linking logic, which can be easily understood and manipulated by users. However, obtaining competitive performance to that of deep learning approaches such as BLINK (Wu et al., 2020) requires a significant amount of manual effort to fine tune the thresholds θi, the feature weights (fwi) and the rule weights (rwi). LNN Reformulation. To facilitate learning of the thresholds and weights in an EL algorithm, we map the Boolean-valued logic rules into the LNN formalism, where the LNN constructs – LNN-∨ (for logical OR) and LNN-∧ (for logical AND) – allow for continuous real-valued numbers in [0, 1]. As described in Section 3.2, LNN-∧ and LNN-∨ are a weighted real-valued version of the classical logical operators, where a hyperparameter α is used as a proxy for 1. Each LNN operator produces a value in [0, 1] based on the values of the inputs, their weights and bias β. Both the weights and β are learnable parameters. The score of each link is based on the score that the LNN operators give, with an added complication related to how we score the feature functions. To illustrate, for the EL rules in Figure 5, the score of a link is computed as: s(mi, eij) =\nLNN- ∨  LNN- ∧ ( TL(jacc(mi, eij), θ1), TL(Ctx(mi, eij), θ2) ) ,\nLNN- ∧ ( TL(lev(mi, eij), θ3), TL(Prom(mi, eij), θ4)\n) \nHere the top-level LNN-∨ represents the disjunction R1 ∨ R2, while the two inner LNN-∧ capture the rules R1 and R2 respectively. For the feature functions with thresholds, a natural scoring mechanism would be to use score(f > θ) = f if f > θ else 0, which filters out the candidates that do not satisfy the condition f > θ, and gives a non-zero score for the candidates that pass the condition. However, since this is a step function which breaks the gradient flow through a neural network, we approximate it via a smooth function TL(f, θ) = f · σ(f − θ), where σ is Sigmoid function and θ is the learnable threshold that is generated using σ, i.e., θ = σ(γ), to ensure that it lies in [0, 1]. Training. We train the LNN formulated EL rules over the labeled data and use a margin-ranking loss over all the candidates in Ci to perform gradient descent. The loss function L(mi, Ci) for mention mi and candidates set Ci is defined as∑\nein∈Ci\\{eip}\nmax(0,−(s(mi, eip)− s(mi, ein)) + µ)\nHere, eip ∈ Ci is a positive candidate, Ci\\{eip} is the set of negative candidates, and µ is a margin hyper parameter. The positive and negative labels are obtained from the given labels Li (see Figure 3). Inference. Given mention mi and candidate set Ci, similar to training, we generate features for each mention-candidate pair (mi, eij) in the feature generation step. We then pass them through the learned LNN network to obtain final scores for each candidate entity in Ci as shown in Figure 3."
    }, {
      "heading" : "5 Evaluation",
      "text" : "We first evaluate our approach w.r.t performance & extensibility, interpretability and transferability. We also discuss the training and inference time. Datasets. As shown in Table 2, we consider three short-text QA datasets. LC-QuAD and QALD-9 are datasets comprising of questions (Q) over DBpedia together with their corresponding SPARQL queries. We extract entities (E) from SPARQL queries and manually annotate mention spans. WebQSPEL dataset (Li et al., 2020) comprises of\nboth mention spans and links to the correct entity. Since the target KG for WebQSP is Wikidata, we translate each Wikidata entity to its DBpedia counterpart using DBpedia Mappings7. In addition, we discard mentions that link to DBpedia concepts (e.g., heaviest player linked to dbo:Person) and mentions mi with empty result (i.e., Ci = φ) or all not-link labels (i.e, ∀lij ∈ Li, lij = 0)8.\nBaselines. We compare our approach to (1) BLINK (Wu et al., 2020), the current state-of-theart on both short-text and long-text EL, (2) three BERT-based models - (a) BERT: both mention and candidate entity embeddings are obtained via BERTbase pre-trained encoder, similar to (Gillick et al., 2019), (b) BERTWiki: mention embeddings are obtained from BERTbase, while candidate entity is from pretrained Wiki2Vec (Yamada et al., 2020), (c) Box: BERTWiki embeddings finetuned with Query2Box embeddings (see Section 4.1). In addition to the aforementioned black-box neural models, we also compare our approach to (3) two logistic regression models that use the same feature set as LNN-EL: LogisticRegression without BLINK and LogisticRegressionBLINK with BLINK.\nFurthermore, we use the following variants of our approach: (4) RuleEL: a baseline rule-based EL approach with manually defined weights and thresholds, (5) LogicEL: a baseline approach built on RuleEL where only the thresholds are learnable, based on product t-norm (see Section 3.2), (6) LNN-EL: our core LNN-based method using non-embedding features plus SpaCy, and (7) LNN-ELens: an ensemble combining core LNNEL with additional features from existing EL approaches, namely BLINK and Box (we consider Box, as it outperforms BERT and BERTWiki on all datasets). Detailed rule templates are provided in Appendix A.3.\nSetup. All the baselines are trained for 30 epochs, except for BLINK which we use as a zero-shot approach. For BERT approaches, we use BERTbase as pretrained model. We used two Nvidia V100 GPUs with 16GB memory each. We perform hyperparameter search for margin µ and learning rates in the range [0.6, 0.95], [10−5, 10−1] respectively.\n7http://mappings.dbpedia.org/ 8Please check arXiv version for the datasets."
    }, {
      "heading" : "5.1 Results",
      "text" : "Overall Performance. As seen in Table 3, among logic-based approaches, LNN-EL outperforms LogicEL and RuleEL, showing that parameterized real-valued LNN learning is more effective than the non-parameterized version with t-norm (LogicEL) and the manually tuned RuleEL. Logistic regression models which also learn weights over features achieve competitive performance to LNNEL models; however they lack the representation power that LNN-EL offer in the form of logical rules comprising of conjunctions and disjunctions. In other words, LNN-EL allows learning over a richer space of models that help in achieving better performance as observed in Table 3.\nOn the other hand, simple BERT-based approaches (BERT, BERTWiki, Box) that are trained on the QA datasets underperform the logic-based approaches, which incorporate finer-grained features. BLINK (also a BERT-based approach, but trained on the entire Wikipedia) is used as zero-shot approach and achieves SotA performance (when not counting the LNN-EL variants). The core LNNEL version is competitive with BLINK on LCQuAD and QALD-9, despite being a rule-based approach. Furthermore, LNN-ELens, which combines the core LNN-EL with both BLINK and Box features, easily beats BLINK on LC-QuAD and QALD-9 and slightly on WebQSPEL.\nTable 4 shows the Recall@k performance of LNN-EL against the BLINK model. Both LNNEL and LNN-ELens have better Recall@k performance against BLINK on LC-QuAD and QALD-9 datasets, however BLINK’s Recall@k achieves a slightly better performance for WebQSPEL dataset. Extensibility. Here, we inspect empirically how a multitude of EL features coming from various black-box approaches can be combined in a principled way with LNN-EL, often leading to an overall better performance than the individual approaches. A detailed ablation study of the core LNN-EL ver-\nsion can be found in Appendix A.2. As seen in Table 5, approaches like BERTWiki and Box which in isolation underperform compared to LNN-EL, help boost the latter’s performance if they are included as predicates. Similarly, LNN-EL which has comparable performance to BLINK, can accommodate the latter’s score to produce better performance (see LNN-EL+BLINK). We also note that adding features is not a guarantee to improve performance, as LNN-ELens (which includes both BLINK and Box) slightly underperforms LNN-EL+BLINK on WebQSPEL. For such cases, the interpretability of LNN-EL (discussed next) can help users select the right features based on their relative importance.\nInterpretability. Unlike black-box models, rulebased approaches provide the capability to inspect the model, specifically on how the features impact performance. This inspection can help in dropping or adjusting features that are detrimental. For instance, consider our case of LNN-EL+BLINK and LNN-ELens trained on WebQSPEL dataset, where we observed that LNN-ELens’s performance is inferior to LNN-EL+BLINK even though the former model has more features. A human expert can find\ninsights into this behavior by looking at the feature weights in each model. In Figure 6 (left), the disjunction tree with the Box feature is given a low weight of 0.26, thus discounting some of the other useful features in the same tree. Removal of the Box feature leads to a re-weighting of the features in the model; the modified disjunction tree (Figure 6 (left)) has now a weight of 0.42. Such visualization can help the rule designer to judiciously select features to combine towards building a performant model.\nTransferability. To study the transferability aspect, we train LNN-EL on one dataset and evaluate the model on the other two, without any finetuning. We use the core LNN-EL variant for this, but similar properties hold for the other variants. Table 6 shows F1 scores on different train-test configurations, with diagonal (underlined numbers) denoting the F1 score when trained and tested on the same dataset. We observe that LNN-EL transfers reasonably well, even in cases where training is done on a very small dataset. For example, when we transfer from QALD-9 (with only a few hundred questions to train) to WebQSPEL, we obtain an F1-score of 83.06 which is within 2 percentage points of the F1-score when trained directly on WebQSPEL. We remark that the zero-shot BLINK by design has very good transferability and achieves F1 scores of 87.04, 89.14, 92.10 on LCQuAD, QALD-9, WebQSPEL respectively. However, BLINK is trained on the entire Wikipedia, while LNN-EL needs much less data to achieve reasonable transfer performance.\nRuntime Analysis. We study the efficiency of LNN-ELens across three aspects: 1) candidate & feature generation, 2) training, and 3) inference. Candidate & feature generation involve using the DBpedia lookup API to obtain candidates for each mention, pruning non-entity candidates (i.e., categories, disambiguation links, etc.), obtaining any missing descriptions for candidates using SPARQL endpoint, and finally generating feature vectors for each mention-candidate pair using the feature functions described in Section 4.1. The generated features for the train and test data are then used, respectively, to train and test the LNN-EL models. The number of parameters in an LNN-EL model is linearly proportional to the combined number of disjunctions and conjunctions, which typically is in the order of few 10s. For example, LNN-ELens comprises of 72 parameters, which is several orders of magnitude smaller than in neural black box models such as BLINK. Table 7 provides the time (in seconds) taken per question for candidate & feature generation, as well as 5-run average training and inference time per epoch."
    }, {
      "heading" : "6 Conclusions",
      "text" : "We introduced LNN-EL, a neuro-symbolic approach for entity linking on short text. Our approach complements human-given rule templates through neural learning and achieves competitive performance against SotA black-box neural models, while exhibiting interpretability and transferability without requiring a large amount of labeled data. While LNN-EL provides an extensible framework where one can easily add and test new features in existing rule templates, currently this is done manually. A future direction is to automatically learn the rules with the optimal combinations of features."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank Ibrahim Abdelaziz, Pavan Kapanipathi, Srinivas Ravishankar, Berthold Reinwald, Salim Roukos and anonymous reviewers for their valuable inputs and feedback."
    }, {
      "heading" : "A Appendix",
      "text" : "A.1 t-norm and t-conorm While linear classifiers, decision lists/trees may also be considered interpretable, rules expressed in first-order logic (FOL) form a much more powerful, closed language that offer semantics clear enough for human interpretation and a larger range of operators facilitating the expression of richer models. To learn these rules, neuro-symbolic AI substitutes conjunctions (disjunctions) with differentiable t-norms (t-conorms) (Esteva and Godo, 2001). However, since it does not have any learnable parameters, this behavior cannot be adjusted, which limits how well it can model the data. For example, while linear classifiers such as logistic regression can only express a (weighted) sum of features which is similar to logic’s disjunction (∨) operator, logic also contains other operators including, but not limited to, conjunction (∧), and negation (¬).\nAs opposed to inductive logic programming (Muggleton, 1996) and statistical relational learning (Getoor and Taskar, 2007), neuro-symbolic AI utilizes neural networks to learn rules. Towards achieving this, the first challenge to overcome is that classical Boolean logic is non-differentiable and thus, not amenable to gradient-based optimization (e.g., backpropagation). To address this, neuro-symbolic AI substitutes conjunctions (disjunctions) with differentiable t-norms (t-conorms) (Esteva and Godo, 2001). For example, product t-norm, used in multiple neuro-symbolic rulelearners (Evans and Grefenstette, 2018; Yang et al., 2017), is given by x ∧ y ≡ xy, where x, y ∈ [0, 1] denote input features in real-valued logic. Product t-norm agrees with Boolean conjunction at the extremities, i.e., when x, y are set to 0 (false) or 1 (true). However, when x, y ∈ [0, 1] \\ {0, 1}, its behavior is governed by the product function. More importantly, since it does not have any learnable parameters, this behavior cannot be adjusted, which limits how well it can model the data."
    }, {
      "heading" : "A.2 Ablation Study",
      "text" : "To understand the roles of eac rule in LNN-EL, we also conduct ablation study on the largest benchmark dataset LC-QuAD (see Table 8). We observe that Context is the most performant rule alone. Although PureName rule is behind the other two alone, PureName + Context improves the performance of Context by 1%. Meanwhile, Context\n+ Type only improves Context’s performance by 0.05%. Interestingly, the combination of three rules performs slightly worse than PureName + Context by 0.35%. These results show that Type rule is less important among the three rules. To be consistent with the RuleEL system, we apply “PureName + Context + Type” setting for LNN-EL in our experiments.\nAdditionally, we also show the transferability of LR in Table 9. This must be compared with the corresponding LNN-EL results in the earlier Table 6. In particular, we observe that LNN-EL outperforms LR in 4 out of 6 transferability tests, demonstrating that LNN-EL has superior transferability."
    }, {
      "heading" : "A.3 LNN-EL Rules",
      "text" : "In our experiments, we explore the following modules, implemented in PyTorch."
    }, {
      "heading" : "Name Rule:",
      "text" : "Rname ← [fjacc(mi, eij) > θ1 ∨ flev(mi, eij) > θ2 ∨ fjw(mi, eij) > θ3 ∨ fspacy(mi, eij) > θ4] ∧ fprom(mi, eij)"
    }, {
      "heading" : "Context Rule:",
      "text" : "Rctx ← [fjacc(mi, eij) > θ1 ∨ flev(mi, eij) > θ2 ∨ fjw(mi, eij) > θ3 ∨ fspacy(mi, eij) > θ4] ∧ fctx(mi, eij) > θ5 ∧ fprom(mi, eij)"
    }, {
      "heading" : "Type Rule:",
      "text" : "Rtype ← [fjacc(mi, eij) > θ1 ∨ flev(mi, eij) > θ2 ∨ fjw(mi, eij) > θ3 ∨ fspacy(mi, eij) > θ4] ∧ ftype(mi, eij) > θ5 ∧ fprom(mi, eij)"
    }, {
      "heading" : "Blink Rule:",
      "text" : "Rblink ← [fjacc(mi, eij) > θ1 ∨ flev(mi, eij) > θ2 ∨ fjw(mi, eij) > θ3 ∨ fspacy(mi, eij) > θ4] ∧ fblink(mi, eij)"
    }, {
      "heading" : "Box Rule:",
      "text" : "Rbox ← [fjacc(mi, eij) > θ1 ∨ flev(mi, eij) > θ2 ∨ fjw(mi, eij) > θ3 ∨ fspacy(mi, eij) > θ4] ∨ fbox(mi, eij) > θ5"
    }, {
      "heading" : "BERT Rule:",
      "text" : "Rbert ← [fjacc(mi, eij) > θ1 ∨ flev(mi, eij) > θ2 ∨ fjw(mi, eij) > θ3 ∨ fspacy(mi, eij) > θ4] ∨ fbert(mi, eij) > θ5\nLNN-EL:\nRLNN−EL ←Rname ∨Rctx ∨Rtype\nLNN-EL+BLINK:\nRLNN−EL+BLINK ←RLNN−EL ∨Rblink\nLNN-ELens:\nRLNN−ELens ←RLNN−EL ∨Rblink ∨Rbox"
    } ],
    "references" : [ {
      "title" : "On active learning of record matching packages",
      "author" : [ "Arvind Arasu", "Michaela Götz", "Raghav Kaushik." ],
      "venue" : "Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data, SIGMOD ’10, page 783–794, New York, NY, USA.",
      "citeRegEx" : "Arasu et al\\.,? 2010",
      "shortCiteRegEx" : "Arasu et al\\.",
      "year" : 2010
    }, {
      "title" : "Hinge-loss markov random fields and probabilistic soft logic",
      "author" : [ "Stephen H. Bach", "Matthias Broecheler", "Bert Huang", "Lise Getoor." ],
      "venue" : "J. Mach. Learn. Res., 18(1):3846–3912.",
      "citeRegEx" : "Bach et al\\.,? 2017",
      "shortCiteRegEx" : "Bach et al\\.",
      "year" : 2017
    }, {
      "title" : "Using encyclopedic knowledge for named entity disambiguation",
      "author" : [ "Razvan Bunescu", "Marius Pasca." ],
      "venue" : "Proceesings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06), pages 9–16, Trento,",
      "citeRegEx" : "Bunescu and Pasca.,? 2006",
      "shortCiteRegEx" : "Bunescu and Pasca.",
      "year" : 2006
    }, {
      "title" : "Example-driven design of efficient record matching queries",
      "author" : [ "S. Chaudhuri", "Bee-Chung Chen", "V. Ganti", "R. Kaushik." ],
      "venue" : "VLDB.",
      "citeRegEx" : "Chaudhuri et al\\.,? 2007",
      "shortCiteRegEx" : "Chaudhuri et al\\.",
      "year" : 2007
    }, {
      "title" : "Large-scale named entity disambiguation based on Wikipedia data",
      "author" : [ "Silviu Cucerzan." ],
      "venue" : "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-",
      "citeRegEx" : "Cucerzan.,? 2007",
      "shortCiteRegEx" : "Cucerzan.",
      "year" : 2007
    }, {
      "title" : "A survey of the state of explainable AI for natural language processing",
      "author" : [ "Marina Danilevsky", "Kun Qian", "Ranit Aharonov", "Yannis Katsis", "Ban Kawas", "Prithviraj Sen." ],
      "venue" : "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Associa-",
      "citeRegEx" : "Danilevsky et al\\.,? 2020",
      "shortCiteRegEx" : "Danilevsky et al\\.",
      "year" : 2020
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova" ],
      "venue" : null,
      "citeRegEx" : "Devlin et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Monoidal t-norm based logic: Towards a logic for left-continuous t-norms",
      "author" : [ "F. Esteva", "L. Godo." ],
      "venue" : "Fuzzy Sets and Systems.",
      "citeRegEx" : "Esteva and Godo.,? 2001",
      "shortCiteRegEx" : "Esteva and Godo.",
      "year" : 2001
    }, {
      "title" : "Learning explanatory rules from noisy data",
      "author" : [ "Richard Evans", "Edward Grefenstette." ],
      "venue" : "JAIR.",
      "citeRegEx" : "Evans and Grefenstette.,? 2018",
      "shortCiteRegEx" : "Evans and Grefenstette.",
      "year" : 2018
    }, {
      "title" : "Fast and accurate annotation of short texts with wikipedia pages",
      "author" : [ "Paolo Ferragina", "Ugo Scaiella." ],
      "venue" : "IEEE Softw., 29(1):70–75.",
      "citeRegEx" : "Ferragina and Scaiella.,? 2012",
      "shortCiteRegEx" : "Ferragina and Scaiella.",
      "year" : 2012
    }, {
      "title" : "Deep joint entity disambiguation with local neural attention",
      "author" : [ "Octavian-Eugen Ganea", "Thomas Hofmann." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2619–2629, Copenhagen, Denmark. Associa-",
      "citeRegEx" : "Ganea and Hofmann.,? 2017",
      "shortCiteRegEx" : "Ganea and Hofmann.",
      "year" : 2017
    }, {
      "title" : "Introduction to Statistical Relational Learning (Adaptive Computation and Machine Learning)",
      "author" : [ "Lise Getoor", "Ben Taskar." ],
      "venue" : "The MIT Press.",
      "citeRegEx" : "Getoor and Taskar.,? 2007",
      "shortCiteRegEx" : "Getoor and Taskar.",
      "year" : 2007
    }, {
      "title" : "Learning dense representations for entity retrieval",
      "author" : [ "Daniel Gillick", "Sayali Kulkarni", "Larry Lansing", "Alessandro Presta", "Jason Baldridge", "Eugene Ie", "Diego Garcia-Olano" ],
      "venue" : null,
      "citeRegEx" : "Gillick et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Gillick et al\\.",
      "year" : 2019
    }, {
      "title" : "A survey of methods for explaining black box models",
      "author" : [ "Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini", "Fosca Giannotti", "Dino Pedreschi." ],
      "venue" : "ACM Computing Surveys.",
      "citeRegEx" : "Guidotti et al\\.,? 2018",
      "shortCiteRegEx" : "Guidotti et al\\.",
      "year" : 2018
    }, {
      "title" : "Hil: A high-level scripting language for entity integration",
      "author" : [ "Mauricio Hernández", "Georgia Koutrika", "Rajasekar Krishnamurthy", "Lucian Popa", "Ryan Wisnesky." ],
      "venue" : "Proceedings of the 16th International Conference on Extending Database Technol-",
      "citeRegEx" : "Hernández et al\\.,? 2013",
      "shortCiteRegEx" : "Hernández et al\\.",
      "year" : 2013
    }, {
      "title" : "Kore: Keyphrase overlap relatedness for entity disambiguation",
      "author" : [ "Johannes Hoffart", "Stephan Seufert", "Dat Ba Nguyen", "Martin Theobald", "Gerhard Weikum." ],
      "venue" : "Proceedings of the 21st ACM International Conference on Information and Knowledge",
      "citeRegEx" : "Hoffart et al\\.,? 2012",
      "shortCiteRegEx" : "Hoffart et al\\.",
      "year" : 2012
    }, {
      "title" : "Robust disambiguation of named entities in text",
      "author" : [ "Johannes Hoffart", "Mohamed Amir Yosef", "Ilaria Bordino", "Hagen Fürstenau", "Manfred Pinkal", "Marc Spaniol", "Bilyana Taneva", "Stefan Thater", "Gerhard Weikum." ],
      "venue" : "Proceedings of the 2011 Conference",
      "citeRegEx" : "Hoffart et al\\.,? 2011",
      "shortCiteRegEx" : "Hoffart et al\\.",
      "year" : 2011
    }, {
      "title" : "Leveraging abstract meaning representation for knowledge",
      "author" : [ "Pavan Kapanipathi", "Ibrahim Abdelaziz", "Srinivas Ravishankar", "Salim Roukos", "Alexander Gray", "Ramon Astudillo", "Maria Chang", "Cristina Cornelio", "Saswati Dana", "Achille Fokoue" ],
      "venue" : null,
      "citeRegEx" : "Kapanipathi et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Kapanipathi et al\\.",
      "year" : 2021
    }, {
      "title" : "Efficient one-pass end-to-end entity linking for questions",
      "author" : [ "Belinda Z. Li", "Sewon Min", "Srinivasan Iyer", "Yashar Mehdad", "Wen-tau Yih." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Zero-shot entity linking by reading entity descriptions",
      "author" : [ "Lajanugen Logeswaran", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova", "Jacob Devlin", "Honglak Lee." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Logeswaran et al\\.,? 2019",
      "shortCiteRegEx" : "Logeswaran et al\\.",
      "year" : 2019
    }, {
      "title" : "Dbpedia spotlight: shedding light on the web of documents",
      "author" : [ "Pablo N Mendes", "Max Jakob", "Andrés García-Silva", "Christian Bizer." ],
      "venue" : "Proceedings of the 7th international conference on semantic systems, pages 1–8.",
      "citeRegEx" : "Mendes et al\\.,? 2011",
      "shortCiteRegEx" : "Mendes et al\\.",
      "year" : 2011
    }, {
      "title" : "Wikify! linking documents to encyclopedic knowledge",
      "author" : [ "Rada Mihalcea", "Andras Csomai." ],
      "venue" : "Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM ’07, page 233–242, New York, NY,",
      "citeRegEx" : "Mihalcea and Csomai.,? 2007",
      "shortCiteRegEx" : "Mihalcea and Csomai.",
      "year" : 2007
    }, {
      "title" : "Learning from positive data",
      "author" : [ "Stephen Muggleton." ],
      "venue" : "Worshop on ILP.",
      "citeRegEx" : "Muggleton.,? 1996",
      "shortCiteRegEx" : "Muggleton.",
      "year" : 1996
    }, {
      "title" : "Aida-light: High-throughput named-entity disambiguation",
      "author" : [ "D. Nguyen", "Johannes Hoffart", "M. Theobald", "G. Weikum." ],
      "venue" : "LDOW.",
      "citeRegEx" : "Nguyen et al\\.,? 2014",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2014
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D. Manning." ],
      "venue" : "Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Generic statistical relational entity resolution in knowledge graphs",
      "author" : [ "J. Pujara", "L. Getoor." ],
      "venue" : "ArXiv, abs/1607.00992.",
      "citeRegEx" : "Pujara and Getoor.,? 2016",
      "shortCiteRegEx" : "Pujara and Getoor.",
      "year" : 2016
    }, {
      "title" : "Local and global algorithms for disambiguation to Wikipedia",
      "author" : [ "Lev Ratinov", "Dan Roth", "Doug Downey", "Mike Anderson." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technolo-",
      "citeRegEx" : "Ratinov et al\\.,? 2011",
      "shortCiteRegEx" : "Ratinov et al\\.",
      "year" : 2011
    }, {
      "title" : "Query2box: Reasoning over knowledge graphs in vector space using box embeddings",
      "author" : [ "Hongyu Ren", "Weihua Hu", "Jure Leskovec." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,",
      "citeRegEx" : "Ren et al\\.,? 2020",
      "shortCiteRegEx" : "Ren et al\\.",
      "year" : 2020
    }, {
      "title" : "Markov logic networks",
      "author" : [ "Matthew Richardson", "Pedro Domingos." ],
      "venue" : "Mach. Learn., 62(1–2):107–136.",
      "citeRegEx" : "Richardson and Domingos.,? 2006",
      "shortCiteRegEx" : "Richardson and Domingos.",
      "year" : 2006
    }, {
      "title" : "Old is gold: Linguistic driven approach for entity and relation linking of short text",
      "author" : [ "Ahmad Sakor", "Isaiah Onando Mulang", "Kuldeep Singh", "Saeedeh Shekarpour", "Maria Esther Vidal", "Jens Lehmann", "Sören Auer" ],
      "venue" : null,
      "citeRegEx" : "Sakor et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Sakor et al\\.",
      "year" : 2019
    }, {
      "title" : "Entity linking with a knowledge base: Issues, techniques, and solutions",
      "author" : [ "W. Shen", "J. Wang", "J. Han." ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering, 27(2):443–460.",
      "citeRegEx" : "Shen et al\\.,? 2015",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2015
    }, {
      "title" : "Linking named entities to any database",
      "author" : [ "Avirup Sil", "Ernest Cronin", "Penghai Nie", "Yinfei Yang", "Ana-Maria Popescu", "Alexander Yates." ],
      "venue" : "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Com-",
      "citeRegEx" : "Sil et al\\.,? 2012",
      "shortCiteRegEx" : "Sil et al\\.",
      "year" : 2012
    }, {
      "title" : "Entity resolution with markov logic",
      "author" : [ "Parag Singla", "Pedro Domingos." ],
      "venue" : "Proceedings of the Sixth International Conference on Data Mining, ICDM ’06, page 572–582, USA. IEEE Computer Society.",
      "citeRegEx" : "Singla and Domingos.,? 2006",
      "shortCiteRegEx" : "Singla and Domingos.",
      "year" : 2006
    }, {
      "title" : "Yago: a core of semantic knowledge",
      "author" : [ "Fabian M Suchanek", "Gjergji Kasneci", "Gerhard Weikum." ],
      "venue" : "Proceedings of the 16th international conference on World Wide Web, pages 697–706.",
      "citeRegEx" : "Suchanek et al\\.,? 2007",
      "shortCiteRegEx" : "Suchanek et al\\.",
      "year" : 2007
    }, {
      "title" : "Lc-quad: A corpus for complex question answering over knowledge graphs",
      "author" : [ "Priyansh Trivedi", "Gaurav Maheshwari", "Mohnish Dubey", "Jens Lehmann." ],
      "venue" : "The Semantic Web – ISWC 2017, pages 210–218, Cham. Springer International Publishing.",
      "citeRegEx" : "Trivedi et al\\.,? 2017",
      "shortCiteRegEx" : "Trivedi et al\\.",
      "year" : 2017
    }, {
      "title" : "9th challenge on question answering over linked data (qald-9) (invited paper)",
      "author" : [ "Ricardo Usbeck", "Ria Hari Gusmita", "AxelCyrille Ngonga Ngomo", "M. Saleem." ],
      "venue" : "Semdeep/NLIWoD@ISWC.",
      "citeRegEx" : "Usbeck et al\\.,? 2018",
      "shortCiteRegEx" : "Usbeck et al\\.",
      "year" : 2018
    }, {
      "title" : "Wikidata: A free collaborative knowledgebase",
      "author" : [ "Denny Vrandečić", "Markus Krötzsch." ],
      "venue" : "Commun. ACM, 57(10):78–85.",
      "citeRegEx" : "Vrandečić and Krötzsch.,? 2014",
      "shortCiteRegEx" : "Vrandečić and Krötzsch.",
      "year" : 2014
    }, {
      "title" : "Crowder: Crowdsourcing entity resolution",
      "author" : [ "Jiannan Wang", "Tim Kraska", "Michael J. Franklin", "Jianhua Feng." ],
      "venue" : "Proc. VLDB Endow., 5(11):1483–1494.",
      "citeRegEx" : "Wang et al\\.,? 2012",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2012
    }, {
      "title" : "Zero-shot entity linking with dense entity retrieval",
      "author" : [ "Ledell Wu", "Fabio Petroni", "Martin Josifoski", "Sebastian Riedel", "Luke Zettlemoyer." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Wu et al\\.,? 2020",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Wikipedia2Vec: An efficient toolkit for learning and visualizing the embeddings of words and entities from Wikipedia",
      "author" : [ "Ikuya Yamada", "Akari Asai", "Jin Sakuma", "Hiroyuki Shindo", "Hideaki Takeda", "Yoshiyasu Takefuji", "Yuji Matsumoto." ],
      "venue" : "In",
      "citeRegEx" : "Yamada et al\\.,? 2020",
      "shortCiteRegEx" : "Yamada et al\\.",
      "year" : 2020
    }, {
      "title" : "Differentiable learning of logical rules for knowledge base reasoning",
      "author" : [ "Fan Yang", "Zhilin Yang", "William W Cohen." ],
      "venue" : "NeurIPS.",
      "citeRegEx" : "Yang et al\\.,? 2017",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2017
    }, {
      "title" : "For example, product t-norm, used in multiple neuro-symbolic rulelearners (Evans and Grefenstette, 2018; Yang et al., 2017), is given by x ∧ y ≡ xy, where x, y ∈ [0, 1] denote input features",
      "author" : [ "Esteva", "Godo" ],
      "venue" : null,
      "citeRegEx" : "Esteva and Godo,? \\Q2001\\E",
      "shortCiteRegEx" : "Esteva and Godo",
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 33,
      "context" : "Entity Linking (EL) is the task of disambiguating textual mentions by linking them to canonical entities provided by a knowledge graph (KG) such as DBpedia, YAGO (Suchanek et al., 2007) or Wikidata (Vrandečić and Krötzsch, 2014).",
      "startOffset" : 162,
      "endOffset" : 185
    }, {
      "referenceID" : 2,
      "context" : ", comprising of multiple sentences) (Bunescu and Pasca, 2006).",
      "startOffset" : 36,
      "endOffset" : 61
    }, {
      "referenceID" : 21,
      "context" : "approach is: 1) extract features measuring some degree of similarity between the textual mention and any one of several candidate entities (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011), followed by 2) the disambiguation step, either heuristics-based (non-learning) (Hoffart et al.",
      "startOffset" : 139,
      "endOffset" : 204
    }, {
      "referenceID" : 4,
      "context" : "approach is: 1) extract features measuring some degree of similarity between the textual mention and any one of several candidate entities (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011), followed by 2) the disambiguation step, either heuristics-based (non-learning) (Hoffart et al.",
      "startOffset" : 139,
      "endOffset" : 204
    }, {
      "referenceID" : 26,
      "context" : "approach is: 1) extract features measuring some degree of similarity between the textual mention and any one of several candidate entities (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011), followed by 2) the disambiguation step, either heuristics-based (non-learning) (Hoffart et al.",
      "startOffset" : 139,
      "endOffset" : 204
    }, {
      "referenceID" : 16,
      "context" : ", 2011), followed by 2) the disambiguation step, either heuristics-based (non-learning) (Hoffart et al., 2011; Sakor et al., 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al.",
      "startOffset" : 88,
      "endOffset" : 160
    }, {
      "referenceID" : 29,
      "context" : ", 2011), followed by 2) the disambiguation step, either heuristics-based (non-learning) (Hoffart et al., 2011; Sakor et al., 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al.",
      "startOffset" : 88,
      "endOffset" : 160
    }, {
      "referenceID" : 9,
      "context" : ", 2011), followed by 2) the disambiguation step, either heuristics-based (non-learning) (Hoffart et al., 2011; Sakor et al., 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al.",
      "startOffset" : 88,
      "endOffset" : 160
    }, {
      "referenceID" : 21,
      "context" : ", 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011; Hoffart et al., 2012; Ganea and Hofmann, 2017), to link the mention to an actual entity.",
      "startOffset" : 56,
      "endOffset" : 168
    }, {
      "referenceID" : 4,
      "context" : ", 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011; Hoffart et al., 2012; Ganea and Hofmann, 2017), to link the mention to an actual entity.",
      "startOffset" : 56,
      "endOffset" : 168
    }, {
      "referenceID" : 26,
      "context" : ", 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011; Hoffart et al., 2012; Ganea and Hofmann, 2017), to link the mention to an actual entity.",
      "startOffset" : 56,
      "endOffset" : 168
    }, {
      "referenceID" : 15,
      "context" : ", 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011; Hoffart et al., 2012; Ganea and Hofmann, 2017), to link the mention to an actual entity.",
      "startOffset" : 56,
      "endOffset" : 168
    }, {
      "referenceID" : 10,
      "context" : ", 2019; Ferragina and Scaiella, 2012) or learning-based (Mihalcea and Csomai, 2007; Cucerzan, 2007; Ratinov et al., 2011; Hoffart et al., 2012; Ganea and Hofmann, 2017), to link the mention to an actual entity.",
      "startOffset" : 56,
      "endOffset" : 168
    }, {
      "referenceID" : 29,
      "context" : "Short-text EL is particularly challenging because the limited context surrounding mentions results in greater ambiguity (Sakor et al., 2019).",
      "startOffset" : 120,
      "endOffset" : 140
    }, {
      "referenceID" : 26,
      "context" : "While the use of priors, local features and nonlocal features (for collective linking) has been proposed before (Ratinov et al., 2011), our goal in this paper is to provide an extensible framework that can combine any number of such features and more, including contextual embeddings such as BERT encodings (Devlin et al.",
      "startOffset" : 112,
      "endOffset" : 134
    }, {
      "referenceID" : 6,
      "context" : ", 2011), our goal in this paper is to provide an extensible framework that can combine any number of such features and more, including contextual embeddings such as BERT encodings (Devlin et al., 2019) and Query2box embeddings (Ren et al.",
      "startOffset" : 180,
      "endOffset" : 201
    }, {
      "referenceID" : 27,
      "context" : ", 2019) and Query2box embeddings (Ren et al., 2020), and even the results of previously developed neural EL models (e.",
      "startOffset" : 33,
      "endOffset" : 51
    }, {
      "referenceID" : 13,
      "context" : "Additionally, such a framework must not only allow for easy inclusion of new sources of evidence but also for interpretability of the resulting model (Guidotti et al., 2018).",
      "startOffset" : 150,
      "endOffset" : 173
    }, {
      "referenceID" : 22,
      "context" : "While inductive logic programming (Muggleton, 1996) and statistical relational learning (Getoor and Taskar, 2007) have for long focused on learning FOL rules from labeled data, more recent approaches based on neuro-symbolic AI have led to impressive advances.",
      "startOffset" : 34,
      "endOffset" : 51
    }, {
      "referenceID" : 11,
      "context" : "While inductive logic programming (Muggleton, 1996) and statistical relational learning (Getoor and Taskar, 2007) have for long focused on learning FOL rules from labeled data, more recent approaches based on neuro-symbolic AI have led to impressive advances.",
      "startOffset" : 88,
      "endOffset" : 113
    }, {
      "referenceID" : 38,
      "context" : ", BLINK (Wu et al., 2020)) even though we are constrained on using rules.",
      "startOffset" : 8,
      "endOffset" : 25
    }, {
      "referenceID" : 2,
      "context" : "Approaches such as (Bunescu and Pasca, 2006; Ratinov et al., 2011; Sil et al., 2012; Hoffart et al., 2011; Shen et al., 2015) use a myriad of classical ML and deep learning models to combine priors, local and global features.",
      "startOffset" : 19,
      "endOffset" : 125
    }, {
      "referenceID" : 26,
      "context" : "Approaches such as (Bunescu and Pasca, 2006; Ratinov et al., 2011; Sil et al., 2012; Hoffart et al., 2011; Shen et al., 2015) use a myriad of classical ML and deep learning models to combine priors, local and global features.",
      "startOffset" : 19,
      "endOffset" : 125
    }, {
      "referenceID" : 31,
      "context" : "Approaches such as (Bunescu and Pasca, 2006; Ratinov et al., 2011; Sil et al., 2012; Hoffart et al., 2011; Shen et al., 2015) use a myriad of classical ML and deep learning models to combine priors, local and global features.",
      "startOffset" : 19,
      "endOffset" : 125
    }, {
      "referenceID" : 16,
      "context" : "Approaches such as (Bunescu and Pasca, 2006; Ratinov et al., 2011; Sil et al., 2012; Hoffart et al., 2011; Shen et al., 2015) use a myriad of classical ML and deep learning models to combine priors, local and global features.",
      "startOffset" : 19,
      "endOffset" : 125
    }, {
      "referenceID" : 30,
      "context" : "Approaches such as (Bunescu and Pasca, 2006; Ratinov et al., 2011; Sil et al., 2012; Hoffart et al., 2011; Shen et al., 2015) use a myriad of classical ML and deep learning models to combine priors, local and global features.",
      "startOffset" : 19,
      "endOffset" : 125
    }, {
      "referenceID" : 29,
      "context" : "For short-text EL, some prior works (Sakor et al., 2019; Ferragina and Scaiella, 2012; Mendes et al., 2011) address the joint problem of mention detection and linking, with primary focus on identifying mention spans, while linking is done via heuristic methods without learning.",
      "startOffset" : 36,
      "endOffset" : 107
    }, {
      "referenceID" : 9,
      "context" : "For short-text EL, some prior works (Sakor et al., 2019; Ferragina and Scaiella, 2012; Mendes et al., 2011) address the joint problem of mention detection and linking, with primary focus on identifying mention spans, while linking is done via heuristic methods without learning.",
      "startOffset" : 36,
      "endOffset" : 107
    }, {
      "referenceID" : 20,
      "context" : "For short-text EL, some prior works (Sakor et al., 2019; Ferragina and Scaiella, 2012; Mendes et al., 2011) address the joint problem of mention detection and linking, with primary focus on identifying mention spans, while linking is done via heuristic methods without learning.",
      "startOffset" : 36,
      "endOffset" : 107
    }, {
      "referenceID" : 29,
      "context" : "(Sakor et al., 2019) also jointly extracts relation spans which aide in overall linking performance.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 18,
      "context" : "The recent ELQ (Li et al., 2020) extends BLINK to jointly learn mention detection and linking.",
      "startOffset" : 15,
      "endOffset" : 32
    }, {
      "referenceID" : 32,
      "context" : "Approaches such as (Singla and Domingos, 2006; Pujara and Getoor, 2016) induce probabilistic rules using MLNs (Richardson and Domingos, 2006) and PSL (Bach et al.",
      "startOffset" : 19,
      "endOffset" : 71
    }, {
      "referenceID" : 25,
      "context" : "Approaches such as (Singla and Domingos, 2006; Pujara and Getoor, 2016) induce probabilistic rules using MLNs (Richardson and Domingos, 2006) and PSL (Bach et al.",
      "startOffset" : 19,
      "endOffset" : 71
    }, {
      "referenceID" : 28,
      "context" : "Approaches such as (Singla and Domingos, 2006; Pujara and Getoor, 2016) induce probabilistic rules using MLNs (Richardson and Domingos, 2006) and PSL (Bach et al.",
      "startOffset" : 110,
      "endOffset" : 141
    }, {
      "referenceID" : 1,
      "context" : "Approaches such as (Singla and Domingos, 2006; Pujara and Getoor, 2016) induce probabilistic rules using MLNs (Richardson and Domingos, 2006) and PSL (Bach et al., 2017), respectively.",
      "startOffset" : 150,
      "endOffset" : 169
    }, {
      "referenceID" : 29,
      "context" : "(Sakor et al., 2019; Wu et al., 2020), we use off-the-shelf lookup tools such as DBpedia lookup2 to retrieve top-100 candidates for each mention.",
      "startOffset" : 0,
      "endOffset" : 37
    }, {
      "referenceID" : 38,
      "context" : "(Sakor et al., 2019; Wu et al., 2020), we use off-the-shelf lookup tools such as DBpedia lookup2 to retrieve top-100 candidates for each mention.",
      "startOffset" : 0,
      "endOffset" : 37
    }, {
      "referenceID" : 13,
      "context" : "Fueled by the rise in complexity of deep learning, recently there has been a push towards learning interpretable models (Guidotti et al., 2018; Danilevsky et al., 2020).",
      "startOffset" : 120,
      "endOffset" : 168
    }, {
      "referenceID" : 5,
      "context" : "Fueled by the rise in complexity of deep learning, recently there has been a push towards learning interpretable models (Guidotti et al., 2018; Danilevsky et al., 2020).",
      "startOffset" : 120,
      "endOffset" : 168
    }, {
      "referenceID" : 23,
      "context" : "Type: the overlap similarity of mention mi’s type to eij’s domain (class) set, similar to the domain-entity coherence score proposed in (Nguyen et al., 2014).",
      "startOffset" : 136,
      "endOffset" : 157
    }, {
      "referenceID" : 23,
      "context" : "Unlike in (Nguyen et al., 2014), instead of using a single type for all men-",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 24,
      "context" : "These include SpaCy’s semantic similarity6 function that uses Glove (Pennington et al., 2014) trained on Common Crawl.",
      "startOffset" : 68,
      "endOffset" : 93
    }, {
      "referenceID" : 38,
      "context" : "In addition to SpaCy, we also use scores from an entity linking system such as BLINK (Wu et al., 2020) (a state-of-the-art entity linking model) as a feature function in our system.",
      "startOffset" : 85,
      "endOffset" : 102
    }, {
      "referenceID" : 39,
      "context" : "a pre-trained graph embedding Wiki2Vec (Yamada et al., 2020), i.",
      "startOffset" : 39,
      "endOffset" : 60
    }, {
      "referenceID" : 27,
      "context" : "To this end, we adapt the recent Query2Box (Ren et al., 2020), whose goal is to answer FOL queries over a KG.",
      "startOffset" : 43,
      "endOffset" : 61
    }, {
      "referenceID" : 38,
      "context" : "However, obtaining competitive performance to that of deep learning approaches such as BLINK (Wu et al., 2020) requires a significant amount of man-",
      "startOffset" : 93,
      "endOffset" : 110
    }, {
      "referenceID" : 34,
      "context" : "0 (Trivedi et al., 2017) 4,000 6,823 1000 1,721 QALD-9 (Usbeck et al.",
      "startOffset" : 2,
      "endOffset" : 24
    }, {
      "referenceID" : 35,
      "context" : ", 2017) 4,000 6,823 1000 1,721 QALD-9 (Usbeck et al., 2018) 408 568 150 174 WebQSPEL (Li et al.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 18,
      "context" : ", 2018) 408 568 150 174 WebQSPEL (Li et al., 2020) 2974 3,237 1603 1,798",
      "startOffset" : 33,
      "endOffset" : 50
    }, {
      "referenceID" : 18,
      "context" : "WebQSPEL dataset (Li et al., 2020) comprises of both mention spans and links to the correct entity.",
      "startOffset" : 17,
      "endOffset" : 34
    }, {
      "referenceID" : 38,
      "context" : "We compare our approach to (1) BLINK (Wu et al., 2020), the current state-of-theart on both short-text and long-text EL, (2) three BERT-based models - (a) BERT: both mention and candidate entity embeddings are obtained via BERTbase pre-trained encoder, similar to (Gillick et al.",
      "startOffset" : 37,
      "endOffset" : 54
    }, {
      "referenceID" : 12,
      "context" : ", 2020), the current state-of-theart on both short-text and long-text EL, (2) three BERT-based models - (a) BERT: both mention and candidate entity embeddings are obtained via BERTbase pre-trained encoder, similar to (Gillick et al., 2019), (b) BERTWiki: mention embeddings are obtained from BERTbase, while candidate entity is from pretrained Wiki2Vec (Yamada et al.",
      "startOffset" : 217,
      "endOffset" : 239
    }, {
      "referenceID" : 39,
      "context" : ", 2019), (b) BERTWiki: mention embeddings are obtained from BERTbase, while candidate entity is from pretrained Wiki2Vec (Yamada et al., 2020),",
      "startOffset" : 121,
      "endOffset" : 142
    } ],
    "year" : 2021,
    "abstractText" : "Entity linking (EL), the task of disambiguating mentions in text by linking them to entities in a knowledge graph, is crucial for text understanding, question answering or conversational systems. Entity linking on short text (e.g., single sentence or question) poses particular challenges due to limited context. While prior approaches use either heuristics or blackbox neural methods, here we propose LNNEL, a neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. Even though constrained to using rules, LNN-EL performs competitively against SotA black-box neural approaches, with the added benefits of extensibility and transferability. In particular, we show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, BERT encodings, box embeddings, etc), and even scores resulting from previous EL methods, thus improving on such methods. For instance, on the LC-QuAD-1.0 dataset, we show more than 4% increase in F1 score over previous SotA. Finally, we show that the inductive bias offered by using logic results in learned rules that transfer well across datasets, even without fine tuning, while maintaining high accuracy.",
    "creator" : "LaTeX with hyperref"
  }
}