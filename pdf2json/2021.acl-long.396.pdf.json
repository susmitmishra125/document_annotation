{
  "name" : "2021.acl-long.396.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Reasoning over Entity-Action-Location Graph for Procedural Text Understanding",
    "authors" : [ "Hao Huang", "Xiubo Geng", "Pei Jian", "Guodong Long", "Daxin Jiang" ],
    "emails" : [ "hao.huang-4@{student.uts,uts}.edu.au", "guodong.long@{student.uts,uts}.edu.au", "xigeng@microsoft.com,", "djiang@microsoft.com,", "jpei@cs.sfu.ca" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5100–5109\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n5100"
    }, {
      "heading" : "1 Introduction",
      "text" : "Procedural text often consists of a sequence of sentences describing processes, such as a phenomenon in nature (e.g., how sedimentary rock forms) (Dalvi et al., 2018) or instructions to complete a task (e.g., the recipe of Mac and Cheese) (Bosselut et al., 2018). Given a paragraph and its participant entities, the task of procedural text understanding is to track the states (e.g., create, move, destroy) and locations (a span in the text) of the\n∗Work is done during internship at Microsoft. †Corresponding author.\nentities. Compared with traditional machine reading task, which mainly focuses on the static relations among entities, procedural text understanding is more challenging since it involves discovering complex temporal-spatial relations among various entities from the process dynamics.\nTo effectively track the states and locations of entities, it is crucial to systematically model rich relations among various concepts in the paragraph, including entities, actions, and locations. Three types of relations are of particular interest.\nFirst, mentions of the same entity in different sentences are related. The inherent relation among these mentions may provide clues for a model to generate consistent predictions about the entity. For example, the entity electrical pulses are mentioned in two sentences “The retina’s rods and cones convert it to electrical pulses. The optic nerve carries electrical pulses through the optic canal.”. Connecting its two mentions in two sentences helps to infer its location in the first sentence using the second sentence’s information.\nSecond, detecting connections between an entity and the corresponding actions helps to make state predictions more accurate. Take the sentence “As the encased bones decay, minerals seep in replacing the organic material.” as an example. The entity bone is related to decay which indicates the state destroy, while it is not connected to seep indicating the state move. Given the relation between bone and decay, it is easier for the model to predict the state of bone as destroy, instead of being misled by the action seep.\nLast, when the state or location of one entity changes, it may impact all associated entities. For example, in sentence “trashbags are thrown into trashcans.”, trashbags are associated with trashcans. Then, in the following sentence “The trashcan is emptied by a large trash truck.”, although trashbags are not explicitly mentioned, their loca-\ntions are changed by the association with trashcan. Recent works on procedural text understanding have achieved remarkable progress (Tandon et al., 2018; Bosselut et al., 2018; Gupta and Durrett, 2019b; Du et al., 2019; Das et al., 2019; Gupta and Durrett, 2019a). However, the existing methods do not systematically model the relations among entities, actions, and locations. Instead, most methods either leverage inherent constraints on entity states or exploit external knowledge to make predictions. For example, Gupta and Durrett (2019b) propose a structural neural network to track each entity’s hidden state and summarize the global state transitions with a CRF model. Tandon et al. (2018) inject commonsense knowledge into a neural model with soft and hard constraints. Although Das et al. (2019) model the relation between entities and locations, there is no general framework to model the relations, and some important relations, such as entityaction and entity-entity relations, are ignored.\nA general framework to systematically model the rich types of relations among entities, actions, and locations is essential to procedural text understanding. To the best of our knowledge, we are the first to explore comprehensive relation modeling, representation, and reasoning systematically. Specifically, we first construct an entity-actionlocation graph from a given paragraph, where three types of concepts (i.e., entities, locations, and actions) are identified and extracted as nodes. We then detect critical connections among those concepts and represent them as edges. Finally, we adopt a graph attention network to conduct Reasoning over the Entity-Action-Location graph (REAL), which provides expressive representations for downstream state and location predictions.\nWe evaluate the proposed approach on two benchmark datasets for procedural text understanding, ProPara (Dalvi et al., 2018) and Recipes (Bosselut et al., 2018). Our approach outperforms the state-of-the-art strong baselines by a large marge, i.e., 5.0% on ProPara and 3.2% on Recipes. The ablation study and analysis show that the graph-based reasoning approach generates better representations for entities, locations, and actions. Thus, it is highly valuable for both state and location tracking of entities."
    }, {
      "heading" : "2 Related Work",
      "text" : "REAL is closely related to two lines of works, i.e., procedural text understanding and graph reasoning\nin language understanding.\nProcedural Text Understanding. Compared with early-stage models (Henaff et al., 2017; Seo et al., 2017), recent progress in the procedural text understanding task is mainly made on ensuring the prediction’s consistency or injecting external knowledge. Various approaches (Dalvi et al., 2018; Gupta and Durrett, 2019b; Amini et al., 2020) have been proposed to predict consistent state sequence. For example, NCET (Gupta and Durrett, 2019b) tracks the entity in a continuous space and leverages a conditional random field (CRF) to keep a consistent prediction sequence. Other models inject knowledge from external data sources to complement missing knowledge. ProStruct (Tandon et al., 2018) introduces commonsense constraints to refine the probability space, while KOALA (Zhang et al., 2020) leverages Bert Encoder pre-trained on related corpus from Wiki, and injects the ConceptNet (Speer et al., 2017) knowledge. Besides, a few models (Das et al., 2019; Dalvi et al., 2019) are proposed to build graphs on the procedural text. For instance, KG-MRC (Das et al., 2019) constructs dynamic knowledge graphs between entities and locations. However, these methods can not systematically capture the relations among entities, actions, and locations, and entity-action and entity-entity relations are ignored.\nGraph Reasoning in Language Understanding. Graph-based reasoning methods (Zeng et al., 2020; Zhong et al., 2020; Zheng and Kordjamshidi, 2020) are widely used in natural language understanding tasks to enhance performance. For example, Zeng et al. (2020) constructs a double graph design for the document-level Relation Extraction (RE) task, Zhong et al. (2020) constructs the retrieved evidence sentences as a graph for Fact-Checking task. Compared with these works, the entity-actionlocation graph in our approach copes better with procedural text understanding task since it precisely defines concepts we are concerned within the task and captures the rich and expressive relations among them."
    }, {
      "heading" : "3 Model",
      "text" : "Task Definition. The procedural text understanding task is defined as follows. Given a paragraph P consists of T sentences (S1, S2, ..., ST ), describing the process (e.g., photosynthesis, erosion) of a set of N pre-specified entities {e1, e2, ..., eN},\nwe need to predict the state yst and location y l t for each entity at each step t corresponding to sentence St\n1. Candidate states are pre-defined (e.g., yst ∈ {not exist (O), exist (E), move (M), create (C), destroy (D)} in the ProPara dataset), and location ylt is usually a text span in the paragraph. Gold annotations for state and location at each step t are denoted as ỹst and ỹ s t , respectively.\nFigure 1 shows the overview of our approach, which consists of three main components: graph construction, graph-based representation learning, and prediction module. The graph construction module extracts nodes and edges from the input procedural paragraph and constructs a graph. The graph reasoning module initializes nodes representations using contextual word representations and reasons over the built graph. Finally, the prediction module leverages the graph-based representations to predict the state and location."
    }, {
      "heading" : "3.1 Graph Construction",
      "text" : "Figure 2 shows an example of the graph constructed for a paragraph which describes how fossil forms. A semantic graph is denoted asG = (N,E), where N = {ni}Ki=1 denotes all the nodes, and E = {ei}Li=1 denotes all the edges.\nNodes Extraction. We first extract text spans as nodes from the given paragraph. The text spans in the extracted nodes should cover all essential concepts in the paragraph. Three types of concepts play an important role in the entity tracking task, i.e., actions, entity mentions, and location mentions. Therefore, we extract nodes for them and get all the nodes N = {Na, Ne, Nl} where Na represents\n1We will use step and sentence interchangeably.\naction nodes, Ne represents entity mention nodes, and Nl represents location mention nodes.\nWe first tag all the verbs by an off-the-shelf partof-speech (POS) tagger2 and construct a set of action nodes Na with each node associated with a single verb or a phrase consisting of two consecutive verbs. For the entity mentions, we extract the explicit (exact matching or matching after lemmatization) or implicit (pronouns) mentions of all the entities. Coreference resolution is used to find pronoun mentions in data pre-processing. Besides, we utilize the POS tagger to extract location mentions. Each tagged noun or consecutive phrase of adjective + noun is identified as a location mention.\nEdges Generation. Capturing the semantic relations between various nodes is critical for understanding the process dynamics in the procedural text. To this end, we first derive verb-centric semantic structures via semantic role labeling (SRL)3 (Shi and Lin, 2019) for each sentence and then establish intra- and inter-semantic structure edges.\nGiven a verb-centric structure consisting of a central verb and corresponding arguments, we create two types of edges. (1) If an entity mention ne ∈ Ne or location mention nl ∈ Nl is a substring of an argument for verb na ∈ Na, then we connect ne/nl to na. For example, for the sentence “As the encased bones decay, minerals seep in replacing ...”, the verb decay has an argument the encased bones where bones is an entity mention, then we will connect the action node decay and entity mention node bones. (2) Two mentions in two arguments of the same verb are connected too. For example, for the sentence “The trashbags are thrown into a large outdoor trashcan”, the verb thrown has two arguments, the trashbags and into a large outdoor trashcan, then we connect the two mention nodes trashbags and trashcans.\nWe also create edges between mentions of the same entity in different semantic structures. For example, in Figure 2, the entity bones are mentioned in two sentences, which correspond to two entity mention nodes. We connect these two nodes to propagate information from one to the other during graph-based reasoning."
    }, {
      "heading" : "3.2 Graph-based Representation Learning",
      "text" : "Nodes Representation. We first feed the entire paragraph to the BERT (Devlin et al., 2019)\n2https://github.com/flairNLP/flair 3https://github.com/allenai/allennlp.\nmodel, which is then sent into a Bidirectional LSTM (Hochreiter and Schmidhuber, 1997) (BiLSTM) to obtain the contextual embedding for each token. Each node in our graph is associated with a text span in the paragraph. Therefore, the initial node representation is derived by mean pooling over all token embeddings in its corresponding text span. The contextual representation of node ni ∈ N is denoted as hi (i = 1, . . . ,K) with hi ∈ Rd.\nGraph Reasoning. We leverage a graph attention network (GAT) (Velickovic et al., 2018) for reasoning over the built graph. The network performs masked attention over neighbor nodes (i.e., connected with an edge) instead of all the nodes in the graph. We apply a two-layer GAT, which means each node can aggregate information from their two-hop neighbor nodes (nodes that can be reached within two edges).\nIn each GAT layer, we first extract a set of neighbor nodesNi for each node ni. The attention coefficients between node ni and its neighbour nj can be computed through a shared attention mechanism,\neij = a T [Whi‖Whj ], (1)\nwhere a ∈ R2d and W ∈ Rd×d are learnable parameters, and ‖ is the concatenation operation. We apply a LeakyReLU activate function and normalize the attention coefficients,\nαij = softmax j (LeakyReLU (eij)) . (2)\nThen, we aggregate the information from the neighbor nodes with multi-head attention to enhance the stability and efficiency. The aggregated feature for ni with a K-head attention can be represented as\nh′i = K∥∥∥∥ k=1 σ  ∑ nj∈Ni αkijW khj  (3)\nin the first layer, and\nh′′i = σ  1 K K∑ k=1 ∑ nj∈Ni α′kijW ′kh′j  (4) in the second layer, where ‖ is the concatenation operation, σ is the sigmoid activate function, Wk ∈ Rd×d is learnable matrix for kth head in first layer, and W′k ∈ RKd×d is learnable matrix for kth head in second layer. αkij and α ′k ij are calculated with the corresponding Wk and W′k, respectively."
    }, {
      "heading" : "3.3 Prediction Model",
      "text" : "Inspired by NCET (Gupta and Durrett, 2019b), we track the state and location separately, by a state tracking and a location prediction module. Each module takes the representations of concerned nodes as input and outputs the prediction (i.e., state or location of an entity) at each time step.\nState Tracking. Given a paragraph P and an entity e, the state tracking module tracks the state of the entity for each sentence. We first generate the representations of all sentences for the entity. Considering that actions are good state-changing signals, we concatenate the embeddings of entity\nmention node and action node in the sentence as representation at step t. That is,\nxet = { [het‖hvt ], if St contains ne 0, otherwise\n(5)\nwhere xet denotes the representation of entity e in sentence St , het denotes the representation of the entity mention node ne in sentence St, hvt denotes the representation of the action node na connected with ne in sentence St. If entity e is not mentioned in sentence St, we use zero vector as representation of St for e. Note if there are multiple mention nodes for the entity e in sentence St, we take the mean pooling over all mention nodes as het . And we take similar approach for multiple actions.\nWe utilize a BiLSTM layer on the sequence of sentence embeddings. And a conditional random field (CRF) (Durrett and Klein, 2015) is applied on the top of the BiLSTM to make the final prediction. The loss function for the state tracking module is defined as Lstate = − ∑\n(e,P )∈D\n1\nT T∑ t=1 logP ( ỹst |P, e; θG, θst ) ,\n(6) whereD is the training collection containing entityparagraph pairs, P ( ỹst |P, e; θG, θst ) represents the predicted probability of gold state ỹst in sentence St given the entity e and paragraph P , θG are parameters for graph reasoning and the text encoder, and θst are parameters in state tracking module.\nLocation Prediction. For the location prediction module, we first collect all the location mention nodes as location candidates set C. We add an isolated location node to represent the special location\ncandidate ‘?’, which means the location cannot be found in the paragraph. The representation of this node is randomly initialized and learnable during the training process.\nGiven an entity e and location candidate l ∈ C, we represent the sentence St as\nxlt = [h e t‖hlt], (7)\nwhere het and h l t denotes the representation of the entity mention node and location mention node in sentence St. If the entity or location candidate is not mentioned in sentence St, we use a zero vector replacing het or h l t.\nWe use a BiLSTM followed by a linear layer for the location predictor. The model outputs a score for each candidate at each step t. Then, we apply a softmax layer over all the location candidates’ scores at the same step, resulting in a normalized probabilistic distribution. The location loss is defined as Lloc = − ∑\n(e,P )∈D\n1\nT T∑ t=1 logP ( ỹlt|P, e; θG, θloc ) ,\n(8) whereP ( ỹlt|P, e; θG, θloc ) represents the predicted probability of gold location ỹlt for entity e in sentence St, and θloc are parameters for location prediction module."
    }, {
      "heading" : "3.4 Learning and Inference",
      "text" : "We create a single graph for each paragraph, which stays unchanged once created. Then the graph reasoning module and state/location prediction module are jointly trained in an end-to-end manner. The overall loss is defined as\nLtotal = Lstate + λlocLloc, (9)\nwhere λloc is the hyper-parameter to balance the state tracking and the location prediction loss.\nWe perform inference in pipeline mode. Specifically, for each entity, we first apply the state tracking module to infer its state at each time step. Then we only predict its location at steps when its state is changed (i.e., the predicted state is create or move4). And the locations of an entity with unchanged states can be inferred according to its locations in previous steps. Such pipeline fashion\n4The location of an entity will be None if its state is destroy. Therefore, we do not need to predict its location when an entity is destroyed.\ncan increase consistency between states and locations of an entity than inferring location and state simultaneously."
    }, {
      "heading" : "4 Experiments",
      "text" : "This section describes the evaluation results of REAL on two datasets (ProPara (Dalvi et al., 2018) and Recipes (Bosselut et al., 2018)). We also provide ablation study and case analysis to illustrate the effectiveness of graph-based reasoning."
    }, {
      "heading" : "4.1 Datasets and Evaluation Metrics",
      "text" : "ProPara contains procedural texts about scientific processes, e.g., photosynthesis, fossil formulation. It contains about 1.9k instances (one entityparagraph pair as an instance) written and annotated by human crowd workers. We follow the official split (Dalvi et al., 2018) for train/dev/test set. The Recipes dataset consists of paragraphs describing cooking procedures and their ingredients as entities. We only use the human-labeled data in our experiment, with 80%/10%/10% of the data for train/dev/test, respectively. Detail statistics for the two datasets can be found in Table 1.\nWe follow previous work’s setting (Dalvi et al., 2018) and evaluate the proposed approach on two types of tasks on the ProPara dataset, documentlevel task and sentence-level task. Document-level task focuses on figuring out input entities, output entities, entity conversions, and entity movements by answering corresponding questions. More details can be found in the official script5. Following the official script, we evaluate models with averaged precision, recall, and F1 scores. In sentencelevel task, we need to answer three categories of questions: (Cat-1) Is entity e created (destroyed, moved) in the process? (Cat-2) When is e created (destroyed, moved)? (Cat-3) Where is e created (destroyed, moved from/to)? For this task, we take\n5https://github.com/allenai/aristo-leaderboard/tree/master /propara\nmacro-average and micro-average of the score for three sets of questions as evaluation metrics6.\nFor the Recipes dataset, we take the same setting as (Zhang et al., 2020), where the goal is to predict the ingredients’ location changes during the process. We take precision, recall, and F1 scores to evaluate models7."
    }, {
      "heading" : "4.2 Implementation Details",
      "text" : "We use Bert base (Devlin et al., 2019) as encoder and reason with 3-heads GAT. Batch size is set to 16, and embedding size is set to 256. The learning rate r, location loss coefficient λloc and dropout rate d are derived by grid searching with in 9 trials in r ∈ {2.5 × 10−5, 3 × 10−5, 3.5 × 10−5}, λloc ∈ {0.2, 0.3, 0.4}, and d ∈ {0.3, 0.4, 0.5}. The implementation is based on Python and trained on a Tesla P40 GPU with Adam optimizer for approximately one hour (with approximately 112M parameters). We choose the best model with highest prediction accuracy on development set."
    }, {
      "heading" : "4.3 Main Results",
      "text" : "Table 2 compares REAL with previous work on the ProPara data for both document-level and sentencelevel tasks. Our proposed approach consistently outperforms all previous models, which do not utilize external knowledge on all metrics. In particular, compared to DYNAPRO, it increases the document-level F1 score by 5.3%, and sentencelevel macro averaged accuracy from 55.4% to 58.2%. Without any external data, our approach achieves comparable results to KOALA, which extensively leverages rich external knowledge in ConceptNet and Wikipedia pages, demonstrating the effectiveness of exploiting the entity-actionlocation graph. We also compare REAL with the re-implemented NCET8 on the Recipes dataset. As shown in 3, REAL also surpass the strong baseline by 3.2%. All these results verify the effectiveness of the proposed graph-based reasoning approach."
    }, {
      "heading" : "4.4 Ablations",
      "text" : "We conduct an ablation study to testify the effectiveness of multiple components in our approach. Table 4 and Table 3 list the results on ProPara and\n6https://github.com/allenai/propara/tree/master/propara/ evaluation\n7https://github.com/ytyz1307zzh/Recipes 8The re-implemented NCET achieves comparable accuracy with the previous state-of-the-art algorithm, DYNAPRO, i.e., 65.2% F1 score for NCET v.s. 65.5% for DYNAPRO.\nRecipes, respectively. As shown in Table 4, removing the graph-based representation learning for location/state prediction decreases the F1 score by 3.1%/3.6%, the gap becomes 4.4% without any graph-based reasoning. We can get similar observations on the Recipes dataset, indicating that exploiting the paragraph’s rich relations is critical for both state tracking and location prediction."
    }, {
      "heading" : "4.5 Analyses of Different Relations",
      "text" : "To further illustrate the effectiveness of different types of relations, we conduct below analyses and present three cases with predictions of REAL with and without graph reasoning in Figure 5.\nFirst, to verify the effectiveness of action-entity relations in multi-verb sentences, we compare REAL of with and without graph reasoning on sen-\ntences containing multiple (i.e., more than 2) verbs in Table 5. We figure out that graph-based reasoning increases the performance by 5.7%, indicating that accurately connecting entities and corresponding actions improves the prediction accuracy. For case 1 shown in Figure 5, the relation between the entity bone the action decay helps the model to correctly predict the state of bone as destroy since the action decay indicates destroy. However, without such accurate connection between bone and decay, the prediction model is very likely to be misled by other actions such as seep or replace.\nSecond, we illustrate the impact of entity-entity relations by comparing our approach and baseline where the entity is not explicitly mentioned9. As shown in Table 5, REAL increase the accuracy by 4.8%, which indicates the effectiveness of our approach by modeling cross-entity relations. The second case in Figure 5 illustrates the effectiveness of using entity-entity relations. The entity bags is not explicitly mentioned in the sentence “Trashcan gets emptied into trash truck”, and thus the baseline model cannot correctly predict its state and\n9We only compare performance for those entity-sentence pairs with gold state as Move, Create and Destroy.\nlocation. However, connecting it to the entity trashcan which is derived in the first sentence, helps the model infer its state and location correctly.\nThird, as discussed in section 1, mentionmention connections might improve accuracy when there are multiple mentions for the same entity. The third case in Figure 5 shows how REAL utilizes relations between different mentions for the same entity. In the first sentence, the location of entity small image is not mentioned, which results in wrong location prediction when no graph reasoning is used. In contrast, the built graph connects this mention with preposition it in the second sentence where its location is revealed as retina. Therefore, our model correctly predicts small image’s location by graph-based representation learning."
    }, {
      "heading" : "4.6 Error Analyses",
      "text" : "We randomly sample 100 wrongly predicted examples and summarize them into the following types.\nFirst, the ambiguity between similar entities makes it difficult to derive accurate representations for them. For instance, fixed nitrogen and gasbased nitrogen are two different entities related to nitrogen in the paragraph “Nitrogen exists naturally in the atmosphere. Bacteria in soil fix the nitrogen. Nitrogen is now usable by living things.”. It is difficult for a model to distinguish which entity the mention nitrogen refers to.\nSecond, commonsense knowledge is required. For example, it is difficult to infer the location of\nthe entity bone in the sentence “An animal dies. It is buried in a watery environment.” without the knowledge “bone is part of animal”. Therefore, injecting appropriate external knowledge while avoiding noise may improve the model.\nThird, similar actions indicate different states in different contexts. For instance, in sentence “the tree eventually dies.”, the state of tree is labeled as destroy, while in sentence “most fossils formed when animals or plants die in wet environment.”, the state of animals and plants are all annotated as exist, which may confuse the model."
    }, {
      "heading" : "5 Conclusion and Future Work",
      "text" : "In this work, we propose a novel approach REAL for procedural text understanding. Unlike all previous works, we systematically exploit the rich semantic relations between entities, location, and actions. We design an entity-action-location graph to systematically model various types of concepts and their relations and develop the algorithms for graph construction, representation, and reasoning. We comprehensively conduct a quantitative and qualitative comparison of the proposed approach with strong baselines on two popular benchmark datasets for procedural text understanding and demonstrate the effectiveness of our approach. In the future, we will investigate approaches to further advance the procedural text understanding task, such as incorporating entity disambiguation and external knowledge in our approach."
    } ],
    "references" : [ {
      "title" : "Procedural reading comprehension with attribute-aware context flow",
      "author" : [ "Aida Amini", "Antoine Bosselut", "Bhavana Dalvi Mishra", "Yejin Choi", "Hannaneh Hajishirzi." ],
      "venue" : "Conference on Automated Knowledge Base Construction, AKBC 2020, Virtual, June",
      "citeRegEx" : "Amini et al\\.,? 2020",
      "shortCiteRegEx" : "Amini et al\\.",
      "year" : 2020
    }, {
      "title" : "Simulating action dynamics with neural process networks",
      "author" : [ "Antoine Bosselut", "Omer Levy", "Ari Holtzman", "Corin Ennis", "Dieter Fox", "Yejin Choi." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April",
      "citeRegEx" : "Bosselut et al\\.,? 2018",
      "shortCiteRegEx" : "Bosselut et al\\.",
      "year" : 2018
    }, {
      "title" : "Tracking state changes in procedural text: a challenge dataset and models for process paragraph comprehension",
      "author" : [ "Bhavana Dalvi", "Lifu Huang", "Niket Tandon", "Wen-tau Yih", "Peter Clark." ],
      "venue" : "Proceedings of the 2018 Conference of the North American",
      "citeRegEx" : "Dalvi et al\\.,? 2018",
      "shortCiteRegEx" : "Dalvi et al\\.",
      "year" : 2018
    }, {
      "title" : "Everything happens for a reason: Discovering the purpose of actions in procedural text",
      "author" : [ "Bhavana Dalvi", "Niket Tandon", "Antoine Bosselut", "Wentau Yih", "Peter Clark." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natu-",
      "citeRegEx" : "Dalvi et al\\.,? 2019",
      "shortCiteRegEx" : "Dalvi et al\\.",
      "year" : 2019
    }, {
      "title" : "Building dynamic knowledge graphs from text using machine reading comprehension",
      "author" : [ "Rajarshi Das", "Tsendsuren Munkhdalai", "Xingdi Yuan", "Adam Trischler", "Andrew McCallum." ],
      "venue" : "7th International Conference on Learning Representations,",
      "citeRegEx" : "Das et al\\.,? 2019",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2019
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Be consistent! improving procedural text comprehension using label consistency",
      "author" : [ "Xinya Du", "Bhavana Dalvi Mishra", "Niket Tandon", "Antoine Bosselut", "Wen-tau Yih", "Peter Clark", "Claire Cardie." ],
      "venue" : "Proceedings of the 2019 Conference of the North",
      "citeRegEx" : "Du et al\\.,? 2019",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural CRF parsing",
      "author" : [ "Greg Durrett", "Dan Klein." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Nat-",
      "citeRegEx" : "Durrett and Klein.,? 2015",
      "shortCiteRegEx" : "Durrett and Klein.",
      "year" : 2015
    }, {
      "title" : "Effective use of transformer networks for entity tracking",
      "author" : [ "Aditya Gupta", "Greg Durrett." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan-",
      "citeRegEx" : "Gupta and Durrett.,? 2019a",
      "shortCiteRegEx" : "Gupta and Durrett.",
      "year" : 2019
    }, {
      "title" : "Tracking discrete and continuous entity state for process understanding",
      "author" : [ "Aditya Gupta", "Greg Durrett." ],
      "venue" : "Proceedings of the Third Workshop on Structured Prediction for NLP@NAACL-HLT 2019, Minneapolis, Minnesota, Jun 7, 2019, pages 7–12.",
      "citeRegEx" : "Gupta and Durrett.,? 2019b",
      "shortCiteRegEx" : "Gupta and Durrett.",
      "year" : 2019
    }, {
      "title" : "Tracking the world state with recurrent entity networks",
      "author" : [ "Mikael Henaff", "Jason Weston", "Arthur Szlam", "Antoine Bordes", "Yann LeCun." ],
      "venue" : "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Con-",
      "citeRegEx" : "Henaff et al\\.,? 2017",
      "shortCiteRegEx" : "Henaff et al\\.",
      "year" : 2017
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural Comput., 9(8):1735– 1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Query-reduction networks for question answering",
      "author" : [ "Min Joon Seo", "Sewon Min", "Ali Farhadi", "Hannaneh Hajishirzi." ],
      "venue" : "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference",
      "citeRegEx" : "Seo et al\\.,? 2017",
      "shortCiteRegEx" : "Seo et al\\.",
      "year" : 2017
    }, {
      "title" : "Simple BERT models for relation extraction and semantic role labeling",
      "author" : [ "Peng Shi", "Jimmy Lin." ],
      "venue" : "CoRR, abs/1904.05255.",
      "citeRegEx" : "Shi and Lin.,? 2019",
      "shortCiteRegEx" : "Shi and Lin.",
      "year" : 2019
    }, {
      "title" : "Conceptnet 5.5: An open multilingual graph of general knowledge",
      "author" : [ "Robyn Speer", "Joshua Chin", "Catherine Havasi" ],
      "venue" : "In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Speer et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Speer et al\\.",
      "year" : 2017
    }, {
      "title" : "Reasoning about actions and state changes by injecting commonsense knowledge",
      "author" : [ "Niket Tandon", "Bhavana Dalvi", "Joel Grus", "Wen-tau Yih", "Antoine Bosselut", "Peter Clark." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Lan-",
      "citeRegEx" : "Tandon et al\\.,? 2018",
      "shortCiteRegEx" : "Tandon et al\\.",
      "year" : 2018
    }, {
      "title" : "Graph attention networks",
      "author" : [ "Petar Velickovic", "Guillem Cucurull", "Arantxa Casanova", "Adriana Romero", "Pietro Liò", "Yoshua Bengio." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May",
      "citeRegEx" : "Velickovic et al\\.,? 2018",
      "shortCiteRegEx" : "Velickovic et al\\.",
      "year" : 2018
    }, {
      "title" : "Double graph based reasoning for documentlevel relation extraction",
      "author" : [ "Shuang Zeng", "Runxin Xu", "Baobao Chang", "Lei Li." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, Novem-",
      "citeRegEx" : "Zeng et al\\.,? 2020",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2020
    }, {
      "title" : "Knowledge-aware procedural text understanding with multi-stage training",
      "author" : [ "Zhihan Zhang", "Xiubo Geng", "Tao Qin", "Yunfang Wu", "Daxin Jiang." ],
      "venue" : "CoRR, abs/2009.13199.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "SRLGRN: semantic role labeling graph reasoning network",
      "author" : [ "Chen Zheng", "Parisa Kordjamshidi." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 8881–",
      "citeRegEx" : "Zheng and Kordjamshidi.,? 2020",
      "shortCiteRegEx" : "Zheng and Kordjamshidi.",
      "year" : 2020
    }, {
      "title" : "Reasoning over semantic-level graph for fact checking",
      "author" : [ "Wanjun Zhong", "Jingjing Xu", "Duyu Tang", "Zenan Xu", "Nan Duan", "Ming Zhou", "Jiahai Wang", "Jian Yin." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Zhong et al\\.,? 2020",
      "shortCiteRegEx" : "Zhong et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : ", how sedimentary rock forms) (Dalvi et al., 2018) or instructions to complete a task (e.",
      "startOffset" : 30,
      "endOffset" : 50
    }, {
      "referenceID" : 15,
      "context" : "Recent works on procedural text understanding have achieved remarkable progress (Tandon et al., 2018; Bosselut et al., 2018; Gupta and Durrett, 2019b; Du et al., 2019; Das et al., 2019; Gupta and Durrett, 2019a).",
      "startOffset" : 80,
      "endOffset" : 211
    }, {
      "referenceID" : 1,
      "context" : "Recent works on procedural text understanding have achieved remarkable progress (Tandon et al., 2018; Bosselut et al., 2018; Gupta and Durrett, 2019b; Du et al., 2019; Das et al., 2019; Gupta and Durrett, 2019a).",
      "startOffset" : 80,
      "endOffset" : 211
    }, {
      "referenceID" : 9,
      "context" : "Recent works on procedural text understanding have achieved remarkable progress (Tandon et al., 2018; Bosselut et al., 2018; Gupta and Durrett, 2019b; Du et al., 2019; Das et al., 2019; Gupta and Durrett, 2019a).",
      "startOffset" : 80,
      "endOffset" : 211
    }, {
      "referenceID" : 6,
      "context" : "Recent works on procedural text understanding have achieved remarkable progress (Tandon et al., 2018; Bosselut et al., 2018; Gupta and Durrett, 2019b; Du et al., 2019; Das et al., 2019; Gupta and Durrett, 2019a).",
      "startOffset" : 80,
      "endOffset" : 211
    }, {
      "referenceID" : 4,
      "context" : "Recent works on procedural text understanding have achieved remarkable progress (Tandon et al., 2018; Bosselut et al., 2018; Gupta and Durrett, 2019b; Du et al., 2019; Das et al., 2019; Gupta and Durrett, 2019a).",
      "startOffset" : 80,
      "endOffset" : 211
    }, {
      "referenceID" : 8,
      "context" : "Recent works on procedural text understanding have achieved remarkable progress (Tandon et al., 2018; Bosselut et al., 2018; Gupta and Durrett, 2019b; Du et al., 2019; Das et al., 2019; Gupta and Durrett, 2019a).",
      "startOffset" : 80,
      "endOffset" : 211
    }, {
      "referenceID" : 2,
      "context" : "We evaluate the proposed approach on two benchmark datasets for procedural text understanding, ProPara (Dalvi et al., 2018) and Recipes (Bosselut et al.",
      "startOffset" : 103,
      "endOffset" : 123
    }, {
      "referenceID" : 10,
      "context" : "Compared with early-stage models (Henaff et al., 2017; Seo et al., 2017), recent progress in the procedural text understanding task is mainly made on ensuring the prediction’s consistency or injecting external knowledge.",
      "startOffset" : 33,
      "endOffset" : 72
    }, {
      "referenceID" : 12,
      "context" : "Compared with early-stage models (Henaff et al., 2017; Seo et al., 2017), recent progress in the procedural text understanding task is mainly made on ensuring the prediction’s consistency or injecting external knowledge.",
      "startOffset" : 33,
      "endOffset" : 72
    }, {
      "referenceID" : 2,
      "context" : "Various approaches (Dalvi et al., 2018; Gupta and Durrett, 2019b; Amini et al., 2020) have been proposed to predict consistent state sequence.",
      "startOffset" : 19,
      "endOffset" : 85
    }, {
      "referenceID" : 9,
      "context" : "Various approaches (Dalvi et al., 2018; Gupta and Durrett, 2019b; Amini et al., 2020) have been proposed to predict consistent state sequence.",
      "startOffset" : 19,
      "endOffset" : 85
    }, {
      "referenceID" : 0,
      "context" : "Various approaches (Dalvi et al., 2018; Gupta and Durrett, 2019b; Amini et al., 2020) have been proposed to predict consistent state sequence.",
      "startOffset" : 19,
      "endOffset" : 85
    }, {
      "referenceID" : 9,
      "context" : "For example, NCET (Gupta and Durrett, 2019b) tracks the entity in a continuous space and leverages a conditional random field (CRF) to keep a consistent prediction sequence.",
      "startOffset" : 18,
      "endOffset" : 44
    }, {
      "referenceID" : 15,
      "context" : "ProStruct (Tandon et al., 2018) introduces commonsense constraints to refine the probability space, while KOALA (Zhang",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 14,
      "context" : ", 2020) leverages Bert Encoder pre-trained on related corpus from Wiki, and injects the ConceptNet (Speer et al., 2017) knowledge.",
      "startOffset" : 99,
      "endOffset" : 119
    }, {
      "referenceID" : 4,
      "context" : "Besides, a few models (Das et al., 2019; Dalvi et al., 2019) are proposed to build graphs on the procedural text.",
      "startOffset" : 22,
      "endOffset" : 60
    }, {
      "referenceID" : 3,
      "context" : "Besides, a few models (Das et al., 2019; Dalvi et al., 2019) are proposed to build graphs on the procedural text.",
      "startOffset" : 22,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : "For instance, KG-MRC (Das et al., 2019) constructs dynamic knowledge graphs between entities and locations.",
      "startOffset" : 21,
      "endOffset" : 39
    }, {
      "referenceID" : 17,
      "context" : "Graph-based reasoning methods (Zeng et al., 2020; Zhong et al., 2020; Zheng and Kordjamshidi, 2020) are widely used in natural language understanding tasks to enhance performance.",
      "startOffset" : 30,
      "endOffset" : 99
    }, {
      "referenceID" : 20,
      "context" : "Graph-based reasoning methods (Zeng et al., 2020; Zhong et al., 2020; Zheng and Kordjamshidi, 2020) are widely used in natural language understanding tasks to enhance performance.",
      "startOffset" : 30,
      "endOffset" : 99
    }, {
      "referenceID" : 19,
      "context" : "Graph-based reasoning methods (Zeng et al., 2020; Zhong et al., 2020; Zheng and Kordjamshidi, 2020) are widely used in natural language understanding tasks to enhance performance.",
      "startOffset" : 30,
      "endOffset" : 99
    }, {
      "referenceID" : 13,
      "context" : "To this end, we first derive verb-centric semantic structures via semantic role labeling (SRL)3 (Shi and Lin, 2019) for each sentence and then establish intra- and inter-semantic structure edges.",
      "startOffset" : 96,
      "endOffset" : 115
    }, {
      "referenceID" : 5,
      "context" : "We first feed the entire paragraph to the BERT (Devlin et al., 2019)",
      "startOffset" : 47,
      "endOffset" : 68
    }, {
      "referenceID" : 11,
      "context" : "model, which is then sent into a Bidirectional LSTM (Hochreiter and Schmidhuber, 1997) (BiLSTM) to obtain the contextual embedding for each token.",
      "startOffset" : 52,
      "endOffset" : 86
    }, {
      "referenceID" : 16,
      "context" : "We leverage a graph attention network (GAT) (Velickovic et al., 2018) for reasoning over the built graph.",
      "startOffset" : 44,
      "endOffset" : 69
    }, {
      "referenceID" : 9,
      "context" : "Inspired by NCET (Gupta and Durrett, 2019b), we track the state and location separately, by a state tracking and a location prediction module.",
      "startOffset" : 17,
      "endOffset" : 43
    }, {
      "referenceID" : 7,
      "context" : "And a conditional random field (CRF) (Durrett and Klein, 2015) is applied on the top of the BiLSTM to make the final prediction.",
      "startOffset" : 37,
      "endOffset" : 62
    }, {
      "referenceID" : 2,
      "context" : "This section describes the evaluation results of REAL on two datasets (ProPara (Dalvi et al., 2018) and Recipes (Bosselut et al.",
      "startOffset" : 79,
      "endOffset" : 99
    }, {
      "referenceID" : 2,
      "context" : "We follow the official split (Dalvi et al., 2018) for train/dev/test set.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 2,
      "context" : "We follow previous work’s setting (Dalvi et al., 2018) and evaluate the proposed approach on two types of tasks on the ProPara dataset, documentlevel task and sentence-level task.",
      "startOffset" : 34,
      "endOffset" : 54
    }, {
      "referenceID" : 18,
      "context" : "For the Recipes dataset, we take the same setting as (Zhang et al., 2020), where the goal is to predict the ingredients’ location changes during the process.",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 5,
      "context" : "We use Bert base (Devlin et al., 2019) as encoder and reason with 3-heads GAT.",
      "startOffset" : 17,
      "endOffset" : 38
    } ],
    "year" : 2021,
    "abstractText" : "Procedural text understanding aims at tracking the states (e.g., create, move, destroy) and locations of the entities mentioned in a given paragraph. To effectively track the states and locations, it is essential to capture the rich semantic relations between entities, actions, and locations in the paragraph. Although recent works have achieved substantial progress, most of them focus on leveraging the inherent constraints or incorporating external knowledge for state prediction. The rich semantic relations in the given paragraph are largely overlooked. In this paper, we propose a novel approach (REAL) to procedural text understanding, where we build a general framework to systematically model the entityentity, entity-action, and entity-location relations using a graph neural network. We further develop algorithms for graph construction, representation learning, and state and location tracking. We evaluate the proposed approach on two benchmark datasets, ProPara, and Recipes. The experimental results show that our method outperforms strong baselines by a large margin, i.e., 5.0% on ProPara and 3.2% on Recipes, illustrating the utility of semantic relations and the effectiveness of the graph-based reasoning model.",
    "creator" : "LaTeX with hyperref"
  }
}