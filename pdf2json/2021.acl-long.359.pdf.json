{
  "name" : "2021.acl-long.359.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "How Knowledge Graph and Attention Help? A Qualitative Analysis into Bag-level Relation Extraction",
    "authors" : [ "Zikun Hu", "Yixin Cao", "Lifu Huang", "Tat-Seng Chua" ],
    "emails" : [ "zikunhu@nus.edu.sg,", "yixin.cao@ntu.edu.sg", "lifuh@vt.edu,", "chuats@comp.nus.edu.sg" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4662–4671\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4662"
    }, {
      "heading" : "1 Introduction",
      "text" : "Relation Extraction (RE) is crucial for Knowledge Graph (KG) construction and population. Most recent efforts rely on neural networks to learn efficient features from large-scale annotated data, thus correctly extract the relationship between entities. To save the manual annotation cost and alleviate the issue of data scarcity, distant supervision relation extraction (DSRE) (Mintz et al., 2009) is proposed and becomes increasingly popular as it can automatically generate large-scale labeled data. DSRE is based on a simple yet effective principle: if there is a relation between two entities in KG, then all sentences containing mentions of both entities are\nassumed to express this relation and will form a sentence bag as its annotations.\nAlthough effective, distant supervision may introduce noise to a sentence bag when the assumption fails — some sentences are not describing the target relation (Zeng et al., 2015) (a.k.a. noisy annotation). To alleviate the negative impacts of noise, recent studies (Lin et al., 2016; Ji et al., 2017; Du et al., 2018; Li et al., 2020) leveraged attention to select informative instances from a bag. Furthermore, researchers introduced KG embeddings to enhance the attention mechanism (Hu et al., 2019; Han et al., 2018a). The basic idea is to utilize entity embeddings as the query to compute attention scores, so that the sentences with high attention weights are more likely to be valid annotations (Zhang et al., 2019). Previous studies have shown performance gain on DSRE with attention module and KG embeddings, however, it’s still not clear how these mechanisms work, and, are there any limitations to apply them?\nIn this paper, we aim to provide a thorough and quantitative analysis about the impact of both attention mechanism and KG on DSRE. By analyzing several public benchmarks including NYT-FB60K (Han et al., 2018a), we observe lots of disturbing bags — all of the bag’s sentences are valid or noisy annotations, which shall lead to the failure of attention. As shown in Figure-1, all of annotations in the first disturbing bag are valid, while the learned attentions assign the second annotation\nwith a very low weight, which suggests an inefficient utilization of annotations and exacerbates the data sparsity issue. Or, in the second bag, all sentences are noisy, can attention and KG still improve the performance? If so, how do they work and to what extent can they tolerate these disturbing bags? Answering these questions is crucial since this type of noise is common in practice. The unveiling of their working mechanism shall shed light on future research direction, not limited to DSRE.\nTo achieve this, we propose a paradigm based on newly curated DSRE benchmark, BagRel-Wiki73K extracted from FewRel (Han et al., 2018b) and Wikidata 1, for quantitative analysis of attention and KG. With extensive experiments, we conclude the following innovative and inspiring findings:\n(1) The accuracy of attention is inversely proportional to the total noise ratio and disturbing bag ratio of training data; (2) attention effectively selects valid annotations by comparing their contexts with the semantics of relations, thus tends to rely more on the context to make predictions. However, it somehow lowers the model’s robustness to noisy sentences that do not express the relation; (3) KG-enhanced attention indeed improves RE performance, surprisingly not via enhanced attention accuracy, but by incorporating entity features to reduce the demand of contexts when facing noise; (4) attention could hurt the performance especially when there is no sufficient training data.\nBased on the above observations, we propose a new straightforward yet effective model based on pre-trained BERT (Devlin et al., 2018) for RE with Concatenated KG Embedding, namely BRE+CE. Instead of in-bag attention, it breaks the bag and ensembles the results of all sentences belonging to the bag. For each sentence, we directly incorporate entity embeddings into BERT, rather than to enhance attentions, to improve the robustness of extracting both context and mention features. BRE+CE significantly outperforms existing state-of-the-arts on two publicly available datasets, NYT-FB60K (Han et al., 2018a) and GIDS-FB8K (Jat et al., 2018), by 6% AUC on average. We summarize our contributions as follows:\n• To the best of our knowledge, our proposed framework is the first work to quantitatively analyze the working mechanism of Knowledge Graph and attention for bag-level RE.\n1dumps.wikimedia.org/wikidatawiki/entities/20201109/\n• We have conducted extensive experiments to inspire and support us with the above findings.\n• We demonstrate that a straightforward method based on the findings can achieve improvements on public datasets."
    }, {
      "heading" : "2 Related Work",
      "text" : "To address the issue of insufficient annotations, Mintz et al. (2009) proposed distant supervision to generate training data automatically, which also introduces much noise. From then, DSRE becomes a standard solution that relies on multi-instance learning from a bag of sentences instead of a single sentence (Riedel et al., 2010; Hoffmann et al., 2011). Attention mechanism (Lin et al., 2016) accelerates this trend via strong ability in handling noisy instances within a bag (Liu et al., 2017; Du et al., 2018). Aside from intra-bag attention, Ye and Ling (2019) also designed inter-bag attention simultaneously handling bags with the same relation. To deal with only-one-instance bags, Li et al. (2020) utilized a new selective gate (SeG) framework to independently assign weights to each sentence. External KG is also incorporated to enhance the attention module (Han et al., 2018a; Hu et al., 2019). However, due to the lack of sentencelevel ground truth, it is difficult to quantitatively evaluate the performance of the attention module. Previous researchers tend to provide examples as case study.2 Therefore, we aim to fill in this research gap by constructing a dataset and providing a framework for thorough analysis."
    }, {
      "heading" : "3 Preliminary",
      "text" : "Knowledge Graph (KG) is a directed graph G = {E,R, T}, where E denotes the set of entities, R denotes the set of relation types in G, and T = {(h, r, t)} ⊆ E ×R×E denotes the set of triples. KG embedding models, e.g., RotatE (Sun et al., 2019), can preserve the structure information in the learned vectors eh, et and er. We adopt TransE (Bordes et al., 2013) in experiments.\nBag-level relation extraction (RE) takes a bag of sentences B = {s1, s2, . . . , sm} as input. Each sentence si in the bag contains the same entity pair (h, t), where h, t ∈ E. The goal is to predict a relation y ∈ R between (h, t).\nAttention-based Bag-level RE uses attention to assign a weight to each sentence within a bag.\n2Shahbazi et al. (2020) claim to annotate each positive bag in NYT-FB60K, but haven’t published their code and dataset.\nGiven a bag B from the dataset D, an encoder is first used to encode all sentences from B into vectors {s′1, s′2, . . . , s′m} separately. Then, an attention module computes an attention weight αi for each sentence and outputs the weighted sum of {s′i} as s to denote B:\nωi = vy · s′i (1)\nαi = exp(ωi) m∑ j=1 exp(ωj) (2)\ns = m∑ i=1 αis ′ i (3)\nwhere vy is the label embedding of relation y in the classification layer, we denote this attention module as ATT in the rest of paper.\nKG-enhanced attention aims to improve vy with entities eh and et (Han et al., 2018a):\nrht = eh − et (4)\nωi = rht · tanh(Wss′i + bs) (5)\nwhere rht is regarded as latent relation embedding. We mark this way of computing ωi as KA. Ws and bs are learnable parameters.\nGiven a bag representation s, the classification layer further predicts a confidence of each relation:\no = Wbs+ bb (6)\nP (y|B) = Softmax(o) (7)\nwhere o is a logit vector. Wb and bb are learnable parameters. During training, the loss is computed by:\nL = − n∑\ni=0\nlog(P (yi|Bi)) (8)\nwhere n is the number of training bags in D. Since the classification layer is linear, we can rewrite the bag’s logit vector o using a weighted sum of each sentence’s logit vector o:\noi = Wbs ′ i + bb (9)\no = m∑ i=1 αioi (10)\nFrom equation 10, we can see that the model’s output on the whole bag depends on three aspects: (1) the model’s output on valid sentences within the bag; (2) the model’s output on noisy sentences within the bag; (3) the attention weight assigned to valid sentences and noisy ones."
    }, {
      "heading" : "4 Benchmark",
      "text" : "To quantitatively evaluate the effect of attention and KG on Bag-level RE, we first define two metrics to measure the noise pattern (Section 4.1). Then, we construct a KG and a Bag-level RE dataset (Section 4.2). Finally, we introduce a general evaluation framework to assess attention, KG and the entire RE model (Section 4.3)."
    }, {
      "heading" : "4.1 Metrics Describing Noise Pattern",
      "text" : "To analyze how attention module functions on different noise patterns, we first design 2 metrics to describe the noise pattern: Noise Ratio (NR) and Disturbing Bag Ratio (DR).\nNoise Ratio (NR) represents the proportion of noisy sentences in the dataset. Given a bag Bi and its relation label yi, a sentence sij ∈ Bi is noisy if its context does not express yi. Suppose Isn(sij , yi) is an indicator function to tell whether sij is noise. Then NR is defined as:\nNR =\nn∑ i=1 |Bi|∑ j=1 Isn(sij , yi)\nn∑ i=1 |Bi|\n(11)\nwhere |Bi| is the size of Bi, n is the total number of bags.\nDisturbing Bag Ratio (DR) means the proportion of disturbing bags in the dataset. A bag is disturbing if all sentences in it are valid or all sentences are noisy. Formally, we use function Isd(Bi) to indicate whether a bag is disturbing or not: Isd(Bi) = |Bi|∏ j=1 Isn(sij , yi) + |Bi|∏ j=1 (1− Isn(sij , yi)) (12) Then we define DR as follows:\nDR =\nn∑ i=1 Isd(Bi)\nn (13)"
    }, {
      "heading" : "4.2 Dataset Construction",
      "text" : "Based on FewRel and Wikidata, we construct a Bag-level RE dataset containing multiple training sets with different noise patterns, a test set and a development set. For each sentence in the bags, there is a ground truth attention label indicating whether it is a valid sentence or noise. We also construct a KG containing all entities in the RE dataset by retrieving one-hop triples from Wikidata.\nSynthesize Sentence FewRel is a sentence-level RE dataset, including 80 relations. For each relation, there are 700 valid sentences. Each sentence has a unique entity pair. Every sentence along with its entities and relation label form a tuple (s, h, t, y). We thus synthesize valid and noisy sentences for the same entity pair for data augmentation.\nThe first step is to divide sentences of each relation into 3 sets: trainFewRel, testFewRel and devFewRel, where each set has 500, 100 and 100 sentences. Then, for each tuple (s, h, t, y) in the set, we aim to augment it to a bag B, where all of its sentences contain (h, t). Besides, the sentences in B are either the original s, or a synthesized valid sentence, or a synthesized noisy sentence. We synthesize sentences in the form of (s′, h, t, y, z), where z denotes the attention label (1 for valid, 0 for noisy). In specific, to synthesize a sentence, we randomly replace the source pair of entity mentions with other target entity pairs while keeping the context unchanged. Thus, if the contexts express the same relation type with the entity pair, we can automatically assign an attention label.\nWe illustrate the synthesizing process in Figure 2. (s2, h2, t2, crosses) is a sentence from trainFewRel. To generate a valid sentence, we randomly select another sentence (s1, h1, t1, crosses) which is labeled with the same relation as s2 from trainFewRel. Then we replace its entity mentions h1 and t1 as h2 and t2. The output is (s4, h2, t2, crosses, 1). Since its context correctly describe crosses, we regard s4 as valid. For the noisy sentence, we randomly select a sentence (s3, h3, t3, isA) under another relation. With similar process for s4, we get a synthesize sentence (s5, h2, t2, crosses, 0). Because the context of s5 does not express target relation, we label it as a noise.\nTraining Sets with Different Noise Patterns As defined in Section 4.1, we use NR and DR to measure the noise pattern of Bag-level RE dataset. By controlling the number of synthesized noisy sentences in each bag and the total ratio of noise among all sentences, we can construct several training sets with different patterns. In the following sections, we denote a training set of which the NR is x and DR is y as trainx,y. Higher x and y indicate noisy sentences and disturbing bags account for larger proportion. For example, in Figure 2, assuming there are 4 sentences in trainFewRel, for each sentence, we synthesize two noisy sentences that form the bag together with the original sentence. Thus each bag contains 3 sentences: 1 valid and 2 noisy, and its NR is 2/3 and DR is 0. For the other 3 sets, the number of synthesized noisy sentences equals the sum of original valid sentences and synthesized valid sentences. Thus they all have a NR of 1/2. Since we define bags containing no valid sentences or no noisy sentences as disturbing bags, the third set and fourth set have 2 and 4 disturbing bags, with a DR of 1/2 and 1, respectively.\nTest Set and Development Set We also construct a test and a development set. Similar as the second set in Figure 2, each bag in the test/dev sets contains two sentences, the NR of both sets is 1/2 while the DR is 0. I.e., in every bag of test/dev sets, there is one valid sentence and one noisy sentence. Instead of multiple test sets of different noise patterns, we only have one test set so that the evaluation of different models is consistent. To avoid information leak, when construct trainx,y, test and development sets, the context of synthesized sentences only come from trainFewRel, testFewRel and developmentFewRel, respectively.\nThe final BagRel contains 9 train sets, 1 test and\n1 development set, as listed in Table 1. The NR of the training sets has three options: 1/3, 1/2 or 2/3, and similarly, DR can be 0, 1/2 or 1. The NR of both test and development sets are 1/2, while their DR are 0. All data sets contain 80 relations. For training sets whose NR are 1/3, 1/2 and 2/3, every bag in these sets contains 3, 2 and 3 sentences, respectively.\nKG Construction To evaluate the impact of KG on attention mechanism, we also construct a KG based on Wikidata. Denoting the set of entities appearing in FewRel as E, we link each entity in E to Wikidata by its Freebase ID, and then extract all triples T = (h, r, t) in Wikidata where h, t ∈ E. To evaluate the effect of structural information from KG, we also construct a random KG whose triple set is T̂ . Specifically, for each triple (h, r, t) in T , we corrupt it into (h, r̂, t) by replacing r with a random relation r̂ 6= r. Thus the prior knowledge within the KG is destroyed. KG-73K and KG73Krandom have the same scale: 72,954 entities, 552 relations and 407,821 triples.\nFinally, we obtain BagRel-Wiki73K, including the Bag-level RE sets and KG-73K."
    }, {
      "heading" : "4.3 Evaluation Framework",
      "text" : "We first define several measurements to evaluate the effect of the attention mechanism and KG: Attention Accuracy (AAcc), Area Under precisionrecall Curve (AUC), AUC on Valid sentences (AUCV) and AUC on Noisy sentences (AUCN).\nAAcc measures the attention module’s ability to assign higher weights to valid sentences than noisy sentences. Given a non-disturbing bag (a bag containing both valid and noisy sentences) Bi = {(sj , hi, ti, yi, zj)} and the predicted probability distribution pi, the AAcc of this bag is calculated\nby the following formula:\nAAcci =\nm∑ j=1 m∑ k=1 I(zj)I(1− zk)I(pij > pik)\nm∑ j=1 I(zj) m∑ j=1 I(1− zj)\n(14) wherem = |Bi| is the size ofBi, I(·) is an indicator function which returns 1 or 0 if the input is True\nor False. By m∑ j=1 I(zj) m∑ j=1 I(1− zj), we count how many valid-noisy sentence pairs contained in Bi.\nWith m∑ j=1 m∑ k=1 I(zj)I(1− zk)I(pij > pik), we count how many pairs show higher weight on the valid sentence. Then the AAcc of the whole data set is computed as AAcc = (\nn∑ i=1 AAcci)/n where n is\nthe number of bags in the data set. AAcc is designed specifically for non-disturbing bags. On disturbing bags, with all sentences noisy or valid, it is meaningless to evaluate attention module’s performance. So in test/dev sets of our BagRel-Wiki73k, all bags are non-disturbing bags. Then without distraction, the evaluation results can better present how the attention module works.\nAUC is a standard metric to evaluate DSRE model’s performance on bag-level test set. As mentioned in section 3, attention-based model’s performance on non-disturbing bags relies on three aspects: (1)AAcc, (2) model’s performance on valid sentences and (3) model’s performance on noisy sentences. So we use AUCV and AUCN to measure the second and the third aspects, respectively. The difference between AUC and AUCV is that AUC is computed on the original test set D = {Bi}, while AUCV is AUC computed on the Valid-only test set Dv = {Bvi }. Compared with Bi, Bvi has the same label but removes all noisy sentences within it. Thus there is no noisy context feature in Dv, then models can utilize both entity mentions and contexts to achieve a high AUCV. On the opposite, AUCN is AUC computed on the Noise-only test set Dn = {Bni }, where Bni removes all valid sentences in Bi. Since all context features in Dn are noisy, to achieve a high AUCN, models have to ignore context and rely more on mention features to make predictions.\nAUC, AUCV and AUCN range from 0 to 1, and a higher value of the 3 metrics indicates that a model makes better prediction on the whole bag, valid sentences and noisy sentences, respectively."
    }, {
      "heading" : "5 Method",
      "text" : "To evaluate the effects of attention and KG, we design two straightforward Bag-level RE models without the attention module, BRE and BRE+CE. By comparing their performance with BRE+ATT (BRE with attention module) and BRE+KA (BRE with KG-enhanced attention module), we can have a better understanding of the roles of ATT and Knowledge-enhanced ATT.\nBRE uses BERT (Devlin et al., 2018) as the encoder. Specifically, we follow the way described in (Peng et al., 2020; Soares et al., 2019): entity mentions in sentences are highlighted with special markers before and after mentions. Then the concatenation of head and tail entity representations are used as the representation s′. Since BRE does not have attention mechanism, it breaks the bags and compute loss on each sentence:\nL = − n∑\ni=1 |Bi|∑ j=1 log(P (yi|sij)) (15)\nP (yi|sij) = softmax(Wbs′ij + bb) (16)\nBRE can be viewed as a special case of BRE+ATT. Its attention module assigns all sentences in all bags with the same attention weight 1. During inference, given a bag, BRE uses the mean of each sentence’s prediction as the whole bag’s prediction:\nP (yi|Bi) = ( |Bi|∑ j=1 P (yi|sij))/|Bi| (17)\nBRE+CE concatenates an additional feature vector rht with BERT output, where rht is defined based on entity embeddings of h and t. The concatenated vector is used as the representation of the sentence and fed into the classification layer."
    }, {
      "heading" : "6 Experiment",
      "text" : "We apply our proposed framework on BagRelWiki73K and two real-world datasets to explore the following questions:\n• How noise pattern affects the attention module?\n• Whether attention mechanism promotes RE model’s performance?\n• How KG affects the attention mechanism?\n• Whether attention aggravates data sparsity?"
    }, {
      "heading" : "6.1 Experimental Setup",
      "text" : "For fair comparison, all of baselines share the same encoding structure as BRE. The attentionbased models include BRE+ATT,BRE+KA and BRE+SeG, where SeG (Li et al., 2020) is an advanced attention mechanism which achieves the state-of-the-art performance on NYT-FB60K. Briefly, SeG uses sigmoid instead of softmax to compute attention weights of each instance in a bag. The models without attention are BRE and BRE+CE. To check the effect of noise pattern, we train model on different train sets. As a reminder, trainx,y is a train set whose NR and DR is x and y, respectively."
    }, {
      "heading" : "6.2 Noise Pattern v.s. Attention Accuracy",
      "text" : "We train BRE+ATT on 9 different training sets with different noise patterns. As shown in Figure 3, we can see that: (1) higher noise ratio (NR) makes the model harder to highlight valid sentences, leading to a lower attention accuracy (AAcc); (2) higher disturbing bag ratio (DR) results in lower AAcc, indicating that disturbing bags challenge the attention module. Based on these results, we claim that the noise pattern within the training set largely affects the attention module’s effectiveness."
    }, {
      "heading" : "6.3 Attention v.s. RE Performance",
      "text" : "To quantitatively analyze the effect of attention mechanism, we compare the performance of BRE and BRE+ATT in Table 2, keeping other variables of the model unchanged. Particularly, a higher\nAUCV indicates the stronger ability of the model itself — in an ideal setting without any noise, and a higher AUCN indicates higher robustness of model to noise. Surprisingly, when using the same training set train 1\n2 ,0, the AUC of the attention-enhanced\nmodel is lower than the AUC of the model without attention (0.878 v.s. 0.910). In addition, BRE+ATT has lowest AUC using train 1\n2 ,0, which\nhas no disturbing bags. The highest AAcc (0.881) also suggests that the attention module does effectively select valid sentences. Why the most effective attention module leads to the worst performance? The reason is that BRE+ATT-train 1\n2 ,0 has\na much lower AUCN, which indicates that it is less robust to noisy sentences.\nIs it true that an effective attention module shall hurt model’s robustness to noise? This is actually against our intuition. To answer it, we draw Figure 4 by assigning fixed attention weights to sentences during training. Specifically, each bag in train 1\n2 ,0 has a valid sentence and a noisy sen-\ntence, and we assign fixed attention weight α to the valid and 1 − α to the noisy one, instead of computing α with attention module. Then we test the resulting model’s AUCN and AUCV performance. We can see that when the valid sentences receive higher attention weights, the AUCV curve rises slightly, indicating the model’s performance indeed gets enhanced. Meanwhile, the AUCN curve goes down sharply. This demonstrates the effective attention weakens the model’s robustness to noise. The reason is that the model with a high-performance attention module prefers to utilize context information instead of entity mention features. Thus, it usually fails if most contexts are noisy. Thus we can explain the results in Table 2. train 1\n2 ,0 has the\nhighest AAcc, indicating that it assigns very low weights to noisy sentences. Thus the gain from AUCV can not make up the loss from AUCN, resulting a worse AUC.\nIn conclusion, attention module can effectively select valid sentences during training and test. But\nit has an underlying drawback that it might hurt the model’s ability to predict based on entity mention features, which are important in RE tasks (Li et al., 2020) (Peng et al., 2020), leading to worse overall performance."
    }, {
      "heading" : "6.4 KG v.s. Attention",
      "text" : "To measure KG’s effect on the combined with attention mechanism, we compare the results of KA with ATT, while keeping other parts of the model unchanged. As shown in Table 3. When trained on train 1\n2 ,0, the KG-enhanced model (KA-\ntrain 1 2 ,0) has lower AAcc than the model without KG (ATT-train 1 2 ,0) (0.857 v.s. 0.881), while the AUC is higher (0.932 v.s. 0.878). This is because the KA version has a higher AUCN (0.560) and comparable AUCV and AAcc. Thus, the KGenhanced model achieves better performance on noisy bags, leading to a better RE performance.\nIn addition, comparing Table 2 and Table 3, KA shows lower AAcc and higher AUCN than ATT on all three train sets. This also demonstrates that KG does not promote model’s performance by improving attention module’s accuracy, but by enhancing the encoder and classification layer’s robustness\nto noisy sentences. This makes sense because the information from KG focuses on entities instead of contexts. By incorporating KG, the model relies more on entity mention features instead of noisy contexts feature, thus becomes better at classifying noisy sentences.\nMoreover, comparing BRE+KArand’s performance with BRE+KA on train 1\n2 ,0, we can observe\nthat after incorporating entity embeddings learned from a random KG, BRE+KArand has a much lower attention accuracy. This indicates that misleading knowledge would hurt attention mechanism."
    }, {
      "heading" : "6.5 Attention v.s. Data Sparsity",
      "text" : "Attention module assigns low weights to part of training sentences. When training data is insufficient, not making full use of all training examples could aggravate the data sparsity issue. Thus we compare performance of models trained on subsets of train 1\n2 , 1 2 . From Figure 5, we can see that along\nwith the decreasing size of training data, the performance gap between BRE+ATT and BRE+CE becomes larger. This is because the latter one fully utilizes every example by assigning the same weight 1 to all sentences. We also check each model’s attention weights. BRE+SeG assigns all sentences with weights > 0.9, so its performance drop is similar to the model without attention. Thus, we claim that traditional attention mechanism could exacerbate the model’s ability to insufficient data. This motivates us a better attention mechanism for few-shot settings. We leave it in the future."
    }, {
      "heading" : "6.6 Stability of Attention v.s. Noise Pattern",
      "text" : "From results in Table 2 and Table 3, we can see that the performance of BRE+CE is stable when\nthe ratio of disturbing bags changes. In comparison, BRE+ATT and BRE+KA show varying results across different train sets. On train 1\n2 ,1 which\nhas the most disturbing bags, BRE+CE outperforms BRE+ATT and BRE+KA, demonstrating that BRE+CE could be a competitive method for Bag-level DSRE."
    }, {
      "heading" : "6.7 Results on Real-world Datasets",
      "text" : "Based on previous observations, we find that BRE and BRE+CE could avoid latent drawbacks of attention mechanism and have a stable performance on datasets with different noise patterns, thus they are competitive methods compared with prior baselines. To examine whether they work on the real-world Bag-level DSRE datasets, we compare our method to 3 previous baselines on NYTFB60K (Han et al., 2018a) and GIDS-FB8K (Jat et al., 2018). We select JointE (Han et al., 2018a), RELE (Hu et al., 2019) and SeG (Li et al., 2020) as baselines, because they achieve state-of-the-art performance on bag-level RE. To collect AUC results, we carefully re-run published codes of them using suggested hyperparameters from the original papers. We also draw precision-recall curves following prior works. As shown in Table 4 and Figure 6, our method BRE+CE largely outperforms existing methods on NYT-FB60K and has comparable performance on GIDS-FB8K. Such result demonstrates that we avoid attention mechanism’s latent\ndrawback of hurting model’s robustness. Furthermore, the model’s improvement on NYT-FB60K is promising (around 13% AUC). This is due to two reasons: (1) NYT-FB60K is a noisy dataset containing prevalent disturbing bags, which is similar to our synthesized datasets. (2)NYT-FB60K is highly imbalanced and most relation types only have limited training data, while all relation types in our balanced datasets have the same number of training examples; thus BRE+CE and BRE achieve much higher improvement on NYT-FB60K compared with synthesized datasets. In conclusion, the high performance not only validates our claim that attention module may not perform well on noisy and insufficient training data, but also verifies that our thorough analysis on attention and KG have practical significance."
    }, {
      "heading" : "6.8 Effect of KG",
      "text" : "From results in Table 5, we provide a straight comparison between models with KG (BRE+KA, BRE+CE) and models without KG (BRE+ATT, BRE). Apparently, both methods of utilizing KG (combined with attention and concatenated as additional features) outperforms methods not using KG. This demonstrates the prior knowledge from KG is beneficial for relation extraction task. Except our naive BRE+CE, we expect that a carefully designed mechanism incorporating KG can lead to higher improvement. We leave it in the future."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In conclusion, we construct a set of datasets and propose a framework to quantitatively evaluate how attention module and KG work in the bag-level RE. Based on the findings, we demonstrate the effectiveness of a straightforward solution on this task. Experiment results well support our claims that the accuracy of attention mechanism depends on the noise pattern of the training set. In addition, although effectively selecting valid sentences, attention mechanism could harm model’s robustness to noisy sentences and aggravate the data sparsity\nissue. As for KG’s effects on attention, we observe that it promotes model’s performance by enhancing its robustness with external entity information, instead of improving attention accuracy.\nIn the future, we are interested in developing a more general evaluation framework for other tasks, such as question answering, and improving the attention mechanism to be robust to noise and insufficient data, and an effective approach to incorporate the KG knowledge to guide the model training."
    }, {
      "heading" : "Acknowledgement",
      "text" : "This research/project is supported by NExT Research Centre. This research was also conducted in collaboration with SenseTime. This work is partially supported by A*STAR through the Industry Alignment Fund - Industry Collaboration Projects Grant, by NTU (NTU–ACE2020-01) and Ministry of Education (RG96/20), and by the National Research Foundation, Prime Minister’s Office, Singapore under its Energy Programme (EP Award No. NRF2017EWT-EP003-023) administrated by the Energy Market Authority of Singapore."
    } ],
    "references" : [ {
      "title" : "Translating embeddings for modeling multirelational data",
      "author" : [ "Antoine Bordes", "Nicolas Usunier", "Alberto GarciaDuran", "Jason Weston", "Oksana Yakhnenko." ],
      "venue" : "Neural Information Processing Systems (NIPS), pages 1–9.",
      "citeRegEx" : "Bordes et al\\.,? 2013",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2013
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Multi-level structured self-attentions for distantly supervised relation extraction",
      "author" : [ "Jinhua Du", "Jingguang Han", "Andy Way", "Dadong Wan." ],
      "venue" : "arXiv preprint arXiv:1809.00699.",
      "citeRegEx" : "Du et al\\.,? 2018",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2018
    }, {
      "title" : "Neural knowledge acquisition via mutual attention between knowledge graph and text",
      "author" : [ "Xu Han", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.",
      "citeRegEx" : "Han et al\\.,? 2018a",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2018
    }, {
      "title" : "FewRel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation",
      "author" : [ "Xu Han", "Hao Zhu", "Pengfei Yu", "Ziyun Wang", "Yuan Yao", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Meth-",
      "citeRegEx" : "Han et al\\.,? 2018b",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2018
    }, {
      "title" : "Knowledgebased weak supervision for information extraction of overlapping relations",
      "author" : [ "Raphael Hoffmann", "Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S Weld." ],
      "venue" : "Proceedings of the 49th annual meeting of the association for computational",
      "citeRegEx" : "Hoffmann et al\\.,? 2011",
      "shortCiteRegEx" : "Hoffmann et al\\.",
      "year" : 2011
    }, {
      "title" : "Improving distantly-supervised relation extraction with joint label embedding",
      "author" : [ "Linmei Hu", "Luhao Zhang", "Chuan Shi", "Liqiang Nie", "Weili Guan", "Cheng Yang." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Hu et al\\.,? 2019",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2019
    }, {
      "title" : "Improving distantly supervised relation extraction using word and entity based attention",
      "author" : [ "Sharmistha Jat", "Siddhesh Khandelwal", "Partha Talukdar." ],
      "venue" : "arXiv preprint arXiv:1804.06987.",
      "citeRegEx" : "Jat et al\\.,? 2018",
      "shortCiteRegEx" : "Jat et al\\.",
      "year" : 2018
    }, {
      "title" : "Distant supervision for relation extraction with sentence-level attention and entity descriptions",
      "author" : [ "Guoliang Ji", "Kang Liu", "Shizhu He", "Jun Zhao." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 31.",
      "citeRegEx" : "Ji et al\\.,? 2017",
      "shortCiteRegEx" : "Ji et al\\.",
      "year" : 2017
    }, {
      "title" : "Self-attention enhanced selective gate with entity-aware embedding for distantly supervised relation extraction",
      "author" : [ "Yang Li", "Guodong Long", "Tao Shen", "Tianyi Zhou", "Lina Yao", "Huan Huo", "Jing Jiang." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial In-",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural relation extraction with selective attention over instances",
      "author" : [ "Yankai Lin", "Shiqi Shen", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa-",
      "citeRegEx" : "Lin et al\\.,? 2016",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2016
    }, {
      "title" : "A soft-label method for noisetolerant distantly supervised relation extraction",
      "author" : [ "Tianyu Liu", "Kexiang Wang", "Baobao Chang", "Zhifang Sui." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Liu et al\\.,? 2017",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2017
    }, {
      "title" : "Distant supervision for relation extraction without labeled data",
      "author" : [ "Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky." ],
      "venue" : "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on",
      "citeRegEx" : "Mintz et al\\.,? 2009",
      "shortCiteRegEx" : "Mintz et al\\.",
      "year" : 2009
    }, {
      "title" : "Learning from context or names? an empirical study on neural relation extraction",
      "author" : [ "Hao Peng", "Tianyu Gao", "Xu Han", "Yankai Lin", "Peng Li", "Zhiyuan Liu", "Maosong Sun", "Jie Zhou." ],
      "venue" : "arXiv preprint arXiv:2010.01923.",
      "citeRegEx" : "Peng et al\\.,? 2020",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2020
    }, {
      "title" : "Modeling relations and their mentions without labeled text",
      "author" : [ "Sebastian Riedel", "Limin Yao", "Andrew McCallum." ],
      "venue" : "Joint European Conference",
      "citeRegEx" : "Riedel et al\\.,? 2010",
      "shortCiteRegEx" : "Riedel et al\\.",
      "year" : 2010
    }, {
      "title" : "Relation extraction with explanation",
      "author" : [ "Hamed Shahbazi", "Xiaoli Z Fern", "Reza Ghaeini", "Prasad Tadepalli." ],
      "venue" : "arXiv preprint arXiv:2005.14271.",
      "citeRegEx" : "Shahbazi et al\\.,? 2020",
      "shortCiteRegEx" : "Shahbazi et al\\.",
      "year" : 2020
    }, {
      "title" : "Matching the blanks: Distributional similarity for relation learning",
      "author" : [ "Livio Baldini Soares", "Nicholas FitzGerald", "Jeffrey Ling", "Tom Kwiatkowski." ],
      "venue" : "arXiv preprint arXiv:1906.03158.",
      "citeRegEx" : "Soares et al\\.,? 2019",
      "shortCiteRegEx" : "Soares et al\\.",
      "year" : 2019
    }, {
      "title" : "Rotate: Knowledge graph embedding by relational rotation in complex space",
      "author" : [ "Zhiqing Sun", "Zhi-Hong Deng", "Jian-Yun Nie", "Jian Tang." ],
      "venue" : "arXiv preprint arXiv:1902.10197.",
      "citeRegEx" : "Sun et al\\.,? 2019",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Distant supervision relation extraction with intra-bag and inter-bag attentions",
      "author" : [ "Zhi-Xiu Ye", "Zhen-Hua Ling." ],
      "venue" : "arXiv preprint arXiv:1904.00143.",
      "citeRegEx" : "Ye and Ling.,? 2019",
      "shortCiteRegEx" : "Ye and Ling.",
      "year" : 2019
    }, {
      "title" : "Distant supervision for relation extraction via piecewise convolutional neural networks",
      "author" : [ "Daojian Zeng", "Kang Liu", "Yubo Chen", "Jun Zhao." ],
      "venue" : "Proceedings of the 2015 conference on empirical methods in natural language processing, pages 1753–",
      "citeRegEx" : "Zeng et al\\.,? 2015",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2015
    }, {
      "title" : "Long-tail relation extraction via knowledge graph embeddings and graph convolution networks",
      "author" : [ "Ningyu Zhang", "Shumin Deng", "Zhanlin Sun", "Guanying Wang", "Xi Chen", "Wei Zhang", "Huajun Chen." ],
      "venue" : "arXiv preprint arXiv:1903.01306.",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "To save the manual annotation cost and alleviate the issue of data scarcity, distant supervision relation extraction (DSRE) (Mintz et al., 2009) is proposed and becomes increasingly popular as it can automatically generate large-scale labeled data.",
      "startOffset" : 124,
      "endOffset" : 144
    }, {
      "referenceID" : 19,
      "context" : "Although effective, distant supervision may introduce noise to a sentence bag when the assumption fails — some sentences are not describing the target relation (Zeng et al., 2015) (a.",
      "startOffset" : 160,
      "endOffset" : 179
    }, {
      "referenceID" : 10,
      "context" : "To alleviate the negative impacts of noise, recent studies (Lin et al., 2016; Ji et al., 2017; Du et al., 2018; Li et al., 2020) leveraged attention to select informative instances from a bag.",
      "startOffset" : 59,
      "endOffset" : 128
    }, {
      "referenceID" : 8,
      "context" : "To alleviate the negative impacts of noise, recent studies (Lin et al., 2016; Ji et al., 2017; Du et al., 2018; Li et al., 2020) leveraged attention to select informative instances from a bag.",
      "startOffset" : 59,
      "endOffset" : 128
    }, {
      "referenceID" : 2,
      "context" : "To alleviate the negative impacts of noise, recent studies (Lin et al., 2016; Ji et al., 2017; Du et al., 2018; Li et al., 2020) leveraged attention to select informative instances from a bag.",
      "startOffset" : 59,
      "endOffset" : 128
    }, {
      "referenceID" : 9,
      "context" : "To alleviate the negative impacts of noise, recent studies (Lin et al., 2016; Ji et al., 2017; Du et al., 2018; Li et al., 2020) leveraged attention to select informative instances from a bag.",
      "startOffset" : 59,
      "endOffset" : 128
    }, {
      "referenceID" : 6,
      "context" : "Furthermore, researchers introduced KG embeddings to enhance the attention mechanism (Hu et al., 2019; Han et al., 2018a).",
      "startOffset" : 85,
      "endOffset" : 121
    }, {
      "referenceID" : 3,
      "context" : "Furthermore, researchers introduced KG embeddings to enhance the attention mechanism (Hu et al., 2019; Han et al., 2018a).",
      "startOffset" : 85,
      "endOffset" : 121
    }, {
      "referenceID" : 20,
      "context" : "The basic idea is to utilize entity embeddings as the query to compute attention scores, so that the sentences with high attention weights are more likely to be valid annotations (Zhang et al., 2019).",
      "startOffset" : 179,
      "endOffset" : 199
    }, {
      "referenceID" : 3,
      "context" : "By analyzing several public benchmarks including NYT-FB60K (Han et al., 2018a), we observe lots of disturbing bags — all of the bag’s sentences are valid or noisy annotations, which shall lead to the failure of attention.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 4,
      "context" : "To achieve this, we propose a paradigm based on newly curated DSRE benchmark, BagRel-Wiki73K extracted from FewRel (Han et al., 2018b) and Wikidata 1, for quantitative analysis of attention and KG.",
      "startOffset" : 115,
      "endOffset" : 134
    }, {
      "referenceID" : 1,
      "context" : "Based on the above observations, we propose a new straightforward yet effective model based on pre-trained BERT (Devlin et al., 2018) for RE with Concatenated KG Embedding, namely BRE+CE.",
      "startOffset" : 112,
      "endOffset" : 133
    }, {
      "referenceID" : 3,
      "context" : "BRE+CE significantly outperforms existing state-of-the-arts on two publicly available datasets, NYT-FB60K (Han et al., 2018a) and GIDS-FB8K (Jat et al.",
      "startOffset" : 106,
      "endOffset" : 125
    }, {
      "referenceID" : 7,
      "context" : ", 2018a) and GIDS-FB8K (Jat et al., 2018), by 6% AUC on average.",
      "startOffset" : 23,
      "endOffset" : 41
    }, {
      "referenceID" : 14,
      "context" : "From then, DSRE becomes a standard solution that relies on multi-instance learning from a bag of sentences instead of a single sentence (Riedel et al., 2010; Hoffmann et al., 2011).",
      "startOffset" : 136,
      "endOffset" : 180
    }, {
      "referenceID" : 5,
      "context" : "From then, DSRE becomes a standard solution that relies on multi-instance learning from a bag of sentences instead of a single sentence (Riedel et al., 2010; Hoffmann et al., 2011).",
      "startOffset" : 136,
      "endOffset" : 180
    }, {
      "referenceID" : 10,
      "context" : "Attention mechanism (Lin et al., 2016) accelerates this trend via strong ability in handling noisy instances within a bag (Liu et al.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 11,
      "context" : ", 2016) accelerates this trend via strong ability in handling noisy instances within a bag (Liu et al., 2017; Du et al., 2018).",
      "startOffset" : 91,
      "endOffset" : 126
    }, {
      "referenceID" : 2,
      "context" : ", 2016) accelerates this trend via strong ability in handling noisy instances within a bag (Liu et al., 2017; Du et al., 2018).",
      "startOffset" : 91,
      "endOffset" : 126
    }, {
      "referenceID" : 3,
      "context" : "External KG is also incorporated to enhance the attention module (Han et al., 2018a; Hu et al., 2019).",
      "startOffset" : 65,
      "endOffset" : 101
    }, {
      "referenceID" : 6,
      "context" : "External KG is also incorporated to enhance the attention module (Han et al., 2018a; Hu et al., 2019).",
      "startOffset" : 65,
      "endOffset" : 101
    }, {
      "referenceID" : 17,
      "context" : ", RotatE (Sun et al., 2019), can preserve the structure information in the learned vectors eh, et and er.",
      "startOffset" : 9,
      "endOffset" : 27
    }, {
      "referenceID" : 3,
      "context" : "KG-enhanced attention aims to improve vy with entities eh and et (Han et al., 2018a):",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 13,
      "context" : "Specifically, we follow the way described in (Peng et al., 2020; Soares et al., 2019): entity mentions in sentences are highlighted with special markers before and after mentions.",
      "startOffset" : 45,
      "endOffset" : 85
    }, {
      "referenceID" : 16,
      "context" : "Specifically, we follow the way described in (Peng et al., 2020; Soares et al., 2019): entity mentions in sentences are highlighted with special markers before and after mentions.",
      "startOffset" : 45,
      "endOffset" : 85
    }, {
      "referenceID" : 9,
      "context" : "The attentionbased models include BRE+ATT,BRE+KA and BRE+SeG, where SeG (Li et al., 2020) is an",
      "startOffset" : 72,
      "endOffset" : 89
    }, {
      "referenceID" : 9,
      "context" : "it has an underlying drawback that it might hurt the model’s ability to predict based on entity mention features, which are important in RE tasks (Li et al., 2020) (Peng et al.",
      "startOffset" : 146,
      "endOffset" : 163
    }, {
      "referenceID" : 13,
      "context" : ", 2020) (Peng et al., 2020), leading to worse overall performance.",
      "startOffset" : 8,
      "endOffset" : 27
    }, {
      "referenceID" : 3,
      "context" : "To examine whether they work on the real-world Bag-level DSRE datasets, we compare our method to 3 previous baselines on NYTFB60K (Han et al., 2018a) and GIDS-FB8K (Jat et al.",
      "startOffset" : 130,
      "endOffset" : 149
    }, {
      "referenceID" : 9,
      "context" : ", 2019) and SeG (Li et al., 2020) as baselines, because they achieve state-of-the-art performance on bag-level RE.",
      "startOffset" : 16,
      "endOffset" : 33
    } ],
    "year" : 2021,
    "abstractText" : "Knowledge Graph (KG) and attention mechanism have been demonstrated effective in introducing and selecting useful information for weakly supervised methods. However, only qualitative analysis and ablation study are provided as evidence. In this paper, we contribute a dataset and propose a paradigm to quantitatively evaluate the effect of attention and KG on bag-level relation extraction (RE). We find that (1) higher attention accuracy may lead to worse performance as it may harm the model’s ability to extract entity mention features; (2) the performance of attention is largely influenced by various noise distribution patterns, which is closely related to real-world datasets; (3) KG-enhanced attention indeed improves RE performance, while not through enhanced attention but by incorporating entity prior; and (4) attention mechanism may exacerbate the issue of insufficient training data. Based on these findings, we show that a straightforward variant of RE model can achieve significant improvements (6% AUC on average) on two real-world datasets as compared with three state-of-the-art baselines. Our codes and datasets are available at https://github.com/zigkwin-hu/how-KG-ATT-help.",
    "creator" : "LaTeX with hyperref"
  }
}