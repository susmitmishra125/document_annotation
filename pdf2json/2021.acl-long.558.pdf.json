{
  "name" : "2021.acl-long.558.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "SpanNER: Named Entity Re-/Recognition as Span Prediction",
    "authors" : [ "Jinlan Fu", "Xuanjing Huang", "Pengfei Liu", "SeqLab SeqLab" ],
    "emails" : [ "fujl16@fudan.edu.cn", "xjhuang@fudan.edu.cn", "pliu3@cs.cmu.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 7183–7195\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n7183\nRecent years have seen the paradigm shift of Named Entity Recognition (NER) systems from sequence labeling to span prediction. Despite its preliminary effectiveness, the span prediction model’s architectural bias has not been fully understood. In this paper, we first investigate the strengths and weaknesses when the span prediction model is used for named entity recognition compared with the sequence labeling framework and how to further improve it, which motivates us to make complementary advantages of systems based on different paradigms. We then reveal that span prediction, simultaneously, can serve as a system combiner to re-recognize named entities from different systems’ outputs. We experimentally implement 154 systems on 11 datasets, covering three languages, comprehensive results show the effectiveness of span prediction models that both serve as base NER systems and system combiners. We make all code and datasets available: https:// github.com/neulab/spanner, as well as an online system demo: http://spanner. sh. Our model also has been deployed into the EXPLAINABOARD (Liu et al., 2021) platform, which allows users to flexibly perform the system combination of top-scoring systems in an interactive way: http://explainaboard. nlpedia.ai/leaderboard/task-ner/."
    }, {
      "heading" : "1 Introduction",
      "text" : "The rapid evolution of neural architectures (Kalchbrenner et al., 2014a; Kim, 2014; Hochreiter and Schmidhuber, 1997) and large pre-trained models (Devlin et al., 2019; Lewis et al., 2020) not only drive the state-of-the-art performance of many NLP tasks (Devlin et al., 2019; Liu and Lapata, 2019) to a new level but also change the way\n∗This work is done when Jinlan visited CMU remotely. †Corresponding author.\nhow researchers formulate the task. For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al., 2020; Mengge et al., 2020; Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020), which regards NER either as question answering (Li et al., 2020; Mengge et al., 2020), span classification (Jiang et al., 2020; Ouchi et al., 2020; Yamada et al., 2020), and dependency parsing tasks (Yu et al., 2020).\nHowever, despite the success of span predictionbased systems, as a relatively newly-explored framework, the understanding of its architectural bias has not been fully understood so far. For example, what are the complementary advantages compared with SEQLAB frameworks and how to make full use of them? Motivated by this, in this paper, we make two scientific contributions.\nWe first investigate what strengths and weaknesses are when NER is conceptualized as a span prediction task. To achieve this goal, we\nperform a fine-grained evaluation of SPANNER systems against SEQLAB systems and find there are clear complementary advantages between these two frameworks. For example, SEQLAB-based models are better at dealing with those entities that are long and with low label consistency. By contrast, SPANNER systems do better in sentences with more Out-of-Vocabulary (OOV) words and entities with medium length (§3.3).\nSecondly, we reveal the unique advantage brought by the architectural bias of the span prediction framework: it can not only be used as a base system for named entity recognition but also serve as a meta-system to combine multiple NER systems’ outputs. In other words, the span prediction model play two roles showing in Fig. 1: (i) as a base NER system; and (ii) as a system combiner of multiple base systems. We claim that compared with traditional ensemble learning of the NER task, SPANNER combiners are advantageous in the following aspects:\n1. Most of the existing NER combiners rely on heavy feature engineering and external knowledge (Florian et al., 2003; Wu et al., 2003; Saha and Ekbal, 2013). Instead, the SPANNER models we proposed for system combination train in an end-to-end fashion. 2. Combining complementarities of different paradigms: most previous works perform NER system combination solely focusing on the sequence labeling framework. It is still an understudied topic how systems from different frameworks help each other. 3. No extra training overhead and flexibility of use: Existing ensemble learning algorithms are expensive, which usually need to collect training samples by k-fold cross-validation for system combiner (Speck and Ngomo, 2014), reducing their practicality. 4. Connecting two separated training processes: previously, the optimization of base NER systems and ensemble learning for combiner are two independent processes. Our work builds their connection and the same set of parameters shared over these two processes.\nExperimentally, we first implement 154 systems on 11 datasets, on which we comprehensively evaluate the effectiveness of our proposed span prediction-based system combiner. Empirical results show its superior performance against several typical ensemble learning algorithms.\nLastly, we make an engineering contribution that benefits from the practicality of our proposed methods. Specifically, we developed an online demo system based on our proposed method, and integrate it into the NER Leaderboard, which is very convenient for researchers to find the complementarities among different combinations of systems, and search for a new state-of-the-art system."
    }, {
      "heading" : "2 Preliminaries",
      "text" : ""
    }, {
      "heading" : "2.1 Task",
      "text" : "NER is frequently formulated as a sequence labeling (SEQLAB) problem (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016), where X = {x1, x2, . . . , xT } is an input sequence and Y = {y1, y2, . . . , yT } is the output label (e.g., “B-PER”, “I-LOC”, “O”) sequence. The goal of this task is to accurately predict entities by assigning output label yt for each token xt. We take the F1-score1 as the evaluation metric for the NER task."
    }, {
      "heading" : "2.2 Datasets",
      "text" : "To make a comprehensive evaluation, in this paper, we use multiple NER datasets that cover different domains and languages. CoNLL-2003 2 (Sang and De Meulder, 2003) covers two different languages: English and German. Here, we only consider the English (EN) dataset collected from the Reuters Corpus. CoNLL-2002 3 (Sang, 2002) contains annotated corpus in Dutch (NL) collected from De Morgen news, and Spanish (ES) collected from Spanish EFE News Agency. We evaluate both languages. OntoNotes 5.0 4 (Weischedel et al., 2013) is a large corpus consisting of three different languages: English, Chinese, and Arabic, involving six genres: newswire (NW), broadcast news (BN), broadcast conversation (BC), magazine (MZ), web data (WB), and telephone conversation (TC). Following previous works (Durrett and Klein, 2014; Ghaddar and Langlais, 2018), we utilize different domains in English to test the robustness of proposed models.\n1http://www.clips.uantwerpen.be/ conll2000/chunking/conlleval.txt\n2https://www.clips.uantwerpen.be/ conll2003/ner/\n3https://www.clips.uantwerpen.be/ conll2002/ner/\n4https://catalog.ldc.upenn.edu/ LDC2013T19\nWNUT-2016 5 and WNUT-2017 6 (Strauss et al., 2016; Derczynski et al., 2017) are social media data from Twitter, which were public as a shared task at WNUT-2016 (W16) and WNUT-2017 (W17)."
    }, {
      "heading" : "3 Span Prediction for NE Recognition",
      "text" : "Although this is not the first work that formulates NER as a span prediction problem (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020; Li et al., 2020; Mengge et al., 2020), we contribute by (1) exploring how different design choices influence the performance of SPANNER and (2) interpreting complementary strengths between SEQLAB and SPANNER with different design choices. In what follows, we first detail span prediction-based NER systems with the vanilla configuration and proposed advanced featurization."
    }, {
      "heading" : "3.1 SPANNER as NER System",
      "text" : "Overall, the span prediction-based framework for NER consists of three major modules: token representation layer, span representation layer, and span prediction layer."
    }, {
      "heading" : "3.1.1 Token Representation Layer",
      "text" : "Given a sentence X = {x1, · · · , xn} with n tokens, the token representation hi is as follows:\nu1, · · · ,un = EMB(x1, · · · , xn), (1) h1, · · · ,hn = BILSTM(u1, · · · ,un), (2)\nwhere EMB(·) is the pre-trained embeddings, such as non-contextualized embeddings GloVe (Pennington et al., 2014) or contextualized pre-trained embeddings BERT (Devlin et al., 2018). BILSTM is the bidirectional LSTM (Hochreiter and Schmidhuber, 1997)."
    }, {
      "heading" : "3.1.2 Span Representation Layer",
      "text" : "First, we enumerate all the possible m spans S = {s1, · · · , si, · · · , sm} for sentence X = {x1, · · · , xn} and then re-assign a label y ∈ Y for each span s. For example, for sentence: “London1 is2 beautiful3”, the possible span’s (start, end) indices are {(1, 1), (2, 2), (3, 3), (1, 2), (2, 3), (1, 3)}, and the labels of these spans are all “O” except (1, 1) (London) is “LOC”. We use bi and ei to denote the start- and end- index of the span si, respectively,\n5http://noisy-text.github.io/2016/ ner-shared-task.html\n6http://noisy-text.github.io/2017/ emerging-rare-entities.html\nand 1 ≤ bi ≤ ei ≤ n. Then each span can be represented as si = {xbi , xbi+1, · · · , xei}. The vectorial representation of each span could be calculated based on the following parts: Boundary embedding: span representation is calculated by the concatenation of the start and end tokens’ representations zbi = [hbi ;hei ] Span length embedding: we additionally featurize each span representation by introducing its length embedding zli, which can be obtained by a learnable look-up table.\nThe final representation of each span si can be obtained as: si = [zbi ; z l i]."
    }, {
      "heading" : "3.1.3 Span Prediction Layer",
      "text" : "The span representations si are fed into a softmax function to get the probability w.r.t label y.\nP(y|si) = score(si,y)∑\ny′∈Y score(si,y\n′) , (3)\nwhere score(·) is a function that measures the compatibility between a specified label and a span:\nscore(si,yk) = exp(s T i yk), (4)\nwhere si denotes the span representation and yk is a learnable representation of the class k.\nHeuristic Decoding Regarding the flat NER task without nested entities, we present a heuristic decoding method to avoid the prediction of overlapped spans. Specifically, for those overlapped spans, we keep the span with the highest prediction probability and drop the others."
    }, {
      "heading" : "3.2 Exp-I: Effectiveness of Model Variants",
      "text" : "Setup To explore how different mechanisms influence the performance of span prediction models, We design four specific model variants (i) generic SPANNER: only using boundary embedding (ii) boundary embedding + span length embedding, (iii) boundary embedding + heuristic decoding, (iv) heuristic decoding + (ii).\nResults As shown in Tab. 1, we can observe that: (i) heuristic decoding is an effective method that can boost the generic model’s performance over all the datasets. (ii) span length feature works most of the time. The performances on 10 of the 11 datasets have improved against the generic model. (iii) By combining two mechanisms together, significant improvements were achieved on all datasets."
    }, {
      "heading" : "3.3 Exp-II: Analysis of Complementarity",
      "text" : "The holistic results in Tab. 1 make it hard for us to interpret the relative advantages of NER systems with different structural biases. To address this problem, we follow the interpretable evaluation idea (Fu et al., 2020a,c) that proposes to breakdown the holistic performance into different buckets from different perspectives and use a performance heatmap to illustrate relative advantages between two systems, i.e., system-pair diagnosis.\nSetup As a comparison, we replicate five topscoring SEQLAB-based NER systems, which are sq1 : 92.41, sq2 : 92.01, sq3 : 92.46, sq4 : 92.11, sq5 : 91.99. Notably, to make a fair comparison, all five SEQLABs are with closed performance comparing to the above SPANNERs. Although we will detail configurations of these systems later (to reduce content redundancy) in §5.1 Tab. 3 , it would not influence our analysis in this section.\nRegarding interpretable evaluation, we choose the CoNLL-2003 (EN) dataset as a case study and breakdown the holistic performance into four groups based on different attributes. Specifically,\ngiven an entity e that belongs to a sentence S, the following attribute feature functions can be defined:\n• φeLen = len(e): entity length • φsLen = len(S): sentence length • φoDen = |OOVs| len(S) : density of OOVs • φeCon = |{ε|label(ε)=label(e),∀ε∈E}|\n|E| : entity label consistency\nwhere len(·) counts the number of words, label(e) gets the label for span e, E denotes all spans in the training set. |OOVs| is the number of OOV words in the sentence.\nWe additionally use a training set dependent attribute: entity label consistency (eCon), which measures how consistently a particular entity is labeled with a particular label. For example, if an entity with the label “LOC” has a higher eCon, it means that the entity is frequently labeled as “LOC” in the training set. Based on the attribute value of entities, we partition test entities into four buckets: extra-small (XS), small (S), large (L), and extra-large (XL).7. For each bucket, we calculate a\n7we show detailed bucket intervals in the appendix\nbucket-wise F1.\nAnalysis As shown in Tab. 2, the green area indicates SEQLAB performs better while the red area implies the span model is better. We observe that: (1) The generic SPANNER shows clear complementary advantages with SEQLAB-based systems. Specifically, almost all SEQLAB-based models outperform generic SPANNER when (i) entities are long and with lower label consistency (ii) sentences are long and with fewer OOV words. By contrast, SPANNER is better at dealing with entities locating on sentences with more OOV words and entities with medium length. (2) By introducing heuristic decoding and span length features, SPANNERs do slightly better in long sentences and long entities, but are still underperforming on entities with lower label consistency.\nThe complementary advantages presented by SEQLABs and SPANNERs motivate us to search for an effective framework to utilize them."
    }, {
      "heading" : "4 Span Prediction for NE Re-recognition",
      "text" : "The development of ensemble learning for NER systems, so far, lags behind the architectural evolution of the NER task. Based on our evidence from §3.3, we propose a new ensemble learning framework for NER systems.\nSPANNER as System Combiner The basic idea is that each span prediction NER (SPANNER) system itself can also conceptualize as a system combiner to re-recognize named entities from different systems’ outputs. Specifically, Fig. 2 illustrates the general workflow. Here, SPANNER plays two roles, (1) as a base model to identify potential named entities; (2) as a meta-model (combiner) to calculate the score for each potential named entity.\nGiven a test span s and prediction label set L̂ from m base systems (|L̂| = m). Let L be NER label set where |L| = c and c is the number of pre-defined NER classes (i.e., “LOC, ORG, PER, MISC, O” in CoNLL 2003 (EN).)\nFor each l ∈ L we define P (s, l) as the combined probability that span s can be assigned as label l, which can be calculated as:\nP (s, l) = ∑\nl̂∈L̂∧l̂=l\nscore(s, l̂), (5)\nwhere score(·) is defined as Eq.4. Then the final prediction label is:\nargmax l∈(L) P (s, l), (6)\nIntuitively, Fig. 2 gives an example of how SPANNER re-recognizes the entity “New York” based on outputs from four base systems. As a base system, SPANNER predicts this span as “LOC”, and the label will be considered as one input of the combiner model.\nThe prediction labels of the other three base models are “LOC”, “ORG”, and “O”, respectively. Then, as a combiner, SPANNER calculates the score for each predicted label. We sum weights (scores) of the same label that are predicted by the base models and select the label that achieves the maximum score as the output of the combiner."
    }, {
      "heading" : "5 Experiment",
      "text" : ""
    }, {
      "heading" : "5.1 Base Systems",
      "text" : "To make a thorough evaluation of SPANNER as a system combiner, as illustrated in Tab. 3, we first implement 10 SEQLAB based systems that cover rich combinations of popular neural components. To be fair for other system combination methods, we also include two SPANNERs as base systems. To reduce the uncertainty, we run experiments with multiple trials and also perform the significant test with Wilcoxon Signed-Rank Test (Wilcoxon et al., 1970) at p < 0.05.\n8Since the lack of an official EMLo language model in Spanish and Dutch, we do not implement these base models.\nRegarding SEQLAB-base systems, following (Fu et al., 2020b), their designs are diverse in four components: (1) character/subword-sensitive representation: ELMo (Peters et al., 2018), Flair (Akbik et al., 2018, 2019), BERT 9 (Devlin et al., 2018) 2) word representation: GloVe (Pennington et al., 2014), fastText (Bojanowski et al., 2017); (3) sentence-level encoders: LSTM (Hochreiter and Schmidhuber, 1997), CNN (Kalchbrenner et al., 2014b; Chen et al., 2019); (4) decoders: CRF (Lample et al., 2016; Collobert et al., 2011). We keep the testing result from the model with the best performance on the development set, terminating training when the performance of the development set is not improved in 20 epochs."
    }, {
      "heading" : "5.2 Baselines",
      "text" : "We extensively explore six system combination methods as competitors, which involves supervised and unsupervised fashions."
    }, {
      "heading" : "5.2.1 Voting-based Approaches",
      "text" : "Voting, as an unsupervised method, has been commonly used in existing works: Majority voting (VM): All the individual classifiers are combined into a final system based on the majority voting. Weighted voting base on overall F1-score (VOF1): The taggers are combined according to\n9We view BERT as the subword-sensitive representation because we get the representation of each subword.\nthe weights, which is the overall F1-score on the testing set. Weighted voting base on class F1-score (VCF1): Also weighted voting, the weights are the categories’ F1-score."
    }, {
      "heading" : "5.2.2 Stacking-based Approaches",
      "text" : "Stacking (a.k.a, Stacked Generalization) is a general method of using a high-level model to combine lower-level models to achieve greater predictive accuracy (Ting and Witten, 1997). To make a comprehensive evaluation, we investigated three popular methods that are supervised learning, thereby requiring additional training samples. Specifically, there are: Support Vector Machines (SVM) (Hearst et al., 1998) is a supervised machine learning algorithm, which can train quickly over large datasets. Therefore, the ensemble classifier is usually SVM. Random Forest (RF) (Breiman, 2001) is a common ensemble classifier that randomly selects a subset of training samples and variables to make multiple decision trees. Extreme Gradient Boosting (XGB) (Chen and Guestrin, 2016) is also an ensemble machine learning algorithm. It is based on the decisiontree and the gradient boosting decision (Friedman et al., 2000).\nNotably, compared to our model, these methods are computationally expensive since they require external training samples for system combiners,\nwhich is achieved by (i) collecting training data by performing five-fold cross-validation (Wu et al., 2003; Florian et al., 2003) on the original training samples of each dataset (ii) training a system combiner based on collected samples."
    }, {
      "heading" : "5.3 Exp-III: Nuanced View",
      "text" : "Setup Most previous works on system combination only consider one combination case where all base systems are put together. In this setting, we aim to explore more fine-grained combination cases. Specifically, we first sort systems based on their performance in a descending order to get a list m. We refer to m[i : k] as one combination case, dubbed combined interval, which represents systems whose ranks are between i and k. In practice, we consider 23 combination cases showing in Tab. 4. To examine whether the SPANNNER is significantly better than the other baseline methods, we conduct the significance test with Wilcoxon Signed-RankTest (Wilcoxon et al., 1970) at p < 0.05.\nResults Tab. 4 shows results of our SPANNER against six baseline combiner methods on CoNLL-2003 and OntoNotes5.0-BN under a nuanced view. We can observe that: (1) Overall, our proposed SPANNER outperforms all other competitors significantly (p-value < 0.05) on most of the combination cases include the one (“all”) that most previous works have explored. (2) As more base systems are introduced in descending order, the combined performance will be improved gradually. The combination performance will decrease with the reduction of the best single system, which holds for all the combiners. (3) The best performance is always achieved on the combination case with more models, instead of the one with a small number of top-scoring base models. This suggests that introducing more base models with diverse structures will provide richer complementary information."
    }, {
      "heading" : "5.4 Exp-IV: Aggregated View",
      "text" : "Setup To also explore the effectiveness of SPANNER on the other datasets, we calculate the average performance of each system combination method\nover 23 combination cases.\nResults Tab. 5 shows the results, and we can observe that: comparing with the three voting combiner, SPANNER achieves the best average combination performance with the lowest standard deviation, which holds for seven of nine testing datasets with statistical significance p<0.05. Specifically, the performance gap between SPANNER and other combiners is larger on datasets from web domain: WB and Twitter: W16, W17."
    }, {
      "heading" : "5.5 Exp-VI: Interpretable Analysis",
      "text" : "Setup The above experiments have shown the superior performance of SPANNER on system combination. To further investigate where the gains of the SPANNER come from, similar to §3.3, we perform fine-grained evaluation on CoNLL-2003 dataset using one combination case to interpret how SPANNER outperform other (i) base systems and (ii) other baseline combiners. The combination case contains base systems: sq0-5 together with sp1, sp2 (model’s detail can refer to Tab.3).\nResults As shown in Tab. 6, we can find: (1) SPANNER v.s. Base systems: the improvements of all base systems largely come from entities with low label consistency (eCon: XS, S). Particularly, base systems with SEQLAB benefit a lot from short entities while base systems with SPANNER gain mainly from long entities. (2) SPANNER v.s. Other combiners: as a system combiner, the improvement of SPANNER against other baselines mainly comes from low label consistency (eCon: XS, S). By contrast,\ntraditional combiners surpass SPANNER when dealing with long sentences (sLen: XL)."
    }, {
      "heading" : "6 Related Work",
      "text" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results. For example, (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020) shift NER from tokenlevel tagging to span-level prediction task while (Li et al., 2020; Mengge et al., 2020) conceptualize it as reading comprehension task. In this work we aim to interpret the complementarity between sequence labeling and span prediction.\nSystem Combination Traditionally, system combination was used to improve the performance of statistical MT systems (González-Rubio et al., 2011; Watanabe and Sumita, 2011; Duh et al., 2011; Mizumoto and Matsumoto, 2016). Some recent work (Zhou et al., 2017; Huang et al., 2020) also extended this method to neural MT where\nthe meta-model and base systems are all neural models. There is a handful of works about system combination for NER. (Wu et al., 2003; Florian et al., 2003) investigated stacking and voting methods for combining strong classifiers. Ekbal and Saha (2011); Zhang et al. (2014) proposes a weighted voting approach based on differential evolution. These works commonly require training samples and rely heavily on feature engineering."
    }, {
      "heading" : "7 Implications and Future Directions",
      "text" : "Co-evolution of NLP Systems and their combiners Systems for NLP tasks (e.g., NER model) and their combiners (e.g., ensemble learning for NER) are developing in two parallel directions. This paper builds the connection between them and proposes a model that can be utilized as both a base NER system and a system combiner. Our work opens up a direction toward making the algorithms of NLP models and system combination co-evolved. The unified idea can be applied to other NLP tasks, and some traditional methods like reranking in syntactic parsing can be re-visited. For example, we can formulate constituency parsing (Jiang et al., 2020) as well as its re-ranking (Collins and Koo, 2005; Huang, 2008) as a span prediction (Stern et al., 2017) problem, which is be unified and parameterized with the same form.\nCombinaBoard It has become a trend to use a Leaderboard (e.g., paperwithcode10) to track current progress in a particular field, especially with the rapid emergence of a plethora of models. Leaderboard makes us pay more attention to and even obsess over the state-of-the-art systems (Ethayarajh and Jurafsky, 2020). We argue that Leaderboard with an effective system combination (dubbed COMBINABOARD) feature would allow researchers to quickly find the complementarities among different systems. As a result, the value of a worse-ranked model still could be observed through its combined results. In this paper, we make the first step towards this by releasing a preliminary COMBINABOARD for the NER task http://spanner.sh. Our model also has been deployed into the EXPLAINABOARD (Liu et al., 2021) platform, which allows users to flexibly perform system combination of top-scoring systems in an interactive way: http://explainaboard. nlpedia.ai/leaderboard/task-ner/\n10https://paperswithcode.com/"
    }, {
      "heading" : "Acknowledgements",
      "text" : "We thank Professor Graham Neubig and anonymous reviewers for valuable feedback and helpful suggestions. This work was supported by the Air Force Research Laboratory under agreement number FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the Air Force Research Laboratory or the U.S. Government."
    }, {
      "heading" : "A Attribute Interval",
      "text" : "The detailed attribute interval for attributes: eCon, sLen, eLen, and oDen."
    }, {
      "heading" : "B Model Name illustration of SEQLAB",
      "text" : "Tab. 8 illustrates the full model name and the detailed structure of the SEQLAB models. All the SEQLAB models use the CRF as the decoder. For example, the full model name of “sq0” is “CflairWglove lstmCrf”, representing a sequence labeling model that uses the Flair as characterlevel embedding, GloVe as word-level embedding, LSTM as the sentence-level encoder, and CRF as the decoder. For “sq3”, its full model name is “CbertWnon lstmCrf”, representing a sequence\nlabeling model that uses the BERT as characterlevel embedding, LSTM as the sentence-level encoder, and CRF as the decoder."
    } ],
    "references" : [ {
      "title" : "Pooled contextualized embeddings for named entity recognition",
      "author" : [ "Alan Akbik", "Tanja Bergmann", "Roland Vollgraf." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
      "citeRegEx" : "Akbik et al\\.,? 2019",
      "shortCiteRegEx" : "Akbik et al\\.",
      "year" : 2019
    }, {
      "title" : "Contextual string embeddings for sequence labeling",
      "author" : [ "Alan Akbik", "Duncan Blythe", "Roland Vollgraf." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 1638–1649.",
      "citeRegEx" : "Akbik et al\\.,? 2018",
      "shortCiteRegEx" : "Akbik et al\\.",
      "year" : 2018
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 5:135– 146.",
      "citeRegEx" : "Bojanowski et al\\.,? 2017",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2017
    }, {
      "title" : "Random forests",
      "author" : [ "Leo Breiman." ],
      "venue" : "Machine learning, 45(1):5–32.",
      "citeRegEx" : "Breiman.,? 2001",
      "shortCiteRegEx" : "Breiman.",
      "year" : 2001
    }, {
      "title" : "Grn: Gated relation network to enhance convolutional neural network for named entity recognition",
      "author" : [ "Hui Chen", "Zijia Lin", "Guiguang Ding", "Jianguang Lou", "Yusen Zhang", "Borje Karlsson." ],
      "venue" : "ThirtyThird AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Xgboost: A scalable tree boosting system",
      "author" : [ "Tianqi Chen", "Carlos Guestrin." ],
      "venue" : "Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785– 794.",
      "citeRegEx" : "Chen and Guestrin.,? 2016",
      "shortCiteRegEx" : "Chen and Guestrin.",
      "year" : 2016
    }, {
      "title" : "Named entity recognition with bidirectional lstm-cnns",
      "author" : [ "Jason PC Chiu", "Eric Nichols." ],
      "venue" : "arXiv preprint arXiv:1511.08308.",
      "citeRegEx" : "Chiu and Nichols.,? 2015",
      "shortCiteRegEx" : "Chiu and Nichols.",
      "year" : 2015
    }, {
      "title" : "Discriminative reranking for natural language parsing",
      "author" : [ "Michael Collins", "Terry Koo." ],
      "venue" : "Computational Linguistics, 31(1):25–70.",
      "citeRegEx" : "Collins and Koo.,? 2005",
      "shortCiteRegEx" : "Collins and Koo.",
      "year" : 2005
    }, {
      "title" : "Natural language processing (almost) from scratch",
      "author" : [ "Ronan Collobert", "Jason Weston", "Léon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa." ],
      "venue" : "Journal of Machine Learning Research, 12(Aug):2493–2537.",
      "citeRegEx" : "Collobert et al\\.,? 2011",
      "shortCiteRegEx" : "Collobert et al\\.",
      "year" : 2011
    }, {
      "title" : "Results of the wnut2017 shared task on novel and emerging entity recognition",
      "author" : [ "Leon Derczynski", "Eric Nichols", "Marieke van Erp", "Nut Limsopatham." ],
      "venue" : "Proceedings of the 3rd Workshop on Noisy User-generated Text, pages 140–147.",
      "citeRegEx" : "Derczynski et al\\.,? 2017",
      "shortCiteRegEx" : "Derczynski et al\\.",
      "year" : 2017
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "NAACL-HLT (1).",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Generalized minimum bayes risk system combination",
      "author" : [ "Kevin Duh", "Katsuhito Sudoh", "Xianchao Wu", "Hajime Tsukada", "Masaaki Nagata." ],
      "venue" : "Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1356–1360.",
      "citeRegEx" : "Duh et al\\.,? 2011",
      "shortCiteRegEx" : "Duh et al\\.",
      "year" : 2011
    }, {
      "title" : "A joint model for entity analysis: Coreference, typing, and linking",
      "author" : [ "Greg Durrett", "Dan Klein." ],
      "venue" : "Transactions of the association for computational linguistics, 2:477–490.",
      "citeRegEx" : "Durrett and Klein.,? 2014",
      "shortCiteRegEx" : "Durrett and Klein.",
      "year" : 2014
    }, {
      "title" : "Weighted vote-based classifier ensemble for named entity recognition: A genetic algorithm-based approach",
      "author" : [ "Asif Ekbal", "Sriparna Saha." ],
      "venue" : "ACM Transactions on Asian Language Information Processing (TALIP), 10(2):1–37.",
      "citeRegEx" : "Ekbal and Saha.,? 2011",
      "shortCiteRegEx" : "Ekbal and Saha.",
      "year" : 2011
    }, {
      "title" : "Utility is in the eye of the user: A critique of NLP leaderboards",
      "author" : [ "Kawin Ethayarajh", "Dan Jurafsky." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4846–4853, Online. Association for Computa-",
      "citeRegEx" : "Ethayarajh and Jurafsky.,? 2020",
      "shortCiteRegEx" : "Ethayarajh and Jurafsky.",
      "year" : 2020
    }, {
      "title" : "Named entity recognition through classifier combination",
      "author" : [ "Radu Florian", "Abe Ittycheriah", "Hongyan Jing", "Tong Zhang." ],
      "venue" : "Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003, pages 168–171.",
      "citeRegEx" : "Florian et al\\.,? 2003",
      "shortCiteRegEx" : "Florian et al\\.",
      "year" : 2003
    }, {
      "title" : "Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors)",
      "author" : [ "Jerome Friedman", "Trevor Hastie", "Robert Tibshirani" ],
      "venue" : "Annals of statistics,",
      "citeRegEx" : "Friedman et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Friedman et al\\.",
      "year" : 2000
    }, {
      "title" : "Larger-context tagging: When and why does it work? arXiv preprint arXiv:2104.04434",
      "author" : [ "Jinlan Fu", "Liangjing Feng", "Qi Zhang", "Xuanjing Huang", "Pengfei Liu" ],
      "venue" : null,
      "citeRegEx" : "Fu et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Fu et al\\.",
      "year" : 2021
    }, {
      "title" : "Interpretable multi-dataset evaluation for named entity recognition",
      "author" : [ "Jinlan Fu", "Pengfei Liu", "Graham Neubig." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural",
      "citeRegEx" : "Fu et al\\.,? 2020a",
      "shortCiteRegEx" : "Fu et al\\.",
      "year" : 2020
    }, {
      "title" : "Rethinking generalization of neural models: A named entity recognition case study",
      "author" : [ "Jinlan Fu", "Pengfei Liu", "Qi Zhang." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 7732–7739.",
      "citeRegEx" : "Fu et al\\.,? 2020b",
      "shortCiteRegEx" : "Fu et al\\.",
      "year" : 2020
    }, {
      "title" : "2020c. RethinkCWS: Is Chinese word segmentation a solved task",
      "author" : [ "Jinlan Fu", "Pengfei Liu", "Qi Zhang", "Xuanjing Huang" ],
      "venue" : "In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Fu et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Fu et al\\.",
      "year" : 2020
    }, {
      "title" : "Robust lexical features for improved neural network named-entity recognition",
      "author" : [ "Abbas Ghaddar", "Philippe Langlais." ],
      "venue" : "arXiv preprint arXiv:1806.03489.",
      "citeRegEx" : "Ghaddar and Langlais.,? 2018",
      "shortCiteRegEx" : "Ghaddar and Langlais.",
      "year" : 2018
    }, {
      "title" : "Minimum Bayes-risk system combination",
      "author" : [ "Jesús González-Rubio", "Alfons Juan", "Francisco Casacuberta." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages",
      "citeRegEx" : "González.Rubio et al\\.,? 2011",
      "shortCiteRegEx" : "González.Rubio et al\\.",
      "year" : 2011
    }, {
      "title" : "Support vector machines",
      "author" : [ "Marti A. Hearst", "Susan T Dumais", "Edgar Osuna", "John Platt", "Bernhard Scholkopf." ],
      "venue" : "IEEE Intelligent Systems and their applications, 13(4):18–28.",
      "citeRegEx" : "Hearst et al\\.,? 1998",
      "shortCiteRegEx" : "Hearst et al\\.",
      "year" : 1998
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural computation, 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Forest reranking: Discriminative parsing with non-local features",
      "author" : [ "Liang Huang." ],
      "venue" : "Proceedings of ACL-08: HLT, pages 586–594, Columbus, Ohio. Association for Computational Linguistics.",
      "citeRegEx" : "Huang.,? 2008",
      "shortCiteRegEx" : "Huang.",
      "year" : 2008
    }, {
      "title" : "Modeling voting for system combination in machine translation",
      "author" : [ "Xuancheng Huang", "Jiacheng Zhang", "Zhixing Tan", "Derek F. Wong", "Huanbo Luan", "Jingfang Xu", "Maosong Sun", "Yang Liu." ],
      "venue" : "Proceedings of the Twenty-Ninth International",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "Bidirectional lstm-crf models for sequence tagging",
      "author" : [ "Zhiheng Huang", "Wei Xu", "Kai Yu." ],
      "venue" : "arXiv preprint arXiv:1508.01991.",
      "citeRegEx" : "Huang et al\\.,? 2015",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2015
    }, {
      "title" : "Generalizing natural language analysis through span-relation representations",
      "author" : [ "Zhengbao Jiang", "Wei Xu", "Jun Araki", "Graham Neubig." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Jiang et al\\.,? 2020",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2020
    }, {
      "title" : "A convolutional neural network for modelling sentences",
      "author" : [ "Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Kalchbrenner et al\\.,? 2014a",
      "shortCiteRegEx" : "Kalchbrenner et al\\.",
      "year" : 2014
    }, {
      "title" : "A convolutional neural network for modelling sentences",
      "author" : [ "Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Kalchbrenner et al\\.,? 2014b",
      "shortCiteRegEx" : "Kalchbrenner et al\\.",
      "year" : 2014
    }, {
      "title" : "Convolutional neural networks for sentence classification",
      "author" : [ "Yoon Kim." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751, Doha, Qatar. Association for Computational Lin-",
      "citeRegEx" : "Kim.,? 2014",
      "shortCiteRegEx" : "Kim.",
      "year" : 2014
    }, {
      "title" : "Neural architectures for named entity recognition",
      "author" : [ "Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer." ],
      "venue" : "Proceedings of NAACL-HLT, pages 260–270.",
      "citeRegEx" : "Lample et al\\.,? 2016",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2016
    }, {
      "title" : "BART: Denoising sequence-to-sequence pretraining for natural language",
      "author" : [ "Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "A unified MRC framework for named entity recognition",
      "author" : [ "Xiaoya Li", "Jingrong Feng", "Yuxian Meng", "Qinghong Han", "Fei Wu", "Jiwei Li." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Triggerner: Learning with entity triggers as explanations for named entity recognition",
      "author" : [ "Bill Yuchen Lin", "Dong-Ho Lee", "Ming Shen", "Ryan Moreno", "Xiao Huang", "Prashant Shiralkar", "Xiang Ren." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the",
      "citeRegEx" : "Lin et al\\.,? 2020",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "Explainaboard: An explainable leaderboard for nlp",
      "author" : [ "Pengfei Liu", "Jinlan Fu", "Yang Xiao", "Weizhe Yuan", "Shuaicheng Chang", "Junqi Dai", "Yixin Liu", "Zihuiwen Ye", "Graham Neubig." ],
      "venue" : "arXiv preprint arXiv:2104.06387.",
      "citeRegEx" : "Liu et al\\.,? 2021",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2021
    }, {
      "title" : "Text summarization with pretrained encoders",
      "author" : [ "Yang Liu", "Mirella Lapata." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
      "citeRegEx" : "Liu and Lapata.,? 2019",
      "shortCiteRegEx" : "Liu and Lapata.",
      "year" : 2019
    }, {
      "title" : "Hierarchical contextualized representation for named entity recognition",
      "author" : [ "Ying Luo", "Fengshun Xiao", "Hai Zhao." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 8441–8448.",
      "citeRegEx" : "Luo et al\\.,? 2020",
      "shortCiteRegEx" : "Luo et al\\.",
      "year" : 2020
    }, {
      "title" : "End-to-end sequence labeling via bi-directional lstm-cnns-crf",
      "author" : [ "Xuezhe Ma", "Eduard Hovy." ],
      "venue" : "Proceedings of the 54th Annual Meeting of ACL, volume 1, pages 1064–1074.",
      "citeRegEx" : "Ma and Hovy.,? 2016",
      "shortCiteRegEx" : "Ma and Hovy.",
      "year" : 2016
    }, {
      "title" : "Coarse-tofine pre-training for named entity recognition",
      "author" : [ "Xue Mengge", "Bowen Yu", "Zhenyu Zhang", "Tingwen Liu", "Yue Zhang", "Bin Wang." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Mengge et al\\.,? 2020",
      "shortCiteRegEx" : "Mengge et al\\.",
      "year" : 2020
    }, {
      "title" : "Discriminative reranking for grammatical error correction with statistical machine translation",
      "author" : [ "Tomoya Mizumoto", "Yuji Matsumoto." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Mizumoto and Matsumoto.,? 2016",
      "shortCiteRegEx" : "Mizumoto and Matsumoto.",
      "year" : 2016
    }, {
      "title" : "Instance-based learning of span representations: A case study through named entity recognition",
      "author" : [ "Hiroki Ouchi", "Jun Suzuki", "Sosuke Kobayashi", "Sho Yokoi", "Tatsuki Kuribayashi", "Ryuto Konno", "Kentaro Inui." ],
      "venue" : "arXiv preprint arXiv:2004.14514.",
      "citeRegEx" : "Ouchi et al\\.,? 2020",
      "shortCiteRegEx" : "Ouchi et al\\.",
      "year" : 2020
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher Manning." ],
      "venue" : "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of NAACL, volume 1, pages 2227–2237.",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Combining multiple classifiers using vote based classifier ensemble technique for named entity recognition",
      "author" : [ "Sriparna Saha", "Asif Ekbal." ],
      "venue" : "Data & Knowledge Engineering, 85:15–39.",
      "citeRegEx" : "Saha and Ekbal.,? 2013",
      "shortCiteRegEx" : "Saha and Ekbal.",
      "year" : 2013
    }, {
      "title" : "Introduction to the conll-2003 shared task: Languageindependent named entity recognition",
      "author" : [ "Erik F Sang", "Fien De Meulder." ],
      "venue" : "arXiv preprint cs/0306050.",
      "citeRegEx" : "Sang and Meulder.,? 2003",
      "shortCiteRegEx" : "Sang and Meulder.",
      "year" : 2003
    }, {
      "title" : "Introduction to the conll-2002 shared task: Language-independent named entity recognition",
      "author" : [ "Erik F. Tjong Kim Sang." ],
      "venue" : "Proceedings of the 6th Conference on Natural Language Learning, CoNLL 2002, Held in cooperation with COLING 2002,",
      "citeRegEx" : "Sang.,? 2002",
      "shortCiteRegEx" : "Sang.",
      "year" : 2002
    }, {
      "title" : "Ensemble learning for named entity recognition",
      "author" : [ "René Speck", "Axel-Cyrille Ngonga Ngomo." ],
      "venue" : "International semantic web conference, pages 519– 534. Springer.",
      "citeRegEx" : "Speck and Ngomo.,? 2014",
      "shortCiteRegEx" : "Speck and Ngomo.",
      "year" : 2014
    }, {
      "title" : "A minimal span-based neural constituency parser",
      "author" : [ "Mitchell Stern", "Jacob Andreas", "Dan Klein." ],
      "venue" : "arXiv preprint arXiv:1705.03919.",
      "citeRegEx" : "Stern et al\\.,? 2017",
      "shortCiteRegEx" : "Stern et al\\.",
      "year" : 2017
    }, {
      "title" : "Results of the wnut16 named entity recognition shared task",
      "author" : [ "Benjamin Strauss", "Bethany Toma", "Alan Ritter", "MarieCatherine De Marneffe", "Wei Xu." ],
      "venue" : "Proceedings of the 2nd Workshop on Noisy Usergenerated Text (WNUT), pages 138–144.",
      "citeRegEx" : "Strauss et al\\.,? 2016",
      "shortCiteRegEx" : "Strauss et al\\.",
      "year" : 2016
    }, {
      "title" : "Stacked generalizations: When does it work",
      "author" : [ "Kai Ming Ting", "Ian H. Witten" ],
      "venue" : "In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Ting and Witten.,? \\Q1997\\E",
      "shortCiteRegEx" : "Ting and Witten.",
      "year" : 1997
    }, {
      "title" : "Machine translation system combination by confusion forest",
      "author" : [ "Taro Watanabe", "Eiichiro Sumita." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1249–1257, Portland,",
      "citeRegEx" : "Watanabe and Sumita.,? 2011",
      "shortCiteRegEx" : "Watanabe and Sumita.",
      "year" : 2011
    }, {
      "title" : "Linguistic Data Consortium, Philadel",
      "author" : [ "Ralph Weischedel", "Martha Palmer", "Mitchell Marcus", "Eduard Hovy", "Sameer Pradhan", "Lance Ramshaw", "Nianwen Xue", "Ann Taylor", "Jeff Kaufman", "Michelle Franchini" ],
      "venue" : "Ontonotes release",
      "citeRegEx" : "Weischedel et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Weischedel et al\\.",
      "year" : 2013
    }, {
      "title" : "Critical values and probability levels for the wilcoxon rank sum test and the wilcoxon signed rank test",
      "author" : [ "Frank Wilcoxon", "SK Katti", "Roberta A Wilcox." ],
      "venue" : "Selected tables in mathematical statistics, 1:171–259.",
      "citeRegEx" : "Wilcoxon et al\\.,? 1970",
      "shortCiteRegEx" : "Wilcoxon et al\\.",
      "year" : 1970
    }, {
      "title" : "A stacked, voted, stacked model for named entity recognition",
      "author" : [ "Dekai Wu", "Grace Ngai", "Marine Carpuat." ],
      "venue" : "Proceedings of the seventh conference on Natural language learning at HLTNAACL 2003, pages 200–203.",
      "citeRegEx" : "Wu et al\\.,? 2003",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2003
    }, {
      "title" : "Multi-grained named entity recognition",
      "author" : [ "Congying Xia", "Chenwei Zhang", "Tao Yang", "Yaliang Li", "Nan Du", "Xian Wu", "Wei Fan", "Fenglong Ma", "S Yu Philip." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Xia et al\\.,? 2019",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2019
    }, {
      "title" : "LUKE: Deep contextualized entity representations with entity-aware self-attention",
      "author" : [ "Ikuya Yamada", "Akari Asai", "Hiroyuki Shindo", "Hideaki Takeda", "Yuji Matsumoto." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural",
      "citeRegEx" : "Yamada et al\\.,? 2020",
      "shortCiteRegEx" : "Yamada et al\\.",
      "year" : 2020
    }, {
      "title" : "Named entity recognition as dependency parsing",
      "author" : [ "Juntao Yu", "Bernd Bohnet", "Massimo Poesio." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6470–6476, Online. Association for Computational",
      "citeRegEx" : "Yu et al\\.,? 2020",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2020
    }, {
      "title" : "A weighted voting classifier based on differential evolution",
      "author" : [ "Yong Zhang", "Hongrui Zhang", "Jing Cai", "Binbin Yang." ],
      "venue" : "Abstract and Applied Analysis, volume 2014. Hindawi.",
      "citeRegEx" : "Zhang et al\\.,? 2014",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2014
    }, {
      "title" : "Neural system combination for machine translation",
      "author" : [ "Long Zhou", "Wenpeng Hu", "Jiajun Zhang", "Chengqing Zong." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),",
      "citeRegEx" : "Zhou et al\\.,? 2017",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 37,
      "context" : "Our model also has been deployed into the EXPLAINABOARD (Liu et al., 2021) platform, which allows users to flexibly perform the system combination of top-scoring systems in an interactive way: http://explainaboard.",
      "startOffset" : 56,
      "endOffset" : 74
    }, {
      "referenceID" : 30,
      "context" : "The rapid evolution of neural architectures (Kalchbrenner et al., 2014a; Kim, 2014; Hochreiter and Schmidhuber, 1997) and large pre-trained models (Devlin et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 32,
      "context" : "The rapid evolution of neural architectures (Kalchbrenner et al., 2014a; Kim, 2014; Hochreiter and Schmidhuber, 1997) and large pre-trained models (Devlin et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 25,
      "context" : "The rapid evolution of neural architectures (Kalchbrenner et al., 2014a; Kim, 2014; Hochreiter and Schmidhuber, 1997) and large pre-trained models (Devlin et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 11,
      "context" : ", 2014a; Kim, 2014; Hochreiter and Schmidhuber, 1997) and large pre-trained models (Devlin et al., 2019; Lewis et al., 2020) not only drive the state-of-the-art performance of many NLP tasks (Devlin et al.",
      "startOffset" : 83,
      "endOffset" : 124
    }, {
      "referenceID" : 34,
      "context" : ", 2014a; Kim, 2014; Hochreiter and Schmidhuber, 1997) and large pre-trained models (Devlin et al., 2019; Lewis et al., 2020) not only drive the state-of-the-art performance of many NLP tasks (Devlin et al.",
      "startOffset" : 83,
      "endOffset" : 124
    }, {
      "referenceID" : 11,
      "context" : ", 2020) not only drive the state-of-the-art performance of many NLP tasks (Devlin et al., 2019; Liu and Lapata, 2019) to a new level but also change the way",
      "startOffset" : 74,
      "endOffset" : 117
    }, {
      "referenceID" : 38,
      "context" : ", 2020) not only drive the state-of-the-art performance of many NLP tasks (Devlin et al., 2019; Liu and Lapata, 2019) to a new level but also change the way",
      "startOffset" : 74,
      "endOffset" : 117
    }, {
      "referenceID" : 6,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 28,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 40,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 33,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 1,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 45,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 10,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 57,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 39,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 36,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 18,
      "context" : "For example, recent years have seen frequent paradigm shifts for the task of named entity recognition (NER) from token-level tagging, which conceptualize NER as a sequence labeling (SEQLAB) task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Luo et al., 2020; Lin et al., 2020; Fu et al., 2021), to span-level prediction (SPANNER) (Li et al.",
      "startOffset" : 195,
      "endOffset" : 412
    }, {
      "referenceID" : 35,
      "context" : ", 2021), to span-level prediction (SPANNER) (Li et al., 2020; Mengge et al., 2020; Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020), which regards NER either as question answering (Li et al.",
      "startOffset" : 44,
      "endOffset" : 139
    }, {
      "referenceID" : 41,
      "context" : ", 2021), to span-level prediction (SPANNER) (Li et al., 2020; Mengge et al., 2020; Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020), which regards NER either as question answering (Li et al.",
      "startOffset" : 44,
      "endOffset" : 139
    }, {
      "referenceID" : 29,
      "context" : ", 2021), to span-level prediction (SPANNER) (Li et al., 2020; Mengge et al., 2020; Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020), which regards NER either as question answering (Li et al.",
      "startOffset" : 44,
      "endOffset" : 139
    }, {
      "referenceID" : 43,
      "context" : ", 2021), to span-level prediction (SPANNER) (Li et al., 2020; Mengge et al., 2020; Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020), which regards NER either as question answering (Li et al.",
      "startOffset" : 44,
      "endOffset" : 139
    }, {
      "referenceID" : 59,
      "context" : ", 2021), to span-level prediction (SPANNER) (Li et al., 2020; Mengge et al., 2020; Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020), which regards NER either as question answering (Li et al.",
      "startOffset" : 44,
      "endOffset" : 139
    }, {
      "referenceID" : 35,
      "context" : ", 2020), which regards NER either as question answering (Li et al., 2020; Mengge et al., 2020), span classification (Jiang et al.",
      "startOffset" : 56,
      "endOffset" : 94
    }, {
      "referenceID" : 41,
      "context" : ", 2020), which regards NER either as question answering (Li et al., 2020; Mengge et al., 2020), span classification (Jiang et al.",
      "startOffset" : 56,
      "endOffset" : 94
    }, {
      "referenceID" : 29,
      "context" : ", 2020), span classification (Jiang et al., 2020; Ouchi et al., 2020; Yamada et al., 2020), and dependency parsing tasks (Yu et al.",
      "startOffset" : 29,
      "endOffset" : 90
    }, {
      "referenceID" : 43,
      "context" : ", 2020), span classification (Jiang et al., 2020; Ouchi et al., 2020; Yamada et al., 2020), and dependency parsing tasks (Yu et al.",
      "startOffset" : 29,
      "endOffset" : 90
    }, {
      "referenceID" : 58,
      "context" : ", 2020), span classification (Jiang et al., 2020; Ouchi et al., 2020; Yamada et al., 2020), and dependency parsing tasks (Yu et al.",
      "startOffset" : 29,
      "endOffset" : 90
    }, {
      "referenceID" : 59,
      "context" : ", 2020), and dependency parsing tasks (Yu et al., 2020).",
      "startOffset" : 38,
      "endOffset" : 55
    }, {
      "referenceID" : 16,
      "context" : "Most of the existing NER combiners rely on heavy feature engineering and external knowledge (Florian et al., 2003; Wu et al., 2003; Saha and Ekbal, 2013).",
      "startOffset" : 92,
      "endOffset" : 153
    }, {
      "referenceID" : 56,
      "context" : "Most of the existing NER combiners rely on heavy feature engineering and external knowledge (Florian et al., 2003; Wu et al., 2003; Saha and Ekbal, 2013).",
      "startOffset" : 92,
      "endOffset" : 153
    }, {
      "referenceID" : 46,
      "context" : "Most of the existing NER combiners rely on heavy feature engineering and external knowledge (Florian et al., 2003; Wu et al., 2003; Saha and Ekbal, 2013).",
      "startOffset" : 92,
      "endOffset" : 153
    }, {
      "referenceID" : 49,
      "context" : "No extra training overhead and flexibility of use: Existing ensemble learning algorithms are expensive, which usually need to collect training samples by k-fold cross-validation for system combiner (Speck and Ngomo, 2014), reducing their practicality.",
      "startOffset" : 198,
      "endOffset" : 221
    }, {
      "referenceID" : 6,
      "context" : "NER is frequently formulated as a sequence labeling (SEQLAB) problem (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016), where X = {x1, x2, .",
      "startOffset" : 69,
      "endOffset" : 153
    }, {
      "referenceID" : 28,
      "context" : "NER is frequently formulated as a sequence labeling (SEQLAB) problem (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016), where X = {x1, x2, .",
      "startOffset" : 69,
      "endOffset" : 153
    }, {
      "referenceID" : 40,
      "context" : "NER is frequently formulated as a sequence labeling (SEQLAB) problem (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016), where X = {x1, x2, .",
      "startOffset" : 69,
      "endOffset" : 153
    }, {
      "referenceID" : 33,
      "context" : "NER is frequently formulated as a sequence labeling (SEQLAB) problem (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016), where X = {x1, x2, .",
      "startOffset" : 69,
      "endOffset" : 153
    }, {
      "referenceID" : 48,
      "context" : "CoNLL-2002 3 (Sang, 2002) contains annotated corpus in Dutch (NL) collected from De Morgen news, and Spanish (ES) collected from Spanish EFE News Agency.",
      "startOffset" : 13,
      "endOffset" : 25
    }, {
      "referenceID" : 54,
      "context" : "0 4 (Weischedel et al., 2013) is a large corpus consisting of three different languages: English, Chinese, and Arabic, involving six genres: newswire (NW), broadcast news (BN), broadcast conversation (BC), magazine (MZ), web data (WB), and telephone conversation (TC).",
      "startOffset" : 4,
      "endOffset" : 29
    }, {
      "referenceID" : 13,
      "context" : "Following previous works (Durrett and Klein, 2014; Ghaddar and Langlais, 2018), we utilize different domains in English to test the robustness of proposed models.",
      "startOffset" : 25,
      "endOffset" : 78
    }, {
      "referenceID" : 22,
      "context" : "Following previous works (Durrett and Klein, 2014; Ghaddar and Langlais, 2018), we utilize different domains in English to test the robustness of proposed models.",
      "startOffset" : 25,
      "endOffset" : 78
    }, {
      "referenceID" : 51,
      "context" : "7185 WNUT-2016 5 and WNUT-2017 6 (Strauss et al., 2016; Derczynski et al., 2017) are social media data from Twitter, which were public as a shared task at WNUT-2016 (W16) and WNUT-2017 (W17).",
      "startOffset" : 33,
      "endOffset" : 80
    }, {
      "referenceID" : 9,
      "context" : "7185 WNUT-2016 5 and WNUT-2017 6 (Strauss et al., 2016; Derczynski et al., 2017) are social media data from Twitter, which were public as a shared task at WNUT-2016 (W16) and WNUT-2017 (W17).",
      "startOffset" : 33,
      "endOffset" : 80
    }, {
      "referenceID" : 29,
      "context" : "Although this is not the first work that formulates NER as a span prediction problem (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020; Li et al., 2020; Mengge et al., 2020), we contribute by (1) exploring how different design choices influence the performance of SPANNER and (2) interpreting complementary strengths between SEQLAB and SPANNER with different design choices.",
      "startOffset" : 85,
      "endOffset" : 180
    }, {
      "referenceID" : 43,
      "context" : "Although this is not the first work that formulates NER as a span prediction problem (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020; Li et al., 2020; Mengge et al., 2020), we contribute by (1) exploring how different design choices influence the performance of SPANNER and (2) interpreting complementary strengths between SEQLAB and SPANNER with different design choices.",
      "startOffset" : 85,
      "endOffset" : 180
    }, {
      "referenceID" : 59,
      "context" : "Although this is not the first work that formulates NER as a span prediction problem (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020; Li et al., 2020; Mengge et al., 2020), we contribute by (1) exploring how different design choices influence the performance of SPANNER and (2) interpreting complementary strengths between SEQLAB and SPANNER with different design choices.",
      "startOffset" : 85,
      "endOffset" : 180
    }, {
      "referenceID" : 35,
      "context" : "Although this is not the first work that formulates NER as a span prediction problem (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020; Li et al., 2020; Mengge et al., 2020), we contribute by (1) exploring how different design choices influence the performance of SPANNER and (2) interpreting complementary strengths between SEQLAB and SPANNER with different design choices.",
      "startOffset" : 85,
      "endOffset" : 180
    }, {
      "referenceID" : 41,
      "context" : "Although this is not the first work that formulates NER as a span prediction problem (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020; Li et al., 2020; Mengge et al., 2020), we contribute by (1) exploring how different design choices influence the performance of SPANNER and (2) interpreting complementary strengths between SEQLAB and SPANNER with different design choices.",
      "startOffset" : 85,
      "endOffset" : 180
    }, {
      "referenceID" : 44,
      "context" : "where EMB(·) is the pre-trained embeddings, such as non-contextualized embeddings GloVe (Pennington et al., 2014) or contextualized pre-trained embeddings BERT (Devlin et al.",
      "startOffset" : 88,
      "endOffset" : 113
    }, {
      "referenceID" : 10,
      "context" : ", 2014) or contextualized pre-trained embeddings BERT (Devlin et al., 2018).",
      "startOffset" : 54,
      "endOffset" : 75
    }, {
      "referenceID" : 55,
      "context" : "To reduce the uncertainty, we run experiments with multiple trials and also perform the significant test with Wilcoxon Signed-Rank Test (Wilcoxon et al., 1970) at p < 0.",
      "startOffset" : 136,
      "endOffset" : 159
    }, {
      "referenceID" : 20,
      "context" : "Regarding SEQLAB-base systems, following (Fu et al., 2020b), their designs are diverse in four components: (1) character/subword-sensitive representation: ELMo (Peters et al.",
      "startOffset" : 41,
      "endOffset" : 59
    }, {
      "referenceID" : 45,
      "context" : ", 2020b), their designs are diverse in four components: (1) character/subword-sensitive representation: ELMo (Peters et al., 2018), Flair (Akbik et al.",
      "startOffset" : 109,
      "endOffset" : 130
    }, {
      "referenceID" : 10,
      "context" : ", 2018, 2019), BERT 9 (Devlin et al., 2018) 2) word representation: GloVe (Pennington et al.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 44,
      "context" : ", 2018) 2) word representation: GloVe (Pennington et al., 2014), fastText (Bojanowski et al.",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 2,
      "context" : ", 2014), fastText (Bojanowski et al., 2017); (3) sentence-level encoders: LSTM (Hochreiter and Schmidhuber, 1997), CNN (Kalchbrenner et al.",
      "startOffset" : 18,
      "endOffset" : 43
    }, {
      "referenceID" : 25,
      "context" : ", 2017); (3) sentence-level encoders: LSTM (Hochreiter and Schmidhuber, 1997), CNN (Kalchbrenner et al.",
      "startOffset" : 43,
      "endOffset" : 77
    }, {
      "referenceID" : 31,
      "context" : ", 2017); (3) sentence-level encoders: LSTM (Hochreiter and Schmidhuber, 1997), CNN (Kalchbrenner et al., 2014b; Chen et al., 2019); (4) decoders: CRF (Lample et al.",
      "startOffset" : 83,
      "endOffset" : 130
    }, {
      "referenceID" : 4,
      "context" : ", 2017); (3) sentence-level encoders: LSTM (Hochreiter and Schmidhuber, 1997), CNN (Kalchbrenner et al., 2014b; Chen et al., 2019); (4) decoders: CRF (Lample et al.",
      "startOffset" : 83,
      "endOffset" : 130
    }, {
      "referenceID" : 52,
      "context" : "a, Stacked Generalization) is a general method of using a high-level model to combine lower-level models to achieve greater predictive accuracy (Ting and Witten, 1997).",
      "startOffset" : 144,
      "endOffset" : 167
    }, {
      "referenceID" : 24,
      "context" : "Specifically, there are: Support Vector Machines (SVM) (Hearst et al., 1998) is a supervised machine learning algorithm, which can train quickly over large datasets.",
      "startOffset" : 55,
      "endOffset" : 76
    }, {
      "referenceID" : 3,
      "context" : "Random Forest (RF) (Breiman, 2001) is a common ensemble classifier that randomly selects a subset of training samples and variables to make multiple decision trees.",
      "startOffset" : 19,
      "endOffset" : 34
    }, {
      "referenceID" : 5,
      "context" : "Extreme Gradient Boosting (XGB) (Chen and Guestrin, 2016) is also an ensemble machine learning algorithm.",
      "startOffset" : 32,
      "endOffset" : 57
    }, {
      "referenceID" : 17,
      "context" : "It is based on the decisiontree and the gradient boosting decision (Friedman et al., 2000).",
      "startOffset" : 67,
      "endOffset" : 90
    }, {
      "referenceID" : 56,
      "context" : "which is achieved by (i) collecting training data by performing five-fold cross-validation (Wu et al., 2003; Florian et al., 2003) on the original training samples of each dataset (ii) training a system combiner based on collected samples.",
      "startOffset" : 91,
      "endOffset" : 130
    }, {
      "referenceID" : 16,
      "context" : "which is achieved by (i) collecting training data by performing five-fold cross-validation (Wu et al., 2003; Florian et al., 2003) on the original training samples of each dataset (ii) training a system combiner based on collected samples.",
      "startOffset" : 91,
      "endOffset" : 130
    }, {
      "referenceID" : 55,
      "context" : "To examine whether the SPANNNER is significantly better than the other baseline methods, we conduct the significance test with Wilcoxon Signed-RankTest (Wilcoxon et al., 1970) at p < 0.",
      "startOffset" : 152,
      "endOffset" : 175
    }, {
      "referenceID" : 6,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 28,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 40,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 33,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 1,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 45,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 10,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 57,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 0,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 39,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 36,
      "context" : "NER as Different Tasks Although NER is commonly formulated as a sequence labeling task (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016; Akbik et al., 2018; Peters et al., 2018; Devlin et al., 2018; Xia et al., 2019; Akbik et al., 2019; Luo et al., 2020; Lin et al., 2020), recently other new forms of frameworks have been explored and have shown impressive results.",
      "startOffset" : 87,
      "endOffset" : 307
    }, {
      "referenceID" : 29,
      "context" : "For example, (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020) shift NER from tokenlevel tagging to span-level prediction task while (Li et al.",
      "startOffset" : 13,
      "endOffset" : 70
    }, {
      "referenceID" : 43,
      "context" : "For example, (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020) shift NER from tokenlevel tagging to span-level prediction task while (Li et al.",
      "startOffset" : 13,
      "endOffset" : 70
    }, {
      "referenceID" : 59,
      "context" : "For example, (Jiang et al., 2020; Ouchi et al., 2020; Yu et al., 2020) shift NER from tokenlevel tagging to span-level prediction task while (Li et al.",
      "startOffset" : 13,
      "endOffset" : 70
    }, {
      "referenceID" : 35,
      "context" : ", 2020) shift NER from tokenlevel tagging to span-level prediction task while (Li et al., 2020; Mengge et al., 2020) conceptualize it as reading comprehension task.",
      "startOffset" : 78,
      "endOffset" : 116
    }, {
      "referenceID" : 41,
      "context" : ", 2020) shift NER from tokenlevel tagging to span-level prediction task while (Li et al., 2020; Mengge et al., 2020) conceptualize it as reading comprehension task.",
      "startOffset" : 78,
      "endOffset" : 116
    }, {
      "referenceID" : 23,
      "context" : "System Combination Traditionally, system combination was used to improve the performance of statistical MT systems (González-Rubio et al., 2011; Watanabe and Sumita, 2011; Duh et al., 2011; Mizumoto and Matsumoto, 2016).",
      "startOffset" : 115,
      "endOffset" : 219
    }, {
      "referenceID" : 53,
      "context" : "System Combination Traditionally, system combination was used to improve the performance of statistical MT systems (González-Rubio et al., 2011; Watanabe and Sumita, 2011; Duh et al., 2011; Mizumoto and Matsumoto, 2016).",
      "startOffset" : 115,
      "endOffset" : 219
    }, {
      "referenceID" : 12,
      "context" : "System Combination Traditionally, system combination was used to improve the performance of statistical MT systems (González-Rubio et al., 2011; Watanabe and Sumita, 2011; Duh et al., 2011; Mizumoto and Matsumoto, 2016).",
      "startOffset" : 115,
      "endOffset" : 219
    }, {
      "referenceID" : 42,
      "context" : "System Combination Traditionally, system combination was used to improve the performance of statistical MT systems (González-Rubio et al., 2011; Watanabe and Sumita, 2011; Duh et al., 2011; Mizumoto and Matsumoto, 2016).",
      "startOffset" : 115,
      "endOffset" : 219
    }, {
      "referenceID" : 61,
      "context" : "Some recent work (Zhou et al., 2017; Huang et al., 2020) also extended this method to neural MT where",
      "startOffset" : 17,
      "endOffset" : 56
    }, {
      "referenceID" : 27,
      "context" : "Some recent work (Zhou et al., 2017; Huang et al., 2020) also extended this method to neural MT where",
      "startOffset" : 17,
      "endOffset" : 56
    }, {
      "referenceID" : 56,
      "context" : "(Wu et al., 2003; Florian et al., 2003) investigated stacking and voting methods for combining strong classifiers.",
      "startOffset" : 0,
      "endOffset" : 39
    }, {
      "referenceID" : 16,
      "context" : "(Wu et al., 2003; Florian et al., 2003) investigated stacking and voting methods for combining strong classifiers.",
      "startOffset" : 0,
      "endOffset" : 39
    }, {
      "referenceID" : 29,
      "context" : "For example, we can formulate constituency parsing (Jiang et al., 2020) as well as its re-ranking (Collins and Koo, 2005; Huang, 2008) as a span prediction (Stern et al.",
      "startOffset" : 51,
      "endOffset" : 71
    }, {
      "referenceID" : 7,
      "context" : ", 2020) as well as its re-ranking (Collins and Koo, 2005; Huang, 2008) as a span prediction (Stern et al.",
      "startOffset" : 34,
      "endOffset" : 70
    }, {
      "referenceID" : 26,
      "context" : ", 2020) as well as its re-ranking (Collins and Koo, 2005; Huang, 2008) as a span prediction (Stern et al.",
      "startOffset" : 34,
      "endOffset" : 70
    }, {
      "referenceID" : 50,
      "context" : ", 2020) as well as its re-ranking (Collins and Koo, 2005; Huang, 2008) as a span prediction (Stern et al., 2017) problem, which is be unified and parameterized with the same form.",
      "startOffset" : 92,
      "endOffset" : 112
    }, {
      "referenceID" : 15,
      "context" : "Leaderboard makes us pay more attention to and even obsess over the state-of-the-art systems (Ethayarajh and Jurafsky, 2020).",
      "startOffset" : 93,
      "endOffset" : 124
    }, {
      "referenceID" : 37,
      "context" : "Our model also has been deployed into the EXPLAINABOARD (Liu et al., 2021) platform, which allows users to flexibly perform system combination of top-scoring systems in an interactive way: http://explainaboard.",
      "startOffset" : 56,
      "endOffset" : 74
    } ],
    "year" : 2021,
    "abstractText" : "Recent years have seen the paradigm shift of Named Entity Recognition (NER) systems from sequence labeling to span prediction. Despite its preliminary effectiveness, the span prediction model’s architectural bias has not been fully understood. In this paper, we first investigate the strengths and weaknesses when the span prediction model is used for named entity recognition compared with the sequence labeling framework and how to further improve it, which motivates us to make complementary advantages of systems based on different paradigms. We then reveal that span prediction, simultaneously, can serve as a system combiner to re-recognize named entities from different systems’ outputs. We experimentally implement 154 systems on 11 datasets, covering three languages, comprehensive results show the effectiveness of span prediction models that both serve as base NER systems and system combiners. We make all code and datasets available: https:// github.com/neulab/spanner, as well as an online system demo: http://spanner. sh. Our model also has been deployed into the EXPLAINABOARD (Liu et al., 2021) platform, which allows users to flexibly perform the system combination of top-scoring systems in an interactive way: http://explainaboard. nlpedia.ai/leaderboard/task-ner/.",
    "creator" : "LaTeX with hyperref"
  }
}