{
  "name" : "2021.acl-long.61.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER",
    "authors" : [ "Weile Chen", "Huiqiang Jiang", "Qianhui Wu", "Börje F. Karlsson", "Yi Guan" ],
    "emails" : [ "chen.weile7@gmail.com,", "jhq@pku.edu.cn,", "guanyi@hit.edu.cn,", "wuqianhui@tsinghua.org.cn,", "borje.karlsson@microsoft.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 743–753\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n743"
    }, {
      "heading" : "1 Introduction",
      "text" : "Named entity recognition (NER) is a fundamental information extraction task, which seeks to identify named entities in text and classify them into predefined entity types (such as person, organization, location, etc.) and it is key in various downstream tasks, e.g., question answering (Mollá et al., 2006). Neural NER models are highly successful for languages with a large amount of quality annotated data. However, most languages don’t have enough labeled data to train a fully supervised model. This motivates research on cross-lingual transfer, which leverages labeled data from a source language (e.g.,\n1Code is publicly available at https://aka.ms/ AdvPicker\nEnglish) to address the lack of training data problem in a target language. In this paper, following Wu and Dredze (2019) and Wu et al. (2020a), we focus on zero-shot cross-lingual NER, where labeled data is not available in the target language.\nThe state-of-the-art methods for zero-shot cross-lingual NER are mainly divided into three categories: i) feature-based methods (Wu and Dredze, 2019; Wu et al., 2020b; Pfeiffer et al., 2020), which train a NER model to capture language-independent features of the labeled source-language data and then apply it to the target language; ii) translation-based methods (Mayhew et al., 2017; Xie et al., 2018), which build pseudo target-language dataset via translating from labeled source-language data and mapping entity labels; and iii) pseudo-labeling methods, which generate pseudo-labeled data for training a target-language NER model via a source-language model (Wu et al., 2020a) or annotation projection (Ni et al., 2017).\nHowever, each method has its own disadvantages. Feature-based methods only learn the knowledge in the source language, but cannot leverage any target-language information. Translation-based methods require high-quality translation resources, which are expensive to obtain. And pseudo-labeled methods assume that all pseudo-labeled data is beneficial for cross-lingual transfer learning, which is not always the case.\nTherefore, here we propose a novel approach – AdvPicker – which combines feature-based and pseudo-labeling methods, while not requiring any extra costly resources (e.g., translation models or parallel data). Furthermore, to address the described problems, we enhance the source-language NER model with unlabeled target language data via adversarial training. Unlike other pseudolabeling methods, we only leverage the languageindependent pseudo-labeled data selected by an adversarial discriminator, to alleviate overfitting the\nmodel in language-specific features of the sourcelanguage.\nSpecifically, we first train an encoder and a NER classifier on labeled source-language data to learn entity domain knowledge. Meanwhile, a language discriminator and the encoder are trained on a token-level adversarial task which enhances the ability of the encoder to capture shared features. We then apply the encoder and the NER classifier on unlabeled target-language data to generate pseudolabels and use an adversarial discriminator to select less language-specific data samples. Finally, we utilize knowledge distillation to train a targetlanguage NER model on this selected dataset.\nWe evaluate our proposed AdvPicker over 3 target languages on standard benchmark datasets. Our experimental results show that the proposed method benefits strongly from this data selection process and outperforms existing SOTA methods; without requiring any additional external resources (e.g., gazetteers or machine translation).\nOur major contributions are as follows:\n• We propose a novel approach to combine feature-based and pseudo-labeling methods via language adversarial learning for crosslingual NER; • We adopt an adversarial discriminator to select what language-independent data to leverage in training a cross-lingual NER model to improved performance. To the best of our knowledge, this is the first successful attempt in selecting data by adversarial discriminator for XL-NER; • Experiments on standard multi-lingual datasets showcase AdvPicker achieves new state-of-the-art results in cross-lingual NER."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Cross-Lingual NER",
      "text" : "Cross-lingual transfer for NER has been widely studied in recent years. Prior works are divided into three categories: feature-based, translation-based, and pseudo-labeling.\nFeature-based methods generally use languageindependent features to train a NER model in the labeled source-language data, which include word clusters (Täckström et al., 2012), Wikifier features (Tsai et al., 2016), gazetteers (Zirikly and Hagiwara, 2015), and aligned word representations (Ni et al., 2017; Wu and Dredze, 2019), etc. Moreover, for language-independent features, adversar-\nial learning was applied on word/char embedding layers (Huang et al., 2019; Bari et al., 2020) or encoders (Zhou et al., 2019; Keung et al., 2019). Translation-based methods generally use pseudo target-language data translated from labeled sourcelanguage data. Ni et al. (2017) proposed to project labels from the source language into the target language by using word alignment information. Most recent methods translate the annotated corpus in the source language to the target language word-byword (Xie et al., 2018) or phrase-by-phrase (Mayhew et al., 2017) and then copy the labels for each word/phrase to their translations. While (Jain et al., 2019) proposed to translate full sentences in the source language and project entity labels to targetlanguage sentences.\nTo leverage unlabeled target-language data, pseudo-labeling methods generate the pseudolabels by annotation projection on comparable corpora (Ni et al., 2017) or via models trained on source-language labeled data (Wu et al., 2020a).\nIn this paper, we propose AdvPicker, an approach that requires no translation and combines feature-based and pseudo-labeling methods. Moreover, we leverage pseudo-labeled data differently from other pseudo-labeling methods. Through adversarial training, we select language-independent pseudo-labeled data for training a new targetlanguage model."
    }, {
      "heading" : "2.2 Language Adversarial Learning",
      "text" : "Language-adversarial training (Zhang et al., 2017) was proposed for the unsupervised bilingual lexicon induction task. And it has been applied in inducing language-independent features for crosslingual tasks in NER (Zhou et al., 2019; Xie et al., 2018), text classification (Chen et al., 2019b), and sentiment classification (Chen et al., 2018).\nKeung et al. (2019) proposed a multilingual BERT with sentence-level adversarial learning. However, this method does not improve crosslingual NER performance significantly. To address this limitation, AdvPicker uses multilingual BERT with token-level adversarial training for cross-lingual NER, which induces more languageindependent features for each token embedding."
    }, {
      "heading" : "2.3 Knowledge Distillation",
      "text" : "Knowledge distillation was proposed to compress models (Buciluă et al., 2006) or ensembles of models (Rusu et al., 2016; Hinton et al., 2015; Sanh et al., 2019; Mukherjee and Hassan Awadallah,\n2020) via transferring knowledge from one or more models (teacher models) to a smaller one (student model). Besides model compression, knowledge distillation has also been applied to various tasks, like cross-modal learning (Hu et al., 2020), machine translation (Weng et al., 2020), and automated machine learning (Kang et al., 2020).\nIn this paper, we adapt knowledge distillation to leverage unlabeled data in the cross-lingual NER task. This helps the student model learn richer information from easily obtainable data (with pseudolabels)."
    }, {
      "heading" : "3 AdvPicker",
      "text" : "In this section, we introduce our approach (AdvPicker) which utilizes the adversarial learning approach to select language-independent pseudolabeled data for training an effective targetlanguage NER model. Figure 1 illustrates the framework of the proposed AdvPicker. Specifically, as shown in Figure 1(a), we train an encoder and a NER classifier on the labeled source-language data. Meanwhile, a language discriminator and the encoder are trained on the token-level adversarial task. We then apply encoder and classifier over unlabeled target-language data to generate pseudolabels and use the adversarial discriminator to select the most language-independent pseudo-labeled data samples. Finally, we utilize knowledge distillation to train a target-language NER model on this selected dataset.\nIn the following section, we describe the language-independent data selection process, including the token-level adversarial training, data selection by the discriminator, and knowledge distillation on select language-independent data."
    }, {
      "heading" : "3.1 Token-level Adversarial Training for Cross-Lingual NER",
      "text" : "To avoid the model overfitting on language-specific features of the source-language, we propose the token-level adversarial learning (TLADV) framework, which is shown in Figure 1(a).\nFollowing Keung et al. (2019), we formulate adversarial cross-lingual NER as a multi-task problem: i) NER and ii) binary language classification (i.e source vs. target language). For the NER task, we train the encoder and classification layer on NER annotated text in the source language. The encoder learns to capture the NER features of the input sentences and then the classification layer tries\nto predict the entity labels for each word based on their feature vectors.\nFor the language classification task, we train a language discriminator and an encoder on the labeled source-language dataset and unlabeled targetlanguage data. The language discriminator is added to classify whether an embedding generated by the encoder is associated to the source or the target language. The encoder tries to produce languageindependent embeddings that are difficult for the language discriminator to classify correctly. We define the encoder, the language discriminator, and their objectives as follows: Encoder Given an input sentence x = [xi]1≤i≤N with N words, we feed it into encoder E to obtain feature vectors h = [hi]1≤i≤N for all words:\nh = E(x) (1)\nwhere E is the feature encoder which generates language-independent feature vectors h for each sentence x. Following Keung et al. (2019), we use multilingual BERT as the feature encoder here and denote the encoder as mBERT-TLADV. NER Classifier We feed h into the NER classifier which is a linear classification layer with the softmax activation function to predict the entity label of token x.\nPθ(Y NER) = softmax(W NERh + bNER) (2)\nwhere Pθ(Y NER) ∈ R|C| is the probability distribution of entity labels for token x and C is the entity label set. W NER ∈ Rde×|C| and bNER ∈ R|C| denote the to-be-learned parameters with de being the dimension of vector h. Language Discriminator The language discriminator is comprised of two linear transformations and a ReLU function for classifying token embedding. The sigmoid function is used to predict the probability of whether h belongs to the source language.\nPθ(Y DIS) = σ(W DIS1 ReLU(W DIS2h)) (3)\nwhere W DIS1 ∈ Rdd×de and W DIS2 ∈ Rd`×dd , with dd being the hidden dimension of discriminator and d` the language classification task label size. σ is the sigmoid function to obtain the language probability of each word.\nFor language-adversarial training, we have 3 loss functions: the encoder loss LE, the language discriminator loss LDIS, and the NER task loss LNER.\n1\nNote that we don’t add these three loss functions together for backward propagation. Parameters of different components in adversarial learning are alternatively updated based on the corresponding loss function, similarly to Keung et al. (2019). Specifically, for the NER task, the parameters of the encoder and the NER classifier are updated based on LNER. For the adversarial task, the parameters of the encoder are updated based on LE, while the parameters of the discriminator are updated based on LDIS. Algorithm 1 shows the pseudocode for the adversarial training process.\nLE = − 1 N ∑ i∈[1,N ] logPθ(Y DISi = ỹDISi )\n+ logPθ(Y DISi = yDISi )\nLDIS = − 1 N ∑ i∈[1,N ] logPθ(Y DISi = yDISi )\n+ logPθ(Y DISi = ỹDISi )\nLNER = − 1 N ∑ i∈[1,N ] logPθ(Y NERi = yNERi )\n(4)\nwhere x is the sentence, yDIS ∈ {0, 1} is the ground truth label for the language classification task, ỹDIS ∈ {0, 1} is the negative label for the language classification task, and yNER ∈ RN×|C| is the ground truth of named entity recognition task for corresponding input x."
    }, {
      "heading" : "3.2 Language-Independent Data Selection",
      "text" : "To obtain the pseudo labels ŷT-NER for targetlanguage examples, we apply the learned mBERTTLADV model on the unlabeled target-language data xT. However, the pseudo-labeled dataset D = {xT, ŷT-NER} may then contain lots of languagespecific samples. We then leverage the adversarial discriminator to select pseudo languageindependent samples from the generated set.\nThe language discriminator tries to make the encoder unable to distinguish the language of a token through confrontation. In this way, the encoder should pay more attention to features that are less related to the source language when learning the NER task. After adversarial training, the language discriminator can still correctly classify certain embeddings with a high probability. We define these as language-specific samples. Other samples are ambiguous regarding language (for example, sentences with probability close to 0.5), and they are defined as samples that are more languageindependent.\nIn order to quantify the language independence of each sample, we use the language discriminator to calculate the probability of whether the sentence xT is from the source language Pθ(Y DIS,xT), the formula is as follows:\nPθ(Y DIS,xT) = σ(W DIS1 ReLU(W DIS2hT)) (5)\nwhere xT and hT, respectively, denote the target-\nAlgorithm 1 Pseudocode for token-level adversarial training on zero-shot cross-lingual NER.\nRequire: training set DE = DDIS = {(x,yDIS)} and DNER = {(x,yNER)}, batch size bs = 1 for clarity, batch number B, the output probability of model Pθ(Y m), the hidden vector of model h.\n1: Initialize hidden vector of W ∗, b∗; 2: for i = 1, · · · , B do 3: for model m in {NER, E, DIS} do 4: Sample batch (x, y) ∈ Dm; 5: # Calculate model hidden vector; 6: h = E(x), refer to Equ(1) 7: if model m equal to model NER then 8: Calculate Pθ(Y NER), Eq.(2) 9: else\n10: Calculate Pθ(Y DIS), Eq.(3) 11: end if 12: Calculate model loss Lm using x, y and Pθ(Y m), Eq.(4) 13: Update parameters of embeddings w.r.t.\nthe gradients using ∇Lm with parameters Wm, bm and the encoder E (if m in {NER, E}).\n14: end for 15: end for\nlanguage sentence and its feature vector, and Pθ(Y DIS,xT) is the probability of xT mentioned in Eq.( 3).\nIn order to select from the pseudo-labeled data, we design an index `score to represent the language independence of a sentence xT (the degree of model confusion on different languages). We assume it follows a uniform distribution and reaches its maximum when Pθ(Y DIS,xT) = 0.5. Conversely, the index is at its minimal value when Pθ(Y DIS,xT) is equal to 0 or 1.\n`score(x T) = 1− ∥∥Pθ(Y DIS,xT)− 0.5∥∥ (6) We select target-language samples with the highest `score in the top ρ as language-independent data. ρ is a hyper-parameter which is the data ratio of pseudo-labeled data. Finally, we obtain the selected target-language pseudo-labeled dataset Dsubset = {xTsubset, ŷ T-NER subset }, a subset of target language pseudo-labeled dataset. There are two reasons for selecting languageindependent samples by the language discriminator. First, these samples’ feature vectors contain\nless language-specific information which is helpful for cross-lingual transfer learning. Second, the NER classifier is trained on source-language labeled data. Therefore, it is more likely to generate high-quality predictive labels on selected targetlanguage samples that have similar feature vectors to source-language samples."
    }, {
      "heading" : "3.3 Knowledge Distillation on Language-Independent Data",
      "text" : "To leverage such less language-dependent data, we train a target-language NER model on the selected pseudo-labeled data Dsubset. Considering a lot of helpful information can be carried in soft targets instead of hard targets (Hinton et al., 2015), we use the soft labels of the selected pseudo-data to train a student model hTstu via knowledge distillation. To construct the student model, we used the pretrained cased multilingual BERT(mBERT) (Devlin et al., 2019) as the initialization and a linear layer with softmax function:\nPθ(Y T-NER) = softmax(W T-NERhTstu + bT-NER) (7) where Pθ(Y T-NER) is the distribution of entity labels probability output from the student model. W T-NER ∈ Rds×|C| and bT-NER ∈ R|C| are learnable parameters of the student NER model.\nFollowing Wu et al. (2020a), the loss function LKD is defined as the mean squared error (MSE) between the prediction output Pθ(Y T-NER) and the soft labels of the selected data, which is formulated as:\nLKD = 1 N ∑ i∈[1,N ] (Pθ(Y T-NER)− ŷT-NERsubset )2 (8)\nwhere ŷT-NERsubset ∈ Dsubset are the selected soft labels with N tokens and Pθ(Y T-NER) is the prediction probability of the selected sentence xT. By minimizing the MSE loss, the student model is trained supervised on the target-language selected data pseudo-labels.\nFor inference in the target language, we only apply the student model on test cases to predict the probability distribution of entity labels for each token in sentences, as Eq.(7). To ensure the entity labels follow the NER tagging scheme, the prediction result is generated by Viterbi decoding (Chen et al., 2019a)."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Experiment Settings",
      "text" : "Datasets We conduct experiments in 4 different languages: English [en], Spanish [es], Dutch [nl], German [de]. Spanish and Dutch data is from the CoNLL-2002 NER shared task (Tjong Kim Sang, 2002a)2, while English and German are from CoNLL-2003 (Tjong Kim Sang, 2002b)3. Table 1 presents some basic statistics of the datasets used in our experiments.\nCoNLL-2002/2003 data uses gold standard labelling and it is tagged with four entity types: PER, LOC, ORG, and MISC. Following Wu and Dredze (2019), we use the BIO labeling scheme (Farber et al., 2008) and the official split of train/validation/test sets. As previous works (Täckström et al., 2012; Jain et al., 2019; Wu et al., 2020b), for all experiments, we always use English as source language and the others as target languages. Our models are trained on the training set of English and evaluated on the test sets of each target language.\nNote that for each target language, we only use text in its training set to train our model with these unlabeled target language data. In adversarial learning, we randomly sample data from all target languages and construct a target-language dataset of the same size as the English training dataset.\nImplementation Details We implement AdvPicker using PyTorch 1.6.0. For data pre-processing, we leverage WordPiece (Wu et al., 2016) to tokenize each sentence into a sequence of sub-words which are then fed into the model. For the encoder (i.e. E in Eq.(1)) and student model (i.e. hTstu in Eq.(7)), we employ the\n2https://www.clips.uantwerpen.be/conll2002/ner/ 3https://www.clips.uantwerpen.be/conll2003/ner/\npre-trained cased multilingual BERT in HuggingFace’s Transformers (Wolf et al., 2020)4 as backbone model, which has 12 transformer blocks, 12 attention heads, and 768 hidden units.\nWe empirically select the following hyperparameters. Specifically, referring to the settings of Wu et al. (2020b), we freeze the parameters of the embedding layer and the bottom three layers of the multilingual BERT used in the encoder and the NER student model. We train all models using a batch size of 32, maximum sequence length of 128, a dropout rate of 0.1, and use AdamW (Loshchilov and Hutter, 2019) as optimizer. For sequence prediction, we apply Viterbi decoding (Chen et al., 2019a) on all models in our experiments.\nFollowing Keung et al. (2020), in all experiments the other hyper-parameters are tuned on each target language dev set. We train all models for 10 epochs and choose the best model checkpoint with the target dev set. For adversarial learning, we set the learning rate of 6e-5 for the NER loss LNER and 6e-7 for both loss encoder LE and discriminator loss LDIS. For knowledge distillation, we use a learning rate of 6e-5 for the student models. We set the hidden dimension of the discriminator as 500. For data selection, ρ is set to 0.8. Following Tjong Kim Sang (2002a), we use the entity level F1score as evaluation metric. Moreover, experiments are repeated 5 times for different random seeds on each corpus.\nNote that the selected data from the discriminator is generated by combination of output from mBERT-TLADVs with different random seeds, as we observe only a small number of samples with high `score in the selected data generated by each model. Specifically, for each target-language sentence xT, there are 5 corresponding soft label sequences generated from 5 different mBERTTLADV models. From those, only sequences that have the highest sum of each predicted label confidence are kept.\nOur models are trained on a Tesla P100 GPU (16GB). mBERT-TLADV has 178M parameters and trains in ≈130min, while the student models hTstu have 177M parameters and take ≈21min."
    }, {
      "heading" : "4.2 Comparison with State-of-The-Art Results",
      "text" : "Table 2 reports the zero-shot cross-lingual NER results of different methods on the 3 target languages.\n4https://github.com/huggingface\nThese include AdvPicker, prior SOTA methods, and two re-implemented baseline methods, i.e., mBERT-TLADV (Section 3.1) and mBERT-ft (mBERT fine-tuned on labeled source-language data). Note that some existing methods use the translation model as an additional data transfer source, whereas our method does not. For a fair comparison, we compare against the version of UniTrans (Wu et al., 2020a) w/o translation (as reported in their paper). Our method outperforms the existing methods with F1-scores of 75.01, 79.90, and 82.90, when using only source-language labeled data and target-language unlabeled data. Particularly, compared with Unitrans* (previous SOTA), AdvPicker achieves an improvement of F1-score ranging from 1.41 in German to 1.71 in Dutch. Furthermore, our result is comparable to the full UniTrans using also translation (0.04 F1 difference on average).\nBesides, AdvPicker achieves an average F1score improvement of 1.83 over mBERT-TLADV and 2.95 over mBERT-ft. These results well demonstrate the effectiveness of the proposed approach, which is mainly attributed to more effectively leveraging unlabeled target language data and selecting the language-independent data for cross-lingual transfer."
    }, {
      "heading" : "4.3 Quality of Selected Data",
      "text" : "Language-Independence We use the selected dataset Dsubset to train student models via knowledge distillation. Pθ(Y T-NER) in Dsubset is calcu-\nlated over feature vectors generated by mBERTTLADV. To validate the language-independence of these feature vectors, we apply three discriminators defined as in Eq.(3) to classify the token fea-\nture vectors from three different encoders: mBERT, mBERT-ft, and mBERT-TLADV.\nUnlike in the adversarial learning setting, we fix the parameters of the three encoders and only train the discriminators. We use each language training set to train discriminators and evaluate on each target language corresponding test set. Table 3 reports the discriminator accuracy for 3 different encoders. We can see that the classification accuracy is reduced with adversarial training, which suggests that the similarity of feature vectors between the source language and the target language is improved; which further demonstrates the feature vectors become more language-independent when adversarial training is applied. Pseudo Labels To evaluate the languageindependent quality of pseudo labels, we calculate the F1 scores of the pseudo labels and the number of sentences involved. We denote languageindependent data and language-specific data as “selected data” and “other data” respectively.\nTable 4 reports the pseudo labels F1 scores of both language-independent data and languagespecific data for each target language using mBERT-TLADV. Generally, the average F1 score of language-independent data is 12.87 points higher than language-specific data, which suggests that language-independent data has higher quality pseudo-labels. Furthermore, the selected data contains less language-specific information.\nTable 5 reports the number of languageindependent and language-specific examples for each language. From these results (Tables 4, 5), we observe that the selected data is still high-quality, even if we set a very loose threshold (80% of unlabeled data being selected)."
    }, {
      "heading" : "4.4 Model Performance over Selected/Other Data Splits",
      "text" : "In order to better analyse the behaviour of AdvPicker across data variations, we use the trained language discriminator to split the target language test sets into Selected and Other partitions (similarly to how the training set is processed). Table 7 shows the different models’s F1 scores for the partitioned data.\nFrom Table 7, we can draw these conclusions: 1) As expected, models perform better over Selected data than over Other data; 2) AdvPicker is only trained on Selected data, but nonetheless outperforms all baseline models in\nboth data partitions; 3) AdvPicker’s approach effectively selects examples with better features and is not over-biased towards Selected data."
    }, {
      "heading" : "4.5 Ablation Study",
      "text" : "To validate the contributions of different process in the proposed AdvPicker, we introduce the following variants of AdvPicker and baselines to perform an ablation study: 1) AdvPicker w/o KD, which directly combines the prediction of test data from mBERT-TLADVs with different seeds without knowledge distillation on pseudo-labeled training data. 2) AdvPicker w All-Data, which trains a student model on all target-language pseudo-labeled data generated by mBERT-TLADV. 3) mBERT-ft, mBERT fine-tuned on source-language labeled data. 4) mBERT-TLADV (Section 3.1), meaning mBERT trained on source-language labeled data with token-level adversarial learning.\nTable 6 reports the performance of each method and their performance drops compared to AdvPicker. Moreover, we can draw more in-depth observations as follows:\n1) Comparing AdvPicker with AdvPicker w/o KD and AdvPicker w All-Data, we can see that selecting the language-independent data is reasonable. That also validates the effectiveness of the model trained on language-independent data via knowledge distillation.\n2) mBERT-ft outperforms mBERT-TLADV. Such results well demonstrate that token-level adversarial learning is helpful to train a languageindependent feature encoder and brings performance improvement.\n3) By comparing the F1 scores of AdvPicker w All-Data and AdvPicker on the target languages, we observe that training on selected data brings higher performance improvements on larger datasets, e.g., German [de] and Dutch [nl], and lower improvements on the smaller Spanish [es] dataset. Although selected data has high-quality pseudo labels, smaller sizes of selected datasets may limit performance improvements."
    }, {
      "heading" : "4.6 Stability Analysis",
      "text" : "Because BERT fine-tuning is known to be unstable in few-shot tasks, as discussed in Zhang et al. (2021). mBERT-based methods’ performances on the CoNLL NER dataset are likely also unstable. To evaluate the stability of AdvPicker, we compare\nthe standard deviation of F1 scores for mBERT-ft, Unitrans, and AdvPicker.\nTable 2 includes the standard deviation of F1 scores over five runs for each model. AdvPicker has a lower average standard deviation in the three target languages than the other mBERT-based methods. Such results demonstrate that selected data can bring a degree of stability to the model, or limit instability, as the student model in AdvPicker is trained on selected data with the soft labels from other trained models."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we propose a novel approach to combine the feature-based method and pseudo labeling via language adversarial learning for cross-lingual NER. AdvPicker is the first successful attempt in selecting language-independent data by adversarial discriminator to cross-lingual NER. Our experimental results show that the proposed system benefits strongly from this new data selection process and outperforms existing state-of-the-art methods, even without requiring additional extra resources."
    } ],
    "references" : [ {
      "title" : "Zero-resource cross-lingual named entity recognition",
      "author" : [ "M. Saiful Bari", "Shafiq R. Joty", "Prathyusha Jwalapuram." ],
      "venue" : "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial",
      "citeRegEx" : "Bari et al\\.,? 2020",
      "shortCiteRegEx" : "Bari et al\\.",
      "year" : 2020
    }, {
      "title" : "Model compression",
      "author" : [ "Cristian Buciluă", "Rich Caruana", "Alexandru Niculescu-Mizil." ],
      "venue" : "Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535–541.",
      "citeRegEx" : "Buciluă et al\\.,? 2006",
      "shortCiteRegEx" : "Buciluă et al\\.",
      "year" : 2006
    }, {
      "title" : "GRN: Gated relation network to enhance convolutional neural network for named entity recognition",
      "author" : [ "Hui Chen", "Zijia Lin", "Guiguang Ding", "Jian-Guang Lou", "Yusen Zhang", "Börje F. Karlsson." ],
      "venue" : "The Thirty-Third AAAI Conference on Artificial Intelli-",
      "citeRegEx" : "Chen et al\\.,? 2019a",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Multisource cross-lingual model transfer: Learning what to share",
      "author" : [ "Xilun Chen", "Ahmed Hassan Awadallah", "Hany Hassan", "Wei Wang", "Claire Cardie." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguis-",
      "citeRegEx" : "Chen et al\\.,? 2019b",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Adversarial deep averaging networks for cross-lingual sentiment classification",
      "author" : [ "Xilun Chen", "Yu Sun", "Ben Athiwaratkun", "Claire Cardie", "Kilian Weinberger." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 6:557–570.",
      "citeRegEx" : "Chen et al\\.,? 2018",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2018
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Improving NER in Arabic using a morphological tagger",
      "author" : [ "Benjamin Farber", "Dayne Freitag", "Nizar Habash", "Owen Rambow." ],
      "venue" : "Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08), Marrakech, Mo-",
      "citeRegEx" : "Farber et al\\.,? 2008",
      "shortCiteRegEx" : "Farber et al\\.",
      "year" : 2008
    }, {
      "title" : "Distilling the knowledge in a neural network",
      "author" : [ "Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean." ],
      "venue" : "arXiv preprint arXiv:1503.02531.",
      "citeRegEx" : "Hinton et al\\.,? 2015",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2015
    }, {
      "title" : "Creating something from nothing: Unsupervised knowledge distillation for cross-modal hashing",
      "author" : [ "Hengtong Hu", "Lingxi Xie", "Richang Hong", "Qi Tian." ],
      "venue" : "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seat-",
      "citeRegEx" : "Hu et al\\.,? 2020",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2020
    }, {
      "title" : "Crosslingual multi-level adversarial transfer to enhance low-resource name tagging",
      "author" : [ "Lifu Huang", "Heng Ji", "Jonathan May." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
      "citeRegEx" : "Huang et al\\.,? 2019",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2019
    }, {
      "title" : "Entity projection via machine translation for cross-lingual NER",
      "author" : [ "Alankar Jain", "Bhargavi Paranjape", "Zachary C. Lipton." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Jain et al\\.,? 2019",
      "shortCiteRegEx" : "Jain et al\\.",
      "year" : 2019
    }, {
      "title" : "Towards oracle knowledge distillation with neural architecture search",
      "author" : [ "Minsoo Kang", "Jonghwan Mun", "Bohyung Han." ],
      "venue" : "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of",
      "citeRegEx" : "Kang et al\\.,? 2020",
      "shortCiteRegEx" : "Kang et al\\.",
      "year" : 2020
    }, {
      "title" : "Adversarial learning with contextual embeddings for zero-resource cross-lingual classification and NER",
      "author" : [ "Phillip Keung", "Yichao Lu", "Vikas Bhardwaj." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
      "citeRegEx" : "Keung et al\\.,? 2019",
      "shortCiteRegEx" : "Keung et al\\.",
      "year" : 2019
    }, {
      "title" : "Don’t use English dev: On the zero-shot cross-lingual evaluation of contextual embeddings",
      "author" : [ "Phillip Keung", "Yichao Lu", "Julian Salazar", "Vikas Bhardwaj." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Keung et al\\.,? 2020",
      "shortCiteRegEx" : "Keung et al\\.",
      "year" : 2020
    }, {
      "title" : "Decoupled weight decay regularization",
      "author" : [ "Ilya Loshchilov", "Frank Hutter." ],
      "venue" : "7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.",
      "citeRegEx" : "Loshchilov and Hutter.,? 2019",
      "shortCiteRegEx" : "Loshchilov and Hutter.",
      "year" : 2019
    }, {
      "title" : "Cheap translation for cross-lingual named entity recognition",
      "author" : [ "Stephen Mayhew", "Chen-Tse Tsai", "Dan Roth." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2536–2545, Copenhagen, Denmark. As-",
      "citeRegEx" : "Mayhew et al\\.,? 2017",
      "shortCiteRegEx" : "Mayhew et al\\.",
      "year" : 2017
    }, {
      "title" : "Named entity recognition for question answering",
      "author" : [ "Diego Mollá", "Menno van Zaanen", "Daniel Smith." ],
      "venue" : "Proceedings of the Australasian Language Technology Workshop 2006, pages 51–58, Sydney, Australia.",
      "citeRegEx" : "Mollá et al\\.,? 2006",
      "shortCiteRegEx" : "Mollá et al\\.",
      "year" : 2006
    }, {
      "title" : "XtremeDistil: Multi-stage distillation for massive multilingual models",
      "author" : [ "Subhabrata Mukherjee", "Ahmed Hassan Awadallah." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2221–2234, Online. As-",
      "citeRegEx" : "Mukherjee and Awadallah.,? 2020",
      "shortCiteRegEx" : "Mukherjee and Awadallah.",
      "year" : 2020
    }, {
      "title" : "Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection",
      "author" : [ "Jian Ni", "Georgiana Dinu", "Radu Florian." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Ni et al\\.,? 2017",
      "shortCiteRegEx" : "Ni et al\\.",
      "year" : 2017
    }, {
      "title" : "MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer",
      "author" : [ "Jonas Pfeiffer", "Ivan Vulić", "Iryna Gurevych", "Sebastian Ruder." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Pfeiffer et al\\.,? 2020",
      "shortCiteRegEx" : "Pfeiffer et al\\.",
      "year" : 2020
    }, {
      "title" : "Policy distillation",
      "author" : [ "Andrei A. Rusu", "Sergio Gomez Colmenarejo", "Çaglar Gülçehre", "Guillaume Desjardins", "James Kirkpatrick", "Razvan Pascanu", "Volodymyr Mnih", "Koray Kavukcuoglu", "Raia Hadsell." ],
      "venue" : "4th International Conference on",
      "citeRegEx" : "Rusu et al\\.,? 2016",
      "shortCiteRegEx" : "Rusu et al\\.",
      "year" : 2016
    }, {
      "title" : "Distilbert, a distilled version of BERT: smaller, faster, cheaper and lighter",
      "author" : [ "Victor Sanh", "Lysandre Debut", "Julien Chaumond", "Thomas Wolf." ],
      "venue" : "Proceedings of the NeurIPS Workshop on Energy Efficient Machine Learning and Cognitive Computing",
      "citeRegEx" : "Sanh et al\\.,? 2019",
      "shortCiteRegEx" : "Sanh et al\\.",
      "year" : 2019
    }, {
      "title" : "Cross-lingual word clusters for direct transfer of linguistic structure",
      "author" : [ "Oscar Täckström", "Ryan McDonald", "Jakob Uszkoreit." ],
      "venue" : "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguis-",
      "citeRegEx" : "Täckström et al\\.,? 2012",
      "shortCiteRegEx" : "Täckström et al\\.",
      "year" : 2012
    }, {
      "title" : "Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition",
      "author" : [ "Erik F. Tjong Kim Sang." ],
      "venue" : "COLING-02: The 6th Conference on Natural Language Learning 2002 (CoNLL-2002).",
      "citeRegEx" : "Sang.,? 2002a",
      "shortCiteRegEx" : "Sang.",
      "year" : 2002
    }, {
      "title" : "Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition",
      "author" : [ "Erik F. Tjong Kim Sang." ],
      "venue" : "COLING-02: The 6th Conference on Natural Language Learning 2002 (CoNLL-2002).",
      "citeRegEx" : "Sang.,? 2002b",
      "shortCiteRegEx" : "Sang.",
      "year" : 2002
    }, {
      "title" : "Cross-lingual named entity recognition via wikification",
      "author" : [ "Chen-Tse Tsai", "Stephen Mayhew", "Dan Roth." ],
      "venue" : "Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, pages 219–228, Berlin, Germany. Association",
      "citeRegEx" : "Tsai et al\\.,? 2016",
      "shortCiteRegEx" : "Tsai et al\\.",
      "year" : 2016
    }, {
      "title" : "Acquiring knowledge from pre-trained model to neural machine translation",
      "author" : [ "Rongxiang Weng", "Heng Yu", "Shujian Huang", "Shanbo Cheng", "Weihua Luo." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9266–",
      "citeRegEx" : "Weng et al\\.,? 2020",
      "shortCiteRegEx" : "Weng et al\\.",
      "year" : 2020
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander Rush." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    }, {
      "title" : "Unitrans: Unifying model transfer and data transfer for crosslingual named entity recognition with unlabeled data",
      "author" : [ "Qianhui Wu", "Zijia Lin", "Börje F. Karlsson", "Biqing Huang", "Jian-Guang Lou." ],
      "venue" : "Proceedings of the Twenty-Ninth Interna-",
      "citeRegEx" : "Wu et al\\.,? 2020a",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Enhanced meta-learning for cross-lingual named entity recognition with minimal resources",
      "author" : [ "Qianhui Wu", "Zijia Lin", "Guoxin Wang", "Hui Chen", "Börje F. Karlsson", "Biqing Huang", "Chin-Yew Lin." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial In-",
      "citeRegEx" : "Wu et al\\.,? 2020b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Beto, bentz, becas: The surprising cross-lingual effectiveness",
      "author" : [ "Shijie Wu", "Mark Dredze" ],
      "venue" : null,
      "citeRegEx" : "Wu and Dredze.,? \\Q2019\\E",
      "shortCiteRegEx" : "Wu and Dredze.",
      "year" : 2019
    }, {
      "title" : "Google’s neural machine translation system: Bridging the gap between human and machine",
      "author" : [ "Yonghui Wu", "Mike Schuster", "Zhifeng Chen", "Quoc V Le", "Mohammad Norouzi", "Wolfgang Macherey", "Maxim Krikun", "Yuan Cao", "Qin Gao", "Klaus Macherey" ],
      "venue" : null,
      "citeRegEx" : "Wu et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural crosslingual named entity recognition with minimal resources",
      "author" : [ "Jiateng Xie", "Zhilin Yang", "Graham Neubig", "Noah A. Smith", "Jaime Carbonell." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Xie et al\\.,? 2018",
      "shortCiteRegEx" : "Xie et al\\.",
      "year" : 2018
    }, {
      "title" : "Adversarial training for unsupervised bilingual lexicon induction",
      "author" : [ "Meng Zhang", "Yang Liu", "Huanbo Luan", "Maosong Sun." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
      "citeRegEx" : "Zhang et al\\.,? 2017",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2017
    }, {
      "title" : "Revisiting fewsample BERT fine-tuning",
      "author" : [ "Tianyi Zhang", "Felix Wu", "Arzoo Katiyar", "Kilian Q Weinberger", "Yoav Artzi." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "Dual adversarial neural transfer for low-resource named entity recognition",
      "author" : [ "Joey Tianyi Zhou", "Hao Zhang", "Di Jin", "Hongyuan Zhu", "Meng Fang", "Rick Siow Mong Goh", "Kenneth Kwok." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association",
      "citeRegEx" : "Zhou et al\\.,? 2019",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2019
    }, {
      "title" : "Crosslingual transfer of named entity recognizers without parallel corpora",
      "author" : [ "Ayah Zirikly", "Masato Hagiwara." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Confer-",
      "citeRegEx" : "Zirikly and Hagiwara.,? 2015",
      "shortCiteRegEx" : "Zirikly and Hagiwara.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "2020), which train a NER model to capture language-independent features of the labeled source-language data and then apply it to the target language; ii) translation-based methods (Mayhew et al., 2017; Xie et al., 2018), which build pseudo",
      "startOffset" : 180,
      "endOffset" : 219
    }, {
      "referenceID" : 32,
      "context" : "2020), which train a NER model to capture language-independent features of the labeled source-language data and then apply it to the target language; ii) translation-based methods (Mayhew et al., 2017; Xie et al., 2018), which build pseudo",
      "startOffset" : 180,
      "endOffset" : 219
    }, {
      "referenceID" : 22,
      "context" : "Feature-based methods generally use languageindependent features to train a NER model in the labeled source-language data, which include word clusters (Täckström et al., 2012), Wikifier features (Tsai et al.",
      "startOffset" : 151,
      "endOffset" : 175
    }, {
      "referenceID" : 25,
      "context" : ", 2012), Wikifier features (Tsai et al., 2016), gazetteers (Zirikly and Hagiwara, 2015), and aligned word representations (Ni et al.",
      "startOffset" : 27,
      "endOffset" : 46
    }, {
      "referenceID" : 36,
      "context" : ", 2016), gazetteers (Zirikly and Hagiwara, 2015), and aligned word representations (Ni et al.",
      "startOffset" : 20,
      "endOffset" : 48
    }, {
      "referenceID" : 18,
      "context" : ", 2016), gazetteers (Zirikly and Hagiwara, 2015), and aligned word representations (Ni et al., 2017; Wu and Dredze, 2019), etc.",
      "startOffset" : 83,
      "endOffset" : 121
    }, {
      "referenceID" : 30,
      "context" : ", 2016), gazetteers (Zirikly and Hagiwara, 2015), and aligned word representations (Ni et al., 2017; Wu and Dredze, 2019), etc.",
      "startOffset" : 83,
      "endOffset" : 121
    }, {
      "referenceID" : 9,
      "context" : "Moreover, for language-independent features, adversarial learning was applied on word/char embedding layers (Huang et al., 2019; Bari et al., 2020) or encoders (Zhou et al.",
      "startOffset" : 108,
      "endOffset" : 147
    }, {
      "referenceID" : 0,
      "context" : "Moreover, for language-independent features, adversarial learning was applied on word/char embedding layers (Huang et al., 2019; Bari et al., 2020) or encoders (Zhou et al.",
      "startOffset" : 108,
      "endOffset" : 147
    }, {
      "referenceID" : 32,
      "context" : "Most recent methods translate the annotated corpus in the source language to the target language word-byword (Xie et al., 2018) or phrase-by-phrase (Mayhew et al.",
      "startOffset" : 109,
      "endOffset" : 127
    }, {
      "referenceID" : 15,
      "context" : ", 2018) or phrase-by-phrase (Mayhew et al., 2017) and then copy the labels for each word/phrase to their translations.",
      "startOffset" : 28,
      "endOffset" : 49
    }, {
      "referenceID" : 10,
      "context" : "While (Jain et al., 2019) proposed to translate full sentences in the source language and project entity labels to targetlanguage sentences.",
      "startOffset" : 6,
      "endOffset" : 25
    }, {
      "referenceID" : 18,
      "context" : "pseudo-labeling methods generate the pseudolabels by annotation projection on comparable corpora (Ni et al., 2017) or via models trained on source-language labeled data (Wu et al.",
      "startOffset" : 97,
      "endOffset" : 114
    }, {
      "referenceID" : 28,
      "context" : ", 2017) or via models trained on source-language labeled data (Wu et al., 2020a).",
      "startOffset" : 62,
      "endOffset" : 80
    }, {
      "referenceID" : 33,
      "context" : "Language-adversarial training (Zhang et al., 2017) was proposed for the unsupervised bilingual lex-",
      "startOffset" : 30,
      "endOffset" : 50
    }, {
      "referenceID" : 35,
      "context" : "And it has been applied in inducing language-independent features for crosslingual tasks in NER (Zhou et al., 2019; Xie et al., 2018), text classification (Chen et al.",
      "startOffset" : 96,
      "endOffset" : 133
    }, {
      "referenceID" : 32,
      "context" : "And it has been applied in inducing language-independent features for crosslingual tasks in NER (Zhou et al., 2019; Xie et al., 2018), text classification (Chen et al.",
      "startOffset" : 96,
      "endOffset" : 133
    }, {
      "referenceID" : 3,
      "context" : ", 2018), text classification (Chen et al., 2019b), and sentiment classification (Chen et al.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 4,
      "context" : ", 2019b), and sentiment classification (Chen et al., 2018).",
      "startOffset" : 39,
      "endOffset" : 58
    }, {
      "referenceID" : 1,
      "context" : "Knowledge distillation was proposed to compress models (Buciluă et al., 2006) or ensembles of models (Rusu et al.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 8,
      "context" : "Besides model compression, knowledge distillation has also been applied to various tasks, like cross-modal learning (Hu et al., 2020), machine translation (Weng et al.",
      "startOffset" : 116,
      "endOffset" : 133
    }, {
      "referenceID" : 26,
      "context" : ", 2020), machine translation (Weng et al., 2020), and automated machine learning (Kang et al.",
      "startOffset" : 29,
      "endOffset" : 48
    }, {
      "referenceID" : 11,
      "context" : ", 2020), and automated machine learning (Kang et al., 2020).",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 7,
      "context" : "Considering a lot of helpful information can be carried in soft targets instead of hard targets (Hinton et al., 2015), we use",
      "startOffset" : 96,
      "endOffset" : 117
    }, {
      "referenceID" : 5,
      "context" : "To construct the student model, we used the pretrained cased multilingual BERT(mBERT) (Devlin et al., 2019) as the initialization and a linear layer",
      "startOffset" : 86,
      "endOffset" : 107
    }, {
      "referenceID" : 2,
      "context" : "To ensure the entity labels follow the NER tagging scheme, the prediction result is generated by Viterbi decoding (Chen et al., 2019a).",
      "startOffset" : 114,
      "endOffset" : 134
    }, {
      "referenceID" : 6,
      "context" : "Following Wu and Dredze (2019), we use the BIO labeling scheme (Farber et al., 2008) and the official split of train/validation/test sets.",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 22,
      "context" : "(Täckström et al., 2012; Jain et al., 2019; Wu et al., 2020b), for all experiments, we always use English as source language and the others as target languages.",
      "startOffset" : 0,
      "endOffset" : 61
    }, {
      "referenceID" : 10,
      "context" : "(Täckström et al., 2012; Jain et al., 2019; Wu et al., 2020b), for all experiments, we always use English as source language and the others as target languages.",
      "startOffset" : 0,
      "endOffset" : 61
    }, {
      "referenceID" : 29,
      "context" : "(Täckström et al., 2012; Jain et al., 2019; Wu et al., 2020b), for all experiments, we always use English as source language and the others as target languages.",
      "startOffset" : 0,
      "endOffset" : 61
    }, {
      "referenceID" : 31,
      "context" : "For data pre-processing, we leverage WordPiece (Wu et al., 2016) to tokenize each sentence into a sequence of sub-words which are then fed into the model.",
      "startOffset" : 47,
      "endOffset" : 64
    }, {
      "referenceID" : 2,
      "context" : "For sequence prediction, we apply Viterbi decoding (Chen et al., 2019a) on all models in our experiments.",
      "startOffset" : 51,
      "endOffset" : 71
    }, {
      "referenceID" : 28,
      "context" : "comparison, we compare against the version of UniTrans (Wu et al., 2020a) w/o translation (as reported in their paper).",
      "startOffset" : 55,
      "endOffset" : 73
    } ],
    "year" : 2021,
    "abstractText" : "Neural methods have been shown to achieve high performance in Named Entity Recognition (NER), but rely on costly high-quality labeled data for training, which is not always available across languages. While previous works have shown that unlabeled data in a target language can be used to improve crosslingual model performance, we propose a novel adversarial approach (AdvPicker) to better leverage such data and further improve results. We design an adversarial learning framework in which an encoder learns entity domain knowledge from labeled source-language data and better shared features are captured via adversarial training where a discriminator selects less language-dependent target-language data via similarity to the source language. Experimental results on standard benchmark datasets well demonstrate that the proposed method benefits strongly from this data selection process and outperforms existing state-ofthe-art methods; without requiring any additional external resources (e.g., gazetteers or via machine translation). 1",
    "creator" : "LaTeX with hyperref"
  }
}