{
  "name" : "2021.acl-long.407.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "A Knowledge-Guided Framework for Frame Identification",
    "authors" : [ "Xuefeng Su", "Ru Li", "Xiaoli Li", "Jeff Z.Pan", "Hu Zhang", "Qinghua Chai", "Xiaoqi Han" ],
    "emails" : [ "suexf@163.com,", "xiaoqisev@163.com,", "liru@sxu.edu.cn", "zhanghu@sxu.edu.cn", "charles@sxu.edu.cn", "xlli@ntu.edu.sg,", "j.z.pan@ed.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5230–5240\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n5230\nA Knowledge-Guided Framework for Frame Identification Xuefeng Su1,2, Ru Li1,3,∗, Xiaoli Li4, Jeff Z.Pan5, Hu Zhang1, Qinghua Chai1, Xiaoqi Han1\n1. School of Computer and Information Technology, Shanxi University, Taiyuan, China 2. School of E-commerce and Logistics, Shanxi Vocational University\nof Engineering Technology, Taiyuan, China 3. Key Laboratory of Computational Intelligence and Chinese Information\nProcessing of Ministry of Education, Shanxi University, Taiyuan, China 4. Institute for Infocomm Research, A*Star, Singapore\n5. ILCC, School of Informatics, University of Edinburgh, UK {suexf,xiaoqisev}@163.com, {liru,zhanghu,charles}@sxu.edu.cn\nxlli@ntu.edu.sg, j.z.pan@ed.ac.uk Abstract\nFrame Identification (FI) is a fundamental and challenging task in frame semantic parsing. The task aims to find the exact frame evoked by a target word in a given sentence. It is generally regarded as a classification task in existing work, where frames are treated as discrete labels or represented using one-hot embeddings. However, the valuable knowledge about frames is neglected. In this paper, we propose a Knowledge-Guided Frame Identification framework (KGFI) that integrates three types frame knowledge, including frame definitions, frame elements and frameto frame relations, to learn better frame representation, which guides the KGFI to jointly map target words and frames into the same embedding space and subsequently identify the best frame by calculating the dot-product similarity scores between the target word embedding and all of the frame embeddings. The extensive experimental results demonstrate KGFI significantly outperforms the state-of-theart methods on two benchmark datasets."
    }, {
      "heading" : "1 Introduction",
      "text" : "Frame Identification (FI) aims to find the exact frame evoked by a target word in a given sentence. A frame represents an event scenario, and possesses frame elements (or semantic roles) that participate in the event (Hermann et al., 2014), which is described in the FrameNet knowledge base (Baker et al., 1998; Ruppenhofer et al., 2016) grounded on the theory of Frame Semantics (Fillmore et al., 2002). The theory asserts that people understand the meaning of words largely by virtue of the frames which they evoke. In general, many words are polysemous and can evoke different frames in different contexts.\nAs shown in Figure 1, the word stopped evokes the frame Activity stop and the frame ∗Corresponding author.\nThe company stopped producing the profitable toy.\nActivity_stop stop.v\nAgent Activity Process_stop stop.v\nProcess Time The fighting has stopped for more than two years .\nFigure 1: Two annotated examples with the target word marked in bold and frame elements (semantic roles) in rounded rectangles. The target word stopped (stop.v denotes its form of lexical unit) evokes the frame Activity stop and the frame Process stop respectively in different contexts. Here, the key to distinguish these two frames is identifying whether the subject (The compony or The fighting) of stopped is an Agent or a Process (see the frame definitions in Table 1).\nProcess stop respectively in two sentences. It is a challenging task to distinguish the frames evoked by target words in sentences. Furthermore, FI is a key step before Frame Semantic Role Labeling (FSRL) (Das et al., 2010, 2014; Swayamdipta et al., 2017; Kalyanpur et al., 2020) which is widely used in event recognition (Liu et al., 2016), machine reading comprehension (Guo et al., 2020b,a), relation extraction (Zhao et al., 2020), etc. Through FI process, hundreds of role labels in FrameNet are reduced to a manageable small set (Hartmann et al., 2017), which can significantly improve the performance of FSRL models. Thus, FI is a fundamental and critical task in NLP.\nFI is typically regarded as a classification task, in which class labels are frame names. In earlier studies, researchers manually construct features and then use supervised learning methods to learn classification models (Bejan and Hathaway, 2007; Johansson and Nugues, 2007; Das et al., 2010, 2014). These methods, however, do not take the valuable semantic information about frames into considera-\ntion, and merely treat them as discrete labels. The recent studies of FI use distributed representations of target words and their syntactic context to construct features, and construct classification models with deep neural network (Hartmann et al., 2017; Kabbach et al., 2018). These methods usually transform frame labels into one-hot representations (Hermann et al., 2014; Täckström et al., 2015), and then learn the embeddings of target words and frames simultaneously. However, the abundant semantic information and structure knowledge of frames contained in FrameNet are still neglected.\nKnowledge of frames defined by linguists, such as frame definition, frame elements and frame-toframe relations, can enrich frame labels with rich semantic information that can potentially guide FI models to learn more unique and distinguishable representations. Thus, in this paper, we propose a Knowledge Guided Frame Identification framework (KGFI) which consists of a Bert-based context encoder and a frame encoder based on a specialized graph convolutional network (FrameGCN). In particular, the frame encoder incorporates multiple types of frame knowledge into frame representation which guides the KGFI to jointly map target words and frames into the same embedding space. Instead of predicting the frame label directly, KGFI chooses the best suitable frame evoked by the target word in a given sentence by calculating the dot-product similarity scores between the target word embedding and all of the frame embeddings. In summary, our contribution is threefold:\n• To the best of our knowledge, we are the †See the details in https://FN.icsi.berkeley.edu/fndrupal/\nfirst to propose a unified FI method which leverages heterogeneous frame knowledge for building rich frame representations.\n• We design a novel Framework KGFI, consisting of a Bert-based context encoder and a GCN-based frame encoder, which learns the model from a combination of annotated data and FrameNet knowledge base, and maps target words and frames into the same embedding space.\n• Extensive experimental results demonstrate our proposed KGFI framework outperforms the state-of-the-art models across two benchmark datasets."
    }, {
      "heading" : "2 FrameNet and FI Task Definition",
      "text" : ""
    }, {
      "heading" : "2.1 FrameNet",
      "text" : "FrameNet is built on the hypothesis that people understand things by performing mental operations on what they already know (Baker et al., 1998). Such knowledge reflecting people’s cognitive experience is described as structured information packets called frames. A frame represents an event scenario, associated with a set of semantic roles (frame elements (FEs)). Lexical units (LUs) are capable of evoking the scenario (Kshirsagar et al., 2015). Frame elements in terms of how central they are to a particular frame can be divided into three distinguishing levels: core, peripheral and extra-thematic. Each frame has a textual definition (Def), depicting the scenario and how the roles interact in the scenario. Frames are organized as a network with several kinds of frame-to-frame relations (FRs).\nTable 1 shows the structure of frame Activity stop and frame Process stop in FrameNet."
    }, {
      "heading" : "2.2 FI Task Definition",
      "text" : "Frame Identification (FI) is the task of predicting a frame evoked by the target word in a sentence. Let c=w0,w1,...,wst ,...,wen,...,wn denote a given sentence, and t=wst ,...,wen (t ⊂ c) represent the target word, where st and en are the start and end index respectively for the target word t in the sentence. Let F = ( f1, f2, ..., f|F |) denote the set of all frames in FrameNet. The FI model is defined as a mapping function G : (c, t,st,en)→ f j, subject to f j ∈ F ."
    }, {
      "heading" : "3 Methodology",
      "text" : "Table 1 illustrates the structured knowledge (Def, FEs, LUs) of two different frames and their frameto-frame relations (FRs). We explicitly leverage them to enrich the frame embeddings with semantic information. The resulted informative frame representations serve two purposes: 1) guide our model to learn more distinguishable embeddings of target words, and 2) improve FI model’s generalization performance in the prediction phase.\nThe proposed KGFI framework consists of three components: context encoder, frame encoder and scoring module, as shown in Figure 2. Specifically, context encoder is used to represent the context-aware target word into an embedding with a Bert-based module, and frame encoder is used to incorporate three types of knowledge about a frame into frame embeddings. With the guidance of the knowledge about frames, two encoders jointly learn the embeddings of target words and frames. Finally, a scoring module is used to calculate the similarity scores between the given target word embedding and all frames’ embeddings, to identify the best frame with the highest score."
    }, {
      "heading" : "3.1 Context Encoder",
      "text" : "To get the context-aware embeddings of target words, we employ Bert (Devlin et al., 2019) for our context encoder, since its architecture is a multilayer bidirectional Transformer which can aggregate information from context into the target word through the self-attention mechanism. As we know, Bert model is pre-trained on a large corpus and can transfer language knowledge into the context encoder, which is very helpful for the target word representation as the manually labeled training data of FI is very small.\nThe context encoder, which we define as Ec, takes given sentence c containing a target word t as input. We denote the last layer of Bert’s output as Ht . The context encoder can be expressed as :\nrt = Ec(c, t,st,en) =W Tc ht +bc (1)\nwhere\nht = 1\nen+1− st\nen\n∑ i=st (Ht [i]), (2)\nWc ∈ Rn×mand bc ∈ Rm are learned parameters."
    }, {
      "heading" : "3.2 Frame Encoder",
      "text" : "In FrameNet, all the frames are connected into a directed graph through the frame-to-frame relations, as shown in Figure 3. Moreover, the graph convolutional network(GCN) (Kipf and Welling, 2017) has been proved to be effective to model the relationship between labels (Yan et al., 2019; Chen et al., 2019; Cheng et al., 2020; Linmei et al., 2019), and it can enrich the representation of the node through aggregating information from its neighbors. In order to make better use of frame knowledge and the advantage of GCN, we propose a specialized GCN, called FrameGCN, to incorporate multiple frame knowledge into frame representations."
    }, {
      "heading" : "3.2.1 Structure of FrameGCN",
      "text" : "FrameGCN is a combination of two dedicated GCNs (FEsGCN and DefGCN) and an attention network, as shown in Figure 2. FEsGCN is used to represent frame by aggregating the FEs features of its neighbors, while DefGCN is used to represent frame by aggregating the Def features of its neighbors. The attention network is responsible for incorporating the outputs of two GCNs into one unified embedding where adjacent matrix A is shared by the two dedicated GCNs.\nFrame-to-frame relation in FrameNet is a asymmetric relation between two frames, where one frame is called super-frame and the other is called sub-frame, as shown in Figure 3. A frame typically obtains/inherits more information from its super-frame than from its sub-frame. Therefore, we define the adjacent matrix of the graph as a weighted asymmetric matrix denoted as A = (ai j)|F |×|F |, where\nai j =  3, f j = fi 2, f j is a super− f rame o f fi 1, f j is a sub− f rame o f fi 0, other . (3)\nThree types of frame-to-frames relations, including Inherits, Using and Subframe, are used in this study."
    }, {
      "heading" : "3.2.2 FEsGCN",
      "text" : "The FEs of a frame express its semantic roles and structure. Frames which have similar structures imply that they have close semantic, so we regard FEs as features and use them to represent frames. Let FE = (e1,e2, ...,e|FE|) denote\nthe set of all frame elements in FrameNet, and Ve ∈ R|F |×|FE| denote the feature matrix of frames represented by FEs. The ith row of Ve is the feature vector of ith frame fi, and can be expressed as Ve[i, :] = (ve1,ve2, ...,ve|FE|), where\nve j = { 1, e j ∈ FE fi 0, other , (4)\nFE fi ⊂ FE is the FEs of frame fi. FEsGCN is used to learn a map function which maps the node (frame) vectors represented by FEs to a new representation via convolutional operation defined by A. We take a two-layer GCN to implement the map function, which can be expressed as:\ng(0)e (A,Ve) = ReLU(AVeW (0) e ),\ng(1)e (A,Ve) = Tanh(Ag (0) e (A,Ve)W (1) e ).\n(5)\nHere, W (0)e ∈ R|FE|×h is an input-to-hidden weight matrix for the hidden layer and W (1)e ∈ Rh×m is a hidden-to-output weight matrix."
    }, {
      "heading" : "3.2.3 DefGCN",
      "text" : "Since the frame definition is a short text that depicts an event scenario and frame elements that participate in the event, we employ Bert as a feature extractor to construct the feature matrix Vd of frames. Specifically, we first input a frame definition into Bert, and subsequently take the first token’s representation (corresponding to the input [CLS] token) in Bert’s last layer as the feature vector of the frame. Since the name of a frame is also meaningful, we concatenate the frame name and frame definition into one string, e.g. Activity stop: an agent ceases an activity without completing it.\nDefGCN is used to learn a map function which maps the node (frame) vectors represented by definition to a new representation via convolutional operation defined by A. We use a network similar to FEsGCN, which can be expressed as:\ng(0)d (A,Vd) = ReLU(AVdW (0) d ), g(1)d (A,Vd) = Tanh(Ag (0) d (A,Vd)W (1) d ).\n(6)\nHere, W (0)d ∈ Rn×h is an input-to-hidden weight matrix for a hidden layer with h feature maps, and W (1)e ∈ Rh×m is a hidden-to-output weight matrix."
    }, {
      "heading" : "3.2.4 Attentive Graph Combination",
      "text" : "We use an attention network to dynamic incorporate the outputs of FEsGCN and DefGCN into one frame embedding through the attention weighting\nmechanism. The incorporation operation takes the following function:\nr fi = ∑ k∈{e,d} ai,kg (1) k (A,Vk)i (7)\nwhere r fi ∈ Rm is the embedding of ith frame, g(1)k (A,Vk)i is the ith row of convolved representation of graph k, and ai,k is a weight of ith frame against the graph k, which is computed as:\nai,k = exp(wag\n(1) k (A,Vk)i)\n∑k′∈{e,d} exp(wag (1) k′ (A,Vk′)i)\n(8)\nwhere wa ∈ Rmis a learnable vector."
    }, {
      "heading" : "3.3 Scoring and Prediction",
      "text" : "After obtaining the embeddings of target words and frames through context encoder and frame encoder respectively, we score a target word t with each frame f j ∈ F by computing the dot product similarity between rt and each r f for f j ∈ F :\nS(rt ,r f j) = rt .r f j , j = 1,2, ..., |F | (9)\nDuring training, all model parameters are jointly learned by minimizing a cross-entropy loss:\nL(θ) =− 1 |D|\n|D| ∑ i |F | ∑ j yi jlog(ŷi j) (10)\nwhere D is the number of the training data, |F | is the total number of frames in FrameNet, yi j (onehot representation of frame labels) and ŷi j are true labels. The predicted probability over frames is calculated by the softmax function over the scores.\nDuring prediction, we predict the frame evoked by the target word t to be f j ∈ F , whose representation r f j has the highest score with rt . The prediction function is defined as:\nf̂ = argmax f j∈FS(rt ,r f j) (11)\nNote most of the frames contain a set of lexical units (LUs) in the form of lemma.POS (e.g. stop.v). As shown in Table 1, the LUs of the frame Activity stop and the frame Process stop are listed in the fourth row. Therefore, we adopt the lexicon filtering operation to reduce the possible candidate frame set. Firstly, we utilize lemmatization and POS tools to convert the target word t into the form of LU (e.g. stop.v). Secondly, we use this LU to match the frames whose LUs contains this LU, and then use the matched frames as the possible candidate frame set Ft for the target word t. At last, we predict the frame label by the following function:\nf̂ = argmax f j∈Ft S(rt ,r f j) (12)\nIn the light of the coverage issue of FrameNet (see Section 4.4), these two prediction functions (11 and 12) can be used in different circumstances. In general, we can first use LU to obtain candidate frame set Ft by performing lexicon filtering and then use function 12 to identify best frame from Ft . However, if we can not find any candidate frame using LUs, i.e. Ft = /0, then we have to identify best frame from F using function 11. Note that Ft only contains a couple of candidate frames, while F contains more than one thousand of frames. This requires FI models have very good generalization performance to handle a big F set."
    }, {
      "heading" : "4 Experimental Settings",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We have employed two knowledge bases, i.e. FrameNet1.5 and FrameNet1.7. Both of them contain various documents which have been annotated manually, including target words and corresponding evoked frames. Documents and corresponding annotations in FrameNet1.7 are extended from FrameNet 1.5 and thus are more complete. Note train, dev and test documents in both data have been partitioned following (Swayamdipta et al., 2017). Given a sentence in documents may contain multiple target words, we regard it as multiple pairs of target word and sentence in train, dev and test sets. The statistics of two datasets are illustrated in Table 2.\nTo test the model’s performance on the more challenging ambiguous data, following the previous studies, we constructed a specialized dataset by extracting pairs of target word and annotated sentence from test data, in which the target words are polysemous or can evoke multiple frames."
    }, {
      "heading" : "4.2 Baselines",
      "text" : "We first compare the KGFI against five existing models. Semafor (Das et al., 2014) is a conditional log-linear model which uses statistical features about target word to predict the frame label. Hermann-14 (Hermann et al., 2014) is a\njoint learning model which maps frame labels and the dependency path of target word into a common embedding space. SimpleFrameId (Hartmann et al., 2017) models a classifier based on the embeddings of entire words in the sentence. OpenSesame (Swayamdipta et al., 2017) models a classifier based on bi-directional LSTM. Hermann14 converts frame labels into onehot embeddings, while other models treat frame labels as discrete supervision signals. Peng’s model (Peng et al., 2018) is a joint learning model for FI and FSRL, which both uses exemplars in FrameNet knowledge base and the full-text annotation training data to train the model.\nIn addition, we also implemented two additional Bert-based baselines for fair comparison. One is called Bert-cls that uses Bert to represent the target word in a sentence and treats discrete frame labels as supervision signals. The other is called Bertonehot, which also uses the dual-encoder architecture (Context encoder and frame encoder) and maps target words and frames into a common embedding space. The difference between KGFI and Bert-onehot is that KGFI uses GCN-based modules to incorporate frame knowledge into frame embeddings, while Bert-onehot uses a linear network to map onehot vector of frame labels into frame embeddings without incorporating knowledge. Clearly, we will test if the knowledge plays a significant role for better frame embeddings and subsequent FI task."
    }, {
      "heading" : "4.3 Parameter Settings",
      "text" : "All Bert modules in KGFI were initialized with Bert-base. We set both the dimensions of target word embedding rt and frame embedding r f to 128 (m=128), the hidden layer size of FEsGCN and DefGCN to 256 (h=256). The size of Bert embedding is n=768. The dimensions of FEs and FRs feature vectors are related to FrameNet version (see Table 2). For optimization, we use BertAdam optimizer and set learning rate to 5e− 5. As for parameter tuning, our parameters are tuned using the development set with the early stop strategy."
    }, {
      "heading" : "4.4 Test Settings",
      "text" : "FrameNet has a few coverage issues in that: (1) the LUs set is incomplete for some frames; (2) many words that should evoke frames are not included in LUs set of frames. Thus, we design two types of test settings: test without lexicon filtering, or test\nthat does not use LUs (use Fun 11) and test with lexicon filtering, or test that uses LUs (use Fun 12)."
    }, {
      "heading" : "5 Evaluation",
      "text" : ""
    }, {
      "heading" : "5.1 Overall Results",
      "text" : "The overall testing results, as shown in Table 3, demonstrate that Bert-cls and Bert-onehot are two strong baselines, outperforming all of the prior work that does not incorporate pre-training modules into their systems. Bert-onehot slightly outperforms Bert-cls in all of the testing settings, indicating joint learning target word embedding and frame embedding is helpful for FI task.\nOur best KGFI models, including KGFI (2- layers) for FrameNet1.7 and KEFI (1-layer) for FrameNet1.5, outperform all the baseline models of FI in terms of accuracy. Compared with the stronger Bert-onehot model, our model achieves absolute 1.83% and 0.67% improvements on two datasets respectively in All test setting. With the help of lexicon filtering with LUs in FrameNet, the model predicts the exact frame evoked by the target word among a small set of candidate frames. Clearly, the improvements are credited to the model’s performance improvement in predicting frames for ambiguous target words, since the model achieves absolute 3.75% and 1.56% improvements in Amb test setting on two datasets respectively.\nTo the best of our knowledge, few previous work focus on frame prediction without lexicon filtering\nexcept for SimpleFrameId model, so we choose SimpleFrameId and the stronger Bert-onehot model as our baseline to compare our best model’s performance under no-lexicon filter setting. As shown in Table 4, in comparison with the stronger Bert-onehot model, our model achieves absolute 5.72% and 3.63% improvements on two datasets respectively in all setting (without using LUs and compared with more than 1000 frames), signifying the generalization performance of our model achieves significant improvement, considering that the model predicts the exact frame evoked by the target word among all the frames without knowing the possible candidate frames of the target word in no-lexicon filtering setting.\nTo further test the performance of our best KGFI model, we use the top-K accuracy to measure the model performance without lexicon filtering. The higher top-K accuracy indicates that the model has learned better frame representations. Furthermore, the model can reduce the candidate frame set into a small frame subset (containing K most possible frames), which is useful for the downstream tasks, such as LUs induction for FrameNet, FSRL, etc. As shown in Table 5, compared with Bert-onehot baseline, our best KGFI model achieves higher top-K (K=1,2,3,5) accuracy, which further demonstrates the model has learned the better frame representation through incorporating the frame knowledge.\nConsidering FrameNet1.5 dataset is relatively small, the performance of simple structure model (using 1-layer GCN) achieves the best performance, while the performance of the model using 2-layers GCN drops slightly. In general, no matter how many layers are adopted, our models outperform all the baselines and achieve the best performance on two datasets in all settings consistently."
    }, {
      "heading" : "5.2 Ablation Studies",
      "text" : "To test the function of each component in KGFI, we conduct the ablation study. As shown in Table 6, the results demonstrate that all of the three components, i.e. DefGCN, FEsGCN and attention network, are helpful for enhancing the model’s performance. Even with DefGCN or FEsGCN individually, the performance of our model is still better than the stronger baseline Bert-onehot, which indicates the frame definition, FEs and FRs are all useful knowledge for frame representation, and our proposed GCN-based model architecture is effective to incorporate them into the informative embeddings. Compared with frame definition, FEs are more useful for frame representation, since the performance of GKFI (with FEsGCN) outperforms KGFI (with DefGCN), although it slightly lags behind KGFI full model (with FrameGCN). Note that the attention module is removed when DefGCN or FEsGCN is used as the frame encoder.\nAs for the attention module, the performance of KGFI (with FrameGCN) drops when we replace it with a simple addition operation, suggesting it is necessary to use attention mechanism to integrate the outputs of DefGCN and FEsGCN."
    }, {
      "heading" : "5.3 Weighting Method for Adjacent Matrix",
      "text" : "To test the rationality of our proposed weighting method for adjacent matrix A, we conduct a set of\ncomparison experiments, in which the weighted matrix is replaced with a binary matrix. Binary matrix is widely used approach to express the relations between nodes in graph modeling. Our weighting method expresses the hierarchy relationships between frames straightforwardly. The results demonstrate that the weighted method has significant impact on the model’s performance, and our proposed weighting method for adjacent matrix is quite reasonable, since the performance of all the models using weighted matrix outperforms their counterparts using binary matrix, shown in Table 7."
    }, {
      "heading" : "5.4 Case Studies",
      "text" : "Figure 4 shows that KGFI (w/FEsGCN) model tends to predict correct frame by finding the semantic relatedness between FEs and the context of target word. For instance, in sentence 1), the target word stopped may evoke Activity stop or Process stop, and the phrase the fighting is the key to distinguish two frames evoked by the word stopped, since these two frames differ in that the subject of stopped is an Agent or a Process. Our KGFI(w/FEsGCN) model has learned the semantic relation between the fighting phrase and FE Process, and outputs the correct frame, since FE Agent is related to an entity in general. The Bertonehot model can’t grasp this relation, so it outputs a wrong prediction Activity stop. On the other hand, the KGFI(w/ DefGCN) model tends to predict the frame with the semantic similarities between frame definition and the sentence. For instance, in sentence 2), the word Traversing in definition is similar to phrase passed through, so the model outputs the correct frame Traversing.\nIn sentence 3), the KGFI(w/ DefGCN) model outputs a wrong prediction Quitting a place due\n1) The fighting has stopped for more than two years . FEs of Process_stop : (Process,..) FEs of Activity_stop: (Agent,...)\nA. Activity_stop, B.Process_stop, C.Process_stop, D. Process_stop\n×\nto the similar meaning of the word depart in the sentence and the word leaves in the frame definition (Quitting a place: a Self mover leaves an initial Source location.). The KGFI(w/ FEsGCN) model, on the other hand, has learned that the word Ferries in the sentence is more closely related to FE Theme of frame Departing (Departing: a Theme moves away from a Source.) rather than FE self mover of frame Quitting a place, and outputs the correct frame Departing, since the self mover generally refers to a living object (e.g. a person, an animal). Note that the frame Departing is inherited by the frame Quitting a place, so they have nearly the same FEs set except for FE Theme and FE self mover. In other words, our KGFI(w/ DefGCN) and KGFI(w/ FEsGCN) are complementary to each other to some extent. KGFI(w/ FEsGCN) can capture the subtle differences between different frames, even if the frames have close frame-toframe or semantic relations.\nThe case studies show that KGFI models can incorporate frame knowledge into its representations and guide the context encoder to learn the semantic relations between frames and the context-aware representations of target words and frames through joint learning."
    }, {
      "heading" : "6 Related work",
      "text" : "Researchers have made great effort to tackle the FI problem since it has been proposed in the Semeval2007 (Baker et al., 2007). It is generally regarded as a classification task. The best system (Johansson and Nugues, 2007) in the SemEval-2007 adopted SVM to learn the classifier to identify frames with a set of features, such as target lemma, target word, and so on. SEMAFOR (Das et al., 2014) uti-\nlized a conditional model that shares features and weights across all targets, frames, and prototypes. These approaches use manually designed features and traditional machine learning methods to learn the classification models, while the class labels as supervision signals are discrete frame names.\nRecently, distributed feature representation and models based on neural network are used to tackle FI. According to the model architecture, there are two trends of work. One is joint learning approach that converts the discrete frame labels into continuous embedding by learning the embeddings of target words and frames simultaneously. For instance, Hermann-14 (Hermann et al., 2014) implemented a model that jointly maps possible frame labels and the syntax context of target words into the same latent space using the WSABIE algorithm, and the syntax context was initialized with concatenating their word embeddings. SimpleFrameId (Hartmann et al., 2017) useed the concatenation of SentBOW (the average of embeddings of all the words in the sentence) to represent the context and then learns the common embedding space of context and frame labels following the line of (Hermann et al., 2014). The other trend is to construct the classifier model using deep neural network and regard discrete frame labels as supervision signals, which is similar to those earlier work. Open-Sesame (Swayamdipta et al., 2017) used a bidirectional LSTM to construct the FI classifier. Peng (Peng et al., 2018) proposed a joint learning model for FI and FSRL, which adopted a multitask model structure.\nDifferent from previous studies, this paper focuses on how to represent frames by incorporating frame knowledge into frame representations and enriching frame labels with semantic information."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this work, we propose a novel idea that leverages frame knowledge, including frame definition, frame elements and frame-to-frame relations, to improve the model performance of FI task. Our proposed KGFI framework mainly consists of a Bertbased context encoder and a GCN-based frame encoder which can effectively incorporate multiple types of frame knowledge in a unified framework and jointly map frames and target words into the same semantic space. Extensive experimental results demonstrate that all kinds of knowledge about frames are useful for enriching the representation of frames, and the better frame representation is\nhelpful for FI task. The experimental results also show that the proposed model achieves significantly better performance than seven state-of-the-art models across two benchmark datasets."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank the anonymous reviewers for their helpful comments and suggestions. This work was supported by the National Natural Science Foundation of China (No.61936012, No.61772324) and the Open Project Foundation of Intelligent Information Processing Key Laboratory of Shanxi Province (No. CICIP2018007)."
    } ],
    "references" : [ {
      "title" : "Semeval-2007 task 19: Frame semantic structure extraction",
      "author" : [ "Collin F. Baker", "Michael Ellsworth", "Katrin Erk." ],
      "venue" : "Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval@ACL 2007, Prague, Czech Republic, June",
      "citeRegEx" : "Baker et al\\.,? 2007",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 2007
    }, {
      "title" : "The berkeley framenet project",
      "author" : [ "Collin F. Baker", "Charles J. Fillmore", "John B. Lowe." ],
      "venue" : "36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, COLING-ACL ’98, Au-",
      "citeRegEx" : "Baker et al\\.,? 1998",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 1998
    }, {
      "title" : "UTD-SRL: A pipeline architecture for extracting frame semantic structures",
      "author" : [ "Cosmin Adrian Bejan", "Chris Hathaway." ],
      "venue" : "Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval@ACL 2007, Prague, Czech Republic,",
      "citeRegEx" : "Bejan and Hathaway.,? 2007",
      "shortCiteRegEx" : "Bejan and Hathaway.",
      "year" : 2007
    }, {
      "title" : "Multi-label image recognition with graph convolutional networks",
      "author" : [ "Zhao-Min Chen", "Xiu-Shen Wei", "Peng Wang", "Yanwen Guo." ],
      "venue" : "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "SpellGCN: Incorporating phonological and visual similarities into language models for Chinese spelling check",
      "author" : [ "Xingyi Cheng", "Weidi Xu", "Kunlong Chen", "Shaohua Jiang", "Feng Wang", "Taifeng Wang", "Wei Chu", "Yuan Qi." ],
      "venue" : "Proceedings of the 58th",
      "citeRegEx" : "Cheng et al\\.,? 2020",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 2020
    }, {
      "title" : "Framesemantic parsing",
      "author" : [ "Dipanjan Das", "Desai Chen", "André F.T. Martins", "Nathan Schneider", "Noah A. Smith." ],
      "venue" : "Comput. Linguistics, 40(1):9–56.",
      "citeRegEx" : "Das et al\\.,? 2014",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2014
    }, {
      "title" : "Probabilistic frame-semantic parsing",
      "author" : [ "Dipanjan Das", "Nathan Schneider", "Desai Chen", "Noah A. Smith." ],
      "venue" : "Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings,",
      "citeRegEx" : "Das et al\\.,? 2010",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2010
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "The framenet database and software tools",
      "author" : [ "Charles J. Fillmore", "Collin F. Baker", "Hiroaki Sato." ],
      "venue" : "Proceedings of the Third International Conference on Language Resources and Evaluation, LREC 2002, May 29-31, 2002, Las Palmas, Canary Islands,",
      "citeRegEx" : "Fillmore et al\\.,? 2002",
      "shortCiteRegEx" : "Fillmore et al\\.",
      "year" : 2002
    }, {
      "title" : "Incorporating syntax and frame semantics in neural network for machine reading comprehension",
      "author" : [ "Shaoru Guo", "Yong Guan", "Ru Li", "Xiaoli Li", "Hongye Tan." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages",
      "citeRegEx" : "Guo et al\\.,? 2020a",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2020
    }, {
      "title" : "A frame-based sentence representation for machine reading comprehension",
      "author" : [ "Shaoru Guo", "Ru Li", "Hongye Tan", "Xiaoli Li", "Yong Guan", "Hongyan Zhao", "Yueping Zhang." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computation-",
      "citeRegEx" : "Guo et al\\.,? 2020b",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2020
    }, {
      "title" : "Out-of-domain framenet semantic role labeling",
      "author" : [ "Silvana Hartmann", "Ilia Kuznetsov", "Teresa Martin", "Iryna Gurevych." ],
      "venue" : "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017, Va-",
      "citeRegEx" : "Hartmann et al\\.,? 2017",
      "shortCiteRegEx" : "Hartmann et al\\.",
      "year" : 2017
    }, {
      "title" : "Volume 1: Long Papers, pages 471–482",
      "author" : [ "lencia", "Spain", "April" ],
      "venue" : "Association for Computational Linguistics",
      "citeRegEx" : "lencia et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "lencia et al\\.",
      "year" : 2017
    }, {
      "title" : "Semantic frame identification with distributed word representations",
      "author" : [ "Karl Moritz Hermann", "Dipanjan Das", "Jason Weston", "Kuzman Ganchev." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014,",
      "citeRegEx" : "Hermann et al\\.,? 2014",
      "shortCiteRegEx" : "Hermann et al\\.",
      "year" : 2014
    }, {
      "title" : "LTH: semantic structure extraction using nonprojective dependency trees",
      "author" : [ "Richard Johansson", "Pierre Nugues." ],
      "venue" : "Proceedings of the 4th Inter-",
      "citeRegEx" : "Johansson and Nugues.,? 2007",
      "shortCiteRegEx" : "Johansson and Nugues.",
      "year" : 2007
    }, {
      "title" : "Butterfly effects in frame semantic parsing: impact of data processing on model ranking",
      "author" : [ "Alexandre Kabbach", "Corentin Ribeyre", "Aurélie Herbelot." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018, San-",
      "citeRegEx" : "Kabbach et al\\.,? 2018",
      "shortCiteRegEx" : "Kabbach et al\\.",
      "year" : 2018
    }, {
      "title" : "Open-domain frame semantic parsing using transformers",
      "author" : [ "Aditya Kalyanpur", "Or Biran", "Tom Breloff", "Jennifer Chu-Carroll", "Ariel Diertani", "Owen Rambow", "Mark Sammons." ],
      "venue" : "CoRR, abs/2010.10998.",
      "citeRegEx" : "Kalyanpur et al\\.,? 2020",
      "shortCiteRegEx" : "Kalyanpur et al\\.",
      "year" : 2020
    }, {
      "title" : "Semi-supervised classification with graph convolutional networks",
      "author" : [ "Thomas Kipf", "M. Welling." ],
      "venue" : "ArXiv, abs/1609.02907.",
      "citeRegEx" : "Kipf and Welling.,? 2017",
      "shortCiteRegEx" : "Kipf and Welling.",
      "year" : 2017
    }, {
      "title" : "Frame-semantic role labeling with heterogeneous annotations",
      "author" : [ "Meghana Kshirsagar", "Sam Thomson", "Nathan Schneider", "Jaime G. Carbonell", "Noah A. Smith", "Chris Dyer." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computation-",
      "citeRegEx" : "Kshirsagar et al\\.,? 2015",
      "shortCiteRegEx" : "Kshirsagar et al\\.",
      "year" : 2015
    }, {
      "title" : "Heterogeneous graph attention networks for semi-supervised short text classification",
      "author" : [ "Hu Linmei", "Tianchi Yang", "Chuan Shi", "Houye Ji", "Xiaoli Li." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
      "citeRegEx" : "Linmei et al\\.,? 2019",
      "shortCiteRegEx" : "Linmei et al\\.",
      "year" : 2019
    }, {
      "title" : "Leveraging framenet to improve automatic event detection",
      "author" : [ "Shulin Liu", "Yubo Chen", "Shizhu He", "Kang Liu", "Jun Zhao." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin,",
      "citeRegEx" : "Liu et al\\.,? 2016",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning joint semantic parsers from disjoint data",
      "author" : [ "Hao Peng", "Sam Thomson", "Swabha Swayamdipta", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
      "citeRegEx" : "Peng et al\\.,? 2018",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2018
    }, {
      "title" : "Frame-semantic parsing with softmax-margin segmental rnns and a syntactic scaffold",
      "author" : [ "Swabha Swayamdipta", "Sam Thomson", "Chris Dyer", "Noah A. Smith." ],
      "venue" : "CoRR, abs/1706.09528.",
      "citeRegEx" : "Swayamdipta et al\\.,? 2017",
      "shortCiteRegEx" : "Swayamdipta et al\\.",
      "year" : 2017
    }, {
      "title" : "Efficient inference and structured learning for semantic role labeling",
      "author" : [ "Oscar Täckström", "Kuzman Ganchev", "Dipanjan Das." ],
      "venue" : "Trans. Assoc. Comput. Linguistics, 3:29–41.",
      "citeRegEx" : "Täckström et al\\.,? 2015",
      "shortCiteRegEx" : "Täckström et al\\.",
      "year" : 2015
    }, {
      "title" : "Event detection with multi-order graph convolution and aggregated attention",
      "author" : [ "Haoran Yan", "Xiaolong Jin", "Xiangbin Meng", "Jiafeng Guo", "Xueqi Cheng." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Yan et al\\.,? 2019",
      "shortCiteRegEx" : "Yan et al\\.",
      "year" : 2019
    }, {
      "title" : "CFSRE: context-aware based on framesemantics for distantly supervised relation extraction",
      "author" : [ "Hongyan Zhao", "Ru Li", "Xiaoli Li", "Hongye Tan." ],
      "venue" : "Knowl. Based Syst., 210:106480.",
      "citeRegEx" : "Zhao et al\\.,? 2020",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "A frame represents an event scenario, and possesses frame elements (or semantic roles) that participate in the event (Hermann et al., 2014), which is described in the FrameNet knowledge base (Baker et al.",
      "startOffset" : 117,
      "endOffset" : 139
    }, {
      "referenceID" : 1,
      "context" : ", 2014), which is described in the FrameNet knowledge base (Baker et al., 1998; Ruppenhofer et al., 2016) grounded on the theory of Frame Semantics (Fillmore et al.",
      "startOffset" : 59,
      "endOffset" : 105
    }, {
      "referenceID" : 8,
      "context" : ", 2016) grounded on the theory of Frame Semantics (Fillmore et al., 2002).",
      "startOffset" : 50,
      "endOffset" : 73
    }, {
      "referenceID" : 22,
      "context" : "Furthermore, FI is a key step before Frame Semantic Role Labeling (FSRL) (Das et al., 2010, 2014; Swayamdipta et al., 2017; Kalyanpur et al., 2020) which is widely used in event recognition (Liu et al.",
      "startOffset" : 73,
      "endOffset" : 147
    }, {
      "referenceID" : 16,
      "context" : "Furthermore, FI is a key step before Frame Semantic Role Labeling (FSRL) (Das et al., 2010, 2014; Swayamdipta et al., 2017; Kalyanpur et al., 2020) which is widely used in event recognition (Liu et al.",
      "startOffset" : 73,
      "endOffset" : 147
    }, {
      "referenceID" : 20,
      "context" : ", 2020) which is widely used in event recognition (Liu et al., 2016), machine reading comprehension (Guo et al.",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 25,
      "context" : ", 2020b,a), relation extraction (Zhao et al., 2020), etc.",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 11,
      "context" : "Through FI process, hundreds of role labels in FrameNet are reduced to a manageable small set (Hartmann et al., 2017), which can significantly improve the performance of FSRL models.",
      "startOffset" : 94,
      "endOffset" : 117
    }, {
      "referenceID" : 2,
      "context" : "In earlier studies, researchers manually construct features and then use supervised learning methods to learn classification models (Bejan and Hathaway, 2007; Johansson and Nugues, 2007; Das et al., 2010, 2014).",
      "startOffset" : 132,
      "endOffset" : 210
    }, {
      "referenceID" : 14,
      "context" : "In earlier studies, researchers manually construct features and then use supervised learning methods to learn classification models (Bejan and Hathaway, 2007; Johansson and Nugues, 2007; Das et al., 2010, 2014).",
      "startOffset" : 132,
      "endOffset" : 210
    }, {
      "referenceID" : 11,
      "context" : "The recent studies of FI use distributed representations of target words and their syntactic context to construct features, and construct classification models with deep neural network (Hartmann et al., 2017; Kabbach et al., 2018).",
      "startOffset" : 185,
      "endOffset" : 230
    }, {
      "referenceID" : 15,
      "context" : "The recent studies of FI use distributed representations of target words and their syntactic context to construct features, and construct classification models with deep neural network (Hartmann et al., 2017; Kabbach et al., 2018).",
      "startOffset" : 185,
      "endOffset" : 230
    }, {
      "referenceID" : 13,
      "context" : "These methods usually transform frame labels into one-hot representations (Hermann et al., 2014; Täckström et al., 2015), and then learn the embeddings of target words and frames simultaneously.",
      "startOffset" : 74,
      "endOffset" : 120
    }, {
      "referenceID" : 23,
      "context" : "These methods usually transform frame labels into one-hot representations (Hermann et al., 2014; Täckström et al., 2015), and then learn the embeddings of target words and frames simultaneously.",
      "startOffset" : 74,
      "endOffset" : 120
    }, {
      "referenceID" : 1,
      "context" : "FrameNet is built on the hypothesis that people understand things by performing mental operations on what they already know (Baker et al., 1998).",
      "startOffset" : 124,
      "endOffset" : 144
    }, {
      "referenceID" : 18,
      "context" : "Lexical units (LUs) are capable of evoking the scenario (Kshirsagar et al., 2015).",
      "startOffset" : 56,
      "endOffset" : 81
    }, {
      "referenceID" : 7,
      "context" : "words, we employ Bert (Devlin et al., 2019) for our context encoder, since its architecture is a multilayer bidirectional Transformer which can aggregate information from context into the target word through the self-attention mechanism.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 17,
      "context" : "Moreover, the graph convolutional network(GCN) (Kipf and Welling, 2017) has been proved to be effective to model the relationship between labels (Yan et al.",
      "startOffset" : 47,
      "endOffset" : 71
    }, {
      "referenceID" : 24,
      "context" : "Moreover, the graph convolutional network(GCN) (Kipf and Welling, 2017) has been proved to be effective to model the relationship between labels (Yan et al., 2019; Chen et al., 2019; Cheng et al., 2020; Linmei et al., 2019), and it can enrich the representation of the node through aggregating information from its neighbors.",
      "startOffset" : 145,
      "endOffset" : 223
    }, {
      "referenceID" : 3,
      "context" : "Moreover, the graph convolutional network(GCN) (Kipf and Welling, 2017) has been proved to be effective to model the relationship between labels (Yan et al., 2019; Chen et al., 2019; Cheng et al., 2020; Linmei et al., 2019), and it can enrich the representation of the node through aggregating information from its neighbors.",
      "startOffset" : 145,
      "endOffset" : 223
    }, {
      "referenceID" : 4,
      "context" : "Moreover, the graph convolutional network(GCN) (Kipf and Welling, 2017) has been proved to be effective to model the relationship between labels (Yan et al., 2019; Chen et al., 2019; Cheng et al., 2020; Linmei et al., 2019), and it can enrich the representation of the node through aggregating information from its neighbors.",
      "startOffset" : 145,
      "endOffset" : 223
    }, {
      "referenceID" : 19,
      "context" : "Moreover, the graph convolutional network(GCN) (Kipf and Welling, 2017) has been proved to be effective to model the relationship between labels (Yan et al., 2019; Chen et al., 2019; Cheng et al., 2020; Linmei et al., 2019), and it can enrich the representation of the node through aggregating information from its neighbors.",
      "startOffset" : 145,
      "endOffset" : 223
    }, {
      "referenceID" : 22,
      "context" : "Note train, dev and test documents in both data have been partitioned following (Swayamdipta et al., 2017).",
      "startOffset" : 80,
      "endOffset" : 106
    }, {
      "referenceID" : 5,
      "context" : "Semafor (Das et al., 2014) is a conditional log-linear model which uses statistical features about target word to predict the frame label.",
      "startOffset" : 8,
      "endOffset" : 26
    }, {
      "referenceID" : 11,
      "context" : "SimpleFrameId (Hartmann et al., 2017) models a classifier based on the embeddings of entire words in the sentence.",
      "startOffset" : 14,
      "endOffset" : 37
    }, {
      "referenceID" : 22,
      "context" : "OpenSesame (Swayamdipta et al., 2017) models a classifier based on bi-directional LSTM.",
      "startOffset" : 11,
      "endOffset" : 37
    }, {
      "referenceID" : 21,
      "context" : "Peng’s model (Peng et al., 2018) is a joint learning model for FI and FSRL, which both uses exemplars in FrameNet knowledge base and the full-text annotation training data to train the model.",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : "Researchers have made great effort to tackle the FI problem since it has been proposed in the Semeval2007 (Baker et al., 2007).",
      "startOffset" : 106,
      "endOffset" : 126
    }, {
      "referenceID" : 14,
      "context" : "The best system (Johansson and Nugues, 2007) in the SemEval-2007 adopted SVM to learn the classifier to identify frames with a set of features, such as target lemma, target word, and so on.",
      "startOffset" : 16,
      "endOffset" : 44
    }, {
      "referenceID" : 13,
      "context" : "For instance, Hermann-14 (Hermann et al., 2014) implemented a model that jointly maps possible frame labels and the syntax context of target words into the same latent space using the WSABIE algorithm, and the syntax context was initialized with concatenating their word embeddings.",
      "startOffset" : 25,
      "endOffset" : 47
    }, {
      "referenceID" : 13,
      "context" : ", 2017) useed the concatenation of SentBOW (the average of embeddings of all the words in the sentence) to represent the context and then learns the common embedding space of context and frame labels following the line of (Hermann et al., 2014).",
      "startOffset" : 222,
      "endOffset" : 244
    }, {
      "referenceID" : 22,
      "context" : "Open-Sesame (Swayamdipta et al., 2017) used a bidirectional LSTM to construct the FI classifier.",
      "startOffset" : 12,
      "endOffset" : 38
    }, {
      "referenceID" : 21,
      "context" : "Peng (Peng et al., 2018) proposed a joint learning model for FI and FSRL, which adopted a multitask model structure.",
      "startOffset" : 5,
      "endOffset" : 24
    } ],
    "year" : 2021,
    "abstractText" : "and the 11th International Joint Conference on Natural Language Processing, pages 5230–5240 August 1–6, 2021. ©2021 Association for Computational Linguistics 5230 A Knowledge-Guided Framework for Frame Identification Xuefeng Su1,2, Ru Li1,3,∗, Xiaoli Li4, Jeff Z.Pan5, Hu Zhang1, Qinghua Chai1, Xiaoqi Han1 1. School of Computer and Information Technology, Shanxi University, Taiyuan, China 2. School of E-commerce and Logistics, Shanxi Vocational University of Engineering Technology, Taiyuan, China 3. Key Laboratory of Computational Intelligence and Chinese Information Processing of Ministry of Education, Shanxi University, Taiyuan, China 4. Institute for Infocomm Research, A*Star, Singapore 5. ILCC, School of Informatics, University of Edinburgh, UK {suexf,xiaoqisev}@163.com, {liru,zhanghu,charles}@sxu.edu.cn xlli@ntu.edu.sg, j.z.pan@ed.ac.uk Abstract",
    "creator" : "LaTeX with hyperref package"
  }
}