{
  "name" : "2021.acl-long.26.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Exploring the Efficacy of Automatically Generated Counterfactuals for Sentiment Analysis",
    "authors" : [ "Linyi Yang", "Jiazheng Li", "Pádraig Cunningham", "Yue Zhang", "Barry Smyth", "Ruihai Dong" ],
    "emails" : [ "barry.smyth}@insight-centre.org", "padraig.cunningham@ucd.ie", "jiazheng.li@ucdconnect.ie", "yue.zhang@westlake.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 306–316\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n306"
    }, {
      "heading" : "1 Introduction",
      "text" : "Deep neural models have recently made remarkable advances on sentiment analysis (Devlin et al., 2018; Liu et al., 2019; Yang et al., 2019; Xie et al., 2020). However, their implementation in practical applications still encounters significant challenges. Of particular concern, these models tend to learn intended behavior that is often associated with spurious patterns (artifacts) (Jo and Bengio, 2017; Slack\net al., 2020a). As an example, in the sentence “Nolan’s films always shock people, thanks to his superb directing skills”, the most influential word for the prediction of a positive sentiment should be “superb” instead of “Nolan” or “film”. The issue of spurious patterns also partially affects the out-ofdomain (OOD) generalization of the models trained on independent, identical distribution (IID) data, leading to performance decay under distribution shift (Quionero-Candela et al., 2009; Sugiyama and Kawanabe, 2012; Ovadia et al., 2019).\nResearchers have recently found that such concerns about model performance decay and social bias in NLP come about out-of-domain because of a sensitivity to semantically spurious signals (Gardner et al., 2020), and recent studies have uncovered a problematic tendency for gender bias in sentiment analysis (Zmigrod et al., 2019; Maudslay et al., 2019; Lu et al., 2020). To this end, one of the possible solutions is data augmentation with counterfactual examples (Kaushik et al., 2020) to ensure that models learn real causal associations between the input text and labels. For example, a sentiment-flipped counterfactual of last example could be “Nolan’s movies always bore people, thanks to his poor directorial skills.”. When added to the original set of training data, such kinds of counterfactually augmented data (CAD) have shown their benefits on learning real causal associations and improving the model robustness in recent studies (Kaushik et al., 2020, 2021; Wang and Culotta, 2021). Unlike gradient-based adversarial examples (Wang and Wan, 2019; Zhang et al., 2019; Zang et al., 2020), which cannot provide a clear boundary between positive and negative instances to humans, counterfactuals could provide “human-like” logic to show a modification to the\ninput that makes a difference to the output classification (Byrne, 2019).\nRecent attempts for generating counterfactual examples (also known as minimal pairs) rely on human-in-the-loop systems. Kaushik et al. (2020) proposed a human-in-the-loop method to generate CAD by employing human annotators to generate sentiment-flipped reviews. The human labeler is asked to make minimal and faithful edits to produce counterfactual reviews. Similarly, Srivastava et al. (2020) presented a framework to leverage strong prior (human) knowledge to understand the possible distribution shifts for a specific machine learning task; they use human commonsense reasoning as a source of information to build a more robust model against spurious patterns. Although useful for reducing sensitivity to spurious correlations, collecting enough high-quality human annotations is costly and time-consuming.\nThe theory behind the ability of CAD to improve model robustness in sentiment analysis is discussed by Kaushik et al. (2021), where researchers present a theoretical characterization of the impact of noise in causal and non-causal features on model generalization. However, methods for automatically generating CAD have received less attention. The only existing approach (Wang and Culotta, 2021) has been tested on the logistic regression model only, despite the fact that recent state-of-the-art methods for sentiment classification are driven by neural models. Also, their automatically generated CAD cannot produce competitive performance compared to human-generated CAD. We believe that their method does not sufficiently leverage the power of pre-trained language models and fails to generate fluent and effective CAD. In addition, the relationships between out-of-domain generalization and sensitivity to spurious patterns were not explicitly investigated by Wang and Culotta (2021).\nTo address these issues, we use four benchmark datasets (IMDB movie reviews as hold-out test while Amazon, Yelp, and Twitter datasets for outof-domain generalization test) to further explore the efficacy of CAD for sentiment analysis. First, we conduct a systematic comparison of several different state-of-the-art models (Wang and Culotta, 2021). This reveals how large Transformerbased models (Vaswani et al., 2017) with larger parameter sizes may improve the resilience of machine learning models. Specifically, we have found that for increasing parameter spaces, CAD’s per-\nformance benefit tends to decrease, regardless of whether CAD is controlled manually or automatically. Second, we introduce a novel masked language model for helping improve the fluency and grammar correctness of the generated CAD. Third, we add a fine-tuned model as a discriminator for automatically evaluating the edit-distance, using data generated with minimal and fluent edits (same requirements for human annotators in Kaushik et al. (2020)) to ensure the quality of generated counterfactuals. Experimental results show that it leads to significant prediction benefits using both hold-out tests and generalization tests.\nTo the best of our knowledge, we are the first to automatically generate counterfactuals for use as augmented data to improve the robustness of neural classifiers, which can outperform existing, state-ofthe-art, human-in-the-loop approaches. We will release our code and datasets on GitHub 1."
    }, {
      "heading" : "2 Related Work",
      "text" : "This work mainly touches on three important areas: approaches to evaluation that go beyond traditional accuracy measures (Bender and Koller, 2020; Warstadt et al., 2020), the importance of counterfactuals in eXplainable AI (XAI) (Byrne, 2019; Keane and Smyth, 2020), and out-of-domain generalization in sentiment analysis (Kim and Hovy, 2004; Zhang et al., 2018; Zhang and Zhang, 2019).\nThere has been an increasing interest in the role of Robustness Causal Thinking in ML, often by leveraging human feedback. Recently, some of the standard benchmark datasets have been challenged (Gardner et al., 2020; Ribeiro et al., 2020), in which the model performance is significantly lower on contrast sets than on original test sets; a difference of up to 25% in some cases. Researchers propose counterfactual data augmentation approaches for building robust models (Maudslay et al., 2019; Zmigrod et al., 2019; Lu et al., 2020), and find that spurious correlations threaten the model’s validity and reliability. In an attempt to address this problem, Kaushik et al. (2020) explore opportunities for developing human-in-the-loop systems by using crowd-sourcing to generate counterfactual data from original data, for data augmentation. Teney et al. (2020) shows the continuous effectiveness of CAD in computer vision (CV) and NLP.\nThe idea of generating Counterfactuals in XAI 1https://github.com/lijiazheng99/Counterfactuals-for-\nSentiment-Analysis\nalso shares important conceptual features with our work. Since human counterfactual explanations are minimal in the sense that they select a few relevant causes (Byrne, 2019; Keane and Smyth, 2020) as is the requirement of minimal edits in our generation process. This has been explored more in the field of CV (Goyal et al., 2019; Kenny and Keane, 2021), but investigated less in NLP. Recent work (Jacovi and Goldberg, 2020) highlight explanations of a given causal format, and Yang et al. (2020a) generate counterfactuals for explaining the prediction of financial text classification. We propose a similar but different research question, that is, whether the automatically generated counterfactual can be used for data augmentation to build more robust models, which has not been considered by the previous methods in XAI (Pedreschi et al., 2019; Slack et al., 2020b; Yang et al., 2020b; Ding et al., 2020).\nIn the case of Sentiment Analysis, most of the previous works report experiments using a holdout test on the IID dataset (Liu, 2012; Yang et al., 2016; Johnson and Zhang, 2017). The current stateof-the-art methods make use of large pre-trained language models (e.g., BERT (Devlin et al., 2018), RoBERTa (Liu et al., 2019) and SMART-RoBERTa (Jiang et al., 2020)) for calculating input represntations. It has been shown that these methods can suffer from spurious patterns (Kaushik et al., 2020; Wang and Culotta, 2021). Very recently, Wang and Culotta (2021) provide a starting point for exploring the efficacy of automatically generated CAD for sentiment analysis, but it is still based on IID hold-out tests only. However, spurious patterns in the training and test sets could be tightly coupled, which may limit the possibility of observing\ntheir attendant accuracy issues using a hold-out test methodology. For this reason, we designed an indirect method for evaluating the robustness of models, by comparing the performance of models trained on original and augmented data using out-of-domain data. The prediction benefit for out-of-domain data should provide some evidence about whether a model’s sensitivity to spurious patterns has been successfully mitigated. The resulting counterfactuals can be used for data augmentation and can also provide contrastive explanations for classifiers, and important and desirable consideration for the recent move towards more XAI (Ribeiro et al., 2016; Lundberg and Lee, 2017; Lipton, 2018; Pedreschi et al., 2019; Slack et al., 2020b)."
    }, {
      "heading" : "3 Detailed Implementation",
      "text" : "We propose a new approach for automatically generating counterfactuals to enhance the robustness of sentiment analysis models by inverting the sentiment of causally important terms according to Algorithm 1 and based on the following stages:\n1. The identification of genuine causal terms using self-supervised contextual decomposition (Section 3.1).\n2. Generating counterfactual samples by (a) RMCT (removing causal terms) and (b) REP-CT (replacing the causal terms) (Section 3.2).\n3. Selecting the human-like counterfactuals using MoverScore. (Zhao et al., 2019) (Section 3.3).\nThe end result will be a set of counterfactuals that can be used to augment an existing dataset."
    }, {
      "heading" : "3.1 Identifying Causal Terms",
      "text" : "To identify causally important terms, we propose a hierarchical method, based on the sampling and sensitivity of contextual decomposition technique from Jin et al. (2019), by incrementally removing words from a sentence in order to evaluate the model’s sensitivity to these words. Significant changes in model outputs suggest the removal of important terms. For example, removing the word “best” from “The movie is the best that I have ever seen.”, is likely to alter a model’s sentiment prediction more than the removal of other words from the sentence; thus “best” is an important word with respect to this sentence’s sentiment. In a similar way, phrases beginning with negative pronouns will likely be important; for instance, “not satisfy you” is important in “This movie could not satisfy you”.\nGiven a word (or phrase starting with negative limitations) w in the sentence s, the importance of w can be calculated as in Equation 1 where s β\\p denotes the sentence that resulting after masking out a single word (or a negative phrase as above). We use l (s β\\p; ŝ) to represent the model prediction after replacing the masked-out context, while ŝβ is a input sequence sampled from the input s. \\p indicates the operation of masking out the phrase p in a input document D from the training set. The specific candidate causal terms found by this masking operation vary for different prediction models.\nφ(w, ŝ) = Esβ\n[ l (s β; ŝβ)− l (s β\\p; ŝβ)\nl (s β; ŝβ)\n] (1)"
    }, {
      "heading" : "3.2 Generating Human-like Counterfactuals",
      "text" : "This approach and the scoring function in Equation 1 is used in Algorithm 1 in two ways, to generate two types of plausible counterfactuals. First, it is used to identify words to remove from a sentence to produce a plausible counterfactual. This is referred to as RM-CT and is performed by lines 3–5 in Algorithm 1; for a sentence S(i), it’s correctly labeled sentiment words are identified (line 3), and sorted based on Equation 1 (line 4) with classifier C, and the most important of these words is removed from S(i) to produce S(i)rm (line 5).\nSecond, the REP-CT technique instead replaces each causally important sentiment word in S(i) with an alternative word that has an opposing sentiment polarity (lines 6-11 in Algorithm 1). To do this the words in S(i) are each considered for replacement in order of their importance (lines 6 & 7)\nAlgorithm 1 Generating plausible counterfactual instances. Input: Test document D(n)= {P1, P2, ..., Pn}, with corresponding ground-truth labels Y, pre-trained Mask Language Model MLM, fine-tuned transformer classifier C, Positive Word Dictionaries POS, Negative Word Dictionaries NEG. (pos and neg are predicates for positive and negative labels) Output: Plausible counterfactual D(k)cf = {D (k) rep, D (k) rm}\n1: for Pk in D(n) do 2: for S(i), Yi in Pk do 3: Ŝ(i) ← { w ∈ S(i) | (w ∈ POS ∧ Yi = pos) ∨ (w ∈ NEG ∧ Yi = neg)\n} 4: S(i)sorted ← sort ( Ŝ(i), key = φ(w, Ŝ(i)) ) (eq.1) 5: S(i)rm ← S(i)sorted[1 :] 6: S(i)rep ← S(i)sorted 7: for w ∈ S(i)rep do 8: Wp ←MLM ( S (i) mask(w), S (i) rep\n) 9: Wc ← {w ∈ Wp | (w ∈ POS ∧ Yi! = pos) ∨ (w ∈ NEG ∧ Yi! = neg)\n} 10: S(i)rep(w)← sort ( Wc, key = φ(w,Wc) ) [0] 11: end for 12: P (k)rm ← P (k)rm + S(i)rm 13: P (k)rep ← P (k)rep + S(i)rep 14: end for 15: D(n)rm ← D(n)rm + P (k)rm 16: D(n)rep ← D(n)rep + P (k)rep 17: end for 18: return D(n)rm , D(n)rep\nto create a new sentence S(i)rep. For each word w we use a masked language model (MLM) to generate a set of plausible replacements, Wp (line 8), and a subset of these, Wc, as replacement candidates if their sentiment is different from the sentiment of S(i), which is given by Yi (line 9). Here we are using the BERT-base-uncased as the pre-trained MLM for SVM and BiLSTM models 1. The size of candidate substitutions found by MLM output is set to 100 for all models.Then, Wc is sorted in descending order of importance using Equation 1 and the most important candidate is selected and used to replace w in S(i)rep (line 10).\nAlgorithm 1 continues in this fashion to generate counterfactual sentences using RM-CT and REP-CT for each sentence in each paragraph of the target document 2. It returns two counterfactual documents, which correspond to documents produced from the RM-CT and REP-CT sentences; see lines 15–18.\nThe above approach is not guaranteed to always generate counterfactuals. Typically, reviews that\n1For Transformers-based models, we use their own pretrained MLM (e.g., RoBERTa and XLNet) as the generator.\n2Generating one counterfactual edit for an IMDB instance takes an average of ≈ 3.4 seconds based on the RoBERTaLarge model.\ncannot be transformed into plausible counterfactuals contain spurious associations that interfere with the model’s predictions. For example, in our method, the negative review “The film is pretty bad, and her performance is overacted” will be first modified as “The film is pretty good, and her performance is lifelike”. The revised review’s prediction will remain negative. Meanwhile, the word “her” will be identified as a potential causal term. To alleviate this problem, we further conduct the substitution of synonyms for those instances that have been already modified with antonym substitution by using causal terms. As an example, we will continue replacing the word “her” with “their” until the prediction has been flipped; see also Zmigrod et al. (2019) for related ideas.\nIn conclusion, then, the final augmented dataset that is produced of three parts: (1) counterfactuals generated by RM-CT; (2) counterfactuals generated by REP-CT; (3) adversarial examples generated by synonym substitutions."
    }, {
      "heading" : "3.3 Ensuring Minimal Changes",
      "text" : "When generating plausible counterfactuals, it is desirable to make minimal changes so that the resulting counterfactual is as similar as possible to the original instance (Miller, 2019; Keane and Smyth, 2020). To evaluate this for the approach described we use the MoverScore (Zhao et al., 2019) – an edit-distance scoring metric originally designed for machine translation – which confirms that the MoverScore for the automatic CAD instances is marginally higher when compared to human-generated counterfactuals, indicated greater similarity between counterfactuals and their original instances. The MoverScore between humangenerated counterfactuals and original reviews is 0.74 on average (minimum value of 0.55) and our augmented data results in a slightly higher average score than human-generated data for all models. The generated counterfactuals and synonym substitutions that achieve a MoverScore above 0.55 are combined with the original dataset for training robust classifiers."
    }, {
      "heading" : "4 Datasets",
      "text" : "Our evaluation uses three different kinds of datasets, in-domain data, challenge data, and outof-domain data."
    }, {
      "heading" : "4.1 In-domain Data",
      "text" : "We first adopt two of the most popular benchmark datasets – SST-2 and IMDB (Maas et al., 2011) – to show the recent advances on sentiment analysis with the benefit of pre-trained models. However, we mainly focus on the robustness of various models for sentiment analysis in this work, rather than in-domain accuracy. Hence, following Wang and Culotta (2021) and Kaushik et al. (2020), we perform binary sentiment classification experiments on the IMDB dataset sampled from Maas et al. (2011) that contains 1707 training, 245 validation, and 488 testing examples with challenge dataset (paired counterfactuals)."
    }, {
      "heading" : "4.2 Challenge Data",
      "text" : "Based on the in-domain IMDB data, Kaushik et al. (2020) employ crowd workers not to label documents, but to revise movie review to reverse its sentiment, without making any gratuitous changes. We directly use human-generated counterfactuals by Kaushik et al. (2020) as our challenge data, enforcing a 50:50 class balance."
    }, {
      "heading" : "4.3 Out-of-domain Data",
      "text" : "We also evaluate our method on different out-ofdomain datasets, including Amazon reviews (Ni et al., 2019) from six genres: beauty, fashion, appliances, gift cards, magazines, and software, a Yelp review dataset, and the Semeval-2017 Twitter dataset (Rosenthal et al., 2017). These have all been sampled to provide a 50:50 label split. The size of the training data has been kept the same for all methods, and the results reported are the average from five runs to facilitate a direct comparison with baselines (Kaushik et al., 2020, 2021)."
    }, {
      "heading" : "5 Results and Discussions",
      "text" : "We first describe the performance of the current state-of-the-art methods on sentiment analysis based on the SST-2 and IMDB benchmark datasets. Next, we will discuss the performance benefits by using our automatically generated counterfactuals\non an in-domain test. We further compare our method, human-label method, and two state-of-theart style-transfer methods (Sudhakar et al., 2019; Madaan et al., 2020) in terms of the model robustness on generalization test. Notably, we provide an ablation study lastly to discuss the influence of edit-distance for performance benefits."
    }, {
      "heading" : "5.1 State-of-the-art Models",
      "text" : "As the human-generated counterfactuals (Kaushik et al., 2020) are sampled from Maas et al. (2011), the results in Table 1 cannot be directly compared with Table 2 3. As shown in Table 1, by comparing BiLSTM to Transformer-base methods, it can be seen that remarkable advances in sentiment analysis have been achieved in recent years. On SST-2, SMART-RoBERTa (Jiang et al., 2020) outperforms Bi-LSTM by 10.8% (97.5% vs. 86.7%) accuracy, where a similar improvement is observed on IMDB (96.3% vs. 86.0%).\nAccording to the results, we select the following models for our experiments, which covers a spectrum of statistical, neural and pre-trained neural methods: SVM (Suykens and Vandewalle, 1999), Bi-LSTM (Graves and Schmidhuber, 2005), BERTBase (Devlin et al., 2018), RoBERTa-Large (Liu et al., 2019), and XLNet-Large (Yang et al., 2019).\n3We can only get the human-generated counterfactual examples (Kaushik et al., 2020) sampled from the IMDB dataset.\nThe SVM model for sentiment analysis is from scikit-learn and uses TF-IDF (Term FrequencyInverse Document Frequency) scores, while the Transformer-based models are built based on the Pytorch-Transformer package 4. We keep the prediction models the same as Kaushik et al. (2020), except for Naive Bayes, which has been abandoned due to its high-variance performance shown in our experiments.\nIn the following experiments, we only care about whether the robustness of models has been improved when training on the augmented dataset (original data & CAD). Different counterfactual examples have been generated for different models in terms of their own causal terms in practice, while the hyper-parameters for different prediction models are all identified using a grid search conducted over the validation set."
    }, {
      "heading" : "5.2 Comparison with Original Data",
      "text" : ""
    }, {
      "heading" : "On the Influence of Spurious Patterns. As",
      "text" : "shown in Table 2, we find that the linear model (SVM) trained on the original and challenge (human-generated counterfactuals) data can achieve 80% and 91.2% accuracy testing on the IID hold-out data, respectively. However, the accuracy of the SVM model trained on the original set when testing on the challenge data drops dramatically (91.2% vs. 51%), and vice versa (80% vs. 58.3%). Similar findings were reported by Kaushik et al. (2020), where a similar pattern was observed in the Bi-LSTM model and BERT-base model. This provides further evidence supporting the idea that the spurious association in machine learning models is harmful to the performance on the challenge set for sentiment analysis.\n4https://github.com/huggingface/ pytorch-transformers\nOn the Benefits of Robust BERT. As shown in Table 3, we also test whether the sensitivity to spurious patterns has been eliminated in the robust BERT model. We notice that the correlations of the real causal association “superb” and “poor” are improved from 0.213 to 0.627 and -0.551 to -0.999, respectively. While the correlation of spurious association “film” is decreased from 0.446 to 0.019 and -0.257 to -7e-7 on positive and the negative samples, respectively. This shows that the model trained with our CAD data does provide robustness against spurious patterns.\nOn the Influence of Model Size. Previous works (Kaushik et al., 2021; Wang and Culotta, 2021) have not investigated the performance benefits on larger pre-trained models. While we further conduct experiments on various Transformer-based models with different parameter sizes to explore whether the larger transformer-based models can still enjoy the performance benefits of CAD (Table 2). We observe that although the test result can increase with the parameter size increasing (best for 94.9% using XLNet), the performance benefits brought by human-generated CAD and the autogenerated CAD declines continuously with the parameter size increase. For example, the BERT-baseuncased model trained on the auto-generated combined dataset can receive 3.2% (90.6% vs. 87.4%) improvement on accuracy while performance increases only 0.6% (91.8% vs. 91.2%) on accuracy for WWM-BERT-Large. It suggests that larger pretrained Transformer models may be less sensitive to spurious patterns."
    }, {
      "heading" : "5.3 Comparison with Human CAD",
      "text" : "Robustness in the In-domain Test. We can see that all of the models trained on automatic CAD – shown as AC in the Table 2 – can outperform the human-generated CAD varying with the models (AC/O vs. C/O) as follows: SVM (+1.1%), Bi-LSTM (+0.7%), BERT-base-uncased (+2.1%), BERT-Large (+0.8%), XLNet-Large (+1.0%), and RoBERTa-Large (+0.5%) when testing on the original data. If we adopt the automatic CAD (AC), we note a distinct improvement in Table 2 across all models trained on the challenge data in terms of 11.3% in average (AC/O vs. CF/O), whereas the human-generated CAD can achieve 10.2% accuracy improvement (C/O vs. CF/O) in average. It is noteworthy that the human-generated CAD can slightly outperform our method when testing on the\nhuman-generated (CF) data, it may be because the training and test sets of the human-generated (CF) data are generated by the same group of labelers.\nRobustness in the Generalization Test. We explore how our approach makes prediction models more robust out-of-domain in Table 4. For direct comparison between our method and the humangenerated method, we adopt the fine-tuned BERTbase model trained with the augmented dataset (original & automatically revised data). The finetuned model is directly tested for out-of-domain data without any adjustment. As shown in Table 4, only our method and the human-label method can outperform the BERT model trained on the original data with average 6.5% and 5.3% accuracy improvements, respectively. Our method also offers performance benefits over three datasets even when compared to the human-label method on BERT.\nNeural Method vs. Statistical Method. As shown in Table 4, the performance of the SVM model with automatic CAD is more robust than other automated methods (Sudhakar et al., 2019; Madaan et al., 2020) across all datasets. However, the human-labeled CAD can improve Amazon reviews’ accuracy compared to our method using the SVM model by 0.7%. It indicates that humangenerated data may lead to more performance benefits on a statistical model."
    }, {
      "heading" : "5.4 Comparison with Automatic Methods",
      "text" : "Automatic CAD vs. Style-transfer Methods. As shown in Table 4, the style-transfer results are consistent with Kaushik et al. (2021). We find that the sentiment-flipped instances generated by style-transfer methods degrade the test accuracy for all models on all kinds of datasets, whereas our method has achieved the best performance for all settings. It suggests that our method have its absolute advantage for data augmentation in sentiment analysis when compared to the state-of-theart style-transfer models.\nOur Methods vs. Implausible CAD. The authors of the only existing approach for automatically generating CAD (Wang and Culotta, 2021) report that their methods are not able to match the performance of human-generated CAD. Our methods consistently outperform human-labeled methods on both In-domain and Out-of-domain tests. To further provide quantitative evidence of the influence of the edit-distance in automatic CAD, we demonstrate an ablation study in Table 6. The result shows that the quality of the generated CAD, which is ignored in the previous work Wang and Culotta (2021), is crucial when training the robust classifiers. In particular, the BERT model finetuned with implausible CAD (below the threshold) can receive comparable negative results with the style-transfer samples, alongside the performance decrease on all datasets, except for Twitter."
    }, {
      "heading" : "5.5 Case Study and Limitations",
      "text" : "The three most popular kinds of edits are shown in Table 5. These are, negation words removal, sentiment words replacement, and the combination of these. It can be observed from these examples that we ensure the edits on original samples should be minimal and fluent as was required previously with human-annotated counterfactuals (Kaushik\net al., 2020). As shown in Table 5, we flipped the model’s prediction by replacing the causal terms in the phrase “badly directed, badly acted and boring” to “well directed, well acted and entertaining”, or removing “No laughs throughout the movie.” to “Laughs throughout the movie” for a movie review. We also noticed that our method may face the\nchallenge when handling more complex reviews. For example, the sentence “Watch this only if someone has a gun to your head ... maybe.” is an apparent negative review for a human. However, our algorithm is hard to flip the sentiment of such reviews with no explicit casual terms. The technique on sarcasm and irony detection may have benefits for dealing with this challenge."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We proposed a new framework to automatically generate counterfactual augmented data (CAD) for enhancing the robustness of sentiment analysis models. By combining the automatically generated CAD with the original training data, we can produce more robust classifiers. We further show that our methods can achieve better performance even when compared to models trained with humangenerated counterfactuals. More importantly, our evaluation based on several datasets has demonstrated that models trained on the augmented data (original & automatic CAD) appear to be less af-\nfected by spurious patterns and generalize better to out-of-domain data. This suggests there exists a significant opportunity to explore the use of the CAD in a range of tasks (e.g., natural language inference, natural language understanding, and social bias correction.).\nImpact Statement\nAlthough the experiments in this paper are conducted only in the sentiment classification task, this study could be a good starting point to investigate the efficacy of automatically generated CAD for building robust systems in many NLP tasks, including Natural Language Inference (NLI), Named Entity Recognition (NER), Question Answering (QA) system, etc."
    }, {
      "heading" : "Acknowledgment",
      "text" : "We would like to thank Eoin Kenny and Prof. Mark Keane from Insight Centre for their helpful advice and discussion during this work. Also, we would like to thank the anonymous reviewers for their insightful comments and suggestions to help improve the paper. This publication has emanated from research conducted with the financial support of Science Foundation Ireland under Grant number 12/RC/2289 P2."
    } ],
    "references" : [ {
      "title" : "Climbing towards NLU: On meaning, form, and understanding in the age of data",
      "author" : [ "Emily M. Bender", "Alexander Koller." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5185–5198, Online. As-",
      "citeRegEx" : "Bender and Koller.,? 2020",
      "shortCiteRegEx" : "Bender and Koller.",
      "year" : 2020
    }, {
      "title" : "Counterfactuals in explainable artificial intelligence (xai): evidence from human reasoning",
      "author" : [ "Ruth MJ Byrne." ],
      "venue" : "Proceedings of the 28th International Joint Conference on Artificial Intelligence, pages 6276–6282. AAAI Press.",
      "citeRegEx" : "Byrne.,? 2019",
      "shortCiteRegEx" : "Byrne.",
      "year" : 2019
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "HITSCIR at SemEval-2020 task 5: Training pre-trained language model with pseudo-labeling data for counterfactuals detection",
      "author" : [ "Xiao Ding", "Dingkui Hao", "Yuewei Zhang", "Kuo Liao", "Zhongyang Li", "Bing Qin", "Ting Liu." ],
      "venue" : "Proceedings of the Four-",
      "citeRegEx" : "Ding et al\\.,? 2020",
      "shortCiteRegEx" : "Ding et al\\.",
      "year" : 2020
    }, {
      "title" : "Evaluating models’ local decision boundaries via contrast sets",
      "author" : [ "Matt Gardner", "Yoav Artzi", "Victoria Basmov", "Jonathan Berant", "Ben Bogin", "Sihao Chen", "Pradeep Dasigi", "Dheeru Dua", "Yanai Elazar", "Ananth Gottumukkala" ],
      "venue" : null,
      "citeRegEx" : "Gardner et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Gardner et al\\.",
      "year" : 2020
    }, {
      "title" : "Counterfactual visual explanations",
      "author" : [ "Yash Goyal", "Ziyan Wu", "Jan Ernst", "Dhruv Batra", "Devi Parikh", "Stefan Lee." ],
      "venue" : "ICML.",
      "citeRegEx" : "Goyal et al\\.,? 2019",
      "shortCiteRegEx" : "Goyal et al\\.",
      "year" : 2019
    }, {
      "title" : "Framewise phoneme classification with bidirectional lstm and other neural network architectures",
      "author" : [ "Alex Graves", "Jürgen Schmidhuber." ],
      "venue" : "Neural networks, 18(5-6):602–610.",
      "citeRegEx" : "Graves and Schmidhuber.,? 2005",
      "shortCiteRegEx" : "Graves and Schmidhuber.",
      "year" : 2005
    }, {
      "title" : "Mining and summarizing customer reviews",
      "author" : [ "Minqing Hu", "Bing Liu." ],
      "venue" : "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177.",
      "citeRegEx" : "Hu and Liu.,? 2004",
      "shortCiteRegEx" : "Hu and Liu.",
      "year" : 2004
    }, {
      "title" : "Aligning faithful interpretations with their social attribution",
      "author" : [ "Alon Jacovi", "Yoav Goldberg." ],
      "venue" : "arXiv preprint arXiv:2006.01067.",
      "citeRegEx" : "Jacovi and Goldberg.,? 2020",
      "shortCiteRegEx" : "Jacovi and Goldberg.",
      "year" : 2020
    }, {
      "title" : "SMART: Robust and efficient fine-tuning for pretrained natural language models through principled regularized optimization",
      "author" : [ "Haoming Jiang", "Pengcheng He", "Weizhu Chen", "Xiaodong Liu", "Jianfeng Gao", "Tuo Zhao." ],
      "venue" : "Proceedings of the 58th",
      "citeRegEx" : "Jiang et al\\.,? 2020",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards hierarchical importance attribution: Explaining compositional semantics for neural sequence models",
      "author" : [ "Xisen Jin", "Zhongyu Wei", "Junyi Du", "Xiangyang Xue", "Xiang Ren." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Jin et al\\.,? 2019",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2019
    }, {
      "title" : "Measuring the tendency of cnns to learn surface statistical regularities",
      "author" : [ "Jason Jo", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1711.11561.",
      "citeRegEx" : "Jo and Bengio.,? 2017",
      "shortCiteRegEx" : "Jo and Bengio.",
      "year" : 2017
    }, {
      "title" : "Deep pyramid convolutional neural networks for text categorization",
      "author" : [ "Rie Johnson", "Tong Zhang." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 562–570.",
      "citeRegEx" : "Johnson and Zhang.,? 2017",
      "shortCiteRegEx" : "Johnson and Zhang.",
      "year" : 2017
    }, {
      "title" : "Learning the difference that makes a difference with counterfactually-augmented data",
      "author" : [ "Divyansh Kaushik", "Eduard Hovy", "Zachary Lipton." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Kaushik et al\\.,? 2020",
      "shortCiteRegEx" : "Kaushik et al\\.",
      "year" : 2020
    }, {
      "title" : "Explaining the efficacy of counterfactually augmented data",
      "author" : [ "Divyansh Kaushik", "Amrith Setlur", "Eduard Hovy", "Zachary C Lipton." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Kaushik et al\\.,? 2021",
      "shortCiteRegEx" : "Kaushik et al\\.",
      "year" : 2021
    }, {
      "title" : "Good counterfactuals and where to find them: A case-based technique for generating counterfactuals for explainable ai (xai)",
      "author" : [ "Mark T Keane", "Barry Smyth." ],
      "venue" : "International Conference on Case-Based Reasoning (ICCBR).",
      "citeRegEx" : "Keane and Smyth.,? 2020",
      "shortCiteRegEx" : "Keane and Smyth.",
      "year" : 2020
    }, {
      "title" : "On generating plausible counterfactual and semi-factual explanations for deep learning",
      "author" : [ "Eoin M Kenny", "Mark T Keane." ],
      "venue" : "AAAI.",
      "citeRegEx" : "Kenny and Keane.,? 2021",
      "shortCiteRegEx" : "Kenny and Keane.",
      "year" : 2021
    }, {
      "title" : "Determining the sentiment of opinions",
      "author" : [ "Soo-Min Kim", "Eduard Hovy." ],
      "venue" : "COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics, pages 1367–1373.",
      "citeRegEx" : "Kim and Hovy.,? 2004",
      "shortCiteRegEx" : "Kim and Hovy.",
      "year" : 2004
    }, {
      "title" : "The mythos of model interpretability",
      "author" : [ "Zachary C Lipton." ],
      "venue" : "Queue, 16(3):31–57.",
      "citeRegEx" : "Lipton.,? 2018",
      "shortCiteRegEx" : "Lipton.",
      "year" : 2018
    }, {
      "title" : "Sentiment analysis and opinion mining",
      "author" : [ "Bing Liu." ],
      "venue" : "Synthesis lectures on human language technologies, 5(1):1–167.",
      "citeRegEx" : "Liu.,? 2012",
      "shortCiteRegEx" : "Liu.",
      "year" : 2012
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Gender bias in neural natural language processing",
      "author" : [ "Kaiji Lu", "Piotr Mardziel", "Fangjing Wu", "Preetam Amancharla", "Anupam Datta." ],
      "venue" : "Logic, Language, and Security, pages 189–202. Springer.",
      "citeRegEx" : "Lu et al\\.,? 2020",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2020
    }, {
      "title" : "A unified approach to interpreting model predictions",
      "author" : [ "Scott M Lundberg", "Su-In Lee." ],
      "venue" : "Advances in neural information processing systems, pages 4765–4774.",
      "citeRegEx" : "Lundberg and Lee.,? 2017",
      "shortCiteRegEx" : "Lundberg and Lee.",
      "year" : 2017
    }, {
      "title" : "Learning word vectors for sentiment analysis",
      "author" : [ "Andrew L. Maas", "Raymond E. Daly", "Peter T. Pham", "Dan Huang", "Andrew Y. Ng", "Christopher Potts." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Hu-",
      "citeRegEx" : "Maas et al\\.,? 2011",
      "shortCiteRegEx" : "Maas et al\\.",
      "year" : 2011
    }, {
      "title" : "Politeness transfer: A tag and generate approach",
      "author" : [ "Aman Madaan", "Amrith Setlur", "Tanmay Parekh", "Barnabas Poczos", "Graham Neubig", "Yiming Yang", "Ruslan Salakhutdinov", "Alan W Black", "Shrimai Prabhumoye." ],
      "venue" : "Proceedings of the 58th Annual Meet-",
      "citeRegEx" : "Madaan et al\\.,? 2020",
      "shortCiteRegEx" : "Madaan et al\\.",
      "year" : 2020
    }, {
      "title" : "It’s all in the name: Mitigating gender bias with name-based counterfactual data substitution",
      "author" : [ "Rowan Hall Maudslay", "Hila Gonen", "Ryan Cotterell", "Simone Teufel." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Maudslay et al\\.,? 2019",
      "shortCiteRegEx" : "Maudslay et al\\.",
      "year" : 2019
    }, {
      "title" : "Explanation in artificial intelligence: Insights from the social sciences",
      "author" : [ "Tim Miller." ],
      "venue" : "Artificial Intelligence, 267:1–38.",
      "citeRegEx" : "Miller.,? 2019",
      "shortCiteRegEx" : "Miller.",
      "year" : 2019
    }, {
      "title" : "Justifying recommendations using distantly-labeled reviews and fine-grained aspects",
      "author" : [ "Jianmo Ni", "Jiacheng Li", "Julian McAuley." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Ni et al\\.,? 2019",
      "shortCiteRegEx" : "Ni et al\\.",
      "year" : 2019
    }, {
      "title" : "Can you trust your model’s uncertainty? evaluating predictive uncertainty under dataset shift",
      "author" : [ "Yaniv Ovadia", "Emily Fertig", "Jie Ren", "Zachary Nado", "David Sculley", "Sebastian Nowozin", "Joshua Dillon", "Balaji Lakshminarayanan", "Jasper Snoek." ],
      "venue" : "Ad-",
      "citeRegEx" : "Ovadia et al\\.,? 2019",
      "shortCiteRegEx" : "Ovadia et al\\.",
      "year" : 2019
    }, {
      "title" : "Meaningful explanations of black box ai decision systems",
      "author" : [ "Dino Pedreschi", "Fosca Giannotti", "Riccardo Guidotti", "Anna Monreale", "Salvatore Ruggieri", "Franco Turini." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33,",
      "citeRegEx" : "Pedreschi et al\\.,? 2019",
      "shortCiteRegEx" : "Pedreschi et al\\.",
      "year" : 2019
    }, {
      "title" : "Dataset shift in machine learning",
      "author" : [ "Joaquin Quionero-Candela", "Masashi Sugiyama", "Anton Schwaighofer", "Neil D Lawrence." ],
      "venue" : "The MIT Press.",
      "citeRegEx" : "Quionero.Candela et al\\.,? 2009",
      "shortCiteRegEx" : "Quionero.Candela et al\\.",
      "year" : 2009
    }, {
      "title" : " why should i trust you?” explaining the predictions of any classifier",
      "author" : [ "Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin." ],
      "venue" : "Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining,",
      "citeRegEx" : "Ribeiro et al\\.,? 2016",
      "shortCiteRegEx" : "Ribeiro et al\\.",
      "year" : 2016
    }, {
      "title" : "Beyond accuracy: Behavioral testing of NLP models with CheckList",
      "author" : [ "Marco Tulio Ribeiro", "Tongshuang Wu", "Carlos Guestrin", "Sameer Singh." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4902–",
      "citeRegEx" : "Ribeiro et al\\.,? 2020",
      "shortCiteRegEx" : "Ribeiro et al\\.",
      "year" : 2020
    }, {
      "title" : "Semeval-2017 task 4: Sentiment analysis in twitter",
      "author" : [ "Sara Rosenthal", "Noura Farra", "Preslav Nakov." ],
      "venue" : "Proceedings of the 11th international workshop on semantic evaluation (SemEval-2017), pages 502– 518.",
      "citeRegEx" : "Rosenthal et al\\.,? 2017",
      "shortCiteRegEx" : "Rosenthal et al\\.",
      "year" : 2017
    }, {
      "title" : "Fooling lime and shap: Adversarial attacks on post hoc explanation methods",
      "author" : [ "Dylan Slack", "Sophie Hilgard", "Emily Jia", "Sameer Singh", "Himabindu Lakkaraju." ],
      "venue" : "Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, pages 180–186.",
      "citeRegEx" : "Slack et al\\.,? 2020a",
      "shortCiteRegEx" : "Slack et al\\.",
      "year" : 2020
    }, {
      "title" : "How much should i trust you? modeling uncertainty of black box explanations",
      "author" : [ "Dylan Slack", "Sophie Hilgard", "Sameer Singh", "Himabindu Lakkaraju." ],
      "venue" : "arXiv preprint arXiv:2008.05030.",
      "citeRegEx" : "Slack et al\\.,? 2020b",
      "shortCiteRegEx" : "Slack et al\\.",
      "year" : 2020
    }, {
      "title" : "Robustness to spurious correlations via human annotations",
      "author" : [ "Megha Srivastava", "Tatsunori Hashimoto", "Percy Liang." ],
      "venue" : "International Conference on Machine Learning, pages 9109–9119. PMLR.",
      "citeRegEx" : "Srivastava et al\\.,? 2020",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 2020
    }, {
      "title" : "transforming” delete, retrieve, generate approach for controlled text style transfer",
      "author" : [ "Akhilesh Sudhakar", "Bhargav Upadhyay", "Arjun Maheswaran." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
      "citeRegEx" : "Sudhakar et al\\.,? 2019",
      "shortCiteRegEx" : "Sudhakar et al\\.",
      "year" : 2019
    }, {
      "title" : "Machine learning in non-stationary environments: Introduction to covariate shift adaptation",
      "author" : [ "Masashi Sugiyama", "Motoaki Kawanabe." ],
      "venue" : "MIT press.",
      "citeRegEx" : "Sugiyama and Kawanabe.,? 2012",
      "shortCiteRegEx" : "Sugiyama and Kawanabe.",
      "year" : 2012
    }, {
      "title" : "Least squares support vector machine classifiers",
      "author" : [ "Johan AK Suykens", "Joos Vandewalle." ],
      "venue" : "Neural processing letters, 9(3):293–300.",
      "citeRegEx" : "Suykens and Vandewalle.,? 1999",
      "shortCiteRegEx" : "Suykens and Vandewalle.",
      "year" : 1999
    }, {
      "title" : "Learning what makes a difference from counterfactual examples and gradient supervision",
      "author" : [ "Damien Teney", "Ehsan Abbasnedjad", "Anton van den Hengel." ],
      "venue" : "arXiv preprint arXiv:2004.09034.",
      "citeRegEx" : "Teney et al\\.,? 2020",
      "shortCiteRegEx" : "Teney et al\\.",
      "year" : 2020
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "NIPS.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Automatic generation of sentimental texts via mixture adversarial networks",
      "author" : [ "Ke Wang", "Xiaojun Wan." ],
      "venue" : "Artificial Intelligence, 275:540–558.",
      "citeRegEx" : "Wang and Wan.,? 2019",
      "shortCiteRegEx" : "Wang and Wan.",
      "year" : 2019
    }, {
      "title" : "Robustness to spurious correlations in text classification via automatically generated counterfactuals",
      "author" : [ "Zhao Wang", "Aron Culotta." ],
      "venue" : "AAAI.",
      "citeRegEx" : "Wang and Culotta.,? 2021",
      "shortCiteRegEx" : "Wang and Culotta.",
      "year" : 2021
    }, {
      "title" : "Blimp: The benchmark of linguistic minimal pairs for english",
      "author" : [ "Alex Warstadt", "Alicia Parrish", "Haokun Liu", "Anhad Mohananey", "Wei Peng", "Sheng-Fu Wang", "Samuel R Bowman." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 8:377–392.",
      "citeRegEx" : "Warstadt et al\\.,? 2020",
      "shortCiteRegEx" : "Warstadt et al\\.",
      "year" : 2020
    }, {
      "title" : "Unsupervised data augmentation for consistency training",
      "author" : [ "Qizhe Xie", "Zihang Dai", "Eduard Hovy", "Thang Luong", "Quoc Le." ],
      "venue" : "Advances in Neural Information Processing Systems, 33.",
      "citeRegEx" : "Xie et al\\.,? 2020",
      "shortCiteRegEx" : "Xie et al\\.",
      "year" : 2020
    }, {
      "title" : "Generating plausible counterfactual explanations for deep transformers in financial text classification",
      "author" : [ "Linyi Yang", "Eoin Kenny", "Tin Lok James Ng", "Yi Yang", "Barry Smyth", "Ruihai Dong." ],
      "venue" : "Proceedings of the 28th International Conference on Com-",
      "citeRegEx" : "Yang et al\\.,? 2020a",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2020
    }, {
      "title" : "SemEval-2020 task 5: Counterfactual recognition",
      "author" : [ "Xiaoyu Yang", "Stephen Obadinma", "Huasha Zhao", "Qiong Zhang", "Stan Matwin", "Xiaodan Zhu." ],
      "venue" : "Proceedings of the Fourteenth Workshop on Semantic Evaluation, pages 322–335, Barcelona (on-",
      "citeRegEx" : "Yang et al\\.,? 2020b",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2020
    }, {
      "title" : "Xlnet: Generalized autoregressive pretraining for language understanding",
      "author" : [ "Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime Carbonell", "Russ R Salakhutdinov", "Quoc V Le." ],
      "venue" : "Advances in neural information processing systems, pages 5753–5763.",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Hierarchical attention networks for document classification",
      "author" : [ "Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy." ],
      "venue" : "Proceedings of the 2016 conference of the North",
      "citeRegEx" : "Yang et al\\.,? 2016",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2016
    }, {
      "title" : "Word-level textual adversarial attacking as combinatorial optimization",
      "author" : [ "Yuan Zang", "Fanchao Qi", "Chenghao Yang", "Zhiyuan Liu", "Meng Zhang", "Qun Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Zang et al\\.,? 2020",
      "shortCiteRegEx" : "Zang et al\\.",
      "year" : 2020
    }, {
      "title" : "Generating fluent adversarial examples for natural languages",
      "author" : [ "Huangzhao Zhang", "Hao Zhou", "Ning Miao", "Lei Li." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5564–5569.",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Tree communication models for sentiment analysis",
      "author" : [ "Yuan Zhang", "Yue Zhang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3518–3527.",
      "citeRegEx" : "Zhang and Zhang.,? 2019",
      "shortCiteRegEx" : "Zhang and Zhang.",
      "year" : 2019
    }, {
      "title" : "Sentencestate lstm for text representation",
      "author" : [ "Yue Zhang", "Qi Liu", "Linfeng Song." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 317–327.",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Moverscore: Text generation evaluating with contextualized embeddings and earth mover distance",
      "author" : [ "Wei Zhao", "Maxime Peyrard", "Fei Liu", "Yang Gao", "Christian M Meyer", "Steffen Eger." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in",
      "citeRegEx" : "Zhao et al\\.,? 2019",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2019
    }, {
      "title" : "Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology",
      "author" : [ "Ran Zmigrod", "Sebastian J Mielke", "Hanna Wallach", "Ryan Cotterell." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computa-",
      "citeRegEx" : "Zmigrod et al\\.,? 2019",
      "shortCiteRegEx" : "Zmigrod et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Deep neural models have recently made remarkable advances on sentiment analysis (Devlin et al., 2018; Liu et al., 2019; Yang et al., 2019; Xie et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 156
    }, {
      "referenceID" : 20,
      "context" : "Deep neural models have recently made remarkable advances on sentiment analysis (Devlin et al., 2018; Liu et al., 2019; Yang et al., 2019; Xie et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 156
    }, {
      "referenceID" : 48,
      "context" : "Deep neural models have recently made remarkable advances on sentiment analysis (Devlin et al., 2018; Liu et al., 2019; Yang et al., 2019; Xie et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 156
    }, {
      "referenceID" : 45,
      "context" : "Deep neural models have recently made remarkable advances on sentiment analysis (Devlin et al., 2018; Liu et al., 2019; Yang et al., 2019; Xie et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 156
    }, {
      "referenceID" : 11,
      "context" : "Of particular concern, these models tend to learn intended behavior that is often associated with spurious patterns (artifacts) (Jo and Bengio, 2017; Slack et al., 2020a).",
      "startOffset" : 128,
      "endOffset" : 170
    }, {
      "referenceID" : 34,
      "context" : "Of particular concern, these models tend to learn intended behavior that is often associated with spurious patterns (artifacts) (Jo and Bengio, 2017; Slack et al., 2020a).",
      "startOffset" : 128,
      "endOffset" : 170
    }, {
      "referenceID" : 30,
      "context" : "spurious patterns also partially affects the out-ofdomain (OOD) generalization of the models trained on independent, identical distribution (IID) data, leading to performance decay under distribution shift (Quionero-Candela et al., 2009; Sugiyama and Kawanabe, 2012; Ovadia et al., 2019).",
      "startOffset" : 206,
      "endOffset" : 287
    }, {
      "referenceID" : 38,
      "context" : "spurious patterns also partially affects the out-ofdomain (OOD) generalization of the models trained on independent, identical distribution (IID) data, leading to performance decay under distribution shift (Quionero-Candela et al., 2009; Sugiyama and Kawanabe, 2012; Ovadia et al., 2019).",
      "startOffset" : 206,
      "endOffset" : 287
    }, {
      "referenceID" : 28,
      "context" : "spurious patterns also partially affects the out-ofdomain (OOD) generalization of the models trained on independent, identical distribution (IID) data, leading to performance decay under distribution shift (Quionero-Candela et al., 2009; Sugiyama and Kawanabe, 2012; Ovadia et al., 2019).",
      "startOffset" : 206,
      "endOffset" : 287
    }, {
      "referenceID" : 4,
      "context" : "(Gardner et al., 2020), and recent studies have uncovered a problematic tendency for gender bias in sentiment analysis (Zmigrod et al.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 55,
      "context" : ", 2020), and recent studies have uncovered a problematic tendency for gender bias in sentiment analysis (Zmigrod et al., 2019; Maudslay et al., 2019; Lu et al., 2020).",
      "startOffset" : 104,
      "endOffset" : 166
    }, {
      "referenceID" : 25,
      "context" : ", 2020), and recent studies have uncovered a problematic tendency for gender bias in sentiment analysis (Zmigrod et al., 2019; Maudslay et al., 2019; Lu et al., 2020).",
      "startOffset" : 104,
      "endOffset" : 166
    }, {
      "referenceID" : 21,
      "context" : ", 2020), and recent studies have uncovered a problematic tendency for gender bias in sentiment analysis (Zmigrod et al., 2019; Maudslay et al., 2019; Lu et al., 2020).",
      "startOffset" : 104,
      "endOffset" : 166
    }, {
      "referenceID" : 13,
      "context" : "To this end, one of the possible solutions is data augmentation with counterfactual examples (Kaushik et al., 2020) to ensure that models learn real causal associations between the input text and labels.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 43,
      "context" : "When added to the original set of training data, such kinds of counterfactually augmented data (CAD) have shown their benefits on learning real causal associations and improving the model robustness in recent studies (Kaushik et al., 2020, 2021; Wang and Culotta, 2021).",
      "startOffset" : 217,
      "endOffset" : 269
    }, {
      "referenceID" : 42,
      "context" : "Unlike gradient-based adversarial examples (Wang and Wan, 2019; Zhang et al., 2019; Zang et al., 2020), which cannot provide a clear boundary between positive and negative instances to humans, counterfactuals could provide “human-like” logic to show a modification to the",
      "startOffset" : 43,
      "endOffset" : 102
    }, {
      "referenceID" : 51,
      "context" : "Unlike gradient-based adversarial examples (Wang and Wan, 2019; Zhang et al., 2019; Zang et al., 2020), which cannot provide a clear boundary between positive and negative instances to humans, counterfactuals could provide “human-like” logic to show a modification to the",
      "startOffset" : 43,
      "endOffset" : 102
    }, {
      "referenceID" : 50,
      "context" : "Unlike gradient-based adversarial examples (Wang and Wan, 2019; Zhang et al., 2019; Zang et al., 2020), which cannot provide a clear boundary between positive and negative instances to humans, counterfactuals could provide “human-like” logic to show a modification to the",
      "startOffset" : 43,
      "endOffset" : 102
    }, {
      "referenceID" : 43,
      "context" : "The only existing approach (Wang and Culotta, 2021) has been tested on the logistic regression model only,",
      "startOffset" : 27,
      "endOffset" : 51
    }, {
      "referenceID" : 43,
      "context" : "First, we conduct a systematic comparison of several different state-of-the-art models (Wang and Culotta, 2021).",
      "startOffset" : 87,
      "endOffset" : 111
    }, {
      "referenceID" : 41,
      "context" : "This reveals how large Transformerbased models (Vaswani et al., 2017) with larger parameter sizes may improve the resilience of machine learning models.",
      "startOffset" : 47,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : "tional accuracy measures (Bender and Koller, 2020; Warstadt et al., 2020), the importance of counterfactuals in eXplainable AI (XAI) (Byrne, 2019; Keane and Smyth, 2020), and out-of-domain generalization in sentiment analysis (Kim and Hovy, 2004;",
      "startOffset" : 25,
      "endOffset" : 73
    }, {
      "referenceID" : 44,
      "context" : "tional accuracy measures (Bender and Koller, 2020; Warstadt et al., 2020), the importance of counterfactuals in eXplainable AI (XAI) (Byrne, 2019; Keane and Smyth, 2020), and out-of-domain generalization in sentiment analysis (Kim and Hovy, 2004;",
      "startOffset" : 25,
      "endOffset" : 73
    }, {
      "referenceID" : 1,
      "context" : ", 2020), the importance of counterfactuals in eXplainable AI (XAI) (Byrne, 2019; Keane and Smyth, 2020), and out-of-domain generalization in sentiment analysis (Kim and Hovy, 2004;",
      "startOffset" : 67,
      "endOffset" : 103
    }, {
      "referenceID" : 15,
      "context" : ", 2020), the importance of counterfactuals in eXplainable AI (XAI) (Byrne, 2019; Keane and Smyth, 2020), and out-of-domain generalization in sentiment analysis (Kim and Hovy, 2004;",
      "startOffset" : 67,
      "endOffset" : 103
    }, {
      "referenceID" : 4,
      "context" : "(Gardner et al., 2020; Ribeiro et al., 2020), in which the model performance is significantly lower on contrast sets than on original test sets; a difference of up to 25% in some cases.",
      "startOffset" : 0,
      "endOffset" : 44
    }, {
      "referenceID" : 32,
      "context" : "(Gardner et al., 2020; Ribeiro et al., 2020), in which the model performance is significantly lower on contrast sets than on original test sets; a difference of up to 25% in some cases.",
      "startOffset" : 0,
      "endOffset" : 44
    }, {
      "referenceID" : 25,
      "context" : "building robust models (Maudslay et al., 2019; Zmigrod et al., 2019; Lu et al., 2020), and find that spurious correlations threaten the model’s validity and reliability.",
      "startOffset" : 23,
      "endOffset" : 85
    }, {
      "referenceID" : 55,
      "context" : "building robust models (Maudslay et al., 2019; Zmigrod et al., 2019; Lu et al., 2020), and find that spurious correlations threaten the model’s validity and reliability.",
      "startOffset" : 23,
      "endOffset" : 85
    }, {
      "referenceID" : 21,
      "context" : "building robust models (Maudslay et al., 2019; Zmigrod et al., 2019; Lu et al., 2020), and find that spurious correlations threaten the model’s validity and reliability.",
      "startOffset" : 23,
      "endOffset" : 85
    }, {
      "referenceID" : 7,
      "context" : "Sentiment Dictionary refers to the opinion lexicon published by (Hu and Liu, 2004).",
      "startOffset" : 64,
      "endOffset" : 82
    }, {
      "referenceID" : 1,
      "context" : "Since human counterfactual explanations are minimal in the sense that they select a few relevant causes (Byrne, 2019; Keane and Smyth, 2020) as is the requirement of minimal edits in our generation process.",
      "startOffset" : 104,
      "endOffset" : 140
    }, {
      "referenceID" : 15,
      "context" : "Since human counterfactual explanations are minimal in the sense that they select a few relevant causes (Byrne, 2019; Keane and Smyth, 2020) as is the requirement of minimal edits in our generation process.",
      "startOffset" : 104,
      "endOffset" : 140
    }, {
      "referenceID" : 8,
      "context" : "Recent work (Jacovi and Goldberg, 2020) highlight explanations of a given causal format, and Yang et al.",
      "startOffset" : 12,
      "endOffset" : 39
    }, {
      "referenceID" : 19,
      "context" : "In the case of Sentiment Analysis, most of the previous works report experiments using a holdout test on the IID dataset (Liu, 2012; Yang et al., 2016; Johnson and Zhang, 2017).",
      "startOffset" : 121,
      "endOffset" : 176
    }, {
      "referenceID" : 49,
      "context" : "In the case of Sentiment Analysis, most of the previous works report experiments using a holdout test on the IID dataset (Liu, 2012; Yang et al., 2016; Johnson and Zhang, 2017).",
      "startOffset" : 121,
      "endOffset" : 176
    }, {
      "referenceID" : 12,
      "context" : "In the case of Sentiment Analysis, most of the previous works report experiments using a holdout test on the IID dataset (Liu, 2012; Yang et al., 2016; Johnson and Zhang, 2017).",
      "startOffset" : 121,
      "endOffset" : 176
    }, {
      "referenceID" : 20,
      "context" : ", 2018), RoBERTa (Liu et al., 2019) and SMART-RoBERTa (Jiang et al.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 9,
      "context" : ", 2019) and SMART-RoBERTa (Jiang et al., 2020)) for calculating input represntations.",
      "startOffset" : 26,
      "endOffset" : 46
    }, {
      "referenceID" : 13,
      "context" : "It has been shown that these methods can suffer from spurious patterns (Kaushik et al., 2020; Wang and Culotta, 2021).",
      "startOffset" : 71,
      "endOffset" : 117
    }, {
      "referenceID" : 43,
      "context" : "It has been shown that these methods can suffer from spurious patterns (Kaushik et al., 2020; Wang and Culotta, 2021).",
      "startOffset" : 71,
      "endOffset" : 117
    }, {
      "referenceID" : 31,
      "context" : "important and desirable consideration for the recent move towards more XAI (Ribeiro et al., 2016; Lundberg and Lee, 2017; Lipton, 2018; Pedreschi et al., 2019; Slack et al., 2020b).",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 22,
      "context" : "important and desirable consideration for the recent move towards more XAI (Ribeiro et al., 2016; Lundberg and Lee, 2017; Lipton, 2018; Pedreschi et al., 2019; Slack et al., 2020b).",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 18,
      "context" : "important and desirable consideration for the recent move towards more XAI (Ribeiro et al., 2016; Lundberg and Lee, 2017; Lipton, 2018; Pedreschi et al., 2019; Slack et al., 2020b).",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 29,
      "context" : "important and desirable consideration for the recent move towards more XAI (Ribeiro et al., 2016; Lundberg and Lee, 2017; Lipton, 2018; Pedreschi et al., 2019; Slack et al., 2020b).",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 35,
      "context" : "important and desirable consideration for the recent move towards more XAI (Ribeiro et al., 2016; Lundberg and Lee, 2017; Lipton, 2018; Pedreschi et al., 2019; Slack et al., 2020b).",
      "startOffset" : 75,
      "endOffset" : 180
    }, {
      "referenceID" : 26,
      "context" : "desirable to make minimal changes so that the resulting counterfactual is as similar as possible to the original instance (Miller, 2019; Keane and Smyth, 2020).",
      "startOffset" : 122,
      "endOffset" : 159
    }, {
      "referenceID" : 15,
      "context" : "desirable to make minimal changes so that the resulting counterfactual is as similar as possible to the original instance (Miller, 2019; Keane and Smyth, 2020).",
      "startOffset" : 122,
      "endOffset" : 159
    }, {
      "referenceID" : 9,
      "context" : "State-of-the-art Models SST-2 IMDB SMART-RoBERTa (Jiang et al., 2020) 97.",
      "startOffset" : 49,
      "endOffset" : 69
    }, {
      "referenceID" : 23,
      "context" : "We first adopt two of the most popular benchmark datasets – SST-2 and IMDB (Maas et al., 2011) –",
      "startOffset" : 75,
      "endOffset" : 94
    }, {
      "referenceID" : 27,
      "context" : "We also evaluate our method on different out-ofdomain datasets, including Amazon reviews (Ni et al., 2019) from six genres: beauty, fashion, appliances, gift cards, magazines, and software, a Yelp review dataset, and the Semeval-2017 Twitter dataset (Rosenthal et al.",
      "startOffset" : 89,
      "endOffset" : 106
    }, {
      "referenceID" : 33,
      "context" : ", 2019) from six genres: beauty, fashion, appliances, gift cards, magazines, and software, a Yelp review dataset, and the Semeval-2017 Twitter dataset (Rosenthal et al., 2017).",
      "startOffset" : 151,
      "endOffset" : 175
    }, {
      "referenceID" : 37,
      "context" : "method, human-label method, and two state-of-theart style-transfer methods (Sudhakar et al., 2019; Madaan et al., 2020) in terms of the model robustness on generalization test.",
      "startOffset" : 75,
      "endOffset" : 119
    }, {
      "referenceID" : 24,
      "context" : "method, human-label method, and two state-of-theart style-transfer methods (Sudhakar et al., 2019; Madaan et al., 2020) in terms of the model robustness on generalization test.",
      "startOffset" : 75,
      "endOffset" : 119
    }, {
      "referenceID" : 13,
      "context" : "As the human-generated counterfactuals (Kaushik et al., 2020) are sampled from Maas et al.",
      "startOffset" : 39,
      "endOffset" : 61
    }, {
      "referenceID" : 9,
      "context" : "On SST-2, SMART-RoBERTa (Jiang et al., 2020) outperforms Bi-LSTM by 10.",
      "startOffset" : 24,
      "endOffset" : 44
    }, {
      "referenceID" : 39,
      "context" : "According to the results, we select the following models for our experiments, which covers a spectrum of statistical, neural and pre-trained neural methods: SVM (Suykens and Vandewalle, 1999), Bi-LSTM (Graves and Schmidhuber, 2005), BERTBase (Devlin et al.",
      "startOffset" : 161,
      "endOffset" : 191
    }, {
      "referenceID" : 6,
      "context" : "According to the results, we select the following models for our experiments, which covers a spectrum of statistical, neural and pre-trained neural methods: SVM (Suykens and Vandewalle, 1999), Bi-LSTM (Graves and Schmidhuber, 2005), BERTBase (Devlin et al.",
      "startOffset" : 201,
      "endOffset" : 231
    }, {
      "referenceID" : 2,
      "context" : "According to the results, we select the following models for our experiments, which covers a spectrum of statistical, neural and pre-trained neural methods: SVM (Suykens and Vandewalle, 1999), Bi-LSTM (Graves and Schmidhuber, 2005), BERTBase (Devlin et al., 2018), RoBERTa-Large (Liu et al.",
      "startOffset" : 242,
      "endOffset" : 263
    }, {
      "referenceID" : 20,
      "context" : ", 2018), RoBERTa-Large (Liu et al., 2019), and XLNet-Large (Yang et al.",
      "startOffset" : 23,
      "endOffset" : 41
    }, {
      "referenceID" : 13,
      "context" : "We can only get the human-generated counterfactual examples (Kaushik et al., 2020) sampled from the IMDB dataset.",
      "startOffset" : 60,
      "endOffset" : 82
    }, {
      "referenceID" : 14,
      "context" : "Previous works (Kaushik et al., 2021; Wang and Culotta, 2021) have not investigated the performance benefits on larger pre-trained models.",
      "startOffset" : 15,
      "endOffset" : 61
    }, {
      "referenceID" : 43,
      "context" : "Previous works (Kaushik et al., 2021; Wang and Culotta, 2021) have not investigated the performance benefits on larger pre-trained models.",
      "startOffset" : 15,
      "endOffset" : 61
    }, {
      "referenceID" : 37,
      "context" : "As shown in Table 4, the performance of the SVM model with automatic CAD is more robust than other automated methods (Sudhakar et al., 2019; Madaan et al., 2020) across all datasets.",
      "startOffset" : 117,
      "endOffset" : 161
    }, {
      "referenceID" : 24,
      "context" : "As shown in Table 4, the performance of the SVM model with automatic CAD is more robust than other automated methods (Sudhakar et al., 2019; Madaan et al., 2020) across all datasets.",
      "startOffset" : 117,
      "endOffset" : 161
    }, {
      "referenceID" : 43,
      "context" : "thors of the only existing approach for automatically generating CAD (Wang and Culotta, 2021) report that their methods are not able to match the performance of human-generated CAD.",
      "startOffset" : 69,
      "endOffset" : 93
    } ],
    "year" : 2021,
    "abstractText" : "While state-of-the-art NLP models have been achieving the excellent performance of a wide range of tasks in recent years, important questions are being raised about their robustness and their underlying sensitivity to systematic biases that may exist in their training and test data. Such issues come to be manifest in performance problems when faced with out-ofdistribution data in the field. One recent solution has been to use counterfactually augmented datasets in order to reduce any reliance on spurious patterns that may exist in the original data. Producing high-quality augmented data can be costly and time-consuming as it usually needs to involve human feedback and crowdsourcing efforts. In this work, we propose an alternative by describing and evaluating an approach to automatically generating counterfactual data for the purpose of data augmentation and explanation. A comprehensive evaluation on several different datasets and using a variety of state-of-the-art benchmarks demonstrate how our approach can achieve significant improvements in model performance when compared to models training on the original data and even when compared to models trained with the benefit of human-generated augmented data.",
    "creator" : "LaTeX with hyperref"
  }
}