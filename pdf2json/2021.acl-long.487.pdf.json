{
  "name" : "2021.acl-long.487.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Learning from Miscellaneous Other-Class Words for Few-shot Named Entity Recognition",
    "authors" : [ "Meihan Tong", "Shuai Wang", "Bin Xu", "Yixin Cao", "Minghui Liu", "Lei Hou", "Juanzi Li" ],
    "emails" : [ "tongmeihan@gmail.com,", "wangshuai1@yy.com", "xubin@tsinghua.edu.cn,", "caoyixin2011@gmail.com", "lijuanzi@tsinghua.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6236–6247\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n6236"
    }, {
      "heading" : "1 Introduction",
      "text" : "Named Entity Recognition (NER) seeks to locate and classify named entities from sentences into predefined classes (Yadav and Bethard, 2019). Humans can immediately recognize new entity types given just one or a few examples(Lake et al., 2015). Although neural NER networks have achieved superior performance when provided large-scale of training examples (Li et al., 2019), it remains a non-trivial task to learn from limited new samples, also known as few-shot NER (Fritzler et al., 2019).\nTraditional NER models, such as LSTM+CRF (Lample et al., 2016), fail in few-shot settings. They calculate the transition probability matrix based on statistics, which requires a large number of data for optimization. Recently, prototypical\n∗Corresponding author.\nnetwork (Snell et al., 2017) shows potential on fewshot NER. The basic idea is to learn prototypes for each predefined entity class and an other class, then classify examples based on which prototypes they are closest to (Fritzler et al., 2019). Most existing studies focus on the predefined classes and leverage the label semantic to reveal their dependency for enhancement (Hou et al., 2020). However, they ignore the massive semantics hidden in the words of other class (O-class for short).\nIn this paper, we propose to learn from O-class words, rather than using predefined entity classes only, to improve few-shot NER. In fact, O-class contains rich semantics and can provide stand-by knowledge for named entity identification and disambiguation. As shown in Figure 1(a), if we can detect an undefined class consisting of references to named entities (such as pronouns), then due to their interchangeability (Katz and Fodor, 1963), we will obtain prior knowledge for named entity identification. For example, Newton can be replaced with he or professor in S2 and S3. If we can detect additional classes, including he and professor, we will have more evidence about where Newton may appear. In addition, if we can detect an undefined class that composed of Action (O1), we may cap-\nture underlined relations between different named entities, which is important evidence when distinguishing the named entity type (Ghosh et al., 2016; Zheng et al., 2017).\nNevertheless, it is challenging to detect related undefined classes from O class words due to two reasons: 1) Miscellaneous Semantics. O-class contains miscellaneous types of words. Based on our observations, although there are massive related yet undefined classes, the noise maybe even more, such as function and stop words. These noisy classes have little or negative impacts on the identification of target entities. Therefore, how to distinguish noise from task-related classes is a key point. 2) Lack of Golden Label. We neither have the labeled examples nor the metadata of each undefined class. The zero-shot methods (Pushp and Srivastava, 2017) fail in this case, since they need metadata (such as class name and class description) as known information. Unsupervised clustering methods also cannot meet quality requirements as shown in our experiment.\nTo handle the issues, we propose the Mining Undefined Classes from Other-class (MUCO) model to leverage the rich semantics to improve few-shot NER. Instead of a single prototype, we learn multiple prototypes to represent miscellaneous semantics of O-class. Figure 1(b) shows the difference between our method and previous methods. To distinguish task-related undefined classes without annotations, we leverage weakly supervised signals from predefined classes and propose a zero-shot classification method called Zeroshot Miner. The main idea is inspired by transfer learning in prototypical network. Prototypical network can be quickly adapted to new class B when pre-training on related base class A. The underlined reason is that if two classes (A and B) are task-related, when we make examples in A class to cluster in the space, the examples in B class also tend to cluster in the space, even without explicit supervision on class B (Koch et al., 2015). Based on this phenomenon, we first perform prototype learning on predefined classes to cluster words in predefined classes, and then regard words in O-class that also tend to cluster as the undefined classes. Specifically, we train a binary classification to judge whether clustering occurs between any two of the words. After that, we label the found undefined classes back into sentences to jointly recognize predefined and undefined classes\nfor knowledge transfer. Our contributions can be summarized as follows:\n• We propose a novel approach MUCO to leverage rich semantics in O class to improve fewshot NER. To the best of our knowledge, this is the first work exploring O-class in this task.\n• We propose a novel zero-shot classification method for undefined class detection. In the absence of labeled examples and metadata, our proposed zero-shot method creatively use the weakly supervised signal of the predefined classes to find undefined classes.\n• We conduct extensive experiments on four benchmarks as compared with five state-ofthe-art baselines. The results under both 1- shot and 5-shots settings demonstrate the effectiveness of MUCO. Further studies show that our method can also be conveniently adapted to other domains."
    }, {
      "heading" : "2 Related Work",
      "text" : "Few-shot NER aims to recognize new categories with just a handful of examples (Feng et al., 2018; Cao et al., 2019). Four groups of methods are adopted to handle the low-resource issue: knowledge enhanced, cross-lingual enhanced, crossdomain enhanced, and active learning. Knowledgeenhanced methods exploit ontology, knowledge bases or heuristics labeling (Fries et al., 2017; Tsai and Salakhutdinov, 2017; Ma et al., 2016) as side information to improve NER performance in limited data settings, which suffer from knowledge low-coverage issue. Cross-lingual (Feng et al., 2018; Rahimi et al., 2019) and cross-domain enhanced methods (Wang et al., 2018; Zhou et al., 2019) respectively use labeled data from a counterpart language or a different domain as external supervised signals to avoid overfitting. When the language or domain discrepancy is large, these two methods will inevitably face the problem of performance degradation (Huang et al., 2017). Active learning methods (Wei et al., 2019) explicitly expand corpus by selecting the most informative examples for manual annotation, which need extra human-laboring. Different from previous methods, we focus on mining the rich semantics in the O class to improve few-shot NER."
    }, {
      "heading" : "2.1 Prototypical Network",
      "text" : "Prototypical network (Snell et al., 2017), initially proposed for image classification, has been successfully applied to sentence-level classification tasks, such as text classification (Sun et al., 2019) and relation extraction (Gao et al., 2019). However, there is a dilemma to adapt prototypical network for token-level classification tasks such as NER. Prototypical network assumes that each class has uniform semantic and vectors belong to the same class should cluster in the space. However, in NER, data in O class contain multiple semantics and thus violate the uniform semantic hypothesis in prototypical network. To handle the issue, Deng et al. (2020) first trains a binary classifier to distinguish O class from other predefined classes, and then adopt traditional prototypical network methods, which suffers from pipeline error propagation. Fritzler et al. (2019) does not calculate the prototype of O class from data, but directly sets a hyper-parameter bo as the fake distance similarity and optimize bo during training, which still regards O class as a whole. On the contrary, we are the first to divide O class into multiple undefined classes and explicitly learn multiple spatially-dispersed prototypes for O class."
    }, {
      "heading" : "3 Methodology",
      "text" : "Figure 2 illustrated the architecture of the proposed MUCO model. MUCO is composed of two main modules: Undefined Classes Detection detects multiple undefined classes hidden in O class to fully exploit the rich semantics in O class. Joint Classification jointly classifies the undefined classes and predefined classes, so as to leverage the stand-by semantic knowledge in undefined classes to enhance the understanding of predefined classes."
    }, {
      "heading" : "3.1 Notation",
      "text" : "In few-shot NER, we are given training examples D = Dc ∪ Do, where Dc = {xi, yi|Ni=1} is the training examples of predefined classes C = {c1, c2, . . . , ck} and Do = {xi|Mi=1} is the training examples of O class. For each example (x, y), x is composed by S and wj , where S =< w1, w2, . . . , wn > stands for the sentence and wj is the queried named entity, y is the class label of the queried named entity wj . We denote the prototype of class y as py and prototypes for all classes C ∪ O as P = {py|y ∈ C ∪ O}. Formally, our goal is first to detect multiple undefined\nclasses O = {o1, o2, . . . , or} to label the examples in Do, and then maximize the prediction probability P (y|x) on Dc and Do."
    }, {
      "heading" : "3.2 Undefined Classes Detection",
      "text" : "In few-shot NER, most of the words in the sentence belong to O class. Different from predefined classes, O class means none-of-the-above, and contains multiple undefined entity types. Previous methods ignore the fine-grained semantic information in O class and simply regard O as a normal class. We argue to further decouple O class into multiple undefined classes to fully exploit the rich semantics hidden in O class.\nIn the section, we aim to detect undefined classes from O class. It is a non-trivial task since we lack metadata and golden labels to help us distinguish undefined classes. What is worse, the examples from O class is numerous and the search space is large. To handle the issue, we propose a zeroshot classification method called Zero-shot Miner to leverage the weak supervision from predefined classes for undefined classes detection. Our method inspires by transfer learning, we argue that if an undefined class is task-related, when we push the examples in predefined classes to cluster in the space, the examples in the undefined class should also have the signs of gathering, even without explicit supervision (Koch et al., 2015). For instance, in Figure 2, if we guide Emeneya and Newton (the green points 1, 3) to cluster in the space, professor and He (the grey points 9, 12) will also tend to cluster in the space.\nBased on this argument, undefined classes detection could be achieved by finding multiple groups of examples in O class that have a tendency to cluster during the training of the prototypical network on predefined classes. As shown in Figure 2, there are three steps in our zero-shot classification method. In step 1, we train the prototypical network on predefined classes to obtain the learned mapping function. Through the learned mapping function the examples belonging to the same class will cluster in the space. In step 2, we train a binary group classifier on predefined classes base on the position features from the learned mapping function and unlearned mapping function to judge whether any two points tend to cluster during the step 1 training. In step 3, we use the learned binary group classifier in step 2 to infer examples in O class to distinguish undefined classes from each\nother. The following articles will illustrate the three steps sequentially."
    }, {
      "heading" : "3.2.1 Step 1: Mapping Function Learning",
      "text" : "In prototypical network, mapping function fθ(x) aims to map the example x to a hidden representation. BERT is adopted as the mapping function in our model, which is a pre-trained language representation model that employs multi-head attention as the basic unit, and have superior representation ability (Geng et al., 2019).\nWe train the mapping function by correctly distinguishing the predefined classes. First, we extract the feature of the queried word. Formally, given the training example (x, y) ∈ Dc, where x is composed of sentence S =< w1, w2, . . . , wn > and the queried word wj , we extract the j-th representation of the sequence output of the last layer of BERT as the hidden representation.\nh = fθ(x) (1)\nThen, following (Qi et al., 2018), we randomly initialize the prototype py of class y at the beginning of training, and then we shorten the distance between examples in class y to prototype py during training. Compared to traditional prototypical learning (Snell et al., 2017), we do not need to waste part of the examples for prototype calculation.\nd(x, py) = −fθ(x)T py (2)\nwhere fθ(x) and py are first normalized by L2 normalization.\nThe final optimization goal for training the mapping function is\nL(θ1) = −log exp(−d(x, py))∑\npc∈Pc exp(−d(x, pc)) (3)\nwhere Pc = {pc|c ∈ C} stands for the prototypes of all the predefined classes."
    }, {
      "heading" : "3.2.2 Step 2: Binary Group Classifier Training",
      "text" : "Recall that to detect multiple undefined classes, we need to find multiple example groups, and the examples in each group should have a tendency to cluster.\nTo handle the issue, we learn a binary group classifier on predefined classes. The main idea is that if we can determine whether any two examples belong to the same group, we can distinguish groups from each other. Formally, given a pair of examples (xi, yi) and (xj , yj) in Dc, their original position hi, hj from unlearned mapping function fθ(x), and after-training position h̃i, h̃j from learned mapping function f̃θ(x), the probability of xi and xj belonging to the same class is defined as follows:\nbij =W ([hi;hj ; h̃i; h̃j ; |hi − hj |; |h̃i − h̃j |; |hi − h̃i|; |hj − h̃j |]) + b\n(4)\nBy comparing the distance variation between original positions h and the after-training positions h̃, we can tell whether aggregation occurs between any of the two points.\nThe optimization goal of the binary group classifier is\nL(θ2) = 1\nN2 N∑ i N∑ j (−yij ∗ log(bij)\n+ (1− yij) ∗ log(1− bij)) (5)\nwhere N is the numbers of the examples in predefined classes, and yij is the label. If xi and xj are from the same predefined class (yi=yj), yij is 1, otherwise 0."
    }, {
      "heading" : "3.2.3 Step 3: Binary Group Classifier Inference",
      "text" : "After training, we feed each pair of examples xu and xv inDo to the binary group classifier to obtain the group dividing results. The output buv indicates the confidence that xu and xv belong to the same group. We set a threshold to divide the group. If buv is larger than the threshold γ, xu and xv shall belong to the same group (undefined class). If consecutive words belong to the same group, we will treat these words as one multi-word entity. Noted that some of the examples in O class may not belong to any group. We assume that these examples come from the task-irrelevant classes, and no further classification is made for these examples.\nSoft Labeling After the process of group dividing, we obtain labels of multiple undefined classes O = {o1, o2, . . . , or}. We further adopt the soft labeling mechanism. For each undefined class oi, we calculate the mean of the examples as the class center, then we apply softmax on the cosine similarity between examples and its class center as the soft labels. Through soft labeling, we can consider how likely examples belong to the undefined classes."
    }, {
      "heading" : "3.3 Joint Classification",
      "text" : "In the section, we take into consideration of both the predefined classes C and the found undefined classes O for joint classification. First, we label the examples in undefined classes back into the sentences, as shown in Joint Classification of Figure 2. Then, we optimize the examples to make them closer to the corresponding prototype for better discrimination. Comparing to the Equation 3, we add the prototypes from O class Po = {po1 , po2 , . . . , por} as candidate prototypes.\nFormally, given the examples (x, y) ∈ Dc ∪ Do, the corresponding prototype py and prototypes set P = Pc ∪ Po from both predefined classes C and undefined classes O, the optimization object is defined as:\nL(θ3) = −log exp(−d(x, py))∑\np∈{Pc∪Po} exp(−d(x, p)) (6)\nScale Factor When calculating d(x, py), the fθ(x) and py have been normalized and the value is limited to [-1, 1]. When softmax activation is applied, the output is unable to approach the one-hot encoding and therefore imposes a lower bound on the cross-entropy loss (Qi et al., 2018). For instance, even we give the golden prediction: giving 1 for correct category and -1 for the wrong ones, the probability of output p(y|x) = e1/[e1 + (|C ∪ T | − 1)e−1] is still unable to reach 1. The problem becomes more severe as we increase the number of named entity categories by introducing more categories for O class. To alleviate the issue, we modify Eq. 6 by adding a trainable scalar s shared across all classes to scale the inner product (Wang et al., 2017).\nL(θ3) = −log exp(−sd(x, py))∑\np∈{Pc∪Pt} exp(−sd(x, p)) (7)"
    }, {
      "heading" : "3.4 Implementation Details",
      "text" : "Following traditional prototypical network (Snell et al., 2017), we pre-train the model on several base classes, whose types are disjoint to few-shot classes and have abundant labeled corpus. The underlined idea is to leverage existing fully annotated classes to improve the performance of the model on new classes with only a few annotations. All predefined classes (both base classes and few-shot classes) are used when searching for undefined classes, so that the annotations of undefined classes can be shared between pre-training and fine-tuning, which will improve the transfer performance of our model."
    }, {
      "heading" : "4 Experiment",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We conduct experiments on multiple datasets to reduce the dataset bias, including three English benchmarks Conll2003 (Sang and De Meulder, 2003), re3d (Science and Laborator, 2017) and\nOntonote5.0 (Pradhan et al., 2013) and one Chinese benchmark CLUENER2020 (Xu et al., 2020). Conll2003 contains 20,679 labeled sentences, distributed in 4 classes in the News domains. The data in re3d comes from defense and security domain, with 10 classes and 962 labeled sentences. Ontonotes5.0 has 17 classes with 159,615 labeled sentences in mixed domains - News, BN, BC, Web and Tele. CLUENER2020 has 10 fined grained entity types with 12,091 annotated sentences. For all of the datasets, we adopt BIO (Beginning, Inside, and Outside) labeling, which introduces an extra O class for non-entity words."
    }, {
      "heading" : "4.2 Data Split",
      "text" : "We divided the classes of each benchmark into two parts: base classes and few-shot classes. The few-shot classes for Conll / re3d / Ontonote / CLUENER are Person / Person, Nationality, Weapon / Person, Language, Money, Percent, Norp / Game, Government, Name, Scene. The rest are the base classes. The division is based on the average word similarity among classes (mean similarity is reported in Appendix A). At each time, the class with the largest semantic difference from other classes is selected and added to the few-shot classes until the number of few-shot classes reaches 1/3 of the base classes. In this way, we can prevent the few-shot classes and base classes from being too similar, leading to information leakage. We do not follow previous methods (Hou et al., 2020) to adopt different datasets as base and few-shot classes, because there are overlapped classes in such data split, such as Person, which will reduce the difficulty of few-shot setting. For base classes, all examples are used to train the base classifier. For few-shot classes, only K examples are used for training, and the rest are used for testing. Alternatively, we adopt the N-way K-shot setting for fewshot classes, where N is the number of few-shot classes and K is the number of examples sampled from each few-shot class. K is set to 1 and 5 respectively in our experiment. Noted that we can not guarantee the number of the examples is exactly equal to K when sampling, because there will be multiple class labels in one sentence. Following (Fritzler et al., 2019), we ensure there are at least K labels for each few-shot class."
    }, {
      "heading" : "4.3 Evaluation Metrics",
      "text" : "Following (Hou et al., 2020), we measure the precision, recall, and macro-averaged F1 scores on all\nfew-shot classes. For fair comparison with baselines, as long as the found undefined class is classified as O class, it can be considered correct. We report the average on ten runs as the final results."
    }, {
      "heading" : "4.4 Hyperparameters",
      "text" : "For feature extraction, we adopt BERT-base as our backbone 1, which has 12-head attention layers and 768 hidden embedding dimension. For learning rate, we adopt greedy search in the range of 1e-6 to 2e-4. We set learning rage to 2e-5 when pretraining on base classes and 5e-6 when fine-tuning on few-shot classes. The threshold γ is set to 0.68 to ensure that the found undefined classes are sufficiently relevant to the predefined classes. The batch size is 128 and the maximum sequence length 128. We set the scale factor in Eq. 7 to 10 at the beginning. Our code is implemented by Tensorflow and all models can be fit into a single V100 GPU with 32G memory. The training procedure lasts for about a few hours. The best result appears around the 100 epochs of the training process."
    }, {
      "heading" : "4.5 Baselines",
      "text" : "We divide the baselines into two categories: 1) Supervised-Only Methods. BERT uses pre-trained BERT model to sequentially label words in sentence (Devlin et al., 2018). Prototypical network (PN) learns a metric space for each class (Snell et al., 2017). Both of the methods are only trained on the few-shot classes. 2) Few-shot Methods. LTapNet+CDT (LTC) uses semantic associations between base and few-shot classes to improve the prototype quality, which is only trained on base classes (Hou et al., 2020). We use the original published code 2. Warm Prototypical Network (WPN) (Fritzler et al., 2019) is the transfer learning version of PN, which is first pre-trained on base classes and then fine-tuned on few-shot classes. MAML first learns fast-adapted parameters on base classes and then fine-tune the parameters on few-shot classes (Finn et al., 2017)."
    }, {
      "heading" : "4.6 Overall Performance",
      "text" : "Table 1 and 2 present the overall performance of the proposed approach on four NER benchmarks - Conll2003, re3d, Ontonote5.0 and CLUENER2020. MUCO (ours) consistently outperforms state-ofthe-art models, showing the effectiveness of ex-\n1https://github.com/google-research/bert 2https://github.com/AtmaHou/FewShotTagging\nploiting the rich semantics in O class and the superiority of the proposed MUCO model.\nCompared with supervised-only methods (BERT and PN), few-shot methods (TransferBERT, WPN, MAML, L-TapNet+CDT and MUCO(ours)) achieve better performance. By first training on base classes, these methods will learn a prior, which prevents from overfitting densely labeled words. Among few-shot methods, our model achieves the best performance. Previous methods regard O class as a single class. On the contrary, we induce different undefined classes from O class, and add more task-related classes for joint training, which directly handles the dilemma of scarcity of data in few-shot learning and provides stand-by semantics to identify and disambiguate named entity, thereby improving the performance of few-shot NER. No matter English corpus (the first three) or Chinese corpus (the last one), our methods consistently improves the F score, showing the language-independent superiority of our method. Task-agnostic superiority also shows in section 4.10. Our undefined classes detection method is completely data-driven. The found undefined classes will be automatically adjusted to be useful and task-related based on current language or task predefined classes.\nTo further evaluate our core module undefined classes detection in section 3.2, we introduce a Word-Similarity (WS) baseline. WS detects undefined classes by performing KMeans (Kanungo et al., 2002) in O words based on word similarity.\nTo be fair, WS, like our method, uses soft-label enhancement (section 3.2.2). We report the final few-shot NER performance on Ontonote for comparison.\nAs shown in Figure 3, our method achieves better performance, which shows the superior of our undefined classes detection module. Word similarity baseline only uses semantics of words and lacks weak supervision from predefined classes, so that noisy classes (such as punctuation) cannot be distinguished from task-related ones, which inevitably reduces the quality of undefined classes."
    }, {
      "heading" : "4.7 Quality of Found Undefined Classes",
      "text" : "In the section, we evaluate the quality of the found undefined classes from quantitative and qualitative perspective. All the following experiments are conducted on Ontonote5.0.\nFor quantitative analysis, we invite three computer engineers to manually label 100 sentences for human evaluation. The metrics are Intra-class Correlation (IC) and Inter-class Distinction (ID). The IC statistics how many labels actually belong\nto the declared class. The ID counts how many labels belong to only one of the undefined classes, not to multiple classes. We obtain golden labels by applying the majority vote rule. Table 3 reports the average results on undefined classes.\nConsidering the zero-shot setting, the accuracy of 49.15% and 50.85% is high enough, which indicates that the found undefined classes basically have semantic consistency within the classes and semantic difference between classes.\nFor qualitative analysis, we illustrate a case study in Table 4. The words in O1, O2 and O3 are mainly the general entity versions of Person, Location and Numerous respectively. According to the grammatical rules, general entities and named entities can be substituted for each other, Lincoln can also be called president, so identifying general entities can provide additional location knowledge and enhance named entity identification. The words in O4 and O5 are mainly Action, which may imply relations between different named entities and provide important evidence for named entity disambiguation (Tong et al., 2020). The errors mainly come from three aspects: 1) The surrounding words are incorrectly included, such as from in businessmen from in O1; 2) Some strange words reduce intra-class consistency, such as was at the tail in O3; 3) There is semantic overlap between classes, such as O4 and O5. Future work will explore how to improve the quality of the undefined classes."
    }, {
      "heading" : "4.8 Different Number of Undefined Classes",
      "text" : "Since our model needs to manually set the number of undefined classes, we observe the performance of the model under different number settings. We set the number of undefined classes to 1/2/5/10/25/50 by adjusting the threshold γ.\nFigure 4 illustrates the F score of MUCO (ours) on various numbers of undefined classes. It will\nimpair the performance when the number is too large or too small. When the number is too large, the found classes will have overlapping problems, resulting in severe performance degradation (- 11.51%). When the number is too small, the model is unable to find enough task-related classes, limiting the ability to capture the fine-grained semantics in O class. Empirical experiments found that when the number of undefined classes is approximately equal to the number of few-shot classes, our method achieves the best performance (the number is 5 in Figure 4). We argue that the number of predefined classes is proportional to the amount of information hidden in weak supervision. Therefore, with more predefined classes, we can also find more high-quality undefined classes."
    }, {
      "heading" : "4.9 Cross-Domain Ability",
      "text" : "In this section, we answer whether our model could achieve superior performance facing the discrepancy of different domains. To simulate a domain adaption scenario, we choose the benchmark Conll2003 (Sang and De Meulder, 2003) as the source domain and AnEM (Ohta et al., 2012) as the target domain. The entity types in AnEM, such as Pathological-Formation, are all medical academic terms and can ensure the discrepancy to common classes in Conll2003.\nAs illustrated in Table 5, our method achieves the best adaptation performance on the target domain. All the predefined classes, both in source domains and target domains, are used when detection undefined classes. The annotations of undefined classes can be shared between pre-training and fine-tuning, which will improve the transfer performance of our model."
    }, {
      "heading" : "4.10 Task-Agnostic Ability",
      "text" : "In this section, we answer whether our assumption of O class is task-agnostic and effective for few-shot token-level classification tasks other than NER. We conduct experiments on two tasks of widespread concern: Slot Tagging (Hou et al., 2020) and Event Argument Extraction (Ahn, 2006). Slot Tagging aims to discover user intent from task-\noriented dialogue system. We adopt Snips dataset (Coucke et al., 2018) for Slot Tagging, and the split of train/test is We,Mu,Pl,Bo,Se/Re,Cr. Event Argument Extraction aims to extract the main elements of event from sentences. We adopt the ACE2005 dataset 3 with 33 classes and 6 domains. The train/test is bc,bn,cts,nw/un,wl.\nAs illustrated in Table 6, the proposed model achieves superior performance on both tasks, which demonstrates the generalization ability of our method. No matter what task the predefined class belongs to, our method is always able to mine the task-related classes from the O class to help eliminate the ambiguity of the predefined class. The reason is that our detection method is entirely datadriven, and does not rely on manually writing undefined class descriptions. The found category will automatically change according to the task type of the entered predefined classes. Therefore, the migration cost between tasks of our method is meager."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we propose Mining Undefined Classes from Other-class (MUCO) to utilize the rich semantics in O class to improve few-shot NER. Specifically, we first leverage weakly supervised signals from predefined classes to detect undefined classes from O classes. Then, we perform joint classification to exploit the stand-by semantic knowl-\n3http://projects.ldc.upenn.edu/ace/\nedge in undefined classes to enhance the understanding of few-shot classes. Experiments show that our method outperforms five state-of-the-art baselines on four benchmarks."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work is supported by the National Key Research and Development Program of China (2018YFB1005100 and 2018YFB1005101) and NSFC Key Project (U1736204). This work is supported by National Engineering Laboratory for Cyberlearning and Intelligent Technology, Beijing Key Lab of Networked Multimedia and the Institute for Guo Qiang, Tsinghua University (2019GQB0003). This research was conducted in collaboration with SenseTime. This work is partially supported by A*STAR through the Industry Alignment Fund - Industry Collaboration Projects Grant, by NTU (NTU–ACE2020-01) and Ministry of Education (RG96/20)."
    }, {
      "heading" : "A Data Split",
      "text" : "We divided the classes of each benchmark into two parts: base classes and few-shot classes. The division is based on the average word similarity among classes. At each time, the class with the largest semantic difference from other classes is selected and added to the few-shot classes until the number of few-shot classes reaches 1/3 of the base classes. In this way, we can prevent the few-shot classes\nand base classes from being too similar, causing information leakage. The embedding of words are extracted from BERT, and the mean similarity is reported in Table 7."
    } ],
    "references" : [ {
      "title" : "The stages of event extraction",
      "author" : [ "David Ahn." ],
      "venue" : "Proceedings of the Workshop on Annotating and Reasoning about Time and Events, pages 1–8.",
      "citeRegEx" : "Ahn.,? 2006",
      "shortCiteRegEx" : "Ahn.",
      "year" : 2006
    }, {
      "title" : "Low-resource name tagging learned with weakly labeled data",
      "author" : [ "Yixin Cao", "Zikun Hu", "Tat-seng Chua", "Zhiyuan Liu", "Heng Ji." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Cao et al\\.,? 2019",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2019
    }, {
      "title" : "Snips voice platform: an embedded spoken language understanding",
      "author" : [ "Alice Coucke", "Alaa Saade", "Adrien Ball", "Théodore Bluche", "Alexandre Caulier", "David Leroy", "Clément Doumouro", "Thibault Gisselbrecht", "Francesco Caltagirone", "Thibaut Lavril" ],
      "venue" : null,
      "citeRegEx" : "Coucke et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Coucke et al\\.",
      "year" : 2018
    }, {
      "title" : "Metalearning with dynamic-memory-based prototypical network for few-shot event detection",
      "author" : [ "Shumin Deng", "Ningyu Zhang", "Jiaojian Kang", "Yichi Zhang", "Wei Zhang", "Huajun Chen." ],
      "venue" : "Proceedings of the 13th International Conference on Web",
      "citeRegEx" : "Deng et al\\.,? 2020",
      "shortCiteRegEx" : "Deng et al\\.",
      "year" : 2020
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Improving low resource named entity recognition using cross-lingual knowledge transfer",
      "author" : [ "Xiaocheng Feng", "Xiachong Feng", "Bing Qin", "Zhangyin Feng", "Ting Liu." ],
      "venue" : "IJCAI, pages 4071–4077.",
      "citeRegEx" : "Feng et al\\.,? 2018",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2018
    }, {
      "title" : "Model-agnostic meta-learning for fast adaptation of deep networks",
      "author" : [ "Chelsea Finn", "Pieter Abbeel", "Sergey Levine." ],
      "venue" : "International Conference on Machine Learning, pages 1126–1135. PMLR.",
      "citeRegEx" : "Finn et al\\.,? 2017",
      "shortCiteRegEx" : "Finn et al\\.",
      "year" : 2017
    }, {
      "title" : "Swellshark: A generative model for biomedical named entity recognition without labeled data",
      "author" : [ "Jason Fries", "Sen Wu", "Alex Ratner", "Christopher Ré." ],
      "venue" : "arXiv preprint arXiv:1704.06360.",
      "citeRegEx" : "Fries et al\\.,? 2017",
      "shortCiteRegEx" : "Fries et al\\.",
      "year" : 2017
    }, {
      "title" : "Few-shot classification in named entity recognition task",
      "author" : [ "Alexander Fritzler", "Varvara Logacheva", "Maksim Kretov." ],
      "venue" : "Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, pages 993–1000.",
      "citeRegEx" : "Fritzler et al\\.,? 2019",
      "shortCiteRegEx" : "Fritzler et al\\.",
      "year" : 2019
    }, {
      "title" : "Hybrid attention-based prototypical networks for noisy few-shot relation classification",
      "author" : [ "Tianyu Gao", "Xu Han", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6407–6414.",
      "citeRegEx" : "Gao et al\\.,? 2019",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Few-shot text classification with induction network",
      "author" : [ "Ruiying Geng", "Binhua Li", "Yongbin Li", "Yuxiao Ye", "Ping Jian", "Jian Sun." ],
      "venue" : "arXiv preprint arXiv:1902.10482.",
      "citeRegEx" : "Geng et al\\.,? 2019",
      "shortCiteRegEx" : "Geng et al\\.",
      "year" : 2019
    }, {
      "title" : "Feature based approach to named entity recognition and linking for tweets",
      "author" : [ "Souvick Ghosh", "Promita Maitra", "Dipankar Das" ],
      "venue" : null,
      "citeRegEx" : "Ghosh et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Ghosh et al\\.",
      "year" : 2016
    }, {
      "title" : "Fewshot slot tagging with collapsed dependency transfer and label-enhanced task-adaptive projection network",
      "author" : [ "Yutai Hou", "Wanxiang Che", "Yongkui Lai", "Zhihan Zhou", "Yijia Liu", "Han Liu", "Ting Liu." ],
      "venue" : "arXiv preprint arXiv:2006.05702.",
      "citeRegEx" : "Hou et al\\.,? 2020",
      "shortCiteRegEx" : "Hou et al\\.",
      "year" : 2020
    }, {
      "title" : "Zero-shot transfer learning for event extraction",
      "author" : [ "Lifu Huang", "Heng Ji", "Kyunghyun Cho", "Clare R Voss." ],
      "venue" : "arXiv preprint arXiv:1707.01066.",
      "citeRegEx" : "Huang et al\\.,? 2017",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2017
    }, {
      "title" : "An efficient k-means clustering algorithm: Analysis and implementation",
      "author" : [ "Tapas Kanungo", "David M Mount", "Nathan S Netanyahu", "Christine D Piatko", "Ruth Silverman", "Angela Y Wu." ],
      "venue" : "IEEE transactions on pattern analysis and machine intelligence,",
      "citeRegEx" : "Kanungo et al\\.,? 2002",
      "shortCiteRegEx" : "Kanungo et al\\.",
      "year" : 2002
    }, {
      "title" : "The structure of a semantic theory",
      "author" : [ "Jerrold J Katz", "Jerry A Fodor." ],
      "venue" : "language, 39(2):170–210.",
      "citeRegEx" : "Katz and Fodor.,? 1963",
      "shortCiteRegEx" : "Katz and Fodor.",
      "year" : 1963
    }, {
      "title" : "Siamese neural networks for one-shot image recognition",
      "author" : [ "Gregory Koch", "Richard Zemel", "Ruslan Salakhutdinov." ],
      "venue" : "ICML deep learning workshop, volume 2. Lille.",
      "citeRegEx" : "Koch et al\\.,? 2015",
      "shortCiteRegEx" : "Koch et al\\.",
      "year" : 2015
    }, {
      "title" : "Human-level concept learning through probabilistic program induction",
      "author" : [ "Brenden M Lake", "Ruslan Salakhutdinov", "Joshua B Tenenbaum." ],
      "venue" : "Science, 350(6266):1332–1338.",
      "citeRegEx" : "Lake et al\\.,? 2015",
      "shortCiteRegEx" : "Lake et al\\.",
      "year" : 2015
    }, {
      "title" : "Neural architectures for named entity recognition",
      "author" : [ "Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Lample et al\\.,? 2016",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2016
    }, {
      "title" : "Dice loss for data-imbalanced nlp tasks",
      "author" : [ "Xiaoya Li", "Xiaofei Sun", "Yuxian Meng", "Junjun Liang", "Fei Wu", "Jiwei Li." ],
      "venue" : "arXiv preprint arXiv:1911.02855.",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Label embedding for zero-shot fine-grained named entity typing",
      "author" : [ "Yukun Ma", "Erik Cambria", "Sa Gao." ],
      "venue" : "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 171–180.",
      "citeRegEx" : "Ma et al\\.,? 2016",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2016
    }, {
      "title" : "Open-domain anatomical entity mention detection",
      "author" : [ "Tomoko Ohta", "Sampo Pyysalo", "Jun’ichi Tsujii", "Sophia Ananiadou" ],
      "venue" : "In Proceedings of the workshop on detecting structure in scholarly discourse,",
      "citeRegEx" : "Ohta et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Ohta et al\\.",
      "year" : 2012
    }, {
      "title" : "Towards robust linguistic analysis using ontonotes",
      "author" : [ "Sameer Pradhan", "Alessandro Moschitti", "Nianwen Xue", "Hwee Tou Ng", "Anders Björkelund", "Olga Uryupina", "Yuchen Zhang", "Zhi Zhong." ],
      "venue" : "Proceedings of the Seventeenth Conference on Computa-",
      "citeRegEx" : "Pradhan et al\\.,? 2013",
      "shortCiteRegEx" : "Pradhan et al\\.",
      "year" : 2013
    }, {
      "title" : "Train once, test anywhere: Zero-shot learning for text classification",
      "author" : [ "Pushpankar Kumar Pushp", "Muktabh Mayank Srivastava." ],
      "venue" : "CoRR, abs/1712.05972.",
      "citeRegEx" : "Pushp and Srivastava.,? 2017",
      "shortCiteRegEx" : "Pushp and Srivastava.",
      "year" : 2017
    }, {
      "title" : "Low-shot learning with imprinted weights",
      "author" : [ "Hang Qi", "Matthew Brown", "David G Lowe." ],
      "venue" : "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5822–5830.",
      "citeRegEx" : "Qi et al\\.,? 2018",
      "shortCiteRegEx" : "Qi et al\\.",
      "year" : 2018
    }, {
      "title" : "Massively multilingual transfer for ner",
      "author" : [ "Afshin Rahimi", "Yuan Li", "Trevor Cohn." ],
      "venue" : "arXiv preprint arXiv:1902.00193.",
      "citeRegEx" : "Rahimi et al\\.,? 2019",
      "shortCiteRegEx" : "Rahimi et al\\.",
      "year" : 2019
    }, {
      "title" : "Introduction to the conll-2003 shared task: Languageindependent named entity recognition",
      "author" : [ "Erik F Sang", "Fien De Meulder." ],
      "venue" : "arXiv preprint cs/0306050.",
      "citeRegEx" : "Sang and Meulder.,? 2003",
      "shortCiteRegEx" : "Sang and Meulder.",
      "year" : 2003
    }, {
      "title" : "Prototypical networks for few-shot learning",
      "author" : [ "Jake Snell", "Kevin Swersky", "Richard Zemel." ],
      "venue" : "Advances in neural information processing systems, pages 4077–4087.",
      "citeRegEx" : "Snell et al\\.,? 2017",
      "shortCiteRegEx" : "Snell et al\\.",
      "year" : 2017
    }, {
      "title" : "Hierarchical attention prototypical networks for few-shot text classification",
      "author" : [ "Shengli Sun", "Qingfeng Sun", "Kevin Zhou", "Tengchao Lv." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th Inter-",
      "citeRegEx" : "Sun et al\\.,? 2019",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Improving low-resource chinese event detection with multi-task learning",
      "author" : [ "Meihan Tong", "Bin Xu", "Shuai Wang", "Lei Hou", "Juaizi Li." ],
      "venue" : "International Conference on Knowledge Science, Engineering and Management, pages 421–433. Springer.",
      "citeRegEx" : "Tong et al\\.,? 2020",
      "shortCiteRegEx" : "Tong et al\\.",
      "year" : 2020
    }, {
      "title" : "Improving one-shot learning through fusing side information",
      "author" : [ "Yao-Hung Hubert Tsai", "Ruslan Salakhutdinov." ],
      "venue" : "arXiv preprint arXiv:1710.08347.",
      "citeRegEx" : "Tsai and Salakhutdinov.,? 2017",
      "shortCiteRegEx" : "Tsai and Salakhutdinov.",
      "year" : 2017
    }, {
      "title" : "Normface: L2 hypersphere embedding for face verification",
      "author" : [ "Feng Wang", "Xiang Xiang", "Jian Cheng", "Alan Loddon Yuille." ],
      "venue" : "Proceedings of the 25th ACM international conference on Multimedia, pages 1041–1049.",
      "citeRegEx" : "Wang et al\\.,? 2017",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2017
    }, {
      "title" : "Labelaware double transfer learning for cross-specialty medical named entity recognition",
      "author" : [ "Zhenghui Wang", "Yanru Qu", "Liheng Chen", "Jian Shen", "Weinan Zhang", "Shaodian Zhang", "Yimei Gao", "Gen Gu", "Ken Chen", "Yong Yu." ],
      "venue" : "arXiv preprint",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Cost-aware active learning for named entity recognition in clinical text",
      "author" : [ "Qiang Wei", "Yukun Chen", "Mandana Salimi", "Joshua C Denny", "Qiaozhu Mei", "Thomas A Lasko", "Qingxia Chen", "Stephen Wu", "Amy Franklin", "Trevor Cohen" ],
      "venue" : null,
      "citeRegEx" : "Wei et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2019
    }, {
      "title" : "Cluener2020: Fine-grained named entity recognition dataset and benchmark for chinese. arXiv, pages arXiv–2001",
      "author" : [ "Liang Xu", "Qianqian Dong", "Yixuan Liao", "Cong Yu", "Yin Tian", "Weitang Liu", "Lu Li", "Caiquan Liu", "Xuanwei Zhang" ],
      "venue" : null,
      "citeRegEx" : "Xu et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "A survey on recent advances in named entity recognition from deep learning models",
      "author" : [ "Vikas Yadav", "Steven Bethard." ],
      "venue" : "arXiv preprint arXiv:1910.11470.",
      "citeRegEx" : "Yadav and Bethard.,? 2019",
      "shortCiteRegEx" : "Yadav and Bethard.",
      "year" : 2019
    }, {
      "title" : "Joint extraction of entities and relations based on a novel tagging scheme",
      "author" : [ "Suncong Zheng", "Feng Wang", "Hongyun Bao", "Yuexing Hao", "Peng Zhou", "Bo Xu." ],
      "venue" : "arXiv preprint arXiv:1706.05075.",
      "citeRegEx" : "Zheng et al\\.,? 2017",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2017
    }, {
      "title" : "Dual adversarial neural transfer for low-resource named entity recognition",
      "author" : [ "Joey Tianyi Zhou", "Hao Zhang", "Di Jin", "Hongyuan Zhu", "Meng Fang", "Rick Siow Mong Goh", "Kenneth Kwok." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association",
      "citeRegEx" : "Zhou et al\\.,? 2019",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 35,
      "context" : "Named Entity Recognition (NER) seeks to locate and classify named entities from sentences into predefined classes (Yadav and Bethard, 2019).",
      "startOffset" : 114,
      "endOffset" : 139
    }, {
      "referenceID" : 17,
      "context" : "Humans can immediately recognize new entity types given just one or a few examples(Lake et al., 2015).",
      "startOffset" : 82,
      "endOffset" : 101
    }, {
      "referenceID" : 19,
      "context" : "Although neural NER networks have achieved superior performance when provided large-scale of training examples (Li et al., 2019), it remains a non-trivial task to learn from limited new samples, also known as few-shot NER (Fritzler et al.",
      "startOffset" : 111,
      "endOffset" : 128
    }, {
      "referenceID" : 8,
      "context" : ", 2019), it remains a non-trivial task to learn from limited new samples, also known as few-shot NER (Fritzler et al., 2019).",
      "startOffset" : 101,
      "endOffset" : 124
    }, {
      "referenceID" : 18,
      "context" : "Traditional NER models, such as LSTM+CRF (Lample et al., 2016), fail in few-shot settings.",
      "startOffset" : 41,
      "endOffset" : 62
    }, {
      "referenceID" : 27,
      "context" : "network (Snell et al., 2017) shows potential on fewshot NER.",
      "startOffset" : 8,
      "endOffset" : 28
    }, {
      "referenceID" : 8,
      "context" : "The basic idea is to learn prototypes for each predefined entity class and an other class, then classify examples based on which prototypes they are closest to (Fritzler et al., 2019).",
      "startOffset" : 160,
      "endOffset" : 183
    }, {
      "referenceID" : 12,
      "context" : "age the label semantic to reveal their dependency for enhancement (Hou et al., 2020).",
      "startOffset" : 66,
      "endOffset" : 84
    }, {
      "referenceID" : 15,
      "context" : "As shown in Figure 1(a), if we can detect an undefined class consisting of references to named entities (such as pronouns), then due to their interchangeability (Katz and Fodor, 1963), we will obtain prior knowledge for named entity identification.",
      "startOffset" : 161,
      "endOffset" : 183
    }, {
      "referenceID" : 11,
      "context" : "6237 ture underlined relations between different named entities, which is important evidence when distinguishing the named entity type (Ghosh et al., 2016; Zheng et al., 2017).",
      "startOffset" : 135,
      "endOffset" : 175
    }, {
      "referenceID" : 36,
      "context" : "6237 ture underlined relations between different named entities, which is important evidence when distinguishing the named entity type (Ghosh et al., 2016; Zheng et al., 2017).",
      "startOffset" : 135,
      "endOffset" : 175
    }, {
      "referenceID" : 23,
      "context" : "The zero-shot methods (Pushp and Srivastava, 2017) fail in this case, since they need metadata (such as class name and class description) as known information.",
      "startOffset" : 22,
      "endOffset" : 50
    }, {
      "referenceID" : 16,
      "context" : "The underlined reason is that if two classes (A and B) are task-related, when we make examples in A class to cluster in the space, the examples in B class also tend to cluster in the space, even without explicit supervision on class B (Koch et al., 2015).",
      "startOffset" : 235,
      "endOffset" : 254
    }, {
      "referenceID" : 5,
      "context" : "Few-shot NER aims to recognize new categories with just a handful of examples (Feng et al., 2018; Cao et al., 2019).",
      "startOffset" : 78,
      "endOffset" : 115
    }, {
      "referenceID" : 1,
      "context" : "Few-shot NER aims to recognize new categories with just a handful of examples (Feng et al., 2018; Cao et al., 2019).",
      "startOffset" : 78,
      "endOffset" : 115
    }, {
      "referenceID" : 7,
      "context" : "Knowledgeenhanced methods exploit ontology, knowledge bases or heuristics labeling (Fries et al., 2017; Tsai and Salakhutdinov, 2017; Ma et al., 2016) as side information to improve NER performance in limited data settings, which suffer from knowledge low-coverage issue.",
      "startOffset" : 83,
      "endOffset" : 150
    }, {
      "referenceID" : 30,
      "context" : "Knowledgeenhanced methods exploit ontology, knowledge bases or heuristics labeling (Fries et al., 2017; Tsai and Salakhutdinov, 2017; Ma et al., 2016) as side information to improve NER performance in limited data settings, which suffer from knowledge low-coverage issue.",
      "startOffset" : 83,
      "endOffset" : 150
    }, {
      "referenceID" : 20,
      "context" : "Knowledgeenhanced methods exploit ontology, knowledge bases or heuristics labeling (Fries et al., 2017; Tsai and Salakhutdinov, 2017; Ma et al., 2016) as side information to improve NER performance in limited data settings, which suffer from knowledge low-coverage issue.",
      "startOffset" : 83,
      "endOffset" : 150
    }, {
      "referenceID" : 5,
      "context" : "Cross-lingual (Feng et al., 2018; Rahimi et al., 2019) and cross-domain enhanced methods (Wang et al.",
      "startOffset" : 14,
      "endOffset" : 54
    }, {
      "referenceID" : 25,
      "context" : "Cross-lingual (Feng et al., 2018; Rahimi et al., 2019) and cross-domain enhanced methods (Wang et al.",
      "startOffset" : 14,
      "endOffset" : 54
    }, {
      "referenceID" : 32,
      "context" : ", 2019) and cross-domain enhanced methods (Wang et al., 2018; Zhou et al., 2019) respectively use labeled data from a counterpart language or a different domain as external supervised signals to avoid overfitting.",
      "startOffset" : 42,
      "endOffset" : 80
    }, {
      "referenceID" : 37,
      "context" : ", 2019) and cross-domain enhanced methods (Wang et al., 2018; Zhou et al., 2019) respectively use labeled data from a counterpart language or a different domain as external supervised signals to avoid overfitting.",
      "startOffset" : 42,
      "endOffset" : 80
    }, {
      "referenceID" : 13,
      "context" : "When the language or domain discrepancy is large, these two methods will inevitably face the problem of performance degradation (Huang et al., 2017).",
      "startOffset" : 128,
      "endOffset" : 148
    }, {
      "referenceID" : 33,
      "context" : "Active learning methods (Wei et al., 2019) explicitly expand corpus by selecting the most informative examples for manual annotation, which need extra human-laboring.",
      "startOffset" : 24,
      "endOffset" : 42
    }, {
      "referenceID" : 27,
      "context" : "Prototypical network (Snell et al., 2017), initially proposed for image classification, has been successfully applied to sentence-level classification tasks, such as text classification (Sun et al.",
      "startOffset" : 21,
      "endOffset" : 41
    }, {
      "referenceID" : 28,
      "context" : ", 2017), initially proposed for image classification, has been successfully applied to sentence-level classification tasks, such as text classification (Sun et al., 2019) and relation extraction (Gao et al.",
      "startOffset" : 152,
      "endOffset" : 170
    }, {
      "referenceID" : 16,
      "context" : "examples in predefined classes to cluster in the space, the examples in the undefined class should also have the signs of gathering, even without explicit supervision (Koch et al., 2015).",
      "startOffset" : 167,
      "endOffset" : 186
    }, {
      "referenceID" : 10,
      "context" : "BERT is adopted as the mapping function in our model, which is a pre-trained language representation model that employs multi-head attention as the basic unit, and have superior representation ability (Geng et al., 2019).",
      "startOffset" : 201,
      "endOffset" : 220
    }, {
      "referenceID" : 24,
      "context" : "Then, following (Qi et al., 2018), we randomly initialize the prototype py of class y at the beginning of training, and then we shorten the distance between examples in class y to prototype py during training.",
      "startOffset" : 16,
      "endOffset" : 33
    }, {
      "referenceID" : 27,
      "context" : "Compared to traditional prototypical learning (Snell et al., 2017), we do not need to waste part of the examples for prototype calculation.",
      "startOffset" : 46,
      "endOffset" : 66
    }, {
      "referenceID" : 24,
      "context" : "When softmax activation is applied, the output is unable to approach the one-hot encoding and therefore imposes a lower bound on the cross-entropy loss (Qi et al., 2018).",
      "startOffset" : 152,
      "endOffset" : 169
    }, {
      "referenceID" : 31,
      "context" : "6 by adding a trainable scalar s shared across all classes to scale the inner product (Wang et al., 2017).",
      "startOffset" : 86,
      "endOffset" : 105
    }, {
      "referenceID" : 27,
      "context" : "Following traditional prototypical network (Snell et al., 2017), we pre-train the model on several base classes, whose types are disjoint to few-shot classes and have abundant labeled corpus.",
      "startOffset" : 43,
      "endOffset" : 63
    }, {
      "referenceID" : 22,
      "context" : "0 (Pradhan et al., 2013) and one Chinese benchmark CLUENER2020 (Xu et al.",
      "startOffset" : 2,
      "endOffset" : 24
    }, {
      "referenceID" : 34,
      "context" : ", 2013) and one Chinese benchmark CLUENER2020 (Xu et al., 2020).",
      "startOffset" : 46,
      "endOffset" : 63
    }, {
      "referenceID" : 12,
      "context" : "We do not follow previous methods (Hou et al., 2020) to adopt different datasets as base and few-shot classes, because there are overlapped classes in such data split, such as Person, which will reduce the difficulty of few-shot setting.",
      "startOffset" : 34,
      "endOffset" : 52
    }, {
      "referenceID" : 8,
      "context" : "Following (Fritzler et al., 2019), we ensure there are at least K labels for each few-shot class.",
      "startOffset" : 10,
      "endOffset" : 33
    }, {
      "referenceID" : 12,
      "context" : "Following (Hou et al., 2020), we measure the precision, recall, and macro-averaged F1 scores on all few-shot classes.",
      "startOffset" : 10,
      "endOffset" : 28
    }, {
      "referenceID" : 4,
      "context" : "BERT uses pre-trained BERT model to sequentially label words in sentence (Devlin et al., 2018).",
      "startOffset" : 73,
      "endOffset" : 94
    }, {
      "referenceID" : 27,
      "context" : "Prototypical network (PN) learns a metric space for each class (Snell et al., 2017).",
      "startOffset" : 63,
      "endOffset" : 83
    }, {
      "referenceID" : 12,
      "context" : "LTapNet+CDT (LTC) uses semantic associations between base and few-shot classes to improve the prototype quality, which is only trained on base classes (Hou et al., 2020).",
      "startOffset" : 151,
      "endOffset" : 169
    }, {
      "referenceID" : 8,
      "context" : "Warm Prototypical Network (WPN) (Fritzler et al., 2019) is the transfer learning version of PN, which is first pre-trained on base classes and then fine-tuned on few-shot classes.",
      "startOffset" : 32,
      "endOffset" : 55
    }, {
      "referenceID" : 6,
      "context" : "MAML first learns fast-adapted parameters on base classes and then fine-tune the parameters on few-shot classes (Finn et al., 2017).",
      "startOffset" : 112,
      "endOffset" : 131
    }, {
      "referenceID" : 14,
      "context" : "WS detects undefined classes by performing KMeans (Kanungo et al., 2002) in O words based on word similarity.",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 29,
      "context" : "The words in O4 and O5 are mainly Action, which may imply relations between different named entities and provide important evidence for named entity disambiguation (Tong et al., 2020).",
      "startOffset" : 164,
      "endOffset" : 183
    }, {
      "referenceID" : 21,
      "context" : "To simulate a domain adaption scenario, we choose the benchmark Conll2003 (Sang and De Meulder, 2003) as the source domain and AnEM (Ohta et al., 2012) as the target domain.",
      "startOffset" : 132,
      "endOffset" : 151
    }, {
      "referenceID" : 12,
      "context" : "We conduct experiments on two tasks of widespread concern: Slot Tagging (Hou et al., 2020) and Event Argument Extraction (Ahn, 2006).",
      "startOffset" : 72,
      "endOffset" : 90
    }, {
      "referenceID" : 0,
      "context" : ", 2020) and Event Argument Extraction (Ahn, 2006).",
      "startOffset" : 38,
      "endOffset" : 49
    }, {
      "referenceID" : 2,
      "context" : "We adopt Snips dataset (Coucke et al., 2018) for Slot Tagging, and the split of train/test is We,Mu,Pl,Bo,Se/Re,Cr.",
      "startOffset" : 23,
      "endOffset" : 44
    } ],
    "year" : 2021,
    "abstractText" : "Few-shot Named Entity Recognition (NER) exploits only a handful of annotations to identify and classify named entity mentions. Prototypical network shows superior performance on few-shot NER. However, existing prototypical methods fail to differentiate rich semantics in other-class words, which will aggravate overfitting under few shot scenario. To address the issue, we propose a novel model, Mining Undefined Classes from Other-class (MUCO), that can automatically induce different undefined classes from the other class to improve few-shot NER. With these extra-labeled undefined classes, our method will improve the discriminative ability of NER classifier and enhance the understanding of predefined classes with stand-by semantic knowledge. Experimental results demonstrate that our model outperforms five state-of-the-art models in both 1shot and 5-shots settings on four NER benchmarks. We will release the code upon acceptance. The source code is released on https: //github.com/shuaiwa16/OtherClassNER.git.",
    "creator" : "LaTeX with hyperref"
  }
}