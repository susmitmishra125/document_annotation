{
  "name" : "2021.acl-long.423.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "HieRec: Hierarchical User Interest Modeling for Personalized News Recommendation",
    "authors" : [ "Tao Qi", "Fangzhao Wu", "Chuhan Wu", "Peiru Yang", "Yang Yu", "Xing Xie", "Yongfeng Huang" ],
    "emails" : [ "peiruyang17}@gmail.com", "yfhuang@mail.tsinghua.edu.cn", "t-yyu@microsoft.com", "xing.xie@microsoft.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5446–5456\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n5446"
    }, {
      "heading" : "1 Introduction",
      "text" : "Recently, massive people are habituated to reading news articles on online news platforms, such as Google News and Microsoft News (Khattar et al., 2018; Das et al., 2007). To help users efficiently obtain their interested news information, personalized news recommendation technique that aims to recommend news according to user interests, is widely used by these platforms (Wu et al., 2020a; Liu et al., 2010; Lin et al., 2014).\nUser interest modeling is a critical step for personalized news recommendation (Wu et al., 2021; Zheng et al., 2018; Wu et al., 2020c). Existing methods usually learn a single representation vector\nto model overall user interests from users’ clicked news (Okura et al., 2017; Wu et al., 2020b; An et al., 2019). For example, Okura et al. (2017) used a GRU network to model user interests from clicked news. They used the latest hidden state of GRU as the user interest representation. Wu et al. (2019e) used multi-head self-attention network to capture user interests, and used an attentive pooling network to obtain a unified user representation. However, user interest is usually diverse and multigrained. For example, as shown in Fig. 1, a user may have interest in movies, sports, finance and health at the same time. In addition, for users who are interested in sports, some of them may have general interest in this area, while other users like the example user in Fig. 1 may only have interest in a specific sport like football. However, it is difficult for these methods to accurately model the diverse and multi-grained user interest for news recommendation via a single user embedding.\nIn this paper, we propose a personalized news recommendation approach with hierarchical user interest modeling, named HieRec, which can effectively capture the diverse and multi-grained user interest. Our approach contains three levels of user interest representations to model user interests in different aspects and granularities. The first one is subtopic-level, which contains multiple interest representations to model fine-grained user interests in different news subtopics (e.g., interest in football and golf). They are learned from embeddings of subtopics and the clicked news in the correspond-\ning subtopics. The second one is topic-level, which contains multiple interest representations to capture coarse-grained user interests in major news topics (e.g., interest in sports and finance). They are learned from embeddings of news topics and their subordinate subtopic-level interest representations. The third one is user-level, which contains an interest representation to model overall user interests. It is learned from topic-level interest representations. Besides, we propose a hierarchical user interest matching framework to match candidate news with different levels of interest representations to target user interests more accurately. Extensive experiments on two real-world datasets show that HieRec can effectively improve the accuracy of user interest modeling and news recommendation."
    }, {
      "heading" : "2 Related Work",
      "text" : "Personalized news recommendation is an important intelligent application and is widely studied in recent years (Bansal et al., 2015; Wu et al., 2019c; Qi et al., 2020; Ge et al., 2020). Existing methods usually model news from its content, model user interest from user’s clicked news, and recommend candidate news based on their relevance with user interests (Okura et al., 2017). For example, Okura et al. (2017) utilized an auto-encoder to learn news representations from news bodies. They applied a GRU network to capture user interests from the sequence of users’ historical clicks and used the last hidden state vector of GRU as user interest representation. Besides, they proposed to model relevance between user interest and candidate news based on the dot product of their representations. Wu et al. (2019a) learned news representations from news titles, bodies, categories, and subcategories based on an attentive multi-view learning framework. They build user interest representation based on the attentive aggregation of clicked news representations. An et al. (2019) used a CNN network to learn news representations from news titles and categories. They applied a GRU network to user’s clicked news to build a shortterm user interest representation and applied user ID embedding to learn long-term user interest representation. They further learned a unified user interest representation based on the aggregation of short- and long-term user interest representation. Liu et al. (2020) proposed to learn news representations from news titles and entities via a knowledge graph attention network. They also obtained\nuser interest representation from representations of clicked news via an attention network. Besides, all of these three methods adopted the inner product for matching candidate news. Most existing methods learn a single user embedding to represent the overall user interests (Wang et al., 2018; Wu et al., 2019e,b). However, user interests are usually very diverse and multi-grained, which are difficult to be accurately modeled by a single user embedding. Different from these methods, we propose a hierarchical user interest modeling framework to model user interests in different aspects and granularities. In addition, we propose a hierarchical user interest matching framework to understand user interest in candidate news from different interest granularities for more accurate user interest targeting."
    }, {
      "heading" : "3 HieRec",
      "text" : "In this section, we first give a problem formulation of personalized news recommendation. Then we introduce our HieRec method in detail."
    }, {
      "heading" : "3.1 Problem Formulation",
      "text" : "Given a candidate news nc and a target user u, the goal is calculating an interest score o to measure the interest of this user in the candidate news. Each news n has a title, a topic t and a subtopic s. The title is composed of a text sequence T = [w1, w2, ..., wT ] and an entity sequence E = [e1, e2, ..., eE ], where wi and ei respectively denote the i-th word and entity in news title, T and E respectively denote the number of words and entities. We assume the user has M clicked news. In HieRec, we further divide these clicks based on their topics and subtopics for hierarchical user interest modeling. More specifically, we build a clicked topic set {ti|i = 1, ...,m} from topics of user’s clicks, where ti is the i-th clicked topic and m is the number of clicked topics. We can further obtain a clicked subtopic set {sij |j = 1, ..., d} subordinate to each clicked topic ti, where sij is the j-th clicked subtopic subordinate to topic ti and d is the size of the set. Finally, user’s clicked news in topic ti and subtopic sij are divided into the same click group N ij = {n i,j k |k = 1, ..., l}, where n i,j k denotes the k-th clicked news in this group and l is the number of clicked news in the group."
    }, {
      "heading" : "3.2 Hierarchical User Interest Modeling",
      "text" : "In general, user interest is usually very diverse and multi-grained. For example, according to Fig. 1,\nthe example user has interests in many different aspects at the same time, such as sports, movies, and finance. Besides, for users who are interested in sports, some of them may have general interests in this area and may read news on different kinds of sports, such as basketball, football, golf, and so on. While other users (like the example user in Fig. 1) may only have interest in a specific sport like football. Understanding user interest in different aspects and granularities has the potential to model user interests more accurately. Thus, we propose a hierarchical user interest modeling framework, which learns a hierarchical interest tree to capture diverse and multi-grained user interest. As shown in Fig. 2, HieRec represents user interests via a three-level hierarchy.\nFirst, we learn multiple subtopic-level interest representations to model fine-grained user interests in different news subtopics (e.g. football and golf). The subtopic-level interest representation for subtopic sij is learned fromN ij that is composed of user’s clicked news in subtopic sij . Since clicked news may have different informativeness for modeling user interest, we adopt a subtopic-level attention network to select informative clicked news for modeling user interest in subtopic sij :\ncij = l∑\nk=1 γkni,jk , γk = exp(φs(ni,jk ))∑l p=1 exp(φs(n i,j p )) , (1)\nwhere γk denotes the attention weight of the k-th clicked news ni,jk in N i j , n i,j k is the representation of news ni,jk (Section. 3.4 introduces how to obtain it) and φs(·) denotes a dense network. Besides, we also adopt a subtopic embedding layer to capture semantic information of different subtopics, from\nwhich we can obtain the embedding vector sij of subtopic sij . Finally, we learn the subtopic-level user interest representation usi,j based on the combination of cij and sij , i.e., usi,j = cij + sij . Similarly, we also learn subtopic-level interest representations for other subtopics clicked by the user.\nSecond, we learn multiple topic-level interest representations to model coarse-grained user interests in major news topics (e.g. sports and finance). The topic-level interest representation for a clicked topic ti is learned from subtopic-level interest representations {usi,j |j = 1, ..., d} of subtopics {sij |j = 1, ..., d} subordinate to the topic ti. More specifically, user interests in different subtopics may have different importance for modeling user interest in a specific topic. Besides, the number of clicked news on a subtopic may also reflect its importance for modeling topic-level user interest. Thus, we utilize a topic-level attention network to select important subtopic-level user interest representations to model user interest in topic ti:\nzi = d∑\nj=1 βjusi,j , βj = exp(φt(vsi,j))∑d k=1 exp(φt(vsi,k)) , (2)\nwhere vsi,j = [usi,j ; rij ], rij is the embedding vector for the number of clicked news on subtopic sij , [·; ·] is the concatenation operation, βj is the attention weight of usi,j , and φt(·) is a dense network. Besides, we also use a topic embedding layer to model semantic information of different topics and drive the embedding vector ti for topic ti. Finally, we aggregate zi and ti to learn the topic-level user interest representation uti in topic ti: uti = zi + ti. Similarly, we also learn topic-level interest representations for other clicked topics.\nThird, we learn a user-level interest representation ug to model overall user interests. It is learned from topic-level interest representations. Similarly, we adopt a user-level attention network to model relative importance of topic-level user interests to learn user-level interest representation:\nug = m∑ i=1 αiuti, αi = exp(φg(vti))∑m j=1 exp(φg(vtj)) , (3)\nwhere vti = [uti; ri], ri is the embedding vector for the number of user’s clicked news on topic ti, αi denotes the attention weight of the i-th topic-level interest representation, and φg(·) denotes a dense network for calculating attention scores."
    }, {
      "heading" : "3.3 Hierarchical User Interest Matching",
      "text" : "Matching between candidate news and user interests at different granularities can provide various clues for user interest targeting. For example, according to Fig. 1, although all of the 3rd, 4th, and 5th news are about sports, the user only clicks the 3rd news probably because of her fine-grained interests in football rather than basketball and golf. This implies that the matching between candidate news and fine-grained user interests is useful for personalized news recommendation. Besides, not all candidate news can match with fine-grained user interests. For instance, a news on subtopic baseball cannot match any fine-grained interests of the example user in Fig. 1. Fortunately, the coarsegrained user interests (i.e., interest in sports) and overall user interests can match with this candidate news. This implies that matching candidate news with coarse-grained user interests and overall user interests is also important. Thus, we propose a hierarchical user interest matching framework, which models user interests in candidate news from different interest granularities. As shown in Fig. 3, it\ntakes candidate news (including its representation nc, topic tc and subtopic sc) and hierarchical user interest representation as input. First, we match candidate news with overall user interests and calculate a user-level interest score og based on the relevance between nc and ug: og = nc · ug.\nSecond, topic-level interest representation uttc models coarse-grained user interests in the topic tc of candidate news. It can provide coarse-grained information to understand user interest in candidate news. Thus, we match topic-level interest representation uttc with candidate news nc as: ôt = nc · u t tc . Besides, we can infer users may be more interested in topics that they have clicked more. Thus, we weights ôt based on the ratio wtc of topic tc in historical clicked news and obtained topic-level interest score ot: ot = ôt ∗wtc . Besides, if the candidate news does not belong to any user’s clicked topics, we set ot as zero directly.\nThird, subtopic-level interest representation ussc models fine-grained user interest in the subtopic sc of candidate news and can be used to capture fine-grained user interests in candidate news. Thus, we match subtopic-level interest representation ussc and candidate news nc as: ôs = nc · ussc Similarly, we weights ôs based on the ratio wsc of subtopic sc in user’s clicked news and obtain the subtopic-level interest score: os = ôs ∗ wsc .\nFinally, interest scores of three different levels are aggregated to an overall interest score o:\no = λsos + λtot + (1− λs − λt)og, (4)\nwhere λt, λs,∈ R+ are hyper-parameters for controlling the relative importance of interest scores of different levels. Besides, we have λt + λs < 1."
    }, {
      "heading" : "3.4 News Representation",
      "text" : "We introduce how to obtain news representation from texts and entities of news titles. As shown in\nFig. 4, we first use a text encoder to model news texts. It first applies a word embedding layer to enrich semantic information of the model. Next, it adopts a text self-attention network (Vaswani et al., 2017) to learn word representations from contexts of news texts. Then, it uses a text attention network to learn text representation nt by aggregating word representations. Besides texts, knowledge graphs can also provide rich information for understanding news content via entities in news (Wang et al., 2018). Thus, we apply an entity encoder to learn entity representation of news. We first use an entity embedding layer to incorporate information from knowledge graphs into our model. We further apply an entity self-attention network to capture relatedness among entities. Next, we utilize an entity attention network to learn entity representation ne of news by aggregating entities. Finally, we build representation n of news as: n = Wtnt + Wene, where Wt and We are parameters."
    }, {
      "heading" : "3.5 Model Training",
      "text" : "Following (Wu et al., 2019d), we utilize the NCE loss for model optimization. Given a positive sample n+i (a clicked news) in the training dataset O, we randomly select K negative samples [n1i , ..., n K i ] (non-clicked news) for it from the same news impression displayed to the user u. The NCE loss L requires the positive sample should be assigned a higher interest score o+i than other negative samples [o1i , ..., o K i ] and is formulated as:\nL = − |O|∑ i=1 log exp(o+i ) exp(o+i ) + ∑K j=1 exp(o j i ) . (5)"
    }, {
      "heading" : "4 Experiment",
      "text" : ""
    }, {
      "heading" : "4.1 Experimental Datasets and Settings",
      "text" : "We conduct extensive experiments on two realworld datasets to evaluate the effectiveness of Hi-\neRec. The first one is the public MIND dataset (Wu et al., 2020d)1. It is constructed by user behavior data collected from Microsoft News from October 12 to November 22, 2019 (six weeks), where user data in the first four weeks was used to construct users’ reading history, user data in the penultimate week was used for model training and user data in the last week was used for evaluation. Besides, MIND contains off-the-shelf topic and subtopic label for each news. The second one (named Feeds) is constructed by user behavior data sampled from a commercial news feeds app in Microsoft from January 23 to April 01, 2020 (13 weeks). We randomly sample 100,000 and 10,000 impressions from the first ten weeks to construct training and validation set, and 100,000 impressions from the last three weeks to construct test data. Since Feeds only contains topic label of news, we implement a simplified version of HieRec with only user- and topiclevel interest representations on Feeds. Besides, following Wu et al. (2020d), users in Feeds were anonymized via hash algorithms and de-linked from the production system to protect user privacy. Detailed information is summarized in Table 1.\nNext, we introduce experimental settings and hyper-parameters of HieRec. We use the first 30 words and 5 entities of news titles and users’ recent 50 clicked news in experiments. We adopt pre-trained glove (Pennington et al., 2014) word embeddings and TransE entity embeddings (Bordes et al., 2013) for initialization. In HieRec, the word and entity self-attention network output 400- and 100-dimensional vectors, respectively. Besides, the unified news representation is 400-dimensional. Attention networks (i.e., φs(·), φt(·), and φg(·)) are implemented by single-layer dense networks. Besides, dimensions of topic and subtopic embeddings are 400, both of which are randomly initialized and fine-tuned. The hyper-parameters for combining different interest scores, i.e. λt and λs, are set to 0.15 and 0.7 respectively. Moreover, we utilize dropout technique (Srivastava et al., 2014) and Adam optimizer (Kingma and Ba, 2015) for training. HieRec is trained for 5 epochs with 0.0001\n1We use the small version of MIND for quick experiments. This dataset is at https://msnews.github.io/index.html\nlearning rate. All hyper-parameters of HieRec and baseline methods are manually tuned on the validation set.2 Following Wu et al. (2019e), we use four ranking metrics, i.e., AUC, MRR, nDCG@5, and nDCG@10, for performance evaluation."
    }, {
      "heading" : "4.2 Main Results",
      "text" : "We first introduce the baseline methods we compared in experiments: (1) EBNR (Okura et al., 2017): learning user representations from the sequence user’s clicked news via a GRU network. (2) DKN (Wang et al., 2018): using a candidateaware attention network to learn user representations. (3) DAN (Zhu et al., 2019): using an attentive LSTM network to learn user representations. (4) NAML (Wu et al., 2019a): learning user representations by attentively aggregating user’s clicked news. (5) NPA (Wu et al., 2019b): learning news and user representations via personalized attention networks. (6) LSTUR (An et al., 2019): modeling short-term user interests from user’s clicked news via a GRU network and long-term user interests from user-news interactions via user ID embeddings. (7) NRMS (Wu et al., 2019e): applying multi-head self-attention networks to learn news representations and user representations. (8) KRED (Liu et al., 2020): proposing a knowledge graph attention network to learn news representations from texts and entities of news titles. (9) GNewsRec (Hu et al., 2020): modeling short-term user interests from clicked news sequences via an attentive GRU network and long-term user interests from user-news click graph via a graph neural network. (10) FIM (Wang et al., 2020): modeling user interests in candidate news from semantic relevance of user’s clicked news and candidate news\n2https://github.com/JulySinceAndrew/HieRec\nvia a 3-D CNN network. Each experiment is repeated 5 times. The average results and standard deviations are listed in Table 2, from which we have several observations. First, HieRec significantly outperforms other baseline methods which learn a single user embedding to model overall user interests, such as NRMS, NPA, and NAML. This is because user interests are usually diverse and multi-grained. However, it is difficult for a single representation vector to model user interests in different aspects and granularities, which may be suboptimal for personalized news recommendation. Different from these methods, we propose a hierarchical user interest modeling framework, which can represent diverse and multigrained user interests via a three-level hierarchy. Besides, we also propose a hierarchical user interest matching framework to match user interest with candidate news from different granularities, which can better target user interests. Second, HieRec can significantly outperform FIM, which directly model user interests in candidate news from the semantic relevance of candidate news and user’s clicked news. This may be because FIM did not consider user interests from different granularities for matching candidate news."
    }, {
      "heading" : "4.3 Effectiveness in User Modeling",
      "text" : "To fairly compare different methods with HieRec on the performance of interest modeling, we compare them based on the same news modeling method (the news modeling method introduced in Section 3.4). Experimental results are summarized in Table 3 and we only show experimental results on MIND in the following sections. Table 3 shows that HieRec significantly outperforms existing interest modeling methods. This is because user in-\nterests are usually diverse and multi-grained. It is difficult for existing methods with single user embedding to capture user interests in different aspects and granularities. Different from these methods, HieRec learns a three-level hierarchy to represent diverse and multi-grained user interests."
    }, {
      "heading" : "4.4 Ablation Study",
      "text" : "We evaluate the effectiveness of user interest representations of different levels by removing the corresponding interest matching scores from Eq. 4. Results are shown in Fig. 5 and we have several findings. First, HieRec with user- and topic- or subtopic-level interest representation significantly outperforms HieRec with only user-level interest representation. This is because matching candidate news with fine-grained user interests has the potential to improve the accuracy of news recommendation. Topic- and subtopic-level interest representation can model finer-grained user interests than the user-level interest representation. Thus, they can provide additional information to match candidate news than user-level interest representation. Second, HieRec with interest representations of three levels also outperforms HieRec with user- and topic- or subtopic-level interest representation. This may be because matching candidate news with user interests of different granularities can help perform more accurate interest matching. Since topic- and subtopic-level interest representa-\ntion capture user interests at different granularities, incorporating both of them can further improve the recommendation performance."
    }, {
      "heading" : "4.5 Performance on Recall and Diversity",
      "text" : "Next, we compare different user interest modeling methods on the news recall task.3 Since methods that model user interests with candidate news information, e.g., DKN and GNewsRec, cannot be applied in the news recall task due to efficiency issues (Pal et al., 2020), we do not compare them in experiments. We evaluate the accuracy and diversity of top K recalled candidate news. Following existing works (Pal et al., 2020; Chen et al., 2018), the former is measured by recall rates, and the latter is measured by intra-list average distance (ILAD). For HieRec, we employ subtopic-level interest representations to perform multi-channel news recall and equally integrate news recalled by different interest channels. Experimental results are summarized in Fig. 6 and Fig. 7, which show that HieRec significantly outperforms other methods in terms of both recall rates and diversity. This is because user interests are usually very diverse and multi-\n3News recall task aims to recall a small number of candidate news from a large news pool according to user interests.\ngrained, which are difficult to be comprehensively modeled by a single representation vector. Different from these methods, HieRec hierarchically represents user interests and can better model user interests in different aspects and granularities. Besides, this also implies that compared to existing personalized methods, HieRec can help users explore more diverse information and alleviate filter bubble issues (Nguyen et al., 2014) to some extent."
    }, {
      "heading" : "4.6 Hyper-parameters Analysis",
      "text" : "As shown in Fig. 9, we analyze the influence of two important hyper-parameters of HieRec (i.e., λt, λs) used for combining different levels of interest scores. First, when λt is fixed, performance of HieRec first gets better with the increase of λs. This is because λs controls the importance of os. Bedsides, os measures the relevance of candidate news and fine-grained user interests, which can provide accurate information to understand user interests in the candidate news. When λs is too small, HieRec cannot effectively exploit information in os. Second, large value of λs also hurts the performance of HieRec. This is because when λs is too large, HieRec cannot effectively exploit userand topic-level matching scores to recommend can-\ndidate news. However, matching candidate news with both overall and coarse-grained user interests is important for personalized news recommendation. Thus, a moderate λs, i.e., 0.65 or 0.7, is suitable for HieRec. Third, when λs is fixed, the performance of HieRec also first gets better with the increase of λt and gets worse when λt is too large. This is because HieRec cannot effectively utilize information of ot when λt is too small. Besides, HieRec cannot effectively utilize information of og and os when λt is too large. Thus, a moderate λt, i.e., 0.12 or 0.15, is suitable for HieRec."
    }, {
      "heading" : "4.7 Case Study",
      "text" : "We conduct a case study to show the superior performance of HieRec. We compare HieRec with GNewsRec since GNewsRec achieves best AUC score in Table 2 among baseline methods. In Fig. 8, we show the top 5 news recommended by HieRec and GNewsRec in a randomly sampled impression. Besides, we also show the historical clicks of the target user in this impression. We can find that the top 5 news recommended by GNewsRec is dominated by news on politics, which cannot comprehensively cover different user interests. This is because user interests are usually diverse and multigrained. However, it is difficult for GNewsRec, which learns a single representation to model overall user interests, to effectively capture user interests in different aspects and granularities. Different from GNewsRec, the top 5 news recommended by HieRec are diverse and can cover topics that the user may be interested in. Besides, the user clicked a news recommended by HieRec. This is because HieRec learns a hierarchical user interest representation which can effectively model user interests in different aspects and granularities. With the help of the hierarchical user interest representation, HieRec can match candidate news with user interests in different aspects and granularities."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we propose a personalized news recommendation method named HieRec for hierarchical user interest modeling, which can effectively model diverse and multi-grained user interests. HieRec learns a three-level hierarchy to represent user interest in different aspects and granularity. First, we learn multiple subtopic-level interest representations to model fine-grained user interests in different news subtopics. Second, we learn multiple topic-level interest representations to model coarse-grained user interests in several major news topics. Third, we learn a user-level interest representation to model overall user interests. Besides, we propose a hierarchical user interest matching framework to match candidate news with user interest from different granularity for more accurate user interest targeting. Extensive experiments on two real-world datasets show the effectiveness of HieRec in user interest modeling."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported by the National Natural Science Foundation of China under Grant numbers U1936208, U1705261, U1936216, and U1836204. We thank Tao Di and Wei He for their great comments and suggestions.\nEthics and Impact Statement\nIn this paper, we present HieRec to model diverse and multi-grained user interest. HieRec can be applied to online news platforms for personalized news recommendation, which can help platforms improve user experience and help users find interested news information. Although HieRec can bring many benefits, it may also have several potential risks, which we will discuss in detail.\nAccuracy Although HieRec outperforms baseline methods in term of recommendation accuracy (Table 2), it may also have some inaccurate recommendation results that users are not interested in. Users usually just ignore them and will not click them to read. The user experience may be harmed and users may use the online news service less in the future, or turn to other online news platforms.\nPrivacy In HieRec, we rely on user behavior data centrally stored on the news platform for model training and online services. User behavior data is usually privacy-sensitive, and its centralized storage may lead to privacy concerns and risks. In\nthe future, we will explore to train and deploy HieRec in a more privacy-preserving way based on some effective privacy protection techniques like Federated Learning (Qi et al., 2020).\nDiversity Filter bubbles and echo chambers are the common problem for many recommender systems (Nguyen et al., 2014), which harms user experience. Improving recommendation diversity has the potential to alleviate the problem of filter bubbles and echo chambers. Through experiments in Fig. 7, we find that HieRec can outperform many news recommendation methods in term of recommendation diversity. Thus, compared with existing methods, HieRec has the potential to alleviate filter bubble problem to some extent. Besides, in order to further improve recommendation diversity, HieRec can be combined with some existing methods in this field like DPP (Chen et al., 2018).\nFake News and Clickbait There may be some fake news and clickbait in some online platforms. In order to handle the negative social impact and the user experience harm brought by these fake news and clickbait, online news platforms can use some existing fake news detection and clickbait detection techniques such as (Kumar et al., 2018; Shu et al., 2019) to filter these kinds of news before applying HieRec for personalized recommendation.\nFairness Like many other recommender systems, HieRec relies on user behavior data for model training and online service. The bias in user behavior data may lead to some specific groups of users not be able to receive news information with sufficient accuracy and diversity, and the recommendation results may be more suitable for some major populations. Recently, some fairness-aware recommendation methods like FairRec (Wu et al., 2021) have been proposed to eliminate bias and unfairness in recommender systems. We can combine HieRec with these methods to improve the fairness of the recommendation results and mitigate the harms for marginalized populations.\nMisuse The proposed HieRec method works in a data-driven way. It trains the model from the user logs and makes personalized recommendations to users based on their interest inferred from their clicked news. However, in some extreme cases, the recommendation results may be maliciously manipulated to influence users. To avoid the potential misuse, the usage of HieRec should comply with the regulations and laws, and intentional manipulation should be prohibited."
    } ],
    "references" : [ {
      "title" : "Neural news recommendation with long-and short-term user representations",
      "author" : [ "Mingxiao An", "Fangzhao Wu", "Chuhan Wu", "Kun Zhang", "Zheng Liu", "Xing Xie." ],
      "venue" : "ACL, pages 336–345.",
      "citeRegEx" : "An et al\\.,? 2019",
      "shortCiteRegEx" : "An et al\\.",
      "year" : 2019
    }, {
      "title" : "Content driven user profiling for comment-worthy recommendations of news and blog articles",
      "author" : [ "Trapit Bansal", "Mrinal Das", "Chiranjib Bhattacharyya." ],
      "venue" : "RecSys., pages 195–202.",
      "citeRegEx" : "Bansal et al\\.,? 2015",
      "shortCiteRegEx" : "Bansal et al\\.",
      "year" : 2015
    }, {
      "title" : "Translating embeddings for modeling multirelational data",
      "author" : [ "Antoine Bordes", "Nicolas Usunier", "Alberto GarciaDuran", "Jason Weston", "Oksana Yakhnenko." ],
      "venue" : "NIPS, pages 2787–2795.",
      "citeRegEx" : "Bordes et al\\.,? 2013",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2013
    }, {
      "title" : "Fast greedy map inference for determinantal point process to improve recommendation diversity",
      "author" : [ "Laming Chen", "Guoxin Zhang", "Eric Zhou." ],
      "venue" : "NIPS, pages 5622–5633.",
      "citeRegEx" : "Chen et al\\.,? 2018",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2018
    }, {
      "title" : "Google news personalization: scalable online collaborative filtering",
      "author" : [ "Abhinandan S Das", "Mayur Datar", "Ashutosh Garg", "Shyam Rajaram." ],
      "venue" : "WWW, pages 271–280.",
      "citeRegEx" : "Das et al\\.,? 2007",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2007
    }, {
      "title" : "Graph enhanced representation learning for news recommendation",
      "author" : [ "Suyu Ge", "Chuhan Wu", "Fangzhao Wu", "Tao Qi", "Yongfeng Huang." ],
      "venue" : "WWW, pages 2863–2869.",
      "citeRegEx" : "Ge et al\\.,? 2020",
      "shortCiteRegEx" : "Ge et al\\.",
      "year" : 2020
    }, {
      "title" : "Graph neural news recommendation with long-term and short-term interest modeling",
      "author" : [ "Linmei Hu", "Chen Li", "Chuan Shi", "Cheng Yang", "Chao Shao." ],
      "venue" : "IP&M, page 102142.",
      "citeRegEx" : "Hu et al\\.,? 2020",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2020
    }, {
      "title" : "Weave&rec: A word embedding based 3-d convolutional network for news recommendation",
      "author" : [ "Dhruv Khattar", "Vaibhav Kumar", "Vasudeva Varma", "Manish Gupta." ],
      "venue" : "CIKM, pages 1855–1858.",
      "citeRegEx" : "Khattar et al\\.,? 2018",
      "shortCiteRegEx" : "Khattar et al\\.",
      "year" : 2018
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Identifying clickbait: A multi-strategy approach using neural networks",
      "author" : [ "Vaibhav Kumar", "Dhruv Khattar", "Siddhartha Gairola", "Yash Kumar Lal", "Vasudeva Varma." ],
      "venue" : "SIGIR, pages 1225–1228.",
      "citeRegEx" : "Kumar et al\\.,? 2018",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2018
    }, {
      "title" : "Personalized news recommendation via implicit social experts",
      "author" : [ "Chen Lin", "Runquan Xie", "Xinjun Guan", "Lei Li", "Tao Li." ],
      "venue" : "Information Sciences, pages 1–18.",
      "citeRegEx" : "Lin et al\\.,? 2014",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2014
    }, {
      "title" : "Kred: Knowledge-aware document representation for news recommendations",
      "author" : [ "Danyang Liu", "Jianxun Lian", "Shiyin Wang", "Ying Qiao", "Jiun-Hung Chen", "Guangzhong Sun", "Xing Xie." ],
      "venue" : "RecSys., pages 200–209.",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Personalized news recommendation based on click behavior",
      "author" : [ "Jiahui Liu", "Peter Dolan", "Elin Rønby Pedersen." ],
      "venue" : "IUI, pages 31–40.",
      "citeRegEx" : "Liu et al\\.,? 2010",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2010
    }, {
      "title" : "Exploring the filter bubble: the effect of using recommender systems on content diversity",
      "author" : [ "Tien T Nguyen", "Pik-Mai Hui", "F Maxwell Harper", "Loren Terveen", "Joseph A Konstan." ],
      "venue" : "WWW, pages 677– 686.",
      "citeRegEx" : "Nguyen et al\\.,? 2014",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2014
    }, {
      "title" : "Embedding-based news recommendation for millions of users",
      "author" : [ "Shumpei Okura", "Yukihiro Tagami", "Shingo Ono", "Akira Tajima." ],
      "venue" : "KDD, pages 1933–1942.",
      "citeRegEx" : "Okura et al\\.,? 2017",
      "shortCiteRegEx" : "Okura et al\\.",
      "year" : 2017
    }, {
      "title" : "Pinnersage: Multi-modal user embedding framework for recommendations at pinterest",
      "author" : [ "Aditya Pal", "Chantat Eksombatchai", "Yitong Zhou", "Bo Zhao", "Charles Rosenberg", "Jure Leskovec." ],
      "venue" : "KDD, pages 2311–2320.",
      "citeRegEx" : "Pal et al\\.,? 2020",
      "shortCiteRegEx" : "Pal et al\\.",
      "year" : 2020
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher Manning." ],
      "venue" : "EMNLP, pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Privacy-preserving news recommendation model learning",
      "author" : [ "Tao Qi", "Fangzhao Wu", "Chuhan Wu", "Yongfeng Huang", "Xing Xie." ],
      "venue" : "EMNLP: Findings, pages 1423–1432.",
      "citeRegEx" : "Qi et al\\.,? 2020",
      "shortCiteRegEx" : "Qi et al\\.",
      "year" : 2020
    }, {
      "title" : "defend: Explainable fake news detection",
      "author" : [ "Kai Shu", "Limeng Cui", "Suhang Wang", "Dongwon Lee", "Huan Liu." ],
      "venue" : "KDD, pages 395–405.",
      "citeRegEx" : "Shu et al\\.,? 2019",
      "shortCiteRegEx" : "Shu et al\\.",
      "year" : 2019
    }, {
      "title" : "Dropout: A simple way to prevent neural networks from overfitting",
      "author" : [ "Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov." ],
      "venue" : "JMLR, pages 1929–1958.",
      "citeRegEx" : "Srivastava et al\\.,? 2014",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 2014
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "NIPS, pages 6000–6010.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Fine-grained interest matching for neural news recommendation",
      "author" : [ "Heyuan Wang", "Fangzhao Wu", "Zheng Liu", "Xing Xie." ],
      "venue" : "ACL, pages 836–845.",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Dkn: Deep knowledge-aware network for news recommendation",
      "author" : [ "Hongwei Wang", "Fuzheng Zhang", "Xing Xie", "Minyi Guo." ],
      "venue" : "WWW, pages 1835– 1844.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Neural news recommendation with attentive multiview learning",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Mingxiao An", "Jianqiang Huang", "Yongfeng Huang", "Xing Xie." ],
      "venue" : "IJCAI, pages 3863–3869.",
      "citeRegEx" : "Wu et al\\.,? 2019a",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Npa: Neural news recommendation with personalized attention",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Mingxiao An", "Jianqiang Huang", "Yongfeng Huang", "Xing Xie." ],
      "venue" : "KDD, pages 2576–2584.",
      "citeRegEx" : "Wu et al\\.,? 2019b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural news recommendation with topic-aware news representation",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Mingxiao An", "Yongfeng Huang", "Xing Xie." ],
      "venue" : "ACL, pages 1154–1159.",
      "citeRegEx" : "Wu et al\\.,? 2019c",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural news recommendation with heterogeneous user behavior",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Mingxiao An", "Tao Qi", "Jianqiang Huang", "Yongfeng Huang", "Xing Xie." ],
      "venue" : "EMNLP, pages 4876–4885.",
      "citeRegEx" : "Wu et al\\.,? 2019d",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural news recommendation with multi-head selfattention",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Suyu Ge", "Tao Qi", "Yongfeng Huang", "Xing Xie." ],
      "venue" : "EMNLP, pages 6390–6395.",
      "citeRegEx" : "Wu et al\\.,? 2019e",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Sentirec: Sentiment diversity-aware neural news recommendation",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Tao Qi", "Yongfeng Huang." ],
      "venue" : "AACL, pages 44–",
      "citeRegEx" : "Wu et al\\.,? 2020a",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "User modeling with click preference and reading satisfaction for news recommendation",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Tao Qi", "Yongfeng Huang." ],
      "venue" : "IJCAI, pages 3023–3029.",
      "citeRegEx" : "Wu et al\\.,? 2020b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Ptum: Pretraining user model from unlabeled user behaviors via self-supervision",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Tao Qi", "Jianxun Lian", "Yongfeng Huang", "Xing Xie." ],
      "venue" : "EMNLP: Findings, pages 1939–1944.",
      "citeRegEx" : "Wu et al\\.,? 2020c",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Fairrec:fairness-aware news recommendation with decomposed adversarial learning",
      "author" : [ "Chuhan Wu", "Fangzhao Wu", "Xiting Wang", "Yongfeng Huang", "Xing Xie." ],
      "venue" : "AAAI.",
      "citeRegEx" : "Wu et al\\.,? 2021",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2021
    }, {
      "title" : "2020d. Mind: A large-scale dataset for news recommendation",
      "author" : [ "Fangzhao Wu", "Ying Qiao", "Jiun-Hung Chen", "Chuhan Wu", "Tao Qi", "Jianxun Lian", "Danyang Liu", "Xing Xie", "Jianfeng Gao", "Winnie Wu" ],
      "venue" : "In ACL,",
      "citeRegEx" : "Wu et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Drn: A deep reinforcement learning framework for news recommendation",
      "author" : [ "Guanjie Zheng", "Fuzheng Zhang", "Zihan Zheng", "Yang Xiang", "Nicholas Jing Yuan", "Xing Xie", "Zhenhui Li." ],
      "venue" : "WWW, pages 167–176.",
      "citeRegEx" : "Zheng et al\\.,? 2018",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2018
    }, {
      "title" : "Dan: Deep attention neural network for news recommendation",
      "author" : [ "Qiannan Zhu", "Xiaofei Zhou", "Zeliang Song", "Jianlong Tan", "Guo Li." ],
      "venue" : "AAAI, pages 5973–5980.",
      "citeRegEx" : "Zhu et al\\.,? 2019",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "Recently, massive people are habituated to reading news articles on online news platforms, such as Google News and Microsoft News (Khattar et al., 2018; Das et al., 2007).",
      "startOffset" : 130,
      "endOffset" : 170
    }, {
      "referenceID" : 4,
      "context" : "Recently, massive people are habituated to reading news articles on online news platforms, such as Google News and Microsoft News (Khattar et al., 2018; Das et al., 2007).",
      "startOffset" : 130,
      "endOffset" : 170
    }, {
      "referenceID" : 28,
      "context" : "obtain their interested news information, personalized news recommendation technique that aims to recommend news according to user interests, is widely used by these platforms (Wu et al., 2020a; Liu et al., 2010; Lin et al., 2014).",
      "startOffset" : 176,
      "endOffset" : 230
    }, {
      "referenceID" : 12,
      "context" : "obtain their interested news information, personalized news recommendation technique that aims to recommend news according to user interests, is widely used by these platforms (Wu et al., 2020a; Liu et al., 2010; Lin et al., 2014).",
      "startOffset" : 176,
      "endOffset" : 230
    }, {
      "referenceID" : 10,
      "context" : "obtain their interested news information, personalized news recommendation technique that aims to recommend news according to user interests, is widely used by these platforms (Wu et al., 2020a; Liu et al., 2010; Lin et al., 2014).",
      "startOffset" : 176,
      "endOffset" : 230
    }, {
      "referenceID" : 31,
      "context" : "User interest modeling is a critical step for personalized news recommendation (Wu et al., 2021; Zheng et al., 2018; Wu et al., 2020c).",
      "startOffset" : 79,
      "endOffset" : 134
    }, {
      "referenceID" : 33,
      "context" : "User interest modeling is a critical step for personalized news recommendation (Wu et al., 2021; Zheng et al., 2018; Wu et al., 2020c).",
      "startOffset" : 79,
      "endOffset" : 134
    }, {
      "referenceID" : 30,
      "context" : "User interest modeling is a critical step for personalized news recommendation (Wu et al., 2021; Zheng et al., 2018; Wu et al., 2020c).",
      "startOffset" : 79,
      "endOffset" : 134
    }, {
      "referenceID" : 1,
      "context" : "Personalized news recommendation is an important intelligent application and is widely studied in recent years (Bansal et al., 2015; Wu et al., 2019c; Qi et al., 2020; Ge et al., 2020).",
      "startOffset" : 111,
      "endOffset" : 184
    }, {
      "referenceID" : 25,
      "context" : "Personalized news recommendation is an important intelligent application and is widely studied in recent years (Bansal et al., 2015; Wu et al., 2019c; Qi et al., 2020; Ge et al., 2020).",
      "startOffset" : 111,
      "endOffset" : 184
    }, {
      "referenceID" : 17,
      "context" : "Personalized news recommendation is an important intelligent application and is widely studied in recent years (Bansal et al., 2015; Wu et al., 2019c; Qi et al., 2020; Ge et al., 2020).",
      "startOffset" : 111,
      "endOffset" : 184
    }, {
      "referenceID" : 5,
      "context" : "Personalized news recommendation is an important intelligent application and is widely studied in recent years (Bansal et al., 2015; Wu et al., 2019c; Qi et al., 2020; Ge et al., 2020).",
      "startOffset" : 111,
      "endOffset" : 184
    }, {
      "referenceID" : 14,
      "context" : "user interest from user’s clicked news, and recommend candidate news based on their relevance with user interests (Okura et al., 2017).",
      "startOffset" : 114,
      "endOffset" : 134
    }, {
      "referenceID" : 20,
      "context" : "adopts a text self-attention network (Vaswani et al., 2017) to learn word representations from contexts of news texts.",
      "startOffset" : 37,
      "endOffset" : 59
    }, {
      "referenceID" : 22,
      "context" : "graphs can also provide rich information for understanding news content via entities in news (Wang et al., 2018).",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 26,
      "context" : "Following (Wu et al., 2019d), we utilize the NCE loss for model optimization.",
      "startOffset" : 10,
      "endOffset" : 28
    }, {
      "referenceID" : 16,
      "context" : "We adopt pre-trained glove (Pennington et al., 2014) word embeddings and TransE entity embeddings (Bordes et al.",
      "startOffset" : 27,
      "endOffset" : 52
    }, {
      "referenceID" : 2,
      "context" : ", 2014) word embeddings and TransE entity embeddings (Bordes et al., 2013) for initialization.",
      "startOffset" : 53,
      "endOffset" : 74
    }, {
      "referenceID" : 19,
      "context" : "Moreover, we utilize dropout technique (Srivastava et al., 2014) and Adam optimizer (Kingma and Ba, 2015) for training.",
      "startOffset" : 39,
      "endOffset" : 64
    }, {
      "referenceID" : 8,
      "context" : ", 2014) and Adam optimizer (Kingma and Ba, 2015) for training.",
      "startOffset" : 27,
      "endOffset" : 48
    }, {
      "referenceID" : 14,
      "context" : "pared in experiments: (1) EBNR (Okura et al., 2017): learning user representations from the sequence user’s clicked news via a GRU network.",
      "startOffset" : 31,
      "endOffset" : 51
    }, {
      "referenceID" : 22,
      "context" : "(2) DKN (Wang et al., 2018): using a candidateaware attention network to learn user representa-",
      "startOffset" : 8,
      "endOffset" : 27
    }, {
      "referenceID" : 34,
      "context" : "(3) DAN (Zhu et al., 2019): using an attentive LSTM network to learn user representations.",
      "startOffset" : 8,
      "endOffset" : 26
    }, {
      "referenceID" : 23,
      "context" : "(4) NAML (Wu et al., 2019a): learning user representations by attentively aggregating user’s clicked news.",
      "startOffset" : 9,
      "endOffset" : 27
    }, {
      "referenceID" : 0,
      "context" : "(6) LSTUR (An et al., 2019): modeling short-term user interests from user’s clicked news via a GRU network and long-term user interests from user-news interactions via user ID",
      "startOffset" : 10,
      "endOffset" : 27
    }, {
      "referenceID" : 27,
      "context" : "(7) NRMS (Wu et al., 2019e): applying multi-head self-attention networks to learn news representations and user representations.",
      "startOffset" : 9,
      "endOffset" : 27
    }, {
      "referenceID" : 11,
      "context" : "(8) KRED (Liu et al., 2020): proposing a knowledge graph attention network to learn news representations from texts and entities of news titles.",
      "startOffset" : 9,
      "endOffset" : 27
    }, {
      "referenceID" : 6,
      "context" : "(9) GNewsRec (Hu et al., 2020): modeling short-term user interests from clicked news sequences via an attentive GRU network and long-term user interests from user-news click graph via a graph neural network.",
      "startOffset" : 13,
      "endOffset" : 30
    }, {
      "referenceID" : 21,
      "context" : "(10) FIM (Wang et al., 2020): modeling user interests in candidate news from semantic relevance of user’s clicked news and candidate news",
      "startOffset" : 9,
      "endOffset" : 28
    }, {
      "referenceID" : 15,
      "context" : ", DKN and GNewsRec, cannot be applied in the news recall task due to efficiency issues (Pal et al., 2020), we do not compare them in experiments.",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 15,
      "context" : "Following existing works (Pal et al., 2020; Chen et al., 2018), the former is measured by recall rates, and the latter is measured by intra-list average distance (ILAD).",
      "startOffset" : 25,
      "endOffset" : 62
    }, {
      "referenceID" : 3,
      "context" : "Following existing works (Pal et al., 2020; Chen et al., 2018), the former is measured by recall rates, and the latter is measured by intra-list average distance (ILAD).",
      "startOffset" : 25,
      "endOffset" : 62
    }, {
      "referenceID" : 13,
      "context" : "personalized methods, HieRec can help users explore more diverse information and alleviate filter bubble issues (Nguyen et al., 2014) to some extent.",
      "startOffset" : 112,
      "endOffset" : 133
    }, {
      "referenceID" : 17,
      "context" : "eRec in a more privacy-preserving way based on some effective privacy protection techniques like Federated Learning (Qi et al., 2020).",
      "startOffset" : 116,
      "endOffset" : 133
    }, {
      "referenceID" : 13,
      "context" : "Diversity Filter bubbles and echo chambers are the common problem for many recommender systems (Nguyen et al., 2014), which harms user experience.",
      "startOffset" : 95,
      "endOffset" : 116
    }, {
      "referenceID" : 3,
      "context" : "Besides, in order to further improve recommendation diversity, HieRec can be combined with some existing methods in this field like DPP (Chen et al., 2018).",
      "startOffset" : 136,
      "endOffset" : 155
    }, {
      "referenceID" : 31,
      "context" : "Recently, some fairness-aware recommendation methods like FairRec (Wu et al., 2021) have been proposed to eliminate bias and unfairness in recommender systems.",
      "startOffset" : 66,
      "endOffset" : 83
    } ],
    "year" : 2021,
    "abstractText" : "User interest modeling is critical for personalized news recommendation. Existing news recommendation methods usually learn a single user embedding for each user from their previous behaviors to represent their overall interest. However, user interest is usually diverse and multi-grained, which is difficult to be accurately modeled by a single user embedding. In this paper, we propose a news recommendation method with hierarchical user interest modeling, named HieRec. Instead of a single user embedding, in our method each user is represented in a hierarchical interest tree to better capture their diverse and multi-grained interest in news. We use a three-level hierarchy to represent 1) overall user interest; 2) user interest in coarse-grained topics like sports; and 3) user interest in fine-grained topics like football. Moreover, we propose a hierarchical user interest matching framework to match candidate news with different levels of user interest for more accurate user interest targeting. Extensive experiments on two real-world datasets validate our method can effectively improve the performance of user modeling for personalized news recommendation.",
    "creator" : "LaTeX with hyperref"
  }
}