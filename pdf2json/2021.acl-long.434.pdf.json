{
  "name" : "2021.acl-long.434.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Learning to Perturb Word Embeddings for Out-of-distribution QA",
    "authors" : [ "Seanie Lee", "Minki Kang", "Juho Lee", "Sung Ju Hwang" ],
    "emails" : [ "sjhwang82}@kaist.ac.kr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 5583–5595\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n5583"
    }, {
      "heading" : "1 Introduction",
      "text" : "Deep learning models have achieved impressive performances on a variety of real-world natural language understanding tasks such as text classification, machine translation, question answering, and text generation to name a few (Vaswani et al., 2017; Seo et al., 2017). Recently, language models that are pretrained with a large amount of unlabeled data have achieved breakthrough in the performance on these downstream tasks (Devlin et al., 2019), even surpassing human performance on some of them.\nThe success of such data-driven language model pretraining heavily depends on the amount and diversity of training data available, since when\n∗* Equal contribution\ntrained with a small amount of highly-biased data, the pretrained models can overfit and may not generalize well to out-of-distribution data. Data augmentation (DA) techniques (Krizhevsky et al., 2012; Verma et al., 2019a; Yun et al., 2019; Sennrich et al., 2016) can prevent this to a certain extent, but most of them are developed for image domains and are not directly applicable to augmenting words and texts. Perhaps the most important desiderata for an augmentation method in supervised learning, is that it should not change the label of an example. For image domains, there exist several well-defined data augmentation techniques that can produce diverse augmented images without changing the semantics. In contrast, for Natural Language Processing (NLP), it is not straightforward to augment the input texts without changing their semantics. A simple augmentation technique that preserves semantics is replacing words with synonyms or using back translation (Sennrich et al., 2016). However, they do not effectively improve the generalization performance because the diversity of viable transformations with such techniques is highly limited (Pham et al., 2021).\nSome recent works (Wei and Zou, 2019; Ng et al., 2020) propose data augmentation methods tailored for NLP tasks based on dropping or replacing words and show that such augmentation techniques improve the performance on the out-ofdomain as well as the in-domain tasks. As shown in Fig. 1, however, we have observed that most existing data augmentation methods for NLP change the semantics of original inputs. While such change in the semantics may not be a serious problem for certain tasks, it could be critical for Question Answering (QA) task since its sensitivity to the semantic of inputs. For instance, replacing a single word with a synonym (Hesburgh→ Vanroth in Fig. 1) might cause the drastic semantic drift of the answer (Jia and Liang, 2017). Thus, word-based\naugmentations are ineffective for QA tasks, and most existing works on data augmentation for QA tasks resort to question or QA-pair generation. Yet, this approach requires a large amount of training time, since we have to train a separate generator, generate QA pairs from them, and then use the generated pairs to train the QA model. Also, QA-pair generation methods are not sample-efficient since they usually require a large amount of generated pairs to achieve meaningful performance gains.\nTo address such limitations of the existing data augmentation techniques for QA, we propose a novel DA method based on learnable word-level perturbation, which effectively regularizes the model to improve its generalization to unseen questions and contexts with distributional shifts. Specifically, we train a stochastic perturbation function to learn how to perturb each word embedding of the input without changing its semantic, and augment the training data with the perturbed samples. We refer to this data augmentation method as Stochastic Word Embedding Perturbation (SWEP).\nThe objective of the noise generator is to maximize the log-likelihood of the answer of the input with perturbation, while minimizing the KullbackLeibler (KL) divergence between prior noise distribution and conditional noise distribution of given input. Since the perturbation function maximizes the likelihood of the answer of the perturbed input, it learns how to add noise without changing the semantics of the original input. Furthermore, minimizing the KL divergence prevents generating identical noise as the variance of the prior distribution is non-zero, i.e. we can sample diverse noise for the same input.\nWe empirically validate our data augmentation method on both extractive and generative QA tasks.\nWe train the QA model on the SQuAD dataset (Rajpurkar et al., 2016) with our learned perturbations, and evaluate the trained model on the five different domains — BioASQ (Tsatsaronis et al., 2012), New York Times, Reddit post, Amazon review, and Wikipedia (Miller et al., 2020) as well as SQuAD to measure the generalization performance on out-of-domain and in-domain data. The experimental results show that our method improves the in-domain performance as well as out-of-domain robustness of the model with this simple yet effective approach, while existing baseline methods often degrade the performance of the QA model, due to semantics changes in the words. Notably, our model trained only with the SQuAD dataset shows even better performance than the model trained with 240,422 synthetic QA pairs generated from a question generation model. Our contribution in this work is threefold.\n• We propose a simple yet effective data augmentation method to improve the generalization performance of pretrained language models for QA tasks.\n• We show that our learned input-dependent perturbation function transforms the original input without changing its semantics, which is crucial to the success of DA for question answering.\n• We extensively validate our method for domain generalization tasks on diverse datasets, on which it largely outperforms strong baselines, including a QA-pair generation method."
    }, {
      "heading" : "2 Related Work",
      "text" : "Data Augmentation As in image domains (Krizhevsky et al., 2012; Volpi et al.,\n2018; Yun et al., 2019), data augmentation methods are known to be an effective regularizer in text domain (Sennrich et al., 2016). However, unlike the image transformations that do not change their semantics, transforming raw texts without changing their semantics is difficult since they are composed of discrete tokens. The most common approach for data augmentation in NLP is applying simple perturbations to raw words, by either deleting a word or replacing it with synonyms (Wei and Zou, 2019). In addition, back-translation with neural machine translation has also been shown to be effective, as it paraphrases the original sentence with a different set and ordering of words while preserving the semantics to some extent (Xie et al., 2020). Beyond such simple heuristics, Ng et al. (2020) propose to mask the tokens and reconstruct them with pretrained language model to augment training data for text classification and machine translation. For QA tasks, question or QA-pair generation (Zhang and Bansal, 2019; Lee et al., 2020) are also popular augmentation techniques, which generate questions or question-answer pairs from an unlabeled paragraph, thus they can be utilized as additional data to train the model.\nDomain Generalization Unlike domain adaptation in which the target domains are fixed and we can access unlabeled data from them, domain generalization aims to generalize to unseen target domains without access to data from the target distribution. Several prior works (Li et al., 2018; Balaji et al., 2018; Tseng et al., 2020) propose metalearning frameworks to tackle domain generalization, focusing on image domains. For extractive QA, Lee et al. (2019) leverage adversarial training to learn a domain-invariant representation of question and context. However, they require multiple heterogeneous source datasets to train the model to be robust to Out-of-Domain data. In contrast, Volpi et al. (2018) leverage adversarial perturbation to generate fictitious examples from a single source dataset, that can generalize to unseen domains."
    }, {
      "heading" : "3 Method",
      "text" : ""
    }, {
      "heading" : "3.1 Brief Summary of Backgrounds",
      "text" : "The goal of extractive Question Answering (QA) is to point out the start and end position of the answer span y = (ystart, yend) from a paragraph (context) c = (c1, . . . , cL) with length L for a question x = (x1, . . . , xM ). For generative QA, it\naims to generate answer y = (y1, . . . , yK) instead of predicting the position of answer spans from the context. A typical approach to the QA is to train a neural networks to model the conditional distribution pθ(y|x, c), where θ are composed of θf and θg denoted for the parameters of the encoder f(·; θf ) and classifier or decoder g(·; θg) on top of the encoder. We estimate the parameter θ to maximize the log likelihood with N observations {x(i),y(i), c(i)}Ni=1, which are drawn from some unknown distribution ptrain, as follows:\nLMLE(θ) := N∑ i=1 log pθ(y (i)|x(i), c(i)) (1)\nFor convenience, we set the length T := L+M+3 and abuse notations to define the concatenated sequence of the question x and context c as x := (x0, . . . , xL, c0, . . . , cM+1) where x0, c0, cM+1 denote start, separation, and end symbol, respectively.\nHowever, the model trained to maximize the likelihood in Eq. (1) is prone to overfitting and brittle to distributional shifts where target distribution ptest is different from ptrain. In order to tackle this problem, we train the model with additional data drawn from different generative process to increase the support of training distribution, to achieve better generalization on novel data with distributional shifts. We will describe it in the next section."
    }, {
      "heading" : "3.2 Learning to Perturb Word Embeddings",
      "text" : "Several methods for data augmentation have been proposed in text domain, however, unlike in image domains (Verma et al., 2019a,b; Yun et al., 2019), there does not exist a set of well-defined data augmentation methods which transform the input without changing its semantics. We propose a new data augmentation scheme where we sample a noise z = (z1, . . . , zT ) from a distribution qφ(z|x) and perturb the input x with the sampled noise without altering its semantics. To this end, the likelihood pθ(y|x, z) should be kept high even after the perturbation, while the perturbed instance should not collapse to the original input. We estimate such parameters φ and θ by maximizing the following objective: Lnoise(φ, θ) := N∑ i=1 Eqφ(z|x(i))[log pθ(y (i)|x(i), z)]\n− β T∑ t=1 DKL(qφ(zt|x(i)) ‖ pψ(zt))\n(2)\nwhere β ≥ 0 is a hyper-parameter which controls the effect of KL-term. We assume that zt and zt′ are conditionally independent given x if t 6= t′, i.e., qφ(z|x) = ∏T t=1 qφ(zt|x). The parameter of prior ψ is a hyper-parameter to be specified. When β = 1, the objective corresponds to the Evidence Lower BOund (ELBO) of the marginal likelihood.\nMaximizing the expected log-likelihood term in Eq. (2) increases the likelihoods evaluated with the perturbed embeddings, and therefore the semantics of the inputs after perturbations are likely to be preserved. The KL divergence term in Eq. (2) penalizes the perturbation distribution qφ(z|x) deviating too much from the prior distribution pψ(z). We assume that the prior distribution is fully factorized, i.e. pψ(z1, . . . , zT ) = ∏T t=1 pψ(zt). Furthermore, we set each distribution pψ(zt) as a multivariate Gaussian distribution N (1, αId), where 1 = (1, . . . , 1) ∈ Rd, Id, α denotes a vector with ones, identity matrix, and positive real number, respectively. Hence, we expect the inputs perturbed with the multiplicative noises remain close to the original inputs on average. Note that the choice of the prior is closely related to Gaussian dropout (Srivastava et al., 2014); we will elaborate on this connection later.\nThe parameterization of the perturbation function qφ heavily affects the success of the learning with the objective (2). The function needs to control the intensity of perturbation for each token of x without changing the semantics. Since the meaning of each word varies across linguistic contexts, the function should be expressive enough to encode the sentence x into a meaningful latent space embedding to contextualize the subtle meaning of each word in the sentence.\nTo this end, we share the encoder function f(·; θf ) to contextualize the input x into hidden representation (h1, . . . ,hT ) and feed it into the perturbation function as input as shown in the left side of Fig. 2. However, we stop the gradient of φ with respect to L(φ, θ) propagating to the encoder f(·; θf ). Intuitively, it prevents noisy gradient from flowing to pθ for early stage of training. On top of the encoder, we stack two layer feed forward neural network with ReLU activation, which outputs mean µt ∈ Rd and variance σ2t ∈ Rd for each token, following Kingma and Welling (2014). We leverage the reparameterization trick (Kingma and Welling, 2014) to sample zt ∈ Rd. Since x is a sequence of discrete tokens, we map each token\nxt to corresponding word embedding et and multiply it with the noise zt in element-wise manner as follows:\net = WordEmbedding(xt)\n(h1, . . . ,hT ) = f(e1, . . . , eT ; θf )\nµt,σ 2 t = MLP(ht)\nzt = µt + σt , where ∼ N (0, Id) ẽt = et zt\n(3)\nwhere denotes element-wise multiplication. We feed (ẽ1, . . . , ẽT ) to the g ◦ f to compute the likelihood pθ(y|x, z) as shown in Fig. 2."
    }, {
      "heading" : "3.3 Learning Objective",
      "text" : "As described in the section 3.2, we can jointly optimize the parameters θ, φ with gradient ascent. However, we want to train the QA model with additional data drawn from the different generative process as well as the given training data to increase the support of training distribution, which leads to better regularization and robustness to the distributional shift. Therefore, our final learning objective function is a convex combination of LMLE(θ) and Lnoise(φ, θ) as follows:\nL(φ, θ) = λLMLE(θ)+ (1−λ)Lnoise(φ, θ) (4)\nwhere 0 < λ < 1 is a hyper-parameter which controls the importance of each objective. For all the experiments, we set λ as 0.5. In other words, we train the QA model to maximize the conditional log-likelihood of the original input and perturbed one with stochastic gradient ascent."
    }, {
      "heading" : "3.4 Connection to Dropout",
      "text" : "Since each random variable of the perturbation vector zt = (zt,1, . . . , zt,d) is independent, we only\nconsider the i−th coordinate. With the reparameterization trick, we can write zt,i = µt,i + σt,i i, where each i\niid∼ N (0, 1) and µt,i, σt,i are i−th component of µt,σt which are outputs of neural network as described in Eq. (3). Simply, each noise element zt,i is sampled fromN (µt,i, σ2t,i). Assume that z̃ is the noise sampled from the prior distributionN (1, α), i.e. z̃ = 1+α · where ∼ N (0, 1). Then, zt,i can be expressed in terms of z̃ as follows:\nzt,i = σ α z̃ + (µ− σ α ) (5)\nIf we set α = (1 − p)/p where p is the retention probability, we can consider z̃ as a Gaussian dropout mask sampled from N (1, 1−pp ), which shows comparable performance to dropout mask sampled from Bernoulli distribution with probability p (Srivastava et al., 2014). Then, we can interpret our perturbation function as the input dependent dropout which scales and translates the Gaussian dropout mask, and thus it flexibly controls the intensity of perturbation adaptively to each word embedding of the input x."
    }, {
      "heading" : "4 Experiment",
      "text" : ""
    }, {
      "heading" : "4.1 Task",
      "text" : "Our goal is to regularize the QA model to generalize to unseen domains, such that it is able to answer the questions from the new domain. We consider a more challenging setting where the model is trained with a single source dataset and evaluate it on the datasets from the unseen domains as well as on unseen examples from the source domain. Specifically, we train the QA model with SQuAD dataset (Rajpurkar et al., 2016) as source domain, test the model with several different target domain QA datasets — BioASQ (Tsatsaronis et al., 2012), New Wikipedia (Wiki), New York Times (NYT), Reddit posts, and Amazon Reviews (Miller et al., 2020). We evaluate the QA model with F1 and Exact Match (EM) score, following the convention for extractive QA tasks. For the BioASQ dataset, we use the dataset provided in the MRQA shared task (Fisch et al., 2019). We downloaded the other datasets from the official website of Miller et al. (2020)."
    }, {
      "heading" : "4.2 Experimental Setup",
      "text" : "Implementation Detail As for the encoder f , we use the pretrained language model — BERTbase (Devlin et al., 2019), ELECTRA-small (Clark\net al., 2020) for extractive QA and randomly initialize an affine transformation layer for g. For the generative QA task, we use a T5-small (Raffel et al., 2020) for f ◦ g as an encoder-decoder model. For the perturbation function qφ, we stack two feed-forward layers with ReLU on the encoder as described in section 3.2. For the extractive QA task, we train the model for 2 epochs with the batch size 8 and use AdamW optimizer (Loshchilov and Hutter, 2019) with the learning rate 3 · 10−5. For the T5 model, we train it for 4 epochs with batch size 64 and use Adafactor optimizer (Shazeer and Stern, 2018) with learning rate 10−4. We use beam search with width 4 to generate answers for generative question answering.\nBaselines We experiment with our model SWEP and its variant against several baselines.\n1. MLE: This is the base QA model fine-tuned to maximize LMLE(θ). 2. Adv-Aug: Following Volpi et al. (2018), we perturb the word embeddings of the input x with an adversarial objective and use them as additional training data to maximize LMLE(θ). We assume that the answer for each question and context remains the same after the adversarial perturbation. 3. Gaussian-Dropout This is the model whose word embedding is perturbed with dropout mask sampled from a Gaussian distribution N (1, 1−pp ), where p is dropout probability and set to be 0.1 (Srivastava et al., 2014). 4. Bernoulli-Dropout This is the model of which word embedding is perturbed with dropout mask sampled from Bernoulli distribution Ber(1− p), where p is dropout probability and set to be 0.1 (Srivastava et al., 2014). 5. Word-Dropout: This is the model trained to maximize LMLE(θ) with word dropout (Sennrich et al., 2016) where the tokens of x are randomly set to a zero embedding. 6. SSMBA: This is the QA model trained to maximize LMLE(θ), with additional examples generated by the technique proposed in (Ng et al., 2020), which are generated by corrupting the target sequences and reconstructing them using a masked language model, BERT. 7. Prior-Aug This is variant of SWEP trained with additional perturbed data, where the noise is drawn from the prior distribution pψ(z) rather than qφ(z|x).\n8. SWEP: This is our full model which maximizes the objective function in Eq. (4)."
    }, {
      "heading" : "4.3 Experimental Result",
      "text" : "We compare SWEP and its variant Prior-Aug with the baselines as described in section 4.1. As shown in Table 1, our model outperforms all the baselines, whose backbone networks are BERT or ELECTRA, on most of the datasets. The data augmentation with SSMBA improves the performance of ELECTRA on in-domain dataset SQuAD and Wiki. However, it significantly underperforms ours on out-ofdomain datasets even if the data augmentation with SSMBA use 4.8 times more data than ours. Similarly, Table 2 shows that the T5 model trained with our method consistently improves the performance of the model trained with MLE on most of the datasets.\nContrary to ours, SSMBA significantly degrades the performance of the BERT and T5 model both on in-domain and out-of-domain datasets. Since masking and reconstructing some of the tokens from a sentence with a masked language model may cause a semantic drift, those transformations make some questions unanswerable. As a result, the data augmentation with SSMBA often hurts the performance of the QA model. Similarly, Word-Dropout randomly zeros out word embedding of tokens, but some of zeroed out words are critical for answering questions. Adv-aug marginally improves the performance, but it requires an additional backward pass to compute the gradient for adversarial perturbation, which slows down the training procedure."
    }, {
      "heading" : "4.4 Low Resource QA",
      "text" : "We empirically show that our data augmentation SWEP is an effective regularizer in the setting where there are only a few annotated training examples. To simulate such a scenario, we reduce the number of labeled SQuAD data to 80%, 50%, 30%, and 10% and train the model with the same experimental setup as described in section 4.2. Fig. 3 shows the accuracy as a function of the percentage of QA pairs. Ours consistently improves the performance of the QA model at any ratios of labeled data. Even with 10% of labeled data, it increases EM and F1 score by 1%."
    }, {
      "heading" : "4.5 Data augmentation with QG",
      "text" : "We show that our data augmentation is sampleefficient and further improves the performance of\nthe QA model trained with additional synthetic data generated from the question-answer generation model (QG). We use Info-HCVAE (Lee et al., 2020) to generate QA pairs from unlabeled paragraphs and train the BERT model with humanannotated and synthetic QA pairs, while varying the number of the generated pairs. As shown in Fig. 4, SWEP trained only with SQuAD already outperforms the model trained with 240,422 synthetic QA pairs generated with Info-HCVAE. Moreover, when combining the two methods, we achieve even larger performance gains compared to when using either SWEP or Info-HCVAE alone, as the two approaches are orthogonal."
    }, {
      "heading" : "5 Analysis and Discussion",
      "text" : ""
    }, {
      "heading" : "5.1 Ablation Study",
      "text" : "We further perform an ablation study to verify the effectiveness of each component of SWEP. In Table 3, we present the experimental results while removing various parts of our model. First of all, we replace the elementwise multiplicative noise with elementwise additive noise and set the prior distribution as N (0, αId). We observe that the noise generator does not learn meaningful perturbation, which leads to performance degradation. Moreover, instead of learning µt or σt from the data, we fix either of them and perform experiments, which we\ndenote w/ fixed µ and w/ fixed σ. For all the time step t, we set µt as (1, . . . , 1) ∈ Rd for w/ fixed µ. For w/ fixed σ, we set σ2t as (1, . . . , 1) ∈ Rd, i.e. we use the identity matrix Id as the covariance of qφ(z|x). As shown in Table 3, fixing µt or σ2t with predefined values achieves slightly better performance than the Prior-Aug, but it degrades the performance of the full model. Based on this experimental results, we verify that learning µt or σ2t for each word embedding et is crucial to the success of the perturbation function, as it can delicately perturb each words with more flexibility.\nFurthermore, we convert the stochastic perturbation to deterministic one, which we denote as w/o ∼ N (0, Id). To be specific, the MLP(ht) in Eq. (2) only outputs µt alone and we multiply it with et without any sampling, i.e. ẽt = et µt. As shown in Table 3, the deterministic perturbation largely underperforms the full model. In terms of the objective function, we observe that removing LMLE(θ) results in larger performance drops, suggesting that using both augmented and original instance as a single batch is crucial for performance improvement. In addition, the experiment without DKL shows the importance of imposing a constraint on the distribution of perturbation with the KL-term."
    }, {
      "heading" : "5.2 Quantitative Analysis",
      "text" : "We quantitatively analyze the intensity of perturbations given to the input during the training. To quantitatively measure the semantic drift, we measure the extent to how many words are replaced\nwith another word during training for each data augmentation method and plot it in Fig. 6. Unlike SSMBA, which replaces the predefined percentage of words with others, the adversarial augmentation (Adv-Aug) or SWEP perturbs the word embeddings in the latent space. We project the perturbed embedding back to the input space to count how many words are changed. Specifically, each word wt ∈ R|V| is represented as the one-hot vector and mapped to word vector as et =Wewt, where V denotes the vocabulary for training data and We ∈ Rd×|V| is the word embedding matrix. Then, the perturbed word embedding ẽt is projected back to one-hot vector w̃t as follows:\n(v1, . . . , vd) > =W>e ẽt\nj = argmax i {v1, . . . , vi, . . . , vd}\nw̃t = one-hot(j, |V|)\n(6)\nwhere one-hot(j, |V|) makes a one hot vector of which j-th component is one with the length |V|.\nIn Fig. 6, we plot the ratio of how many words are replaced with others in raw data before and after each perturbation for each batch as training goes on. In Fig. 1, for example, SSMBA changes about 11 raw words while SWEP does not change any words. We observe that around 20% of perturbed words are not projected back to each original word if we apply the adversarial augmentation. Also, we see that the adversarial augmentation largely changes the semantics of the words although the perturbation at the final layer is within the epsilon neighborhood of its latent embedding. In contrast, the perturbation by SWEP rarely changes the original words except\nin the very early stage of training. This observation implies that SWEP learns the range of perturbation that preserves the semantics of the original input, which is important when augmenting data for QA tasks and verifies our concept described in Fig. 1."
    }, {
      "heading" : "5.3 Qualitative Analysis",
      "text" : "In Fig. 5, we visualize the value of the l2 distance between the original word and one with the perturbation after the training. We observe that the perturbation function qφ learns to generate adaptive perturbations for each word (i.e. the lowest intensity of perturbation on answer-like words “professor jerome green”). However, it is still unknown why the intensity of certain word is higher than the others and how much difference affects the dynamics of training. We have included more observation such as embedding space visualization in Figure 7."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We proposed a simple yet effective data augmentation method based on a stochastic word embedding perturbation for out-of-distribution QA tasks. Specifically, our stochastic noise generator learns to generate the adaptive noise depending on the contextualized embedding of each word. It maximizes the likelihood of input with perturbation, such that it learns to modulate the intensity of perturbation for each word embedding without changing the semantic of the given question and paragraph. We augmented the training data with the perturbed samples using our method, and trained the model with only a single source dataset and evaluate it on datasets from five different domains as well as the in-domain dataset. Based on the experimental results, we verified that our method improves both the performance of in-domain generalization and robustness to distributional shifts, outperforming the baseline data augmentation methods. Further quantitative and qualitative analysis suggest that our method learns to generate adaptive perturbation without a semantic drift.\nBroader Impact\nOur data augmentation method SWEP efficiently improves the robustness of the QA model to unseen out-of-domain data with a few additional computational cost. This robustness is crucial to the success of the real-world QA models, since they frequently encounter questions for unseen domains, from the end-users. While previous works such as (Lee et al., 2019) require a set of several heterogeneous datasets to learn domain-invariant representations, such is not a sample-efficient method, while our method is simple yet effective and can improve the robustness of the QA model only when trained on a single source dataset."
    }, {
      "heading" : "Acknowledgement",
      "text" : "This work was supported by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2019-0-00075, Artificial Intelligence Graduate School Program(KAIST)), Samsung Electronics Co., Ltd, 42Maru, and the Engineering Research Center Program through the National Research Foundation of Korea (NRF) funded by the Korean Government MSIT (NRF2018R1A5A1059921)."
    }, {
      "heading" : "A Experimental Setup",
      "text" : "A.1 Dataset Statistics Table 4 describes detailed dataset statistics.\nA.2 Baselines 1. Word-Dropout We set the same dropout\nprobability as 0.1, which is the same dropout probability of the backbone networks — BERT, ELECTRA, and T5 model.\n2. Adv-Aug We follow the adversarial perturbation from (Volpi et al., 2018). We set the number of iteration for perturbation as 5, which is much fewer steps than the original paper due to the computational cost.\n3. SSMBA We use the official code of the original paper1 to augment the training data from SQuAD. We set the probability of masking 0.25 and sample 8 different examples for each training data instance. In total, we synthesize 426,266 additional training instances.\n4. Prior-Aug We set the α as 0.1 which is the dropout probability of the backbone networks.\nA.3 Data Augmentation with QG Following the experimental setup from Lee et al. (2020), we split the original SQuAD validation dataset by half into new validation and test set. We download the synthetic QA pairs generated by their generative model Info-HCVAE from the github2 and augment SQuAD training data with them. They leverage the generative model to sample QA pairs from unlabeled paragraph of HarvestingQA dataset3 (Du and Cardie, 2018), varying the different portion of unlabeled paragraph (denoted as H×5%-H×50%). We first finetune BERT-base QA model with the synthetic QA pairs generated for 2 epochs and further train it with the original SQuAD training data for another 2 epochs. We use AdamW optimizer (Loshchilov and Hutter, 2019) and set learning rate 2 · 10−5 and 3 · 10−5 for pretraining and finetuning, respectively with batch size 32. We choose the best checkpoint based on the F1 score from the new validation dataset and evaluate F1 and Exact Match (EM) score on the new test dataset.\n1https://github.com/nng555/ssmba 2https://github.com/seanie12/\nInfo-HCVAE 3https://github.com/xinyadu/ HarvestingQA\nA.4 Computational Cost The number of parameters Our SWEP model requires few additional learnable parameters relative to the size of the language model. Specifically, our model costs only 3d2+3d number of additional parameters, which is less than 2M in the case of BERT-base model where d = 768. Compared to 110M parameters of BERT-base model, our model does not increase the number of parameters a lot.\nComputing infrastructure and Runtime In the case of the BERT-base model, the fine-tuning with SWEP costs less than 4 GPU hours with a single Titan XP GPU."
    }, {
      "heading" : "B Algorithm",
      "text" : "We describe the whole training procedure described in the section 3.3 as follows:\nAlgorithm 1 SWEP 1: Input:\nPre-trained Language Model θ Dataset D = {(x(1),y(1)), ..., (x(N),y(N))}\n2: while training do 3: for (x(i),y(i)) in D do 4: Forward data without perturbation to compute log pθ(y(i)|x(i)) 5: Sample z ∼ qφ(z|x(i)) 6: Forward data with perturbation and compute Lnoise(φ, θ) 7: Update θ, φ with L(φ, θ) 8: end for 9: end while"
    }, {
      "heading" : "C Further Analysis",
      "text" : "Motivated by observations from (Li et al., 2020), we further analyze the adaptive perturbation for\neach word. Li et al. (2020) observe that lowfrequency words disperse sparsely while highfrequency words concentrate densely on the word embedding space of BERT. Following the setting of (Li et al., 2020), we first measure the l2 distance between k-nearest neighbors of each word embedding. Specifically, we rank each word (wordpiece tokens) by frequency counted based on the SQuAD train set and sample 100 examples from the SQuAD train set for analysis. In Table 5, we also observe that low-frequency words have more distance to their neighbor than high-frequency words. Then, we measure the average l2 distance of word embedding before and after perturbation and the average perturbation size for each word as 1 d ∑d i=1 µt,i after the training. We observe that lowfrequency words tend to be perturbed more than high-frequency words. This observation suggests that the noise generator can recognize acceptable extents to perturb words depend on the word embedding distribution then tends to generate more perturbation on sparsely dispersed low-frequency words and less perturbation on densely concentrated high-frequency words. Note that we use beta annealing to magnify the difference for analysis so that the β becomes zero in the second epoch."
    }, {
      "heading" : "D Embedding Space Visualization",
      "text" : "In Figure 7, we visualize the embedding space using t-SNE (Maaten and Hinton, 2008) for both word embedding ((a), (b)) and contextualized embedding ((c), (d)) before and after perturbation from ELECTRA-small model. We sample the example from the SQuAD training set, which is the same example as Figure 1 in the main paper. SWEP encodes each input tokens xt to hidden representation ht with transformers and outputs a desirable noise for each word embedding. The noise zt is multiplied with the word embedding et of each token xt. We observe that the perturbed word embedding is mapped to a different space against orig-\ninal word embedding, however, the contextualized embedding is not much changed by the perturbation. Note that absolute positions are different in each plot because of the randomness inherent in the t-SNE algorithms."
    } ],
    "references" : [ {
      "title" : "Metareg: Towards domain generalization using meta-regularization",
      "author" : [ "Yogesh Balaji", "Swami Sankaranarayanan", "Rama Chellappa." ],
      "venue" : "Advances in Neural Information Processing Systems, 31:998– 1008.",
      "citeRegEx" : "Balaji et al\\.,? 2018",
      "shortCiteRegEx" : "Balaji et al\\.",
      "year" : 2018
    }, {
      "title" : "ELECTRA: pretraining text encoders as discriminators rather than generators",
      "author" : [ "Kevin Clark", "Minh-Thang Luong", "Quoc V. Le", "Christopher D. Manning." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa,",
      "citeRegEx" : "Clark et al\\.,? 2020",
      "shortCiteRegEx" : "Clark et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Harvesting paragraph-level question-answer pairs from wikipedia",
      "author" : [ "Xinya Du", "Claire Cardie." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1907–1917.",
      "citeRegEx" : "Du and Cardie.,? 2018",
      "shortCiteRegEx" : "Du and Cardie.",
      "year" : 2018
    }, {
      "title" : "MRQA 2019 shared task: Evaluating generalization in reading comprehension",
      "author" : [ "Adam Fisch", "Alon Talmor", "Robin Jia", "Minjoon Seo", "Eunsol Choi", "Danqi Chen." ],
      "venue" : "Proceedings of the 2nd Workshop on Machine Reading for Question Answering,",
      "citeRegEx" : "Fisch et al\\.,? 2019",
      "shortCiteRegEx" : "Fisch et al\\.",
      "year" : 2019
    }, {
      "title" : "Adversarial examples for evaluating reading comprehension systems",
      "author" : [ "Robin Jia", "Percy Liang." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-",
      "citeRegEx" : "Jia and Liang.,? 2017",
      "shortCiteRegEx" : "Jia and Liang.",
      "year" : 2017
    }, {
      "title" : "Autoencoding variational bayes",
      "author" : [ "Diederik P. Kingma", "Max Welling." ],
      "venue" : "International Conference on Learning Representations, ICLR 2014,.",
      "citeRegEx" : "Kingma and Welling.,? 2014",
      "shortCiteRegEx" : "Kingma and Welling.",
      "year" : 2014
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton." ],
      "venue" : "Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems",
      "citeRegEx" : "Krizhevsky et al\\.,? 2012",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Generating diverse and consistent QA pairs from contexts with information-maximizing hierarchical conditional vaes",
      "author" : [ "Dong Bok Lee", "Seanie Lee", "Woo Tae Jeong", "Donghwan Kim", "Sung Ju Hwang." ],
      "venue" : "Proceedings of the 58th Annual",
      "citeRegEx" : "Lee et al\\.,? 2020",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2020
    }, {
      "title" : "Domain-agnostic question-answering with adversarial training",
      "author" : [ "Seanie Lee", "Donggyu Kim", "Jangwon Park." ],
      "venue" : "Proceedings of the 2nd Workshop on Machine Reading for Question Answering, MRQA@EMNLP 2019, Hong Kong, China, Novem-",
      "citeRegEx" : "Lee et al\\.,? 2019",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2019
    }, {
      "title" : "On the sentence embeddings from pre-trained language models",
      "author" : [ "Bohan Li", "Hao Zhou", "Junxian He", "Mingxuan Wang", "Yiming Yang", "Lei Li." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning to generalize: Metalearning for domain generalization",
      "author" : [ "Da Li", "Yongxin Yang", "Yi-Zhe Song", "Timothy Hospedales." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Li et al\\.,? 2018",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2018
    }, {
      "title" : "Decoupled weight decay regularization",
      "author" : [ "Ilya Loshchilov", "Frank Hutter." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Loshchilov and Hutter.,? 2019",
      "shortCiteRegEx" : "Loshchilov and Hutter.",
      "year" : 2019
    }, {
      "title" : "Visualizing data using t-sne",
      "author" : [ "L.V.D. Maaten", "Geoffrey E. Hinton." ],
      "venue" : "Journal of Machine Learning Research, 9:2579–2605.",
      "citeRegEx" : "Maaten and Hinton.,? 2008",
      "shortCiteRegEx" : "Maaten and Hinton.",
      "year" : 2008
    }, {
      "title" : "The effect of natural distribution shift on question answering models",
      "author" : [ "John Miller", "Karl Krauth", "Benjamin Recht", "Ludwig Schmidt." ],
      "venue" : "International Conference on Machine Learning, pages 6905–6916. PMLR.",
      "citeRegEx" : "Miller et al\\.,? 2020",
      "shortCiteRegEx" : "Miller et al\\.",
      "year" : 2020
    }, {
      "title" : "Ssmba: Self-supervised manifold based data augmentation for improving out-of-domain robustness",
      "author" : [ "Nathan Ng", "Kyunghyun Cho", "Marzyeh Ghassemi." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Ng et al\\.,? 2020",
      "shortCiteRegEx" : "Ng et al\\.",
      "year" : 2020
    }, {
      "title" : "Meta back-translation",
      "author" : [ "Hieu Pham", "Xinyi Wang", "Yiming Yang", "Graham Neubig." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Pham et al\\.,? 2021",
      "shortCiteRegEx" : "Pham et al\\.",
      "year" : 2021
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J. Liu." ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Raffel et al\\.,? 2020",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2020
    }, {
      "title" : "Squad: 100, 000+ questions for machine comprehension of text",
      "author" : [ "Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin,",
      "citeRegEx" : "Rajpurkar et al\\.,? 2016",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2016
    }, {
      "title" : "Edinburgh neural machine translation systems for wmt 16",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers.",
      "citeRegEx" : "Sennrich et al\\.,? 2016",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2016
    }, {
      "title" : "Bidirectional attention flow for machine comprehension",
      "author" : [ "Min Joon Seo", "Aniruddha Kembhavi", "Ali Farhadi", "Hannaneh Hajishirzi." ],
      "venue" : "International Conference on Learning Representations, ICLR 2017,.",
      "citeRegEx" : "Seo et al\\.,? 2017",
      "shortCiteRegEx" : "Seo et al\\.",
      "year" : 2017
    }, {
      "title" : "Adafactor: Adaptive learning rates with sublinear memory cost",
      "author" : [ "Noam Shazeer", "Mitchell Stern." ],
      "venue" : "International Conference on Machine Learning.",
      "citeRegEx" : "Shazeer and Stern.,? 2018",
      "shortCiteRegEx" : "Shazeer and Stern.",
      "year" : 2018
    }, {
      "title" : "Dropout: a simple way to prevent neural networks from overfitting",
      "author" : [ "Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov." ],
      "venue" : "The journal of machine learning research.",
      "citeRegEx" : "Srivastava et al\\.,? 2014",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 2014
    }, {
      "title" : "Bioasq: A chal",
      "author" : [ "George Tsatsaronis", "Michael Schroeder", "Georgios Paliouras", "Yannis Almirantis", "Ion Androutsopoulos", "Éric Gaussier", "Patrick Gallinari", "Thierry Artières", "Michael R. Alvers", "Matthias Zschunke", "AxelCyrille Ngonga Ngomo" ],
      "venue" : null,
      "citeRegEx" : "Tsatsaronis et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Tsatsaronis et al\\.",
      "year" : 2012
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Manifold mixup: Better representations by interpolating hidden states",
      "author" : [ "Vikas Verma", "Alex Lamb", "Christopher Beckham", "Amir Najafi", "Ioannis Mitliagkas", "David Lopez-Paz", "Yoshua Bengio." ],
      "venue" : "Proceedings of the 36th International Conference",
      "citeRegEx" : "Verma et al\\.,? 2019a",
      "shortCiteRegEx" : "Verma et al\\.",
      "year" : 2019
    }, {
      "title" : "Manifold mixup: Better representations by interpolating hidden states",
      "author" : [ "Vikas Verma", "Alex Lamb", "Christopher Beckham", "Amir Najafi", "Ioannis Mitliagkas", "David Lopez-Paz", "Yoshua Bengio." ],
      "venue" : "International Conference on Machine Learning. PMLR.",
      "citeRegEx" : "Verma et al\\.,? 2019b",
      "shortCiteRegEx" : "Verma et al\\.",
      "year" : 2019
    }, {
      "title" : "Generalizing to unseen domains via adversarial data augmentation",
      "author" : [ "Riccardo Volpi", "Hongseok Namkoong", "Ozan Sener", "John C. Duchi", "Vittorio Murino", "Silvio Savarese." ],
      "venue" : "Advances in Neural Information Processing Systems 31: Annual",
      "citeRegEx" : "Volpi et al\\.,? 2018",
      "shortCiteRegEx" : "Volpi et al\\.",
      "year" : 2018
    }, {
      "title" : "EDA: easy data augmentation techniques for boosting performance on text classification tasks",
      "author" : [ "Jason W. Wei", "Kai Zou." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Wei and Zou.,? 2019",
      "shortCiteRegEx" : "Wei and Zou.",
      "year" : 2019
    }, {
      "title" : "Unsupervised data augmentation for consistency training",
      "author" : [ "Qizhe Xie", "Zihang Dai", "Eduard H. Hovy", "Thang Luong", "Quoc Le." ],
      "venue" : "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems",
      "citeRegEx" : "Xie et al\\.,? 2020",
      "shortCiteRegEx" : "Xie et al\\.",
      "year" : 2020
    }, {
      "title" : "Cutmix: Regularization strategy to train strong classifiers with localizable features",
      "author" : [ "Sangdoo Yun", "Dongyoon Han", "Seong Joon Oh", "Sanghyuk Chun", "Junsuk Choe", "Youngjoon Yoo." ],
      "venue" : "Proceedings of the IEEE International Conference on",
      "citeRegEx" : "Yun et al\\.,? 2019",
      "shortCiteRegEx" : "Yun et al\\.",
      "year" : 2019
    }, {
      "title" : "Addressing semantic drift in question generation for semisupervised question answering",
      "author" : [ "Shiyue Zhang", "Mohit Bansal." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Zhang and Bansal.,? 2019",
      "shortCiteRegEx" : "Zhang and Bansal.",
      "year" : 2019
    }, {
      "title" : "2018), varying the different portion of unlabeled paragraph (denoted as H×5%-H×50%). We first finetune BERT-base QA model with the synthetic QA pairs generated for 2 epochs and further train it with the original",
      "author" : [ "Du", "Cardie" ],
      "venue" : "ingQA",
      "citeRegEx" : "Du and Cardie,? \\Q2018\\E",
      "shortCiteRegEx" : "Du and Cardie",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 24,
      "context" : "1 Introduction Deep learning models have achieved impressive performances on a variety of real-world natural language understanding tasks such as text classification, machine translation, question answering, and text generation to name a few (Vaswani et al., 2017; Seo et al., 2017).",
      "startOffset" : 242,
      "endOffset" : 282
    }, {
      "referenceID" : 20,
      "context" : "1 Introduction Deep learning models have achieved impressive performances on a variety of real-world natural language understanding tasks such as text classification, machine translation, question answering, and text generation to name a few (Vaswani et al., 2017; Seo et al., 2017).",
      "startOffset" : 242,
      "endOffset" : 282
    }, {
      "referenceID" : 2,
      "context" : "Recently, language models that are pretrained with a large amount of unlabeled data have achieved breakthrough in the performance on these downstream tasks (Devlin et al., 2019), even surpassing human performance on some of them.",
      "startOffset" : 156,
      "endOffset" : 177
    }, {
      "referenceID" : 7,
      "context" : "Data augmentation (DA) techniques (Krizhevsky et al., 2012; Verma et al., 2019a; Yun et al., 2019; Sennrich et al., 2016) can prevent this to a certain extent, but most of them are developed for image domains and are not directly applicable to augmenting words and texts.",
      "startOffset" : 34,
      "endOffset" : 121
    }, {
      "referenceID" : 25,
      "context" : "Data augmentation (DA) techniques (Krizhevsky et al., 2012; Verma et al., 2019a; Yun et al., 2019; Sennrich et al., 2016) can prevent this to a certain extent, but most of them are developed for image domains and are not directly applicable to augmenting words and texts.",
      "startOffset" : 34,
      "endOffset" : 121
    }, {
      "referenceID" : 30,
      "context" : "Data augmentation (DA) techniques (Krizhevsky et al., 2012; Verma et al., 2019a; Yun et al., 2019; Sennrich et al., 2016) can prevent this to a certain extent, but most of them are developed for image domains and are not directly applicable to augmenting words and texts.",
      "startOffset" : 34,
      "endOffset" : 121
    }, {
      "referenceID" : 19,
      "context" : "Data augmentation (DA) techniques (Krizhevsky et al., 2012; Verma et al., 2019a; Yun et al., 2019; Sennrich et al., 2016) can prevent this to a certain extent, but most of them are developed for image domains and are not directly applicable to augmenting words and texts.",
      "startOffset" : 34,
      "endOffset" : 121
    }, {
      "referenceID" : 19,
      "context" : "A simple augmentation technique that preserves semantics is replacing words with synonyms or using back translation (Sennrich et al., 2016).",
      "startOffset" : 116,
      "endOffset" : 139
    }, {
      "referenceID" : 16,
      "context" : "However, they do not effectively improve the generalization performance because the diversity of viable transformations with such techniques is highly limited (Pham et al., 2021).",
      "startOffset" : 159,
      "endOffset" : 178
    }, {
      "referenceID" : 28,
      "context" : "Some recent works (Wei and Zou, 2019; Ng et al., 2020) propose data augmentation methods tailored for NLP tasks based on dropping or replacing words and show that such augmentation techniques improve the performance on the out-ofdomain as well as the in-domain tasks.",
      "startOffset" : 18,
      "endOffset" : 54
    }, {
      "referenceID" : 15,
      "context" : "Some recent works (Wei and Zou, 2019; Ng et al., 2020) propose data augmentation methods tailored for NLP tasks based on dropping or replacing words and show that such augmentation techniques improve the performance on the out-ofdomain as well as the in-domain tasks.",
      "startOffset" : 18,
      "endOffset" : 54
    }, {
      "referenceID" : 5,
      "context" : "1) might cause the drastic semantic drift of the answer (Jia and Liang, 2017).",
      "startOffset" : 56,
      "endOffset" : 77
    }, {
      "referenceID" : 18,
      "context" : "We train the QA model on the SQuAD dataset (Rajpurkar et al., 2016) with our learned perturbations, and evaluate the trained model on the five different domains — BioASQ (Tsatsaronis et al.",
      "startOffset" : 43,
      "endOffset" : 67
    }, {
      "referenceID" : 23,
      "context" : ", 2016) with our learned perturbations, and evaluate the trained model on the five different domains — BioASQ (Tsatsaronis et al., 2012), New York Times, Reddit post, Amazon review, and Wikipedia (Miller et al.",
      "startOffset" : 110,
      "endOffset" : 136
    }, {
      "referenceID" : 14,
      "context" : ", 2012), New York Times, Reddit post, Amazon review, and Wikipedia (Miller et al., 2020) as well as SQuAD to measure the generalization performance on out-of-domain and in-domain data.",
      "startOffset" : 67,
      "endOffset" : 88
    }, {
      "referenceID" : 19,
      "context" : ", 2019), data augmentation methods are known to be an effective regularizer in text domain (Sennrich et al., 2016).",
      "startOffset" : 91,
      "endOffset" : 114
    }, {
      "referenceID" : 28,
      "context" : "The most common approach for data augmentation in NLP is applying simple perturbations to raw words, by either deleting a word or replacing it with synonyms (Wei and Zou, 2019).",
      "startOffset" : 157,
      "endOffset" : 176
    }, {
      "referenceID" : 29,
      "context" : "In addition, back-translation with neural machine translation has also been shown to be effective, as it paraphrases the original sentence with a different set and ordering of words while preserving the semantics to some extent (Xie et al., 2020).",
      "startOffset" : 228,
      "endOffset" : 246
    }, {
      "referenceID" : 31,
      "context" : "For QA tasks, question or QA-pair generation (Zhang and Bansal, 2019; Lee et al., 2020) are also popular augmentation techniques, which generate questions or question-answer pairs from an unlabeled paragraph, thus they can be utilized as additional data to train the model.",
      "startOffset" : 45,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "For QA tasks, question or QA-pair generation (Zhang and Bansal, 2019; Lee et al., 2020) are also popular augmentation techniques, which generate questions or question-answer pairs from an unlabeled paragraph, thus they can be utilized as additional data to train the model.",
      "startOffset" : 45,
      "endOffset" : 87
    }, {
      "referenceID" : 11,
      "context" : "Several prior works (Li et al., 2018; Balaji et al., 2018; Tseng et al., 2020) propose metalearning frameworks to tackle domain generalization, focusing on image domains.",
      "startOffset" : 20,
      "endOffset" : 78
    }, {
      "referenceID" : 0,
      "context" : "Several prior works (Li et al., 2018; Balaji et al., 2018; Tseng et al., 2020) propose metalearning frameworks to tackle domain generalization, focusing on image domains.",
      "startOffset" : 20,
      "endOffset" : 78
    }, {
      "referenceID" : 30,
      "context" : "2 Learning to Perturb Word Embeddings Several methods for data augmentation have been proposed in text domain, however, unlike in image domains (Verma et al., 2019a,b; Yun et al., 2019), there does not exist a set of well-defined data augmentation methods which transform the input without changing its semantics.",
      "startOffset" : 144,
      "endOffset" : 185
    }, {
      "referenceID" : 22,
      "context" : "Note that the choice of the prior is closely related to Gaussian dropout (Srivastava et al., 2014); we will elaborate on this connection later.",
      "startOffset" : 73,
      "endOffset" : 98
    }, {
      "referenceID" : 6,
      "context" : "We leverage the reparameterization trick (Kingma and Welling, 2014) to sample zt ∈ Rd.",
      "startOffset" : 41,
      "endOffset" : 67
    }, {
      "referenceID" : 22,
      "context" : "If we set α = (1 − p)/p where p is the retention probability, we can consider z̃ as a Gaussian dropout mask sampled from N (1, 1−p p ), which shows comparable performance to dropout mask sampled from Bernoulli distribution with probability p (Srivastava et al., 2014).",
      "startOffset" : 242,
      "endOffset" : 267
    }, {
      "referenceID" : 18,
      "context" : "Specifically, we train the QA model with SQuAD dataset (Rajpurkar et al., 2016) as source domain, test the model with several different target domain QA datasets — BioASQ (Tsatsaronis et al.",
      "startOffset" : 55,
      "endOffset" : 79
    }, {
      "referenceID" : 23,
      "context" : ", 2016) as source domain, test the model with several different target domain QA datasets — BioASQ (Tsatsaronis et al., 2012), New Wikipedia (Wiki), New York Times (NYT), Reddit posts, and Amazon Reviews (Miller et al.",
      "startOffset" : 99,
      "endOffset" : 125
    }, {
      "referenceID" : 14,
      "context" : ", 2012), New Wikipedia (Wiki), New York Times (NYT), Reddit posts, and Amazon Reviews (Miller et al., 2020).",
      "startOffset" : 86,
      "endOffset" : 107
    }, {
      "referenceID" : 4,
      "context" : "For the BioASQ dataset, we use the dataset provided in the MRQA shared task (Fisch et al., 2019).",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 2,
      "context" : "2 Experimental Setup Implementation Detail As for the encoder f , we use the pretrained language model — BERTbase (Devlin et al., 2019), ELECTRA-small (Clark et al.",
      "startOffset" : 114,
      "endOffset" : 135
    }, {
      "referenceID" : 1,
      "context" : ", 2019), ELECTRA-small (Clark et al., 2020) for extractive QA and randomly initialize an affine transformation layer for g.",
      "startOffset" : 23,
      "endOffset" : 43
    }, {
      "referenceID" : 17,
      "context" : "For the generative QA task, we use a T5-small (Raffel et al., 2020) for f ◦ g as an encoder-decoder model.",
      "startOffset" : 46,
      "endOffset" : 67
    }, {
      "referenceID" : 12,
      "context" : "For the extractive QA task, we train the model for 2 epochs with the batch size 8 and use AdamW optimizer (Loshchilov and Hutter, 2019) with the learning rate 3 · 10−5.",
      "startOffset" : 106,
      "endOffset" : 135
    }, {
      "referenceID" : 21,
      "context" : "For the T5 model, we train it for 4 epochs with batch size 64 and use Adafactor optimizer (Shazeer and Stern, 2018) with learning rate 10−4.",
      "startOffset" : 90,
      "endOffset" : 115
    }, {
      "referenceID" : 19,
      "context" : "Word-Dropout: This is the model trained to maximize LMLE(θ) with word dropout (Sennrich et al., 2016) where the tokens of x are randomly set to a zero embedding.",
      "startOffset" : 78,
      "endOffset" : 101
    }, {
      "referenceID" : 15,
      "context" : "SSMBA: This is the QA model trained to maximize LMLE(θ), with additional examples generated by the technique proposed in (Ng et al., 2020), which are generated by corrupting the target sequences and reconstructing them using a masked language model, BERT.",
      "startOffset" : 121,
      "endOffset" : 138
    }, {
      "referenceID" : 8,
      "context" : "We use Info-HCVAE (Lee et al., 2020) to generate QA pairs from unlabeled paragraphs and train the BERT model with humanannotated and synthetic QA pairs, while varying the number of the generated pairs.",
      "startOffset" : 18,
      "endOffset" : 36
    }, {
      "referenceID" : 9,
      "context" : "While previous works such as (Lee et al., 2019) require a set of several heterogeneous datasets to learn domain-invariant representations, such is not a sample-efficient method, while our method is simple yet effective and can improve the robustness of the QA model only when trained on a single source dataset.",
      "startOffset" : 29,
      "endOffset" : 47
    }, {
      "referenceID" : 27,
      "context" : "Adv-Aug We follow the adversarial perturbation from (Volpi et al., 2018).",
      "startOffset" : 52,
      "endOffset" : 72
    }, {
      "referenceID" : 3,
      "context" : "They leverage the generative model to sample QA pairs from unlabeled paragraph of HarvestingQA dataset3 (Du and Cardie, 2018), varying the different portion of unlabeled paragraph (denoted as H×5%-H×50%).",
      "startOffset" : 104,
      "endOffset" : 125
    }, {
      "referenceID" : 12,
      "context" : "We use AdamW optimizer (Loshchilov and Hutter, 2019) and set learning rate 2 · 10−5 and 3 · 10−5 for pretraining and finetuning, respectively with batch size 32.",
      "startOffset" : 23,
      "endOffset" : 52
    }, {
      "referenceID" : 10,
      "context" : "C Further Analysis Motivated by observations from (Li et al., 2020), we further analyze the adaptive perturbation for",
      "startOffset" : 50,
      "endOffset" : 67
    }, {
      "referenceID" : 10,
      "context" : "Following the setting of (Li et al., 2020), we first measure the l2 distance between k-nearest neighbors of each word embedding.",
      "startOffset" : 25,
      "endOffset" : 42
    }, {
      "referenceID" : 13,
      "context" : "In Figure 7, we visualize the embedding space using t-SNE (Maaten and Hinton, 2008) for both word embedding ((a), (b)) and contextualized embedding ((c), (d)) before and after perturbation from ELECTRA-small model.",
      "startOffset" : 58,
      "endOffset" : 83
    } ],
    "year" : 2021,
    "abstractText" : "QA models based on pretrained language models have achieved remarkable performance on various benchmark datasets. However, QA models do not generalize well to unseen data that falls outside the training distribution, due to distributional shifts. Data augmentation (DA) techniques which drop/replace words have shown to be effective in regularizing the model from overfitting to the training data. Yet, they may adversely affect the QA tasks since they incur semantic changes that may lead to wrong answers for the QA task. To tackle this problem, we propose a simple yet effective DA method based on a stochastic noise generator, which learns to perturb the word embedding of the input questions and context without changing their semantics. We validate the performance of the QA models trained with our word embedding perturbation on a single source dataset, on five different target domains. The results show that our method significantly outperforms the baseline DA methods. Notably, the model trained with ours outperforms the model trained with more than 240K artificially generated QA pairs.",
    "creator" : "LaTeX with hyperref"
  }
}