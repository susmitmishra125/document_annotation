{
  "name" : "2021.acl-long.484.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "SENT: Sentence-level Distant Relation Extraction via Negative Training",
    "authors" : [ "Ruotian Ma", "Tao Gui", "Linyang Li", "Qi Zhang", "Xuanjing Huang", "Yaqian Zhou" ],
    "emails" : [ "rtma19@fudan.edu.cn", "tgui16@fudan.edu.cn", "linyangli19@fudan.edu.cn", "qz@fudan.edu.cn", "xjhuang@fudan.edu.cn", "yqzhou@fudan.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6201–6213\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n6201"
    }, {
      "heading" : "1 Introduction",
      "text" : "Relation extraction (RE), which aims to extract the relation between entity pairs from unstructured text, is a fundamental task in natural language processing. The extracted relation facts can benefit various downstream applications, e.g., knowledge graph completion (Bordes et al., 2013; Wang et al., 2014), information extraction (Wu and Weld, 2010) and question answering (Yao and Van Durme, 2014; Fader et al., 2014).\nA significant challenge for relation extraction is the lack of large-scale labeled data. Thus, distant\n∗ Corresponding authors.\nsupervision (Mintz et al., 2009) is proposed to gather training data through automatic alignment between a database and plain text. Such annotation paradigm results in an inevitable noise problem, which is alleviated by previous studies using multiinstance learning (MIL). In MIL, the training and testing processes are performed at the bag level, where a bag contains noisy sentences mentioning the same entity pair but possibly not describing the same relation. Studies using MIL can be broadly classified into two categories: 1) the soft de-noise methods that leverage soft weights to differentiate the influence of each sentence (Lin et al., 2016; Han et al., 2018c; Li et al., 2020; Hu et al., 2019a; Ye and Ling, 2019; Yuan et al., 2019a,b); 2) the hard de-noise methods that remove noisy sentences from the bag (Zeng et al., 2015; Qin et al., 2018; Han et al., 2018a; Shang, 2019).\nHowever, these bag-level approaches fail to map each sentence inside bags with explicit sentence labels. This problem limits the application of RE in some downstream tasks that require sentencelevel relation type, e.g., Yao and Van Durme (2014) and Xu et al. (2016) use sentence-level relation extraction to identify the relation between the answer and the entity in the question. Therefore, several studies (Jia et al. (2019); Feng et al. (2018)) have made efforts on sentence-level (or instance-level)\ndistant RE, empirically verifying the deficiency of bag-level methods on sentence-level evaluation. However, the instance selection approaches of these methods depend on rewards(Feng et al., 2018) or frequent patterns(Jia et al., 2019) determined by bag-level labels, which contain much noise. For one thing, one bag might be assigned to multiple bag labels, leading to difficulties in one-to-one mapping between sentences and labels. As shown in Fig.1, we have no access to the exact relation between “place of birth” and “employee of” for the sentence “Obama was born in the United States.”. For another, the sentences inside a bag might not express the bag relations. In Fig.1, the sentence “Obama was back to the United States yesterday” actually express the relation “live in”, which is not included in the bag labels.\nIn this work, we propose the use of negative training (NT) (Kim et al., 2019) for distant RE. Different from positive training (PT), NT trains a model by selecting the complementary labels of the given label, regarding that “the input sentence does not belong to this complementary label”. Since the probability of selecting a true label as a complementary label is low, NT decreases the risk of providing noisy information and prevents the model from overfitting the noisy data. Moreover, the model trained with NT is able to separate the noisy data from the training data (a histogram in Fig.3 shows the separated data distribution during NT). Based on NT, we propose SENT, a sentencelevel framework for distant RE. During SENT training, the noisy instances are not only filtered with a noise-filtering strategy, but also transformed into useful training data with a re-labeling method. We further design an iterative training algorithm to take full advantage of these data-refining processes, which significantly boost performance. Our codes are publicly available at Github1.\nTo summarize the contribution of this work:\n• We propose the use of negative training for sentence-level distant RE, which greatly protects the model from noisy information.\n• We present a sentence-level framework, SENT, which includes a noise-filtering and a re-labeling strategy for re-fining distant data.\n• The proposed method achieves significant improvement over previous methods in terms of both RE performance and de-noise effect.\n1https://github.com/rtmaww/SENT"
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Distant Supervision for RE",
      "text" : "Supervised relation extraction (RE) has been constrained by the lack of large-scale labeled data. Therefore, distant supervision (DS) is introduced by Mintz et al. (2009), which employs existing knowledge bases (KBs) as source of supervision instead of annotated text. Riedel et al. (2010) relaxes the DS assumption to the express-at-least-once assumption. As a result, multi-instance learning is introduced (Riedel et al. (2010); Hoffmann et al. (2011); Surdeanu et al. (2012)) for this task, where the training and evaluating process are performed in bag-level, with potential noisy sentences existing in each bag. Most following studies in distant RE adopt this paradigm, aiming to decrease the impact of noisy sentences in each bag. These studies include the attention-based methods to attend to useful information ( Lin et al. (2016); Han et al. (2018c); Li et al. (2020); Hu et al. (2019a); Ye and Ling (2019); Yuan et al. (2019a); Zhu et al. (2019); Yuan et al. (2019b); Wu et al. (2017)), the selection strategies such as RL or adversarial training to remove noisy sentences from the bag (Zeng et al. (2015); Shang (2019); Qin et al. (2018); Han et al. (2018a)) and the incorporation with extra information such as KGs, multi-lingual corpora or other information (Ji et al. (2017); Lei et al. (2018); Vashishth et al. (2018); Han et al. (2018b); Zhang et al. (2019); Qu et al. (2019); Verga et al. (2016); Lin et al. (2017); Wang et al. (2018); Deng and Sun (2019); Beltagy et al. (2019)). Other approaches include soft-label strategy for denoising (Liu et al. (2017)), leveraging pre-trained LM (Alt et al. (2019)), pattern-based method (Zheng et al. (2019)), structured learning method (Bai and Ritter (2019)) and so forth (Luo et al. (2017); Chen et al. (2019)).\nIn this work, we focus on sentence-level relation extraction. Several previous studies also perform Distant RE on sentence-level. Feng et al. (2018) proposes a reinforcement learning framework for sentence selecting, where the reward is given by the classification scores on bag labels. Jia et al. (2019) builds an initial training set and further select confident instances based on selected patterns. The difference between the proposed work and previous works is that we do not rely on bag-level labels for sentence selecting. Furthermore, we leverage NT to dynamically separate the noisy data from\nthe training data, thus can make use of diversified clean data."
    }, {
      "heading" : "2.2 Learning with Noisy Data",
      "text" : "Learning with noisy data is a widely discussed problem in deep learning, especially in the field of computer vision. Existing approaches include robust learning methods such as leveraging a robust loss function or regularization method(Lyu and Tsang, 2020; Zhang and Sabuncu, 2018; Hu et al., 2019b; Kim et al., 2019), re-weighting the loss of potential noisy samples (Ren et al., 2018; Jiang et al., 2018), modeling the corruption probability with a transition matrix (Goldberger and BenReuven, 2016; Xia et al.) and so on. Another line of research tries to recognize or even correct the noisy instances from the training data(Malach and Shalev-Shwartz, 2017; Yu et al., 2019; Arazo et al., 2019; Li et al., 2019).\nIn this paper, we focus on the noisy label problem in distant RE. We first leverage a robust negative loss (Kim et al., 2019) for model training. Then, we develop a new iterative training algorithm for noise selection and correction."
    }, {
      "heading" : "3 Methodology",
      "text" : "In order to achieve sentence-level relation classification using bag-level labels in distant RE, we propose a framework, SENT, which contains three main steps (as shown in Fig.2): (1) Separating the noisy data from the training data with negative training (Sec.3.1); (2) Filtering the noisy data as well as re-labeling a part of confident instances (Sec.3.2); (3) Leveraging an effective training algorithm based on (1) and (2) to further boost\nthe performance (Sec.3.3). Specifically, we denote the input data in this task as S∗ = {(s1, y∗1), . . . , (sN , y∗N )}, where y∗i ∈ R = {1, . . . , C} is the bag-level label of the ith input sentence si. Obviously, this is a noisy dataset drawn from a noisy distribution D∗ because these bag-level labels y∗ come from the distant label of each entity bag. For each si containing a pair of entities < e1, e2 >, y∗i is one of the relation facts2 that < e1, e2 > participates in in the database. Such annotation method indicates that y∗i is a potential noisy label for si. Here, we denote D as the real data distribution without noise, and the clean dataset drawn from D as S = {(s1, y1), . . . , (sN , yN )}. The ambition of this work is to find the best estimated parameters θ of the real mapping f : x → y, (x, y) ∈ D based on the noisy data S∗. We design three steps for achieving this goal: (1) Recognizing the set of noisy data S∗n from S\n∗ using negative training, where S∗n = {(si, y∗i ) | y∗i 6= yi}. (2) Refining S∗ by noise-filtering and re-labeling, e.g., S∗refined = (S\n∗ \\ S∗n) ∪ S∗n,relabeled, where S∗n,relabeled = {(si, yi) | (si, y∗i ) ∈ S∗n}. (3) Iteratively perform (1) and (2) so the refined dataset S∗refined approaches the real dataset S."
    }, {
      "heading" : "3.1 Negative Training on Distant Data",
      "text" : "In order to perform robust training on the noisy distant data, we propose the use of negative Training (NT), which trains based on the concept that “the input sentence does not belong to this complementary label”. We find that NT not only\n2Here, we randomly choose one of the multiple bag labels for injective relation classification. See details in Sec.4.2.\n0.0 0.2 0.4 0.6 0.8 1.0 Probability on given label\n0\n2000\n4000\n6000\n8000\n10000 12000 In st an ce n um be\nr After positive training Noisy data Clean data\n(a) Positive training\n0.0 0.2 0.4 0.6 0.8 Probability on given label\n0\n2000\n4000\n6000\n8000\n10000 After negative training\nNoisy data Clean data\n(b) Negative training\n0.0 0.2 0.4 0.6 0.8 1.0 Probability on given label\n0\n2000\n4000\n6000\n8000\n10000\n12000\n14000\nAfter SENT training Noisy data Clean data\n(c) After SENT\n0.0 0.2 0.4 0.6 0.8 1.0 Probability on given label\n0\n2500\n5000\n7500\n10000\n12500\n15000\nPT after SENT Noisy data Clean data\n(d) PT after SENT\nFigure 3: Data distribution when training with PT and SENT. (a) During PT, the confidence of the clean and noisy data increase simultaneously; (b) During NT, the confidence of the noisy data is much lower than that of the clean data; (c) After training with the SENT method, the clean and noisy data are further separated; (d) PT after SENT helps improve the convergence of the clean data.\nprovides less noisy information, but also separates the noisy and clean data during training."
    }, {
      "heading" : "3.1.1 Positive Training",
      "text" : "Positive training (PT) trains the model towards predicting the given label, based on the concept that “the input sentence belongs to this label”. Here, given any input s with a label y∗ ∈ R = {1, 2, . . . , C}, y ∈ {0, 1}C is the C-dimension one-hot vector of y∗. We denote p = f(s) as the probability vector of a sentence given by a relation classifier f(·). With the cross entropy loss function, the loss defined in typical positive training is:\nLPT (f, y∗) = − C∑\nk=1\nyk log pk (1)\nwhere pk denotes the probability of the kth label. Optimizing on Eq.1 meets the requirement of PL, as the probability of the given label approaches 1 with the loss decreasing."
    }, {
      "heading" : "3.1.2 Negative Training",
      "text" : "In negative training (NT), for each input s with a label y∗ ∈ R, we generate a complementary label y∗ by randomly sampling from the label space except y∗, e.g., y∗ ∈ R\\{y∗}. With the cross entropy loss function, we define the loss in negative training as:\nLNT (f, y∗) = − C∑\nk=1\nyk log(1− pk) (2)\nDifferent from PT, Eq.2 aims to reduce the probability value of the complementary label, as pk → 0 with the loss decreasing.\nTo further illustrate the effect of NT, we train the classifier with PT and NT respectively on a constructed TACRED dataset with 30% noise\n(details shown in Sec.4.1). A histogram3 of the training data after PT and NT is shown in Figs. 3(a),(b), which reveals that, when training with PT, the confidence of clean data and noisy data increase with no difference, resulting in the model to overfit noisy training data. On the contrary, when training with NT, the confidence of noisy data is much lower than that of clean data. This result confirms that the model trained with NT suffers less from overfitting noisy data with less noisy information provided. Moreover, as the confidence value of clean data and noisy data separate from each other, we are able to filter noisy data with a certain threshold. Fig.4 shows the details of the data-filtering effect. After the first iteration of NT, a modest threshold contributes to 97% precision noise-filtering with about 50% recall, which further verifies the effectiveness of NT on noisy data training."
    }, {
      "heading" : "3.2 Noise Filtering and Re-labeling",
      "text" : "In Section 3.1, we have illustrated the effectiveness of NT on training with noisy data, as well as the capability to recognize noisy instances. While filtering noisy data is important for training on distant data, these filtered data contain useful information that can boost performance if properly re-labeled. In this section, we describe the proposed noisefiltering and label-recovering strategy for refining distant data based on NT."
    }, {
      "heading" : "3.2.1 Filtering Noisy Data",
      "text" : "As discussed before, it is intuitive to construct a filtering strategy based on a certain threshold after NT. However, in distant RE, the long-tail problem cannot be neglected. During training, the\n3When drawing the histogram, we omitted the large amount of “NA”-class data (80% of the training data) for a clearer representation of the positive-class data.\ndegree of convergence is disparate among different classes. Simply setting a uniform threshold might harm the data distribution with instances of longtail relations largely filtered out. Therefore, we leverage a dynamic threshold for filtering noisy data. Suppose the probability of class c of the ith instance is pic ∈ (0, phc ), where phc is the maximum probability value in class c. Based on empirical experience, we assume the probability values follow a distribution where the noisy data are largely distributed in low-value areas and the clean data are generally distributed in middle- or high-value areas. Therefore, the filtering threshold of class c is set to:\nThc = Th · phc , phc = N max i=1 {pic} (3)\nwhere Th is a global threshold. In this way, the noise-filtering threshold not only relies on the degree of convergence in each class, but also dynamically changes during the training phase, thus making it more suitable for noise-filtering on long-tail data."
    }, {
      "heading" : "3.2.2 Re-labeling Useful Data",
      "text" : "After noise-filtering, the noisy instances are regarded as unlabeled data, which also contain useful information for training. Here, we design a simple strategy for re-labeling these unlabeled data. Given the set of filtered data Du = {s1, . . . , sm}, we use the classifier trained in this iteration to predict the probability vectors {p1, . . . ,pm}. Then, we re-label these instances by:\nŷi = argmax k {pik}, if max k {pik} > Threlabel\n(4) where pik is the probability of the i\nth instance in class k, and Threlabel is the re-label threshold."
    }, {
      "heading" : "3.3 Iterative Training Algorithm",
      "text" : "Although effective, simply performing a pipeline of NT, noise-filtering and re-labeling fail to take full advantage of each part, thus the model performance can be further boosted through iterative training.\nAs shown in Fig.2, for each iteration, we first train the classifier on the noisy data using NT: for each instance, we randomly sample K complementary labels and calculate the loss on these labels with Eq.(2). After M -epochs negative training, the noise-filtering and re-labeling processes are carried out for updating the training data. Next, we perform a new iteration of training\non the newly-refined data. Here, we re-initialize the classifier in every iteration for two reasons: First, re-initialization ensures that in each iteration, the new classifier is trained on a dataset with higher quality. Second, re-initialization introduces randomness, thus contributing to more robust data-filtering. Finally, we stop the iteration after observing the best result on the dev set. We then perform a round of noise-filtering and re-labeling with the best model in the last iteration to obtain the final refined data.\nFig.3(c) shows the data distribution after certain iterations of SENT. As seen, the noise and clean data are separated by a large margin. Most noisy data are successfully filtered out, with an acceptable number of clean data mistaken. However, we can see that the model trained with NT still lacks convergence (with low-confidence predictions). Therefore, we train the classifier on the iteratively-refined data with PT for better convergence. As shown in Fig.3(d), the model predictions on most of the clean data are in high confidence after PT training."
    }, {
      "heading" : "4 Experiments",
      "text" : "The experiments in this work are divided into two parts, respectively conducted on two datasets: the NYT-10 dataset (Riedel et al., 2010) and the TACRED dataset (Zhang et al., 2017).\nThe first part is the effectiveness study on sentence-level evaluation for distant RE. Different from bag-level evaluation, a sentence-level evaluation compute Precision (Prec.), Recall (Rec.) and F1 metric directly on all of the individual instances in the dataset. In this part, we adopt the NYT10 data set for sentence-level training, following the setting of Jia et al. (2019), who publishes a manually labeled sentence-level test set. 4 Besides, they also publish a test set for evaluating noisefiltering ability. Details of the adopted dataset are shown in Table 1.\nWe construct the second part of experiments (Sec.4.4) to better understand SENT’s behaviors. Since no labeled training data are available in the distant supervision setting, we construct a noisy dataset with 30% noise from a labeled dataset, TACRED (Zhang et al., 2017) 5. We regard this constructed dataset as noisy-TACRED. The reason\n4https://github.com/PaddlePaddle/Research/tree/master/ NLP/ACL2019-ARNOR\n5https://github.com/yuhaozhang/tacred-relation\nwe choose this dataset is that 80% instances in the training data are “no relation”. This “NA” rate is similar to the NYT data which contains 70% “NA” relation type, thus analysis on this dataset is more credible.\nWhen constructing noisy-TACRED, the noisy instances are uniformly selected with 30% noise ratio. Then, each noisy label is created by sampling a label from a complementary class with a weight of class frequency (in order to maintain the data distribution). Note that the original dataset consists of 80% “no relation” data, which means 80% of the noisy instances are “false-positive” instances, corresponding to the large amount of “false-positive” noise in NYT-10. Details of the noisy-TACRED are also shown in Table 1."
    }, {
      "heading" : "4.1 Baselines",
      "text" : "We compare our SENT method with several strong baselines in distant RE. These compared methods can be categorized as: bag-level denoising methods, sentence-level denoising methods, sentence-level non-denoising methods.\nPCNN+SelATT (Lin et al., 2016): A bag-level RE model which leverages an attention mechanism to reduce noise effect.\nPCNN+RA BAG ATT (Ye and Ling, 2019) short for PCNN+ATT RA+BAG ATT, a bag-level model containing both intra-bag and inter-bag attentions to alleviate noise.\nCNN+RL1 (Qin et al., 2018): A RL-based bag-level method. Different from CNN+RL2, they redistribute the filtered data into the negative examples.\nCNN+RL2 (Feng et al., 2018): A sentence-level RE model. It jointly train a instance selector and a\n6Statistics of NYT-10 are quoted from (Jia et al., 2019).\nCNN classifier using reinforcement learning (RL). ARNOR (Jia et al., 2019): A sentence-level RE model which selects confident instances based on the attention score on the selected patterns. It is the state-of-the-art method in sentence level.\nCNN (Zeng et al., 2014), PCNN (Zeng et al., 2015) and BiLSTM (Zhang et al., 2015) are typical architectures used in RE.\nBiLSTM+ATT (Zhang et al., 2017) leverages an attention mechanism based on BiLSTM to capture useful information.\nBiLSTM+BERT (Devlin et al., 2019): Based on BiLSTM, it utilizes the pre-trained BERT representations as word embedding."
    }, {
      "heading" : "4.2 Implementation Details",
      "text" : "As SENT is a model-agnostic framework, we implement the classification model with two typical architectures: BiLSTM and BiLSTM+BERT. Since BiLSTM is also the base model of ARNOR, we can compare these two methods more fairly. During SENT training, we use the 50-dimension glove vectors as word embedding. While for PT after SENT, we randomly initialize the 50-dimension word embedding as the same in ARNOR. In both training phases, we use 50-dimension randomlyinitialized position and entity type embedding. We train a single-layer BiLSTM with hidden size 256 using the adam optimizer at a learning rate of 5e-4. When implemented with BiLSTM+BERT, the setting is the same as those with BiLSTM except that we use a 768-dimension fixed BERT representation as word embedding (we use the “bert-base-uncased” pre-trained model). We tune the hyperparameters on the development set via a grid search. Specifically, when training on the NYT dataset, we train the model for 10 epochs in each iteration, with the global data-filtering threshold Th = 0.25, the re-labeling threshold Threlabel = 0.7 and negative samples number K = 10. When training on the noisy-TACRED, we train for 50 epochs in each iteration, with Th = 0.15, Threlabel = 0.85 and K = 50.\nTo deal with the multi-label problem, we utilize a simple method by randomly selecting one of the bag labels for each sentence. Such random selection turns the multi-label noise into the wronglabel noise, which is easier to handle. According to Surdeanu et al. (2012), there are 31% wrong-label noise and 7.5% multi-label noise in NYT-10, and incorrect selection may result in 4% extra wrong-\nlabel noise, which can be filtered out through NT identically with wrong-label instances."
    }, {
      "heading" : "4.3 Sentence-Level Evaluation",
      "text" : "Table 2 shows the results of SENT and other baselines on sentence-level evaluation, where the results of SENT are obtained by PT after SENT. We can observe that: 1) Bag-level methods fail to perform well on sentence-level evaluation, indicating that it is difficult for these bag-level approaches to benefit downstream tasks with exact sentence labels. This result is consistent with the results in Feng et al. (2018). 2) When performing sentence-level training on the noisy distant data, all baseline models show poor results, including the preeminent pre-trained language model BERT. These results indicate the negative impact of directly using bag-level labels for sentence-level training regardless of noise. 3) The proposed SENT method achieves a significant improvement over previous sentencelevel de-noising methods. When implemented with BiLSTM, the model obtains a 4.09% higher F1 score than ARNOR. Moreover, when implemented with BiLSTM+BERT, the F1 score is further improved by 8.52%. 4) The SENT method achieves much higher precision than the previous de-noising methods when maintaining comparable or higher recall, indicating the effectiveness of the noisefiltering and re-labeling approaches."
    }, {
      "heading" : "4.3.1 Noise-Filtering Effect on Distant Data",
      "text" : "In order to prove the effectiveness of SENT in denoising distant data, we conduct a noise-filtering experiment following ARNOR. We use a test set published by ARNOR, which consists of 200 randomly selected sentences with an “is noise” annotation. We perform a noise-filtering process as described in Sec.3.2.1, and calculate the de-noise accuracy. As seen in Table 3, the SENT method achieves remarkable improvement over ARNOR in F1 score by 12%. While improving in precision, SENT achieves 20% gain over ARNOR in recall. As ARNOR initializes the training data with a small part of frequent patterns, these patterns might limit the model from generalizing to various correct data. Different from ARNOR, SENT leverages negative training to automatically learn the correct patterns, showing better ability in diversity and generalization."
    }, {
      "heading" : "4.4 Analysing SENT on “Labeled Noise”",
      "text" : "In this section, we analyze the effectiveness of the data-refining process with a self-constructed noisy data set: noisy-TACRED (details in Table 1)."
    }, {
      "heading" : "4.4.1 Performance on Noisy-TACRED",
      "text" : "Table 4 shows the results of training on TACRED and noisy-TACRED. As seen, the baseline model degrades dramatically on the noisy data, with the LSTM dropping by 20.2%. However, after training with SENT, the BiLSTM model can achieve comparable results with the model that trained on the clean data. Note that the de-noising method is quite helpful in promoting the precision score, yet the recall is still lower than that on clean data."
    }, {
      "heading" : "4.4.2 Effects of Data-Refining",
      "text" : "We also evaluate the noise-filtering and labelrecovering ability on the noisy-TACRED training set, as shown in Fig.4. We can observe that: 1) SENT achieves about 85% F1 score on the noisyTACRED data. This result is consistent with the noise-filtering results obtained on the NYT dataset\n(with 200 sampled instances), validating the denoising ability of SENT on different datasets. 2) As the training iteration progressed, the precision of noise-filtering decreases with the recall promoting. More noise-filtering contributes to a cleaner dataset, while it might bring more false-noise mistakes. Therefore, we stop the iteration when the model reaches the best score on the development set. 3) As for label-recovering, SENT can achieve about 70% precision with about 25% recall. Here, the threshold setting is also a trade-off that we prefer to adopt a modest value for more accurate re-labeling."
    }, {
      "heading" : "4.4.3 Effects of Dynamically Filtering",
      "text" : "As described in Sec.3.2, we design a dynamic filtering threshold for long-tail data. The effect of this strategy is shown in Fig.5. As seen, the degree of convergence of the long-tail relation “per:cause of death” is much lower than that of the head relation. Simply setting a uniform threshold would harm the data distribution with instances of “per:cause of death” largely filtered. While with a dynamically determined threshold, both data from the head and the long-tail relations are appropriately filtered."
    }, {
      "heading" : "4.5 Ablation Study",
      "text" : "To better illustrate the contribution of each component in SENT, we conduct an ablation study by removing the following components: final PT, re-labeling, dynamic threshold, re-initialization, NT. The test results are shown in Table 6. We can observe that: 1) Removing the final positive training affects little to the performance. This is because the model trained with NT already reaches high accuracy and the purpose of final PT is only to achieve more confidential predictions. 2) Removing the re-labeling process harms the performance, as the filtered instances are simply discarded regardless of the useful information for\ntraining. 3) Without dynamic threshold, clean instances from the tail classes are incorrectly filtered out, which severely degrades the performance. 4) Re-initialization also contributes a lot to the performance. The model trained on the original noisy data inevitably fits to the noisy distribution, while re-initialization helps wash out the overfitted parameters and eliminate the noise effects, thus contributing to better training and noise-filtering. 5) Training with PT instead of NT causes a dramatic decline in performance, especially on the precision, which verifies the effectiveness of NT to prevent the model from overfitting noisy data."
    }, {
      "heading" : "4.6 Case Study",
      "text" : "As discussed, SENT is able to refine the distant RE dataset. In fact, there exists much noise in the NYT data that is difficult to tackle with bag-level methods. In Table 5, we show some examples. (1) The first two rows are the sentences in a multi-label bag. We randomly choose one of the bag labels for each sentence, and the model is able to correct the bad choice (by correcting the second sentence with “place lived” and the first sentence with “NA”). (2) The following three rows show a bag with\nlabel “place of death”, while this whole bag is actually a “NA” bag incorrectly labeled positive. (3) SENT can also recognize the positive samples in “NA”. As shown in the last three rows, each sentence labeled as “NA” is actually expressing a positive label. In fact, such false-negative problem is frequently seen in the NYT data, which contains 70% negative instances that were labeled “NA” only because the entity pairs do not participate in a relation in the database. We believe the capacity to recognize these false-negative samples can significantly boost the performance."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we present SENT, a novel sentencelevel framework based on Negative Training (NT) for sentence-level training on distant RE data. NT not only prevent the model from overfitting noisy data, but also separate the noisy data from the training data. By iteratively performing noisefiltering and re-labeling based on NT, SENT helps re-fine the noisy distant data and achieves remarkable performance. Experimental results verify the improvement of SENT over previous methods on sentence-level relation extraction and noise-filtering effect."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The authors wish to thank the anonymous reviewers for their helpful comments. This work was partially funded by China National Key R&D Program (No. 2018YFB1005100), National Natural Science Foundation of China (No. 61976056, 62076069), Shanghai Municipal Science and Technology Major Project (No.2021SHZDZX0103)."
    } ],
    "references" : [ {
      "title" : "Fine-tuning pre-trained transformer language models to distantly supervised relation extraction",
      "author" : [ "Christoph Alt", "Marc Hübner", "Leonhard Hennig." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Alt et al\\.,? 2019",
      "shortCiteRegEx" : "Alt et al\\.",
      "year" : 2019
    }, {
      "title" : "Unsupervised label noise modeling and loss correction",
      "author" : [ "Eric Arazo", "Diego Ortego", "Paul Albert", "Noel O’Connor", "Kevin McGuinness" ],
      "venue" : "In International Conference on Machine Learning,",
      "citeRegEx" : "Arazo et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Arazo et al\\.",
      "year" : 2019
    }, {
      "title" : "Structured Minimally Supervised Learning for Neural Relation Extraction",
      "author" : [ "Fan Bai", "Alan Ritter." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
      "citeRegEx" : "Bai and Ritter.,? 2019",
      "shortCiteRegEx" : "Bai and Ritter.",
      "year" : 2019
    }, {
      "title" : "Combining distant and direct supervision for neural relation extraction",
      "author" : [ "Iz Beltagy", "Kyle Lo", "Waleed Ammar." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
      "citeRegEx" : "Beltagy et al\\.,? 2019",
      "shortCiteRegEx" : "Beltagy et al\\.",
      "year" : 2019
    }, {
      "title" : "Translating embeddings for modeling multirelational data",
      "author" : [ "Antoine Bordes", "Nicolas Usunier", "Alberto GarciaDuran", "Jason Weston", "Oksana Yakhnenko." ],
      "venue" : "Advances in neural information processing systems, 26:2787–2795.",
      "citeRegEx" : "Bordes et al\\.,? 2013",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2013
    }, {
      "title" : "Uncover the ground-truth relations in distant supervision: A neural expectationmaximization framework",
      "author" : [ "Junfan Chen", "Richong Zhang", "Yongyi Mao", "Hongyu Guo", "Jie Xu." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Leveraging 2hop distant supervision from table entity pairs for relation extraction",
      "author" : [ "Xiang Deng", "Huan Sun." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Deng and Sun.,? 2019",
      "shortCiteRegEx" : "Deng and Sun.",
      "year" : 2019
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Open question answering over curated and extracted knowledge bases",
      "author" : [ "Anthony Fader", "Luke Zettlemoyer", "Oren Etzioni." ],
      "venue" : "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1156–",
      "citeRegEx" : "Fader et al\\.,? 2014",
      "shortCiteRegEx" : "Fader et al\\.",
      "year" : 2014
    }, {
      "title" : "Reinforcement learning for relation classification from noisy data",
      "author" : [ "Jun Feng", "Minlie Huang", "Li Zhao", "Yang Yang", "Xiaoyan Zhu." ],
      "venue" : "Proceedings of the aaai conference on artificial intelligence.",
      "citeRegEx" : "Feng et al\\.,? 2018",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2018
    }, {
      "title" : "Training deep neural-networks using a noise adaptation",
      "author" : [ "Jacob Goldberger", "Ehud Ben-Reuven" ],
      "venue" : null,
      "citeRegEx" : "Goldberger and Ben.Reuven.,? \\Q2016\\E",
      "shortCiteRegEx" : "Goldberger and Ben.Reuven.",
      "year" : 2016
    }, {
      "title" : "Denoising distant supervision for relation extraction via instance-level adversarial training",
      "author" : [ "Xu Han", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "arXiv preprint arXiv:1805.10959.",
      "citeRegEx" : "Han et al\\.,? 2018a",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2018
    }, {
      "title" : "Neural knowledge acquisition via mutual attention between knowledge graph and text",
      "author" : [ "Xu Han", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.",
      "citeRegEx" : "Han et al\\.,? 2018b",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2018
    }, {
      "title" : "Hierarchical relation extraction with coarse-to-fine grained attention",
      "author" : [ "Xu Han", "Pengfei Yu", "Zhiyuan Liu", "Maosong Sun", "Peng Li." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2236–2245.",
      "citeRegEx" : "Han et al\\.,? 2018c",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2018
    }, {
      "title" : "Knowledgebased weak supervision for information extraction of overlapping relations",
      "author" : [ "Raphael Hoffmann", "Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S. Weld." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association",
      "citeRegEx" : "Hoffmann et al\\.,? 2011",
      "shortCiteRegEx" : "Hoffmann et al\\.",
      "year" : 2011
    }, {
      "title" : "Improving distantly-supervised relation extraction with joint label embedding",
      "author" : [ "Linmei Hu", "Luhao Zhang", "Chuan Shi", "Liqiang Nie", "Weili Guan", "Cheng Yang." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural",
      "citeRegEx" : "Hu et al\\.,? 2019a",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2019
    }, {
      "title" : "Simple and effective regularization methods for training on noisily labeled data with generalization guarantee",
      "author" : [ "Wei Hu", "Zhiyuan Li", "Dingli Yu." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Hu et al\\.,? 2019b",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2019
    }, {
      "title" : "Distant supervision for relation extraction with sentence-level attention and entity descriptions",
      "author" : [ "Guoliang Ji", "Kang Liu", "Shizhu He", "Jun Zhao" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "Ji et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Ji et al\\.",
      "year" : 2017
    }, {
      "title" : "ARNOR: Attention regularization based noise reduction for distant supervision relation classification",
      "author" : [ "Wei Jia", "Dai Dai", "Xinyan Xiao", "Hua Wu." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1399–",
      "citeRegEx" : "Jia et al\\.,? 2019",
      "shortCiteRegEx" : "Jia et al\\.",
      "year" : 2019
    }, {
      "title" : "MentorNet: Learning datadriven curriculum for very deep neural networks on corrupted labels",
      "author" : [ "Lu Jiang", "Zhengyuan Zhou", "Thomas Leung", "Li-Jia Li", "Li Fei-Fei." ],
      "venue" : "Proceedings of the 35th International Conference on Machine Learning,",
      "citeRegEx" : "Jiang et al\\.,? 2018",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2018
    }, {
      "title" : "Nlnl: Negative learning for noisy labels",
      "author" : [ "Youngdong Kim", "Junho Yim", "Juseung Yun", "Junmo Kim." ],
      "venue" : "Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 101–110.",
      "citeRegEx" : "Kim et al\\.,? 2019",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2019
    }, {
      "title" : "Cooperative denoising for distantly supervised relation extraction",
      "author" : [ "Kai Lei", "Daoyuan Chen", "Yaliang Li", "Nan Du", "Min Yang", "Wei Fan", "Ying Shen." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages",
      "citeRegEx" : "Lei et al\\.,? 2018",
      "shortCiteRegEx" : "Lei et al\\.",
      "year" : 2018
    }, {
      "title" : "Dividemix: Learning with noisy labels as semisupervised learning",
      "author" : [ "Junnan Li", "Richard Socher", "Steven CH Hoi." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Self-attention enhanced selective gate with entityaware embedding for distantly supervised relation extraction",
      "author" : [ "Yang Li", "Guodong Long", "Tao Shen", "Tianyi Zhou", "Lina Yao", "Huan Huo", "Jing Jiang." ],
      "venue" : "Proceedings of the AAAI Conference on",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural relation extraction with multi-lingual attention",
      "author" : [ "Yankai Lin", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 34–43, Vancouver,",
      "citeRegEx" : "Lin et al\\.,? 2017",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2017
    }, {
      "title" : "Neural relation extraction with selective attention over instances",
      "author" : [ "Yankai Lin", "Shiqi Shen", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume",
      "citeRegEx" : "Lin et al\\.,? 2016",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2016
    }, {
      "title" : "A soft-label method for noisetolerant distantly supervised relation extraction",
      "author" : [ "Tianyu Liu", "Kexiang Wang", "Baobao Chang", "Zhifang Sui." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Liu et al\\.,? 2017",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2017
    }, {
      "title" : "Curriculum loss: Robust learning and generalization against label corruption",
      "author" : [ "Yueming Lyu", "Ivor W. Tsang." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Lyu and Tsang.,? 2020",
      "shortCiteRegEx" : "Lyu and Tsang.",
      "year" : 2020
    }, {
      "title" : "Decoupling” when to update” from” how to update",
      "author" : [ "Eran Malach", "Shai Shalev-Shwartz." ],
      "venue" : "NIPS.",
      "citeRegEx" : "Malach and Shalev.Shwartz.,? 2017",
      "shortCiteRegEx" : "Malach and Shalev.Shwartz.",
      "year" : 2017
    }, {
      "title" : "Distant supervision for relation extraction without labeled data",
      "author" : [ "Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky." ],
      "venue" : "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference",
      "citeRegEx" : "Mintz et al\\.,? 2009",
      "shortCiteRegEx" : "Mintz et al\\.",
      "year" : 2009
    }, {
      "title" : "Robust distant supervision relation extraction via deep reinforcement learning",
      "author" : [ "Pengda Qin", "Weiran Xu", "William Yang Wang." ],
      "venue" : "arXiv preprint arXiv:1805.09927.",
      "citeRegEx" : "Qin et al\\.,? 2018",
      "shortCiteRegEx" : "Qin et al\\.",
      "year" : 2018
    }, {
      "title" : "A fine-grained and noise-aware method for neural relation extraction",
      "author" : [ "Jianfeng Qu", "Wen Hua", "Dantong Ouyang", "Xiaofang Zhou", "Ximing Li." ],
      "venue" : "Proceedings of the 28th ACM International Conference on Information and Knowledge Manage-",
      "citeRegEx" : "Qu et al\\.,? 2019",
      "shortCiteRegEx" : "Qu et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning to reweight examples for robust deep learning",
      "author" : [ "Mengye Ren", "Wenyuan Zeng", "Bin Yang", "Raquel Urtasun." ],
      "venue" : "Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning",
      "citeRegEx" : "Ren et al\\.,? 2018",
      "shortCiteRegEx" : "Ren et al\\.",
      "year" : 2018
    }, {
      "title" : "Modeling relations and their mentions without labeled text",
      "author" : [ "Sebastian Riedel", "Limin Yao", "Andrew McCallum." ],
      "venue" : "Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 148–163. Springer.",
      "citeRegEx" : "Riedel et al\\.,? 2010",
      "shortCiteRegEx" : "Riedel et al\\.",
      "year" : 2010
    }, {
      "title" : "Are noisy sentences useless for distant supervised relation extraction",
      "author" : [ "Yuming Shang" ],
      "venue" : null,
      "citeRegEx" : "Shang.,? \\Q2019\\E",
      "shortCiteRegEx" : "Shang.",
      "year" : 2019
    }, {
      "title" : "Multi-instance multi-label learning for relation extraction",
      "author" : [ "Mihai Surdeanu", "Julie Tibshirani", "Ramesh Nallapati", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Surdeanu et al\\.,? 2012",
      "shortCiteRegEx" : "Surdeanu et al\\.",
      "year" : 2012
    }, {
      "title" : "RESIDE: Improving distantly-supervised neural relation extraction using side information",
      "author" : [ "Shikhar Vashishth", "Rishabh Joshi", "Sai Suman Prayaga", "Chiranjib Bhattacharyya", "Partha Talukdar." ],
      "venue" : "In",
      "citeRegEx" : "Vashishth et al\\.,? 2018",
      "shortCiteRegEx" : "Vashishth et al\\.",
      "year" : 2018
    }, {
      "title" : "Multilingual relation extraction using compositional universal schema",
      "author" : [ "Patrick Verga", "David Belanger", "Emma Strubell", "Benjamin Roth", "Andrew McCallum." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the",
      "citeRegEx" : "Verga et al\\.,? 2016",
      "shortCiteRegEx" : "Verga et al\\.",
      "year" : 2016
    }, {
      "title" : "Adversarial multi-lingual neural relation extraction",
      "author" : [ "Xiaozhi Wang", "Xu Han", "Yankai Lin", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 1156–1166, Santa Fe, New",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Knowledge graph embedding by translating on hyperplanes",
      "author" : [ "Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 28.",
      "citeRegEx" : "Wang et al\\.,? 2014",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2014
    }, {
      "title" : "Open information extraction using Wikipedia",
      "author" : [ "Fei Wu", "Daniel S. Weld." ],
      "venue" : "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 118–127, Uppsala, Sweden. Association for Computational Linguistics.",
      "citeRegEx" : "Wu and Weld.,? 2010",
      "shortCiteRegEx" : "Wu and Weld.",
      "year" : 2010
    }, {
      "title" : "Adversarial training for relation extraction",
      "author" : [ "Yi Wu", "David Bamman", "Stuart Russell." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1778–1783, Copenhagen, Denmark. Association for",
      "citeRegEx" : "Wu et al\\.,? 2017",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2017
    }, {
      "title" : "Question answering on Freebase via relation extraction and textual evidence",
      "author" : [ "Kun Xu", "Siva Reddy", "Yansong Feng", "Songfang Huang", "Dongyan Zhao." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1:",
      "citeRegEx" : "Xu et al\\.,? 2016",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2016
    }, {
      "title" : "Information extraction over structured data: Question answering with Freebase",
      "author" : [ "Xuchen Yao", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
      "citeRegEx" : "Yao and Durme.,? 2014",
      "shortCiteRegEx" : "Yao and Durme.",
      "year" : 2014
    }, {
      "title" : "Distant supervision relation extraction with intra-bag and inter-bag attentions",
      "author" : [ "Zhi-Xiu Ye", "Zhen-Hua Ling." ],
      "venue" : "arXiv preprint arXiv:1904.00143.",
      "citeRegEx" : "Ye and Ling.,? 2019",
      "shortCiteRegEx" : "Ye and Ling.",
      "year" : 2019
    }, {
      "title" : "How does disagreement help generalization against label corruption? In International Conference on Machine Learning, pages 7164–7173",
      "author" : [ "Xingrui Yu", "Bo Han", "Jiangchao Yao", "Gang Niu", "Ivor Tsang", "Masashi Sugiyama." ],
      "venue" : "PMLR.",
      "citeRegEx" : "Yu et al\\.,? 2019",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2019
    }, {
      "title" : "Distant supervision for relation extraction with linear attenuation simulation and non-iid relevance embedding",
      "author" : [ "Changsen Yuan", "Heyan Huang", "Chong Feng", "Xiao Liu", "Xiaochi Wei." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Yuan et al\\.,? 2019a",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2019
    }, {
      "title" : "Cross-relation cross-bag attention for distantly-supervised relation extraction",
      "author" : [ "Yujin Yuan", "Liyuan Liu", "Siliang Tang", "Zhongfei Zhang", "Yueting Zhuang", "Shiliang Pu", "Fei Wu", "Xiang Ren." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial",
      "citeRegEx" : "Yuan et al\\.,? 2019b",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2019
    }, {
      "title" : "Distant supervision for relation extraction via piecewise convolutional neural networks",
      "author" : [ "Daojian Zeng", "Kang Liu", "Yubo Chen", "Jun Zhao." ],
      "venue" : "Proceedings of the 2015 conference on empirical methods in natural language processing, pages",
      "citeRegEx" : "Zeng et al\\.,? 2015",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2015
    }, {
      "title" : "Relation classification via convolutional deep neural network",
      "author" : [ "Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao." ],
      "venue" : "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,",
      "citeRegEx" : "Zeng et al\\.,? 2014",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2014
    }, {
      "title" : "Long-tail relation extraction via knowledge graph embeddings and graph convolution networks",
      "author" : [ "Ningyu Zhang", "Shumin Deng", "Zhanlin Sun", "Guanying Wang", "Xi Chen", "Wei Zhang", "Huajun Chen." ],
      "venue" : "arXiv preprint arXiv:1903.01306.",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Bidirectional long short-term memory networks for relation classification",
      "author" : [ "Shu Zhang", "Dequan Zheng", "Xinchen Hu", "Ming Yang." ],
      "venue" : "Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation, pages 73–78, Shanghai,",
      "citeRegEx" : "Zhang et al\\.,? 2015",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2015
    }, {
      "title" : "Positionaware attention and supervised data improve slot filling",
      "author" : [ "Yuhao Zhang", "Victor Zhong", "Danqi Chen", "Gabor Angeli", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Zhang et al\\.,? 2017",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2017
    }, {
      "title" : "Generalized cross entropy loss for training deep neural networks with noisy labels",
      "author" : [ "Zhilu Zhang", "Mert Sabuncu." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc.",
      "citeRegEx" : "Zhang and Sabuncu.,? 2018",
      "shortCiteRegEx" : "Zhang and Sabuncu.",
      "year" : 2018
    }, {
      "title" : "Improving distantly supervised relation classification with attention and semantic weight",
      "author" : [ "Zhangdong Zhu", "Jindian Su", "Yang Zhou." ],
      "venue" : "IEEE Access, 7:91160–91168.",
      "citeRegEx" : "Zhu et al\\.,? 2019",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : ", knowledge graph completion (Bordes et al., 2013; Wang et al., 2014), information extraction (Wu and Weld, 2010) and question answering (Yao and Van Durme, 2014; Fader et al.",
      "startOffset" : 29,
      "endOffset" : 69
    }, {
      "referenceID" : 39,
      "context" : ", knowledge graph completion (Bordes et al., 2013; Wang et al., 2014), information extraction (Wu and Weld, 2010) and question answering (Yao and Van Durme, 2014; Fader et al.",
      "startOffset" : 29,
      "endOffset" : 69
    }, {
      "referenceID" : 40,
      "context" : ", 2014), information extraction (Wu and Weld, 2010) and question answering (Yao and Van Durme, 2014; Fader et al.",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 8,
      "context" : ", 2014), information extraction (Wu and Weld, 2010) and question answering (Yao and Van Durme, 2014; Fader et al., 2014).",
      "startOffset" : 75,
      "endOffset" : 120
    }, {
      "referenceID" : 48,
      "context" : ", 2019a,b); 2) the hard de-noise methods that remove noisy sentences from the bag (Zeng et al., 2015; Qin et al., 2018; Han et al., 2018a; Shang, 2019).",
      "startOffset" : 82,
      "endOffset" : 151
    }, {
      "referenceID" : 30,
      "context" : ", 2019a,b); 2) the hard de-noise methods that remove noisy sentences from the bag (Zeng et al., 2015; Qin et al., 2018; Han et al., 2018a; Shang, 2019).",
      "startOffset" : 82,
      "endOffset" : 151
    }, {
      "referenceID" : 11,
      "context" : ", 2019a,b); 2) the hard de-noise methods that remove noisy sentences from the bag (Zeng et al., 2015; Qin et al., 2018; Han et al., 2018a; Shang, 2019).",
      "startOffset" : 82,
      "endOffset" : 151
    }, {
      "referenceID" : 34,
      "context" : ", 2019a,b); 2) the hard de-noise methods that remove noisy sentences from the bag (Zeng et al., 2015; Qin et al., 2018; Han et al., 2018a; Shang, 2019).",
      "startOffset" : 82,
      "endOffset" : 151
    }, {
      "referenceID" : 9,
      "context" : "However, the instance selection approaches of these methods depend on rewards(Feng et al., 2018) or frequent patterns(Jia et al.",
      "startOffset" : 77,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : ", 2018) or frequent patterns(Jia et al., 2019) determined by bag-level labels, which contain much noise.",
      "startOffset" : 28,
      "endOffset" : 46
    }, {
      "referenceID" : 20,
      "context" : "In this work, we propose the use of negative training (NT) (Kim et al., 2019) for distant RE.",
      "startOffset" : 59,
      "endOffset" : 77
    }, {
      "referenceID" : 27,
      "context" : "Existing approaches include robust learning methods such as leveraging a robust loss function or regularization method(Lyu and Tsang, 2020; Zhang and Sabuncu, 2018; Hu et al., 2019b; Kim et al., 2019), re-weighting the loss of",
      "startOffset" : 118,
      "endOffset" : 200
    }, {
      "referenceID" : 53,
      "context" : "Existing approaches include robust learning methods such as leveraging a robust loss function or regularization method(Lyu and Tsang, 2020; Zhang and Sabuncu, 2018; Hu et al., 2019b; Kim et al., 2019), re-weighting the loss of",
      "startOffset" : 118,
      "endOffset" : 200
    }, {
      "referenceID" : 16,
      "context" : "Existing approaches include robust learning methods such as leveraging a robust loss function or regularization method(Lyu and Tsang, 2020; Zhang and Sabuncu, 2018; Hu et al., 2019b; Kim et al., 2019), re-weighting the loss of",
      "startOffset" : 118,
      "endOffset" : 200
    }, {
      "referenceID" : 20,
      "context" : "Existing approaches include robust learning methods such as leveraging a robust loss function or regularization method(Lyu and Tsang, 2020; Zhang and Sabuncu, 2018; Hu et al., 2019b; Kim et al., 2019), re-weighting the loss of",
      "startOffset" : 118,
      "endOffset" : 200
    }, {
      "referenceID" : 32,
      "context" : "potential noisy samples (Ren et al., 2018; Jiang et al., 2018), modeling the corruption probability with a transition matrix (Goldberger and BenReuven, 2016; Xia et al.",
      "startOffset" : 24,
      "endOffset" : 62
    }, {
      "referenceID" : 19,
      "context" : "potential noisy samples (Ren et al., 2018; Jiang et al., 2018), modeling the corruption probability with a transition matrix (Goldberger and BenReuven, 2016; Xia et al.",
      "startOffset" : 24,
      "endOffset" : 62
    }, {
      "referenceID" : 28,
      "context" : "the noisy instances from the training data(Malach and Shalev-Shwartz, 2017; Yu et al., 2019; Arazo et al., 2019; Li et al., 2019).",
      "startOffset" : 42,
      "endOffset" : 129
    }, {
      "referenceID" : 45,
      "context" : "the noisy instances from the training data(Malach and Shalev-Shwartz, 2017; Yu et al., 2019; Arazo et al., 2019; Li et al., 2019).",
      "startOffset" : 42,
      "endOffset" : 129
    }, {
      "referenceID" : 1,
      "context" : "the noisy instances from the training data(Malach and Shalev-Shwartz, 2017; Yu et al., 2019; Arazo et al., 2019; Li et al., 2019).",
      "startOffset" : 42,
      "endOffset" : 129
    }, {
      "referenceID" : 22,
      "context" : "the noisy instances from the training data(Malach and Shalev-Shwartz, 2017; Yu et al., 2019; Arazo et al., 2019; Li et al., 2019).",
      "startOffset" : 42,
      "endOffset" : 129
    }, {
      "referenceID" : 20,
      "context" : "We first leverage a robust negative loss (Kim et al., 2019) for model training.",
      "startOffset" : 41,
      "endOffset" : 59
    }, {
      "referenceID" : 33,
      "context" : "The experiments in this work are divided into two parts, respectively conducted on two datasets: the NYT-10 dataset (Riedel et al., 2010) and the TACRED dataset (Zhang et al.",
      "startOffset" : 116,
      "endOffset" : 137
    }, {
      "referenceID" : 52,
      "context" : "Since no labeled training data are available in the distant supervision setting, we construct a noisy dataset with 30% noise from a labeled dataset, TACRED (Zhang et al., 2017) 5.",
      "startOffset" : 156,
      "endOffset" : 176
    }, {
      "referenceID" : 25,
      "context" : "PCNN+SelATT (Lin et al., 2016): A bag-level RE model which leverages an attention mechanism to reduce noise effect.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 44,
      "context" : "PCNN+RA BAG ATT (Ye and Ling, 2019) short for PCNN+ATT RA+BAG ATT, a bag-level model containing both intra-bag and inter-bag attentions to alleviate noise.",
      "startOffset" : 16,
      "endOffset" : 35
    }, {
      "referenceID" : 30,
      "context" : "CNN+RL1 (Qin et al., 2018): A RL-based bag-level method.",
      "startOffset" : 8,
      "endOffset" : 26
    }, {
      "referenceID" : 9,
      "context" : "CNN+RL2 (Feng et al., 2018): A sentence-level RE model.",
      "startOffset" : 8,
      "endOffset" : 27
    }, {
      "referenceID" : 18,
      "context" : "Statistics of NYT-10 are quoted from (Jia et al., 2019).",
      "startOffset" : 37,
      "endOffset" : 55
    }, {
      "referenceID" : 18,
      "context" : "ARNOR (Jia et al., 2019): A sentence-level RE model which selects confident instances based on the attention score on the selected patterns.",
      "startOffset" : 6,
      "endOffset" : 24
    }, {
      "referenceID" : 48,
      "context" : ", 2014), PCNN (Zeng et al., 2015) and BiLSTM (Zhang et al.",
      "startOffset" : 14,
      "endOffset" : 33
    }, {
      "referenceID" : 51,
      "context" : ", 2015) and BiLSTM (Zhang et al., 2015) are typical architectures used in RE.",
      "startOffset" : 19,
      "endOffset" : 39
    }, {
      "referenceID" : 52,
      "context" : "BiLSTM+ATT (Zhang et al., 2017) leverages an attention mechanism based on BiLSTM to capture useful information.",
      "startOffset" : 11,
      "endOffset" : 31
    }, {
      "referenceID" : 7,
      "context" : "BiLSTM+BERT (Devlin et al., 2019): Based on BiLSTM, it utilizes the pre-trained BERT representations as word embedding.",
      "startOffset" : 12,
      "endOffset" : 33
    } ],
    "year" : 2021,
    "abstractText" : "Distant supervision for relation extraction provides uniform bag labels for each sentence inside the bag, while accurate sentence labels are important for downstream applications that need the exact relation type. Directly using bag labels for sentence-level training will introduce much noise, thus severely degrading performance. In this work, we propose the use of negative training (NT), in which a model is trained using complementary labels regarding that “the instance does not belong to these complementary labels”. Since the probability of selecting a true label as a complementary label is low, NT provides less noisy information. Furthermore, the model trained with NT is able to separate the noisy data from the training data. Based on NT, we propose a sentence-level framework, SENT, for distant relation extraction. SENT not only filters the noisy data to construct a cleaner dataset, but also performs a relabeling process to transform the noisy data into useful training data, thus further benefiting the model’s performance. Experimental results show the significant improvement of the proposed method over previous methods on sentence-level evaluation and de-noise effect.",
    "creator" : "LaTeX with hyperref"
  }
}