{
  "name" : "2021.acl-long.250.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech",
    "authors" : [ "Margherita Fanton", "Helena Bonaldi", "Serra Sinem Tekiroğlu", "Marco Guerini" ],
    "emails" : [ "mfanton@fbk.eu,", "hbonaldi@fbk.eu,", "tekiroglu@fbk.eu,", "guerini@fbk.eu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3226–3240\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3226"
    }, {
      "heading" : "1 Introduction",
      "text" : "The proliferation of online hatred has became an alarming issue (Williams, 2019) threatening not only the well-being of target individuals and groups, but also of society as a whole. While authorities establish regulations and policies, social media platforms take actions against hate speech mostly through moderation activities, such as content removal, account suspension, or shadowbanning, at the risk of hindering the freedom of expression. Meanwhile, Non-Governmental Organizations are qualifying volunteers for responding to online hate to promote human dignity and understanding in society. Such responses, i.e., CounterNarratives (CN), are non-aggressive textual feedback using credible evidence, factual arguments,\nalternative viewpoints, and are considered as an effective strategy (Benesch, 2014; Schieb and Preuss, 2016) to confront hate speech while respecting the human rights (Kiritchenko et al., 2020).\nHowever, the vast amount of online hate speech makes an effective manual intervention impossible, which motivates a line of NLP research focusing on semi or fully automatized CN generation solutions1. In recent years, several CN collection strategies and datasets have been proposed addressing the data-hungry nature of current state of the art generation technologies (Mathew et al., 2018; Qian et al., 2019; Chung et al., 2019).\nConsidering the shortcomings of the existing collection strategies (that grant either quality or quantity, but not both), we present an approach to produce high quality CNs for multiple hate targets while reducing the need for expert intervention. To this end, we build on top of the previous hybrid data collection strategies, aiming to increase efficiency while maintaining the requirements of data quality, novelty and diversity. In particular, we start from the work by Tekiroğlu et al. (2020) that uses an author-reviewer framework in which the author – a generative language model – is tasked with generating HS/CN pairs while a pool of human reviewers filter and possibly post-edit the produced output. In the present work we propose to further reduce the data collection effort by closing the pipeline and feeding the post-edited output back to the language model in order to regularly update it and improve\n1In our view the generation process can be fully automatic but generation systems need human supervision and should not be fully autonomous, at least for delicate tasks such as hate countering on social media platforms. For this reason we advocate that generation systems should be used as suggesting tool for NGO operators, to make their countering work more effective. In this way there is always a “human moderator” taking the final decision (Chung et al., 2019). Furthermore, this approach is also in line with de Lima Salge and Berente (2017)’s Ethical framework, since this “suggesting tool” configuration grants compliance with their rules.\nthe quality of the generated pairs. Our experiments comprised of two sessions, spanning a period of 6 months. In the first session we set up a ‘simple’ human-in-the-loop (HITL henceforth) procedure and iterated it several times, measuring at each loop the performance of the whole framework according to relevant metrics. In the second session we run several additional loops in which we test different strategies (i.e. author configurations) to improve the data collection according to the given metrics. Findings show that the HITL framework is scalable, allowing to obtain datasets that are adequate in terms of diversity, novelty, and quantity. Moreover, this framework improves on previous hybrid data collection strategies, reducing at each loop the post-editing effort of the human reviewers or the number of discarded examples (session one). On the other hand, with dynamic adaptation, possible unwanted behaviors or flaws of the data collection can be handled at each loop by simply varying the author configuration (session 2). The final dataset contains 5000 HS/CN pairs in English Language, covering multiple hate targets, in terms of race, religion, country of origin, sexual orientation, disability, or gender. To the best of our knowledge, this is the first multi-target expert-based HS/CN dataset constructed through a semi-automatic mechanism and can be downloaded at the following link: https://github.com/marcoguerini/CONAN."
    }, {
      "heading" : "2 Related Work",
      "text" : "With regard to hatred countering, we will focus on three research aspects relevant for the present work, i.e. (i) publicly available datasets for detection, (ii) publicly available datasets for countering, (iii) approaches for hybrid data collection.\nHate detection datasets. Several datasets for hate detection have been presented, most of which rely on material collected from SMPs, such as Twitter (Waseem and Hovy, 2016; Waseem, 2016; Ross et al., 2017), Facebook (Kumar et al., 2018), WhatsApp (Sprugnoli et al., 2018), and forums (de Gibert et al., 2018). While the above datasets focus on a classification task, Mathew et al. (2020) released a dataset annotated with rationales to improve hate speech interpretability and Sap et al. (2020) proposed the Social Bias Inference Corpus (SBIC) annotated with the description of the biases implicitly present in the language. For a more extensive review, we refer the reader to Poletto et al. (2020) and Vidgen and Derczynski (2020).\nHate countering datasets. While several social studies proved that counter-narratives are effective in hate countering (Benesch, 2014; Silverman et al., 2016; Schieb and Preuss, 2016; Stroud and Cox, 2018; Mathew et al., 2019), only few works have focused on data collection for CN generation. Mathew et al. (2018) focus on crawling, following the intuition that CNs can be found on SMPs as responses to hateful expressions. Qian et al. (2019) propose a crowdsourcing methodology where crowd-workers (non-expert) are instructed to write responses to hate content collected from SMPs. The study by Chung et al. (2019) also relies on outsourcing CNs writing, but via nichesourcing, using NGO operators expert in CN production.\nHybrid models for data collection. Given the data-hungry nature of current NLP technologies, one line of research has recently focused on advanced hybrid models for data collection. Wallace et al. (2019) proposed using model interpretation to guide humans in the creation of adversarial examples for factoid question-answering systems. Dinan et al. (2019) and Vidgen et al. (2020) perform a data collection with HITL for detecting offensive language. In both studies, the dynamic procedure is shown to be successful in reducing model error rate across rounds. Vidgen et al. (2020) point out that the HITL approach has multiple advantages over the static data collection: design flaws can be addressed during the construction of the dataset and annotators’ work is optimized, since it is guided by the feedback from the model. Finally Tekiroğlu et al. (2020) propose a hybrid approach where an LM is trained on a seed datasets of HS/CN pairs to generate new pairs that are then validated and post-edited by annotators."
    }, {
      "heading" : "3 Methodology",
      "text" : "In Figure 1 we present the pipeline of our methodology. Following the idea presented by Tekiroğlu et al. (2020), we have an author module built using GPT-2 language model (Radford et al., 2019) and fine-tuned on a seed dataset of HS/CN pairs. The author produces novel HS/CN candidates while the reviewer(s) filter and eventually post-edit them. We iterate this data collection several times, at each loop reviewed examples are added to training data and the author is fine-tuned from scratch again on all available data. In the following sections we describe the main elements used in our procedures."
    }, {
      "heading" : "3.1 Seed dataset",
      "text" : "To start the process, we built a seed dataset of 880 HS/CN pairs by nichesourcing its collection to 20 experts from two different NGOs. We named this dataset V1. The methodology for collecting V1 closely replicates the one presented by Chung et al. (2019). In particular we first created a list of prototypical hate texts – with the help of an NGO expert – for the following hate targets: DISABLED, JEWS, OVERWEIGHT, LGBT+, MUSLIM, WOMEN, PEOPLE OF COLOR, ROMANI, MIGRANTS. We then prepared two online data collection forms: in the first, NGO operators were asked to respond to examples selected from the prototypical hate text list, in the second they were asked to write their own HS/CN pairs. This data collection session lasted roughly one month."
    }, {
      "heading" : "3.2 Sessions",
      "text" : "Our experiments were run in two separate and subsequent sessions, meant to explore different aspects of the HITL approach.\nIn the first session, after using V1 for the initial fine-tuning of GPT-2, we iterated the data collection 4 times, keeping the author-reviewer configuration as close as possible to the original one presented by Tekiroğlu et al. (2020). Loops are numbered sequentially as V2...Vn. At each loop, we acquired 500 examples of accepted and eventually post-edited HS/CN pairs2. To obtain a new set of 500 pairs (Vi) we fine-tuned GPT-2 every time from scratch using\n2The only exception is V2 that accounts for 620 pairs to have a round number of examples by reaching 1500.\nV1...Vi−1 as training data and administered the generated samples to reviewers until the target number was reached. In total we iterated the procedure 4 times reaching V5 for a total of 3000 pairs.\nIn the second session, we tested several alternative author configurations to ameliorate some unwanted behaviors/trends that emerged during the first session. We ran 4 additional data collection loops, this time in parallel (i.e. all starting from V5 dataset) instead of an iteration. For each loop, represented as V6,{config name}, we collected 500 HS/CN pairs reaching a total of 5000 examples."
    }, {
      "heading" : "3.3 Author Models",
      "text" : "In our experiments all models are variants of the author (GPT-2), obtained by changing the way it is fine-tuned or conditioned. For consistency, each model is trained using the same hyperparameter configurations. In particular, we used GPT2 medium model, fine-tuned for 3 epochs with a batch size of 1024 tokens and a learning rate of 2e-5. Each pair has been represented as < |startofhs|>HS<|endofhs|> <|startofcn|> CN<|endofcn|> for the training. At the generation time, Nucleus Sampling (Holtzman et al., 2019) has been utilized with a p value of 0.9. For the standard configurations we use only < |startofhs|> for conditioning. Given an HS tag, the models produce a chunk of text, which is a list of HS/CN pairs. These pairs are then cleaned from the special tokens and administered to the reviewers for evaluation and possible post-editing."
    }, {
      "heading" : "3.4 Reviewers",
      "text" : "We recruited 3 annotators, from a pool of internship students, as reviewers over a period of 18 weeks to filter and post-edit the generated pairs after an extensive training procedure.\nTraining. Annotators underwent a training for 2 weeks, so that they became “experts” on HS/CN post-editing. The training included: (i) reading and discussing NGO guidelines and public documentation describing the activity of CN writing for hate countering, (ii) reading all V1 pairs to better comprehend the attributes of counter narratives, (iii) reading a sample of 100 HS/CN pairs that have been post-edited by an expert to see concrete examples of post-editing activity, (iv) performing a practice session of CN post-editing and discussing it with an expert NGO operator.\nInstructions. We adapted the reviewing instructions from Tekiroğlu et al. (2020). In particular, for each pair, we asked the operators: (a) to approve it without any modifications if it was a valid pair, (b) if the pair was not perfect, but easily amendable, to modify it, (c) if the CN is completely irrelevant, or does not follow NGO’s guidelines, to discard the pair regardless of HS quality, (d) whenever there are facts or statistics in the CN, check veracity of the information to avoid possible LM hallucination effects. We further instructed the annotators to provide a hate target label for each accepted pair. The labels were useful both for analysis and for the subsequent label-based generation strategies present in V6. In Table 7 we give an example of GPT-2 output and its post-edited version.\nMitigation procedure. We applied an adapted version of the guidelines by Vidgen et al. (2019) to safeguard the annotators’ well-being against the risk of harmful consequences of working with abusive content (present in the HSs and possibly in generated, not well-formed CNs). To this end we first made sure that annotators understood the prosocial aspects of the research and explained them the purpose of their annotation activity in details. Then we instructed the annotators to work no more than 2/3 hours per day and take regular breaks, by adjusting their workload as needed. Finally, we had meetings and feedback from the annotators on a weekly basis to let possible problems or distress emerge. This procedure was repeated throughout the whole data collection campaign."
    }, {
      "heading" : "4 Metrics",
      "text" : "To understand the ‘diachronic’ behavior of our HITL methodology across iterations, the following\nmetrics have been computed at the end of each loop over the newly obtained pairs.\nImbalance degree measures the difference between a perfectly-balanced distribution of the hate target categories and the actual unbalanced datasets; we use Imbalance Degree (ID) since it is specifically devoted to the multi-class scenario (Ortigosa-Hernández et al., 2017). Datasets that are balanced over multiple hate targets could allow building more representative CN generation models.\nAcceptance Rate is the percentage of pairs accepted by the reviewers (either untouched or postedited) over the total number they scrutinised. It represents an overall estimate of the ability of the framework to produce reasonable-quality material.\nHTER is originally a measure of post-editing effort at sentence level translations (Specia and Farzindar, 2010). We adopted it to the measure reviewers’ effort in terms of the average number of edits over the accepted pairs. An upper-bound threshold value of 0.4 is used to account for easily post-editable pairs (Turchi et al., 2013).\nNovelty measures how different two collections of texts are from each other, and it is grounded on Jaccard similarity. We utilized it to compute the originality present in Vi with respect to the training data collected in previous loops (Dziri et al., 2019; Wang and Wan, 2018).\nRepetition Rate measures the intra-corpora quality in terms of language diversity by considering the rate of non-singleton ngram types it contains (Cettolo et al., 2014; Bertoldi et al., 2013). We use it to measure the ability of the framework to provide diverse and varied examples. Repetition Rate (RR) has the advantage of being independent from corpus size, so it can be used to directly compare different versions of our dataset.\nVocabulary Expansion is a measure we introduce to serve two main objectives: (i) quantifying the contribution of the author and the reviewers, by focusing on new tokens appeared at each loop (e.g. the term “peace” was introduced for the first time by annotators in V2), (ii) quantifying the presence of cross-fertilization, i.e. tokens that appear for the first time in version Vn for a particular target, but they were present in a version antecedent to Vn for the other targets (e.g. the term “peace” for the target JEWS appears at V4 but it was already present\nfor the target MUSLIM in V2). The algorithm for computing Vocabulary Expansion is described in Appendix A.1."
    }, {
      "heading" : "5 Session One",
      "text" : "In session one, all the versions of the dataset V2...V5 are generated using GPT-2Vi , where the fine-tuning is performed on all previous versions of the dataset V1...Vi−1 as explained earlier.\nTo produce HS/CN pairs, the author conditioning is performed using only <|startofhs|> tag and collecting all the generated material provided that each pair is encapsulated with the proper tags.\nFor the analysis, we computed the metrics described in Section 4 on the HS/CN pairs obtained in each loop using micro-averaging (in Appendix A.4, Table 5 we report all results in detail). To isolate the possible effect of target-class imbalance, macro averages were also calculated; similarly, to account for element-wise differences we calculated micro averages for HS and CN sets separately3.\nDiscussion. Considering our objective of collecting quality material in an efficient way, we first focus on the ratio of accepted pairs and the postediting effort in each loop. As shown in Figure 2, the percentage of accepted pairs tends to increase across the loops, for both the pairs that are postedited (“modified”) from 35.8 in V2 to 50.1 in V5 and the ones accepted without post-editing (“untouched”) from 1.5 in V2 to 10.9 in V5.\nAt the same time, the average post-editing effort of the reviewers tend to decrease across the versions, as depicted in Figure 3. To ensure that the decrease in HTER is not due to the increasing ratio of untouched pairs to the total number of accepted\n3These results are in line with the ones showed in the paper, and do not change the discussion. They are reported in Appendix A.4, Table 6\npairs, we computed the HTER for the modified pairs alone. Consistently with the overall trend, HTER for modified pairs also declines, indicating that the data collection loops succeeded not only in reducing the reviewer effort, but also in improving the quality of the generated material to be postedited. Notably, after V3 the HTER falls below the 0.4 acceptability threshold as defined in (Turchi et al., 2013) for the AMT scenario (Figure 3). In view of this analysis, we can conclude that the efficiency of data collection is increased by HITL as compared to a static approach that does not retrain the author module (that can be represented by V2).\nRegarding the evaluations with the quality metric Repetition Rate (Figure 3), it increases from V2 on signifying a decrease in the lexical diversity of the generated data. Moreover, we observed a consistent trend for the scores of the second quality metric, i.e. Novelty (Figure 4). Similar to the diversity, novelty of the collected data also decreases across the versions, regardless of the dataset against which the novelty is computed. Particularly, the change in the cumulative novelty represents how the vocabulary becomes less and less enrichable as the loop number increases, indicating a possible saturation point where novel material is highly difficult to obtain. Finally, the distribution of hate targets shows a worsening also in terms of ID that increases from a score of 2.2 in V1 to 4.5 in V5 (see Figure 2) with some targets becoming predominant while others slowly disappearing. More details on each target distribution per loop are given in Appendix A.2, Figure 11.\nAs for pair length, throughout the loops we found that “untouched” pairs are usually shorter (30.7 tokens on average) than the other accepted pairs (37.3 tokens on average before post-editing). During the discussion sessions, annotators reported\nthat the “untouched” pairs are not only shorter but also somewhat stereotypical, with a small novelty added to the overall dataset (e.g. “you cannot say this about an entire religion”, “It’s unfair to say this about an entire religion”)."
    }, {
      "heading" : "6 Session Two",
      "text" : "Given the problems emerged during the loops of the first session (i.e. higher efficiency but lower quality at each loop), we organized an additional session to test several parallel methodologies to ameliorate them. The description of the V6 configurations are as follows:\nV6,SBF : The model GPT-2V5 is conditioned with novel offensive speeches extracted from SBIC corpus (Sap et al., 2020). We chose this resource since: (i) it contains several thousand of social media posts containing biases and stereotypes spanning the same target categories with our study, (ii) for each post it provides an ‘implied statement’ that closely resembles a ‘prototypical hate speech’ on which we trained our system. We sampled the same number of ‘implied statements’ for each target that maps to our labels4 among the ones annotated with ‘the intent behind the statement was to offend’ and/or ’the post could be offensive to someone’. We provide the statements as conditions by appending them to <|startofhs|>. V6,LAB : The model is conditioned specifying on which hate target it should focus on. In this configuration, we trained a variant of GPT-2V5 that takes into account the target label, and modified the original representation of our training data accordingly. In particular we accommodate hate target information within the starting token: <|startofhs: target label|>.\n4In Table 4 in Appendix we provide the mapping we used.\nV6,ARG : We fine-tuned GPT-2 on a dataset of argumentative pairs collected from Kialo5, an online debate platform for constructive and rational discussions among peers that has been exploited recently by the NLP community (Durmus et al., 2019a,b; Scialom et al., 2020). Each discussion in Kialo is represented as a tree of arguments in which a child node is connected to its parent via a “pro” or “con” relation. Extracting all the claims connected by a “con” relation, we obtained a dataset of 128178 argument pairs covering a broader domain as compared to HS/CN pairs. We then fine-tuned GPT-2 for 1 epoch over the argumentation dataset with the standard hyperparameters. Preliminary experiments showed that the best strategy was to represent these pairs with the same format as ours to facilitate transfer of task characteristics and argumentative knowledge. Then this model was again fine-tuned using the standard V1...V5 data. At inference time, conditioning has been performed using lists of unique HSs from the V1...V5 data. V6,MIX : The last model is obtained by blending the three previous versions together, i.e. first finetuning on Kialo dataset, second fine-tuning using target label notation on V1...V5 data, conditioning using SBIC offensive speeches.\nBearing in mind the problems emerged during Session One, our first goal in Session Two was to balance the dataset with respect to the hate targets (i.e. reducing ID score). To this end the conditioning always takes into account the hate target label (with respect to 7 targets: JEWS, LGBT+, MUSLIM, WOMEN, DISABLED,PEOPLE OF COLOR, MIGRANTS) either explicitly as in V6,LAB or V6,MIX , or implicitly as in V6,SBF and V6,ARG. In addition, to better balance the number of pairs for each target, we administered only the first 5 pairs of each generated chunk to the reviewers.\nDiscussion. All the applied methodologies allow for a better balancing of data in terms of hate targets, yielding an average ID score of 2.3 for the V6 configurations in comparison to the ID score of 4.5 for V56. As shown in Figure 5 - left, all V6 configurations have a slightly higher acceptance rate than V57. Thus introducing novel material or data\n5www.kialo.com 6In Appendix, Table 3, we provide the target distribution over the final dataset. 7In order to estimate the trend of each metric after V5, we calculated also V6,PREDICTED , shown as a dashed line in\nrepresentation in fine-tuning stages has no strong perturbation effect. Second, and more interestingly, we observe a significant variation in the ratio of untouched and modified pairs to all the reviewed samples: for all V6 approaches while there is a strong decrease in ratio of untouched pairs (Figure 5, right), there is a significant increase in those modified (see Figure 5, left). In other words these models were able to produce a higher amount of suitable, albeit non perfect, pairs. In particular, comparing V6 configurations we can observe that for the untouched pairs the highest acceptance rate is achieved via V6,ARG with 6.37% accepted pairs, whereas for the modified pairs V6,MIX yields the highest percentage, with 66.15% of the pairs accepted.\nConcerning the reviewer’s effort, we see that the overall HTER increases for the all V6 approaches (Figure 6, left). Considering that we had a lower number of untouched and a higher number of modified pairs this was expected, and if we turn to the HTER of modified pairs alone we see that there is a smaller difference between V5 and V6 HTER. Even more interestingly, the HTER scores of all V6 configurations, even if higher than V5, are still below the acceptability threshold value of 0.4 defined earlier. Going into details, amongst the V6 configurations, HTER reaches its lowest value in V6,ARG, for both the modified and untouched pairs: since it was conditioned using gold HS material, this result is expected. As opposed to the other models, V6,LAB is conditioned only with a label representation and not with actual HSs. This affected negatively the post-editing effort, as we can notice a higher HTER for this configuration. Moreover, V6,LAB has a smaller amount of untouched pairs, so we expected HTER to spike up.\nWith regard to data quality (see Figure 7), we see that all V6 strategies succeed in increasing the novthe plots, using a linear regression model over V1...V5.\nelty both with respect to V5 and expected V6 (the dashed line) , except for V6,ARG, possibly due to its conditioning with HSs from V1 ... V5. Therefore, we also computed the novelty for CN set alone to discard the effect of HS on the metric. In this setting, all V6 configurations reach a novelty between 0.741 and 0.745, as compared to a CN novelty in V5 of 0.737 (as in Appendix A.3). The effect of gold HS conditioning in V6,ARG can also be spotted in the lowest HTER results in Figure 6. The highest increase in novelty is recorded for V6,MIX , reaching a score of 0.76; also novelty scores computed with respect to V5 and V1 confirm the result.\nAll V6 configurations succeeded in reaching an RR lower than both V5 and expected V6 (the dashed line). It is interesting that V6,LAB has the highest RR among the V6 configurations, possibly because it was not built using any external knowledge, but only with a different label representation. On the other hand, V6,ARG configuration, for which an initial argumentation fine-tuning has been performed, has the lowest RR (5.474).\nFrom this analysis we can conclude that V6 configurations are better at producing sub-optimal material but worse at producing perfect material. Still the general quality of the pairs (in terms of novelty and RR) in Session Two is much higher than\nbefore, exhibiting the desired behavior for which these strategies were introduced."
    }, {
      "heading" : "7 Vocabulary analysis.",
      "text" : "We report vocabulary expansion findings in Figure 8. For each loop V2...V5 the average percentage of new words injected into the dataset by the author model (GPT-2) is higher than the average percentage of new words inserted by the three reviewers during post-editing. Both trend-lines, even if slightly decreasing are not converging, implying that fine-tuned GPT-2 is not reaching a “saturation point” and is continuously adding new material. This trend is in line with the decrease in novelty. On the other hand, instructions asked for a minimal post-edit, so the reviewers have less opportunity to inject new material than the author and the decrease is consistent with the decreasing HTER.\nAs for the percentage of words generated by the author model pertaining to the same target, we see an increasing trend throughout the generations due to the cumulative nature of the metric. Still, the presence of words first observed in other targets throughout the loops, shows that the crossfertilization phenomenon generated by GPT-2 persists. This desired feature shows the ability of GPT2 to learn the ‘domain’ vocabulary of other targets and to use it effectively for the target under analysis, in a way that is approved by the humans - reviewers8. Finally, we can remark that V6 versions are able to increase both the injection of novel words from GPT-2 and also its cross-fertilization ability."
    }, {
      "heading" : "8 Qualitative Analysis",
      "text" : "During our exploratory experiments and the discussion sessions with the annotators, several\n8Even though we opted for a distinction in terms of source (same target, other target) for the ‘not-new’ words generated by the author module, we chose not to have the same distinction for the reviewers’ ‘not-new’ words, since we cannot assess if the reviewer was (or not) aware of the presence of a word in previous versions of the dataset.\ninteresting subjects have emerged, which can initiate future work.\nArgumentation and Counter Narratives. In order to obtain even more novelty in produced pairs, V6,ARG model could be used without fine-tuning on the HS/CN dataset under the assumption that a counter argument is the same as a counter narrative. Still, the ability to argument on a variety of topics is not enough to provide a meaningful CN when prompted with an HS. A CN also presuppose values, so - for example - a logically valid argument is not necessarily an acceptable CN, as the first example in Table 2 shows (produced by GPT-2 fine-tuned only on Kialo arguments).\nNew arguments or new paraphrases. One question that emerged is whether GPT-2 is able to produce novel arguments or it is just a very sophisticated paraphrasing tool. During the discussion sessions with annotators and also by manual analysis, we could find CNs that contained genuinely novel arguments, which were not present in the training data but produced by GPT-2. In the second example in Table 2, the novel argument is about capsizing the “imposing the homosexual agenda” argument by providing data on “suicidal attempts among homosexual youth”.\nNovel hate targets and general knowledge. GPT-2 proved to be able to generate HS/CN pairs also for unseen targets, including intersectional ones (e.g. “black women”). Still the lack of a “commonsense knowledge” can produce funny results that are beyond the scope of hallucination (Zellers et al., 2019; Solaiman et al., 2019), such as the third example in Table 2, where GPT-2 addresses muggleborns (target of hate in Harry Potter books)."
    }, {
      "heading" : "9 Conclusions",
      "text" : "In this paper we presented a novel HITL methodology for data collection based on an author-reviewer framework. This methodology puts together an LM and a set of human reviewers, where the LM is refined iteratively, using data from previous loops that have been validated by experts. Experiments show that as loops are iterated, efficiency in data collection increases (acceptance rate and HTER metrics) while the dataset quality decreases in terms of novelty and diversity metrics. For this reason we experimented with additional dynamic loop adaptation that are able to increase the overall quality of the dataset without hindering the efficiency significantly."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was partly supported by the HATEMETER project within the EU Rights, Equality and Citizenship Programme 2014-2020. We are deeply grateful to Stop Hate UK and its volunteers for their help and effort in preparing the seed dataset (version V1) necessary for this work."
    }, {
      "heading" : "A Appendix",
      "text" : "A.1 Vocabulary expansion algorithm The pseudo-code for the vocabulary expansion metric described in Section 4 can be found in Algorithm 1. For each version and target, we define two following sets of words:\nV OCABpe: words from the post-edited pairs\nV OCABgen: words from the generated pairs\nA word is considered novel when it is not present in the collective vocabulary of the previous versions: V OCAB(V1,...,i−1).\nAlgorithm 1: Vocabulary expansion for each target\nfor each version Vi do for each word w in Vi do\nif w in V OCABpe and w in V OCABgen then author w←w if author w in V OCAB(V1,...,i−1) then\nif author w in same target V OCAB then same target author w←author w else other target author w←author w\nelse novel author w←author w\nelse reviewer w←w if reviewer w in V OCAB(V1,...,i−1) then not novel reviewer w←reviewer w\nelse novel reviewer w←reviewer w\nEach word is assigned to one of the following sets: Author-novel, Author-same-target, Authorother-target, Reviewer-novel, Reviewer-not-novel. Considering the size in terms of words of each set, we calculate the percentages for each target and version, so that we are able to obtain the vocabulary expansion scores as macro average percentages.\nA.2 Additional material for Session One In this section, we present the most interesting results that we have obtained by analysing only the HS or the CN sets.\nWhile HTER calculated on CN alone shows a clear decreasing trend (Figure 9 on the left), the\nresults for HS alone are less consistent yielding higher scores for V3 and V4. This can be mostly explained with the different approaches of postediting the HSs by the annotators, which include the possibility to rewrite it entirely when needed. On the other hand, the decreasing trend of HTER for HS starting from V3, resulting in a lower score in V5 than the one calculated on CN only, could be due to the increasing frequency of prototypical HSs. This implication is confirmed by the higher RR scores for HSs as compared to CNs, which grow faster for the former than the latter (Figure 9 on the right). Moreover, the increasing number of prototypical HSs contributes to the novelty scores for HSs only being lower than those of CNs and decreasing more rapidly (Figure 10).\nIn Figure 11 the target distribution at each loop of Session One is shown, in Table 3 the frequencies of targets in the final dataset are displayed. The MUSLIMS target covers a significant percentage of the generations in every loop and consists of more than the half of the pairs V5. In fact it is expected to cause even more imbalanced productions in the next loops. JEWS, MIGRANTS and DISABLED targets diminish over the loops, while the other targets can be considered as stable.\nA.3 Additional material for Session Two Concerning Session Two, the results for CNs are in line with the conclusions drawn in the paper for HS/CN pairs. The same holds for HSs, the only exception being for the cumulative novelty of V6,ARG HSs, as can be seen in Figure 13 and in Table 6. As explained earlier in Section 6, this effect is due to the use of hate speeches from the training set for conditioning GPT-2. This result also corresponds to HSs from V6,ARG having lower HTER (Figure 12) and a higher RR (Figure 14).\nA.4 Tables In Table 5, the main results calculated on the HS/CN pairs are displayed. In Table 6, respectively, the results calculated on HS only and CN only are shown."
    } ],
    "references" : [ {
      "title" : "Countering dangerous speech: New ideas for genocide prevention",
      "author" : [ "Susan Benesch." ],
      "venue" : "Washington, DC: United States Holocaust Memorial Museum.",
      "citeRegEx" : "Benesch.,? 2014",
      "shortCiteRegEx" : "Benesch.",
      "year" : 2014
    }, {
      "title" : "Cache-based online adaptation for machine translation enhanced computer assisted translation",
      "author" : [ "Nicola Bertoldi", "Mauro Cettolo", "Marcello Federico." ],
      "venue" : "MT-Summit, pages 35–42.",
      "citeRegEx" : "Bertoldi et al\\.,? 2013",
      "shortCiteRegEx" : "Bertoldi et al\\.",
      "year" : 2013
    }, {
      "title" : "The repetition rate of text as a predictor of the effectiveness of machine translation adaptation",
      "author" : [ "Mauro Cettolo", "Nicola Bertoldi", "Marcello Federico." ],
      "venue" : "Proceedings of the 11th Biennial Conference of the Association for Machine Translation in the Americas",
      "citeRegEx" : "Cettolo et al\\.,? 2014",
      "shortCiteRegEx" : "Cettolo et al\\.",
      "year" : 2014
    }, {
      "title" : "Build it break it fix it for dialogue safety: Robustness from adversarial human attack",
      "author" : [ "Emily Dinan", "Samuel Humeau", "Bharath Chintagunta", "Jason Weston." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Dinan et al\\.,? 2019",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2019
    }, {
      "title" : "Determining relative argument specificity and stance for complex argumentative structures",
      "author" : [ "Esin Durmus", "Faisal Ladhak", "Claire Cardie." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4630–4641.",
      "citeRegEx" : "Durmus et al\\.,? 2019a",
      "shortCiteRegEx" : "Durmus et al\\.",
      "year" : 2019
    }, {
      "title" : "The role of pragmatic and discourse context in determining argument impact",
      "author" : [ "Esin Durmus", "Faisal Ladhak", "Claire Cardie." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Durmus et al\\.,? 2019b",
      "shortCiteRegEx" : "Durmus et al\\.",
      "year" : 2019
    }, {
      "title" : "Augmenting neural response generation with context-aware topical attention",
      "author" : [ "Nouha Dziri", "Ehsan Kamalloo", "Kory Mathewson", "Osmar R Zaiane." ],
      "venue" : "Proceedings of the First Workshop on NLP for Conversational AI, pages 18–31.",
      "citeRegEx" : "Dziri et al\\.,? 2019",
      "shortCiteRegEx" : "Dziri et al\\.",
      "year" : 2019
    }, {
      "title" : "Hate speech dataset from a white supremacy forum",
      "author" : [ "Ona de Gibert", "Naiara Perez", "Aitor Garcıa-Pablos", "Montse Cuadros." ],
      "venue" : "EMNLP 2018, page 11.",
      "citeRegEx" : "Gibert et al\\.,? 2018",
      "shortCiteRegEx" : "Gibert et al\\.",
      "year" : 2018
    }, {
      "title" : "The curious case of neural text degeneration",
      "author" : [ "Ari Holtzman", "Jan Buys", "Maxwell Forbes", "Yejin Choi." ],
      "venue" : "CoRR, abs/1904.09751.",
      "citeRegEx" : "Holtzman et al\\.,? 2019",
      "shortCiteRegEx" : "Holtzman et al\\.",
      "year" : 2019
    }, {
      "title" : "Confronting abusive language online: A survey from the ethical and human rights perspective",
      "author" : [ "Svetlana Kiritchenko", "Isar Nejadgholi", "Kathleen C. Fraser." ],
      "venue" : "CoRR, abs/2012.12305.",
      "citeRegEx" : "Kiritchenko et al\\.,? 2020",
      "shortCiteRegEx" : "Kiritchenko et al\\.",
      "year" : 2020
    }, {
      "title" : "Benchmarking aggression identification in social media",
      "author" : [ "Ritesh Kumar", "Atul Kr Ojha", "Shervin Malmasi", "Marcos Zampieri." ],
      "venue" : "Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), pages 1–11.",
      "citeRegEx" : "Kumar et al\\.,? 2018",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2018
    }, {
      "title" : "Is that social bot behaving unethically",
      "author" : [ "Carolina Alves de Lima Salge", "Nicholas Berente" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "Salge and Berente.,? \\Q2017\\E",
      "shortCiteRegEx" : "Salge and Berente.",
      "year" : 2017
    }, {
      "title" : "Analyzing the hate and counter speech accounts on twitter",
      "author" : [ "Binny Mathew", "Navish Kumar", "Ravina", "Pawan Goyal", "Animesh Mukherjee." ],
      "venue" : "CoRR, abs/1812.02712.",
      "citeRegEx" : "Mathew et al\\.,? 2018",
      "shortCiteRegEx" : "Mathew et al\\.",
      "year" : 2018
    }, {
      "title" : "Thou shalt not hate: Countering online hate speech",
      "author" : [ "Binny Mathew", "Punyajoy Saha", "Hardik Tharad", "Subham Rajgaria", "Prajwal Singhania", "Suman Kalyan Maity", "Pawan Goyal", "Animesh Mukherjee." ],
      "venue" : "Proceedings of the International AAAI Confer-",
      "citeRegEx" : "Mathew et al\\.,? 2019",
      "shortCiteRegEx" : "Mathew et al\\.",
      "year" : 2019
    }, {
      "title" : "HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection",
      "author" : [ "Binny Mathew", "Punyajoy Saha", "Seid Muhie Yimam", "Chris Biemann", "Pawan Goyal", "Animesh Mukherjee." ],
      "venue" : "arXiv:2012.10289 [cs]. ArXiv: 2012.10289.",
      "citeRegEx" : "Mathew et al\\.,? 2020",
      "shortCiteRegEx" : "Mathew et al\\.",
      "year" : 2020
    }, {
      "title" : "Measuring the class-imbalance extent of multi-class problems",
      "author" : [ "Jonathan Ortigosa-Hernández", "Iñaki Inza", "Jose A Lozano." ],
      "venue" : "Pattern Recognition Letters, 98:32–38.",
      "citeRegEx" : "Ortigosa.Hernández et al\\.,? 2017",
      "shortCiteRegEx" : "Ortigosa.Hernández et al\\.",
      "year" : 2017
    }, {
      "title" : "Resources and benchmark corpora for hate speech detection: a systematic review",
      "author" : [ "Fabio Poletto", "Valerio Basile", "Manuela Sanguinetti", "Cristina Bosco", "Viviana Patti." ],
      "venue" : "Language Resources and Evaluation.",
      "citeRegEx" : "Poletto et al\\.,? 2020",
      "shortCiteRegEx" : "Poletto et al\\.",
      "year" : 2020
    }, {
      "title" : "A benchmark dataset for learning to intervene in online hate speech",
      "author" : [ "Jing Qian", "Anna Bethke", "Yinyin Liu", "Elizabeth Belding", "William Yang Wang." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Qian et al\\.,? 2019",
      "shortCiteRegEx" : "Qian et al\\.",
      "year" : 2019
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "OpenAI Blog, 1(8).",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Measuring the reliability of hate speech annotations: The case of the european refugee crisis",
      "author" : [ "Björn Ross", "Michael Rist", "Guillermo Carbonell", "Benjamin Cabrera", "Nils Kurowsky", "Michael Wojatzki." ],
      "venue" : "CoRR, abs/1701.08118.",
      "citeRegEx" : "Ross et al\\.,? 2017",
      "shortCiteRegEx" : "Ross et al\\.",
      "year" : 2017
    }, {
      "title" : "Social bias frames: Reasoning about social and power implications of language",
      "author" : [ "Maarten Sap", "Saadia Gabriel", "Lianhui Qin", "Dan Jurafsky", "Noah A. Smith", "Yejin Choi." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Sap et al\\.,? 2020",
      "shortCiteRegEx" : "Sap et al\\.",
      "year" : 2020
    }, {
      "title" : "Governing hate speech by means of counterspeech on facebook",
      "author" : [ "Carla Schieb", "Mike Preuss." ],
      "venue" : "66th ica annual conference, at fukuoka, japan, pages 1–23.",
      "citeRegEx" : "Schieb and Preuss.,? 2016",
      "shortCiteRegEx" : "Schieb and Preuss.",
      "year" : 2016
    }, {
      "title" : "Toward stancebased personas for opinionated dialogues",
      "author" : [ "Thomas Scialom", "Serra Sinem Tekiroğlu", "Jacopo Staiano", "Marco Guerini." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings,",
      "citeRegEx" : "Scialom et al\\.,? 2020",
      "shortCiteRegEx" : "Scialom et al\\.",
      "year" : 2020
    }, {
      "title" : "The impact of counter-narratives",
      "author" : [ "Tanya Silverman", "Christopher J Stewart", "Jonathan Birdwell", "Zahed Amanullah." ],
      "venue" : "Institute for Strategic Dialogue, London. https://www. strategicdialogue. org/wp-content/uploads/2016/08/Impact-of-",
      "citeRegEx" : "Silverman et al\\.,? 2016",
      "shortCiteRegEx" : "Silverman et al\\.",
      "year" : 2016
    }, {
      "title" : "Release strategies and the social impacts of language models",
      "author" : [ "Irene Solaiman", "Miles Brundage", "Jack Clark", "Amanda Askell", "Ariel Herbert-Voss", "Jeff Wu", "Alec Radford", "Jasmine Wang." ],
      "venue" : "CoRR, abs/1908.09203.",
      "citeRegEx" : "Solaiman et al\\.,? 2019",
      "shortCiteRegEx" : "Solaiman et al\\.",
      "year" : 2019
    }, {
      "title" : "Estimating machine translation post-editing effort with hter",
      "author" : [ "Lucia Specia", "Atefeh Farzindar." ],
      "venue" : "Proceedings of the Second Joint EM+/CNGL Workshop Bringing MT to the User: Research on Integrating MT in the Translation Industry (JEC 10), pages",
      "citeRegEx" : "Specia and Farzindar.,? 2010",
      "shortCiteRegEx" : "Specia and Farzindar.",
      "year" : 2010
    }, {
      "title" : "Creating a whatsapp dataset to study pre-teen cyberbullying",
      "author" : [ "Rachele Sprugnoli", "Stefano Menini", "Sara Tonelli", "Filippo Oncini", "Enrico Piras." ],
      "venue" : "Proceedings of the 2nd Workshop on Abusive Language Online (ALW2), pages 51–59.",
      "citeRegEx" : "Sprugnoli et al\\.,? 2018",
      "shortCiteRegEx" : "Sprugnoli et al\\.",
      "year" : 2018
    }, {
      "title" : "The varieties of feminist counterspeech in the misogynistic online world",
      "author" : [ "Scott R Stroud", "William Cox." ],
      "venue" : "Mediating Misogyny, pages 293–310. Springer.",
      "citeRegEx" : "Stroud and Cox.,? 2018",
      "shortCiteRegEx" : "Stroud and Cox.",
      "year" : 2018
    }, {
      "title" : "Generating counter narratives against online hate speech: Data and strategies",
      "author" : [ "Serra Sinem Tekiroğlu", "Yi-Ling Chung", "Marco Guerini." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1177–",
      "citeRegEx" : "Tekiroğlu et al\\.,? 2020",
      "shortCiteRegEx" : "Tekiroğlu et al\\.",
      "year" : 2020
    }, {
      "title" : "Coping with the subjectivity of human judgements in mt quality estimation",
      "author" : [ "Marco Turchi", "Matteo Negri", "Marcello Federico." ],
      "venue" : "Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 240–251.",
      "citeRegEx" : "Turchi et al\\.,? 2013",
      "shortCiteRegEx" : "Turchi et al\\.",
      "year" : 2013
    }, {
      "title" : "Directions in abusive language training data, a systematic review: Garbage in, garbage out",
      "author" : [ "Bertie Vidgen", "Leon Derczynski." ],
      "venue" : "PLOS ONE, 15(12):e0243300.",
      "citeRegEx" : "Vidgen and Derczynski.,? 2020",
      "shortCiteRegEx" : "Vidgen and Derczynski.",
      "year" : 2020
    }, {
      "title" : "Challenges and frontiers in abusive content detection",
      "author" : [ "Bertie Vidgen", "Alex Harris", "Dong Nguyen", "Rebekah Tromble", "Scott Hale", "Helen Margetts." ],
      "venue" : "Proceedings of the Third Workshop on Abusive Language Online, pages 80–93, Florence, Italy.",
      "citeRegEx" : "Vidgen et al\\.,? 2019",
      "shortCiteRegEx" : "Vidgen et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning from the worst: Dynamically generated datasets to improve online hate detection",
      "author" : [ "Bertie Vidgen", "Tristan Thrush", "Zeerak Waseem", "Douwe Kiela." ],
      "venue" : "CoRR, abs/2012.15761.",
      "citeRegEx" : "Vidgen et al\\.,? 2020",
      "shortCiteRegEx" : "Vidgen et al\\.",
      "year" : 2020
    }, {
      "title" : "Trick me if you can: Human-in-the-loop generation of adversarial question answering examples",
      "author" : [ "Eric Wallace", "Pedro Rodriguez", "Shi Feng", "Ikuya Yamada", "Jordan Boyd-Graber." ],
      "venue" : "Transactions",
      "citeRegEx" : "Wallace et al\\.,? 2019",
      "shortCiteRegEx" : "Wallace et al\\.",
      "year" : 2019
    }, {
      "title" : "Sentigan: Generating sentimental texts via mixture adversarial networks",
      "author" : [ "Ke Wang", "Xiaojun Wan." ],
      "venue" : "IJCAI, pages 4446–4452.",
      "citeRegEx" : "Wang and Wan.,? 2018",
      "shortCiteRegEx" : "Wang and Wan.",
      "year" : 2018
    }, {
      "title" : "Are you a racist or am i seeing things? annotator influence on hate speech detection on twitter",
      "author" : [ "Zeerak Waseem." ],
      "venue" : "Proceedings of the first workshop on NLP and computational social science, pages 138– 142.",
      "citeRegEx" : "Waseem.,? 2016",
      "shortCiteRegEx" : "Waseem.",
      "year" : 2016
    }, {
      "title" : "Hateful symbols or hateful people? predictive features for hate speech detection on twitter",
      "author" : [ "Zeerak Waseem", "Dirk Hovy." ],
      "venue" : "Proceedings of the NAACL student research workshop, pages 88–93.",
      "citeRegEx" : "Waseem and Hovy.,? 2016",
      "shortCiteRegEx" : "Waseem and Hovy.",
      "year" : 2016
    }, {
      "title" : "Hatred behind the screens: A report on the rise of online hate speech",
      "author" : [ "Matthew Williams" ],
      "venue" : null,
      "citeRegEx" : "Williams.,? \\Q2019\\E",
      "shortCiteRegEx" : "Williams.",
      "year" : 2019
    }, {
      "title" : "Defending against neural fake news",
      "author" : [ "Rowan Zellers", "Ari Holtzman", "Hannah Rashkin", "Yonatan Bisk", "Ali Farhadi", "Franziska Roesner", "Yejin Choi." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 9051–9062.",
      "citeRegEx" : "Zellers et al\\.,? 2019",
      "shortCiteRegEx" : "Zellers et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 37,
      "context" : "The proliferation of online hatred has became an alarming issue (Williams, 2019) threatening not only the well-being of target individuals and",
      "startOffset" : 64,
      "endOffset" : 80
    }, {
      "referenceID" : 0,
      "context" : ", CounterNarratives (CN), are non-aggressive textual feedback using credible evidence, factual arguments, alternative viewpoints, and are considered as an effective strategy (Benesch, 2014; Schieb and Preuss, 2016) to confront hate speech while respecting the human rights (Kiritchenko et al.",
      "startOffset" : 174,
      "endOffset" : 214
    }, {
      "referenceID" : 21,
      "context" : ", CounterNarratives (CN), are non-aggressive textual feedback using credible evidence, factual arguments, alternative viewpoints, and are considered as an effective strategy (Benesch, 2014; Schieb and Preuss, 2016) to confront hate speech while respecting the human rights (Kiritchenko et al.",
      "startOffset" : 174,
      "endOffset" : 214
    }, {
      "referenceID" : 9,
      "context" : ", CounterNarratives (CN), are non-aggressive textual feedback using credible evidence, factual arguments, alternative viewpoints, and are considered as an effective strategy (Benesch, 2014; Schieb and Preuss, 2016) to confront hate speech while respecting the human rights (Kiritchenko et al., 2020).",
      "startOffset" : 273,
      "endOffset" : 299
    }, {
      "referenceID" : 10,
      "context" : ", 2017), Facebook (Kumar et al., 2018), WhatsApp (Sprugnoli et al.",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 26,
      "context" : ", 2018), WhatsApp (Sprugnoli et al., 2018), and forums (de Gibert et al.",
      "startOffset" : 18,
      "endOffset" : 42
    }, {
      "referenceID" : 0,
      "context" : "studies proved that counter-narratives are effective in hate countering (Benesch, 2014; Silverman et al., 2016; Schieb and Preuss, 2016; Stroud and Cox, 2018; Mathew et al., 2019), only few works have focused on data collection for CN genera-",
      "startOffset" : 72,
      "endOffset" : 179
    }, {
      "referenceID" : 23,
      "context" : "studies proved that counter-narratives are effective in hate countering (Benesch, 2014; Silverman et al., 2016; Schieb and Preuss, 2016; Stroud and Cox, 2018; Mathew et al., 2019), only few works have focused on data collection for CN genera-",
      "startOffset" : 72,
      "endOffset" : 179
    }, {
      "referenceID" : 21,
      "context" : "studies proved that counter-narratives are effective in hate countering (Benesch, 2014; Silverman et al., 2016; Schieb and Preuss, 2016; Stroud and Cox, 2018; Mathew et al., 2019), only few works have focused on data collection for CN genera-",
      "startOffset" : 72,
      "endOffset" : 179
    }, {
      "referenceID" : 27,
      "context" : "studies proved that counter-narratives are effective in hate countering (Benesch, 2014; Silverman et al., 2016; Schieb and Preuss, 2016; Stroud and Cox, 2018; Mathew et al., 2019), only few works have focused on data collection for CN genera-",
      "startOffset" : 72,
      "endOffset" : 179
    }, {
      "referenceID" : 13,
      "context" : "studies proved that counter-narratives are effective in hate countering (Benesch, 2014; Silverman et al., 2016; Schieb and Preuss, 2016; Stroud and Cox, 2018; Mathew et al., 2019), only few works have focused on data collection for CN genera-",
      "startOffset" : 72,
      "endOffset" : 179
    }, {
      "referenceID" : 18,
      "context" : "(2020), we have an author module built using GPT-2 language model (Radford et al., 2019) and fine-tuned on a seed dataset of HS/CN pairs.",
      "startOffset" : 66,
      "endOffset" : 88
    }, {
      "referenceID" : 8,
      "context" : "At the generation time, Nucleus Sampling (Holtzman et al., 2019) has been utilized with a p value of 0.",
      "startOffset" : 41,
      "endOffset" : 64
    }, {
      "referenceID" : 25,
      "context" : "HTER is originally a measure of post-editing effort at sentence level translations (Specia and Farzindar, 2010).",
      "startOffset" : 83,
      "endOffset" : 111
    }, {
      "referenceID" : 29,
      "context" : "4 is used to account for easily post-editable pairs (Turchi et al., 2013).",
      "startOffset" : 52,
      "endOffset" : 73
    }, {
      "referenceID" : 6,
      "context" : "We utilized it to compute the originality present in Vi with respect to the training data collected in previous loops (Dziri et al., 2019; Wang and Wan, 2018).",
      "startOffset" : 118,
      "endOffset" : 158
    }, {
      "referenceID" : 34,
      "context" : "We utilized it to compute the originality present in Vi with respect to the training data collected in previous loops (Dziri et al., 2019; Wang and Wan, 2018).",
      "startOffset" : 118,
      "endOffset" : 158
    }, {
      "referenceID" : 2,
      "context" : "Repetition Rate measures the intra-corpora quality in terms of language diversity by considering the rate of non-singleton ngram types it contains (Cettolo et al., 2014; Bertoldi et al., 2013).",
      "startOffset" : 147,
      "endOffset" : 192
    }, {
      "referenceID" : 1,
      "context" : "Repetition Rate measures the intra-corpora quality in terms of language diversity by considering the rate of non-singleton ngram types it contains (Cettolo et al., 2014; Bertoldi et al., 2013).",
      "startOffset" : 147,
      "endOffset" : 192
    }, {
      "referenceID" : 29,
      "context" : "4 acceptability threshold as defined in (Turchi et al., 2013) for the AMT scenario (Figure 3).",
      "startOffset" : 40,
      "endOffset" : 61
    }, {
      "referenceID" : 20,
      "context" : "V6,SBF : The model GPT-2V5 is conditioned with novel offensive speeches extracted from SBIC corpus (Sap et al., 2020).",
      "startOffset" : 99,
      "endOffset" : 117
    }, {
      "referenceID" : 22,
      "context" : "V6,ARG : We fine-tuned GPT-2 on a dataset of argumentative pairs collected from Kialo5, an online debate platform for constructive and rational discussions among peers that has been exploited recently by the NLP community (Durmus et al., 2019a,b; Scialom et al., 2020).",
      "startOffset" : 222,
      "endOffset" : 268
    }, {
      "referenceID" : 38,
      "context" : "(Zellers et al., 2019; Solaiman et al., 2019), such as the third example in Table 2, where GPT-2 addresses muggleborns (target of hate in Harry Potter books).",
      "startOffset" : 0,
      "endOffset" : 45
    }, {
      "referenceID" : 24,
      "context" : "(Zellers et al., 2019; Solaiman et al., 2019), such as the third example in Table 2, where GPT-2 addresses muggleborns (target of hate in Harry Potter books).",
      "startOffset" : 0,
      "endOffset" : 45
    } ],
    "year" : 2021,
    "abstractText" : "Undermining the impact of hateful content with informed and non-aggressive responses, called counter narratives, has emerged as a possible solution for having healthier online communities. Thus, some NLP studies have started addressing the task of counter narrative generation. Although such studies have made an effort to build hate speech / counter narrative (HS/CN) datasets for neural generation, they fall short in reaching either highquality and/or high-quantity. In this paper, we propose a novel human-in-the-loop data collection methodology in which a generative language model is refined iteratively by using its own data from the previous loops to generate new training samples that experts review and/or post-edit. Our experiments comprised several loops including dynamic variations. Results show that the methodology is scalable and facilitates diverse, novel, and cost-effective data collection. To our knowledge, the resulting dataset is the only expertbased multi-target HS/CN dataset available to the community.",
    "creator" : "LaTeX with hyperref"
  }
}