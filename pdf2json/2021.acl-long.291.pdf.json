{
  "name" : "2021.acl-long.291.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "CogAlign: Learning to Align Textual Neural Representations to Cognitive Language Processing Signals",
    "authors" : [ "Yuqi Ren", "Deyi Xiong" ],
    "emails" : [ "dyxiong}@tju.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3758–3769\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3758\nMost previous studies integrate cognitive language processing signals (e.g., eye-tracking or EEG data) into neural models of natural language processing (NLP) just by directly concatenating word embeddings with cognitive features, ignoring the gap between the two modalities (i.e., textual vs. cognitive) and noise in cognitive features. In this paper, we propose a CogAlign approach to these issues, which learns to align textual neural representations to cognitive features. In CogAlign, we use a shared encoder equipped with a modality discriminator to alternatively encode textual and cognitive inputs to capture their differences and commonalities. Additionally, a text-aware attention mechanism is proposed to detect task-related information and to avoid using noise in cognitive features. Experimental results on three NLP tasks, namely named entity recognition, sentiment analysis and relation extraction, show that CogAlign achieves significant improvements with multiple cognitive features over state-of-the-art models on public datasets. Moreover, our model is able to transfer cognitive information to other datasets that do not have any cognitive processing signals. The source code for CogAlign is available at https://github. com/tjunlp-lab/CogAlign.git."
    }, {
      "heading" : "1 Introduction",
      "text" : "Cognitive neuroscience, from a perspective of language processing, studies the biological and cognitive processes and aspects that underlie the mental language processing procedures in human brains while natural language processing (NLP) teaches machines to read, analyze, translate and generate human language sequences (Muttenthaler et al., 2020). The commonality of language processing shared by these two areas forms the base of\n∗Corresponding author\ncognitively-inspired NLP, which uses cognitive language processing signals generated by human brains to enhance or probe neural models in solving a variety of NLP tasks, such as sentiment analysis (Mishra et al., 2017; Barrett et al., 2018), named entity recognition (NER) (Hollenstein and Zhang, 2019), dependency parsing (Strzyz et al., 2019), relation extraction (Hollenstein et al., 2019a), etc.\nIn spite of the success of cognitively-inspired NLP in some tasks, there are some issues in the use of cognitive features in NLP. First, for the integration of cognitive processing signals into neural models of NLP tasks, most previous studies have just directly concatenated word embeddings with cognitive features from eye-tracking or EEG, ignoring the huge differences between these two types of representations. Word embeddings are usually learned as static or contextualized representations of words in large-scale spoken or written texts generated by humans. In contrast, cognitive language processing signals are collected by specific medical equipments, which record the activity of human brains during the cognitive process of language processing. These cognitive processing signals are usually assumed to represent psycholinguistic information (Mathias et al., 2020) or cognitive load (Antonenko et al., 2010). Intuitively, information in these two types of features (i.e., word embeddings and cognitive features) is not directly comparable to each other. As a result, directly concatenating them could be not optimal for neural models to solve NLP tasks.\nThe second issue with the incorporation of cognitive processing signals into neural models of NLP is that not all information in cognitive processing signals is useful for NLP. The recorded signals contain information covering a wide variety of cognitive processes, particularly for EEG (Williams et al., 2019; Eugster et al., 2014). For different tasks, we may need to detect elements in the recorded signals,\nwhich are closely related to specific NLP tasks, and neglect features that are noisy to the tasks.\nIn order to address the two issues, we propose CogAlign, a multi-task neural network that learns to align neural representations of texts to cognitive processing signals, for several NLP tasks. As shown in Figure 1, instead of simply concatenating cognitive features with word embeddings, we use two private encoders to separately encode cognitive processing signals and word embeddings. The two encoders will learn task-specific representations for cognitive and textual inputs in two disentangled spaces. To align the representations of neural network with cognitive processing signals, we further introduce an additional encoder that is shared by both data sources. We alternatively feed cognitive and textual inputs into the shared encoder and force it to minimize an adversarial loss of the discriminator stacked over the shared encoder. The discriminator is task-agnostic so that it can focus on learning both differences and deep commonalities between neural representations of cognitive and textual features in the shared encoder. We want the shared encoder to be able to transfer knowledge of cognitive language processing signals to other datasets even if cognitive processing signals are not available for those datasets. Therefore, CogAlign does not require cognitive processing signals as inputs during inference.\nPartially inspired by the attentive pooling network (Santos et al., 2016), we propose a text-aware attention mechanism to further align textual inputs and cognitive processing signals at the word level.\nThe attention network learns a compatibility matrix of textual inputs to cognitive processing signals. The learned text-aware representations of cognitive processing signals also help the model to detect task-related information and to avoid using other noisy information contained in cognitive processing signals.\nIn a nutshell, our contributions are listed as follows:\n• We present CogAlign that learns to align neural representations of natural language to cognitive processing signals at both word and sentence level. Our analyses show that it can learn task-related specific cognitive processing signals.\n• We propose a text-aware attention mechanism that extracts useful cognitive information via a compatibility matrix.\n• With the adversarially trained shared encoder, CogAlign is capable of transferring cognitive knowledge into other datasets for the same task, where no recorded cognitive processing signals are available.\n• We conduct experiments on incorporating eyetracking and EEG signals into 3 different NLP tasks: NER, sentiment analysis and relation extraction, which show CogAlign achieves new state-of-the-art results and significant improvements over strong baselines."
    }, {
      "heading" : "2 Related Work",
      "text" : "Eye-tracking for NLP. Eye-tracking data have proved to be associated with language comprehension activity in human brains by numerous research in neuroscience (Rayner, 1998; Henderson and Ferreira, 1993). In cognitively motivated NLP, several studies have investigated the impact of eye-tracking data on NLP tasks. In early works, these signals have been used in machine learning approaches to NLP tasks, such as part-of-speech tagging (Barrett et al., 2016), multiword expression extraction (Rohanian et al., 2017), syntactic category prediction (Barrett and Søgaard, 2015). In neural models, eyetracking data are combined with word embeddings to improve various NLP tasks, such as sentiment analysis (Mishra et al., 2017) and NER (Hollenstein and Zhang, 2019). Eye-tracking data have also been used to enhance or constrain neural attention in (Barrett et al., 2018; Sood et al., 2020b,a; Takmaz et al., 2020).\nEEG for NLP. Electroencephalography (EEG) measures potentials fluctuations caused by the activity of neurons in cerebral cortex. The exploration of EEG data in NLP tasks is relatively limited. Chen et al. (2012) improve the performance of automatic speech recognition (ASR) by using EEG signals to classify the speaker’s mental state. Hollenstein et al. (2019a) incorporate EEG signals into NLP tasks, including NER, relation extraction and sentiment analysis. Additionally, Muttenthaler et al. (2020) leverage EEG features to regularize attention on relation extraction.\nAdversarial Learning. The concept of adversarial training originates from the Generative Adversarial Nets (GAN) (Goodfellow et al., 2014) in computer vision. Since then, it has been also applied in NLP (Denton et al., 2015; Ganin et al., 2016). Recently, a great variety of studies attempt to introduce adversarial training into multi-task learning in NLP tasks, such as Chinese NER (Cao et al., 2018), crowdsourcing learning (Yang et al., 2018), cross-lingual transfer learning (Chen et al., 2018; Kim et al., 2017), just name a few. Different from these studies, we use adversarial learning to deeply align cognitive modality to textual modality at the sentence level."
    }, {
      "heading" : "3 CogAlign",
      "text" : "CogAlign is a general framework for incorporating cognitive processing signals into various NLP\ntasks. The target task can be specified at the predictor layer with corresponding task-specific neural network. CogAlign focuses on aligning cognitive processing signals to textual features at the word and encoder level. The text-aware attention aims at learning task-related useful cognitive information (thus filtering out noises) while the shared encoder and discriminator collectively learns to align representations of cognitive processing signals to those of textual inputs in a unified semantic space. The matched neural representations can be transferred to another datasets of the target task even though cognitive processing signals is not present. The neural architecture of CogAlign is visualized in Figure 1. We will elaborate the components of model in the following subsections."
    }, {
      "heading" : "3.1 Input Layer",
      "text" : "The inputs to our model include textual word embeddings and cognitive processing signals.\nWord Embeddings. For a given word xi from the dataset of a target NLP task (e.g., NER), we obtain the vector representation hwordi by looking up a pre-trained embedding matrix. The obtained word embeddings are fixed during training. For NER, previous studies have shown that character-level features can improve the performance of sequence labeling (Lin et al., 2018). We therefore apply a character-level CNN framework (Chiu and Nichols, 2016; Ma and Hovy, 2016) to capture the characterlevel embedding. The word representation of word xi in NER task is the concatenation of word embedding and character-level embedding.\nCognitive Processing Signals. For cognitive inputs, we can obtain word-level eye-tracking and EEG via data preprocessing (see details in Section 5.1). Thus, for each word xi, we employ two cognitive processing signals heyei and h eeg i . The cognitive input hcogi can be either a single type of signal or a concatenation of different cognitive processing signals."
    }, {
      "heading" : "3.2 Text-Aware Attention",
      "text" : "As not all information contained in cognitive processing signals is useful for the target NLP task, we propose a text-aware attention mechanism to assign text sensitive weights to cognitive processing signals. The main process of attention mechanism consists of learning a compatibility matrix between word embeddings Hword ∈ Rdw×N and cognitive representations Hcog ∈ Rdc×N from the input\nlayer and preforming cognitive-wise max-pooling operation over the matrix. The compatibility matrix G ∈ Rdw×dc can be computed as follows:\nG = tanh(HwordUHcog T ) (1)\nwhere dw and dc are the dimension of word embeddings and cognitive representations, respectively, N is the length of the input, and U ∈ RN×N is a trainable parameter matrix.\nWe then obtain a vector gcog ∈ Rdc , which is computed as the importance score for each element in the cognitive processing signals with regard to the word embeddings, by row-wise max-pooling over G. Finally, we compute attention weights and the text-aware representation of cognitive processing signals Hcog ′ as follows:\nαcog = softmax(gcog) (2)\nHcog ′ = αcogHcog (3)"
    }, {
      "heading" : "3.3 Encoder Layer",
      "text" : "We adopt Bi-LSTMs to encode both cognitive and textual inputs following previous works (Hollenstein and Zhang, 2019; Hollenstein et al., 2019a). In this work, we employ two private Bi-LSTMs and one shared Bi-LSTM as shown in Figure 1, where private Bi-LSTMs are used to encode cognitive and textual inputs respectively and the shared Bi-LSTM is used for learning shared semantics of both types of inputs. We concatenate the outputs of private Bi-LSTMs and shared Bi-LSTM as input to the task-specific predictors of subsequent NLP tasks. The hidden states of the shared Bi-LSTM are also fed into the discriminator."
    }, {
      "heading" : "3.4 Modality Discriminator",
      "text" : "We alternatively feed cognitive and textual inputs into the shared Bi-LSTM encoder. Our goal is that the shared encoder is able to map the representations of the two different sources of inputs into the same semantic space so as to learn the deep commonalities of two modalities (cognitive and textual). For this, we use a self-supervised discriminator to provide supervision for training the shared encoder.\nParticularly, the discriminator is acted as a classifier to categorize the alternatively fed inputs into either the textual or cognitive input. For the hidden\nstate of modality k, we use a self-attention mechanism to first reduce the dimension of the output of the shared Bi-LSTM Hsk ∈ Rdh×N :\nα = softmax(vT tanh(WsH s k + bs)) (4)\nhsk = N∑ i=1 αiH s ki\n(5)\nwhere Ws ∈ Rdh×dh , bs ∈ Rdh , v ∈ Rdh are trainable parameters in the model, hsk is the output of self-attention mechanism. Then we predict the category of the input by softmax function:\nD(hsk) = softmax(Wdh s k + bd) (6)\nwhere D(hsk) is the probability that the shared encoder is encoding an input with modality k."
    }, {
      "heading" : "3.5 Predictor Layer",
      "text" : "Given a sample X , the final cognitively augmented representation after the encoder layer can be formulated as H ′ = [Hp;Hs] ∈ R2dh×N . Hp and Hs are the result of private Bi-LSTM and shared Bi-LSTM, respectively.\nFor sequence labeling tasks like NER, we employ the conditional random field (CRF) (Lafferty et al., 2001) as the predictor as Bi-LSTM-CRF is widely used in many sequence labeling tasks (Ma and Hovy, 2016; Luo et al., 2018) due to the excellent performance and also in cognitively inspired NLP (Hollenstein and Zhang, 2019; Hollenstein et al., 2019a). Firstly, we project the feature representation H ′ onto another space of which dimension is equal to the number of NER tags as follows:\noi =Wnh ′ i + bn (7)\nWe then compute the score of a predicted tag sequence y for the given sample X:\nscore(X, y) = N∑ i=1 (oi,yi + Tyi−1,yi) (8)\nwhere T is a transition score matrix which defines the transition probability of two successive labels.\nSentiment analysis and relation extraction can be regarded as multi-class classification tasks, with 3 and 11 classes, respectively. For these two tasks, we use a self attention mechanism to reduce the dimension of H ′ and obtain the probability of a predicted class via the softmax function."
    }, {
      "heading" : "4 Training and Inference",
      "text" : ""
    }, {
      "heading" : "4.1 Adversarial Learning",
      "text" : "In order to learn the deep interaction between cognitive and textual modalities in the same semantic space, we want the shared Bi-LSTM encoder to output representations that can fool the discriminator. Therefore we adopt the adversarial learning strategy. Particularly, the shared encoder acts as the generator that tries to align the textual and cognitive modalities as close as possible so as to mislead the discriminator. The shared encoder and discriminator works in an adversarial way.\nAdditionally, to further increase the difficulty for the discriminator to distinguish modalities, we add a gradient reversal layer (GRL) (Ganin and Lempitsky, 2015) in between the encoder layer and predictor layer. The gradient reversal layer does nothing in the forward pass but reverses the gradients and passes them to the preceding layer during the backward pass. That is, gradients with respect to the adversarial loss ∂LAdv∂θ are replaced with −∂LAdv∂θ after going through GRL."
    }, {
      "heading" : "4.2 Training Objective",
      "text" : "CogAlign is established on a multi-task learning framework, where the final training objective is composed of the adversarial loss LAdv and the loss of the target task LTask. For NER, we exploit the negative log-likelihood objective as the loss function. Given T training examples (Xi; yi)1, LTask is defined as follows:\nLTask = − T∑ i=1 logp(yi|Xi) (9)\nwhere y denotes the ground-truth tag sequence. The probability of y is computed by the softmax function:\np(y|X) = e score(X,y)∑\nỹ∈Y e score(X,ỹ)\n(10)\nFor sentiment analysis and relation extraction tasks, the task objective is similar to that of NER. The only difference is that the label of the task is changed from a tag sequence to a single class.\nThe adversarial loss LAdv is defined as:\nLAdv = min θs (max θd K∑ k=1 Tk∑ i=1 logD(S(Xik))) (11)\n1X can be either textual or cognitive input as we alternatively feed word embeddings and cognitive processing signals into CogAlign.\nwhere θs and θd denote the parameters of the shared Bi-LSTM encoders S and modality discriminator D, respectively, Xik is the representation of sentence i in a modality k. The joint loss of CogAlign is therefore defined as:\nL = LTask + LAdv (12)"
    }, {
      "heading" : "4.3 Inference",
      "text" : "After training, the shared encoder learns a unified semantic space for representations of both cognitive and textual modality. We believe that the shared space embeds knowledge from cognitive processing signals. For inference, we therefore only use the textual part and the shared encoder (components in the red dashed box in Figure 1). The private encoder outputs textual-modality-only representations while the shared encoder generates cognitive-augmented representations. The two representations are concatenated to feed into the predictor layer of the target task. This indicates that we do not need cognitive processing signals for the inference of the target task. It also means that we can pretrain CogAlign with cognitive processing signals and then transfer it to other datasets where cognitive processing signals are not available for the same target task."
    }, {
      "heading" : "5 Experiments",
      "text" : "We conducted experiments on three NLP tasks, namely NER, sentiment analysis and relation extraction with two types of cognitive processing signals (eye-tracking and EEG) to validate the effectiveness of the proposed CogAlign."
    }, {
      "heading" : "5.1 Dataset and Cognitive Processing Signals",
      "text" : "We chose a dataset2 with multiple cognitive processing signals: Zurich Cognitive Language Processing Corpus (ZuCo) (Hollenstein et al., 2018). This corpus contains simultaneous eye-tracking and EEG signals collected when 12 native English speakers are reading 1,100 English sentences. Word-level signals can be divided by the duration of each word.\nThe dataset includes two reading paradigms: normal reading and task-specific reading where subjects exercise some specific task. In this work, we only used the data of normal reading, since this paradigm accords with human natural reading. The materials for normal reading paradigm\n2The data is available here: https://osf.io/q3zws/\nEARLY first fixation duration (FFD) the duration of word w that is first fixatedfirst pass duration (FPD) the sum of the fixations before eyes leave the word w\nLATE\nnumber of fixations (NFIX) the number of times word w that is fixated fixation probability (FP) the probability that word w is fixated mean fixation duration (MFD) the average fixation durations for word w total fixation duration (TFD) the total duration of word w that is fixated n re-fixations (NR) the number of times word w that is fixated after the first fixation re-read probability (RRP) the probability of word w that is fixated more than once\nCONTEXT total regression-from duration (TRD) the total duration of regressions from word w w-2 fixation probability (w-2 FP) the fixation probability of the word w-2 w-1 fixation probability (w-1 FP) the fixation probability of the word w-1 w+1 fixation probability (w+1 FP) the fixation probability of the word w+1 w+2 fixation probability (w+2 FP) the fixation probability of the word w+2 w-2 fixation duration (w-2 FD) the fixation duration of the word w-2 w-1 fixation duration (w-1 FD) the fixation duration of the word w-1 w+1 fixation duration (w+1 FD) the fixation duration of the word w+1 w+2 fixation duration (w+2 FD) the fixation duration of the word w+2\nTable 1: Eye-tracking features used in the NER task.\nconsist of two datasets: 400 movie reviews from Stanford Sentiment Treebank (Socher et al., 2013) with manually annotated sentiment labels, including 123 neutral, 137 negative and 140 positive sentences; 300 paragraphs about famous people from Wikipedia relation extraction corpus (Culotta et al., 2006) labeled with 11 relationship types, such as award, education.\nWe also tested our model on NER task. For NER, the selected 700 sentences in the above two tasks are annotated with three types of entities: PERSON, ORGANIZATION, and LOCATION. All annotated datasets3 are publicly available. The cognitive processing signals and textual features used for each task in this work are the same as (Hollenstein et al., 2019a).\nEye-tracking Features. Eye-tracking signals record human gaze behavior while reading. The eye-tracking data of ZuCo are collected by an infrared video-based eye tracker EyeLink 1000 Plus with a sampling rate of 500 Hz. For NER, we used 17 eye-tracking features that cover all stages of gaze behaviors and the effect of context. According to the reading process, these features are divided into three groups: EARLY, the gaze behavior when a word is fixated for the first time; LATE, the gaze behavior over a word that is fixated many times; CONTEXT, the eye-tracking features over neighboring words of the current word. The 17 eyetracking features used in the NER task are shown in the Table 1. In the other two tasks, we employed 5 gaze behaviors, including the first fixation duration (FFD), the number of fixations (NFIX), the total fixation duration (TFD), the first pass duration\n3https://github.com/DS3Lab/zuco-nlp/\n(FPD), the gaze duration (GD) that is the duration of the first time eyes move to the current word until eyes leave the word.\nEEG Features. EEG signals record the brain’s electrical activity in the cerebral cortex by placing electrodes on the scalp of the subject. In the datasets we used, EEG signals are recorded by a 128-channel EEG Geodesic Hydrocel system (Electrical Geodesics, Eugene, Oregon) at a sampling rate of 500 Hz with a bandpass of 0.1 to 100 Hz. The original EEG signals recorded are of 128 dimensions. Among them, 23 EEG signals are removed during preprocessing since they are not related to the cognitive processing (Hollenstein et al., 2018). After preprocessing, we obtained 105 EEG signals. The left EEG signals are divided into 8 frequency bands by the frequency of brain’s electrical signals: theta1 (t1, 4-6 Hz), theta2 (t2, 6.5-8 Hz), alpha1 (a1, 8.5-10 Hz), alpha2 (a2, 10.5-13 Hz), beta1 (b1, 13.5-18 Hz), beta2 (b2, 18.5-30 Hz), gamma1 (g1, 30.5-40 Hz) and gamma2 (g2, 40-49.5 Hz). The frequency bands reflects the different functions of brain cognitive processing. For NER, we used 8 EEG features that are obtained by averaging the 105 EEG signals at each frequency band. For the other two tasks, EEG features were obtained by averaging the 105 signals over all frequency bands. All used EEG features are obtained by averaging over all subjects and normalization."
    }, {
      "heading" : "5.2 Settings",
      "text" : "We evaluated three NLP tasks in terms of precision, recall and F1 in our experiments. Word embeddings of all NLP tasks were initialized with the publicly available pretrained GloVe (Pennington\net al., 2014) vectors of 300 dimensions. For NER, we used 30-dimensional randomly initialized character embeddings. We set the dimension of hidden states of LSTM to 50 for both the private Bi-LSTM and shared Bi-LSTM. We performed 10-fold cross validation for NER and sentiment analysis and 5- fold cross validation for relation extraction."
    }, {
      "heading" : "5.3 Baselines",
      "text" : "We compared our model with previous state-ofthe-art methods on ZuCo dataset. The method by Hollenstein et al. (2019a) incorporates cognitive processing signals into their model via direct concatenation mentioned before."
    }, {
      "heading" : "5.4 Results",
      "text" : "Results of CogAlign on the three NLP tasks are shown in Table 2. From the table, we observe that:\n• By just simply concatenating word embeddings with cognitive processing signals, the Base model is better than the model without using any cognitive processing signals, indicating that cognitive processing signals (either eye-tracking or EEG signals) can improve all three NLP tasks. Notably, the improvements gained by eye-tracking features are larger than those obtained by EEG signals while the combination of both does not improve over only using one of them. We conjecture that this may be due to the low signal-to-noise ratio of EEG signals, which further decreases when two signals are combined together.\n• Compared with the Base model, the Base+TA achieves better results on all NLP tasks. The\ntext-aware attention gains an absolute improvement of 0.88, 2.04, 0.17 F1 on NER, sentiment analysis, and relation extraction, respectively. With Base+TA, the best results for most tasks are obtained by the combination of eye-tracking and EEG signals. This suggests that the proposed text-aware attention may have alleviated the noise problem of cognitive processing signals.\n• The proposed CogAlign achieves the highest F1 over all three tasks, with improvements of 0.48, 2.17 and 0.87 F1 over Base+TA on NER, sentiment analysis and relation extraction, respectively, which demonstrates the effectiveness of our proposed model. In addition, CogAlign with both cognitive processing signals obtains new state-of-the-art performance in all NLP tasks. This suggests that CogAlign is able to effectively augment neural models with cognitive processing signals."
    }, {
      "heading" : "5.5 Ablation Study",
      "text" : "To take a deep look into the improvements contributed by each part of our model, we perform ablation study on all three NLP tasks with two cognitive processing signals. The ablation test includes: (1) w/o text-aware attention, removing text-aware attention mechanism; (2) w/o cognitive loss, discarding the loss of the cognitive predictor whose inputs are cognitive processing signals; (3) w/o modality discriminator, removing the discriminator to train parameters with the task loss. Table 3 reports the ablation study results.\nThe absence of the text-aware attention, cognitive loss and modality discriminator results in a significant drop in performance. This demonstrates that these components all contribute to the effective incorporation of cognitive processing signals into neural models of the three target tasks. CogAlign outperforms both (2) w/o cognitive loss and (3) w/o modality discriminator by a great margin, indicating that the cognitive features can significantly enhance neural models.\nFurthermore, we visualize the distribution of hidden states learned by the shared Bi-LSTM to give a more intuitive demonstration of the effect of adversarial learning. In Figure 2, clearly, the modality discriminator with adversarial learning forces the shared Bi-LSTM encoder to align textual inputs to cognitive processing signals in the same space."
    }, {
      "heading" : "6 Analysis",
      "text" : ""
    }, {
      "heading" : "6.1 Text-aware Attention Analysis",
      "text" : "In addition to denoising the cognitive processing signals, the text-aware attention mechanism also obtains the task-specific features. To have a clear view of the role that the text-aware attention mechanism plays in CogAlign, we randomly choose samples and visualize the average attention weights over each signal in Figure 3.\nFor eye-tracking, signals reflecting the late syn-\ntactic processing, such as ‘NFIX’ (number of fixation), ‘TFD’ (total fixation duration), play an important role in the three tasks. These results are consistent with findings in cognitive neuroscience. In cognitive neuroscience, researchers have shown that readers tend to gaze at nouns repeatedly (Furtner et al., 2009) (related to the eye-tracking signal NFIX, the number of fixations) and there is a dependency relationship between regression features and sentence syntactic structures (Lopopolo et al., 2019). In other NLP tasks that infused eye-tracking features, the late gaze features have also proved to be more important than early gaze features, such as multiword expression extraction (Rohanian et al., 2017). Moreover, from the additional eye-tracking used in NER, we can find that the cognitive features from the neighboring words are helpful to identify entity, such as ‘w-2 FP’ (w-2 fixation probability), ‘w+1 FP’ (w+1 fixation probability).\nSince a single EEG signal has no practical meaning, we only visualize the attention weights over EEG signals used in the NER task. Obviously, attentions to ‘t1’ (theta1) and ‘a2’ (alpha2) are stronger than other signals, suggesting that low frequency electric activities in the brain are obvious when we recognize an entity."
    }, {
      "heading" : "6.2 Transfer Learning Analysis",
      "text" : "The cognitively-inspired NLP is limited by the collection of cognitive processing signals. Thus, we further investigate whether our model can transfer cognitive features to other datasets without cognitive processing signals for the same task. We enable transfer learning in CogAlign with a method similar to the alternating training approach (Luong et al., 2016) that optimizes each task for a fixed number of mini-batches before shifting to the next task. In our case, we alternately feed instances from the ZuCo dataset and those from other datasets built for the same target task but without cognitive processing signals into CogAlign. Since CogAlign is a multi-task learning framework, model parameters can be updated either by data with cognitive processing signals or by data without such signals, where task-specific loss is used in both situations. Please notice that only textual inputs are fed into trained CogAlign for inference.\nTo evaluate the capacity of CogAlign in transferring cognitive features, we select benchmark datasets for NER and sentiment analysis: Wikigold (Balasuriya et al., 2009) and Stanford Sentiment Treebank (Socher et al., 2013). Since no other datasets use the same set of relation types as that in ZuCo dataset, we do not test the relation extraction task for transfer learning. To ensure that the same textual data are used for comparison, we add a new baseline model (baseline (+Zuco text)) that is trained on the combination of textual data in ZuCo and benchmark dataset. Additionally, as CogAlign uses two encoders for inference (i.e., the textual encoder and shared encoder), for a fair comparison, we setup another baseline (baseline (two encoders)) that also uses two encoders fed with the same textual inputs. The experimental setup is the same as mentioned before.\nResults are shown in the Table 4. We can observe that CogAlign consistently outperforms the\ntwo baselines. It indicates that CogAlign is able to effectively transfer cognitive knowledge (either eye-tracking or EEG) from ZuCo to other datasets. Results show that the best performance is achieved by transferring both eye-tracking and EEG signals at the same time."
    }, {
      "heading" : "7 Conclusions",
      "text" : "In this paper, we have presented CogAlign, a framework that can effectively fuse cognitive processing signals into neural models of various NLP tasks by learning to align the textual and cognitive modality at both word and sentence level. Experiments demonstrate that CogAlign achieves new state-ofthe-art results on three NLP tasks on the Zuco dataset. Analyses suggest that the text-aware attention in CogAlign can learn task-related cognitive processing signals by attention weights while the modality discriminator with adversarial learning forces CogAlign to learn cognitive and textual representations in the unified space. Further experiments exhibit that CogAlign is able to transfer cognitive information from Zuco to other datasets without cognitive processing signals."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The present research was partially supported by the National Key Research and Development Program of China (Grant No. 2019QY1802) and Natural Science Foundation of Tianjin (Grant No. 19JCZDJC31400). We would like to thank the anonymous reviewers for their insightful comments."
    } ],
    "references" : [ {
      "title" : "Using electroencephalography to measure cognitive load",
      "author" : [ "Pavlo Antonenko", "Fred Paas", "Roland Grabner", "Tamara Van Gog." ],
      "venue" : "Educational Psychology Review, 22(4):425–438.",
      "citeRegEx" : "Antonenko et al\\.,? 2010",
      "shortCiteRegEx" : "Antonenko et al\\.",
      "year" : 2010
    }, {
      "title" : "Named entity recognition in wikipedia",
      "author" : [ "Dominic Balasuriya", "Nicky Ringland", "Joel Nothman", "Tara Murphy", "James R. Curran." ],
      "venue" : "Proceedings of the 1st 2009 Workshop on The People’s Web Meets NLP: Collaboratively Constructed Semantic",
      "citeRegEx" : "Balasuriya et al\\.,? 2009",
      "shortCiteRegEx" : "Balasuriya et al\\.",
      "year" : 2009
    }, {
      "title" : "Sequence classification with human attention",
      "author" : [ "Maria Barrett", "Joachim Bingel", "Nora Hollenstein", "Marek Rei", "Anders Søgaard." ],
      "venue" : "Proceedings of the 22nd Conference on Computational Natural Language Learning, pages 302–312.",
      "citeRegEx" : "Barrett et al\\.,? 2018",
      "shortCiteRegEx" : "Barrett et al\\.",
      "year" : 2018
    }, {
      "title" : "Weakly supervised part-ofspeech tagging using eye-tracking data",
      "author" : [ "Maria Barrett", "Joachim Bingel", "Frank Keller", "Anders Søgaard." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Pa-",
      "citeRegEx" : "Barrett et al\\.,? 2016",
      "shortCiteRegEx" : "Barrett et al\\.",
      "year" : 2016
    }, {
      "title" : "Reading behavior predicts syntactic categories",
      "author" : [ "Maria Barrett", "Anders Søgaard." ],
      "venue" : "Proceedings of the 19th Conference on Computational Natural Language Learning, CoNLL 2015, Beijing, China, July 30-31, 2015, pages 345–349. ACL.",
      "citeRegEx" : "Barrett and Søgaard.,? 2015",
      "shortCiteRegEx" : "Barrett and Søgaard.",
      "year" : 2015
    }, {
      "title" : "Adversarial transfer learning for chinese named entity recognition with selfattention mechanism",
      "author" : [ "Pengfei Cao", "Yubo Chen", "Kang Liu", "Jun Zhao", "Shengping Liu." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Lan-",
      "citeRegEx" : "Cao et al\\.,? 2018",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2018
    }, {
      "title" : "Adversarial deep averaging networks for cross-lingual sentiment classification",
      "author" : [ "Xilun Chen", "Yu Sun", "Ben Athiwaratkun", "Claire Cardie", "Kilian Weinberger." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 6:557–570.",
      "citeRegEx" : "Chen et al\\.,? 2018",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2018
    }, {
      "title" : "Towards using EEG to improve ASR accuracy",
      "author" : [ "Yun-Nung Chen", "Kai-min Chang", "Jack Mostow." ],
      "venue" : "Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings,",
      "citeRegEx" : "Chen et al\\.,? 2012",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2012
    }, {
      "title" : "Named entity recognition with bidirectional LSTM-CNNs",
      "author" : [ "Jason PC Chiu", "Eric Nichols." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 4:357–370.",
      "citeRegEx" : "Chiu and Nichols.,? 2016",
      "shortCiteRegEx" : "Chiu and Nichols.",
      "year" : 2016
    }, {
      "title" : "Integrating probabilistic extraction models and data mining to discover relations and patterns in text",
      "author" : [ "Aron Culotta", "Andrew McCallum", "Jonathan Betz." ],
      "venue" : "Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,",
      "citeRegEx" : "Culotta et al\\.,? 2006",
      "shortCiteRegEx" : "Culotta et al\\.",
      "year" : 2006
    }, {
      "title" : "Deep generative image models using a Laplacian Pyramid of Adversarial Networks",
      "author" : [ "Emily L Denton", "Soumith Chintala", "Rob Fergus" ],
      "venue" : "Advances in neural information processing systems,",
      "citeRegEx" : "Denton et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Denton et al\\.",
      "year" : 2015
    }, {
      "title" : "Predicting term-relevance from brain signals",
      "author" : [ "Manuel J.A. Eugster", "Tuukka Ruotsalo", "Michiel M.A. Spapé", "Ilkka Kosunen", "Oswald Barral", "Niklas Ravaja", "Giulio Jacucci", "Samuel Kaski." ],
      "venue" : "The 37th International ACM SIGIR Conference on Re-",
      "citeRegEx" : "Eugster et al\\.,? 2014",
      "shortCiteRegEx" : "Eugster et al\\.",
      "year" : 2014
    }, {
      "title" : "Nomen est omen: Investigating the dominance of nouns in word comprehension with eye movement analyses",
      "author" : [ "Marco R. Furtner", "John F. Rauthmann", "Pierre Sachse." ],
      "venue" : "Advances in Cognitive Psychology, 5.",
      "citeRegEx" : "Furtner et al\\.,? 2009",
      "shortCiteRegEx" : "Furtner et al\\.",
      "year" : 2009
    }, {
      "title" : "Unsupervised domain adaptation by backpropagation",
      "author" : [ "Yaroslav Ganin", "Victor S. Lempitsky." ],
      "venue" : "Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, volume 37 of JMLR Workshop",
      "citeRegEx" : "Ganin and Lempitsky.,? 2015",
      "shortCiteRegEx" : "Ganin and Lempitsky.",
      "year" : 2015
    }, {
      "title" : "Domain-adversarial training of neural networks",
      "author" : [ "Yaroslav Ganin", "Evgeniya Ustinova", "Hana Ajakan", "Pascal Germain", "Hugo Larochelle", "François Laviolette", "Mario Marchand", "Victor Lempitsky." ],
      "venue" : "The Journal of Machine Learning Research,",
      "citeRegEx" : "Ganin et al\\.,? 2016",
      "shortCiteRegEx" : "Ganin et al\\.",
      "year" : 2016
    }, {
      "title" : "Generative adversarial nets",
      "author" : [ "Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio." ],
      "venue" : "Advances in neural information processing systems, 27:2672–2680.",
      "citeRegEx" : "Goodfellow et al\\.,? 2014",
      "shortCiteRegEx" : "Goodfellow et al\\.",
      "year" : 2014
    }, {
      "title" : "Eye movement control during reading: Fixation measures reflect foveal but not parafoveal processing difficulty",
      "author" : [ "John M Henderson", "Fernanda Ferreira." ],
      "venue" : "Canadian Journal of Experimental Psychology/Revue canadienne de psychologie",
      "citeRegEx" : "Henderson and Ferreira.,? 1993",
      "shortCiteRegEx" : "Henderson and Ferreira.",
      "year" : 1993
    }, {
      "title" : "Advancing NLP with cognitive language processing signals",
      "author" : [ "Nora Hollenstein", "Maria Barrett", "Marius Troendle", "Francesco Bigiolli", "Nicolas Langer", "Ce Zhang." ],
      "venue" : "arXiv preprint arXiv:1904.02682.",
      "citeRegEx" : "Hollenstein et al\\.,? 2019a",
      "shortCiteRegEx" : "Hollenstein et al\\.",
      "year" : 2019
    }, {
      "title" : "Zuco, a simultaneous EEG and eye-tracking resource for natural sentence reading",
      "author" : [ "Nora Hollenstein", "Jonathan Rotsztejn", "Marius Troendle", "Andreas Pedroni", "Ce Zhang", "Nicolas Langer." ],
      "venue" : "Scientific data, 5(1):1–13.",
      "citeRegEx" : "Hollenstein et al\\.,? 2018",
      "shortCiteRegEx" : "Hollenstein et al\\.",
      "year" : 2018
    }, {
      "title" : "Entity recognition at first sight: Improving NER with eye movement information",
      "author" : [ "Nora Hollenstein", "Ce Zhang." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Hollenstein and Zhang.,? 2019",
      "shortCiteRegEx" : "Hollenstein and Zhang.",
      "year" : 2019
    }, {
      "title" : "Cross-lingual transfer learning for pos tagging without cross-lingual resources",
      "author" : [ "Joo-Kyung Kim", "Young-Bum Kim", "Ruhi Sarikaya", "Eric Fosler-Lussier." ],
      "venue" : "Proceedings of the 2017 conference on empirical methods in natural language processing,",
      "citeRegEx" : "Kim et al\\.,? 2017",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2017
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira." ],
      "venue" : "Proceedings of the Eighteenth International Conference on Machine Learning (ICML",
      "citeRegEx" : "Lafferty et al\\.,? 2001",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "A multi-lingual multi-task architecture for low-resource sequence labeling",
      "author" : [ "Ying Lin", "Shengqi Yang", "Veselin Stoyanov", "Heng Ji." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Aus-",
      "citeRegEx" : "Lin et al\\.,? 2018",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2018
    }, {
      "title" : "Dependency parsing with your eyes: Dependency structure predicts eye regressions during reading",
      "author" : [ "Alessandro Lopopolo", "Stefan L. Frank", "Antal Van Den Bosch", "Roel Willems." ],
      "venue" : "Proceedings of the Workshop on Cognitive Modeling and Computa-",
      "citeRegEx" : "Lopopolo et al\\.,? 2019",
      "shortCiteRegEx" : "Lopopolo et al\\.",
      "year" : 2019
    }, {
      "title" : "An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition",
      "author" : [ "Ling Luo", "Zhihao Yang", "Pei Yang", "Yin Zhang", "Lei Wang", "Hongfei Lin", "Jian Wang." ],
      "venue" : "Bioinform., 34(8):1381–1388.",
      "citeRegEx" : "Luo et al\\.,? 2018",
      "shortCiteRegEx" : "Luo et al\\.",
      "year" : 2018
    }, {
      "title" : "Multitask sequence to sequence learning",
      "author" : [ "Minh-Thang Luong", "Quoc V. Le", "Ilya Sutskever", "Oriol Vinyals", "Lukasz Kaiser." ],
      "venue" : "4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016,",
      "citeRegEx" : "Luong et al\\.,? 2016",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2016
    }, {
      "title" : "End-to-end sequence labeling via bi-directional LSTM-CNNsCRF",
      "author" : [ "Xuezhe Ma", "Eduard H. Hovy." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume",
      "citeRegEx" : "Ma and Hovy.,? 2016",
      "shortCiteRegEx" : "Ma and Hovy.",
      "year" : 2016
    }, {
      "title" : "Visualizing data using t-SNE",
      "author" : [ "Laurens Van der Maaten", "Geoffrey Hinton." ],
      "venue" : "Journal of machine learning research, 9(11).",
      "citeRegEx" : "Maaten and Hinton.,? 2008",
      "shortCiteRegEx" : "Maaten and Hinton.",
      "year" : 2008
    }, {
      "title" : "A survey on using gaze behaviour for natural language processing",
      "author" : [ "Sandeep Mathias", "Diptesh Kanojia", "Abhijit Mishra", "Pushpak Bhattacharya." ],
      "venue" : "Twenty-Ninth International Joint Conference on Artificial Intelligence and Seventeenth Pacific Rim",
      "citeRegEx" : "Mathias et al\\.,? 2020",
      "shortCiteRegEx" : "Mathias et al\\.",
      "year" : 2020
    }, {
      "title" : "Leveraging cognitive features for sentiment analysis",
      "author" : [ "Abhijit Mishra", "Diptesh Kanojia", "Seema Nagar", "Kuntal Dey", "Pushpak Bhattacharyya." ],
      "venue" : "arXiv preprint arXiv:1701.05581.",
      "citeRegEx" : "Mishra et al\\.,? 2017",
      "shortCiteRegEx" : "Mishra et al\\.",
      "year" : 2017
    }, {
      "title" : "Human brain activity for machine attention",
      "author" : [ "Lukas Muttenthaler", "Nora Hollenstein", "Maria Barrett." ],
      "venue" : "CoRR, abs/2006.05113.",
      "citeRegEx" : "Muttenthaler et al\\.,? 2020",
      "shortCiteRegEx" : "Muttenthaler et al\\.",
      "year" : 2020
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014,",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Eye movements in reading and information processing: 20 years of research",
      "author" : [ "Keith Rayner." ],
      "venue" : "Psychological bulletin, 124(3):372.",
      "citeRegEx" : "Rayner.,? 1998",
      "shortCiteRegEx" : "Rayner.",
      "year" : 1998
    }, {
      "title" : "Using gaze data to predict multiword expressions",
      "author" : [ "Omid Rohanian", "Shiva Taslimipoor", "Victoria Yaneva", "Le An Ha." ],
      "venue" : "Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP 2017, Varna, Bulgaria,",
      "citeRegEx" : "Rohanian et al\\.,? 2017",
      "shortCiteRegEx" : "Rohanian et al\\.",
      "year" : 2017
    }, {
      "title" : "Attentive pooling networks",
      "author" : [ "Cicero dos Santos", "Ming Tan", "Bing Xiang", "Bowen Zhou." ],
      "venue" : "arXiv preprint arXiv:1602.03609.",
      "citeRegEx" : "Santos et al\\.,? 2016",
      "shortCiteRegEx" : "Santos et al\\.",
      "year" : 2016
    }, {
      "title" : "Recursive deep models for semantic compositionality over a sentiment treebank",
      "author" : [ "Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts." ],
      "venue" : "Proceedings of the 2013 conference on",
      "citeRegEx" : "Socher et al\\.,? 2013",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Interpreting attention models with human visual attention in machine reading comprehension",
      "author" : [ "Ekta Sood", "Simon Tannert", "Diego Frassinelli", "Andreas Bulling", "Ngoc Thang Vu." ],
      "venue" : "arXiv preprint arXiv:2010.06396.",
      "citeRegEx" : "Sood et al\\.,? 2020a",
      "shortCiteRegEx" : "Sood et al\\.",
      "year" : 2020
    }, {
      "title" : "Improving natural language processing tasks with human gaze-guided neural attention",
      "author" : [ "Ekta Sood", "Simon Tannert", "Philipp Müller", "Andreas Bulling." ],
      "venue" : "arXiv preprint arXiv:2010.07891.",
      "citeRegEx" : "Sood et al\\.,? 2020b",
      "shortCiteRegEx" : "Sood et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards making a dependency parser see",
      "author" : [ "Michalina Strzyz", "David Vilares", "Carlos GómezRodrı́guez" ],
      "venue" : "arXiv preprint arXiv:1909.01053",
      "citeRegEx" : "Strzyz et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Strzyz et al\\.",
      "year" : 2019
    }, {
      "title" : "Generating image descriptions via sequential cross-modal alignment guided by human gaze",
      "author" : [ "Ece Takmaz", "Sandro Pezzelle", "Lisa Beinborn", "Raquel Fernández." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Takmaz et al\\.,? 2020",
      "shortCiteRegEx" : "Takmaz et al\\.",
      "year" : 2020
    }, {
      "title" : "Thinking theta and alpha: Mechanisms of intuitive and analytical reasoning",
      "author" : [ "Chad C. Williams", "Mitchel Kappen", "Cameron D. Hassall", "Bruce Wright", "Olave E. Krigolson." ],
      "venue" : "NeuroImage, 189:574– 580.",
      "citeRegEx" : "Williams et al\\.,? 2019",
      "shortCiteRegEx" : "Williams et al\\.",
      "year" : 2019
    }, {
      "title" : "Adversarial learning for chinese NER from crowd annotations",
      "author" : [ "YaoSheng Yang", "Meishan Zhang", "Wenliang Chen", "Wei Zhang", "Haofen Wang", "Min Zhang." ],
      "venue" : "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-",
      "citeRegEx" : "Yang et al\\.,? 2018",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 30,
      "context" : "while natural language processing (NLP) teaches machines to read, analyze, translate and generate human language sequences (Muttenthaler et al., 2020).",
      "startOffset" : 123,
      "endOffset" : 150
    }, {
      "referenceID" : 29,
      "context" : "∗Corresponding author cognitively-inspired NLP, which uses cognitive language processing signals generated by human brains to enhance or probe neural models in solving a variety of NLP tasks, such as sentiment analysis (Mishra et al., 2017; Barrett et al., 2018), named",
      "startOffset" : 219,
      "endOffset" : 262
    }, {
      "referenceID" : 2,
      "context" : "∗Corresponding author cognitively-inspired NLP, which uses cognitive language processing signals generated by human brains to enhance or probe neural models in solving a variety of NLP tasks, such as sentiment analysis (Mishra et al., 2017; Barrett et al., 2018), named",
      "startOffset" : 219,
      "endOffset" : 262
    }, {
      "referenceID" : 19,
      "context" : "entity recognition (NER) (Hollenstein and Zhang, 2019), dependency parsing (Strzyz et al.",
      "startOffset" : 25,
      "endOffset" : 54
    }, {
      "referenceID" : 38,
      "context" : "entity recognition (NER) (Hollenstein and Zhang, 2019), dependency parsing (Strzyz et al., 2019), relation extraction (Hollenstein et al.",
      "startOffset" : 75,
      "endOffset" : 96
    }, {
      "referenceID" : 17,
      "context" : ", 2019), relation extraction (Hollenstein et al., 2019a), etc.",
      "startOffset" : 29,
      "endOffset" : 56
    }, {
      "referenceID" : 28,
      "context" : "These cognitive processing signals are usually assumed to represent psycholinguistic information (Mathias et al., 2020) or cognitive load (Antonenko et al.",
      "startOffset" : 97,
      "endOffset" : 119
    }, {
      "referenceID" : 40,
      "context" : "The recorded signals contain information covering a wide variety of cognitive processes, particularly for EEG (Williams et al., 2019; Eugster et al., 2014).",
      "startOffset" : 110,
      "endOffset" : 155
    }, {
      "referenceID" : 11,
      "context" : "The recorded signals contain information covering a wide variety of cognitive processes, particularly for EEG (Williams et al., 2019; Eugster et al., 2014).",
      "startOffset" : 110,
      "endOffset" : 155
    }, {
      "referenceID" : 34,
      "context" : "Partially inspired by the attentive pooling network (Santos et al., 2016), we propose a text-aware attention mechanism to further align textual inputs and cognitive processing signals at the word level.",
      "startOffset" : 52,
      "endOffset" : 73
    }, {
      "referenceID" : 32,
      "context" : "Eye-tracking data have proved to be associated with language comprehension activity in human brains by numerous research in neuroscience (Rayner, 1998; Henderson and Ferreira, 1993).",
      "startOffset" : 137,
      "endOffset" : 181
    }, {
      "referenceID" : 16,
      "context" : "Eye-tracking data have proved to be associated with language comprehension activity in human brains by numerous research in neuroscience (Rayner, 1998; Henderson and Ferreira, 1993).",
      "startOffset" : 137,
      "endOffset" : 181
    }, {
      "referenceID" : 3,
      "context" : "In early works, these signals have been used in machine learning approaches to NLP tasks, such as part-of-speech tagging (Barrett et al., 2016), multiword expression extraction (Rohanian et al.",
      "startOffset" : 121,
      "endOffset" : 143
    }, {
      "referenceID" : 33,
      "context" : ", 2016), multiword expression extraction (Rohanian et al., 2017), syntactic category prediction (Barrett and Søgaard, 2015).",
      "startOffset" : 41,
      "endOffset" : 64
    }, {
      "referenceID" : 4,
      "context" : ", 2017), syntactic category prediction (Barrett and Søgaard, 2015).",
      "startOffset" : 39,
      "endOffset" : 66
    }, {
      "referenceID" : 29,
      "context" : "In neural models, eyetracking data are combined with word embeddings to improve various NLP tasks, such as sentiment analysis (Mishra et al., 2017) and NER (Hollenstein and Zhang, 2019).",
      "startOffset" : 126,
      "endOffset" : 147
    }, {
      "referenceID" : 15,
      "context" : "The concept of adversarial training originates from the Generative Adversarial Nets (GAN) (Goodfellow et al., 2014) in computer vision.",
      "startOffset" : 90,
      "endOffset" : 115
    }, {
      "referenceID" : 10,
      "context" : "Since then, it has been also applied in NLP (Denton et al., 2015; Ganin et al., 2016).",
      "startOffset" : 44,
      "endOffset" : 85
    }, {
      "referenceID" : 14,
      "context" : "Since then, it has been also applied in NLP (Denton et al., 2015; Ganin et al., 2016).",
      "startOffset" : 44,
      "endOffset" : 85
    }, {
      "referenceID" : 41,
      "context" : "2018), crowdsourcing learning (Yang et al., 2018), cross-lingual transfer learning (Chen et al.",
      "startOffset" : 30,
      "endOffset" : 49
    }, {
      "referenceID" : 6,
      "context" : ", 2018), cross-lingual transfer learning (Chen et al., 2018; Kim et al., 2017), just name a few.",
      "startOffset" : 41,
      "endOffset" : 78
    }, {
      "referenceID" : 20,
      "context" : ", 2018), cross-lingual transfer learning (Chen et al., 2018; Kim et al., 2017), just name a few.",
      "startOffset" : 41,
      "endOffset" : 78
    }, {
      "referenceID" : 22,
      "context" : "previous studies have shown that character-level features can improve the performance of sequence labeling (Lin et al., 2018).",
      "startOffset" : 107,
      "endOffset" : 125
    }, {
      "referenceID" : 8,
      "context" : "We therefore apply a character-level CNN framework (Chiu and Nichols, 2016; Ma and Hovy, 2016) to capture the character-",
      "startOffset" : 51,
      "endOffset" : 94
    }, {
      "referenceID" : 26,
      "context" : "We therefore apply a character-level CNN framework (Chiu and Nichols, 2016; Ma and Hovy, 2016) to capture the character-",
      "startOffset" : 51,
      "endOffset" : 94
    }, {
      "referenceID" : 21,
      "context" : "For sequence labeling tasks like NER, we employ the conditional random field (CRF) (Lafferty et al., 2001) as the predictor as Bi-LSTM-CRF is widely used in many sequence labeling tasks (Ma and Hovy, 2016; Luo et al.",
      "startOffset" : 83,
      "endOffset" : 106
    }, {
      "referenceID" : 26,
      "context" : ", 2001) as the predictor as Bi-LSTM-CRF is widely used in many sequence labeling tasks (Ma and Hovy, 2016; Luo et al., 2018) due to the excel-",
      "startOffset" : 87,
      "endOffset" : 124
    }, {
      "referenceID" : 24,
      "context" : ", 2001) as the predictor as Bi-LSTM-CRF is widely used in many sequence labeling tasks (Ma and Hovy, 2016; Luo et al., 2018) due to the excel-",
      "startOffset" : 87,
      "endOffset" : 124
    }, {
      "referenceID" : 19,
      "context" : "lent performance and also in cognitively inspired NLP (Hollenstein and Zhang, 2019; Hollenstein et al., 2019a).",
      "startOffset" : 54,
      "endOffset" : 110
    }, {
      "referenceID" : 17,
      "context" : "lent performance and also in cognitively inspired NLP (Hollenstein and Zhang, 2019; Hollenstein et al., 2019a).",
      "startOffset" : 54,
      "endOffset" : 110
    }, {
      "referenceID" : 13,
      "context" : "Additionally, to further increase the difficulty for the discriminator to distinguish modalities, we add a gradient reversal layer (GRL) (Ganin and Lempitsky, 2015) in between the encoder layer and predictor layer.",
      "startOffset" : 137,
      "endOffset" : 164
    }, {
      "referenceID" : 18,
      "context" : "We chose a dataset2 with multiple cognitive processing signals: Zurich Cognitive Language Processing Corpus (ZuCo) (Hollenstein et al., 2018).",
      "startOffset" : 115,
      "endOffset" : 141
    }, {
      "referenceID" : 35,
      "context" : "consist of two datasets: 400 movie reviews from Stanford Sentiment Treebank (Socher et al., 2013)",
      "startOffset" : 76,
      "endOffset" : 97
    }, {
      "referenceID" : 9,
      "context" : "with manually annotated sentiment labels, including 123 neutral, 137 negative and 140 positive sentences; 300 paragraphs about famous people from Wikipedia relation extraction corpus (Culotta et al., 2006) labeled with 11 relationship types, such as",
      "startOffset" : 183,
      "endOffset" : 205
    }, {
      "referenceID" : 17,
      "context" : "task in this work are the same as (Hollenstein et al., 2019a).",
      "startOffset" : 34,
      "endOffset" : 61
    }, {
      "referenceID" : 18,
      "context" : "moved during preprocessing since they are not related to the cognitive processing (Hollenstein et al., 2018).",
      "startOffset" : 82,
      "endOffset" : 108
    }, {
      "referenceID" : 23,
      "context" : ", 2009) (related to the eye-tracking signal NFIX, the number of fixations) and there is a dependency relationship between regression features and sentence syntactic structures (Lopopolo et al., 2019).",
      "startOffset" : 176,
      "endOffset" : 199
    }, {
      "referenceID" : 33,
      "context" : "features, the late gaze features have also proved to be more important than early gaze features, such as multiword expression extraction (Rohanian et al., 2017).",
      "startOffset" : 137,
      "endOffset" : 160
    }, {
      "referenceID" : 25,
      "context" : "to the alternating training approach (Luong et al., 2016) that optimizes each task for a fixed number of mini-batches before shifting to the next task.",
      "startOffset" : 37,
      "endOffset" : 57
    }, {
      "referenceID" : 1,
      "context" : "(Balasuriya et al., 2009) and Stanford Sentiment Treebank (Socher et al.",
      "startOffset" : 0,
      "endOffset" : 25
    }, {
      "referenceID" : 35,
      "context" : ", 2009) and Stanford Sentiment Treebank (Socher et al., 2013).",
      "startOffset" : 40,
      "endOffset" : 61
    } ],
    "year" : 2021,
    "abstractText" : "Most previous studies integrate cognitive language processing signals (e.g., eye-tracking or EEG data) into neural models of natural language processing (NLP) just by directly concatenating word embeddings with cognitive features, ignoring the gap between the two modalities (i.e., textual vs. cognitive) and noise in cognitive features. In this paper, we propose a CogAlign approach to these issues, which learns to align textual neural representations to cognitive features. In CogAlign, we use a shared encoder equipped with a modality discriminator to alternatively encode textual and cognitive inputs to capture their differences and commonalities. Additionally, a text-aware attention mechanism is proposed to detect task-related information and to avoid using noise in cognitive features. Experimental results on three NLP tasks, namely named entity recognition, sentiment analysis and relation extraction, show that CogAlign achieves significant improvements with multiple cognitive features over state-of-the-art models on public datasets. Moreover, our model is able to transfer cognitive information to other datasets that do not have any cognitive processing signals. The source code for CogAlign is available at https://github. com/tjunlp-lab/CogAlign.git.",
    "creator" : "LaTeX with hyperref"
  }
}