{
  "name" : "2021.acl-long.471.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "RepSum: Unsupervised Dialogue Summarization based on Replacement Strategy",
    "authors" : [ "Xiyan Fu", "Yating Zhang", "Tianyi Wang", "Xiaozhong Liu", "Changlong Sun", "Zhenglu Yang" ],
    "emails" : [ "fuxiyan@mail.nankai.edu.cn,", "ranran.zyt@alibaba-inc.com", "will.wty@alibaba-inc.com", "liu237@indiana.edu,", "changlong.scl@taobao.com,", "yangzl@nankai.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6042–6051\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n6042"
    }, {
      "heading" : "1 Introduction",
      "text" : "Dialogue summarization distills key information from a dialogue context and synopsizes it into a concise summary. As a novel topic of critical importance, it offers powerful potentials for a number of scenarios, e.g, the court debate in civil trial, the customer service calls arisen from agent(s) and customer, the business meeting engaged with multimembers. It also assists users in quick access and consumes the essential content in the dialogue.\nMajor attempts on dialogue summarization are template-based (Wang and Cardie, 2013; Oya et al., 2014) in the primitive stage by extracting key information and filling it into the learned templates. However, these template-based techniques limit the\nscope of their applications and cannot be adapted to a wider range of conversational data since their input structure is predefined and the learned templates are domain-specific. Later, various works explore the assistance from labeled auxiliary information for summary generation, by leveraging either dialogue act (Goo and Chen, 2018), or key point sequence (Liu et al., 2019). The former predicts the dialogue act label of each utterance as explicit interactive signals, while the latter attempts to learn the logic of the summary via key point sequence. Recently, Ganesh and Dingliwal (2019) converts the dialogue into a document by aptly capturing discourse relations which proves to be effective under the scenario of document summarization.\nWhile prior deep content generation methods rely on large amounts of annotated data, they are rarely available for dialogue summarization due to the prohibitive costs of labeled data. A straightforward way to alleviate the dependency of the annotated data is to apply the existing unsupervised methods designed for document summarization (Rossiello et al., 2017; Zheng and Lapata, 2019; Baziotis et al., 2019; Chu and Liu, 2019) to the dialogue scene. However, we argue that these methods accompany weakness either in extractive or in abstractive dialogue summarization. In terms of extractive methods, they mainly rely on semantic information without any supervision signals. As a result, they are ragged in effects due to the limited words in dialogue utterances. As for abstractive approaches, they are commonly designed with an auto-encoder (AE) where the latent variable decodes to a summary which attempts to reconstruct the original input representation. Hence, they are constrained to the small gap between the input text and the target summary (e.g., sentence compression) while failing to reconstruct long input text (e.g., dialogue).\nIn this paper, we propose an innovative unsupervised strategy, dubbed RepSum, which can be applied to both extractive and abstractive summarization. The key intuition is derived from the evaluation methods of extrinsic summarization (Mani, 2001), which testifies the impact of summarization based on how it affects the completion of some other tasks, such as information retrieval, relevance assessment, reading comprehension, etc. We claim that a superior summary can offer a semantic replacement of the original dialogue, which provides equivalent information for completing auxiliary tasks, e.g., dialogue generation, as shown in figure 1. Specifically, we propose two auxiliary tasks which are nth utterance generation and nth utterance selection from K candidates based on the previous contents. Both the dialogue and the summary aim to achieve decent performances on the specific task respectively. Besides, we introduce KL divergence to curtail the difference between results based on the dialogue and the summary. This strategy provides the summarization with essential self-supervised signals via auxiliary tasks. Furthermore, it decouples the training from the reconstruction of AE, which enables to support longer text or dialogue to be effectively summarized.\nOur main contributions are as follows:\n• We propose RepSum, an unsupervised (or self-supervised) strategy for dialogue summarization, which roots from the hypothesis that a superior summary approximates a replacement of the original dialogue for completing other tasks. It leverages several intrinsic selfsupervised signals.\n• Based on the RepSum strategy, we propose the corresponding model and employ it to both extractive and abstractive summarization.\n• The extensive experiments with multiple dialogue datasets demonstrate the superiority of the proposed model over several unsupervised approaches."
    }, {
      "heading" : "2 Related Work",
      "text" : "Dialogue Summarization extracts significant information from dialogues. Most of the initial works adopted extractive-based methods. For instance, Bui et al. (2009) produced multiple short fragments from utterances and then selected the parse of the summary by SVM combined with semanticsimilarity features. Later, (Oya et al., 2014; Wang and Cardie, 2013) induced abstractive generation templates for constructing candidate summary sentences. Moreover, to benefit from the existing technologies for document summarization, Ganesh and Dingliwal (2019) converted the conversation into a text document through discourse relations and lexical information and then created summaries via pointer-generator (See et al., 2017). However, given that dialogues are different from documents in terms of interactive patterns, most researchers explored to summarize the dialogue by leveraging auxiliary information hidden in the utterances. For example, Goo and Chen (2018) proposed to utilize dialogue act as an auxiliary supervised signal and design a sentence-gated mechanism for modeling the relationships between dialogue acts and the summary. In addition, Liu et al. (2019) predicted the keypoint sequence first and then use it to guide the summary prediction.\nIn contrast to the supervision works, we focus on the unsupervised dialogue summarization considering the high cost and limitation of the labeled data in the dialogue scene. Additionally, our proposed strategy is applicable to both extractive and abstractive models without using any outer infor-\nmation (e.g., template, dialogue acts, and keypoint) but leveraging its intrinsic self-supervised nature.\nUnsupervised Summarization Historically, unsupervised summarization focused on extracting utterances directly. For example, LEAD chooses the first several utterances and TextRank (Mihalcea and Tarau, 2004) ranks utterances by running a graph-based algorithm, where each node represents an utterance and the weight between any two nodes is calculated by the semantic similarity. Later, Rossiello et al. (2017) proposed a centroidbased method for text summarization that exploits the compositional capabilities of word embeddings. Zheng and Lapata (2019) improved it by building graphs with directed edges considering the relative positions of any two sentences which contributes to their respective centrality. In recent works, the task of unsupervised summarization is framed as a self-supervised auto-encoder problem, namely sentence compression. Miao and Blunsom (2016); Baziotis et al. (2019); Chu and Liu (2019) applied the auto-encoder framework, where the expected abstract is set to the latent variables from which the input sentence is reconstructed. Févry and Phang (2018) added noise to extend sentences and trained a denoising auto-encoder to recover the input text. Bražinskas et al. (2020) introduced a hierarchical variational auto-encoder to associate the individual reviews with stochastic latent codes for opinion summarization. Recently, another line of works focused on edit-distance-based approaches. West et al. (2019) summarized by applying the Information Bottleneck principle to the objective of conditional language modeling. In addition, Zhou and Rush (2019); Schumann et al. (2020) summarized by hill climbing with word-level extraction, which searches the text for a high-scoring summary by discrete optimization.\nCompared to these works, to the best of our knowledge, our model is one of the pioneers attempting unsupervised dialogue summarization. To improve the effectiveness, we devise a generalized strategy RepSum that incentivizes the summary to complete the auxiliary tasks as the original dialogue does, thus providing self-training signals and in turn enabling long texts to be summarized."
    }, {
      "heading" : "3 RepSum Model",
      "text" : ""
    }, {
      "heading" : "3.1 Mechanism",
      "text" : "RepSum roots from the hypothetical foundation that a superior summary approximates a replace-\nment of the original dialogue, and they are roughly equivalent for completing auxiliary (selfsupervised) tasks. Figure 2 shows the flow chart of the introduced replacement strategy. Specifically, the summary generation module aims at generating a summary from the original dialogue. During this generation process, two auxiliary tasks, nth utterance generation and nth utterance classification, are constructed to transform unsupervised dialogue summarization task into self-supervised mode by learning through auxiliary tasks. Furthermore, we apply RepSum to extractive and abstractive summarization, experiments verify its effectiveness in an empirical point of view."
    }, {
      "heading" : "3.2 Auxiliary Tasks",
      "text" : "As introduced above, we leverage two auxiliary tasks to act as self-supervised signals to assist the generation process of a superior summary. Given that the summary is the replacement of the original dialogue, the input dialogue and the generated summary are expected to achieve similar results on these tasks respectively. Hence, we add the Kullback–Leibler (KL) divergence to curtail the differences between the results of each auxiliary task based on the input dialogue and the generated summary. The details are denoted as follows:\nTask1: Generation (TG) aims at generating the nth utterance. We employ the commonly used encoder-decoder structure. The whole dialogue is\nconcatenated and encoded (as a document) by the bi-directional LSTM(Hochreiter and Schmidhuber, 1997) for the sake of fair comparison with other baselines. The representation of each word is the concatenation of the forward and backward LSTM states, i.e., hi = [h fwd i , h bwd i ]. As for the decoder, we employ a uni-directional LSTM with attention mechanism (Luong et al., 2015). Concretely, the attention distribution at and the following context vector ct are formulated as:\nati = σ(hiWast), ct = n∑\ni=1\naihi (1)\nwhere Wa is the learnable parameter and σ is the softmax function. The context vector and the current decoder state st are employed for predicting the probability distribution of the output word over all the vocabulary words:\np(yt) = σ(Wp(φ(Wk[yt−1; st; ct] + bk)) + bp) (2) where Wp, Wk, bp and bk are learnable parameters. σ is the softmax function and φ is the tanh function. We choose the negative logliklihood as the loss function, and the loss of the utterance generation based on the dialogue via the path of encdia → decdia (see Figure 2) is denoted as:\nLTGdia = − q∑\nt=1\nlog p(lt|l<t; encdia) (3)\nwhere l = {l1, l2, ..., lq} is the generated utterance. Similarly, the utterance generation based on the generated summary LTGsum is calculated via the process of encsum→ decsum in Figure 2. To guarantee the similar performance of the results based on the original dialogue and the generated summary, we also add KL divergence to curtail the difference between the probability distribution of prediction at each timestep: LTGkl = q∑\nt=1\nKL(p(lt|l<t; encdia)||p(lt|l<t; encsum))\n(4) Hence, the loss for the nth utterance generation\ntask is denoted as:\nLTG = α0LTGdia + α1LTGsum + α2LTGkl (5)\nwhere α0, α1, and α2 are the weight for each loss.\nTask2: Classification (TC) is designed to select the correct nth utterance from the K candidate\nutterances. Similar to the dialogue encoding in the task TG, we choose the Bi-LSTM as the encoder. The dialogue representation hd is the average of the hidden state of each word. Besides, each candidate is also encoded by the Bi-LSTM and projected to a dense vector by logit layer f , and then concatenated to hd, formulated as [f(uci);hd]. The probability of each utterance belonging to the correct answer is calculated by a logistic layer. Furthermore, we use cross-entropy for training via the process of encdia → classifierdia (see Figure 2). The loss based on the dialogue is formulated as:\nLTCdia = − K∑\nn=1\nznlogẑn (6)\nSimilarily, LTCsum based on the generated summary through encsum → classifiersum is calculated. We also use the KL divergence to measure the difference between the results from the dialogue and generated summary:\nLTCkl = KL(p(uc dia)||p(ucsum)) (7)\nwhere p(ucdia) and p(ucsum) is the probability distribution on K candidates. All in all, the loss of the nth utterance selection task is formulated as:\nLTC = α3LTCdia + α4LTCsum + α5LTCkl (8)\nwhere α3, α4, and α5 are the weight for each loss. Parameters α0 to α5 are used for normalization."
    }, {
      "heading" : "3.3 Unsupervised Summarization",
      "text" : "The RepSum is employed to both the extractive and abstractive summarization: Extractive Summarization We consider the extractive summarization as a sentence binary classification task as (Nallapati et al., 2017) does, which means R utterances in a dialogue with label one are extracted to be an extractive summary. Specifically, we use encext (encdia in the Figure 2) applied by the Bi-LSTM to encode utterances in dialogue, and they are represented as hidden states h1, h2, ..., hn−1. Then, the representation of the dialogue is the average pooling of the concatenated hidden states of the entire utterances, denoted as:\nd = φ(Wd 1\nn− 1 n−1∑ i=1 [hfwdi ;h bwd i ] + bd) (9)\nwhere Wd and bd are learnable parameters, and φ is the tanh function. For utterances classification,\neach utterance is concatenated with the dialogue representation d. And a logistic layer predicts the probability belonging to the generated summary, as shown below:\np(ui = 1) = ψ(Whhi + hiWhdd+ bh) (10)\nwhere Wh, Whd and bh are learnable parameters,\nand ψ is the sigmoid function. Later, we choose the top probability R utterances as the extractive summary. After obtaining the initial generated summary, the unsupervised extractive summarization can be guided under the RepSum strategy. Specifically, the extractive-based summary is optimized by the auxiliary tasks for the sake of effective results and similar performance of the dialogue. Hence, the training loss for extractive summarization including nth utterance generation and classification is denoted as:\nLext = LextTG + LextTC (11)\nAbstractive Summarization The abstractive summarization process follows the conventional encoder-decoder structure. For each time step, the word prediction probability is calculated via Eq. 2. To generate the abstractive summary used for the auxiliary tasks, we sample each word from the probability ỹt ∼ softmax(p(yt)) and encode them as enca sum (encsum in the Figure 2). However, it is a non-differentiable process, which can not be trained directly.\nHence, we use the Straight-Through (ST) Gumble Estimator introduced in (Bengio et al., 2013) to solve this problem. During the forward training pass and test process, we use the reparametrization trick as a variance approximation of sampling from the original probability (Maddison et al., 2014). Specifically, sampling word is transformed to take the argmax from a new probability, ỹ is discretized using argmax and sampling as:\nỹt = argmax(log(p(yt)) + g),\ng = −log(−log(ξ)), ξ ∼ U(0, 1) (12)\nwhere g is the Gumble distribution and U is the uniform distribution. As for computing the gradient in the backward pass, we use a continuous and differentiable approximation to argmax:\np(yit) = exp((log(p(yit)) + gi)/τ)∑|V | j=1 exp((log(p(y j t )) + gj)/τ) (13)\nwhere |V | is the vocabulary size and the τ ∈ (0,∞) is the temperature parameter. Samples from Gumble Softmax distributions are identical to samples from a categorical distribution as τ → 0. The input for the encoder enca sum is denoted as:\neabsyt = |V |∑ i=1 e(wi)p(y i t) (14)\nwhere e(wi) is the word embedding of the words. After the acquisition of the abstractive summary, we also employ the RepSum strategy for training. Due to the difficulty of the generation, we supply two more other auxiliary losses. Firstly, the experiments indicate that the model is difficult to converge due to the lack of any guidance for the decoder (see w/o fake-sum in Table 5), we employ the extractive summary as a fake summary for teacher forcing training. Hence, the fake summary generation loss Lfs is calculated following the Eq. 1, Eq. 2 and Eq. 3. Moreover, given that abstractive summary is limited to readability and fluency, we pre-train a language model with dialogue utterances to solve this problem. We aim to generate fluent summaries by adding language modeling loss, which approaches the output prediction to language output:\nLlm = KL(p(yt)||plm(yt)) (15)\nHence, the training loss for the unsupervised abstractive dialogue summarization is denoted as:\nLabs = LabsTG + LabsTC + α6Lfs + α7Llm (16)\nParameters α6 and α7 are normalization weight."
    }, {
      "heading" : "4 Experimental Setup",
      "text" : ""
    }, {
      "heading" : "4.1 Dataset",
      "text" : "We evaluate RepSum on a meeting dataset in English AMI and a multi-party court debate dataset in Chinese Justice. The statistics are presented in details (see Tabel 1). AMI. The AMI1 meeting corpus (Carletta et al., 2005) consists of 100 hours of meeting recordings\n1http://groups.inf.ed.ac.uk/ami/corpus/overview.shtml\nin English. It includes high-quality and manually produced transcription, dialogue acts, topic segmentation, extractive and abstractive summaries, etc. In this work, we use the recording transcripts as the original input and the provided abstractive summary as the expected summary to be generated. Justice. The court debate records consist of 30,000 dispute cases. In the court trial scenario, there are multiple roles (i.e., judge, plaintiff, defendant). In the whole debate dialogue, the plaintiff and the defendant debate on controversy focus leading by the judge. After the trial, the judge summarizes the facts recognized through the trial. Thus we use the court debate transcript as the original input and the fact description as the expected summary."
    }, {
      "heading" : "4.2 Parameter Settings",
      "text" : "In our experiments2, we optimize the proposed model using Adam Optimizer (Kingma and Ba, 2014) with the learning rate of 3e-4. We train on a single TeslaP100 GPU with a batch size of 16. The vocabulary size is 30,000 and embedding dimension for each word is 200. The hidden size is 200 for both encoder and decoder. For gumble softmax, we set the temperature τ to 0.5. In the auxiliary task C2, we denote k as 4, which means we select the other 3 similar utterances. They are chosen from all the utterances in the dataset randomly. For extractive summarization, we pick out the top 3 utterances by their probability. We set the α0 to α7 equals 0.5, 0.5, 5, 1, 1, 2, 1, 0.006 respectively to balance the scale of each module."
    }, {
      "heading" : "4.3 Baselines",
      "text" : "We firstly report the performance of the ORACLE as an upper bound, which uses a greedy algo-\n2The code can be found in https://github.com/xiyan524/ RepSum\nrithm to extract several utterances to maximize the ROUGE compared with the ground truth. LEAD3 extracts the first three utterances as the summary.\nAs for the extractive-based methods, we compare with classical TextRank (Mihalcea and Tarau, 2004) which converts the dialogue to a weightedgraph where each node represents an utterance and the edge weight expresses the semantic similarity between any two utterances. Centroid (Rossiello et al., 2017) proposes a centroid-based method for text summarization that exploits the compositional capabilities of word embeddings. PacSum (Zheng and Lapata, 2019) improves the TextRank by building graphs with directed edges considering the relative positions of any two sentences contributing to their respective centrality.\nWith regard to the abstractive-based methods, we compare with several auto-encoder based approaches. 2g shuf (Févry and Phang, 2018) adds noise to extend sentences and trains a denoising auto-encoder to recover the original input text. SEQ3 (Baziotis et al., 2019) constructs a compressor to generate summary and a reconstructor to regenerate input sentence via two chained encoderdecoder pairs. MeanSum (Chu and Liu, 2019) employs the mean of the representations of the input to decode a reasonable summary."
    }, {
      "heading" : "5 Experimental Results",
      "text" : ""
    }, {
      "heading" : "5.1 Quantitative Analysis",
      "text" : "Table 2 shows the experimental results based on the AMI and the Justice datasets. ROUGE 3 score (Lin, 2004) is used for evaluation.\nFor extractive summarization, we found the upper bound ORACLE is quite low in dialogue summarization (see the first row in Table 2) compared\n3https://github.com/pltrdy/files2rouge\nwith the document summarization where R-1 score usually approaches to 50 as reported in (Liu and Lapata, 2019). It indicates that the dialogue summarization is much more challenging. Additionally AMI dataset is more appropriate for abstractive summarization since its ORACLE scores are much lower than those for Justice dataset. The score of LEAD3 estimates the information distribution over dialogues. Furthermore, our proposed RepSum-Ext is compared with other four state-of-the-art models with significant improvement in Rouge score. Table 2 demonstrates that the RepSum strategy is effective for extractive summarization.\nFor abstractive summarization, we mainly compare RepSum-Abs with AE-based methods. We employ the same encoder and decoder settings for baselines for a fair comparison. In terms of ROUGE value, our model outperforms all the baselines, especially in R-L score. We consider that the auxiliary tasks training mechanism helps to prevent the focus on single-word reconstruction, but aims to remain significant continuous information."
    }, {
      "heading" : "5.2 Human Evaluation",
      "text" : "In order to ensure the rationality/correctness of the generated summary, we also conducted a human evaluation. The annotators are required to estimate the quality of the generated summaries with respect to the relevance indicating the connection between the dialogue and the summary and fluency representing the readability. The scores are divided into three levels: +2, +1, 0, in which a higher score stands for excellent. We report the average score and coefficient κ which indicates the consistency of evaluation by different annotators. Specifically, we choose 100 examples for each dataset and six annotators are required to evaluate all the tested methods. The annotators are experienced graduate students who have taken the annotation training before the experiment. Results shown in Table 3 indicate that our proposed strategy is superior to\nall the baselines. Furthermore, compared to the abstractive-based methods, extractive-based methods perform better on fluency. We consider that the difference is due to sentence integrity."
    }, {
      "heading" : "5.3 Ablation Study",
      "text" : "To evaluate the effectiveness of the proposed RepSum strategy, we conduct two ablation studies. We first measure the influence of each auxiliary task (see Table 4). Further, we verify the contribution of each module, shown in Table 5.\nTable 4 indicates that combining the two auxiliary tasks achieves the best performance on both extractive and abstractive methods. The decline of performance is observed once we remove either task, especially the generation task. We assume that the classification task is considerably straightforward, which may not require affluent semantic information. However, it serves as an auxiliary section with complicated generation tasks.\nFurthermore, we remove each component to investigate the module effectiveness in RepSum-Abs. The result is shown in Table 5. It indicates that all the components make a positive contribution. To be specific, fake summary (-w/o fake-sum) is the critical point, which contributes to the model convergence. Besides, if we remove tasks based on the generated summary (-w/o sum-task), the performance declines significantly. It proves the assumption that a superior summary is supposed to conduct the auxiliary tasks as original dialogue does. Either removing tasks based on the dialogue (-w/o dia-\ntask) or adding KL divergence (-w/o kl) to control similar effectiveness between dialogue and generated summary, tends to harm the performance. Moreover, we notice that the pre-trained language model (-w/o lm) benefits the bi-gram by noticing the significant decrease in R-2. The extractivebased method is ignored since its components are the same as the abstractive-based approach."
    }, {
      "heading" : "5.4 Discussion",
      "text" : "Fake Summary Extensive experiments show that abstractive summarization is difficult to converge without word-level guidance. Hence, we propose to construct a fake summary to solve this problem. In this section, we conduct two experiments for different fake summary construction. We first attempt to select T utterances randomly. Further, we choose an extractive summary. Table 6 shows that the random selection result is inferior to extractive summary guidance. Given the consideration of high accuracy, we choose the extractive summary as guidance in this work. However, we assume that random selection can be also employed for efficiency consideration if necessary. Candidates number in TC To further explore the effectiveness of the auxiliary task classification (TC) for unsupervised dialogue summarization, we conduct experiments by varying the candidate’s number K. Such number influences the performance of the extractive summarization on both AMI and Justice datasets. We set the number varying from 3 to 7. The performance of our model with the variation of the number K is shown in Table 7. It indicates that the R-1 approaches a stable value with slight fluctuation when we increase theK continuously. Besides, there exists a drastic increase\nin R-1 when K is augmented from 2 to 3. Hence, given the trade-off between the efficiency and the generation quality, we choose 4 as the number of candidates for all the experiments. Utterance choice in TG The selection of nth utterance for generation in the dialogue is crucial for the model effectiveness. Meaningless utterances such as ”hmmm”, ”the meeting is over” in meeting, and ”please sign the transcript after checking” in court debates may be useless. At the same time, none of the contextual information is integrant. Hence, we conduct experiments to testify the effectiveness of three different utterance selection strategies: Random selects the nth utterance randomly. The utterances before nth are regarded as the input. If the remained dialogue utterances are less than 5, the example is discarded. Last chooses the last utterance of each dialogue for prediction. Moreover, Sec splits the dialogue into several sections and then picks the last utterance of each section. “Sec” is segmented based on the rule which requires each section to contain at least 8 utterances with at least 5 words and 3 significant utterances whose tf-idf value is superior to the threshold.\nFigure 3 shows the result conducted on justice dataset4. It proves that meaningful utterance benefits the performance. Specifically, Last leads to the worst result on both R-1 and R-L due to the universal utterance at the end of a dialogue. We consider that Random prevents semantic information deficiency through selecting crucial utterances occasionally compared with Sec which achieves the best performance.\n4The performance on AMI dataset shows a similar pattern. We only show the visualized result on the justice dataset due to the paper length limitation."
    }, {
      "heading" : "6 Conclusion",
      "text" : "This work investigates the problem of unsupervised dialogue summarization. we propose a novel unsupervised strategy RepSum, which roots from the hypothetical foundation that a superior summary approximates a replacement of the original dialogue, and they are roughly equivalent for completing auxiliary tasks. RepSum is employed on both extractive and abstractive-based models via a self-supervision from two auxiliary tasks. Comprehensive experiments on various datasets show the effectiveness of the proposed mechanism compared to the other unsupervised baselines."
    }, {
      "heading" : "7 Acknowledgments",
      "text" : "We sincerely thank Wei Liu, Yu Duan, and Jie Zhou for the helpful discussions. This research was supported by the National Key Research And Development Program of China (2018YFC0830200; 2018YFC0830206; 2020YFC0832505)"
    } ],
    "references" : [ {
      "title" : "SEQˆ3: Differentiable sequence-to-sequence-to-sequence autoencoder for unsupervised abstractive sentence compression",
      "author" : [ "Christos Baziotis", "Ion Androutsopoulos", "Ioannis Konstas", "Alexandros Potamianos." ],
      "venue" : "Proceedings of the 2019 Con-",
      "citeRegEx" : "Baziotis et al\\.,? 2019",
      "shortCiteRegEx" : "Baziotis et al\\.",
      "year" : 2019
    }, {
      "title" : "Estimating or propagating gradients through stochastic neurons for conditional computation",
      "author" : [ "Yoshua Bengio", "Nicholas Léonard", "Aaron Courville." ],
      "venue" : "arXiv preprint arXiv:1308.3432.",
      "citeRegEx" : "Bengio et al\\.,? 2013",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2013
    }, {
      "title" : "Unsupervised opinion summarization as copycat-review generation",
      "author" : [ "Arthur Bražinskas", "Mirella Lapata", "Ivan Titov." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5151–5169, Online. As-",
      "citeRegEx" : "Bražinskas et al\\.,? 2020",
      "shortCiteRegEx" : "Bražinskas et al\\.",
      "year" : 2020
    }, {
      "title" : "Extracting decisions from multi-party dialogue using directed graphical models and semantic similarity",
      "author" : [ "Trung H Bui", "Matthew Frampton", "John Dowding", "Stanley Peters." ],
      "venue" : "Proceedings of the SIGDIAL 2009 Conference, pages 235–243.",
      "citeRegEx" : "Bui et al\\.,? 2009",
      "shortCiteRegEx" : "Bui et al\\.",
      "year" : 2009
    }, {
      "title" : "The ami meeting corpus: A pre-announcement",
      "author" : [ "Jean Carletta", "Simone Ashby", "Sebastien Bourban", "Mike Flynn", "Mael Guillemot", "Thomas Hain", "Jaroslav Kadlec", "Vasilis Karaiskos", "Wessel Kraaij", "Melissa Kronenthal" ],
      "venue" : null,
      "citeRegEx" : "Carletta et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Carletta et al\\.",
      "year" : 2005
    }, {
      "title" : "Meansum: a neural model for unsupervised multi-document abstractive summarization",
      "author" : [ "Eric Chu", "Peter Liu." ],
      "venue" : "International Conference on Machine Learning, pages 1223–1232.",
      "citeRegEx" : "Chu and Liu.,? 2019",
      "shortCiteRegEx" : "Chu and Liu.",
      "year" : 2019
    }, {
      "title" : "Unsupervised sentence compression using denoising autoencoders",
      "author" : [ "Thibault Févry", "Jason Phang." ],
      "venue" : "Proceedings of the 22nd Conference on Computational Natural Language Learning, pages 413–422, Brussels, Belgium. Association for Com-",
      "citeRegEx" : "Févry and Phang.,? 2018",
      "shortCiteRegEx" : "Févry and Phang.",
      "year" : 2018
    }, {
      "title" : "Abstractive summarization of spoken and written conversation",
      "author" : [ "Prakhar Ganesh", "Saket Dingliwal." ],
      "venue" : "arXiv preprint arXiv:1902.01615.",
      "citeRegEx" : "Ganesh and Dingliwal.,? 2019",
      "shortCiteRegEx" : "Ganesh and Dingliwal.",
      "year" : 2019
    }, {
      "title" : "Abstractive dialogue summarization with sentence-gated modeling optimized by dialogue acts",
      "author" : [ "Chih-Wen Goo", "Yun-Nung Chen." ],
      "venue" : "IEEE Spoken Language Technology Workshop (SLT), pages 735–742.",
      "citeRegEx" : "Goo and Chen.,? 2018",
      "shortCiteRegEx" : "Goo and Chen.",
      "year" : 2018
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural computation, 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Rouge: A package for automatic evaluation of summaries",
      "author" : [ "Chin-Yew Lin." ],
      "venue" : "Text Summarization Branches Out, 8.",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "Automatic dialogue summary generation for customer service",
      "author" : [ "Chunyi Liu", "Peng Wang", "Jiang Xu", "Zang Li", "Jieping Ye." ],
      "venue" : "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 1957–",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Text summarization with pretrained encoders",
      "author" : [ "Yang Liu", "Mirella Lapata." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
      "citeRegEx" : "Liu and Lapata.,? 2019",
      "shortCiteRegEx" : "Liu and Lapata.",
      "year" : 2019
    }, {
      "title" : "Effective approaches to attention-based neural machine translation",
      "author" : [ "Thang Luong", "Hieu Pham", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1412–1421, Lis-",
      "citeRegEx" : "Luong et al\\.,? 2015",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2015
    }, {
      "title" : "A* sampling",
      "author" : [ "Chris J Maddison", "Daniel Tarlow", "Tom Minka." ],
      "venue" : "Conference and Workshop on Neural Information Processing Systems, pages 3086–3094.",
      "citeRegEx" : "Maddison et al\\.,? 2014",
      "shortCiteRegEx" : "Maddison et al\\.",
      "year" : 2014
    }, {
      "title" : "Summarization evaluation: An overview",
      "author" : [ "Inderjeet Mani" ],
      "venue" : null,
      "citeRegEx" : "Mani.,? \\Q2001\\E",
      "shortCiteRegEx" : "Mani.",
      "year" : 2001
    }, {
      "title" : "Language as a latent variable: Discrete generative models for sentence compression",
      "author" : [ "Yishu Miao", "Phil Blunsom." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 319–328, Austin, Texas. Associa-",
      "citeRegEx" : "Miao and Blunsom.,? 2016",
      "shortCiteRegEx" : "Miao and Blunsom.",
      "year" : 2016
    }, {
      "title" : "TextRank: Bringing order into text",
      "author" : [ "Rada Mihalcea", "Paul Tarau." ],
      "venue" : "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 404–411, Barcelona, Spain. Association for Computational Linguistics.",
      "citeRegEx" : "Mihalcea and Tarau.,? 2004",
      "shortCiteRegEx" : "Mihalcea and Tarau.",
      "year" : 2004
    }, {
      "title" : "Summarunner: A recurrent neural network based sequence model for extractive summarization of documents",
      "author" : [ "Ramesh Nallapati", "Feifei Zhai", "Bowen Zhou." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, pages 3075–3081.",
      "citeRegEx" : "Nallapati et al\\.,? 2017",
      "shortCiteRegEx" : "Nallapati et al\\.",
      "year" : 2017
    }, {
      "title" : "A template-based abstractive meeting summarization: Leveraging summary and source text relationships",
      "author" : [ "Tatsuro Oya", "Yashar Mehdad", "Giuseppe Carenini", "Raymond Ng." ],
      "venue" : "Proceedings of the 8th International Natural Language Generation Confer-",
      "citeRegEx" : "Oya et al\\.,? 2014",
      "shortCiteRegEx" : "Oya et al\\.",
      "year" : 2014
    }, {
      "title" : "Centroid-based text summarization through compositionality of word embeddings",
      "author" : [ "Gaetano Rossiello", "Pierpaolo Basile", "Giovanni Semeraro." ],
      "venue" : "Proceedings of the MultiLing 2017 Workshop on Summarization and Summary Evaluation Across",
      "citeRegEx" : "Rossiello et al\\.,? 2017",
      "shortCiteRegEx" : "Rossiello et al\\.",
      "year" : 2017
    }, {
      "title" : "Discrete optimization for unsupervised sentence summarization with word-level extraction",
      "author" : [ "Raphael Schumann", "Lili Mou", "Yao Lu", "Olga Vechtomova", "Katja Markert." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Schumann et al\\.,? 2020",
      "shortCiteRegEx" : "Schumann et al\\.",
      "year" : 2020
    }, {
      "title" : "Get to the point: Summarization with pointergenerator networks",
      "author" : [ "Abigail See", "Peter J. Liu", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1073–",
      "citeRegEx" : "See et al\\.,? 2017",
      "shortCiteRegEx" : "See et al\\.",
      "year" : 2017
    }, {
      "title" : "Domainindependent abstract generation for focused meeting summarization",
      "author" : [ "Lu Wang", "Claire Cardie." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1395–1405,",
      "citeRegEx" : "Wang and Cardie.,? 2013",
      "shortCiteRegEx" : "Wang and Cardie.",
      "year" : 2013
    }, {
      "title" : "BottleSum: Unsupervised and selfsupervised sentence summarization using the information bottleneck principle",
      "author" : [ "Peter West", "Ari Holtzman", "Jan Buys", "Yejin Choi." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natu-",
      "citeRegEx" : "West et al\\.,? 2019",
      "shortCiteRegEx" : "West et al\\.",
      "year" : 2019
    }, {
      "title" : "Sentence centrality revisited for unsupervised summarization",
      "author" : [ "Hao Zheng", "Mirella Lapata." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6236–6247, Florence, Italy. Association for Compu-",
      "citeRegEx" : "Zheng and Lapata.,? 2019",
      "shortCiteRegEx" : "Zheng and Lapata.",
      "year" : 2019
    }, {
      "title" : "Simple unsupervised summarization by contextual matching",
      "author" : [ "Jiawei Zhou", "Alexander Rush." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5101–5106, Florence, Italy. Association for Compu-",
      "citeRegEx" : "Zhou and Rush.,? 2019",
      "shortCiteRegEx" : "Zhou and Rush.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 24,
      "context" : "Major attempts on dialogue summarization are template-based (Wang and Cardie, 2013; Oya et al., 2014) in the primitive stage by extracting key information and filling it into the learned templates.",
      "startOffset" : 60,
      "endOffset" : 101
    }, {
      "referenceID" : 20,
      "context" : "Major attempts on dialogue summarization are template-based (Wang and Cardie, 2013; Oya et al., 2014) in the primitive stage by extracting key information and filling it into the learned templates.",
      "startOffset" : 60,
      "endOffset" : 101
    }, {
      "referenceID" : 8,
      "context" : "Later, various works explore the assistance from labeled auxiliary information for summary generation, by leveraging either dialogue act (Goo and Chen, 2018), or key point sequence (Liu et al.",
      "startOffset" : 137,
      "endOffset" : 157
    }, {
      "referenceID" : 12,
      "context" : "Later, various works explore the assistance from labeled auxiliary information for summary generation, by leveraging either dialogue act (Goo and Chen, 2018), or key point sequence (Liu et al., 2019).",
      "startOffset" : 181,
      "endOffset" : 199
    }, {
      "referenceID" : 21,
      "context" : "A straightforward way to alleviate the dependency of the annotated data is to apply the existing unsupervised methods designed for document summarization (Rossiello et al., 2017; Zheng and Lapata, 2019; Baziotis et al., 2019; Chu and Liu, 2019) to the dialogue scene.",
      "startOffset" : 154,
      "endOffset" : 244
    }, {
      "referenceID" : 26,
      "context" : "A straightforward way to alleviate the dependency of the annotated data is to apply the existing unsupervised methods designed for document summarization (Rossiello et al., 2017; Zheng and Lapata, 2019; Baziotis et al., 2019; Chu and Liu, 2019) to the dialogue scene.",
      "startOffset" : 154,
      "endOffset" : 244
    }, {
      "referenceID" : 0,
      "context" : "A straightforward way to alleviate the dependency of the annotated data is to apply the existing unsupervised methods designed for document summarization (Rossiello et al., 2017; Zheng and Lapata, 2019; Baziotis et al., 2019; Chu and Liu, 2019) to the dialogue scene.",
      "startOffset" : 154,
      "endOffset" : 244
    }, {
      "referenceID" : 5,
      "context" : "A straightforward way to alleviate the dependency of the annotated data is to apply the existing unsupervised methods designed for document summarization (Rossiello et al., 2017; Zheng and Lapata, 2019; Baziotis et al., 2019; Chu and Liu, 2019) to the dialogue scene.",
      "startOffset" : 154,
      "endOffset" : 244
    }, {
      "referenceID" : 23,
      "context" : "a text document through discourse relations and lexical information and then created summaries via pointer-generator (See et al., 2017).",
      "startOffset" : 117,
      "endOffset" : 135
    }, {
      "referenceID" : 18,
      "context" : "For example, LEAD chooses the first several utterances and TextRank (Mihalcea and Tarau, 2004) ranks utterances by running a graph-based algorithm, where each node represents an utterance and the weight between any two nodes is calculated by the semantic similarity.",
      "startOffset" : 68,
      "endOffset" : 94
    }, {
      "referenceID" : 9,
      "context" : "bi-directional LSTM(Hochreiter and Schmidhuber, 1997) for the sake of fair comparison with other baselines.",
      "startOffset" : 19,
      "endOffset" : 53
    }, {
      "referenceID" : 14,
      "context" : "As for the decoder, we employ a uni-directional LSTM with attention mechanism (Luong et al., 2015).",
      "startOffset" : 78,
      "endOffset" : 98
    }, {
      "referenceID" : 19,
      "context" : "The RepSum is employed to both the extractive and abstractive summarization: Extractive Summarization We consider the extractive summarization as a sentence binary classification task as (Nallapati et al., 2017) does, which means R utterances in a dialogue with label one are extracted to be an extractive summary.",
      "startOffset" : 187,
      "endOffset" : 211
    }, {
      "referenceID" : 1,
      "context" : "Hence, we use the Straight-Through (ST) Gumble Estimator introduced in (Bengio et al., 2013) to solve this problem.",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 15,
      "context" : "During the forward training pass and test process, we use the reparametrization trick as a variance approximation of sampling from the original probability (Maddison et al., 2014).",
      "startOffset" : 156,
      "endOffset" : 179
    }, {
      "referenceID" : 4,
      "context" : "The AMI1 meeting corpus (Carletta et al., 2005) consists of 100 hours of meeting recordings",
      "startOffset" : 24,
      "endOffset" : 47
    }, {
      "referenceID" : 18,
      "context" : "As for the extractive-based methods, we compare with classical TextRank (Mihalcea and Tarau, 2004) which converts the dialogue to a weighted-",
      "startOffset" : 72,
      "endOffset" : 98
    }, {
      "referenceID" : 21,
      "context" : "Centroid (Rossiello et al., 2017) proposes a centroid-based method for text summarization that exploits the compositional",
      "startOffset" : 9,
      "endOffset" : 33
    }, {
      "referenceID" : 26,
      "context" : "PacSum (Zheng and Lapata, 2019) improves the TextRank by building graphs with directed edges considering the relative positions of any two sentences contributing to their respective centrality.",
      "startOffset" : 7,
      "endOffset" : 31
    }, {
      "referenceID" : 6,
      "context" : "2g shuf (Févry and Phang, 2018) adds noise to extend sentences and trains a denoising auto-encoder to recover the original input text.",
      "startOffset" : 8,
      "endOffset" : 31
    }, {
      "referenceID" : 0,
      "context" : "SEQ3 (Baziotis et al., 2019) constructs a compressor to generate summary and a reconstructor to regenerate input sentence via two chained encoderdecoder pairs.",
      "startOffset" : 5,
      "endOffset" : 28
    }, {
      "referenceID" : 5,
      "context" : "MeanSum (Chu and Liu, 2019) employs the mean of the representations of the input to decode a reasonable summary.",
      "startOffset" : 8,
      "endOffset" : 27
    }, {
      "referenceID" : 11,
      "context" : "ROUGE 3 score (Lin, 2004) is used for evaluation.",
      "startOffset" : 14,
      "endOffset" : 25
    }, {
      "referenceID" : 13,
      "context" : "with the document summarization where R-1 score usually approaches to 50 as reported in (Liu and Lapata, 2019).",
      "startOffset" : 88,
      "endOffset" : 110
    } ],
    "year" : 2021,
    "abstractText" : "In the field of dialogue summarization, due to the lack of training data, it is often difficult for supervised summary generation methods to learn vital information from dialogue context. Several works on unsupervised summarization for document by leveraging semantic information solely or auto-encoder strategy (i.e., sentence compression), they however cannot be adapted to the dialogue scene due to the limited words in utterances and huge gap between the dialogue and its summary. In this study, we propose a novel unsupervised strategy to address this challenge, which roots from the hypothetical foundation that a superior summary approximates a replacement of the original dialogue, and they are roughly equivalent for auxiliary (self-supervised) tasks, e.g., dialogue generation. The proposed strategy RepSum is applied to generate both extractive and abstractive summary with the guidance of the followed n utterance generation and classification tasks. Extensive experiments on various datasets demonstrate the superiority of the proposed model compared with other unsupervised methods.",
    "creator" : "LaTeX with hyperref"
  }
}