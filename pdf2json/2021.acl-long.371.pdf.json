{
  "name" : "2021.acl-long.371.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "De-biasing Distantly Supervised Named Entity Recognition via Causal Intervention",
    "authors" : [ "Wenkai Zhang", "Hongyu Lin", "Xianpei Han", "Le Sun" ],
    "emails" : [ "wenkai2019@iscas.ac.cn", "hongyu@iscas.ac.cn", "xianpei@iscas.ac.cn", "sunle@iscas.ac.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4803–4813\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4803"
    }, {
      "heading" : "1 Introduction",
      "text" : "Named entity recognition (NER) aims to identify text spans pertaining to specific semantic types, which is a fundamental task of information extraction, and enables various downstream applications such as Relation Extraction (Lin et al., 2016) and Question Answering (Bordes et al., 2015). The past several years have witnessed the remarkable success of supervised NER methods using neural networks (Lample et al., 2016; Ma and Hovy, 2016; Lin et al., 2020), which can automatically extract effective features from data and conduct NER in an end-to-end manner. Unfortunately, supervised methods rely on high-quality labeled data, which is very labor-intensive, and thus severely restricts\n∗Corresponding authors\nthe application of current NER models. To resolve the data bottleneck, a promising approach is distant supervision based NER (DS-NER). DS-NER automatically generates training data by matching entities in easily-obtained dictionaries with plain texts. Then this distantly-labeled data is used to train NER models, commonly be accompanied by a denoising step. DS-NER significantly reduces the annotation cost for building an effective NER model, and therefore has attracted great attention in recent years (Yang et al., 2018; Shang et al., 2018; Peng et al., 2019; Cao et al., 2019; Liang et al., 2020; Zhang et al., 2021).\nHowever, the learning of DS-NER is dictionarybiased, which severely harms the generalization and the robustness of the learned DS-NER models. Specifically, entity dictionaries are often incomplete (missing entities), noisy (containing wrong entities), and ambiguous (a name can be of different entity types, such as Washington). And DS will generate positively-labeled instances from the indictionary names but ignore all other names. Such a biased dataset will inevitably mislead the learned models to overfit in-dictionary names and underfit out-of-dictionary names. We refer to this as intradictionary bias. To illustrate this bias, Figure 1 (a) shows the predicting likelihood of a representa-\ntive DS-NER model (RoBERTa + Classifier (Liang et al., 2020)). We can see that there is a remarkable likelihood gap between in-dictionary mentions and out-of-dictionary mentions: the average likelihoods of out-of-dictionary mentions are < 0.2, which means that a great majority of them cannot be recalled. Furthermore, such a skewed distribution makes DS-NER models very sensitive to slight perturbations. We refer to this as inter-dictionary bias, i.e., different dictionaries can result in very different model behaviors. In the example shown in Figure 1 (b), we train the same DS-NER model by respectively using 4 dictionaries sampled from the same original dictionary, where each of them covers 90% of entities in the original one. We can see that the predicting likelihood diverges significantly even these 4 dictionaries share the majority part. Consequently, the dictionary-biased learning will undermine both the effectiveness and robustness of DS-NER models.\nIn this paper, we propose a causal framework to fundamentally explain and resolve the dictionary bias problem in DS-NER. We first formulate the procedure of DS-NER from the causal view with a Structural Causal Model (SCM) (Pearl et al., 2000), which is shown in the left part of Figure 2. From the SCM, we identified that the intra-dictionary bias stemming from the dictionary which serves as a confounder during the model learning. The dictionary confounder will introduce two backdoor paths, one from positively-labeled instances (Xp) to entity labels (Y ) and the other from negatively-labeled instances (Xn) to entity labels. These backdoor paths introduce spurious correlations during learn-\ning, therefore result in the intra-dictionary bias. Furthermore, the current learning criteria of DSNER models is to optimize over the correlations between the instances (X) and entity types (Y ) given one specific dictionary (D), namely P (Y |X,D). Such criteria, however, diverges from the primary goal of learning a dictionary-free NER model (i.e., P (Y |X)), and results in the inter-dictionary bias. Based on the above analysis, unbiased DS-NER should remove the spurious correlations introduced by backdoor paths and capture the true dictionaryfree causal relations.\nTo this end, we conduct causal interventions to de-bias DS-NER from the biased dictionary. For intra-dictionary bias, we intervene on the positive instances and the negative instances to block the backdoor paths in SCM, then the spurious correlations introduced by dictionary confounder will be removed. Specifically, we conduct backdoor adjustment to learn de-biased DS-NER models, i.e., we optimize the DS-NER model based on the causal distribution, rather than from the spurious correlation distribution. For inter-dictionary bias, we propose to leverage causal invariance regularizer (Mitrovic et al., 2021), which will make the learned representation more robust to the perturbation of dictionaries. For each instance in the training data, causal invariance regularizer will preserve the underlying causal effects unchanged across different dictionaries. The proposed method is modelfree, which can be used to resolve the dictionary bias in different DS-NER models by being applied as a plug-in during model training.\nWe conducted experiments on four standard DS-\nNER datasets: CoNLL2003, Twitter2005, Webpage, and Wikigold. Experiments on three stateof-the-art DS-NER models show that the proposed de-biasing method can effectively solve both intradictionary and inter-dictionary biases, and therefore significantly improve the performance and the robustness of DS-NER in almost all settings. Generally, the main contributions of this paper are:\n• We proposed a causal framework, which not only fundamentally formulates the DS-NER process, but also explains the causes of both intra-dictionary bias and inter-dictionary bias.\n• Based on the causal framework, we conducted causal interventions to de-bias DS-NER. For intra-dictionary bias, we conduct causal interventions via backdoor adjustment to remove spurious correlations introduced by the dictionary confounder. For inter-dictionary bias, we propose a causal invariance regularizer which will make DS-NER models more robust to the perturbation of dictionaries.\n• Experimental results on four standard DSNER datasets and three DS-NER models demonstrate that our method can significantly improve the performance and the robustness of DS-NER."
    }, {
      "heading" : "2 A Causal View on DS-NER",
      "text" : "In this section, we formulate DS-NER with a structural causal model (SCM), then identify the causes of both intra-dictionary bias and inter-dictionary bias using the SCM. An SCM captures the causal effect between different variables and describes the generative process of a causal distribution, which can be visually presented using a directed acyclic graph (DAG). In SCM, each node represents a random variable, and a directed edge represents a direct causal relationship between two variables. Based on SCM, the confounders and backdoor paths (Pearl et al., 2000) can be identified. In the following, we will describe the causal view of DSNER and then identify the dictionary bias."
    }, {
      "heading" : "2.1 Structural Causal Model for DS-NER",
      "text" : "Figure 2 shows the structural causal model for DS-NER, which contains 7 key variables in the DS-NER procedure: 1) the applied dictionary D for distant annotation; 2) the unlabeled instances X , where each instance is a pair of (mention candidate, context), and in training stage X will be\nautomatically labeled by D; 3) the positive training instances Xp, which are instances in X being labeled as positive instances (i.e., entity mentions) by dictionary D; 4) the negative training instancesXn, which are instances being labeled as negative instances by dictionary D; 5) the learned DS-NER model M , which summarizes NER evidences from DS-labeled data during training, and predicts new instances during testing; 6) the representations of instancesR, which is encoded dense representations of instances X using the learned model M ; 7) the predicted entity labels Y of instances in X based on the representation R.\nDefining these variables, the causal process of DS-NER can be formulated using SCM into two steps: distant supervision (DS) step and NER step respectively. For DS step, the procedure will generate DS-labeled data and learn DS-NER models by following causal relations:\n• D→Xp←X and D→Xn←X represent the distant annotation process, which uses dictionary D to annotate the unlabeled instances X and splits them into two sets: Xp and Xn.\n• Xp→M←Xn represents the learning process, where model M is the learned DS-NER model using Xp and Xn. We denote the Xp and Xn generated from dictionary D as Xp(D) and Xn(D) respectively.\nAnd the causal relation in NER step can be summarized as:\n• M→R←X is the representation learning procedure, which uses the learned model M to encode instances X .\n• R→Y represents the entity recognition process, where the labels of instances depend on the learned representation R and instances X . We denote the entity labels corresponding to Xp and Xn as Y p and Y n respectively."
    }, {
      "heading" : "2.2 Cause of Intra-dictionary Bias",
      "text" : "Given distant annotation Xp and Xn, the learning process of DS-NER will maximize the probability P (Y p=1, Y n=0|Xp, Xn, D). Unfortunately, because D is a confounder for Xp and Xn in SCM, this criteria will introduce spurious correlations and result in the intra-dictionary bias: (1) When maximizing P (Y=1|Xp, D), we want NER models to rely on the actual causal path\nXp→Y . However, in SCM there exists a backdoor path Xp←D→Xn→M which will introduce spurious correlation between Y and Xp. Intuitively, this backdoor path appears as the false negative instances in Xn. Because these false negative instances have correct entity contexts but outof-dictionary names, they will mislead the models to underfit the entity context for prediction. (2) When maximizing P (Y=0|Xn, D), we want NER models to rely on the actual causal path Xn→Y . However, in SCM there exists a backdoor pathXn←D→Xp→M which will introduce spurious correlation between Y and Xn. Intuitively, this backdoor path appears as the false positive instances in Xp. Because these false positive instances have in-dictionary entity names but spurious context, they will mislead the models to overfit the names in dictionary.\nIn general, the intra-dictionary bias is caused by backdoor paths introduced by D, and this bias will mislead the NER models to overfit names in dictionary and underfit the context of entities."
    }, {
      "heading" : "2.3 Cause of Inter-dictionary Bias",
      "text" : "As mentioned above, DS-NER models are learned by fitting P (Y p=1, Y n=0|Xp, Xn, D). This criteria will mislead the model when learning the correlation between X and Y with spurious information in D because the learning criteria is conditioned on it. However, a robust NER model should fit the underlying distribution P (Y |X), rather than the dictionary-conditioned distribution P (Y |X,D). From the SCM, the dictionary D will significantly influence the learned NER models M , and in turn result in different learned causal effects in the path X → R→ Y and entity prediction Y . As a result, DS-NER models will fit different underlying distributions given different dictionaries, and therefore results in inter-dictionary bias.\nHowever, in real-world applications, the dictionaries are affected by various factors, such as source, coverage or time. Therefore, to enhance the robustness of the learning process, it is critical to alleviate the spurious influence of dictionary D on the learned causal effects between X and Y . That is, we want DS-NER models to capture the dictionary-invariant entity evidence, rather than fit the dictionary-specific features."
    }, {
      "heading" : "3 De-biasing DS-NER via Causal Intervention",
      "text" : "In this section, we describe how to de-bias DSNER. Specifically, for intra-dictionary bias, we propose to use backdoor adjustment to block the backdoor paths. For inter-dictionary bias, we design a causal invariance regularizer to capture the dictionary-invariant evidence for NER."
    }, {
      "heading" : "3.1 Removing Intra-dictionary Bias via Backdoor Adjustment",
      "text" : "Based on the analysis in Section 2.2, the intradictionary bias is caused by the backdoor paths Xp←D→Xn→M and Xn←D→Xp→M . To remove these biases, we block both backdoor paths by intervening both Xp and Xn. After causal intervention, the learning of DS-NER models will fit the correct causal relation P (Y p=1|do(Xp(D)), Xn) and P (Y n=0|do(Xn(D)), Xp). Here do(Xp(D))=do(Xp=Xp(D)) represents the mathematical operation to intervene Xp and preserve it to be Xp(D) in the whole population.\nBackdoor Adjustments. To calculate the distribution P (Y p=1|do(Xp(D))) after causal intervention, we conduct backdoor adjustment according to causal theory (Pearl, 2009):\nPpos(D),P (Y p=1|do(Xp(D))) = ∑ i P (Y p=1|Xp(D), Xn(Di))\n× P (Di)\n(1)\nwhere Xn(Di) denotes the negative instances generated from the DS dictionary Di. P (Y p=1|Xp(D), Xn(Di)) is the probability of predicting Xp(D) into Y=1, which can be formulated using a neural network-based DS-NER model parametrized by θ, i.e., P (Y |Xp, Xn) = P (Y |Xp, Xn; θ). Detailed derivations is shown in appendix A.\nNote the distribution P (Y p=1|do(Xp(D))) in the causal framework is not the marginalized distribution P (Y p=1|Xp(D)) in the probability framework. Otherwise the marginalization should take place in the conditional distribution P (Di|Xp) rather than P (Di). Furthermore, as shown in Figure 3, Xp=Xp(Di) and Xn=Xn(Dj) can not happen together in probabilistic view unless Di=Dj . However, in the causal view, they can happened together via the causal intervention. That is do(Xp=Xp(Di)) and Xn=Xn(Dj), which is\nshown in Figure 3 (c). For more details, please refer to (Neal, 2020) for a brief introduction.\nSimilarly, to block the backdoor paths and calculate the causal distribution P (Y n=0|do(Xn(D))), we can conduct backdoor adjustment on Xn by:\nPneg(D),P (Y n=0|do(Xn(D))) = ∑ i P (Y n=0|Xn(D), Xp(Di))\n× P (Di)\n(2)\nEstimating Dictionary Probabilities. Because we only have one global dictionary D, it is hard to estimate the probability of other dictionaryDi used in the Equation (1) and (2). To tackle this problem, we sample K sub-dictionaries by sampling entities from the global dictionary D. The probability of each entity being sampled corresponds to its utterance frequency in a large-scale corpus. Then we applied a uniform probability assumption to these sampled dictionaries, which means that these subdictionaries will then be used to conduct backdoor adjustment with equal dictionary probabilities, i.e., P (Di) = 1 K .\nLearning DS-NER Models with Causal Relation. Given the above two causal distributions after backdoor adjustment, the DS-NER models can be effectively learned, and the intra-dictionary bias can be eliminated based on the causal relations between Xp, Xn and Y . Formally, we optimize DS-NER models by minimizing the following negative likelihood based on causal relation:\nLBA(θ)=− logPpos(D)− logPneg(D) (3)\nNote that the proposed method is model-free, which means that it can be applied to the majority\nof previous DS-NER methods by adaptively changing the underlying parametrization of probability distribution P (Y |Xp, Xn; θ) ."
    }, {
      "heading" : "3.2 Eliminating Inter-dictionary Bias via",
      "text" : "Causal Invariance Regularizer\nThis section describes causal invariance regularizer to eliminate the inter-dictionary bias. Specifically, after backdoor adjustment for intra-dictionary bias, the causal distribution we optimize (i.e., Ppos(D) and Pneg(D)) still depends on the dictionaryD. As a result, given different dictionaries, DS-NER models will fit different underlying causal distributions and result in inter-dictionary bias.\nIdeally, a robust DS-NER learning algorithm should be dictionary-free, i.e., we should directly optimize towards the implicit distribution of P (Y |X). However, it is impossible to directly achieve this because the golden answer Y of X is invisible in DS-NER. To enhance the robustness of the learning process, this section proposes a causal invariance regularizer, which ensures DSNER models to learn useful entity evidence for NER but not to fit dictionary-specific features. Specifically, the goal of causal invariance (Pearl et al., 2000) is to ensure learned NER models will keep similar causal effects using different dictionaries, which can be formulated as:\nθ∗inv=argmin θ ‖Ppos(Di)− Ppos(Dj)\n+Pneg(Di)− Pneg(Dj)‖ (4)\nHere || ∗ || measures the distance between two distributions. However, as we mentioned above, this distance cannot be directly optimized because the golden label Y of X is unknown. Fortunately, in the SCM, the impact from dictionary D to the entity label Y are all through the model M and the representation R, i.e., through the path D → M → R → Y . As a result, the bias from the dictionary D can be eliminated by preserving the causal effects between X and any node in the path. A simple and reasonable solution is to preserve the causal invariance of the representation R. That is, given different dictionaries, we keep the causal effects from X to R unchanged, and therefore causal effects of X → Y will remain unchanged. Specifically, when learning causal effects given an dictionary D, the causal invariance regularizer will further enhance its causal consistency with other dictionaries by minimizing its represen-\ntation distances to other dictionaries:\nLCIR(θ;D)= K∑ i=1 ∑ x∈X ||RD(x; θ)\n−RDi(x)||2 (5)\nHere RD(x; θ) is the representation of instance x, which is derived from the NER model M by fitting the causal effects of dictionary D. The reference dictionary Di in the formulations are generated in the same way as we described in Section 3.1 andK is the number of sub-dictionaries. Therefore, this regularizer ensures that the representations learned using different dictionaries will be consistent, and the inter-dictionary bias is eliminated.\nFinally, we combine (3) and (5) to de-bias both intra-dictionary bias and inter-dictionary bias and obtain the final DS-NER models by optimizing:\nL = ∑ i LiBA + λLCIR (6)\nwhere λ is a hyper-parameter which controls the relative importance of these two losses and is tuned on the development set."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Experimental Settings",
      "text" : "Datasets. We conduct experiments on four standard datasets: (1) CoNLL2003 (Tjong Kim Sang and De Meulder, 2003) is a well known opendomain NER dataset. It consists of 20744 sentences collected from 1393 English news articles and is annotated with four types: PER, ORG, LOC and MISC. (2) Twitter (Godin et al., 2015) is from the WNUT 2016 NER shared task. It consists of 7236 sentences with 10 entity types. (3) Webpage (Ratinov and Roth, 2009) contains 20 webpages, including personal, academic and computer-science conference homepages. It consists of 619 sentences with the four types the same as CoNLL2003. (4) Wikigold (Balasuriya et al., 2009) contains 149 articles from the May 22, 2008 dump of English Wikipedia. It consists of 1969 sentences with the same types of CoNLL2003.\nDistant Annotation Settings. We use two distant annotation settings: String-Matching and KBMatching (Liang et al., 2020). String-Matching labels dataset by directly matching names in dictionary with sentences. KB-Matching is more complex, which uses a set of hand-crafted rules to\nmatch entities. We find KB-Matching can generate better data than String-Matching, but StringMatching is a more general setting. In our experiments, we report performance on both KBMatching and String-Matching settings.\nImplementation Detail. We implement BiLSTM-CRF with AllenNLP (Gardner et al., 2017), an open-source NLP research library, and the input vector is the 100-dimension GloVe Embeddings (Pennington et al., 2014). For other baselines, we use the officially released implementation from the authors. We openly release our source code at github.com/zwkatgithub/DSCAU."
    }, {
      "heading" : "4.2 Baselines",
      "text" : "The proposed de-biased training strategy is both model-free, and learning algorithm-free. Therefore, we use the following base DS-NER baselines and compare the performance of using/not using our de-biased training strategy:\nDictMatch , which perform NER by directly matching text with names in a dictionary, so no learning is needed.\nFully-supervised baselines , including: (i) BiLSTM-CRF (Lample et al., 2016), which uses Glove (Pennington et al., 2014) for word embeddings; (ii) RoBERTa-base (Liu et al., 2019), which encodes text using RoBERTa-base then predict token label via a multi-layer perceptron.\nNaive Distant Supervision (Naive) , which directly uses weakly labeled data to train a fullysupervised model. It could be considered as the lower bound of DS-NER.\nPositive-Unlabeled Learning (PU-Learning) (Peng et al., 2019), which formulates DS-NER as a positive-unlabeled learning problem. It could obtain unbiased loss estimation of unlabeled data. However, it assumes that there are no false positive instances which may be incorrect in many datasets.\nBOND (Liang et al., 2020), which is a two-stage learning algorithm: In the first stage, it leverages pre-trained language model to improve the recall and precison of the NER model; In the second stage, it adopts a self-training approach to further improve the model performance."
    }, {
      "heading" : "4.3 Main Results",
      "text" : "Table 1 and Table 2 show the overall performance (F1 scores) of different baselines and our methods.\nFor our method, we use BA to denote backdoor adjustment, and CIR to denote causal invariance regularizer. We conduct our debiasing method on three base models: RoBERTa-base, PU-Learning and BOND, therefore we have 6 systems of our methods: RoBERTa+BA, RoBERT+BA+CIR, PU-Learning+BA, PU-Learning+BA+CIR, BOND +BA, BOND+BA+CIR.\nWe can see that: (1) DS-NER models are severely influenced by the dictionary bias. Without debiasing, the naive DS-NER baselines BiLSTMCRF and RoBERTa-base can only achieve comparable performance with the simple DictMatch baselines. And by taking the dictionary bias into consideration, PU-Learning, BOND with our method can significantly improve the performance of DSNER. Compared with DictMatch, they correspondingly achieve 4.99%, 21.98% F1 improvements on average. This verified that the dictionary bias is critical for DS-NER models. (2) By debiasing DS-NER models via causal intervention, our method can achieve significant improvement. Compared with their counterparts, our full methods RoBERTa+BA+CIR, BOND+BA+CIR correspond-\ningly achieve 4.91%, 3.18% improvements averaged on four datasets in KB-Matching (5.75%, 2.56% improvements on String-Matching) and PULearning+BA+CIR achieves 9.34% improvement on CoNLL2003 dataset in KB-Matching (5.80% improvement in String-Matching). This verified the effectiveness of using causal intervention for debiasing DS-NER. (3) Our method can effectively resolve both intra-dictionary and inter-dictionary biases. Both of backdoor adjustment and causal invariance regularizer can improve the NER performance. By conducting backdoor adjustment, our method can achieve a 3.27% F1 improvement averaged on all base models and all datasets. And further conducting causal invariance regularizer can future improve 4.63% average F1."
    }, {
      "heading" : "4.4 Effects on Robustness",
      "text" : "To verify whether the causal invariance regularizer can significantly improve the robustness of DS-NER across different dictionaries, we further compared the predicting likelihood of golden mentions using different dictionaries. Specifically, we train the same RoBERTa-Classifier DS-NER models by sampling 4 dictionaries. Figure 4 shows the average predicting likelihood before/after using our de-biasing method.\nFrom Figure 4, we can see that the proposed causal invariance regularizer significantly reduced the likelihood gaps between different dictionaries. This verified that removing the inter-dictionary bias can significant benefit the robustness of DS-NER. Furthermore, we can see that the likelihoods of golden mentions are remarkably increased, which represents a better NER performance. These\n71\n73\n75\n77\n79\n81\n83\n85\n1 2 3 4 Quantity of Dictionary\nBOND PUL RoBERTa\n77\n78\n79\n80\n81\n82\n83\n40% 50% 60% 70% 80% Proportion\nBOND PUL RoBERTa\nFigure 5: F1 scores when with different sub-dictionary coverages on the test set of CoNLL2003.\n71\n73\n75\n77\n79\n81\n83\n85\n1 2 3 4 Quantity of Dictionary\nBOND PUL RoBERTa\n77\n78\n79\n80\n81\n82\n83\n40% 50% 60% 70% 80% Proportion\nBOND PUL RoBERTa\nFigure 6: F1 scores when using different sub-dictionary quantities on the test set of CoNLL2003.\nall demonstrate the effectiveness of the proposed causal invariance regularizer."
    }, {
      "heading" : "4.5 Influence of Sub-dictionaries",
      "text" : "To conduct causal intervention, our method needs to sample sub-dictionaries from the original one. To analyze the influence of the coverage and the quantity of sub-dictionaries, we conducted experiments on sub-dictionaries with different coverages and different quantities.\nDictionary Coverage. Figure 5 shows the results with different dictionary coverages. We can see that our method is not sensitive to the coverage of sub-dictionaries: it can achieve robust performance from 40% to 80% coverage. All three models achieved the best performance at the 70% coverage. This result demonstrates the robustness of our method on dictionary coverage.\nDictionary Quantity. Figure 6 shows the results with different sub-dictionary quantities. We can see that our method can achieve performance improvement by sampling more sub-dictionaries. This is because more sub-dictionaries will lead to more accurate estimation of both the dictionary probability in backdoor adjustment and the dictionary variance in causal invariance regularizer. Futhermore, we can see that the performance using only one sub-dictionary (i.e., DS-NER without causal intervention) is significantly worse than other settings, this further verifies the effectiveness of our method."
    }, {
      "heading" : "5 Related Work",
      "text" : "DS-NER. Supervised NER models have achieved promising performance (Lample et al., 2016; Lin et al., 2019a,b). However, the reliance on labeled data limits their applications in open situations. Distant supervision (Mintz et al., 2009) is a promising technique to alleviate the data bottleneck for NER, which generates large-scale training data by matching sentences with external dictionaries. Current DS-NER studies focus on denoising the distantly labeled training data for better model learning. Yang et al. (2018) adopted reinforcement learning for denoising. Shang et al. (2018) proposed a sequence labeling framework TieOrBreak, which can avoid noise caused by a single word. Cao et al. (2019) promoted the quality of data by exploiting labels in Wikipedia. Peng et al. (2019) employed Positive-Unlabeled Learning to obtain unbiased estimation of the loss value. Liang et al. (2020) used self-training method which leverages a pretrained language model as teacher model to guide the training of student model. Causal Inference. Causal Inference (Pearl, 2009; Pearl and Mackenzie, 2018) has been widely adopted in psychology, politics and epidemiology for years (MacKinnon et al., 2007; Richiardi et al., 2013; Keele, 2015). It can provide more reliable explanations by removing confounding bias in data, and also provide debiased solutions by learning\ncausal effect rather than correlation effect. Recently, many causal inference techniques are used in computer vision (Tang et al., 2020; Qi et al., 2020) and natural language process (Wu et al., 2020; Zeng et al., 2020)."
    }, {
      "heading" : "6 Conclusions",
      "text" : "This paper proposes to identify and resolve the dictionary bias in DS-NER via causal intervention. Specifically, we first formulate DS-NER using a structural causal model, then identity the causes of both intra-dictionary and inter-dictionary biases, finally de-bias DS-NER via backdoor adjustment and causal invariance regularizer. Experiments on four datasets and three representative DS-NER models verified the effectiveness and the robustness of our method."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work is supported by the National Natural Science Foundation of China under Grants no.U1936207, Beijing Academy of Artificial Intelligence (BAAI2019QN0502), scientific research projects of the State Language Commission (YW135-78), and in part by the Youth Innovation Promotion Association CAS(2018141). Moreover, we thank all reviewers for their valuable comments and suggestions."
    }, {
      "heading" : "A Proof of Backdoor Adjustment",
      "text" : "We prove the backdoor adjustment for SCM using the do-calculus (Pearl, 1995) and the Truncated Factorization (Neal, 2020).\nFirst of all, we write the joint distribution as shown in our causal graph:\nP (D,Xp, Xn, Y,M,R,X)\n=P (D)P (X)P (Xp|D,X)P (Xn|D,X) P (M |Xp, Xn)P (R|M,X)P (Y |R)\nDue to the objective of our method is debiasing DS-NER models during training, we ignore the unlabeled instances variable X which is not related to the training process. Then we obtain the following equation:\nP (D,Xp, Xn, Y,M,R)\n=P (D)P (Xp|D)P (Xn|D) P (M |Xp, Xn)P (R|M)P (Y |R)\nNote that the prediction step of a NER model M→R→Y doesn’t have causal effects with other variables, we abbreviate P (M |Xp, Xn)P (R|M,X)P (Y |R) as P (Y |Xp, Xn). Finally, we obtain the simplified joint distribution:\nP (D,Xp, Xn, Y )\n=P (D)P (Xp|D)P (Xn|D)P (Y |Xp, Xn)\nThen we conduct causal intervention on Xp, i.e., do(Xp=Xp(D)) where Xp(D) denotes positive instances generated by dictionary D. Here, we abbreviate it as do(Xp(D)). In practice, do(Xp(D)) denotes that we use these positive instances to calculate loss value, therefore, in order to explicitly indicate this, we use Y p=1 in the following equation. According to the Truncated Factorization (Neal, 2020), we can know P (Xp|D)=1, and obtain the following equation:\nP (D,Xn, Y p=1|do(Xp(D))) =P (D)P (Xn|D)P (Y p=1|Xp(D), Xn)\nNext, we integrate D and Xn:\nP (Y p=1|do(Xp(D))) = ∑ i ∑ Xn P (Di)P (X n|Di)P (Y p=1|Xp(D), Xn)\nNote that P (Xn(Di)|Di)=1 if and only if Xn is generated by a specific dictionary Di, therefore we\ncan obtain:\nP (Y p=1|do(Xp(D))) = ∑ i ∑ Xn P (Di)P (X n|Di)P (Y p=1|Xp(D), Xn)\n= ∑ i P (Di)P (Y p=1|Xp(D), Xn(Di))"
    } ],
    "references" : [ {
      "title" : "Named entity recognition in Wikipedia",
      "author" : [ "Dominic Balasuriya", "Nicky Ringland", "Joel Nothman", "Tara Murphy", "James R. Curran." ],
      "venue" : "Proceedings of the 2009 Workshop on The People’s Web Meets NLP: Collaboratively Constructed Semantic Resources",
      "citeRegEx" : "Balasuriya et al\\.,? 2009",
      "shortCiteRegEx" : "Balasuriya et al\\.",
      "year" : 2009
    }, {
      "title" : "Large-scale simple question answering with memory networks",
      "author" : [ "Antoine Bordes", "Nicolas Usunier", "Sumit Chopra", "Jason Weston." ],
      "venue" : "CoRR.",
      "citeRegEx" : "Bordes et al\\.,? 2015",
      "shortCiteRegEx" : "Bordes et al\\.",
      "year" : 2015
    }, {
      "title" : "Low-resource name tagging learned with weakly labeled data",
      "author" : [ "Yixin Cao", "Zikun Hu", "Tat-seng Chua", "Zhiyuan Liu", "Heng Ji." ],
      "venue" : "Association for Computational Linguistics.",
      "citeRegEx" : "Cao et al\\.,? 2019",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2019
    }, {
      "title" : "Allennlp: A deep semantic natural language processing platform",
      "author" : [ "Matt Gardner", "Joel Grus", "Mark Neumann", "Oyvind Tafjord", "Pradeep Dasigi", "Nelson F. Liu", "Matthew Peters", "Michael Schmitz", "Luke S. Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Gardner et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Gardner et al\\.",
      "year" : 2017
    }, {
      "title" : "The statistics of causal inference: A view from political methodology",
      "author" : [ "Luke Keele." ],
      "venue" : "Political Analysis, pages 313–335.",
      "citeRegEx" : "Keele.,? 2015",
      "shortCiteRegEx" : "Keele.",
      "year" : 2015
    }, {
      "title" : "Neural architectures for named entity recognition",
      "author" : [ "Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer." ],
      "venue" : "Association for Computational Linguistics.",
      "citeRegEx" : "Lample et al\\.,? 2016",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2016
    }, {
      "title" : "Bond: Bert-assisted open-domain named entity recognition with distant supervision",
      "author" : [ "Chen Liang", "Yue Yu", "Haoming Jiang", "Siawpeng Er", "Ruijia Wang", "Tuo Zhao", "Chao Zhang." ],
      "venue" : "ACM SIGKDD International Conference on Knowledge",
      "citeRegEx" : "Liang et al\\.,? 2020",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2020
    }, {
      "title" : "Sequence-to-nuggets: Nested entity mention detection via anchor-region networks",
      "author" : [ "Hongyu Lin", "Yaojie Lu", "Xianpei Han", "Le Sun." ],
      "venue" : "Association for Computational Linguistics.",
      "citeRegEx" : "Lin et al\\.,? 2019a",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2019
    }, {
      "title" : "Gazetteerenhanced attentive neural networks for named entity recognition",
      "author" : [ "Hongyu Lin", "Yaojie Lu", "Xianpei Han", "Le Sun", "Bin Dong", "Shanshan Jiang." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Lin et al\\.,? 2019b",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2019
    }, {
      "title" : "A rigorous study on named entity recognition: Can fine-tuning pretrained model lead to the promised land",
      "author" : [ "Hongyu Lin", "Yaojie Lu", "Jialong Tang", "Xianpei Han", "Le Sun", "Zhicheng Wei", "Nicholas Jing Yuan" ],
      "venue" : "In Proceedings of the 2020 Con-",
      "citeRegEx" : "Lin et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural relation extraction with selective attention over instances",
      "author" : [ "Yankai Lin", "Shiqi Shen", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun." ],
      "venue" : "Association for Computational Linguistics.",
      "citeRegEx" : "Lin et al\\.,? 2016",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2016
    }, {
      "title" : "Roberta: A robustly optimized BERT pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "CoRR, abs/1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "End-to-end sequence labeling via bi-directional LSTM-CNNsCRF",
      "author" : [ "Xuezhe Ma", "Eduard Hovy." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computa-",
      "citeRegEx" : "Ma and Hovy.,? 2016",
      "shortCiteRegEx" : "Ma and Hovy.",
      "year" : 2016
    }, {
      "title" : "Mediation analysis",
      "author" : [ "David P MacKinnon", "Amanda J Fairchild", "Matthew S Fritz." ],
      "venue" : "Annu. Rev. Psychol., 58:593–614.",
      "citeRegEx" : "MacKinnon et al\\.,? 2007",
      "shortCiteRegEx" : "MacKinnon et al\\.",
      "year" : 2007
    }, {
      "title" : "Distant supervision for relation extraction without labeled data",
      "author" : [ "Mike Mintz", "Steven Bills", "Rion Snow", "Daniel Jurafsky." ],
      "venue" : "Association for Computational Linguistics.",
      "citeRegEx" : "Mintz et al\\.,? 2009",
      "shortCiteRegEx" : "Mintz et al\\.",
      "year" : 2009
    }, {
      "title" : "Representation learning via invariant causal mechanisms",
      "author" : [ "Jovana Mitrovic", "Brian McWilliams", "Jacob C Walker", "Lars Holger Buesing", "Charles Blundell." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Mitrovic et al\\.,? 2021",
      "shortCiteRegEx" : "Mitrovic et al\\.",
      "year" : 2021
    }, {
      "title" : "Introduction to Causal Inference from a Machine Learning Perspective",
      "author" : [ "Brady Neal" ],
      "venue" : null,
      "citeRegEx" : "Neal.,? \\Q2020\\E",
      "shortCiteRegEx" : "Neal.",
      "year" : 2020
    }, {
      "title" : "Causal diagrams for empirical research",
      "author" : [ "Judea Pearl." ],
      "venue" : "Biometrika, 82(4):669–688.",
      "citeRegEx" : "Pearl.,? 1995",
      "shortCiteRegEx" : "Pearl.",
      "year" : 1995
    }, {
      "title" : "Causality",
      "author" : [ "Judea Pearl." ],
      "venue" : "Cambridge university press.",
      "citeRegEx" : "Pearl.,? 2009",
      "shortCiteRegEx" : "Pearl.",
      "year" : 2009
    }, {
      "title" : "The Book of Why: The New Science of Cause and Effect",
      "author" : [ "Judea Pearl", "Dana Mackenzie." ],
      "venue" : "Basic Books.",
      "citeRegEx" : "Pearl and Mackenzie.,? 2018",
      "shortCiteRegEx" : "Pearl and Mackenzie.",
      "year" : 2018
    }, {
      "title" : "Models, reasoning and inference",
      "author" : [ "Judea Pearl" ],
      "venue" : "Cambridge, UK: CambridgeUniversityPress.",
      "citeRegEx" : "Pearl,? 2000",
      "shortCiteRegEx" : "Pearl",
      "year" : 2000
    }, {
      "title" : "Distantly supervised named entity recognition using positive-unlabeled learning",
      "author" : [ "Minlong Peng", "Xiaoyu Xing", "Qi Zhang", "Jinlan Fu", "Xuanjing Huang." ],
      "venue" : "Association for Computational Linguistics.",
      "citeRegEx" : "Peng et al\\.,? 2019",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2019
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D. Manning." ],
      "venue" : "Empirical Methods in Natural Language Processing (EMNLP).",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Two causal principles for improving visual dialog",
      "author" : [ "Jiaxin Qi", "Yulei Niu", "Jianqiang Huang", "Hanwang Zhang." ],
      "venue" : "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10860–10869.",
      "citeRegEx" : "Qi et al\\.,? 2020",
      "shortCiteRegEx" : "Qi et al\\.",
      "year" : 2020
    }, {
      "title" : "Design challenges and misconceptions in named entity recognition",
      "author" : [ "Lev Ratinov", "Dan Roth." ],
      "venue" : "Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009). Association for Computational Lin-",
      "citeRegEx" : "Ratinov and Roth.,? 2009",
      "shortCiteRegEx" : "Ratinov and Roth.",
      "year" : 2009
    }, {
      "title" : "Mediation analysis in epidemiology: methods, interpretation and bias",
      "author" : [ "Lorenzo Richiardi", "Rino Bellocco", "Daniela Zugna." ],
      "venue" : "International journal of epidemiology, 42(5):1511–1519.",
      "citeRegEx" : "Richiardi et al\\.,? 2013",
      "shortCiteRegEx" : "Richiardi et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning named entity tagger using domain-specific dictionary",
      "author" : [ "Jingbo Shang", "Liyuan Liu", "Xiaotao Gu", "Xiang Ren", "Teng Ren", "Jiawei Han." ],
      "venue" : "Association for Computational Linguistics.",
      "citeRegEx" : "Shang et al\\.,? 2018",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2018
    }, {
      "title" : "Long-tailed classification by keeping the good and removing the bad momentum causal effect",
      "author" : [ "Kaihua Tang", "Jianqiang Huang", "Hanwang Zhang." ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Tang et al\\.,? 2020",
      "shortCiteRegEx" : "Tang et al\\.",
      "year" : 2020
    }, {
      "title" : "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
      "author" : [ "Erik F. Tjong Kim Sang", "Fien De Meulder." ],
      "venue" : "Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003.",
      "citeRegEx" : "Sang and Meulder.,? 2003",
      "shortCiteRegEx" : "Sang and Meulder.",
      "year" : 2003
    }, {
      "title" : "De-biased court’s view generation with causality",
      "author" : [ "Yiquan Wu", "Kun Kuang", "Yating Zhang", "Xiaozhong Liu", "Changlong Sun", "Jun Xiao", "Yueting Zhuang", "Luo Si", "Fei Wu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Wu et al\\.,? 2020",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Distantly supervised NER with partial annotation learning and reinforcement learning",
      "author" : [ "Yaosheng Yang", "Wenliang Chen", "Zhenghua Li", "Zhengqiu He", "Min Zhang." ],
      "venue" : "Association for Computational Linguistics.",
      "citeRegEx" : "Yang et al\\.,? 2018",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2018
    }, {
      "title" : "Counterfactual generator: A weaklysupervised method for named entity recognition",
      "author" : [ "Xiangji Zeng", "Yunliang Li", "Yuchen Zhai", "Yin Zhang." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Zeng et al\\.,? 2020",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2020
    }, {
      "title" : "Denoising distantly supervised named entity recognition via a hypergeometric probabilistic model",
      "author" : [ "Wenkai Zhang", "Hongyu Lin", "Xianpei Han", "Le Sun", "Huidan Liu", "Zhicheng Wei", "Nicholas Yuan." ],
      "venue" : "Proceedings of the AAAI Conference on Ar-",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "Named entity recognition (NER) aims to identify text spans pertaining to specific semantic types, which is a fundamental task of information extraction, and enables various downstream applications such as Relation Extraction (Lin et al., 2016) and Question Answering (Bordes et al.",
      "startOffset" : 225,
      "endOffset" : 243
    }, {
      "referenceID" : 5,
      "context" : "The past several years have witnessed the remarkable success of supervised NER methods using neural networks (Lample et al., 2016; Ma and Hovy, 2016; Lin et al., 2020), which can automatically extract effective features from data and conduct NER in an end-to-end manner.",
      "startOffset" : 109,
      "endOffset" : 167
    }, {
      "referenceID" : 12,
      "context" : "The past several years have witnessed the remarkable success of supervised NER methods using neural networks (Lample et al., 2016; Ma and Hovy, 2016; Lin et al., 2020), which can automatically extract effective features from data and conduct NER in an end-to-end manner.",
      "startOffset" : 109,
      "endOffset" : 167
    }, {
      "referenceID" : 9,
      "context" : "The past several years have witnessed the remarkable success of supervised NER methods using neural networks (Lample et al., 2016; Ma and Hovy, 2016; Lin et al., 2020), which can automatically extract effective features from data and conduct NER in an end-to-end manner.",
      "startOffset" : 109,
      "endOffset" : 167
    }, {
      "referenceID" : 30,
      "context" : "DS-NER significantly reduces the annotation cost for building an effective NER model, and therefore has attracted great attention in recent years (Yang et al., 2018; Shang et al., 2018; Peng et al., 2019; Cao et al., 2019; Liang et al., 2020; Zhang et al., 2021).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 26,
      "context" : "DS-NER significantly reduces the annotation cost for building an effective NER model, and therefore has attracted great attention in recent years (Yang et al., 2018; Shang et al., 2018; Peng et al., 2019; Cao et al., 2019; Liang et al., 2020; Zhang et al., 2021).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 21,
      "context" : "DS-NER significantly reduces the annotation cost for building an effective NER model, and therefore has attracted great attention in recent years (Yang et al., 2018; Shang et al., 2018; Peng et al., 2019; Cao et al., 2019; Liang et al., 2020; Zhang et al., 2021).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 2,
      "context" : "DS-NER significantly reduces the annotation cost for building an effective NER model, and therefore has attracted great attention in recent years (Yang et al., 2018; Shang et al., 2018; Peng et al., 2019; Cao et al., 2019; Liang et al., 2020; Zhang et al., 2021).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 6,
      "context" : "DS-NER significantly reduces the annotation cost for building an effective NER model, and therefore has attracted great attention in recent years (Yang et al., 2018; Shang et al., 2018; Peng et al., 2019; Cao et al., 2019; Liang et al., 2020; Zhang et al., 2021).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 32,
      "context" : "DS-NER significantly reduces the annotation cost for building an effective NER model, and therefore has attracted great attention in recent years (Yang et al., 2018; Shang et al., 2018; Peng et al., 2019; Cao et al., 2019; Liang et al., 2020; Zhang et al., 2021).",
      "startOffset" : 146,
      "endOffset" : 262
    }, {
      "referenceID" : 6,
      "context" : "tive DS-NER model (RoBERTa + Classifier (Liang et al., 2020)).",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 15,
      "context" : "For inter-dictionary bias, we propose to leverage causal invariance regularizer (Mitrovic et al., 2021), which will make the learned representation more robust to the perturbation of dictionaries.",
      "startOffset" : 80,
      "endOffset" : 103
    }, {
      "referenceID" : 18,
      "context" : "tion, we conduct backdoor adjustment according to causal theory (Pearl, 2009):",
      "startOffset" : 64,
      "endOffset" : 77
    }, {
      "referenceID" : 16,
      "context" : "For more details, please refer to (Neal, 2020) for a brief introduction.",
      "startOffset" : 34,
      "endOffset" : 46
    }, {
      "referenceID" : 24,
      "context" : "(3) Webpage (Ratinov and Roth, 2009) contains 20 webpages, including personal, academic and computer-science conference homepages.",
      "startOffset" : 12,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "(4) Wikigold (Balasuriya et al., 2009) contains 149 articles from the May 22, 2008 dump of English Wikipedia.",
      "startOffset" : 13,
      "endOffset" : 38
    }, {
      "referenceID" : 6,
      "context" : "We use two distant annotation settings: String-Matching and KBMatching (Liang et al., 2020).",
      "startOffset" : 71,
      "endOffset" : 91
    }, {
      "referenceID" : 3,
      "context" : "We implement BiLSTM-CRF with AllenNLP (Gardner et al., 2017), an open-source NLP research library, and the input vector is the 100-dimension GloVe Embeddings (Pennington et al.",
      "startOffset" : 38,
      "endOffset" : 60
    }, {
      "referenceID" : 22,
      "context" : ", 2017), an open-source NLP research library, and the input vector is the 100-dimension GloVe Embeddings (Pennington et al., 2014).",
      "startOffset" : 105,
      "endOffset" : 130
    }, {
      "referenceID" : 5,
      "context" : "Fully-supervised baselines , including: (i) BiLSTM-CRF (Lample et al., 2016), which uses Glove (Pennington et al.",
      "startOffset" : 55,
      "endOffset" : 76
    }, {
      "referenceID" : 22,
      "context" : ", 2016), which uses Glove (Pennington et al., 2014) for word embeddings; (ii) RoBERTa-base (Liu et al.",
      "startOffset" : 26,
      "endOffset" : 51
    }, {
      "referenceID" : 11,
      "context" : ", 2014) for word embeddings; (ii) RoBERTa-base (Liu et al., 2019), which encodes text using RoBERTa-base then predict token label via a multi-layer perceptron.",
      "startOffset" : 47,
      "endOffset" : 65
    }, {
      "referenceID" : 21,
      "context" : "Positive-Unlabeled Learning (PU-Learning) (Peng et al., 2019), which formulates DS-NER as a positive-unlabeled learning problem.",
      "startOffset" : 42,
      "endOffset" : 61
    }, {
      "referenceID" : 6,
      "context" : "BOND (Liang et al., 2020), which is a two-stage learning algorithm: In the first stage, it leverages pre-trained language model to improve the recall and precison of the NER model; In the second stage, it adopts a self-training approach to further improve the model performance.",
      "startOffset" : 5,
      "endOffset" : 25
    }, {
      "referenceID" : 21,
      "context" : "Table 2: F1 scores on CoNLL2003 dataset based on PU-Learning (Peng et al., 2019).",
      "startOffset" : 61,
      "endOffset" : 80
    }, {
      "referenceID" : 14,
      "context" : "Distant supervision (Mintz et al., 2009) is a promising technique to alleviate the data bottleneck for",
      "startOffset" : 20,
      "endOffset" : 40
    }, {
      "referenceID" : 18,
      "context" : "Causal Inference (Pearl, 2009; Pearl and Mackenzie, 2018) has been widely adopted in psychology, politics and epidemiology for years (MacKinnon et al.",
      "startOffset" : 17,
      "endOffset" : 57
    }, {
      "referenceID" : 19,
      "context" : "Causal Inference (Pearl, 2009; Pearl and Mackenzie, 2018) has been widely adopted in psychology, politics and epidemiology for years (MacKinnon et al.",
      "startOffset" : 17,
      "endOffset" : 57
    }, {
      "referenceID" : 13,
      "context" : "Causal Inference (Pearl, 2009; Pearl and Mackenzie, 2018) has been widely adopted in psychology, politics and epidemiology for years (MacKinnon et al., 2007; Richiardi et al., 2013; Keele, 2015).",
      "startOffset" : 133,
      "endOffset" : 194
    }, {
      "referenceID" : 25,
      "context" : "Causal Inference (Pearl, 2009; Pearl and Mackenzie, 2018) has been widely adopted in psychology, politics and epidemiology for years (MacKinnon et al., 2007; Richiardi et al., 2013; Keele, 2015).",
      "startOffset" : 133,
      "endOffset" : 194
    }, {
      "referenceID" : 4,
      "context" : "Causal Inference (Pearl, 2009; Pearl and Mackenzie, 2018) has been widely adopted in psychology, politics and epidemiology for years (MacKinnon et al., 2007; Richiardi et al., 2013; Keele, 2015).",
      "startOffset" : 133,
      "endOffset" : 194
    }, {
      "referenceID" : 27,
      "context" : "Recently, many causal inference techniques are used in computer vision (Tang et al., 2020; Qi et al., 2020) and natural language process (Wu et al.",
      "startOffset" : 71,
      "endOffset" : 107
    }, {
      "referenceID" : 23,
      "context" : "Recently, many causal inference techniques are used in computer vision (Tang et al., 2020; Qi et al., 2020) and natural language process (Wu et al.",
      "startOffset" : 71,
      "endOffset" : 107
    }, {
      "referenceID" : 29,
      "context" : ", 2020) and natural language process (Wu et al., 2020; Zeng et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 73
    }, {
      "referenceID" : 31,
      "context" : ", 2020) and natural language process (Wu et al., 2020; Zeng et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 73
    } ],
    "year" : 2021,
    "abstractText" : "Distant supervision tackles the data bottleneck in NER by automatically generating training instances via dictionary matching. Unfortunately, the learning of DS-NER is severely dictionary-biased, which suffers from spurious correlations and therefore undermines the effectiveness and the robustness of the learned models. In this paper, we fundamentally explain the dictionary bias via a Structural Causal Model (SCM), categorize the bias into intra-dictionary and inter-dictionary biases, and identify their causes. Based on the SCM, we learn de-biased DS-NER via causal interventions. For intra-dictionary bias, we conduct backdoor adjustment to remove the spurious correlations introduced by the dictionary confounder. For inter-dictionary bias, we propose a causal invariance regularizer which will make DS-NER models more robust to the perturbation of dictionaries. Experiments on four datasets and three DS-NER models show that our method can significantly improve the performance of DS-NER.",
    "creator" : "LaTeX with hyperref"
  }
}