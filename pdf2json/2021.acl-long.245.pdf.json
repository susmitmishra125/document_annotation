{
  "name" : "2021.acl-long.245.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "From Machine Translation to Code-Switching: Generating High-Quality Code-Switched Text",
    "authors" : [ "Ishan Tarunesh", "Syamantak Kumar", "Preethi Jyothi" ],
    "emails" : [ "syamantak.kumar}@gmail.com,", "pjyothi@cse.iitb.ac.in" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3154–3169\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3154"
    }, {
      "heading" : "1 Introduction",
      "text" : "Code-switching (CS) refers to the linguistic phenomenon of using more than one language within a single sentence or conversation. CS appears naturally in conversational speech among multilingual speakers. The main challenge with building models for conversational CS text is that we do not have access to large amounts of CS text that is conversational in style. One might consider using social media text that contains CS and is more readily available. However, the latter is quite different from conversational CS text in its vocabulary (e.g., due to the frequent use of abbreviated slang terms,\n∗Work done while first two authors were students at IIT Bombay.\nhashtags and mentions), in its sentence structure (e.g., due to character limits in tweets) and in its word forms (e.g., due to transliteration being commonly employed in social media posts). This motivates the need for a generative model of realistic CS text that can be sampled to subsequently train models for CS text.\nIn this work, we tackle the problem of generating high-quality CS text using only limited amounts of real CS text during training. We also assume access to large amounts of monolingual text in the component languages and parallel text in both languages, which is a reasonable assumption to make for many of the world’s languages. We focus on Hindi-English CS text where the matrix (dominant) language is Hindi and the embedded language is English.1 Rather than train a generative model, we treat this problem as a translation task where the source and target languages are monolingual Hindi text and Hindi-English CS text, respectively. We also use the monolingual Hindi text to construct synthetic CS sentences using simple techniques. We show that synthetic CS text, albeit being naive in its construction, plays an important role in improving our model’s ability to capture CS patterns.\nWe draw inspiration from the large body of recent work on unsupervised machine translation (Lample et al., 2018a,b) to design our model, which will henceforth be referred to as Translation for Code-Switching, or TCS. TCS, once trained, will convert a monolingual Hindi sentence into a Hindi-English CS sentence. TCS makes effective use of parallel text when it is available and uses backtranslation-based objective functions with monolingual text.\n1Given the non-trivial effort involved in collecting annotations from professional annotators and crowd workers, we focused on a single language pair (Hindi-English) and leave explorations on more language pairs for future work.\nBelow, we summarize our main contributions:\n1. We propose a state-of-the-art translation model that generates Hindi-English CS text starting from monolingual Hindi text. This model requires very small amounts of real CS text, uses both supervised and unsupervised training objectives and considerably benefits from a carefully designed training curriculum, that includes pretraining with synthetically constructed CS sentences.\n2. We introduce a new Hindi-English CS text corpus in this work.2 Each CS sentence is accompanied by its monolingual Hindi translation. We also designed a crowdsourcing task to collect CS variants of monolingual Hindi sentences. The crowdsourced CS sentences were manually verified and form a part of our new dataset.\n3. We use sentences generated from our model to train language models for Hindi-English CS text and show significant improvements in perplexity compared to other approaches.\n4. We present a rigorous evaluation of the quality of our generated text using multiple objective metrics and a human evaluation study, and they clearly show that the sentences generated by our model are superior in quality and successfully capture naturally occurring CS patterns."
    }, {
      "heading" : "2 Related Work",
      "text" : "Early approaches of language modeling for codeswitched text included class-based n-gram models (Yeh et al.), factored language models that exploited a large number of syntactic and semantic features (Adel et al., 2015), and recurrent neural language models (Adel et al., 2013) for CS text. All these approaches relied on access to real CS text to train the language models. Towards alleviating this dependence on real CS text, there has been prior work on learning code-switched language models from bilingual data (Li and Fung, 2014b,a; Garg et al., 2018b) and a more recent direction that explores the possibility of generating synthetic CS sentences. (Pratapa et al., 2018) presents a technique to generate synthetic CS text that grammatically adheres to a linguistic theory\n2The new dataset and relevant code is available at: https://www.cse.iitb.ac.in/~pjyothi/TCS.\nof code-switching known as the equivalence constraint (EC) theory (Poplack, 1979; Sankoff, 1998). Lee and Li (2020) proposed a bilingual attention language model for CS text trained solely using a parallel corpus.\nAnother recent line of work has explored neural generative models for CS text. Garg et al. (2018a) use a sequence generative adversarial network (SeqGAN (Yu et al., 2017)) trained on real CS text to generate sentences that are used to aid language model training. Another GAN-based method proposed by Chang et al. (2019) aims to predict the probability of switching at each token. Winata et al. (2018) and Winata et al. (2019) use a sequence-to-sequence model enabled with a copy mechanism (Pointer Network (Vinyals et al., 2015)) to generate CS data by leveraging parallel monolingual translations from a limited source of CS data. Samanta et al. (2019) proposed a hierarchical variational autoencoder-based model tailored for code-switching that takes into account both syntactic information and language switching signals via the use of language tags. (We present a comparison of TCS with both Samanta et al. (2019) and Garg et al. (2018a) in Section 5.2.1.)\nIn a departure from using generative models for CS text, we view this problem as one of sequence transduction where we train a model to convert a monolingual sentence into its CS counterpart. Chang et al. (2019); Gao et al. (2019) use GAN-based models to modify monolingual sentences into CS sentences, while we treat this problem of CS generation as a translation task and draw inspiration from the growing body of recent work on neural unsupervised machine translation models (Lample et al., 2018a,b) to build an effective model of CS text.\nThe idea of using translation models for codeswitching has been explored in early work (Vu et al., 2012; Li and Fung, 2013; Dhar et al., 2018). Concurrent with our work, there have been efforts towards building translation models from English to CS text (Solorio et al., 2021) and CS text to English (Gupta et al., 2021). While these works focus on translating from the embedded language (English) to the CS text or vice-versa, our approach starts with sentences in thematrix language (Hindi) which is the more dominant language in the CS text. Also, ours is the first work, to our knowledge, to repurpose an unsupervised neural machine translation model to translate monolingual sentences\ninto CS text. Powerful pretrained models like mBART (Liu et al., 2020) have been used for codemixed translation tasks in concurrent work (Gautam et al., 2021). We will further explore the use of synthetic text with such models as part of future work."
    }, {
      "heading" : "3 Our Approach",
      "text" : "Figure 1 shows the overall architecture of our model. This is largely motivated by prior work on unsupervised neural machine translation (Lample et al., 2018a,b). The model comprises of three layers of stacked Transformer (Vaswani et al., 2017) encoder and decoder layers, two of which are shared and the remaining layer is private to each language. Monolingual Hindi (i.e. the source language) has its own private encoder and decoder layers (denoted by Encp0 and Decp0 , respectively) while English and Hindi-English CS text jointly make use of the remaining private encoder and decoder layers (denoted by Encp1 and Decp1 , respectively). In our model, the target language is either English or CS text. Ideally, we would like Encp1 and Decp1 to be trained only using CS text. However, due to the paucity of CS text, we also use text in the embedded language (i.e. English) to train these layers. Next, we outline the three main training steps of TCS.\n(I) Denoising autoencoding (DAE). We use monolingual text in each language to estimate language models. In Lample et al. (2018b), this is achieved via denoising autoencoding where an autoencoder is used to reconstruct a sentence given a noisy version as its input whose structure is altered by dropping and swapping words arbitrarily (Lample et al., 2018a). The loss incurred in this step is denoted by LDAE and is composed of two terms based on the reconstruction of the source and target language sentences, respectively.\n(II) Backtranslation (BT): Once the layers are initialized, one can use non-parallel text in both languages to generate a pseudo-parallel corpus of backtranslated pairs (Sennrich et al., 2015). That is, a corpus of parallel text is constructed by translating sentences in the source language via the pipeline, Encp0 , Encsh, Decsh and Decp1 , and translating target sentences back to the source language via Encp1 , Encsh, Decsh and Decp0 . The backtranslation loss LBT is composed of crossentropy losses from using these pseudo-parallel\nsentences in both directions.\n(III) Cross-entropy loss (CE): Both the previous steps used unsupervised training objectives and make use of non-parallel text. With access to parallel text, one can use the standard supervised cross-entropy loss (denoted by LCE) to train the translation models (i.e. going from Encp0 to Decp1 and Encp1 to Decp0 via the common shared layers)."
    }, {
      "heading" : "3.1 Synthetic CS text",
      "text" : "Apart from the use of parallel text and monolingual text employed in training TCS, we also construct large volumes of synthetic CS text using two simple techniques. This synthetic CS text is nonparallel and is used to optimize both LDAE and LBT . The role of the synthetic CS text is to expose TCS to various CS patterns (even if noisy), thereby encouraging the model to code-switch. The final step of finetuning using All-CS enables model to mimic switching patterns of real CS texts\nThe first technique (named LEX) is a simple heuristic-based technique that constructs a CS sentence by traversing a Hindi sentence and randomly replacing a word by its English translation using a bilingual lexicon (Conneau et al., 2017). The probability of replacing a word is chosen to match the switching distribution in real CS text. The second technique (named EMT) is more linguistically aware. Following the methodology proposed by Bhat et al. (2016) that is based on the embedded\nmatrix theory (EMT) for code-switching, we apply clause substitution methods to monolingual text to construct synthetic CS text. From inspecting English parse trees, we found that replacing embedded sentence clauses or subordinate clauses with their Hindi translations would likely produce CS text that appears somewhat natural."
    }, {
      "heading" : "4 Description of Datasets",
      "text" : ""
    }, {
      "heading" : "4.1 A New Hindi-English CS Dataset",
      "text" : "We introduce a new Hindi-English CS dataset, that we will refer to as All-CS. It is partitioned into two subsets, Movie-CS and Treebank-CS, based on their respective sources. Movie-CS consists of conversational Hindi-English CS text extracted from 30 contemporary Bollywood scripts that were publicly available.3 The Hindi words in these sentences were all Romanized with potentially multiple non-canonical forms existing for the same Hindi token. We employed a professional annotation company to convert the Romanized Hindi words into their respective backtransliterated forms rendered in Devanagari script. We also asked the annotators to provide monolingual Hindi translations for all these sentences. Using these monolingual Hindi sentences as a starting point, we additionally crowdsourced for CS sentences via Amazon’s Mechanical Turk (MTurk) (Amazon, 2005). Table 1 shows two Hindi sentences fromMovie-CS and Treebank-CS, along with the different variants of CS sentences.\nTurkers were asked to convert a monolingual Hindi sentence into a natural-sounding CS variant that was semantically identical. Each Turker had to work on five Hindi sentences. We developed a web interface using which Turkers could easily copy parts of the Hindi sentence they wanted to retain and splice in English segments. More details about this interface, the crowdsourcing task and worker statistics are available in Appendix A.\nAll-CS comprises a second subset of CS sentences, Treebank-CS, that was crowdsourcing usingMTurk. We extracted 5292monolingual Hindi sentences (with sentence lengths less than or equal to 15 words) from the publicly available Hindi Dependency Treebank that contains dependency parses.4 These annotations parse each Hindi sentence into chunks, where a chunk is defined as\n3https://www.filmcompanion.in/category/fc-pro/scripts/ https://moifightclub.com/category/scripts/\n4http://ltrc.iiit.ac.in/treebank_H2014/\na minimal, non recursive phrase. Turkers were asked to convert at least one Hindi chunk into English. This was done in an attempt to elicit longer spans of English segments within each sentence. Figure 2 shows the sentence length distributions for Movie-CS and Treebank-CS, along with histograms accumulating English segments of different lengths in both subsets. We clearly see a larger fraction of English segments with lengths within the range [2-6] in Treebank-CS compared to Movie-CS.\nTable 2 provides detailed statistics of the new CS dataset. We also report two metrics proposed by Guzmán et al. (2017) to measure the amount of code-switching present in this new corpus. Monolingual Index (M-Index) is a value between 0 and 1\nthat quantifies the amount of mixing between languages (0 denotes a purelymonolingual corpus and 1 denotes equal mixing from both languages) and I-Index measures the fraction of switching points in the corpus. We observe Treebank-CS exhibits higher M-index and I-index values compared to Movie-CS indicating more code-switching overall. All-CS also contains a non-trivial number of named entities (NEs) which are replaced by an NE tag in all our language modeling experiments."
    }, {
      "heading" : "4.2 Other Datasets",
      "text" : "Parallel Hindi-English Text. As described in Section 5, TCS uses parallel text for supervised training. For this purpose, we use the IIT Bombay English-Hindi Corpus (Kunchukuttan et al., 2017) containing parallel Hindi-English text. We also construct a larger parallel corpus using text from the OpenSubtitles (OpSub) corpus (Lison and Tiedemann, 2016) that is more conversational and hence more similar in style to Movie-CS. We chose ~1 million English sentences (OpSub-EN), where each sentence contained an embedded clause or a subordinate clause to support the construction of EMT lines. We used the Google Translate API to obtain Hindi translations for all these sentences (OpSub-HI). Henceforth, we use OpSub to refer to this parallel corpus of OpSub-EN paired with OpSub-HI. We extracted 318K sentences from the IITB corpus after thresholding on length (5-15) and considering overlap in vocabulary with OpSub. (One could avoid the use of an external service like Google Translate and use existing parallel text (Zhang et al., 2020)) in conjunction with a word aligner to construct EMT lines. OpSub, being more conversational in style, turns out to be a better pretraining corpus. A detailed comparison of these choices is described in Appendix H.)\nSynthetic CS Datasets. As mentioned in Section 3.1, we use two simple techniques LEX and EMT to generate synthetic CS text, which in turn is used to train TCS in an unsupervised training phase. For each Hindi monolingual sentence in OpSub, we generate two LEX and two EMT synthetic CS sentences giving us OpSub-LEX and OpSub-EMT, respectively. We also generate five LEX and five EMT lines for each monolingual sentence in All-CS. In order to generate EMT lines, we first translate the monolingual Hindi\nsentences in All-CS to English using Google Translate and then follow the EMT generation scheme. This results in two datasets, All-CS-LEX and All-CS-EMT, which appear in later evaluations. (Appendix B contains more details about EMT applied to OPUS and All-CS.)\nDatasets from existing approaches. (I) VACS (Samanta et al., 2019) is a hierarchical variational autoencoder-based model designed to generate CS text. We train two VACS models, one on All-CS (VACSv1) and the other on OpSub-EMT followed by All-CS (VACSv2). (II) Garg et al. (2018a) use SeqGAN (Yu et al., 2017) – a GAN-based sequence generation model – to generate CS sentences by providing an RNNLM as the generator. As with VACS, we train two SeqGAN5 models, one on All-CS (SeqGANv1) and one on OpSub-EMT followed by All-CS (SeqGANv2). Samples are drawn from both SeqGAN and VACS by first drawing a random sample from the standard normal distribution in the learned latent space and then decoding via an RNN-based generator for SeqGAN and a VAE-based decoder for VACS. We sample ~2M lines for each dataset to match the size of the other synthetic datasets."
    }, {
      "heading" : "5 Experiments and Results",
      "text" : "First, we investigate various training curricula to train TCS and identify the best training strategy by evaluating BLEU scores on the test set of All-CS (§5.1). Next, we compare the output from TCS with synthetic CS text generated by other methods (§5.2). We approach this via language modeling (§5.2.1), human evaluations (§5.2.2) and two downstream tasks—Natural Language Inference and Sentiment Analysis—involving real CS text (§5.2.3). Apart from these tasks, we also present four different objective evaluation metrics to evaluate synthetic CS text: BERTScore, Accuracy of a BERT-based classifier and two diversity scores (§5.3)."
    }, {
      "heading" : "5.1 Improving Quality of TCS Outputs",
      "text" : "Table 3 shows the importance of various training curricula in training TCS; these models are evaluated using BLEU (Papineni et al., 2002) scores computed with the ground-truth CS sentences for\n5https://github.com/suragnair/seqGAN\nthe test set of All-CS.We start with supervised pretraining of TCS using the two parallel datasets we have in hand – IITB and OpSub (System A). A is then further finetuned with real CS text in AllCS. The improvements in BLEU scores moving from SystemO (trained only on All-CS) to System B illustrate the benefits of pretraining TCS using Hindi-English parallel text.\nSystems C and D in Table 3 use our synthetic CS datasets OpSub-LEX and OpSub-EMT, respectively. These systems are further finetuned on AllCS using both unsupervised and supervised training objectives to give C1, C2, D1 and D2, respectively. Comparing these four systems with System B shows the importance of using synthetic CS for pretraining. Further, comparingC1 againstD1 and\nC2 against D2, we observe that OpSub-EMT is indeed a better choice for pretraining compared to OpSub-LEX. Also, supervised finetuning with AllCS is clearly superior to unsupervised finetuning. Henceforth, SystemsD1 andD2 will be referred to as TCS (U) and TCS (S), respectively.\nWhile having access to parallel CS data is an advantage, we argue that the benefits of having parallel data only marginally increase after a threshold. Figure 3 shows how BLEU scores vary when changing the amount of parallel CS text used to trainD2. We observe that BLEU increases substantially when we increase CS data from 1000 lines to 5000 lines, after which there is a trend of diminishing returns. We also find that D1 (that uses the data in All-CS as non-parallel text) is as good as the model trained using 4000 lines of parallel text."
    }, {
      "heading" : "5.2 Comparing TCS with Other Synthetic CS",
      "text" : ""
    }, {
      "heading" : "5.2.1 Language Modeling",
      "text" : "We use text generated by our model to train a language model (LM) and evaluate perplexities on the test set of All-CS to show how closely sentences from TCS mimic real CS text. We use a state-of-the-art RNNLM model AWD-LSTMLM Merity et al. (2018) as a blackbox LM and only experiment with different training datasets. The model uses three LSTM layers of 1200 hidden units with weight tying and 300-dimensional word embeddings. In initial runs, we trained our language model on the large parallel/synthetic CS datasets and finetuned on the All-CS data. However, this training strategy was prone to overfitting on All-CS data. To counter this problem of forgetting during the pretrain-finetuning steps, we adopted the Mix-review strategy proposed by He et al. (2021). The training sentences from All-CS remain constant through the epochs and the amount of pretraining data is exponentially decayed with each epoch. This greatly alleviates the forgetting problem in our model, and leads to better overall perplexities. Additional details about these LMs are provided in Appendix E.\nTable 4 shows test perplexities using different training curricula and data generated using two prior approaches, VACS and SeqGAN. Sentences generated using TCS yield the largest reductions in test perplexities, compared to all other approaches."
    }, {
      "heading" : "5.2.2 Human Evaluation",
      "text" : "We evaluated the quality of sentences generated by TCS using a human evaluation study. We sampled 150 sentences each, using both TCS (U) and TCS (S), starting from monolingual Hindi sentences in the evaluation sets of All-CS. The sentences were chosen such that they were consistent with the length distribution of All-CS. For the sake of comparison, corresponding to the above-mentioned 150 monolingual Hindi samples, we also chose 150 CS sentences each from All-CS-LEX and AllCS-EMT. Along with the ground-truth CS sentences from All-CS, this resulted in a total of 750 sentences.6 These sentences were given to three linguistic experts in Hindi and they were asked to provide scores ranging between 1 and 5 (1 for worst, 5 for best) under three heads: “Syntactic correctness”, “Semantic correctness” and “Naturalness”. Table 5 shows that the sentences generated using TCS (S) and TCS (U) are far superior to the EMT and LEX sentences on all three criteria. TCS (S) is quite close in overall quality to the real sentences and TCS (U) fares worse, but only by a small margin.\nTable 6 shows some illustrative examples of code-switching using TCS (U) on test samples. We also show some examples of code-switching\nGenerated using MovieCS\nमैं खुश हँू तुमने नो टस कया (I am glad you noticed) i am happy तुमने notice कया नह ं मैं तुमसे बहुत प्यार करता हँू सच में ले कन िसफर् एक दोस्त क तरह (No i really love you but just like a friend) नह ं i love you very much सच में but िसफर् एक friend क तरह\nwithin monolingual sentences from OpSub. We observe that the model is able to introduce long contiguous spans of English words (e.g. “meeting next week”, “but it is clear”, etc.). The model also displays the ability to meaningfully switch multiple times within the same sentence (e.g., “i love you very much”, “but”, “friend”). There are also interesting cases of English segments that appear to be ungrammatical but make sense in the CS context (e.g., “because i know main dish”, etc.)."
    }, {
      "heading" : "5.2.3 GLUECoS Benchmark",
      "text" : "GLUECoS (Khanuja et al., 2020) is an evaluation benchmark spanning six natural language tasks for code-switched English-Hindi and English-Spanish data. The authors observe that M-BERT (Pires et al., 2019) consistently outperforms cross-lingual embedding techniques. Furthermore, pretraining M-BERT on small amounts of code-switched text improves its performance in most cases. For our evaluation, we select two tasks that require semantic understanding: Natural Language Inference (NLI) and Sentiment Analysis (SA).\nWe sample 100K monolingual sentences from\nOpSub-HI and select corresponding LEX, EMT and TCS (S) sentences. M-BERT is then trained using the masked language modelling (MLM) objective on text from all 4 systems (including OpSub-HI) for 2 epochs. We also train M-BERT on 21K sentences from All-CS (real CS). Finally, these pretrained models are fine-tuned on the selected GLUECoS tasks. (More details are in Appendix G.)\nTable 7 lists the accuracies and F1 scores using different pretraining schemes for both NLI and sentiment analysis, respectively. Plain monolingual pretraining by itself leads to performance improvements on both tasks, presumably due to domain similarity betweenGLUECoS (movie scripts, social media etc.) and OpSub. As mentioned in Khanuja et al. (2020), pretraining on CS text further improves performance for both NLI and SA. Among the synthetic methods, TCS (S) has consistently better scores than LEX and EMT. For SA, TCS (S) even outperforms pretraining on real CS text from All-CS."
    }, {
      "heading" : "5.3 Other Objective Evaluation Metrics",
      "text" : "BERTScore. BERTScore (Zhang* et al., 2020) is a recently-proposed evaluation metric for text generation. Similarity scores are computed between each token in the candidate sentence and\neach token in the reference sentence, using contextual BERT embeddings (Devlin et al., 2018) of the tokens. We use this as an additional objective metric to evaluate the quality of the sentences generated using TCS. We use the real monolingual sentence as the reference and the generated CS sentence as the candidate, excluding sentences from TCS (S) and TCS (U) that exactly match the real sentence. Since our data is Hindi-English CS text, we use Multilingual BERT (M-BERT) (Pires et al., 2019) for high-quality multilingual representations.\nTable 8 outlines our main results on the test set of All-CS. TCS sometimes generates purely monolingual sentences. This might unfairly tilt the scores in favour of TCS since the reference sentences are also monolingual. To discount for such biases, we remove sentences generated by TCS (U) and TCS (S) that are purely monolingual (Row label “Mono” in BERTScore). Sentences having <UNK> tokens (labeled “UNK”) are also filtered out since these tokens are only generated by TCS for out-of-vocabulary words. “UNK & Mono” refers to applying both these filters.\nEMT lines consistently show the worst performance, which is primarily due to the somewhat poor quality of translations involved in generating these lines (refer to Appendix B). With removing both monolingual and <UNK> tokens, we observe that TCS (U) and TCS (S) yield the highest BERTScores, even outperforming the BERTScore on real data obtained from the Turkers.\nBERT-based Classifier. In this evaluation, we use M-BERT (Pires et al., 2019) to build a classifier that distinguishes real CS sentences from synthetically generated ones (fake). When subject to examples from high-quality generators, the classifier should find it hard to tell apart real from fake\nsamples. We add a fully connected layer over the M-BERT base architecture that takes the [CLS] token as its input to predict the probability of the sentence being real or fake. Fake sentences are drawn from the union of TCS (U), TCS (S), All-CS-LEX and All-CS-EMT. In order to alleviate the class imbalance problem, we oversample the real sentences by a factor of 5 and shuffle the data. The model converges after training for 5 epochs. We see in Table 8 that the classification accuracy of whether a sample is fake or not is lowest for the outputs from TCS among the different generation techniques.\nMeasuring Diversity. We are interested in finding out how diverse the predictions from TCS are. We propose a simplemeasure of diversity in the CS variants that is based on how effectively sentences can be compressed using the gzip utility.7 We considered using Byte Pair Encoding (BPE) (Gage, 1994) as a measure of data compression. However, BPE operates at the level of individual words. Two word sequences “w1 w2 w3” and “w3 w2 w1” would be identically compressed by a BPE tokenizer. We would ideally like to account for such diversity and not discard this information. gzip uses Lempel-Ziv coding (Ziv and Lempel, 1977) that considers substrings of characters during compression, thus allowing for diversity in word ordering to be captured.\nOur diversity measure D is simply the following: For a given set of CS sentences, run gzip on each sentence individually and sum the resulting file sizes (S1). Next, paste all the CS sentences into a single file and run gzip on it to get a file of size S2. Then, D = S1−S2. SmallerD scores indicate larger diversity. If the variants of a sentence are dissimilar to one another and hence very diverse, then S2 would be large thus leading to smaller values of D. Table 8 shows the diversity scores for different techniques. Both TCS (S) and TCS (U) have a higher diversity score compared to LEX and EMT. TCS (U) exceeds even the responses received viaMTurk (Real) in diversity. We note here that diversity, by itself, is not necessarily a desirable trait. Our goal is to generate sentences that are diverse while being natural and semanticallymeaningful. The latter properties for text from TCS (S) and TCS (U) have already been verified in our human evaluation study.\nZhu et al. (2018) propose self-BLEU score as a metric to evaluate the diversity of generated data.\n7http://www.gzip.org/\nHowever, using self-BLEU is slightly problematic in our setting as systems like LEX that switch words at random positions would result in low self-BLEU (indicating high diversity). This is indeed the case, as shown in Table 8 - LEX, EMT give lower self-BLEU scores as compared to TCS. However, note that the scores of the TCS models are comparable to that of real CS data."
    }, {
      "heading" : "6 Conclusions",
      "text" : "In this work, we present a neural translation model for CS text that transduces monolingual Hindi sentences into realistic Hindi-English CS text. Text generated by our model is evaluated using a number of different objective metrics, along with LM, NLI and sentiment analysis tasks, and a detailed human evaluation study. The role of synthetic data in training such models merits a more detailed investigation which we leave for future work."
    }, {
      "heading" : "7 Acknowledgements",
      "text" : "We thank all the anonymous reviewers for their constructive feedback which helped improve the presentation of this work. We also thank all the volunteers who helped with the collection of CS text that is released as part of our dataset, All-CS."
    }, {
      "heading" : "A MTurk Task Details",
      "text" : "Figure 4 depicts the portal used to collect data using Amazon’s Mechanical Turk platform. The collection was done in two rounds, first for MovieCS and then for Treebank-CS. With Treebank-CS, the sentences were first divided into chunks and the Turkers were providedwith a sentence grouped into chunks as shown in Figure 4. They were required to switch at least one chunk in the sentence entirely to English so as to ensure a longer span of English words in the resulting CS sentence. A suggestion box converted transliterated Hindi words into Devanagari and also provided English suggestions to aid the workers in completing their task. With Movie-CS, since there were no chunk labels associated with the sentences, they were tokenized into words.\nOn MTurk, we selected workers with HIT approval rate of 90% and location restricted to countries with significant Hindi speakers - Australia, Bahrain, Canada, India, Kuwait, Malaysia, Mauritius, Myanmar, Nepal, Netherlands, New Zealand, Oman, Pakistan, Qatar, Saudi Arabia, Singapore, South Africa, Sri Lanka, Thailand, United Arab Emirates, UnitedKingdom, United States of America. It was clearly specified in the guidelines that the task must be attempted by native Hindi speakers. Each response was manually checked before approving. Turkers were paid $0.15 for working on 5 sentences (roughly takes 3-4 minutes). This amounts to $2.25-$3/hr which is in the ballpark of\na median hourly wage on MTurk of ~$2/hr (Hara et al., 2018)."
    }, {
      "heading" : "B EMT lines generation",
      "text" : "Following the methodology described in (Bhat et al., 2016), we apply clause substitution methodology to produce EMT sentences. To create OpSub-EMT, we start with the gold English sentence that contains either embedded sentence clauses (S) or subordinate clauses (SBAR) and swap one or more of them with their Hindi translations to produce an EMT synthetic CS sentence. Due to the lack of gold English translations available for All-CS sentences, we used the Google Translate API to first acquire their English translation. Many of the sentences in All-CS are shorter in length and do not contain the abovementioned clauses. So, we also considered inverted declarative sentence clauses (SINV), inverted question clauses (SQ) and direct question clauses (SBARQ) in addition to S and SBAR. In case none of the clause level tags were present, we considered the following phrase level tags as switching candidates: Noun Phrase (NP), Verb Phrase (VP), Adjective Phrase (ADJP) and Adverb Phase (ADVP). Owing to the shorter length and lack of clauselevel tags, we switch only one tag per sentence for All-CS-EMT. The choice of which clause to switch was made empirically by observing what switches caused the resulting sentence to resemble a naturally occurring CS sentence. One can also use the toolkit provided by Rizvi et al. (2021) for generating EMT lines.\nC Implementation Details: TCS\nAs an initialisation step, we learn the token embeddings (Mikolov et al., 2013) on the same corpus using skipgram. The embedding dimension was set to be 256 and the encoder-decoder layers share these lookup tables. Adam optimiser with a learning rate of 0.0001was used to train the model. Validation BLEU scores on (HI → ENG/CS) translations and (EN → HI → EN) reconstructions were used as metrics to save the best model for TCS (S) and TCS (U), respectively."
    }, {
      "heading" : "D Human Evaluation",
      "text" : "The 150 samples evaluated in Table 5 were taken entirely from test/validation splits. We undertook an alternate human evaluation experiment involving 100 real CS sentences and its corresponding\nCS sentences using LEX, EMT, TCS (U) and TCS (S). Out of these 100 sentences, 40 of them came entirely from the test and validation splits and the remaining 60 are training sentences which we filtered tomake sure that sentences generated by TCS (S) and TCS (U) never exactly matched the real CS sentence. The table below (Table 9) reports the evaluations on the complete set of 100 sentences from 5 datasets. We observe that the trend remains exactly the same as in Table 5, with TCS (S) being very close to real CS sentences in its evaluation and TCS (U) trailing behind TCS (S)."
    }, {
      "heading" : "E Language Model Training",
      "text" : "The AWD-LSTM language model was trained for 100 epochs with a batch size of 80 and a sequence length of 70 in each batch. The learning rate was set at 30. The model uses NT-ASGD, a variant of the averaged stochastic gradient method, to update the weights. The mix-review decay parameter was set to 0.9. This implies that the fraction of pretraining batches being considered at the end ofn epochs is 0.9n, starting from all batches initially. Two decay coefficients {0.8, 0.9} were tested and 0.9 was chosen based on validation perplexities."
    }, {
      "heading" : "F Code-switching examples",
      "text" : "The sentences in Table 10 have been generated on the test and validation splits of All-CS as well as the OpSub dataset. Overall, they depict how the model is able to retain context over long sentences (e.g. “and social sectors”) and performmeaningful switching over large spans of words (e.g. “old conversation writer media”, “regularly security practices”). We also note that at times, the model uses words which are different from the natural English translations of the sentence, which are appropriate within the context of a CS sentence (e.g. the use of “manage” instead of “manageable”)."
    }, {
      "heading" : "G Details of GLUECoS Experiments",
      "text" : "For masked language modeling (MLM), we select the default parameters for the learning rate (5e-5),\nbatch masking probability (0.15), sequence length (512). The models are trained for 2 epochs with a batch size of 4 and gradient accumulation step of 10. For task specific fine tuning we rely on the official training scripts provided by GLUECoS repository. 8 We train the models for 5 seed (0,1,2,3 and 4) and report mean and standard deviations of Accuracy and F1 for NLI and Sentiment Analysis respectively"
    }, {
      "heading" : "H Additional Dataset and Experiments",
      "text" : "Dataset The additional corpus on which experiments were performed is OPUS-100 (Zhang et al., 2020) which was sampled from the original OPUS corpus (Tiedemann, 2012). The primary difference between OpSub and OPUS-100 is that OpSub does not have manual Hindi translations\n8https://github.com/microsoft/GLUECoS\nGenerated using Movie-CS\nसारे पुराने बातचीत लेखक मी डया और राजनीित में जमा हो गए हैं (All the old conversation writers have gathered in media and politics) सारे old conversation writer media और politics में जमा हो गए हैं क्या बात है तुमने आखर बार कब पाट क थी (What is the last time you had a party) क्या बात है तुमने last time party कब क थी तू अपने कमरे में जा यार आप दोनों कृपया शांत हो जाओ (You go to your room man please relax both of you) तू अपने room में जा यार आप दोनों please calm down\nGenerated using TreebankCS\nयह पॉिलसी पित प ी के संयु नाम से थी (This policy was in the joint name of husband and wife) यह policy husband wife के joint नाम से थी स्कूलों में तो िनयिमत रूप से सुरक्षा अभ्यास कराए जाने लगे हैं (Regular safety exercises are being conducted in schools) schools में तो regularly security practice कये जाने लगे हैं इसमें बुिनयाद कृ ष और सामा जक के्षऽों में सावर्जिनक िनवेशभी शािमल है (It also includes public investment in basic agricultural and social sectors) इसमें बुिनयाद farming and social areas में public investment भी शािमल है\nof its sentences and requires the use of an external API such as Google Translate for translation. However, OPUS-100 has manually annotated sentences as part of the corpus. The source of OPUS-100 ranges from movie subtitles to GNOME documentation to the Bible. We extract 340K sentences from OPUS-100 corpus after thresholding on length (5-15). We offer this comparison of systems trained on OpSub and OPUS-100 to show how our models fare when using two datasets that are very different in their composition.\nLEX lines generation. Generation of LEX lines is straightforward and requires only a bilingual lexicon. For each monolingual Hindi sentence we generate ~5 sentences on OPUS-100 resulting in OPUS-100-LEX (to roughly match the size of OpSub-LEX).\nEMT lines generation. For generation of EMT lines we have two strategies depending on the availability of tools (parsers, translation service, aligners, etc). The first strategy requires a translation service (either in-house or publicly available). We substitute the embedded clause from parse trees of English sentences with their Hindi translations. This strategy does not require a parallel Hindi corpus and has been previously used for generating OpSub-EMT and All-CS-EMT (Described in detail in Appendix B).\nThe second strategy, that is used to generate OPUS-100-EMT, requires a parallel corpus, a constituent parser in English and a word aligner between parallel sentences. OPUS-100 sentences are aligned using SimAlign (Jalili Sabet et al., 2020) and embedded clauses from parse trees of English sentences are replaced by Hindi clauses using word aligners. Here again, for each monolingual Hindi sentenece we generate ~5 EMT sentences (strategy-2) on OPUS-100 resulting in OPUS-100-EMT.\nCurriculum Training Experiments. Table 11 provides a walkthrough of systems using various training curricula that are evaluated for two different choices of datasets - OpSub vs OPUS-100 differing in the generation of EMT lines. The models are evaluated using BLEU (Papineni et al., 2002) scores computed on the test set of All-CS. The vo-\ncabulary is generated by combining train sets of all datasets to be used in the curricula. It is 126,576 when X = OpSub and 164,350 when X = OPUS100 (OpSub shows a higher overlap in vocabulary with All-CS compared to OPUS-100). The marginal difference in System O for OpSub and OPUS-100 is attributed to differences in the size of the vocabulary. OpSub being conversational in nature, is a better pretraining corpus compared to OPUS-100 as seen from System A, the sources of the latter being GNOME documentations and The Bible, apart from movie subtitles.\nThe results for C1, C2, D1, D2 are consistently better when X = OpSub versus when X = OPUS100. We choose to highlight four models from Table 11 which together demonstrate multiple use-cases of TCS in Table 12. TCS (LEX) refers to (C2, X=OpSub), TCS (U) refers to (D1, X=OpSub), TCS (S) refers to (D2, X=OpSub) and TCS (simalign) refers to (D2, X=OPUS-100).\nLanguage Modelling Experiments. Table 13 shows results from LM experiments (using the same setup as in Section 5.2.1). The values for TCS (S) and TCS (U) have been reproduced here\nfor ease of comparison. (Note that TCS (simalign) does not perform as well as the other models since the sentences for training the language model are generated on OpSub for all the models here, but TCS (simalign) has been trained on OPUS-100.)\nEvaluation Metrics. Table 14 shows the results of the three objective evaluation metrics on the additional TCS models. In comparison with the results in Table 8, we observe that TCS (LEX) and TCS (simalign) perform comparably to TCS (S) and TCS (U) on all metrics."
    } ],
    "references" : [ {
      "title" : "Syntactic and semantic features for code-switching factored language models",
      "author" : [ "Heike Adel", "Ngoc Thang Vu", "Katrin Kirchhoff", "Dominic Telaar", "Tanja Schultz." ],
      "venue" : "IEEE/ACM transactions on audio, speech, and language Processing, 23(3):431–440.",
      "citeRegEx" : "Adel et al\\.,? 2015",
      "shortCiteRegEx" : "Adel et al\\.",
      "year" : 2015
    }, {
      "title" : "Recurrent neural network language modeling for code switching conversational speech",
      "author" : [ "Heike Adel", "Ngoc Thang Vu", "Franziska Kraus", "Tim Schlippe", "Haizhou Li", "Tanja Schultz." ],
      "venue" : "2013 IEEE International Conference on Acoustics, Speech and",
      "citeRegEx" : "Adel et al\\.,? 2013",
      "shortCiteRegEx" : "Adel et al\\.",
      "year" : 2013
    }, {
      "title" : "Amazon mechanical turk website",
      "author" : [ "Amazon." ],
      "venue" : "Visited on 2020-01-02.",
      "citeRegEx" : "Amazon.,? 2005",
      "shortCiteRegEx" : "Amazon.",
      "year" : 2005
    }, {
      "title" : "Grammatical constraints on intra-sentential code-switching:from theories to working models",
      "author" : [ "Gayatri Bhat", "Monojit Choudhury", "Kalika Bali." ],
      "venue" : "arXiv:1612.04538.",
      "citeRegEx" : "Bhat et al\\.,? 2016",
      "shortCiteRegEx" : "Bhat et al\\.",
      "year" : 2016
    }, {
      "title" : "Code-Switching Sentence Generation by Generative Adversarial Networks and its Application to Data Augmentation",
      "author" : [ "Ching-Ting Chang", "Shun-Po Chuang", "Hung-Yi Lee." ],
      "venue" : "Proc. Interspeech 2019, pages 554–558.",
      "citeRegEx" : "Chang et al\\.,? 2019",
      "shortCiteRegEx" : "Chang et al\\.",
      "year" : 2019
    }, {
      "title" : "Word translation without parallel data",
      "author" : [ "Alexis Conneau", "Guillaume Lample", "Marc’Aurelio Ranzato", "Ludovic Denoyer", "Hervé Jégou" ],
      "venue" : "arXiv preprint arXiv:1710.04087",
      "citeRegEx" : "Conneau et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2017
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "CoRR, abs/1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Enabling code-mixed translation: Parallel corpus creation and MT augmentation approach",
      "author" : [ "Mrinal Dhar", "Vaibhav Kumar", "Manish Shrivastava." ],
      "venue" : "Proceedings of the First Workshop on Linguistic Resources for Natural Language Processing, pages",
      "citeRegEx" : "Dhar et al\\.,? 2018",
      "shortCiteRegEx" : "Dhar et al\\.",
      "year" : 2018
    }, {
      "title" : "A new algorithm for data compression",
      "author" : [ "Philip Gage." ],
      "venue" : "C Users J., 12(2):23–38.",
      "citeRegEx" : "Gage.,? 1994",
      "shortCiteRegEx" : "Gage.",
      "year" : 1994
    }, {
      "title" : "Code-switching sentence generation by bert and generative adversarial networks",
      "author" : [ "Yingying Gao", "Junlan Feng", "Ying Liu", "Leijing Hou", "Xin Pan", "Yong Ma." ],
      "venue" : "INTERSPEECH, pages 3525–3529.",
      "citeRegEx" : "Gao et al\\.,? 2019",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Code-switched language models using dual RNNs and same-source pretraining",
      "author" : [ "Saurabh Garg", "Tanmay Parekh", "Preethi Jyothi." ],
      "venue" : "Proceedings of the 2018Conference on EmpiricalMethods in Natural Language Processing, pages 3078–3083, Brus-",
      "citeRegEx" : "Garg et al\\.,? 2018a",
      "shortCiteRegEx" : "Garg et al\\.",
      "year" : 2018
    }, {
      "title" : "Dual language models for code switched speech recognition",
      "author" : [ "Saurabh Garg", "Tanmay Parekh", "Preethi Jyothi." ],
      "venue" : "Proceedings of Interspeech, pages 2598–2602.",
      "citeRegEx" : "Garg et al\\.,? 2018b",
      "shortCiteRegEx" : "Garg et al\\.",
      "year" : 2018
    }, {
      "title" : "Comet: Towards code-mixed translation using parallel monolingual sentences",
      "author" : [ "Devansh Gautam", "Prashant Kodali", "Kshitij Gupta", "Anmol Goel", "Manish Shrivastava", "Ponnurangam Kumaraguru." ],
      "venue" : "Proceedings of the Fifth Workshop on Computa-",
      "citeRegEx" : "Gautam et al\\.,? 2021",
      "shortCiteRegEx" : "Gautam et al\\.",
      "year" : 2021
    }, {
      "title" : "Training data augmentation for code-mixed translation",
      "author" : [ "Abhirut Gupta", "Aditya Vavre", "Sunita Sarawagi." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
      "citeRegEx" : "Gupta et al\\.,? 2021",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2021
    }, {
      "title" : "Metrics for modeling code-switching across corpora",
      "author" : [ "Gualberto A. Guzmán", "Joseph Ricard", "Jacqueline Serigos", "Barbara E. Bullock", "Almeida Jacqueline Toribio." ],
      "venue" : "INTERSPEECH.",
      "citeRegEx" : "Guzmán et al\\.,? 2017",
      "shortCiteRegEx" : "Guzmán et al\\.",
      "year" : 2017
    }, {
      "title" : "A Data-Driven Analysis of Workers’ Earnings on Amazon Mechanical Turk, page 1–14",
      "author" : [ "Kotaro Hara", "Abigail Adams", "Kristy Milland", "Saiph Savage", "Chris Callison-Burch", "Jeffrey P. Bigham." ],
      "venue" : "Association for Computing Machinery, New York,",
      "citeRegEx" : "Hara et al\\.,? 2018",
      "shortCiteRegEx" : "Hara et al\\.",
      "year" : 2018
    }, {
      "title" : "Analyzing the forgetting problem in pretrain-finetuning of open-domain dialogue response models",
      "author" : [ "Tianxing He", "Jun Liu", "Kyunghyun Cho", "Myle Ott", "Bing Liu", "James Glass", "Fuchun Peng." ],
      "venue" : "Proceedings of the 16th Conference of the European Chap-",
      "citeRegEx" : "He et al\\.,? 2021",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2021
    }, {
      "title" : "SimAlign: High quality word alignments without parallel training data using static and contextualized embeddings",
      "author" : [ "Masoud Jalili Sabet", "Philipp Dufter", "François Yvon", "Hinrich Schütze." ],
      "venue" : "Findings of the Association for Computational Linguis-",
      "citeRegEx" : "Sabet et al\\.,? 2020",
      "shortCiteRegEx" : "Sabet et al\\.",
      "year" : 2020
    }, {
      "title" : "GLUECoS: An evaluation benchmark for code-switched NLP",
      "author" : [ "Simran Khanuja", "Sandipan Dandapat", "Anirudh Srinivasan", "Sunayana Sitaram", "Monojit Choudhury." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Khanuja et al\\.,? 2020",
      "shortCiteRegEx" : "Khanuja et al\\.",
      "year" : 2020
    }, {
      "title" : "The IIT bombay english-hindi parallel corpus",
      "author" : [ "Anoop Kunchukuttan", "Pratik Mehta", "Pushpak Bhattacharyya." ],
      "venue" : "CoRR, abs/1710.02855.",
      "citeRegEx" : "Kunchukuttan et al\\.,? 2017",
      "shortCiteRegEx" : "Kunchukuttan et al\\.",
      "year" : 2017
    }, {
      "title" : "Unsupervised machine translation using monolingual corpora only",
      "author" : [ "Guillaume Lample", "Alexis Conneau", "Ludovic Denoyer", "Marc’Aurelio Ranzato" ],
      "venue" : "In International Conference on Learning Representations",
      "citeRegEx" : "Lample et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2018
    }, {
      "title" : "2018b. Phrase-based & neural unsupervised machine translation",
      "author" : [ "Guillaume Lample", "Myle Ott", "Alexis Conneau", "Ludovic Denoyer", "Marc’Aurelio Ranzato" ],
      "venue" : "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Lample et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2018
    }, {
      "title" : "Modeling codeswitch languages using bilingual parallel corpus",
      "author" : [ "Grandee Lee", "Haizhou Li." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 860– 870, Online. Association for Computational Linguis-",
      "citeRegEx" : "Lee and Li.,? 2020",
      "shortCiteRegEx" : "Lee and Li.",
      "year" : 2020
    }, {
      "title" : "Improved mixed language speech recognition using asymmetric acoustic model and language model with code-switch inversion constraints",
      "author" : [ "Ying Li", "Pascale Fung." ],
      "venue" : "2013 IEEE International Conference on Acoustics, Speech and Signal Processing,",
      "citeRegEx" : "Li and Fung.,? 2013",
      "shortCiteRegEx" : "Li and Fung.",
      "year" : 2013
    }, {
      "title" : "Code switch language modeling with functional head constraint",
      "author" : [ "Ying Li", "Pascale Fung." ],
      "venue" : "2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 4913–4917.",
      "citeRegEx" : "Li and Fung.,? 2014a",
      "shortCiteRegEx" : "Li and Fung.",
      "year" : 2014
    }, {
      "title" : "Language modeling with functional head constraint for code switching",
      "author" : [ "Ying Li", "Pascale Fung" ],
      "venue" : null,
      "citeRegEx" : "Li and Fung.,? \\Q2014\\E",
      "shortCiteRegEx" : "Li and Fung.",
      "year" : 2014
    }, {
      "title" : "Opensubtitles2016: Extracting large parallel corpora from movie and tv subtitles",
      "author" : [ "Pierre Lison", "Jörg Tiedemann." ],
      "venue" : "LREC.",
      "citeRegEx" : "Lison and Tiedemann.,? 2016",
      "shortCiteRegEx" : "Lison and Tiedemann.",
      "year" : 2016
    }, {
      "title" : "Multilingual denoising pretraining for neural machine translation",
      "author" : [ "Yinhan Liu", "Jiatao Gu", "Naman Goyal", "Xian Li", "Sergey Edunov", "Marjan Ghazvininejad", "Mike Lewis", "Luke Zettlemoyer." ],
      "venue" : "Transactions of the Association for Computational Linguis-",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Regularizing and optimizing LSTM language models",
      "author" : [ "Stephen Merity", "Nitish Shirish Keskar", "Richard Socher." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Merity et al\\.,? 2018",
      "shortCiteRegEx" : "Merity et al\\.",
      "year" : 2018
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "CoRR, abs/1310.4546.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Bleu: A method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "ToddWard", "andWeiJing Zhu" ],
      "venue" : "In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,",
      "citeRegEx" : "Papineni et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "How multilingual is multilingual BERT? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4996– 5001, Florence, Italy",
      "author" : [ "Telmo Pires", "Eva Schlinger", "Dan Garrette." ],
      "venue" : "Association for Computational",
      "citeRegEx" : "Pires et al\\.,? 2019",
      "shortCiteRegEx" : "Pires et al\\.",
      "year" : 2019
    }, {
      "title" : "sometimes i’ll start a sentence in spanish y termino en español”: Toward a typology of code-switching",
      "author" : [ "Shana Poplack" ],
      "venue" : null,
      "citeRegEx" : "Poplack.,? \\Q1979\\E",
      "shortCiteRegEx" : "Poplack.",
      "year" : 1979
    }, {
      "title" : "Language modeling for code-mixing: The role of linguistic theory based synthetic data",
      "author" : [ "Adithya Pratapa", "Gayatri Bhat", "Monojit Choudhury", "Sunayana Sitaram", "Sandipan Dandapat", "Kalika Bali." ],
      "venue" : "Proceedings of ACL 2018. ACL.",
      "citeRegEx" : "Pratapa et al\\.,? 2018",
      "shortCiteRegEx" : "Pratapa et al\\.",
      "year" : 2018
    }, {
      "title" : "Gcm: A toolkit for generating synthetic code-mixed text",
      "author" : [ "Mohd Sanad Zaki Rizvi", "Anirudh Srinivasan", "T. Ganu", "M. Choudhury", "Sunayana Sitaram." ],
      "venue" : "EACL.",
      "citeRegEx" : "Rizvi et al\\.,? 2021",
      "shortCiteRegEx" : "Rizvi et al\\.",
      "year" : 2021
    }, {
      "title" : "A deep generative model for code switched text",
      "author" : [ "Bidisha Samanta", "Sharmila Reddy", "Hussain Jagirdar", "Niloy Ganguly", "Soumen Chakrabarti." ],
      "venue" : "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-",
      "citeRegEx" : "Samanta et al\\.,? 2019",
      "shortCiteRegEx" : "Samanta et al\\.",
      "year" : 2019
    }, {
      "title" : "A formal production-based explanation of the facts of code-switching",
      "author" : [ "David Sankoff." ],
      "venue" : "Bilingualism: Language and Cognition, 1(1):39–50.",
      "citeRegEx" : "Sankoff.,? 1998",
      "shortCiteRegEx" : "Sankoff.",
      "year" : 1998
    }, {
      "title" : "Improving neural machine translation models with monolingual data",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "CoRR, abs/1511.06709.",
      "citeRegEx" : "Sennrich et al\\.,? 2015",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2015
    }, {
      "title" : "Parallel data, tools and interfaces in OPUS",
      "author" : [ "Jörg Tiedemann." ],
      "venue" : "Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC’12), pages 2214–2218, Istanbul, Turkey. European Language Resources Association",
      "citeRegEx" : "Tiedemann.,? 2012",
      "shortCiteRegEx" : "Tiedemann.",
      "year" : 2012
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "CoRR, abs/1706.03762.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Pointer networks",
      "author" : [ "Oriol Vinyals", "Meire Fortunato", "Navdeep Jaitly." ],
      "venue" : "Advances in neural information processing systems, pages 2692–2700.",
      "citeRegEx" : "Vinyals et al\\.,? 2015",
      "shortCiteRegEx" : "Vinyals et al\\.",
      "year" : 2015
    }, {
      "title" : "A first speech recognition system for mandarinenglish code-switch conversational speech",
      "author" : [ "Ngoc Thang Vu", "Dau-Cheng Lyu", "Jochen Weiner", "Dominic Telaar", "Tim Schlippe", "Fabian Blaicher", "EngSiong Chng", "Tanja Schultz", "Haizhou Li." ],
      "venue" : "In",
      "citeRegEx" : "Vu et al\\.,? 2012",
      "shortCiteRegEx" : "Vu et al\\.",
      "year" : 2012
    }, {
      "title" : "Learn to code-switch: Data augmentation using copy mechanism on language modeling",
      "author" : [ "Genta Indra Winata", "Andrea Madotto", "Chien-Sheng Wu", "Pascale Fung." ],
      "venue" : "CoRR, abs/1810.10254.",
      "citeRegEx" : "Winata et al\\.,? 2018",
      "shortCiteRegEx" : "Winata et al\\.",
      "year" : 2018
    }, {
      "title" : "Code-switched language models using neural based synthetic data from parallel sentences",
      "author" : [ "Genta Indra Winata", "Andrea Madotto", "Chien-Sheng Wu", "Pascale Fung." ],
      "venue" : "CoNLL.",
      "citeRegEx" : "Winata et al\\.,? 2019",
      "shortCiteRegEx" : "Winata et al\\.",
      "year" : 2019
    }, {
      "title" : "An integrated framework for transcribing mandarin-english code-mixed lectures with improved acoustic and language modeling",
      "author" : [ "Ching Feng Yeh", "Chao Yu Huang", "Liang Che Sun", "Lin Shan Lee" ],
      "venue" : null,
      "citeRegEx" : "Yeh et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Yeh et al\\.",
      "year" : 2010
    }, {
      "title" : "Seqgan: Sequence generative adversarial nets with policy gradient",
      "author" : [ "Lantao Yu", "Weinan Zhang", "Jun Wang", "Yong Yu." ],
      "venue" : "Thirty-First AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Yu et al\\.,? 2017",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2017
    }, {
      "title" : "Improving massively multilingual neural machine translation and zero-shot translation",
      "author" : [ "Biao Zhang", "Philip Williams", "Ivan Titov", "Rico Sennrich." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1628–",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Bertscore: Evaluating text generation with bert",
      "author" : [ "Tianyi Zhang", "Varsha Kishore", "Felix Wu", "Kilian Q. Weinberger", "Yoav Artzi" ],
      "venue" : "In International Conference on Learning Representations",
      "citeRegEx" : "Zhang. et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Zhang. et al\\.",
      "year" : 2020
    }, {
      "title" : "Texygen: A benchmarking platform for text generation models",
      "author" : [ "Yaoming Zhu", "Sidi Lu", "Lei Zheng", "Jiaxian Guo", "Weinan Zhang", "Jun Wang", "Yong Yu." ],
      "venue" : "The 41st International ACM SIGIR Conference on Research Development in In-",
      "citeRegEx" : "Zhu et al\\.,? 2018",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2018
    }, {
      "title" : "A universal algorithm for sequential data compression",
      "author" : [ "J. Ziv", "A. Lempel." ],
      "venue" : "IEEE Transactions on Information Theory, 23(3):337–343.",
      "citeRegEx" : "Ziv and Lempel.,? 1977",
      "shortCiteRegEx" : "Ziv and Lempel.",
      "year" : 1977
    }, {
      "title" : "2021) for generating EMT lines. C Implementation Details: TCS As an initialisation step, we learn the token embeddings (Mikolov et al., 2013) on the same corpus",
      "author" : [ "Rizvi" ],
      "venue" : null,
      "citeRegEx" : "Rizvi,? \\Q2013\\E",
      "shortCiteRegEx" : "Rizvi",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "), factored language models that exploited a large number of syntactic and semantic features (Adel et al., 2015), and recurrent neural language models (Adel et al.",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 1,
      "context" : ", 2015), and recurrent neural language models (Adel et al., 2013) for CS text.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 11,
      "context" : "Towards alleviating this dependence on real CS text, there has been prior work on learning code-switched language models from bilingual data (Li and Fung, 2014b,a; Garg et al., 2018b) and a more recent direction that explores the possibility of generating synthetic CS sentences.",
      "startOffset" : 141,
      "endOffset" : 183
    }, {
      "referenceID" : 33,
      "context" : "(Pratapa et al., 2018) presents a technique to generate synthetic CS text that grammatically adheres to a linguistic theory",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 32,
      "context" : "of code-switching known as the equivalence constraint (EC) theory (Poplack, 1979; Sankoff, 1998).",
      "startOffset" : 66,
      "endOffset" : 96
    }, {
      "referenceID" : 36,
      "context" : "of code-switching known as the equivalence constraint (EC) theory (Poplack, 1979; Sankoff, 1998).",
      "startOffset" : 66,
      "endOffset" : 96
    }, {
      "referenceID" : 45,
      "context" : "(2018a) use a sequence generative adversarial network (SeqGAN (Yu et al., 2017)) trained on real CS text to generate sentences that are used to aid language model training.",
      "startOffset" : 62,
      "endOffset" : 79
    }, {
      "referenceID" : 40,
      "context" : "use a sequence-to-sequence model enabled with a copy mechanism (Pointer Network (Vinyals et al., 2015)) to generate CS data by leveraging parallel monolingual translations from a limited source of CS data.",
      "startOffset" : 80,
      "endOffset" : 102
    }, {
      "referenceID" : 41,
      "context" : "The idea of using translation models for codeswitching has been explored in early work (Vu et al., 2012; Li and Fung, 2013; Dhar et al., 2018).",
      "startOffset" : 87,
      "endOffset" : 142
    }, {
      "referenceID" : 23,
      "context" : "The idea of using translation models for codeswitching has been explored in early work (Vu et al., 2012; Li and Fung, 2013; Dhar et al., 2018).",
      "startOffset" : 87,
      "endOffset" : 142
    }, {
      "referenceID" : 7,
      "context" : "The idea of using translation models for codeswitching has been explored in early work (Vu et al., 2012; Li and Fung, 2013; Dhar et al., 2018).",
      "startOffset" : 87,
      "endOffset" : 142
    }, {
      "referenceID" : 27,
      "context" : "Powerful pretrained models like mBART (Liu et al., 2020) have been used for codemixed translation tasks in concurrent work (Gautam et al.",
      "startOffset" : 38,
      "endOffset" : 56
    }, {
      "referenceID" : 12,
      "context" : ", 2020) have been used for codemixed translation tasks in concurrent work (Gautam et al., 2021).",
      "startOffset" : 74,
      "endOffset" : 95
    }, {
      "referenceID" : 39,
      "context" : "The model comprises of three layers of stacked Transformer (Vaswani et al., 2017) encoder and decoder layers, two of which are shared and the remaining layer is private to each language.",
      "startOffset" : 59,
      "endOffset" : 81
    }, {
      "referenceID" : 37,
      "context" : "(II) Backtranslation (BT): Once the layers are initialized, one can use non-parallel text in both languages to generate a pseudo-parallel corpus of backtranslated pairs (Sennrich et al., 2015).",
      "startOffset" : 169,
      "endOffset" : 192
    }, {
      "referenceID" : 5,
      "context" : "The first technique (named LEX) is a simple heuristic-based technique that constructs a CS sentence by traversing a Hindi sentence and randomly replacing a word by its English translation using a bilingual lexicon (Conneau et al., 2017).",
      "startOffset" : 214,
      "endOffset" : 236
    }, {
      "referenceID" : 2,
      "context" : "Using these monolingual Hindi sentences as a starting point, we additionally crowdsourced for CS sentences via Amazon’s Mechanical Turk (MTurk) (Amazon, 2005).",
      "startOffset" : 144,
      "endOffset" : 158
    }, {
      "referenceID" : 19,
      "context" : "For this purpose, we use the IIT Bombay English-Hindi Corpus (Kunchukuttan et al., 2017) containing parallel Hindi-English text.",
      "startOffset" : 61,
      "endOffset" : 88
    }, {
      "referenceID" : 26,
      "context" : "We also construct a larger parallel corpus using text from the OpenSubtitles (OpSub) corpus (Lison and Tiedemann, 2016) that is more conversational and hence more similar in style to Movie-CS.",
      "startOffset" : 92,
      "endOffset" : 119
    }, {
      "referenceID" : 46,
      "context" : "(One could avoid the use of an external service like Google Translate and use existing parallel text (Zhang et al., 2020)) in conjunction with a word aligner to construct EMT lines.",
      "startOffset" : 101,
      "endOffset" : 121
    }, {
      "referenceID" : 35,
      "context" : "(I) VACS (Samanta et al., 2019) is a hierarchical variational autoencoder-based model designed to generate CS text.",
      "startOffset" : 9,
      "endOffset" : 31
    }, {
      "referenceID" : 45,
      "context" : "(2018a) use SeqGAN (Yu et al., 2017) – a GAN-based sequence generation model – to generate CS sentences by providing an RNNLM as the generator.",
      "startOffset" : 19,
      "endOffset" : 36
    }, {
      "referenceID" : 30,
      "context" : "Table 3 shows the importance of various training curricula in training TCS; these models are evaluated using BLEU (Papineni et al., 2002) scores computed with the ground-truth CS sentences for",
      "startOffset" : 114,
      "endOffset" : 137
    }, {
      "referenceID" : 18,
      "context" : "GLUECoS (Khanuja et al., 2020) is an evaluation benchmark spanning six natural language tasks for code-switched English-Hindi and English-Spanish data.",
      "startOffset" : 8,
      "endOffset" : 30
    }, {
      "referenceID" : 31,
      "context" : "The authors observe that M-BERT (Pires et al., 2019) consistently outperforms cross-lingual embedding techniques.",
      "startOffset" : 32,
      "endOffset" : 52
    }, {
      "referenceID" : 47,
      "context" : "BERTScore (Zhang* et al., 2020) is a recently-proposed evaluation metric for text generation.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 6,
      "context" : "Similarity scores are computed between each token in the candidate sentence and each token in the reference sentence, using contextual BERT embeddings (Devlin et al., 2018) of the tokens.",
      "startOffset" : 151,
      "endOffset" : 172
    }, {
      "referenceID" : 31,
      "context" : "Since our data is Hindi-English CS text, we use Multilingual BERT (M-BERT) (Pires et al., 2019) for high-quality multilingual representations.",
      "startOffset" : 75,
      "endOffset" : 95
    }, {
      "referenceID" : 31,
      "context" : "In this evaluation, we use M-BERT (Pires et al., 2019) to build a classifier that distinguishes real CS sentences from synthetically generated ones (fake).",
      "startOffset" : 34,
      "endOffset" : 54
    }, {
      "referenceID" : 8,
      "context" : "7 We considered using Byte Pair Encoding (BPE) (Gage, 1994) as a measure of data compression.",
      "startOffset" : 47,
      "endOffset" : 59
    }, {
      "referenceID" : 49,
      "context" : "gzip uses Lempel-Ziv coding (Ziv and Lempel, 1977) that considers substrings of characters during compression, thus allowing for diversity in word ordering to be captured.",
      "startOffset" : 28,
      "endOffset" : 50
    } ],
    "year" : 0,
    "abstractText" : "Generating code-switched text is a problem of growing interest, especially given the scarcity of corpora containing large volumes of real code-switched text. In this work, we adapt a state-of-the-art neural machine translation model to generate Hindi-English codeswitched sentences starting from monolingual Hindi sentences. We outline a carefully designed curriculum of pretraining steps, including the use of synthetic code-switched text, that enable themodel to generate high-quality codeswitched text. Using text generated from our model as data augmentation, we show significant reductions in perplexity on a language modeling task, compared to using text from other generative models of CS text. We also show improvements using our text for a downstream code-switched natural language inference task. Our generated text is further subjected to a rigorous evaluation using a human evaluation study and a range of objective metrics, where we show performance comparable (and sometimes even superior) to codeswitched text obtained via crowd workers who are native Hindi speakers.",
    "creator" : null
  }
}