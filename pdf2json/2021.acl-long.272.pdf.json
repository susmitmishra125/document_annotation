{
  "name" : "2021.acl-long.272.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Diversifying Dialog Generation via Adaptive Label Smoothing",
    "authors" : [ "Yida Wang", "Yinhe Zheng", "Yong Jiang", "Minlie Huang" ],
    "emails" : [ "wangyd18@mails.tsinghua.edu.cn,", "yh.zheng@samsung.com,", "jiangy@sz.tsinghua.edu.cn,", "aihuang@tsinghua.edu.cn", "aihuang@tsinghua.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3507–3520\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3507"
    }, {
      "heading" : "1 Introduction",
      "text" : "The success of neural models has greatly advanced the research of dialog generation (Huang et al., 2020; Wang et al., 2020; Zhang et al., 2020). However, most of these models suffer from a lowdiversity issue where models tend to generate bland and generic responses such as I don’t know or I’m OK (Li et al., 2016). Although various approaches have been proposed to tackle this issue (Li et al., 2016; Zhao et al., 2017; Du et al., 2018; Zhou et al., 2018; Welleck et al., 2020; Zheng et al., 2020b), there are still remarkable gaps between responses generated by neural models and those from humans (Holtzman et al., 2020). Further, some existing methods may even harm the fluency or coherence when improving the diversity of generated\n∗ Equal contribution † Corresponding Author: aihuang@tsinghua.edu.cn\nresponses. (Ippolito et al., 2019; Massarelli et al., 2020; Zheng et al., 2020a).\nRecently, Jiang and de Rijke (2018); Jiang et al. (2019) show that there is a strong connection between the low-diversity problem and the overconfidence issue. i.e., over-confident dialogue models tend to produce low-diversity responses. One of the reasons can be attributed to the supervision target. Specifically, training a dialogue generation model with the Maximum Likelihood Estimation (MLE) objective under the hard target (i.e., one-hot distribution as ground truth) makes the model favor high-frequency tokens and produce over-confident probability estimation (Gowda and May, 2020), which ultimately leads to poor calibration (Mukhoti et al., 2020), and thus low diversity (Jiang et al., 2019). Hinton et al. (2015) and Yang et al. (2018) suggest that the ideal training target should be a soft target that assigns probability mass on multiple valid candidates (see Figure 1). With such a soft target, the over-confidence issue can be alleviated (Müller et al., 2019), and thus the diversity of the output responses can be improved.\nUnfortunately, the ideal soft target is challenging to obtain. Early works try to tackle this issue\nusing label smoothing (Szegedy et al., 2016), i.e., a small probability is uniformly assigned to nontarget words. However, the target distribution constructed in this way is far from ideal: First, the probability of the target word is chosen manually and fixed, which cannot adapt to different contexts. However, as Holtzman et al. (2020) demonstrated, human text distribution exhibits remarkable fluctuations in the per-token perplexity. We argue that different target probabilities should be used for different contexts. Second, the uniform assignment of the probability mass on non-target words ignores the semantic relationship between the context and each word. Ideally, a word should receive more probability mass if it is more relevant to the context. For the example shown in Figure 1, word “fun” is more likely to appear behind the context “I make the robots seem more ” than word “bank”.\nTo address the above issue, we propose an Adaptive Label smoothing (AdaLabel) method that can dynamically estimate a soft target distribution at each time step for different contexts. Specifically, for each target word yt in the training data, the probability distribution predicted by the current model is first obtained. The maximum probability pmax in this distribution measures the confidence of the current prediction, i.e., a higher pmax means higher confidence for the current prediction. To avoid over-confidence, we use pmax as the supervision signal for the target word yt in the training process so that the model will not be optimized towards yt when it correctly predicts yt. A word-level factor is also introduced to facilitate the learning of low-frequency words.\nMoreover, we introduce a novel auxiliary decoder module Da to produce the supervision signals for these non-target words in each training step. Da only contains one transformer block, and it is optimized to predict words based on bi-directional contexts. A novel Target-Mask attention scheme is devised to prevent Da from seeing the target word in the training process. This scheme also enables parallel training and inference of Da.\nWe perform extensive experiments on two benchmark datasets: DailyDialog and OpenSubtitles. Our method outperforms various competitive baselines and significantly improves the diversity of generated responses while ensuring fluency and coherency. Our major contributions are summarized:\n1. We propose AdaLabel, a method that can produce a soft target distribution considering the\ncurrent context and the model’s confidence. Specifically, AdaLabel ensures that the dialogue model will not be optimized toward the target word yt if yt has been correctly predicted. This prevents our model from being over-confident.\n2. We introduce a light-weight bi-directional decoder that can produce context-aware supervision signals for non-target words. A novel Target-Mask attention scheme is devised to facilitate the parallel training and inference of this decoder.\n3. Extensive experiments on two benchmark dialogue datasets with both automatic and human evaluation results show that our method helps to alleviate the model over-confident issue and significantly improves the model’s diversity."
    }, {
      "heading" : "2 Related work",
      "text" : "Diversity Promotion: Existing approaches for solving the low diversity issue of neural dialogue models generally involve two categories:\nThe first category is training-based, where new training objectives are designed (Li et al., 2016; Zhang et al., 2018; Gao et al., 2019) or latent variables are introduced (Zhao et al., 2017; Zhou et al., 2018) in the dialogue model. Some methods also try to refine the training target used in the MLE loss (Choi et al., 2020; Jiang et al., 2019; Li et al., 2019), or directly penalize the trivial responses with auxiliary loss terms (Welleck et al., 2020; Li et al., 2020). Unlike these existing approaches, our method tries to adaptively adjust the training target by utilizing the current predictions.\nThe second category is decoding-based, in which different heuristic decoding rules are designed (Holtzman et al., 2020; Kulikov et al., 2019). Note that these decoding techniques are independent of the model setting, and our method can be used in combination with these techniques.\nConfidence Calibration: Modern deep neural networks suffer from the over-confidence issue (Guo et al., 2017; Kumar and Sarawagi, 2019), and various remedies are proposed (Pereyra et al., 2017; Mukhoti et al., 2020; Lin et al., 2017). Following the work of Jiang and de Rijke (2018); Jiang et al. (2019), our method is proposed to tackle the overconfidence issue to improve the diversity of the generated responses. However, different from existing approaches, our method enables more flexible controls over the target distribution.\nKnowledge Distillation: Another important technique similar to our work is knowledge distilla-\ntion, in which a learned teacher model is distilled to a student model by minimizing a KL term (Hinton et al., 2015; Kim and Rush, 2016).\nThe most related work comparing to ours is the C-MLM approach (Chen et al., 2020), in which a BERT model is fine-tuned to be a teacher. Our approach and C-MLM’s primary difference is that our auxiliary decoder Da is a one layer module that is jointly trained with the dialogue model. However, the BERT teacher in C-MLM contains much more parameters, and it is trained using an expensive pretrained and then fine-tuned process. Moreover, the target-masked attention scheme in Da enables parallel inferences of v for each training sequence Y . In contrast, multiple independent forward passes are required for the BERT teacher."
    }, {
      "heading" : "3 Method",
      "text" : ""
    }, {
      "heading" : "3.1 Background: MLE with Hard Target",
      "text" : "The goal of generative dialogue modeling is to learn a conditional probability distribution p(Y |X), where X is the dialogue context, Y = y1, ..., yT is a response word sequence, and yi ∈ V is a word from the vocabulary V . In an auto-regressive manner, p(Y |X) is factorized as ∏ t p(yt|y<t, X). For each target word yt in the training sequence Y , a conventional MLE training approach try to optimize the following cross entropy loss:\nL(q,p) = − ∑ wk∈V qklog [p(wk|y<t, X)] , (1)\nwhere q is a one-hot distribution (i.e., a hard target) that assigns a probability of 1 for the target word yt and 0 otherwise, i.e., qk = 1 only when wk = yt. For simplicity of notation, we abbreviate\nthe dependency of yt in the notation of each distribution in our paper, i.e., different target word yt in Y corresponds to different values of q and p."
    }, {
      "heading" : "3.2 Method Overview",
      "text" : "We propose to adaptively construct a soft target distribution q′ to replace q in Eq. 1. Specifically,\nq′ = ε · q + (1− ε) · v, (2)\nwhere ε ∈ [0, 1] is an adaption factor, and v is an auxiliary distribution vector that depends on the current time step. (see Figure 2 for an overview).\nIn this study, we constrain v to assign zero probability for the target word yt and non-zero probabilities for these non-target words V6=yt = {yi|yi ∈ V, yi 6= yt}. This constraint allows us to explicitly control the supervisions assigned to yt. Specifically, the first term ε · q and the second term (1− ε) · v in Eq. 2 respectively determines how much probability q′ assigns to yt and V6=yt . This setting differs from conventional knowledge distillation (Kim and Rush, 2016) because it facilitates more flexible controls over q′, so that we can use the factor ε to determine the supervision signal provided for the target word yt. The following sections detail how to compute ε and v."
    }, {
      "heading" : "3.3 Target Word Probability",
      "text" : "We control the probability of the target word yt in p′ by manipulating the adaption factor ε in Eq. 2. Specifically, for a training dialogue pair 〈X,Y 〉 and each target word yt ∈ Y , the current distribution p(·|y<t, X) is first calculated, and the maximum probability in this distribution is obtained:\npmax = max wk∈V\np(wk|y<t, X). (3)\nε is then obtained:\nε = max(pmax, λ), (4)\nwhere λ serves as a lower-bound of ε (i.e., ε ≥ λ). The basic intuition behind Eq. 4 is to set ε = pmax when pmax is reasonably large. This design prevents our model from receiving supervisions sharper than pmax, when the current prediction is confidence enough.\nFurther, to ensure that the target word yt always receives the largest probability in q′, i.e., to ensure ε > (1− ε) ·max(v) (see Eq. 2), in which max(v) is the maximum probabilities for non-target words V6=yt , we have to enforce ε > max(v) 1+max(v) . Thus we propose to calculate the lower-bound λ of ε as:\nλ = max(v)\n1 + max(v) + η, (5)\nwhere η > 0 is a hyper-parameter that controls the margin between the probability of the target word and non-target words in p′.\nTo facilitate faster converge and better learning of low-probability words, an empirical factor α ∈ [0, 1] is further introduced to adjust the calculation of ε on the basis of Eq. 4:\nε = 1− α · (1−max(pmax, λ)), (6)\nwhere α is calculated as the relative ratio to pmax:\nα =\n[ p(yt|y<t, X)\npmax\n]2 , (7)\nwhere p(yt|y<t, X) is the probability for the target word yt. Note that Eq. 6 and Eq. 4 is equivalent if α = 1. Intuitively, α accelerates the training of lowfrequency words because if yt is of low-frequency in the corpus, then yt is usually under-trained and thus p(yt|y<t, X) is generally small. This leads to a small α and thus increases the probability for yt in p′.\nNote that ε, λ and α are all time-step specific variables, whereas η is a fixed hyper-parameter. This allows the values adapt to dynamic contexts. In our experiments, Eq. 6 is used to calculate ε."
    }, {
      "heading" : "3.4 Non-target Words Probabilities",
      "text" : "The auxiliary distribution v in Eq. 2 is calculated using an auxiliary decoder Da, which is a singlelayer transformer-based decoder that is jointly optimized with the generation model. Figure 3 shows the structure ofDa, in which a novel target-masked\nattention scheme is devised to mask each target word yt in the self attention module of the decoder when calculating the corresponding v (see Figure 3b and 3c). In this way, bi-directional contexts can be utilized when predicting the auxiliary distribution v for yt. Moreover, it is important to use only one decoder layer in Da because stacking multiple layers in Da leaks the information of yt to v.\nNote that using one layer in Da does not necessarily downgrade its performance (Kasai et al., 2021). Our experiment results in Section 5.1 indicate that with the help of bi-directional contexts, the accuracy of Da largely outperforms the unidirectional dialogue decoder that is much deeper than Da. Moreover, for a training response Y , the structure of Da enables us infer the auxiliary distribution in parallel for all the target words in Y within a single forward pass. This differs from the BERT teacher used by Chen et al. (2020), in which multiple independent forward passes are needed to get the teacher distributions for all the words in Y .\nWhen training Da, the following standard MLE loss is optimized for each target word yt:\nL(q,v) = − |V|∑ k=1 qklogvk, (8)\nin which the notation of qk follows Eq. 1. The outputs ofDa are used as the logits to infer v to be further used in Eq. 2. Specifically, the logit of the target word yt is masked to−∞ before Softmax to ensure yt always receives zero probability in v. Moreover, we also follow the approach used by Tang et al. (2020) to truncate the head and tail of the remaining logits before inferring v in Eq.\n2, i.e., all the logits are ranked in a descending order and only the logits ranked from n to m are kept while the rest logits are masked to −∞. This masks the head and tail probabilities in v to zero. We argue that truncating the tail probabilities of v filters noises, and truncating the head probabilities of v encourages the dialogue model to focus more on low-probability words. In our experiments, we set n = 2 and m = 500. An extensive hyperparameter search indicates that our method is not sensitive to the value of n and m.\nThere are two major differences between our auxiliary decoder Da and the teacher model used in conventional knowledge distillation approaches: First, conventional teacher models usually carry more parameters than their students, whereas Da is rather light-weight. Second, conventional teacher models are typically pre-trained before being utilized in the distillation process, whereas Da is trained jointly with our dialogue model."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Dataset",
      "text" : "We use two benchmark datasets for open-domain dialogue generation: DailyDialog (Li et al., 2017) is a high-quality multi-turn dialogue dataset that is collected from daily conversations. OpenSubtitles 1 contains dialogues collected from movie subtitles. Moreover, we follow Li et al. (2016) and Jiang et al. (2019) to focus on short conversations, i.e., dialogues with posts or responses longer than 100 tokens are removed. See Table 1 for more details."
    }, {
      "heading" : "4.2 Implementation Details",
      "text" : "The backbone of our model is the transformerbased sequence to sequence model (Vaswani et al., 2017), and most hyper-parameters follow Cai et al. (2020). Specifically, the encoder and decoder each contains 6 layers. Each layer has 8 attention heads, and the hidden size is set to 512. The auxiliary decoder Da follows the same hyper-parameter setting as the dialogue decoder, but it only contains one layer. The WordPiece tokenizer provided by\n1http://opus.nlpl.eu/OpenSubtitles.php\nBERT (Devlin et al., 2019) is used, and the Adam optimizer (Kingma and Ba, 2015) is employed to train our model from random initializations with a learning rate of 1e-4. η in Eq. 5 is set to 0.2 for all datasets. See Appendix A for more details. 2"
    }, {
      "heading" : "4.3 Baselines",
      "text" : "We compared our method with two groups of baselines that try to tackle the over-confidence issue.\nThe first group modifies the training target used to compute the loss function: 1) LS (Szegedy et al., 2016): uses the label smoothing approach to construct a target distribution by adding the onehot target and a uniform distribution; 2) FL (Lin et al., 2017): uses the focal loss to down-weigh well-classified tokens in each time step. 3) FACE (Jiang et al., 2019): uses the frequency-aware crossentropy loss to balance per-token training losses. Specifically, relative low losses are assigned to high-frequency words to explicitly tackle the overconfidence issue. We used the best performing “Pre-weigh” version in our experiments. 4) F2 (Choi et al., 2020): factorizes the target distribution based on the token frequencies.\nThe second group of baselines add some penalty term to the standard MLE loss: 5) CP (Pereyra et al., 2017): a confidence penalty term is added to regularize the entropy of the model, so that over-confident predictions are penalized; 6) UL (Welleck et al., 2020): an unlikelihood loss term is added to penalize the frequently generated words. 7) NL (He and Glass, 2020): works similarly with baseline UL except a negative loss term is used instead of the unlikelihood loss term. 8) D2GPo (Li et al., 2019): augments the MLE loss with a data-dependent gaussian prior objective to assign different losses for different non-target words.\nWe also compared to: 9) CE: a vanilla Seq2Seq model trained with the cross-entropy loss. For fair comparisons, the C-MLM model proposed by Chen et al. (2020) is not used as our baseline since the BERT teacher in C-MLM requires a large amount of extra data to pre-train. Nevertheless, AdaLabel still surpasses C-MLM on various metrics (see Appendix F for more analysis).\nAll our baselines are adapted from the authors’ official codes with the same backbone architecture and hyper-parameters as our model (see details in Appendix B). Following the original setting, a train-\n2Our code is available at: https://github.com/ lemon234071/AdaLabel\nand-refine strategy is used in baseline 3, 6, and 7, i.e., these baselines are refined based on CE. We follow the setting of Jiang et al. (2019) to use deterministic decoding scheme (particularly, greedy decoding) for our model and all baselines. Note that our method can be adapted to other decoding schemes such as beam-search or top-K sampling. See Appendix C for more detailed analysis."
    }, {
      "heading" : "4.4 Automatic Evaluation",
      "text" : "Metrics: We first used automatic metrics to evaluate our method: 1) Distinct (Dist) (Li et al., 2016) calculates the proportion of unique n-grams (n=1, 2) in the generated responses, which is widely used to measure the response diversity. 2) Entropy (Ent) (Zhang et al., 2018) evaluates how evenly the empirical n-gram (n=1, 2) distribution is. Higher sores mean more diverse of the response. 3) LowFrequency Token Ratio (LF) (Li et al., 2019) further measures the model diversity by counting the ratio of low-frequency words in the generated responses. We chose words with a frequency less than 100 in each corpus as low-frequency words. Over-confident models tend to omit low-frequency words (i.e., get low LF scores) and yield less diversified responses. 4) BLEU (Papineni et al., 2002) measures n-gram (n=2, 3, 4) overlap between the generated responses and references.\nResults: As shown in Table 2, our method AdaLabel outperforms all the baselines by large margins on all the datasets. We can further observe that: 1) AdaLabel achieves the best diversity scores (Dist-1,2, Ent-1,2, and LF). This indicates that our method yields better training targets that help to produce more diverse responses; 2). The models that explicitly tackle the over-confidence issue (i.e., AdaLabel and FACE) generally outperform\nother baselines in diversity-related metrics. For example, FACE obtains the second-best diversity scores (i.e., Dist, Ent, and LF) on the OpenSubtitles dataset. This verifies our motivation that alleviating the over-confidence issue helps to produce more diverse responses.\nNote that our method also outperforms all the baselines using the stochastic decoding scheme. Please refer to Appendix C for more details."
    }, {
      "heading" : "4.5 Manual Evaluation",
      "text" : "Metrics: Pairwise manual evaluations are conducted to further validate our method. Specifically, for a given dialogue post, our model’s response is paired with the one from a baseline. Three individual annotators were employed to rank each response pair from three aspects: 1) Fluency (Flu.): which response is more fluent; 2) Coherency (Coh.): which response is more coherent to the context; 3) Informativeness (Info.): which response contains more informative content. We also asked the annotator to choose an overall preferred response (Pref.). Ties were allowed.\nResults: 200 posts were randomly sampled from each of these two datasets, respectively, and totally 3.6K response pairs were generated. The inter-rater annotation agreement was measured using Fleiss’s kappa κ (Fleiss, 1971). Particularly, the κ value on DailyDialog, OpenSubtitles dataset was 0.59 and 0.55, respectively, indicating moderate agreement.\nAs shown in Table 3, AdaLabel outperforms all the baselines on the informativeness measure. This means that our method can respond with more informative content. We can further observe that:\n1). All models achieve competitive fluency because it is easy for neural models to produce fluent responses by yielding trivial responses like “I\ndon’t know”. However, our model surpasses most baselines in terms of fluency while ensuring high diversity scores. This demonstrates the superiority of our method in producing high quality responses.\n2). AdaLabel produces more coherent responses comparing to most baselines. This verifies that our model does not sacrifice the response quality when achieving high diversity scores. In fact, by controlling the model’s confidence, more lowfrequency words are encouraged, and thus AdaLabel can produce more relevant and coherent responses. This claim is further verified by observing that our model achieves the best overall preference score among all the baselines."
    }, {
      "heading" : "4.6 Ablation study",
      "text" : "Ablation studies were performed to verify the effect of each component in our method. Specifically, two groups of variants were tested:\nThe first group validates the effectiveness of the calculated target word probability, i.e., ε: 1). w/o ε directly sets a fixed value for ε in Eq. 2. The specific value of ε is searched from 0.1 to 0.7 with a stride of 0.1; 2). w/o α omits the empirical factor α in calculating ε, i.e., the value of ε in Eq. 2 is calculated using Eq. 4 in instead of Eq. 6.\nThe second group validates the effectiveness of\nthe non-target word probabilities produced by Da, i.e., v: 3). Orig. v does not truncate the head of v when inferring from Da. Note that the truncation for the tail of v is still applied since its effectiveness has already been proved in previous studies (Tang et al., 2020; Tan et al., 2019); 4). Uniform uses an uniform distribution as v in Eq. 2. Note that different from the baseline LS, the value of ε is calculated using Eq. 6 in this ablation model, whereas the value of ε in the baseline LS is fixed ; 5). Rand use a random distributions as v in Eq. 2; 6). BERT follows the work of Chen et al. (2020) to fine-tune a pre-trained BERT model to produce v. Note that our dialogue model may benefit from the multi-task training of Da since Da shares the same encoder with our dialogue model. Optimizing Eq. 8 may help the encoder to capture better features. For fair comparison, we kept the task of optimizing Da in ablation models 4-6 although it is not used to infer v.\nTable 4 shows the results of ablation models on the DailyDialog dataset. As can be seen from the first two rows, our method to adaptively calculate ε helps to improve the performance of our model by a large margin, and the empirical adjustment factor α helps to further improve our performance by facilitating the learning of low-probability words. The performance of ablation models 3-6 in Table 4 proves that v captures reliable distribution and helps our model produce more diverse responses. Moreover, truncating the head distribution of v enables the dialogue model to focus more on the low-frequency words and thus facilitates more informative responses.\nIt is also interesting to note that our auxiliary decoder Da surpasses the BERT teacher used by Chen et al. (2020) in helping the dialogue model\nto produce more diverse responses. This further proves the effectiveness of Da considering that BERT contains 6 times parameters than Da and consumes much more computation resources."
    }, {
      "heading" : "5 Discussion",
      "text" : ""
    }, {
      "heading" : "5.1 Auxiliary Decoder",
      "text" : "To further test the performance of Da, we evaluated the averaged accuracy score of Da when predicting each target word in the test set (first row in Table 5). Specifically, a target word yt in the reference response is determined to be correctly predicted if it is top-ranked in the predicted distribution p(·|y<t, X). A better decoder is generally believed to obtain a higher accuracy. Table 5 also reports the uni-directional dialogue decoders’ accuracy in AdaLabel and CE. It can be seen that Da can make substantially more accurate predictions with the help of modeling bi-directional contexts using only one layer. Moreover, the dialogue model’s decoder in AdaLabel, which is guided by Da, achieves better accuracies than the CE. This further proves that our light-weight Da is capable of producing effective v."
    }, {
      "heading" : "5.2 Prediction Confidence",
      "text" : "We also visualized the distribution of confidence scores assigned by each dialogue model to highfrequency words. Figure 4 shows the results of\nfour best performing models on the OpenSubtitles dataset. The spikes of high confidence score observed in Figure 4b and 4d indicate that CE and FACE assign extremely high confidence scores to a large number of high-frequency words. Although the smoothed labels in LS manage to alleviate these high-confidence-spikes (Figure 4c), a considerable amount of words still receives high confidence scores in LS. Our model outperforms all the baselines to avoid assigning over-confidence scores, thus alleviating the over-confidence issue. A similar trend is also observed on the DailyDialog dataset (see Appendix D for results of all models on both datasets)."
    }, {
      "heading" : "5.3 Predicted Rare Word Distribution",
      "text" : "Over-confident models produce less diversified responses because they usually under-estimate rare words. To evaluate the effectiveness of AdaLabel, we tested whether AdaLabel encourages more “rare words” in its generations. Specifically, the ratio of generated tokens corresponding to different token frequency bins is calculated, and the results on the OpenSubtitles dataset are shown in Figure 5. It can be seen that AdaLabel produces more rare words in the generated responses than other baselines. Similar results are also observed on the DailyDialog dataset (see Appendix E)."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We address the low-diversity issue of neural dialogue models by introducing an adaptive label smoothing approach, AdaLabel. In our method, the probability of each target word is estimated based on the current dialogue model’s prediction, and the probabilities for these non-target words are calculated using a novel auxiliary decoder Da. A target-masked attention scheme is introduced inDa\nto help capture forward and backward contexts. We evaluate our method on two benchmark datasets: DailyDialog and OpenSubtitles. Extensive experiments show that our method effectively alleviates the over-confidence issue and improves the diversity of the generated responses. As future work, we believe this method is extensible to other text generation tasks."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was partly supported by the NSFC projects (Key project with No. 61936010 and regular project with No. 61876096). This work was also supported by the Guoqiang Institute of Tsinghua University, with Grant No. 2019GQG1 and 2020GQG0005. We thank Jinchao Zhang and Yao Qiu for early discussions and insightful comments of this work."
    }, {
      "heading" : "B Baseline Implementation Details",
      "text" : "This appendix contains more implementation details of our baselines. All the baselines utilize the same backbone architecture and basic hyperparameter settings as our model (see Appendix A). The hyper-parameters specialized for each baseline is determined with the grid search based on the Dist\nmeasures on the validation set: For Label smoothing (LS), we searched the smoothing parameter in [0.05, 0.1, 0.2, 0.3, 0.4, 0.5], and found 0.1 works best on all the datasets; For Confidence penalty (CP), we searched the weight of penalty in [0.0005, 0.001, 0.01, 0.05, 0.1] and found 0.05 works best on all the datasets while ensuring the loss to be positive; For Focal loss (FL), we searched the hyperparameter γ in [0.1, 0.5, 1, 2, 3], and found 2 works best on all the datasets. For Unlikelihood loss (UL), we searched the weight of penalty in [1, 10, 100, 1000], and select 1000 on all the datasets. For FACE, we experiment with the Output token frequency & PRe-weigh version, which is reported to be the best version of FACE. For Negative loss (NL), F2-softmax (F2) and Datadependent Gaussian Prior objective (D2GPo), the selection of hyper-parameters follows the author’s suggestion."
    }, {
      "heading" : "C Automatic Evaluation Results with Other Decoding Schemes",
      "text" : "This appendix reports our model’s automatic evaluation results and all the baselines when different decoding schemes are used. Specifically, Table 6 shows the results for the beam search decoding scheme (beam size of 5), and Table 7 shows the results when the top-K decoding scheme (k = 10) is used. Note that for the F2-softmax, we use the decoupled top-k sampling as the authors suggested.\nAs can be seen from Table 6 and 7, our method outperforms all the baselines on the diversityrelated scores (i.e., Dist, Ent, and LF) by a large margin. This indicates that our method can produce\nmore diverse responses even with the stochastic based decoding scheme.\nWe also include the results of AdaLabel when the greedy decoding scheme is used in Table 6 and Table 7 (the second line from the bottom). It is interesting to see that the greedily decoded responses from AdaLabel are more diverse than some baselines that are decoded using the sampling scheme (see Table 7). Moreover, our model AdaLabel with the greedy decoding scheme achieves the best BLEU among all the baselines on both datasets."
    }, {
      "heading" : "D Prediction Confidence",
      "text" : "This appendix reports the prediction confidence scores assigned by each model to high-frequency words. Specifically, words occupying the top 40% of the frequency mass in the training set of each dataset are regarded as high-frequency words.\nFigure 6 shows the results of our model and all the baselines on the DailyDialog dataset. Figure 7 shows the results of our model and all the baselines on the OpenSubtitles dataset. It can be seen that most of our baselines assign extremely high confidence scores (nearly 1.0) to these high-frequency words, and thus resulting in a spike of high confidence scores in the plotted distribution. Our model outperforms all the baselines in avoiding assigning extremely high confidence scores to these highfrequency words."
    }, {
      "heading" : "E Predicted Rare Word Distribution on DailyDialog",
      "text" : "This appendix shows the distribution of rare words in the generated responses on the DailyDialog\ndataset (see Figure 8). It can be seen that more “rare words” are predicted by our method on the DailyDialog dataset. This observation is in line with the results on the OpenSubtitles dataset as reported in Section 5.3."
    }, {
      "heading" : "F Use BERT Model to Obtain v",
      "text" : "This appendix provides more experiment results comparing to the CMLM model (Chen et al., 2020): 1). CMLM exactly follows the setting of Chen et al. (2020), i.e., the teacher distribution produced by\nModel BLEU-3,4 Dist-1,2 Ent-1,2 LF\n1. CMLM 6.18 4.09 2.20 11.83 4.59 6.79 4.62 2. CMLM+ε 9.36 7.31 3.78 21.05 4.96 7.61 6.88 3. CMLM+ε+Da 11.6 9.34 3.67 20.97 5.02 7.71 7.28\nAdaLabel 13.38 11.01 3.96 23.53 5.17 8.00 8.49\nTable 8: Ablation study results based on BERT on DailyDialog (%).\nthe BERT model is merged with the one-hot distribution using a fixed ε. 2). CMLM+ε adaptively adjust the value of ε using Eq. 6 in our paper. 3). CMLM+ε+Da add an additional training task to optimize the auxiliary decoder Da on the basis of CMLM+ε. It is expected that optimizing Da help our dialogue encoder to capture better representations. The trainedDa is not used in the training and inference phase of our dialogue model. Note that the last model CMLM+ε+Da is the same with our ablation model 6. BERT as reported in our paper.\nAs can be seen Table 8, our approach to adaptively change ε helps to produce better dialogue responses, and the training of Da helps our dialogue encoder to learn better representations."
    }, {
      "heading" : "G Case study",
      "text" : "We sampled some generated cases on the DailyDialog and OpenSubtitles dataset. The results of our model and some competitive baselines are shown in Table 9 and Table 10. It can be seen that the responses generated by our method are coherent to the context and contain richer contents. Moreover, our model also produces more rare words that make our response more diverse."
    } ],
    "references" : [ {
      "title" : "Data manipulation: Towards effective instance learning for neural dialogue generation via learning to augment and reweight",
      "author" : [ "Hengyi Cai", "Hongshen Chen", "Yonghao Song", "Cheng Zhang", "Xiaofang Zhao", "Dawei Yin." ],
      "venue" : "Proceedings of the 58th An-",
      "citeRegEx" : "Cai et al\\.,? 2020",
      "shortCiteRegEx" : "Cai et al\\.",
      "year" : 2020
    }, {
      "title" : "Distilling knowledge learned in BERT for text generation",
      "author" : [ "Yen-Chun Chen", "Zhe Gan", "Yu Cheng", "Jingzhou Liu", "Jingjing Liu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7893–7905, On-",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "Fˆ2-softmax: Diversifying neural text generation via frequency factorized softmax",
      "author" : [ "Byung-Ju Choi", "Jimin Hong", "David Park", "Sang Wan Lee." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process-",
      "citeRegEx" : "Choi et al\\.,? 2020",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Variational autoregressive decoder for neural response generation",
      "author" : [ "Jiachen Du", "Wenjie Li", "Yulan He", "Ruifeng Xu", "Lidong Bing", "Xuan Wang." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Meth-",
      "citeRegEx" : "Du et al\\.,? 2018",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2018
    }, {
      "title" : "Measuring nominal scale agreement among many raters",
      "author" : [ "Joseph L Fleiss." ],
      "venue" : "Psychological bulletin, 76(5):378.",
      "citeRegEx" : "Fleiss.,? 1971",
      "shortCiteRegEx" : "Fleiss.",
      "year" : 1971
    }, {
      "title" : "Jointly optimizing diversity and relevance in neural response generation",
      "author" : [ "Xiang Gao", "Sungjin Lee", "Yizhe Zhang", "Chris Brockett", "Michel Galley", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the",
      "citeRegEx" : "Gao et al\\.,? 2019",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Finding the optimal vocabulary size for neural machine translation",
      "author" : [ "Thamme Gowda", "Jonathan May." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3955–3964, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Gowda and May.,? 2020",
      "shortCiteRegEx" : "Gowda and May.",
      "year" : 2020
    }, {
      "title" : "On calibration of modern neural networks",
      "author" : [ "Chuan Guo", "Geoff Pleiss", "Yu Sun", "Kilian Q Weinberger." ],
      "venue" : "International Conference on Machine Learning, pages 1321–1330. PMLR.",
      "citeRegEx" : "Guo et al\\.,? 2017",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2017
    }, {
      "title" : "Negative training for neural dialogue response generation",
      "author" : [ "Tianxing He", "James Glass." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2044– 2058, Online. Association for Computational Lin-",
      "citeRegEx" : "He and Glass.,? 2020",
      "shortCiteRegEx" : "He and Glass.",
      "year" : 2020
    }, {
      "title" : "Distilling the knowledge in a neural network",
      "author" : [ "Geoffrey E. Hinton", "Oriol Vinyals", "Jeffrey Dean." ],
      "venue" : "CoRR, abs/1503.02531.",
      "citeRegEx" : "Hinton et al\\.,? 2015",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2015
    }, {
      "title" : "The curious case of neural text degeneration",
      "author" : [ "Ari Holtzman", "Jan Buys", "Li Du", "Maxwell Forbes", "Yejin Choi." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.",
      "citeRegEx" : "Holtzman et al\\.,? 2020",
      "shortCiteRegEx" : "Holtzman et al\\.",
      "year" : 2020
    }, {
      "title" : "Challenges in building intelligent open-domain dialog systems",
      "author" : [ "Minlie Huang", "Xiaoyan Zhu", "Jianfeng Gao." ],
      "venue" : "ACM Transactions on Information Systems (TOIS), 38(3):1–32.",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "Comparison of diverse decoding methods from conditional language models",
      "author" : [ "Daphne Ippolito", "Reno Kriz", "João Sedoc", "Maria Kustikova", "Chris Callison-Burch." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computa-",
      "citeRegEx" : "Ippolito et al\\.,? 2019",
      "shortCiteRegEx" : "Ippolito et al\\.",
      "year" : 2019
    }, {
      "title" : "Improving neural response diversity with frequency-aware cross-entropy loss",
      "author" : [ "Shaojie Jiang", "Pengjie Ren", "Christof Monz", "Maarten de Rijke." ],
      "venue" : "The World Wide Web Conference, pages 2879– 2885.",
      "citeRegEx" : "Jiang et al\\.,? 2019",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2019
    }, {
      "title" : "Why are sequence-to-sequence models so dull? understanding the low-diversity problem of chatbots",
      "author" : [ "Shaojie Jiang", "Maarten de Rijke." ],
      "venue" : "Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented",
      "citeRegEx" : "Jiang and Rijke.,? 2018",
      "shortCiteRegEx" : "Jiang and Rijke.",
      "year" : 2018
    }, {
      "title" : "Deep encoder, shallow decoder: Reevaluating non-autoregressive machine translation",
      "author" : [ "Jungo Kasai", "Nikolaos Pappas", "Hao Peng", "James Cross", "Noah Smith." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Kasai et al\\.,? 2021",
      "shortCiteRegEx" : "Kasai et al\\.",
      "year" : 2021
    }, {
      "title" : "Sequencelevel knowledge distillation",
      "author" : [ "Yoon Kim", "Alexander M. Rush." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1317–1327, Austin, Texas. Association for Computational Linguistics.",
      "citeRegEx" : "Kim and Rush.,? 2016",
      "shortCiteRegEx" : "Kim and Rush.",
      "year" : 2016
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "OpenNMT: Opensource toolkit for neural machine translation",
      "author" : [ "Guillaume Klein", "Yoon Kim", "Yuntian Deng", "Jean Senellart", "Alexander Rush." ],
      "venue" : "Proceedings of ACL 2017, System Demonstrations, pages 67–72, Vancouver, Canada. Association for",
      "citeRegEx" : "Klein et al\\.,? 2017",
      "shortCiteRegEx" : "Klein et al\\.",
      "year" : 2017
    }, {
      "title" : "Importance of search and evaluation strategies in neural dialogue modeling",
      "author" : [ "Ilia Kulikov", "Alexander Miller", "Kyunghyun Cho", "Jason Weston." ],
      "venue" : "Proceedings of the 12th International Conference on Natural Language Generation, pages 76–87, Tokyo,",
      "citeRegEx" : "Kulikov et al\\.,? 2019",
      "shortCiteRegEx" : "Kulikov et al\\.",
      "year" : 2019
    }, {
      "title" : "Calibration of encoder decoder models for neural machine translation",
      "author" : [ "Aviral Kumar", "Sunita Sarawagi." ],
      "venue" : "CoRR, abs/1903.00802.",
      "citeRegEx" : "Kumar and Sarawagi.,? 2019",
      "shortCiteRegEx" : "Kumar and Sarawagi.",
      "year" : 2019
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Don’t say that! making inconsistent dialogue unlikely with unlikelihood training",
      "author" : [ "Margaret Li", "Stephen Roller", "Ilia Kulikov", "Sean Welleck", "Y-Lan Boureau", "Kyunghyun Cho", "Jason Weston." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Asso-",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "DailyDialog: A manually labelled multi-turn dialogue dataset",
      "author" : [ "Yanran Li", "Hui Su", "Xiaoyu Shen", "Wenjie Li", "Ziqiang Cao", "Shuzi Niu." ],
      "venue" : "Proceedings of the Eighth International Joint Conference on",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "Data-dependent gaussian prior objective for language generation",
      "author" : [ "Zuchao Li", "Rui Wang", "Kehai Chen", "Masso Utiyama", "Eiichiro Sumita", "Zhuosheng Zhang", "Hai Zhao." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Focal loss for dense object detection",
      "author" : [ "Tsung-Yi Lin", "Priya Goyal", "Ross Girshick", "Kaiming He", "Piotr Dollár." ],
      "venue" : "Proceedings of the IEEE international conference on computer vision, pages 2980– 2988.",
      "citeRegEx" : "Lin et al\\.,? 2017",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2017
    }, {
      "title" : "How decoding strategies affect the verifiability of generated text",
      "author" : [ "Luca Massarelli", "Fabio Petroni", "Aleksandra Piktus", "Myle Ott", "Tim Rocktäschel", "Vassilis Plachouras", "Fabrizio Silvestri", "Sebastian Riedel." ],
      "venue" : "Findings of the Association for Compu-",
      "citeRegEx" : "Massarelli et al\\.,? 2020",
      "shortCiteRegEx" : "Massarelli et al\\.",
      "year" : 2020
    }, {
      "title" : "Calibrating deep neural networks using focal loss",
      "author" : [ "Jishnu Mukhoti", "Viveka Kulharia", "Amartya Sanyal", "Stuart Golodetz", "Philip H.S. Torr", "Puneet K. Dokania." ],
      "venue" : "Advances in Neural Information Processing Systems 33: Annual Conference on Neu-",
      "citeRegEx" : "Mukhoti et al\\.,? 2020",
      "shortCiteRegEx" : "Mukhoti et al\\.",
      "year" : 2020
    }, {
      "title" : "When does label smoothing help",
      "author" : [ "Rafael Müller", "Simon Kornblith", "Geoffrey E Hinton" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Müller et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Müller et al\\.",
      "year" : 2019
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia,",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Regularizing neural networks by penalizing confident output distributions",
      "author" : [ "Gabriel Pereyra", "George Tucker", "Jan Chorowski", "Lukasz Kaiser", "Geoffrey E. Hinton." ],
      "venue" : "5th International Conference on Learning Representations, ICLR 2017, Toulon,",
      "citeRegEx" : "Pereyra et al\\.,? 2017",
      "shortCiteRegEx" : "Pereyra et al\\.",
      "year" : 2017
    }, {
      "title" : "Rethinking the inception architecture for computer vision",
      "author" : [ "Christian Szegedy", "Vincent Vanhoucke", "Sergey Ioffe", "Jon Shlens", "Zbigniew Wojna." ],
      "venue" : "Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2818–2826.",
      "citeRegEx" : "Szegedy et al\\.,? 2016",
      "shortCiteRegEx" : "Szegedy et al\\.",
      "year" : 2016
    }, {
      "title" : "Multilingual neural machine translation with knowledge distillation",
      "author" : [ "Xu Tan", "Yi Ren", "Di He", "Tao Qin", "Zhou Zhao", "Tie-Yan Liu." ],
      "venue" : "7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.",
      "citeRegEx" : "Tan et al\\.,? 2019",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2019
    }, {
      "title" : "Understanding and improving knowledge distillation",
      "author" : [ "Jiaxi Tang", "Rakesh Shivanna", "Zhe Zhao", "Dong Lin", "Anima Singh", "Ed H. Chi", "Sagar Jain." ],
      "venue" : "CoRR, abs/2002.03532.",
      "citeRegEx" : "Tang et al\\.,? 2020",
      "shortCiteRegEx" : "Tang et al\\.",
      "year" : 2020
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "A large-scale chinese short-text conversation dataset",
      "author" : [ "Yida Wang", "Pei Ke", "Yinhe Zheng", "Kaili Huang", "Yong Jiang", "Xiaoyan Zhu", "Minlie Huang." ],
      "venue" : "CCF International Conference on Natural Language Processing and Chinese Computing, pages",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural text generation with unlikelihood training",
      "author" : [ "Sean Welleck", "Ilia Kulikov", "Stephen Roller", "Emily Dinan", "Kyunghyun Cho", "Jason Weston." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April",
      "citeRegEx" : "Welleck et al\\.,? 2020",
      "shortCiteRegEx" : "Welleck et al\\.",
      "year" : 2020
    }, {
      "title" : "Knowledge distillation in generations: More tolerant teachers educate better students",
      "author" : [ "Chenglin Yang", "Lingxi Xie", "Siyuan Qiao", "Alan L. Yuille." ],
      "venue" : "CoRR, abs/1805.05551.",
      "citeRegEx" : "Yang et al\\.,? 2018",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2018
    }, {
      "title" : "Dialogue distillation: Open-domain dialogue augmentation using unpaired data",
      "author" : [ "Rongsheng Zhang", "Yinhe Zheng", "Jianzhi Shao", "Xiaoxi Mao", "Yadong Xi", "Minlie Huang." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Generating informative and diverse conversational responses via adversarial information maximization",
      "author" : [ "Yizhe Zhang", "Michel Galley", "Jianfeng Gao", "Zhe Gan", "Xiujun Li", "Chris Brockett", "Bill Dolan." ],
      "venue" : "Advances in Neural Information Processing Sys-",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning discourse-level diversity for neural dialog models using conditional variational autoencoders",
      "author" : [ "Tiancheng Zhao", "Ran Zhao", "Maxine Eskenazi." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Zhao et al\\.,? 2017",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2017
    }, {
      "title" : "Stylized dialogue response generation using stylized unpaired texts",
      "author" : [ "Yinhe Zheng", "Zikai Chen", "Rongsheng Zhang", "Shilei Huang", "Xiaoxi Mao", "Minlie Huang." ],
      "venue" : "AAAI.",
      "citeRegEx" : "Zheng et al\\.,? 2020a",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2020
    }, {
      "title" : "A pre-training based personalized dialogue generation model with persona-sparse data",
      "author" : [ "Yinhe Zheng", "Rongsheng Zhang", "Minlie Huang", "Xiaoxi Mao." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9693–9700.",
      "citeRegEx" : "Zheng et al\\.,? 2020b",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2020
    }, {
      "title" : "Elastic responding machine",
      "author" : [ "Qing He" ],
      "venue" : null,
      "citeRegEx" : "He.,? \\Q2018\\E",
      "shortCiteRegEx" : "He.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "The success of neural models has greatly advanced the research of dialog generation (Huang et al., 2020; Wang et al., 2020; Zhang et al., 2020).",
      "startOffset" : 84,
      "endOffset" : 143
    }, {
      "referenceID" : 36,
      "context" : "The success of neural models has greatly advanced the research of dialog generation (Huang et al., 2020; Wang et al., 2020; Zhang et al., 2020).",
      "startOffset" : 84,
      "endOffset" : 143
    }, {
      "referenceID" : 39,
      "context" : "The success of neural models has greatly advanced the research of dialog generation (Huang et al., 2020; Wang et al., 2020; Zhang et al., 2020).",
      "startOffset" : 84,
      "endOffset" : 143
    }, {
      "referenceID" : 22,
      "context" : "However, most of these models suffer from a lowdiversity issue where models tend to generate bland and generic responses such as I don’t know or I’m OK (Li et al., 2016).",
      "startOffset" : 152,
      "endOffset" : 169
    }, {
      "referenceID" : 22,
      "context" : "Although various approaches have been proposed to tackle this issue (Li et al., 2016; Zhao et al., 2017; Du et al., 2018; Zhou et al., 2018; Welleck et al., 2020; Zheng et al., 2020b), there are still remarkable gaps between responses generated by neural models and those from humans (Holtzman et al.",
      "startOffset" : 68,
      "endOffset" : 183
    }, {
      "referenceID" : 41,
      "context" : "Although various approaches have been proposed to tackle this issue (Li et al., 2016; Zhao et al., 2017; Du et al., 2018; Zhou et al., 2018; Welleck et al., 2020; Zheng et al., 2020b), there are still remarkable gaps between responses generated by neural models and those from humans (Holtzman et al.",
      "startOffset" : 68,
      "endOffset" : 183
    }, {
      "referenceID" : 4,
      "context" : "Although various approaches have been proposed to tackle this issue (Li et al., 2016; Zhao et al., 2017; Du et al., 2018; Zhou et al., 2018; Welleck et al., 2020; Zheng et al., 2020b), there are still remarkable gaps between responses generated by neural models and those from humans (Holtzman et al.",
      "startOffset" : 68,
      "endOffset" : 183
    }, {
      "referenceID" : 37,
      "context" : "Although various approaches have been proposed to tackle this issue (Li et al., 2016; Zhao et al., 2017; Du et al., 2018; Zhou et al., 2018; Welleck et al., 2020; Zheng et al., 2020b), there are still remarkable gaps between responses generated by neural models and those from humans (Holtzman et al.",
      "startOffset" : 68,
      "endOffset" : 183
    }, {
      "referenceID" : 43,
      "context" : "Although various approaches have been proposed to tackle this issue (Li et al., 2016; Zhao et al., 2017; Du et al., 2018; Zhou et al., 2018; Welleck et al., 2020; Zheng et al., 2020b), there are still remarkable gaps between responses generated by neural models and those from humans (Holtzman et al.",
      "startOffset" : 68,
      "endOffset" : 183
    }, {
      "referenceID" : 11,
      "context" : ", 2020b), there are still remarkable gaps between responses generated by neural models and those from humans (Holtzman et al., 2020).",
      "startOffset" : 109,
      "endOffset" : 132
    }, {
      "referenceID" : 7,
      "context" : ", one-hot distribution as ground truth) makes the model favor high-frequency tokens and produce over-confident probability estimation (Gowda and May, 2020), which ultimately leads to poor calibration (Mukhoti et al.",
      "startOffset" : 134,
      "endOffset" : 155
    }, {
      "referenceID" : 28,
      "context" : ", one-hot distribution as ground truth) makes the model favor high-frequency tokens and produce over-confident probability estimation (Gowda and May, 2020), which ultimately leads to poor calibration (Mukhoti et al., 2020), and thus low diversity (Jiang et al.",
      "startOffset" : 200,
      "endOffset" : 222
    }, {
      "referenceID" : 29,
      "context" : "With such a soft target, the over-confidence issue can be alleviated (Müller et al., 2019), and thus the diversity of the output responses can be improved.",
      "startOffset" : 69,
      "endOffset" : 90
    }, {
      "referenceID" : 22,
      "context" : "Diversity Promotion: Existing approaches for solving the low diversity issue of neural dialogue models generally involve two categories: The first category is training-based, where new training objectives are designed (Li et al., 2016; Zhang et al., 2018; Gao et al., 2019) or latent variables are introduced (Zhao et al.",
      "startOffset" : 218,
      "endOffset" : 273
    }, {
      "referenceID" : 40,
      "context" : "Diversity Promotion: Existing approaches for solving the low diversity issue of neural dialogue models generally involve two categories: The first category is training-based, where new training objectives are designed (Li et al., 2016; Zhang et al., 2018; Gao et al., 2019) or latent variables are introduced (Zhao et al.",
      "startOffset" : 218,
      "endOffset" : 273
    }, {
      "referenceID" : 6,
      "context" : "Diversity Promotion: Existing approaches for solving the low diversity issue of neural dialogue models generally involve two categories: The first category is training-based, where new training objectives are designed (Li et al., 2016; Zhang et al., 2018; Gao et al., 2019) or latent variables are introduced (Zhao et al.",
      "startOffset" : 218,
      "endOffset" : 273
    }, {
      "referenceID" : 41,
      "context" : ", 2019) or latent variables are introduced (Zhao et al., 2017; Zhou et al., 2018) in the dialogue model.",
      "startOffset" : 43,
      "endOffset" : 81
    }, {
      "referenceID" : 2,
      "context" : "Some methods also try to refine the training target used in the MLE loss (Choi et al., 2020; Jiang et al., 2019; Li et al., 2019), or directly penalize the trivial responses with auxiliary loss terms (Welleck et al.",
      "startOffset" : 73,
      "endOffset" : 129
    }, {
      "referenceID" : 14,
      "context" : "Some methods also try to refine the training target used in the MLE loss (Choi et al., 2020; Jiang et al., 2019; Li et al., 2019), or directly penalize the trivial responses with auxiliary loss terms (Welleck et al.",
      "startOffset" : 73,
      "endOffset" : 129
    }, {
      "referenceID" : 25,
      "context" : "Some methods also try to refine the training target used in the MLE loss (Choi et al., 2020; Jiang et al., 2019; Li et al., 2019), or directly penalize the trivial responses with auxiliary loss terms (Welleck et al.",
      "startOffset" : 73,
      "endOffset" : 129
    }, {
      "referenceID" : 37,
      "context" : ", 2019), or directly penalize the trivial responses with auxiliary loss terms (Welleck et al., 2020; Li et al., 2020).",
      "startOffset" : 78,
      "endOffset" : 117
    }, {
      "referenceID" : 23,
      "context" : ", 2019), or directly penalize the trivial responses with auxiliary loss terms (Welleck et al., 2020; Li et al., 2020).",
      "startOffset" : 78,
      "endOffset" : 117
    }, {
      "referenceID" : 11,
      "context" : "The second category is decoding-based, in which different heuristic decoding rules are designed (Holtzman et al., 2020; Kulikov et al., 2019).",
      "startOffset" : 96,
      "endOffset" : 141
    }, {
      "referenceID" : 20,
      "context" : "The second category is decoding-based, in which different heuristic decoding rules are designed (Holtzman et al., 2020; Kulikov et al., 2019).",
      "startOffset" : 96,
      "endOffset" : 141
    }, {
      "referenceID" : 8,
      "context" : "Confidence Calibration: Modern deep neural networks suffer from the over-confidence issue (Guo et al., 2017; Kumar and Sarawagi, 2019), and various remedies are proposed (Pereyra et al.",
      "startOffset" : 90,
      "endOffset" : 134
    }, {
      "referenceID" : 21,
      "context" : "Confidence Calibration: Modern deep neural networks suffer from the over-confidence issue (Guo et al., 2017; Kumar and Sarawagi, 2019), and various remedies are proposed (Pereyra et al.",
      "startOffset" : 90,
      "endOffset" : 134
    }, {
      "referenceID" : 31,
      "context" : ", 2017; Kumar and Sarawagi, 2019), and various remedies are proposed (Pereyra et al., 2017; Mukhoti et al., 2020; Lin et al., 2017).",
      "startOffset" : 69,
      "endOffset" : 131
    }, {
      "referenceID" : 28,
      "context" : ", 2017; Kumar and Sarawagi, 2019), and various remedies are proposed (Pereyra et al., 2017; Mukhoti et al., 2020; Lin et al., 2017).",
      "startOffset" : 69,
      "endOffset" : 131
    }, {
      "referenceID" : 26,
      "context" : ", 2017; Kumar and Sarawagi, 2019), and various remedies are proposed (Pereyra et al., 2017; Mukhoti et al., 2020; Lin et al., 2017).",
      "startOffset" : 69,
      "endOffset" : 131
    }, {
      "referenceID" : 10,
      "context" : "tion, in which a learned teacher model is distilled to a student model by minimizing a KL term (Hinton et al., 2015; Kim and Rush, 2016).",
      "startOffset" : 95,
      "endOffset" : 136
    }, {
      "referenceID" : 17,
      "context" : "tion, in which a learned teacher model is distilled to a student model by minimizing a KL term (Hinton et al., 2015; Kim and Rush, 2016).",
      "startOffset" : 95,
      "endOffset" : 136
    }, {
      "referenceID" : 1,
      "context" : "The most related work comparing to ours is the C-MLM approach (Chen et al., 2020), in which a BERT model is fine-tuned to be a teacher.",
      "startOffset" : 62,
      "endOffset" : 81
    }, {
      "referenceID" : 17,
      "context" : "This setting differs from conventional knowledge distillation (Kim and Rush, 2016) because it facilitates more flexible controls over q′, so that we can use the factor ε to determine the supervision signal provided for the target word yt.",
      "startOffset" : 62,
      "endOffset" : 82
    }, {
      "referenceID" : 16,
      "context" : "Note that using one layer in Da does not necessarily downgrade its performance (Kasai et al., 2021).",
      "startOffset" : 79,
      "endOffset" : 99
    }, {
      "referenceID" : 24,
      "context" : "We use two benchmark datasets for open-domain dialogue generation: DailyDialog (Li et al., 2017) is a high-quality multi-turn dialogue dataset that is collected from daily conversations.",
      "startOffset" : 79,
      "endOffset" : 96
    }, {
      "referenceID" : 35,
      "context" : "The backbone of our model is the transformerbased sequence to sequence model (Vaswani et al., 2017), and most hyper-parameters follow Cai et al.",
      "startOffset" : 77,
      "endOffset" : 99
    }, {
      "referenceID" : 3,
      "context" : "php BERT (Devlin et al., 2019) is used, and the Adam optimizer (Kingma and Ba, 2015) is employed to train our model from random initializations with a learning rate of 1e-4.",
      "startOffset" : 9,
      "endOffset" : 30
    }, {
      "referenceID" : 18,
      "context" : ", 2019) is used, and the Adam optimizer (Kingma and Ba, 2015) is employed to train our model from random initializations with a learning rate of 1e-4.",
      "startOffset" : 40,
      "endOffset" : 61
    }, {
      "referenceID" : 32,
      "context" : "The first group modifies the training target used to compute the loss function: 1) LS (Szegedy et al., 2016): uses the label smoothing approach to construct a target distribution by adding the onehot target and a uniform distribution; 2) FL (Lin et al.",
      "startOffset" : 86,
      "endOffset" : 108
    }, {
      "referenceID" : 26,
      "context" : ", 2016): uses the label smoothing approach to construct a target distribution by adding the onehot target and a uniform distribution; 2) FL (Lin et al., 2017): uses the focal loss to down-weigh well-classified tokens in each time step.",
      "startOffset" : 140,
      "endOffset" : 158
    }, {
      "referenceID" : 14,
      "context" : "3) FACE (Jiang et al., 2019): uses the frequency-aware crossentropy loss to balance per-token training losses.",
      "startOffset" : 8,
      "endOffset" : 28
    }, {
      "referenceID" : 2,
      "context" : "4) F2 (Choi et al., 2020): factorizes the target distribution based on the token frequencies.",
      "startOffset" : 6,
      "endOffset" : 25
    }, {
      "referenceID" : 31,
      "context" : "The second group of baselines add some penalty term to the standard MLE loss: 5) CP (Pereyra et al., 2017): a confidence penalty term is added to regularize the entropy of the model, so that over-confident predictions are penalized; 6) UL (Welleck et al.",
      "startOffset" : 84,
      "endOffset" : 106
    }, {
      "referenceID" : 37,
      "context" : ", 2017): a confidence penalty term is added to regularize the entropy of the model, so that over-confident predictions are penalized; 6) UL (Welleck et al., 2020): an unlikelihood loss term is added to penalize the frequently generated words.",
      "startOffset" : 140,
      "endOffset" : 162
    }, {
      "referenceID" : 9,
      "context" : "7) NL (He and Glass, 2020): works similarly with baseline UL except a negative loss term is used instead of the unlikelihood loss term.",
      "startOffset" : 6,
      "endOffset" : 26
    }, {
      "referenceID" : 25,
      "context" : "8) D2GPo (Li et al., 2019): augments the MLE loss with a data-dependent gaussian prior objective to assign different losses for different non-target words.",
      "startOffset" : 9,
      "endOffset" : 26
    }, {
      "referenceID" : 22,
      "context" : "Metrics: We first used automatic metrics to evaluate our method: 1) Distinct (Dist) (Li et al., 2016) calculates the proportion of unique n-grams (n=1, 2) in the generated responses, which is widely used to measure the response diversity.",
      "startOffset" : 84,
      "endOffset" : 101
    }, {
      "referenceID" : 40,
      "context" : "2) Entropy (Ent) (Zhang et al., 2018) evaluates how evenly the empirical n-gram (n=1, 2) distribution is.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 25,
      "context" : "3) LowFrequency Token Ratio (LF) (Li et al., 2019) further measures the model diversity by counting the ratio of low-frequency words in the generated responses.",
      "startOffset" : 33,
      "endOffset" : 50
    }, {
      "referenceID" : 30,
      "context" : "4) BLEU (Papineni et al., 2002) measures n-gram (n=2, 3, 4) overlap between the generated responses and references.",
      "startOffset" : 8,
      "endOffset" : 31
    }, {
      "referenceID" : 5,
      "context" : "The inter-rater annotation agreement was measured using Fleiss’s kappa κ (Fleiss, 1971).",
      "startOffset" : 73,
      "endOffset" : 87
    }, {
      "referenceID" : 34,
      "context" : "Note that the truncation for the tail of v is still applied since its effectiveness has already been proved in previous studies (Tang et al., 2020; Tan et al., 2019); 4).",
      "startOffset" : 128,
      "endOffset" : 165
    }, {
      "referenceID" : 33,
      "context" : "Note that the truncation for the tail of v is still applied since its effectiveness has already been proved in previous studies (Tang et al., 2020; Tan et al., 2019); 4).",
      "startOffset" : 128,
      "endOffset" : 165
    } ],
    "year" : 2021,
    "abstractText" : "Neural dialogue generation models trained with the one-hot target distribution suffer from the over-confidence issue, which leads to poor generation diversity as widely reported in the literature. Although existing approaches such as label smoothing can alleviate this issue, they fail to adapt to diverse dialog contexts. In this paper, we propose an Adaptive Label Smoothing (AdaLabel) approach that can adaptively estimate a target label distribution at each time step for different contexts. The maximum probability in the predicted distribution is used to modify the soft target distribution produced by a novel light-weight bi-directional decoder module. The resulting target distribution is aware of both previous and future contexts and is adjusted to avoid over-training the dialogue model. Our model can be trained in an endto-end manner. Extensive experiments on two benchmark datasets show that our approach outperforms various competitive baselines in producing diverse responses.",
    "creator" : "LaTeX with hyperref"
  }
}