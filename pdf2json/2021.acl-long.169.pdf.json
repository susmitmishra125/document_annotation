{
  "name" : "2021.acl-long.169.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "PLOTCODER: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context",
    "authors" : [ "Xinyun Chen", "Linyuan Gong", "Alvin Cheung", "Dawn Song" ],
    "emails" : [ "dawnsong}@berkeley.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2169–2181\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n2169"
    }, {
      "heading" : "1 Introduction",
      "text" : "Visualizations play a crucial role in obtaining insights from data. While a number of libraries (Hunter, 2007; Seaborn, 2020; Bostock et al., 2011) have been developed for creating visualizations that range from simple scatter plots to complex 3D bar charts, writing visualization code remains a difficult task. For instance, drawing a scatter plot using the Python matplotlib library can be done using both the scatter and plot methods, and the scatter method (Matplotlib, 2020) takes in 2 required parameters (the values to plot) along with 11 other optional parameters (marker type, color, etc), with some parameters having numeric types (e.g., the size of each marker) and some being\n1Our code and data are available at https://github. com/jungyhuk/plotcoder.\narrays (e.g., the list of colors for each collection of the plotted data, where each color is specified as a string or another array of RGB values). Looking up each parameter’s meaning and its valid values remains tedious and error-prone, and the multitude of libraries available further compounds the difficulty for developers to create effective visualizations.\nIn this paper, we propose to automatically synthesize visualization programs using a combination of natural language utterances and the programmatic context that the visualization program will reside (e.g., code written in the same file as the visualization program to load the plotted data), focusing on programs that create static visualizations (e.g., line charts, scatter plots, etc). While there has been prior work on synthesizing code from natural language (Zettlemoyer and Collins, 2012; Oda et al., 2015; Wang et al., 2015; Yin et al., 2018), and with addition information such as database schemas (Zhong et al., 2017; Yu et al., 2018, 2019b,a) or input-output examples (Polosukhin and Skidanov, 2018; Zavershynskyi et al., 2018), synthesizing general-purpose code from natural language remains highly difficult due to the ambiguity in the natural language input and complexity of the target. Our key insight in synthesizing visualization programs is to leverage their properties: they tend to be short, do not use complex programmatic control structures (typically a few lines of method calls without any control flow or loop constructs), with each method call restricted to a single plotting command (e.g., scatter, pie) along with its parameters (e.g., the plotted data). This influences our model architecture design as we will explain.\nTo study the visualization code synthesis problem, we use the Python Jupyter notebooks from the JuiCe dataset (Agashe et al., 2019), where each notebook contains the visualization program and its programmatic context. These notebooks\nare crawled from GitHub and written by various programmers, thus a main challenge is understanding the complexity and the noisiness of real-world programmatic contexts and the huge variance in the quality of natural language comments. Unfortunately, using standard LSTM-based models and Transformer architectures (Vaswani et al., 2017) fails to solve the task, as noted in prior work (Agashe et al., 2019).\nWe observe that while data to be plotted is usually stored in pandas dataframes (Pandas, 2020), they are not explicitly annotated in JuiCe. Hence, unlike prior work, we augment the programmatic context with dataframe names and their schema when available in predicting the plotted data.\nWe next utilize our insight above and design a hierarchical deep neural network code generation model called PLOTCODER that decomposes synthesis into two subtasks: generating the plot command, then the parameters to pass in given the command. PLOTCODER uses a pointer network architecture (Vinyals et al., 2015), which allows the model to directly select code tokens in the previous code cells in the same notebook as the plotted data. Meanwhile, inspired by the schema linking techniques proposed for semantic parsing with structured inputs, such as text to SQL tasks (Iyer et al., 2017; Wang et al., 2019a; Guo et al., 2019), PLOTCODER’s encoder connects the embedding of the natural language descriptions with their corresponding code fragments in previous code cells within each notebook. Although the constructed links can be noisy because the code context is less structured than the database tables in text-to-SQL problems, we observe that our approach results in substantial performance gain.\nWe evaluate PLOTCODER’s ability to synthesize visualization programs using Jupyter notebooks of homework assignments or exam solutions. On the gold test set where the notebooks are official solutions, our best model correctly predicts the plot types for over 80% of samples, and precisely predicts both the plot types and the plotted data for over 50% of the samples. On the more noisy test splits with notebooks written by students, which may include work-in-progress code, our model still achieves over 70% plot type prediction accuracy, and around 35% accuracy for generating the entire code, showing how PLOTCODER’s design decisions improve our prediction accuracy.\nPLOTCODER: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context Anonymous NAACL-HLT 2021 submission Abstract\n001\nNatural Language Explore the relationship between rarity and a skill of your choice. Choose one skill (‘Attack’,‘Defense’ or ‘Speed’) and do the following. Use the scipy package to assess whether Catch Rate predicts the skill. Create a scatterplot to visualize how the skill depends upon the rarity of the pokemon. Overlay a best fit line onto the scatterplot.\nLocal Code Context slope, intercept, r_value, p_value, std_err =\nlinregress(df['Catch_Rate'], df['Speed'],) x = np.arange(256) y = slope * x + intercept Distant Dataframe Context df['Weight_kg'].describe() df['Color'].value_counts().plot(kind='bar') df['Body_Style'].value_counts().plot(kind='bar') grouped = df.groupby(['Body_Style','hasGender',]).mean() df.groupby('Color')['Attack'].mean() df.groupby('Color')['Pr_Male'].mean() df.sort_values('Catch_Rate',ascending=False).head() Dataframe Schema df: ['Catch_Rate', 'Speed', 'Weight_kg', 'Color',\n'Body_Style']\nGround Truth plt.scatter(df['Catch_Rate'], df['Speed']) plt.plot(x,y)002\n(a) Natural Language Create a scatter plot of the observations in the ‘credit’ dataset for the attributes ‘Duration’ and ‘Age’ (age should be shown on the xaxis).\nLocal Code Context duration = credit['Duration'].values age = credit['Age'].values Ground Truth plt.scatter(age, duration)\nPrediction plt.scatter(duration, age)003\n(b) Natural Language This graph provides more evidence that the higher a state’s participation rates, the lower that state’s averages scores are likely to be. The higher the participation rate, the lower the expected average verbal scores.\nLocal Code Context plt.plot(sat_data['Math'], sat_data['Verbal']) Dataframe Schema sat: ['Rate', 'Math', 'Verbal'] Ground Truth plt.plot(sat_data['Rate'], sat_data['Math']) plt.plot(sat_data['Rate'], sat_data['Verbal']) Prediction plt.plot(sat_data['Math'], sat_data['Verbal']) plt.plot(sat_data['Rate'], sat_data['Verbal']) 004\n(a) Natural Language Plot a Gaussian by looping through a range of x values and creating a resulting list of Gaussian values, g\nLocal Code Context x_axis = np.arange(-20, 20, 0.1) g = [] for x in x_axis:\ng.append(f(mu, sigma2, x))\nGround Truth & Prediction plt.plot(x_axis, g) 005\n(b) Natural Language Like in Q9, let’s start by thinking about two dice\nLocal Code Context results = [] for i in range(1,7):\nfor j in range(1,7): print((i,j),max(i,j)) results.append(max(i,j))\nGround Truth & Prediction plt.hist(results) 006\n1\nFigure 1: An example of plot code synthesis problem studied in this work. Given the natural language, code context within a few code cells from the target code, and other code snippets related to dataframes, PLOTCODER synthesizes the data visualization code."
    }, {
      "heading" : "2 Related Work",
      "text" : "There has been work on translating natural language to code in different languages (Zettlemoyer and Collins, 2012; Wang et al., 2015; Oda et al., 2015; Yin et al., 2018; Zhong et al., 2017; Yu et al., 2018; Lin et al., 2018). While the input specification only includes the natural language for most tasks, prior work also uses additional information for program prediction, including database schemas and contents for SQL query synthesis (Zhong et al., 2017; Yu et al., 2018, 2019b,a), input-output examples (Polosukhin and Skidanov, 2018; Zavershynskyi et al., 2018), and code context (Iyer et al., 2018; Agashe et al., 2019). There has also been work on synthesizing data manipulation programs only from input-output examples (Drosos et al., 2020; Wang et al., 2017). In this work, we focus on synthesizing visualization code from both natural language description and code context, and we construct our benchmark based on the Python Jupyter notebooks from the JuiCe (Agashe et al., 2019). Compared to JuiCe’s input format, we also annotate dataframe schema if available, which is especially important for visualization code synthesis.\nPrior work has studied generating plots from other specifications. Falx (Wang et al., 2019b,\n2021) synthesizes plots from input-output examples, but do not use any learning technique, and focuses on developing a domain-specific language for plot generation instead. In (Dibia and Demiralp, 2019), the authors apply a standard LSTM-based sequence-to-sequence model with attention for plot generation, but the model takes in only raw data to be visualized with no natural language input. The visualization code synthesis problem studied in our work is much more complex, where both the natural language and the code context can be long, and program specifications are implicit and ambiguous.\nOur design of hierarchical program decoding is inspired by prior work on sketch learning for program synthesis, where various sketch representations have been proposed for different applications (Solar-Lezama, 2008; Murali et al., 2018; Dong and Lapata, 2018; Nye et al., 2019). Compared to other code synthesis tasks, a key difference is that our sketch representation distinguishes between dataframes and other variables, which is important for synthesizing visualization code.\nOur code synthesis problem is also related to code completion, i.e., autocompleting the program given the code context (Raychev et al., 2014; Li et al., 2018; Svyatkovskiy et al., 2020). However, standard code completion only requires the model to generate a few tokens following the code context, rather than entire statements. In contrast, our task requires the model to synthesize complete and executable visualization code. Furthermore, unlike standard code completion, our model synthesizes code from both the natural language description and code context. Nevertheless, when the prefix of the visualization code is given, our model could also be used for code completion, by including the given partial code as part of the code context."
    }, {
      "heading" : "3 Visualization Code Synthesis Problem",
      "text" : "We now discuss our problem setup of synthesizing visualization code in programmatic context, where the model input includes different types of specifications. We first describe the model inputs, then introduce our code canonicalization process to make it easier to train our models and evaluate the accuracy, and finally our evaluation metrics."
    }, {
      "heading" : "3.1 Program Specification",
      "text" : "We illustrate our program specification in Figure 1, which represents a Jupyter notebook fragment. Our task is to synthesize the visualization code given\nthe natural language description and code from the preceding cells. To do so, our model takes in the following inputs: • The natural language description for the visual-\nization, which we extract from the natural language markdown above the target code cell containing the gold program in the notebook. • The local code context, defined as a few code cells that immediately precede the target code cell. The number of cells to include is a tunable hyper-parameter to be described in Section 5. • The code snippets related to dataframe manipulation that appear before the target code cell in the notebook, but are not included in the local code context. We refer to such code as the distant dataframe context. When such context contains code that uses dataframes, they are part of the model input by default. As mentioned in Section 1, unlike JuiCe, we also extract the code snippets related to dataframes, and annotate the dataframe schemas according to their syntax trees. As shown in Figure 1, knowing the column names in each dataframe is important for our task, as dataframes are often used for plotting."
    }, {
      "heading" : "3.2 Code Canonicalization",
      "text" : "One way to train our models is to directly utilize the plotting code in Jupyter notebooks as the ground truth. However, due to the variety of plotting APIs and coding styles, such a model rarely predicts exactly the same code as written in Jupyter notebooks. For example, there are at least four ways in Matplotlib (and similar in other libraries) to create a scatter plot for columns ‘y’ against ‘x’ from a dataframe df: plt.scatter(df[’x’],df[’y’]), plt.plot(df[’x’],df[’y’],’o’), df.plot.scatter(x=’x’,y=’y’), df.plot(kind=’scatter’,x=’x’,y=’y’). Moreover, given that the natural language description is ambiguous, many plot attributes are hard to precisely predict. For example, from the context shown in Figure 1, there are many valid ways to specify the plot title, the marker style, axis ranges, etc. In our experiments, we find that when trained on raw target programs, fewer than 5% predictions are exactly the same as the ground truth, and a similar phenomenon is also observed earlier (Agashe et al., 2019).\nTherefore, we design a canonical representation for plotting programs, which covers the core of plot generation. Specifically, we convert the plotting\ncode into one of the following templates: • LIB.PLOT TYPE(X,{Y}∗), where LIB is a plot-\nting library, and PLOT TYPE is the plot type to be created. The number of arguments may vary for different PLOT TYPE, e.g., 1 for histograms and pie charts, and 2 for scatter plots. • L0 \\n L1 \\n ... Lm, where each Li is a plotting command in the above template, and \\n are separators. For example, when using plt as the library (a commonly used abbreviation of matplotlib.pyplot), we convert df.plot(kind=’scatter’,x=’x’,y=’y’) into plt.scatter(df[’x’],df[’y’]), where LIB = plt and PLOT TYPE = scatter. Plotting code in other libraries could be converted similarly.\nThe tokens that represent the plotted data, i.e., X and Y, are annotated in the code context as follows: • VAR, when the token is a variable name, e.g., x\nand y in Figure 1. • DF, when the token is a Pandas dataframe or a\nPython dictionary, e.g., df in Figure 1. • STR, when the token is a column name of a\ndataframe, or a key name of a Python dictionary, such as ‘Catch Rate’ and ‘Speed’ in Figure 1. The above annotations are used to cover different types of data references. For example, a column in a dataframe is usually referred to as DF[STR], and sometimes as DF[VAR] where VAR is a string. In Section 4.2, we will show how to utilize these annotations for hierarchical program decoding, where our decoder first generates a program sketch that predicts these token types without the plotted data, then predicts the actual plotted data subsequently."
    }, {
      "heading" : "3.3 Evaluation Metrics",
      "text" : "Plot type accuracy. To compute this metric, we categorize all plots into several types, and a prediction is correct when it belongs to the same type as the ground truth. In particular, we consider the following categories: (1) scatter plots (e.g., generated by plt.scatter); (2) histograms (e.g., generated by plt.hist); (3) pie charts (e.g., generated by plt.pie); (4) a scatterplot overlaid by a line (e.g., such as that shown in Figure 1, or generated by sns.lmplot); (5) a plot including a kernel density estimate (e.g., plots generated by sns.distplot or sns.kdeplot); and (6) others, which are mostly plots generated by plt.plot.\nPlotted data accuracy. This metric measures whether the predicted program selects the same\ndata to plot as the ground truth. Unless otherwise specified, the ordering of variables must match the ground truth as well, i.e., swapping the data used to plot x and y axes result in different plots. Program accuracy. We consider a predicted program to be correct if both the plot type and plotted data are correct. As discussed in Section 3.2, we do not evaluate the correctness of other plot attributes because they are mostly unspecified."
    }, {
      "heading" : "4 PLOTCODER Model Architecture",
      "text" : "In this section, we present PLOTCODER, a hierarchical model architecture for synthesizing visualization code from natural language and code context. PLOTCODER includes an LSTM-based encoder (Hochreiter and Schmidhuber, 1997) to jointly embed the natural language and code context, as well as a hierarchical decoder that generates API calls and selects data for plotting. We provide an overview of our model architecture in Figure 2."
    }, {
      "heading" : "4.1 NL-Code Context Encoder",
      "text" : "PLOTCODER’s encoder computes a vector representation for each token in the natural language description and the code context, where the code context is the concatenation of the code snippets describing dataframe schemas and the local code cells, as described in Section 3.1. NL encoder. We build a vocabulary for the natural language tokens, and train an embedding matrix for it. Afterwards, we use a bi-directional LSTM to encode the input natural language sequence (denoted as LSTMnl), and use the LSTM’s output at each timestep as the contextual embedding vector for each token. Code context encoder. We build a vocabulary Vc for the code context, and train an embedding matrix for it. Vc also includes the special tokens {VAR, DF, STR} used for sketch decoding in Section 4.2. We train another bi-directional LSTM (LSTMc), which computes a contextual embedding vector for each token in a similar way to the natural language encoder. We denote the hidden state of LSTMc at the last timestep as Hc. NL-code linking. Capturing the correspondence between the code context and natural language is crucial in achieving a good prediction performance. For example, in Figure 2, PLOTCODER infers that the dataframe column “age” should be plotted, as this column name is mentioned in the natural language description. Inspired by this observation, we\ndesign the NL-code linking mechanism to explicitly connect the embedding vectors of code tokens and their corresponding natural language words. Specifically, for each token in the code context that also occurs in the natural language, let hc and hnl be its embedding vectors computed by LSTMc and LSTMnl, respectively, we compute a new code token embedding vector as: h′c = Wl([hc;hnl]) where Wl is a linear layer, and [hc;hnl] is the concatenation of hc and hnl. When no natural language word matches the code token, hnl is the embedding vector of the [EOS] token at the end of the natural language description. When we include this NL-code linking component in the model, h′c replaces the original embedding hc for each token in the code context, and the new embedding is used for decoding. We observe that many informative natural language descriptions explicitly state the variable names and dataframe columns for plotting, which makes our NL-code linking effective. Moreover, this component is especially useful when the variable names for plotting are unseen in the training set, thus NL-code linking provides the only cue to indicate that these variables are relevant."
    }, {
      "heading" : "4.2 Hierarchical Program Decoder",
      "text" : "We train another LSTM to decode the visualization code sequence, denoted as LSTMp. Our decoder generates the program in a hierarchical way. At each timestep, the model first predicts a token from the code token vocabulary that represents the program sketch. As shown in Figure 2, the program sketch does not include the plotted data. After that, the decoder predicts the plotted data, where it employs a copy mechanism (Gu et al., 2016; Vinyals et al., 2015) to select tokens from the code context.\nFirst, we initiate the hidden state of LSTMp with Hc, the final hidden state of LSTMc, and the start token is [GO] for both sketch and full program decoding. At each step t, let st−1 and ot−1 be the\nsketch token and output program token generated at the previous step. Note that st−1 and ot−1 are different only when st−1 ∈ {VAR, DF, STR}, where ot−1 is the actual data name with the corresponding type. Let est−1 and eot−1 be the embedding vectors of st−1 and ot−1 respectively, which are computed using the same embedding matrix for the code context encoder. The input of LSTMp is the concatenation of the two embedding vectors, i.e., [est−1; eot−1]. Attention. To compute attention vectors over the natural language description and the code context, we employ the two-step attention in (Iyer et al., 2018). Specifically, we first use hpt to compute the attention vector over the natural language input using the standard attention mechanism (Bahdanau et al., 2015), and we denote the attention vector as attnt. Then, we use attnt to compute the attention vector over the code context, denoted as attpt. Sketch decoding. For sketch decoding, the model computes the probability distribution among all sketch tokens in the code token vocabulary Vc:\nPr(st) = Softmax(Ws(hpt + attnt + attpt))\nHere Ws is a linear layer. For hierarchical decoding, we do not allow the model to directly decode the names of the plotted data during sketch decoding, so st is selected only from the valid sketch tokens, such as library names, plotting function names, and special tokens for plotted data representation in templates discussed in Section 3.2. Data selection. For st ∈ {VAR, DF, STR}, we use the copy mechanism to select the plotted data from the code context. Specifically, our decoder includes 3 pointer networks (Vinyals et al., 2015) for selecting data with the type VAR, DF, and STR respectively, and they employ similar architectures but different model parameters.\nWe take variable name selection as an instance to illustrate our data selection approach using the copy\nSplit Train Dev (gold) Test (gold) Dev (hard) Test (hard)\nmechanism. We first compute vt = Wv(attnt), where Wv is a linear layer. For the i-th token ci in the code context, let hci be its embedding vector, we compute its prediction probability as:\nPr(ci) = exp vTt hci∑ j exp v T t hcj\nAfter that, the model selects the token with the highest prediction probability as the next program token ot, and uses the corresponding embedding vectors for st and ot as the input for the next decoding step of LSTMp.\nThe decoding process terminates when the model generates the [EOF] token."
    }, {
      "heading" : "5 Experiments",
      "text" : "In this section, we first describe our dataset for visualization code synthesis, then introduce our experimental setup and discuss the results."
    }, {
      "heading" : "5.1 Dataset Construction",
      "text" : "We build our benchmark upon the JuiCe dataset, and select those that call plotting APIs, including those from matplotlib.pyplot (plt), pandas.DataFrame.plot, seaborn (sns), ggplot, bokeh, plotly, geoplotlib, pygal. Over 99% of the samples use plt, pandas.DataFrame.plot, or sns. We first extract plot samples from the original dev and test splits of JuiCe to construct Dev (gold) and Test (gold). However, the gold splits are too small to obtain quantitative results. Therefore, we extract around 1,700 Jupyter notebooks of homeworks and exams from JuiCe’s training set, and split them roughly evenly into Dev (hard) and Test (hard). All remaining plot samples from the JuiCe training split are included in our training set. The length of the visualization programs to be generated varies between 6 and 80 tokens, but the code context is typically much longer. We summarize the dataset statistics in Table 1."
    }, {
      "heading" : "5.2 Evaluation Setup",
      "text" : "Implementation details. Unless otherwise specified, for the input specification we include K = 3 previous code cells as the local context, which usually provides the best accuracy. We set 512 as the length limit for both the natural language and the code context. For all model architectures, we train them for 50 epochs, and select the best checkpoint based on the program accuracy on the Dev (hard) split. More details are deferred to Appendix A.\nBaselines. We compare the full PLOTCODER against the following baselines: (1) - Hierarchy: the encoder is the same as in the full PLOTCODER, but the decoder directly generates the full program without predicting the sketch. (2) - Link: the encoder does not use NL-code linking, and the decoder is not hierarchical. (3) LSTM: the model does not use NL-code linking, copy mechanism, and hierarchical decoding. The encoder still uses two separate LSTMs to embed the natural language and code context, which performs better than the LSTM baseline in prior work (Agashe et al., 2019). (4) + BERT: we use the same hierarchical decoder as the full model, but replace the encoder with a Transformer architecture (Vaswani et al., 2017) initialized from a pre-trained model, and we fine-tune the encoder with other part of the model. We evaluated two pre-trained models. One is RoBERTa-base (Liu et al., 2019), an improved version of BERT-Base (Devlin et al., 2018) pre-trained on a large text corpus. Another is codeBERT (Feng et al., 2020), which has the same architecture as RoBERTa-base, but is pre-trained on GitHub code in several programming languages including Python, and has demonstrated good performance on code retrieval tasks. To demonstrate the effectiveness of target code canonicalization discussed in Section 3.2, we also compare with models that are directly trained on the raw ground truth code from the same set of Jupyter notebooks."
    }, {
      "heading" : "5.3 Results",
      "text" : "We present the program prediction accuracies in Table 2. First, training on the canonicalized code significantly boosts the performance for all models, suggesting that canonicalization improves data quality and hence prediction accuracies. When trained with target code canonicalization, the full PLOTCODER significantly outperforms other model variants on different data splits. On the hard data splits, the hierarchical PLOTCODER predicts\n35% of the samples correctly, improving over the non-hierarchical model by 3− 4.5%. Meanwhile, NL-code linking enables the model to better capture the correspondence between the code context and the natural language, and consistently improves the performance when trained on canonicalized target code. Without the copy mechanism, the baseline LSTM cannot predict any token outside of the code vocabulary. Therefore, this model performs worse than other LSTM-based models, especially on plotted data accuracies, as shown in Table 3.\nInterestingly, while our hierarchical decoding, NL-code linking, and copy mechanism are mainly designed to improve the prediction accuracy of the plotted data, as shown in Table 4, we observe that the plot type accuracies of our full model are also mostly better, especially on the hard splits. To better understand this, we break down the results by plot type, and observe that the most significant improvement comes from the predictions of scatter plots (“S”) and plots in “Others” category. We posit that these two categories constitute the majority of the dataset, and the hierarchical model learns to better categorize plot types from a large number of training samples. In addition, we observe that the full model does not always perform better than other baselines on data splits of small sizes, and the difference mainly comes from the ambiguity in the natural language description. We defer more discussion to Section 5.4.\nAlso, using BERT-like encoders does not improve the results. This might be due to the difference in data distribution for pre-training and vocabularies. Specifically, RoBERTa is pre-trained on English passages, which does not include many visualization-related descriptions and code comments. Therefore, the subword vocabulary utilized by RoBERTa breaks down important keywords for visualization, e.g., “scatterplots” and “histograms” into multiple words, which limits model performance, especially for plot type prediction. Using codeBERT improves the performance of RoBERTa, but it still does not improve over the LSTM-based models, which may again due to vocabulary mismatch. As a result, in Table 4, the plot type accuracies of both models using BERT-like encoders are considerably lower than the LSTM-based models.\nTo better understand the plotted data prediction performance, in addition to the default plotted data accuracy that requires the data order to be the same as the ground truth, we also evaluate a relaxed\nModel Test (hard) Dev (hard) Test (gold) Dev (gold)\nModel Test (hard) Dev (hard) Test (gold) Dev (gold)\nversion without ordering constraints. Note that the ordering includes two factors: (1) the ordering of the plotted data for the different axes; and (2) the ordering of plots when multiple plots are included. We observe that the ordering issue happens for around 1.5% of samples, and is more problematic for scatter plots (“S”) and “Others.” Figure 3 shows sample predictions where the model selects the correct set of data to plot, but the ordering is wrong. Although sometimes the natural language explicitly specifies which axes to plot (e.g., Figure 3 (a)), such descriptions are mostly implicit (e.g., Figure 3 (b)), making it hard for the model to learn. Full results on different plot types are in Section 5.4."
    }, {
      "heading" : "5.3.1 The Effect of Different Model Inputs",
      "text" : "To evaluate the effect of including different input specifications, we present the results in Table 5. Specifically, - NL means the model input does not include the natural language, and - Distant DFs means the code context only includes the local code cells. Interestingly, even without the natural language description, PLOTCODER correctly predicts a considerable number of samples. Figure 4 shows sample correct predictions without relying on the natural language description. To predict the plotted\nModel Test (hard) Dev (hard) Test (gold) Dev (gold)\nWith code canonicalization Full Model 70.58% 71.46% 83.33% 78.95% − Hierarchy 64.65% 68.92% 87.50% 82.46% − Link 65.32% 64.09% 81.25% 73.68% LSTM 66.67% 67.47% 85.42% 85.96% + codeBERT 65.44% 67.96% 75.00% 57.89% + RoBERTa 65.21% 66.38% 66.67% 54.39%\nWithout code canonicalization Full Model 63.53% 65.66% 72.92% 80.70% − Hierarchy 61.41% 67.47% 66.67% 73.68% − Link 61.30% 63.72% 64.58% 77.19% LSTM 64.65% 65.78% 81.25% 70.18% + CodeBERT 56.04% 57.07% 60.42% 56.14% + RoBERTa 61.30% 61.91% 68.75% 49.12%\nTable 4: Evaluation on plot type accuracy.\nPLOTCODER: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context\nAnonymous NAACL-HLT 2021 submission\nAbstract 001\nNatural Language Explore the relationship between rarity and a skill of your choice. Choose one skill (‘Attack’,‘Defense’ or ‘Speed’) and do the following. Use the scipy package to assess whether Catch Rate predicts the skill. Create a scatterplot to visualize how the skill depends upon the rarity of the pokemon. Overlay a best fit line onto the scatterplot.\nLocal Code Context slope, intercept, r_value, p_value, std_err =\nlinregress(df['Catch_Rate'], df['Speed'],) x = np.arange(256) y = slope * x + intercept Distant Dataframe Context df['Weight_kg'].describe() df['Color'].value_counts().plot(kind='bar') df['Body_Style'].value_counts().plot(kind='bar') grouped = df.groupby(['Body_Style','hasGender',]).mean() df.groupby('Color')['Attack'].mean() df.groupby('Color')['Pr_Male'].mean() df.sort_values('Catch_Rate',ascending=False).head() Dataframe Schema df: ['Catch_Rate', 'Speed', 'Weight_kg', 'Color',\n'Body_Style']\nGround Truth plt.scatter(df['Catch_Rate'], df['Speed']) plt.plot(x,y)002\n(a) Natural Language Plot a Gaussian by looping through a range of x values and creating a resulting list of Gaussian values, g\nLocal Code Context x_axis = np.arange(-20, 20, 0.1) g = [] for x in x_axis:\ng.append(f(mu, sigma2, x)) Ground Truth & Prediction plt.plot(x_axis, g)003\n(b) Natural Language Like in Q9, let’s start by thinking about two dice\nLocal Code Context results = [] for i in range(1,7):\nfor j in range(1,7): print((i,j),max(i,j)) results.append(max(i,j)) Ground Truth & Prediction plt.hist(results)004\n(a) Natural Language Create a scatter plot of the observations in the ‘credit’ dataset for the attributes ‘Duration’ and ‘Age’ (age should be shown on the xaxis).\nLocal Code Context duration = credit['Duration'].values age = credit['Age'].values Ground Truth plt.scatter(age, duration) Prediction\nplt.scatter(duration, age) 005\n(b) Natural Language This graph provides more evidence that the higher a state’s participation rates, the lower that state’s averages scores are likely to be. The higher the participation rate, the lower the expected average verbal scores.\nLocal Code Context plt.plot(sat_data['Math'], sat_data['Verbal']) Dataframe Schema sat: ['Rate', 'Math', 'Verbal'] Ground Truth plt.plot(sat_data['Rate'], sat_data['Math']) plt.plot(sat_data['Rate'], sat_data['Verbal']) Prediction plt.plot(sat_data['Math'], sat_data['Verbal']) plt.plot(sat_data['Rate'], sat_data['Verbal']) 006\n1\nFigure 3: Examples of predictions where the model selects the correct set of data to plot, but the order is wrong.\ndata, a simple yet effective heuristic is to select variable names appearing in the most recent code context. This is also one possible reason that causes the wrong data ordering prediction in Figure 3(a); in fact, the prediction is correct if we change the order of assignment statements for variables age and duration in the code context.\nInput Test (hard) Dev (hard) Test (gold) Dev (gold) Full input 34.79% 34.70% 56.25% 47.37% − Distant DFs 34.34% 34.10% 52.08% 45.61% − NL 27.52% 28.42% 43.75% 21.05%\nTable 5: Evaluation on the full hierarchical model with different inputs.\nMeanwhile, we evaluated PLOTCODER by varying the number of local code cells K. The results show that the program accuracies converge or start\nPLOTCODER: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context Anonymous NAACL-HLT 2021 submission Abstract 001\nNatural Language Explore the relationship between rarity and a skill of your choice. Choose one skill (‘Attack’,‘Defense’ or ‘Speed’) and do the following. Use the scipy package to assess whether Catch Rate predicts the skill. Create a scatterplot to visualize how the skill depends upon the rarity of the pokemon. Overlay a best fit line onto the scatterplot.\nLocal Code Context slope, intercept, r_value, p_value, std_err =\nlinregress(df['Catch_Rate'], df['Speed'],) x = np.arange(256) y = slope * x + intercept Distant Dataframe Context df['Weight_kg'].describe() df['Color'].value_counts().plot(kind='bar') df['Body_Style'].value_counts().plot(kind='bar') grouped = df.groupby(['Body_Style','hasGender',]).mean() df.groupby('Color')['Attack'].mean() df.groupby('Color')['Pr_Male'].mean() df.sort_values('Catch_Rate',ascending=False).head() Dataframe Schema df: ['Catch_Rate', 'Speed', 'Weight_kg', 'Color',\n'Body_Style']\nGround Truth plt.scatter(df['Catch_Rate'], df['Speed']) plt.plot(x,y)002\n(a) Natural Language Create a scatter plot of the observations in the ‘credit’ dataset for the attributes ‘Duration’ and ‘Age’ (age should be shown on the xaxis).\nLocal Code Context duration = credit['Duration'].values age = credit['Age'].values Ground Truth plt.scatter(age, duration)\nPredic ion plt.scatter(duration, age)003\n(b) Natural Language This graph provides more evidence that the higher a state’s participation rates, the lower that state’s averages scores are likely to be. The higher the participation rate, the lower the expected average verbal scores. Local Code Context plt.plot(sat_data['Math'], sat_data['Verbal']) Dataframe Schema sat: ['Rate', 'Math', 'Verbal'] Ground Truth plt.plot(sat_data['Rate'], sat_data['Math']) plt.plot(sat_data['Rate'], sat_data['Verbal']) Prediction plt.plot(sat_data['Math'], sat_data['Verbal']) plt.plot(sat_data['Rate'], sat_data['Verbal']) 004\n(a) Natural Language Plot a Gaussian by looping through a range of x values and creating a resulting list of Gaussian values, g\nLocal Code Context x_axis = np.arange(-20, 20, 0.1) g = [] for x in x_axis:\ng.append(f(mu, sigma2, x))\nGround Truth & Prediction plt.plot(x_axis, g) 005\n(b) Natural Language Like in Q9, let’s start by thinking about two dice\nLocal Code Context results = [] for i in range(1,7):\nfor j in range(1,7): print((i,j),max(i,j)) results.append(max(i,j))\nGround Truth & Prediction plt.hist(results) 006\n1\nFigure 4: Examples of model predictions even without the natural language input.\n1\n000 001 002 003 004 005 006 007 008 009\n010\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n050 051 052 053 054 055 056 057 058 059\n060\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099\nACL-IJCNLP 2021 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE. PLOTCODER: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context Anonymous ACL-IJCNLP submission\nAbstr t\nNatural Language Explore the relationship between rarity and a skill of your choice. Choose one skill (‘Attack’,‘Defense’ or ‘Speed’) and do the following. Us the scipy package to assess whether Catch Rate predicts the skill. Create a scatterplot to visualize how the skill depends upon the rarity of the pokemon Overlay a best fit line onto the scatterplot.\nLocal Code Context slope, intercept, r_value, p_value, std_err =\nlinregress(df['Catch_Rate'], df['Speed'],) x = np.arange(256) y = sl pe * x + intercept Distant Dataframe Context df['Weight_kg'].describe() df['Color'].value_counts().plot(kind='bar')\ndf['Body_Style'].value_counts().plot(kind='bar')\ngrouped = df.groupby(['Body_Style','hasGender',]).mean() df.groupby('Color')['Attack'].mean() df.groupby('Color')['Pr_Male'].mean() df.sort_values('Catch_Rate',ascending=False).head() Dataframe Schema df: ['Catch_Rate', 'Speed', 'Weight_kg', 'Color',\n'Body_Style']\nGround Truth plt.scat er(df['Catch_Rate'], df['Speed']) plt.plot(x,y)\n(a) Natural La gu ge Plot Gaussian by looping through a range of x values and creating a r sulting list of Gau sian values, g\nLocal Code Context x_axis = np.arange(-20, 20, 0.1) g = [] for x in x_axis:\ng.append(f(mu, sigma2, x)) Ground Truth & Prediction plt.plot(x_axis, g)\n(b) Natural Language Like in Q9, let’s start by thinking about two dice\nLocal Code Context results = [] for i in range(1,7):\nfor j in range(1,7): print((i,j),max(i,j)) results.append(max(i,j))\nGround Truth & Prediction\nplt.hist(results)\n(a) Natural Language Create a scatter plo of the observations in the ‘credit’ dataset for the attributes ‘Duration’ and ‘Age’ (age should be shown on the xaxis).\nLocal Code Context duration = credit['Duration'].values age = credit['Age'].values Ground Truth plt.scatter(age, duration) Prediction plt.scatter(duration, age)\n(b) Natural Language This graph provides more evidence that the higher a state’s participation rates, the lower that state’s averages scores are likely to be. The higher the participation rate, the lower the expected average verbal scores.\nLocal Code Context plt.plot(sat_data['Math'], sat_data['Verbal']) Dataframe Schema sat: ['Rate', 'Math', 'Verbal'] Ground Truth plt.plot(sat_data['Rate'], sat_data['Math']) plt.plot(sat_data['Rate'], sat_data['Verbal'])\nPrediction\nplt.plot(sat_data['Math'], sat_data['Verbal'])\nplt.plot(sat_data['Rate'], sat_data['Verbal'])\nNatural Language Problem 5. Age groups (1 point) Create a histogram of all people’s ages. Use the default settings. Add the label ”Age” on the x-axis and ”Count” on the y-axis.\nLocal Code Context income_data.columns = [\"age\",\"workclass\",\"fnlwgt\", \"education\",\"education_num\", \"marital_status\", \"occupation\",\"relationship\",\"race\",\"sex\", \"capital_gain\",\"capital_loss\",\"hours_per_week\", \"native_country\",\"income_class\"] ... married_af_peoples = \\\\ income_data[income_data[\"marital_status\"].str.contains( \"Married-AF-spouse\")].shape[0] ... Dataframe Schema income_data: ['age', 'workclass', ..., 'income_class'] married_af_peoples: ['age', 'workclass', ..., 'income_class'] Ground Truth plt.hist(income_data.age) Prediction plt.hist(married_af_peoples.age)\nFigure 5: A sample prediction that requires a good understanding of the code context.\nto decrease when K > 3 for different models, as observed in (Agashe et al., 2019). However, the accuracy drop of our hierarchical model is much less noticeable than the baselines, suggesting that our model is more resilient to the addition of irrelevant code context. See Appendix B for more discussion."
    }, {
      "heading" : "5.4 Prediction Results Per Plot Type",
      "text" : "We present the breakdown results per plot type in Tables 6 and 7. To better understand the plotted data prediction performance, in addition to the default plotted data accuracy that requires the data order to be the same as the ground truth, we also evaluate a relaxed version without ordering constraints, described as permutation invariant in Table 7. We compute the results on Test (hard), which\nhas more samples per plot type than the gold splits. Compared to the non-hierarchical models, the most significant improvement comes from the predictions of scatter plots (“S”) and plots in “Others” category. We posit that these two categories constitute the majority of the dataset, and the hierarchical model learns to better categorize plot types from a large number of training samples. The accuracy of the hierarchical model on some categories is lower than the baseline’s, but the difference is not statistically significant since those categories only contain a few examples. A more detailed discussion is included in Appendix C."
    }, {
      "heading" : "5.4.1 Error Analysis",
      "text" : "To better understand the challenges of our task, we conduct a qualitative error analysis and categorize the main reasons of error predictions. We investigate all error cases on Test (gold) split for the full hierarchical model, and present the results in Table 8. We summarize the key observations below, and defer more discussion to Appendix E. • Around half of error cases are due to the ambigu-\nity of the natural language description. (1-3) • About 10% samples require longer code context\nfor prediction, because the program selects the plotted data from distant code context that exceeds the input length limit. (4)\n• Sometimes the model generates semantically same but syntactically different programs from the ground truth, which can happen when two variables or data frames contain the same data.(5) • Besides understanding complex natural language description, as shown in Figure 3, another challenge is to understand the code context and reason about the data stored in different variables. For example, in Figure 5, although both dataframes income data and married af peoples include the age column, the model must infer that married af peoples is a subset of income data, thus it should select income data to plot the statistics of people from all groups. (6-7)"
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we conduct the first study of visualization code synthesis from natural language and programmatic context. We describe PLOTCODER, a model architecture that includes an encoder that links the natural language description and code context, and a hierarchical program decoder that synthesizes plotted data from the code context and dataframe items. Results on real-world Jupyter notebooks show that PLOTCODER can synthesize visualization code for different plot types, and outperforms various baseline models."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This material is in part based upon work supported by the National Science Foundation under Grant No. TWC-1409915, IIS-1546083, IIS1955488, IIS-2027575, CCF-1723352, DOE award DE-SC0016260, DARPA D3M under Grant No. FA8750-17-2-0091; Berkeley DeepDrive, the IntelNSF CAPA center, and gifts from Adobe, Facebook, Google, and VMware. Xinyun Chen is supported by the Facebook Fellowship."
    }, {
      "heading" : "B Training with Varying Number of Contextual Code Cells",
      "text" : "As discussed in Section 5.3.1, we provide the results of including different number of local code cells as the model input in Figure 6. We also evaluated the upper bounds of program accuracies for different values of K, where we consider an example to be predictable if all plotted data in the target program are covered in the input code context. We observe that including dataframe manipulation code in distant code cells improves the coverage, especially when K is small."
    }, {
      "heading" : "C Detailed Analysis on Results Per Plot Type",
      "text" : "In Section 5.4, we present the breakdown results per plot type in Tables 6 and 7, where we observed that “Scatter” and “Others” constitute the majority\n2RoBERTa: https://github.com/pytorch/fairseq/ tree/master/examples/roberta codeBERT: https://github.com/microsoft/CodeBERT\nof the dataset, and the hierarchical model learns to better categorize plot types from a large number of training samples.\nNote that for categories that the hierarchical model does not perform better than baselines, even if the accuracy differences are noticeable, the numbers of correct predictions do not differ much. For example, among the 13 samples in the “Pie” category, the hierarchical model correctly classifies 8 samples, while the non-hierarchical version makes 10 correct predictions. When looking at the predictions, we observe that the 2 different predictions are mainly due to the ambiguity of the natural language descriptions. Specifically, the text descriptions are “The average score of group A is better than average score of group B in 51% of the state” and “I am analyzing the data of all male passengers”. In fact, for both examples, the hierarchical model still generates a program including the plotted data in the ground truth. However, the hierarchical model wrongly selects plt.bar as the plotting API for the former sample, and selects plt.scatter for the latter sample, where it additionally selects another variable for the x-axis. For these 2 samples, we observe that the code context includes plotting programs that use other data to generate pie charts,\nand the non-hierarchical model picks a heuristic to select the same plot type in the code context when there is no cue provided in the natural language description, while the hierarchical model selects plot types that happen more frequently in the training distribution. A similar phenomenon holds for other categories or data splits with a small number of examples."
    }, {
      "heading" : "D Other Plot Types",
      "text" : "In the “Others” category discussed in Section 3.3, besides the plots generated by plt.plot, there are also other plot types, with much smaller data sizes than plt.plot. In Table 9, we present the breakdown accuracies of some plot types, which constitute the largest percentages in the “Others” category excluding plt.plot samples. Specifically, around 4% samples use boxplot, and each of the other 3 plot types include around 1% samples. Due to the lack of data for such plot types, the results are much lower than the overall accuracies of all plot categories, but still non-trivial."
    }, {
      "heading" : "E More Discussion of Error Analysis",
      "text" : "As discussed in Section 5.4.1, the lack of information in natural language descriptions is the main reason for a large proportion of wrong predictions (categories 1-3 in Table 8). • Many natural language descriptions only mention\nthe plot type, e.g., “Make a scatter plot,” which is one reason that the plot type accuracy is generally much higher than the plotted data accuracy. (1) • Sometimes the text only mentions the plotted data without specifying the plot type, e.g., “Plot the data x1 and x2,” where both plt.plot(x1,x2) and plt.scatter(x1,x2) are possible predictions, and the model needs to infer the plot type from the code context. (2) • The text description includes no plotting information at all, e.g., “Localize your search around the value you found above,” where the model needs to infer which variables are search results and could be plotted. (3)\nWe consider several directions to address different error categories as future work. To mitigate the ambiguity of natural language descriptions, we could incorporate additional program specifications such as input-output examples. Input-output examples are also helpful for evaluating the execution accuracy, which considers all semantically correct programs as correct predictions even if they differ from the ground truth. Most Jupyter notebooks from GitHub do not contain sufficient execution information, e.g., many of them load external data for plotting, and the data sources are not public. Therefore, developing techniques to automatically synthesize input-output examples is a promising future direction. Designing new models for code representation learning is another future direction, which could help address the challenge of embedding long code context."
    } ],
    "references" : [ {
      "title" : "Juice: A large scale distantly supervised dataset for open domain context-based code generation",
      "author" : [ "Rajas Agashe", "Srinivasan Iyer", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Agashe et al\\.,? 2019",
      "shortCiteRegEx" : "Agashe et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Bahdanau et al\\.,? 2015",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2015
    }, {
      "title" : "D3 data-driven documents",
      "author" : [ "Michael Bostock", "Vadim Ogievetsky", "Jeffrey Heer." ],
      "venue" : "IEEE transactions on visualization and computer graphics, 17(12):2301–2309.",
      "citeRegEx" : "Bostock et al\\.,? 2011",
      "shortCiteRegEx" : "Bostock et al\\.",
      "year" : 2011
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Data2vis: Automatic generation of data visualizations using sequence-to-sequence recurrent neural networks",
      "author" : [ "Victor Dibia", "Çağatay Demiralp." ],
      "venue" : "IEEE computer graphics and applications, 39(5):33–46.",
      "citeRegEx" : "Dibia and Demiralp.,? 2019",
      "shortCiteRegEx" : "Dibia and Demiralp.",
      "year" : 2019
    }, {
      "title" : "Coarse-to-fine decoding for neural semantic parsing",
      "author" : [ "Li Dong", "Mirella Lapata." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 731–742.",
      "citeRegEx" : "Dong and Lapata.,? 2018",
      "shortCiteRegEx" : "Dong and Lapata.",
      "year" : 2018
    }, {
      "title" : "Wrex: A unified programming-by-example interaction for synthesizing readable code for data scientists",
      "author" : [ "Ian Drosos", "Titus Barik", "Philip J. Guo", "Robert DeLine", "Sumit Gulwani." ],
      "venue" : "CHI ’20: CHI Conference on Human Factors in Comput-",
      "citeRegEx" : "Drosos et al\\.,? 2020",
      "shortCiteRegEx" : "Drosos et al\\.",
      "year" : 2020
    }, {
      "title" : "Codebert: A pre-trained model for programming and natural languages. arXiv preprint arXiv:2002.08155",
      "author" : [ "Zhangyin Feng", "Daya Guo", "Duyu Tang", "Nan Duan", "Xiaocheng Feng", "Ming Gong", "Linjun Shou", "Bing Qin", "Ting Liu", "Daxin Jiang" ],
      "venue" : null,
      "citeRegEx" : "Feng et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2020
    }, {
      "title" : "Incorporating copying mechanism in sequence-to-sequence learning",
      "author" : [ "Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor OK Li." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
      "citeRegEx" : "Gu et al\\.,? 2016",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2016
    }, {
      "title" : "Towards complex text-to-sql in cross-domain database with intermediate representation",
      "author" : [ "Jiaqi Guo", "Zecheng Zhan", "Yan Gao", "Yan Xiao", "Jian-Guang Lou", "Ting Liu", "Dongmei Zhang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Asso-",
      "citeRegEx" : "Guo et al\\.,? 2019",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2019
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural computation, 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Matplotlib: A 2d graphics environment",
      "author" : [ "John D Hunter." ],
      "venue" : "Computing in science & engineering, 9(3):90–95.",
      "citeRegEx" : "Hunter.,? 2007",
      "shortCiteRegEx" : "Hunter.",
      "year" : 2007
    }, {
      "title" : "Learning a neural semantic parser from user feedback",
      "author" : [ "Srinivasan Iyer", "Ioannis Konstas", "Alvin Cheung", "Jayant Krishnamurthy", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1:",
      "citeRegEx" : "Iyer et al\\.,? 2017",
      "shortCiteRegEx" : "Iyer et al\\.",
      "year" : 2017
    }, {
      "title" : "Mapping language to code in programmatic context",
      "author" : [ "Srinivasan Iyer", "Ioannis Konstas", "Alvin Cheung", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1643–1652.",
      "citeRegEx" : "Iyer et al\\.,? 2018",
      "shortCiteRegEx" : "Iyer et al\\.",
      "year" : 2018
    }, {
      "title" : "Code completion with neural attention and pointer networks",
      "author" : [ "Jian Li", "Yue Wang", "Michael R Lyu", "Irwin King." ],
      "venue" : "Proceedings of the 27th International Joint Conference on Artificial Intelligence, pages 4159–25.",
      "citeRegEx" : "Li et al\\.,? 2018",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2018
    }, {
      "title" : "Nl2bash: A corpus and semantic parser for natural language interface to the linux operating system",
      "author" : [ "Xi Victoria Lin", "Chenglong Wang", "Luke Zettlemoyer", "Michael D Ernst." ],
      "venue" : "Proceedings of the Eleventh International Conference on Language Re-",
      "citeRegEx" : "Lin et al\\.,? 2018",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2018
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv:1907.11692 [cs]. ArXiv:",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Matplotlib scatter method documentation",
      "author" : [ "Matplotlib." ],
      "venue" : "https://matplotlib.org/3.3.3/api/ as gen/matplotlib.pyplot.scatter.html.",
      "citeRegEx" : "Matplotlib.,? 2020",
      "shortCiteRegEx" : "Matplotlib.",
      "year" : 2020
    }, {
      "title" : "Neural sketch learning for conditional program generation",
      "author" : [ "Vijayaraghavan Murali", "Letao Qi", "Swarat Chaudhuri", "Chris Jermaine." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Murali et al\\.,? 2018",
      "shortCiteRegEx" : "Murali et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning to infer program sketches",
      "author" : [ "Maxwell Nye", "Luke Hewitt", "Joshua Tenenbaum", "Armando Solar-Lezama." ],
      "venue" : "International Conference on Machine Learning, pages 4861–4870.",
      "citeRegEx" : "Nye et al\\.,? 2019",
      "shortCiteRegEx" : "Nye et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning to generate pseudo-code from source code using statistical machine translation (t)",
      "author" : [ "Yusuke Oda", "Hiroyuki Fudaba", "Graham Neubig", "Hideaki Hata", "Sakriani Sakti", "Tomoki Toda", "Satoshi Nakamura." ],
      "venue" : "2015 30th IEEE/ACM In-",
      "citeRegEx" : "Oda et al\\.,? 2015",
      "shortCiteRegEx" : "Oda et al\\.",
      "year" : 2015
    }, {
      "title" : "Pandas dataframe documentation",
      "author" : [ "Pandas." ],
      "venue" : "https://pandas.pydata.org/pandas-docs/stable/ reference/api/pandas.DataFrame.html.",
      "citeRegEx" : "Pandas.,? 2020",
      "shortCiteRegEx" : "Pandas.",
      "year" : 2020
    }, {
      "title" : "Neural program search: Solving programming tasks from description and examples",
      "author" : [ "Illia Polosukhin", "Alexander Skidanov." ],
      "venue" : "arXiv preprint arXiv:1802.04335.",
      "citeRegEx" : "Polosukhin and Skidanov.,? 2018",
      "shortCiteRegEx" : "Polosukhin and Skidanov.",
      "year" : 2018
    }, {
      "title" : "Code completion with statistical language models",
      "author" : [ "Veselin Raychev", "Martin Vechev", "Eran Yahav." ],
      "venue" : "Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 419–428.",
      "citeRegEx" : "Raychev et al\\.,? 2014",
      "shortCiteRegEx" : "Raychev et al\\.",
      "year" : 2014
    }, {
      "title" : "mwaskom/seaborn library documentation",
      "author" : [ "Seaborn." ],
      "venue" : "https://doi.org/10.5281/zenodo.592845.",
      "citeRegEx" : "Seaborn.,? 2020",
      "shortCiteRegEx" : "Seaborn.",
      "year" : 2020
    }, {
      "title" : "Program Synthesis by Sketching",
      "author" : [ "Armando Solar-Lezama." ],
      "venue" : "Ph.D. thesis, UC Berkeley.",
      "citeRegEx" : "Solar.Lezama.,? 2008",
      "shortCiteRegEx" : "Solar.Lezama.",
      "year" : 2008
    }, {
      "title" : "Intellicode compose: Code generation using transformer",
      "author" : [ "Alexey Svyatkovskiy", "Shao Kun Deng", "Shengyu Fu", "Neel Sundaresan." ],
      "venue" : "arXiv preprint arXiv:2005.08025.",
      "citeRegEx" : "Svyatkovskiy et al\\.,? 2020",
      "shortCiteRegEx" : "Svyatkovskiy et al\\.",
      "year" : 2020
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in neural information processing systems, pages 5998–6008.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Pointer networks",
      "author" : [ "Oriol Vinyals", "Meire Fortunato", "Navdeep Jaitly." ],
      "venue" : "Advances in neural information processing systems, pages 2692–2700.",
      "citeRegEx" : "Vinyals et al\\.,? 2015",
      "shortCiteRegEx" : "Vinyals et al\\.",
      "year" : 2015
    }, {
      "title" : "Rat-sql: Relation-aware schema encoding and linking for text-to-sql parsers",
      "author" : [ "Bailin Wang", "Richard Shin", "Xiaodong Liu", "Oleksandr Polozov", "Matthew Richardson." ],
      "venue" : "arXiv preprint arXiv:1911.04942.",
      "citeRegEx" : "Wang et al\\.,? 2019a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Synthesizing highly expressive SQL queries from input-output examples",
      "author" : [ "Chenglong Wang", "Alvin Cheung", "Rastislav Bodı́k" ],
      "venue" : "In Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation,",
      "citeRegEx" : "Wang et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2017
    }, {
      "title" : "Visualization by example",
      "author" : [ "Chenglong Wang", "Yu Feng", "Rastislav Bodik", "Alvin Cheung", "Isil Dillig." ],
      "venue" : "Proceedings of the ACM on Programming Languages, 4(POPL):1–28.",
      "citeRegEx" : "Wang et al\\.,? 2019b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Falx: Synthesis-powered visualization authoring",
      "author" : [ "Chenglong Wang", "Yu Feng", "Rastislav Bodı́k", "Isil Dillig", "Alvin Cheung", "Amy J. Ko" ],
      "venue" : "In CHI ’21: CHI Conference on Human Factors in Computing Systems,",
      "citeRegEx" : "Wang et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2021
    }, {
      "title" : "Building a semantic parser overnight",
      "author" : [ "Yushi Wang", "Jonathan Berant", "Percy Liang." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Pro-",
      "citeRegEx" : "Wang et al\\.,? 2015",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to mine aligned code and natural language pairs",
      "author" : [ "Pengcheng Yin", "Bowen Deng", "Edgar Chen", "Bogdan Vasilescu", "Graham Neubig" ],
      "venue" : null,
      "citeRegEx" : "Yin et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Yin et al\\.",
      "year" : 2018
    }, {
      "title" : "2019a. Cosql: A conversational text-to-sql challenge towards cross-domain natural language interfaces to databases",
      "author" : [ "Tao Yu", "Rui Zhang", "Heyang Er", "Suyi Li", "Eric Xue", "Bo Pang", "Xi Victoria Lin", "Yi Chern Tan", "Tianze Shi", "Zihan Li" ],
      "venue" : null,
      "citeRegEx" : "Yu et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2019
    }, {
      "title" : "Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql",
      "author" : [ "Tao Yu", "Rui Zhang", "Kai Yang", "Michihiro Yasunaga", "Dongxu Wang", "Zifan Li", "James Ma", "Irene Li", "Qingning Yao", "Shanelle Roman" ],
      "venue" : null,
      "citeRegEx" : "Yu et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2018
    }, {
      "title" : "2019b. Sparc: Crossdomain semantic parsing in context",
      "author" : [ "Tao Yu", "Rui Zhang", "Michihiro Yasunaga", "Yi Chern Tan", "Xi Victoria Lin", "Suyi Li", "Heyang Er", "Irene Li", "Bo Pang", "Tao Chen" ],
      "venue" : "In Proceedings of the 57th Annual Meeting of the Association",
      "citeRegEx" : "Yu et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2019
    }, {
      "title" : "Naps: Natural program synthesis dataset",
      "author" : [ "Maksym Zavershynskyi", "Alex Skidanov", "Illia Polosukhin." ],
      "venue" : "arXiv preprint arXiv:1807.03168.",
      "citeRegEx" : "Zavershynskyi et al\\.,? 2018",
      "shortCiteRegEx" : "Zavershynskyi et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars",
      "author" : [ "Luke S Zettlemoyer", "Michael Collins." ],
      "venue" : "arXiv preprint arXiv:1207.1420.",
      "citeRegEx" : "Zettlemoyer and Collins.,? 2012",
      "shortCiteRegEx" : "Zettlemoyer and Collins.",
      "year" : 2012
    }, {
      "title" : "Seq2sql: Generating structured queries from natural language using reinforcement learning",
      "author" : [ "Victor Zhong", "Caiming Xiong", "Richard Socher." ],
      "venue" : "arXiv preprint arXiv:1709.00103.",
      "citeRegEx" : "Zhong et al\\.,? 2017",
      "shortCiteRegEx" : "Zhong et al\\.",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "While a number of libraries (Hunter, 2007; Seaborn, 2020; Bostock et al., 2011) have been developed for creating visualizations that range from simple scatter plots to complex 3D bar charts, writing visualization code remains a difficult task.",
      "startOffset" : 28,
      "endOffset" : 79
    }, {
      "referenceID" : 24,
      "context" : "While a number of libraries (Hunter, 2007; Seaborn, 2020; Bostock et al., 2011) have been developed for creating visualizations that range from simple scatter plots to complex 3D bar charts, writing visualization code remains a difficult task.",
      "startOffset" : 28,
      "endOffset" : 79
    }, {
      "referenceID" : 2,
      "context" : "While a number of libraries (Hunter, 2007; Seaborn, 2020; Bostock et al., 2011) have been developed for creating visualizations that range from simple scatter plots to complex 3D bar charts, writing visualization code remains a difficult task.",
      "startOffset" : 28,
      "endOffset" : 79
    }, {
      "referenceID" : 17,
      "context" : "For instance, drawing a scatter plot using the Python matplotlib library can be done using both the scatter and plot methods, and the scatter method (Matplotlib, 2020) takes in 2 required parameters (the values to plot) along with 11 other optional parameters (marker type, color, etc), with some parameters having numeric types (e.",
      "startOffset" : 149,
      "endOffset" : 167
    }, {
      "referenceID" : 39,
      "context" : "While there has been prior work on synthesizing code from natural language (Zettlemoyer and Collins, 2012; Oda et al., 2015; Wang et al., 2015; Yin et al., 2018), and with addition information such as database schemas (Zhong et al.",
      "startOffset" : 75,
      "endOffset" : 161
    }, {
      "referenceID" : 20,
      "context" : "While there has been prior work on synthesizing code from natural language (Zettlemoyer and Collins, 2012; Oda et al., 2015; Wang et al., 2015; Yin et al., 2018), and with addition information such as database schemas (Zhong et al.",
      "startOffset" : 75,
      "endOffset" : 161
    }, {
      "referenceID" : 33,
      "context" : "While there has been prior work on synthesizing code from natural language (Zettlemoyer and Collins, 2012; Oda et al., 2015; Wang et al., 2015; Yin et al., 2018), and with addition information such as database schemas (Zhong et al.",
      "startOffset" : 75,
      "endOffset" : 161
    }, {
      "referenceID" : 34,
      "context" : "While there has been prior work on synthesizing code from natural language (Zettlemoyer and Collins, 2012; Oda et al., 2015; Wang et al., 2015; Yin et al., 2018), and with addition information such as database schemas (Zhong et al.",
      "startOffset" : 75,
      "endOffset" : 161
    }, {
      "referenceID" : 22,
      "context" : ", 2018, 2019b,a) or input-output examples (Polosukhin and Skidanov, 2018; Zavershynskyi et al., 2018), synthesizing general-purpose code from natural language remains highly difficult due to the ambiguity in the natural language input and complexity of the target.",
      "startOffset" : 42,
      "endOffset" : 101
    }, {
      "referenceID" : 38,
      "context" : ", 2018, 2019b,a) or input-output examples (Polosukhin and Skidanov, 2018; Zavershynskyi et al., 2018), synthesizing general-purpose code from natural language remains highly difficult due to the ambiguity in the natural language input and complexity of the target.",
      "startOffset" : 42,
      "endOffset" : 101
    }, {
      "referenceID" : 0,
      "context" : "To study the visualization code synthesis problem, we use the Python Jupyter notebooks from the JuiCe dataset (Agashe et al., 2019), where each notebook contains the visualization program and its programmatic context.",
      "startOffset" : 110,
      "endOffset" : 131
    }, {
      "referenceID" : 27,
      "context" : "Unfortunately, using standard LSTM-based models and Transformer architectures (Vaswani et al., 2017) fails to solve the task, as noted in prior work (Agashe et al.",
      "startOffset" : 78,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : ", 2017) fails to solve the task, as noted in prior work (Agashe et al., 2019).",
      "startOffset" : 56,
      "endOffset" : 77
    }, {
      "referenceID" : 21,
      "context" : "We observe that while data to be plotted is usually stored in pandas dataframes (Pandas, 2020), they are not explicitly annotated in JuiCe.",
      "startOffset" : 80,
      "endOffset" : 94
    }, {
      "referenceID" : 28,
      "context" : "PLOTCODER uses a pointer network architecture (Vinyals et al., 2015), which allows the model to directly select code tokens in the previous code cells in the same notebook as the plotted data.",
      "startOffset" : 46,
      "endOffset" : 68
    }, {
      "referenceID" : 12,
      "context" : "Meanwhile, inspired by the schema linking techniques proposed for semantic parsing with structured inputs, such as text to SQL tasks (Iyer et al., 2017; Wang et al., 2019a; Guo et al., 2019), PLOTCODER’s encoder connects the embedding of the natural language descriptions with their corresponding code fragments in previous code cells within each notebook.",
      "startOffset" : 133,
      "endOffset" : 190
    }, {
      "referenceID" : 29,
      "context" : "Meanwhile, inspired by the schema linking techniques proposed for semantic parsing with structured inputs, such as text to SQL tasks (Iyer et al., 2017; Wang et al., 2019a; Guo et al., 2019), PLOTCODER’s encoder connects the embedding of the natural language descriptions with their corresponding code fragments in previous code cells within each notebook.",
      "startOffset" : 133,
      "endOffset" : 190
    }, {
      "referenceID" : 9,
      "context" : "Meanwhile, inspired by the schema linking techniques proposed for semantic parsing with structured inputs, such as text to SQL tasks (Iyer et al., 2017; Wang et al., 2019a; Guo et al., 2019), PLOTCODER’s encoder connects the embedding of the natural language descriptions with their corresponding code fragments in previous code cells within each notebook.",
      "startOffset" : 133,
      "endOffset" : 190
    }, {
      "referenceID" : 39,
      "context" : "There has been work on translating natural language to code in different languages (Zettlemoyer and Collins, 2012; Wang et al., 2015; Oda et al., 2015; Yin et al., 2018; Zhong et al., 2017; Yu et al., 2018; Lin et al., 2018).",
      "startOffset" : 83,
      "endOffset" : 224
    }, {
      "referenceID" : 33,
      "context" : "There has been work on translating natural language to code in different languages (Zettlemoyer and Collins, 2012; Wang et al., 2015; Oda et al., 2015; Yin et al., 2018; Zhong et al., 2017; Yu et al., 2018; Lin et al., 2018).",
      "startOffset" : 83,
      "endOffset" : 224
    }, {
      "referenceID" : 20,
      "context" : "There has been work on translating natural language to code in different languages (Zettlemoyer and Collins, 2012; Wang et al., 2015; Oda et al., 2015; Yin et al., 2018; Zhong et al., 2017; Yu et al., 2018; Lin et al., 2018).",
      "startOffset" : 83,
      "endOffset" : 224
    }, {
      "referenceID" : 34,
      "context" : "There has been work on translating natural language to code in different languages (Zettlemoyer and Collins, 2012; Wang et al., 2015; Oda et al., 2015; Yin et al., 2018; Zhong et al., 2017; Yu et al., 2018; Lin et al., 2018).",
      "startOffset" : 83,
      "endOffset" : 224
    }, {
      "referenceID" : 40,
      "context" : "There has been work on translating natural language to code in different languages (Zettlemoyer and Collins, 2012; Wang et al., 2015; Oda et al., 2015; Yin et al., 2018; Zhong et al., 2017; Yu et al., 2018; Lin et al., 2018).",
      "startOffset" : 83,
      "endOffset" : 224
    }, {
      "referenceID" : 36,
      "context" : "There has been work on translating natural language to code in different languages (Zettlemoyer and Collins, 2012; Wang et al., 2015; Oda et al., 2015; Yin et al., 2018; Zhong et al., 2017; Yu et al., 2018; Lin et al., 2018).",
      "startOffset" : 83,
      "endOffset" : 224
    }, {
      "referenceID" : 15,
      "context" : "There has been work on translating natural language to code in different languages (Zettlemoyer and Collins, 2012; Wang et al., 2015; Oda et al., 2015; Yin et al., 2018; Zhong et al., 2017; Yu et al., 2018; Lin et al., 2018).",
      "startOffset" : 83,
      "endOffset" : 224
    }, {
      "referenceID" : 22,
      "context" : ", 2018, 2019b,a), input-output examples (Polosukhin and Skidanov, 2018; Zavershynskyi et al., 2018), and code context (Iyer et al.",
      "startOffset" : 40,
      "endOffset" : 99
    }, {
      "referenceID" : 38,
      "context" : ", 2018, 2019b,a), input-output examples (Polosukhin and Skidanov, 2018; Zavershynskyi et al., 2018), and code context (Iyer et al.",
      "startOffset" : 40,
      "endOffset" : 99
    }, {
      "referenceID" : 6,
      "context" : "There has also been work on synthesizing data manipulation programs only from input-output examples (Drosos et al., 2020; Wang et al., 2017).",
      "startOffset" : 100,
      "endOffset" : 140
    }, {
      "referenceID" : 30,
      "context" : "There has also been work on synthesizing data manipulation programs only from input-output examples (Drosos et al., 2020; Wang et al., 2017).",
      "startOffset" : 100,
      "endOffset" : 140
    }, {
      "referenceID" : 0,
      "context" : "In this work, we focus on synthesizing visualization code from both natural language description and code context, and we construct our benchmark based on the Python Jupyter notebooks from the JuiCe (Agashe et al., 2019).",
      "startOffset" : 199,
      "endOffset" : 220
    }, {
      "referenceID" : 4,
      "context" : "In (Dibia and Demiralp, 2019), the authors apply a standard LSTM-based sequence-to-sequence model with attention for plot generation, but the model takes in only raw data to be visualized with no natural language input.",
      "startOffset" : 3,
      "endOffset" : 29
    }, {
      "referenceID" : 25,
      "context" : "Our design of hierarchical program decoding is inspired by prior work on sketch learning for program synthesis, where various sketch representations have been proposed for different applications (Solar-Lezama, 2008; Murali et al., 2018; Dong and Lapata, 2018; Nye et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 277
    }, {
      "referenceID" : 18,
      "context" : "Our design of hierarchical program decoding is inspired by prior work on sketch learning for program synthesis, where various sketch representations have been proposed for different applications (Solar-Lezama, 2008; Murali et al., 2018; Dong and Lapata, 2018; Nye et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 277
    }, {
      "referenceID" : 5,
      "context" : "Our design of hierarchical program decoding is inspired by prior work on sketch learning for program synthesis, where various sketch representations have been proposed for different applications (Solar-Lezama, 2008; Murali et al., 2018; Dong and Lapata, 2018; Nye et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 277
    }, {
      "referenceID" : 19,
      "context" : "Our design of hierarchical program decoding is inspired by prior work on sketch learning for program synthesis, where various sketch representations have been proposed for different applications (Solar-Lezama, 2008; Murali et al., 2018; Dong and Lapata, 2018; Nye et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 277
    }, {
      "referenceID" : 23,
      "context" : ", autocompleting the program given the code context (Raychev et al., 2014; Li et al., 2018; Svyatkovskiy et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 118
    }, {
      "referenceID" : 14,
      "context" : ", autocompleting the program given the code context (Raychev et al., 2014; Li et al., 2018; Svyatkovskiy et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 118
    }, {
      "referenceID" : 26,
      "context" : ", autocompleting the program given the code context (Raychev et al., 2014; Li et al., 2018; Svyatkovskiy et al., 2020).",
      "startOffset" : 52,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : "In our experiments, we find that when trained on raw target programs, fewer than 5% predictions are exactly the same as the ground truth, and a similar phenomenon is also observed earlier (Agashe et al., 2019).",
      "startOffset" : 188,
      "endOffset" : 209
    }, {
      "referenceID" : 10,
      "context" : "PLOTCODER includes an LSTM-based encoder (Hochreiter and Schmidhuber, 1997) to jointly embed the natural language and code context, as well as a hierarchical decoder that generates API calls and selects data for plotting.",
      "startOffset" : 41,
      "endOffset" : 75
    }, {
      "referenceID" : 8,
      "context" : "After that, the decoder predicts the plotted data, where it employs a copy mechanism (Gu et al., 2016; Vinyals et al., 2015) to select tokens from the code context.",
      "startOffset" : 85,
      "endOffset" : 124
    }, {
      "referenceID" : 28,
      "context" : "After that, the decoder predicts the plotted data, where it employs a copy mechanism (Gu et al., 2016; Vinyals et al., 2015) to select tokens from the code context.",
      "startOffset" : 85,
      "endOffset" : 124
    }, {
      "referenceID" : 13,
      "context" : "To compute attention vectors over the natural language description and the code context, we employ the two-step attention in (Iyer et al., 2018).",
      "startOffset" : 125,
      "endOffset" : 144
    }, {
      "referenceID" : 1,
      "context" : "Specifically, we first use hpt to compute the attention vector over the natural language input using the standard attention mechanism (Bahdanau et al., 2015), and we denote the attention vector as attnt.",
      "startOffset" : 134,
      "endOffset" : 157
    }, {
      "referenceID" : 28,
      "context" : "Specifically, our decoder includes 3 pointer networks (Vinyals et al., 2015) for selecting data with the type VAR, DF, and STR respectively, and they employ similar architectures but different model parameters.",
      "startOffset" : 54,
      "endOffset" : 76
    }, {
      "referenceID" : 0,
      "context" : "The encoder still uses two separate LSTMs to embed the natural language and code context, which performs better than the LSTM baseline in prior work (Agashe et al., 2019).",
      "startOffset" : 149,
      "endOffset" : 170
    }, {
      "referenceID" : 27,
      "context" : "(4) + BERT: we use the same hierarchical decoder as the full model, but replace the encoder with a Transformer architecture (Vaswani et al., 2017) initialized from a pre-trained model, and we fine-tune the encoder with other part of the model.",
      "startOffset" : 124,
      "endOffset" : 146
    }, {
      "referenceID" : 16,
      "context" : "One is RoBERTa-base (Liu et al., 2019), an improved version of BERT-Base (Devlin et al.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 3,
      "context" : ", 2019), an improved version of BERT-Base (Devlin et al., 2018) pre-trained on a large text corpus.",
      "startOffset" : 42,
      "endOffset" : 63
    }, {
      "referenceID" : 7,
      "context" : "Another is codeBERT (Feng et al., 2020), which has the same architecture as RoBERTa-base, but is pre-trained on GitHub code in several programming languages including Python, and has demonstrated good performance on code retrieval tasks.",
      "startOffset" : 20,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : "to decrease when K > 3 for different models, as observed in (Agashe et al., 2019).",
      "startOffset" : 60,
      "endOffset" : 81
    } ],
    "year" : 2021,
    "abstractText" : "Creating effective visualization is an important part of data analytics. While there are many libraries for creating visualizations, writing such code remains difficult given the myriad of parameters that users need to provide. In this paper, we propose the new task of synthesizing visualization programs from a combination of natural language utterances and code context. To tackle the learning problem, we introduce PLOTCODER, a new hierarchical encoder-decoder architecture that models both the code context and the input utterance. We use PLOTCODER to first determine the template of the visualization code, followed by predicting the data to be plotted. We use Jupyter notebooks containing visualization programs crawled from GitHub to train PLOTCODER. On a comprehensive set of test samples from those notebooks, we show that PLOTCODER correctly predicts the plot type of about 70% samples, and synthesizes the correct programs for 35% samples, performing 34.5% better than the baselines.1",
    "creator" : "LaTeX with hyperref"
  }
}