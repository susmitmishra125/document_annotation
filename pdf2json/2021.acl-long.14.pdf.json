{
  "name" : "2021.acl-long.14.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data",
    "authors" : [ "Haoyu Song", "Yan Wang", "Kaiyan Zhang", "Wei-Nan Zhang", "Ting Liu" ],
    "emails" : [ "hysong@ir.hit.edu.cn", "kyzhang@ir.hit.edu.cn", "wnzhang@ir.hit.edu.cn", "tliu@ir.hit.edu.cn", "yanwang.branden@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 167–177\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n167"
    }, {
      "heading" : "1 Introduction",
      "text" : "Various approaches have been explored to introduce explicit personas in dialogue models (Qian et al., 2018; Song et al., 2019; Zheng et al., 2020; Liu et al., 2020). The PERSONA can be defined as a composite of elements of identity, such as profiles and background personal facts. In persona-based dialogues, the generated responses are conditioned not only on the dialogue context but also on some predefined personas, so the presenting personality could be more consistent.\nExisting persona-based dialogue models heavily utilize a set of persona-related dialogue data (Wolf et al., 2019; Golovanov et al., 2019), such as the PersonaChat (Zhang et al., 2018). This kind of crowd-sourced dataset covers rich persona features,\n∗Wei-Nan Zhang is the corresponding author.\nnamely “persona-dense”. Nevertheless, the scale of such crowd-sourced datasets is limited by the expensive costs: two annotators are asked to act the part of a given provided persona and chat naturally to get to know each other during the conversation. On the other hand, conversations in daily life are not always persona-related. According to Twitter content analysis, less than 10% messages on Twitter reveal personal anecdote or activities at home or work and even less for personally identifiable information (Naaman et al., 2010; Humphreys et al., 2014). As a result, the large-scale data collected from social media would only contain a limited amount of persona-related dialogues, which is “persona-sparse”. The limited-scale of crowd-sourced data and the persona-sparsity in large-scale data present one common challenge: a model trained on limited personalized data cannot sufficiently understand persona consistency. As shown in Figure 1, a 12-layer GPT2 (Radford et al., 2019) finetuned on the PersonaChat dataset still shows a lack of consistency.\nAfter rethinking the essence of persona-based dialogue generation, we can find that it requires the dialogue agent to own the capabilities to 1) understand the persona-response consistency and 2) generate a persona-related response given the dialogue context. Obviously, an ideal dataset that satisfies both features are difficult to annotate. However, once we disentangle persona-based dialogue generation into two sub-tasks: consistency understanding and dialogue generation, it is easy to find\nabundant data resources for them. For consistency understanding, we may leverage large-scale nondialogue inference data, such as SNLI (Bowman et al., 2015) and MNLI (Williams et al., 2018) as the training data. As for dialogue generation, we already have various large-scale persona-sparse datasets.\nInspired by the aforementioned motivation, in this work, we explore to learn a consistent personabased dialogue model from limited personalized dialogues, with the assistance of large-scale nondialogue inference data. Specifically, the proposed model consists of an encoder E, an auto-regressive decoder D1 for response generation, and a bidirectional decoder D2 for consistency understanding. Given personas P and dialogue query Q, the E and D1 jointly work in an encoder-decoder manner to capture a typical query to response mapping FG(S|Q,P ), and generate a coarse response representation R1. Then R1 and personas P are fed into the bidirectional decoder D2 to mapR1 to final response representations R2: FU (R2|S, P ). Since the consistency understanding part FU (R|S, P ) is independent of the dialogue query Q, it can be learned on non-dialogue inference datasets. Here an unlikelihood training objective (Welleck et al., 2019a) is applied to make contradicted cases in the inference data less likely so that D2 could acquire the ability of consistency understanding.\nWe initialize all modules from BERT (Devlin et al., 2019) and name the proposed model BERTover-BERT (BoB). To verify the effectiveness of our model, we experiment on two limited data scenarios: 1) a persona-dense scenario (Zhang et al., 2018) with low-resource settings (Zhao et al., 2019), and 2) a persona-sparse scenario (Zheng et al., 2019). Both automatic and human evaluations indicate that our model generalizes well under different settings and outperforms strong baselines on most metrics, especially on persona consistency.\nContributions in this work are three-fold:\n• We disentangled the task of persona-based dialogue generation into two sub-tasks: consistency understanding and dialogue generation.\n• A BERT-based generative framework, BoB, was proposed for training persona-based dialogue models from limited data.\n• An unlikelihood training method with nondialogue inference data was introduced to enhance persona consistency understanding."
    }, {
      "heading" : "2 Related Work",
      "text" : "Persona-based Dialogues Recent studies on persona-based dialogue generation focus on a datadriven manner. They learn persona-related features directly from personalized dialogue datasets, either with implicit persona embeddings (Li et al., 2016b) or with explicit profiles (Qian et al., 2018) and personal facts (Mazaré et al., 2018). Following this research line, more sophisticated neural models are emerging, such as modeling mutual-persona (Liu et al., 2020) and multi-stage persona-based dialogue generation (Song et al., 2020a).\nMeanwhile, various pre-training methods have also been applied in this field. Wolf et al. (2019) and Golovanov et al. (2019) show that fine-tuning pre-trained GPT on the persona-dense dataset can improve the quality of generated responses. Zheng et al. (2020) propose an attention-routing mechanism in a GPT-based model to control the flow of persona information. Lin et al. (2020) explore how to leverage BERT model for dialogue generation. Different large-scale pretrained chatbots (Roller et al., 2020; Madotto et al., 2020) also show their effectiveness on persona-based dialogues.\nDisentangled Representation The concept of “disentangling” can be defined as transformations that only change some properties of the underlying model while leaving all other properties invariant (Higgins et al., 2018). The variational autoencoder (Kingma and Welling, 2013) could be regarded as a disentangled representation learning framework, and various methods are built within it (Kim and Mnih, 2018; Locatello et al., 2019).\nUnlikelihood Training Likelihood tries to maximize the probability of target sequence, while unlikelihood corrects known biases by minimizing the probability of negative candidates (Welleck et al., 2019a). Closely related to our work, Li et al. (2020) first explored unlikelihood training in addressing dialogue logical contradictions. They get contradicted dialogues from PersonaChat according to DNLI (Welleck et al., 2019b), a PersonaChatoriented dialogue inference dataset. Then unlikelihood training is applied to reduce the probability of contradicted responses. Different from Li et al. (2020), with carefully designed decoders, our model could learn from large-scale non-dialogue inference datasets, making it generalizable to different scenarios, such as persona-dense and personasparse datasets, as will be seen in our experiments."
    }, {
      "heading" : "3 Model",
      "text" : ""
    }, {
      "heading" : "3.1 Overview",
      "text" : "In this work, our goal is to learn a persona-based dialogue model from limited personalized data. To address the challenges of consistency understanding brought by limited data, we leverage large-scale non-dialogue inference data in our model.\nFormally, let Q = q1, q2, ..., qn denote the dialogue query,R = r1, r2, ..., rm denote the target response, and P denote the personas. In addition, let N denote the non-dialogue inference data, which consists of premise, hypothesis, and their label. The premise and hypothesis are both natural sentences. Note that in the following sections, we use fonts to distinguish between sentences (P , Q, R) and their vector representations (P , Q, R1, R2).\nThe task of the proposed model M is to generate a persona consistent response R̂ = r̂1, r̂2, ..., r̂m, based on both persona P and query Q, i.e., R̂ = M(Q,P). As shown in Figure 2, the proposed model M consists of three BERT-based submodules: an encoder E, a response decoder D1, and a consistency understanding decoder D2. More concretely, E encodes the embeddings of persona and query, i.e., P and Q, into hidden states H . D1 performs cross-attention on H in a typical encoderdecoder manner, and generate a coarse representation R1. D2 learns consistency understanding from non-dialogue inference dataN and further converts P and R1 into final representations R2. At last, a consistent response R̂ could be generated from R2."
    }, {
      "heading" : "3.2 Disentangling",
      "text" : "For response generation, a typical persona-based dialogue model needs persona P and dialogue query Q to generate a response. For consistency understanding, a model needs persona P , response R, and the consistency labels between P andR. However, if we entangle generation and understanding, it is not easy to obtain sufficient annotated data that satisfy the format of {P , Q,R, Label}.\nInstead, in our model, we design the decoder D2 to disentangle generation and understanding, where D2 maps R1, rather than Q, to R2. The key to “disentangling” is we can get R1 without the participation of Q, as R1 is the representation of R. As a result, the mapping from R1 to R2 could be independent of Q. In this way, it becomes possible to 1) learn persona-based dialogue generation from {P , Q, R}, i.e., the personalized data, and 2) learn consistency understanding from {P , R, Label}. Moreover, considering the limited amount of such annotated data, we could approximate {P , R, Label} by the abundant non-dialogue inference data N={Premise, Hypothesis, Label}, where P andR corresponds to the Premise and Hypothesis.\nGiven data P and R, suppose D2 understands persona consistency, it should maximize the likelihood of generatingR ifR is not contradicted to P . Otherwise, it should minimize the likelihood of generating R. Motivated by this observation, we choose to apply unlikelihood training on D2 to make it understand consistency. The detailed training objectives will be provided in Sec 3.4."
    }, {
      "heading" : "3.3 BERT-over-BERT",
      "text" : ""
    }, {
      "heading" : "3.3.1 Encoder",
      "text" : "The encoder E works like a standard BERT model, which bidirectionally encodes the input embeddings to a sequence of hidden vectors, from which the downstream tasks will be performed on.\nIn our model, the input consists of persona P and dialogue query Q. For persona, whether P is personal facts (e.g., “I have two dogs”) or profiles (e.g., “location: Seattle”), we could always convert it into a sequence of words. A special token is placed between persona sequence and dialogue query, and the input is formated as:\ninput = p (0) 1 , p (0) 2 , ..., p (t) ut , [s], q1, q2, ..., qn (1)\nThen the embedding layer will convert input into representations. Following usual practice, the input representations are the sum of the corresponding token, type, and position embeddings, where the type embedding is 0 and 1 for persona and query, respectively. P and Q can also get their independent representations. The resulted representations are P and Q, which could be jointly denoted as emb = ep1, e p 2, ..., e q l , where l is the maximum length of the input. Once we get the input representations, encoder E will perform multi-head attetnion (Vaswani et al., 2017) on the emb to transform the embeddings into a sequence of hidden vectors H . The multi-head attetnion could be denoted as MultiHead(query, key, value), where scaled dot-product attention is performed on query, key, and value. There are N identical layers in E, for each layer:\nhi+1 = FNN(MultiHead(hi, hi, hi)), (2)\nwhere h0 = emb, and FNN is a fully connected feed-forward network containing two linear transformations with a ReLU activation in between. hN is the final output of encoder E, i.e., H ."
    }, {
      "heading" : "3.3.2 Response Generation Decoder",
      "text" : "The response generation decoder D1 is initialized from BERT to inherit its robust language model but works in an auto-regressive decoder manner. First, a cross-attention is inserted between E and D1 to pass the context information. Second, a leftto-right mask is applied to D1 to preserve the autoregressive generation property.\nAs the cross-attention does not exist in the BERT model, it is randomly initialized and updated during\ntraining. In the cross-attention, the query comes from the previous layer of D1, and the key and value come from H:\nri+11 = FNN(MultiHead(r i 1, H,H)). (3)\nThis attention is similar to the typical encoderdecoder attention mechanism in sequence to sequence models (Bahdanau et al., 2015), which attends to all positions in the context representations H according to the variations of r1. In training, r01 is initialized from the embeddings of the target response. At each generation step, future tokens in the target response should not be considered. Therefore, as shown in Figure 2, a left-to-right mask is applied to D1 to ensure that the predictions can only depend on the known outputs. D1 also has N identical layers. And the output of the last layer rN1 , i.e., R1, is further fed to D2."
    }, {
      "heading" : "3.3.3 Consistency Understanding Decoder",
      "text" : "Like E and D1, the consistency understanding decoder D2 is also initialized from BERT, from where D2 initializes a good semantic representation for understanding tasks.\nIn each layer of D2, the multi-head attention is performed twice:\npi+1 = FNN(MultiHead(ri2, P, P )), (4) ri+12 = FNN(MultiHead(p i+1, R1, R1)). (5)\nThe resulted ri+12 in each layer thus fuses information from both P and R1. The output of the last layer of D2 is the final representations R2. With an output layer, e.g. linear layers, upon the R2, we can get the generated response R̂."
    }, {
      "heading" : "3.4 Training Objectives",
      "text" : "We employ negative log-likelihood (NLL) loss and unlikelihood loss for dialogue generation and consistency understanding. A brief illustration is shown in the last column of Figure 2 and detailed descriptions will be provided in this section.\nResponse Generation In our model, the widely adopted negative log-likelihood loss is applied in the training. For E and D1, they read the persona P and dialogue queryQ to predict the target response R, which yields the raw representations R1:\nLD1NLL = −log(pθ(R|P,Q))\n= − |R|∑ i=1 log(pθ(ri|P,Q,R<i)). (6)\nThe generation part in D2 is also trained by NLL. D2 reads persona embeddings P and raw representations R1 to predict the target responseR:\nLD2NLL = −log(pγ(R|P,R1))\n= − |R|∑ i=1 log(pγ(ri|P,R1,R<i)). (7)\nUnlikelihood Training Given large-scale nondialogue inference dataset, we collect positive data D+ from the entailed category and collect negative data D− from the contradicted category:\nD+ = {(P̄(i), R̄(i)+)}, D− = {(P̄(j), R̄(j)−)}, (8)\nwhere P̄ and R̄ are premise and hypothesis from the non-dialogue inference data, and their representations in our model are denoted as P̄ and R̄. For data from D+, we still apply the NLL loss:\nLD + 2 UL = − |R̄|∑ i=1 log(pγ(r̄i|P̄ , R̄, R̄<i)), (9)\nFor data from D−, we apply the unlikelihood objective to minimize the likelihood of contradictions:\nLD − 2 UL = − |R̄|∑ i=1 log(1− pγ(r̄i|P̄ , R̄, R̄<i)), (10)\nwhich penalizes every token in the contradicted target. Therefore, the loss LD − 2\nUL makes generating contradicted responses less likely.\nTraining Procedure The training steps can be summarized as follows:\n1) Response Generation. Given P , Q, and R from personalized dialogue data, we calculate the response generation loss L1 = LD1NLL + αL D2 NLL;\n2) Consistency Understanding. Given D+ and D− from non-dialogue inference data, we calculate the unlikelihood loss L2 = βL D+2 UL + (1− β)L D−2 UL;\n3) Optimization. Sum up L1 and L2. Update parameters with back-propagation.\nWe initialize our model from the publicly available BERT base model, with 12 layers and hidden size 768. We employ an Adam optimizer with a learning rate of varying from 5e-6 to 5e-5. Empirically, we set α to 5e-3 and β to 0.1. The training of the proposed model was done on an Nvidia Telsa V100 32G GPU. Other details please refer to the released projects."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "To evaluate the performance of the proposed model, we carried out persona-based dialogue generation experiments in a persona-dense scenario and a persona-sparse scenario with two publicly available datasets:\n• PersonaChat (Zhang et al., 2018) is a crowdsourced dataset covering rich persona features. The dialogues in this dataset are grounded on specific personal facts. Here we use the ConvAI2 PersonaChat (Dinan et al., 2019), so the results are comparable to existing methods.\n• PersonalDialog (Zheng et al., 2019) is a large-scale persona-sparse dataset, which is collected from Chinese social media Weibo. This dataset provides persona profiles and dialogues, but the majority of the dialogues are not persona-related. Two testsets are provided: a random testset, which is identically distributed as the training data, and a biased testset, which is manually selected to cover persona-related features.\nWe summarize the key statistics of two personalized dialogue datasets in Tabel 1.\nAs aforementioned, we leverage non-dialogue inference data to address the consistency understanding issue brought by limited personalized data. Here we use the non-dialogue inference dataset MNLI (Williams et al., 2018) and its Chinese version CMNLI (Xu et al., 2020) as our auxiliary data. Moreover, to better compare models’ performance on persona consistency, we leverage two dialogue inference datasets, DNLI (Welleck et al., 2019b) and KvPI (Song et al., 2020b), for evaluations. The statistics1 of these inference datasets are summarized in Table2."
    }, {
      "heading" : "4.2 Compared Methods",
      "text" : "The following models, including both nonpretrained and pretrained ones, have been compared in the experiments.\nBaselines. Vanilla Transformer (Vaswani et al., 2017) is employed as baselines for the experiments on both PersonaChat and PersonalDialog. Personas are concatenated to the dialogue queries.\n1Note that for the DNLI, we only count the tuples that can be restored as {persona, query, response} in our experiments.\nDataset # Entailed # Neutral # Contra.\nNon-Pretrained Models. Meta-learning has recently been explored in addressing the limited personalized data issue. CMAML (Song et al., 2020c) is a meta-learning based method that learns from few shot personas by customizing the model structures. Besides the meta-learning methods, GDR (Song et al., 2020a) introduces inference ability on the PersonaChat with a generate-refine framework. However, the two models are elaborately designed for the persona-dense dataset and not appliable for the persona-sparse scenario. Thus we only employ them for experiments on PersonaChat.\nPre-training Models. In the ConvAI2 challenge (Dinan et al., 2019), which utilizes PersonaChat as the competition dataset, LIC (Golovanov et al., 2019) is the best performing model. Thus we compare this model in the experiments on both PersonaChat and PersonalDialog. AttentionRouting (Zheng et al., 2020) is a pre-training method specially designed for the persona-sparse dataset, and it is also the latest model on PersonalDialog. We also finetune a GPT2 (Radford et al., 2019) for a thorough comparison on PersonaChat."
    }, {
      "heading" : "4.3 Evaluation Metrics",
      "text" : "We focus on two main aspects of the persona-based dialogues: response quality and persona consistency. To compare different models, we employ both automatic metrics and human evaluations.\nAutomatic Metrics For dialogue quality, we employ perplexity (PPL.) and distinct 1/2 (Dist.1/2) following common practice (Zhang et al., 2018; Zheng et al., 2020). Lower perplexity means better language modeling. Distinct 1/2 (Li et al., 2016a) are the ratio of distinct uni-grams / bi-grams, and higher distinct means better reponse diversity.\nFor persona consistency, we employ two metrics. The first is Consistency Score (C.Score) (Madotto et al., 2019), which leverages a referee model to predict consistency and can be defined as:\nNLI(r, pi) =  −1, if r contradicts pi, 0, if r is irrelevant to pi,\n1, if r entails pi. C.Score(r) = ∑t\ni=1 NLI(r, pi).\n(11) Here the NLI is a pre-trained RoBERTa model (Liu et al., 2019) finetuned with the dialogue inference datasets, i.e., DNLI and KvPI, as descriped in Table 2. The RoBERT model achieves testset accuracy of 89.3% and 88.9% on DNLI and KvPI, which is aligned to the reported 88.20% (Welleck et al., 2019b) and 88.0% (Song et al., 2020b).\nThe second metric is Delta Perplexity (∆P), which evaluates consistency from model’s internal distributions. Li et al. (2020) first calculates the perplexity of entailed (p.Ent) and contradicted (p.Ctd) dialogues in the inference dataset. A dialogue model with good understanding ability should assign lower perplexity to the entailed dialogues while higher perplexity to the contradictions. From this intuition, the ∆P can be defined as:\n∆P = PPL(Contradicted)− PPL(Entailed), (12) where a larger ∆P means the model has a better ability to distinguish entailment from contradiction. In our experiments, we get entailed and contradicted {persona, query, response} tuples from the dialogue inference datasets DNLI and KvPI.\nHuman Evaluations We recruit two teams (one for English and another for Chinese), each consists of five professional annotators, from a third-party company. These annotators are proficient in language tasks but know nothing about the models. We sample 100 {persona, query, response} tuples for each model’s evaluation under every setting.\nHuman annotators are asked to evaluate dialogue quality from three conventional criteria: fluency (Flue.), informativeness (Info.), and relevance (Relv.). Each criterion is rated on a fivescale, where 1, 3, and 5 indicate unacceptable, moderate, and perfect performance, respectively. The annotators are also instructed to label the consistency (Per.C.) between persona and response, where 1 means persona-related and consistent, 0 means irrelevant, and -1 means contradicted."
    }, {
      "heading" : "4.4 Persona-Dense Results",
      "text" : "Full PersonaChat We first report the full PersonaChat experimental results in Table 3. Our method achieves better performance consistently across all automatic and human evaluation metrics, which shows the effectiveness of our model.\nAmong all the metrics, our model obtains significant improvements on PPL and ∆P. The lowest testset PPL means our model has learned a good language model fitting this dataset. Moreover, the highest ∆P shows that our model could more effectively distinguish entailment from contradiction than other baselines, which indicates our model has a better understanding of persona consistency.\nLess Personalized Data Now that our model achieves better performance with a large margin on the full PersonaChat dataset, we want to test our model by simulating a low-resource scenario (Zhao et al., 2019), where we gradually reduce the number of examples by halving the training set. We report the low-resource settings’ results in Table 4.\nAs we can see, our model can outperform most of the baselines’ best results even by using only 1/8 of the training data. The performance gains largely benefit from the powerful language model of the backbone BERT model. Furthermore, due to the disentangling of generation and understanding, our model presents a stable performance on ∆P regardless of the size of the training set. This is in line with our expectations because the proposed model learns consistency understanding from the\nnon-dialogue inference data rather than the personadense dialogue data. We observe that the method also improves fluency and informativeness. It is mainly due to the introduction of the non-dialogue inference data in the training procedure, which potentially enriches the dialogue language model."
    }, {
      "heading" : "4.5 Validations on Persona-Sparse",
      "text" : "We further validate our model on a persona-sparse scenario. To have a more intuitive understanding of “sparsity”, we recruit the same annotation team to annotate whether the dataset response is personarelated in the sampled random and biased test data. Results show that only 1% responses are personarelated in the random test data and 28% in the biased test data. We calculate the Fleiss’ Kappa among the five annotators and obtain a kappa of 0.774, which means substantial agreement (Landis and Koch, 1977). We report the evaluation results on both random and biased testsets in Table 5.\nOn the random test set, experimental results demonstrate that our model has some advantages over other methods, but no method can consistently outperform the others. One possible reason is that the task has degenerated into the ordinary dialogue generation in the random test set, so our model’s advantages can not be effectively leveraged. In contrast, on the biased test set, our model achieves the best performance on most metrics. The good performance on the metrics C.Score and Per.C. indicates that our model can be effectively trained from a dataset with limited personalized dialogues."
    }, {
      "heading" : "4.6 Analysis and Ablation Study",
      "text" : "In addition to the good performance of the BoB model, we are also curious about Q1: what is the key to the BoB model’s understanding ability? Q2: can the pre-trained models understand persona consistency just through finetuning on the personalized dialogues? And Q3: does the extremely low PPL come from the initialization of the BERT model or the architecture of the proposed BoB model?\nTo better answer the above questions, we ablate the BoB model in the following three ways: 1) w/o UL. It removes the unlikelihood objective. 2) E+D1. It removes the unlikelihood objective and the second decoder D2. 3) E. It removes the unlikelihood objective and both decoders and thus degenerates into a vanilla BERT model. We report the ablation results on PersonalDialog in Table 5 and full PersonaChat in Table 6. From these results:\nAnswer to Q1: The key to our model’s understanding is the unlikelihood training. In training, our model assigns large perplexity to the contradictions. In generating, the non-contradicted responses are more likely to be generated as they are with much smaller losses. Table 7 shows an example. And as presented in the results, after removing the unlikelihood objective, all ablated models suffer from significant performance degradations in consistency-related metrics, such as Per.C. and ∆P.\nAnswer to Q2: Pretrained models barely understand consistency from personalized dialogues. According to the poor performances on ∆P, the three BERT-based ablated models can hardly distinguish contradiction from entailment. Although their Per.C. metric still looks good, it may come from just mimicking and copying words rather than understanding. A similar phenomenon also occurs to the pre-trained GPT2, as shown in Table 3. It is also this phenomenon that motivates us to introduce the unlikelihood training into the BoB model.\nAnswer to Q3: D2 in the BoB architecture contributes most to the PPL. As shown in both datasets’ ablation results, the PPL decreases the most after removing D2. We can also see an apparent gap between the models with D2 and the vanilla BERT on PPL. Nevertheless, the BERT model still offers a good initialization for the BoB model to achieve the best performance on different metrics."
    }, {
      "heading" : "4.7 Reproducibility",
      "text" : "The implementation for the BoB model is released at https://github.com/songhaoyu/BoB."
    }, {
      "heading" : "5 Conclusions",
      "text" : "In this work, we propose a novel BERT-based dialogue model to learn from limited personalized data by disentangling response generation and consistency understanding. Unlikelihood training with non-dialogue inference data is introduced to en-\nhance the model’s understanding ability. Experiments on two publicly available datasets demonstrate that our model can be trained with limited personalized dialogue data while still obtain significant improvements over strong methods."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This paper is supported by the National Natural Science Foundation of China under Grant No.62076081, No.61772153, and No.61936010, and supported by the Science and Technology Innovation 2030 Major Project of China under Grant No.2020AAA0108605. We thank all the anonymous reviewers for their helpful comments and suggestions.\nEthical Statement\nPersona-based dialogue research intends to address the persona inconsistency issue in open-domain dialogue to facilitate human-computer interactions. Giving dialogue system a specific persona is a mainstream to alleviate the inconsistency issue of dialogues under the current stage. The purpose is to endow the dialogue system with self logical consistency rather than imitate specific human beings. Simultaneously, in this work, the data resources we use are all from published works and do not involve privacy issues related to data collection. We also confirm that this work neither automatically infers or attributes identity characteristics to the participants nor categorizes them in the training datasets."
    } ],
    "references" : [ {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015,",
      "citeRegEx" : "Bahdanau et al\\.,? 2015",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2015
    }, {
      "title" : "A large annotated corpus for learning natural language inference",
      "author" : [ "Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Bowman et al\\.,? 2015",
      "shortCiteRegEx" : "Bowman et al\\.",
      "year" : 2015
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "The second conversational intelligence challenge (convai2)",
      "author" : [ "Emily Dinan", "Varvara Logacheva", "Valentin Malykh", "Alexander Miller", "Kurt Shuster", "Jack Urbanek", "Douwe Kiela", "Arthur Szlam", "Iulian Serban", "Ryan Lowe" ],
      "venue" : null,
      "citeRegEx" : "Dinan et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2019
    }, {
      "title" : "Large-scale transfer learning for natural language generation",
      "author" : [ "Sergey Golovanov", "Rauf Kurbanov", "Sergey Nikolenko", "Kyryl Truskovskyi", "Alexander Tselousov", "Thomas Wolf." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Com-",
      "citeRegEx" : "Golovanov et al\\.,? 2019",
      "shortCiteRegEx" : "Golovanov et al\\.",
      "year" : 2019
    }, {
      "title" : "Towards a definition of disentangled representations. CoRR, abs/1812.02230",
      "author" : [ "Irina Higgins", "David Amos", "David Pfau", "Sébastien Racanière", "Loı̈c Matthey", "Danilo J. Rezende", "Alexander Lerchner" ],
      "venue" : null,
      "citeRegEx" : "Higgins et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Higgins et al\\.",
      "year" : 2018
    }, {
      "title" : "Twitter: a content analysis of personal information",
      "author" : [ "Lee Humphreys", "Phillipa Gill", "Balachander Krishnamurthy." ],
      "venue" : "Information, Communication & Society, 17(7):843–857.",
      "citeRegEx" : "Humphreys et al\\.,? 2014",
      "shortCiteRegEx" : "Humphreys et al\\.",
      "year" : 2014
    }, {
      "title" : "Disentangling by factorising",
      "author" : [ "Hyunjik Kim", "Andriy Mnih." ],
      "venue" : "International Conference on Machine Learning, pages 2649–2658. PMLR.",
      "citeRegEx" : "Kim and Mnih.,? 2018",
      "shortCiteRegEx" : "Kim and Mnih.",
      "year" : 2018
    }, {
      "title" : "Autoencoding variational bayes",
      "author" : [ "Diederik P Kingma", "Max Welling." ],
      "venue" : "arXiv preprint arXiv:1312.6114.",
      "citeRegEx" : "Kingma and Welling.,? 2013",
      "shortCiteRegEx" : "Kingma and Welling.",
      "year" : 2013
    }, {
      "title" : "The measurement of observer agreement for categorical data",
      "author" : [ "J Richard Landis", "Gary G Koch." ],
      "venue" : "biometrics, pages 159–174.",
      "citeRegEx" : "Landis and Koch.,? 1977",
      "shortCiteRegEx" : "Landis and Koch.",
      "year" : 1977
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Li et al\\.,? 2016a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "A persona-based neural conversation model",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Georgios Spithourakis", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long",
      "citeRegEx" : "Li et al\\.,? 2016b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Don’t say that! making inconsistent dialogue unlikely with unlikelihood training",
      "author" : [ "Margaret Li", "Stephen Roller", "Ilia Kulikov", "Sean Welleck", "Y-Lan Boureau", "Kyunghyun Cho", "Jason Weston." ],
      "venue" : "In",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Xpersona: Evaluating multilingual personalized chatbot",
      "author" : [ "Zhaojiang Lin", "Zihan Liu", "Genta Indra Winata", "Samuel Cahyawijaya", "Andrea Madotto", "Yejin Bang", "Etsuko Ishii", "Pascale Fung." ],
      "venue" : "arXiv preprint arXiv:2003.07568.",
      "citeRegEx" : "Lin et al\\.,? 2020",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "You impress me: Dialogue generation via mutual persona perception",
      "author" : [ "Qian Liu", "Yihong Chen", "Bei Chen", "Jian-Guang Lou", "Zixuan Chen", "Bin Zhou", "Dongmei Zhang." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov" ],
      "venue" : null,
      "citeRegEx" : "Liu et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Disentangling factors of variations using few labels",
      "author" : [ "Francesco Locatello", "Michael Tschannen", "Stefan Bauer", "Gunnar Rätsch", "Bernhard Schölkopf", "Olivier Bachem." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Locatello et al\\.,? 2019",
      "shortCiteRegEx" : "Locatello et al\\.",
      "year" : 2019
    }, {
      "title" : "The adapter-bot: All-in-one controllable conversational model",
      "author" : [ "Andrea Madotto", "Zhaojiang Lin", "Yejin Bang", "Pascale Fung." ],
      "venue" : "arXiv preprint arXiv:2008.12579.",
      "citeRegEx" : "Madotto et al\\.,? 2020",
      "shortCiteRegEx" : "Madotto et al\\.",
      "year" : 2020
    }, {
      "title" : "Personalizing dialogue agents via meta-learning",
      "author" : [ "Andrea Madotto", "Zhaojiang Lin", "Chien-Sheng Wu", "Pascale Fung." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5454–5459, Florence, Italy. Asso-",
      "citeRegEx" : "Madotto et al\\.,? 2019",
      "shortCiteRegEx" : "Madotto et al\\.",
      "year" : 2019
    }, {
      "title" : "Training millions of personalized dialogue agents",
      "author" : [ "Pierre-Emmanuel Mazaré", "Samuel Humeau", "Martin Raison", "Antoine Bordes." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2775–2779,",
      "citeRegEx" : "Mazaré et al\\.,? 2018",
      "shortCiteRegEx" : "Mazaré et al\\.",
      "year" : 2018
    }, {
      "title" : "Is it really about me? message content in social awareness streams",
      "author" : [ "Mor Naaman", "Jeffrey Boase", "Chih-Hui Lai." ],
      "venue" : "Proceedings of the 2010 ACM conference on Computer supported cooperative work, pages 189–192.",
      "citeRegEx" : "Naaman et al\\.,? 2010",
      "shortCiteRegEx" : "Naaman et al\\.",
      "year" : 2010
    }, {
      "title" : "Assigning personality/profile to a chatting machine for coherent conversation generation",
      "author" : [ "Qiao Qian", "Minlie Huang", "Haizhou Zhao", "Jingfang Xu", "Xiaoyan Zhu." ],
      "venue" : "Proceedings of the TwentySeventh International Joint Conference on Artificial",
      "citeRegEx" : "Qian et al\\.,? 2018",
      "shortCiteRegEx" : "Qian et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "OpenAI blog, 1(8):9.",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Recipes for building an open-domain chatbot",
      "author" : [ "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Kurt Shuster", "Eric M Smith" ],
      "venue" : "arXiv preprint arXiv:2004.13637",
      "citeRegEx" : "Roller et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Roller et al\\.",
      "year" : 2020
    }, {
      "title" : "Generate, delete and rewrite: A three-stage framework for improving persona consistency of dialogue generation",
      "author" : [ "Haoyu Song", "Yan Wang", "Wei-Nan Zhang", "Xiaojiang Liu", "Ting Liu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Asso-",
      "citeRegEx" : "Song et al\\.,? 2020a",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2020
    }, {
      "title" : "Profile consistency identification for open-domain dialogue agents",
      "author" : [ "Haoyu Song", "Yan Wang", "Wei-Nan Zhang", "Zhengyu Zhao", "Ting Liu", "Xiaojiang Liu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process-",
      "citeRegEx" : "Song et al\\.,? 2020b",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2020
    }, {
      "title" : "Exploiting persona information for diverse generation of conversational responses",
      "author" : [ "Haoyu Song", "Wei-Nan Zhang", "Yiming Cui", "Dong Wang", "Ting Liu." ],
      "venue" : "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intel-",
      "citeRegEx" : "Song et al\\.,? 2019",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning to customize model structures for few-shot dialogue generation tasks",
      "author" : [ "Yiping Song", "Zequn Liu", "Wei Bi", "Rui Yan", "Ming Zhang." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5832–",
      "citeRegEx" : "Song et al\\.,? 2020c",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2020
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "NIPS.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Neural text generation with unlikelihood training",
      "author" : [ "Sean Welleck", "Ilia Kulikov", "Stephen Roller", "Emily Dinan", "Kyunghyun Cho", "Jason Weston." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Welleck et al\\.,? 2019a",
      "shortCiteRegEx" : "Welleck et al\\.",
      "year" : 2019
    }, {
      "title" : "Dialogue natural language inference",
      "author" : [ "Sean Welleck", "Jason Weston", "Arthur Szlam", "Kyunghyun Cho." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3731–3741, Florence, Italy. Association for",
      "citeRegEx" : "Welleck et al\\.,? 2019b",
      "shortCiteRegEx" : "Welleck et al\\.",
      "year" : 2019
    }, {
      "title" : "A broad-coverage challenge corpus for sentence understanding through inference",
      "author" : [ "Adina Williams", "Nikita Nangia", "Samuel Bowman." ],
      "venue" : "Proceedings of the 2018 Conference of the North American",
      "citeRegEx" : "Williams et al\\.,? 2018",
      "shortCiteRegEx" : "Williams et al\\.",
      "year" : 2018
    }, {
      "title" : "Transfertransfo: A transfer learning approach for neural network based conversational agents",
      "author" : [ "Thomas Wolf", "Victor Sanh", "Julien Chaumond", "Clement Delangue." ],
      "venue" : "arXiv preprint arXiv:1901.08149.",
      "citeRegEx" : "Wolf et al\\.,? 2019",
      "shortCiteRegEx" : "Wolf et al\\.",
      "year" : 2019
    }, {
      "title" : "CLUE: A Chinese language understanding evaluation benchmark",
      "author" : [ "Zuoyu Tian", "Yiwen Zhang", "He Zhou", "Shaoweihua Liu", "Zhe Zhao", "Qipeng Zhao", "Cong Yue", "Xinrui Zhang", "Zhengliang Yang", "Kyle Richardson", "Zhenzhong Lan." ],
      "venue" : "Proceed-",
      "citeRegEx" : "Tian et al\\.,? 2020",
      "shortCiteRegEx" : "Tian et al\\.",
      "year" : 2020
    }, {
      "title" : "Personalizing dialogue agents: I have a dog, do you have pets too",
      "author" : [ "Saizheng Zhang", "Emily Dinan", "Jack Urbanek", "Arthur Szlam", "Douwe Kiela", "Jason Weston" ],
      "venue" : "In Proceedings of the 56th Annual Meeting of the Association",
      "citeRegEx" : "Zhang et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Low-resource knowledge-grounded dialogue generation",
      "author" : [ "Xueliang Zhao", "Wei Wu", "Chongyang Tao", "Can Xu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Zhao et al\\.,? 2019",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2019
    }, {
      "title" : "Personalized dialogue generation with diversified traits",
      "author" : [ "Yinhe Zheng", "Guanyi Chen", "Minlie Huang", "Song Liu", "Xuan Zhu." ],
      "venue" : "ArXiv, abs/1901.09672.",
      "citeRegEx" : "Zheng et al\\.,? 2019",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2019
    }, {
      "title" : "A pre-training based personalized dialogue generation model with persona-sparse data",
      "author" : [ "Yinhe Zheng", "Rongsheng Zhang", "Minlie Huang", "Xiaoxi Mao." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, 34(05):9693–9700.",
      "citeRegEx" : "Zheng et al\\.,? 2020",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "Various approaches have been explored to introduce explicit personas in dialogue models (Qian et al., 2018; Song et al., 2019; Zheng et al., 2020; Liu et al., 2020).",
      "startOffset" : 88,
      "endOffset" : 164
    }, {
      "referenceID" : 26,
      "context" : "Various approaches have been explored to introduce explicit personas in dialogue models (Qian et al., 2018; Song et al., 2019; Zheng et al., 2020; Liu et al., 2020).",
      "startOffset" : 88,
      "endOffset" : 164
    }, {
      "referenceID" : 37,
      "context" : "Various approaches have been explored to introduce explicit personas in dialogue models (Qian et al., 2018; Song et al., 2019; Zheng et al., 2020; Liu et al., 2020).",
      "startOffset" : 88,
      "endOffset" : 164
    }, {
      "referenceID" : 14,
      "context" : "Various approaches have been explored to introduce explicit personas in dialogue models (Qian et al., 2018; Song et al., 2019; Zheng et al., 2020; Liu et al., 2020).",
      "startOffset" : 88,
      "endOffset" : 164
    }, {
      "referenceID" : 32,
      "context" : "Existing persona-based dialogue models heavily utilize a set of persona-related dialogue data (Wolf et al., 2019; Golovanov et al., 2019), such as the PersonaChat (Zhang et al.",
      "startOffset" : 94,
      "endOffset" : 137
    }, {
      "referenceID" : 4,
      "context" : "Existing persona-based dialogue models heavily utilize a set of persona-related dialogue data (Wolf et al., 2019; Golovanov et al., 2019), such as the PersonaChat (Zhang et al.",
      "startOffset" : 94,
      "endOffset" : 137
    }, {
      "referenceID" : 20,
      "context" : "According to Twitter content analysis, less than 10% messages on Twitter reveal personal anecdote or activities at home or work and even less for personally identifiable information (Naaman et al., 2010; Humphreys et al., 2014).",
      "startOffset" : 182,
      "endOffset" : 227
    }, {
      "referenceID" : 6,
      "context" : "According to Twitter content analysis, less than 10% messages on Twitter reveal personal anecdote or activities at home or work and even less for personally identifiable information (Naaman et al., 2010; Humphreys et al., 2014).",
      "startOffset" : 182,
      "endOffset" : 227
    }, {
      "referenceID" : 22,
      "context" : "As shown in Figure 1, a 12-layer GPT2 (Radford et al., 2019) finetuned on the PersonaChat dataset still shows a lack of consistency.",
      "startOffset" : 38,
      "endOffset" : 60
    }, {
      "referenceID" : 1,
      "context" : "For consistency understanding, we may leverage large-scale nondialogue inference data, such as SNLI (Bowman et al., 2015) and MNLI (Williams et al.",
      "startOffset" : 100,
      "endOffset" : 121
    }, {
      "referenceID" : 31,
      "context" : ", 2015) and MNLI (Williams et al., 2018) as the training data.",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 29,
      "context" : "Here an unlikelihood training objective (Welleck et al., 2019a) is applied to make contradicted cases in the inference data less likely so that D2 could acquire the ability of consistency understanding.",
      "startOffset" : 40,
      "endOffset" : 63
    }, {
      "referenceID" : 2,
      "context" : "We initialize all modules from BERT (Devlin et al., 2019) and name the proposed model BERTover-BERT (BoB).",
      "startOffset" : 36,
      "endOffset" : 57
    }, {
      "referenceID" : 34,
      "context" : "To verify the effectiveness of our model, we experiment on two limited data scenarios: 1) a persona-dense scenario (Zhang et al., 2018) with low-resource settings (Zhao et al.",
      "startOffset" : 115,
      "endOffset" : 135
    }, {
      "referenceID" : 35,
      "context" : ", 2018) with low-resource settings (Zhao et al., 2019), and 2) a persona-sparse scenario (Zheng et al.",
      "startOffset" : 35,
      "endOffset" : 54
    }, {
      "referenceID" : 36,
      "context" : ", 2019), and 2) a persona-sparse scenario (Zheng et al., 2019).",
      "startOffset" : 42,
      "endOffset" : 62
    }, {
      "referenceID" : 11,
      "context" : "They learn persona-related features directly from personalized dialogue datasets, either with implicit persona embeddings (Li et al., 2016b) or with explicit profiles (Qian et al.",
      "startOffset" : 122,
      "endOffset" : 140
    }, {
      "referenceID" : 21,
      "context" : ", 2016b) or with explicit profiles (Qian et al., 2018) and personal facts (Mazaré et al.",
      "startOffset" : 35,
      "endOffset" : 54
    }, {
      "referenceID" : 14,
      "context" : "Following this research line, more sophisticated neural models are emerging, such as modeling mutual-persona (Liu et al., 2020) and multi-stage persona-based dialogue generation (Song et al.",
      "startOffset" : 109,
      "endOffset" : 127
    }, {
      "referenceID" : 24,
      "context" : ", 2020) and multi-stage persona-based dialogue generation (Song et al., 2020a).",
      "startOffset" : 58,
      "endOffset" : 78
    }, {
      "referenceID" : 23,
      "context" : "Different large-scale pretrained chatbots (Roller et al., 2020; Madotto et al., 2020) also show their effectiveness on persona-based dialogues.",
      "startOffset" : 42,
      "endOffset" : 85
    }, {
      "referenceID" : 17,
      "context" : "Different large-scale pretrained chatbots (Roller et al., 2020; Madotto et al., 2020) also show their effectiveness on persona-based dialogues.",
      "startOffset" : 42,
      "endOffset" : 85
    }, {
      "referenceID" : 5,
      "context" : "ing model while leaving all other properties invariant (Higgins et al., 2018).",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 8,
      "context" : "The variational autoencoder (Kingma and Welling, 2013) could be regarded as a disentangled representation learning framework, and various methods are built within it (Kim and Mnih, 2018; Locatello et al.",
      "startOffset" : 28,
      "endOffset" : 54
    }, {
      "referenceID" : 7,
      "context" : "The variational autoencoder (Kingma and Welling, 2013) could be regarded as a disentangled representation learning framework, and various methods are built within it (Kim and Mnih, 2018; Locatello et al., 2019).",
      "startOffset" : 166,
      "endOffset" : 210
    }, {
      "referenceID" : 16,
      "context" : "The variational autoencoder (Kingma and Welling, 2013) could be regarded as a disentangled representation learning framework, and various methods are built within it (Kim and Mnih, 2018; Locatello et al., 2019).",
      "startOffset" : 166,
      "endOffset" : 210
    }, {
      "referenceID" : 29,
      "context" : "Unlikelihood Training Likelihood tries to maximize the probability of target sequence, while unlikelihood corrects known biases by minimizing the probability of negative candidates (Welleck et al., 2019a).",
      "startOffset" : 181,
      "endOffset" : 204
    }, {
      "referenceID" : 30,
      "context" : "They get contradicted dialogues from PersonaChat according to DNLI (Welleck et al., 2019b), a PersonaChatoriented dialogue inference dataset.",
      "startOffset" : 67,
      "endOffset" : 90
    }, {
      "referenceID" : 28,
      "context" : "Once we get the input representations, encoder E will perform multi-head attetnion (Vaswani et al., 2017) on the emb to transform the embeddings into a sequence of hidden vectors H .",
      "startOffset" : 83,
      "endOffset" : 105
    }, {
      "referenceID" : 0,
      "context" : "This attention is similar to the typical encoderdecoder attention mechanism in sequence to sequence models (Bahdanau et al., 2015), which attends to all positions in the context representations H according to the variations of r1.",
      "startOffset" : 107,
      "endOffset" : 130
    }, {
      "referenceID" : 34,
      "context" : "• PersonaChat (Zhang et al., 2018) is a crowdsourced dataset covering rich persona features.",
      "startOffset" : 14,
      "endOffset" : 34
    }, {
      "referenceID" : 3,
      "context" : "Here we use the ConvAI2 PersonaChat (Dinan et al., 2019), so the results are comparable to existing methods.",
      "startOffset" : 36,
      "endOffset" : 56
    }, {
      "referenceID" : 36,
      "context" : "• PersonalDialog (Zheng et al., 2019) is a large-scale persona-sparse dataset, which is collected from Chinese social media Weibo.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 31,
      "context" : "Here we use the non-dialogue inference dataset MNLI (Williams et al., 2018) and its Chinese version CMNLI (Xu et al.",
      "startOffset" : 52,
      "endOffset" : 75
    }, {
      "referenceID" : 30,
      "context" : "Moreover, to better compare models’ performance on persona consistency, we leverage two dialogue inference datasets, DNLI (Welleck et al., 2019b) and KvPI (Song et al.",
      "startOffset" : 122,
      "endOffset" : 145
    }, {
      "referenceID" : 25,
      "context" : ", 2019b) and KvPI (Song et al., 2020b), for evaluations.",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 28,
      "context" : "Vanilla Transformer (Vaswani et al., 2017) is employed as baselines for the experiments on both PersonaChat and PersonalDialog.",
      "startOffset" : 20,
      "endOffset" : 42
    }, {
      "referenceID" : 27,
      "context" : "CMAML (Song et al., 2020c) is a meta-learning based method that learns from few shot personas by customizing the model structures.",
      "startOffset" : 6,
      "endOffset" : 26
    }, {
      "referenceID" : 24,
      "context" : "Besides the meta-learning methods, GDR (Song et al., 2020a) introduces inference ability on the PersonaChat with a generate-refine framework.",
      "startOffset" : 39,
      "endOffset" : 59
    }, {
      "referenceID" : 3,
      "context" : "In the ConvAI2 challenge (Dinan et al., 2019), which utilizes PersonaChat as the competition dataset, LIC (Golovanov et al.",
      "startOffset" : 25,
      "endOffset" : 45
    }, {
      "referenceID" : 4,
      "context" : ", 2019), which utilizes PersonaChat as the competition dataset, LIC (Golovanov et al., 2019) is the best performing model.",
      "startOffset" : 68,
      "endOffset" : 92
    }, {
      "referenceID" : 37,
      "context" : "AttentionRouting (Zheng et al., 2020) is a pre-training method specially designed for the persona-sparse dataset, and it is also the latest model on PersonalDialog.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 22,
      "context" : "We also finetune a GPT2 (Radford et al., 2019) for a thorough comparison on PersonaChat.",
      "startOffset" : 24,
      "endOffset" : 46
    }, {
      "referenceID" : 10,
      "context" : "Distinct 1/2 (Li et al., 2016a) are the ratio of distinct uni-grams / bi-grams, and higher distinct means better reponse diversity.",
      "startOffset" : 13,
      "endOffset" : 31
    }, {
      "referenceID" : 18,
      "context" : "Score) (Madotto et al., 2019), which leverages a referee model to predict consistency and can be defined as:",
      "startOffset" : 7,
      "endOffset" : 29
    }, {
      "referenceID" : 15,
      "context" : "(11) Here the NLI is a pre-trained RoBERTa model (Liu et al., 2019) finetuned with the dialogue inference datasets, i.",
      "startOffset" : 49,
      "endOffset" : 67
    }, {
      "referenceID" : 35,
      "context" : "Less Personalized Data Now that our model achieves better performance with a large margin on the full PersonaChat dataset, we want to test our model by simulating a low-resource scenario (Zhao et al., 2019), where we gradually reduce the number of examples by halving the training set.",
      "startOffset" : 187,
      "endOffset" : 206
    }, {
      "referenceID" : 9,
      "context" : "774, which means substantial agreement (Landis and Koch, 1977).",
      "startOffset" : 39,
      "endOffset" : 62
    } ],
    "year" : 2021,
    "abstractText" : "Maintaining consistent personas is essential for dialogue agents. Although tremendous advancements have been brought, the limitedscale of annotated persona-dense data are still barriers towards training robust and consistent persona-based dialogue models. In this work, we show how the challenges can be addressed by disentangling persona-based dialogue generation into two sub-tasks with a novel BERTover-BERT (BoB) model. Specifically, the model consists of a BERT-based encoder and two BERT-based decoders, where one decoder is for response generation, and another is for consistency understanding. In particular, to learn the ability of consistency understanding from large-scale non-dialogue inference data, we train the second decoder in an unlikelihood manner. Under different limited data settings, both automatic and human evaluations demonstrate that the proposed model outperforms strong baselines in response quality and persona consistency.",
    "creator" : "LaTeX with hyperref"
  }
}