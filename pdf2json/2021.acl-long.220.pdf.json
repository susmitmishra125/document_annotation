{
  "name" : "2021.acl-long.220.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "OntoED: Low-resource Event Detection with Ontology Embedding",
    "authors" : [ "Shumin Deng", "Ningyu Zhang", "Luoqiu Li", "Hui Chen", "Huaixiao Tou", "Mosha Chen", "Fei Huang", "Huajun Chen" ],
    "emails" : [ "3160102409}@zju.edu.cn,", "huaixiao.thx}@alibaba-inc.com,", "f.huang}@alibaba-inc.com,", "huajunsir@zju.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2828–2839\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n2828"
    }, {
      "heading" : "1 Introduction",
      "text" : "Event Detection (ED) (Chen et al., 2015) is the task to extract structure information of events from unstructured texts. For example, in the event mention “Jack is married to the Iraqi microbiologist known as Dr. Germ.”, an ED model should identify the event type as ‘Marry’ where the word ‘married’ triggers the event. The extracted events with canonical structure facilitate various social applications, such as biomedical science (Li et al., 2019; Wang et al., 2020c), financial analysis (Deng et al., 2019; Liang et al., 2020), fake news detection (Wang et al., 2018; Nikiforos et al., 2020) and so on.\nAs a non-trivial task, ED suffers from the lowresource issues. On the one hand, the maldistribu-\n∗ Equal Contribution. † Corresponding Author.\ntion of samples is quite serious in ED benchmark datasets, e.g., FewEvent (Deng et al., 2020) and MAVEN (Wang et al., 2020b), where a large portion of event types contain relatively few training instances. As shown in Figure 1, the sample size of two event types Attack and Riot differs greatly (4816 & 30). In low-resource scenarios, supervised ED models (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018) are prone to overfitting since they require sufficient training instances for all event types. On the other hand, real-world applications tend to be open and evolve promptly, and accordingly there can be numerous new unseen event types. Handling new event types may even entail starting over, without being able to re-use annotations from previous ones (Huang et al., 2018).\nRegarding low-resource ED, Huang et al. (2018) take a fresh look at ED, by mapping each event mention to a specific type in a target event ontology, which can train from few seen event types and then transfer knowledge to new unseen ones. However, the event ontology here merely considers the intrastructure for each event mention and event type.\nIn this paper, we enrich the event ontology with more inter-structures of event types, such as temporal, causal and hierarchical event-event relations (Ning et al., 2018; Wang et al., 2020a). For example, as seen in Figure 1, Attack CAUSE−−−−→ Sentence, Sentence BEFORE−−−−→ Acquit, Attack COSUPER−−−−−→ Riot. Our key intention is to fully utilize the event ontology and leverage correlation knowledge from datarich event types (i.e., Attack) to data-poor ones (i.e., Sentence, Acquit and Riot). Besides, new event types (i.e., Be-Born) can be learned with correlation (i.e., COSUPER) of existing ones (i.e., Injure).\nAs the first attempt to construct such event ontology, we propose a novel ED framework with ontology embedding called OntoED. First, we establish the initial event ontology with event instances and types. We capture semantic features and relations of event instances with BERT (Devlin et al., 2019) and utilize prototypes (Snell et al., 2017) to represent event types, where a prototype is the average of its instance embeddings. Second, we extend the event ontology with event-event relations based on extracted relations among event instances, and then learn ontology embedding by aggregating neighbor prototypes for each prototype w.r.t. correlations among event types. In this way, semantically similar event types in vector space will be closer, thus, improving the discrimination of dissimilar event types. Third, we design an event correlation inference mechanism to induce new event correlations based on symbolic rules, e.g., (Sentence, BEFORE, Acquit) ∧ (Acquit, BEFORE, Pardon)→ (Sentence, BEFORE, Pardon). Thus, we can induce new eventevent relations to further enrich the event ontology. To the best of our knowledge, it is the first work to explicitly model correlations among event types with event ontology in low-resource ED.\nOur contributions can be summarized as follows:\n• We study the low-resource event detection problem and propose a novel ontology-based model, OntoED, that encodes intra and inter structures of events.\n• We provide a novel ED framework based on ontology embedding with event correlations, which interoperates symbolic rules with popular deep neural networks.\n• We build a new dataset OntoEvent for ED. Extensive experimental results demonstrate that our model can achieve better performance on the overall, few-shot, and zero-shot setting."
    }, {
      "heading" : "2 Related Work",
      "text" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios. Most previous low-resource ED methods (Peng et al., 2016) have been based on supervised learning. However, supervised-based methods are too dependent on data, and fail to be applied to new types without additional annotation efforts. Another popular methods for low-resource ED are based on meta learning. Deng et al. (2020); Lai et al. (2020); Shen et al. (2021) reformulate ED as a few-shot learning problem to extend ED with limited labeled samples to new event types, and propose to resolve few-shot ED with meta learning. Besides, knowledge enhancement and transfer learning are applied to tackle low-resource ED problems. Tong et al. (2020) leverage open-domain trigger knowledge to address long-tail issues in ED. Liu et al. (2020); Du and Cardie (2020) propose to handle few-shot and zero-shot ED tasks by casting it as a machine reading comprehension problem. Huang et al. (2018) propose to tackle zero-shot ED problem by mapping each event mention to a specific type in a target event ontology. Note that Huang et al. (2018) establish the event ontology merely with intra-structure of events, while we extend it with inter-structure of event correlations. Though these methods are suitable for low-resource scenarios, they mostly ignore implicit correlation among event types and lack reasoning ability.\nIn order to utilize correlation knowledge among event types, Li et al. (2020) propose a new event graph schema, where two event types are connected through multiple paths involving entities. However, it requires various annotations of entities and entity-entity relations, which is complicated and demanding. Different from Li et al. (2020), we propose to revisit the ED task as an ontology learning process, inspired by relation extraction (RE) tasks based on ontology and logic-based learning. Lima et al. (2018, 2019) present a logic-based relational learning approach to RE that uses inductive logic programming for generating information extraction (IE) models in the form of symbolic rules, demonstrating that ontology-based IE approaches are advantageous in capturing correlation among classes, and succeed in symbolic reasoning."
    }, {
      "heading" : "3 Methodology",
      "text" : ""
    }, {
      "heading" : "3.1 Problem Formulation",
      "text" : "We revisit the event detection task as an iterative process of event ontology population. Given an event ontology O with an event type set E = {ei|i ∈ [1, Ne]}, and corpus T = {Xi|i ∈ [1,K]} that contains K instances, the goal of event ontology population is to establish proper linkages between event types and instances. Specifically, each instance Xi in T is denoted as a token sequence Xi = {xji |j ∈ [1, L]} with maximum L tokens, where the event trigger xti are annotated. We expect to predict the index t (1 ≤ t ≤ L) and the event label ei for each instance respectively.\nBesides, we utilize a multi-faceted event-event relation set R = RH t RT t RC for event ontology population and learning. Thereinto,RH = {SUBSUPER, SUPERSUB,COSUPER1} denotes a set of relation labels defined in the subevent relation extraction task (Wang et al., 2020a; Yao et al., 2020). RT = {BEFORE,AFTER, EQUAL2} denotes a set of temporal relations (Han et al., 2020). RC = {CAUSE,CAUSEDBY} denotes a set of causal relations (Ning et al., 2018)."
    }, {
      "heading" : "3.2 Model Overview",
      "text" : "In this paper, we propose a general framework called OntoED with three modules: (1) Event Detection (Ontology Population), (2) Event Ontology Learning, and (3) Event Correlation Inference. Figure 2 shows the key idea of the three modules.\nEvent Detection aims at identifying the event trigger xti and type ei for each input tokens Xi, and then identify relations among event instances. The average instance embedding of each type is calculated as the primitive event prototype.\nEvent Ontology Learning aims to obtain event ontology embedding with the correlation of event prototypes, based on the relations among event types derived from instances.\n1(ei, COSUPER, ej): ei and ej has the same super type. 2(ei, EQUAL, ej): ei and ej happens simultaneously.\nEvent Correlation Inference seeks to infer new event correlations based on existing event-event relations, so as to obtain a solid event ontology.\nThe detailed architecture of OntoED with running examples is illustrated in Figure 3."
    }, {
      "heading" : "3.3 Event Detection (Ontology Population)",
      "text" : "The input of ED is an initial event ontology with event types E and coarse corpus T .\nInstance Encoder. Given a token sequence Xi = {x1i , · · · , xLi } with trigger xti, we use a pretrained BERT (Devlin et al., 2019) to get a contextual representation Xti for x t i, and use the token embedding of [CLS] as the contextual representation Xi for Xi. Note that the instance encoder is pluggable, and can be replaced as other models followed by (Deng et al., 2020; Cui et al., 2020).\nClass Encoder. We then represent event types as prototypes (Snell et al., 2017), as it is proven to be robust for low-resource ED (Deng et al., 2020).\nInitially, event types have no correlation with others, thus we require to compute the prototype Pk for ek ∈ E by averaging its instance embeddings:\nPk = 1\nNk\n∑Nk i=1 Xi (1)\nwhere Nk is the instance number of ek. Afterward, event prototypes will be induced from the module of event correlation inference, as shown in Figure 3.\nEvent Detector. Given embeddings of a token sequence, we treat each token as an event trigger candidate and then compute probability of the corresponding event type for event trigger candidate xti, denoted by:\nP (y = ek) = exp(−‖Xti − Pk‖)∑Ne j=1 exp(−‖Xti − Pj‖) (2)\nwhere ‖ · ‖ denotes Euclidean distance, and Ne = |E| denotes the number of event types.\nAs general, we adopt cross entropy as the loss function for event detection, denoted by:\nLED = − ∑Ne\nk=1 y logP (y = ek) (3)\nwhere y is the ground-truth label for xti. Instance Relation Extractor. For each event instance pair (Xi, Xj), we adopt a comprehensive way to model embedding interactions (Zhou et al., 2020), denoted by Xpij = [Xi,Xj ,Xi Xj ,Xi− Xj ], where [·, ·] denotes a vector concatenation, and is the element-wise Hadamard product.\nWe then calculate the probability P (y = rk) of relation rk ∈ R between (Xi, Xj) by softmax. Generally, we adopt cross entropy as the loss function for instance relation extraction, denoted by:\nLRE = − ∑Nr\nk=1 y logP (y = rk) (4)\nwhere y is the ground-truth for (Xi, Xj), andNr = |R| denotes the number of event-event relations.\nOverall, the loss function for event detection (ontology population) is calculated by:\nLOP = γLED + (1− γ)LRE (5)\nwhere γ is a hyperparameter."
    }, {
      "heading" : "3.4 Event Ontology Learning",
      "text" : "Ontology Completion. We complete event ontology O with both intra and inter structure of events. We normatively link event instances T to event types E , and establish correlations among event types based on linkages among event instances.\nInstance-to-class Linking. Given a sentence Si (formalized as a token sequence Xi) with a trigger xti of an event instance, we link these information to its corresponding event type ei with normative triples: (Si, triggerIs, xti) and (Si, instanceOf, ei).\nClass-to-class Linking. Given an event instance pair (Xi, Xj) with a relation r, we upgrade the\ninstance correlation to corresponding event types, denoted by (ei, r, ej). Besides, we link each event subtype to its corresponding supertype3 with a SUBSUPER relation (SUPERSUB in reverse), and we link each event subtype pair having the same supertype with a COSUPER relation.\nOntology Embedding. We represent the event ontology considering both instances and correlations for each event type. Specifically, given a triple ` = (eh, r, et) ∈ O, we propagate the prototype Ph of head event type eh to prototype Pt of tail event type et with a relation transformation matrix Mr ∈ Rd×d. We select a matrix to embed r as it shows great robustness to model relations in lowresource senarios (Zhang et al., 2019). We then aggregate propagation from all head event types by\nP ∗t = ∑\n(eih,ri,et)∈O`\nP ihMri (6)\nwhere O` is all one-hop neighbor triples of et in O. The prototype Pt of et in ` after propagation is a weighted average of Pt and P ∗t with weight λ ∈ [0, 1], denoted by:\nPt = λPt + (1− λ)P ∗t (7) 3The supertypes and its corresponding subtypes in this\npaper are pre-defined and will be introduced in appendix.\nWe calculate the possibility that r is the relation between eh and et with a truth value for (eh, r, et): φ(eh, r, et) = sim(PhMr,Pt) = σ(P > h MrPt), where σ is sigmoid function, and the similarity between PhMr and Pt is evaluated via dot product.\nOverall, the loss fuction for event ontology learning is defined by:\nLOL = − ∑\n(eh,r,et)∈O\ny log φ(eh, r, et) (8)\nand y denotes the ground-truth label for (eh, r, et)."
    }, {
      "heading" : "3.5 Event Correlation Inference",
      "text" : "Given the event ontology with correlations among event types, we infer new event correlations based on existing ones. To be specific, we utilize the grounding g to infer new event correlation triples, which can be generalized as the following form:\n(eIh, r I , eIt )← (e1h, r1, e1t ), · · · , (enh, rn, ent ) (9)\nwhere the right side event triples (ekh, r k, ekt ) ∈ O with k ∈ [1, n] have already existed in O and (eIh, r\nI , eIt ) /∈ O is new inferred triples to be added. To compute the truth value of the grounding g, we select three object properties (OP) of relations defined in OWL24 Web Ontology Language: subOP, inverseOP, and transitiveOP, and then learn matrics of relations from linear map assumption (Zhang et al., 2019), presented in Table 1. Wang et al. (2020a); Ning et al. (2018) have defined some conjunctive constraints of relations between the event pair, we translate them into object property axioms, shown in Table 2.\nAssuming that M †r and M ‡ r denotes the relation set on left and right of Eq (9) respectively, they are 4https://www.w3.org/TR/owl2-profiles/\nmatrices either from a single matrix or a product of two matrices. As relation constraints are derived from ideal linear map assumption (the 3rd column in Table 1), M †r and M ‡ r are usually unequal but similar during training. Thus, the normalized truth value Fp of g can be calculated based on relation constraints (the 4th column in Table 1):\nF ′p = ‖M †r −M ‡r ‖F , Fp = Fmaxp −F\n′ p\nFmaxp −Fminp where ‖ · ‖F denotes Frobenius norm, and subscript p respectively denotes one of the three object properties. Fmaxp and Fminp is a the maximum and minimum Frobenius norm score. Fp ∈ [0, 1] is the truth value for the grounding g and the higher Fp means the more confident that g is valid.\nThe loss function for new event correlation inference is defined by:\nLER =− ψS ∑\ni∈G(S) logF ip − ψV ∑ j∈G(V ) logF jp\n− ψT ∑\nk∈G(T ) logFkp\n(10) G(·) denotes all groundings w.r.t. subOP (S), inverseOP (V ), and transitiveOP (T ). ψS , ψV , and ψT are hyperparameters for the loss of three object properties respectively.\nAs a whole, the final loss function for OntoED is denoted by:\nL = αLOP + βLOL + LER (11)\nwhere α and β are hyperparameters for the loss of event ontology population (Eq (5)) and event ontology learning (Eq (8)) respectively."
    }, {
      "heading" : "4 Experiments",
      "text" : "The experiments seek to: (1) demonstrate that OntoED with ontology embedding can benefit both standard and low-resource ED, and (2) assess the effectiveness of different modules in OntoED and provide error analysis. To this end, we verify the effectiveness of OntoED in three types of evaluation: (1) Overall Evaluation, (2) Few-shot Evaluation, and (3) Zero-shot Evaluation."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "As none of present datasets for ED is annotated with relations among events, we propose a new ED dataset namely OntoEvent with event correlations. It contains 13 supertypes with 100 subtypes, derived from 4,115 documents with 60,546 event instances. The details of OntoEvent are introduced in appendix. We show the main statistics of OntoEvent and compare them with some existing widely-used ED datasets in Table 3.\nOntoEvent is established based on two newly proposed datasets for ED: MAVEN (Wang et al., 2020b) and FewEvent (Deng et al., 2020). They are constructed from Wikipedia documents or based on existing event datasets, such as ACE-20055 and TAC-KBP-20176. In terms of event-event relation annotation in OntoEvent, we jointly use two models: TCR (Ning et al., 2018) is applied to extract temporal and causal relations, and JCL (Wang et al., 2020a) is used for extract hierarchical relations. The source code of OntoED and OntoEvent dataset can be obtained from the link: https://github.com/231sm/Reasoning In EE."
    }, {
      "heading" : "4.2 Baselines",
      "text" : "For overall evaluation, we adopt CNN-based model DMCNN (Chen et al., 2015), RNN-based model JRNN (Nguyen et al., 2016), and GCNbased model JMEE (Liu et al., 2018). Besides, we adopt BERT-based model AD-DMBERT (Wang et al., 2019) with adversarial imitation learning. We also adopt graph-based models OneIE (Lin et al., 2020) and PathLM (Li et al., 2020) which generate graphs from event instances for ED. For few-shot evaluation and zero-shot evaluation, we adopt some metric-based models for few-shot ED, such as MatchNet (Lai et al., 2020), ProtoNet (Snell et al., 2017) and DMBPN (Deng et al., 2020). We also adopt knowledge-enhanced model EKD\n5http://projects.ldc.upenn.edu/ace/ 6https://tac.nist.gov/2017/KBP/Event/index.html\n(Tong et al., 2020) and BERT-based models QAEE (Du and Cardie, 2020) as well as RCEE (Liu et al., 2020) based on machine reading comprehension. Besides, we adopt ZSEE (Huang et al., 2018) especially for zero-shot ED."
    }, {
      "heading" : "4.3 Experiment Settings",
      "text" : "With regard to settings of the training process, SGD (Ketkar, 2014) optimizer is used, with 30,000 iterations of training and 2,000 iterations of testing. The dimension of token embedding is 50, and the maximum length of a token sequence is 128. In OntoED, a dropout rate of 0.2 is used to avoid over-fitting, and the learning rate is 1× 10−3. The hyperparameters of γ, λ, α, and β are set to 0.5, 0.5, 1.5 and 1 respectively. ψS , ψV , and ψT are set to 0.5, 0.5 and 1 respectively. We evaluate performance of ED with Precision (P), Recall (R) and F1 Score (F)."
    }, {
      "heading" : "4.4 Overall Evaluation",
      "text" : "Setting. We follow the evaluation protocol of standard ED models, e.g., DMCNN (Chen et al., 2015). Event instances are split into training, validating, and testing subset with ratio of 0.8, 0.1 and 0.1 respectively. Note that there are no new event types in testing set which are not seen in training set.\nAs seen from Table 4, OntoED achieves larger gains compared to conventional baselines, e.g., DMCNN, JRNN and JMEE. Moreover, OntoED still generally excel BERT-based AD-DMBERT. This implies the effectiveness of ED framework with ontology embedding, which can leverage and propagate correlations among event types, so that reduce the dependence on data to some extent. Especially, OntoED also outperform graph-based models, i.e., OneIE and PathLM. The possible reason is that although they both convert sentences into instance graphs, and PathLM even connects event types with multiple entities, the event correlations are still implicit and hard to capture. OntoED can explicitly utilize event correlations and directly propagate information among event types."
    }, {
      "heading" : "4.5 Few-shot Evaluation",
      "text" : "Setting. We follow the evaluation protocol and metrics of data-scarce ED models, i.e., RCEE (Liu et al., 2020), which train models with partial data. We randomly sample nearly 80% event types for training, 10% for validating, and 10% for testing. Differently from overall evaluation, the event types in testing set are not exsiting in training set.\nAs seen from Table 5, we demonstrate F1 score results in extremely low-resource scenarios (training with less than 20% data, with the similar setting to Liu et al. (2020)). Obviously, OntoED behaves tremendous advantages in low-resource ED. For example, OntoED obtains 44.98% F1 with 1% data, in comparison to 7.09% in MatchNet and 8.18% in ProtoNet. We also illustrate accuracy results with different ratios of training data followed by Liu et al. (2020), show in Figure 4. As seen, OntoED demonstrates superior performance with less data dependence than baselines. Especially comparing with DMBPN and EKD, which require 60% training data to closely achieve the best results, while OntoED only uses 20%. Besides, we find that the performance on DMBPN increases first and then slightly decreases as the ratio of training data in-\ncreases, the possible reason may lie in data noise and redundancy. In low-resource scenarios, more data are not always better. Particularly for some merely data-driven ED models, such as DMBPN, may obtain a worse effect instead if added data are dirty or duplicated. But for OntoED, as it utilizes correlation knowledge in the event ontology and has less dependence on event instances, making it more robust to noisy and redundant data. Furthermore, OntoED also outperforms than BERT-based model with regarding each event instance as a question, i.e., QAEE and RCEE. This implies that event ontology learning with event type knowledge may resolve low-resource ED more advantageously than training merely with event instances."
    }, {
      "heading" : "4.6 Zero-shot Evaluation",
      "text" : "Setting. We follow the evaluation protocol and metrics of zero-shot ED models, i.e., ZSEE (Huang et al., 2018), and comply with the same dataset segmentation policy as few-shot evaluation, thus there are also new unseen event types for testing. Differently, ED data are completely banned for training, meaning that we train models only with event types other than instances.\nTable 6 demonstrates the results regarding zeroshot ED. We can see that OntoED achieves best precision and F1 score as well as comparable recall results in comparison to baselines. This illustrates the effectiveness of OntoED handling new unseen event types without introducing outsourcing data.\nTraditional models, such as EKD and RCEE, require to adopt other datasets, e.g., WordNet (Miller et al., 1990) (where words are grouped and interlinked with semantic relations) and FrameNet (Baker, 2014) (where frames are treated as meta event types) to increase the persuasiveness of results. In contrast, OntoED naturally models the structure of event types with an event ontology, thus even for a new unseen event type without instance data, we can also obtain its representation through the event-event correlation. Moreover, OntoED is also beneficial to resolve zero-shot ED than ZSEE. This may due to OntoED modeling with both intra and inter structures of events while ZSEE merely considering the intra-structure."
    }, {
      "heading" : "5 Further Analysis",
      "text" : ""
    }, {
      "heading" : "5.1 Ablation Study",
      "text" : "To assess the effect of event ontology learning and correlation inference, we remove the two modules in OntoED, and evaluate F1 score shown in Figure 5. From the results, we observe that OntoED outperforms the two baselines in all evaluation settings, indicating that event ontology learning and correlation inference facilitate ED, as they utilize knowledge among event types and has less dependence on instance data. Furthermore, in terms of performance degradation compared to OntoED, F1 score of OntoED merely without event correlation inference (e.g., 10.9%↓) drops more seriously than that without event ontology learning (e.g., 6.6%↓), and the phenomenon is more obvious in few-shot and zero-shot evaluation (e.g., 10.9%↓ v.s. 15.9%↓ and 28.1%↓). This illustrates that event correlation inference is more necessary in OntoED, as it establishes more correlations among event types, thereby knowledge can be propagated more adequately, especially from data-rich to data-poor events."
    }, {
      "heading" : "5.2 Error Analysis",
      "text" : "We further conduct error analysis and provide some representative examples. (1) One typical error relates to similar event-event structures in the event ontology. As OntoED considers event correlations,\nevent types with similar neighbor triples can be indistinguishable. For example, Robbery and Kidnapping have the same supertype Crime, and they both have the neighbor triples of (∗, CAUSE, Arrest). (2) The second error relates to wrong instance relations. As the instance relation extraction directly influence the establishment of event correlations, wrong instance relations will cause error propagation. (3) The third error relates to the same event mention for different event types. For example, ‘Of the 126 people aboard, 47 died and 74 sustained serious injuries.’ both mentions Die and Injure."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "This paper proposes a novel event detection framework with ontology embedding called OntoED. We revisit the ED task by linking each event instance to a specific type in a target event ontology. To facilitate the linkage, we enrich the event ontology with event-event relations, such as temporal, causal and hierarchical correlation, and induce more event correlations based on existing ones. The key insight is that event ontology can help to reduce model dependence on instance data, especially in low-resource scenarios. As data-rich event types can propagate correlation knowledge to data-poor ones, and new event types can establish linkages to the event ontology. We demonstrate the effectiveness of OntoED in three settings: overall, few-shot as well as zeroshot, and experiments show that OntoED excels previous methods with great robustness.\nIn the future, we intend to extend our work in several aspects. First, we would improve the event ontology and consider more event correlations. Second, we would explore if low-resource ED can also boost to identify event correlation. Third, we would develop more neuro-symbolic methods for ED."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We want to express gratitude to the anonymous reviewers for their hard work and kind comments. This work is funded by National Key R&D Program of China (Funding No.2018YFB1402800) and NSFC91846204.\nBroader Impact Statement\nA broad goal of event detection is to extract structured knowledge from unstructured texts to facilitate knowledge acquisition. For example, it is valuable in the medical domain and provides social benefits to analyze dispensatory details as well as electronic health records. Furthermore, a solid ED system can also be applied to many society issues, such as anti-terrorist and public opinion analysis.\nIn this paper, we present a new dataset OntoEvent for ED with event-event correlations. The event data are all collected from existing datasets (i.e., ACE 2005) or open source databases (e.g., Wikipedia), and the annotation are generated from existing models with citations. In experiments, we detailedly describe how to evaluate the newly-proposed OntoEvent and provide specific analysis. The code and dataset are both available.\nOur approach to ED can leverage only a few event corpus to establish the linkage between event types and event instances w.r.t. event correlations. In addition, this work is also a brand-new attempt to combine information extraction and symbolic reasoning, based on ontology embedding. Our intention is to develop an ontology-based ED system for the NLP community, and wish our innovation can become a small step in this direction."
    }, {
      "heading" : "B Hierarchical Event Type Schema (Part 2)",
      "text" : ""
    }, {
      "heading" : "A Hierarchical Event Type Schema (Part 1)",
      "text" : ""
    }, {
      "heading" : "C Overview of Temporal & Causal Event-Event Correlations",
      "text" : ""
    } ],
    "references" : [ {
      "title" : "Framenet: A knowledge base for natural language processing",
      "author" : [ "Collin F Baker." ],
      "venue" : "Proceedings of Frame Semantics in NLP: A workshop in honor of Chuck Fillmore (1929-2014), pages 1–5.",
      "citeRegEx" : "Baker.,? 2014",
      "shortCiteRegEx" : "Baker.",
      "year" : 2014
    }, {
      "title" : "Event extraction via dynamic multipooling convolutional neural networks",
      "author" : [ "Yubo Chen", "Liheng Xu", "Kang Liu", "Daojian Zeng", "Jun Zhao." ],
      "venue" : "ACL (1), pages 167–176. The Association for Computer Linguistics.",
      "citeRegEx" : "Chen et al\\.,? 2015",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2015
    }, {
      "title" : "Edgeenhanced graph convolution networks for event detection with syntactic relation",
      "author" : [ "Shiyao Cui", "Bowen Yu", "Tingwen Liu", "Zhenyu Zhang", "Xuebin Wang", "Jinqiao Shi." ],
      "venue" : "EMNLP (Findings), pages 2329–2339. Association for Computa-",
      "citeRegEx" : "Cui et al\\.,? 2020",
      "shortCiteRegEx" : "Cui et al\\.",
      "year" : 2020
    }, {
      "title" : "Metalearning with dynamic-memory-based prototypical network for few-shot event detection",
      "author" : [ "Shumin Deng", "Ningyu Zhang", "Jiaojian Kang", "Yichi Zhang", "Wei Zhang", "Huajun Chen." ],
      "venue" : "WSDM, pages 151–159. ACM.",
      "citeRegEx" : "Deng et al\\.,? 2020",
      "shortCiteRegEx" : "Deng et al\\.",
      "year" : 2020
    }, {
      "title" : "Knowledge-driven stock trend prediction and explanation via temporal convolutional network",
      "author" : [ "Shumin Deng", "Ningyu Zhang", "Wen Zhang", "Jiaoyan Chen", "Jeff Z. Pan", "Huajun Chen." ],
      "venue" : "WWW (Companion Volume), pages 678–685. ACM.",
      "citeRegEx" : "Deng et al\\.,? 2019",
      "shortCiteRegEx" : "Deng et al\\.",
      "year" : 2019
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "NAACL-HLT (1), pages 4171–4186. Association for Computational Linguistics.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Event extraction by answering (almost) natural questions",
      "author" : [ "Xinya Du", "Claire Cardie." ],
      "venue" : "EMNLP (1), pages 671–683. Association for Computational Linguistics.",
      "citeRegEx" : "Du and Cardie.,? 2020",
      "shortCiteRegEx" : "Du and Cardie.",
      "year" : 2020
    }, {
      "title" : "Domain knowledge empowered structured neural net for end-to-end event temporal relation extraction",
      "author" : [ "Rujun Han", "Yichao Zhou", "Nanyun Peng." ],
      "venue" : "EMNLP (1), pages 5717–5729. Association for Computational Linguistics.",
      "citeRegEx" : "Han et al\\.,? 2020",
      "shortCiteRegEx" : "Han et al\\.",
      "year" : 2020
    }, {
      "title" : "Zero-shot transfer learning for event extraction",
      "author" : [ "Lifu Huang", "Heng Ji", "Kyunghyun Cho", "Ido Dagan", "Sebastian Riedel", "Clare R. Voss." ],
      "venue" : "ACL (1), pages 2160–2170. Association for Computational Linguistics.",
      "citeRegEx" : "Huang et al\\.,? 2018",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2018
    }, {
      "title" : "Stochastic gradient descent",
      "author" : [ "Nikhil Ketkar." ],
      "venue" : "Optimization.",
      "citeRegEx" : "Ketkar.,? 2014",
      "shortCiteRegEx" : "Ketkar.",
      "year" : 2014
    }, {
      "title" : "Extensively matching for few-shot learning event detection",
      "author" : [ "Viet Dac Lai", "Thien Huu Nguyen", "Franck Dernoncourt." ],
      "venue" : "NUSE@ACL, pages 38–",
      "citeRegEx" : "Lai et al\\.,? 2020",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 2020
    }, {
      "title" : "Biomedical event extraction based on knowledgedriven tree-lstm",
      "author" : [ "Diya Li", "Lifu Huang", "Heng Ji", "Jiawei Han." ],
      "venue" : "NAACL-HLT (1), pages 1421– 1430. Association for Computational Linguistics.",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Connecting the dots: Event graph schema induction with path language modeling",
      "author" : [ "Manling Li", "Qi Zeng", "Ying Lin", "Kyunghyun Cho", "Heng Ji", "Jonathan May", "Nathanael Chambers", "Clare R. Voss." ],
      "venue" : "EMNLP (1), pages 684–695. Association for Com-",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "F-HMTC: detecting financial events for investment decisions based on neural hierarchical multi-label text classification",
      "author" : [ "Xin Liang", "Dawei Cheng", "Fangzhou Yang", "Yifeng Luo", "Weining Qian", "Aoying Zhou." ],
      "venue" : "IJCAI, pages 4490–4496. ijcai.org.",
      "citeRegEx" : "Liang et al\\.,? 2020",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2020
    }, {
      "title" : "Ontoilper: an ontology- and inductive logic programming-based system to extract entities and relations from text",
      "author" : [ "Rinaldo Lima", "Bernard Espinasse", "Fred Freitas." ],
      "venue" : "Knowl. Inf. Syst., 56(1):223–255.",
      "citeRegEx" : "Lima et al\\.,? 2018",
      "shortCiteRegEx" : "Lima et al\\.",
      "year" : 2018
    }, {
      "title" : "A logic-based relational learning approach to relation extraction: The ontoilper system",
      "author" : [ "Rinaldo Lima", "Bernard Espinasse", "Fred Freitas." ],
      "venue" : "Eng. Appl. Artif. Intell., 78:142–157.",
      "citeRegEx" : "Lima et al\\.,? 2019",
      "shortCiteRegEx" : "Lima et al\\.",
      "year" : 2019
    }, {
      "title" : "A joint neural model for information extraction with global features",
      "author" : [ "Ying Lin", "Heng Ji", "Fei Huang", "Lingfei Wu." ],
      "venue" : "ACL, pages 7999–8009. Association for Computational Linguistics.",
      "citeRegEx" : "Lin et al\\.,? 2020",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "Event extraction as machine reading comprehension",
      "author" : [ "Jian Liu", "Yubo Chen", "Kang Liu", "Wei Bi", "Xiaojiang Liu." ],
      "venue" : "EMNLP (1), pages 1641–1651. Association for Computational Linguistics.",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Jointly multiple events extraction via attentionbased graph information aggregation",
      "author" : [ "Xiao Liu", "Zhunchen Luo", "Heyan Huang." ],
      "venue" : "EMNLP, pages 1247–1256. Association for Computational Linguistics.",
      "citeRegEx" : "Liu et al\\.,? 2018",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2018
    }, {
      "title" : "Mlbinet: A crosssentence collective event detection network",
      "author" : [ "Dongfang Lou", "Zhilin Liao", "Shumin Deng", "Ningyu Zhang", "Huajun Chen." ],
      "venue" : "ACL. Association for Computational Linguistics.",
      "citeRegEx" : "Lou et al\\.,? 2021",
      "shortCiteRegEx" : "Lou et al\\.",
      "year" : 2021
    }, {
      "title" : "Introduction to wordnet: An on-line lexical database",
      "author" : [ "George A Miller", "Richard Beckwith", "Christiane Fellbaum", "Derek Gross", "Katherine J Miller." ],
      "venue" : "International journal of lexicography, 3(4):235– 244.",
      "citeRegEx" : "Miller et al\\.,? 1990",
      "shortCiteRegEx" : "Miller et al\\.",
      "year" : 1990
    }, {
      "title" : "Joint event extraction via recurrent neural networks",
      "author" : [ "Thien Huu Nguyen", "Kyunghyun Cho", "Ralph Grishman." ],
      "venue" : "HLT-NAACL, pages 300–309. The Association for Computational Linguistics.",
      "citeRegEx" : "Nguyen et al\\.,? 2016",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2016
    }, {
      "title" : "Fake news detection regarding the hong kong events from tweets",
      "author" : [ "Maria Nefeli Nikiforos", "Spiridon Vergis", "Andreana Stylidou", "Nikolaos Augoustis", "Katia Lida Kermanidis", "Manolis Maragoudakis." ],
      "venue" : "AIAI Workshops, volume 585 of IFIP Ad-",
      "citeRegEx" : "Nikiforos et al\\.,? 2020",
      "shortCiteRegEx" : "Nikiforos et al\\.",
      "year" : 2020
    }, {
      "title" : "Joint reasoning for temporal and causal relations",
      "author" : [ "Qiang Ning", "Zhili Feng", "Hao Wu", "Dan Roth." ],
      "venue" : "ACL (1), pages 2278–2288. Association for Computational Linguistics.",
      "citeRegEx" : "Ning et al\\.,? 2018",
      "shortCiteRegEx" : "Ning et al\\.",
      "year" : 2018
    }, {
      "title" : "Event detection and co-reference with minimal supervision",
      "author" : [ "Haoruo Peng", "Yangqiu Song", "Dan Roth." ],
      "venue" : "EMNLP, pages 392–402. The Association for Computational Linguistics.",
      "citeRegEx" : "Peng et al\\.,? 2016",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2016
    }, {
      "title" : "Hierarchical chinese legal event extraction via pedal attention mechanism",
      "author" : [ "Shirong Shen", "Guilin Qi", "Zhen Li", "Sheng Bi", "Lusheng Wang." ],
      "venue" : "COLING, pages 100–113. International Committee on Computational Linguistics.",
      "citeRegEx" : "Shen et al\\.,? 2020",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2020
    }, {
      "title" : "Adaptive knowledge-enhanced bayesian meta-learning for few-shot event detection",
      "author" : [ "Shirong Shen", "Tongtong Wu", "Guilin Qi", "Yuan-Fang Li", "Gholamreza Haffari", "Sheng Bi." ],
      "venue" : "Findings of ACL. Association for Computational Linguistics.",
      "citeRegEx" : "Shen et al\\.,? 2021",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2021
    }, {
      "title" : "Prototypical networks for few-shot learning",
      "author" : [ "Jake Snell", "Kevin Swersky", "Richard S. Zemel." ],
      "venue" : "NIPS, pages 4077–4087.",
      "citeRegEx" : "Snell et al\\.,? 2017",
      "shortCiteRegEx" : "Snell et al\\.",
      "year" : 2017
    }, {
      "title" : "Improving event detection via open-domain trigger knowledge",
      "author" : [ "Meihan Tong", "Bin Xu", "Shuai Wang", "Yixin Cao", "Lei Hou", "Juanzi Li", "Jun Xie." ],
      "venue" : "ACL, pages 5887–5897. Association for Computational Linguistics.",
      "citeRegEx" : "Tong et al\\.,? 2020",
      "shortCiteRegEx" : "Tong et al\\.",
      "year" : 2020
    }, {
      "title" : "Joint constrained learning for event-event relation extraction",
      "author" : [ "Haoyu Wang", "Muhao Chen", "Hongming Zhang", "Dan Roth." ],
      "venue" : "EMNLP (1), pages 696–706. Association for Computational Linguistics.",
      "citeRegEx" : "Wang et al\\.,? 2020a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Adversarial training for weakly supervised event detection",
      "author" : [ "Xiaozhi Wang", "Xu Han", "Zhiyuan Liu", "Maosong Sun", "Peng Li." ],
      "venue" : "NAACL-HLT (1), pages 998–1008. Association for Computational Linguistics.",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "MAVEN: A massive general domain event detection dataset",
      "author" : [ "Xiaozhi Wang", "Ziqi Wang", "Xu Han", "Wangyi Jiang", "Rong Han", "Zhiyuan Liu", "Juanzi Li", "Peng Li", "Yankai Lin", "Jie Zhou." ],
      "venue" : "EMNLP (1), pages 1652–1671. Association for Computational",
      "citeRegEx" : "Wang et al\\.,? 2020b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Biomedical event extraction as multi-turn question answering",
      "author" : [ "Xing David Wang", "Leon Weber", "Ulf Leser." ],
      "venue" : "LOUHI@EMNLP, pages 88–96. Association for Computational Linguistics.",
      "citeRegEx" : "Wang et al\\.,? 2020c",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "EANN: event adversarial neural networks for multi-modal fake news detection",
      "author" : [ "Yaqing Wang", "Fenglong Ma", "Zhiwei Jin", "Ye Yuan", "Guangxu Xun", "Kishlay Jha", "Lu Su", "Jing Gao." ],
      "venue" : "KDD, pages 849–857. ACM.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Event detection with multi-order graph convolution and aggregated attention",
      "author" : [ "Haoran Yan", "Xiaolong Jin", "Xiangbin Meng", "Jiafeng Guo", "Xueqi Cheng." ],
      "venue" : "EMNLP/IJCNLP (1), pages 5765–5769. Association for Computational Linguistics.",
      "citeRegEx" : "Yan et al\\.,? 2019",
      "shortCiteRegEx" : "Yan et al\\.",
      "year" : 2019
    }, {
      "title" : "Weakly supervised subevent knowledge acquisition",
      "author" : [ "Wenlin Yao", "Zeyu Dai", "Maitreyi Ramaswamy", "Bonan Min", "Ruihong Huang." ],
      "venue" : "EMNLP (1), pages 5345–5356. Association for Computational Linguistics.",
      "citeRegEx" : "Yao et al\\.,? 2020",
      "shortCiteRegEx" : "Yao et al\\.",
      "year" : 2020
    }, {
      "title" : "Iteratively learning embeddings and rules for knowledge graph reasoning",
      "author" : [ "Wen Zhang", "Bibek Paudel", "Liang Wang", "Jiaoyan Chen", "Hai Zhu", "Wei Zhang", "Abraham Bernstein", "Huajun Chen." ],
      "venue" : "WWW, pages 2366–2377. ACM.",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Temporal common sense acquisition with minimal supervision",
      "author" : [ "Ben Zhou", "Qiang Ning", "Daniel Khashabi", "Dan Roth." ],
      "venue" : "ACL, pages 7579– 7589. Association for Computational Linguistics.",
      "citeRegEx" : "Zhou et al\\.,? 2020",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Event Detection (ED) (Chen et al., 2015) is the task to extract structure information of events from unstructured texts.",
      "startOffset" : 21,
      "endOffset" : 40
    }, {
      "referenceID" : 11,
      "context" : "The extracted events with canonical structure facilitate various social applications, such as biomedical science (Li et al., 2019; Wang et al., 2020c), financial analysis (Deng et al.",
      "startOffset" : 113,
      "endOffset" : 150
    }, {
      "referenceID" : 32,
      "context" : "The extracted events with canonical structure facilitate various social applications, such as biomedical science (Li et al., 2019; Wang et al., 2020c), financial analysis (Deng et al.",
      "startOffset" : 113,
      "endOffset" : 150
    }, {
      "referenceID" : 4,
      "context" : ", 2020c), financial analysis (Deng et al., 2019; Liang et al., 2020), fake news detection (Wang et al.",
      "startOffset" : 29,
      "endOffset" : 68
    }, {
      "referenceID" : 13,
      "context" : ", 2020c), financial analysis (Deng et al., 2019; Liang et al., 2020), fake news detection (Wang et al.",
      "startOffset" : 29,
      "endOffset" : 68
    }, {
      "referenceID" : 33,
      "context" : ", 2020), fake news detection (Wang et al., 2018; Nikiforos et al., 2020) and so on.",
      "startOffset" : 29,
      "endOffset" : 72
    }, {
      "referenceID" : 22,
      "context" : ", 2020), fake news detection (Wang et al., 2018; Nikiforos et al., 2020) and so on.",
      "startOffset" : 29,
      "endOffset" : 72
    }, {
      "referenceID" : 3,
      "context" : "Event Correlation in FewEvent (Deng et al., 2020) Dataset.",
      "startOffset" : 30,
      "endOffset" : 49
    }, {
      "referenceID" : 31,
      "context" : ", 2020) and MAVEN (Wang et al., 2020b), where a large portion of event types contain relatively few training instances.",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 1,
      "context" : "In low-resource scenarios, supervised ED models (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018) are prone to overfitting since they require sufficient training instances for all event types.",
      "startOffset" : 48,
      "endOffset" : 106
    }, {
      "referenceID" : 21,
      "context" : "In low-resource scenarios, supervised ED models (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018) are prone to overfitting since they require sufficient training instances for all event types.",
      "startOffset" : 48,
      "endOffset" : 106
    }, {
      "referenceID" : 18,
      "context" : "In low-resource scenarios, supervised ED models (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018) are prone to overfitting since they require sufficient training instances for all event types.",
      "startOffset" : 48,
      "endOffset" : 106
    }, {
      "referenceID" : 8,
      "context" : "Handling new event types may even entail starting over, without being able to re-use annotations from previous ones (Huang et al., 2018).",
      "startOffset" : 116,
      "endOffset" : 136
    }, {
      "referenceID" : 23,
      "context" : "2829 In this paper, we enrich the event ontology with more inter-structures of event types, such as temporal, causal and hierarchical event-event relations (Ning et al., 2018; Wang et al., 2020a).",
      "startOffset" : 156,
      "endOffset" : 195
    }, {
      "referenceID" : 29,
      "context" : "2829 In this paper, we enrich the event ontology with more inter-structures of event types, such as temporal, causal and hierarchical event-event relations (Ning et al., 2018; Wang et al., 2020a).",
      "startOffset" : 156,
      "endOffset" : 195
    }, {
      "referenceID" : 5,
      "context" : "We capture semantic features and relations of event instances with BERT (Devlin et al., 2019) and utilize prototypes (Snell et al.",
      "startOffset" : 72,
      "endOffset" : 93
    }, {
      "referenceID" : 27,
      "context" : ", 2019) and utilize prototypes (Snell et al., 2017) to represent event types, where a prototype is the average of its instance embeddings.",
      "startOffset" : 31,
      "endOffset" : 51
    }, {
      "referenceID" : 1,
      "context" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios.",
      "startOffset" : 65,
      "endOffset" : 215
    }, {
      "referenceID" : 21,
      "context" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios.",
      "startOffset" : 65,
      "endOffset" : 215
    }, {
      "referenceID" : 18,
      "context" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios.",
      "startOffset" : 65,
      "endOffset" : 215
    }, {
      "referenceID" : 30,
      "context" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios.",
      "startOffset" : 65,
      "endOffset" : 215
    }, {
      "referenceID" : 34,
      "context" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios.",
      "startOffset" : 65,
      "endOffset" : 215
    }, {
      "referenceID" : 2,
      "context" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios.",
      "startOffset" : 65,
      "endOffset" : 215
    }, {
      "referenceID" : 25,
      "context" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios.",
      "startOffset" : 65,
      "endOffset" : 215
    }, {
      "referenceID" : 19,
      "context" : "Traditional approaches to ED are mostly based on neural networks (Chen et al., 2015; Nguyen et al., 2016; Liu et al., 2018; Wang et al., 2019; Yan et al., 2019; Cui et al., 2020; Shen et al., 2020; Lou et al., 2021), and ignore correlation knowledge of event types, especially in low-resource scenarios.",
      "startOffset" : 65,
      "endOffset" : 215
    }, {
      "referenceID" : 24,
      "context" : "Most previous low-resource ED methods (Peng et al., 2016) have been based on supervised learning.",
      "startOffset" : 38,
      "endOffset" : 57
    }, {
      "referenceID" : 29,
      "context" : "Thereinto,RH = {SUBSUPER, SUPERSUB,COSUPER1} denotes a set of relation labels defined in the subevent relation extraction task (Wang et al., 2020a; Yao et al., 2020).",
      "startOffset" : 127,
      "endOffset" : 165
    }, {
      "referenceID" : 35,
      "context" : "Thereinto,RH = {SUBSUPER, SUPERSUB,COSUPER1} denotes a set of relation labels defined in the subevent relation extraction task (Wang et al., 2020a; Yao et al., 2020).",
      "startOffset" : 127,
      "endOffset" : 165
    }, {
      "referenceID" : 7,
      "context" : "RT = {BEFORE,AFTER, EQUAL2} denotes a set of temporal relations (Han et al., 2020).",
      "startOffset" : 64,
      "endOffset" : 82
    }, {
      "referenceID" : 23,
      "context" : "RC = {CAUSE,CAUSEDBY} denotes a set of causal relations (Ning et al., 2018).",
      "startOffset" : 56,
      "endOffset" : 75
    }, {
      "referenceID" : 5,
      "context" : "Xi = {x(1)i , · · · , xi } with trigger xi, we use a pretrained BERT (Devlin et al., 2019) to get a contextual representation Xt i for x t i, and use the token embedding of [CLS] as the contextual representation Xi for Xi.",
      "startOffset" : 69,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "Note that the instance encoder is pluggable, and can be replaced as other models followed by (Deng et al., 2020; Cui et al., 2020).",
      "startOffset" : 93,
      "endOffset" : 130
    }, {
      "referenceID" : 2,
      "context" : "Note that the instance encoder is pluggable, and can be replaced as other models followed by (Deng et al., 2020; Cui et al., 2020).",
      "startOffset" : 93,
      "endOffset" : 130
    }, {
      "referenceID" : 27,
      "context" : "We then represent event types as prototypes (Snell et al., 2017), as it is proven to be robust for low-resource ED (Deng et al.",
      "startOffset" : 44,
      "endOffset" : 64
    }, {
      "referenceID" : 3,
      "context" : ", 2017), as it is proven to be robust for low-resource ED (Deng et al., 2020).",
      "startOffset" : 58,
      "endOffset" : 77
    }, {
      "referenceID" : 37,
      "context" : "For each event instance pair (Xi, Xj), we adopt a comprehensive way to model embedding interactions (Zhou et al., 2020), denoted by X ij = [Xi,Xj ,Xi Xj ,Xi− Xj ], where [·, ·] denotes a vector concatenation, and is the element-wise Hadamard product.",
      "startOffset" : 100,
      "endOffset" : 119
    }, {
      "referenceID" : 36,
      "context" : "We select a matrix to embed r as it shows great robustness to model relations in lowresource senarios (Zhang et al., 2019).",
      "startOffset" : 102,
      "endOffset" : 122
    }, {
      "referenceID" : 36,
      "context" : "To compute the truth value of the grounding g, we select three object properties (OP) of relations defined in OWL24 Web Ontology Language: subOP, inverseOP, and transitiveOP, and then learn matrics of relations from linear map assumption (Zhang et al., 2019), presented in Table 1.",
      "startOffset" : 238,
      "endOffset" : 258
    }, {
      "referenceID" : 31,
      "context" : "OntoEvent is established based on two newly proposed datasets for ED: MAVEN (Wang et al., 2020b) and FewEvent (Deng et al.",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 23,
      "context" : "In terms of event-event relation annotation in OntoEvent, we jointly use two models: TCR (Ning et al., 2018) is applied to extract temporal and causal relations, and JCL (Wang et al.",
      "startOffset" : 89,
      "endOffset" : 108
    }, {
      "referenceID" : 29,
      "context" : ", 2018) is applied to extract temporal and causal relations, and JCL (Wang et al., 2020a) is used for extract hierarchical relations.",
      "startOffset" : 69,
      "endOffset" : 89
    }, {
      "referenceID" : 1,
      "context" : "For overall evaluation, we adopt CNN-based model DMCNN (Chen et al., 2015), RNN-based model JRNN (Nguyen et al.",
      "startOffset" : 55,
      "endOffset" : 74
    }, {
      "referenceID" : 21,
      "context" : ", 2015), RNN-based model JRNN (Nguyen et al., 2016), and GCNbased model JMEE (Liu et al.",
      "startOffset" : 30,
      "endOffset" : 51
    }, {
      "referenceID" : 30,
      "context" : "Besides, we adopt BERT-based model AD-DMBERT (Wang et al., 2019) with adversarial imitation learning.",
      "startOffset" : 45,
      "endOffset" : 64
    }, {
      "referenceID" : 16,
      "context" : "We also adopt graph-based models OneIE (Lin et al., 2020) and PathLM (Li et al.",
      "startOffset" : 39,
      "endOffset" : 57
    }, {
      "referenceID" : 12,
      "context" : ", 2020) and PathLM (Li et al., 2020) which generate graphs from event instances for ED.",
      "startOffset" : 19,
      "endOffset" : 36
    }, {
      "referenceID" : 10,
      "context" : "For few-shot evaluation and zero-shot evaluation, we adopt some metric-based models for few-shot ED, such as MatchNet (Lai et al., 2020), ProtoNet (Snell et al.",
      "startOffset" : 118,
      "endOffset" : 136
    }, {
      "referenceID" : 27,
      "context" : ", 2020), ProtoNet (Snell et al., 2017) and DMBPN (Deng et al.",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 28,
      "context" : "html (Tong et al., 2020) and BERT-based models QAEE (Du and Cardie, 2020) as well as RCEE (Liu et al.",
      "startOffset" : 5,
      "endOffset" : 24
    }, {
      "referenceID" : 6,
      "context" : ", 2020) and BERT-based models QAEE (Du and Cardie, 2020) as well as RCEE (Liu et al.",
      "startOffset" : 35,
      "endOffset" : 56
    }, {
      "referenceID" : 17,
      "context" : ", 2020) and BERT-based models QAEE (Du and Cardie, 2020) as well as RCEE (Liu et al., 2020) based on machine reading comprehension.",
      "startOffset" : 73,
      "endOffset" : 91
    }, {
      "referenceID" : 8,
      "context" : "Besides, we adopt ZSEE (Huang et al., 2018) especially for zero-shot ED.",
      "startOffset" : 23,
      "endOffset" : 43
    }, {
      "referenceID" : 9,
      "context" : "With regard to settings of the training process, SGD (Ketkar, 2014) optimizer is used, with 30,000 iterations of training and 2,000 iterations of testing.",
      "startOffset" : 53,
      "endOffset" : 67
    }, {
      "referenceID" : 17,
      "context" : ", RCEE (Liu et al., 2020), which train models with partial data.",
      "startOffset" : 7,
      "endOffset" : 25
    }, {
      "referenceID" : 8,
      "context" : ", ZSEE (Huang et al., 2018), and comply with the same dataset segmentation policy as few-shot evaluation, thus there are also new unseen event types for testing.",
      "startOffset" : 7,
      "endOffset" : 27
    }, {
      "referenceID" : 20,
      "context" : ", WordNet (Miller et al., 1990) (where words are grouped and interlinked with semantic relations) and FrameNet (Baker, 2014) (where frames are treated as meta event types) to increase the persuasiveness of results.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 0,
      "context" : ", 1990) (where words are grouped and interlinked with semantic relations) and FrameNet (Baker, 2014) (where frames are treated as meta event types) to increase the persuasiveness of results.",
      "startOffset" : 87,
      "endOffset" : 100
    } ],
    "year" : 2021,
    "abstractText" : "Event Detection (ED) aims to identify event trigger words from a given text and classify it into an event type. Most of current methods to ED rely heavily on training instances, and almost ignore the correlation of event types. Hence, they tend to suffer from data scarcity and fail to handle new unseen event types. To address these problems, we formulate ED as a process of event ontology population: linking event instances to pre-defined event types in event ontology, and propose a novel ED framework entitled OntoED with ontology embedding. We enrich event ontology with linkages among event types, and further induce more event-event correlations. Based on the event ontology, OntoED can leverage and propagate correlation knowledge, particularly from datarich to data-poor event types. Furthermore, OntoED can be applied to new unseen event types, by establishing linkages to existing ones. Experiments indicate that OntoED is more predominant and robust than previous approaches to ED, especially in data-scarce scenarios.",
    "creator" : "LaTeX with hyperref package"
  }
}