{
  "name" : "2021.acl-long.339.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Neural Stylistic Response Generation with Disentangled Latent Variables",
    "authors" : [ "Qingfu Zhu", "Weinan Zhang", "Ting Liu", "William Yang Wang" ],
    "emails" : [ "tliu}@ir.hit.edu.cn", "william@cs.ucsb.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 4391–4401\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n4391"
    }, {
      "heading" : "1 Introduction",
      "text" : "Linguistic style is an essential aspect of natural language interaction and provides particular ways of using language to engage with the audiences (Kabbara and Cheung, 2016). In human-bot conversations, it is crucial to generate stylistic responses for increasing user engagement to conversational systems (Gan et al., 2017). Currently, most of the existing parallel datasets are not stylistically consistent. Samples in these datasets are usually contributed by a variety of users, resulting in an averaging effect across style characteristics (Zhang et al., 2018a). Meanwhile, constructing a parallel stylistic dataset for training the open-domain conversational agents is both labor-intensive and time-consuming.\nRecent studies show the effect of stylizing responses using a monolingual dataset in the desired style and a conventional conversational dataset (Niu and Bansal, 2018; Gao et al., 2019b). However, increasing style intensity often leads to\n∗Corresponding author.\nthe expense of decreasing content relevance between dialogue history and response. As an example in Figure 1 shows, Niu and Bansal (2018) independently train a response generation model and a stylistic language model and subsequently interpolates them in the inference phase. Lacking the interaction between the stylistic language model and response generation encoder, it usually yields a trade-off between style intensity and content relevance. Gao et al. (2019a,b) fuse a structured latent space where the direction denotes the diversity, and the distance denotes style intensity and content relevance. The main issue is that style intensity and content relevance are contradictory in measurement but are coupling to the same “distance” metric of the latent space. To sum up, the key issue of the above studies is the improper entanglement of style and content.\nTo address the issue, we propose to disentangle the style and content of a response. The disentanglement is conducted on the structured latent space, where each sentence (dialogue history, response,\nand stylistic sentence) is projected into a vector representation. We further split the representation into two components: style and content representations. The former is a corpus-level feature since sentences within a dataset have the same style. In contrast, the content representation is a sentence-level feature decided by a sentence itself. We thus disentangle the content and style by diluting sentence-level information in the style representation. This encourages the encoding of content information into the content representation. Otherwise, the content information will be corrupted in the style representation, making it hard to reconstruct the original content in the subsequent decoding process. We conduct experiments on DailyDialogue conversational dataset (Li et al., 2017) and Holmes monolingual stylistic dataset (Gao et al., 2019b). Experimental results show that our proposed approach improves style intensity and maintains content relevance. Our contributions are listed below:\n• We propose a unified framework to simultaneously improve style intensity and maintain content relevance for neural stylistic response generation.\n• We introduce a scheme of learning latent variables by a diluting strategy to disentangle the style and content.\n• Experimental results show that our approach achieves higher performance in style intensity without decreasing content relevance, compared with previous approaches."
    }, {
      "heading" : "2 Method",
      "text" : ""
    }, {
      "heading" : "2.1 Task Definition",
      "text" : "The task of stylistic response generation is defined as follows: given a monolingual stylistic dataset S = {S1, ...,SN}1 and a conversational dataset C = {(X1,Y1), ..., (XM ,YM )}, where Si, Xi, and Yi denote a stylistic sentence, dialogue history, and a response respectively, the goal is to learn a generation model P (Ŷ |X), where Ŷ is a generated response expected to be in the style of S (called the desired style in the following sections). We will first briefly review the concept of structured latent space and then introduce our disentanglement approach.\n1Throughout the paper, we use bold letters to denote vectors, i.e., V = {V1, V2, ..., VN}."
    }, {
      "heading" : "2.2 Background: Structured Latent Space",
      "text" : "Overview The structured latent space is constructed by two main mechanisms: (i) sharing a decoder between a sequence-to-sequence (S2S) model and an auto-encoder (AE), and (ii) fusion and smoothness objectives. As an example in Figure 2 shows, a response representation ZAE(Yi) is regularized by the two mechanisms to be distributed around its dialogue history representation ZS2S(Xi). The notations ZAE(·) and ZS2S(·) denote the representations computed by AE encoder and S2S encoder, respectively. Such a latent space makes it possible to predict a response Ŷ by sampling nearby the dialogue history representation. Based on that, Gao et al. (2019b) further align stylistic sentence representations into the latent space, which improves the style intensity of generated responses. In summary, the construction of the structred latent space is a process of aligning the three spaces (ZS2S(Xi), ZAE(Yi), and ZAE(Sj)) by two mechanisms (sharing the decoder, and fusion and smoothness objectives).\nFusion Objective cross-aligns sentences of different spaces. Since Xi and Yi are paired, we align them by minimizing their pair-wise dissimilarity:\ndconv = ∑\ni∈batch\ndE(ZS2S(Xi),ZAE(Yi))\nn √ l\n, (1)\nwhere dE denotes the Euclidean distance, n is the batch size, and l is the dimensionality of the latent space. In contrast, the pair-wise dissimilarity can-\nnot be applied to stylistic sentences since they are not paired with conversational data. To this end, the fusion objective instead optimizes the nearest neighbor distance between the two datasets:\ndstyle = 1\n2 dcrossNN ({ZS2S(Xi)}, {ZAE(Sj)})\n+ 1\n2 dcrossNN ({ZAE(Sj)}, {ZS2S(Xi)}), (2)\nwhere dcrossNN ({ai}, {bj}) denotes the batch average distance between ai and its nearest neighbor in the set {bj}. To further encourage the representations spread-out the latent space, a inner-distance loss is introduced:\ndspread-out = min{dinnerNN (ZS2S(Xi)), dinnerNN (ZAE(Yi)),\ndinnerNN (ZAE(Sj))}, (3)\nwhere dinnerNN ({ai}) denotes the batch average distance between ai and its nearest neighbor in the set {ai}. The final fusion objective is defined as:\nLfuse = dconv + dstyle − dspread-out. (4)\nSmoothness Objective aims to make the structured latent space a continuous space, where each point can decode a natural sentence. Given three discrete points ZS2S(Xi), ZAE(Yi), and ZAE(Sj), the objective encourages points in the area between ZS2S(Xi) and ZAE(Yi) to generate Yi:\nZconv = UZS2S(Xi) + (1− U)ZAE(Yi) + , Lsmooth,conv = − logP (Yi|Zconv), (5)\nwhere ∼ N(0, σ2I), and U ∼ U(0, 1). Meanwhile, as a point moves from ZAE(Yi) to ZAE(Sj), the corresponding generation is expected to gradually move from Yi to Sj :\nZstyle = UZAE(Yi) + (1− U)ZAE(Sj) + Lsmooth,style = −U logP (Yi|Zstyle)\n− (1− U) logP (Sj |Zstyle). (6)\nThe smoothness objective Lsmooth is the sum of Lsmooth,conv and Lsmooth,style, and is added to the final loss function along with the fusion objective and response generation loss of S2S."
    }, {
      "heading" : "2.3 Our Method",
      "text" : "Despite aligning monolingual stylistic sentences into the structured latent space helps stylize generated responses, their style intensity is still limited.\nWe conjecture this is due to the coupling of the style and the content in sentence representations. To this end, we propose to disentangle the two aspects in the structured latent space.\nIn our proposed approach, a sentence representation Z ∈ Rl in the latent space consists of two components: content representation Zc ∈ Rlc and style representation Zs ∈ Rls , where l is the dimensionality of latent space and lc + ls = l. Zs encodes all the style information of a sentence. It is a corpus-level feature because Zs for different sentences in the same corpus should be similar. In contrast, Zc can be seen as a sentence-level feature which only decided by the content of its corresponding sentence.\nFigure 3 shows an example of our approach, where Zc and Zs can be seen as two “containers”. Colored squares represent the content and style information. We encourage the disentanglement of the two types of information by diluting sentence-level content information in Zs. As an example in Figure 3 (a) shows, the content and style information may be mixed in both Zc and Zs. During the decoding process of a sentence, i.e., Yi, we replace its style representation ZsAE(Yi) with its batch average style representation Z̄sAE(Yi) = 1 n ∑ j∈batchZ s AE(Yj). In this way, its sentence-level content information will be diluted since it greatly varies from other sentences’ content information, which introduces extra noise. In contrast, its corpus-level style information, which is similar to that of other sentences within the batch, will remain unaffected. As the training processes, the content information will be encouraged to be encoded into Zc where it can remain unchanged, as an example in Figure 3 (b) shows. Otherwise, the content information will be corrupted in Zs, making it hard to recover the content of Yi. As a result, the encoding process will be punished by the response generation loss of S2S and the reconstruction loss of AE, as shown in Figure 3 (a).\nBased on that, we update the response generation process by replacing its style representation Zs with the corresponding batch average style representation Z̄s:\nLS2S = − logP (Yi|[ZcS2S(Xi) : Z̄sS2S(Xi)]), (7)\nwhere the bracket [:] denotes concatenation. The decoding process in the smoothness objective is updated similarly. Note that when we move from\nYi to Sj , and from Xi to Yi, we only interpolate their content representations Zc in the latent space:\nZcconv = UZ c S2S(Xi) + (1− U)ZcAE(Yi) + , Zcstyle = UZ c AE(Yi) + (1− U)ZcAE(Sj) + .\n(8)\nThe batch average style representation Z̄s remains consistent with the target, i.e., being Z̄sAE(Sj) when the target is Sj . The updated smoothness objective is as follows:\nLsmooth,conv = − logP (Yi|[Zcconv : Z̄sAE(Yi)]), Lsmooth,style = −U logP (Yi|[Zcstyle : Z̄sAE(Yi)]) − (1− U) logP (Sj |[Zcstyle : Z̄sAE(Sj)]). (9)\nThe final training loss is the sum of the response generation loss, fusion objective, and smoothness objective:\nL =LS2S + Lfuse + Lsmooth. (10)\nHere, we do not employ pre-training models, i.e., DialoGPT (Zhang et al., 2020b) and OpenAI GPT2 (Radford et al., 2019). This is because the disentanglement is usually conducted on a sentence representation. While most of the pre-training models depend on the attention mechanism, and there is no static global sentence representation during the decoding process."
    }, {
      "heading" : "2.4 Inference",
      "text" : "To generate a stylistic response Ŷi given dialogue history Xi during the inference process, we first\nobtain ZcS2S(Xi) by S2S encoder and subsequently sample Zc(Ŷi) from the hypersphere of ZcS2S(Xi) with a mannually tuned radius r. After that, we generate Ŷi by concatenating Zc(Ŷi) and Z̄sAE(Sj), which is the batch average style representation of randomly sampled stylistic sentences.\nConsidering the discrepancy between training and inference that content and style representations in different corpora have never been concatenated for generation, we propose a soft combination approach to introduce the desired style by interpolating ZsS2S(Xi) and Z̄ s AE(Sj):\nZssoft = Z s S2S(Xi) + α ∗ Z̄sAE(Sj), (11)\nwhere α is the weight of the desired style. After that, Ŷi is generated by the decoder whose hidden state is set to [Zc(Ŷi) : Zssoft].\nTo further balance style intensity and content relevance, we also employ the re-ranking strategy following Gao et al. (2019b). It samples Ny candidate responses and re-ranks them by:\nsr = γ ∗PS2S(Ŷi|Xi)+(1−γ)∗Pstyle(Ŷi), (12)\nwhere PS2S(Ŷi|Xi) is the generation probability under a S2S model measuring the relevance. Pstyle(Ŷi) is the probability that Ŷi has the desired style. It is a interpolation between the probabilities of a neural-based classifier and a n-gram classifier:\nPstyle(Ŷi) =η ∗ Pneural(Ŷi) + (1− η)\n∗ N∑\nn=1\nwn ∗ Pn-gram(Ŷi), (13)\nwhere wn is a weight which is set to the accuracy of the corresponding classifier."
    }, {
      "heading" : "3 Experiments",
      "text" : ""
    }, {
      "heading" : "3.1 Data",
      "text" : "Conversational Dataset We employ DailyDialog2 (Li et al., 2017) as our conversational dataset C. It is a human-written multi-turn dataset covering various topics of daily life. Table 1 shows some statistics of its training, validation, and test set. We split dialogue of K utterances into K-1 samples. Each sample consists of at most three continuous utterances. The last utterance of a sample is regarded as the response. The previous utterances of the response are concatenated as its dialogue history. Here, Reddit dataset is not employed as Gao et al. (2019b) because the post-reply format data collected from social networks is noisy and different from real conversations (Li et al., 2017).\nMonolingual Stylistic Dataset Following Gao et al. (2019b), we use Holmes3 as the stylistic dataset S. It is collected from the Sherlock Holmes novel series and consists of roughly 38k sentences. We do not use the arXiv dataset as it contains too many special tokens, i.e., equations, and incomplete sentences, such as “is concerned” and “exactly identical restrictions”."
    }, {
      "heading" : "3.2 Baselines",
      "text" : "We compare the proposed approach with the following baselines:\n• S2S, the sequence-to-sequence response generation model (Shang et al., 2015).\n• S2S+LM, a S2S trained on C and a stylistic language model trained on S (Niu and Bansal, 2018). During the inference process, it generates a stylistic response by interpolating outputs of the two models.\n2http://yanran.li/dailydialog 3https://github.com/golsun/StyleFusion\n• Style Fusion, a multi-task learning based model whose latent space fuses dialogue history, responses, and stylistic sentences with a specific structure (Gao et al., 2019b).\nNote that we do not consider the Label-FineTuning model and Polite Reinforcement Learning model (Niu and Bansal, 2018), because they require some training samples in the conversational dataset to have the desired style (Gao et al., 2019b)."
    }, {
      "heading" : "3.3 Experiment Settings",
      "text" : "We implement the proposed approach based on the released code of Style Fusion model4. The vocabulary table consists of the most frequent 20,000 words. S2S encoder, AE encoder, and the shared decoder are two-layer LSTMs. The number of their hidden units is 1000, which is also the size of the structured latent space. The dimension of Zc and Zs is 950 and 50, respectively. The maximum length is set to 90 for the dialogue history and 30 for the response.\nDuring the training process, we use the ADAM optimizer, whose learning rate is 0.0003. σ2 for sampling in Equation 8 is 0.12. Table 2 shows the average running time on a single TITAN X (Pascal) GPU. During the inference process, the weights γ and η for re-ranking are set to 0.5. The weight (accuracy) of n-gram classifier is 0.93, 0.87, 0.77, and 0.65 for n from 1 to 4. The number of candidate responses, Ny, is set to 10. The radius r is set to 3."
    }, {
      "heading" : "4 Results",
      "text" : ""
    }, {
      "heading" : "4.1 Evaluation Metrics",
      "text" : "Automatic Evaluation Considering that it is unfair to evaluate a response by the classifiers that are used for selecting the response (Song et al., 2020), we fine-tune a BERT (Devlin et al., 2019) to measure style intensity. Concretely, positive samples are the stylistic sentences. Negative samples are\n4https://github.com/golsun/StyleFusion\nrandomly selected from DailyDialog’s responses, which are of the same amount of sentences as the positive samples. Given the fine-tuned BERT classifier (whose accuracy achieves 0.96 on the validation set), we report the average probability of responses being positive as a measurement of the style intensity. For brevity, we denote this metric as SI. The content relevance is evaluated by BLEU. Since it may correlate weakly with human judgments of quality in a single reference setting (Liu et al., 2016), we employ the expanded responses in multi-reference DailyDialog test set (Gupta et al., 2019) as references to alleviate the problem. Meanwhile, we evaluate the diversity by Dist-k (Li et al., 2016), which is the number of distinct k-grams normalized by the total number of words of responses.\nHuman Evaluation We randomly sample 200 messages from the test set of C to conduct the human evaluation from two aspects: style intensity and content relevance. Each aspect is independently evaluated by five Amazon Mechanical Turk (AMT)5 workers whose approval rate is greater than 95%, and the number of approved is greater than 500. Given dialogue history and two responses generated by a baseline and our approach, the workers are asked to give a preference of which one is\n5https://www.mturk.com\nbetter (ties are also permitted)."
    }, {
      "heading" : "4.2 Results",
      "text" : "Figure 4 shows the trade-off between style intensity and content relevance in our approach. There is an improvement in SI and a decrease in BLEU associated with the increase of α in Equation 11. To assess the overall performance, we also compute their harmonic mean, whose maximum lies around α = 0.5. We thus conduct the human evaluation and analysis in this parameter setting.\nWe report the human evaluation results in Table 4. Our approach is clearly preferred in style intensity because the percentage of Win is significantly higher than that of Lose (p <0.001, T-test). In terms of content relevance, the ratios of Win in “vs. S2S” and “vs. Style Fusion” are similar to those of Lose. This suggests that our approach can significantly improve the style intensity without decreasing the content relevance. In contrast, S2S+LM loses in most of the cases in the content relevance. Following Zhou et al. (2018) and Ke et al. (2018), we evaluate the agreement of annotators via inter-rater consistency. The percentage of samples that at least three annotators have the same preference (3/5 agreement) is 81.80%. And the percentage for 4/5 agreement is 32.15%.\nTable 3 shows the results of the automatic evaluation. Our approach has the highest mean score, which indicates that it achieves the best overall performance. S2S+LM has a high SI score, but its BLEU scores are not as good as others, i.e., S2S.\nThis is in line with our human evaluation results and Niu and Bansal (2018)’s observation that biasing a decoder with a stylistic language model may harm the content relevance. In contrast, our approach (α = 0.25) significantly outperforms S2S and is comparable to Style Fusion. By increasing α to 0.5, the BLEU score drops slightly but is comparable to baselines (evidenced by the human evaluation results). Meanwhile, there is a significant improvement (up to 95.37%) in SI comparing with Style Fusion. This verifies the effectiveness of our disentanglement approach in improving the style intensity and maintaining the content relevance. Besides, the Dist-k results in Table 3 also indicate that the diversity of our approach is comparable to the best-performed Style Fusion."
    }, {
      "heading" : "4.3 Ablation Study",
      "text" : "We conduct ablation studies to investigate the contributions of the fusion objective, smoothness objective, and our disentanglement approach. To focus on their effects on the generation process, in this section, we sample a single response without using the re-ranking strategy (Equation 12).\nTable 5 shows the results of the ablation study. There is a significant decline in SI and a slight change in BLEU-3 and BLEU-4 after removing each component. This indicates that a multi-task learning architecture without the three components\ncan achieve a good content relevance performance but fails to stylize a response. By removing the disentanglement component, our approach degenerates into Style Fusion. In this case, the SI score decreases significantly while BLEU scores are nearly unchanged, which demonstrates the disentanglement could improve the style intensity and maintain the relevance at the same time. The decreases in SI after removing the fusion objective and smoothness objective are more significant than that after removing the disentanglement. This is because the two objectives are bottom components for constructing the structured latent space, where our approach and Style Fusion are built upon."
    }, {
      "heading" : "4.4 Analysis",
      "text" : "In this section, we analyze whether style information is disentangled into Zs. To achieve this goal, we train style classifiers taking as input a latent variable and use the validation accuracy as an indicator. Taking our approach as an instance, we first freeze the parameters of our well-trained model. Then we independently learn two style classifiers whose inputs are the full latent variable ([Zc : Zs]) and Zs respectively. Note that Zc and Zs in Style Fusion are a simple partition of its latent variable. There are not any disentanglement approaches applied to obtain the two representations. As shown in Table 6, Style Fusion achieves 0.83 validation accuracy training on its full latent variable. And the accuracy decreases by 13.02% when the classification is only based on Zs. In contrast, the decrease of our approach is only 1.71%, indicating that most of the style information is disentangled into Zs.\nWe show a visualization of the disentanglement of the latent variable by MDS (Borg and Groenen, 2005) in Figure 5. Each figure consists of Zs (black) and three continuous sub-sequences extracted from the head (yellow), middle (red), and tail (blue) of Zc. The sub-sequences are of the same length with Zs. For both stylistic and conversational samples, all the sub-sequences and Zs are mixed in Style Fusion. In contrast, there is a clear separation between Zs and the sub-sequences\nin our approach. This is because most of the style information is disentangled into Zs in our approach, making its distribution different from sub-sequences of Zc."
    }, {
      "heading" : "4.5 Case Study",
      "text" : "Table 7 shows some examples of generated responses. There is no significant Holmes style in responses of S2S. Similarly, the style intensity of responses in Style Fusion is also limited. The semantics of S2S+LM’s response in the first example is not very clear, making it less relevant to the dialogue history than other responses. We believe this is also due to the lack of interaction between the response generation encoder and the stylistic language model. In contrast, our approach not only achieves a good content relevance performance but also has a significant Holmes style, which is quite polite and formal."
    }, {
      "heading" : "5 Related Work",
      "text" : ""
    }, {
      "heading" : "5.1 Text Style Transfer without Parallel Data",
      "text" : "The task of text style transfer aims at transferring the style of a sentence while preserving its meaning. One way is to disentangle the content and style,\nand subsequently combine the content with the desired style. The disentanglement can be achieved by adversarial learning (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; Logeswaran et al., 2018), reinforcement learning (Jain et al., 2019), back-translation (Prabhumoye et al., 2018; Nogueira dos Santos et al., 2018), multi-task learning (John et al., 2019), and removing stylistic phrases (Li et al., 2018; Xu et al., 2018; Zhang et al., 2018b). The other way transfers the style without disentangled representations, for example using generator-evaluator architecture (Gong et al., 2019), cycle reconstruction (Dai et al., 2019), parameter sharing (Wang et al., 2020), and data augmentation (Zhang et al., 2020a).\nThe main difference between our task and text style transfer lies in two aspects. First, all the content to be generated is available in the input in text style transfer, while our task needs to create new (response) content. And the key is content relevance to the dialogue history, rather than content preservation of the input. Second, the data for text style transfer is isomorphic. Data in different styles are in the same free-text format. However, our conversational data are context-response pairs while the stylistic data are free-texts, which is heterogeneous and requires more sophisticated structures, i.e., the structured latent space (Gao et al., 2019b)."
    }, {
      "heading" : "5.2 Stylistic Response Generation without Parallel Stylistic Data",
      "text" : "Niu and Bansal(2018) propose three weaksupervised models based on reinforcement learning, conditional text generation, and language model. Gao et al. (2019b) fuses the latent spaces of a response generation model and a stylistic autoencoder to improve the style intensity of sampled responses. Yang et al. (2020) inject the style information by introducing a word-level KL loss and a sentence-level style classifier to the fine-turning process of DialoGPT (Zhang et al., 2020b). Distinct from previous work, we explicitly disentangle the style and content in the latent space and employ a unified architecture to jointly optimize the style intensity and content relevance."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We propose a uniform framework to simultaneously improve the style intensity and maintain the content relevance for neural stylistic response generation. In contrast to existing approaches, our approach\ndisentangles the style and the content in the latent space by a diluting strategy. Experiments show that our approach improves the style intensity of generated responses and maintains the content relevance at the same time, which demonstrates the effectiveness of this approach."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The authors would like to thank all the anonymous reviewers for their insightful comments. The authors from HIT are supported by the National Natural Science Foundation of China (No. 62076081, No. 61772153, and No. 61936010) and Science and Technology Innovation 2030 Major Project of China (No. 2020AAA0108605). The author from UCSB is not supported by any of the projects above.\nEthical Statement\nThis paper honors the ACL Code of Ethics. Stylistic response generation intends to improve the engagement of a dialogue system in human-bot conversations. It responds to users with the desired style, i.e., being polite, humorous, or romantic, rather than imitating any specific person. Meanwhile, style is a linguistic aspect of natural language interaction. There is not any identity characteristic being used as a variable."
    } ],
    "references" : [ {
      "title" : "Modern multidimensional scaling: Theory and applications",
      "author" : [ "Ingwer Borg", "Patrick JF Groenen." ],
      "venue" : "Springer Science & Business Media.",
      "citeRegEx" : "Borg and Groenen.,? 2005",
      "shortCiteRegEx" : "Borg and Groenen.",
      "year" : 2005
    }, {
      "title" : "Style transformer: Unpaired text style transfer without disentangled latent representation",
      "author" : [ "Ning Dai", "Jianze Liang", "Xipeng Qiu", "Xuanjing Huang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Dai et al\\.,? 2019",
      "shortCiteRegEx" : "Dai et al\\.",
      "year" : 2019
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Style transfer in text: Exploration and evaluation",
      "author" : [ "Zhenxin Fu", "Xiaoye Tan", "Nanyun Peng", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Thirty-Second AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Fu et al\\.,? 2018",
      "shortCiteRegEx" : "Fu et al\\.",
      "year" : 2018
    }, {
      "title" : "Stylenet: Generating attractive visual captions with styles",
      "author" : [ "Chuang Gan", "Zhe Gan", "Xiaodong He", "Jianfeng Gao", "Li Deng." ],
      "venue" : "Proceedings of CVPR, pages 955–964. IEEE.",
      "citeRegEx" : "Gan et al\\.,? 2017",
      "shortCiteRegEx" : "Gan et al\\.",
      "year" : 2017
    }, {
      "title" : "Jointly optimizing diversity and relevance in neural response generation",
      "author" : [ "Xiang Gao", "Sungjin Lee", "Yizhe Zhang", "Chris Brockett", "Michel Galley", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the",
      "citeRegEx" : "Gao et al\\.,? 2019a",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Structuring latent spaces for stylized response generation",
      "author" : [ "Xiang Gao", "Yizhe Zhang", "Sungjin Lee", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Gao et al\\.,? 2019b",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Reinforcement learning based text style transfer without parallel training corpus",
      "author" : [ "Hongyu Gong", "Suma Bhat", "Lingfei Wu", "JinJun Xiong", "Wen-mei Hwu." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Com-",
      "citeRegEx" : "Gong et al\\.,? 2019",
      "shortCiteRegEx" : "Gong et al\\.",
      "year" : 2019
    }, {
      "title" : "Investigating evaluation of open-domain dialogue systems with human generated multiple references",
      "author" : [ "Prakhar Gupta", "Shikib Mehri", "Tiancheng Zhao", "Amy Pavel", "Maxine Eskenazi", "Jeffrey Bigham." ],
      "venue" : "Proceedings of the 20th Annual SIGdial Meeting",
      "citeRegEx" : "Gupta et al\\.,? 2019",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2019
    }, {
      "title" : "Toward controlled generation of text",
      "author" : [ "Zhiting Hu", "Zichao Yang", "Xiaodan Liang", "Ruslan Salakhutdinov", "Eric P Xing." ],
      "venue" : "Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1587–1596. JMLR. org.",
      "citeRegEx" : "Hu et al\\.,? 2017",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2017
    }, {
      "title" : "Unsupervised controllable text formalization",
      "author" : [ "Parag Jain", "Abhijit Mishra", "Amar Prakash Azad", "Karthik Sankaranarayanan." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6554–6561.",
      "citeRegEx" : "Jain et al\\.,? 2019",
      "shortCiteRegEx" : "Jain et al\\.",
      "year" : 2019
    }, {
      "title" : "Disentangled representation learning for non-parallel text style transfer",
      "author" : [ "Vineet John", "Lili Mou", "Hareesh Bahuleyan", "Olga Vechtomova." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 424–434.",
      "citeRegEx" : "John et al\\.,? 2019",
      "shortCiteRegEx" : "John et al\\.",
      "year" : 2019
    }, {
      "title" : "Stylistic transfer in natural language generation systems using recurrent neural networks",
      "author" : [ "Jad Kabbara", "Jackie Chi Kit Cheung." ],
      "venue" : "Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust",
      "citeRegEx" : "Kabbara and Cheung.,? 2016",
      "shortCiteRegEx" : "Kabbara and Cheung.",
      "year" : 2016
    }, {
      "title" : "Generating informative responses with controlled sentence function",
      "author" : [ "Pei Ke", "Jian Guan", "Minlie Huang", "Xiaoyan Zhu." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1), pages 1499–1508.",
      "citeRegEx" : "Ke et al\\.,? 2018",
      "shortCiteRegEx" : "Ke et al\\.",
      "year" : 2018
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Delete, retrieve, generate: a simple approach to sentiment and style transfer",
      "author" : [ "Juncen Li", "Robin Jia", "He He", "Percy Liang." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics,Volume 1,",
      "citeRegEx" : "Li et al\\.,? 2018",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2018
    }, {
      "title" : "Dailydialog: A manually labelled multi-turn dialogue dataset",
      "author" : [ "Yanran Li", "Hui Su", "Xiaoyu Shen", "Wenjie Li", "Ziqiang Cao", "Shuzi Niu." ],
      "venue" : "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers),",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
      "author" : [ "Chia-Wei Liu", "Ryan Lowe", "Iulian Serban", "Mike Noseworthy", "Laurent Charlin", "Joelle Pineau." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Liu et al\\.,? 2016",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2016
    }, {
      "title" : "Content preserving text generation with attribute controls",
      "author" : [ "Lajanugen Logeswaran", "Honglak Lee", "Samy Bengio." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 5103–5113.",
      "citeRegEx" : "Logeswaran et al\\.,? 2018",
      "shortCiteRegEx" : "Logeswaran et al\\.",
      "year" : 2018
    }, {
      "title" : "Polite dialogue generation without parallel data",
      "author" : [ "Tong Niu", "Mohit Bansal." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 6:373–389.",
      "citeRegEx" : "Niu and Bansal.,? 2018",
      "shortCiteRegEx" : "Niu and Bansal.",
      "year" : 2018
    }, {
      "title" : "Style transfer through back-translation",
      "author" : [ "Shrimai Prabhumoye", "Yulia Tsvetkov", "Ruslan Salakhutdinov", "Alan W Black." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1), pages 866–876.",
      "citeRegEx" : "Prabhumoye et al\\.,? 2018",
      "shortCiteRegEx" : "Prabhumoye et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Fighting offensive language on social media with unsupervised text style transfer",
      "author" : [ "Cicero Nogueira dos Santos", "Igor Melnyk", "Inkit Padhi." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2),",
      "citeRegEx" : "Santos et al\\.,? 2018",
      "shortCiteRegEx" : "Santos et al\\.",
      "year" : 2018
    }, {
      "title" : "Neural responding machine for short-text conversation",
      "author" : [ "Lifeng Shang", "Zhengdong Lu", "Hang Li." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the",
      "citeRegEx" : "Shang et al\\.,? 2015",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2015
    }, {
      "title" : "Style transfer from non-parallel text by cross-alignment",
      "author" : [ "Tianxiao Shen", "Tao Lei", "Regina Barzilay", "Tommi Jaakkola." ],
      "venue" : "Advances in neural information processing systems, pages 6830–6841.",
      "citeRegEx" : "Shen et al\\.,? 2017",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2017
    }, {
      "title" : "Generating persona consistent dialogues by exploiting natural language inference",
      "author" : [ "Haoyu Song", "Wei-Nan Zhang", "Jingwen Hu", "Ting Liu." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, 34(05):8878–8885.",
      "citeRegEx" : "Song et al\\.,? 2020",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2020
    }, {
      "title" : "Formality style transfer with shared latent space",
      "author" : [ "Yunli Wang", "Yu Wu", "Lili Mou", "Zhoujun Li", "Wenhan Chao." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 2236–2249.",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Unpaired sentiment-to-sentiment translation: A cycled reinforcement learning approach",
      "author" : [ "Jingjing Xu", "Xu Sun", "Qi Zeng", "Xiaodong Zhang", "Xuancheng Ren", "Houfeng Wang", "Wenjie Li." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association",
      "citeRegEx" : "Xu et al\\.,? 2018",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2018
    }, {
      "title" : "StyleDGPT: Stylized response generation with pretrained language models",
      "author" : [ "Ze Yang", "Wei Wu", "Can Xu", "Xinnian Liang", "Jiaqi Bai", "Liran Wang", "Wei Wang", "Zhoujun Li." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020,",
      "citeRegEx" : "Yang et al\\.,? 2020",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2020
    }, {
      "title" : "Unsupervised text style transfer using language models as discriminators",
      "author" : [ "Zichao Yang", "Zhiting Hu", "Chris Dyer", "Eric P Xing", "Taylor Berg-Kirkpatrick." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 7287–7298.",
      "citeRegEx" : "Yang et al\\.,? 2018",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2018
    }, {
      "title" : "SHAPED: Shared-private encoder-decoder for text style adaptation",
      "author" : [ "Ye Zhang", "Nan Ding", "Radu Soricut." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Zhang et al\\.,? 2018a",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Parallel data augmentation for formality style transfer",
      "author" : [ "Yi Zhang", "Tao Ge", "Xu Sun." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3221– 3228, Online. Association for Computational Lin-",
      "citeRegEx" : "Zhang et al\\.,? 2020a",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning sentiment memories for sentiment modification without parallel data",
      "author" : [ "Yi Zhang", "Jingjing Xu", "Pengcheng Yang", "Xu Sun." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1103–1108.",
      "citeRegEx" : "Zhang et al\\.,? 2018b",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "DIALOGPT : Largescale generative pre-training for conversational response generation",
      "author" : [ "Liu", "Bill Dolan." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 270–",
      "citeRegEx" : "Liu and Dolan.,? 2020b",
      "shortCiteRegEx" : "Liu and Dolan.",
      "year" : 2020
    }, {
      "title" : "Commonsense knowledge aware conversation generation with graph attention",
      "author" : [ "Hao Zhou", "Tom Young", "Minlie Huang", "Haizhou Zhao", "Jingfang Xu", "Xiaoyan Zhu." ],
      "venue" : "the 27th International Joint Conference on Artificial Intelligence and the",
      "citeRegEx" : "Zhou et al\\.,? 2018",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "In human-bot conversations, it is crucial to generate stylistic responses for increasing user engagement to conversational systems (Gan et al., 2017).",
      "startOffset" : 131,
      "endOffset" : 149
    }, {
      "referenceID" : 30,
      "context" : "Samples in these datasets are usually contributed by a variety of users, resulting in an averaging effect across style characteristics (Zhang et al., 2018a).",
      "startOffset" : 135,
      "endOffset" : 156
    }, {
      "referenceID" : 19,
      "context" : "Recent studies show the effect of stylizing responses using a monolingual dataset in the desired style and a conventional conversational dataset (Niu and Bansal, 2018; Gao et al., 2019b).",
      "startOffset" : 145,
      "endOffset" : 186
    }, {
      "referenceID" : 6,
      "context" : "Recent studies show the effect of stylizing responses using a monolingual dataset in the desired style and a conventional conversational dataset (Niu and Bansal, 2018; Gao et al., 2019b).",
      "startOffset" : 145,
      "endOffset" : 186
    }, {
      "referenceID" : 19,
      "context" : "Figure 1: An example of responses generated by S2S, S2S+LM (Niu and Bansal, 2018), Style Fusion (Gao et al.",
      "startOffset" : 59,
      "endOffset" : 81
    }, {
      "referenceID" : 6,
      "context" : "Figure 1: An example of responses generated by S2S, S2S+LM (Niu and Bansal, 2018), Style Fusion (Gao et al., 2019b), and our approach, targeting the Holmes style, which is quite formal and polite.",
      "startOffset" : 96,
      "endOffset" : 115
    }, {
      "referenceID" : 16,
      "context" : "We conduct experiments on DailyDialogue conversational dataset (Li et al., 2017) and Holmes monolingual stylistic dataset (Gao et al.",
      "startOffset" : 63,
      "endOffset" : 80
    }, {
      "referenceID" : 6,
      "context" : ", 2017) and Holmes monolingual stylistic dataset (Gao et al., 2019b).",
      "startOffset" : 49,
      "endOffset" : 68
    }, {
      "referenceID" : 16,
      "context" : "Conversational Dataset We employ DailyDialog2 (Li et al., 2017) as our conversational dataset C.",
      "startOffset" : 46,
      "endOffset" : 63
    }, {
      "referenceID" : 16,
      "context" : "(2019b) because the post-reply format data collected from social networks is noisy and different from real conversations (Li et al., 2017).",
      "startOffset" : 121,
      "endOffset" : 138
    }, {
      "referenceID" : 23,
      "context" : "• S2S, the sequence-to-sequence response generation model (Shang et al., 2015).",
      "startOffset" : 58,
      "endOffset" : 78
    }, {
      "referenceID" : 19,
      "context" : "• S2S+LM, a S2S trained on C and a stylistic language model trained on S (Niu and Bansal, 2018).",
      "startOffset" : 73,
      "endOffset" : 95
    }, {
      "referenceID" : 6,
      "context" : "• Style Fusion, a multi-task learning based model whose latent space fuses dialogue history, responses, and stylistic sentences with a specific structure (Gao et al., 2019b).",
      "startOffset" : 154,
      "endOffset" : 173
    }, {
      "referenceID" : 19,
      "context" : "Note that we do not consider the Label-FineTuning model and Polite Reinforcement Learning model (Niu and Bansal, 2018), because they require some training samples in the conversational dataset to have the desired style (Gao et al.",
      "startOffset" : 96,
      "endOffset" : 118
    }, {
      "referenceID" : 6,
      "context" : "Note that we do not consider the Label-FineTuning model and Polite Reinforcement Learning model (Niu and Bansal, 2018), because they require some training samples in the conversational dataset to have the desired style (Gao et al., 2019b).",
      "startOffset" : 219,
      "endOffset" : 238
    }, {
      "referenceID" : 25,
      "context" : "Automatic Evaluation Considering that it is unfair to evaluate a response by the classifiers that are used for selecting the response (Song et al., 2020), we fine-tune a BERT (Devlin et al.",
      "startOffset" : 134,
      "endOffset" : 153
    }, {
      "referenceID" : 2,
      "context" : ", 2020), we fine-tune a BERT (Devlin et al., 2019) to measure style intensity.",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 8,
      "context" : ", 2016), we employ the expanded responses in multi-reference DailyDialog test set (Gupta et al., 2019) as references to alleviate the problem.",
      "startOffset" : 82,
      "endOffset" : 102
    }, {
      "referenceID" : 14,
      "context" : "Meanwhile, we evaluate the diversity by Dist-k (Li et al., 2016), which is the number of distinct k-grams normalized by the total number of words of responses.",
      "startOffset" : 47,
      "endOffset" : 64
    }, {
      "referenceID" : 0,
      "context" : "We show a visualization of the disentanglement of the latent variable by MDS (Borg and Groenen, 2005) in Figure 5.",
      "startOffset" : 77,
      "endOffset" : 101
    }, {
      "referenceID" : 24,
      "context" : "The disentanglement can be achieved by adversarial learning (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; Logeswaran et al., 2018), reinforcement learning (Jain et al.",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 9,
      "context" : "The disentanglement can be achieved by adversarial learning (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; Logeswaran et al., 2018), reinforcement learning (Jain et al.",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 3,
      "context" : "The disentanglement can be achieved by adversarial learning (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; Logeswaran et al., 2018), reinforcement learning (Jain et al.",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 29,
      "context" : "The disentanglement can be achieved by adversarial learning (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; Logeswaran et al., 2018), reinforcement learning (Jain et al.",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 18,
      "context" : "The disentanglement can be achieved by adversarial learning (Shen et al., 2017; Hu et al., 2017; Fu et al., 2018; Yang et al., 2018; Logeswaran et al., 2018), reinforcement learning (Jain et al.",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 10,
      "context" : ", 2018), reinforcement learning (Jain et al., 2019), back-translation (Prabhumoye et al.",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 20,
      "context" : ", 2019), back-translation (Prabhumoye et al., 2018; Nogueira dos Santos et al., 2018), multi-task learning (John et al.",
      "startOffset" : 26,
      "endOffset" : 85
    }, {
      "referenceID" : 11,
      "context" : ", 2018), multi-task learning (John et al., 2019), and removing stylistic phrases (Li et al.",
      "startOffset" : 29,
      "endOffset" : 48
    }, {
      "referenceID" : 15,
      "context" : ", 2019), and removing stylistic phrases (Li et al., 2018; Xu et al., 2018; Zhang et al., 2018b).",
      "startOffset" : 40,
      "endOffset" : 95
    }, {
      "referenceID" : 27,
      "context" : ", 2019), and removing stylistic phrases (Li et al., 2018; Xu et al., 2018; Zhang et al., 2018b).",
      "startOffset" : 40,
      "endOffset" : 95
    }, {
      "referenceID" : 32,
      "context" : ", 2019), and removing stylistic phrases (Li et al., 2018; Xu et al., 2018; Zhang et al., 2018b).",
      "startOffset" : 40,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : "The other way transfers the style without disentangled representations, for example using generator-evaluator architecture (Gong et al., 2019), cycle reconstruction (Dai et al.",
      "startOffset" : 123,
      "endOffset" : 142
    }, {
      "referenceID" : 1,
      "context" : ", 2019), cycle reconstruction (Dai et al., 2019), parameter sharing (Wang et al.",
      "startOffset" : 30,
      "endOffset" : 48
    }, {
      "referenceID" : 26,
      "context" : ", 2019), parameter sharing (Wang et al., 2020), and data augmentation (Zhang et al.",
      "startOffset" : 27,
      "endOffset" : 46
    } ],
    "year" : 2021,
    "abstractText" : "Generating open-domain conversational responses in the desired style usually suffers from the lack of parallel data in the style. Meanwhile, using monolingual stylistic data to increase style intensity often leads to the expense of decreasing content relevance. In this paper, we propose to disentangle the content and style in latent space by diluting sentence-level information in style representations. Combining the desired style representation and a response content representation will then obtain a stylistic response. Our approach achieves a higher BERT-based style intensity score and comparable BLEU scores, compared with baselines. Human evaluation results show that our approach significantly improves style intensity and maintains content relevance.",
    "creator" : "LaTeX with hyperref"
  }
}