{
  "name" : "2021.acl-long.505.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Measuring and Increasing Context Usage in Context-Aware Machine Translation",
    "authors" : [ "Patrick Fernandes", "Kayo Yin", "Graham Neubig", "André F. T. Martins" ],
    "emails" : [ "gneubig}@cs.cmu.edu", "andre.t.martins@tecnico.ulisboa.pt" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 6467–6478\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n6467"
    }, {
      "heading" : "1 Introduction",
      "text" : "While neural machine translation (NMT) is reported to have achieved human parity in some domains and language pairs (Hassan et al., 2018), these claims seem overly optimistic and no longer hold with document-level evaluation (Toral et al., 2018; Läubli et al., 2018). Recent work on contextaware NMT attempts to alleviate this discrepancy by incorporating the surrounding context sentences (in either or both the source and target sides) in the translation system. This can be done by, for example, feeding context sentences to standard NMT\n1https://github.com/neulab/contextual-mt\nmodels (Tiedemann and Scherrer, 2017), using different encoders for context (Zhang et al., 2018), having cache-based memories (Tu et al., 2018a), or using models with hierarchical attention mechanisms (Miculicich et al., 2018; Maruf et al., 2019a) — more details in §2. While such works report gains in translation quality compared to sentence-level baselines trained on small datasets, recent work has shown that, in more realistic high-resourced scenarios, these systems fail to outperform simpler baselines with respect to overall translation accuracy, pronoun translation, or lexical cohesion (Lopes et al., 2020).\nWe hypothesize that one major reason for these lacklustre results is due to the fact that models with the architectural capacity to model cross-sentential context do not necessarily learn to do so when trained with existing training paradigms. However, even quantifying model usage of context is an ongoing challenge; while contrastive evaluation has been proposed to measure performance on inter-sentential discourse phenomena (Müller et al., 2018; Bawden et al., 2018), this approach is confined to a narrow set of phenomena, such as pronoun translation and lexical cohesion. A toolbox to measure the impact of context in broader settings is still missing.\nTo address the limitations above, we take inspiration from the recent work of Bugliarello et al. (2020) and propose a new metric, conditional cross-mutual information (CXMI, §3), to measure quantitatively how much context-aware models actually use the provided context by comparing the model distributions over a dataset with and without context. Figure 1 illustrates how it measures context usage. This metric applies to any probabilistic context-aware machine translation model, not only the ones used in this paper. We release a software package to encourage the use of this metric in future context-aware machine translation research. We then perform a rigorous empirical analysis of the CXMI between the context and target for different context sizes, and between source and target context. We find that: (1) context-aware models use some information from the context, but the amount of information used does not increase uniformly with the context size, and can even lead to a reduction in context usage; (2) target context seems to be used more by models than source context.\nGiven the findings, we next consider how to encourage models to use more context. Specifically, we introduce a simple but effective variation of word dropout (Sennrich et al., 2016a) for context-aware machine translation, dubbed COWORD dropout (§4). Put simply, we randomly drop words from the current source sentence by replacing them with a placeholder token. Intuitively, this encourages the model to use extra-sentential information to compensate for the missing information in the current source sentence. We show that models trained with COWORD dropout not only increase context usage compared to models trained\nwithout it but also improve the quality of translation, both according to standard evaluation metrics (BLEU and COMET) and according to contrastive evaluation based on inter-sentential discourse phenomena such as anaphoric pronoun resolution and lexical cohesion (§4.2, Table 1)."
    }, {
      "heading" : "2 Context-Aware Neural Machine Translation",
      "text" : "We are interested in learning a system that translates documents consisting of multiple sentences between two languages.2 More formally, given a corpus of parallel documents in two languages, D = {D1, ..., DN}, where each document is a sequence of source and target sentences, D = {(x(1), y(1)), ..., (x(K), y(K))}, we are interested in learning the mapping between the two languages.\nWe consider the typical (auto-regressive) neural machine translation system qθ parameterized by θ. The probability of translating x(i) into y(i) given the context of the sentence C(i) is\nqθ(y (i)|x(i), C(i)) = T∏ t=1 qθ(y (i) t |x(i), y (i) <t, C (i))\nwhere y(i)t represents the t th token of sentence y(i). This context can take various forms. On one end, we have the case where no context is passed, C(i) = ∅, and the problem is reduced to sentence-level translation. On the other end, we have the case where all the source sentences and all the previous generated target sentences are passed as context C(i) = {x(1), ..., x(K), y(1), ..., y(i−1)}.\nAs mentioned, there are many architectural approaches to leveraging context (see §5 for a more complete review), and the methods that we present in this paper are compatible with most architectures because they do not specify how the model qθ uses the context. In experiments, we focus mostly on the simpler approach of concatenating the context to the current sentences (Tiedemann and Scherrer, 2017). Recent work by Lopes et al. (2020) has shown that, given enough data (either through pretraining or larger contextual datasets), this simple approach tends to be competitive with or even outperform its more complex counterparts\n2Here, a “document” could be an actual document but it could also represent other contextual collections of text, such as a sequence of dialogue utterances."
    }, {
      "heading" : "3 Measuring Context Usage",
      "text" : ""
    }, {
      "heading" : "3.1 Conditional Cross-Mutual Information",
      "text" : "While context-aware models allow use of context, they do not ensure contextual information is actually used: models could just be relying on the current source sentence and/or previously generated target words from the same sentence when generating the output.\nContrastive evaluation, where models are assessed based on the ability to distinguish correct translations from contrastive ones, is a common way to assess the ability of context-aware models to capture specific discourse phenomena that require inter-sentential context, such as anaphora resolution (Müller et al., 2018) and lexical cohesion (Bawden et al., 2018). However, these methods only provide an indirect measure of context usage with respect to a limited number of phenomena and can fail to capture other, unknown ways in which the model might be using context. Kim et al. (2019) showed that most improvements to translation quality are due to non-interpretable usages of context, such as the introduction of noise that acts as a regularizer to the encoder/decoder. This problem is further exacerbated by the fact that there is no clear definition of what entails “context usage”.\nIn a different context, Bugliarello et al. (2020) introduced cross-mutual information (XMI), to measure the “difficulty” of translating between different language pairs in sentence-level neural machine translation. Given a language model qLM for a target sentence Y and a translation model qMT for translating from X to Y , XMI is defined as:\nXMI(X → Y ) = HqLM (Y )− HqMT (Y |X),\nwhere HqLM denotes the cross-entropy of the target sentence Y under the language model qLM and HqMT the conditional cross-entropy of Y given X under the translation model qMT . This allows us to measure how much information the source sentence gives us about the target sentence (an analogue of mutual information for cross-entropy). In the case where qLM and qMT perfectly model the underlying probabilities we would have XMI(X → Y ) = MI(X,Y ), the true mutual information.\nTaking inspiration from the above, we propose Conditional Cross-Mutual Information (CXMI), a new measure of the influence of context on a model’s predictions. This is done by considering an additional variable for the context C and\nmeasuring how much information the context C provides about the target Y given the source X . This can then be formulated as\nCXMI(C → Y |X) = HqMTA (Y |X)− HqMTC (Y |X,C)\nwhere HqMTA is the entropy of a context-agnostic machine translation model, and HqMTC refers to a context-aware machine translation model. This quantity can be estimated (see Appendix A for a more formal derivation) over an held-out test set with N sentence pairs and the respective context as:\nCXMI(C → Y |X) ≈\n− 1 N N∑ i=1 log qMTA(y (i)|x(i)) qMTC (y (i)|x(i), C(i))\nWhile qMTA and qMTC can, in theory, be any models, we are interested in removing any confounding factors other than the context that might lead to instability in the estimates of the distributions. For example, if qMTA and qMTC use completely different models, it would not be clear if the difference in the probability estimates is due to the introduction of context or due to other extraneous factors such as differences in architectures, training regimens, or random seeds. To address this we consider a single model, qMT , that is able to translate with and without context (more on how this achieved in §3.2). We can then set the context-agnostic model and the contextual model to be the same model qMTA = qMTC = qMT . This way we attribute the information gain to the introduction of context. Throughout the rest of this work, when we reference “context usage” we will precisely mean this information gain (or loss)."
    }, {
      "heading" : "3.2 Experiments",
      "text" : "Data We experiment with a document-level translation task by training models on the IWSLT2017 (Cettolo et al., 2012) dataset for language pairs EN → DE and EN → FR (with approximately 200K sentences for both pairs). We use the test sets 2011-2014 as validation sets and the 2015 as test sets. To address the concerns pointed out by Lopes et al. (2020) that gains in performance are due to the use of small training corpora and weak baselines, we use Paracrawl (Esplà et al., 2019) and perform some data cleaning based on language identification tools, creating a pretraining dataset of around\n82M and 104M sentence pairs for EN→ DE and EN→ FR respectively.\nAll data is encoded/vectorized with byte-pair encoding (Sennrich et al., 2016b) using the SentencePiece framework (Kudo and Richardson, 2018). For the non-pretrained case, we use 20K vocabulary size shared across source/target, while for the pretrained case we use a 32K vocabulary size.\nBesides translation quality, we also evaluate our models on two contrastive datasets for different discourse phenomena to better assess the ability of our models to capture context (more on this in §4.2):\n• For the EN → DE language pair, we evaluate on the ContraPro dataset (Müller et al., 2018), targeting anaphoric pronoun resolution. Source-side sentences contain the English anaphoric pronoun it while target-side sentences contain the corresponding German translations er, sie or es. Contrastive erroneous translations are automatically created by replacing the correct pronoun with one of the other two. The test set contains 4,000 examples for each target pronoun type and context is needed to correctly disambiguate. Context includes the four previous sentences\n• For the EN→ FR language pair, we evaluate on the dataset by Bawden et al. (2018) targeting anaphoric pronoun resolution and lexical cohesion. It contains 200 manually curated examples for each phenomenon. Anaphora examples include singular and plural personal and possessive pronouns that require context to be correctly inferred and the dataset is balanced such that a model that does not use context can only achieve 50% accuracy. Context includes the previous sentence\nModels and Optimization For all our experiments, we consider an encoder-decoder Transformer architecture (Vaswani et al., 2017). In particular, we train the transformer small (hidden size of 512, feedforward size of 1024, 6 layers, 8 attention heads). For the pretrained setup, we also pre-train a transformer large architecture (hidden size of 1024, feedforward size of 4096, 6 layers, 16 attention heads) and subsequently fine-tune on the IWSL2017 datasets.\nAs in Vaswani et al. (2017), we train using the Adam optimizer with β1 = 0.9 and β2 = 0.98 and use an inverse square root learning rate scheduler,\nwith an initial value of 10−4 and 5 × 10−4 for pretrained and non-pretrained cases respectively, and with a linear warm-up in the first 4000 steps. We train the models with early stopping on the validation perplexity.\nWe train all our models on top of the Fairseq framework (Ott et al., 2019).\nWhat Context Matters? To assess the relative importance of different context sizes on both the source and target side, we start by considering two models, one for the source-side context and one for the target-side context, that receive context of size k, C(i) = {x(i−k), . . . , x(i−1)} or C(i) = {y(i−k), . . . , y(i−1)}. During training, k is selected randomly to be in {1, . . . , 4} for every example. This way the model is trained to translate the same source without and with different context sizes and is thus able to translate based on any context size in that interval.\nFigure 2 shows the CXMI values computed over the test set as a function of the context size for both the source-side and target-side contextual models for both the non-pretrained and pretrained regimens for the EN → DE language pair. Results for the EN → FR language pair are similar and can be found in Appendix B.\nFor the non-pretrained case, for both the source and target context, the biggest jump in context usage is when we increase the context size from 0 to 1. After that, increasing the context size leads to diminishing increases in context usage and even reduced context usage for the source-side context. Interestingly, when the model is stronger, such as in the pretrained case, we can see that it can leverage target-side context even better than the nonpretrained case, with a similar trend of diminishing increases in context usage for both regimes. However, this is not the case for the source-side context, and it seems that the pretrained model is barely able to use the contextual information on this side.\nOverall, for this regime, we can conclude that having a context size of one or two previous sentences on both sides is beneficial to the model, and that target-side context is slightly more used than source-side context. This appears to corroborate the findings of Bawden et al. (2018) that target-side context is more effective than the source context.\nDoes CXMI Really Measure Context Usage? To assert that CXMI correlates with interpretable measures of context usage, we perform a correlation analysis with the performance in the contrastive datasets mentioned. In these datasets, usage of context is evident where the model picks the right answer when it is passed the context and is not able to do so when no context is given. Thus Table 2 shows the point-biserial correlation coefficient3 between the per-sample CXMI and binary random variable and a binary variable that takes the value 1 if the contextual model picks the correct translation and the non-contextual model picks the incorrect one, for different context sizes on the pretrained model. We can see that there is a statistically significant correlation between both values, which strengthens the notion that CXMI captures previous measures of context usage to some extent.\n3The Point-Biserial correlation coefficient is a special case of the Pearson correlation coefficient when one of the random variables is dichotomous."
    }, {
      "heading" : "4 Increasing Context Usage",
      "text" : ""
    }, {
      "heading" : "4.1 Context-aware Word Dropout",
      "text" : "Motivated by the above results demonstrating the limited context usage of models trained using the standard MLE training paradigm, particularly with respect to more distant context, we now ask the question: “Is it possible to modify the training methodology to increase context usage by the model?” As an answer, we extend a popular regularization technique used in sentence-level machine translation, word dropout (Sennrich et al., 2016a), to the context-aware setting. The idea behind context-aware word (COWORD) dropout is to model the translation probability between x(i) and y(i) as\npθ(y (i)|x(i)) = T∏ t=1 pθ(y (i) t |x̃(i), y (i) <t, C (i)),\nwhere x̃(i) is a perturbed version of the current source sentence generated by randomly dropping tokens and replacing them with a mask token given a dropout probability p:\nr (i) t ∼ Bernoulli(p)\nx̃ (i) t = { 〈MASK〉 if r(i)t = 1 x (i) t otherwise.\nIn the case where no context is passed C(i) = ∅, COWORD dropout reduces to word dropout. The intuition behind such a perturbation is that, by dropping information from the current source and not the context, we increase the relative reliability of context C(i), therefore providing the inductive bias\nthat context is important for the translation. We will see in §4.2 that this inductive bias is beneficial and that COWORD dropout not only improves performance but also increases context usage."
    }, {
      "heading" : "4.2 Experiments",
      "text" : "Setup As in §3.2, we consider transformer models trained on the IWSLT2017 for both EN→ DE and EN → FR, both from scratch and pretrained using the procedure previously described. In particular, due to findings in the previous section, we consider models with either only target-side context or both source-side and target-side context.\nContext Usage To assess if our proposed regularization technique, COWORD dropout, increases context usage by models, we train a model using the same dynamic context size setting used in §3.2.\nFigure 3 plots the CXMI values on the test set as a function of the target context size as we increase the dropout value p. We see that increasing this value consistently increases context usage according to CXMI across different context sizes. Note that, at test time, COWORD dropout is disabled, which means that it provides inductive bias only during training and models learn to use more context by themselves.\nTable 3 illustrates some examples where the COWORD dropout increased the per-sample CXMI significantly. While the model only has access to target context, we present the source context for clarity. In the first example, while the source is a complete sentence, the target is only a fragment of one so the context helps complete it. In the other two examples shown, we can see that context helps disambiguate the gender of the German\ntranslation of the English pronoun it. Interestingly, the words that use context the most according to CXMI match very closely to the ones that native speakers annotated.\nTranslation Quality To evaluate if the increased usage of context correlates with better machine translation quality, based on the previous experiments on context usage and values for COWORD dropout, we consider three models trained with fixed-size context:\n• A baseline that has no context, reducing to sentence-level model ie: i.e., C(i) = ∅;\n• a one-to-two model having as context the previous target sentence, i.e., C(i) = {y(i−1)};\n• a two-to-two model having as context the previous source sentence and the previous target sentence, i.e., C(i) = {x(i−1), y(i−1)}.\nIn addition, to explore the benefits of COWORD dropout in other architectures, we also train a one-to-two multi-encoder (Jean et al., 2017) transformer small model (more details in Appendix §C). For all models with target context, when decoding, we use the previous decoded sentences as target context.\nTable 4 shows the performance across three different seeds of the baseline and contextual models for both the non-pretrained and pretrained setting, with increasing values of COWORD dropout p. We also run the baseline with COWORD dropout (which, as said previously, reduces to word dropout) to ensure that improvements were not only due to regularization effects on the current source/target. We report the standard BLEU score (Papineni et al., 2002) calculated using sacreBLEU (Post, 2018) and COMET, a more accurate evaluation method using multilingual embeddings (Rei et al., 2020).\nFor the non-pretrained case, we can see that a COWORD dropout value p > 0 consistently improves the performance of the contextual models when compared to models running with p = 0 and with the sentence-level baseline with the same values for word dropout. For the pretrained case, the improvements are not as noticeable, although models trained with COWORD dropout still always outperform models trained without it. This is perhaps a reflection of the general trend that better models are harder to improve.\nTable 5 shows that COWORD dropout is also helpful for the multi-encoder model, with COWORD dropout helping significantly. This shows that this method could be helpful for contextaware architectures other than concatenationbased.\nDiscourse Phenomena While automatic metrics such as BLEU and COMET allow us to measure translation quality, they mostly target sentencelevel quality and do not specifically focus on phenomena that require context-awareness. Contrastive datasets, as described in §3.2, allow us to measure the performance of context-aware models in specific discourse phenomena by comparing the probability of correct translation against the contrastive translations. Models that capture the targeted discourse phenomena well will consistently rank the correct translation higher than the contrastive ones. While there is a disconnect between the translation (done via decoding) and contrastive evaluation, it is currently the best way to measure a model’s performance on context-aware discourse phenomena.\nTable 6 shows the average performance over the contrastive datasets of the baseline and contextual models for both the (non-)pretrained settings, with increasing values of COWORD dropout p. We can see that in general, increasing COWORD dropout leads to improved performance, particularly for the non-pretrained case. This gain is particularly clear for pronoun resolution and the EN → DE language pair. We hypothesise that this is due to the small size of the contrastive sets for the EN→ FR language pair, which leads to high variance.\nTable 7 similarly shows that COWORD dropout improves the performance of the multi-encoder model across all phenomena, which again shows that our proposed regularization method has benefits for multiple architectures for context-aware machine translation. Curiously, when these models are trained without COWORD dropout, they achieve performance similar to the sentence-level baseline, while when dropout is applied, they are able to effectively start using context."
    }, {
      "heading" : "5 Related Work",
      "text" : "Context-aware Machine Translation There have been many works in the literature that try to incorporate context into NMT systems. Tiedemann and Scherrer (2017) first proposed the simple approach of concatenating the previous sentences in both the source and target side to the input to the system; Jean et al. (2017), Bawden et al. (2018), and Zhang et al. (2018) used an additional contextspecific encoder to extract contextual features from the previous sentences; Maruf and Haffari (2018) and Tu et al. (2018b) used cache-based memories to encode context; Wang et al. (2017) used a hierarchical RNN to encode the global context from all previous sentences; Miculicich et al. (2018) and Maruf et al. (2019a) used hierarchical attention networks to encode context; Chen et al. (2020) added document-level discourse structure information to the input; Sun et al. (2020) trained a simple concatenation-based model with varying context size during training to have a model that is able to translate with any context size, similar to what is done in this work. Similarly to what we do with COWORD dropout, Jean and Cho (2019) attempted to maximise sensitivity to context by introducing a margin-based regularization term to explicitly encourage context usage.\nFor a more detailed overview, Maruf et al. (2019b) extensively describe the different approaches and how they leverage context. While these models lead to improvements with small training sets, Lopes et al. (2020) showed that the improvements are negligible when compared with the concatenation baseline when using larger datasets.\nHowever, importantly, both our metric CXMI for measuring context usage and the proposed regularization method of COWORD dropout, can theoretically be applied to any of the above-mentioned methods.\nEvaluation In terms of evaluation, most previous work focuses on targeting a system’s performance on contrastive datasets for specific inter-sentential discourse phenomena. Müller et al. (2018) built a large-scale dataset for anaphoric pronoun resolution, Bawden et al. (2018) manually created a dataset for both pronoun resolution and lexical choice and Voita et al. (2019) created a dataset that targets deixis, ellipsis and lexical cohesion. Stojanovski et al. (2020) showed through adversarial attacks that models that do well on other contrastive datasets rely on surface heuristics and create a contrastive dataset to address this. In contrast, our CXMI metric is phenomenon-agnostic and can be measured with respect to all phenomena that require context in translation.\nInformation-Theoretic Analysis Bugliarello et al. (2020) first proposed cross-mutual information (XMI) in the context of measuring the difficulty of translating between languages. Our work differs in that we propose a conditional version of XMI, where S is always observed, and we use it to assess the information gain of context rather than the difficulty of translating different languages."
    }, {
      "heading" : "6 Implications and Future Work",
      "text" : "We introduce a new, architecture-agnostic, metric to measure how context-aware machine translation models are using context and propose a simple regularization technique to increase context usage by these models. Our results are theoretically applicable to almost all recently proposed context-aware models and future work should go about measuring exactly how much these models leverage context and if COWORD dropout also improves context usage and performance in these.\nWe also hope this work motivates exploring (C)XMI for other uses cases where measuring the relevance/usage of inputs to a particular model other than context-aware machine translation. It could, for example, be used in conditional language modelling to analyse how the inputs we are conditioning on are being used by the model."
    }, {
      "heading" : "7 Acknowledgements",
      "text" : "We would like to thank all the members of DeepSPIN, NeuLab, and Unbabel who provided feedback on earlier versions of this work. This work was supported by the European Research Council (ERC StG DeepSPIN 758969), by the P2020 programs MAIA and Unbabel4EU (LISBOA-01-0247FEDER-045909 and LISBOA-01-0247-FEDER042671), and by the Fundação para a Ciência e Tecnologia through contracts SFRH/BD/150706/2020 and UIDB/50008/2020."
    }, {
      "heading" : "A Estimating CXMI",
      "text" : "Let S denote a random variable over source sentences, T a random variable over target sentences and C a random variable over possible context. We assume these random variables are distributed according to some true, unknown distribution p(s, t, c). The cross-entropy between the true distribution p and a probabilistic context-aware neural translation model qMTC (t|s, c) is defined as\nHqMT (T |S,C) = − ∑\ns∈V ∗S ∑ t∈V ∗T ∑ c∈V ∗C p(s, t, c) log qMT (s, t, c)\nwhere V ∗S , V ∗ T , V ∗ C represent the space of possible source sentences, target sentences and contexts respectively. Since we do not know the true distribution p, we cannot compute this quantity exactly. However, given a dataset of samples {(s(i), t(i), c(i))}Ni=0 assumed to be drawn from p, we can estimate this quantity using the Monte Carlo estimator\nHqMTC (T |S,C) ≈\n− 1 N N∑ i=0 log qMTC (s (i), t(i), c(i))\nIf we consider the marginal p(s, t) =∑ c∈V ∗C\np(s, t, c), we can by a similar argument obtain an estimate for the cross-entropy for a contextagnostic neural translation model qMTA as:\nHqMTA (T |S) ≈ − 1\nN N∑ i=0 log qMTA(s (i), t(i))\nThis leads trivially to the estimator for the crossmutual information:\nCXMI(C → Y |X) ≈\n− 1 N N∑ i=1 log qMTA(y (i)|x(i)) qMTC (y (i)|x(i), C(i))"
    }, {
      "heading" : "B CXMI for EN→ FR",
      "text" : ""
    }, {
      "heading" : "C Multi-Encoder",
      "text" : "For the multi-encoder model, we take the approach of initializing a separate transformer encoder for the context, with shared input-output embeddings with the original encoder (or decoder in the case of target context). The tokens in the current sentence attend to the context by the means of crossattention. There are several other ways of formulation a multi-encoder context-aware systems, and exploring them is left for future research."
    } ],
    "references" : [ {
      "title" : "Evaluating discourse phenomena in neural machine translation",
      "author" : [ "Rachel Bawden", "Rico Sennrich", "Alexandra Birch", "Barry Haddow." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics:",
      "citeRegEx" : "Bawden et al\\.,? 2018",
      "shortCiteRegEx" : "Bawden et al\\.",
      "year" : 2018
    }, {
      "title" : "It’s easier to translate out of English than into it: Measuring neural translation difficulty by cross-mutual information",
      "author" : [ "Emanuele Bugliarello", "Sabrina J. Mielke", "Antonios Anastasopoulos", "Ryan Cotterell", "Naoaki Okazaki." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Bugliarello et al\\.,? 2020",
      "shortCiteRegEx" : "Bugliarello et al\\.",
      "year" : 2020
    }, {
      "title" : "WIT3: Web inventory of transcribed and translated talks",
      "author" : [ "Mauro Cettolo", "Christian Girardi", "Marcello Federico." ],
      "venue" : "Proceedings of the 16th Annual conference of the European Association for Machine Translation, pages 261–268, Trento, Italy. Eu-",
      "citeRegEx" : "Cettolo et al\\.,? 2012",
      "shortCiteRegEx" : "Cettolo et al\\.",
      "year" : 2012
    }, {
      "title" : "Modeling discourse structure for document-level neural machine translation",
      "author" : [ "Junxuan Chen", "Xiang Li", "Jiarui Zhang", "Chulun Zhou", "Jianwei Cui", "Bin Wang", "Jinsong Su." ],
      "venue" : "Proceedings of the First Workshop on Automatic Simultaneous Translation,",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "ParaCrawl: Web-scale parallel corpora for the languages of the EU",
      "author" : [ "Miquel Esplà", "Mikel Forcada", "Gema Ramı́rez-Sánchez", "Hieu Hoang" ],
      "venue" : "In Proceedings of Machine Translation Summit XVII Volume 2: Translator, Project and User Tracks,",
      "citeRegEx" : "Esplà et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Esplà et al\\.",
      "year" : 2019
    }, {
      "title" : "Achieving human parity on automatic chinese to english news translation",
      "author" : [ "Xia", "Dongdong Zhang", "Zhirui Zhang", "Ming Zhou." ],
      "venue" : "CoRR, abs/1803.05567.",
      "citeRegEx" : "Xia et al\\.,? 2018",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2018
    }, {
      "title" : "Contextaware learning for neural machine translation",
      "author" : [ "Sébastien Jean", "Kyunghyun Cho." ],
      "venue" : "CoRR, abs/1903.04715.",
      "citeRegEx" : "Jean and Cho.,? 2019",
      "shortCiteRegEx" : "Jean and Cho.",
      "year" : 2019
    }, {
      "title" : "Does neural machine translation benefit from larger context",
      "author" : [ "Sebastien Jean", "Stanislas Lauly", "Orhan Firat", "Kyunghyun Cho" ],
      "venue" : null,
      "citeRegEx" : "Jean et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Jean et al\\.",
      "year" : 2017
    }, {
      "title" : "When and why is document-level context useful in neural machine translation",
      "author" : [ "Yunsu Kim", "Duc Thanh Tran", "Hermann Ney" ],
      "venue" : "In Proceedings of the Fourth Workshop on Discourse in Machine Translation (DiscoMT",
      "citeRegEx" : "Kim et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2019
    }, {
      "title" : "SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
      "author" : [ "Taku Kudo", "John Richardson." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System",
      "citeRegEx" : "Kudo and Richardson.,? 2018",
      "shortCiteRegEx" : "Kudo and Richardson.",
      "year" : 2018
    }, {
      "title" : "Has machine translation achieved human parity? a case for document-level evaluation",
      "author" : [ "Samuel Läubli", "Rico Sennrich", "Martin Volk." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4791–4796,",
      "citeRegEx" : "Läubli et al\\.,? 2018",
      "shortCiteRegEx" : "Läubli et al\\.",
      "year" : 2018
    }, {
      "title" : "Document-level neural MT: A systematic comparison",
      "author" : [ "António Lopes", "M. Amin Farajian", "Rachel Bawden", "Michael Zhang", "André F.T. Martins." ],
      "venue" : "Proceedings of the 22nd Annual Conference of the European Association for Machine Transla-",
      "citeRegEx" : "Lopes et al\\.,? 2020",
      "shortCiteRegEx" : "Lopes et al\\.",
      "year" : 2020
    }, {
      "title" : "Document context neural machine translation with memory networks",
      "author" : [ "Sameen Maruf", "Gholamreza Haffari." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1275–",
      "citeRegEx" : "Maruf and Haffari.,? 2018",
      "shortCiteRegEx" : "Maruf and Haffari.",
      "year" : 2018
    }, {
      "title" : "Selective attention for contextaware neural machine translation",
      "author" : [ "Sameen Maruf", "André F.T. Martins", "Gholamreza Haffari." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:",
      "citeRegEx" : "Maruf et al\\.,? 2019a",
      "shortCiteRegEx" : "Maruf et al\\.",
      "year" : 2019
    }, {
      "title" : "A survey on document-level machine translation: Methods and evaluation",
      "author" : [ "Sameen Maruf", "Fahimeh Saleh", "Gholamreza Haffari." ],
      "venue" : "ArXiv, abs/1912.08494.",
      "citeRegEx" : "Maruf et al\\.,? 2019b",
      "shortCiteRegEx" : "Maruf et al\\.",
      "year" : 2019
    }, {
      "title" : "Document-level neural machine translation with hierarchical attention networks",
      "author" : [ "Lesly Miculicich", "Dhananjay Ram", "Nikolaos Pappas", "James Henderson." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Process-",
      "citeRegEx" : "Miculicich et al\\.,? 2018",
      "shortCiteRegEx" : "Miculicich et al\\.",
      "year" : 2018
    }, {
      "title" : "A large-scale test set for the evaluation of context-aware pronoun translation in neural machine translation",
      "author" : [ "Mathias Müller", "Annette Rios", "Elena Voita", "Rico Sennrich." ],
      "venue" : "Proceedings of the Third Conference on Machine Translation: Research Pa-",
      "citeRegEx" : "Müller et al\\.,? 2018",
      "shortCiteRegEx" : "Müller et al\\.",
      "year" : 2018
    }, {
      "title" : "fairseq: A fast, extensible toolkit for sequence modeling",
      "author" : [ "Myle Ott", "Sergey Edunov", "Alexei Baevski", "Angela Fan", "Sam Gross", "Nathan Ng", "David Grangier", "Michael Auli." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chap-",
      "citeRegEx" : "Ott et al\\.,? 2019",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2019
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311–318.",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "A call for clarity in reporting BLEU scores",
      "author" : [ "Matt Post." ],
      "venue" : "Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186– 191, Brussels, Belgium. Association for Computational Linguistics.",
      "citeRegEx" : "Post.,? 2018",
      "shortCiteRegEx" : "Post.",
      "year" : 2018
    }, {
      "title" : "COMET: A neural framework for MT evaluation",
      "author" : [ "Ricardo Rei", "Craig Stewart", "Ana C Farinha", "Alon Lavie." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2685–2702, Online. Associa-",
      "citeRegEx" : "Rei et al\\.,? 2020",
      "shortCiteRegEx" : "Rei et al\\.",
      "year" : 2020
    }, {
      "title" : "Edinburgh neural machine translation systems for WMT 16",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers, pages 371–376, Berlin, Germany. As-",
      "citeRegEx" : "Sennrich et al\\.,? 2016a",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural machine translation of rare words with subword units",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715–",
      "citeRegEx" : "Sennrich et al\\.,? 2016b",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2016
    }, {
      "title" : "ContraCAT: Contrastive coreference analytical templates for machine translation",
      "author" : [ "Dario Stojanovski", "Benno Krojer", "Denis Peskov", "Alexander Fraser." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 4732–",
      "citeRegEx" : "Stojanovski et al\\.,? 2020",
      "shortCiteRegEx" : "Stojanovski et al\\.",
      "year" : 2020
    }, {
      "title" : "Capturing longer context for document-level neural machine translation: A multi-resolutional approach",
      "author" : [ "Zewei Sun", "Mingxuan Wang", "Hao Zhou", "Chengqi Zhao", "Shujian Huang", "Jiajun Chen", "Lei Li." ],
      "venue" : "arXiv, abs/2010.08961.",
      "citeRegEx" : "Sun et al\\.,? 2020",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural machine translation with extended context",
      "author" : [ "Jörg Tiedemann", "Yves Scherrer." ],
      "venue" : "Proceedings of the Third Workshop on Discourse in Machine Translation, pages 82–92, Copenhagen, Denmark. Association for Computational Linguistics.",
      "citeRegEx" : "Tiedemann and Scherrer.,? 2017",
      "shortCiteRegEx" : "Tiedemann and Scherrer.",
      "year" : 2017
    }, {
      "title" : "Attaining the unattainable? reassessing claims of human parity in neural machine translation",
      "author" : [ "Antonio Toral", "Sheila Castilho", "Ke Hu", "Andy Way." ],
      "venue" : "Proceedings of the Third Conference on Machine Translation: Research Papers, pages 113–123, Brus-",
      "citeRegEx" : "Toral et al\\.,? 2018",
      "shortCiteRegEx" : "Toral et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning to remember translation history with a continuous cache",
      "author" : [ "Zhaopeng Tu", "Yang Liu", "Shuming Shi", "Tong Zhang." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 6:407–420.",
      "citeRegEx" : "Tu et al\\.,? 2018a",
      "shortCiteRegEx" : "Tu et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning to remember translation history with a continuous cache",
      "author" : [ "Zhaopeng Tu", "Yang Liu", "Shuming Shi", "Tong Zhang." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 6:407–420.",
      "citeRegEx" : "Tu et al\\.,? 2018b",
      "shortCiteRegEx" : "Tu et al\\.",
      "year" : 2018
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion",
      "author" : [ "Elena Voita", "Rico Sennrich", "Ivan Titov." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for",
      "citeRegEx" : "Voita et al\\.,? 2019",
      "shortCiteRegEx" : "Voita et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploiting cross-sentence context for neural machine translation",
      "author" : [ "Longyue Wang", "Zhaopeng Tu", "Andy Way", "Qun Liu." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2826–2831, Copenhagen,",
      "citeRegEx" : "Wang et al\\.,? 2017",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2017
    }, {
      "title" : "Improving the transformer translation model with document-level context",
      "author" : [ "Jiacheng Zhang", "Huanbo Luan", "Maosong Sun", "Feifei Zhai", "Jingfang Xu", "Min Zhang", "Yang Liu." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Lan-",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : ", 2018), these claims seem overly optimistic and no longer hold with document-level evaluation (Toral et al., 2018; Läubli et al., 2018).",
      "startOffset" : 95,
      "endOffset" : 136
    }, {
      "referenceID" : 10,
      "context" : ", 2018), these claims seem overly optimistic and no longer hold with document-level evaluation (Toral et al., 2018; Läubli et al., 2018).",
      "startOffset" : 95,
      "endOffset" : 136
    }, {
      "referenceID" : 25,
      "context" : "models (Tiedemann and Scherrer, 2017), using different encoders for context (Zhang et al.",
      "startOffset" : 7,
      "endOffset" : 37
    }, {
      "referenceID" : 32,
      "context" : "models (Tiedemann and Scherrer, 2017), using different encoders for context (Zhang et al., 2018), having cache-based memories (Tu et al.",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 27,
      "context" : ", 2018), having cache-based memories (Tu et al., 2018a), or using models with hierarchical attention mechanisms (Miculicich et al.",
      "startOffset" : 37,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : ", 2018a), or using models with hierarchical attention mechanisms (Miculicich et al., 2018; Maruf et al., 2019a)",
      "startOffset" : 65,
      "endOffset" : 111
    }, {
      "referenceID" : 13,
      "context" : ", 2018a), or using models with hierarchical attention mechanisms (Miculicich et al., 2018; Maruf et al., 2019a)",
      "startOffset" : 65,
      "endOffset" : 111
    }, {
      "referenceID" : 11,
      "context" : "pler baselines with respect to overall translation accuracy, pronoun translation, or lexical cohesion (Lopes et al., 2020).",
      "startOffset" : 102,
      "endOffset" : 122
    }, {
      "referenceID" : 16,
      "context" : "However, even quantifying model usage of context is an ongoing challenge; while contrastive evaluation has been proposed to measure performance on inter-sentential discourse phenomena (Müller et al., 2018; Bawden et al., 2018), this approach is confined to a narrow set of phenomena, such as pronoun translation and lexical cohesion.",
      "startOffset" : 184,
      "endOffset" : 226
    }, {
      "referenceID" : 0,
      "context" : "However, even quantifying model usage of context is an ongoing challenge; while contrastive evaluation has been proposed to measure performance on inter-sentential discourse phenomena (Müller et al., 2018; Bawden et al., 2018), this approach is confined to a narrow set of phenomena, such as pronoun translation and lexical cohesion.",
      "startOffset" : 184,
      "endOffset" : 226
    }, {
      "referenceID" : 21,
      "context" : "Specifically, we introduce a simple but effective variation of word dropout (Sennrich et al., 2016a) for context-aware machine translation, dubbed COWORD dropout (§4).",
      "startOffset" : 76,
      "endOffset" : 100
    }, {
      "referenceID" : 25,
      "context" : "In experiments, we focus mostly on the simpler approach of concatenating the context to the current sentences (Tiedemann and Scherrer, 2017).",
      "startOffset" : 110,
      "endOffset" : 140
    }, {
      "referenceID" : 16,
      "context" : "to capture specific discourse phenomena that require inter-sentential context, such as anaphora resolution (Müller et al., 2018) and lexical cohesion (Bawden et al.",
      "startOffset" : 107,
      "endOffset" : 128
    }, {
      "referenceID" : 2,
      "context" : "Data We experiment with a document-level translation task by training models on the IWSLT2017 (Cettolo et al., 2012) dataset for language pairs EN → DE and EN → FR (with approximately 200K sentences for both pairs).",
      "startOffset" : 94,
      "endOffset" : 116
    }, {
      "referenceID" : 4,
      "context" : "(2020) that gains in performance are due to the use of small training corpora and weak baselines, we use Paracrawl (Esplà et al., 2019) and perform some data cleaning based on language identification tools, creating a pretraining dataset of around",
      "startOffset" : 115,
      "endOffset" : 135
    }, {
      "referenceID" : 22,
      "context" : "All data is encoded/vectorized with byte-pair encoding (Sennrich et al., 2016b) using the SentencePiece framework (Kudo and Richardson, 2018).",
      "startOffset" : 55,
      "endOffset" : 79
    }, {
      "referenceID" : 9,
      "context" : ", 2016b) using the SentencePiece framework (Kudo and Richardson, 2018).",
      "startOffset" : 43,
      "endOffset" : 70
    }, {
      "referenceID" : 16,
      "context" : "• For the EN → DE language pair, we evaluate on the ContraPro dataset (Müller et al., 2018), targeting anaphoric pronoun resolution.",
      "startOffset" : 70,
      "endOffset" : 91
    }, {
      "referenceID" : 29,
      "context" : "ments, we consider an encoder-decoder Transformer architecture (Vaswani et al., 2017).",
      "startOffset" : 63,
      "endOffset" : 85
    }, {
      "referenceID" : 17,
      "context" : "We train all our models on top of the Fairseq framework (Ott et al., 2019).",
      "startOffset" : 56,
      "endOffset" : 74
    }, {
      "referenceID" : 21,
      "context" : "methodology to increase context usage by the model?” As an answer, we extend a popular regularization technique used in sentence-level machine translation, word dropout (Sennrich et al., 2016a), to the context-aware setting.",
      "startOffset" : 169,
      "endOffset" : 193
    }, {
      "referenceID" : 7,
      "context" : "In addition, to explore the benefits of COWORD dropout in other architectures, we also train a one-to-two multi-encoder (Jean et al., 2017) transformer small model (more details in Appendix §C).",
      "startOffset" : 120,
      "endOffset" : 139
    }, {
      "referenceID" : 18,
      "context" : "We report the standard BLEU score (Papineni et al., 2002) calculated using sacreBLEU",
      "startOffset" : 34,
      "endOffset" : 57
    }, {
      "referenceID" : 19,
      "context" : "(Post, 2018) and COMET, a more accurate evaluation method using multilingual embeddings (Rei et al.",
      "startOffset" : 0,
      "endOffset" : 12
    }, {
      "referenceID" : 20,
      "context" : "(Post, 2018) and COMET, a more accurate evaluation method using multilingual embeddings (Rei et al., 2020).",
      "startOffset" : 88,
      "endOffset" : 106
    } ],
    "year" : 2021,
    "abstractText" : "Recent work in neural machine translation has demonstrated both the necessity and feasibility of using inter-sentential context — context from sentences other than those currently being translated. However, while many current methods present model architectures that theoretically can use this extra context, it is often not clear how much they do actually utilize it at translation time. In this paper, we introduce a new metric, conditional cross-mutual information, to quantify the usage of context by these models. Using this metric, we measure how much document-level machine translation systems use particular varieties of context. We find that target context is referenced more than source context, and that conditioning on a longer context has a diminishing effect on results. We then introduce a new, simple training method, context-aware word dropout, to increase the usage of context by context-aware models. Experiments show that our method increases context usage and that this reflects on the translation quality according to metrics such as BLEU and COMET, as well as performance on anaphoric pronoun resolution and lexical cohesion contrastive datasets.1",
    "creator" : "LaTeX with hyperref"
  }
}