{
  "name" : "2021.acl-long.181.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "CLINE: Contrastive Learning with Semantic Negative Examples for Natural Language Understanding",
    "authors" : [ "Dong Wang", "Ning Ding", "Piji Li", "Hai-Tao Zheng" ],
    "emails" : [ "wangd18@mails.tsinghua.edu.cn", "dingn18@mails.tsinghua.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 2332–2342\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n2332"
    }, {
      "heading" : "1 Introduction",
      "text" : "Pre-trained language models (PLMs) such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019) have been proved to be an effective way to improve various natural language processing tasks. However, recent works show that PLMs suffer from\n∗ Equal contribution. This work was mainly done when Dong Wang was an intern at Tencent AI Lab.\n† Corresponding authors.\npoor robustness when encountering adversarial examples (Jin et al., 2020; Li et al., 2020; Garg and Ramakrishnan, 2020; Zang et al., 2020; Lin et al., 2020a). As shown in Table 1, the BERT model can be fooled easily just by replacing ultimately with a similar word lastly.\nTo improve the robustness of PLMs, recent studies attempt to adopt adversarial training on PLMs, which applies gradient-based perturbations to the word embeddings during training (Miyato et al., 2017; Zhu et al., 2020; Jiang et al., 2020) or adds high-quality adversarial textual examples to the training phase (Wang and Bansal, 2018; Michel et al., 2019). The primary goal of these adversarial methods is to keep the label unchanged when the input has small changes. These models yield promising performance by constructing high-quality perturbated examples and adopting adversarial mechanisms. However, due to the discrete nature of natural language, in many cases, small perturbations can cause significant changes in the semantics of sentences. As shown in Table 1, negative sentiment can be turned into a positive one by changing only one word, but the model can not recognize the change. Some recent works create contrastive sets (Kaushik et al., 2020; Gardner et al., 2020),\nwhich manually perturb the test instances in small but meaningful ways that change the gold label. In this paper, we denote the perturbated examples without changed semantics as adversarial examples and the ones with changed semantics as contrastive examples, and most of the methods to improve robustness of PLMs mainly focus on the former examples, little study pays attention to the semantic negative examples.\nThe phenomenon makes us wonder can we train a BERT that is both defensive against adversarial attacks and sensitive to semantic changes by using both adversarial and contrastive examples? To answer that, we need to assess if the current robust models are meanwhile semantically sensitive. We conduct sets of pilot experiments (Section 2) to compare the performances of vanilla PLMs and adversarially trained PLMs on the contrastive examples. We observe that while improving the robustness of PLMs against adversarial attacks, the performance on contrastive examples drops.\nTo train a robust semantic-aware PLM, we propose Contrastive Learning with semantIc Negative Examples (CLINE). CLINE is a simple and effective method to generate adversarial and contrastive examples and contrastively learn from both of them. The contrastive manner has shown effectiveness in learning sentence representations (Luo et al., 2020; Wu et al., 2020; Gao et al., 2021), yet these studies neglect the generation of negative instances. In CLINE, we use external semantic knowledge, i.e., WordNet (Miller, 1995), to generate adversarial and contrastive examples by unsupervised replacing few specific representative tokens. Equipped by replaced token detection and contrastive objectives, our method gathers similar sentences with semblable semantics and disperse ones with different even opposite semantics, simultaneously improving the robustness and semantic sensitivity of PLMs. We conduct extensive experiments on several widely used text classification benchmarks to verify the effectiveness of CLINE. To be more specific, our model achieves +1.6% absolute improvement on 4 contrastive test sets and +0.5% absolute improvement on 4 adversarial test sets compared to RoBERTa model (Liu et al., 2019). That is, with the training on the proposed objectives, CLINE simultaneously gains the robustness of adversarial attacks and sensitivity of semantic changes1.\n1The source code of CLINE will be publicly available at https://github.com/kandorm/CLINE"
    }, {
      "heading" : "2 Pilot Experiment and Analysis",
      "text" : "To study how the adversarial training methods perform on the adversarial set and contrastive set, we first conduct pilot experiments and detailed analyses in this section."
    }, {
      "heading" : "2.1 Model and Datasets",
      "text" : "There are a considerable number of studies constructing adversarial examples to attack large-scale pre-trained language models, of which we select a popular method, TextFooler (Jin et al., 2020), as the word-level adversarial attack model to construct adversarial examples. Recently, many researchers create contrastive sets to more accurately evaluate a model’s true linguistic capabilities (Kaushik et al., 2020; Gardner et al., 2020). Based on these methods, the following datasets are selected to construct adversarial and contrastive examples in our pilot experiments and analyses:\nIMDB (Maas et al., 2011) is a sentiment analysis dataset and the task is to predict the sentiment (positive or negative) of a movie review.\nSNLI (Bowman et al., 2015) is a natural language inference dataset to judge the relationship between two sentences: whether the second sentence can be derived from entailment, contradiction, or neutral relationship with the first sentence.\nTo improve the generalization and robustness of language models, many adversarial training methods that minimize the maximal risk for labelpreserving input perturbations have been proposed, and we select an adversarial training method FreeLB (Zhu et al., 2020) for our pilot experiment. We evaluate the vanilla BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019), and the FreeLB version on the adversarial set and contrastive set."
    }, {
      "heading" : "2.2 Result Analysis",
      "text" : "Table 2 shows a detailed comparison of different models on the adversarial test set and the contrast test set. From the results, we can observe that, compared to the vanilla version, the adversarial training method FreeLB achieves higher accuracy on the adversarial sets, but suffers a considerable performance drop on the contrastive sets, especially for the BERT. The results are consistent with the intuition in Section 1, and also demonstrates that adversarial training is not suitable for the contrastive set and even brings negative effects. Intuitively, adversarial training tends to keep labels unchanged while the contrastive set tends to make small but label-\nchanging modifications. The adversarial training and contrastive examples seem to constitute a natural contradiction, revealing that additional strategies need to be applied to the training phase for the detection of the fine-grained changes of semantics. We provide a case study in Section 2.3, which further shows this difference."
    }, {
      "heading" : "2.3 Case Study",
      "text" : "To further understand why the adversarial training method fails on the contrastive sets, we carry out a thorough case study on IMDB. The examples we choose here are predicted correctly by the vanilla version of BERT but incorrectly by the FreeLB version. For the example in Tabel 3, we can observe that many parts are expressing positive sentiments (red part) in the sentence, and a few parts are expressing negative sentiments (blue parts). Overall, this case expresses negative sentiments, and the vanilla BERT can accurately capture the negative sentiment of the whole document. However, the FreeLB version of BERT may take the features of negative sentiment as noise and predict the whole document as a positive sentiment. This result in-\ndicates that the adversarially trained BERT could be fooled in a reversed way of traditional adversarial training. From this case study, we can observe that the adversarial training methods may not be suitable for these semantic changed adversarial examples, and to the best of our knowledge, there is no defense method for this kind of adversarial attack. Thus, it is crucial to explore the appropriate methods to learn changed semantics from semantic negative examples."
    }, {
      "heading" : "3 Method",
      "text" : "As stated in the observations in Section 2, we explore strategies that could improve the sensitivity of PLMs. In this section, we present CLINE, a simple and effective method to generate the adversarial and contrastive examples and learn from both of them. We start with the generation of adversarial and contrastive examples in Section 3.1, and then introduce the learning objectives of CLINE in Section 3.2."
    }, {
      "heading" : "3.1 Generation of Examples",
      "text" : "We expect that by contrasting sentences with the same and different semantics, our model can be more sensitive to the semantic changes. To do so, we adopt the idea of contrastive learning, which aims to learn the representation by concentrating positive pairs and pushing negative pairs apart. Therefore it is essential to define appropriate positive and negative pairs. In this paper, we regard sentences with the same semantics as positive pairs and sentences with opposite semantics as negative pairs. Some works (Alzantot et al., 2018; Tan et al., 2020; Wu et al., 2020) attempt to utilize data augmentation (such as synonym replacement, back translation, etc) to generate positive instances, but few works pay attention to the negative instances. And it is difficult to obtain opposite semantic instances for textual examples.\nIntuitively, when we replace the representative words in a sentence with its antonym, the semantic of the sentence is easy to be irrelevant or even opposite to the original sentence. As shown in Figure 1, given the sentence “Batman is an fictional superhero written by”, we can replace “fictional” with its antonym “real-life”, and then we get a counterfactual sentence “Batman is an real-life super-hero written by”. The latter contradicts the former and forms a negative pair with it.\nWe generate two sentences from the original input sequence xori, which express substantially different semantics but have few different words. One of the sentences is semantically close to xori (denoted as xsyn), while the other is far from or even opposite to xori (denoted as xant). In specific, we utilize spaCy2 to conduct segmentation and POS for the original sentences, extracting verbs, nouns, adjectives, and adverbs. xsyn is generated by replacing the extracted words with synonyms, hypernyms and morphological changes, and xant is generated by replacing them with antonyms and random words. For xsyn, about 40% tokens are replaced. For xant, about 20% tokens are replaced."
    }, {
      "heading" : "3.2 Training Objectives",
      "text" : "CLINE trains a neural text encoder (i.e., deep Transformer) Eφ parameterized by φ that maps a sequence of input tokens x = [x1, ..., xT ] to a sequence of representations h = [h1, .., hT ], hi∈[1:T ] ∈ Rd, where d is the dimen-\n2https://github.com/explosion/spaCy\nsion: h = Eφ(x). (1)\nMasked Language Modeling Objective With random tokens masked by special symbols [MASK], the input sequence is partially corrupted. Following BERT (Devlin et al., 2019), we adopt the masked language model objective (denoted as LMLM), which reconstructs the sequence by predicting the masked tokens. Replaced Token Detection Objective On the basis of xsyn and xant, we adopt an additional classifier C for the two generated sequences and detect which tokens are replaced by conducting two-way classification with a sigmoid output layer:\np(xsyn, t) = sigmoid(w>hsynt ), (2)\np(xant, t) = sigmoid(w>hantt ). (3)\nThe loss, denoted as LRTD is computed by:\nLRTD = ∑\nx′∈{xsyn,xant} − T∑ t=1 δtlog p(x′, t)\n− (1− δt)log(1− p(x′, t)),\n(4)\nwhere δt = 1 when the token xt is corrupted, and δt = 0 otherwise. Contrastive Objective The intuition of CLINE is to accurately predict if the semantics are changed when the original sentences are modified. In other words, in feature space, the metric between hori\nand hsyn should be close and the metric between hori and hant should be far. Thus, we develop a contrastive objective, where (xori, xsyn) is considered a positive pair and (xori, xant) is negative. We use hc to denote the embedding of the special symbol [CLS]. In the training of CLINE, we follow the setting of RoBERTa (Liu et al., 2019) to omit the next sentence prediction (NSP) objective since previous works have shown that NSP objective can hurt the performance on the downstream tasks (Liu et al., 2019; Joshi et al., 2020). Alternatively, adopt the embedding of [CLS] as the sentence representation for a contrastive objective. The metric between sentence representations is calculated as the dot product between [CLS] embeddings:\nf(x∗,x′) = exp(h∗>c h ′ c). (5)\nInspired by InfoNCE, we define an objective Lcts in the contrastive manner:\nLcts=− ∑ x∈X log f(xori,xsyn) f(xori,xsyn) + f(xori,xant) .\n(6) Note that different from some contrastive strategies that usually randomly sample multiple negative examples, we only utilize one xant as the negative example for training. This is because the primary goal of our pre-training objectives is to improve the robustness under semantically adversarial attacking. And we only focus on the negative sample (i.e., xant) that is generated for our goal, instead of arbitrarily sampling other sentences from the pre-training corpus as negative samples.\nFinally, we have the following training loss:\nL=λ1LMLM + λ2LRTD + λ3Lcts, (7)\nwhere λi is the task weighting learned by training."
    }, {
      "heading" : "4 Experiments",
      "text" : "We conduct extensive experiments and analyses to evaluate the effectiveness of CLINE. In this section, we firstly introduce the implementation (Section 4.1) and the datasets (Section 4.2) we used, then we introduce the experiments on contrastive sets (Section 4.3) and adversarial sets (Section 4.4), respectively. Finally, we conduct the ablation study (Section 4.5) and analysis about sentence representation (Section 4.6)."
    }, {
      "heading" : "4.1 Implementation",
      "text" : "To better acquire the knowledge from the existing pre-trained model, we did not train from scratch\nbut the official RoBERTa-base model. We train for 30K steps with a batch size of 256 sequences of maximum length 512 tokens. We use Adam with a learning rate of 1e-4, β1 = 0.9, β2 = 0.999, =1e-8, L2 weight decay of 0.01, learning rate warmup over the first 500 steps, and linear decay of the learning rate. We use 0.1 for dropout on all layers and in attention. The model is pre-trained on 32 NVIDIA Tesla V100 32GB GPUs. Our model is pre-trained on a combination of BookCorpus (Zhu et al., 2015) and English Wikipedia datasets, the data BERT used for pre-training."
    }, {
      "heading" : "4.2 Datasets",
      "text" : "We evaluate our model on six text classification tasks:\n• IMDB (Maas et al., 2011) is a sentiment analysis dataset and the task is to predict the sentiment (positive or negative) of a movie review.\n• SNLI (Bowman et al., 2015) is a natural language inference dataset to judge the relationship between two sentences: whether the second sentence can be derived from entailment, contradiction, or neutral relationship with the first sentence.\n• PERSPECTRUM (Chen et al., 2019) is a natural language inference dataset to predict whether a relevant perspective is for/against the given claim.\n• BoolQ (Clark et al., 2019) is a dataset of reading comprehension instances with boolean (yes or no) answers.\n• AG (Zhang et al., 2015) is a sentencelevel classification with regard to four news topics: World, Sports, Business, and Science/Technology.\n• MR (Pang and Lee, 2005) is a sentence-level sentiment classification on positive and negative movie reviews."
    }, {
      "heading" : "4.3 Experiments on Contrastive Sets",
      "text" : "We evaluate our model on four contrastive sets: IMDB, PERSPECTRUM, BoolQ and SNLI, which were provided by Contrast Sets3 (Gardner et al., 2020). We compare our approach with BERT and\n3https://github.com/allenai/ contrast-sets\nRoBERTa across the original test set (Ori) and contrastive test set (Rev). Contrast consistency (Con) is a metric defined by Gardner et al. (2020) to evaluate whether a model’s predictions are all correct for the same examples in both the original test set and the contrastive test set. We fine-tune each model many times using different learning rates (1e-5,2e5,3e-5,4e-5,5e-5) and select the best result on the contrastive test set.\nFrom the results shown in Table 4, we can observe that our model outperforms the baseline. Especially in the contrast consistency metric, our method significantly outperforms other methods, which means our model is sensitive to the small change of semantic, rather than simply capturing the characteristics of the dataset. On the other hand, our model also has some improvement on the original test set, which means our method can boost the performance of PLMs on the common examples."
    }, {
      "heading" : "4.4 Experiments on Adversarial Sets",
      "text" : "To evaluate the robustness of the model, we compare our model with BERT and RoBERTa on the vanilla version and FreeLB version across several adversarial test sets. Instead of using an adversarial attacker to attack the model, we use the adversarial examples generated by TextFooler (Jin et al., 2020) as a benchmark to evaluate the performance against adversarial examples. TextFooler identifies the important words in the text and then prioritizes\nto replace them with the most semantically similar and grammatically correct words.\nFrom the experimental results in Table 5, we can observe that our vanilla model achieves higher accuracy on all the four benchmark datasets compared to the vanilla BERT and RoBERTa. By constructing similar semantic adversarial examples and using the contrastive training objective, our model can concentrate the representation of the original example and the adversarial example, and then achieve better robustness. Furthermore, our method is in the pre-training stage, so it can also be combined with the existing adversarial training methods. Compared with the FreeLB version of BERT and RoBERTa, our model can achieve stateof-the-art (SOTA) performances on the adversarial sets. Experimental results on contrastive sets and adversarial sets show that our model is sensitive to semantic changes and keeps robust at the same time."
    }, {
      "heading" : "4.5 Ablation Study",
      "text" : "To further analyze the effectiveness of different factors of our CLINE, we choose PERSPECTRUM (Chen et al., 2019) and BoolQ (Clark et al., 2019) as benchmark datasets and report the ablation test in terms of 1) w/o RTD: we remove the replaced token detection objective (LRTD) in our model to verify whether our model mainly benefits from the contrastive objective. 2) w/o Hard Negative: we replace the constructed negative examples with random sampling examples to verify whether the negative examples constructed by unsupervised word substitution are better. We also add 1% and 10% settings, meaning using only 1% / 10% data of the training set, to simulate a low-resource scenario and observe how the model performance across different datasets and settings. From Table 6, we can observe that: 1) Our CLINE outperformance RoBERTa on all settings, which indicates that our method is universal and robust. Especially in the\nlow-resource scenario (1% and 10% supervised training data), our method shows a prominent improvement. 2) Compared to the CLINE, w/o RTD just has a little bit of performance degradation. This proves that the improvement of performance mainly benefits from the contrastive objective and the replaced token detection objective can further make the model sensitive to the change of the words. 3) Compared to CLINE, we can see that the w/o Hard Negative has a significant performance degradation in most settings, proving the effectiveness of constructing hard negative instances."
    }, {
      "heading" : "4.6 Sentence Semantic Representation",
      "text" : "To evaluate the semantic sensitivity of the models, we generate 9626 sentence triplets from a sentencelevel sentiment analysis dataset MR (Pang and Lee, 2005). Each of the triples contains an original sentence xori from MR, a sentence with similar\nsemantics xsyn and a sentence with opposite semantic xant. We generate xsyn/xant by replacing a word in xori with its synonym/antonym from WordNet (Miller, 1995). And then we compute the cosine similarity between sentence pairs with [CLS] token and the mean-pooling of all tokens. And we also use a SOTA algorithm, BertScore (Zhang et al., 2020) to compute similarity scores of sentence pairs. We consider cases in which the model correctly identifies the semantic relationship (e.g., if BertScore(xori,xsyn)>BertScore(xori,xant)) as Hits. And higher Hits means the model can better distinguish the sentences, which express substantially different semantics but have few different words.\nWe show the max Hits on all layers (from 1 to 12) of Transformers-based encoder in Table 7. We can observe: 1) In the BERT model, using the [CLS] token as sentence representation achieves worse results than mean-pooling, which shows the same conclusion as Sentence-BERT (Reimers and Gurevych, 2019). And because RoBERTa omits the NSP objective, so its result of CLS has no meaning. 2) The BertScore can compute semantic similarity better than other methods and our method CLINE-B can further improve the Hits. 3) By constructing positive and negative examples for contrastive learning in pre-training stage, our method CLINE-B and CLINE-R learn better sentence representation and detect small semantic changes. 4) We can observe that the RoBERTa has less Hits than BERT, and our CLINE-B has significant improvement compared to BERT. We speculate that there may be two reasons, the first is that BERT can better identify sentence-level semantic changes\nbecause it has been trained with the next sentence prediction (NSP) objective in the pre-training stage. And the second is that the BERT is not trained enough, so it can not represent sentence semantics well, and our method can improve the semantic representation ability of the model."
    }, {
      "heading" : "5 Related Work",
      "text" : ""
    }, {
      "heading" : "5.1 Pre-trained Language Models",
      "text" : "The PLMs have proven their advantages in capturing implicit language features. Two main research directions of PLMs are autoregressive (AR) pre-training (such as GPT (Radford et al., 2018)) and denoising autoencoding (DAE) pre-training (such as BERT (Devlin et al., 2019)). AR pretraining aims to predict the next word based on previous tokens but lacks the modeling of the bidirectional context. And DAE pre-training aims to reconstruct the input sequences using left and right context. However, previous works mainly focus on the token-level pre-training tasks and ignore modeling the global semantic of sentences."
    }, {
      "heading" : "5.2 Adversarial Training",
      "text" : "To make neural networks more robust to adversarial examples, many defense strategies have been proposed, and adversarial training is widely considered to be the most effective. Different from the image domain, it is more challenging to deal with text data due to its discrete property, which is hard to optimize. Previous works focus on heuristics for creating adversarial examples in the black-box setting. Belinkov and Bisk (2018) manipulate every word in a sentence with synthetic or natural noise in machine translation systems. Iyyer et al. (2018) leverage back-translated to produce paraphrases that have different sentence structures. Recently, Miyato et al. (2017) extend adversarial and virtual adversarial training (Miyato et al., 2019) to text classification tasks by applying perturbations to word embeddings rather than discrete input symbols. Following this, many adversarial training methods in the text domain have been proposed and have been applied to the state-of-the-art PLMs. Li and Qiu (2020) introduce a token-level perturbation to improves the robustness of PLMs. Zhu et al. (2020) use the gradients obtained in adversarial training to boost the performance of PLMs. Although many studies seem to achieve a robust representation, our pilot experiments (Section 2) show that there is still a long way to go."
    }, {
      "heading" : "5.3 Contrastive Learning",
      "text" : "Contrastive learning is an unsupervised representation learning method, which has been widely used in learning graph representations (Velickovic et al., 2019), visual representations (van den Oord et al., 2018; He et al., 2020; Chen et al., 2020), response representations (Lin et al., 2020b; Su et al., 2020), text representations (Iter et al., 2020; Ding et al., 2021) and structured world models (Kipf et al., 2020). The main idea is to learn a representation by contrasting positive pairs and negative pairs, which aims to concentrate positive samples and push apart negative samples. In natural language processing (NLP), contrastive self-supervised learning has been widely used for learning better sentence representations. Logeswaran and Lee (2018) sample two contiguous sentences for positive pairs and the sentences from the other document as negative pairs. Luo et al. (2020) present contrastive pretraining for learning denoised sequence representations in a self-supervised manner. Wu et al. (2020) present multiple sentence-level augmentation strategies for contrastive sentence representation learning. The main difference between these works is their various definitions of positive examples. However, recent works pay little attention to the construction of negative examples, only using simple random sampling sentences. In this paper, we propose a negative example construction strategy with opposite semantics to improve the sentence representation learning and the robustness of the pre-trained language model."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we focus on one specific problem how to train a pre-trained language model with robustness against adversarial attacks and sensitivity to small changed semantics. We propose CLINE, a simple and effective method to tackle the challenge. In the training phase of CLINE, it automatically generates the adversarial example and semantic negative example to the original sentence. And then the model is trained by three objectives to make full utilization of both sides of examples. Empirical results demonstrate that our method could considerably improve the sensitivity of pre-trained language models and meanwhile gain robustness."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This research is supported by National Natural Science Foundation of China (Grant No. 61773229\nand 6201101015), Tencent AI Lab Rhino-Bird Focused Research Program (No. JR202032), Shenzhen Giiso Information Technology Co. Ltd., Natural Science Foundation of Guangdong Province (Grant No. 2021A1515012640), the Basic Research Fund of Shenzhen City (Grand No. JCYJ20190813165003837), and Overseas Cooperation Research Fund of Graduate School at Shenzhen, Tsinghua University (Grant No. HW2018002)."
    } ],
    "references" : [ {
      "title" : "Generating natural language adversarial examples",
      "author" : [ "Moustafa Alzantot", "Yash Sharma", "Ahmed Elgohary", "Bo-Jhang Ho", "Mani B. Srivastava", "Kai-Wei Chang." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Alzantot et al\\.,? 2018",
      "shortCiteRegEx" : "Alzantot et al\\.",
      "year" : 2018
    }, {
      "title" : "Synthetic and natural noise both break neural machine translation",
      "author" : [ "Yonatan Belinkov", "Yonatan Bisk." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track",
      "citeRegEx" : "Belinkov and Bisk.,? 2018",
      "shortCiteRegEx" : "Belinkov and Bisk.",
      "year" : 2018
    }, {
      "title" : "A large annotated corpus for learning natural language inference",
      "author" : [ "Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Bowman et al\\.,? 2015",
      "shortCiteRegEx" : "Bowman et al\\.",
      "year" : 2015
    }, {
      "title" : "Seeing things from a different angle: Discovering diverse perspectives about claims",
      "author" : [ "Sihao Chen", "Daniel Khashabi", "Wenpeng Yin", "Chris Callison-Burch", "Dan Roth." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Asso-",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "A simple framework for contrastive learning of visual representations",
      "author" : [ "Ting Chen", "Simon Kornblith", "Mohammad Norouzi", "Geoffrey E. Hinton." ],
      "venue" : "Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020,",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "Boolq: Exploring the surprising difficulty of natural yes/no questions",
      "author" : [ "Christopher Clark", "Kenton Lee", "Ming-Wei Chang", "Tom Kwiatkowski", "Michael Collins", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American",
      "citeRegEx" : "Clark et al\\.,? 2019",
      "shortCiteRegEx" : "Clark et al\\.",
      "year" : 2019
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Prototypical representation learning for relation extraction",
      "author" : [ "Ning Ding", "Xiaobin Wang", "Yao Fu", "Guangwei Xu", "Rui Wang", "Pengjun Xie", "Ying Shen", "Fei Huang", "Hai-Tao Zheng", "Rui Zhang." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Ding et al\\.,? 2021",
      "shortCiteRegEx" : "Ding et al\\.",
      "year" : 2021
    }, {
      "title" : "Simcse: Simple contrastive learning of sentence embeddings",
      "author" : [ "Tianyu Gao", "Xingcheng Yao", "Danqi Chen." ],
      "venue" : "CoRR, abs/2104.08821.",
      "citeRegEx" : "Gao et al\\.,? 2021",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2021
    }, {
      "title" : "Evaluating models’ local decision boundaries via contrast sets",
      "author" : [ "F. Liu", "Phoebe Mulcaire", "Qiang Ning", "Sameer Singh", "Noah A. Smith", "Sanjay Subramanian", "Reut Tsarfaty", "Eric Wallace", "Ally Zhang", "Ben Zhou" ],
      "venue" : "In Proceedings of the 2020 Con-",
      "citeRegEx" : "Liu et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "BAE: bert-based adversarial examples for text classification",
      "author" : [ "Siddhant Garg", "Goutham Ramakrishnan." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020,",
      "citeRegEx" : "Garg and Ramakrishnan.,? 2020",
      "shortCiteRegEx" : "Garg and Ramakrishnan.",
      "year" : 2020
    }, {
      "title" : "Momentum contrast for unsupervised visual representation learning",
      "author" : [ "Kaiming He", "Haoqi Fan", "Yuxin Wu", "Saining Xie", "Ross B. Girshick." ],
      "venue" : "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA,",
      "citeRegEx" : "He et al\\.,? 2020",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2020
    }, {
      "title" : "Pretraining with contrastive sentence objectives improves discourse performance of language models",
      "author" : [ "Dan Iter", "Kelvin Guu", "Larry Lansing", "Dan Jurafsky." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Iter et al\\.,? 2020",
      "shortCiteRegEx" : "Iter et al\\.",
      "year" : 2020
    }, {
      "title" : "Adversarial example generation with syntactically controlled paraphrase networks",
      "author" : [ "Mohit Iyyer", "John Wieting", "Kevin Gimpel", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Iyyer et al\\.,? 2018",
      "shortCiteRegEx" : "Iyyer et al\\.",
      "year" : 2018
    }, {
      "title" : "SMART: robust and efficient fine-tuning for pretrained natural language models through principled regularized optimization",
      "author" : [ "Haoming Jiang", "Pengcheng He", "Weizhu Chen", "Xiaodong Liu", "Jianfeng Gao", "Tuo Zhao." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Jiang et al\\.,? 2020",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2020
    }, {
      "title" : "Is BERT really robust? A strong baseline for natural language attack on text classification and entailment",
      "author" : [ "Di Jin", "Zhijing Jin", "Joey Tianyi Zhou", "Peter Szolovits." ],
      "venue" : "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020,",
      "citeRegEx" : "Jin et al\\.,? 2020",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2020
    }, {
      "title" : "Spanbert: Improving pre-training by representing and predicting spans",
      "author" : [ "Mandar Joshi", "Danqi Chen", "Yinhan Liu", "Daniel S. Weld", "Luke Zettlemoyer", "Omer Levy." ],
      "venue" : "Trans. Assoc. Comput. Linguistics, 8:64–77.",
      "citeRegEx" : "Joshi et al\\.,? 2020",
      "shortCiteRegEx" : "Joshi et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning the difference that makes A difference with counterfactuallyaugmented data",
      "author" : [ "Divyansh Kaushik", "Eduard H. Hovy", "Zachary Chase Lipton." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa,",
      "citeRegEx" : "Kaushik et al\\.,? 2020",
      "shortCiteRegEx" : "Kaushik et al\\.",
      "year" : 2020
    }, {
      "title" : "Contrastive learning of structured world models",
      "author" : [ "Thomas N. Kipf", "Elise van der Pol", "Max Welling." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.",
      "citeRegEx" : "Kipf et al\\.,? 2020",
      "shortCiteRegEx" : "Kipf et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT-ATTACK: adversarial attack against BERT using BERT",
      "author" : [ "Linyang Li", "Ruotian Ma", "Qipeng Guo", "Xiangyang Xue", "Xipeng Qiu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, On-",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Textat: Adversarial training for natural language understanding with token-level perturbation",
      "author" : [ "Linyang Li", "Xipeng Qiu." ],
      "venue" : "CoRR, abs/2004.14543.",
      "citeRegEx" : "Li and Qiu.,? 2020",
      "shortCiteRegEx" : "Li and Qiu.",
      "year" : 2020
    }, {
      "title" : "Commonsense knowledge adversarial dataset",
      "author" : [ "Gongqi Lin", "Yuan Miao", "Xiaoyong Yang", "Wenwu Ou", "Lizhen Cui", "Wei Guo", "Chunyan Miao" ],
      "venue" : null,
      "citeRegEx" : "Lin et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "The world is not binary: Learning to rank with grayscale data for dialogue response selection",
      "author" : [ "Zibo Lin", "Deng Cai", "Yan Wang", "Xiaojiang Liu", "Haitao Zheng", "Shuming Shi." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Nat-",
      "citeRegEx" : "Lin et al\\.,? 2020b",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "Roberta: A robustly optimized BERT pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "CoRR, abs/1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "An efficient framework for learning sentence representations",
      "author" : [ "Lajanugen Logeswaran", "Honglak Lee." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track",
      "citeRegEx" : "Logeswaran and Lee.,? 2018",
      "shortCiteRegEx" : "Logeswaran and Lee.",
      "year" : 2018
    }, {
      "title" : "CAPT: contrastive pretraining for learning denoised sequence representations",
      "author" : [ "Fuli Luo", "Pengcheng Yang", "Shicheng Li", "Xuancheng Ren", "Xu Sun." ],
      "venue" : "CoRR, abs/2010.06351.",
      "citeRegEx" : "Luo et al\\.,? 2020",
      "shortCiteRegEx" : "Luo et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning word vectors for sentiment analysis",
      "author" : [ "Andrew L. Maas", "Raymond E. Daly", "Peter T. Pham", "Dan Huang", "Andrew Y. Ng", "Christopher Potts." ],
      "venue" : "The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Tech-",
      "citeRegEx" : "Maas et al\\.,? 2011",
      "shortCiteRegEx" : "Maas et al\\.",
      "year" : 2011
    }, {
      "title" : "On evaluation of adversarial perturbations for sequence-to-sequence models",
      "author" : [ "Paul Michel", "Xian Li", "Graham Neubig", "Juan Miguel Pino." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Michel et al\\.,? 2019",
      "shortCiteRegEx" : "Michel et al\\.",
      "year" : 2019
    }, {
      "title" : "Wordnet: A lexical database for english",
      "author" : [ "George A. Miller." ],
      "venue" : "Commun. ACM, 38(11):39–41.",
      "citeRegEx" : "Miller.,? 1995",
      "shortCiteRegEx" : "Miller.",
      "year" : 1995
    }, {
      "title" : "Adversarial training methods for semi-supervised text classification",
      "author" : [ "Takeru Miyato", "Andrew M. Dai", "Ian J. Goodfellow." ],
      "venue" : "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Con-",
      "citeRegEx" : "Miyato et al\\.,? 2017",
      "shortCiteRegEx" : "Miyato et al\\.",
      "year" : 2017
    }, {
      "title" : "Representation learning with contrastive predictive coding",
      "author" : [ "Aäron van den Oord", "Yazhe Li", "Oriol Vinyals." ],
      "venue" : "CoRR, abs/1807.03748.",
      "citeRegEx" : "Oord et al\\.,? 2018",
      "shortCiteRegEx" : "Oord et al\\.",
      "year" : 2018
    }, {
      "title" : "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
      "author" : [ "Bo Pang", "Lillian Lee." ],
      "venue" : "ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 25-30",
      "citeRegEx" : "Pang and Lee.,? 2005",
      "shortCiteRegEx" : "Pang and Lee.",
      "year" : 2005
    }, {
      "title" : "Improving language understanding by generative pre-training",
      "author" : [ "Alec Radford", "Karthik Narasimhan", "Tim Salimans", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2018
    }, {
      "title" : "Sentencebert: Sentence embeddings using siamese bertnetworks",
      "author" : [ "Nils Reimers", "Iryna Gurevych." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Nat-",
      "citeRegEx" : "Reimers and Gurevych.,? 2019",
      "shortCiteRegEx" : "Reimers and Gurevych.",
      "year" : 2019
    }, {
      "title" : "Dialogue response selection with hierarchical curriculum learning",
      "author" : [ "Yixuan Su", "Deng Cai", "Qingyu Zhou", "Zibo Lin", "Simon Baker", "Yunbo Cao", "Shuming Shi", "Nigel Collier", "Yan Wang." ],
      "venue" : "CoRR, abs/2012.14756.",
      "citeRegEx" : "Su et al\\.,? 2020",
      "shortCiteRegEx" : "Su et al\\.",
      "year" : 2020
    }, {
      "title" : "It’s morphin’ time! combating linguistic discrimination with inflectional perturbations",
      "author" : [ "Samson Tan", "Shafiq R. Joty", "Min-Yen Kan", "Richard Socher." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL",
      "citeRegEx" : "Tan et al\\.,? 2020",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2020
    }, {
      "title" : "Deep graph infomax",
      "author" : [ "Petar Velickovic", "William Fedus", "William L. Hamilton", "Pietro Liò", "Yoshua Bengio", "R. Devon Hjelm." ],
      "venue" : "7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.",
      "citeRegEx" : "Velickovic et al\\.,? 2019",
      "shortCiteRegEx" : "Velickovic et al\\.",
      "year" : 2019
    }, {
      "title" : "Robust machine comprehension models via adversarial training",
      "author" : [ "Yicheng Wang", "Mohit Bansal." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo-",
      "citeRegEx" : "Wang and Bansal.,? 2018",
      "shortCiteRegEx" : "Wang and Bansal.",
      "year" : 2018
    }, {
      "title" : "CLEAR: contrastive learning for sentence representation",
      "author" : [ "Zhuofeng Wu", "Sinong Wang", "Jiatao Gu", "Madian Khabsa", "Fei Sun", "Hao Ma." ],
      "venue" : "CoRR, abs/2012.15466.",
      "citeRegEx" : "Wu et al\\.,? 2020",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Word-level textual adversarial attacking as combinatorial optimization",
      "author" : [ "Yuan Zang", "Fanchao Qi", "Chenghao Yang", "Zhiyuan Liu", "Meng Zhang", "Qun Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Zang et al\\.,? 2020",
      "shortCiteRegEx" : "Zang et al\\.",
      "year" : 2020
    }, {
      "title" : "Bertscore: Evaluating text generation with BERT",
      "author" : [ "Tianyi Zhang", "Varsha Kishore", "Felix Wu", "Kilian Q. Weinberger", "Yoav Artzi." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Character-level convolutional networks for text classification",
      "author" : [ "Xiang Zhang", "Junbo Jake Zhao", "Yann LeCun." ],
      "venue" : "Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-",
      "citeRegEx" : "Zhang et al\\.,? 2015",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2015
    }, {
      "title" : "Freelb: Enhanced adversarial training for natural language understanding",
      "author" : [ "Chen Zhu", "Yu Cheng", "Zhe Gan", "Siqi Sun", "Tom Goldstein", "Jingjing Liu." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April",
      "citeRegEx" : "Zhu et al\\.,? 2020",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2020
    }, {
      "title" : "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
      "author" : [ "Yukun Zhu", "Ryan Kiros", "Richard S. Zemel", "Ruslan Salakhutdinov", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler." ],
      "venue" : "2015 IEEE Interna-",
      "citeRegEx" : "Zhu et al\\.,? 2015",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Pre-trained language models (PLMs) such as BERT (Devlin et al., 2019) and RoBERTa (Liu et al.",
      "startOffset" : 48,
      "endOffset" : 69
    }, {
      "referenceID" : 23,
      "context" : ", 2019) and RoBERTa (Liu et al., 2019) have been proved to be an effective way to improve various natural language processing tasks.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 15,
      "context" : "poor robustness when encountering adversarial examples (Jin et al., 2020; Li et al., 2020; Garg and Ramakrishnan, 2020; Zang et al., 2020; Lin et al., 2020a).",
      "startOffset" : 55,
      "endOffset" : 157
    }, {
      "referenceID" : 19,
      "context" : "poor robustness when encountering adversarial examples (Jin et al., 2020; Li et al., 2020; Garg and Ramakrishnan, 2020; Zang et al., 2020; Lin et al., 2020a).",
      "startOffset" : 55,
      "endOffset" : 157
    }, {
      "referenceID" : 10,
      "context" : "poor robustness when encountering adversarial examples (Jin et al., 2020; Li et al., 2020; Garg and Ramakrishnan, 2020; Zang et al., 2020; Lin et al., 2020a).",
      "startOffset" : 55,
      "endOffset" : 157
    }, {
      "referenceID" : 39,
      "context" : "poor robustness when encountering adversarial examples (Jin et al., 2020; Li et al., 2020; Garg and Ramakrishnan, 2020; Zang et al., 2020; Lin et al., 2020a).",
      "startOffset" : 55,
      "endOffset" : 157
    }, {
      "referenceID" : 29,
      "context" : "To improve the robustness of PLMs, recent studies attempt to adopt adversarial training on PLMs, which applies gradient-based perturbations to the word embeddings during training (Miyato et al., 2017; Zhu et al., 2020; Jiang et al., 2020) or adds high-quality adversarial textual examples to the training phase (Wang and Bansal, 2018; Michel et al.",
      "startOffset" : 179,
      "endOffset" : 238
    }, {
      "referenceID" : 42,
      "context" : "To improve the robustness of PLMs, recent studies attempt to adopt adversarial training on PLMs, which applies gradient-based perturbations to the word embeddings during training (Miyato et al., 2017; Zhu et al., 2020; Jiang et al., 2020) or adds high-quality adversarial textual examples to the training phase (Wang and Bansal, 2018; Michel et al.",
      "startOffset" : 179,
      "endOffset" : 238
    }, {
      "referenceID" : 14,
      "context" : "To improve the robustness of PLMs, recent studies attempt to adopt adversarial training on PLMs, which applies gradient-based perturbations to the word embeddings during training (Miyato et al., 2017; Zhu et al., 2020; Jiang et al., 2020) or adds high-quality adversarial textual examples to the training phase (Wang and Bansal, 2018; Michel et al.",
      "startOffset" : 179,
      "endOffset" : 238
    }, {
      "referenceID" : 37,
      "context" : ", 2020) or adds high-quality adversarial textual examples to the training phase (Wang and Bansal, 2018; Michel et al., 2019).",
      "startOffset" : 80,
      "endOffset" : 124
    }, {
      "referenceID" : 27,
      "context" : ", 2020) or adds high-quality adversarial textual examples to the training phase (Wang and Bansal, 2018; Michel et al., 2019).",
      "startOffset" : 80,
      "endOffset" : 124
    }, {
      "referenceID" : 17,
      "context" : "Some recent works create contrastive sets (Kaushik et al., 2020; Gardner et al., 2020),",
      "startOffset" : 42,
      "endOffset" : 86
    }, {
      "referenceID" : 25,
      "context" : "The contrastive manner has shown effectiveness in learning sentence representations (Luo et al., 2020; Wu et al., 2020; Gao et al., 2021), yet these studies neglect the generation of negative instances.",
      "startOffset" : 84,
      "endOffset" : 137
    }, {
      "referenceID" : 38,
      "context" : "The contrastive manner has shown effectiveness in learning sentence representations (Luo et al., 2020; Wu et al., 2020; Gao et al., 2021), yet these studies neglect the generation of negative instances.",
      "startOffset" : 84,
      "endOffset" : 137
    }, {
      "referenceID" : 8,
      "context" : "The contrastive manner has shown effectiveness in learning sentence representations (Luo et al., 2020; Wu et al., 2020; Gao et al., 2021), yet these studies neglect the generation of negative instances.",
      "startOffset" : 84,
      "endOffset" : 137
    }, {
      "referenceID" : 28,
      "context" : "WordNet (Miller, 1995), to generate adversarial and contrastive examples by unsupervised replacing few specific representative tokens.",
      "startOffset" : 8,
      "endOffset" : 22
    }, {
      "referenceID" : 23,
      "context" : "5% absolute improvement on 4 adversarial test sets compared to RoBERTa model (Liu et al., 2019).",
      "startOffset" : 77,
      "endOffset" : 95
    }, {
      "referenceID" : 15,
      "context" : "There are a considerable number of studies constructing adversarial examples to attack large-scale pre-trained language models, of which we select a popular method, TextFooler (Jin et al., 2020), as the word-level adversarial attack model to construct adversarial examples.",
      "startOffset" : 176,
      "endOffset" : 194
    }, {
      "referenceID" : 17,
      "context" : "model’s true linguistic capabilities (Kaushik et al., 2020; Gardner et al., 2020).",
      "startOffset" : 37,
      "endOffset" : 81
    }, {
      "referenceID" : 26,
      "context" : "Based on these methods, the following datasets are selected to construct adversarial and contrastive examples in our pilot experiments and analyses: IMDB (Maas et al., 2011) is a sentiment analysis dataset and the task is to predict the sentiment (positive or negative) of a movie review.",
      "startOffset" : 154,
      "endOffset" : 173
    }, {
      "referenceID" : 2,
      "context" : "SNLI (Bowman et al., 2015) is a natural language inference dataset to judge the relationship",
      "startOffset" : 5,
      "endOffset" : 26
    }, {
      "referenceID" : 42,
      "context" : "of language models, many adversarial training methods that minimize the maximal risk for labelpreserving input perturbations have been proposed, and we select an adversarial training method FreeLB (Zhu et al., 2020) for our pilot experiment.",
      "startOffset" : 197,
      "endOffset" : 215
    }, {
      "referenceID" : 6,
      "context" : "We evaluate the vanilla BERT (Devlin et al., 2019) and RoBERTa (Liu et al.",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 23,
      "context" : ", 2019) and RoBERTa (Liu et al., 2019), and the FreeLB version on the adversarial set and contrastive set.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 0,
      "context" : "Some works (Alzantot et al., 2018; Tan et al., 2020; Wu et al., 2020) attempt to utilize data augmentation (such as synonym replacement, back translation, etc) to generate positive instances, but few works pay attention to the negative instances.",
      "startOffset" : 11,
      "endOffset" : 69
    }, {
      "referenceID" : 35,
      "context" : "Some works (Alzantot et al., 2018; Tan et al., 2020; Wu et al., 2020) attempt to utilize data augmentation (such as synonym replacement, back translation, etc) to generate positive instances, but few works pay attention to the negative instances.",
      "startOffset" : 11,
      "endOffset" : 69
    }, {
      "referenceID" : 38,
      "context" : "Some works (Alzantot et al., 2018; Tan et al., 2020; Wu et al., 2020) attempt to utilize data augmentation (such as synonym replacement, back translation, etc) to generate positive instances, but few works pay attention to the negative instances.",
      "startOffset" : 11,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "Following BERT (Devlin et al., 2019), we adopt the masked language model objective (denoted as LMLM), which reconstructs the sequence by predicting the masked tokens.",
      "startOffset" : 15,
      "endOffset" : 36
    }, {
      "referenceID" : 23,
      "context" : "In the training of CLINE, we follow the setting of RoBERTa (Liu et al., 2019) to omit the next sentence prediction (NSP) objective since previous works have shown that NSP objective can hurt the performance on the downstream tasks (Liu et al.",
      "startOffset" : 59,
      "endOffset" : 77
    }, {
      "referenceID" : 23,
      "context" : ", 2019) to omit the next sentence prediction (NSP) objective since previous works have shown that NSP objective can hurt the performance on the downstream tasks (Liu et al., 2019; Joshi et al., 2020).",
      "startOffset" : 161,
      "endOffset" : 199
    }, {
      "referenceID" : 16,
      "context" : ", 2019) to omit the next sentence prediction (NSP) objective since previous works have shown that NSP objective can hurt the performance on the downstream tasks (Liu et al., 2019; Joshi et al., 2020).",
      "startOffset" : 161,
      "endOffset" : 199
    }, {
      "referenceID" : 43,
      "context" : "Our model is pre-trained on a combination of BookCorpus (Zhu et al., 2015) and English Wikipedia datasets, the data BERT used for pre-training.",
      "startOffset" : 56,
      "endOffset" : 74
    }, {
      "referenceID" : 26,
      "context" : "• IMDB (Maas et al., 2011) is a sentiment analysis dataset and the task is to predict the sentiment (positive or negative) of a movie review.",
      "startOffset" : 7,
      "endOffset" : 26
    }, {
      "referenceID" : 3,
      "context" : "• PERSPECTRUM (Chen et al., 2019) is a natural language inference dataset to predict whether a relevant perspective is for/against the given claim.",
      "startOffset" : 14,
      "endOffset" : 33
    }, {
      "referenceID" : 5,
      "context" : "• BoolQ (Clark et al., 2019) is a dataset of reading comprehension instances with boolean",
      "startOffset" : 8,
      "endOffset" : 28
    }, {
      "referenceID" : 41,
      "context" : "• AG (Zhang et al., 2015) is a sentencelevel classification with regard to four news topics: World, Sports, Business, and Science/Technology.",
      "startOffset" : 5,
      "endOffset" : 25
    }, {
      "referenceID" : 31,
      "context" : "• MR (Pang and Lee, 2005) is a sentence-level sentiment classification on positive and negative movie reviews.",
      "startOffset" : 5,
      "endOffset" : 25
    }, {
      "referenceID" : 15,
      "context" : "Instead of using an adversarial attacker to attack the model, we use the adversarial examples generated by TextFooler (Jin et al., 2020) as a benchmark to evaluate the performance against adversarial examples.",
      "startOffset" : 118,
      "endOffset" : 136
    }, {
      "referenceID" : 3,
      "context" : "To further analyze the effectiveness of different factors of our CLINE, we choose PERSPECTRUM (Chen et al., 2019) and BoolQ (Clark et al.",
      "startOffset" : 94,
      "endOffset" : 113
    }, {
      "referenceID" : 5,
      "context" : ", 2019) and BoolQ (Clark et al., 2019) as benchmark datasets and report the ablation test in terms of 1) w/o RTD: we remove the replaced token detection objective (LRTD) in our model to verify whether our model mainly benefits from the",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 31,
      "context" : "To evaluate the semantic sensitivity of the models, we generate 9626 sentence triplets from a sentencelevel sentiment analysis dataset MR (Pang and Lee, 2005).",
      "startOffset" : 138,
      "endOffset" : 158
    }, {
      "referenceID" : 28,
      "context" : "We generate xsyn/xant by replacing a word in xori with its synonym/antonym from WordNet (Miller, 1995).",
      "startOffset" : 88,
      "endOffset" : 102
    }, {
      "referenceID" : 40,
      "context" : "we also use a SOTA algorithm, BertScore (Zhang et al., 2020) to compute similarity scores of sentence pairs.",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 33,
      "context" : "We can observe: 1) In the BERT model, using the [CLS] token as sentence representation achieves worse results than mean-pooling, which shows the same conclusion as Sentence-BERT (Reimers and Gurevych, 2019).",
      "startOffset" : 178,
      "endOffset" : 206
    }, {
      "referenceID" : 32,
      "context" : "Two main research directions of PLMs are autoregressive (AR) pre-training (such as GPT (Radford et al., 2018)) and denoising autoencoding (DAE) pre-training (such as BERT (Devlin et al.",
      "startOffset" : 87,
      "endOffset" : 109
    }, {
      "referenceID" : 6,
      "context" : ", 2018)) and denoising autoencoding (DAE) pre-training (such as BERT (Devlin et al., 2019)).",
      "startOffset" : 69,
      "endOffset" : 90
    }, {
      "referenceID" : 36,
      "context" : "Contrastive learning is an unsupervised representation learning method, which has been widely used in learning graph representations (Velickovic et al., 2019), visual representations (van den Oord et al.",
      "startOffset" : 133,
      "endOffset" : 158
    }, {
      "referenceID" : 22,
      "context" : ", 2020), response representations (Lin et al., 2020b; Su et al., 2020), text representations (Iter et al.",
      "startOffset" : 34,
      "endOffset" : 70
    }, {
      "referenceID" : 34,
      "context" : ", 2020), response representations (Lin et al., 2020b; Su et al., 2020), text representations (Iter et al.",
      "startOffset" : 34,
      "endOffset" : 70
    }, {
      "referenceID" : 12,
      "context" : ", 2020), text representations (Iter et al., 2020; Ding et al., 2021) and structured world models (Kipf et al.",
      "startOffset" : 30,
      "endOffset" : 68
    }, {
      "referenceID" : 7,
      "context" : ", 2020), text representations (Iter et al., 2020; Ding et al., 2021) and structured world models (Kipf et al.",
      "startOffset" : 30,
      "endOffset" : 68
    }, {
      "referenceID" : 18,
      "context" : ", 2021) and structured world models (Kipf et al., 2020).",
      "startOffset" : 36,
      "endOffset" : 55
    } ],
    "year" : 2021,
    "abstractText" : "Despite pre-trained language models have proven useful for learning high-quality semantic representations, these models are still vulnerable to simple perturbations. Recent works aimed to improve the robustness of pre-trained models mainly focus on adversarial training from perturbed examples with similar semantics, neglecting the utilization of different or even opposite semantics. Different from the image processing field, the text is discrete and few word substitutions can cause significant semantic changes. To study the impact of semantics caused by small perturbations, we conduct a series of pilot experiments and surprisingly find that adversarial training is useless or even harmful for the model to detect these semantic changes. To address this problem, we propose Contrastive Learning with semantIc Negative Examples (CLINE), which constructs semantic negative examples unsupervised to improve the robustness under semantically adversarial attacking. By comparing with similar and opposite semantic examples, the model can effectively perceive the semantic changes caused by small perturbations. Empirical results show that our approach yields substantial improvements on a range of sentiment analysis, reasoning, and reading comprehension tasks. And CLINE also ensures the compactness within the same semantics and separability across different semantics in sentence-level.",
    "creator" : "LaTeX with hyperref"
  }
}