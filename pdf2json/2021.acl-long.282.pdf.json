{
  "name" : "2021.acl-long.282.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Measuring Fine-Grained Domain Relevance of Terms: A Hierarchical Core-Fringe Approach",
    "authors" : [ "Jie Huang", "Kevin Chen-Chuan", "Chang Jinjun Xiong", "Wen-mei Hwu" ],
    "emails" : [ "w-hwu}@illinois.edu", "jinjun@us.ibm.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 3641–3651\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n3641"
    }, {
      "heading" : "1 Introduction",
      "text" : "With countless terms in human languages, no one can know all terms, especially those belonging to a technical domain. Even for domain experts, it is quite challenging to identify all terms in the domains they are specialized in. However, recognizing and understanding domain-relevant terms is the basis to master domain knowledge. And having a sense of domains that terms are relevant to is an initial and crucial step for term understanding.\nIn this paper, as our problem, we propose to measure fine-grained domain relevance, which is defined as the degree that a term is relevant to a\n1The code and data, along with several term lists with domain relevance scores produced by our methods are available at https://github.com/jeffhj/ domain-relevance.\ngiven domain, and the given domain can be broad or narrow– an important property of terms that has not been carefully studied before. E.g., deep learning is a term relevant to the domains of computer science and, more specifically, machine learning, but not so much to others like database or compiler. Thus, it has a high domain relevance for the former domains but a low one for the latter. From another perspective, we propose to decouple extraction and evaluation in automatic term extraction that aims to extract domain-specific terms from texts (Amjadian et al., 2018; Hätty et al., 2020). This decoupling setting is novel and useful because it is not limited to broad domains where a domain-specific corpus is available, and also does not require terms must appear in the corpus.\nA good command of domain relevance of terms will facilitate many downstream applications. E.g., to build a domain taxonomy or ontology, a crucial step is to acquire relevant terms (Al-Aswadi et al., 2019; Shang et al., 2020). Also, it can provide or filter necessary candidate terms for domain-focused natural language tasks (Huang et al., 2020). In addition, for text classification and recommendation, the domain relevance of a document can be measured by that of its terms.\nWe aim to measure fine-grained domain relevance as a semantic property of any term in human languages. Therefore, to be practical, the proposed model for domain relevance measuring must meet the following requirements: 1) covering almost all terms in human languages; 2) applying to a wide range of broad and narrow domains; and 3) relying on little or no human annotation.\nHowever, among countless terms, only some of them are popular ones organized and associated with rich information on the Web, e.g., Wikipedia pages, which we can leverage to characterize the domain relevance of such “head terms.” In contrast, there are numerous “long-tail terms”– those not as\nfrequently used– which lack descriptive information. As Challenge 1, how to measure the domain relevance for such long-tail terms?\nOn the other hand, among possible domains of interest, only those broad ones (e.g., physics, computer science) naturally have domain-specific corpora. Many existing works (Velardi et al., 2001; Amjadian et al., 2018; Hätty et al., 2020) have relied on such domain-specific corpora to identify domain-specific terms by contrasting their distributions to general ones. In contrast, those fine-grained domains (e.g., quantum mechanics, deep learning)– which can be any topics of interest– do not usually have a matching corpus. As Challenge 2, how to achieve good performance for a fine-grained domain without assuming a domain-specific corpus?\nFinally, automatic learning usually requires large amounts of training data. Since there are countless terms and plentiful domains, human annotation is very time-consuming and laborious. As Challenge 3, how to reduce expensive human efforts when applying machine learning methods to our problem?\nAs our solutions, we propose a hierarchical corefringe domain relevance learning approach that addresses these challenges. First, to deal with longtail terms, we design the core-anchored semantic graph, which includes core terms which have rich description and fringe terms without that information. Based on this graph, we can bridge the domain relevance through term relevance and include any term in evaluation. Second, to leverage the graph and support fine-grained domains without relying on domain-specific corpora, we propose hierarchical core-fringe learning, which learns the domain relevance of core and fringe terms jointly in a semi-supervised manner contextualized in the hierarchy of the domain. Third, to reduce human effort, we employ automatic annotation and hierarchical positive-unlabeled learning, which allow to train our model with little even no human effort.\nOverall, our framework consists of two processes: 1) the offline construction process, where a domain relevance measuring model is trained by taking a large set of seed terms and their features as input; 2) the online query process, where the trained model can return the domain relevance of query terms by including them in the core-anchored semantic graph. Our approach applies to a wide range of domains and can handle any query, while nearly no human effort is required. To validate the effectiveness of our proposed methods, we conduct\nextensive experiments on various domains with different settings. Results show our methods significantly outperform well-designed baselines and even surpass human performance by professionals."
    }, {
      "heading" : "2 Related Work",
      "text" : "The problem of domain relevance of terms is related to automatic term extraction, which aims to extract domain-specific terms from texts automatically. Compared to our task, automatic term extraction, where extraction and evaluation are combined, possesses a limited application and has a relatively large dependence on corpora and human annotation, so it is limited to several broad domains and may only cover a small number of terms. Existing approaches for automatic term extraction can be roughly divided into three categories: linguistic, statistical, and machine learning methods. Linguistic methods apply human-designed rules to identify technical/legal terms in a target corpus (Handler et al., 2016; Ha and Hyland, 2017). Statistical methods use statistical information, e.g., frequency of terms, to identify terms from a corpus (Frantzi et al., 2000; Nakagawa and Mori, 2002; Velardi et al., 2001; Drouin, 2003; Meijer et al., 2014). Machine learning methods learn a classifier, e.g., logistic regression classifier, with manually labeled data (Conrado et al., 2013; Fedorenko et al., 2014; Hätty et al., 2017). There also exists some work on automatic term extraction with Wikipedia (Vivaldi et al., 2012; Wu et al., 2012). However, terms studied there are restricted to terms associated with a Wikipedia page.\nRecently, inspired by distributed representations of words (Mikolov et al., 2013a), methods based on deep learning are proposed and achieve state-ofthe-art performance. Amjadian et al. (2016, 2018) design supervised learning methods by taking the concatenation of domain-specific and general word embeddings as input. Hätty et al. (2020) propose a multi-channel neural network model that leverages domain-specific and general word embeddings.\nThe techniques behind our hierarchical corefringe learning methods are related to research on graph neural networks (GNNs) (Kipf and Welling, 2017; Hamilton et al., 2017); hierarchical text classification (Vens et al., 2008; Wehrmann et al., 2018; Zhou et al., 2020); and positive-unlabeled learning (Liu et al., 2003; Elkan and Noto, 2008; Bekker and Davis, 2020)."
    }, {
      "heading" : "3 Methodology",
      "text" : "We study the Fine-Grained Domain Relevance of terms, which is defined as follows:\nDefinition 1 (Fine-Grained Domain Relevance) The fine-grained domain relevance of a term is the degree that the term is relevant to a given domain, and the given domain can be broad or narrow.\nThe domain relevance of terms depends on many factors. In general, a term with higher semantic relevance, broader meaning scope, and better usage possesses a higher domain relevance regarding the target domain. To measure the fine-grained domain relevance of terms, we propose a hierarchical corefringe approach, which includes an offline training process and can handle any query term in evaluation. The overview of the framework is illustrated in Figure 1."
    }, {
      "heading" : "3.1 Core-Anchored Semantic Graph",
      "text" : "There exist countless terms in human languages; thus it is impractical to include all terms in a system initially. To build the offline system, we need to provide seed terms, which can come from knowledge bases or be extracted from broad, large corpora by existing term/phrase extraction methods (Handler et al., 2016; Shang et al., 2018).\nIn addition to providing seed terms, we should also give some knowledge to machines so that they can differentiate whether a term is domain-relevant or not. To this end, we can leverage the description information of terms. For instance, Wikipedia\ncontains a large number of terms (the surface form of page titles), where each term is associated with a Wikipedia article page. With this page information, humans can easily judge whether a term is domain-relevant or not. In Section 3.3, we will show the labeling can even be done completely automatically.\nHowever, considering the countless terms, the number of terms that are well-organized and associated with rich description is small. How to measure the fine-grained domain relevance of terms without rich information is quite challenging for both machines and humans.\nFortunately, terms are not isolated, while complex relations exist between them. If a term is relevant to a domain, it must also be relevant to some domain-relevant terms and vice versa. This is to say, we can bridge the domain relevance of terms through term relevance. Summarizing the observations, we divide terms into two categories: core terms, which are terms associated with rich description information, e.g., Wikipedia article pages, and fringe terms, which are terms without that information. We assume, for each term, there exist some relevant core terms that share similar domains. If we can find the most relevant core terms for a given term, its domain relevance can be evaluated with the help of those terms. To this end, we can utilize the rich information of core terms for ranking.\nTaking Wikipedia as an example, each core term is associated with an article page, so they can\nbe returned as the ranking results (result term) for a given term (query term). Considering the data resources, we use the built-in Elasticsearch based Wikipedia search engine2 (Gormley and Tong, 2015). More specifically, we set the maximum number of links as k (5 as default). For a query term v, i.e., any seed term, we first achieve the top 2k Wikipedia pages with exact match. For each result term u in the core, we create a link from u to v. If the number of links is smaller than k, we do this process again without exact match and build additional links. Finally, we construct a term graph, named Core-Anchored Semantic Graph, where nodes are terms and edges are links between terms.\nIn addition, for terms that are not provided initially, we can also handle them as fringe terms and connect them to core terms in evaluation. In this way, we can include any term in the graph."
    }, {
      "heading" : "3.2 Hierarchical Core-Fringe Learning",
      "text" : "In this section, we aim to design learning methods to learn the fine-grained domain relevance of core and fringe terms jointly. In addition to using the term graph, we can achieve features of both core and fringe terms based on their linguistic and statistical properties (Terryn et al., 2019; Conrado et al., 2013) or distributed representations (Mikolov et al., 2013b; Yu and Dredze, 2015). We assume the labels, i.e., domain-relevant or not, of core terms are available, which can be achieved by an automatic annotation mechanism introduced in Section 3.3.\nAs stated above, if a term is highly relevant to a given domain, it must also be highly relevant to some other terms with a high domain relevance and vice versa. Therefore, to measure the domain relevance of a term, in addition to using its own features, we aggregate its neighbors’ features. Specifically, we propagate the features of terms via the term graph and use the label information of core terms for supervision. In this way, core and fringe terms help each other, and the domain relevance is learned jointly. The propagation process can be achieved by graph convolutions (Hammond et al., 2011). We first apply the vanilla graph convolutional networks (GCNs) (Kipf and Welling, 2017) in our framework. The graph convolution operation (GCNConv) at the l-th layer is formulated as the\n2https://en.wikipedia.org/w/index.php? search\nfollowing aggregation and update process:\nh (l+1) i = φ ( ∑ j∈Ni∪{i} 1 cij W (l)c h (l) j + b (l) c ) , (1)\nwhere Ni is the neighbor set of node i. cij is the normalization constant. h(l)j ∈ Rd\n(l)×1 is the hidden state of node j at the l-th layer, with d(l) being the number of units; h(0)j = xj , which is the feature vector of node j. W (l)c ∈ Rd (l+1)×d(l) is the trainable weight matrix at the l-th layer, and b(l)c is the bias vector. φ(·) is the nonlinearity activation function, e.g., ReLU(·) = max(0, ·).\nSince core terms are labeled as domain-relevant or not, we can use the labels to calculate the loss:\nL = − ∑\ni∈Vcore\n(yi log zi + (1− yi) log(1− zi)),\n(2) where yi is the label of node i regarding the target domain, and zi = σ(hoi ), with h o i being the output of the last GCNConv layer for node i and σ(·) being the sigmoid function. The weights of the model are trained by minimizing the loss. The relative domain relevance is obtained as s = z.\nCombining with the overall framework, we get the first domain relevance measuring model, CFL, i.e., Core-Fringe Domain Relevance Learning.\nCFL is useful to measure the domain relevance for broad domains such as computer science. For domains with relatively narrow scopes, e.g., machine learning, we can also leverage the label information of domains at the higher level of the hierarchy, e.g., CS→ AI→ ML, which is based on the idea that a domain-relevant term regarding the target domain should also be relevant to the parent domain. Inspired by related work on hierarchical multi-label classification (Vens et al., 2008; Wehrmann et al., 2018), we introduce a hierarchical learning method considering both global and local information.\nWe first apply lc GCNConv layers according to Eq. (1) and get the output of the last GCNConv layer, which is h(lc)i . In order not to confuse, we omit the subscript that identifies the node number. For each domain in the hierarchy, we introduce a hierarchical global activation ap. The activation at the (l + 1)-th level of the hierarchy is given as\na(l+1)p = φ(W (l) p [a (l) p ;h (lc)] + b(l)p ), (3)\nwhere [·; ·] indicates the concatenation of two vectors; a(1)p = φ(W (0) p h (lc) + b (0) p ). The global in-\nformation is produced after a fully connected layer:\nzp = σ(W (lp) p a (lp) p + b (lp) p ), (4)\nwhere lp is the total number of hierarchical levels. To achieve the local information for each level of the hierarchy, the model first generates the local hidden state a(l)q by a fully connected layer:\na(l)q = φ(W (l) t a (l) p + b (l) t ). (5)\nThe local information at the l-th level of the hierarchy is then produced as\nz(l)q = σ(W (l) q a (l) q + b (l) q ). (6)\nIn our core-fringe framework, all the core terms are labeled at each level of the hierarchy. Therefore, the loss of hierarchical learning is computed as\nLh = (zp,y(lp)) + lp∑ l=1 (z(l)q ,y (l)), (7)\nwhere y(l) denotes the labels regarding the domain at the l-th level of the hierarchy and (z,y) is the binary cross-entropy loss described in Eq. (2). In testing, The relative domain relevance s is calculated as\ns = α · zp + (1−α) · (z(1)q ◦ z(2)q , ...,z (lp) q ), (8)\nwhere ◦ denotes element-wise multiplication. α is a hyperparameter to balance the global and local information (0.5 as default). Combining with our general framework, we refer to this model as HiCFL, i.e., Hierarchical CFL.\nOnline Query Process. If seed terms are provided by extracting from broad, large corpora relevant to the target domain, most terms of interest will be already included in the offline process. In evaluation, for terms that are not provided initially, our model treats them as fringe terms. Specifically, when receiving such a term, the model connects it to core terms by the method described in Section 3.1. With its features (e.g., compositional term embeddings) or only its neighbors’ features (when features cannot be generated directly), the trained model can return the domain relevance of any query."
    }, {
      "heading" : "3.3 Automatic Annotation and Hierarchical Positive-Unlabeled Learning",
      "text" : "Automatic Annotation. For the fine-grained domain relevance problem, human annotation is very\ntime-consuming and laborious because the number of core terms is very large regarding a wide range of domains. Fortunately, in addition to building the term graph, we can also leverage the rich information of core terms for automatic annotation.\nIn the core-anchored semantic graph constructed with Wikipedia, each core term is associated with a Wikipedia page, and each page is assigned one or more categories. All the categories form a hierarchy, furthermore providing a category tree. For a given domain, we can first traverse from a root category and collect some gold subcategories. For instance, for computer science, we treat category: subfields of computer science3 as the root category and take categories at the first three levels of it as gold subcategories. Then we collect categories for each core term and examine whether the term itself or one of the categories is a gold subcategory. If so, we label the term as positive. Otherwise, we label it as negative. We can also combine gold subcategories from some existing domain taxonomies and extract the categories of core terms from the text description, which usually contains useful text patterns like “x is a subfield of y”.\nHierarchical Positive-Unlabeled Learning. According to the above methods, we can learn the finegrained domain relevance of terms for any domain as long as we can collect enough gold subcategories for that domain. However, for domains at the low level of the hierarchy, e.g., deep learning, a category tree might not be available in Wikipedia. To deal with this issue, we apply our learning methods in a positive-unlabeled (PU) setting (Bekker and Davis, 2020), where only a small number of terms, e.g., 10, are labeled as positive, and all the other terms are unlabeled. We use this setting based on the following consideration: if a user is interested in a specific domain, it is quite easy for her to give some important terms relevant to that domain.\nBenefiting from our hierarchical core-fringe learning approach, we can still obtain labels for domains at the high level of the hierarchy with the automatic annotation mechanism. Therefore, all the negative examples of the last labeled hierarchy can be used as reliable negatives for the target domain. For instance, if the target domain is deep learning, which is in the CS→ AI→ ML→ DL hierarchy, we consider all the non-ML terms as the reliable negatives for DL. Taking the positively\n3https://en.wikipedia.org/wiki/ Category:Subfields_of_computer_science\nlabeled examples and the reliable negatives for supervision, we can learn the domain relevance of terms by our proposed HiCFL model contextualized in the hierarchy of the domain."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we evaluate our model from different perspectives. 1) We compare with baselines by treating some labeled terms as queries. 2) We compare with human professionals by letting humans and machines judge which term in a query pair is more relevant to a target domain. 3) We conduct intuitive case studies by ranking terms according to their domain relevance."
    }, {
      "heading" : "4.1 Experimental Setup",
      "text" : "Datasets and Preprocessing. To build the system, for offline processing, we extract seed terms from the arXiv dataset (version 6)4. As an example, for computer science or its sub-domains, we collect the abstracts in computer science according to the arXiv Category Taxonomy5, and apply phrasemachine to extract terms (Handler et al., 2016) with lemmatization and several filtering rules: frequency > 10; length ≤ 6; only contain letters, numbers, and hyphen; not a stopword or a single letter.\nWe select three broad domains, including computer science (CS), physics (Phy), and mathematics (Math); and three narrow sub-domains of them, including machine learning (ML), quantum mechanics (QM), and abstract algebra (AA), with the hierarchies CS→ AI→ML, Phy→ mechanics→ QM, and Math→ algebra→ AA. Each broad domain and its sub-domains share seed terms because they share a corpus. To achieve gold subcategories for automatic annotation (Section 3.3), we collect subcategories at the first three levels of a root category (e.g., category: subfields of physics) for broad domains (e.g., physics); or the first two levels for narrow domains, e.g., category: machine learning for machine learning. Table 1 reports the total sizes and the ratios that are core terms.\nBaselines. Since our task on fine-grained domain relevance is new, there is no existing baseline for model comparison. We adapt the following models on relevant tasks in our setting with additional inputs (e.g., domain-specific corpora):\n4https://www.kaggle.com/ Cornell-University/arxiv\n5https://arxiv.org/category_taxonomy\n• Relative Domain Frequency (RDF): Since domain-relevant terms usually occur more in a domain-specific corpus, we apply a statistical method using freqs(w)/freqg(w) to measure the domain relevance of term w, where freqs(·) and freqg(·) denote the frequency of occurrence in the domain-specific/general corpora respectively. • Logistic Regression (LR): Logistic regression is a standard supervised learning method. We use core terms with labels (domain-relevant or not) as training data, where features are term embeddings trained by a general corpus. • Multilayer Perceptron (MLP): MLP is a standard neural neural-based model. We train MLP using embeddings trained with a domain-specific corpus or a general corpus as term features, respectively. We also concatenate the two embeddings as features (Amjadian et al., 2016, 2018). • Multi-Channel (MC): Multi-Channel (Hätty et al., 2020) is the state-of-the-art model for automatic term extraction, which is based on a multi-channel neural network that takes domainspecific and general corpora as input.\nTraining. For all supervised learning methods, we apply automatic annotation in Section 3.3, i.e., we automatically label all the core terms for model training. In the PU setting, we remove labels on target domains. Only 20 (10 in the case studies) domain-relevant core terms are randomly selected as the positives, with the remaining terms unlabeled. In training, all the negative examples at the previous level of the hierarchy are used as reliable negatives.\nImplementation Details. Though our proposed methods are independent of corpora, some baselines (e.g., MC) require term embeddings trained from general/domain-specific corpora. For easy and fair comparison, we adopt the following approach to generate term features. We consider each term as a single token, and apply word2vec CBOW (Mikolov et al., 2013a) with negative sampling, where dimensionality is 100, window size is 5, and number of negative samples is 5. The training cor-\npus can be a general one (the entire arXiv corpus, denoted as G), or a domain-specific one (the subcorpus in the branch of the corresponding domain, denoted as S). We also apply compositional GloVe embeddings (Pennington et al., 2014) (elementwise addition of the pre-trained 100d word embeddings, denoted as C) as non-corpus-specific features of terms for reference.\nFor all the neural network-based models, we use Adam (Kingma and Ba, 2015) with learning rate of 0.01 for optimization, and adopt a fixed hidden dimensionality of 256 and a fixed dropout ratio of 0.5. For the learning part of CFL and HiCFL, we apply two GCNConv layers and use the symmetric graph for training. To avoid overfitting, we adopt batch normalization (Ioffe and Szegedy, 2015) right after each layer (except for the output layer) and before activation and apply dropout (Hinton et al., 2012) after the activation. We also try to add regularizations for MLP and MC with full-batch or mini-batch training, and select the best architecture. To construct the core-anchored semantic graph, we set k as 5. All experiments are run on an NVIDIA Quadro RTX 5000 with 16GB of memory under the PyTorch framework. The training of CFL for the CS domain can finish in 1 minute.\nWe report the mean and standard deviation of the test results corresponding to the best validation results with 5 different random seeds."
    }, {
      "heading" : "4.2 Comparison to Baselines",
      "text" : "To compare with baselines, we separate a portion of core terms as queries for evaluation. Specifically, for each domain, we use 80% labeled terms for training, 10% for validation, and 10% for testing\n(with automatic annotation). Terms in the validation and testing sets are treated as fringe terms. By doing this, the evaluation can represent the general performance for all fringe terms to some extent. And the model comparison is fair since the rich information of terms for evaluation is not used in training. We also create a test set with careful human annotation on machine learning to support our overall evaluation, which contains 2000 terms, with half for evaluation and half for testing.\nAs evaluation metrics, we calculate both ROCAUC and PR-AUC with automatic or manually created labels. ROC-AUC is the area under the receiver operating characteristic curve, and PR-AUC is the area under the precision-recall curve. If a model achieves higher values, most of the domainrelevant terms are ranked higher, which means the model has a better measurement on the domain relevance of terms.\nTable 2 and Table 3 show the results for three broad/narrow domains respectively. We observe our proposed CFL and HiCFL outperform all the baselines, and the standard deviations are low. Compared to MLP, CFL achieves much better performance benefiting from the core-anchored semantic graph and feature aggregation, which demonstrates the domain relevance can be bridged via term relevance. Compared to CFL, HiCFL works better owing to hierarchical learning.\nIn the PU setting– the situation when automatic annotation is not applied to the target domain, although only 20 positives are given, HiCFL still achieves satisfactory performance and significantly outperforms all the baselines (Table 4).\nThe PR-AUC scores on the manually created test\nset without and with the PU setting are reported in Table 5. We observe that the results are generally consistent with results reported in Table 3 and Table 4, which indicates the evaluation with core terms can work just as well."
    }, {
      "heading" : "4.3 Comparison to Human Performance",
      "text" : "In this section, we aim to compare our model with human professionals in measuring the fine-grained domain relevance of terms. Because it is difficult for humans to assign a score representing do-\nmain relevance directly, we generate term pairs as queries and let humans judge which one in a pair is more relevant to machine learning. Specifically, we create 100 ML-AI, ML-CS, and AI-CS pairs respectively. Taking ML-AI as an example, each query pair consists of an ML term and an AI term, and the judgment is considered right if the ML term is selected.\nThe human annotation is conducted by five senior students majoring in computer science and doing research related to terminology. Because there is no clear boundary between ML, AI, and CS, it is possible that a CS term is more relevant to machine learning than an AI term. However, the overall trend is that the higher the accuracy, the better the performance. From Table 6, we observe that HiCFL far outperforms human performance.\nAlthough we have reduced the difficulty, the task is still very challenging for human professionals."
    }, {
      "heading" : "4.4 Case Studies",
      "text" : "We interpret our results by ranking terms according to their domain relevance regarding machine learning or deep learning, with hierarchy CS → AI→ML→ DL. For CS-ML, we label terms with automatic annotation. For DL, we create 10 DL terms manually as the positives for PU learning.\nTable 7 and Table 8 show the ranking results (1-10 represents terms ranked 1st to 10th). We observe the performance is satisfactory. For ML, important concepts such as supervised learning, unsupervised learning, and deep learning are ranked very high. Also, terms ranked before 1010th are all good domain-relevant terms. For DL, although only 10 positives are provided, the ranking results are quite impressive. E.g., unlabeled positive terms like artificial neural network, generative adversarial network, and neural architecture search are ranked very high. Besides, terms ranked 101st to 110th are all highly relevant to DL, and terms ranked 1001st to 1010th are related to ML."
    }, {
      "heading" : "5 Conclusion",
      "text" : "We introduce and study the fine-grained domain relevance of terms– an important property of terms that has not been carefully studied before. We\npropose a hierarchical core-fringe domain relevance learning approach, which can cover almost all terms in human languages and various domains, while requires little or even no human annotation.\nWe believe this work will inspire an automated solution for knowledge management and help a wide range of downstream applications in natural language processing. It is also interesting to integrate our methods to more challenging tasks, for example, to characterize more complex properties of terms even understand terms."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank the anonymous reviewers for their valuable comments and suggestions. This material is based upon work supported by the National Science Foundation IIS 16-19302 and IIS 16-33755, Zhejiang University ZJU Research 083650, IBMIllinois Center for Cognitive Computing Systems Research (C3SR) - a research collaboration as part of the IBM Cognitive Horizon Network, grants from eBay and Microsoft Azure, UIUC OVCR CCIL Planning Grant 434S34, UIUC CSBS Small Grant 434C8U, and UIUC New Frontiers Initiative. Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the author(s) and do not necessarily reflect the views of the funding agencies."
    } ],
    "references" : [ {
      "title" : "Automatic ontology construction from text: a review from shallow to deep learning trend",
      "author" : [ "Fatima N Al-Aswadi", "Huah Yong Chan", "Keng Hoon Gan." ],
      "venue" : "Artificial Intelligence Review, pages 1–28.",
      "citeRegEx" : "Al.Aswadi et al\\.,? 2019",
      "shortCiteRegEx" : "Al.Aswadi et al\\.",
      "year" : 2019
    }, {
      "title" : "Distributed specificity for automatic terminology extraction",
      "author" : [ "Ehsan Amjadian", "Diana Inkpen", "T Sima Paribakht", "Farahnaz Faez." ],
      "venue" : "Terminology. International Journal of Theoretical and Applied Issues in Specialized Communication, 24(1):23–40.",
      "citeRegEx" : "Amjadian et al\\.,? 2018",
      "shortCiteRegEx" : "Amjadian et al\\.",
      "year" : 2018
    }, {
      "title" : "Local-global vectors to improve unigram terminology extraction",
      "author" : [ "Ehsan Amjadian", "Diana Inkpen", "Tahereh Paribakht", "Farahnaz Faez." ],
      "venue" : "Proceedings of the 5th International Workshop on Computational Terminology, pages 2–11.",
      "citeRegEx" : "Amjadian et al\\.,? 2016",
      "shortCiteRegEx" : "Amjadian et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning from positive and unlabeled data: a survey",
      "author" : [ "Jessa Bekker", "Jesse Davis." ],
      "venue" : "Mach. Learn., 109(4):719–760.",
      "citeRegEx" : "Bekker and Davis.,? 2020",
      "shortCiteRegEx" : "Bekker and Davis.",
      "year" : 2020
    }, {
      "title" : "A machine learning approach to automatic term extraction using a rich feature set",
      "author" : [ "Merley Conrado", "Thiago Pardo", "Solange Oliveira Rezende." ],
      "venue" : "Proceedings of the 2013 NAACL HLT Student Research Workshop, pages 16–23.",
      "citeRegEx" : "Conrado et al\\.,? 2013",
      "shortCiteRegEx" : "Conrado et al\\.",
      "year" : 2013
    }, {
      "title" : "Term extraction using nontechnical corpora as a point of leverage",
      "author" : [ "Patrick Drouin." ],
      "venue" : "Terminology, 9(1):99–115.",
      "citeRegEx" : "Drouin.,? 2003",
      "shortCiteRegEx" : "Drouin.",
      "year" : 2003
    }, {
      "title" : "Learning classifiers from only positive and unlabeled data",
      "author" : [ "Charles Elkan", "Keith Noto." ],
      "venue" : "Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 213–220.",
      "citeRegEx" : "Elkan and Noto.,? 2008",
      "shortCiteRegEx" : "Elkan and Noto.",
      "year" : 2008
    }, {
      "title" : "Automatic recognition of domain-specific terms: an experimental evaluation",
      "author" : [ "Denis Fedorenko", "N Astrakhantsev", "D Turdakov." ],
      "venue" : "Proceedings of the Institute for System Programming, 26(4):55–72.",
      "citeRegEx" : "Fedorenko et al\\.,? 2014",
      "shortCiteRegEx" : "Fedorenko et al\\.",
      "year" : 2014
    }, {
      "title" : "Automatic recognition of multi-word terms",
      "author" : [ "Katerina Frantzi", "Sophia Ananiadou", "Hideki Mima." ],
      "venue" : "the c-value/nc-value method. International journal on digital libraries, 3(2):115–130.",
      "citeRegEx" : "Frantzi et al\\.,? 2000",
      "shortCiteRegEx" : "Frantzi et al\\.",
      "year" : 2000
    }, {
      "title" : "Elasticsearch: the definitive guide: a distributed real-time search and analytics engine",
      "author" : [ "Clinton Gormley", "Zachary Tong." ],
      "venue" : "” O’Reilly Media, Inc.”.",
      "citeRegEx" : "Gormley and Tong.,? 2015",
      "shortCiteRegEx" : "Gormley and Tong.",
      "year" : 2015
    }, {
      "title" : "What is technicality? a technicality analysis model for eap vocabulary",
      "author" : [ "Althea Ying Ho Ha", "Ken Hyland." ],
      "venue" : "Journal of English for Academic Purposes, 28:35–49.",
      "citeRegEx" : "Ha and Hyland.,? 2017",
      "shortCiteRegEx" : "Ha and Hyland.",
      "year" : 2017
    }, {
      "title" : "Inductive representation learning on large graphs",
      "author" : [ "William L Hamilton", "Rex Ying", "Jure Leskovec." ],
      "venue" : "Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 1025–1035.",
      "citeRegEx" : "Hamilton et al\\.,? 2017",
      "shortCiteRegEx" : "Hamilton et al\\.",
      "year" : 2017
    }, {
      "title" : "Wavelets on graphs via spectral graph theory",
      "author" : [ "David K Hammond", "Pierre Vandergheynst", "Rémi Gribonval." ],
      "venue" : "Applied and Computational Harmonic Analysis, 30(2):129–150.",
      "citeRegEx" : "Hammond et al\\.,? 2011",
      "shortCiteRegEx" : "Hammond et al\\.",
      "year" : 2011
    }, {
      "title" : "Bag of what? simple noun phrase extraction for text analysis",
      "author" : [ "Abram Handler", "Matthew Denny", "Hanna Wallach", "Brendan O’Connor" ],
      "venue" : "In Proceedings of the First Workshop on NLP and Computational Social Science,",
      "citeRegEx" : "Handler et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Handler et al\\.",
      "year" : 2016
    }, {
      "title" : "Evaluating the reliability and interaction of recursively used feature classes for terminology extraction",
      "author" : [ "Anna Hätty", "Michael Dorna", "Sabine Schulte im Walde." ],
      "venue" : "Proceedings of the student research workshop at the 15th conference of the Eu-",
      "citeRegEx" : "Hätty et al\\.,? 2017",
      "shortCiteRegEx" : "Hätty et al\\.",
      "year" : 2017
    }, {
      "title" : "Predicting degrees of technicality in automatic terminology extraction",
      "author" : [ "Anna Hätty", "Dominik Schlechtweg", "Michael Dorna", "Sabine Schulte im Walde." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Hätty et al\\.,? 2020",
      "shortCiteRegEx" : "Hätty et al\\.",
      "year" : 2020
    }, {
      "title" : "Improving neural networks by preventing coadaptation of feature detectors",
      "author" : [ "Geoffrey E Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov." ],
      "venue" : "arXiv preprint arXiv:1207.0580.",
      "citeRegEx" : "Hinton et al\\.,? 2012",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2012
    }, {
      "title" : "Exploring semantic capacity of terms",
      "author" : [ "Jie Huang", "Zilong Wang", "Kevin Chen-Chuan Chang", "Wen-mei Hwu", "Jinjun Xiong." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing.",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "Batch normalization: Accelerating deep network training by reducing internal covariate shift",
      "author" : [ "Sergey Ioffe", "Christian Szegedy." ],
      "venue" : "International Conference on Machine Learning, pages 448–456.",
      "citeRegEx" : "Ioffe and Szegedy.,? 2015",
      "shortCiteRegEx" : "Ioffe and Szegedy.",
      "year" : 2015
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "Proceedings of the 3rd International Conference on Learning Representations.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Semisupervised classification with graph convolutional networks",
      "author" : [ "Thomas N. Kipf", "Max Welling." ],
      "venue" : "Proceedings of International Conference on Learning Representations.",
      "citeRegEx" : "Kipf and Welling.,? 2017",
      "shortCiteRegEx" : "Kipf and Welling.",
      "year" : 2017
    }, {
      "title" : "Building text classifiers using positive and unlabeled examples",
      "author" : [ "Bing Liu", "Yang Dai", "Xiaoli Li", "Wee Sun Lee", "Philip S Yu." ],
      "venue" : "Third IEEE International Conference on Data Mining, pages 179– 186. IEEE.",
      "citeRegEx" : "Liu et al\\.,? 2003",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2003
    }, {
      "title" : "A semantic approach for extracting domain taxonomies from text",
      "author" : [ "Kevin Meijer", "Flavius Frasincar", "Frederik Hogenboom." ],
      "venue" : "Decision Support Systems, 62:78–93.",
      "citeRegEx" : "Meijer et al\\.,? 2014",
      "shortCiteRegEx" : "Meijer et al\\.",
      "year" : 2014
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "arXiv preprint arXiv:1301.3781.",
      "citeRegEx" : "Mikolov et al\\.,? 2013a",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean." ],
      "venue" : "Advances in neural information processing systems, pages 3111–3119.",
      "citeRegEx" : "Mikolov et al\\.,? 2013b",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "A simple but powerful automatic term extraction method",
      "author" : [ "Hiroshi Nakagawa", "Tatsunori Mori." ],
      "venue" : "COLING-02: COMPUTERM 2002: Second International Workshop on Computational Terminology.",
      "citeRegEx" : "Nakagawa and Mori.,? 2002",
      "shortCiteRegEx" : "Nakagawa and Mori.",
      "year" : 2002
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D Manning." ],
      "venue" : "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Taxonomy construction of unseen domains via graph-based cross-domain knowledge transfer",
      "author" : [ "Chao Shang", "Sarthak Dash", "Md Faisal Mahbub Chowdhury", "Nandana Mihindukulasooriya", "Alfio Gliozzo." ],
      "venue" : "Proceedings of the 58th Annual",
      "citeRegEx" : "Shang et al\\.,? 2020",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2020
    }, {
      "title" : "Automated phrase mining from massive text corpora",
      "author" : [ "Jingbo Shang", "Jialu Liu", "Meng Jiang", "Xiang Ren", "Clare R Voss", "Jiawei Han." ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering, 30(10):1825–1837.",
      "citeRegEx" : "Shang et al\\.,? 2018",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2018
    }, {
      "title" : "In no uncertain terms: a dataset for monolingual and multilingual automatic term extraction from comparable corpora",
      "author" : [ "Ayla Rigouts Terryn", "Véronique Hoste", "Els Lefever." ],
      "venue" : "Language Resources and Evaluation, pages 1–34.",
      "citeRegEx" : "Terryn et al\\.,? 2019",
      "shortCiteRegEx" : "Terryn et al\\.",
      "year" : 2019
    }, {
      "title" : "Identification of relevant terms to support the construction of domain ontologies",
      "author" : [ "Paola Velardi", "Michele Missikoff", "Roberto Basili." ],
      "venue" : "Proceedings of the ACL 2001 Workshop on Human Language Technology and Knowledge Management.",
      "citeRegEx" : "Velardi et al\\.,? 2001",
      "shortCiteRegEx" : "Velardi et al\\.",
      "year" : 2001
    }, {
      "title" : "Decision trees for hierarchical multi-label classification",
      "author" : [ "Celine Vens", "Jan Struyf", "Leander Schietgat", "Sašo Džeroski", "Hendrik Blockeel." ],
      "venue" : "Machine learning, 73(2):185.",
      "citeRegEx" : "Vens et al\\.,? 2008",
      "shortCiteRegEx" : "Vens et al\\.",
      "year" : 2008
    }, {
      "title" : "Using wikipedia to validate the terminology found in a corpus of basic textbooks",
      "author" : [ "Jorge Vivaldi", "Luis Adrián Cabrera-Diego", "Gerardo Sierra", "Marı́a Pozzi" ],
      "venue" : "In LREC,",
      "citeRegEx" : "Vivaldi et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Vivaldi et al\\.",
      "year" : 2012
    }, {
      "title" : "Hierarchical multi-label classification networks",
      "author" : [ "Jonatas Wehrmann", "Ricardo Cerri", "Rodrigo Barros." ],
      "venue" : "International Conference on Machine Learning, pages 5075–5084.",
      "citeRegEx" : "Wehrmann et al\\.,? 2018",
      "shortCiteRegEx" : "Wehrmann et al\\.",
      "year" : 2018
    }, {
      "title" : "Extracting domain-relevant term using wikipedia based on random walk model",
      "author" : [ "Wenjuan Wu", "Tao Liu", "He Hu", "Xiaoyong Du." ],
      "venue" : "2012 Seventh ChinaGrid Annual Conference, pages 68–75. IEEE.",
      "citeRegEx" : "Wu et al\\.,? 2012",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2012
    }, {
      "title" : "Learning composition models for phrase embeddings",
      "author" : [ "Mo Yu", "Mark Dredze." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 3:227– 242.",
      "citeRegEx" : "Yu and Dredze.,? 2015",
      "shortCiteRegEx" : "Yu and Dredze.",
      "year" : 2015
    }, {
      "title" : "Hierarchy-aware global model for hierarchical text classification",
      "author" : [ "Jie Zhou", "Chunping Ma", "Dingkun Long", "Guangwei Xu", "Ning Ding", "Haoyu Zhang", "Pengjun Xie", "Gongshen Liu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Zhou et al\\.,? 2020",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "From another perspective, we propose to decouple extraction and evaluation in automatic term extraction that aims to extract domain-specific terms from texts (Amjadian et al., 2018; Hätty et al., 2020).",
      "startOffset" : 158,
      "endOffset" : 201
    }, {
      "referenceID" : 15,
      "context" : "From another perspective, we propose to decouple extraction and evaluation in automatic term extraction that aims to extract domain-specific terms from texts (Amjadian et al., 2018; Hätty et al., 2020).",
      "startOffset" : 158,
      "endOffset" : 201
    }, {
      "referenceID" : 0,
      "context" : "step is to acquire relevant terms (Al-Aswadi et al., 2019; Shang et al., 2020).",
      "startOffset" : 34,
      "endOffset" : 78
    }, {
      "referenceID" : 27,
      "context" : "step is to acquire relevant terms (Al-Aswadi et al., 2019; Shang et al., 2020).",
      "startOffset" : 34,
      "endOffset" : 78
    }, {
      "referenceID" : 17,
      "context" : "Also, it can provide or filter necessary candidate terms for domain-focused natural language tasks (Huang et al., 2020).",
      "startOffset" : 99,
      "endOffset" : 119
    }, {
      "referenceID" : 30,
      "context" : "Many existing works (Velardi et al., 2001; Amjadian et al., 2018; Hätty et al., 2020) have relied on such domain-specific corpora to identify domain-specific terms by contrasting their distributions to general ones.",
      "startOffset" : 20,
      "endOffset" : 85
    }, {
      "referenceID" : 1,
      "context" : "Many existing works (Velardi et al., 2001; Amjadian et al., 2018; Hätty et al., 2020) have relied on such domain-specific corpora to identify domain-specific terms by contrasting their distributions to general ones.",
      "startOffset" : 20,
      "endOffset" : 85
    }, {
      "referenceID" : 15,
      "context" : "Many existing works (Velardi et al., 2001; Amjadian et al., 2018; Hätty et al., 2020) have relied on such domain-specific corpora to identify domain-specific terms by contrasting their distributions to general ones.",
      "startOffset" : 20,
      "endOffset" : 85
    }, {
      "referenceID" : 13,
      "context" : "Linguistic methods apply human-designed rules to identify technical/legal terms in a target corpus (Handler et al., 2016; Ha and Hyland, 2017).",
      "startOffset" : 99,
      "endOffset" : 142
    }, {
      "referenceID" : 10,
      "context" : "Linguistic methods apply human-designed rules to identify technical/legal terms in a target corpus (Handler et al., 2016; Ha and Hyland, 2017).",
      "startOffset" : 99,
      "endOffset" : 142
    }, {
      "referenceID" : 8,
      "context" : ", frequency of terms, to identify terms from a corpus (Frantzi et al., 2000; Nakagawa and Mori, 2002; Velardi et al., 2001; Drouin, 2003; Meijer et al., 2014).",
      "startOffset" : 54,
      "endOffset" : 158
    }, {
      "referenceID" : 25,
      "context" : ", frequency of terms, to identify terms from a corpus (Frantzi et al., 2000; Nakagawa and Mori, 2002; Velardi et al., 2001; Drouin, 2003; Meijer et al., 2014).",
      "startOffset" : 54,
      "endOffset" : 158
    }, {
      "referenceID" : 30,
      "context" : ", frequency of terms, to identify terms from a corpus (Frantzi et al., 2000; Nakagawa and Mori, 2002; Velardi et al., 2001; Drouin, 2003; Meijer et al., 2014).",
      "startOffset" : 54,
      "endOffset" : 158
    }, {
      "referenceID" : 5,
      "context" : ", frequency of terms, to identify terms from a corpus (Frantzi et al., 2000; Nakagawa and Mori, 2002; Velardi et al., 2001; Drouin, 2003; Meijer et al., 2014).",
      "startOffset" : 54,
      "endOffset" : 158
    }, {
      "referenceID" : 22,
      "context" : ", frequency of terms, to identify terms from a corpus (Frantzi et al., 2000; Nakagawa and Mori, 2002; Velardi et al., 2001; Drouin, 2003; Meijer et al., 2014).",
      "startOffset" : 54,
      "endOffset" : 158
    }, {
      "referenceID" : 4,
      "context" : ", logistic regression classifier, with manually labeled data (Conrado et al., 2013; Fedorenko et al., 2014; Hätty et al., 2017).",
      "startOffset" : 61,
      "endOffset" : 127
    }, {
      "referenceID" : 7,
      "context" : ", logistic regression classifier, with manually labeled data (Conrado et al., 2013; Fedorenko et al., 2014; Hätty et al., 2017).",
      "startOffset" : 61,
      "endOffset" : 127
    }, {
      "referenceID" : 14,
      "context" : ", logistic regression classifier, with manually labeled data (Conrado et al., 2013; Fedorenko et al., 2014; Hätty et al., 2017).",
      "startOffset" : 61,
      "endOffset" : 127
    }, {
      "referenceID" : 32,
      "context" : "There also exists some work on automatic term extraction with Wikipedia (Vivaldi et al., 2012; Wu et al., 2012).",
      "startOffset" : 72,
      "endOffset" : 111
    }, {
      "referenceID" : 34,
      "context" : "There also exists some work on automatic term extraction with Wikipedia (Vivaldi et al., 2012; Wu et al., 2012).",
      "startOffset" : 72,
      "endOffset" : 111
    }, {
      "referenceID" : 23,
      "context" : "Recently, inspired by distributed representations of words (Mikolov et al., 2013a), methods based on deep learning are proposed and achieve state-ofthe-art performance.",
      "startOffset" : 59,
      "endOffset" : 82
    }, {
      "referenceID" : 20,
      "context" : "The techniques behind our hierarchical corefringe learning methods are related to research on graph neural networks (GNNs) (Kipf and Welling, 2017; Hamilton et al., 2017); hierarchical text classification (Vens et al.",
      "startOffset" : 123,
      "endOffset" : 170
    }, {
      "referenceID" : 11,
      "context" : "The techniques behind our hierarchical corefringe learning methods are related to research on graph neural networks (GNNs) (Kipf and Welling, 2017; Hamilton et al., 2017); hierarchical text classification (Vens et al.",
      "startOffset" : 123,
      "endOffset" : 170
    }, {
      "referenceID" : 31,
      "context" : ", 2017); hierarchical text classification (Vens et al., 2008; Wehrmann et al., 2018; Zhou et al., 2020); and positive-unlabeled learning (Liu et al.",
      "startOffset" : 42,
      "endOffset" : 103
    }, {
      "referenceID" : 33,
      "context" : ", 2017); hierarchical text classification (Vens et al., 2008; Wehrmann et al., 2018; Zhou et al., 2020); and positive-unlabeled learning (Liu et al.",
      "startOffset" : 42,
      "endOffset" : 103
    }, {
      "referenceID" : 36,
      "context" : ", 2017); hierarchical text classification (Vens et al., 2008; Wehrmann et al., 2018; Zhou et al., 2020); and positive-unlabeled learning (Liu et al.",
      "startOffset" : 42,
      "endOffset" : 103
    }, {
      "referenceID" : 21,
      "context" : ", 2020); and positive-unlabeled learning (Liu et al., 2003; Elkan and Noto, 2008; Bekker and Davis, 2020).",
      "startOffset" : 41,
      "endOffset" : 105
    }, {
      "referenceID" : 6,
      "context" : ", 2020); and positive-unlabeled learning (Liu et al., 2003; Elkan and Noto, 2008; Bekker and Davis, 2020).",
      "startOffset" : 41,
      "endOffset" : 105
    }, {
      "referenceID" : 3,
      "context" : ", 2020); and positive-unlabeled learning (Liu et al., 2003; Elkan and Noto, 2008; Bekker and Davis, 2020).",
      "startOffset" : 41,
      "endOffset" : 105
    }, {
      "referenceID" : 13,
      "context" : "To build the offline system, we need to provide seed terms, which can come from knowledge bases or be extracted from broad, large corpora by existing term/phrase extraction methods (Handler et al., 2016; Shang et al., 2018).",
      "startOffset" : 181,
      "endOffset" : 223
    }, {
      "referenceID" : 28,
      "context" : "To build the offline system, we need to provide seed terms, which can come from knowledge bases or be extracted from broad, large corpora by existing term/phrase extraction methods (Handler et al., 2016; Shang et al., 2018).",
      "startOffset" : 181,
      "endOffset" : 223
    }, {
      "referenceID" : 9,
      "context" : "Considering the data resources, we use the built-in Elasticsearch based Wikipedia search engine2 (Gormley and Tong, 2015).",
      "startOffset" : 97,
      "endOffset" : 121
    }, {
      "referenceID" : 29,
      "context" : "In addition to using the term graph, we can achieve features of both core and fringe terms based on their linguistic and statistical properties (Terryn et al., 2019; Conrado et al., 2013) or distributed representations (Mikolov et al.",
      "startOffset" : 144,
      "endOffset" : 187
    }, {
      "referenceID" : 4,
      "context" : "In addition to using the term graph, we can achieve features of both core and fringe terms based on their linguistic and statistical properties (Terryn et al., 2019; Conrado et al., 2013) or distributed representations (Mikolov et al.",
      "startOffset" : 144,
      "endOffset" : 187
    }, {
      "referenceID" : 24,
      "context" : ", 2013) or distributed representations (Mikolov et al., 2013b; Yu and Dredze, 2015).",
      "startOffset" : 39,
      "endOffset" : 83
    }, {
      "referenceID" : 35,
      "context" : ", 2013) or distributed representations (Mikolov et al., 2013b; Yu and Dredze, 2015).",
      "startOffset" : 39,
      "endOffset" : 83
    }, {
      "referenceID" : 12,
      "context" : "The propagation process can be achieved by graph convolutions (Hammond et al., 2011).",
      "startOffset" : 62,
      "endOffset" : 84
    }, {
      "referenceID" : 20,
      "context" : "We first apply the vanilla graph convolutional networks (GCNs) (Kipf and Welling, 2017) in our framework.",
      "startOffset" : 63,
      "endOffset" : 87
    }, {
      "referenceID" : 31,
      "context" : "Inspired by related work on hierarchical multi-label classification (Vens et al., 2008; Wehrmann et al., 2018), we introduce a hierarchical learning method considering both global and local information.",
      "startOffset" : 68,
      "endOffset" : 110
    }, {
      "referenceID" : 33,
      "context" : "Inspired by related work on hierarchical multi-label classification (Vens et al., 2008; Wehrmann et al., 2018), we introduce a hierarchical learning method considering both global and local information.",
      "startOffset" : 68,
      "endOffset" : 110
    }, {
      "referenceID" : 3,
      "context" : "To deal with this issue, we apply our learning methods in a positive-unlabeled (PU) setting (Bekker and Davis, 2020), where only a small number of terms, e.",
      "startOffset" : 92,
      "endOffset" : 116
    }, {
      "referenceID" : 13,
      "context" : "As an example, for computer science or its sub-domains, we collect the abstracts in computer science according to the arXiv Category Taxonomy5, and apply phrasemachine to extract terms (Handler et al., 2016) with lemmatization and several filtering rules: frequency > 10; length ≤ 6; only contain letters, numbers, and hyphen; not a stopword or a single letter.",
      "startOffset" : 185,
      "endOffset" : 207
    }, {
      "referenceID" : 15,
      "context" : "• Multi-Channel (MC): Multi-Channel (Hätty et al., 2020) is the state-of-the-art model for au-",
      "startOffset" : 36,
      "endOffset" : 56
    }, {
      "referenceID" : 23,
      "context" : "We consider each term as a single token, and apply word2vec CBOW (Mikolov et al., 2013a) with negative sampling, where dimensionality is 100, window size is 5, and number of negative samples is 5.",
      "startOffset" : 65,
      "endOffset" : 88
    }, {
      "referenceID" : 26,
      "context" : "We also apply compositional GloVe embeddings (Pennington et al., 2014) (elementwise addition of the pre-trained 100d word embeddings, denoted as C) as non-corpus-specific features of terms for reference.",
      "startOffset" : 45,
      "endOffset" : 70
    }, {
      "referenceID" : 19,
      "context" : "For all the neural network-based models, we use Adam (Kingma and Ba, 2015) with learning rate of 0.",
      "startOffset" : 53,
      "endOffset" : 74
    }, {
      "referenceID" : 18,
      "context" : "To avoid overfitting, we adopt batch normalization (Ioffe and Szegedy, 2015) right after each layer (except for the output layer) and before activation and apply dropout (Hinton et al.",
      "startOffset" : 51,
      "endOffset" : 76
    }, {
      "referenceID" : 16,
      "context" : "To avoid overfitting, we adopt batch normalization (Ioffe and Szegedy, 2015) right after each layer (except for the output layer) and before activation and apply dropout (Hinton et al., 2012) after the activation.",
      "startOffset" : 170,
      "endOffset" : 191
    } ],
    "year" : 2021,
    "abstractText" : "We propose to measure fine-grained domain relevance– the degree that a term is relevant to a broad (e.g., computer science) or narrow (e.g., deep learning) domain. Such measurement is crucial for many downstream tasks in natural language processing. To handle longtail terms, we build a core-anchored semantic graph, which uses core terms with rich description information to bridge the vast remaining fringe terms semantically. To support a finegrained domain without relying on a matching corpus for supervision, we develop hierarchical core-fringe learning, which learns core and fringe terms jointly in a semi-supervised manner contextualized in the hierarchy of the domain. To reduce expensive human efforts, we employ automatic annotation and hierarchical positive-unlabeled learning. Our approach applies to big or small domains, covers head or tail terms, and requires little human effort. Extensive experiments demonstrate that our methods outperform strong baselines and even surpass professional human performance.1",
    "creator" : "LaTeX with hyperref"
  }
}