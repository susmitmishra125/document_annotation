{
  "name" : "2021.acl-long.5.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Unified Dual-view Cognitive Model for Interpretable Claim Verification",
    "authors" : [ "Lianwei Wu", "Yuan Rao", "Yuqian Lan", "Ling Sun", "Zhaoyin Qi" ],
    "emails" : [ "xjtu@stu.xjtu.edu.cn", "sunling@stu.xjtu.edu.cn", "daqige123@stu.xjtu.edu.cn", "raoyuan@mail.xjtu.edu.cn" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, pages 59–68\nAugust 1–6, 2021. ©2021 Association for Computational Linguistics\n59"
    }, {
      "heading" : "1 Introduction",
      "text" : "The problem of claim credibility has seriously affected the media ecosystem. Research (Allen et al., 2020) illustrates that the prevalence of ‘fake news’ has decreased trust in public institutions, and undermined democracy. Meanwhile, ‘massive infodemic’ during COVID-19 has taken a great toll on health-care systems and lives (Fleming, 2020). Therefore, how to verify the claims spread in networks has become a crucial issue.\nCurrent approaches on claim verification could be divided into two categories: 1) The first category re-\nlies on traditional machine learning and deep learning methods to capture semantics (Yang et al., 2019), sentiments (Ajao et al., 2019), writing styles (Przybyla, 2020), and stances (Kumar and Carley, 2019) from claim content, and meta-data features, such as user profiles (Shu et al., 2019; Wu et al., 2020b) for verification. Such approaches could improve verification performance, but they are hard to make reasonable explanations for the verified results, i.e., where false claims go wrong; 2) To tackle this issue, many researchers further focus on interpretable claim verification (the second category) by establishing interactive models between claims and each individual relevant article (or comment) to explore coherent (Ma et al., 2019; Wu et al., 2021), similar (Nie et al., 2019; Wu et al., 2020a), or conflicting (Zhou et al., 2020) semantics as evidence for verifying the false parts of claims.\nIn interpretable claim verification, the majority of models construct interactions between claims and each single user response (i.e., a comment or a relevant article) to capture evidence, which could effectively learn some of errant aspects of false claims. Due to different single responses reflect the cognition of different individual users, the evidence captured by these models is usually confined to individual cognition. However, individuals’ cognition of social things is not always able to truly reflect the objective (Greenwald et al., 1998; Boogert et al., 2018). Owing to individuals are affected by factors such as emotional tendency (Ji et al., 2019), traditional beliefs (Willard and Norenzayan, 2017), and selectively capturing information (Hoffman, 2018), there\nare considerable differences in cognition of different individuals, and they are prone to cognitive bias, like primacy effect (Troyer, 2011) and halo effect (Goldstein and Naglieri, 2011), there may be one-sided or biased semantics in their expressed opinions. Thus, the captured evidence also correspondingly contains some unobjective and biased evidence fragments, deteriorating task performance. For instance, as shown in Figure 1, facing a claim to be verified, different individual users (here, users are the normal users on social media, not journalists or professionals) have different reactions. R2 (i.e., response 2 or relevant article 2) and R3 released by users contain unreliable and biased information perceived by their individuals, which may lead to some misleading information being captured as evidence by existing interactive models. Therefore, how to explore users’ collective cognition on claims is a major challenge for interpretable claim verification.\nTo address the deficiencies, we propose a unified Dual-view model based on Collective and Individual Cognition (CICD) for interpretable claim verification, which focuses on discovering global evidence and local key evidence, respectively, and then strengthens the consistent shared evidence between the both. Specifically, to explore users’ collective cognition to capture global evidence, we design Collective cognition view-based Encoder-Decoder module (CED). CED develops claim-guided encoder that not only learns word-level semantics based on individual user, but also captures sentence-level semantics (i.e., the overall opinions) among all users. Here, a relevant article (a response) released by an individual user is usually a sentence sequence, so all sentence-level semantics convey the overall opinions of all users. Then, CED develops hierarchical attention decoder to generate global evidence by adjusting weights of word-level and sentence-level semantics. To further acquire the local key evidence based on individual cognition, we develop Individual cognition view-based Selected Interaction module (ISI) to screen representative top-k articles with high difference and interact with the claim to gain local key evidence fragments. To weaken the bias of individual cognition view and strengthen the consistent shared evidence between global and local evidence, we project inconsistent loss to suppress the divergence. Experimental results not only reveal the effectiveness of CICD but also provide its interpretability. Our contributions are summarized:\n• A novel framework integrating interdisciplinary knowledge on interpretable claim verification is\nexplored, which discovers global and local evidence from the perspectives of collective and individual cognition to interpret verified results.\n• Proposed CED captures word-level (individual) and sentence-level (holistic) opinions, and reasonably adjusts the proportion between them, which generates global evidence of the view of all users.\n• Experiments on three competitive datasets demonstrate that CICD achieves better performance than other strong baselines."
    }, {
      "heading" : "2 Related Work",
      "text" : "Automatic verification approaches rely on neural networks to extract content-based features, like semantics (Popat et al., 2018; Wu et al., 2019), sentiments (Nguyen et al., 2020), writing styles (Przybyla, 2020), etc., and metadata-based features, like user profilesbased (Kumar and Carley, 2019), comment-based (Bovet and Makse, 2019), etc., for verification. These methods could improve the accuracy of claim verification, but they are lack of interpretability for the verified results. To tackle this, interpretable claim verification has received great attention. Its basic principle is to obtain queried, corrected, and rumorrefuted semantics from the articles (or comments) related to claims to interpret the credibility of claims. At present, the methods for this task generally focus on direct interactions between claims and relevant articles to identify their matching degree (Nie et al., 2019), consistency (Ma et al., 2019), implication (Liu et al., 2019), conflict (Wu et al., 2020c), etc., to learn practical evidence. For instances, HAN (Ma et al., 2019) and EHIAN (Wu et al., 2020c) learned implication relationships between claims and relevant articles to capture semantic conflicts as evidence, which reflected a certain interpretability. However, since all relevant articles are involved, the captured conflicts may be affected by some low-quality articles with noisy semantics, easily resulting in the invalidation of the evidence. In our model, we design ISI module to screen all relevant articles to capture the valuable representative articles with differential semantics, so as to learn local key evidence fragments. In addition, some methods, such as GEAR (Zhou et al., 2019) and KGAT (Liu et al., 2020), relied on graph-based networks to conduct semantic aggregation and reasoning on relevant articles, so as to capture global evidence. Nevertheless, these models treat an entire article (at the sentence level) as a node and ignore the importance of word-level semantics in each article.\nTo overcome these defects, our model constructs a hierarchical attention decoder to fuse sentence-level and word-level semantics for finely-grained generating global evidence."
    }, {
      "heading" : "3 The Proposed Approach",
      "text" : "In this section, we introduce the details of CICD as illustrated in Figure 2.\nInputs and Outputs For cognitive input representations, the inputs of CED are a claim sequence and the concatenation of its all relevant articles with the number of N , while the inputs of ISI are a claim sequence and each relevant article. Given any a sequence of length l words X={x1, x2, ..., xl}, where each word xi∈Rd is a d-dimensional vector obtained by pre-trained BERT model (Devlin et al., 2019). Particularly, the length of each sequence in relevant articles is l and that of the claim sequence is p. Thus, we obtain the representations of the i-th relevant article and the claim as Xri ∈Rl×d, Xc∈Rp×d, respectively. For the outputs of the model, the outputs of CED are the generated global evidence sequence of length o words G={g1, g2, ..., go}, where gt is the representation of the t-th generated word and o is the length of G. The outputs of ISI are the integrated vector of top-k local key evidence fragments I=[I1; I2, ; ...; Ik], where ; is the concatenation operation."
    }, {
      "heading" : "3.1 Collective Cognition View-based Encoder-Decoder (CED)",
      "text" : "To explore users’ collective cognition on claims, we first rely on claim-guided encoder to capture word-level and sentence-level semantics from all relevant articles, and then adjust the proportion between the both by hierarchical attention decoder to generate global evidence."
    }, {
      "heading" : "3.1.1 Claim-guided Encoder",
      "text" : "The claim-guided encoder module involves a sequence encoding layer and a matching layer.\nSequence Encoding Layer We rely on BiLSTMs to encode all relevant articles and the claim for their contextual representations. We utilize the produced hidden states Hr = {hr1,hr2, ...,hrlall} (where lall means the total length of all articles) and Hc={hc1,hc2, ...,hcp} to denote the contextual representations of relevant articles and the claim, respectively, where hi (i.e., hri or h c i ) is defined as follows:\nhi = [ −→ hi ; ←− hi ] (1)\nwhere −→ hi ∈Rdh and ←−hi ∈Rdh are the i-th hidden\nstate of the forward and backward LSTMs for the word xi respectively. ; is concatenation operation.\nAttention-based Matching Layer is engaged to aggregate the relevant information from the claim for each word within the context of relevant articles. The aggregation operation ai=attn(hri ,H c) is as follows:\nai =\nkc∑\nj=1\nαi,jh c j (2)\nαi,j=exp(si,j)/\np∑\nk=1\nexp(si,k) (3)\nsi,j = (h r i ) W1hcj (4)\nwhere ai is the aggregated vector for the i-th word of the articles. αi,j is the normalized attention score between hri and h c j.\nHere, the purpose of adopting claim to guide the encoding of relevant articles includes two perspectives: 1) Strengthening the focus of consistent semantics associated with the claim in relevant articles, i.e., exploring how relevant articles evaluate the claim; and 2) Making the encoding semantics purer. We observe that there are some advertisements or useless information in relevant articles. This way is able to effectively filter the noise irrelevant to the claim from relevant articles, and consolidates the generation of relevant semantics in the decoder module.\nFurthermore, we output the hidden state corresponding to the last word encoded by each relevant article to form consistent sentence-level representations, where hsi represents sentence-level representations of the i-th relevant article. Particularly, we apply word-level representations Hr={hr1,hr2, ...,hrlall} (which can also be represented in the form of different relevant articles, i.e., Hr={hr1,1,hr1,2, ...,hrN,l}, where lall=N×l) and sentence-level representations Hrs={hs1,hs2, ...,hsN} as memory bank for decoder generation."
    }, {
      "heading" : "3.1.2 Hierarchical Attention Decoder",
      "text" : "To capture the collective cognition-view evidence from relevant articles, we devise hierarchical attention decoder to consider the consistent semantics with different granularity of relevant articles to generate global evidence. Specifically, we employ unidirectional LSTM as the decoder, and at each decoding time-step, we calculate in parallel both sentencelevel attention weight β and word-level α by:\nβi = (h s i ) W2hdt αi,j = (h r i,j) W3hdt (5)\nγi,j = αi,jβi∑ i,j αi,jβi\n(6)\nwhere hdt is the hidden state of the decoder at the t-th time-step, W2 and W3 are trainable parameters. The word-level attention ascertains how to distribute the attention over words in each sentence (each article), which could learn salient evidence segments in each article, while the sentence-level attention determines how much each article should contribute to the generation at current time-step, which could capture potential global semantics in all articles.\nThen the context vector ct is derived as a combination of all word-level representations reweighted by combined attention γ:\nct = ∑\ni,j\nγi,jh r i (7)\nAnd the attentional vector is calculated as: ĥdt = tanh(W4[h d t ; ct]) (8)\nFinally, the predicted probability distribution over the vocabulary V at the current step is: PV = softmax(WV ĥdt + bV ) (9) where W4, WV , and bV are trainable parameters.\nWe adopt G={g1, g2, ..., go} to denote the generated sequence rich in global evidence."
    }, {
      "heading" : "3.2 Individual Cognition View-based",
      "text" : "Selected Interaction (ISI)\nTo capture evidence fragments from individual cognition view, we design ISI module with the following layers: 1) Sentence-level representation for capturing high-level representations of relevant articles; 2) Selected mechanism for screening the representative top-k relevant articles with degree of difference; and 3) Co-interaction layer for making the claim and the selected articles interact with each other to explore local key evidence fragments."
    }, {
      "heading" : "3.2.1 Sentence-level Representation",
      "text" : "We exploit BiLSTM to encode each relevant article and capture the output of the last hidden state as the sentence-level representation, where the encoding process is similar to sequence encoding layer in Section 3.2.1, where the sentence-level representation of the i-th article is hrsi ."
    }, {
      "heading" : "3.2.2 Selected Mechanism",
      "text" : "To capture representative top-k articles, we develop selected mechanism to calculate the difference between each articles and other articles in an automated manner. To do this, selected mechanism learns and optimizes an inter-sentential attention matrix A∈RN×N . The entry (m,n) of A holds the difference between article m and article n (1≤m,n≤N and m =n) and is computed as: um=ϕ(Wmhrsm+bm) un=ϕ(Wnh rs n +bn) (10)\nA[m,n] = exp(um un)∑N i=1 exp(ui un)\n(11)\nwhere ϕ is a activation function, Wm and Wn are weight matrix, bm and bn are biases, and denotes dot product operator. The larger the entry A[m,n] is, the higher the similar between article m and article n is. Thus, the smaller A[m,n] corresponds to articlem and n contain more differential semantics, and finally we screen top-k relevant articles with high difference for further downstream interaction."
    }, {
      "heading" : "3.2.3 Co-Interaction Layer",
      "text" : "This co-interaction layer aims to explore local key evidence fragments. Specifically, the layer enables the claim to focus on the i-th article to discover the specific evidence fragment, while the i-th article pays close attention to the claim to explore the possible false part of\nthe claim. Finally, we combine the two interactions to constitute the individual key local evidence fragments.\nHrini = h rs i + softmax(h rs i ((H cs) ))Hcs (12) Hcin = Hcs + softmax(Hcs((hrsi ) ))hrsi (13)\nIi = [Hrini ;H cin] (14)\nwhere Hrini is the evidence fragment of the i-th article, Hcin is the false part of the claim, and Hcs is the outputs of the last time step of Hc.\nFor all top-k articles, we integrate all local evidence fragments by concatenation operation.\nI = [I1; I2; ...; Ik] (15)"
    }, {
      "heading" : "3.3 Dual-View Classification",
      "text" : "To alleviate the bias of individual cognition-view evidence fragments and strengthen the consistent shared evidence between global and local evidence, we introduce an inconsistency loss to penalize the disagreement between the both evidence. We define the inconsistency loss function as the KulllbackLeibler (KL) divergence between G and I.\nLossin = DKL(G||I) = K∑\nk=1\nG ′ klog\nG ′ k\nI′k (16)\nwhere G ′ k is the k-th element of the concatenation of the words in G, and I′k is the k-th element of I. Furthermore, we fuse the two types of penalized evidence, and adopt softmax function to emit the probability distribution for training, where a loss forces the model to minimize the cross-entropy error for a training sample with ground-truth label y:\nLoss = − ∑ ylogp (17)\np = softmax(Wp[G; I] + bp) (18)\nwhere Wp and bp are the learnable parameters. To ensure the effective synergy of the two cognition views, we put together all loss mentioned above for joint training. L = Loss + αLossin (19) where α is the hyper-parameter."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets and Evaluation Metrics",
      "text" : "For evaluation, we utilize three publicly available datasets, i.e., Snopes, PolitiFact (both released by (Popat et al., 2018)), and FEVER (Thorne et al., 2018). The first two datasets contain 4,341 and 3,568 news claims, associating with 29,242 and 29,556 relevant articles (these articles can be regarded as\nresponses of different individual users to claims) collected from various web sources respectively. FEVER consists of 185,445 claims accompanied by manual annotation Wikipedia articles. For labels, each claim in Snopes is labeled as true and false, while PolitiFact divides claims into six kinds of credibility labels: true, mostly true, half true, mostly false, false, and pants on fire. To distinguish the veracity more practically, like Ma et al. (2019), we merge mostly true, half true and mostly false into mixed, and treat false and pants on fire as false. Then, the labels of PolitiFact are classified as true, mixed, and false. On FEVER, each claim is partitioned as supported, refuted, or NEI (not enough information). For evaluation metrics, on Snopes and PolitiFact, we exploit micro-/macro-averaged F1(micF1/macF1), class-specific precision (Prec.), recall (Rec.) and F1score (F1) as evaluation metrics. We hold out 10% of the claims for tuning the hyper parameters, and conduct 5-fold cross-validation on the rest of the claims. On FEVER, we leverage accuracy (Acc.), and F1score (F1) as evaluation metrics, and follow Thorne et al. (2018) to partition the annotated claims into training, development (Dev.), and testing (Test.) sets."
    }, {
      "heading" : "4.2 Settings",
      "text" : "For parameter configurations, we adjust them according to the performance of development sets, we set the word embedding size d to 768. The dimensionality of LSTM hidden states dh is 120. The length l of each relevant article is 100 and that of the claim p is assigned as 20. Due to no parameters depend on the number of articles N , instead of intercepting a fixed number, we set N to vary with claims. Initial learning rate is set to 2e-3. The loss weight coefficient α is trained to 0.2. The dropout rate is 0.4, and we set the mini-batch size of the three datasets as 32, 32, and 64, respectively. Additionally, an Adam (Kingma and Ba, 2015) optimizer with β1 as 0.9 and β2 as 0.999 is used to optimize all trainable parameters."
    }, {
      "heading" : "4.3 Experiments on Snopes and PolitiFact",
      "text" : ""
    }, {
      "heading" : "4.3.1 Performance Comparison",
      "text" : "We compare CICD and several competitive baselines: 1) DeClarE (Popat et al., 2018) models joint interactions between claims and articles and aggregates word-level credibility signals from external articles for evidence-aware assessment; 2) BERT (Devlin et al., 2019), we employ pre-trained BERT classifier to verify claims; 3) HAN (Ma et al., 2019), a hierarchical attention network, constructs the interactions between claims and relevant articles for capturing sentence-\nlevel evidence by considering their topical coherence and semantic inference strength; 4) HAN-ba (Ma et al., 2019) is a variant of HAN, where the gated attention is replaced to biaffine attention for acquiring evidence; and 5) EHIAN (Wu et al., 2020c) is an evidence-aware hierarchical interactive attention network, which focuses on the direct interaction between claim and relevant articles to explore key evidence fragments. As shown in Table 1, we observe that:\n• BERT achieves at least 6.5% improvement on micF1 than DeClarE, which illustrates pre-trained model can learn rich semantic context features to improve performance, which is also the reason that we adopt BERT to train word embeddings. HAN consistently outperforms BERT, which indicates HAN capturing the coherence between relevant articles could help improve the task performance.\n• In interpretable methods, CICD outperforms DeClarE, which is because our model not only focuses on word-level semantics like DeClarE, but also grasps the holistic sentence-level features. Moreover, owing to HAN and HAN-ba drive all relevant articles to participate in the interaction, prompting them to gain a small boost in precision on Snopes, but this way may introduce noise from nonsignificant articles. CICD effectively avoids this problem by selecting vital articles for interaction, which obtains significant improvements in other metrics compared with HAN and HAN-ba. Furthermore, CICD consistently outperforms EHIAN on Snopes and PolitiFact. The superiority is clear: CICD not only values individual cognition view to capture key evidence fragments, but also generates collective cognition-view evidence for claim verification."
    }, {
      "heading" : "4.3.2 Ablation Study",
      "text" : "In order to evaluate the impact of each component of CICD, we ablate CICD into the following simplified models: 1) -matching U represents the attentionbased matching layer of CED is removed; 2) -CED\nmeans CED is deleted from our model; 3) -selected I refers to the selected mechanism is removed from ISI; 4) -interaction I represents the co-interaction unit of ISI is replaced by concatenation operation; 5) -ISI corresponds to ISI is separated; and 6) -inconsistency loss means the inconsistency loss is removed. As shown in Table 2, we observe that:\n• The removal of each module (-CED or -ISI) weakens the performance of CICD, presenting from 4.2% to 5.5% degradation in micF1, and the stripping of different layers (like -selected I and - interaction I) of each module also reduces the model performance, reducing at least 2.4% performance in micF1, which describes the effectiveness of each component and the organic integrity of CICD.\n• -CED reflects the lowest performance in all simplified models, decreasing 5.5% and 4.6% in micF1 on the two datasets, respectively, which elaborates the effectiveness of our CICD capturing the collective cognition-view global evidence. Meanwhile, -ISI underperforms CICD, showing 4.3% and 4.2% degradation in micF1 on the two datasets respectively, which conveys the necessity of the exploration of local key evidence fragments from individual cognition view.\n• When compared with -inconsistency loss, CICD significantly improves the performance on the two datasets with the help of inconsistency loss unit, which verifies the effectiveness of our model rely-\ning on inconsistency loss to discover shared valuable semantics between global and local evidence."
    }, {
      "heading" : "4.3.3 Evaluation of Co-Interaction Networks",
      "text" : "To obtain a more detailed understanding of the superiority of our co-interaction networks (CoI), we compare CoI with the following prevalent interaction networks: 1) MLP (Multilayer Perceptron) acts as an interaction strategy to automatically abstract the integrated representation of claims and articles; 2) Self-Att (Self-attention Networks) (Vaswani et al., 2017) adopts the claim as query, and relevant articles to serve as values and keys for interaction; 3) Biaf-Att (Biaffine Attention) (Ma et al., 2019) measures the degree of semantic matching for interaction; and 4) Symm-Intr (Symmetric interaction attention) (Tao et al., 2019) is exploited to model the interaction between claims and articles. Specifically, we investigate the performance and time cost of these methods on Snopes and PolitiFact based on Linux CentOS with NVIDIA TITAN Xp GPU, as shown in Figure 3. We observe that:\nFrom the overall performance of all methods, our method achieves the optimal performance, outperforming other methods by more than 5.1% and 5.6% performance in micF1, respectively. From the indicator of time cost, our method saves a great deal of time. Compared with Self-Att and Symm-Intr, our method saves from 500 to 1,000 seconds in time cost on the two datasets, respectively. The reason is that the structures of multiple mappings of self-attention networks and the repeat stacks of symmetric attention delay the efficiency. Although the time cost of our method is higher than that of MLP and Biaf-Att, the performance of both methods is unsatisfactory, which is lower than our method al least 2.6% and 3.7% in micF1 on both datasets. On the whole, these adequately manifest the superiority of our method."
    }, {
      "heading" : "4.3.4 Evaluation of Hierarchical Attention Decoder",
      "text" : "To verify the effectiveness of the internal structure of hierarchical attention decoder (HAD) in CED, we ablate HAD with the following models: -word., -sentence., and -merge. respectively denote HAD removing word-level attention α, sentence-level attention β, and merged semantics γ. decoder. represents the vanilla decoder. Experimental results are shown in Table 3, we observe that: first, the removal of any module of HAD could weaken the performance of the model, which confirms the effectiveness of each module. Second, in addition to the basic decoder,\nour model achieves the most prominent boost with the support of sentence-level attention, which proves the effectiveness of HAD fusing sentence-level semantics to capture global semantics of HAD.\nTo further investigate the contribution of sentencelevel semantics to the global evidence, we take Figure 1 as an example to visualize the global evidence generated by our model with and without sentence-level attention, respectively. As shown in Figure 4, we observe that the model with sentence-level attention focuses more on the sentences with maximum weight, that is, R4, such as the words ‘do not spread’ and ‘refuted it spreads in the air’, while the model without sentence-level attention does not identify which relevant articles are more valuable, so that they concentrate more on R2 and R3, like ‘get infected husband’ and ‘not all types of mosquitoes’. These fully prove the effectiveness of sentence-level semantics for the generation of global evidence."
    }, {
      "heading" : "4.4 Experiments on FEVER",
      "text" : "To examine the extensibility of our model, we also compare CICD and the following state-of-theart baselines on FEVER dataset: 1) NSMN: The pipeline-based system, Neural Semantic Matching Network (Nie et al., 2019), conducts document retrieval, sentence selection, and claim verification jointly for fact extraction and verification; 2) HAN: It has introduced in Section 4.3.1; 3) GEAR: A graph-\nbased evidence aggregating and reasoning model (Zhou et al., 2019) enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multi-evidence information; 4) KGAT: Kernel graph attention network (Liu et al., 2020) conducts more fine-grained fact verification with kernel-based attentions, where using BERT (Base) encoder with ESIM retrieved sentences.\nAs shown in Table 4, we observe that: CICD outperforms the two pipelines (NSMN and HAN) by from 4.3% to 11.0% boost in accuracy, respectively. This is because these two baselines lack the integration and reasoning process between relevant articles when capturing evidence. CICD boosts the performance in comparison with GEAR and KGAT, showing at least 1.8% and 1.5% improvement in accuracy on development and testing sets, respectively. The reason may be that although the two graph-based models aggregate and reason information from relevant articles to collect multi-evidence, they treat each relevant article equally, leading to individual-cognitive relevant articles with some biased semantics interfering with their reasoning process. It is more feasible for our model to discover global evidence and local key evidence fragments comprehensively from the perspectives of collective and individual cognition."
    }, {
      "heading" : "4.5 Case Study: Cognition-view Explanation Analysis",
      "text" : "To interpret the results of our model more transparently and intuitively, we visualize the outputs of each module of CICD as shown in Figure 5, where Figure\n5 (a) is the sequence generated by CED module, and the highlighted words in Figure 5(b) and 5 (c) are respectively the words captured by CICD to interpret the results and the words obtained by ISI module to obtain the evidence fragments. We could learn:\n• ISI ignores some articles with pale and feeble semantics (R2 and R4), and selects the articles with more valuable semantics (R1, R3, and R5) and captures multiple local evidence fragments, such as ‘this video screenshot shows’ (E1), ‘serious error’ (E2), and ‘screenshot of the video is one-sided’ (E3). Particularly, fragment E1 is misleading, which reflects the deviation of individual cognition.\n• The sequence generated by CED effectively gains available evidence ‘120 million Americans a serious error’ and ‘the screenshot is one-sided’ through balancing the possible evidence semantics in relevant articles from a global perspective.\n• By constraining global and local evidence, CICD disciplines the misleading evidence fragment E1 captured by ISI, and finally highlights the shared salient evidence between the both as the final interpretability of the verification results."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we proposed a unified dual-view model based on the perspectives of collective and individual cognition for interpretable claim verification, which constructed collective cognition view-based\nencoder-decoder module to generate global evidence and designed individual cognition view-based selected interaction module to explore local key evidence segments. Besides, we introduced inconsistent loss to penalize the disagreement between global and local evidence for promoting the capture of consistent shared evidence. Experiments on three different widely used datasets demonstrated the effectiveness and interpretability of our model. In the future, we plan to expand the work as follows: 1) Developing questioning mechanism to filter the suspicious evidence; and 2) Integrating social cognition, psychology, and other interdisciplinary knowledge to improve the interpretability of claim verification."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The research work was supported by National Key Research and Development Program in China (2019YFB2102300); The World-Class Universities (Disciplines) and the Characteristic Development Guidance Funds for the Central Universities of China (PY3A022); Ministry of Education Fund Projects (18JZD022 and 2017B00030); Shenzhen Science and Technology Project (JCYJ20180306170836595); Basic Scientific Research Operating Expenses of Central Universities (ZDYF2017006); Xi’an Navinfo Corp.& Engineering Center of Xi’an Intelligence Spatialtemporal Data Analysis Project (C2020103); Beilin District of Xi’an Science & Technology Project (GX1803). We would like to thank the anonymous reviewers for their valuable and constructive comments."
    } ],
    "references" : [ {
      "title" : "Sentiment aware fake news detection on online social networks",
      "author" : [ "Oluwaseun Ajao", "Deepayan Bhowmik", "Shahrzad Zargari." ],
      "venue" : "ICASSP 20192019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages",
      "citeRegEx" : "Ajao et al\\.,? 2019",
      "shortCiteRegEx" : "Ajao et al\\.",
      "year" : 2019
    }, {
      "title" : "Evaluating the fake news problem at the scale of the information ecosystem",
      "author" : [ "Jennifer Allen", "Baird Howland", "Markus Mobius", "David Rothschild", "Duncan J Watts." ],
      "venue" : "Science Advances, 6(14):eaay3539.",
      "citeRegEx" : "Allen et al\\.,? 2020",
      "shortCiteRegEx" : "Allen et al\\.",
      "year" : 2020
    }, {
      "title" : "Measuring and understanding individual differences in cognition",
      "author" : [ "N. Boogert", "J. Madden", "J. Morand-Ferron", "A. Thornton." ],
      "venue" : "Philosophical Transactions of the Royal Society B: Biological Sciences, 373.",
      "citeRegEx" : "Boogert et al\\.,? 2018",
      "shortCiteRegEx" : "Boogert et al\\.",
      "year" : 2018
    }, {
      "title" : "Influence of fake news in twitter during the 2016",
      "author" : [ "Alexandre Bovet", "Hernán A Makse" ],
      "venue" : null,
      "citeRegEx" : "Bovet and Makse.,? \\Q2019\\E",
      "shortCiteRegEx" : "Bovet and Makse.",
      "year" : 2019
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Coronavirus misinformation, and how scientists can help to fight it",
      "author" : [ "Nic Fleming." ],
      "venue" : "Nature, 583:155– 156.",
      "citeRegEx" : "Fleming.,? 2020",
      "shortCiteRegEx" : "Fleming.",
      "year" : 2020
    }, {
      "title" : "Measuring individual differences in implicit cognition: the implicit association test",
      "author" : [ "A. Greenwald", "D. McGhee", "J.L. Schwartz." ],
      "venue" : "Journal of personality and social psychology, 74 6:1464–80.",
      "citeRegEx" : "Greenwald et al\\.,? 1998",
      "shortCiteRegEx" : "Greenwald et al\\.",
      "year" : 1998
    }, {
      "title" : "An individual differences approach to semantic cognition: Divergent effects of age on representation, retrieval and selection",
      "author" : [ "Paul Hoffman." ],
      "venue" : "Scientific Reports, 8.",
      "citeRegEx" : "Hoffman.,? 2018",
      "shortCiteRegEx" : "Hoffman.",
      "year" : 2018
    }, {
      "title" : "Spontaneous cognition in dysphoria: reduced positive bias in imagining the future",
      "author" : [ "J. Ji", "E. Holmes", "C. MacLeod", "F. Murphy." ],
      "venue" : "Psychological Research, 83:817 – 831.",
      "citeRegEx" : "Ji et al\\.,? 2019",
      "shortCiteRegEx" : "Ji et al\\.",
      "year" : 2019
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "ICLR (Poster).",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Tree lstms with convolution units to predict stance and rumor veracity in social media conversations",
      "author" : [ "Sumeet Kumar", "Kathleen M Carley." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5047–",
      "citeRegEx" : "Kumar and Carley.,? 2019",
      "shortCiteRegEx" : "Kumar and Carley.",
      "year" : 2019
    }, {
      "title" : "Trust or suspect? an empirical ensemble framework for fake news classification",
      "author" : [ "Shuaipeng Liu", "Shuo Liu", "Lei Ren." ],
      "venue" : "Proceedings of the 12th ACM International Conference on Web Search and Data Mining, pages 11–15.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Fine-grained fact verification with kernel graph attention network",
      "author" : [ "Zhenghao Liu", "Chenyan Xiong", "Maosong Sun", "Zhiyuan Liu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7342–7351.",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Sentence-level evidence embedding for claim verification with hierarchical attention networks",
      "author" : [ "Jing Ma", "Wei Gao", "Shafiq Joty", "Kam-Fai Wong." ],
      "venue" : "ACL, pages 2561–2571.",
      "citeRegEx" : "Ma et al\\.,? 2019",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2019
    }, {
      "title" : "Fang: Leveraging social context for fake news detection using graph",
      "author" : [ "Van-Hoang Nguyen", "Kazunari Sugiyama", "Preslav Nakov", "Min-Yen Kan" ],
      "venue" : null,
      "citeRegEx" : "Nguyen et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2020
    }, {
      "title" : "Combining fact extraction and verification with neural semantic matching networks",
      "author" : [ "Yixin Nie", "Haonan Chen", "Mohit Bansal." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6859–6866.",
      "citeRegEx" : "Nie et al\\.,? 2019",
      "shortCiteRegEx" : "Nie et al\\.",
      "year" : 2019
    }, {
      "title" : "Declare: Debunking fake news and false claims using evidence-aware deep learning",
      "author" : [ "Kashyap Popat", "Subhabrata Mukherjee", "Andrew Yates", "Gerhard Weikum." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Popat et al\\.,? 2018",
      "shortCiteRegEx" : "Popat et al\\.",
      "year" : 2018
    }, {
      "title" : "Capturing the style of fake news",
      "author" : [ "Piotr Przybyla." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 490–497.",
      "citeRegEx" : "Przybyla.,? 2020",
      "shortCiteRegEx" : "Przybyla.",
      "year" : 2020
    }, {
      "title" : "The role of user profiles for fake news detection",
      "author" : [ "Kai Shu", "Xinyi Zhou", "Suhang Wang", "Reza Zafarani", "Huan Liu." ],
      "venue" : "Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, pages 436–",
      "citeRegEx" : "Shu et al\\.,? 2019",
      "shortCiteRegEx" : "Shu et al\\.",
      "year" : 2019
    }, {
      "title" : "One time of interaction may not be enough: Go deep with an interaction-over-interaction network for response selection in dialogues",
      "author" : [ "Chongyang Tao", "Wei Wu", "Can Xu", "Wenpeng Hu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Proceedings of the 57th An-",
      "citeRegEx" : "Tao et al\\.,? 2019",
      "shortCiteRegEx" : "Tao et al\\.",
      "year" : 2019
    }, {
      "title" : "Fever: a large-scale dataset for fact extraction and verification",
      "author" : [ "James Thorne", "Andreas Vlachos", "Christos Christodoulopoulos", "Arpit Mittal." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Thorne et al\\.,? 2018",
      "shortCiteRegEx" : "Thorne et al\\.",
      "year" : 2018
    }, {
      "title" : "Primacy Effect, pages 2017– 2018",
      "author" : [ "Angela K. Troyer." ],
      "venue" : "New York, NY.",
      "citeRegEx" : "Troyer.,? 2011",
      "shortCiteRegEx" : "Troyer.",
      "year" : 2011
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in neural information processing systems, pages 5998–6008.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "spiritual but not religious: Cognition, schizotypy, and conversion in alternative beliefs",
      "author" : [ "Aiyana K. Willard", "A. Norenzayan." ],
      "venue" : "Cognition, 165:137–146.",
      "citeRegEx" : "Willard and Norenzayan.,? 2017",
      "shortCiteRegEx" : "Willard and Norenzayan.",
      "year" : 2017
    }, {
      "title" : "Different absorption from the same sharing: Sifted multi-task learning for fake news detection",
      "author" : [ "Lianwei Wu", "Yuan Rao", "Haolin Jin", "Ambreen Nazir", "Ling Sun." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Wu et al\\.,? 2019",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "2020a. Dtca: Decision tree-based co-attention networks for explainable claim verification",
      "author" : [ "Lianwei Wu", "Yuan Rao", "Hao Liang", "Ambreen Nazir" ],
      "venue" : "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Wu et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Discovering differential features: Adversarial learning for information credibility evaluation",
      "author" : [ "Lianwei Wu", "Yuan Rao", "Ambreen Nazir", "Haolin Jin." ],
      "venue" : "Information Sciences, 516:453–473.",
      "citeRegEx" : "Wu et al\\.,? 2020b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Evidence inference networks for interpretable claim verification",
      "author" : [ "Lianwei Wu", "Yuan Rao", "Ling Sun", "Wangbo He." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, pages 1165–1174.",
      "citeRegEx" : "Wu et al\\.,? 2021",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2021
    }, {
      "title" : "Evidence-aware hierarchical interactive attention networks for explainable claim verification",
      "author" : [ "Lianwei Wu", "Yuan Rao", "Xiong Yang", "Wanzhen Wang", "Ambreen Nazir." ],
      "venue" : "Proceedings of IJCAI.",
      "citeRegEx" : "Wu et al\\.,? 2020c",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Unsupervised fake news detection on social media: A generative approach",
      "author" : [ "Shuo Yang", "Kai Shu", "Suhang Wang", "Renjie Gu", "Fan Wu", "Huan Liu." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 5644–5651.",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Gear: Graph-based evidence aggregating and reasoning for fact verification",
      "author" : [ "Jie Zhou", "Xu Han", "Cheng Yang", "Zhiyuan Liu", "Lifeng Wang", "Changcheng Li", "Maosong Sun." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Zhou et al\\.,? 2019",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2019
    }, {
      "title" : "Safe: Similarity-aware multi-modal fake news detection",
      "author" : [ "Xinyi Zhou", "Jindi Wu", "Reza Zafarani." ],
      "venue" : "Pacific-Asia Conference on Knowledge Discovery and Data Mining, pages 354–367. Springer.",
      "citeRegEx" : "Zhou et al\\.,? 2020",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Research (Allen et al., 2020) illustrates that the prevalence of ‘fake news’ has decreased trust in public institutions, and undermined democracy.",
      "startOffset" : 9,
      "endOffset" : 29
    }, {
      "referenceID" : 5,
      "context" : "Meanwhile, ‘massive infodemic’ during COVID-19 has taken a great toll on health-care systems and lives (Fleming, 2020).",
      "startOffset" : 103,
      "endOffset" : 118
    }, {
      "referenceID" : 29,
      "context" : "lies on traditional machine learning and deep learning methods to capture semantics (Yang et al., 2019), sentiments (Ajao et al.",
      "startOffset" : 84,
      "endOffset" : 103
    }, {
      "referenceID" : 0,
      "context" : ", 2019), sentiments (Ajao et al., 2019), writing styles (Przybyla, 2020), and stances (Kumar and Carley, 2019) from",
      "startOffset" : 20,
      "endOffset" : 39
    }, {
      "referenceID" : 17,
      "context" : ", 2019), writing styles (Przybyla, 2020), and stances (Kumar and Carley, 2019) from",
      "startOffset" : 24,
      "endOffset" : 40
    }, {
      "referenceID" : 10,
      "context" : ", 2019), writing styles (Przybyla, 2020), and stances (Kumar and Carley, 2019) from",
      "startOffset" : 54,
      "endOffset" : 78
    }, {
      "referenceID" : 18,
      "context" : "claim content, and meta-data features, such as user profiles (Shu et al., 2019; Wu et al., 2020b) for verification.",
      "startOffset" : 61,
      "endOffset" : 97
    }, {
      "referenceID" : 26,
      "context" : "claim content, and meta-data features, such as user profiles (Shu et al., 2019; Wu et al., 2020b) for verification.",
      "startOffset" : 61,
      "endOffset" : 97
    }, {
      "referenceID" : 13,
      "context" : ", where false claims go wrong; 2) To tackle this issue, many researchers further focus on interpretable claim verification (the second category) by establishing interactive models between claims and each individual relevant article (or comment) to explore coherent (Ma et al., 2019; Wu et al., 2021), similar (Nie et al.",
      "startOffset" : 265,
      "endOffset" : 299
    }, {
      "referenceID" : 27,
      "context" : ", where false claims go wrong; 2) To tackle this issue, many researchers further focus on interpretable claim verification (the second category) by establishing interactive models between claims and each individual relevant article (or comment) to explore coherent (Ma et al., 2019; Wu et al., 2021), similar (Nie et al.",
      "startOffset" : 265,
      "endOffset" : 299
    }, {
      "referenceID" : 15,
      "context" : ", 2021), similar (Nie et al., 2019; Wu et al., 2020a), or conflicting (Zhou et al.",
      "startOffset" : 17,
      "endOffset" : 53
    }, {
      "referenceID" : 8,
      "context" : "Owing to individuals are affected by factors such as emotional tendency (Ji et al., 2019), traditional",
      "startOffset" : 72,
      "endOffset" : 89
    }, {
      "referenceID" : 23,
      "context" : "beliefs (Willard and Norenzayan, 2017), and selectively capturing information (Hoffman, 2018), there",
      "startOffset" : 8,
      "endOffset" : 38
    }, {
      "referenceID" : 7,
      "context" : "beliefs (Willard and Norenzayan, 2017), and selectively capturing information (Hoffman, 2018), there",
      "startOffset" : 78,
      "endOffset" : 93
    }, {
      "referenceID" : 21,
      "context" : "individuals, and they are prone to cognitive bias, like primacy effect (Troyer, 2011) and halo effect (Goldstein and Naglieri, 2011), there may be one-sided or biased semantics in their expressed opinions.",
      "startOffset" : 71,
      "endOffset" : 85
    }, {
      "referenceID" : 16,
      "context" : "Automatic verification approaches rely on neural networks to extract content-based features, like semantics (Popat et al., 2018; Wu et al., 2019), sentiments (Nguyen et al.",
      "startOffset" : 108,
      "endOffset" : 145
    }, {
      "referenceID" : 24,
      "context" : "Automatic verification approaches rely on neural networks to extract content-based features, like semantics (Popat et al., 2018; Wu et al., 2019), sentiments (Nguyen et al.",
      "startOffset" : 108,
      "endOffset" : 145
    }, {
      "referenceID" : 14,
      "context" : ", 2019), sentiments (Nguyen et al., 2020), writing styles (Przybyla, 2020), etc.",
      "startOffset" : 20,
      "endOffset" : 41
    }, {
      "referenceID" : 10,
      "context" : ", and metadata-based features, like user profilesbased (Kumar and Carley, 2019), comment-based (Bovet and Makse, 2019), etc.",
      "startOffset" : 55,
      "endOffset" : 79
    }, {
      "referenceID" : 3,
      "context" : ", and metadata-based features, like user profilesbased (Kumar and Carley, 2019), comment-based (Bovet and Makse, 2019), etc.",
      "startOffset" : 95,
      "endOffset" : 118
    }, {
      "referenceID" : 15,
      "context" : "At present, the methods for this task generally focus on direct interactions between claims and relevant articles to identify their matching degree (Nie et al., 2019), consistency (Ma et al.",
      "startOffset" : 148,
      "endOffset" : 166
    }, {
      "referenceID" : 13,
      "context" : ", 2019), consistency (Ma et al., 2019), implication (Liu et al.",
      "startOffset" : 21,
      "endOffset" : 38
    }, {
      "referenceID" : 11,
      "context" : ", 2019), implication (Liu et al., 2019), conflict (Wu et al.",
      "startOffset" : 21,
      "endOffset" : 39
    }, {
      "referenceID" : 13,
      "context" : "For instances, HAN (Ma et al., 2019) and EHIAN (Wu et al.",
      "startOffset" : 19,
      "endOffset" : 36
    }, {
      "referenceID" : 28,
      "context" : ", 2019) and EHIAN (Wu et al., 2020c) learned implica-",
      "startOffset" : 18,
      "endOffset" : 36
    }, {
      "referenceID" : 30,
      "context" : "In addition, some methods, such as GEAR (Zhou et al., 2019) and KGAT (Liu et al.",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 12,
      "context" : ", 2019) and KGAT (Liu et al., 2020), relied on graph-based networks to conduct semantic aggregation and reasoning on relevant articles, so as to capture global evidence.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 4,
      "context" : ", xl}, where each word xi∈R is a d-dimensional vector obtained by pre-trained BERT model (Devlin et al., 2019).",
      "startOffset" : 89,
      "endOffset" : 110
    }, {
      "referenceID" : 16,
      "context" : ", Snopes, PolitiFact (both released by (Popat et al., 2018)), and FEVER (Thorne et al.",
      "startOffset" : 39,
      "endOffset" : 59
    }, {
      "referenceID" : 9,
      "context" : "Additionally, an Adam (Kingma and Ba, 2015) optimizer with β1 as 0.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 16,
      "context" : "We compare CICD and several competitive baselines: 1) DeClarE (Popat et al., 2018) models joint inter-",
      "startOffset" : 62,
      "endOffset" : 82
    }, {
      "referenceID" : 4,
      "context" : "actions between claims and articles and aggregates word-level credibility signals from external articles for evidence-aware assessment; 2) BERT (Devlin et al., 2019), we employ pre-trained BERT classifier to verify claims; 3) HAN (Ma et al.",
      "startOffset" : 144,
      "endOffset" : 165
    }, {
      "referenceID" : 13,
      "context" : ", 2019), we employ pre-trained BERT classifier to verify claims; 3) HAN (Ma et al., 2019), a hierarchical attention network, constructs the interactions between claims and relevant articles for capturing sentence-",
      "startOffset" : 72,
      "endOffset" : 89
    }, {
      "referenceID" : 28,
      "context" : ", 2019) is a variant of HAN, where the gated attention is replaced to biaffine attention for acquiring evidence; and 5) EHIAN (Wu et al., 2020c) is an evidence-aware hierarchical interactive attention network, which focuses on the direct interaction between claim and relevant articles to explore key evidence fragments.",
      "startOffset" : 126,
      "endOffset" : 144
    }, {
      "referenceID" : 13,
      "context" : "2017) adopts the claim as query, and relevant articles to serve as values and keys for interaction; 3) Biaf-Att (Biaffine Attention) (Ma et al., 2019) measures the degree of semantic matching for interaction; and 4) Symm-Intr (Symmetric interaction attention) (Tao et al.",
      "startOffset" : 133,
      "endOffset" : 150
    }, {
      "referenceID" : 19,
      "context" : ", 2019) measures the degree of semantic matching for interaction; and 4) Symm-Intr (Symmetric interaction attention) (Tao et al., 2019) is exploited to model the interaction between claims and articles.",
      "startOffset" : 117,
      "endOffset" : 135
    }, {
      "referenceID" : 15,
      "context" : "Network (Nie et al., 2019), conducts document retrieval, sentence selection, and claim verification jointly for fact extraction and verification; 2) HAN: It has introduced in Section 4.",
      "startOffset" : 8,
      "endOffset" : 26
    }, {
      "referenceID" : 30,
      "context" : "(Zhou et al., 2019) enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multi-evidence information; 4) KGAT: Kernel graph attention network (Liu et al.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 12,
      "context" : ", 2019) enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multi-evidence information; 4) KGAT: Kernel graph attention network (Liu et al., 2020) conducts more fine-grained fact verification with kernel-based attentions, where using BERT (Base) encoder with ESIM retrieved sentences.",
      "startOffset" : 195,
      "endOffset" : 213
    } ],
    "year" : 2021,
    "abstractText" : "Recent studies constructing direct interactions between the claim and each single user response to capture evidence have shown remarkable success in interpretable claim verification. Owing to different single responses convey different cognition of individual users, the captured evidence belongs to the perspective of individual cognition. However, individuals’ cognition of social things is not always able to truly reflect the objective. There may be one-sided or biased semantics in their opinions on a claim. The captured evidence correspondingly contains some unobjective and biased information. In this paper, we propose a Dual-view model based on the views of Collective and Individual Cognition (CICD) for interpretable claim verification. For collective cognition, we not only capture the word-level semantics based on individual users, but also focus on sentencelevel semantics (i.e., the overall responses) among all users to generate global evidence. For individual cognition, we select the top-k articles with high degree of difference and interact with the claim to explore the local key evidence fragments. To weaken the bias of individual cognition-view evidence, we devise an inconsistent loss to suppress the divergence between global and local evidence for strengthening the consistent shared evidence between the both. Experiments on three benchmark datasets confirm the effectiveness of CICD.",
    "creator" : "LaTeX with hyperref package"
  }
}