section TITLE
id pdf2json/2021.acl-long.62.pdf.json
compare O
to O
the O
knowledge O
: O
graph O
neural O
fake O
news O
detection O
with O
external O
knowledge O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
nowadays O
, O
fake O
news O
detection O
, O
which O
aims O
to O
verify O
whether O
a O
news O
document O
is O
trusted O
or O
fake O
, O
has O
become O
urgent O
and O
important O
. O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
most O
existing O
methods O
rely O
heavily O
on O
linguistic O
and O
semantic O
features O
from O
the O
news O
content O
, O
and O
fail O
to O
effectively O
exploit O
external O
knowledge O
which O
could O
help O
determine O
whether O
the O
news O
document O
is O
trusted O
. O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
in O
this O
paper O
, O
we O
propose O
a O
novel O
end-to-end O
graph O
neural O
model O
called O
comparenet O
, O
which O
compares O
the O
news O
to O
the O
knowledge O
base O
( O
kb O
) O
through O
entities O
for O
fake O
news O
detection O
. O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
considering O
that O
fake O
news O
detection O
is O
correlated O
with O
topics O
, O
we O
also O
incorporate O
topics O
to O
enrich O
the O
news O
representation O
. O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
specifically O
, O
we O
first O
construct O
a O
directed O
heterogeneous O
document O
graph O
for O
each O
news O
incorporating O
topics O
and O
entities O
. O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
based O
on O
the O
graph O
, O
we O
develop O
a O
heterogeneous O
graph O
attention O
network O
for O
learning O
the O
topic-enriched O
news O
representation O
as O
well O
as O
the O
contextual O
entity O
representations O
that O
encode O
the O
semantics O
of O
the O
news O
content O
. O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
the O
contextual O
entity O
representations O
are O
then O
compared O
to O
the O
corresponding O
kb-based O
entity O
representations O
through O
a O
carefully O
designed O
entity O
comparison O
network O
, O
to O
capture O
the O
consistency O
between O
the O
news O
content O
and O
kb O
. O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
finally O
, O
the O
topic-enriched O
news O
representation O
combining O
the O
entity O
comparison O
features O
are O
fed O
into O
a O
fake O
news O
classifier O
. O

section ABSTRACT
id pdf2json/2021.acl-long.62.pdf.json
experimental O
results O
on O
two O
benchmark O
datasets O
demonstrate O
that O
comparenet O
significantly O
outperforms O
state-of-the-art O
methods O
. O

section 0
id pdf2json/2021.acl-long.62.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
754–763 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.62.pdf.json
©2021 O
association O
for O
computational O
linguistics O
754 O

section 1
id pdf2json/2021.acl-long.62.pdf.json
with O
the O
rapid O
development O
of O
the O
internet O
, O
there O
are O
increasingly O
huge O
opportunities O
for O
fake O
news O
∗the O
work O
was O
done O
while O
visiting O
micorosft O
research O
asia O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
production O
, O
dissemination O
and O
consumption O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
fake O
news O
are O
news O
documents O
that O
are O
intentionally O
and O
verifiably O
false O
, O
and O
could O
mislead O
readers O
( O
allcott O
and O
gentzkow O
, O
2017 O
) O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
fake O
news O
can O
easily O
misguide O
public O
opinion O
, O
cause O
the O
crisis O
of O
confidence O
, O
and O
disturb O
the O
social O
order O
( O
vosoughi O
et O
al. O
, O
2018 O
) O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
it O
is O
well O
known O
that O
fake O
news O
exerted O
an O
influence O
in O
the O
past O
2016 O
us O
presidential O
elections O
( O
allcott O
and O
gentzkow O
, O
2017 O
) O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
thus O
, O
it O
is O
very O
important O
to O
develop O
effective O
methods O
for O
early O
fake O
news O
detection O
based O
on O
the O
textual O
content O
of O
the O
news O
document O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
some O
existing O
fake O
news O
detection O
methods O
rely O
heavily O
on O
various O
hand-crafted O
linguistic O
and O
semantic O
features O
for O
differentiating O
between O
news O
documents O
( O
conroy O
et O
al. O
, O
2015 O
; O
rubin O
et O
al. O
, O
2016 O
; O
rashkin O
et O
al. O
, O
2017 O
; O
khurana O
and O
intelligentie O
, O
2017 O
; O
shu O
et O
al. O
, O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
to O
avoid O
feature O
engineering O
, O
deep O
neural O
models O
such O
as O
bi-lstm O
and O
convolutional O
neural O
networks O
( O
cnn O
) O
have O
been O
employed O
( O
oshikawa O
et O
al. O
, O
2020 O
; O
wang O
, O
2017 O
; O
rodrı́guez O
and O
iglesias O
, O
2019 O
) O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
however O
, O
they O
fail O
to O
consider O
the O
sentence O
interactions O
in O
the O
document O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
vaibhav O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
showed O
that O
trusted O
news O
and O
fake O
news O
have O
different O
patterns O
of O
sentence O
interactions O
( O
vaibhav O
et O
al. O
, O
2019 O
) O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
they O
modeled O
a O
news O
document O
as O
a O
fully O
connected O
sentence O
graph O
and O
proposed O
a O
graph O
attention O
model O
for O
fake O
news O
detection O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
although O
these O
existing O
approaches O
can O
be O
effective O
, O
they O
fail O
to O
fully O
exploit O
external O
kb O
which O
could O
help O
determine O
whether O
the O
news O
is O
fake O
or O
trusted O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
external O
kb O
such O
as O
wikipedia O
contains O
a O
large O
amount O
of O
high-quality O
structured O
subjectpredicate-object O
triplets O
and O
unstructured O
entity O
descriptions O
, O
which O
could O
serve O
as O
evidence O
for O
detecting O
fake O
news O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
as O
shown O
in O
figure O
4 O
, O
the O
news O
document O
about O
“ O
mammograms O
are O
not O
effective O
at O
detecting O
breast O
tumors O
” O
is O
likely O
to O
be O
detected O
as O
fake O
news O
with O
the O
knowledge O
that O
“ O
the O
goal O
of O
mammography O
is O
the O
early O
detection O
of O
breast O
cancer O
” O
in O
the O
wikipedia O
entity O
description O
page O
1 O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
pan O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
proposed O
to O
construct O
knowledge O
graphs O
from O
positive O
and O
negative O
news O
, O
and O
apply O
transe O
to O
learn O
triplet O
scores O
for O
fake O
news O
detection O
( O
pan O
et O
al. O
, O
2018 O
) O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
nevertheless O
, O
the O
performance O
is O
largely O
influenced O
by O
construction O
of O
the O
knowledge O
graph O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
in O
this O
paper O
, O
to O
take O
full O
advantage O
of O
the O
external O
knowledge O
, O
we O
propose O
a O
novel O
endto-end O
graph O
neural O
model O
comparenet O
which O
directly O
compares O
the O
news O
to O
the O
kb O
through O
entities O
for O
fake O
news O
detection O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
in O
comparenet O
, O
we O
also O
consider O
using O
topics O
to O
enrich O
the O
news O
document O
representation O
for O
improving O
fake O
news O
detection O
, O
since O
fake O
news O
detection O
and O
topics O
are O
highly O
correlated O
( O
zhang O
et O
al. O
, O
2020 O
; O
jin O
et O
al. O
, O
2016 O
) O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
for O
example O
, O
the O
news O
documents O
in O
the O
“ O
health O
” O
topic O
are O
inclined O
towards O
false O
, O
while O
the O
documents O
belonging O
to O
the O
“ O
economy O
” O
topic O
are O
biased O
to O
be O
trusted O
instead O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
particularly O
, O
we O
first O
construct O
a O
directed O
heterogeneous O
document O
graph O
for O
each O
news O
document O
, O
containing O
sentences O
, O
topics O
and O
entities O
as O
nodes.the O
sentences O
are O
fully O
connected O
in O
bidirection O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
each O
sentence O
is O
also O
connected O
with O
its O
top O
relevant O
topics O
in O
bi-direction O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
if O
a O
sentence O
contains O
an O
entity O
, O
one O
directed O
link O
is O
built O
from O
the O
sentence O
to O
the O
entity O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
the O
reason O
for O
building O
one-way O
links O
from O
sentences O
to O
entities O
is O
to O
ensure O
that O
we O
can O
learn O
contextual O
entity O
representations O
that O
encode O
the O
semantics O
of O
the O
news O
, O
while O
avoiding O
the O
influence O
of O
the O
true O
entity O
knowledge O
to O
the O
news O
representation O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
based O
on O
the O
directed O
heterogeneous O
document O
graph O
, O
we O
develop O
a O
heterogeneous O
graph O
attention O
network O
to O
learn O
topic-enriched O
news O
representations O
and O
contextual O
entity O
representations O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
the O
learned O
contextual O
entity O
representations O
are O
then O
compared O
to O
the O
corresponding O
kb-based O
entity O
representations O
with O
a O
carefully O
designed O
entity O
comparison O
network O
, O
in O
order O
to O
capture O
the O
semantic O
consistency O
between O
the O
news O
content O
and O
external O
kb O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
finally O
, O
the O
topic-enriched O
news O
representations O
and O
the O
entity O
comparison O
features O
are O
combined O
for O
fake O
news O
classification O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
to O
facilitate O
related O
researches O
, O
we O
release O
both O
our O
code O
and O
dataset O
to O
the O
public2 O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
1https O
: O
//en.wikipedia.org/wiki/mammography O
2https O
: O
//github.com/ytc272098215/fakenewsdetection O
in O
summary O
, O
our O
main O
contributions O
include O
: O
1 O
) O
in O
this O
paper O
, O
we O
propose O
a O
novel O
end-to-end O
graph O
neural O
model O
comparenet O
which O
compares O
the O
news O
to O
the O
external O
knowledge O
through O
entities O
for O
fake O
news O
detection O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
2 O
) O
in O
comparenet O
, O
we O
also O
consider O
the O
useful O
topic O
information O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
we O
construct O
a O
directed O
heterogeneous O
document O
graph O
incorporating O
topics O
and O
entities O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
then O
we O
develop O
heterogeneous O
graph O
attention O
networks O
to O
learn O
topicenriched O
news O
representations O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
a O
novel O
entity O
comparison O
network O
is O
designed O
to O
compare O
the O
news O
to O
the O
kb O
. O

section 1
id pdf2json/2021.acl-long.62.pdf.json
3 O
) O
extensive O
experiments O
on O
two O
benchmark O
datasets O
demonstrate O
that O
our O
model O
significantly O
outperforms O
state-of-the-art O
models O
on O
fake O
news O
detection O
by O
effectively O
incorporating O
external O
knowledge O
and O
topic O
information O
. O

section 2
id pdf2json/2021.acl-long.62.pdf.json
fake O
news O
detection O
has O
attracted O
much O
attention O
in O
recent O
years O
( O
zhou O
and O
zafarani O
, O
2020 O
; O
oshikawa O
et O
al. O
, O
2020 O
) O
. O

section 2
id pdf2json/2021.acl-long.62.pdf.json
a O
lot O
of O
works O
also O
focus O
on O
the O
related O
problem O
, O
i.e. O
, O
fact O
checking O
, O
which O
aims O
to O
search O
evidence O
from O
external O
knowledge O
to O
verify O
the O
veracity O
of O
a O
claim O
( O
e.g. O
, O
a O
subject-predicateobject O
triple O
) O
( O
thorne O
et O
al. O
, O
2018 O
; O
zhou O
et O
al. O
, O
2019 O
; O
zhong O
et O
al. O
, O
2020 O
) O
. O

section 2
id pdf2json/2021.acl-long.62.pdf.json
generally O
, O
fake O
news O
detection O
usually O
focuses O
on O
news O
events O
while O
fact-checking O
is O
broader O
( O
oshikawa O
et O
al. O
, O
2020 O
) O
. O

section 2
id pdf2json/2021.acl-long.62.pdf.json
the O
approaches O
for O
fake O
news O
detection O
can O
be O
divided O
into O
two O
categories O
: O
social-based O
and O
content-based O
. O

section 3
id pdf2json/2021.acl-long.62.pdf.json
social O
context O
related O
to O
news O
documents O
contains O
rich O
information O
such O
as O
user O
profiles O
and O
social O
relationships O
to O
help O
detect O
fake O
news O
. O

section 3
id pdf2json/2021.acl-long.62.pdf.json
social O
based O
models O
basically O
include O
stance-based O
and O
propagation-based O
. O

section 3
id pdf2json/2021.acl-long.62.pdf.json
stance-based O
models O
utilize O
users O
’ O
opinions O
to O
infer O
news O
veracity O
( O
jin O
et O
al. O
, O
2016 O
; O
wu O
et O
al. O
, O
2019 O
) O
. O

section 3
id pdf2json/2021.acl-long.62.pdf.json
tacchini O
et O
al O
. O

section 3
id pdf2json/2021.acl-long.62.pdf.json
constructed O
a O
bipartite O
network O
of O
user O
and O
posts O
with O
‘ O
like O
’ O
stance O
information O
, O
and O
proposed O
a O
semisupervised O
probabilistic O
model O
to O
predict O
the O
likelihood O
of O
posts O
being O
hoaxes O
( O
tacchini O
et O
al. O
, O
2017 O
) O
. O

section 3
id pdf2json/2021.acl-long.62.pdf.json
propagation-based O
approaches O
for O
fake O
news O
detection O
are O
based O
on O
the O
basic O
assumption O
that O
the O
credibility O
of O
a O
news O
event O
is O
highly O
related O
to O
the O
credibilities O
of O
relevant O
social O
media O
posts O
. O

section 3
id pdf2json/2021.acl-long.62.pdf.json
both O
homogeneous O
( O
jin O
et O
al. O
, O
2016 O
) O
and O
heterogeneous O
credibility O
networks O
( O
gupta O
et O
al. O
, O
2012 O
; O
shu O
et O
al. O
, O
2019 O
; O
zhang O
et O
al. O
, O
2020 O
) O
have O
been O
built O
to O
model O
the O
propagation O
process O
. O

section 3
id pdf2json/2021.acl-long.62.pdf.json
for O
instance O
, O
( O
zhang O
et O
al. O
, O
2020 O
) O
constructed O
a O
heterogeneous O
network O
of O
news O
articles O
, O
creators O
and O
news O
subjects O
, O
and O
proposed O
a O
deep O
diffusive O
network O
model O
for O
incorporating O
the O
network O
structure O
information O
to O
simultaneously O
detect O
fake O
news O
articles O
, O
creators O
and O
subjects O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
on O
the O
other O
hand O
, O
news O
contents O
contain O
the O
clues O
to O
differentiate O
fake O
and O
trusted O
news O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
a O
lot O
of O
existing O
works O
extract O
specific O
writing O
styles O
such O
as O
lexical O
and O
syntactic O
features O
( O
conroy O
et O
al. O
, O
2015 O
; O
rubin O
et O
al. O
, O
2016 O
; O
khurana O
and O
intelligentie O
, O
2017 O
; O
rashkin O
et O
al. O
, O
2017 O
; O
shu O
et O
al. O
, O
2020 O
; O
oshikawa O
et O
al. O
, O
2020 O
) O
and O
sensational O
headlines O
( O
potthast O
et O
al. O
, O
2018 O
; O
sitaula O
et O
al. O
, O
2019 O
) O
for O
fake O
news O
classifier O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
to O
avoid O
hand-crafted O
feature O
engineering O
, O
neural O
models O
have O
been O
proposed O
( O
wang O
, O
2017 O
; O
rodrı́guez O
and O
iglesias O
, O
2019 O
) O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
for O
example O
, O
ibrain O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
applied O
deep O
neural O
networks O
, O
such O
as O
bilstm O
and O
convolutional O
neural O
networks O
( O
cnn O
) O
for O
fake O
news O
detection O
( O
rodrı́guez O
and O
iglesias O
, O
2019 O
) O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
however O
, O
these O
works O
fail O
to O
consider O
different O
sentence O
interaction O
patterns O
between O
trusted O
and O
fake O
news O
documents O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
vaibhav O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
proposed O
to O
model O
a O
document O
as O
a O
sentence O
graph O
capturing O
the O
sentence O
interactions O
and O
applied O
graph O
attention O
networks O
for O
learning O
document O
representation O
( O
vaibhav O
et O
al. O
, O
2019 O
) O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
pan O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
proposed O
to O
construct O
knowledge O
graphs O
from O
positive O
and O
negative O
news O
, O
and O
apply O
transe O
to O
learn O
triplet O
scores O
for O
fake O
news O
detection O
( O
pan O
et O
al. O
, O
2018 O
) O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
nevertheless O
, O
they O
relied O
heavily O
on O
the O
quality O
of O
the O
construction O
of O
knowledge O
graphs O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
in O
this O
paper O
, O
we O
propose O
a O
novel O
graph O
neural O
model O
com- O
parenet O
which O
directly O
compares O
the O
news O
to O
external O
knowledge O
for O
fake O
news O
detection O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
considering O
that O
the O
detection O
of O
fake O
news O
is O
correlated O
with O
topics O
, O
we O
also O
use O
topics O
to O
enrich O
the O
news O
representation O
for O
improving O
fake O
news O
detection O
. O

section 4
id pdf2json/2021.acl-long.62.pdf.json
some O
works O
( O
wang O
, O
2017 O
; O
khattar O
et O
al. O
, O
2019 O
; O
wang O
et O
al. O
, O
2020 O
) O
also O
consider O
incorporating O
multi-modal O
features O
such O
as O
images O
for O
improving O
fake O
news O
detection O
. O

section 5
id pdf2json/2021.acl-long.62.pdf.json
in O
this O
section O
, O
we O
detail O
our O
proposed O
fake O
news O
detection O
model O
comparenet O
, O
which O
directly O
compares O
the O
news O
to O
external O
knowledge O
for O
fake O
news O
detection O
. O

section 5
id pdf2json/2021.acl-long.62.pdf.json
as O
shown O
in O
figure O
2 O
, O
we O
also O
consider O
topics O
for O
enriching O
news O
representation O
since O
fake O
news O
detection O
is O
highly O
correlated O
with O
topics O
( O
zhang O
et O
al. O
, O
2020 O
) O
. O

section 5
id pdf2json/2021.acl-long.62.pdf.json
specifically O
, O
we O
first O
construct O
a O
directed O
heterogeneous O
document O
graph O
for O
each O
news O
document O
incorporating O
topics O
and O
entities O
as O
shown O
in O
figure O
1 O
. O

section 5
id pdf2json/2021.acl-long.62.pdf.json
the O
graph O
well O
captures O
the O
interactions O
among O
sentences O
, O
topics O
and O
entities O
. O

section 5
id pdf2json/2021.acl-long.62.pdf.json
based O
on O
the O
graph O
, O
we O
develop O
a O
heterogeneous O
graph O
attention O
network O
to O
learn O
the O
topic-enriched O
news O
representation O
as O
well O
as O
the O
contextual O
entity O
representations O
that O
encode O
the O
semantics O
of O
the O
news O
document O
. O

section 5
id pdf2json/2021.acl-long.62.pdf.json
to O
fully O
leverage O
external O
kb O
, O
we O
take O
the O
entities O
as O
the O
bridge O
between O
the O
news O
document O
and O
the O
kb O
. O

section 5
id pdf2json/2021.acl-long.62.pdf.json
we O
compare O
the O
contextual O
entity O
representations O
with O
the O
corresponding O
kb-based O
entity O
representations O
using O
a O
carefully O
designed O
entity O
comparison O
network O
. O

section 5
id pdf2json/2021.acl-long.62.pdf.json
finally O
, O
the O
obtained O
entity O
comparison O
features O
are O
combined O
with O
the O
topic-enriched O
news O
document O
representation O
for O
fake O
news O
detection O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
for O
each O
news O
document O
d O
, O
we O
construct O
a O
directed O
heterogeneous O
document O
graph O
g O
= O
( O
v O
, O
e O
) O
incorporating O
topics O
and O
entities O
, O
as O
shown O
in O
figure O
1 O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
there O
are O
three O
kinds O
of O
nodes O
in O
the O
graph O
: O
sentences O
s O
= O
{ O
s1 O
, O
s2 O
, O
· O
· O
· O
, O
sm O
} O
, O
topics O
t O
= O
{ O
t1 O
, O
t2 O
, O
· O
· O
· O
, O
tk O
} O
and O
entities O
e O
= O
{ O
e1 O
, O
e2 O
, O
· O
· O
· O
, O
en O
} O
, O
i.e. O
, O
v O
= O
s O
∪ O
t O
∪ O
e. O
the O
set O
of O
edges O
e O
represent O
the O
relations O
among O
sentences O
, O
topics O
and O
entities O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
the O
details O
of O
constructing O
the O
graph O
are O
described O
as O
follows O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
we O
first O
split O
the O
news O
document O
as O
a O
set O
of O
sentences O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
sentences O
are O
bidirectionally O
connected O
with O
each O
other O
in O
the O
graph O
, O
capturing O
the O
interaction O
of O
each O
sentence O
with O
every O
other O
sentence O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
since O
topic O
information O
is O
important O
for O
fake O
news O
detection O
( O
zhang O
et O
al. O
, O
2020 O
) O
, O
we O
apply O
the O
unsupervised O
lda O
( O
blei O
et O
al. O
, O
2003 O
) O
( O
the O
total O
topic O
number O
k O
is O
set O
as O
100 O
) O
to O
mine O
the O
latent O
topics O
t O
from O
all O
the O
sentences O
of O
all O
the O
documents O
in O
our O
dataset O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
specifically O
, O
each O
sentence O
is O
taken O
as O
a O
pseudo-document O
and O
is O
assigned O
to O
the O
top O
p O
relevant O
topics O
with O
the O
largest O
probabilities O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
thus O
, O
each O
sentence O
is O
also O
connected O
with O
its O
top O
p O
assigned O
topics O
in O
bi-direction O
, O
allowing O
the O
useful O
topic O
information O
to O
propagate O
among O
the O
sentences O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
note O
that O
we O
can O
also O
deal O
with O
new O
coming O
news O
documents O
by O
inferring O
the O
topics O
with O
trained O
lda O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
we O
identify O
the O
entities O
e O
in O
the O
document O
d O
and O
map O
them O
to O
wikipedia O
using O
the O
entity O
linking O
tool O
tagme3 O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
if O
a O
sentence O
s O
contains O
an O
entity O
e O
, O
we O
build O
a O
one-way O
directed O
edge O
from O
a O
sentence O
to O
the O
entity O
e O
, O
in O
order O
to O
allow O
only O
information O
propagation O
from O
sentences O
to O
entities O
. O

section 6
id pdf2json/2021.acl-long.62.pdf.json
in O
this O
way O
, O
we O
can O
avoid O
integrating O
true O
entity O
knowledge O
directly O
into O
news O
representation O
, O
which O
may O
mislead O
the O
detection O
of O
fake O
news O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
based O
on O
the O
above O
directed O
heterogeneous O
document O
graph O
g O
, O
we O
develop O
a O
heterogeneous O
graph O
attention O
network O
for O
learning O
the O
news O
representation O
as O
well O
as O
the O
contextual O
entity O
representations O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
it O
considers O
not O
only O
the O
weights O
of O
different O
nodes O
with O
different O
types O
( O
hu O
et O
al. O
, O
2019 O
) O
but O
also O
the O
edge O
directions O
in O
the O
heterogeneous O
graph O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
formally O
, O
we O
have O
three O
types O
t O
= O
{ O
τ1 O
, O
τ2 O
, O
τ3 O
} O
of O
nodes O
: O
sentences O
s O
, O
topics O
t O
and O
entities O
e O
with O
different O
feature O
spaces O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
we O
apply O
lstm O
to O
encode O
a O
sentence O
s O
= O
{ O
w1 O
, O
· O
· O
· O
, O
wm O
} O
and O
get O
its O
feature O
vector O
xs O
∈ O
rm O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
the O
entity O
e O
∈ O
e O
is O
initialized O
with O
the O
entity O
representations O
ekb O
∈ O
rm O
learned O
from O
the O
external O
kb O
( O
see O
subsection O
3.3.1 O
) O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
the O
topic O
t O
∈ O
t O
is O
initialized O
with O
one-hot O
vector O
xt O
∈ O
rk O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
next O
, O
consider O
the O
graph O
g O
= O
( O
v O
, O
e O
) O
where O
v O
and O
e O
represent O
the O
set O
of O
nodes O
and O
edges O
respectively O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
let O
x O
∈ O
r|v|×m O
be O
a O
matrix O
containing O
the O
nodes O
with O
their O
features O
xv O
∈ O
rm O
( O
each O
row O
xv O
is O
a O
feature O
vector O
for O
a O
node O
v O
) O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
a O
and O
d O
are O
3https O
: O
//sobigdata.d4science.org/group/tagme/ O
the O
adjacency O
matrix O
and O
the O
degree O
matrix O
, O
respectively O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
the O
heterogeneous O
convolution O
layer O
updates O
the O
( O
l O
+ O
1 O
) O
-th O
layer O
representation O
of O
the O
nodes O
h O
( O
l+1 O
) O
by O
aggregating O
the O
features O
of O
their O
neighboring O
nodes O
h O
( O
l O
) O
τ O
with O
different O
types O
τ O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
( O
initially O
, O
h O
( O
0 O
) O
= O
x O
) O
: O
h O
( O
l+1 O
) O
= O
σ O
( O
∑ O
τ∈t O
bτ O
·h O
( O
l O
) O
τ O
·w O
( O
l O
) O
τ O
) O
, O
( O
1 O
) O
where O
σ O
( O
· O
) O
denotes O
the O
activation O
function O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
nodes O
with O
different O
types O
τ O
have O
different O
transformation O
matrix O
w O
( O
l O
) O
τ O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
the O
transformation O
matrix O
w O
( O
l O
) O
τ O
considers O
the O
different O
feature O
spaces O
and O
projects O
them O
into O
an O
implicit O
common O
space O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
bτ O
∈ O
r|v|×|vτ O
| O
is O
the O
attention O
matrix O
, O
whose O
rows O
represent O
all O
the O
nodes O
and O
columns O
represent O
their O
neighboring O
nodes O
with O
the O
type O
τ O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
its O
element O
βvv′ O
in O
the O
v-th O
row O
and O
the O
v′-th O
column O
is O
computed O
as O
follows O
: O
βvv′ O
= O
softmaxv′ O
( O
σ O
( O
νt O
· O
ατ O
[ O
hv O
, O
hv′ O
] O
) O
) O
, O
( O
2 O
) O
where O
ν O
is O
the O
attention O
vector O
and O
ατ O
is O
the O
typelevel O
attention O
weight O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
hv O
and O
hv′ O
are O
respectively O
the O
representation O
of O
the O
current O
node O
v O
and O
its O
neighboring O
node O
v′ O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
softmax O
function O
is O
applied O
to O
normalize O
across O
the O
neighboring O
nodes O
of O
node O
v. O
we O
calculate O
the O
type-level O
attention O
weights O
ατ O
based O
on O
the O
current O
node O
embedding O
hv O
and O
the O
type O
embedding O
hτ O
= O
∑ O
v′ O
ãvv′hv′ O
( O
the O
weighted O
sum O
of O
the O
neighboring O
node O
embeddings O
hv′ O
with O
the O
type O
τ O
, O
where O
the O
weight O
matrix O
ã O
= O
d− O
1 O
2 O
( O
a+ O
i O
) O
d− O
1 O
2 O
is O
the O
normalized O
adjacency O
matrix O
with O
added O
self-connections O
) O
as O
follows O
: O
ατ O
= O
softmaxτ O
( O
σ O
( O
µtτ O
· O
[ O
hv O
, O
hτ O
] O
) O
) O
, O
( O
3 O
) O
where O
µτ O
is O
the O
attention O
vector O
for O
the O
type O
τ O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
softmax O
function O
is O
applied O
to O
normalize O
across O
all O
the O
types O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
after O
l-layer O
heterogeneous O
graph O
convolution O
, O
we O
can O
finally O
get O
all O
the O
node O
( O
including O
sentences O
and O
entities O
) O
representations O
aggregating O
neighborhood O
semantics O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
we O
use O
max O
pooling O
over O
the O
representations O
of O
the O
sentence O
nodes O
hs O
∈ O
rn O
to O
obtain O
the O
final O
topic-enriched O
news O
document O
embedding O
hd O
∈ O
rn O
. O

section 7
id pdf2json/2021.acl-long.62.pdf.json
the O
learned O
entity O
representations O
that O
encode O
the O
contextual O
semantics O
of O
the O
document O
are O
taken O
as O
contextual O
entity O
representations O
ec O
∈ O
rn O
. O

section 8
id pdf2json/2021.acl-long.62.pdf.json
in O
this O
subsection O
, O
we O
detail O
our O
entity O
comparison O
network O
which O
compares O
the O
learned O
contextual O
entity O
embeddings O
ec O
to O
the O
corresponding O
kbbased O
entity O
embeddings O
ekb O
. O

section 8
id pdf2json/2021.acl-long.62.pdf.json
we O
believe O
entity O
comparison O
features O
could O
improve O
fake O
news O
detection O
based O
on O
the O
assumption O
that O
ec O
learned O
from O
trusted O
news O
document O
can O
be O
better O
aligned O
with O
the O
corresponding O
ekb O
; O
while O
inverse O
for O
fake O
news O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
we O
first O
illustrate O
how O
to O
take O
full O
advantage O
of O
both O
structured O
subject-predicate-object O
triplets O
and O
unstructured O
textual O
entity O
descriptions O
in O
the O
kb O
( O
i.e. O
, O
wikipedia O
) O
to O
learn O
kb-based O
entity O
representations O
ekb O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
structural O
embedding O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
a O
wide O
range O
of O
knowledge O
graph O
embedding O
methods O
can O
be O
applied O
to O
obtain O
structured O
entity O
embeddings O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
due O
to O
the O
simplicity O
of O
transe O
( O
bordes O
et O
al. O
, O
2013 O
) O
, O
we O
adopted O
transe O
to O
learn O
entity O
representations O
es O
∈ O
rm O
from O
the O
triplets O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
formally O
, O
given O
a O
triplet O
( O
h O
, O
r O
, O
t O
) O
, O
transe O
regards O
a O
relationship O
r O
as O
a O
translation O
vector O
r O
from O
the O
head O
entity O
h O
to O
the O
tail O
entity O
t O
, O
namely O
h O
+ O
r O
= O
t. O
textual O
embedding O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
for O
each O
entity O
, O
we O
take O
the O
first O
paragraph O
of O
the O
corresponding O
wikipedia O
page O
as O
its O
text O
description O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
then O
we O
apply O
lstm O
( O
hochreiter O
and O
schmidhuber O
, O
1997 O
) O
to O
learn O
entity O
representations O
ed O
∈ O
rm O
that O
encode O
the O
entity O
descriptions O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
gating O
integration O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
since O
both O
the O
structural O
triplets O
and O
textual O
description O
provide O
valuable O
information O
for O
an O
entity O
, O
we O
integrate O
these O
information O
into O
a O
joint O
representation O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
particularly O
, O
as O
we O
have O
the O
structural O
embedding O
es O
and O
textual O
embedding O
ed O
, O
we O
adopt O
a O
learnable O
gating O
function O
to O
integrate O
entity O
embeddings O
from O
the O
two O
sources O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
formally O
, O
ekb O
= O
ge O
es O
+ O
( O
1− O
ge O
) O
ed O
, O
( O
4 O
) O
where O
ge O
∈ O
rm O
is O
a O
gating O
vector O
( O
w.r.t O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
the O
entity O
e O
) O
to O
trade-off O
information O
from O
the O
two O
sources O
and O
its O
elements O
are O
in O
[ O
0 O
, O
1 O
] O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
denotes O
elementwise O
multiplication O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
the O
gating O
vector O
ge O
means O
that O
each O
dimension O
of O
es O
and O
ed O
are O
summed O
by O
different O
weights O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
to O
constrain O
the O
value O
of O
each O
element O
in O
[ O
0 O
, O
1 O
] O
, O
we O
compute O
the O
gate O
ge O
with O
the O
sigmoid O
function O
: O
ge O
= O
σ O
( O
g̃e O
) O
, O
( O
5 O
) O
where O
g̃e O
∈ O
rm O
is O
a O
real-value O
vector O
and O
is O
learned O
in O
the O
training O
process O
. O

section 9
id pdf2json/2021.acl-long.62.pdf.json
after O
fusing O
the O
two O
types O
of O
embeddings O
with O
the O
gating O
function O
, O
we O
obtain O
the O
final O
kb-based O
entity O
embeddings O
ekb O
∈ O
rm O
which O
encode O
both O
structural O
information O
from O
the O
triplets O
and O
textual O
information O
from O
the O
entity O
descriptions O
in O
the O
kb O
. O

section 10
id pdf2json/2021.acl-long.62.pdf.json
we O
then O
perform O
entity-to-entity O
comparison O
between O
the O
news O
document O
and O
the O
kb O
, O
to O
capture O
the O
semantic O
consistency O
between O
the O
news O
content O
and O
the O
kb O
. O

section 10
id pdf2json/2021.acl-long.62.pdf.json
we O
calculate O
a O
comparison O
vector O
ai O
between O
each O
contextual O
entity O
representation O
ec O
∈ O
rn O
and O
its O
corresponding O
kb-based O
entity O
embedding O
ekb O
∈ O
rm O
. O

section 10
id pdf2json/2021.acl-long.62.pdf.json
ai O
= O
fcmp O
( O
ec O
, O
we O
· O
ekb O
) O
, O
( O
6 O
) O
where O
fcmp O
( O
) O
denotes O
the O
comparison O
function O
, O
and O
we O
∈ O
rn×m O
is O
a O
transformation O
matrix O
. O

section 10
id pdf2json/2021.acl-long.62.pdf.json
to O
measure O
the O
embedding O
closeness O
and O
relevance O
( O
shen O
et O
al. O
, O
2018 O
) O
, O
we O
design O
our O
comparison O
function O
as O
: O
fcmp O
( O
x O
, O
y O
) O
= O
wa O
[ O
x− O
y O
, O
x O
y O
] O
, O
( O
7 O
) O
where O
wa O
∈ O
rn×2n O
is O
a O
transformation O
matrix O
and O
is O
hadamard O
product O
, O
i.e. O
, O
element-wise O
product O
. O

section 10
id pdf2json/2021.acl-long.62.pdf.json
the O
final O
output O
comparison O
feature O
vector O
c O
∈ O
rn O
is O
obtained O
by O
the O
max O
pooling O
over O
the O
alignment O
vectors O
a O
= O
[ O
a1 O
, O
a2 O
, O
... O
, O
an O
] O
of O
all O
the O
entities O
e O
= O
{ O
e1 O
, O
e2 O
, O
... O
, O
en O
} O
in O
the O
news O
document O
. O

section 11
id pdf2json/2021.acl-long.62.pdf.json
after O
obtaining O
the O
comparison O
vector O
c O
∈ O
rn O
and O
the O
final O
news O
document O
representation O
vector O
hd O
∈ O
rn O
, O
we O
concatenate O
and O
feed O
them O
into O
a O
softmax O
layer O
for O
fake O
news O
classification O
. O

section 11
id pdf2json/2021.acl-long.62.pdf.json
formally O
, O
z O
= O
softmax O
( O
wo O
[ O
hd O
, O
c O
] O
+ O
bo O
) O
, O
( O
8 O
) O
where O
wo O
and O
bo O
are O
the O
parameter O
matrix O
and O
vection O
of O
a O
linear O
transformation O
. O

section 11
id pdf2json/2021.acl-long.62.pdf.json
during O
model O
training O
, O
we O
exploit O
the O
cross-entropy O
loss O
over O
the O
training O
data O
with O
the O
l2-norm O
of O
the O
parameters O
: O
l O
= O
− O
∑ O
i∈dtrain O
∑ O
j=1 O
yij O
· O
logzij O
+ O
η O
‖θ‖2 O
, O
( O
9 O
) O
where O
dtrain O
is O
the O
set O
of O
news O
documents O
for O
training O
, O
y O
is O
the O
corresponding O
label O
indicator O
matrix O
, O
θ O
is O
the O
model O
parameters O
, O
and O
η O
is O
regularization O
factor O
. O

section 11
id pdf2json/2021.acl-long.62.pdf.json
for O
model O
optimization O
, O
we O
adopt O
the O
gradient O
descent O
algorithm O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
we O
conduct O
extensive O
experiments O
across O
various O
settings O
and O
datasets O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
following O
the O
previous O
work O
( O
vaibhav O
et O
al. O
, O
2019 O
) O
, O
we O
use O
sln O
: O
satirical O
and O
legitimate O
news O
database O
( O
rubin O
et O
al. O
, O
2016 O
) O
, O
and O
lun O
: O
labeled O
unreliable O
news O
dataset O
( O
rashkin O
et O
al. O
, O
2017 O
) O
for O
our O
experiments O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
table O
1 O
shows O
the O
statistics O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
our O
baseline O
models O
include O
deep O
neural O
models O
: O
lstm O
( O
hochreiter O
and O
schmidhuber O
, O
1997 O
) O
, O
cnn O
( O
kim O
, O
2014 O
) O
, O
bert+lstm O
( O
vaibhav O
et O
al. O
, O
2019 O
) O
( O
bert O
for O
sentence O
encoder O
and O
then O
lstm O
for O
document O
encoder O
) O
and O
bert O
( O
devlin O
et O
al. O
, O
2019 O
) O
( O
directly O
for O
document O
encoder O
) O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
we O
also O
compare O
our O
model O
with O
graph O
neural O
models O
: O
gcn O
and O
gat O
based O
on O
an O
undirected O
fully-connected O
sentence O
graph O
, O
which O
use O
attention O
pooling O
or O
max O
pooling O
for O
learning O
news O
document O
representation O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
for O
fair O
comparison O
with O
the O
previous O
work O
( O
vaibhav O
et O
al. O
, O
2019 O
) O
, O
we O
use O
lstm O
to O
encode O
sentences O
with O
randomly O
initialized O
word O
embeddings O
, O
which O
is O
the O
same O
as O
all O
the O
graph O
neural O
baselines O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
we O
run O
our O
model O
5 O
times O
and O
report O
the O
micro-averaged O
( O
precision O
= O
recall O
= O
f1 O
) O
and O
macro-averaged O
scores O
( O
precision O
, O
recall O
, O
f1 O
) O
in O
all O
the O
settings O
including O
2-way O
and O
4-way O
classification O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
2-way O
classification O
: O
we O
use O
the O
satirical O
and O
trusted O
news O
articles O
from O
lun-train O
for O
training O
, O
lun-test O
for O
validation O
and O
evaluate O
our O
model O
on O
the O
entire O
sln O
dataset O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
this O
is O
done O
to O
emulate O
a O
real-world O
scenario O
where O
we O
want O
to O
see O
the O
performance O
of O
our O
model O
on O
an O
out-of-domain O
dataset O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
4-way O
classification O
: O
we O
split O
the O
lun-train O
into O
a O
80:20 O
split O
to O
create O
our O
training O
and O
validation O
set O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
we O
use O
the O
lun-test O
as O
our O
in-domain O
test O
set O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
experimental O
setting O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
in O
our O
experiments O
, O
we O
set O
the O
number O
of O
topics O
k O
= O
100 O
in O
lda O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
each O
sentence O
is O
assigned O
to O
top O
p O
= O
2 O
topics O
with O
the O
largest O
probabilities O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
the O
layer O
number O
of O
our O
heterogeneous O
graph O
convolution O
is O
set O
as O
l O
= O
1 O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
these O
parameters O
are O
chosen O
according O
to O
the O
best O
experimental O
results O
on O
validation O
set O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
the O
other O
hyper-parameters O
are O
set O
as O
the O
same O
as O
the O
baseline O
( O
vaibhav O
et O
al. O
, O
2019 O
) O
for O
fair O
comparison O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
specifically O
, O
all O
the O
hidden O
dimensions O
used O
in O
our O
model O
are O
set O
as O
m O
= O
100 O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
the O
node O
embedding O
dimension O
n= O
32 O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
for O
gcn O
, O
gat O
and O
comparenet O
, O
we O
set O
the O
activation O
function O
as O
leakyrelu O
with O
slope O
0.2 O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
for O
model O
training O
, O
we O
train O
the O
models O
for O
a O
maximum O
of O
15 O
epochs O
and O
use O
adam O
optimizer O
with O
learning O
rate O
0.001 O
. O

section 12
id pdf2json/2021.acl-long.62.pdf.json
we O
set O
l2 O
normalization O
factor O
η O
as O
1e-6 O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
table O
2 O
shows O
the O
results O
for O
the O
two-way O
classification O
between O
satirical O
and O
trusted O
news O
articles O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
we O
report O
only O
micro O
f1 O
since O
micro O
precision=recall=f1 O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
as O
we O
can O
see O
, O
our O
proposed O
model O
comparenet O
significantly O
outperforms O
all O
the O
state-of-the-art O
baselines O
in O
terms O
of O
all O
the O
metrics O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
compared O
to O
the O
best O
baseline O
model O
, O
comparenet O
improves O
both O
micro O
f1 O
and O
macro O
f1 O
by O
nearly O
3 O
% O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
we O
can O
also O
find O
that O
the O
graph O
neural O
network O
based O
models O
gcn O
and O
gat O
all O
perform O
better O
than O
the O
deep O
neural O
models O
including O
cnn O
, O
lstm O
and O
bert O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
the O
reason O
is O
that O
the O
deep O
neural O
models O
fail O
to O
consider O
the O
interactions O
between O
sentences O
, O
which O
is O
important O
for O
fake O
news O
detection O
since O
different O
interaction O
patterns O
are O
observed O
in O
trusted O
and O
fake O
news O
documents O
( O
vaibhav O
et O
al. O
, O
2019 O
) O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
our O
model O
comparenet O
further O
improves O
fake O
news O
detection O
by O
effectively O
exploiting O
the O
topics O
as O
well O
as O
the O
external O
kb O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
the O
topics O
enrich O
the O
news O
representation O
, O
and O
the O
external O
kb O
offers O
evidences O
for O
fake O
news O
detection O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
we O
also O
present O
the O
results O
of O
four-way O
classification O
in O
table O
3 O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
consistently O
, O
all O
graph O
neural O
models O
capturing O
sentence O
interactions O
outperform O
the O
deep O
neural O
models O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
our O
model O
comparenet O
achieves O
the O
best O
performance O
in O
terms O
of O
all O
metrics O
. O

section 13
id pdf2json/2021.acl-long.62.pdf.json
we O
believe O
that O
our O
model O
comparenet O
benefits O
from O
the O
topics O
and O
external O
knowledge O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
in O
this O
subsection O
, O
we O
conduct O
experiments O
to O
study O
the O
effectiveness O
of O
each O
module O
in O
comparenet O
and O
the O
way O
we O
incorporate O
external O
knowledge O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
we O
study O
the O
average O
performance O
of O
5 O
runs O
on O
the O
lun-test O
set O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
as O
shown O
in O
table O
4 O
, O
we O
test O
the O
performance O
of O
comparenet O
removing O
structured O
triplets O
, O
removing O
the O
entire O
external O
knowledge O
, O
removing O
topics O
, O
and O
removing O
both O
topics O
and O
external O
knowledge O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
in O
the O
last O
two O
rows O
, O
we O
further O
examine O
the O
constructed O
directed O
heterogeneous O
document O
graph O
and O
the O
designed O
entity O
comparison O
function O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
the O
variant O
comparenet O
( O
undirected O
) O
does O
not O
consider O
the O
edge O
directions O
of O
the O
directed O
heterogeneous O
document O
graph O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
the O
variant O
model O
comparenet O
( O
concatenation O
) O
replaces O
the O
entity O
comparison O
function O
as O
the O
simple O
concatenation O
operation O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
as O
we O
can O
see O
from O
table O
4 O
, O
removing O
structural O
entity O
knowledge O
( O
i.e. O
, O
w/o O
structured O
triplets O
) O
leads O
to O
slight O
performance O
drop O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
if O
we O
remove O
the O
entire O
external O
knowledge O
( O
i.e. O
, O
w/o O
entity O
cmp O
) O
, O
the O
performance O
decreases O
by O
around O
1.3 O
% O
and O
1.8 O
% O
on O
micro O
f1 O
and O
macro O
f1 O
, O
respectively O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
removing O
topics O
( O
i.e. O
, O
w/o O
topics O
) O
will O
comparably O
impair O
the O
performance O
, O
which O
shows O
that O
the O
topic O
information O
is O
as O
important O
as O
the O
external O
knowledge O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
removing O
both O
topics O
and O
external O
knowledge O
( O
i.e. O
, O
w/o O
both O
) O
will O
lead O
to O
substantial O
performance O
drop O
( O
4.0-5.0 O
% O
) O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
it O
demonstrates O
the O
importance O
of O
both O
topics O
and O
external O
knowledge O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
the O
variant O
model O
comparenet O
( O
undirected O
) O
although O
incorporating O
both O
topics O
and O
external O
knowledge O
achieves O
lower O
performance O
than O
comparenet O
w/o O
entity O
cmp O
and O
comparenet O
w/o O
topics O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
the O
reason O
could O
be O
that O
comparenet O
( O
undirected O
) O
directly O
aggregates O
the O
true O
entity O
knowledge O
into O
the O
news O
representation O
in O
graph O
convolution O
without O
considering O
the O
directed O
edges O
, O
which O
misleads O
the O
classifier O
for O
differentiating O
fake O
news O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
this O
verifies O
the O
appropriateness O
of O
our O
constructed O
directed O
heterogeneous O
document O
graph O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
the O
last O
variant O
comparenet O
( O
concatenation O
) O
also O
performs O
lower O
than O
comparenet O
w/o O
entity O
cmp O
, O
further O
indicating O
that O
directly O
concatenating O
true O
entity O
knowledge O
is O
not O
a O
good O
way O
for O
incorporating O
entity O
knowledge O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
its O
performance O
drops O
by O
around O
2.0 O
% O
compared O
to O
comparenet O
. O

section 14
id pdf2json/2021.acl-long.62.pdf.json
these O
demonstrate O
the O
effectiveness O
of O
the O
carefully O
designed O
entity O
comparison O
network O
in O
comparenet O
. O

section 15
id pdf2json/2021.acl-long.62.pdf.json
figure O
3 O
shows O
the O
performance O
( O
micro O
and O
macro O
f1 O
) O
of O
our O
model O
comparenet O
on O
lun O
validation O
set O
with O
different O
number O
of O
top O
assigned O
topics O
p O
to O
each O
sentence O
. O

section 15
id pdf2json/2021.acl-long.62.pdf.json
as O
we O
can O
see O
clearly O
, O
micro O
f1 O
and O
macro O
f1 O
first O
consistently O
rises O
with O
the O
increase O
of O
p O
and O
then O
drops O
when O
p O
is O
larger O
than O
2 O
. O

section 15
id pdf2json/2021.acl-long.62.pdf.json
this O
may O
because O
that O
connecting O
too O
many O
lowprobability O
topics O
will O
introduce O
some O
noise O
. O

section 15
id pdf2json/2021.acl-long.62.pdf.json
thus O
, O
in O
our O
experiments O
, O
we O
set O
p O
= O
2 O
. O

section 16
id pdf2json/2021.acl-long.62.pdf.json
to O
further O
illustrate O
why O
our O
model O
outperforms O
state-of-the-art O
baseline O
gat+attn O
( O
vaibhav O
et O
al. O
, O
2019 O
) O
, O
we O
present O
two O
real O
news O
examples O
from O
the O
lun-test O
set O
. O

section 16
id pdf2json/2021.acl-long.62.pdf.json
the O
baseline O
model O
gat+attn O
and O
the O
variant O
model O
comparenet O
w/o O
entity O
cmp O
mistakenly O
predict O
these O
two O
examples O
as O
trusted O
news O
, O
while O
our O
model O
comparenet O
can O
successfully O
predict O
both O
of O
them O
. O

section 16
id pdf2json/2021.acl-long.62.pdf.json
as O
we O
can O
see O
from O
figure O
4 O
, O
the O
content O
of O
the O
news O
document O
is O
in O
conflict O
with O
the O
entity O
description O
from O
wikipedia O
. O

section 16
id pdf2json/2021.acl-long.62.pdf.json
specifically O
, O
the O
news O
about O
“ O
fda O
target O
and O
threaten O
the O
natural O
health O
community O
” O
delivers O
contrary O
meaning O
from O
the O
entity O
description O
that O
“ O
fda O
is O
responsible O
for O
protecting O
and O
promoting O
public O
health O
” O
4 O
. O

section 16
id pdf2json/2021.acl-long.62.pdf.json
similarly O
, O
the O
news O
document O
about O
“ O
mammograms O
are O
not O
effective O
at O
detecting O
breast O
tumors O
” O
conveys O
different O
meaning O
from O
the O
entity O
description O
of O
“ O
mammograms O
” O
. O

section 16
id pdf2json/2021.acl-long.62.pdf.json
we O
believe O
that O
our O
model O
comparenet O
benefits O
from O
the O
comparison O
to O
wikipedia O
knowledge O
by O
the O
entity O
comparison O
network O
. O

section 16
id pdf2json/2021.acl-long.62.pdf.json
we O
find O
there O
are O
also O
unsuccessful O
cases O
since O
an O
entity O
could O
be O
mistakenly O
linked O
to O
a O
wrong O
entity O
in O
the O
wikipedia O
. O

section 17
id pdf2json/2021.acl-long.62.pdf.json
in O
this O
paper O
, O
we O
propose O
a O
novel O
end-to-end O
graph O
neural O
model O
comparenet O
which O
compares O
the O
news O
to O
the O
external O
knowledge O
for O
fake O
news O
detection O
. O

section 17
id pdf2json/2021.acl-long.62.pdf.json
considering O
that O
the O
detection O
of O
fake O
news O
is O
correlated O
with O
topics O
, O
in O
our O
model O
, O
we O
also O
use O
topics O
to O
enrich O
the O
news O
document O
representation O
for O
improving O
fake O
news O
detection O
. O

section 17
id pdf2json/2021.acl-long.62.pdf.json
particularly O
, O
we O
first O
construct O
a O
directed O
heterogeneous O
document O
graph O
for O
each O
news O
document O
capturing O
the O
interactions O
among O
sentences O
, O
topics O
and O
entities O
. O

section 17
id pdf2json/2021.acl-long.62.pdf.json
4https O
: O
//en.wikipedia.org/wiki/food O
and O
drug O
administration O
based O
on O
the O
graph O
, O
we O
develop O
a O
heterogeneous O
graph O
attention O
network O
for O
learning O
topic-enriched O
news O
representation O
as O
well O
as O
contextual O
entity O
representations O
that O
encode O
the O
semantics O
of O
the O
content O
of O
the O
news O
document O
. O

section 17
id pdf2json/2021.acl-long.62.pdf.json
to O
capture O
the O
semantic O
consistency O
of O
the O
news O
content O
and O
the O
kb O
, O
the O
learned O
contextual O
entity O
representations O
are O
then O
compared O
to O
the O
kb-based O
entity O
representations O
, O
with O
a O
carefully O
designed O
entity O
comparison O
network O
. O

section 17
id pdf2json/2021.acl-long.62.pdf.json
finally O
, O
the O
obtained O
entity O
comparison O
features O
are O
combined O
with O
the O
news O
representation O
for O
an O
improved O
fake O
news O
classifier O
. O

section 17
id pdf2json/2021.acl-long.62.pdf.json
experiments O
on O
two O
benchmark O
datasets O
have O
demonstrated O
the O
effectiveness O
of O
the O
way O
we O
incorporate O
the O
external O
knowledge O
and O
topics O
. O

section 17
id pdf2json/2021.acl-long.62.pdf.json
in O
future O
work O
, O
we O
will O
explore O
a O
better O
way O
to O
combine O
multi-modal O
data O
( O
e.g. O
, O
images O
) O
and O
external O
knowledge O
for O
fake O
news O
detection O
. O

section 18
id pdf2json/2021.acl-long.62.pdf.json
the O
work O
is O
supported O
by O
the O
national O
natural O
science O
fundation O
of O
china O
( O
no O
. O

section 18
id pdf2json/2021.acl-long.62.pdf.json
61806020 O
, O
u1936220 O
, O
61972047 O
, O
62076245 O
) O
and O
the O
microsoft O
research O
asia O
’ O
s O
star O
track O
project O
. O

section TITLE
id pdf2json/2021.acl-long.83.pdf.json
a O
dqn-based O
approach O
to O
finding O
precise O
evidences O
for O
fact O
verification O

section ABSTRACT
id pdf2json/2021.acl-long.83.pdf.json
computing O
precise O
evidences O
, O
namely O
minimal O
sets O
of O
sentences O
that O
support O
or O
refute O
a O
given O
claim O
, O
rather O
than O
larger O
evidences O
is O
crucial O
in O
fact O
verification O
( O
fv O
) O
, O
since O
larger O
evidences O
may O
contain O
conflicting O
pieces O
some O
of O
which O
support O
the O
claim O
while O
the O
other O
refute O
, O
thereby O
misleading O
fv O
. O

section ABSTRACT
id pdf2json/2021.acl-long.83.pdf.json
despite O
being O
important O
, O
precise O
evidences O
are O
rarely O
studied O
by O
existing O
methods O
for O
fv O
. O

section ABSTRACT
id pdf2json/2021.acl-long.83.pdf.json
it O
is O
challenging O
to O
find O
precise O
evidences O
due O
to O
a O
large O
search O
space O
with O
lots O
of O
local O
optimums O
. O

section ABSTRACT
id pdf2json/2021.acl-long.83.pdf.json
inspired O
by O
the O
strong O
exploration O
ability O
of O
the O
deep O
q-learning O
network O
( O
dqn O
) O
, O
we O
propose O
a O
dqn-based O
approach O
to O
retrieval O
of O
precise O
evidences O
. O

section ABSTRACT
id pdf2json/2021.acl-long.83.pdf.json
in O
addition O
, O
to O
tackle O
the O
label O
bias O
on O
q-values O
computed O
by O
dqn O
, O
we O
design O
a O
postprocessing O
strategy O
which O
seeks O
best O
thresholds O
for O
determining O
the O
true O
labels O
of O
computed O
evidences O
. O

section ABSTRACT
id pdf2json/2021.acl-long.83.pdf.json
experimental O
results O
confirm O
the O
effectiveness O
of O
dqn O
in O
computing O
precise O
evidences O
and O
demonstrate O
improvements O
in O
achieving O
accurate O
claim O
verification.1 O

section 0
id pdf2json/2021.acl-long.83.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
1030–1039 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.83.pdf.json
©2021 O
association O
for O
computational O
linguistics O
1030 O

section 1
id pdf2json/2021.acl-long.83.pdf.json
with O
the O
growing O
false O
information O
, O
such O
as O
fake O
news O
, O
political O
deception O
and O
online O
rumors O
, O
automatic O
fact-checking O
systems O
have O
emerged O
to O
automatically O
identify O
and O
filter O
this O
information O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
fact O
verification O
( O
fv O
) O
is O
a O
special O
fact-checking O
task O
that O
aims O
to O
retrieve O
related O
evidences O
from O
a O
text O
corpus O
to O
verify O
a O
textual O
claim O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
taking O
figure O
1 O
as O
example O
, O
an O
existing O
method O
for O
fv O
first O
retrieves O
related O
documents O
from O
the O
given O
corpus O
at O
stage O
1 O
( O
namely O
the O
document O
retrieval O
stage O
) O
, O
then O
finds O
key O
sentences O
from O
the O
documents O
at O
stage O
2 O
( O
namely O
the O
sentence O
selection O
stage O
) O
, O
and O
finally O
treats O
the O
set O
of O
key O
sentences O
as O
an O
evidence O
to O
verify O
the O
claim O
at O
stage O
∗corresponding O
author O
1source O
code O
and O
data O
are O
available O
at O
https O
: O
// O
github.com/sysulic/dqn-fv O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
3 O
( O
namely O
the O
claim O
verification O
stage O
) O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
as O
can O
be O
seen O
in O
this O
example O
, O
it O
is O
desirable O
to O
retrieve O
an O
evidence O
consisting O
of O
the O
first O
two O
sentences O
only O
, O
since O
it O
does O
not O
contain O
unnecessary O
sentences O
to O
determine O
the O
truthfulness O
of O
the O
claim O
and O
can O
alleviate O
human O
efforts O
to O
further O
validate O
the O
evidence O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
more O
importantly O
, O
an O
evidence O
containing O
unnecessary O
sentences O
may O
involve O
conflicting O
pieces O
some O
of O
which O
support O
the O
claim O
while O
the O
other O
refute O
the O
claim O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
thus O
, O
it O
is O
crucial O
to O
compute O
minimal O
sets O
of O
sentences O
that O
can O
determine O
the O
truthfulness O
of O
the O
claim O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
in O
this O
paper O
, O
we O
refer O
to O
a O
minimal O
set O
of O
sentences O
that O
supports O
or O
refutes O
a O
given O
claim O
as O
a O
precise O
evidence O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
existing O
methods O
for O
fv O
do O
not O
target O
the O
retrieval O
of O
precise O
evidences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
most O
existing O
studies O
( O
thorne O
et O
al. O
, O
2018b O
; O
nie O
et O
al. O
, O
2019 O
; O
zhou O
et O
al. O
, O
2019 O
; O
liu O
et O
al. O
, O
2020 O
; O
zhong O
et O
al. O
, O
2020 O
; O
ye O
et O
al. O
, O
2020 O
; O
subramanian O
and O
lee O
, O
2020 O
; O
wang O
et O
al. O
, O
2020 O
) O
formulate O
fv O
as O
a O
three-stage O
pipeline O
task O
as O
illustrated O
in O
figure O
1 O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
this O
way O
makes O
the O
retrieval O
of O
precise O
evidences O
extremely O
difficult O
since O
the O
sentence O
selection O
stage O
is O
required O
to O
select O
a O
precise O
set O
of O
relevant O
sentences O
rather O
than O
a O
fixed O
number O
of O
sentences O
as O
in O
existing O
methods O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
to O
the O
best O
of O
our O
knowledge O
, O
twowingos O
( O
yin O
and O
roth O
, O
2018 O
) O
is O
the O
only O
method O
by O
now O
which O
does O
not O
follow O
the O
three-stage O
pipeline O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
instead O
, O
it O
exploits O
a O
supervised O
training O
scheme O
to O
train O
the O
last O
two O
stages O
jointly O
and O
is O
able O
to O
compute O
precise O
evidences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
however O
, O
it O
exhibits O
a O
significantly O
worse O
performance O
than O
other O
state-ofthe-art O
methods O
for O
fv O
, O
especially O
in O
terms O
of O
the O
recall O
of O
evidences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
therefore O
, O
there O
is O
still O
a O
need O
for O
designing O
new O
methods O
to O
compute O
precise O
evidences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
these O
methods O
are O
expected O
to O
achieve O
better O
performance O
than O
twowingos O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
it O
is O
challenging O
to O
compute O
precise O
evidences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
on O
one O
hand O
, O
the O
search O
space O
for O
precise O
evidences O
is O
very O
large O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
for O
example O
, O
in O
the O
benchmark O
fact O
extraction O
and O
verification O
( O
fever O
) O
dataset O
( O
thorne O
et O
al. O
, O
2018b O
) O
the O
average O
number O
of O
sentences O
for O
each O
claim O
input O
to O
the O
sentence O
selection O
stage O
is O
40 O
, O
and O
an O
output O
evidence O
has O
up O
to O
5 O
sentences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
hence O
there O
are O
up O
to∑5 O
i=1c O
i O
40 O
= O
760 O
, O
098 O
candidates O
in O
the O
search O
space O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
on O
the O
other O
hand O
, O
greedy O
search O
of O
precise O
evidences O
easily O
falls O
into O
a O
local O
optimum O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
as O
shown O
in O
our O
experiments O
( O
see O
table O
6 O
) O
, O
a O
greedy O
search O
method O
does O
not O
perform O
well O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
inspired O
by O
the O
strong O
exploration O
ability O
of O
the O
deep O
q-learning O
network O
( O
dqn O
) O
( O
mnih O
et O
al. O
, O
2015 O
) O
, O
we O
develop O
a O
dqn-based O
approach O
to O
retrieval O
of O
precise O
evidences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
in O
this O
approach O
, O
we O
first O
employ O
dqn O
to O
compute O
candidate O
pairs O
of O
precise O
evidences O
and O
their O
labels O
, O
and O
then O
use O
a O
post-processing O
strategy O
to O
refine O
candidate O
pairs O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
we O
notice O
that O
q-values O
computed O
by O
dqn O
has O
label O
bias O
due O
to O
two O
reasons O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
on O
one O
hand O
, O
the O
label O
“ O
not O
enough O
info O
” O
does O
not O
locate O
at O
the O
same O
concept O
level O
as O
“ O
supports O
” O
or O
“ O
refutes O
” O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
on O
the O
other O
hand O
, O
there O
is O
not O
a O
fixed O
range O
for O
q-values O
, O
making O
q-values O
hard O
to O
accurately O
estimate O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
thus O
, O
a O
post-processing O
strategy O
is O
needed O
to O
tackle O
the O
label O
bias O
on O
q-values O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
we O
develop O
such O
a O
strategy O
to O
seek O
best O
thresholds O
in O
determining O
the O
true O
labels O
of O
computed O
evidences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
our O
experimental O
results O
on O
fever O
( O
thorne O
et O
al. O
, O
2018b O
) O
confirm O
that O
our O
dqn-based O
approach O
is O
effective O
in O
finding O
precise O
evidences O
. O

section 1
id pdf2json/2021.acl-long.83.pdf.json
more O
importantly O
, O
the O
approach O
is O
shown O
to O
outper- O
form O
state-of-the-art O
methods O
for O
fv O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
the O
fever O
1.0 O
shared O
task O
( O
thorne O
et O
al. O
, O
2018b O
) O
aims O
to O
develop O
an O
automatic O
fact O
verification O
system O
to O
determine O
the O
truthfulness O
of O
a O
textual O
claim O
by O
extracting O
related O
evidences O
from O
wikipedia O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
thorne O
et O
al O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
( O
2018a O
) O
has O
formalized O
this O
task O
, O
released O
a O
large-scale O
benchmark O
dataset O
fever O
( O
thorne O
et O
al. O
, O
2018b O
) O
, O
and O
designed O
the O
three-stage O
pipeline O
framework O
for O
fv O
, O
which O
consists O
of O
the O
document O
retrieval O
stage O
, O
the O
sentence O
selection O
stage O
and O
the O
claim O
verification O
stage O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
most O
existing O
methods O
follow O
this O
framework O
and O
mainly O
focus O
on O
the O
last O
stage O
( O
liu O
et O
al. O
, O
2020 O
) O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
for O
the O
document O
retrieval O
stage O
, O
most O
methods O
reuse O
the O
document O
retrieval O
component O
of O
topperforming O
systems O
( O
hanselowski O
et O
al. O
, O
2018 O
; O
yoneda O
et O
al. O
, O
2018 O
; O
nie O
et O
al. O
, O
2019 O
) O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
for O
the O
sentence O
selection O
stage O
, O
there O
are O
three O
approaches O
commonly O
used O
, O
including O
keyword O
matching O
, O
supervised O
classification O
, O
and O
sentence O
similarity O
scoring O
( O
thorne O
et O
al. O
, O
2018b O
) O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
for O
the O
claim O
verification O
stage O
, O
most O
recent O
studies O
formulate O
this O
task O
as O
a O
graph O
reasoning O
task O
( O
zhou O
et O
al. O
, O
2019 O
; O
liu O
et O
al. O
, O
2020 O
; O
ye O
et O
al. O
, O
2020 O
; O
zhong O
et O
al. O
, O
2020 O
; O
subramanian O
and O
lee O
, O
2020 O
; O
wang O
et O
al. O
, O
2020 O
) O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
different O
from O
most O
existing O
methods O
that O
focus O
on O
claim O
verification O
, O
yin O
and O
roth O
( O
2018 O
) O
proposed O
a O
supervised O
training O
method O
named O
twowingos O
to O
jointly O
conduct O
sentence O
selection O
and O
claim O
verification O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
nowadays O
pre-trained O
language O
models O
like O
bert O
( O
devlin O
et O
al. O
, O
2019 O
) O
have O
been O
widely O
used O
in O
claim O
verification O
( O
li O
et O
al. O
, O
2019 O
; O
zhou O
et O
al. O
, O
2019 O
; O
soleimani O
et O
al. O
, O
2020 O
) O
. O

section 3
id pdf2json/2021.acl-long.83.pdf.json
following O
this O
way O
we O
employed O
roberta O
( O
liu O
et O
al. O
, O
2019 O
) O
, O
an O
enhanced O
version O
of O
bert O
, O
as O
the O
sentence O
encoder O
in O
our O
dqn-based O
approach O
in O
experiments O
. O

section 4
id pdf2json/2021.acl-long.83.pdf.json
reinforcement O
learning O
( O
rl O
) O
is O
about O
an O
agent O
interacting O
with O
the O
environment O
, O
objective O
to O
maximize O
the O
cumulative O
rewards O
of O
a O
sequence O
of O
states O
and O
actions O
by O
adjusting O
its O
policies O
. O

section 4
id pdf2json/2021.acl-long.83.pdf.json
qlearning O
( O
mnih O
et O
al. O
, O
2015 O
) O
is O
a O
popular O
reinforcement O
learning O
technique O
. O

section 4
id pdf2json/2021.acl-long.83.pdf.json
it O
aims O
to O
approximate O
the O
optimal O
value O
function O
q∗ O
( O
o O
, O
a O
) O
to O
measure O
the O
expected O
long-term O
rewards O
for O
a O
given O
pair O
of O
state O
o O
and O
action O
a O
. O

section 4
id pdf2json/2021.acl-long.83.pdf.json
deep O
q-learning O
network O
( O
dqn O
) O
( O
mnih O
et O
al. O
, O
2015 O
) O
is O
a O
combination O
of O
deep O
learning O
and O
q-learning O
. O

section 4
id pdf2json/2021.acl-long.83.pdf.json
it O
typically O
uses O
the O
following O
equation O
( O
1 O
) O
derived O
from O
the O
bellman O
equation O
( O
cao O
and O
zhimin O
, O
2019 O
) O
to O
approximate O
the O
optimal O
q-value O
function O
: O
q O
( O
o O
( O
t O
) O
, O
a O
( O
t O
) O
) O
= O
eo O
( O
t+1 O
) O
[ O
r O
( O
t O
) O
+λmax O
a′ O
q O
( O
o O
( O
t+1 O
) O
, O
a′ O
) O
] O
, O
( O
1 O
) O
where O
o O
( O
t O
) O
, O
a O
( O
t O
) O
, O
r O
( O
t O
) O
respectively O
denote O
the O
state O
, O
action O
and O
reward O
at O
step O
t O
, O
and O
λ O
∈ O
[ O
0 O
, O
1 O
] O
is O
a O
discounted O
factor O
for O
future O
rewards O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
given O
a O
set O
of O
candidate O
sentences O
s O
= O
{ O
s1 O
, O
s2 O
, O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
} O
, O
a O
claim O
c O
, O
a O
set O
of O
precise O
evidences O
e O
⊂ O
2s O
, O
and O
a O
true O
label O
y O
∈ O
y O
= O
{ O
t O
, O
f O
, O
n O
} O
that O
determines O
whether O
every O
precise O
evidence O
supports O
or O
refutes O
the O
claim O
, O
where O
t/f/n O
denotes O
“ O
supports O
” O
/ O
“ O
refutes O
” O
/ O
“ O
not O
enough O
info O
” O
, O
we O
aim O
to O
train O
a O
model O
to O
predict O
a O
precise O
evidence O
; O
more O
precisely O
, O
to O
train O
a O
model O
for O
retrieving O
an O
evidence O
ê O
⊂ O
s O
and O
predicting O
a O
label O
ŷ O
∈ O
y O
such O
that O
ŷ O
= O
y O
and O
ê O
= O
e O
for O
some O
e O
∈ O
e O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
this O
goal O
is O
different O
from O
the O
goal O
targeted O
by O
existing O
methods O
, O
which O
aim O
to O
retrieve O
an O
evidence O
ê O
⊂ O
s O
and O
predict O
a O
label O
ŷ O
∈ O
y O
such O
that O
ŷ O
= O
y O
and O
e O
⊆ O
ê O
for O
some O
e O
∈ O
e O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
we O
define O
the O
four O
ingredients O
of O
dqn O
namely O
states O
, O
actions O
, O
transitions O
and O
rewards O
as O
follows O
: O
• O
state O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
a O
state O
o O
is O
a O
tuple O
( O
c O
, O
ê O
, O
ŷ O
) O
for O
c O
a O
claim O
, O
ê O
a O
set O
of O
sentences O
and O
ŷ O
a O
label O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
• O
action O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
an O
action O
a O
is O
a O
sentence O
in O
s. O
• O
transition O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
a O
transition O
at O
step O
t O
is O
a O
tuple O
( O
o O
( O
t O
) O
, O
a O
( O
t O
) O
, O
o O
( O
t+1 O
) O
) O
, O
where O
o O
( O
t O
) O
= O
( O
c O
, O
ê O
( O
t O
) O
, O
ŷ O
) O
, O
o O
( O
t+1 O
) O
= O
( O
c O
, O
ê O
( O
t+1 O
) O
, O
ŷ O
) O
and O
ê O
( O
t+1 O
) O
= O
ê O
( O
t O
) O
∪ O
{ O
a O
( O
t O
) O
} O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
• O
reward O
. O

section 6
id pdf2json/2021.acl-long.83.pdf.json
the O
reward O
r O
for O
a O
transition O
( O
o O
( O
t O
) O
, O
a O
( O
t O
) O
, O
o O
( O
t+1 O
) O
) O
is O
defined O
as O
r O
( O
t O
) O
= O
1 O
, O
ŷ=y∧ O
( O
y=n∨∃e O
∈ O
e O
: O
a O
( O
t O
) O
∈e O
) O
−1 O
, O
ŷ O
6=y∧|ê O
( O
t+1 O
) O
|=k O
0 O
, O
otherwise O
( O
2 O
) O
where O
the O
numberk O
is O
a O
hyper-parameter O
, O
and O
|s| O
denotes O
the O
cardinality O
of O
a O
set O
s O
. O

section 7
id pdf2json/2021.acl-long.83.pdf.json
the O
core O
of O
our O
proposed O
approach O
is O
the O
dqnbased O
model O
, O
illustrated O
in O
figure O
2 O
. O

section 8
id pdf2json/2021.acl-long.83.pdf.json
we O
employ O
roberta O
in O
this O
module O
to O
extract O
the O
final O
hidden O
state O
of O
〈s〉 O
as O
the O
sentence O
representation O
, O
where O
〈s〉 O
and O
〈/s〉 O
mentioned O
in O
the O
following O
are O
the O
special O
classification O
tokens O
in O
roberta O
. O

section 8
id pdf2json/2021.acl-long.83.pdf.json
specifically O
, O
following O
kgat O
( O
liu O
et O
al. O
, O
2020 O
) O
, O
we O
first O
concatenate O
the O
claim O
c O
, O
the O
document O
title O
l O
, O
and O
a O
sentence O
s O
( O
resp O
. O

section 8
id pdf2json/2021.acl-long.83.pdf.json
an O
action O
a O
) O
as O
“ O
〈s〉c〈/s〉l〈/s〉s〈/s〉 O
” O
( O
resp O
. O

section 8
id pdf2json/2021.acl-long.83.pdf.json
“ O
〈s〉c〈/s〉l〈/s〉a〈/s〉 O
” O
) O
and O
then O
feed O
it O
into O
roberta O
to O
obtain O
the O
sentence O
representation O
hs O
∈ O
rd0 O
( O
resp O
. O

section 8
id pdf2json/2021.acl-long.83.pdf.json
the O
action O
representation O
ha O
∈ O
rd0 O
) O
, O
where O
d0 O
is O
the O
dimension O
of O
the O
representation O
. O

section 8
id pdf2json/2021.acl-long.83.pdf.json
we O
also O
feed O
the O
claim O
“ O
〈s〉c〈/s〉 O
” O
alone O
to O
obtain O
the O
claim O
representation O
hc O
∈ O
rd0 O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
this O
module O
is O
used O
to O
get O
an O
aggregated O
evidence O
representation O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
it O
consists O
of O
two O
sub-modules O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
context O
sub-module O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
it O
is O
obvious O
that O
the O
sentences O
in O
an O
evidence O
are O
always O
contextual O
dependent O
, O
so O
we O
apply O
two O
different O
networks O
bilstm O
( O
nguyen O
et O
al. O
, O
2016 O
) O
and O
transformer O
( O
vaswani O
et O
al. O
, O
2017 O
) O
for O
comparison O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
these O
two O
different O
networks O
are O
widely O
used O
to O
encode O
contextualaware O
information O
of O
sequential O
text O
in O
the O
nlp O
community O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
formally O
, O
we O
either O
define O
[ O
h′ O
ê0 O
, O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
, O
h′ O
ê|ê|−1 O
] O
= O
bilstm O
( O
ha O
, O
hê O
) O
( O
3 O
) O
if O
the O
bilstm O
network O
is O
used O
, O
or O
define O
[ O
h′ O
ê0 O
, O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
, O
h′ O
ê|ê|−1 O
] O
= O
transformer O
( O
ha O
, O
hê O
) O
( O
4 O
) O
if O
the O
transformer O
is O
used O
, O
where O
hê O
= O
[ O
hê0 O
, O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
, O
hê|ê|−1 O
] O
, O
hêi O
∈ O
r O
d0 O
is O
the O
i-th O
sentence O
representation O
in O
ê O
, O
h′ O
êi O
∈ O
rd1 O
is O
the O
corresponding O
context-aware O
sentence O
representation O
in O
ê O
, O
and O
d1 O
is O
the O
dimension O
of O
the O
representation O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
aggregation O
sub-module O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
this O
sub-module O
is O
used O
to O
fuse O
the O
sentence O
representations O
in O
evidences O
to O
obtain O
an O
aggregated O
evidence O
representation O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
we O
also O
apply O
two O
different O
networks O
in O
this O
sub-module O
: O
transformer O
and O
attention O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
unlike O
the O
transformer O
with O
self-attention O
in O
the O
first O
submodule O
, O
the O
query O
in O
this O
sub-module O
is O
the O
claim O
and O
the O
key/value O
is O
the O
context-aware O
sentence O
representation O
from O
the O
first O
sub-module O
. O

section 9
id pdf2json/2021.acl-long.83.pdf.json
for O
the O
attention O
network O
, O
we O
define O
e O
= O
|ê|−1∑ O
i=0 O
αi O
· O
h′i O
( O
5 O
) O
αi O
= O
exp O
( O
mlp O
( O
[ O
hc O
; O
h′i O
] O
) O
) O
|ê|−1∑ O
j=0 O
exp O
( O
mlp O
( O
[ O
hc O
; O
h′j O
] O
) O
) O
( O
6 O
) O
where O
e O
∈ O
rd1 O
is O
the O
aggregated O
evidence O
representation O
, O
mlp O
( O
· O
) O
= O
linear O
( O
relu O
( O
linear O
( O
· O
) O
) O
) O
is O
a O
two-layer O
fully O
connected O
network O
using O
rectified O
linear O
unit O
as O
the O
activation O
function O
, O
and O
[ O
; O
] O
denotes O
the O
concatenation O
of O
two O
vectors O
. O

section 10
id pdf2json/2021.acl-long.83.pdf.json
this O
module O
is O
used O
to O
obtain O
the O
q-value O
vector O
for O
all O
labels O
, O
simply O
written O
as O
q O
( O
o O
, O
a O
; O
θ O
) O
for O
θ O
denoting O
the O
set O
of O
learnable O
parameters O
, O
which O
is O
formally O
defined O
as O
q O
( O
o O
, O
a O
; O
θ O
) O
= O
mlp O
( O
[ O
hcw O
; O
e O
] O
) O
( O
7 O
) O
where O
mlp O
( O
· O
) O
= O
linear O
( O
relu O
( O
linear O
( O
· O
) O
) O
) O
is O
similar O
to O
mlp O
( O
· O
) O
used O
in O
equation O
( O
6 O
) O
except O
that O
different O
parameters O
in O
linear O
layers O
are O
used O
, O
w O
∈ O
rd0×d0 O
is O
a O
learnable O
matrix O
, O
and O
q O
( O
o O
, O
a O
; O
θ O
) O
∈ O
rd2 O
for O
d2 O
the O
number O
of O
different O
labels O
. O

section 11
id pdf2json/2021.acl-long.83.pdf.json
given O
a O
transition O
( O
o O
( O
t O
) O
, O
a O
( O
t O
) O
, O
o O
( O
t+1 O
) O
) O
and O
its O
reward O
r O
( O
t O
) O
, O
we O
use O
the O
double O
deep O
q-learning O
network O
( O
ddqn O
) O
( O
mnih O
et O
al. O
, O
2015 O
) O
technique O
to O
train O
our O
model O
through O
the O
temporal O
difference O
error O
( O
mnih O
et O
al. O
, O
2015 O
) O
. O

section 11
id pdf2json/2021.acl-long.83.pdf.json
this O
error O
δ O
is O
formally O
defined O
as O
δ O
= O
qŷ O
( O
o O
( O
t O
) O
, O
a O
( O
t O
) O
; O
θ O
) O
− O
v O
( O
o O
( O
t+1 O
) O
, O
r O
( O
t O
) O
) O
( O
8 O
) O
where O
v O
( O
· O
) O
denotes O
the O
target O
value O
defined O
as O
v O
( O
o O
, O
r O
) O
= O
{ O
r O
, O
if O
|ê|=k O
r+λq̂ŷ O
( O
o O
, O
a O
∗ O
; O
θ̂ O
) O
otherwise O
( O
9 O
) O
for O
a∗ O
= O
argmax O
a∈s\ê O
qŷ O
( O
o O
, O
a O
; O
θ O
) O
. O

section 11
id pdf2json/2021.acl-long.83.pdf.json
in O
the O
above O
equation O
, O
q̂ O
( O
· O
; O
θ̂ O
) O
is O
the O
target O
network O
in O
ddqn O
, O
qŷ O
denotes O
the O
q-value O
of O
ŷ O
for O
ŷ O
the O
predicted O
label O
in O
o O
, O
ê O
is O
the O
predicted O
evidence O
in O
o O
, O
and O
λ O
∈ O
[ O
0 O
, O
1 O
] O
is O
a O
hyper-parameter O
representing O
the O
discount O
factor O
. O

section 11
id pdf2json/2021.acl-long.83.pdf.json
we O
use O
the O
huber O
loss O
to O
minimise O
δ O
: O
l O
= O
1 O
|b| O
∑ O
( O
( O
o O
( O
t O
) O
, O
a O
( O
t O
) O
, O
o O
( O
t+1 O
) O
) O
, O
r O
( O
t O
) O
) O
∈b O
l O
( O
δ O
) O
( O
10 O
) O
l O
( O
δ O
) O
= O
1 O
2 O
δ2 O
if O
|δ| O
≤ O
1 O
|δ| O
− O
1 O
2 O
otherwise O
( O
11 O
) O
where O
b O
is O
a O
batch O
of O
transition-reward O
pairs O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
algorithm O
1 O
shows O
how O
to O
train O
the O
dqn-based O
model O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
first O
, O
we O
initialize O
three O
replay O
memories O
, O
the O
dqn-based O
model O
, O
and O
the O
target O
network O
in O
line O
1-3 O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
then O
, O
in O
line O
9-17 O
, O
we O
obtain O
the O
training O
algorithm O
1 O
: O
model O
training O
for O
dqn O
, O
where O
the O
memory O
capacity O
m O
, O
the O
maximum O
evidence O
size O
k O
, O
the O
maximum O
number O
of O
epochs O
t O
and O
the O
reset O
interval O
c O
are O
hyper-parameters O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
1 O
initialize O
a O
replay O
memory O
with O
a O
capacity O
m O
for O
each O
label O
: O
rŷ O
= O
∅ O
, O
∀ŷ O
∈ O
{ O
t O
, O
f O
, O
n O
} O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
2 O
initialize O
dqn O
q O
( O
o O
, O
a O
; O
θ O
) O
with O
random O
weights O
θ O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
3 O
initialize O
the O
target O
network O
q̂ O
( O
o O
, O
a O
; O
θ̂ O
) O
with O
θ̂ O
= O
θ O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
4 O
for O
e O
= O
1→ O
t O
do O
5 O
shuffle O
the O
training O
set O
d. O
6 O
foreach O
( O
c O
, O
y O
, O
e O
, O
s O
) O
∈ O
d O
do O
7 O
initialize O
one O
state O
for O
each O
label O
: O
o O
( O
0 O
) O
ŷ O
= O
( O
c O
, O
ê O
( O
0 O
) O
, O
ŷ O
) O
, O
∀ŷ O
∈ O
{ O
t O
, O
f O
, O
n O
} O
, O
where O
ê O
( O
0 O
) O
= O
∅ O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
8 O
for O
t O
= O
0→ O
k O
− O
1 O
do O
9 O
foreach O
ŷ O
∈ O
{ O
t O
, O
f O
, O
n O
} O
do O
10 O
if O
random O
( O
) O
< O
-greedy O
then O
11 O
a O
( O
t O
) O
= O
random O
select O
( O
s O
\ O
ê O
( O
t O
) O
) O
, O
where O
ê O
( O
t O
) O
comes O
from O
o O
( O
t O
) O
ŷ O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
12 O
else O
13 O
a O
( O
t O
) O
= O
argmax O
a∈s\ê O
( O
t O
) O
qŷ O
( O
o O
( O
t O
) O
ŷ O
, O
a O
; O
θ O
) O
, O
where O
q O
( O
· O
) O
is O
defined O
in O
eq O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
( O
7 O
) O
and O
qŷ O
denotes O
the O
q-value O
of O
ŷ O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
14 O
end O
15 O
o O
( O
t+1 O
) O
ŷ O
= O
( O
c O
, O
ê O
( O
t+1 O
) O
, O
ŷ O
) O
, O
where O
ê O
( O
t+1 O
) O
= O
ê O
( O
t O
) O
∪ O
{ O
a O
( O
t O
) O
} O
and O
ê O
( O
t O
) O
comes O
from O
o O
( O
t O
) O
ŷ O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
16 O
calculate O
r O
( O
t O
) O
based O
on O
eq O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
( O
2 O
) O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
17 O
store O
( O
( O
o O
( O
t O
) O
ŷ O
, O
a O
( O
t O
) O
, O
o O
( O
t+1 O
) O
ŷ O
) O
, O
r O
( O
t O
) O
) O
into O
ry O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
18 O
end O
19 O
sample O
a O
mini-batch O
of O
transition-reward O
pairs O
from O
rt O
, O
rf O
, O
rn O
and O
update O
q O
( O
o O
, O
a O
; O
θ O
) O
based O
on O
eq O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
( O
8 O
) O
– O
( O
11 O
) O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
20 O
for O
every O
c O
steps O
reset O
the O
target O
network O
q̂ O
( O
o O
, O
a O
; O
θ̂ O
) O
by O
θ̂ O
= O
θ O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
21 O
endfor O
22 O
end O
23 O
endfor O
24 O
return O
q O
( O
o O
, O
a O
; O
θ O
) O
transition-reward O
pairs O
by O
letting O
the O
dqn-based O
model O
interact O
with O
the O
environment O
in O
an O
-greedy O
exploration-exploitation O
way O
( O
mnih O
et O
al. O
, O
2015 O
) O
. O

section 13
id pdf2json/2021.acl-long.83.pdf.json
finally O
, O
in O
line O
19 O
, O
we O
sample O
a O
mini-batch O
of O
transition-reward O
pairs O
to O
update O
the O
dqn-based O
model O
, O
while O
in O
line O
20 O
, O
for O
every O
c O
steps O
we O
reset O
the O
target O
network O
to O
the O
dqn-based O
model O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
algorithm O
2 O
shows O
how O
to O
retrieve O
a O
pair O
( O
candidate O
list O
, O
score O
list O
) O
for O
each O
label O
, O
where O
the O
can- O
algorithm O
2 O
: O
candidate O
retrieval O
for O
a O
claim O
c O
from O
a O
set O
s O
of O
sentences O
, O
where O
k O
is O
the O
maximum O
evidence O
size O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
1 O
initialize O
êŷ O
= O
[ O
] O
, O
qŷ O
= O
[ O
] O
, O
∀ŷ O
∈ O
{ O
t O
, O
f O
, O
n O
} O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
2 O
initialize O
one O
state O
for O
each O
label O
: O
o O
( O
0 O
) O
ŷ O
= O
( O
c O
, O
ê O
( O
0 O
) O
, O
ŷ O
) O
, O
∀ŷ O
∈ O
{ O
t O
, O
f O
, O
n O
} O
, O
where O
ê O
( O
0 O
) O
= O
∅ O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
3 O
for O
t O
= O
0→ O
k O
− O
1 O
do O
4 O
foreach O
ŷ O
∈ O
{ O
t O
, O
f O
, O
n O
} O
do O
5 O
a O
( O
t O
) O
= O
argmax O
a∈s\ê O
( O
t O
) O
qŷ O
( O
o O
( O
t O
) O
ŷ O
, O
a O
; O
θ O
) O
6 O
q O
( O
t O
) O
= O
qŷ O
( O
o O
( O
t O
) O
ŷ O
, O
a O
( O
t O
) O
) O
7 O
o O
( O
t+1 O
) O
ŷ O
= O
( O
c O
, O
ê O
( O
t+1 O
) O
, O
ŷ O
) O
, O
where O
ê O
( O
t+1 O
) O
= O
ê O
( O
t O
) O
∪ O
{ O
a O
( O
t O
) O
} O
and O
ê O
( O
t O
) O
comes O
from O
o O
( O
t O
) O
ŷ O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
8 O
store O
ê O
( O
t+1 O
) O
into O
êŷ O
and O
q O
( O
t O
) O
into O
qŷ O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
9 O
end O
10 O
endfor O
11 O
return O
{ O
( O
êŷ O
, O
qŷ O
) O
} O
ŷ∈ O
{ O
t O
, O
f O
, O
n O
} O
algorithm O
3 O
: O
making O
final O
prediction O
from O
{ O
( O
〈ê O
( O
1 O
) O
ŷ O
, O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
, O
ê O
( O
k O
) O
ŷ O
〉 O
, O
〈q O
( O
0 O
) O
ŷ O
, O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
, O
q O
( O
k−1 O
) O
ŷ O
〉 O
) O
} O
ŷ∈ O
{ O
t O
, O
f O
, O
n O
} O
, O
using O
thresholds O
αt O
, O
αf O
, O
αn O
for O
different O
labels O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
1 O
let O
ty O
= O
argmax O
0≤t≤k−1 O
q O
( O
t O
) O
y O
, O
∀y O
∈ O
{ O
t O
, O
f O
, O
n O
} O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
2 O
let O
ê O
= O
ê O
( O
tŷ+1 O
) O
ŷ O
, O
where O
ŷ O
= O
argmax O
y∈ O
{ O
t O
, O
f O
} O
q O
( O
ty O
) O
y O
. O

section 14
id pdf2json/2021.acl-long.83.pdf.json
3 O
if O
q O
( O
tn O
) O
n O
> O
max O
{ O
q O
( O
tt O
) O
t O
, O
q O
( O
tf O
) O
f O
} O
and O
min O
0≤t≤k−1 O
q O
( O
t O
) O
n O
− O
max O
ŷ∈ O
{ O
t O
, O
f O
} O
q O
( O
tŷ O
) O
ŷ O
> O
αn O
then O
4 O
ŷ′ O
= O
n O
5 O
else O
if O
q O
( O
tt O
) O
t O
> O
q O
( O
tf O
) O
f O
then O
6 O
if O
q O
( O
tt O
) O
t O
− O
max O
ŷ∈ O
{ O
f O
, O
n O
} O
q O
( O
tt O
) O
ŷ O
> O
αt O
then O
ŷ O
′ O
= O
t O
; O
7 O
else O
ŷ′ O
= O
n O
; O
8 O
else O
9 O
if O
q O
( O
tf O
) O
f O
− O
max O
ŷ∈ O
{ O
t O
, O
n O
} O
q O
( O
tf O
) O
ŷ O
> O
αf O
then O
ŷ O
′ O
= O
f O
; O

section 17
id pdf2json/2021.acl-long.83.pdf.json
didate O
list O
stores O
progressively O
enlarged O
sentence O
sets O
, O
where O
each O
sentence O
set O
is O
a O
candidate O
of O
the O
predicted O
evidence O
, O
and O
the O
score O
list O
stores O
the O
strengths O
that O
the O
corresponding O
candidates O
support O
the O
label O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
we O
enlarge O
the O
two-list O
pair O
for O
each O
label O
through O
a O
greedy-search O
way O
( O
line O
3-10 O
) O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
specifically O
, O
for O
each O
label O
, O
we O
first O
select O
the O
action O
with O
the O
largest O
q-value O
( O
line O
5 O
) O
, O
then O
update O
the O
state O
by O
adding O
the O
chosen O
action O
into O
its O
predicted O
evidence O
( O
line O
7 O
) O
, O
and O
finally O
add O
the O
evidence O
and O
score O
into O
the O
corresponding O
list O
( O
line O
8 O
) O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
algorithm O
4 O
: O
searching O
for O
best O
thresholds O
, O
where O
min O
qŷ O
is O
short O
for O
mint O
q O
( O
t O
) O
ŷ O
and O
max O
qŷ O
for O
maxt O
q O
( O
t O
) O
ŷ O
, O
for O
all O
ŷ O
∈ O
{ O
t O
, O
f O
, O
n O
} O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
1 O
construct O
v O
= O
{ O
( O
qt O
, O
qf O
, O
qn O
, O
y O
) O
} O
from O
the O
development O
set O
by O
algorithm O
2 O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
2 O
initialize O
cŷ O
= O
lŷ O
= O
l′ŷ O
= O
[ O
] O
, O
∀ŷ O
∈ O
{ O
t O
, O
f O
, O
n O
} O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
3 O
foreach O
( O
qt O
, O
qf O
, O
qn O
, O
y O
) O
∈ O
v O
do O
4 O
if O
max O
qn O
> O
max O
{ O
max O
qt O
, O
max O
qf O
} O
then O
5 O
v O
= O
min O
qn O
−max O
{ O
max O
qt O
, O
max O
qf O
} O
6 O
store O
v O
into O
ln O
and O
( O
v O
, O
y O
) O
into O
cn O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
7 O
end O
8 O
end O
9 O
sort O
ln O
in O
ascending O
order O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
10 O
calculate O
the O
medians O
of O
adjacent O
values O
in O
ln O
and O
store O
them O
into O
l′n O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
11 O
αn O
= O
argmax O
α∈l′n O
∑ O
( O
v O
, O
y O
) O
∈cn O
1 O
( O
( O
v O
> O
α O
∧ O
y O
= O
n O
) O
∨ O
( O
v O
≤ O
α O
∧ O
y O
6= O
n O
) O
) O
12 O
foreach O
( O
qt O
, O
qf O
, O
qn O
, O
y O
) O
∈ O
v O
do O
13 O
if O
max O
qn O
≤ O
max O
{ O
max O
qt O
, O
max O
qf O
} O
or O
min O
qn O
−max O
{ O
max O
qt O
, O
max O
qf O
} O
≤ O
αn O
then O
14 O
tŷ O
= O
argmax O
t O
q O
( O
t O
) O
ŷ O
, O
∀ŷ O
∈ O
{ O
t O
, O
f O
} O
15 O
if O
q O
( O
tt O
) O
t O
> O
q O
( O
tf O
) O
f O
then O
16 O
v O
= O
q O
( O
tt O
) O
t O
−max O
{ O
q O
( O
tt O
) O
f O
, O
q O
( O
tt O
) O
n O
} O
17 O
store O
v O
into O
lt O
and O
( O
v O
, O
y O
) O
into O
ct. O
18 O
else O
19 O
v O
= O
q O
( O
tf O
) O
f O
−max O
{ O
q O
( O
tf O
) O
t O
, O
q O
( O
tf O
) O
n O
} O
20 O
store O
v O
into O
lf O
and O
( O
v O
, O
y O
) O
into O
cf O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
21 O
end O
22 O
end O
23 O
end O
24 O
foreach O
ŷ O
∈ O
{ O
t O
, O
f O
} O
do O
25 O
sort O
lŷ O
in O
ascending O
order O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
26 O
calculate O
the O
medians O
of O
adjacent O
values O
in O
lŷ O
and O
store O
them O
into O
l′ŷ O
. O

section 17
id pdf2json/2021.acl-long.83.pdf.json
27 O
αŷ O
= O
argmax O
α∈l′ O
ŷ O
∑ O
( O
v O
, O
y O
) O
∈cŷ O
1 O
( O
v O
> O
α O
∧ O
y O
= O
ŷ O
) O
− O
1 O
( O
v O
> O
α O
∧ O
y O
= O
n O
) O
28 O
end O
29 O
return O
( O
αt O
, O
αf O
, O
αn O
) O

section 18
id pdf2json/2021.acl-long.83.pdf.json
algorithm O
3 O
shows O
how O
to O
compute O
the O
target O
evidence-label O
pair O
from O
the O
( O
candidate O
list O
, O
score O
list O
) O
pairs O
obtained O
by O
algorithm O
2 O
, O
where O
the O
thresholds O
are O
determined O
by O
algorithm O
4 O
. O

section 18
id pdf2json/2021.acl-long.83.pdf.json
in O
this O
algorithm O
, O
we O
first O
use O
the O
condition O
given O
by O
algorithm O
4 O
to O
predict O
n O
( O
line O
3 O
) O
, O
and O
then O
refine O
the O
prediction O
of O
t O
( O
line O
6 O
) O
and O
f O
( O
line O
9 O
) O
in O
turn O
. O

section 18
id pdf2json/2021.acl-long.83.pdf.json
in O
line O
2 O
, O
we O
focus O
on O
the O
evidences O
with O
the O
highest O
score O
for O
t O
and O
f O
, O
while O
we O
ignore O
the O
evidence O
for O
n O
, O
due O
to O
the O
following O
reasons O
: O
( O
1 O
) O
there O
are O
no O
supporting O
sentences O
in O
the O
evidence O
for O
n O
; O
( O
2 O
) O
we O
follow O
a O
strategy O
commonly O
used O
in O
existing O
methods O
for O
fv O
, O
i.e. O
, O
focusing O
only O
on O
the O
evidence O
for O
t O
and O
f O
. O

section 19
id pdf2json/2021.acl-long.83.pdf.json
algorithm O
4 O
shows O
how O
to O
search O
for O
the O
best O
thresholds O
( O
αt O
, O
αf O
, O
αn O
) O
to O
maximize O
the O
label O
accuracy O
( O
la O
) O
over O
the O
development O
set O
. O

section 19
id pdf2json/2021.acl-long.83.pdf.json
we O
first O
call O
algorithm O
2 O
to O
construct O
a O
set O
of O
tuples O
( O
qt O
, O
qf O
, O
qn O
, O
y O
) O
from O
the O
development O
set O
, O
each O
of O
which O
corresponds O
to O
a O
development O
instance O
, O
where O
qt O
, O
qf O
and O
qn O
are O
respectively O
the O
output O
score O
lists O
for O
the O
three O
labels O
t O
, O
f O
and O
n O
, O
and O
y O
is O
the O
corresponding O
true O
label O
( O
line O
1 O
) O
. O

section 19
id pdf2json/2021.acl-long.83.pdf.json
we O
then O
go O
through O
the O
following O
two O
stages O
. O

section 19
id pdf2json/2021.acl-long.83.pdf.json
the O
first O
stage O
( O
line O
3-11 O
) O
finds O
a O
threshold O
αn O
that O
can O
maximize O
la O
for O
label O
n O
, O
where O
maximizing O
la O
is O
amount O
to O
maximizing O
the O
difference O
between O
the O
number O
of O
correctly O
and O
incorrectly O
predicted O
instances O
. O

section 19
id pdf2json/2021.acl-long.83.pdf.json
the O
second O
stage O
( O
line O
12-28 O
) O
finds O
the O
thresholds O
αt O
and O
αf O
that O
can O
maximize O
la O
for O
label O
t O
and O
f O
, O
respectively O
, O
where O
those O
instances O
that O
satisfy O
the O
conditions O
for O
n O
are O
neglected O
( O
line O
13 O
) O
. O

section 22
id pdf2json/2021.acl-long.83.pdf.json
our O
experiments O
are O
conducted O
on O
the O
large-scale O
benchmark O
dataset O
fever O
( O
thorne O
et O
al. O
, O
2018a O
) O
, O
which O
consists O
of O
185,455 O
annotated O
claims O
with O
a O
set O
of O
5,416,537 O
wikipedia O
documents O
from O
the O
june O
2017 O
wikipedia O
dump O
. O

section 22
id pdf2json/2021.acl-long.83.pdf.json
all O
claims O
are O
labeled O
as O
“ O
supports O
” O
, O
“ O
refutes O
” O
, O
or O
“ O
not O
enough O
info O
” O
. O

section 22
id pdf2json/2021.acl-long.83.pdf.json
what O
’ O
s O
more O
, O
each O
claim O
for O
“ O
supports O
” O
and O
“ O
refutes O
” O
is O
accompanied O
by O
some O
evidences O
extracted O
from O
wikipedia O
documents O
. O

section 22
id pdf2json/2021.acl-long.83.pdf.json
the O
dataset O
partition O
is O
kept O
the O
same O
with O
thorne O
et O
al O
. O

section 22
id pdf2json/2021.acl-long.83.pdf.json
( O
2018b O
) O
as O
shown O
in O
table O
1 O
. O

section 23
id pdf2json/2021.acl-long.83.pdf.json
the O
task O
has O
five O
evaluation O
metrics O
: O
1 O
) O
fever O
, O
the O
primary O
scoring O
metric O
that O
measures O
the O
accuracy O
of O
claim O
verification O
with O
a O
requirement O
that O
the O
predicted O
evidences O
fully O
covers O
the O
ground-true O
evidences O
for O
supports O
and O
refutes O
claims O
; O
2 O
) O
label O
accuracy O
( O
la O
) O
, O
the O
accuracy O
of O
claim O
verification O
without O
considering O
the O
validity O
of O
the O
predicted O
evidences O
; O
3 O
) O
precision O
( O
pre O
) O
, O
the O
macroprecision O
of O
the O
evidences O
for O
supports O
and O
refutes O
claims O
; O
4 O
) O
recall O
, O
the O
macro-recall O
of O
the O
evidences O
for O
supports O
and O
refutes O
claims O
; O
5 O
) O
f1 O
, O
the O
f1-score O
of O
the O
evidences O
for O
supports O
and O
refutes O
claims O
. O

section 23
id pdf2json/2021.acl-long.83.pdf.json
we O
choose O
f1 O
as O
our O
main O
metric O
because O
it O
can O
directly O
show O
the O
performance O
of O
methods O
on O
retrieval O
of O
precise O
evidences O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
document O
retrieval O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
the O
document O
retrieval O
stage O
is O
kept O
the O
same O
as O
previous O
work O
( O
hanselowski O
et O
al. O
, O
2018 O
; O
zhou O
et O
al. O
, O
2019 O
; O
liu O
et O
al. O
, O
2020 O
; O
ye O
et O
al. O
, O
2020 O
) O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
given O
a O
claim O
, O
the O
method O
first O
utilizes O
the O
constituency O
parser O
from O
allennlp O
( O
gardner O
et O
al. O
, O
2018 O
) O
to O
extract O
potential O
entities O
from O
the O
claim O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
then O
it O
uses O
the O
entities O
as O
search O
queries O
to O
find O
the O
relevant O
documents O
via O
the O
online O
mediawiki O
api2 O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
the O
convinced O
articles O
are O
reserved O
( O
hanselowski O
et O
al. O
, O
2018 O
) O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
sentence O
selection O
and O
claim O
verification O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
we O
implement O
our O
dqn-based O
model O
with O
pytorch O
and O
train O
it O
with O
the O
adamw O
( O
loshchilov O
and O
hutter O
, O
2019 O
) O
optimizer O
while O
keeping O
the O
sentence O
encoding O
module O
frozen O
and O
inheriting O
the O
roberta O
implementation O
from O
wolf O
et O
al O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
( O
2020 O
) O
3 O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
specifically O
, O
the O
learning O
rate O
is O
5e-6 O
, O
the O
batch O
size O
is O
128 O
, O
the O
training O
epochs O
is O
30 O
, O
the O
iteration O
steps O
( O
or O
largest O
evidence O
size O
, O
i.e. O
, O
k O
) O
is O
5 O
, O
the O
discount O
factor O
λ O
is O
0.95 O
, O
and O
the O
layer O
number O
of O
the O
context O
sub-module O
is O
3 O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
prioritized O
experience O
replay O
memory O
( O
schaul O
et O
al. O
, O
2016 O
) O
with O
a O
capacity O
of O
10,000 O
is O
used O
to O
store O
transitions O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
the O
target O
network O
is O
reset O
when O
dqn O
is O
updated O
every O
10 O
times O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
the O
probability O
of O
-greedy O
policy O
starts O
at O
0.9 O
and O
decays O
exponentially O
towards O
0.05 O
, O
and O
the O
rate O
of O
the O
decay O
is O
12000 O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
table O
2 O
shows O
the O
thresholds O
2https O
: O
//www.mediawiki.org/wiki/api O
: O
main_page O
3https O
: O
//github.com/huggingface/ O
pytorch-transformers O
αt O
, O
αf O
and O
αn O
computed O
by O
algorithm O
4 O
. O

section 24
id pdf2json/2021.acl-long.83.pdf.json
all O
experiments O
were O
conducted O
on O
an O
nvidia O
gtx O
2080ti O
10gb O
gpu O
. O

section 25
id pdf2json/2021.acl-long.83.pdf.json
we O
compare O
our O
method O
with O
the O
following O
baselines O
, O
including O
six O
methods O
that O
focus O
on O
claim O
verification O
and O
one O
joint O
method O
twowingos O
( O
yin O
and O
roth O
, O
2018 O
) O
. O

section 25
id pdf2json/2021.acl-long.83.pdf.json
the O
six O
methods O
include O
: O
( O
1 O
) O
gear O
( O
zhou O
et O
al. O
, O
2019 O
) O
uses O
two O
kinds O
of O
attentions O
to O
conduct O
reasoning O
and O
aggregation O
in O
a O
graph O
model O
; O
( O
2 O
) O
kgat O
( O
liu O
et O
al. O
, O
2020 O
) O
employes O
the O
kernel O
graph O
attention O
network O
to O
capture O
fine-grained O
information O
over O
evidences O
for O
more O
accurate O
claim O
verification O
; O
( O
3 O
) O
dream O
( O
zhong O
et O
al. O
, O
2020 O
) O
introduces O
semantic O
structures O
for O
evidences O
obtained O
by O
semantic O
role O
labeling O
in O
claim O
verification O
; O
( O
4 O
) O
corefbert O
( O
ye O
et O
al. O
, O
2020 O
) O
extends O
kgat O
and O
can O
explicitly O
model O
co-reference O
relationship O
in O
context O
; O
( O
5 O
) O
hesm O
( O
subramanian O
and O
lee O
, O
2020 O
) O
is O
a O
framework O
that O
can O
encode O
and O
attend O
the O
claim O
and O
evidence O
sets O
at O
different O
levels O
of O
hierarchy O
; O
( O
6 O
) O
dgat O
( O
wang O
et O
al. O
, O
2020 O
) O
is O
a O
double O
graph O
attention O
network O
that O
performs O
well O
in O
multi-domain O
datasets O
. O

section 25
id pdf2json/2021.acl-long.83.pdf.json
the O
join O
method O
twowingos O
( O
yin O
and O
roth O
, O
2018 O
) O
exploits O
a O
two-wing O
optimization O
strategy O
that O
optimizes O
sentence O
selection O
and O
claim O
verification O
in O
a O
jointly O
supervised O
training O
scheme O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
as O
shown O
in O
table O
3 O
, O
we O
implement O
four O
versions O
of O
the O
evidence O
encoding O
module O
and O
evaluate O
them O
on O
the O
dev O
set O
and O
the O
blind O
test O
set O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
the O
fever O
metric O
of O
the O
top O
six O
methods O
is O
calculated O
with O
the O
imprecise O
evidences O
, O
so O
we O
introduce O
the O
fever O
@ O
5 O
metric O
for O
a O
fair O
comparison O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
we O
analyze O
our O
method O
from O
the O
following O
four O
aspects O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
comparison O
with O
the O
state-of-the-art O
methods O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
results O
in O
table O
3 O
show O
that O
all O
versions O
( O
except O
bilstm-a O
) O
with O
post-processing O
significantly O
outperform O
the O
state-of-the-art O
methods O
on O
fever O
, O
pre O
, O
and O
f1 O
, O
especially O
for O
t-a O
on O
f1 O
, O
which O
shows O
the O
superiority O
of O
our O
method O
in O
retrival O
of O
precise O
evidences O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
however O
, O
none O
of O
the O
four O
versions O
of O
our O
method O
can O
achieve O
the O
best O
result O
on O
fever O
@ O
5 O
, O
la O
, O
and O
recall O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
the O
reason O
for O
low O
recall O
is O
that O
the O
number O
of O
sentences O
in O
precise O
evidences O
is O
less O
than O
that O
in O
imprecise O
evidences O
, O
which O
means O
other O
methods O
have O
a O
higher O
probability O
to O
recall O
the O
ground-true O
evidences O
than O
ours O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
besides O
, O
the O
relatively O
low O
la O
is O
caused O
by O
the O
low O
recall O
of O
precise O
evidences O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
to O
further O
clarify O
this O
point O
, O
we O
evaluate O
our O
method O
on O
a O
subset O
of O
the O
dev O
set O
where O
the O
ground-true O
evidences O
are O
recalled O
successfully O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
our O
method O
improves O
significantly O
the O
performance O
on O
this O
subset O
, O
as O
shown O
in O
table O
4 O
, O
which O
justifies O
our O
point O
of O
view O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
fever O
is O
affected O
by O
the O
la O
and O
recall O
, O
thereby O
the O
low O
fever O
@ O
5 O
is O
also O
due O
to O
the O
low O
recall O
of O
precise O
evidences O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
in O
addition O
, O
the O
results O
reported O
in O
table O
5 O
show O
that O
our O
method O
can O
significantly O
reduce O
the O
number O
of O
unnecessary O
sentences O
in O
a O
predicted O
evidence O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
comparison O
between O
different O
versions O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
as O
shown O
in O
table O
3 O
, O
t-t O
and O
t-a O
perform O
respectively O
better O
than O
bilstm-t O
and O
bilstm-a O
on O
almost O
all O
metrics O
except O
that O
t-t O
is O
slightly O
worse O
than O
bilstm-a O
on O
fever O
@ O
5 O
, O
which O
suggests O
transformer O
can O
encode O
better O
context-aware O
representations O
than O
bilstm O
in O
our O
context O
sub-module O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
moreover O
, O
we O
find O
that O
t-a O
performs O
better O
than O
t-t O
on O
almost O
all O
metrics O
except O
recall O
and O
that O
bilstm-a O
is O
worse O
than O
bilstm-t O
on O
pre O
and O
f1 O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
this O
contrary O
result O
shows O
that O
the O
performance O
of O
the O
aggregation O
sub-module O
is O
impacted O
by O
the O
context O
sub-module O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
thus O
, O
the O
choice O
between O
transformer O
and O
attention O
should O
depend O
on O
the O
context O
sub-module O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
overall O
, O
t-a O
achieves O
the O
best O
performance O
among O
all O
the O
four O
versions O
of O
our O
proposed O
method O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
comparison O
on O
retrieval O
of O
precise O
evidences O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
twowingos O
is O
a O
supervised-learning O
method O
that O
can O
also O
find O
precise O
evidences O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
although O
it O
achieves O
slightly O
better O
performance O
on O
la O
than O
ours O
, O
its O
f1 O
and O
other O
metrics O
are O
much O
worse O
, O
indicating O
that O
it O
performs O
worse O
than O
our O
method O
except O
for O
bilstm-a O
in O
retrieval O
of O
preciseevidences O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
we O
also O
enhance O
kgat O
to O
conduct O
beam-search O
for O
finding O
precise O
evidences O
and O
report O
the O
results O
in O
table O
6 O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
the O
f1 O
score O
of O
kgat O
is O
always O
higher O
than O
twowingos O
but O
is O
still O
lower O
than O
our O
method O
except O
for O
bilstm-a O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
comparison O
between O
the O
methods O
with O
and O
without O
post-processing O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
it O
can O
be O
seen O
from O
table O
3 O
and O
table O
6 O
that O
, O
post-processing O
( O
namely O
threshold O
searching O
and O
final O
prediction O
from O
candidates O
) O
consistently O
improves O
fever O
and O
la O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
although O
with O
post-processing O
, O
our O
method O
( O
except O
t-a O
) O
achieves O
slightly O
lower O
scores O
on O
fever O
@ O
5 O
, O
kgat O
still O
achieves O
significantly O
higher O
scores O
on O
fever O
@ O
5 O
as O
on O
other O
metrics O
. O

section 26
id pdf2json/2021.acl-long.83.pdf.json
these O
results O
show O
that O
post O
processing O
is O
very O
important O
in O
retrieval O
of O
precise O
evidences O
. O

section 27
id pdf2json/2021.acl-long.83.pdf.json
in O
table O
7 O
we O
provide O
some O
cases O
to O
demonstrate O
the O
effectiveness O
of O
our O
method O
( O
t-a O
) O
in O
retrieving O
precise O
evidences O
. O

section 27
id pdf2json/2021.acl-long.83.pdf.json
in O
case O
# O
1 O
and O
case O
# O
2 O
, O
our O
method O
exactly O
finds O
ground-true O
evidences O
without O
introducing O
any O
unnecessary O
sentence O
, O
while O
geat O
and O
kgat O
can O
not O
. O

section 27
id pdf2json/2021.acl-long.83.pdf.json
in O
case O
# O
3 O
and O
case O
# O
4 O
, O
our O
method O
generates O
less O
unnessary O
sentences O
in O
prdicted O
evidents O
than O
geat O
and O
kgat O
do O
. O

section 28
id pdf2json/2021.acl-long.83.pdf.json
in O
this O
paper O
, O
we O
have O
proposed O
a O
novel O
dqn-based O
approach O
to O
finding O
precise O
evidences O
for O
fact O
verification O
. O

section 28
id pdf2json/2021.acl-long.83.pdf.json
it O
provides O
a O
method O
to O
solve O
the O
preciseevidence O
problem O
by O
first O
employing O
a O
dqn O
to O
compute O
some O
candidates O
and O
then O
introducing O
a O
post-processing O
strategy O
to O
extract O
the O
target O
evidence O
and O
its O
label O
from O
the O
candidates O
. O

section 28
id pdf2json/2021.acl-long.83.pdf.json
experimental O
results O
show O
that O
the O
approach O
achieves O
state-of-the-art O
performance O
in O
terms O
of O
retrieval O
of O
precise O
evidences O
. O

section 28
id pdf2json/2021.acl-long.83.pdf.json
besides O
, O
to O
the O
best O
of O
our O
knowledge O
, O
it O
is O
the O
first O
attempt O
to O
employ O
dqn O
in O
the O
fact O
verification O
task O
. O

section 28
id pdf2json/2021.acl-long.83.pdf.json
future O
work O
will O
incorporate O
external O
knowledge O
into O
our O
approach O
to O
improve O
the O
retrieval O
recall O
. O

section 29
id pdf2json/2021.acl-long.83.pdf.json
this O
work O
is O
supported O
by O
the O
guangdong O
province O
science O
and O
technology O
plan O
projects O
( O
2017b010110011 O
) O
, O
the O
national O
natural O
science O
foundation O
of O
china O
( O
no O
. O

section 29
id pdf2json/2021.acl-long.83.pdf.json
61876204 O
, O
61976232 O
, O
and O
51978675 O
) O
, O
the O
national O
key O
r O
& O
d O
program O
of O
china O
( O
no.2018yfc0830600 O
) O
, O
guangdong O
province O
natural O
science O
foundation O
( O
no O
. O

section 29
id pdf2json/2021.acl-long.83.pdf.json
2018a030313086 O
) O
, O
all-china O
federation O
of O
returned O
over-seas O
chinese O
research O
project O
( O
no O
. O

section 29
id pdf2json/2021.acl-long.83.pdf.json
17bzqk216 O
) O
. O

section TITLE
id pdf2json/2021.acl-long.425.pdf.json
article O
reranking O
by O
memory-enhanced O
key O
sentence O
matching O
for O
detecting O
previously O
fact-checked O
claims O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
false O
claims O
that O
have O
been O
previously O
factchecked O
can O
still O
spread O
on O
social O
media O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
to O
mitigate O
their O
continual O
spread O
, O
detecting O
previously O
fact-checked O
claims O
is O
indispensable O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
given O
a O
claim O
, O
existing O
works O
retrieve O
fact-checking O
articles O
( O
fc-articles O
) O
for O
detection O
and O
focus O
on O
reranking O
candidate O
articles O
in O
the O
typical O
two-stage O
retrieval O
framework O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
however O
, O
their O
performance O
may O
be O
limited O
as O
they O
ignore O
the O
following O
characteristics O
of O
fc-articles O
: O
( O
1 O
) O
claims O
are O
often O
quoted O
to O
describe O
the O
checked O
events O
, O
providing O
lexical O
information O
besides O
semantics O
; O
and O
( O
2 O
) O
sentence O
templates O
to O
introduce O
or O
debunk O
claims O
are O
common O
across O
articles O
, O
providing O
pattern O
information O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
in O
this O
paper O
, O
we O
propose O
a O
novel O
reranker O
, O
mtm O
( O
memoryenhanced O
transformers O
for O
matching O
) O
, O
to O
rank O
fc-articles O
using O
key O
sentences O
selected O
using O
event O
( O
lexical O
and O
semantic O
) O
and O
pattern O
information O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
for O
event O
information O
, O
we O
propose O
to O
finetune O
the O
transformer O
with O
regression O
of O
rouge O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
for O
pattern O
information O
, O
we O
generate O
pattern O
vectors O
as O
a O
memory O
bank O
to O
match O
with O
the O
parts O
containing O
patterns O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
by O
fusing O
event O
and O
pattern O
information O
, O
we O
select O
key O
sentences O
to O
represent O
an O
article O
and O
then O
predict O
if O
the O
article O
fact-checks O
the O
given O
claim O
using O
the O
claim O
, O
key O
sentences O
, O
and O
patterns O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
experiments O
on O
two O
real-world O
datasets O
show O
that O
mtm O
outperforms O
existing O
methods O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
human O
evaluation O
proves O
that O
mtm O
can O
capture O
key O
sentences O
for O
explanations O
. O

section ABSTRACT
id pdf2json/2021.acl-long.425.pdf.json
the O
code O
and O
the O
dataset O
are O
at O
https O
: O
//github.com/ O
ictmcg/mtm O
. O

section 0
id pdf2json/2021.acl-long.425.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
5468–5481 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.425.pdf.json
©2021 O
association O
for O
computational O
linguistics O
5468 O

section 1
id pdf2json/2021.acl-long.425.pdf.json
social O
media O
posts O
with O
false O
claims O
have O
led O
to O
real-world O
threats O
on O
many O
aspects O
such O
as O
politics O
( O
fisher O
et O
al. O
, O
2016 O
) O
, O
social O
order O
( O
wang O
and O
li O
, O
2011 O
) O
, O
and O
personal O
health O
( O
chen O
, O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
to O
tackle O
this O
issue O
, O
over O
300 O
fact-checking O
projects O
have O
been O
launched O
, O
such O
as O
snopes1 O
and O
jiaozhen2 O
( O
duke O
reporters O
’ O
lab O
, O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
meanwhile O
, O
automatic O
systems O
have O
been O
developed O
for O
detecting O
suspicious O
claims O
on O
social O
media O
( O
zhou O
et O
al. O
, O
2015 O
; O
popat O
et O
al. O
, O
2018a O
) O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
this O
is O
however O
not O
the O
end O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
a O
considerable O
amount O
of O
false O
claims O
continually O
spread O
, O
even O
though O
they O
are O
already O
proved O
false O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
according O
to O
a O
recent O
report O
( O
xinhua O
net O
, O
2019 O
) O
, O
around O
12 O
% O
of O
false O
claims O
published O
on O
chinese O
social O
media O
, O
are O
actually O
“ O
old O
” O
, O
as O
they O
have O
been O
debunked O
previously O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
hence O
, O
detecting O
previously O
fact-checked O
claims O
is O
an O
important O
1https O
: O
//www.snopes.com O
2https O
: O
//fact.qq.com/ O
task O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
according O
to O
the O
seminal O
work O
by O
shaar O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
( O
2020 O
) O
, O
the O
task O
is O
tackled O
by O
a O
two-stage O
information O
retrieval O
approach O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
its O
typical O
workflow O
is O
illustrated O
in O
figure O
1 O
( O
a O
) O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
given O
a O
claim O
as O
a O
query O
, O
in O
the O
first O
stage O
a O
basic O
searcher O
( O
e.g. O
, O
bm25 O
robertson O
and O
zaragoza O
, O
2009 O
) O
searches O
for O
candidate O
articles O
from O
a O
collection O
of O
fact-checking O
articles O
( O
fc-articles O
) O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
in O
the O
second O
stage O
, O
a O
more O
powerful O
model O
( O
e.g. O
, O
bert O
, O
devlin O
et O
al. O
, O
2019 O
) O
reranks O
the O
candidates O
to O
provide O
evidence O
for O
manual O
or O
automatic O
detection O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
existing O
works O
focus O
on O
the O
reranking O
stage O
: O
vo O
and O
lee O
( O
2020 O
) O
model O
the O
interactions O
between O
a O
claim O
and O
the O
whole O
candidate O
articles O
, O
while O
shaar O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
( O
2020 O
) O
extract O
several O
semantically O
similar O
sentences O
from O
fc-articles O
as O
a O
proxy O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
nevertheless O
, O
these O
methods O
treat O
fcarticles O
as O
general O
documents O
and O
ignore O
characteristics O
of O
fc-articles O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
figure O
1 O
( O
b O
) O
shows O
three O
sentences O
from O
candidate O
articles O
for O
the O
given O
claim O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
among O
them O
, O
s1 O
is O
more O
friendly O
to O
semantic O
matching O
than O
s2 O
and O
s3 O
because O
the O
whole O
s1 O
focuses O
on O
describing O
its O
topic O
and O
does O
not O
contain O
tokens O
irrelevant O
to O
the O
given O
claim O
, O
e.g. O
, O
” O
has O
spread O
over O
years O
” O
in O
s2 O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
thus O
, O
a O
semantic-based O
model O
does O
not O
require O
to O
have O
strong O
filtering O
capability O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
if O
we O
use O
only O
general O
methods O
on O
this O
task O
, O
the O
relevant O
s2 O
and O
s3 O
may O
be O
neglected O
while O
irrelevant O
s1 O
is O
focused O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
to O
let O
the O
model O
focus O
on O
key O
sentences O
( O
i.e. O
, O
sentences O
as O
a O
good O
proxy O
of O
article-level O
relevance O
) O
like O
s2 O
and O
s3 O
, O
we O
need O
to O
consider O
two O
characteristics O
of O
fc-articles O
besides O
semantics O
: O
c1 O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
claims O
are O
often O
quoted O
to O
describe O
the O
checked O
events O
( O
e.g. O
, O
the O
underlined O
text O
in O
s2 O
) O
; O
c2 O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
event-irrelevant O
patterns O
to O
introduce O
or O
debunk O
claims O
are O
common O
in O
fc-articles O
( O
e.g. O
, O
bold O
texts O
in O
s2 O
and O
s3 O
) O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
based O
on O
the O
observations O
, O
we O
propose O
a O
novel O
reranker O
, O
mtm O
( O
memory-enhanced O
transformers O
for O
matching O
) O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
the O
reranker O
identifies O
key O
sentences O
per O
article O
using O
claim- O
and O
pattern-sentence O
relevance O
, O
and O
then O
integrates O
information O
from O
the O
claim O
, O
key O
sentences O
, O
and O
patterns O
for O
article-level O
relevance O
prediction O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
in O
particular O
, O
regarding O
c1 O
, O
we O
propose O
rouge-guided O
transformer O
( O
rot O
) O
to O
score O
claim-sentence O
relevance O
literally O
and O
semantically O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
as O
for O
c2 O
, O
we O
obtain O
the O
pattern O
vectors O
by O
clustering O
the O
difference O
of O
sentence O
and O
claim O
vectors O
for O
scoring O
pattern-sentence O
relevance O
and O
store O
them O
in O
the O
pattern O
memory O
bank O
( O
pmb O
) O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
the O
joint O
use O
of O
rot O
and O
pmb O
allows O
us O
to O
iden- O
tify O
key O
sentences O
that O
reflect O
the O
two O
characteristics O
of O
fc-articles O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
subsequently O
, O
fine-grained O
interactions O
among O
claims O
and O
key O
sentences O
are O
modeled O
by O
the O
multi-layer O
transformer O
and O
aggregated O
with O
patterns O
to O
obtain O
an O
article-level O
feature O
representation O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
the O
article O
feature O
is O
fed O
into O
a O
multi-layer O
perceptron O
( O
mlp O
) O
to O
predict O
the O
claim-article O
relevance O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
to O
validate O
the O
effectiveness O
of O
our O
method O
, O
we O
built O
the O
first O
chinese O
dataset O
for O
this O
task O
with O
11,934 O
claims O
collected O
from O
chinese O
weibo3 O
and O
27,505 O
fact-checking O
articles O
from O
multiple O
sources O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
39,178 O
claim-article O
pairs O
are O
annotated O
as O
relevant O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
experiments O
on O
the O
english O
dataset O
and O
the O
newly O
built O
chinese O
dataset O
show O
that O
mtm O
outperforms O
existing O
methods O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
further O
human O
evaluation O
and O
case O
studies O
prove O
that O
mtm O
finds O
key O
sentences O
as O
explanations O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
our O
main O
contributions O
are O
as O
follows O
: O
• O
we O
propose O
a O
novel O
reranker O
mtm O
for O
factchecked O
claim O
detection O
, O
which O
can O
better O
identify O
key O
sentences O
in O
fact-checking O
articles O
by O
exploiting O
their O
characteristics O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
• O
we O
design O
rouge-guided O
transformer O
to O
combine O
lexical O
and O
semantic O
information O
and O
propose O
a O
memory O
mechanism O
to O
capture O
and O
exploit O
common O
patterns O
in O
fact-checking O
articles O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
• O
experiments O
on O
two O
real-world O
datasets O
show O
that O
mtm O
outperforms O
existing O
methods O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
further O
human O
evaluation O
and O
case O
studies O
prove O
that O
our O
model O
finds O
key O
sentences O
as O
good O
explanations O
. O

section 1
id pdf2json/2021.acl-long.425.pdf.json
• O
we O
built O
the O
first O
chinese O
dataset O
for O
factchecked O
claim O
detection O
with O
fact-checking O
articles O
from O
diverse O
sources O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
to O
defend O
against O
false O
information O
, O
researchers O
are O
mainly O
devoted O
to O
two O
threads O
: O
( O
1 O
) O
automatic O
fact-checking O
methods O
mainly O
retrieve O
relevant O
factual O
information O
from O
designated O
sources O
and O
judge O
the O
claim O
’ O
s O
veracity O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
thorne O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
( O
2018 O
) O
use O
wikipedia O
as O
a O
fact O
tank O
and O
build O
a O
shared O
task O
for O
automatic O
fact-checking O
, O
while O
popat O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
( O
2018b O
) O
and O
wang O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
( O
2018 O
) O
retrieve O
webpages O
as O
evidence O
and O
use O
their O
stances O
on O
claims O
for O
veracity O
prediction O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
( O
2 O
) O
fake O
news O
detection O
methods O
often O
use O
non-factual O
signals O
, O
such O
as O
styles O
( O
przybyla O
, O
2020 O
; O
qi O
et O
al. O
, O
2019 O
) O
, O
emotions O
( O
ajao O
3https O
: O
//weibo.com O
et O
al. O
, O
2019 O
; O
zhang O
et O
al. O
, O
2021 O
) O
, O
source O
credibility O
( O
nguyen O
et O
al. O
, O
2020 O
) O
, O
user O
response O
( O
shu O
et O
al. O
, O
2019 O
) O
and O
diffusion O
network O
( O
liu O
and O
wu O
, O
2018 O
; O
rosenfeld O
et O
al. O
, O
2020 O
) O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
however O
, O
these O
methods O
mainly O
aim O
at O
newly O
emerged O
claims O
and O
do O
not O
address O
those O
claims O
that O
have O
been O
fact-checked O
but O
continually O
spread O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
our O
work O
is O
in O
a O
new O
thread O
, O
detecting O
previously O
fact-checked O
claims O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
vo O
and O
lee O
( O
2020 O
) O
models O
interaction O
between O
claims O
and O
fc-articles O
by O
combining O
glove O
( O
pennington O
et O
al. O
, O
2014 O
) O
and O
elmo O
embeddings O
( O
peters O
et O
al. O
, O
2018 O
) O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
shaar O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
( O
2020 O
) O
train O
a O
ranksvm O
with O
scores O
from O
bm25 O
and O
sentence-bert O
for O
relevance O
prediction O
. O

section 2
id pdf2json/2021.acl-long.425.pdf.json
these O
methods O
ignore O
the O
characteristics O
of O
fc-articles O
, O
which O
limits O
the O
ranking O
performance O
and O
explainability O
. O

section 3
id pdf2json/2021.acl-long.425.pdf.json
given O
a O
claim O
q O
and O
a O
candidate O
set O
of O
k1 O
fcarticles O
d O
obtained O
by O
a O
standard O
full-text O
retrieval O
model O
( O
bm25 O
) O
, O
we O
aim O
to O
rerank O
fc-articles O
truly O
relevant O
w.r.t O
. O

section 3
id pdf2json/2021.acl-long.425.pdf.json
q O
at O
the O
top O
by O
modeling O
fine-grained O
relevance O
between O
q O
and O
each O
article O
d O
∈ O
d. O
this O
is O
accomplished O
by O
memory-enhanced O
transformers O
for O
matching O
( O
mtm O
) O
, O
which O
conceptually O
has O
two O
steps O
, O
( O
1 O
) O
key O
sentence O
identification O
and O
( O
2 O
) O
article O
relevance O
prediction O
, O
see O
figure O
2 O
. O

section 3
id pdf2json/2021.acl-long.425.pdf.json
for O
an O
article O
of O
l O
sentences O
, O
let O
s O
= O
{ O
s1 O
, O
... O
, O
sl O
} O
be O
its O
sentence O
set O
. O

section 3
id pdf2json/2021.acl-long.425.pdf.json
in O
step O
( O
1 O
) O
, O
for O
each O
sentence O
, O
we O
derive O
claim-sentence O
relevance O
score O
from O
rougeguided O
transformer O
( O
rot O
) O
and O
pattern-sentence O
relevance O
score O
from O
pattern O
memory O
bank O
( O
pmb O
) O
. O

section 3
id pdf2json/2021.acl-long.425.pdf.json
the O
scores O
indicate O
how O
similar O
the O
sentence O
is O
to O
the O
claim O
and O
pattern O
vectors O
, O
i.e. O
, O
how O
possible O
to O
be O
a O
key O
sentence O
. O

section 3
id pdf2json/2021.acl-long.425.pdf.json
top O
k2 O
sentences O
are O
selected O
for O
more O
complicated O
interactions O
and O
aggregation O
with O
the O
claim O
and O
pattern O
vectors O
in O
step O
( O
2 O
) O
. O

section 3
id pdf2json/2021.acl-long.425.pdf.json
the O
aggregated O
vector O
is O
used O
for O
the O
final O
prediction O
. O

section 3
id pdf2json/2021.acl-long.425.pdf.json
we O
detail O
the O
components O
and O
then O
summarize O
the O
training O
procedure O
below O
. O

section 4
id pdf2json/2021.acl-long.425.pdf.json
3.1.1 O
rouge-guided O
transformer O
( O
rot O
) O
rot O
( O
left O
top O
of O
figure O
. O

section 4
id pdf2json/2021.acl-long.425.pdf.json
2 O
) O
is O
used O
to O
evaluate O
the O
relevance O
between O
q O
and O
each O
sentence O
s O
in O
{ O
si O
} O
k1i=1 O
, O
both O
lexically O
and O
semantically O
. O

section 4
id pdf2json/2021.acl-long.425.pdf.json
inspired O
by O
( O
gao O
et O
al. O
, O
2020 O
) O
, O
we O
choose O
to O
“ O
inject O
” O
the O
ability O
to O
consider O
lexical O
relevance O
into O
the O
semantic O
model O
. O

section 4
id pdf2json/2021.acl-long.425.pdf.json
as O
the O
bert O
is O
proved O
to O
capture O
and O
evaluate O
semantic O
relevance O
( O
zhang O
et O
al. O
, O
2020 O
) O
, O
we O
use O
a O
one-layer O
transformer O
initialized O
with O
the O
first O
block O
of O
pretrained O
bert O
to O
obtain O
the O
initial O
semantic O
representation O
of O
q O
and O
s O
: O
zq O
, O
s O
= O
transformer O
( O
[ O
cls O
] O
q O
[ O
sep O
] O
s O
) O
( O
1 O
) O
where O
[ O
cls O
] O
and O
[ O
sep O
] O
are O
preserved O
tokens O
and O
zq O
, O
s O
is O
the O
output O
representation O
. O

section 4
id pdf2json/2021.acl-long.425.pdf.json
to O
force O
rot O
to O
consider O
the O
lexical O
relevance O
, O
we O
finetune O
the O
pretrained O
transformer O
with O
the O
guidance O
of O
rouge O
( O
lin O
, O
2004 O
) O
, O
a O
widely-used O
metric O
to O
evaluate O
the O
lexical O
similarity O
of O
two O
segments O
in O
summarization O
and O
translation O
tasks O
. O

section 4
id pdf2json/2021.acl-long.425.pdf.json
the O
intuition O
is O
that O
lexical O
relevance O
can O
be O
characterized O
by O
token O
overlapping O
, O
which O
rouge O
exactly O
measures O
. O

section 4
id pdf2json/2021.acl-long.425.pdf.json
we O
minimize O
the O
mean O
square O
error O
between O
the O
prediction O
and O
the O
precision O
and O
recall O
of O
rouge-2 O
between O
q O
and O
s O
( O
r2 O
∈ O
r2 O
) O
to O
optimize O
the O
rot O
: O
r̂ O
( O
q O
, O
s O
) O
= O
mlp O
( O
zq O
, O
s O
( O
[ O
cls O
] O
) O
) O
( O
2 O
) O
lr O
= O
‖r̂ O
( O
q O
, O
s O
) O
− O
r2 O
( O
q O
, O
s O
) O
‖22 O
+ O
λr‖∆θ‖22 O
( O
3 O
) O
where O
the O
first O
term O
is O
the O
regression O
loss O
and O
the O
second O
is O
to O
constraint O
the O
change O
of O
parameters O
as O
the O
ability O
to O
capture O
semantic O
relevance O
should O
be O
maintained O
. O

section 4
id pdf2json/2021.acl-long.425.pdf.json
λr O
is O
a O
control O
factor O
and O
∆θ O
represents O
the O
change O
of O
parameters O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
the O
pattern O
memory O
bank O
( O
pmb O
) O
is O
to O
generate O
, O
store O
, O
and O
update O
the O
vectors O
which O
represent O
the O
common O
patterns O
in O
fc-articles O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
the O
vectors O
in O
pmb O
will O
be O
used O
to O
evaluate O
pattern-sentence O
relevance O
( O
see O
section O
3.1.3 O
) O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
here O
we O
detail O
how O
to O
formulate O
, O
initialize O
, O
and O
update O
these O
patterns O
below O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
formulation O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
intuitively O
, O
one O
can O
summarize O
the O
templates O
, O
like O
“ O
... O
has O
been O
debunked O
by O
... O
” O
, O
and O
explicitly O
do O
exact O
matching O
, O
but O
the O
templates O
are O
costly O
to O
obtain O
and O
hard O
to O
integrate O
into O
neural O
models O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
instead O
, O
we O
implicitly O
represent O
the O
common O
patterns O
using O
vectors O
derived O
from O
embeddings O
of O
our O
model O
, O
rot O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
inspired O
by O
( O
wu O
et O
al. O
, O
2018 O
) O
, O
we O
use O
a O
memory O
bankm O
to O
store O
k O
common O
patterns O
( O
as O
vectors O
) O
, O
i.e. O
, O
m O
= O
{ O
mi O
} O
ki=1 O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
initialization O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
we O
first O
represent O
each O
q O
in O
the O
training O
set O
and O
s O
in O
the O
corresponding O
articles O
by O
averaging O
its O
token O
embeddings O
( O
from O
the O
embedding O
layer O
of O
rot O
) O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
considering O
that O
a O
pattern O
vector O
should O
be O
event-irrelevant O
, O
we O
heuristically O
remove O
the O
event-related O
part O
in O
s O
as O
possible O
by O
calculating O
the O
residual O
embeddings O
rs O
, O
q O
, O
i.e. O
, O
subtracting O
q O
from O
s. O
we O
rule O
out O
the O
residual O
embeddings O
that O
do O
not O
satisfy O
tlow O
< O
‖rs O
, O
q‖2 O
< O
thigh O
, O
because O
they O
are O
unlikely O
to O
contain O
good O
pattern O
information O
: O
‖rs O
, O
q‖2 O
≤ O
tlow O
indicates O
q O
and O
s O
are O
highly O
similar O
and O
thus O
leave O
little O
pattern O
information O
, O
while O
‖rs O
, O
q‖2 O
≥ O
thigh O
indicates O
s O
may O
not O
align O
with O
q O
in O
terms O
of O
the O
event O
, O
so O
the O
corresponding O
rs O
, O
q O
is O
of O
little O
sense O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
finally O
, O
we O
aggregate O
the O
valid O
residual O
embeddings O
into O
k O
clusters O
using O
k-means O
and O
obtain O
the O
initial O
memory O
bankm O
: O
m O
= O
k-means O
( O
{ O
rvalids O
, O
q O
} O
) O
= O
{ O
m1 O
, O
... O
, O
mk O
} O
( O
4 O
) O
where O
{ O
rvalids O
, O
q O
} O
is O
the O
set O
of O
valid O
residual O
embeddings O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
update O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
as O
the O
initial O
k O
vectors O
may O
not O
accurately O
represent O
common O
patterns O
, O
we O
update O
the O
memory O
bank O
according O
to O
the O
feedbacks O
of O
results O
during O
training O
: O
if O
the O
model O
predicts O
rightly O
, O
the O
key O
sentence O
, O
say O
s O
, O
should O
be O
used O
to O
update O
its O
nearest O
pattern O
vector O
m. O
to O
maintain O
stability O
, O
we O
use O
an O
epoch-wise O
update O
instead O
of O
an O
iterationwise O
update O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
take O
updating O
m O
as O
an O
example O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
after O
an O
epoch O
, O
we O
extract O
all O
n O
key O
sentences O
whose O
nearest O
pattern O
vector O
is O
m O
and O
their O
n O
corresponding O
claims O
, O
which O
is O
denoted O
as O
a O
tuple O
set O
( O
s O
, O
q O
) O
m. O
then O
( O
s O
, O
q O
) O
m O
is O
separated O
into O
two O
subsets O
, O
rm O
and O
wm O
, O
which O
contain O
nr O
and O
nw O
sentence-claim O
tuples O
from O
the O
rightly O
and O
wrongly O
predicted O
samples O
, O
respectively O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
the O
core O
of O
our O
update O
mechanism O
( O
figure O
3 O
) O
is O
to O
draw O
m O
closer O
to O
the O
residual O
embeddings O
inrm O
and O
push O
it O
away O
from O
those O
in O
wm O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
we O
denote O
the O
ith O
residual O
embedding O
from O
the O
two O
subsets O
as O
rrmi O
and O
rwmi O
, O
respectively O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
to O
determine O
the O
update O
direction O
, O
we O
calculate O
a O
weighted O
sum O
of O
residual O
embeddings O
according O
to O
the O
predicted O
matching O
scores O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
for O
( O
s O
, O
q O
) O
, O
suppose O
mtm O
output O
ŷs O
, O
q O
∈ O
[ O
0 O
, O
1 O
] O
as O
the O
predicted O
matching O
score O
of O
q O
and O
d O
( O
whose O
key O
sentence O
is O
s O
) O
, O
the O
weight O
of O
rs O
, O
q O
is O
|ŷs O
, O
q O
− O
0.5| O
( O
denoted O
as O
ws O
, O
q O
) O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
weighted O
residual O
embeddings O
are O
respectively O
summed O
and O
normalized O
as O
the O
components O
of O
the O
direction O
vector O
( O
eq O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
5 O
) O
: O
umr O
= O
( O
nr∑ O
i=1 O
wrmi O
rrmi O
) O
, O
umw O
= O
( O
nw∑ O
i=1 O
wwmi O
rwmi O
) O
( O
5 O
) O
where O
umr O
and O
umw O
are O
the O
aggregated O
residual O
embeddings O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
the O
direction O
is O
determined O
by O
eq O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
6 O
: O
um O
= O
wr O
( O
u O
mr O
−m O
) O
︸ O
︷︷ O
︸ O
draw O
closer O
+ww O
( O
m− O
umw O
) O
︸ O
︷︷ O
︸ O
push O
away O
( O
6 O
) O
where O
wr O
and O
ww O
are O
the O
normalized O
sum O
of O
corresponding O
weights O
used O
in O
eq O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
5 O
( O
wr O
+ O
ww O
= O
1 O
) O
. O

section 5
id pdf2json/2021.acl-long.425.pdf.json
the O
pattern O
vector O
m O
is O
updated O
with O
: O
mnew O
= O
mold O
+ O
λm‖mold‖2 O
um O
‖um‖2 O
( O
7 O
) O
where O
mold O
and O
mnew O
are O
the O
memory O
vector O
m O
before O
and O
after O
updating O
; O
the O
constant O
λm O
and O
‖mold‖2 O
jointly O
control O
the O
step O
size O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
whether O
a O
sentence O
is O
selected O
as O
a O
key O
sentence O
is O
determined O
by O
combining O
claim- O
and O
patternsentence O
relevance O
scores O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
the O
former O
is O
calculated O
with O
the O
distance O
of O
q O
and O
s O
trained O
with O
rot O
( O
eq O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
8 O
) O
and O
the O
latter O
uses O
the O
distance O
between O
the O
nearest O
pattern O
vector O
in O
pmb O
and O
the O
residual O
embedding O
( O
eq O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
9 O
) O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
the O
scores O
are O
scaled O
to O
[ O
0 O
, O
1 O
] O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
for O
each O
sentence O
s O
in O
d O
, O
the O
relevance O
score O
with O
q O
is O
calculated O
by O
eq O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
10 O
: O
scrq O
( O
q O
, O
s O
) O
= O
scale O
( O
‖rs O
, O
q‖2 O
) O
( O
8 O
) O
scrp O
( O
q O
, O
s O
) O
= O
scale O
( O
‖mu O
− O
rs O
, O
q‖2 O
) O
( O
9 O
) O
scr O
( O
q O
, O
s O
) O
= O
λqscrq O
( O
q O
, O
s O
) O
+ O
λp O
scrp O
( O
q O
, O
s O
) O
( O
10 O
) O
where O
scale O
( O
x O
) O
=1− O
x−minmax−min O
and O
max O
and O
min O
are O
the O
maximum O
and O
minimum O
distance O
of O
s O
in O
d O
, O
respectively O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
u O
= O
arg O
mini O
‖mi O
− O
rs O
, O
q‖2 O
, O
and O
λq O
and O
λp O
are O
hyperparameters O
whose O
sum O
is O
1 O
. O

section 6
id pdf2json/2021.acl-long.425.pdf.json
finally O
, O
sentences O
with O
top-k2 O
scores O
, O
denoted O
as O
k O
= O
{ O
skeyi O
( O
q O
, O
d O
) O
} O
k2 O
i=1 O
, O
are O
selected O
as O
the O
key O
sentences O
in O
d O
for O
the O
claim O
q O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
sentence O
representation O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
we O
model O
more O
complicated O
interactions O
between O
the O
claim O
and O
the O
key O
sentences O
by O
feeding O
each O
zq O
, O
skey O
( O
derived O
from O
rot O
) O
into O
a O
multi-layer O
transformer O
( O
multitransformer O
) O
: O
z′q O
, O
skey O
= O
multitransformer O
( O
zq O
, O
skey O
) O
( O
11 O
) O
following O
( O
reimers O
and O
gurevych O
, O
2019 O
) O
, O
we O
respectively O
compute O
the O
mean O
of O
all O
output O
token O
vectors O
of O
q O
and O
s O
in O
z′ O
q O
, O
skey O
to O
obtain O
the O
fixed O
sized O
sentence O
vectors O
q′ O
∈ O
rdim O
and O
skey′ O
∈ O
rdim O
, O
where O
dim O
is O
the O
dimension O
of O
a O
token O
in O
transformers O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
weighted O
memory-aware O
aggregation O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
for O
final O
prediction O
, O
we O
use O
a O
score-weighted O
memory-aware O
aggregation O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
to O
make O
the O
predictor O
aware O
of O
the O
pattern O
information O
, O
we O
append O
the O
corresponding O
nearest O
pattern O
vectors O
to O
the O
claim O
and O
key O
sentence O
vectors O
: O
vi O
= O
[ O
q O
′ O
, O
skey′i O
( O
q O
, O
d O
) O
, O
mj O
] O
( O
12 O
) O
where O
i=1 O
, O
... O
, O
k2 O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
j=arg O
mink O
∥∥∥mk−rskeyi O
, O
q∥∥∥2 O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
intuitively O
, O
a O
sentence O
with O
higher O
score O
should O
be O
attended O
more O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
thus O
, O
the O
concatenated O
vectors O
( O
eq O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
12 O
) O
are O
weighted O
by O
the O
relevance O
scores O
from O
eq O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
10 O
( O
normalized O
across O
the O
top-k2 O
sentences O
) O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
the O
weighted O
aggregating O
vector O
is O
fed O
into O
a O
mlp O
which O
outputs O
the O
probability O
that O
d O
fact-checks O
q O
: O
scr′ O
( O
q O
, O
skeyi O
) O
= O
normalize O
( O
scr O
( O
q O
, O
skeyi O
) O
) O
( O
13 O
) O
ŷq O
, O
d O
= O
mlp O
( O
k2∑ O
i=1 O
scr′ O
( O
q O
, O
skeyi O
) O
vi O
) O
( O
14 O
) O
where O
ŷq O
, O
d O
∈ O
[ O
0 O
, O
1 O
] O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
if O
ŷq O
, O
d O
> O
0.5 O
, O
the O
model O
predicts O
that O
d O
fact-checks O
q O
, O
otherwise O
does O
not O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
the O
loss O
function O
is O
cross O
entropy O
: O
lm O
= O
crossentropy O
( O
ŷq O
, O
d O
, O
yq O
, O
d O
) O
( O
15 O
) O
where O
yq O
, O
d O
∈ O
{ O
0 O
, O
1 O
} O
is O
the O
ground O
truth O
label O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
yq O
, O
d O
= O
1 O
if O
d O
fact-checks O
q O
and O
0 O
otherwise O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
the O
predicted O
values O
are O
used O
to O
rank O
all O
k1 O
candidate O
articles O
retrieved O
in O
the O
first O
stage O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
3.3 O
training O
mtm O
we O
summarize O
the O
training O
procedure O
of O
mtm O
in O
algorithm O
1 O
, O
including O
the O
pretraining O
of O
rot O
, O
the O
initialization O
of O
pmb O
, O
the O
training O
of O
arp O
, O
and O
the O
epoch-wise O
update O
of O
pmb O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
algorithm O
1 O
mtm O
training O
procedure O
input O
: O
training O
set O
t O
= O
[ O
( O
q0 O
, O
d00 O
) O
, O
... O
, O
( O
q0 O
, O
d0k1 O
) O
, O
... O
, O
( O
qn O
, O
dnk1 O
) O
] O
where O
the O
k1 O
candidate O
articles O
for O
each O
claim O
are O
retrieved O
by O
bm25 O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
1 O
: O
pre-train O
rouge-guided O
transformer O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
2 O
: O
initialize O
the O
pattern O
memory O
bank O
( O
pmb O
) O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
3 O
: O
for O
each O
epoch O
do O
4 O
: O
for O
( O
q O
, O
d O
) O
in O
t O
do O
5 O
: O
// O
key O
sentence O
identification O
6 O
: O
calculate O
scrq O
( O
q O
, O
s O
) O
via O
rot O
and O
scrp O
( O
q O
, O
s O
) O
via O
pmb O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
7 O
: O
calculate O
scr O
( O
q O
, O
s O
) O
using O
eq.10 O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
8 O
: O
select O
key O
sentences O
k. O
9 O
: O
// O
article O
relevance O
prediction O
( O
arp O
) O
10 O
: O
calculate O
v O
for O
each O
s O
in O
k O
and O
ŷq O
, O
d O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
11 O
: O
update O
the O
arp O
to O
minimize O
lm O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
12 O
: O
end O
for O
13 O
: O
update O
the O
pmb O
using O
eq O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
7 O
. O

section 7
id pdf2json/2021.acl-long.425.pdf.json
14 O
: O
end O
for O

section 8
id pdf2json/2021.acl-long.425.pdf.json
in O
this O
section O
, O
we O
mainly O
answer O
the O
following O
experimental O
questions O
: O
eq1 O
: O
can O
mtm O
improve O
the O
ranking O
performance O
of O
fc-articles O
given O
a O
claim O
? O

section 8
id pdf2json/2021.acl-long.425.pdf.json
eq2 O
: O
how O
effective O
are O
the O
components O
of O
mtm O
, O
including O
rouge-guided O
transformer O
, O
pattern O
memory O
bank O
, O
and O
weighted O
memory-aware O
aggregation O
in O
article O
relevance O
prediction O
? O

section 8
id pdf2json/2021.acl-long.425.pdf.json
eq3 O
: O
to O
what O
extent O
can O
mtm O
identify O
key O
sentences O
in O
the O
articles O
, O
especially O
in O
the O
longer O
ones O
? O

section 9
id pdf2json/2021.acl-long.425.pdf.json
we O
conducted O
the O
experiments O
on O
two O
real-world O
datasets O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
table O
1 O
shows O
the O
statistics O
of O
the O
two O
datasets O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
the O
details O
are O
as O
follows O
: O
twitter O
dataset O
the O
twitter4 O
dataset O
is O
originated O
from O
( O
vo O
and O
lee O
, O
2019 O
) O
and O
processed O
by O
vo O
and O
lee O
( O
2020 O
) O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
the O
dataset O
pairs O
the O
claims O
( O
tweets O
) O
with O
the O
corresponding O
fc-articles O
from O
snopes O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
for O
tweets O
with O
images O
, O
it O
appends O
the O
ocr O
results O
to O
the O
tweets O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
we O
remove O
the O
manually O
normalized O
claims O
in O
snopes O
’ O
fc-articles O
to O
adapt O
to O
more O
general O
scenarios O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
the O
data O
split O
is O
the O
same O
as O
that O
in O
( O
vo O
and O
lee O
, O
2020 O
) O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
weibo O
dataset O
we O
built O
the O
first O
chinese O
dataset O
for O
the O
task O
of O
detecting O
previously O
fact-checked O
claims O
in O
this O
ar- O
4https O
: O
//twitter.com O
ticle O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
the O
claims O
are O
collected O
from O
weibo O
and O
the O
fc-articles O
are O
from O
multiple O
fact-checking O
sources O
including O
jiaozhen O
, O
zhuoyaoji5 O
, O
etc O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
we O
recruited O
annotators O
to O
match O
claims O
and O
fc-articles O
based O
on O
basic O
search O
results O
. O

section 9
id pdf2json/2021.acl-long.425.pdf.json
appendix O
a O
introduce O
the O
details O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
bert-based O
rankers O
from O
general O
ir O
tasks O
bert O
( O
devlin O
et O
al. O
, O
2019 O
) O
: O
a O
method O
of O
pretraining O
language O
representations O
with O
a O
family O
of O
pretrained O
models O
, O
which O
has O
been O
used O
in O
general O
document O
reranking O
to O
predict O
the O
relevance O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
( O
nogueira O
and O
cho O
, O
2019 O
; O
akkalyoncu O
yilmaz O
et O
al. O
, O
2019 O
) O
duobert O
( O
nogueira O
et O
al. O
, O
2019 O
) O
: O
a O
popular O
bert-based O
reranker O
for O
multi-stage O
document O
ranking O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
its O
input O
is O
a O
query O
and O
a O
pair O
of O
documents O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
the O
pairwise O
scores O
are O
aggregated O
for O
final O
document O
ranking O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
our O
first O
baseline O
, O
bert O
( O
trained O
with O
query-article O
pairs O
) O
, O
provides O
the O
inputs O
for O
duobert O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
bert O
( O
transfer O
) O
: O
as O
no O
sentence-level O
labels O
are O
provided O
in O
most O
document O
retrieval O
datasets O
, O
yang O
et O
al O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
( O
2019 O
) O
finetune O
bert O
with O
short O
text O
matching O
data O
and O
then O
apply O
to O
score O
the O
relevance O
between O
query O
and O
each O
sentence O
in O
documents O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
the O
three O
highest O
scores O
are O
combined O
with O
bm25 O
score O
for O
document-level O
prediction O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
rankers O
from O
related O
works O
of O
our O
task O
sentence-bert O
: O
shaar O
et O
al O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
( O
2020 O
) O
use O
pretrained O
sentence-bert O
models O
to O
calculate O
cosine O
similarity O
between O
each O
sentence O
and O
the O
given O
claim O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
then O
the O
top O
similarity O
scores O
are O
fed O
into O
a O
neural O
network O
to O
predict O
document O
relevance O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
ranksvm O
: O
a O
pairwise O
ranksvm O
model O
for O
reranking O
using O
the O
scores O
from O
bm25 O
and O
sentence-bert O
( O
mentioned O
above O
) O
, O
which O
achieves O
the O
best O
results O
in O
( O
shaar O
et O
al. O
, O
2020 O
) O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
5https O
: O
//piyao.sina.cn O
ctm O
( O
vo O
and O
lee O
, O
2020 O
) O
: O
this O
method O
leverages O
glove O
and O
elmo O
to O
jointly O
represent O
the O
claims O
and O
the O
fc-articles O
for O
predicting O
the O
relevance O
scores O
. O

section 10
id pdf2json/2021.acl-long.425.pdf.json
its O
multi-modal O
version O
is O
not O
included O
as O
mtm O
focuses O
on O
key O
textual O
information O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
evaluation O
metrics O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
as O
this O
is O
a O
binary O
retrieval O
task O
, O
we O
follow O
shaar O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
( O
2020 O
) O
and O
report O
mean O
reciprocal O
rank O
( O
mrr O
) O
, O
mean O
average O
precision O
@ O
k O
( O
map O
@ O
k O
, O
k O
= O
1 O
, O
3 O
, O
5 O
) O
and O
hit O
@ O
k O
( O
k O
= O
3 O
, O
5 O
) O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
see O
equations O
in O
appendix O
b O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
implementation O
details O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
in O
mtm O
, O
the O
rot O
and O
arp O
components O
have O
one O
and O
eleven O
transformer O
layers O
, O
respectively O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
the O
initial O
parameters O
are O
obtained O
from O
pretrained O
bert O
models6 O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
other O
parameters O
are O
randomly O
initialized O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
the O
dimension O
of O
claim O
and O
sentence O
representation O
in O
arp O
and O
pattern O
vectors O
are O
768 O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
number O
of O
clusters O
in O
pmb O
k O
is O
20 O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
following O
( O
shaar O
et O
al. O
, O
2020 O
) O
and O
( O
vo O
and O
lee O
, O
2020 O
) O
, O
we O
use O
k1 O
= O
50 O
candidates O
retrieved O
by O
bm25 O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
k2 O
= O
3 O
( O
weibo O
, O
hereafter O
, O
w O
) O
/ O
5 O
( O
twitter O
, O
hereafter O
, O
t O
) O
key O
sentences O
are O
selected O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
we O
use O
adam O
( O
p. O
kingma O
and O
ba O
, O
2015 O
) O
for O
optimization O
with O
= O
10−6 O
, O
β1 O
= O
0.9 O
, O
β2 O
= O
0.999 O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
the O
learning O
rates O
are O
5× O
10−6 O
( O
w O
) O
and O
1× O
10−4 O
( O
t O
) O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
the O
batch O
size O
is O
512 O
for O
pretraining O
rot O
, O
64 O
for O
the O
main O
task O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
according O
to O
the O
quantiles O
on O
6we O
use O
bert-base-chinese O
for O
weibo O
and O
bert-base-uncased O
for O
twitter O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
training O
sets O
, O
we O
set O
tlow O
= O
0.252 O
( O
w O
) O
/ O
0.190 O
( O
t O
) O
, O
thigh O
= O
0.295 O
( O
w O
) O
/ O
0.227 O
( O
t O
) O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
the O
following O
hyperparameters O
are O
selected O
according O
to O
the O
best O
validation O
performance O
: O
λr O
= O
0.01 O
( O
w O
) O
/ O
0.05 O
( O
t O
) O
, O
λq O
= O
0.6 O
, O
λp O
= O
0.4 O
, O
and O
λm O
= O
0.3 O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
the O
maximum O
epoch O
is O
5 O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
all O
experiments O
were O
conducted O
on O
nvidia O
v100 O
gpus O
with O
pytorch O
( O
paszke O
et O
al. O
, O
2019 O
) O
. O

section 11
id pdf2json/2021.acl-long.425.pdf.json
the O
implementation O
details O
of O
baselines O
are O
in O
appendix O
c O
. O

section 12
id pdf2json/2021.acl-long.425.pdf.json
to O
answer O
eq1 O
, O
we O
compared O
the O
performance O
of O
baselines O
and O
our O
method O
on O
the O
two O
datasets O
, O
as O
shown O
in O
table O
2 O
. O

section 12
id pdf2json/2021.acl-long.425.pdf.json
we O
see O
that O
: O
( O
1 O
) O
mtm O
ourperforms O
all O
compared O
methods O
on O
the O
two O
datasets O
( O
the O
exception O
is O
only O
the O
map O
@ O
1 O
on O
twitter O
) O
, O
which O
indicates O
that O
it O
can O
effectively O
find O
related O
fc-articles O
and O
provide O
evidence O
for O
determining O
if O
a O
claim O
is O
previously O
fact-checked O
. O

section 12
id pdf2json/2021.acl-long.425.pdf.json
( O
2 O
) O
for O
all O
methods O
, O
the O
performance O
on O
weibo O
is O
worse O
than O
that O
on O
twitter O
because O
the O
weibo O
dataset O
contains O
more O
claim-sentence O
pairs O
( O
from O
multiple O
sources O
) O
than O
twitter O
and O
is O
more O
challenging O
. O

section 12
id pdf2json/2021.acl-long.425.pdf.json
despite O
this O
, O
mtm O
’ O
s O
improvement O
is O
significant O
. O

section 12
id pdf2json/2021.acl-long.425.pdf.json
( O
3 O
) O
bert O
( O
transfer O
) O
, O
sentence-bert O
and O
ranksvm O
use O
transferred O
sentence-level O
knowledge O
from O
other O
pretext O
tasks O
but O
did O
not O
outperform O
the O
document-level O
bert O
. O

section 12
id pdf2json/2021.acl-long.425.pdf.json
this O
is O
because O
fcarticles O
have O
their O
own O
characteristics O
, O
which O
may O
not O
be O
covered O
by O
transferred O
knowledge O
. O

section 12
id pdf2json/2021.acl-long.425.pdf.json
in O
con- O
trast O
, O
our O
observed O
characteristics O
help O
mtm O
achieve O
good O
performance O
. O

section 12
id pdf2json/2021.acl-long.425.pdf.json
moreover O
, O
mtm O
is O
also O
efficiency O
compared O
to O
bert O
( O
transfer O
) O
, O
which O
also O
uses O
12-layer O
bert O
and O
selects O
sentences O
, O
because O
our O
model O
uses O
only O
one O
layer O
for O
all O
sentences O
( O
other O
11 O
layers O
are O
for O
key O
sentences O
) O
, O
while O
all O
sentences O
are O
fed O
into O
the O
12 O
layers O
in O
bert O
( O
transfer O
) O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
to O
answer O
eq2 O
, O
we O
evaluated O
three O
ablation O
groups O
of O
mtm O
’ O
s O
variants O
( O
ag1∼ag3 O
) O
to O
investigate O
the O
effectiveness O
of O
the O
model O
design.7 O
table O
3 O
shows O
the O
performance O
of O
variants O
and O
mtm O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
ag1 O
: O
with O
vs O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
without O
rouge O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
the O
variant O
removes O
the O
guidance O
of O
rouge O
( O
mtm O
w/o O
rouge O
guidance O
) O
to O
check O
the O
effectiveness O
of O
rougeguided O
finetuning O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
the O
variant O
performs O
worse O
on O
weibo O
, O
but O
map O
@ O
1 O
slightly O
increases O
on O
twitter O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
this O
is O
probably O
because O
there O
are O
more O
lexical O
overlapping O
between O
claims O
and O
fc-articles O
in O
the O
weibo O
dataset O
, O
while O
most O
of O
the O
fc-articles O
in O
the O
twitter O
dataset O
choose O
to O
summarize O
the O
claims O
to O
fact-check O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
ag2 O
: O
cluster-based O
initialization O
vs. O
random O
initialization O
vs O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
without O
update O
vs O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
without O
pmb O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
the O
first O
variant O
( O
mtm O
w/ O
rand O
mem O
init O
) O
uses O
random O
initialization O
and O
the O
second O
( O
mtm O
w/o O
mem O
update O
) O
uses O
pattern O
vectors O
without O
updating O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
the O
last O
one O
( O
mtm O
w/o O
pmb O
) O
removes O
the O
pmb O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
we O
see O
that O
the O
variants O
all O
perform O
worse O
than O
mtm O
on O
mrr O
, O
of O
which O
w/ O
rand O
mem O
init O
performs O
the O
worst O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
this O
indicates O
that O
cluster-based O
initialization O
provides O
a O
good O
start O
and O
facilitates O
the O
following O
updates O
while O
the O
random O
one O
may O
harm O
further O
learning O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
ag3 O
: O
score-weighted O
pooling O
vs. O
average O
pooling O
, O
and O
with O
vs O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
without O
pattern O
vector O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
the O
first O
variant O
, O
mtm O
w/ O
avg O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
pool O
, O
replace O
the O
score-weighted O
pooling O
with O
average O
pooling O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
the O
comparison O
in O
terms O
of O
mrr O
and O
map O
shows O
the O
effectiveness O
of O
using O
relevance O
scores O
as O
weights O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
the O
second O
, O
mtm O
w/o O
pattern O
aggr. O
, O
does O
not O
append O
the O
pattern O
vector O
to O
claim O
and O
sentence O
vectors O
before O
aggregation O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
it O
yields O
worse O
results O
, O
indicating O
the O
patterns O
should O
be O
taken O
into O
consideration O
for O
final O
prediction O
. O

section 13
id pdf2json/2021.acl-long.425.pdf.json
7we O
do O
not O
run O
mtm O
without O
sentence O
selection O
due O
to O
its O
high O
computational O
overhead O
which O
makes O
it O
unfeasible O
for O
training O
and O
inference O
. O

section 14
id pdf2json/2021.acl-long.425.pdf.json
to O
probe O
what O
the O
pmb O
summarizes O
and O
memorizes O
, O
we O
selected O
and O
analyzed O
the O
key O
sentences O
corresponding O
to O
the O
residual O
embeddings O
around O
pattern O
vectors O
. O

section 14
id pdf2json/2021.acl-long.425.pdf.json
figure O
4 O
shows O
example O
sentences O
where O
highly O
frequent O
words O
are O
in O
boldface O
. O

section 14
id pdf2json/2021.acl-long.425.pdf.json
these O
examples O
indicate O
that O
the O
pattern O
vectors O
do O
cluster O
key O
sentences O
with O
common O
patterns O
like O
“ O
... O
spread O
in O
wechat O
moments O
” O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
the O
quality O
of O
selected O
sentences O
can O
not O
be O
automatically O
evaluated O
due O
to O
the O
lack O
of O
sentencelevel O
labels O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
to O
answer O
eq3 O
, O
we O
conducted O
a O
human O
evaluation O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
we O
randomly O
sampled O
370 O
claimarticle O
pairs O
whose O
articles O
were O
with O
over O
20 O
sentences O
from O
the O
weibo O
dataset O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
then O
we O
showed O
each O
claim O
and O
top O
three O
sentences O
selected O
from O
the O
corresponding O
fc-article O
by O
mtm O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
three O
anno- O
tators O
were O
asked O
to O
check O
if O
an O
auto-selected O
sentence O
helped O
match O
the O
given O
query O
and O
the O
source O
article O
( O
i.e. O
, O
key O
sentences O
) O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
figure O
5 O
shows O
( O
a O
) O
mtm O
hit O
at O
least O
one O
key O
sentence O
in O
83.0 O
% O
of O
the O
articles O
; O
( O
b O
) O
73.0 O
% O
of O
the O
sentences O
at O
rank O
1 O
are O
key O
sentences O
, O
followed O
by O
65.1 O
% O
at O
rank O
2 O
and O
56.8 O
% O
at O
rank O
3 O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
this O
proves O
that O
mtm O
can O
find O
the O
key O
sentences O
in O
long O
fc-articles O
and O
provide O
helpful O
explanations O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
we O
also O
show O
the O
positional O
distribution O
in O
figure O
5 O
( O
c O
) O
, O
where O
key O
sentences O
are O
scattered O
throughout O
the O
articles O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
using O
mtm O
to O
find O
key O
sentences O
can O
save O
fact-checkers O
’ O
time O
to O
scan O
these O
long O
articles O
for O
determining O
whether O
the O
given O
claim O
was O
fact-checked O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
additionally O
, O
we O
exhibit O
two O
cases O
in O
the O
evaluation O
set O
in O
figure O
6 O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
these O
cases O
prove O
that O
mtm O
found O
the O
key O
sentences O
that O
correspond O
to O
the O
characteristics O
described O
in O
section O
1 O
. O

section 15
id pdf2json/2021.acl-long.425.pdf.json
please O
refer O
to O
appendix O
d O
for O
further O
case O
analysis O
. O

section 16
id pdf2json/2021.acl-long.425.pdf.json
we O
propose O
mtm O
to O
select O
from O
fact-checked O
articles O
key O
sentences O
that O
introduce O
or O
debunk O
claims O
. O

section 16
id pdf2json/2021.acl-long.425.pdf.json
these O
auto-selected O
sentences O
are O
exploited O
in O
an O
end-to-end O
network O
for O
estimating O
the O
relevance O
of O
the O
fact-checked O
articles O
w.r.t O
. O

section 16
id pdf2json/2021.acl-long.425.pdf.json
a O
given O
claim O
. O

section 16
id pdf2json/2021.acl-long.425.pdf.json
experiments O
on O
the O
public O
twitter O
dataset O
and O
the O
private O
weibo O
dataset O
show O
that O
mtm O
outperforms O
the O
state O
of O
the O
art O
. O

section 16
id pdf2json/2021.acl-long.425.pdf.json
moreover O
, O
human O
evaluation O
and O
case O
studies O
demonstrate O
that O
the O
selected O
sentences O
provide O
helpful O
explanations O
of O
the O
results O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
the O
authors O
thank O
guang O
yang O
, O
tianyun O
yang O
, O
peng O
qi O
and O
anonymous O
reviewers O
for O
their O
insightful O
comments O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
also O
, O
we O
thank O
rundong O
li O
, O
qiong O
nan O
, O
and O
other O
annotators O
for O
their O
efforts O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
this O
work O
was O
supported O
by O
the O
national O
key O
research O
and O
development O
program O
of O
china O
( O
2017yfc0820604 O
) O
, O
the O
national O
natural O
science O
foundation O
of O
china O
( O
u1703261 O
) O
, O
and O
the O
fundamental O
research O
funds O
for O
the O
central O
universities O
and O
the O
research O
funds O
of O
renmin O
university O
of O
china O
( O
no O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
18xnlg19 O
) O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
the O
corresponding O
authors O
are O
juan O
cao O
and O
xirong O
li O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
broader O
impact O
statement O
our O
work O
involves O
two O
scenarios O
that O
need O
the O
ability O
to O
detect O
previously O
fact-checked O
claims O
: O
( O
1 O
) O
for O
social O
media O
platforms O
, O
our O
method O
can O
check O
whether O
a O
newly O
published O
post O
contains O
false O
claims O
that O
have O
been O
debunked O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
the O
platform O
may O
help O
the O
users O
to O
be O
aware O
of O
the O
text O
’ O
s O
veracity O
by O
providing O
the O
key O
sentences O
selected O
from O
fact-checking O
articles O
and O
their O
links O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
( O
2 O
) O
for O
manual O
or O
automatic O
fact-checking O
systems O
, O
it O
can O
be O
a O
filter O
to O
avoid O
redundant O
fact-checking O
work O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
when O
functioning O
well O
, O
it O
can O
assist O
platforms O
, O
users O
, O
and O
fact-checkers O
to O
maintain O
more O
credible O
cyberspace O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
but O
in O
the O
failure O
cases O
, O
some O
well-disguised O
claims O
may O
escape O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
this O
method O
functions O
with O
reliance O
on O
the O
used O
fact-checking O
article O
databases O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
thus O
, O
authority O
and O
credibility O
need O
to O
be O
carefully O
considered O
in O
practice O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
we O
did O
our O
best O
to O
make O
the O
new O
weibo O
dataset O
for O
academic O
purpose O
reliable O
. O

section 17
id pdf2json/2021.acl-long.425.pdf.json
appendix O
a O
introduces O
more O
details O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
to O
construct O
datasets O
for O
fact-checked O
claim O
detection O
on O
social O
media O
, O
we O
need O
to O
( O
1 O
) O
collect O
the O
fact-checked O
claims O
( O
social O
media O
posts O
) O
; O
( O
2 O
) O
collect O
fact-checking O
articles O
( O
fc-articles O
) O
; O
and O
( O
3 O
) O
generate O
claim-article O
pairs O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
collection O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
in O
step O
( O
1 O
) O
, O
we O
used O
posts O
whose O
labels O
are O
fake O
from O
the O
datasets O
for O
fake O
news O
detection O
( O
zhang O
et O
al. O
, O
2021 O
; O
zhou O
et O
al. O
, O
2015 O
) O
, O
because O
their O
labels O
were O
determined O
by O
fact-checking O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
in O
step O
( O
2 O
) O
, O
we O
crawled O
fact-checking O
articles O
from O
multiple O
sources O
to O
enrich O
the O
article O
base O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
the O
sources O
are O
partially O
listed O
in O
table O
4 O
due O
to O
the O
space O
limit O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
for O
the O
claims O
and O
articles O
which O
contained O
much O
text O
in O
the O
attached O
images O
, O
we O
recognized O
the O
text O
using O
ocr O
service O
on O
baidu O
ai O
platform8 O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
note O
that O
we O
only O
crawled O
the O
claims O
and O
articles O
that O
were O
publicly O
available O
at O
the O
crawling O
time O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
to O
protect O
privacy O
, O
the O
publishers O
’ O
names O
were O
removed O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
however O
, O
we O
preserved O
names O
and O
offensive O
words O
in O
the O
main O
text O
because O
they O
were O
crucial O
for O
summarizing O
the O
events O
and O
performing O
the O
matching O
process O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
8https O
: O
//ai.baidu.com/tech/ocr O
annotation O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
in O
step O
( O
3 O
) O
, O
we O
performed O
a O
modelassisted O
human O
annotation O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
we O
first O
duplicated O
the O
data O
collected O
in O
step O
( O
1 O
) O
and O
( O
2 O
) O
and O
then O
used O
bm25 O
to O
retrieve O
the O
relevant O
fc-articles O
as O
candidates O
with O
the O
claims O
as O
queries O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
twenty-six O
annotators O
( O
postgraduates O
) O
were O
instructed O
( O
by O
a O
chinese O
guideline O
with O
examples O
written O
by O
the O
first O
author O
) O
to O
check O
whether O
the O
candidates O
did O
fact-check O
the O
given O
claims O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
we O
dropped O
the O
claims O
that O
are O
annotated O
as O
irrelevant O
to O
all O
candidates O
. O

section 18
id pdf2json/2021.acl-long.425.pdf.json
for O
claims O
that O
were O
with O
highly O
overlapping O
candidates O
but O
different O
annotation O
results O
, O
the O
authors O
manually O
checked O
and O
corrected O
the O
wrongly O
annotated O
samples O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
assume O
that O
query O
setq O
has O
|q| O
queries O
and O
the O
ith O
query O
has O
ni O
relevant O
documents O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
we O
calculate O
the O
evaluation O
metrics O
using O
the O
following O
equations O
: O
mrr O
= O
1 O
|q| O
|q|∑ O
i=1 O
1 O
ranki O
( O
16 O
) O
where O
ranki O
refers O
to O
the O
rank O
position O
of O
the O
first O
relevant O
answer O
for O
the O
ith O
query O
in O
the O
corresponding O
retrieving O
result O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
( O
wikipedia O
, O
2021 O
) O
map O
@ O
k O
= O
1 O
|q| O
|q|∑ O
i=1 O
1 O
ni O
ni∑ O
j=1 O
pi O
( O
j O
) O
reli O
( O
j O
) O
( O
17 O
) O
where O
pi O
( O
j O
) O
is O
the O
proportion O
of O
returned O
documents O
in O
the O
top-j O
set O
for O
the O
ith O
query O
that O
are O
relevant O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
reli O
( O
j O
) O
is O
an O
indicator O
function O
equaling O
1 O
if O
the O
document O
at O
rank O
j O
in O
the O
returned O
list O
for O
the O
ith O
query O
is O
relevant O
and O
0 O
otherwise O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
( O
li O
et O
al. O
, O
2016 O
) O
hit O
@ O
k O
= O
1 O
|q| O
|q|∑ O
i=1 O
hasi O
( O
k O
) O
( O
18 O
) O
where O
hasi O
( O
k O
) O
is O
an O
indicator O
function O
equaling O
1 O
if O
ranki O
≤ O
k O
and O
0 O
otherwise O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
( O
yang O
et O
al. O
, O
2012 O
) O
note O
that O
we O
guarantee O
that O
a O
query O
has O
at O
least O
one O
relevant O
document O
in O
its O
candidate O
list O
, O
so O
the O
corner O
case O
of O
empty O
ground O
truth O
set O
is O
ignored O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
c O
implementation O
of O
bm25 O
and O
baselines O
bm25 O
: O
the O
articles O
were O
indexed O
with O
gensim O
( O
řehůřek O
and O
sojka O
, O
2010 O
) O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
bert O
: O
we O
finetuned O
the O
last O
transformer O
layer O
of O
bert-base-chinese O
for O
chinese O
and O
bert-base-uncased O
for O
english O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
following O
the O
commonly O
used O
strategy O
( O
e.g. O
, O
xie O
et O
al. O
, O
2020 O
) O
, O
we O
truncated O
the O
sequences O
to O
the O
maximum O
length O
of O
512 O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
the O
maximum O
length O
of O
claims O
is O
the O
same O
as O
mtm O
and O
the O
rest O
tokens O
are O
from O
articles O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
duobert O
: O
we O
used O
top O
20 O
articles O
from O
the O
results O
of O
bert O
as O
candidates O
to O
construct O
article O
pairs O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
for O
each O
article O
, O
the O
score O
is O
obtained O
by O
summing O
its O
pairwise O
scores O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
the O
used O
pretrained O
models O
are O
the O
same O
as O
bert O
( O
mentioned O
above O
) O
and O
we O
finetuned O
the O
layers O
except O
the O
embedding O
layer O
and O
the O
first O
transformer O
layer O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
bert O
( O
transfer O
) O
: O
for O
the O
twitter O
data O
, O
we O
used O
the O
models O
provided O
in O
birch O
( O
akkalyoncu O
yilmaz O
et O
al. O
, O
2019 O
) O
that O
was O
finetuned O
on O
trec O
microblog O
track O
data O
( O
lin O
et O
al. O
, O
2014 O
) O
; O
for O
the O
weibo O
data O
, O
we O
used O
lcqmc O
dataset O
( O
liu O
et O
al. O
, O
2018 O
) O
containing O
260,068 O
text O
pairs O
to O
finetune O
bert-based-chinese O
for O
20 O
epochs O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
considering O
the O
value O
difference O
between O
bm25 O
and O
bert O
scores O
, O
the O
weight O
of O
bm25 O
score O
was O
learned O
by O
grid O
search O
in O
[ O
0 O
, O
1 O
] O
but O
the O
weights O
of O
others O
were O
in O
[ O
0 O
, O
5 O
] O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
the O
step O
size O
was O
0.1 O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
we O
got O
the O
best O
results O
with O
bm25 O
weight O
= O
0.2 O
( O
weibo O
) O
/ O
0.1 O
( O
twitter O
) O
and O
the O
weights O
of O
top-3 O
sentences O
= O
1.2 O
, O
0.4 O
, O
0.9 O
( O
weibo O
) O
/ O
4.8 O
, O
4 O
, O
2.5 O
( O
twitter O
) O
, O
respectively O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
sentence-bert O
: O
we O
used O
the O
base O
versions O
in O
sentence-transformers O
( O
reimers O
and O
gurevych O
, O
2019 O
) O
to O
obtain O
the O
embeddings O
against O
the O
claims O
and O
sentences O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
specifically O
, O
we O
used O
stsb-xlm-r-multilingual O
( O
reimers O
and O
gurevych O
, O
2020 O
) O
for O
the O
weibo O
data O
and O
stsb-bert-base O
for O
twitter9 O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
according O
to O
shaar O
et O
al O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
( O
2020 O
) O
, O
we O
calculated O
the O
cosine O
similarity O
of O
each O
claim-sentence O
pair O
and O
fed O
the O
top-5 O
scores O
into O
a O
simple O
neural O
network O
( O
20-relu-10relu O
) O
for O
classification O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
we O
trained O
the O
model O
for O
20 O
epochs O
with O
class O
weighted O
cross O
entropy O
as O
the O
loss O
function O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
the O
class O
weights O
were O
calculated O
across O
the O
dataset O
( O
tensorflow O
, O
2021 O
) O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
ranksvm O
: O
we O
combined O
the O
scores O
and O
their O
reciprocal O
ranks O
obtained O
from O
sentence-bert O
models O
and O
bm25 O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
then O
we O
fed O
them O
into O
a O
ranksvm10 O
( O
joachims O
, O
2006 O
) O
for O
classification O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
we O
used O
sentence-bert O
models O
trained O
with O
{ O
3 O
, O
4 O
, O
5 O
, O
6 O
} O
sentences O
for O
twitter O
and O
those O
trained O
with O
{ O
6 O
, O
7 O
, O
8 O
, O
9 O
} O
sentences O
for O
weibo O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
we O
kept O
the O
default O
settings O
in O
the O
package O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
ctm O
: O
for O
the O
twitter O
dataset O
, O
we O
followed O
( O
vo O
and O
lee O
, O
2020 O
) O
to O
use O
glove.6b11 O
( O
pennington O
et O
al. O
, O
2014 O
) O
and O
the O
elmo O
original O
( O
5.5b O
) O
12 O
( O
peters O
et O
al. O
, O
2018 O
) O
; O
for O
the O
weibo O
data O
, O
we O
used O
sgns.weibo.bigram-char13 O
( O
li O
et O
al. O
, O
2018 O
) O
and O
simplified-chinese O
9https O
: O
//www.sbert.net/docs/ O
pretrained_models.html O
10http O
: O
//www.cs.cornell.edu/people/tj/ O
svm_light/svm_rank.html O
11https O
: O
//nlp.stanford.edu/projects/ O
glove/ O
12https O
: O
//allennlp.org/elmo O
13https O
: O
//github.com/embedding/ O
chinese-word-vectors O
elmo14 O
( O
che O
et O
al. O
, O
2018 O
; O
fares O
et O
al. O
, O
2017 O
) O
. O

section 19
id pdf2json/2021.acl-long.425.pdf.json
we O
kept O
the O
default O
settings O
provided O
by O
the O
authors15 O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
we O
reviewed O
the O
fact-checking O
articles O
in O
the O
set O
for O
human O
evaluation O
wherein O
mtm O
hit O
less O
than O
two O
key O
sentences O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
we O
here O
exhibit O
two O
situations O
that O
make O
mtm O
did O
not O
perform O
well O
: O
( O
1 O
) O
in O
figure O
7 O
, O
the O
claim O
is O
about O
where O
cao O
cao O
was O
born O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
mtm O
found O
three O
sentences O
with O
significant O
patterns O
( O
shown O
in O
boldface O
) O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
however O
, O
only O
14https O
: O
//github.com/hit-scir/ O
elmoformanylangs O
15https O
: O
//github.com/nguyenvo09/ O
emnlp2020 O
s1 O
is O
related O
to O
the O
claim O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
s2 O
and O
s3 O
introduce O
similar O
but O
irrelevant O
claims O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
this O
is O
because O
that O
the O
fact-checking O
article O
is O
actually O
a O
collection O
of O
rumors O
about O
south O
korea O
on O
the O
chinese O
social O
media O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
the O
claims O
in O
this O
article O
are O
all O
similar O
to O
each O
other O
, O
and O
thus O
, O
to O
differentiate O
them O
needs O
more O
delicate O
semantic O
understanding O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
( O
2 O
) O
figure O
8 O
shows O
a O
case O
where O
mtm O
found O
no O
key O
sentence O
from O
the O
article O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
we O
append O
the O
key O
sentences O
selected O
manually O
below O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
we O
speculate O
that O
the O
failure O
is O
due O
to O
the O
length O
of O
the O
given O
claim O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
the O
claim O
is O
longer O
than O
general O
posts O
on O
weibo O
and O
contains O
many O
details O
, O
making O
the O
model O
lose O
focus O
on O
the O
key O
elements O
of O
the O
event O
description O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
thus O
, O
s1 O
describing O
another O
news O
about O
mh370 O
’ O
s O
activity O
in O
vietnam O
was O
selected O
, O
instead O
of O
the O
ground O
truth O
sentences O
. O

section 20
id pdf2json/2021.acl-long.425.pdf.json
to O
achieve O
better O
performance O
, O
future O
work O
may O
consider O
improving O
the O
semantic O
modeling O
and O
summarizing O
key O
information O
from O
both O
fact-checking O
articles O
and O
claims O
. O

section TITLE
id pdf2json/2021.acl-long.188.pdf.json
a O
unified O
generative O
framework O
for O
aspect-based O
sentiment O
analysis O

section ABSTRACT
id pdf2json/2021.acl-long.188.pdf.json
aspect-based O
sentiment O
analysis O
( O
absa O
) O
aims O
to O
identify O
the O
aspect O
terms O
, O
their O
corresponding O
sentiment O
polarities O
, O
and O
the O
opinion O
terms O
. O

section ABSTRACT
id pdf2json/2021.acl-long.188.pdf.json
there O
exist O
seven O
subtasks O
in O
absa O
. O

section ABSTRACT
id pdf2json/2021.acl-long.188.pdf.json
most O
studies O
only O
focus O
on O
the O
subsets O
of O
these O
subtasks O
, O
which O
leads O
to O
various O
complicated O
absa O
models O
while O
hard O
to O
solve O
these O
subtasks O
in O
a O
unified O
framework O
. O

section ABSTRACT
id pdf2json/2021.acl-long.188.pdf.json
in O
this O
paper O
, O
we O
redefine O
every O
subtask O
target O
as O
a O
sequence O
mixed O
by O
pointer O
indexes O
and O
sentiment O
class O
indexes O
, O
which O
converts O
all O
absa O
subtasks O
into O
a O
unified O
generative O
formulation O
. O

section ABSTRACT
id pdf2json/2021.acl-long.188.pdf.json
based O
on O
the O
unified O
formulation O
, O
we O
exploit O
the O
pre-training O
sequence-to-sequence O
model O
bart O
to O
solve O
all O
absa O
subtasks O
in O
an O
endto-end O
framework O
. O

section ABSTRACT
id pdf2json/2021.acl-long.188.pdf.json
extensive O
experiments O
on O
four O
absa O
datasets O
for O
seven O
subtasks O
demonstrate O
that O
our O
framework O
achieves O
substantial O
performance O
gain O
and O
provides O
a O
real O
unified O
end-to-end O
solution O
for O
the O
whole O
absa O
subtasks O
, O
which O
could O
benefit O
multiple O
tasks1 O
. O

section 0
id pdf2json/2021.acl-long.188.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
2416–2429 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.188.pdf.json
©2021 O
association O
for O
computational O
linguistics O
2416 O

section 1
id pdf2json/2021.acl-long.188.pdf.json
aspect-based O
sentiment O
analysis O
( O
absa O
) O
is O
the O
fine-grained O
sentiment O
analysis O
( O
sa O
) O
task O
, O
which O
aims O
to O
identify O
the O
aspect O
term O
( O
a O
) O
, O
its O
corresponding O
sentiment O
polarity O
( O
s O
) O
, O
and O
the O
opinion O
term O
( O
o O
) O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
for O
example O
, O
in O
the O
sentence O
“ O
the O
drinks O
are O
always O
well O
made O
and O
wine O
selection O
is O
fairly O
priced O
” O
, O
the O
aspect O
terms O
are O
“ O
drinks O
” O
and O
“ O
wine O
selection O
” O
, O
and O
their O
sentiment O
polarities O
are O
both O
“ O
positive O
” O
, O
and O
the O
opinion O
terms O
are O
“ O
well O
made O
” O
and O
“ O
fairly O
priced O
” O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
based O
on O
the O
combination O
of O
the O
a O
, O
s O
, O
o O
, O
there O
exist O
seven O
subtasks O
in O
absa O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
we O
summarize O
these O
subtasks O
in O
figure O
1 O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
specifically O
, O
their O
definitions O
are O
as O
follows O
: O
∗equal O
contribution O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
†corresponding O
author O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
1code O
is O
available O
at O
https O
: O
//github.com/yhcc/ O
bartabsa O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
•aspect O
term O
extraction O
( O
ae O
) O
: O
extracting O
all O
the O
aspect O
terms O
from O
a O
sentence O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
• O
opinion O
term O
extraction O
( O
oe O
) O
: O
extracting O
all O
the O
opinion O
terms O
from O
a O
sentence O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
• O
aspect-level O
sentiment O
classification O
( O
alsc O
) O
: O
predicting O
the O
sentiment O
polarities O
for O
every O
given O
aspect O
terms O
in O
a O
sentence O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
• O
aspect-oriented O
opinion O
extraction O
( O
aoe O
) O
: O
extracting O
the O
paired O
opinion O
terms O
for O
every O
given O
aspect O
terms O
in O
a O
sentence O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
• O
aspect O
term O
extraction O
and O
sentiment O
classification O
( O
aesc O
) O
: O
extracting O
the O
aspect O
terms O
as O
well O
as O
the O
corresponding O
sentiment O
polarities O
simultaneously O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
• O
pair O
extraction O
( O
pair O
) O
: O
extracting O
the O
aspect O
terms O
as O
well O
as O
the O
corresponding O
opinion O
terms O
simultaneously O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
• O
triplet O
extraction O
( O
triplet O
) O
: O
extracting O
all O
aspects O
terms O
with O
their O
corresponding O
opinion O
terms O
and O
sentiment O
polarity O
simultaneously O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
although O
these O
absa O
subtasks O
are O
strongly O
related O
, O
most O
of O
the O
existing O
work O
only O
focus O
1∼3 O
subtasks O
individually O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
the O
following O
divergences O
make O
it O
difficult O
to O
solve O
all O
subtasks O
in O
a O
unified O
framework O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
1 O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
input O
: O
some O
subtasks O
( O
ae O
, O
oe O
, O
aesc O
, O
pair O
and O
triplet O
) O
only O
take O
the O
text O
sentence O
as O
input O
, O
while O
the O
remained O
subtasks O
( O
alsc O
and O
aoe O
) O
take O
the O
text O
and O
a O
given O
aspect O
term O
as O
input O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
2 O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
output O
: O
some O
tasks O
( O
ae O
, O
oe O
, O
alsc O
, O
aoe O
) O
only O
output O
a O
certain O
type O
from O
a O
, O
s O
or O
o O
, O
while O
the O
remained O
tasks O
( O
aesc O
, O
pair O
and O
triplet O
) O
return O
compound O
output O
as O
the O
combination O
of O
a O
, O
s O
and O
o O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
3 O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
task O
type O
: O
there O
are O
two O
kinds O
of O
tasks O
: O
extraction O
task O
( O
extracting O
aspect O
and O
opinion O
) O
and O
classification O
task O
( O
predicting O
sentiment O
) O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
because O
of O
the O
above O
divergences O
, O
a O
myriad O
of O
previous O
works O
only O
focus O
on O
the O
subset O
of O
these O
subtasks O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
however O
, O
the O
importance O
of O
solving O
the O
whole O
absa O
subtasks O
in O
a O
unified O
framework O
remains O
significant O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
recently O
, O
several O
works O
make O
attempts O
on O
this O
track O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
some O
methods O
( O
peng O
et O
al. O
, O
2020 O
; O
mao O
et O
al. O
, O
2021 O
) O
apply O
the O
pipeline O
model O
to O
output O
the O
a O
, O
s O
, O
o O
from O
the O
inside O
sub-models O
separately O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
however O
, O
the O
pipeline O
process O
is O
not O
end-to-end O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
another O
line O
follows O
the O
sequence O
tagging O
method O
by O
extending O
the O
tagging O
schema O
( O
xu O
et O
al. O
, O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
however O
, O
the O
compositionality O
of O
candidate O
labels O
hinders O
the O
performance O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
in O
conclusion O
, O
the O
existing O
methods O
can O
hardly O
solve O
all O
the O
subtasks O
by O
a O
unified O
framework O
without O
relying O
on O
the O
sub-models O
or O
changing O
the O
model O
structure O
to O
adapt O
to O
all O
absa O
subtasks O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
motivated O
by O
the O
above O
observations O
, O
we O
propose O
a O
unified O
generative O
framework O
to O
address O
all O
the O
absa O
subtasks O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
we O
first O
formulate O
all O
these O
subtasks O
as O
a O
generative O
task O
, O
which O
could O
handle O
the O
obstacles O
on O
the O
input O
, O
output O
, O
and O
task O
type O
sides O
and O
adapt O
to O
all O
the O
subtasks O
without O
any O
model O
structure O
changes O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
specifically O
, O
we O
model O
the O
extraction O
and O
classification O
tasks O
as O
the O
pointer O
indexes O
and O
class O
indexes O
generation O
, O
respectively O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
based O
on O
the O
unified O
task O
formulation O
, O
we O
use O
the O
sequence-to-sequence O
pre-trained O
model O
bart O
( O
lewis O
et O
al. O
, O
2020 O
) O
as O
our O
backbone O
to O
generate O
the O
target O
sequence O
in O
an O
end-to-end O
process O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
to O
validate O
the O
effectiveness O
of O
our O
method O
, O
we O
conduct O
extensive O
experiments O
on O
public O
datasets O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
the O
comparison O
results O
demonstrate O
that O
our O
proposed O
framework O
outperforms O
most O
state-of-the-art O
( O
sota O
) O
models O
in O
every O
subtask O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
in O
summary O
, O
our O
main O
contributions O
are O
as O
follows O
: O
•we O
formulate O
both O
the O
extraction O
task O
and O
classification O
task O
of O
absa O
into O
a O
unified O
index O
gen- O
eration O
problem O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
unlike O
previous O
unified O
models O
, O
our O
method O
needs O
not O
to O
design O
specific O
decoders O
for O
different O
output O
types O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
• O
with O
our O
re-formulation O
, O
all O
absa O
subtasks O
can O
be O
solved O
in O
sequence-to-sequence O
framework O
, O
which O
is O
easy-to-implement O
and O
can O
be O
built O
on O
the O
pre-trained O
models O
, O
such O
as O
bart O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
•we O
conduct O
extensive O
experiments O
on O
four O
public O
datasets O
, O
and O
each O
dataset O
contains O
a O
subset O
of O
all O
absa O
subtasks O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
to O
the O
best O
of O
our O
knowledge O
, O
it O
is O
the O
first O
work O
to O
evaluate O
a O
model O
on O
all O
absa O
tasks O
. O

section 1
id pdf2json/2021.acl-long.188.pdf.json
• O
the O
experimental O
results O
show O
that O
our O
proposed O
framework O
significantly O
outperforms O
recent O
sota O
methods O
. O

section 3
id pdf2json/2021.acl-long.188.pdf.json
in O
this O
section O
, O
we O
first O
review O
the O
existing O
studies O
on O
single O
output O
subtasks O
, O
and O
then O
turn O
to O
studies O
focusing O
on O
the O
compound O
output O
subtasks O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
some O
researches O
mainly O
focus O
on O
the O
single O
output O
subtasks O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
the O
ae O
, O
oe O
, O
alsc O
and O
aoe O
subtasks O
only O
output O
one O
certain O
type O
from O
a O
, O
s O
or O
o. O
ae O
most O
studies O
treat O
ae O
subtask O
as O
a O
sequence O
tagging O
problem O
( O
li O
and O
lam O
, O
2017 O
; O
xu O
et O
al. O
, O
2018 O
; O
li O
et O
al. O
, O
2018b O
) O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
recent O
works O
explore O
sequence-to-sequence O
learning O
on O
ae O
subtask O
, O
which O
obtain O
promissing O
results O
especially O
with O
the O
pre-training O
language O
models O
( O
ma O
et O
al. O
, O
2019 O
; O
li O
et O
al. O
, O
2020 O
) O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
oe O
most O
studies O
treat O
oe O
subtask O
as O
an O
auxiliary O
task O
( O
wang O
et O
al. O
, O
2016a O
, O
2017 O
; O
wang O
and O
pan O
, O
2018 O
; O
chen O
and O
qian O
, O
2020 O
; O
he O
et O
al. O
, O
2019 O
) O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
most O
works O
can O
only O
extract O
the O
unpaired O
aspect O
and O
opinion O
terms2 O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
in O
this O
case O
, O
opinion O
terms O
are O
independent O
of O
aspect O
terms O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
alsc O
tang O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
( O
2016a O
) O
use O
the O
long O
short O
term O
memory O
( O
lstm O
) O
network O
to O
enhance O
the O
interactions O
between O
aspects O
and O
context O
words O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
wang O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
( O
2016b O
) O
; O
liu O
and O
zhang O
( O
2017 O
) O
; O
ma O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
( O
2017 O
) O
; O
tay O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
( O
2018 O
) O
incorporate O
the O
attention O
mechanism O
into O
the O
lstm-based O
neural O
network O
models O
to O
model O
relations O
of O
aspects O
and O
their O
contextual O
words O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
other O
model O
structures O
such O
as O
convolutional O
neural O
network O
( O
cnn O
) O
( O
li O
et O
al. O
, O
2018a O
; O
xue O
and O
li O
, O
2018 O
) O
, O
gated O
neural O
network O
( O
zhang O
et O
al. O
, O
2016 O
; O
xue O
and O
li O
, O
2018 O
) O
, O
memory O
neural O
2it O
is O
also O
referred O
to O
as O
the O
ae-oe O
co-extraction O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
network O
( O
tang O
et O
al. O
, O
2016b O
; O
chen O
et O
al. O
, O
2017 O
) O
have O
also O
been O
applied O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
aoe O
this O
subtask O
is O
first O
introduced O
by O
fan O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
( O
2019 O
) O
and O
they O
propose O
the O
datasets O
for O
this O
subtask O
. O

section 4
id pdf2json/2021.acl-long.188.pdf.json
most O
studies O
apply O
sequence O
tagging O
method O
for O
this O
subtask O
( O
wu O
et O
al. O
, O
2020 O
; O
pouran O
ben O
veyseh O
et O
al. O
, O
2020 O
) O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
some O
researchers O
pay O
more O
attention O
and O
efforts O
to O
the O
subtasks O
with O
compound O
output O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
we O
review O
them O
as O
follows O
: O
aesc O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
one O
line O
follows O
pipeline O
method O
to O
solve O
this O
problem O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
other O
works O
utilize O
unified O
tagging O
schema O
( O
mitchell O
et O
al. O
, O
2013 O
; O
zhang O
et O
al. O
, O
2015 O
; O
li O
et O
al. O
, O
2019 O
) O
or O
multi-task O
learning O
( O
he O
et O
al. O
, O
2019 O
; O
chen O
and O
qian O
, O
2020 O
) O
to O
avoid O
the O
error-propagation O
problem O
( O
ma O
et O
al. O
, O
2018 O
) O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
spanbased O
aesc O
works O
are O
also O
proposed O
recently O
( O
hu O
et O
al. O
, O
2019 O
) O
, O
which O
can O
tackle O
the O
sentiment O
inconsistency O
problem O
in O
the O
unified O
tagging O
schema O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
pairs O
zhao O
et O
al O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
propose O
to O
extract O
all O
( O
a O
, O
o O
) O
pair-wise O
relations O
from O
scratch O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
they O
propose O
a O
multi-task O
learning O
framework O
based O
on O
the O
spanbased O
extraction O
method O
to O
handle O
this O
subtask O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
triplet O
this O
subtask O
is O
proposed O
by O
peng O
et O
al O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
and O
gains O
increasing O
interests O
recently O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
xu O
et O
al O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
design O
the O
position-aware O
tagging O
schema O
and O
apply O
model O
based O
on O
crf O
( O
lafferty O
et O
al. O
, O
2001 O
) O
and O
semi-markov O
crf O
( O
sarawagi O
and O
cohen O
, O
2004 O
) O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
however O
, O
the O
time O
complexity O
limits O
the O
model O
to O
detect O
the O
aspect O
term O
with O
longdistance O
opinion O
terms O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
mao O
et O
al O
. O

section 5
id pdf2json/2021.acl-long.188.pdf.json
( O
2021 O
) O
formulate O
triplet O
as O
a O
two-step O
mrc O
problem O
, O
which O
applies O
the O
pipeline O
method O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
the O
sequence-to-sequence O
framework O
has O
been O
long O
studied O
in O
the O
nlp O
field O
to O
tackle O
various O
tasks O
( O
sutskever O
et O
al. O
, O
2014 O
; O
cho O
et O
al. O
, O
2014 O
; O
vinyals O
et O
al. O
, O
2015 O
; O
luong O
et O
al. O
, O
2015 O
) O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
inspired O
by O
the O
success O
of O
ptms O
( O
pre-trained O
models O
) O
( O
qiu O
et O
al. O
, O
2020 O
; O
peters O
et O
al. O
, O
2018 O
; O
devlin O
et O
al. O
, O
2019 O
; O
brown O
et O
al. O
, O
2020 O
) O
, O
song O
et O
al O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
( O
2019 O
) O
; O
raffel O
et O
al O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
; O
lewis O
et O
al O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
try O
to O
pre-train O
sequence-tosequence O
models O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
among O
them O
, O
we O
use O
the O
bart O
( O
lewis O
et O
al. O
, O
2020 O
) O
as O
our O
backbone O
, O
while O
the O
other O
sequence-to-sequence O
pre-training O
models O
can O
also O
be O
applied O
in O
our O
architecture O
to O
use O
the O
pointer O
mechanism O
( O
vinyals O
et O
al. O
, O
2015 O
) O
, O
such O
as O
mass O
( O
song O
et O
al. O
, O
2019 O
) O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
bart O
is O
a O
strong O
sequence-to-sequence O
pretrained O
model O
for O
natural O
language O
generation O
( O
nlg O
) O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
bart O
is O
a O
denoising O
autoencoder O
composed O
of O
several O
transformer O
( O
vaswani O
et O
al. O
, O
2017 O
) O
encoder O
and O
decoder O
layers O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
it O
is O
worth O
noting O
that O
the O
bart-base O
model O
contains O
a O
6-layer O
encoder O
and O
6-layer O
decoder O
, O
which O
makes O
it O
similar O
number O
of O
parameters3 O
with O
the O
bert-base O
model O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
bart O
is O
pretrained O
on O
denoising O
tasks O
where O
the O
input O
sentence O
is O
noised O
by O
some O
methods O
, O
such O
as O
masking O
and O
permutation O
. O

section 6
id pdf2json/2021.acl-long.188.pdf.json
the O
encoder O
takes O
the O
noised O
sentence O
as O
input O
, O
and O
the O
decoder O
will O
restore O
the O
original O
sentence O
in O
an O
autoregressive O
manner O
. O

section 7
id pdf2json/2021.acl-long.188.pdf.json
although O
there O
are O
two O
types O
of O
tasks O
among O
the O
seven O
absa O
subtasks O
, O
they O
can O
be O
formulated O
under O
a O
generative O
framework O
. O

section 7
id pdf2json/2021.acl-long.188.pdf.json
in O
this O
part O
, O
we O
first O
introduce O
our O
sequential O
representation O
for O
each O
absa O
subtask O
. O

section 7
id pdf2json/2021.acl-long.188.pdf.json
then O
we O
detail O
our O
method O
, O
which O
utilizes O
bart O
to O
generate O
these O
sequential O
representations O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
as O
depicted O
in O
figure O
1 O
, O
there O
are O
two O
types O
of O
tasks O
, O
namely O
the O
extraction O
and O
classification O
, O
whose O
target O
can O
be O
represented O
as O
a O
sequence O
of O
pointer O
indexes O
and O
class O
indexes O
, O
respectively O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
therefore O
, O
we O
can O
formulate O
these O
two O
types O
of O
tasks O
in O
a O
unified O
generative O
framework O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
we O
use O
a O
, O
s O
, O
o O
, O
to O
represent O
the O
aspect O
term O
, O
sentiment O
polarity O
, O
and O
opinion O
term O
, O
respectively O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
moreover O
, O
we O
use O
the O
superscript O
s O
and O
e O
to O
denote O
the O
start O
index O
and O
end O
index O
of O
a O
term O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
for O
example O
, O
os O
, O
ae O
represent O
the O
start O
index O
of O
an O
opinion O
term O
o O
and O
the O
end O
index O
of O
an O
aspect O
term O
a O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
we O
use O
the O
sp O
to O
denote O
the O
index O
of O
sentiment O
polarity O
class O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
the O
target O
sequence O
for O
each O
subtask O
is O
as O
follows O
: O
• O
ae O
: O
y O
= O
[ O
as1 O
, O
ae1 O
, O
... O
, O
asi O
, O
aei O
, O
... O
] O
, O
• O
oe O
: O
y O
= O
[ O
os1 O
, O
oe1 O
, O
... O
, O
osi O
, O
oei O
, O
... O
] O
, O
• O
aesc O
: O
y O
= O
[ O
as1 O
, O
ae1 O
, O
s O
p O
1 O
, O
... O
, O
a O
s O
i O
, O
a O
e O
i O
, O
s O
p O
i O
, O
... O
] O
, O
• O
pair O
: O
y O
= O
[ O
as1 O
, O
ae1 O
, O
os1 O
, O
oe1 O
, O
... O
, O
asi O
, O
aei O
, O
osi O
, O
oei O
, O
... O
] O
, O
• O
triplet O
: O
y O
= O
[ O
as1 O
, O
ae1 O
, O
os1 O
, O
oe1 O
, O
s O
p O
1 O
, O
... O
, O
a O
s O
i O
, O
a O
e O
i O
, O
o O
s O
i O
, O
oei O
, O
s O
p O
i O
, O
... O
] O
, O
the O
above O
subtasks O
only O
rely O
on O
the O
input O
sentence O
, O
while O
for O
the O
alsc O
and O
aoe O
subtasks O
, O
they O
also O
depend O
on O
a O
specific O
aspect O
term O
a O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
instead O
of O
putting O
the O
aspect O
term O
on O
the O
input O
side O
, O
we O
put O
3because O
of O
the O
cross-attention O
between O
encoder O
and O
decoder O
, O
the O
number O
of O
parameters O
of O
bart O
is O
about O
10 O
% O
larger O
than O
its O
counterpart O
of O
bert O
( O
lewis O
et O
al. O
, O
2020 O
) O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
and O
the O
class O
index O
will O
be O
converted O
to O
corresponding O
class O
tokens O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
embedding O
vectors O
in O
ll O
boxes O
are O
retrieved O
from O
same O
embedding O
matrix O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
we O
use O
different O
position O
embeddings O
in O
the O
source O
and O
target O
for O
better O
generation O
performance O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
them O
on O
the O
target O
side O
so O
that O
the O
target O
sequences O
are O
as O
follows O
: O
• O
alsc O
: O
y O
= O
[ O
as O
, O
ae O
, O
sp O
] O
, O
• O
aoe O
: O
y O
= O
[ O
as O
, O
ae O
, O
os1 O
, O
oe1 O
, O
... O
, O
osi O
, O
oei O
, O
... O
] O
, O
where O
the O
underlined O
tokens O
are O
given O
during O
inference O
. O

section 8
id pdf2json/2021.acl-long.188.pdf.json
detailed O
target O
sequence O
examples O
for O
each O
subtask O
are O
presented O
in O
figure O
3 O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
as O
our O
discussion O
in O
the O
last O
section O
, O
all O
subtasks O
can O
be O
formulated O
as O
taking O
the O
x O
= O
[ O
x1 O
, O
... O
, O
xn O
] O
as O
input O
and O
outputting O
a O
target O
sequence O
y O
= O
[ O
y1 O
, O
... O
, O
ym O
] O
, O
where O
y0 O
is O
the O
start-of-the-sentence O
token O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
therefore O
, O
different O
absa O
subtasks O
can O
be O
formulated O
as O
: O
p O
( O
y O
|x O
) O
= O
m∏ O
t=1 O
p O
( O
yt|x O
, O
y O
< O
t O
) O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
( O
1 O
) O
to O
get O
the O
index O
probability O
distribution O
pt O
= O
p O
( O
yt|x O
, O
y O
< O
t O
) O
for O
each O
step O
, O
we O
use O
a O
model O
composed O
of O
two O
components O
: O
( O
1 O
) O
encoder O
; O
( O
2 O
) O
decoder O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
encoder O
the O
encoder O
part O
is O
to O
encode O
x O
into O
vectors O
he O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
we O
use O
the O
bart O
model O
, O
therefore O
, O
the O
start O
of O
sentence O
( O
< O
s O
> O
) O
and O
the O
end O
of O
sentence O
( O
< O
/s O
> O
) O
tokens O
will O
be O
added O
to O
the O
start O
and O
end O
of O
x O
, O
respectively O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
we O
ignore O
the O
< O
s O
> O
token O
in O
our O
equations O
for O
simplicity O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
the O
encoder O
part O
is O
as O
follows O
: O
he O
= O
bartencoder O
( O
[ O
x1 O
, O
... O
, O
xn O
] O
) O
, O
( O
2 O
) O
where O
he O
∈ O
rn×d O
, O
and O
d O
is O
the O
hidden O
dimension O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
decoder O
the O
decoder O
part O
takes O
the O
encoder O
outputs O
he O
and O
previous O
decoder O
outputs O
y O
< O
t O
as O
inputs O
to O
get O
pt O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
however O
, O
the O
y O
< O
t O
is O
an O
index O
sequence O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
therefore O
, O
for O
each O
yt O
in O
y O
< O
t O
, O
we O
first O
need O
to O
use O
the O
following O
index2token O
module O
to O
conduct O
a O
conversion O
ŷt O
= O
{ O
xyt O
, O
if O
yt O
is O
a O
pointer O
index O
, O
cyt−n O
, O
if O
yt O
is O
a O
class O
index O
, O
( O
3 O
) O
where O
c O
= O
[ O
c1 O
, O
... O
, O
cl O
] O
is O
the O
class O
token O
list4 O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
after O
that O
, O
we O
use O
the O
bart O
decoder O
to O
get O
the O
last O
hidden O
state O
hdt O
= O
bartdecoder O
( O
h O
e O
; O
ŷ O
< O
t O
) O
, O
( O
4 O
) O
where O
hdt O
∈ O
rd O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
with O
hdt O
, O
we O
predict O
the O
token O
probability O
distribution O
pt O
as O
follows O
: O
ee O
= O
barttokenembed O
( O
x O
) O
, O
( O
5 O
) O
ĥe O
= O
mlp O
( O
he O
) O
, O
( O
6 O
) O
h̄e O
= O
αĥe O
+ O
( O
1− O
α O
) O
ee O
, O
( O
7 O
) O
cd O
= O
barttokenembed O
( O
c O
) O
, O
( O
8 O
) O
pt O
= O
softmax O
( O
[ O
h̄ O
e O
; O
cd O
] O
hdt O
) O
, O
( O
9 O
) O
where O
ee O
, O
he O
, O
ĥe O
, O
h̄e O
∈ O
rn×d O
; O
cd O
∈ O
rl×d O
; O
and O
pt O
∈ O
r O
( O
n+l O
) O
is O
the O
final O
distribution O
on O
all O
indexes O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
during O
the O
training O
phase O
, O
we O
use O
the O
teacher O
forcing O
to O
train O
our O
model O
and O
the O
negative O
loglikelihood O
to O
optimize O
the O
model O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
moreover O
, O
during O
the O
inference O
, O
we O
use O
the O
beam O
search O
to O
get O
the O
target O
sequence O
y O
in O
an O
autoregressive O
manner O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
after O
that O
, O
we O
need O
to O
use O
the O
decoding O
algorithm O
to O
convert O
this O
sequence O
into O
the O
term O
spans O
and O
sentiment O
polarity O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
we O
use O
the O
triplet O
task O
as O
an O
example O
and O
present O
the O
decoding O
algorithm O
in O
algorithm O
1 O
, O
the O
decoding O
algorithm O
for O
other O
tasks O
are O
much O
depicted O
in O
the O
supplementary O
material O
. O

section 9
id pdf2json/2021.acl-long.188.pdf.json
algorithm O
1 O
decoding O
algorithm O
for O
the O
triplet O
subtask O
input O
: O
number O
of O
tokens O
in O
the O
input O
sentence O
n O
, O
target O
sequence O
y O
= O
[ O
y1 O
, O
... O
, O
ym O
] O
and O
yi O
∈ O
[ O
1 O
, O
n+ O
|c| O
] O
output O
: O
target O
span O
set O
l O
= O
{ O
( O
as1 O
, O
ae1 O
, O
os1 O
, O
oe1 O
, O
s1 O
) O
, O
... O
, O
( O
asi O
, O
aei O
, O
osi O
, O
oei O
, O
si O
) O
, O
... O
} O
1 O
: O
l O
= O
{ O
} O
, O
e O
= O
[ O
] O
, O
i O
= O
1 O
2 O
: O
while O
i O
< O
= O
m O
do O
3 O
: O
yi O
= O
y O
[ O
i O
] O
4 O
: O
if O
yi O
> O
n O
then O
5 O
: O
l.add O
( O
( O
e O
, O
cyi−n O
) O
) O
6 O
: O
e O
= O
[ O
] O
7 O
: O
else O
8 O
: O
e.append O
( O
yi O
) O
9 O
: O
end O
if O
10 O
: O
i+ O
= O
1 O
11 O
: O
end O
while O
12 O
: O
return O
l O

section 11
id pdf2json/2021.acl-long.188.pdf.json
we O
evaluate O
our O
method O
on O
four O
absa O
datasets O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
all O
of O
them O
are O
originated O
from O
the O
semeval O
challenges O
( O
pontiki O
et O
al. O
, O
2014a O
, O
b O
, O
c O
) O
, O
where O
only O
the O
aspect O
terms O
and O
their O
sentiment O
polarities O
are O
labeled O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
the O
first O
dataset O
( O
d175 O
) O
is O
annotated O
by O
wang O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
( O
2017 O
) O
, O
where O
the O
unpaire O
opinion O
terms O
are O
labeled O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
the O
second O
dataset O
( O
d19 O
) O
is O
annotated O
by O
fan O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
( O
2019 O
) O
, O
where O
they O
pair O
opinion O
terms O
with O
4in O
our O
implement O
, O
yt O
∈ O
[ O
1 O
, O
n+ O
l O
] O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
the O
x1 O
has O
the O
pointer O
index O
1 O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
5each O
dataset O
only O
contains O
a O
subset O
of O
all O
absa O
subtasks O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
we O
use O
the O
published O
year O
of O
the O
dataset O
to O
distinguish O
them O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
corresponding O
aspects O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
the O
third O
dataset O
( O
d20a O
) O
is O
from O
peng O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
they O
refine O
the O
data O
in O
< O
a O
, O
o O
, O
s O
> O
triplet O
form O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
the O
fourth O
dataset O
( O
d20b O
) O
from O
xu O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
is O
the O
revised O
variant O
of O
peng O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
, O
where O
the O
missing O
triplets O
with O
overlapping O
opinions O
are O
corrected O
. O

section 11
id pdf2json/2021.acl-long.188.pdf.json
we O
present O
the O
statistics O
for O
these O
four O
datasets O
in O
table O
1 O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
to O
have O
a O
fair O
comparison O
, O
we O
summarize O
topperforming O
baselines O
of O
all O
absa O
subtasks O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
given O
different O
absa O
subtasks O
, O
datasets O
, O
and O
experimental O
setups O
, O
existing O
baselines O
can O
be O
separated O
into O
three O
groups O
roughly O
as O
shown O
in O
table O
2 O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
the O
baselines O
in O
the O
first O
group O
are O
conducted O
on O
d17 O
dataset O
, O
covering O
the O
ae O
, O
oe O
, O
alsc O
, O
and O
aesc O
subtasks O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
span-based O
method O
span-bert O
( O
hu O
et O
al. O
, O
2019 O
) O
and O
sequence O
tagging O
method O
, O
imnbert O
( O
he O
et O
al. O
, O
2019 O
) O
and O
racl-bert O
( O
chen O
and O
qian O
, O
2020 O
) O
, O
are O
selected O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
specifically O
, O
the O
imn-bert O
model O
is O
reproduced O
by O
chen O
and O
qian O
( O
2020 O
) O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
all O
these O
baselines O
are O
implemented O
on O
bert-large O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
the O
baselines O
of O
the O
second O
group O
are O
conducted O
on O
d19 O
dataset O
, O
mainly O
focusing O
on O
aoe O
subtask O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
interestingly O
, O
we O
find O
that O
sequence O
tagging O
method O
is O
the O
main O
solution O
for O
this O
subtask O
( O
fan O
et O
al. O
, O
2019 O
; O
wu O
et O
al. O
, O
2020 O
; O
pouran O
ben O
veyseh O
et O
al. O
, O
2020 O
) O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
the O
baselines O
of O
the O
third O
group O
are O
mainly O
conducted O
on O
d20a O
and O
d20b O
datasets O
, O
which O
could O
cover O
almost O
all O
the O
absa O
subtasks O
except O
for O
one O
certain O
subtask O
depending O
on O
the O
baseline O
structures O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
for O
the O
following O
baselines O
: O
rinante O
( O
dai O
and O
song O
, O
2019 O
) O
, O
cmla O
( O
wang O
et O
al. O
, O
2017 O
) O
, O
liunified O
( O
li O
et O
al. O
, O
2019 O
) O
, O
the O
suffix O
“ O
+ O
” O
in O
table O
2 O
denotes O
the O
corresponding O
model O
variant O
modified O
by O
peng O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.188.pdf.json
( O
2020 O
) O
for O
being O
capable O
of O
aesc O
, O
pair O
and O
triplet O
. O

section 13
id pdf2json/2021.acl-long.188.pdf.json
following O
previous O
studies O
, O
we O
use O
different O
metrics O
according O
to O
different O
subtasks O
and O
datasets O
. O

section 13
id pdf2json/2021.acl-long.188.pdf.json
specifically O
, O
for O
the O
single O
output O
subtasks O
ae O
, O
oe O
, O
and O
aoe O
, O
the O
prediction O
span O
would O
be O
considered O
as O
correct O
only O
if O
it O
exactly O
matches O
the O
start O
and O
the O
end O
boundaries O
. O

section 13
id pdf2json/2021.acl-long.188.pdf.json
for O
the O
alsc O
subtask O
, O
we O
require O
the O
generated O
sentiment O
polarity O
of O
the O
given O
aspect O
should O
be O
the O
same O
as O
the O
ground O
truth O
. O

section 13
id pdf2json/2021.acl-long.188.pdf.json
as O
for O
compound O
output O
subtasks O
, O
aesc O
, O
pair O
and O
triplet O
, O
a O
prediction O
result O
is O
correct O
only O
when O
all O
the O
span O
boundaries O
and O
the O
generated O
sentiment O
polarity O
are O
accurately O
identified O
. O

section 13
id pdf2json/2021.acl-long.188.pdf.json
we O
report O
the O
precision O
( O
p O
) O
, O
recall O
( O
r O
) O
, O
and O
f1 O
scores O
for O
all O
experiments6 O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
on O
d17 O
dataset O
( O
wang O
et O
al. O
, O
2017 O
) O
, O
we O
compare O
our O
method O
for O
ae O
, O
oe O
, O
alsc O
, O
and O
aesc O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
the O
comparison O
results O
are O
shown O
in O
table O
3 O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
most O
of O
our O
results O
achieve O
better O
or O
comparable O
results O
to O
6due O
to O
the O
limited O
space O
, O
we O
would O
present O
detailed O
experiments O
for O
each O
dataset O
in O
the O
supplementary O
material O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
baselines O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
however O
, O
these O
baselines O
yield O
competitive O
results O
based O
on O
the O
bert-large O
pre-trained O
models O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
while O
our O
results O
are O
achieved O
on O
the O
bart-base O
model O
with O
almost O
half O
parameters O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
this O
shows O
that O
our O
framework O
is O
more O
suitable O
for O
these O
absa O
subtasks O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
on O
d19 O
dataset O
( O
fan O
et O
al. O
, O
2019 O
) O
, O
we O
compare O
our O
method O
for O
aoe O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
the O
comparison O
results O
are O
shown O
in O
table O
4 O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
we O
can O
observe O
that O
our O
method O
achieves O
significant O
p/r/f1 O
improvements O
on O
14res O
, O
15res O
, O
and O
16res O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
additionally O
, O
we O
notice O
that O
our O
f1 O
score O
on O
14lap O
is O
close O
to O
the O
previous O
sota O
result O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
this O
is O
probably O
caused O
by O
the O
dataset O
domain O
difference O
as O
the O
14lap O
is O
the O
laptop O
comments O
while O
the O
others O
are O
restaurant O
comments O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
on O
d20a O
dataset O
( O
peng O
et O
al. O
, O
2020 O
) O
, O
we O
compare O
our O
method O
for O
aesc O
, O
pair O
, O
and O
triplet O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
the O
comparison O
results O
are O
shown O
in O
table O
5 O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
we O
can O
observe O
that O
our O
proposed O
method O
is O
able O
to O
outperform O
other O
baselines O
on O
all O
datasets O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
specifically O
, O
we O
achieve O
the O
better O
results O
for O
triplet O
, O
which O
demonstrates O
the O
effectiveness O
of O
our O
method O
on O
capturing O
interactions O
among O
aspect O
terms O
, O
opinion O
terms O
, O
and O
sentiment O
polarities O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
we O
also O
observe O
that O
the O
span-based O
methods O
show O
superior O
performance O
to O
sequence O
tagging O
methods O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
this O
may O
be O
caused O
by O
the O
higher O
compositionality O
of O
candidate O
labels O
in O
sequence O
tagging O
methods O
( O
hu O
et O
al. O
, O
2019 O
) O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
as O
the O
previous O
sota O
method O
, O
the O
dualmrc O
shows O
competitive O
performance O
by O
utilizing O
the O
span-based O
extraction O
method O
and O
the O
mrc O
mechanism O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
however O
, O
their O
inference O
process O
is O
not O
an O
end-to-end O
process O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
on O
d20b O
dataset O
( O
xu O
et O
al. O
, O
2020 O
) O
, O
we O
compare O
our O
method O
for O
triplet O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
the O
comparison O
results O
can O
be O
found O
in O
table O
6 O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
our O
method O
achieves O
the O
best O
results O
with O
nearly O
7 O
f1 O
points O
improvements O
on O
14res O
, O
15res O
, O
and O
16res O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
our O
method O
achieves O
nearly O
13 O
, O
9 O
, O
7 O
, O
12 O
points O
improvements O
on O
each O
dataset O
for O
the O
recall O
scores O
compared O
with O
other O
baselines O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
this O
also O
explains O
the O
drop O
performance O
of O
the O
precision O
score O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
since O
d20b O
is O
refined O
from O
d20a O
, O
we O
specifically O
compare O
the O
triplet O
results O
of O
the O
corresponding O
dataset O
in O
d20a O
and O
d20b O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
interestingly O
, O
we O
discover O
that O
all O
baselines O
have O
a O
much O
bigger O
performance O
change O
on O
15res O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
we O
conjecture O
the O
distribution O
differences O
may O
be O
the O
cause O
reason O
. O

section 14
id pdf2json/2021.acl-long.188.pdf.json
in O
conclusion O
, O
all O
the O
experiment O
results O
confirm O
that O
our O
proposed O
method O
, O
which O
unifies O
the O
training O
and O
the O
inference O
to O
an O
end-to-end O
generative O
framework O
, O
provides O
a O
new O
sota O
solution O
for O
the O
whole O
absa O
task O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
to O
better O
understand O
our O
proposed O
framework O
, O
we O
conduct O
analysis O
experiments O
on O
the O
d20b O
dataset O
( O
xu O
et O
al. O
, O
2020 O
) O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
to O
validate O
whether O
our O
proposed O
framework O
could O
adapt O
to O
the O
generative O
absa O
task O
, O
we O
metric O
the O
invalid O
predictions O
for O
the O
triplet O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
specifically O
, O
since O
the O
triplet O
requires O
the O
prediction O
for- O
mat O
like O
[ O
as O
, O
ae O
, O
os O
, O
oe O
, O
sp O
] O
, O
it O
is O
mandatory O
that O
one O
valid O
triplet O
prediction O
should O
be O
in O
length O
5 O
, O
noted O
as O
“ O
5-len O
” O
, O
and O
obviously O
all O
end O
index O
should O
be O
larger O
than O
the O
corresponding O
start O
index O
, O
noted O
as O
“ O
ordered O
prediction O
” O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
we O
calculate O
number O
of O
non−5−len O
total O
prediction O
, O
referred O
to O
as O
the O
“ O
invalid O
size O
” O
, O
and O
the O
number O
of O
non−ordered O
predictiontotal O
5−len O
prediction O
, O
referred O
to O
as O
the O
“ O
invalid O
order O
” O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
the O
“ O
invalid O
token O
” O
means O
the O
as O
is O
not O
the O
start O
of O
a O
token O
, O
instead O
, O
it O
is O
the O
index O
of O
an O
inside O
subword O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
from O
table O
7 O
, O
we O
can O
observe O
that O
bart O
could O
learn O
this O
task O
form O
easily O
as O
the O
low O
rate O
for O
all O
the O
three O
metrics O
, O
which O
demonstrate O
that O
the O
generative O
framework O
for O
absa O
is O
not O
only O
a O
theoretically O
unified O
task O
form O
but O
also O
a O
realizable O
framework O
in O
practical O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
we O
remove O
these O
invalid O
predictions O
in O
our O
implementation O
of O
experiments O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
as O
shown O
in O
table O
4 O
, O
we O
give O
some O
analysis O
on O
the O
impact O
of O
the O
beam O
size O
, O
as O
we O
are O
a O
generation O
method O
. O

section 15
id pdf2json/2021.acl-long.188.pdf.json
however O
, O
the O
beam O
size O
seems O
to O
have O
little O
impact O
on O
the O
f1 O
scores O
. O

section 16
id pdf2json/2021.acl-long.188.pdf.json
this O
paper O
summarizes O
the O
seven O
absa O
subtasks O
and O
previous O
studies O
, O
which O
shows O
that O
there O
exist O
divergences O
on O
all O
the O
input O
, O
output O
, O
and O
task O
type O
sides O
. O

section 16
id pdf2json/2021.acl-long.188.pdf.json
previous O
studies O
have O
limitations O
on O
handling O
all O
these O
divergences O
in O
a O
unified O
framework O
. O

section 16
id pdf2json/2021.acl-long.188.pdf.json
we O
propose O
to O
convert O
all O
the O
absa O
subtasks O
to O
a O
unified O
generative O
task O
. O

section 16
id pdf2json/2021.acl-long.188.pdf.json
we O
implement O
the O
bart O
to O
generate O
the O
target O
sequence O
in O
an O
end-to-end O
process O
based O
on O
the O
unified O
task O
formulation O
. O

section 16
id pdf2json/2021.acl-long.188.pdf.json
we O
conduct O
massive O
experiments O
on O
public O
datasets O
for O
seven O
absa O
subtasks O
and O
achieve O
significant O
improvements O
on O
most O
datasets O
. O

section 16
id pdf2json/2021.acl-long.188.pdf.json
the O
experimental O
results O
demonstrate O
the O
effectiveness O
of O
our O
method O
. O

section 16
id pdf2json/2021.acl-long.188.pdf.json
our O
work O
leads O
to O
several O
promising O
directions O
, O
such O
as O
sequence-to-sequence O
framework O
on O
other O
tasks O
, O
and O
data O
augmentation O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
we O
would O
like O
to O
thank O
the O
anonymous O
reviewers O
for O
their O
insightful O
comments O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
the O
discussion O
with O
colleagues O
in O
aws O
shanghai O
ai O
lab O
was O
quite O
fruitful O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
we O
also O
thank O
the O
developers O
of O
fastnlp7 O
and O
fitlog8 O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
this O
work O
was O
supported O
by O
the O
national O
key O
research O
and O
development O
program O
of O
china O
( O
no O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
2020aaa0106700 O
) O
and O
national O
natural O
science O
foundation O
of O
china O
( O
no O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
62022027 O
) O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
ethical O
considerations O
for O
the O
consideration O
of O
ethical O
concerns O
, O
we O
would O
make O
detailed O
description O
as O
follows O
: O
( O
1 O
) O
all O
the O
experiments O
are O
conducted O
on O
existing O
datasets O
, O
which O
are O
derived O
from O
public O
scientific O
papers O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
( O
2 O
) O
we O
describe O
the O
characteristics O
of O
the O
datasets O
in O
a O
specific O
section O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
our O
analysis O
is O
consistent O
with O
the O
results O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
( O
3 O
) O
our O
work O
does O
not O
contain O
identity O
characteristics O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
it O
does O
not O
harm O
anyone O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
( O
4 O
) O
our O
experiments O
do O
not O
need O
a O
lot O
of O
computer O
resources O
compared O
to O
pre-trained O
models O
. O

section 17
id pdf2json/2021.acl-long.188.pdf.json
( O
5 O
) O
we O
will O
open O
source O
all O
our O
code O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
a.1 O
experimental O
environment O
we O
use O
the O
triangular O
learning O
rate O
warmup O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
all O
experiments O
are O
conducted O
in O
the O
nvidia O
ge-force O
rtx-3090 O
graphical O
card O
with O
24g O
graphical O
memory O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
the O
averages O
running O
time O
for O
experiments O
on O
each O
dataset O
is O
less O
than O
15 O
minutes O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
the O
number O
of O
parameters O
is O
as O
follows O
: O
• O
bart-base O
model O
: O
12 O
layers O
, O
768 O
hidden O
dimensions O
and O
16 O
heads O
with O
the O
total O
number O
of O
parameters O
, O
139m O
; O
• O
bert-base O
model O
: O
12 O
layers O
, O
768 O
hidden O
dimensions O
and O
12 O
heads O
with O
the O
total O
number O
of O
parameters O
, O
110m O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
a.2 O
decoding O
algorithm O
for O
different O
datasets O
in O
this O
part O
, O
we O
introduce O
the O
decoding O
algorithm O
we O
used O
to O
convert O
the O
predicted O
target O
sequence O
y O
into O
the O
target O
span O
set O
l. O
these O
algorithm O
can O
be O
found O
in O
algorithm O
2 O
, O
3 O
, O
4 O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
algorithm O
2 O
decoding O
algorithm O
for O
the O
aoe O
subtask O
input O
: O
number O
of O
tokens O
in O
the O
input O
sentence O
n O
, O
target O
sequence O
y O
= O
[ O
y1 O
, O
... O
, O
ym O
] O
and O
yi O
∈ O
[ O
1 O
, O
n+ O
|c| O
] O
, O
lt O
is O
a O
given O
length O
for O
different O
tasks O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
output O
: O
target O
span O
set O
l O
= O
{ O
( O
os1 O
, O
oe1 O
, O
... O
, O
osi O
, O
oei O
) O
} O
1 O
: O
l O
= O
{ O
} O
, O
e O
= O
[ O
] O
, O
i O
= O
3 O
2 O
: O
while O
i O
< O
= O
m O
do O
3 O
: O
yi O
= O
y O
[ O
i O
] O
4 O
: O
e.append O
( O
yi O
) O
5 O
: O
i+ O
= O
1 O
6 O
: O
end O
while O
7 O
: O
l.add O
( O
e O
) O
8 O
: O
return O
l O
a.3 O
detailed O
experimental O
setup O
experiments O
on O
each O
dataset O
as O
the O
different O
subtasks O
are O
conducted O
on O
different O
datasets O
, O
specifically O
, O
we O
conduct O
the O
following O
experiments O
on O
each O
dataset O
: O
• O
on O
the O
d17 O
dataset O
, O
we O
conduct O
the O
aesc O
and O
the O
oe O
in O
multi-task O
learning O
method O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
to O
that O
end O
, O
we O
feed O
the O
pre-defined O
task O
tags O
“ O
< O
aesc O
> O
” O
and O
“ O
< O
oe O
> O
” O
to O
the O
decoder O
first O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
for O
example O
, O
for O
the O
input O
“ O
the O
drinks O
are O
always O
: O
: O
: O
: O
well O
: O
: O
: O
: O
: O
made O
and O
wine O
selection O
is O
: O
: O
: O
: O
: O
fairly O
: O
: O
: O
: O
: O
: O
priced O
” O
from O
d17 O
dataset O
, O
we O
algorithm O
3 O
decoding O
algorithm O
for O
the O
aesc O
subtask O
input O
: O
number O
of O
tokens O
in O
the O
input O
sentence O
n O
, O
target O
sequence O
y O
= O
[ O
y1 O
, O
... O
, O
ym O
] O
and O
yi O
∈ O
[ O
1 O
, O
n+ O
|c| O
] O
output O
: O
target O
span O
set O
l O
= O
{ O
( O
as1 O
, O
ae1 O
, O
s1 O
) O
, O
... O
, O
( O
asi O
, O
aei O
, O
si O
) O
} O
1 O
: O
l O
= O
{ O
} O
, O
e O
= O
[ O
] O
, O
i O
= O
1 O
2 O
: O
while O
i O
< O
= O
m O
do O
3 O
: O
yi O
= O
y O
[ O
i O
] O
4 O
: O
if O
yi O
> O
n O
then O
5 O
: O
l.add O
( O
( O
e O
, O
cyi−n O
) O
) O
6 O
: O
e O
= O
[ O
] O
7 O
: O
else O
8 O
: O
e.append O
( O
yi O
) O
9 O
: O
end O
if O
10 O
: O
i+ O
= O
1 O
11 O
: O
end O
while O
12 O
: O
return O
l O
algorithm O
4 O
decoding O
algorithm O
for O
the O
ae/oe/pair O
subtasks O
input O
: O
number O
of O
tokens O
in O
the O
input O
sentence O
n O
, O
target O
sequence O
y O
= O
[ O
y1 O
, O
... O
, O
ym O
] O
and O
yi O
∈ O
[ O
1 O
, O
n+ O
|c| O
] O
, O
lt O
is O
a O
given O
length O
for O
different O
tasks O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
output O
: O
target O
span O
set O
l O
= O
{ O
x1 O
, O
... O
, O
xi O
} O
( O
xi O
is O
( O
asi O
, O
a O
e O
i O
) O
, O
( O
o O
s O
i O
, O
o O
e O
i O
) O
and O
( O
a O
s O
i O
, O
a O
e O
i O
, O
o O
s O
i O
, O
o O
e O
i O
) O
for O
ae/oe/pair O
, O
respectively O
) O
1 O
: O
l O
= O
{ O
} O
, O
e O
= O
[ O
] O
, O
i O
= O
1 O
2 O
: O
while O
i O
< O
= O
m O
do O
3 O
: O
yi O
= O
y O
[ O
i O
] O
4 O
: O
if O
len O
( O
e O
) O
== O
lt O
then O
5 O
: O
l.add O
( O
( O
e O
, O
cyi−n O
) O
) O
6 O
: O
e O
= O
[ O
] O
7 O
: O
end O
if O
8 O
: O
e.append O
( O
yi O
) O
9 O
: O
i+ O
= O
1 O
10 O
: O
end O
while O
11 O
: O
return O
l O
define O
the O
aesc O
sequence O
and O
the O
oe O
target O
sequence O
as O
“ O
< O
aesc O
> O
, O
1 O
, O
1 O
, O
pos O
, O
7 O
, O
8 O
, O
pos O
, O
< O
/s O
> O
” O
and O
“ O
< O
oe O
> O
, O
4 O
, O
5 O
, O
10 O
, O
11 O
, O
< O
/s O
> O
” O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
• O
on O
the O
d19 O
dataset O
, O
we O
conduct O
the O
aoe O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
as O
the O
aoe O
subtask O
requires O
to O
detect O
the O
opinion O
terms O
given O
aspect O
terms O
in O
advance O
, O
the O
aspect O
terms O
need O
to O
be O
fed O
to O
our O
decoder O
first O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
for O
the O
aforementioned O
example O
sentence O
from O
d19 O
dataset O
, O
we O
define O
the O
aoe O
target O
sequence O
as O
“ O
1 O
, O
1 O
, O
4 O
, O
5 O
, O
< O
/s O
> O
” O
and O
the O
“ O
7 O
, O
8 O
, O
10 O
, O
11 O
, O
< O
/s O
> O
” O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
• O
on O
thed20a O
andd20b O
datasets O
, O
we O
conduct O
the O
triplet O
extraction O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
for O
the O
aforementioned O
example O
sentence O
fromd20a O
andd20b O
dataset O
, O
we O
define O
the O
triplet O
target O
sequence O
as O
“ O
1 O
, O
1 O
, O
4 O
, O
5 O
, O
pos O
, O
7 O
, O
8 O
, O
10 O
, O
11 O
, O
pos O
, O
< O
/s O
> O
” O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
specific O
subtask O
metrics O
• O
on O
the O
d17 O
dataset O
, O
we O
get O
the O
aesc O
and O
oe O
results O
directly O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
following O
previous O
work O
, O
we O
only O
calculate O
the O
metrics O
for O
aesc O
and O
alsc O
from O
those O
true O
positive O
ae O
predictions O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
specifically O
, O
the O
f1 O
• O
on O
the O
d19 O
dataset O
, O
we O
get O
the O
aoe O
results O
directly O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
the O
metrics O
for O
aoe O
are O
standard O
precision O
, O
recall O
and O
the O
f1 O
score O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
• O
on O
the O
d20a O
and O
d20b O
datasets O
, O
we O
get O
the O
triplet O
results O
directly O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
we O
preserve O
the O
< O
at O
, O
ot O
> O
for O
pair O
metric O
and O
< O
at O
, O
sp O
> O
for O
aesc O
metric O
. O

section 18
id pdf2json/2021.acl-long.188.pdf.json
the O
metrics O
for O
them O
are O
standard O
precision O
, O
recall O
and O
the O
f1 O
score O
. O

section TITLE
id pdf2json/2021.acl-long.395.pdf.json
coins O
: O
dynamically O
generating O
contextualized O
inference O
rules O
for O
narrative O
story O
completion O

section ABSTRACT
id pdf2json/2021.acl-long.395.pdf.json
despite O
recent O
successes O
of O
large O
pre-trained O
language O
models O
in O
solving O
reasoning O
tasks O
, O
their O
inference O
capabilities O
remain O
opaque O
. O

section ABSTRACT
id pdf2json/2021.acl-long.395.pdf.json
we O
posit O
that O
such O
models O
can O
be O
made O
more O
interpretable O
by O
explicitly O
generating O
interim O
inference O
rules O
, O
and O
using O
them O
to O
guide O
the O
generation O
of O
task-specific O
textual O
outputs O
. O

section ABSTRACT
id pdf2json/2021.acl-long.395.pdf.json
in O
this O
paper O
we O
present O
coins O
, O
a O
recursive O
inference O
framework O
that O
i O
) O
iteratively O
reads O
context O
sentences O
, O
ii O
) O
dynamically O
generates O
contextualized O
inference O
rules O
, O
encodes O
them O
, O
and O
iii O
) O
uses O
them O
to O
guide O
task-specific O
output O
generation O
. O

section ABSTRACT
id pdf2json/2021.acl-long.395.pdf.json
we O
apply O
coins O
to O
a O
narrative O
story O
completion O
task O
that O
asks O
a O
model O
to O
complete O
a O
story O
with O
missing O
sentences O
, O
to O
produce O
a O
coherent O
story O
with O
plausible O
logical O
connections O
, O
causal O
relationships O
, O
and O
temporal O
dependencies O
. O

section ABSTRACT
id pdf2json/2021.acl-long.395.pdf.json
by O
modularizing O
inference O
and O
sentence O
generation O
steps O
in O
a O
recurrent O
model O
, O
we O
aim O
to O
make O
reasoning O
steps O
and O
their O
effects O
on O
next O
sentence O
generation O
transparent O
. O

section ABSTRACT
id pdf2json/2021.acl-long.395.pdf.json
our O
automatic O
and O
manual O
evaluations O
show O
that O
the O
model O
generates O
better O
story O
sentences O
than O
sota O
baselines O
, O
especially O
in O
terms O
of O
coherence O
. O

section ABSTRACT
id pdf2json/2021.acl-long.395.pdf.json
we O
further O
demonstrate O
improved O
performance O
over O
strong O
pre-trained O
lms O
in O
generating O
commonsense O
inference O
rules O
. O

section ABSTRACT
id pdf2json/2021.acl-long.395.pdf.json
the O
recursive O
nature O
of O
coins O
holds O
the O
potential O
for O
controlled O
generation O
of O
longer O
sequences O
. O

section 0
id pdf2json/2021.acl-long.395.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
5086–5099 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.395.pdf.json
©2021 O
association O
for O
computational O
linguistics O
5086 O

section 1
id pdf2json/2021.acl-long.395.pdf.json
narrative O
story O
understanding O
, O
and O
similarly O
story O
generation O
, O
requires O
the O
ability O
to O
construe O
meaning O
that O
is O
not O
explicitly O
stated O
through O
commonsense O
reasoning O
over O
events O
in O
the O
story O
( O
rashkin O
et O
al. O
, O
2018a O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
previous O
work O
in O
modeling O
narrative O
stories O
has O
focused O
on O
learning O
scripts1 O
( O
schank O
and O
abelson O
, O
1977 O
; O
mooney O
and O
dejong O
, O
1985 O
) O
and O
learning O
narrative O
schemas O
using O
corpus O
statis- O
1scripts O
are O
structured O
knowledge O
about O
stereotypical O
event O
sequences O
together O
with O
their O
participants O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
tics O
( O
chambers O
and O
jurafsky O
, O
2009 O
; O
balasubramanian O
et O
al. O
, O
2013 O
; O
nguyen O
et O
al. O
, O
2015 O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
recently O
, O
large O
pretrained O
language O
models O
( O
lms O
) O
such O
as O
gpt-2 O
have O
shown O
remarkable O
performance O
on O
various O
generation O
tasks O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
while O
these O
pretrained O
lms O
learn O
probabilistic O
associations O
between O
words O
and O
sentences O
, O
they O
still O
have O
difficulties O
in O
modeling O
causality O
( O
mostafazadeh O
et O
al. O
, O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
also O
, O
in O
narrative O
story O
generation O
, O
models O
need O
to O
be O
consistent O
with O
everyday O
commonsense O
norms O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
hence O
, O
to O
address O
a O
story O
generation O
task O
, O
i O
) O
models O
need O
to O
be O
equipped O
with O
suitable O
knowledge O
, O
ii O
) O
they O
need O
effective O
knowledge O
integration O
and O
reasoning O
methods O
, O
and O
ideally O
iii O
) O
we O
want O
to O
be O
able O
to O
make O
the O
effectiveness O
of O
these O
methods O
transparent O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
in O
this O
work O
we O
focus O
on O
the O
aspects O
i O
) O
to O
iii O
) O
, O
by O
investigating O
new O
methods O
that O
build O
on O
pretrained O
lms O
to O
generate O
missing O
sentences O
from O
an O
incomplete O
narrative O
story O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
specifically O
, O
we O
focus O
on O
narrative O
story O
completion O
( O
nsc O
) O
, O
a O
new O
task O
setting O
for O
story O
generation O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
given O
an O
incomplete O
story O
, O
specified O
only O
through O
its O
beginning O
and O
ending O
, O
the O
task O
is O
to O
generate O
the O
missing O
sentences O
to O
complete O
the O
story O
( O
see O
figure O
1 O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
our O
hypothesis O
is O
that O
in O
order O
to O
obtaining O
a O
consistent O
and O
coherent O
narrative O
story O
, O
the O
task O
requires O
a O
model O
’ O
s O
ability O
to O
perform O
commonsense O
inference O
about O
events O
and O
entities O
in O
a O
story O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
unlike O
other O
existing O
tasks O
, O
nsc O
requires O
: O
i O
) O
generating O
multiple O
sentences O
to O
complete O
a O
story O
, O
and O
ii O
) O
ensuring O
that O
the O
generated O
sentences O
are O
coherent O
with O
respect O
to O
both O
beginning O
and O
ending O
of O
the O
story O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
hence O
, O
the O
nsc O
task O
offers O
a O
challenging O
setup O
for O
investigating O
the O
reasoning O
capacities O
of O
a O
story O
generation O
model O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
humans O
excel O
in O
drawing O
inferences O
and O
constructing O
causal O
chains O
that O
explain O
the O
connection O
between O
events O
( O
kintsch O
and O
dijk O
, O
1978 O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
figure O
1 O
illustrates O
this O
with O
an O
example O
from O
our O
nsc O
task.2 O
from O
janie O
was O
excited O
to O
see O
her O
sister O
’ O
s O
play O
in O
theatre O
( O
s1 O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
janie O
got O
a O
call O
from O
her O
boss O
about O
new O
work O
( O
s2 O
) O
and O
the O
outcome O
janie O
watched O
a O
video O
of O
the O
play O
later O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
( O
s5 O
) O
– O
we O
can O
construct O
inference O
rules O
in O
forward O
and O
backward O
direction O
: O
forward O
via O
effect O
: O
someoneb O
( O
boss O
) O
gave O
work O
to O
someonea O
( O
janie O
) O
; O
backward O
via O
cause O
: O
someonea O
( O
janie O
) O
wasn O
’ O
t O
able O
to O
go O
somewhereb O
( O
to O
the O
theatre O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
by O
combining O
these O
inferences O
, O
we O
can O
obtain O
a O
representation O
from O
which O
to O
generate O
a O
connection O
that O
completes O
the O
story O
, O
e.g. O
, O
janie O
’ O
s O
boss O
wanted O
her O
to O
look O
after O
the O
issue O
( O
s3 O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
she O
missed O
the O
theatre O
play O
( O
s4 O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
in O
this O
work O
, O
we O
propose O
coins O
: O
a O
recursive O
model O
that O
jointly O
learns O
to O
i O
) O
dynamically O
generate O
commonsense O
inference O
rules3 O
grounded O
in O
the O
context O
and O
to O
ii O
) O
perform O
controled O
and O
coherent O
story O
generation O
, O
using O
the O
generated O
inferences O
as O
a O
guide O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
we O
hypothesize O
that O
jointly O
learning O
to O
generate O
contextualized O
inference O
rules O
from O
dynamically O
predicted O
contextualized O
inference O
rules O
and O
learning O
to O
generate O
story O
sentences O
incrementally O
while O
taking O
the O
inferences O
into O
account O
, O
will O
improve O
the O
quality O
of O
both O
the O
predicted O
inference O
rules O
and O
of O
generated O
story O
sentences O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
moreover O
, O
the O
recursive O
nature O
of O
the O
model O
and O
the O
individuation O
of O
the O
inference O
prediction O
and O
sentence O
generation O
tasks O
make O
the O
process O
more O
interpretable O
: O
the O
generated O
inference O
rules O
can O
be O
viewed O
as O
intermediate O
representations O
, O
and O
can O
serve O
as O
explanations O
of O
how O
the O
dynamically O
produced O
inferences O
influence O
the O
quality O
of O
generated O
story O
sentences O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
our O
main O
contributions O
are O
as O
follows O
: O
1 O
) O
we O
propose O
a O
new O
setting O
for O
a O
narrative O
story O
completion O
task O
, O
which O
asks O
a O
system O
to O
complete O
a O
narrative O
story O
given O
its O
beginning O
and O
ending O
, O
2we O
use O
the O
rocstories O
dataset O
to O
frame O
the O
nsc O
task O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
3in O
this O
paper O
, O
similar O
to O
mostafazadeh O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
, O
we O
will O
use O
“ O
inference O
rule O
” O
and O
“ O
explanation O
” O
interchangeably O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
with O
the O
aim O
of O
examining O
the O
reasoning O
capacities O
of O
a O
model O
that O
solves O
the O
task O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
2 O
) O
we O
propose O
an O
integrated O
reasoning O
and O
nl O
generation O
model O
, O
coins O
, O
that O
based O
on O
its O
current O
context O
generates O
contextualized O
commonsense O
inference O
rules O
and O
follow-up O
sentences O
, O
in O
a O
stepwise O
recurrent O
process O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
3 O
) O
we O
conduct O
extensive O
experiments O
with O
automatic O
and O
human O
evaluation O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
automatic O
evaluations O
show O
that O
coins O
outperforms O
strong O
baselines O
( O
+2.2 O
bleu O
score O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
human O
evaluation O
shows O
that O
compared O
to O
strong O
baselines O
, O
our O
model O
yields O
better O
sentence O
generations O
with O
respect O
to O
coherence O
( O
+50.5 O
% O
) O
and O
grammaticality O
( O
+20.5 O
% O
) O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
4 O
) O
we O
show O
that O
coins O
generates O
better O
inference O
rules O
( O
+2.3 O
bleu O
score O
) O
compared O
to O
a O
finetuned O
gpt-2 O
model O
, O
and O
that O
jointly O
learning O
to O
generate O
inferences O
and O
story O
sentences O
improves O
the O
quality O
of O
the O
generated O
inference O
rules O
. O

section 1
id pdf2json/2021.acl-long.395.pdf.json
our O
code O
is O
made O
publicly O
available.4 O

section 2
id pdf2json/2021.acl-long.395.pdf.json
sentence-level O
commonsense O
inference O
and O
beyond O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
recent O
research O
in O
this O
area O
has O
focused O
on O
commonsense O
knowledge O
acquisition O
( O
sap O
et O
al. O
, O
2019 O
; O
zhang O
et O
al. O
, O
2020 O
; O
speer O
et O
al. O
, O
2017 O
; O
malaviya O
et O
al. O
, O
2020 O
) O
and O
commonsense O
reasoning O
( O
zellers O
et O
al. O
, O
2019 O
; O
talmor O
et O
al. O
, O
2018 O
) O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
in O
our O
work O
, O
we O
focus O
on O
inferential O
knowledge O
about O
events O
, O
and O
entities O
participating O
in O
such O
events O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
rashkin O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2018b O
) O
introduced O
a O
knowledge O
resource O
of O
commonsense O
inferences O
regarding O
people O
’ O
s O
intents O
and O
reactions O
towards O
a O
diverse O
set O
of O
events O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
with O
comet O
, O
bosselut O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2019 O
) O
have O
shown O
that O
pre-trained O
neural O
language O
models O
can O
be O
fine-tuned O
using O
large O
knowledge O
bases O
( O
such O
as O
atomic O
, O
sap O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2019 O
) O
) O
to O
generate O
inferences O
for O
a O
given O
event O
or O
sentence O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
however O
, O
the O
generated O
knowledge O
from O
comet O
is O
noncontextualized O
and O
hence O
, O
can O
be O
inconsistent O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
recently O
, O
mostafazadeh O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
proposed O
glucose O
, O
a O
new O
resource O
and O
dataset O
that O
offers O
semistructured O
commonsense O
inference O
rules O
that O
are O
grounded O
in O
sentences O
of O
specific O
stories O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
they O
show O
that O
fine-tuning O
a O
pre-trained O
lm O
on O
the O
glucose O
dataset O
helps O
the O
model O
to O
better O
generate O
inferrable O
commonsense O
explanations O
given O
a O
complete O
story O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
in O
concurrent O
work O
, O
gabriel O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2021 O
) O
proposed O
para-comet O
, O
a O
model O
that O
in- O
4https O
: O
//github.com/heidelberg-nlp/ O
coins O
corporates O
paragraph-level O
information O
to O
generate O
coherent O
commonsense O
inferences O
from O
narratives O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
in O
this O
work O
, O
we O
investigate O
how O
well O
a O
neural O
model O
can O
generate O
contextualized O
commonsense O
inference O
rules O
for O
an O
incomplete O
story O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
learning O
to O
predict O
iterative O
inference O
steps O
for O
successive O
events O
in O
a O
narration O
using O
semi-structured O
knowledge O
rules O
is O
still O
a O
difficult O
and O
underexplored O
task O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
we O
propose O
a O
model O
that O
learns O
to O
iteratively O
generate O
a O
coherent O
completion O
of O
an O
incomplete O
narrative O
story O
utilizing O
semi-structured O
knowledge O
as O
offered O
by O
the O
glucose O
framework O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
commonsense O
reasoning O
in O
narrative O
stories O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
early O
work O
on O
narrative O
events O
focused O
on O
script O
learning O
, O
by O
defining O
stereotypical O
event O
sequences O
together O
with O
their O
participants O
( O
schank O
and O
abelson O
, O
1977 O
) O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
in O
later O
works O
, O
chambers O
and O
jurafsky O
( O
2008 O
, O
2009 O
) O
; O
balasubramanian O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2013 O
) O
; O
nguyen O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2015 O
) O
; O
pichotta O
and O
mooney O
( O
2014 O
) O
proposed O
methods O
to O
learn O
narrative O
event O
chains O
using O
a O
simpler O
event O
representation O
that O
allows O
for O
efficient O
learning O
and O
inference O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
chambers O
and O
jurafsky O
( O
2009 O
) O
acquired O
narrative O
event O
schemata O
from O
corpora O
and O
established O
the O
narrative O
cloze O
task O
( O
chambers O
and O
jurafsky O
, O
2008 O
) O
that O
evaluates O
script O
knowledge O
by O
predicting O
a O
missing O
event O
( O
verb O
and O
its O
arguments O
) O
in O
a O
sequence O
of O
observed O
events O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
more O
recently O
, O
mostafazadeh O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2016 O
) O
proposed O
the O
story O
cloze O
task O
that O
selects O
a O
plausible O
( O
right O
) O
over O
an O
implausible O
( O
wrong O
) O
story O
ending O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
bhagavatula O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
proposed O
an O
abductive O
reasoning O
task O
to O
test O
a O
model O
’ O
s O
ability O
to O
generate O
plausible O
explanations O
for O
an O
incomplete O
set O
of O
observations O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
paul O
and O
frank O
( O
2020 O
) O
proposed O
a O
multi-head O
knowledge O
attention O
method O
to O
dynamically O
incorporate O
non-contextualized O
inferential O
knowledge O
to O
address O
the O
abductive O
reasoning O
task O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
qin O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
proposed O
an O
unsupervised O
decoding O
algorithm O
that O
can O
flexibly O
incorporate O
both O
the O
past O
and O
future O
contexts O
using O
only O
off-the-shelf O
language O
models O
to O
generate O
plausible O
explanations O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
concurrent O
to O
our O
work O
, O
paul O
and O
frank O
( O
2021 O
) O
presented O
a O
method O
for O
addressing O
the O
abductive O
reasoning O
task O
by O
explicitly O
learning O
what O
events O
could O
follow O
other O
events O
in O
a O
hypothetical O
scenario O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
in O
our O
work O
, O
we O
make O
use O
of O
the O
rocstories O
dataset O
( O
mostafazadeh O
et O
al. O
, O
2016 O
) O
to O
build O
a O
narrative O
story O
completion O
task O
that O
tests O
a O
model O
’ O
s O
ability O
of O
generating O
missing O
sentences O
in O
a O
story O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
we O
propose O
a O
model O
that O
aims O
to O
produce O
coherent O
narrative O
stories O
by O
performing O
iterative O
commonsense O
inference O
steps O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
narrative O
story O
generation O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
much O
existing O
work O
on O
story O
generation O
relied O
on O
symbolic O
planning O
methods O
( O
lebowitz O
, O
1987 O
; O
pérez O
and O
sharples O
, O
2001 O
; O
józefowicz O
et O
al. O
, O
2016 O
) O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
with O
the O
advances O
of O
seq2seq O
models O
, O
several O
works O
applied O
them O
in O
automatic O
story O
generation O
tasks O
( O
roemmele O
, O
2016 O
; O
jain O
et O
al. O
, O
2017 O
) O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
fan O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2018 O
) O
proposed O
a O
hierarchical O
approach O
to O
generate O
short O
stories O
from O
initial O
prompts O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
recently O
, O
many O
works O
have O
focused O
on O
integrating O
external O
commonsense O
knowledge O
from O
large O
static O
knowledge O
bases O
like O
atomic O
( O
sap O
et O
al. O
, O
2019 O
) O
or O
conceptnet O
( O
speer O
et O
al. O
, O
2017 O
) O
for O
different O
tasks O
such O
as O
story O
ending O
generation O
( O
ji O
et O
al. O
, O
2020 O
; O
guan O
et O
al. O
, O
2019 O
) O
or O
story O
generation O
( O
guan O
et O
al. O
, O
2020 O
; O
xu O
et O
al. O
, O
2020 O
) O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
in O
concurrent O
work O
, O
ammanabrolu O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
( O
2021 O
) O
look O
into O
causality O
for O
a O
commonsense O
plot O
generation O
task O
. O

section 2
id pdf2json/2021.acl-long.395.pdf.json
in O
our O
work O
, O
we O
model O
the O
assumption O
that O
contextualized O
inference O
rules O
provide O
inferred O
information O
that O
can O
guide O
a O
system O
in O
generating O
both O
contextually O
grounded O
and O
coherent O
follow-up O
sentences O
in O
a O
story O
generation O
task O
. O

section 3
id pdf2json/2021.acl-long.395.pdf.json
we O
formulate O
the O
narrative O
story O
completion O
task O
( O
nsc O
) O
as O
follows O
: O
given O
an O
incomplete O
story O
( O
s= O
s1 O
, O
s2 O
, O
sn O
) O
as O
a O
sequence O
of O
tokens O
t O
= O
{ O
t1 O
, O
t2 O
, O
... O
, O
tsep O
, O
... O
, O
tm O
} O
( O
with O
tsep O
a O
mask O
token O
delimiting O
s2 O
and O
sn O
) O
, O
the O
goal O
is O
to O
generate O
the O
missing O
sentences O
( O
s3 O
, O
... O
, O
sn−1 O
) O
as O
a O
sequence O
of O
tokens O
ysi= O
{ O
ysi1 O
, O
y O
si O
2 O
, O
... O
, O
y O
si O
v O
} O
( O
with O
i O
= O
3 O
, O
... O
, O
n−1 O
and O
v O
the O
maximum O
length O
of O
each O
sentence O
) O
. O

section 3
id pdf2json/2021.acl-long.395.pdf.json
in O
the O
setting O
of O
the O
nsc O
task O
, O
we O
expect O
the O
completed O
story O
to O
be O
coherent O
. O

section 3
id pdf2json/2021.acl-long.395.pdf.json
that O
is O
, O
the O
generated O
sentences O
should O
exhibit O
reasonable O
logical O
connections O
, O
causal O
relationships O
, O
and O
temporal O
dependencies O
with O
each O
other O
and O
the O
given O
beginning O
and O
ending O
of O
the O
story O
. O

section 3
id pdf2json/2021.acl-long.395.pdf.json
in O
this O
paper O
, O
we O
define O
a O
discourse O
to O
be O
coherent O
if O
successive O
sentences O
that O
are O
about O
the O
same O
entities O
, O
and O
the O
reported O
events O
involving O
them O
can O
be O
construed O
to O
reflect O
common O
knowledge O
about O
how O
events O
are O
typically O
connected O
in O
a O
temporal O
sequence O
or O
by O
causal O
relations O
. O

section 3
id pdf2json/2021.acl-long.395.pdf.json
similar O
to O
hobbs O
( O
1985 O
) O
, O
the O
criteria O
to O
conclude O
that O
discourse O
is O
coherent O
include O
require O
that O
there O
are O
reflections O
of O
causality O
in O
the O
text O
. O

section 3
id pdf2json/2021.acl-long.395.pdf.json
our O
take O
on O
this O
task O
is O
to O
incrementally O
generate O
contextualized O
inference O
rules O
from O
the O
given O
context O
, O
and O
to O
make O
use O
of O
this O
knowledge O
to O
generate O
missing O
story O
sentences O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
this O
section O
details O
how O
we O
construct O
training O
data O
for O
the O
nsc O
task O
, O
by O
enriching O
stories O
with O
automatically O
predicted O
contextualized O
inferences.5 O
we O
utilize O
the O
glucose O
( O
mostafazadeh O
et O
al. O
, O
2020 O
) O
dataset O
, O
which O
contains O
implicit O
commonsense O
knowledge O
in O
form O
of O
semi-structured O
general O
and O
specific O
inference O
rules6 O
( O
cf O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
table O
1 O
) O
that O
are O
grounded O
in O
the O
context O
of O
individual O
stories O
from O
rocstories O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
in O
glucose O
, O
given O
a O
story O
s O
and O
a O
selected O
sentence O
x O
from O
the O
story O
, O
the O
authors O
define O
ten O
dimensions O
d O
of O
commonsense O
causal O
explanations O
related O
to O
x O
, O
inspired O
by O
human O
cognitive O
psychology O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
only O
a O
small O
part O
of O
rocstories O
is O
annotated O
with O
glucose O
inferences O
( O
table O
3 O
) O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
given O
the O
amount O
of O
commonsense O
knowledge O
needed O
for O
real-world O
tasks O
, O
a O
static O
knowledge O
resource O
is O
always O
incomplete O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
thus O
, O
we O
fine-tune O
a O
pre-trained O
gpt-2 O
model O
on O
the O
annotated O
part O
of O
glucose O
to O
dynamically O
generate O
inference O
rules O
for O
each O
sentence O
xi O
of O
each O
story O
si O
from O
the O
underlying O
rocstories O
data O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
we O
fine-tune O
two O
separate O
language O
models O
csigen O
and O
csispec O
for O
general O
and O
specific O
rules O
, O
respectively O
( O
table O
2 O
) O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
the O
10 O
dimensions O
d O
in O
glucose O
cover O
im5for O
testing O
we O
rely O
on O
glucose O
’ O
s O
manually O
validated O
inference O
rules O
on O
a O
small O
subset O
of O
the O
rocstories O
corpus O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
6specific O
means O
rules O
grounded O
in O
a O
given O
context O
and O
general O
corresponds O
to O
rules O
that O
are O
applicable O
to O
other O
contexts O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
plicit O
causes O
and O
effects O
of O
a O
sentence O
x O
in O
a O
given O
story O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
in O
our O
work O
, O
we O
are O
interested O
in O
inference O
rules O
that O
explain O
a O
sentence O
’ O
s O
causes O
and O
effects O
, O
to O
study O
the O
impact O
of O
such O
inferences O
on O
narrative O
story O
completion O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
we O
therefore O
cluster O
all O
dimensions O
d O
into O
the O
two O
categories O
effect O
vs O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
cause O
( O
table O
1 O
) O
and O
aggregate O
all O
rules O
from O
the O
respective O
categories O
( O
preserving O
their O
dimensions O
) O
. O

section 4
id pdf2json/2021.acl-long.395.pdf.json
once O
our O
models O
( O
csigen O
, O
csispec O
) O
are O
trained O
, O
we O
apply O
them O
to O
our O
nsc O
task O
training O
data O
, O
to O
enrich O
it O
with O
inference O
rules O
for O
each O
sentence O
and O
story O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
in O
this O
section O
we O
introduce O
a O
recursively O
operating O
reasoning O
and O
sentence O
generation O
model O
: O
coins O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
an O
overview O
is O
given O
in O
figure O
2 O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
in O
each O
iteration O
, O
the O
model O
applies O
two O
consecutive O
steps O
: O
( O
1 O
) O
inference O
step O
: O
given O
an O
incomplete O
story O
context O
s′= O
x O
⊕ O
si O
and O
relation O
r O
, O
an O
inference O
model O
csi O
( O
gen O
or O
spec O
) O
generates O
contextualized O
inference O
rules O
of O
type O
r. O
( O
2 O
) O
generation O
step O
: O
a O
sentence O
generator O
reads O
the O
generated O
inference O
rules O
concatenated O
with O
the O
current O
context O
s′ O
and O
generates O
the O
next O
story O
sentence O
si+1 O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
the O
context O
s′ O
is O
updated O
with O
si+1 O
and O
steps O
( O
1 O
) O
and O
( O
2 O
) O
are O
repeated O
( O
cf O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
algorithm O
1 O
) O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
this O
formulation O
allows O
us O
to O
i O
) O
examine O
inference O
and O
generation O
capabilities O
separately O
from O
each O
other O
, O
ii O
) O
helps O
determine O
the O
impact O
of O
inferential O
knowledge O
on O
story O
generation O
, O
and O
iii O
) O
can O
give O
us O
insight O
into O
how O
knowledge O
can O
guide O
story O
generation O
in O
a O
recursive O
inference O
framework O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
inference O
step O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
we O
define O
the O
initial O
story O
context O
s′ O
= O
{ O
s1 O
, O
s2 O
, O
[ O
sep O
] O
, O
sn O
} O
, O
a O
selected O
sentence O
as O
si O
, O
and O
relation O
type O
r O
∈ O
{ O
effect O
, O
cause O
} O
, O
where O
i O
∈ O
[ O
2 O
, O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
n-1 O
] O
, O
si= O
{ O
wsi1 O
, O
.. O
, O
wsiv O
} O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
we O
adopt O
a O
pretrained O
gpt-2 O
( O
base O
) O
( O
radford O
et O
al. O
, O
2019 O
) O
transformer O
model O
with O
multiple O
transformer O
blocks O
of O
multi-head O
self-attention O
and O
fully O
connected O
layers O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
during O
training O
, O
in O
each O
iteration O
the O
input O
to O
the O
model O
is O
a O
concatenation O
of O
the O
current O
source O
( O
s′ O
, O
si O
, O
r O
) O
and O
target O
sequence O
i.e. O
, O
the O
inference O
rules O
( O
ei O
or O
ci O
) O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
eq O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
( O
1 O
) O
defines O
the O
inference O
rule O
( O
ir O
) O
generation O
model O
: O
h0p O
= O
ep O
+ O
pp O
, O
hlp O
= O
block O
( O
h O
l−1 O
< O
p O
) O
, O
l O
∈ O
[ O
1 O
, O
l O
] O
p O
( O
yp|y O
< O
p O
, O
p O
) O
= O
softmax O
( O
hlpw O
t O
) O
( O
1 O
) O
where O
h0p O
is O
a O
summation O
of O
token O
embedding O
ep O
and O
position O
embedding O
pp O
for O
the O
p-th O
token O
; O
hlp O
is O
the O
l-th O
layer O
’ O
s O
output O
at O
position O
p O
, O
computed O
through O
transformer O
blocks O
with O
the O
masked O
multi-head O
self O
attention O
mechanism O
; O
hlp O
is O
the O
final O
layer O
’ O
s O
hidden O
state O
and O
y O
< O
p O
indicates O
the O
left O
context O
of O
position O
p. O
the O
softmax O
layer O
defines O
the O
model O
to O
output O
the O
most O
probable O
target O
sequence O
: O
the O
most O
likely O
inference O
rules O
( O
ei O
and O
ci O
) O
for O
each O
relation O
type O
( O
cf O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
algorithm O
line O
4-5 O
) O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
during O
training O
, O
we O
minimize O
the O
objective O
( O
2 O
) O
li O
( O
β O
) O
= O
− O
m+n∑ O
k=m O
log O
p O
( O
eki O
|s′ O
, O
si O
, O
effect O
) O
− O
m+n∑ O
k=m O
log O
p O
( O
cki O
|s′ O
, O
sn O
, O
cause O
) O
( O
2 O
) O
where O
m O
, O
n O
denote O
the O
number O
of O
tokens O
in O
the O
source O
( O
s′ O
, O
si O
, O
r O
) O
and O
target O
sequence O
( O
inference O
rules O
) O
respectively O
; O
β O
refers O
to O
model O
parameters O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
in O
this O
work O
, O
we O
focus O
on O
the O
nsc O
task O
, O
which O
requires O
our O
model O
to O
capture O
temporal O
dependencies O
and O
causal O
relationships O
between O
events O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
while O
we O
designed O
our O
sentence O
generation O
model O
in O
such O
a O
way O
that O
it O
can O
utilize O
inference O
rules O
from O
both O
forward O
and O
backward O
directions O
for O
each O
sentence O
, O
we O
here O
trigger O
the O
generation O
of O
cause O
inference O
rules O
for O
sn O
, O
since O
we O
expect O
that O
events O
, O
motivations O
or O
attributes O
that O
cause O
sn O
will O
be O
relevant O
for O
generating O
the O
preceding O
sentences O
[ O
s3 O
, O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
sn−1 O
] O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
algorithm O
1 O
coins O
input O
: O
initial O
context O
( O
s′ O
= O
{ O
s1 O
, O
s2 O
, O
[ O
sep O
] O
, O
sn O
} O
) O
1 O
: O
memir← O
empty O
2 O
: O
gens O
← O
empty O
list O
3 O
: O
for O
i← O
2 O
to O
n− O
1 O
do O
4 O
: O
ei O
= O
geninferencerules O
( O
s′ O
, O
si O
, O
effect O
) O
5 O
: O
ci O
= O
geninferencerules O
( O
s′ O
, O
sn O
, O
cause O
) O
6 O
: O
ii O
= O
ei O
⊕ O
ci O
7 O
: O
si+1 O
= O
gennewsentence O
( O
ii O
, O
s′ O
) O
8 O
: O
gens O
: O
= O
gens O
+ O
si+1 O
9 O
: O
memir O
: O
= O
memir O
⊕ O
ii O
10 O
: O
ls O
+= O
−logp O
( O
θ O
) O
( O
si+1|ii O
, O
s O
′ O
) O
−logp O
( O
β O
) O
( O
ii|s O
′ O
) O
11 O
: O
lir O
+= O
−logp O
( O
θ O
) O
( O
si+1|ii O
, O
s O
′ O
) O
−logp O
( O
β O
) O
( O
ii|s O
′ O
) O
12 O
: O
s′ O
: O
= O
{ O
s1 O
, O
s2 O
, O
si+1 O
, O
[ O
sep O
] O
, O
sn O
} O
13 O
: O
end O
for O
14 O
: O
return O
gens O
, O
memir O
similarly O
, O
we O
generate O
effect O
relations O
for O
si O
, O
assuming O
that O
an O
event O
, O
changes O
of O
emotion O
or O
changes O
of O
attribute O
that O
are O
possible O
effects O
caused O
by O
si O
will O
be O
most O
relevant O
for O
generating O
the O
missing O
follow-up O
sentences O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
in O
principle O
, O
however O
, O
for O
nsc O
and O
other O
story O
generation O
tasks O
, O
we O
may O
consider O
cause O
and O
effect O
relations O
for O
all O
sentences O
, O
letting O
the O
model O
freely O
choose O
from O
the O
full O
space O
of O
inferences O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
we O
concatenate O
the O
generated O
inference O
rules O
( O
ii O
= O
ei O
⊕ O
ci O
) O
7 O
and O
store O
the O
last O
hidden O
representation O
in O
memir O
∈ O
irn×l×h O
, O
where O
n O
is O
the O
number O
of O
sentences O
, O
l O
the O
maximum O
inference O
sequence O
length O
and O
h O
the O
hidden O
state O
dimensions O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
memir O
is O
updated O
with O
the O
hidden O
representations O
of O
inference O
rules O
in O
each O
iteration O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
hence O
, O
memir O
could O
act O
as O
an O
intermediate O
representation O
, O
and O
as O
a O
basis O
for O
providing O
explanations O
for O
observed O
story O
sentence O
generations O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
memir O
may O
also O
be O
used O
as O
a O
memory O
for O
long-form O
text O
generation O
tasks O
, O
to O
keep O
track O
of O
implicit O
knowledge O
triggered O
by O
previously O
generated O
text O
, O
and O
could O
support O
flexible O
discourse O
serialization O
patterns.8 O
generation O
step O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
given O
the O
generated O
inference O
rules O
ii O
( O
in O
form O
of O
tokens O
) O
and O
the O
incomplete O
story O
context O
s′ O
, O
we O
aim O
to O
generate O
the O
next O
missing O
sentence O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
we O
pass O
the O
input O
through O
another O
pretrained O
gpt-2 O
( O
base O
) O
model O
( O
cf O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
equation O
1 O
) O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
the O
loss O
function O
for O
the O
sentence O
generator O
is O
ls O
( O
θ O
) O
= O
− O
v∑ O
k=1 O
log O
p O
( O
y O
si+1 O
k O
|ii O
, O
[ O
eok O
] O
, O
s O
′ O
) O
( O
3 O
) O
where O
yk O
denotes O
the O
k-th O
token O
and O
v O
the O
maximum O
length O
of O
the O
generated O
sentence O
; O
7we O
use O
[ O
sep O
] O
token O
to O
delimit O
the O
individual O
ei O
and O
ci O
when O
concatenating O
them O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
8we O
leave O
such O
extensions O
to O
future O
work O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
i O
∈ O
[ O
2 O
, O
n− O
1 O
] O
; O
[ O
eok O
] O
denotes O
the O
end O
of O
knowledge O
rule O
tokens O
, O
and O
θ O
refers O
to O
model O
parameters O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
update O
story O
context O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
in O
the O
final O
step O
we O
update O
the O
story O
context O
by O
inserting O
the O
generated O
sentence O
si+1 O
into O
the O
previous O
story O
context O
( O
cf O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
algorithm O
1 O
, O
line O
12 O
) O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
training O
and O
inference O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
we O
add O
the O
losses O
li O
for O
inference O
generation O
and O
ls O
for O
sentence O
generation O
to O
make O
the O
models O
dependent O
on O
each O
other O
( O
algorithm O
1 O
, O
line O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
10-11 O
) O
. O

section 5
id pdf2json/2021.acl-long.395.pdf.json
for O
both O
the O
inference O
and O
the O
generation O
step O
model O
, O
we O
minimize O
the O
negative O
log O
likelihood O
loss O
of O
the O
respective O
target O
sequence O
. O

section 7
id pdf2json/2021.acl-long.395.pdf.json
we O
apply O
coins O
to O
the O
nsc O
and O
the O
story O
ending O
generation O
tasks.9 O
for O
data O
statistics O
see O
table O
3 O
. O

section 7
id pdf2json/2021.acl-long.395.pdf.json
narrative O
story O
completion O
. O

section 7
id pdf2json/2021.acl-long.395.pdf.json
we O
follow O
the O
task O
definition O
as O
introduced O
in O
§3 O
. O

section 7
id pdf2json/2021.acl-long.395.pdf.json
data O
collection O
. O

section 7
id pdf2json/2021.acl-long.395.pdf.json
we O
construct O
the O
nsc O
dataset O
on O
the O
basis O
of O
the O
rocstories O
corpus O
( O
mostafazadeh O
et O
al. O
, O
2016 O
) O
, O
which O
contains O
98,162 O
five-sentence O
stories O
with O
a O
clear O
beginning O
and O
ending O
, O
thus O
making O
it O
a O
good O
choice O
for O
this O
task O
. O

section 7
id pdf2json/2021.acl-long.395.pdf.json
we O
choose O
the O
first O
two O
sentences O
( O
s1 O
, O
s2 O
) O
as O
beginning O
rather O
than O
just O
s1 O
because O
the O
first O
sentence O
( O
s1 O
) O
tends O
to O
be O
short O
in O
length O
, O
and O
usually O
introduces O
characters O
or O
sets O
the O
scene O
( O
mostafazadeh O
et O
al. O
, O
2016 O
) O
, O
wherease O
the O
second O
sentence O
( O
s2 O
) O
provides O
more O
information O
about O
the O
initial O
story O
. O

section 8
id pdf2json/2021.acl-long.395.pdf.json
parameter O
size O
. O

section 8
id pdf2json/2021.acl-long.395.pdf.json
for O
gpt-2 O
we O
use O
the O
gpt-2 O
small O
checkpoint O
( O
117m O
parameters O
) O
based O
on O
the O
implementation O
of O
huggingface O
( O
wolf O
et O
al. O
, O
2020 O
) O
. O

section 8
id pdf2json/2021.acl-long.395.pdf.json
decoding O
strategy O
. O

section 8
id pdf2json/2021.acl-long.395.pdf.json
in O
the O
inference O
stage O
, O
we O
adopt O
beam O
search O
decoding O
with O
a O
beam O
size O
of O
5 O
for O
all O
our O
models O
and O
all O
baselines O
we O
produce O
. O

section 8
id pdf2json/2021.acl-long.395.pdf.json
we O
used O
the O
following O
set O
of O
hyperparameters O
for O
our O
coins O
model O
: O
batch O
size O
: O
{ O
2 O
, O
4 O
} O
; O
epochs O
: O
{ O
3 O
, O
5 O
} O
; O
learning O
rate O
: O
{ O
1e-5 O
, O
5e-6 O
} O
. O

section 8
id pdf2json/2021.acl-long.395.pdf.json
we O
use O
adam O
optimizer O
, O
and O
dropout O
rate O
= O
0.1 O
. O

section 8
id pdf2json/2021.acl-long.395.pdf.json
we O
ran O
our O
experiments O
with O
gpu O
sizes O
of O
11gb O
and O
24gb O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
we O
compare O
our O
coins O
model O
to O
the O
following O
baselines O
: O
9the O
results O
for O
story O
ending O
generation O
will O
corroborate O
our O
results O
for O
nsc O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
all O
details O
are O
given O
in O
the O
appendix O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
( O
a O
) O
gpt-2 O
( O
radford O
et O
al. O
, O
2018 O
) O
( O
with O
12-layer O
, O
768-hidden O
, O
12-heads O
) O
, O
trained O
with O
an O
objective O
to O
predict O
the O
next O
word O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
the O
input O
to O
the O
gpt-2 O
model O
is O
the O
concatenation O
of O
the O
source O
and O
the O
target O
story O
sequence O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
we O
follow O
the O
standard O
procedure O
to O
fine-tune O
gpt-2 O
on O
the O
nsc O
task O
during O
training O
and O
minimize O
the O
loss O
function O
: O
−log O
( O
s3 O
, O
s4| O
[ O
sos O
] O
s1 O
, O
s2 O
, O
[ O
sep O
] O
, O
s5 O
[ O
eos O
] O
) O
( O
4 O
) O
( O
b O
) O
knowledge-enhanced O
gpt-2 O
( O
ke O
) O
( O
guan O
et O
al. O
, O
2020 O
) O
is O
the O
current O
sota O
for O
rocstories O
generation O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
it O
first O
fine-tunes O
a O
pre-trained O
gpt-2 O
( O
small O
) O
model O
with O
knowledge O
triples O
from O
commonsense O
datasets O
( O
conceptnet O
[ O
cn O
] O
speer O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
( O
2017 O
) O
and O
atomic O
[ O
at O
] O
sap O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
) O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
the O
knowledge O
triples O
were O
converted O
to O
sentences O
using O
templates O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
a O
multitask O
learning O
framework O
further O
fine-tunes O
this O
model O
on O
both O
the O
story O
ending O
generation O
task O
and O
classifying O
corrupted O
stories O
from O
real O
ones O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
as O
our O
baseline O
we O
choose O
the O
version O
without O
multi-tasking O
, O
since O
the O
corrupted O
story O
setting O
is O
not O
applicable O
for O
the O
nsc O
task O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
( O
c O
) O
grf O
( O
ji O
et O
al. O
, O
2020 O
) O
is O
the O
current O
sota O
for O
the O
abductive O
reasoning O
and O
the O
story O
ending O
generation O
tasks O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
grf O
enables O
pre-trained O
models O
( O
gpt-2 O
small O
) O
with O
dynamic O
multi-hop O
reasoning O
on O
multi-relational O
paths O
extracted O
from O
the O
external O
conceptnet O
commonsense O
knowledge O
graph O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
( O
d O
) O
glucose-gpt-2 O
similar O
to O
guan O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
, O
we O
fine-tune O
pretrained O
gpt-2 O
( O
small O
) O
on O
the O
glucose O
dataset O
using O
general O
rules O
( O
gr O
) O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
we O
follow O
the O
same O
procedure O
as O
guan O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
and O
( O
i O
) O
first O
fine-tune O
a O
pre-trained O
gpt-2 O
, O
but O
here O
on O
the O
glucose O
dataset O
, O
with O
the O
following O
loss O
: O
−log O
( O
ii|s O
, O
si O
, O
r O
) O
, O
( O
5 O
) O
where O
r O
: O
cause/effect O
, O
ii O
: O
inference O
rules O
. O

section 9
id pdf2json/2021.acl-long.395.pdf.json
( O
ii O
) O
then O
we O
fine-tune O
the O
above O
model O
again O
on O
the O
nsc O
dataset O
with O
the O
following O
loss O
: O
−log O
( O
s3 O
, O
s4| O
[ O
sos O
] O
s1 O
, O
s2 O
, O
[ O
sep O
] O
, O
s5 O
[ O
eos O
] O
) O
( O
6 O
) O
the O
main O
difference O
between O
glucose-gpt-2 O
and O
coins O
is O
: O
coins O
explicitly O
learns O
to O
generate O
( O
contextualized O
) O
inference O
rules O
on O
the O
fly O
during O
the O
inference O
step O
and O
incorporates O
them O
in O
the O
story O
generation O
step O
. O

section 10
id pdf2json/2021.acl-long.395.pdf.json
for O
automatic O
evaluation O
in O
the O
nsc O
task O
we O
use O
as O
metrics O
perplexity O
( O
indicates O
fluency O
of O
text O
generation O
) O
, O
bleu-1/2 O
( O
papineni O
et O
al. O
, O
2002 O
) O
and O
rougel O
( O
lin O
, O
2004 O
) O
. O

section 10
id pdf2json/2021.acl-long.395.pdf.json
we O
report O
performance O
on O
the O
test O
sets O
by O
averaging O
results O
obtained O
for O
5 O
different O
seeds O
. O

section 10
id pdf2json/2021.acl-long.395.pdf.json
all O
improvements O
across O
all O
model O
variants O
are O
statistically O
significant O
at O
p O
< O
0.05 O
) O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
our O
experimental O
results O
are O
summarised O
in O
tables O
4 O
and O
6 O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
nsc O
task O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
table O
4 O
shows O
the O
results O
for O
the O
models O
described O
in O
§6.3 O
and O
evaluated O
as O
per O
§6.4 O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
we O
observe O
the O
following O
: O
( O
i O
) O
coins O
outperforms O
all O
strong O
baseline O
models O
that O
utilize O
pre-trained O
language O
models O
and O
incorporate O
external O
commonsense O
knowledge O
with O
respect O
to O
all O
automatic O
evaluation O
metrics O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
note O
that O
glucose-gpt2 O
and O
coins O
are O
using O
the O
same O
knowledge O
resource O
, O
hence O
the O
clear O
performance O
increase O
of O
coins O
( O
+4.92 O
bleu O
score O
) O
indicates O
that O
jointly O
learning O
to O
generate O
contextualized O
inferences O
rules O
and O
missing O
sentences O
in O
a O
recursive O
manner O
can O
enhance O
generation O
quality.10 O
( O
ii O
) O
similar O
to O
ji O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
we O
observe O
that O
fine-tuning O
gpt2 O
over O
knowledge O
triples O
( O
[ O
cn O
] O
, O
[ O
at O
] O
omic O
or O
[ O
gl O
] O
ucose O
) O
doesn O
’ O
t O
improve O
the O
overall O
performance O
by O
much O
( O
table O
4 O
, O
line O
2 O
: O
[ O
cn+at O
] O
vs. O
line O
3 O
: O
[ O
gl O
] O
vs. O
line O
1 O
: O
[ O
no O
csk O
] O
) O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
( O
iii O
) O
for O
coins O
, O
general O
rules O
( O
gr O
) O
boost O
performance O
more O
than O
specific O
rules O
, O
indicating O
that O
the O
sentence O
generation O
model O
generalizes O
well O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
( O
iv O
) O
in O
the O
oracle O
settings O
at O
inference O
time O
we O
provide O
the O
model O
with O
the O
silver O
inference O
rules O
( O
generated O
as O
per O
§4 O
) O
that O
use O
the O
complete O
story O
context O
as O
background O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
the O
result O
indicates O
that O
sr O
performs O
better O
than O
gr O
when O
the O
model O
sees O
the O
full O
story O
context O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
in O
general O
we O
observe O
that O
story O
generation O
benefits O
from O
higher-quality O
, O
contextualized O
inference O
10since O
grf O
’ O
s O
architecture O
is O
specific O
for O
conceptnet O
, O
we O
can O
not O
exclude O
that O
the O
better O
performance O
of O
coins O
( O
+2.2 O
bleu O
) O
is O
in O
part O
due O
to O
differences O
in O
the O
used O
knowledge O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
rules O
from O
glucose O
( O
for O
coins O
) O
.11 O
the O
improvement O
of O
coins O
over O
glucose-gpt-2 O
indicates O
that O
our O
model O
is O
well O
able O
to O
utilize O
and O
profit O
from O
the O
inference O
rules O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
in O
the O
oracle O
setting O
, O
sr O
performs O
much O
better O
than O
gr O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
this O
is O
expected O
, O
since O
oracle O
rules O
with O
access O
to O
the O
full O
context O
will O
deliver O
more O
contextually-relevant O
inferences O
, O
while O
gr O
rules O
may O
diverge O
more O
from O
the O
story O
context O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
however O
, O
in O
the O
realistic O
nsc O
task O
setting O
( O
table O
4 O
, O
lines O
5,6 O
) O
gr O
outperforms O
sr O
, O
which O
again O
underlines O
the O
generalization O
capacities O
of O
coins O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
impact O
of O
different O
inputs O
for O
the O
generation O
step O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
in O
table O
5 O
we O
investigate O
the O
performance O
of O
coins O
with O
different O
inputs O
to O
the O
sentence O
generation O
component O
at O
inference O
time O
: O
( O
i O
) O
when O
only O
inference O
rules O
( O
from O
the O
inference O
step O
) O
are O
given O
to O
the O
model O
without O
any O
story O
context O
( O
s′ O
= O
{ O
s1 O
, O
s2 O
, O
[ O
sep O
] O
, O
sn O
} O
) O
( O
ir O
only O
) O
, O
sentence O
generation O
benefits O
when O
specific O
rules O
are O
used O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
this O
is O
expected O
since O
the O
specific O
rules O
contain O
statements O
with O
concrete O
character O
names O
and O
paraphrased O
events O
from O
the O
story O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
( O
ii O
) O
when O
only O
the O
story O
beginning O
( O
s1,2 O
) O
is O
provided O
to O
the O
sentence O
generation O
model O
without O
the O
ending O
sentence O
sn O
( O
w/ose O
) O
nor O
inference O
rules O
( O
w/oir O
) O
we O
observe O
that O
the O
performance O
drops O
compared O
to O
models O
given O
the O
full O
incomplete O
context O
( O
s′ O
) O
, O
indicating O
that O
knowing O
the O
story O
ending O
helps O
the O
model O
to O
generate O
missing O
sentences O
that O
are O
coherent O
with O
the O
story O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
however O
, O
( O
iii O
) O
when O
adding O
inference O
rules O
ir O
( O
from O
the O
inference O
step O
i.e. O
, O
ei O
+ O
ci O
) O
to O
the O
context O
( O
s1,2 O
) O
without O
ending O
sentence O
( O
w/ose O
) O
, O
performance O
again O
improves O
( O
+5.85 O
bleu O
scores O
) O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
note O
that O
the O
inference O
rule O
contains O
the O
cause O
relation O
for O
sn O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
this O
indicates O
that O
the O
model O
is O
able O
to O
utilize O
inference O
rules O
for O
story O
generation.12 O
11automatic O
( O
silver O
) O
glucose O
inference O
rules O
( O
cf O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
§4 O
) O
of O
type O
gr O
yield O
60.8 O
bleu O
score O
i.e. O
, O
performance O
of O
csigen O
( O
avg O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
of O
both O
relation O
types O
) O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
12here O
, O
we O
report O
the O
results O
with O
generalized O
rules O
as O
gr O
works O
better O
than O
sr O
when O
context O
is O
given O
( O
cf O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
table O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
4 O
) O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
performance O
of O
inference O
rule O
generation O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
we O
now O
investigate O
how O
difficult O
it O
is O
to O
generate O
contextualized O
inference O
rules O
( O
specific O
and O
general O
) O
when O
multiple O
sentences O
are O
missing O
from O
a O
story O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
for O
this O
we O
compare O
coins O
to O
a O
gpt-2 O
model O
fine-tuned O
on O
glucose O
data O
to O
generate O
inference O
rules O
( O
cf O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
§4 O
) O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
we O
study O
the O
impact O
of O
jointly O
and O
dynamically O
learning O
sentence O
and O
inference O
rule O
generation O
( O
in O
coins O
) O
on O
the O
inference O
generation O
task O
– O
while O
the O
fine-tuned O
gpt-2 O
model O
only O
learns O
to O
generate O
inference O
rules O
conditioned O
on O
the O
static O
story O
context O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
we O
specifically O
examine O
the O
difficulty O
of O
generating O
inference O
rules O
for O
two O
consecutive O
sentences O
( O
s3 O
and O
s4 O
) O
in O
a O
5-sentence O
context O
, O
as O
opposed O
to O
shorter O
sequences O
, O
in O
three O
different O
scenarios O
: O
i O
) O
when O
the O
complete O
story O
context O
s O
is O
given O
; O
ii O
) O
when O
the O
incomplete O
context O
s′ O
( O
i.e. O
, O
s1 O
, O
s2 O
and O
s5 O
) O
is O
given O
, O
plus O
either O
s3 O
or O
s4 O
( O
1-missing O
sentence O
) O
, O
and O
iii O
) O
when O
s′ O
is O
given O
, O
but O
neither O
of O
the O
intermediate O
sentences O
s3 O
and O
s4 O
( O
2-missing O
sentences O
) O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
in O
each O
setting O
, O
we O
generate O
effect O
and O
cause O
rules O
for O
the O
targeted O
sentences O
s3 O
, O
s4 O
, O
and O
compare O
their O
quality O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
the O
results O
are O
reported O
in O
table O
6 O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
we O
observe O
that O
in O
the O
2-missing O
sentences O
setting O
, O
coins O
outperforms O
gpt-2 O
( O
by O
+2.3 O
bleu O
score O
on O
average O
) O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
this O
indicates O
that O
learning O
to O
perform O
inference O
rule O
generation O
jointly O
with O
sentence O
generation O
is O
beneficial O
for O
filling-in O
multiple O
story O
sentences O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
interestingly O
, O
for O
increasing O
numbers O
of O
missing O
sentences O
, O
performance O
drops O
drastically O
for O
cause O
( O
as O
opposed O
to O
effect O
) O
, O
but O
less O
so O
for O
coins O
as O
opposed O
to O
gpt-2 O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
a O
possible O
reason O
for O
this O
may O
be O
the O
conditional O
, O
uni-directional O
nature O
of O
the O
underlying O
gpt-2 O
language O
model O
, O
which O
is O
trained O
to O
predict O
follow-up O
words O
in O
forward O
direction O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
this O
may O
favor O
future-directed O
effect O
rules O
– O
as O
opposed O
to O
cause O
relations O
. O

section 11
id pdf2json/2021.acl-long.395.pdf.json
the O
milder O
effect O
on O
coins O
could O
indicate O
that O
the O
concurrent O
inference O
model O
supports O
the O
sentence O
generation O
model O
to O
overcome O
this O
weakness.13 O

section 12
id pdf2json/2021.acl-long.395.pdf.json
automatic O
metrics O
can O
give O
us O
some O
indication O
of O
nlg O
quality O
, O
however O
, O
these O
metrics O
do O
not O
necessarily O
reflect O
the O
coherence O
of O
generated O
story O
sentences O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
thus O
conduct O
a O
human O
evaluation O
focusing O
on O
the O
grammaticality O
and O
coherence O
of O
the O
generated O
sentences O
in O
their O
story O
context O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
13in O
future O
work O
, O
we O
will O
test O
the O
above O
hypothesis O
by O
experimenting O
with O
a O
bi-directional O
transformer O
generation O
model O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
conduct O
pairwise O
comparisons O
for O
randomly O
sampled O
100 O
instances O
of O
our O
best O
model O
, O
i.e. O
, O
coins O
with O
gr O
( O
according O
to O
automatic O
metrics O
) O
with O
four O
strong O
baseline O
models O
( O
gpt-2 O
, O
glucosegpt-2 O
, O
grf O
, O
ke O
) O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
for O
each O
pair O
of O
instances O
( O
one O
from O
coins O
, O
the O
other O
from O
a O
baseline O
model O
) O
, O
we O
present O
the O
generated O
sentences O
in O
their O
story O
context O
, O
and O
asked O
three O
annotators O
to O
give O
a O
preference O
rating O
( O
win O
, O
tie O
, O
lose O
) O
according O
to O
the O
criteria O
grammaticality O
and O
coherence O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
for O
grammaticality O
, O
we O
present O
each O
sentence O
in O
isolation O
and O
ask O
the O
annotators O
to O
rate O
which O
sentence O
is O
more O
fluent O
, O
readable O
, O
and O
compliant O
with O
the O
english O
standard O
usage O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
for O
coherence O
, O
we O
ask O
the O
annotators O
to O
assess O
which O
of O
the O
two O
generated O
sentences O
are O
more O
logically O
coherent O
with O
each O
other O
and O
the O
story O
beginning O
and O
ending O
, O
in O
terms O
of O
causal O
and O
temporal O
dependencies O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
applied O
majority O
voting O
among O
the O
three O
annotators O
to O
obtain O
final O
decisions O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
more O
details O
about O
the O
annotation O
are O
given O
in O
appendix O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
the O
human O
evaluation O
results O
are O
presented O
in O
table O
7.14 O
the O
results O
show O
that O
our O
model O
produces O
more O
coherent O
and O
more O
grammatically O
correct O
sentences O
compared O
to O
all O
baselines O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
this O
indicates O
that O
with O
support O
of O
learned O
contextualized O
inference O
rules O
based O
on O
glucose O
knowledge O
, O
our O
model O
generates O
more O
coherent O
story O
sentences O
that O
are O
causally O
and O
temporally O
well O
connected O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
relevance O
of O
generated O
inferences O
rules O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
further O
conduct O
human O
evaluation O
to O
validate O
the O
effectiveness O
and O
relevance O
of O
the O
generated O
inference O
rules O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
randomly O
select O
50 O
instances O
from O
the O
nsc O
dev O
set O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
asked O
three O
annotators O
to O
evaluate O
the O
( O
gr O
) O
inference O
rules15 O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
define O
an O
inference O
rule O
to O
be O
relevant O
if O
( O
a O
) O
it O
captures O
im- O
14we O
report O
inter-annotator O
agreement O
scores O
calculated O
with O
fless O
’ O
kappa O
κ O
( O
fleiss O
, O
1971 O
) O
, O
calculated O
for O
each O
comparison O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
find O
moderate O
or O
fair O
agreement O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
15we O
report O
only O
coins O
( O
gr O
) O
, O
our O
best O
model O
according O
to O
automatic O
metrics O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
plicit O
causes O
and O
effects O
of O
a O
selected O
sentence O
x O
given O
an O
incomplete O
story O
s′ O
, O
and O
( O
b O
) O
it O
is O
providing O
useful O
explanations O
for O
the O
incomplete O
story O
s′ O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
the O
result O
for O
this O
evaluation O
is O
shown O
in O
fig.3 O
, O
for O
effect O
and O
cause O
relations O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
find O
that O
in O
36 O
% O
and O
34 O
% O
of O
cases O
for O
effects O
and O
causes O
, O
respectively O
( O
computed O
on O
the O
basis O
of O
majority O
agreement O
) O
, O
our O
algorithm O
was O
able O
to O
generate O
relevant O
inference O
rules O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
our O
annotations O
yielded O
fair O
inter-annotator O
agreement O
of O
fleiss O
’ O
κ O
= O
0.45 O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
case O
study O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
provide O
an O
example O
from O
nsc O
with O
different O
generation O
outputs O
( O
table O
8 O
) O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
note O
that O
the O
generated O
sentences O
are O
grounded O
to O
the O
inference O
rules O
obtained O
from O
the O
inference O
step O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
hence O
, O
the O
rules O
provide O
both O
an O
intermediate O
representation O
and O
explanations O
for O
how O
knowledge O
can O
guide O
or O
influence O
story O
generation O
. O

section 12
id pdf2json/2021.acl-long.395.pdf.json
we O
provide O
more O
qualitative O
examples O
in O
the O
appendix O
. O

section 13
id pdf2json/2021.acl-long.395.pdf.json
we O
addressed O
a O
narrative O
story O
completion O
task O
that O
allows O
us O
to O
probe O
the O
coherence O
capabilities O
of O
a O
neural O
generation O
model O
. O

section 13
id pdf2json/2021.acl-long.395.pdf.json
we O
proposed O
coins O
, O
a O
model O
that O
iteratively O
generates O
commonsense O
inference O
rules O
grounded O
in O
the O
context O
and O
generates O
story O
sentences O
, O
using O
the O
generated O
inferences O
as O
a O
guide O
. O

section 13
id pdf2json/2021.acl-long.395.pdf.json
human O
and O
automatic O
eval- O
uations O
show O
that O
the O
model O
outperforms O
strong O
commonsense O
knowledge-based O
generation O
models O
. O

section 13
id pdf2json/2021.acl-long.395.pdf.json
by O
individuating O
the O
inference O
rule O
and O
sentence O
generation O
steps O
, O
coins O
can O
make O
the O
contribution O
of O
commonsense O
knowledge O
on O
story O
generation O
transparent O
. O

section 13
id pdf2json/2021.acl-long.395.pdf.json
the O
recursive O
nature O
of O
the O
inference-driven O
generation O
model O
holds O
potential O
for O
knowledge-driven O
control O
in O
the O
generation O
of O
longer O
sequences O
. O

section 13
id pdf2json/2021.acl-long.395.pdf.json
in O
future O
work O
we O
will O
explore O
how O
an O
enhanced O
memory O
of O
generated O
inferences O
can O
realize O
more O
complex O
narrative O
patterns O
that O
diverge O
from O
strictly O
ordered O
narrative O
sequences O
. O

section 14
id pdf2json/2021.acl-long.395.pdf.json
this O
work O
has O
been O
supported O
by O
the O
german O
research O
foundation O
as O
part O
of O
the O
research O
training O
group O
“ O
adaptive O
preparation O
of O
information O
from O
heterogeneous O
sources O
” O
( O
aiphes O
) O
under O
grant O
no O
. O

section 14
id pdf2json/2021.acl-long.395.pdf.json
grk O
1994/1 O
. O

section 14
id pdf2json/2021.acl-long.395.pdf.json
we O
thank O
our O
annotators O
for O
their O
valuable O
annotations O
. O

section 14
id pdf2json/2021.acl-long.395.pdf.json
we O
also O
thank O
nvidia O
corporation O
for O
donating O
gpus O
used O
in O
this O
research O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
a.1 O
manual O
evaluation O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
we O
perform O
an O
error O
analysis O
to O
better O
understand O
the O
generation O
quality O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
we O
ask O
our O
annotators O
to O
assess O
whether O
the O
generated O
text O
contains O
any O
pieces O
of O
information O
that O
are O
contradicting O
the O
given O
incomplete O
story O
or O
not O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
our O
annotations O
were O
performed O
by O
three O
annotators O
with O
a O
linguistic O
background O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
figure O
5 O
, O
shows O
a O
screenshot O
of O
the O
annotation O
guidelines O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
figure O
4 O
depicts O
the O
result O
, O
we O
observe O
the O
that O
our O
coins O
models O
produce O
less O
contradicting O
missing O
sentences O
compare O
to O
other O
baselines O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
a.2 O
hyperparameter O
details O
parameter O
size O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
for O
gpt-2 O
we O
use O
the O
gpt-2 O
small O
checkpoint O
( O
117m O
parameters O
) O
based O
on O
the O
implementation O
of O
huggingface O
( O
wolf O
et O
al. O
, O
2020 O
) O
at O
: O
https O
: O
//github.com/huggingface/transformers/ O
tree/master/src/transformers/models/gpt2 O
decoding O
strategy O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
in O
the O
inference O
stage O
, O
we O
adopt O
beam O
search O
decoding O
with O
a O
beam O
size O
of O
5 O
for O
all O
our O
models O
and O
all O
baselines O
we O
produce O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
we O
used O
the O
following O
set O
of O
hyperparameters O
for O
our O
coins O
model O
: O
batch O
size O
: O
{ O
2 O
, O
4 O
} O
; O
epochs O
: O
{ O
3 O
, O
5 O
} O
; O
learning O
rate O
: O
{ O
1e-5 O
, O
5e-6 O
} O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
we O
use O
adam O
optimizer O
, O
and O
dropout O
rate O
= O
0.1 O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
we O
ran O
our O
experiments O
with O
gpu O
sizes O
of O
11gb O
and O
24gb O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
training O
details O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
our O
training O
time O
is O
≈24 O
hours O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
the O
original O
rocstories O
corpus O
can O
be O
found O
at O
: O
https O
: O
//cs.rochester.edu/nlp/ O
rocstories/ O
a.3 O
story O
ending O
generation O
task O
data O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
this O
task O
is O
to O
generate O
a O
reasonable O
ending O
given O
a O
four-sentence O
story O
context O
( O
guan O
et O
al. O
, O
2019 O
) O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
the O
stories O
are O
from O
rocstories O
( O
mostafazadeh O
et O
al. O
, O
2016 O
) O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
we O
use O
the O
same O
data O
splits O
as O
guan O
et O
al O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
( O
2019 O
) O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
seg O
task O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
we O
also O
investigate O
how O
coins O
performs O
when O
applied O
to O
the O
task O
of O
generating O
a O
story O
ending O
when O
given O
a O
4-sentence O
story O
( O
seg O
) O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
in O
this O
task O
our O
model O
takes O
only O
one O
iteration O
step O
to O
generate O
the O
story O
ending O
, O
where O
in O
the O
inference O
step O
it O
generates O
effect O
inference O
rules O
for O
sentence O
( O
s4 O
) O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
as O
seen O
in O
table O
9 O
, O
the O
coins O
model O
outperforms O
all O
previous O
strong O
baselines O
, O
including O
gpt2-glucose O
that O
uses O
the O
same O
knowledge O
resource O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
interestingly O
, O
we O
also O
observe O
that O
fine-tuning O
on O
glucose O
or O
conceptnet O
knowledge O
improves O
the O
text O
generation O
diversity O
, O
indicating O
that O
the O
models O
leverage O
concepts O
and O
event O
knowledge O
during O
generation O
( O
cf O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
table O
9 O
line.4-8 O
) O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
automatic O
metrics O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
for O
story O
ending O
generation O
( O
seg O
) O
we O
follow O
the O
metrics O
used O
in O
guan O
et O
al O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
( O
2019 O
) O
; O
ji O
et O
al O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
( O
2020 O
) O
: O
they O
use O
bleu-1/2 O
to O
measure O
n-gram O
overlap O
between O
generated O
and O
human-written O
story O
endings O
, O
and O
distinct-n O
( O
li O
et O
al. O
, O
2016 O
) O
to O
measure O
the O
generation O
diversity O
using O
maximum O
mutual O
information O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
baselines O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
for O
the O
story O
ending O
generation O
task O
, O
we O
compare O
coins O
to O
the O
ie+ga O
model O
( O
guan O
et O
al. O
, O
2019 O
) O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
it O
is O
based O
on O
incremental O
encoding O
and O
multi-source O
graph O
attention O
( O
guan O
et O
al. O
, O
2019 O
) O
. O

section 15
id pdf2json/2021.acl-long.395.pdf.json
we O
also O
compare O
to O
a O
seq2seq O
model O
( O
luong O
et O
al. O
, O
2015 O
) O
based O
on O
gated O
recurrent O
units O
( O
gru O
) O
and O
attention O
mechanism O
. O

section TITLE
id pdf2json/2021.acl-long.96.pdf.json
can O
vectors O
read O
minds O
better O
than O
experts O
? O

section TITLE
id pdf2json/2021.acl-long.96.pdf.json
comparing O
data O
augmentation O
strategies O
for O
the O
automated O
scoring O
of O
children O
’ O
s O
mindreading O
ability O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
in O
this O
paper O
we O
implement O
and O
compare O
7 O
different O
data O
augmentation O
strategies O
for O
the O
task O
of O
automatic O
scoring O
of O
children O
’ O
s O
ability O
to O
understand O
others O
’ O
thoughts O
, O
feelings O
, O
and O
desires O
( O
or O
“ O
mindreading O
” O
) O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
we O
recruit O
in-domain O
experts O
to O
re-annotate O
augmented O
samples O
and O
determine O
to O
what O
extent O
each O
strategy O
preserves O
the O
original O
rating O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
carry O
out O
multiple O
experiments O
to O
measure O
how O
much O
each O
augmentation O
strategy O
improves O
the O
performance O
of O
automatic O
scoring O
systems O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
to O
determine O
the O
capabilities O
of O
automatic O
systems O
to O
generalize O
to O
unseen O
data O
, O
we O
create O
uk-mind-20 O
a O
new O
corpus O
of O
children O
’ O
s O
performance O
on O
tests O
of O
mindreading O
, O
consisting O
of O
10,320 O
question-answer O
pairs O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
we O
obtain O
a O
new O
state-of-the-art O
performance O
on O
the O
mind-ca O
corpus O
, O
improving O
macrof1-score O
by O
6 O
points O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
results O
indicate O
that O
both O
the O
number O
of O
training O
examples O
and O
the O
quality O
of O
the O
augmentation O
strategies O
affect O
the O
performance O
of O
the O
systems O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
the O
taskspecific O
augmentations O
generally O
outperform O
task-agnostic O
augmentations O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
automatic O
augmentations O
based O
on O
vectors O
( O
glove O
, O
fasttext O
) O
perform O
the O
worst O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
we O
find O
that O
systems O
trained O
on O
mind-ca O
generalize O
well O
to O
uk-mind-20 O
. O

section ABSTRACT
id pdf2json/2021.acl-long.96.pdf.json
we O
demonstrate O
that O
data O
augmentation O
strategies O
also O
improve O
the O
performance O
on O
unseen O
data O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
1196–1206 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
©2021 O
association O
for O
computational O
linguistics O
1196 O
we O
recruit O
in-domain O
experts O
to O
re-annotate O
augmented O
samples O
and O
determine O
to O
what O
extent O
each O
strategy O
preserves O
the O
original O
rating O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
carry O
out O
multiple O
experiments O
to O
measure O
how O
much O
each O
augmentation O
strategy O
improves O
the O
performance O
of O
automatic O
scoring O
systems O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
to O
determine O
the O
capabilities O
of O
automatic O
systems O
to O
generalize O
to O
unseen O
data O
, O
we O
create O
uk-mind-20 O
- O
a O
new O
corpus O
of O
children O
’ O
s O
performance O
on O
tests O
of O
mindreading O
, O
consisting O
of O
10,320 O
question-answer O
pairs O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
we O
obtain O
a O
new O
state-of-the-art O
performance O
on O
the O
mind-ca O
corpus O
, O
improving O
macrof1-score O
by O
6 O
points O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
results O
indicate O
that O
both O
the O
number O
of O
training O
examples O
and O
the O
quality O
of O
the O
augmentation O
strategies O
affect O
the O
performance O
of O
the O
systems O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
the O
taskspecific O
augmentations O
generally O
outperform O
task-agnostic O
augmentations O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
automatic O
augmentations O
based O
on O
vectors O
( O
glove O
, O
fasttext O
) O
perform O
the O
worst O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
we O
find O
that O
systems O
trained O
on O
mind-ca O
generalize O
well O
to O
uk-mind-20 O
. O

section 0
id pdf2json/2021.acl-long.96.pdf.json
we O
demonstrate O
that O
data O
augmentation O
strategies O
also O
improve O
the O
performance O
on O
unseen O
data O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
many O
state-of-the-art O
nlp O
models O
are O
limited O
by O
the O
availability O
of O
high O
quality O
human-annotated O
training O
data O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
the O
process O
of O
gathering O
and O
annotating O
additional O
data O
is O
often O
expensive O
and O
time O
consuming O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
it O
is O
especially O
difficult O
to O
gather O
data O
for O
tasks O
within O
psychology O
and O
psycholinguistics O
, O
as O
test O
administration O
typically O
requires O
highly O
trained O
in-domain O
experts O
, O
controlled O
environments O
, O
and O
large O
numbers O
of O
human O
participants O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
data O
augmentation O
is O
a O
popular O
technique O
for O
artificially O
enlarging O
datasets O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
typically O
, O
data O
augmentation O
uses O
one O
or O
more O
predefined O
strategies O
to O
modify O
existing O
gold-standard O
examples O
while O
retaining O
the O
original O
label O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
the O
objectives O
of O
data O
augmentation O
are O
: O
1 O
) O
to O
increase O
the O
size O
of O
the O
dataset O
; O
2 O
) O
to O
introduce O
more O
variety O
; O
3 O
) O
to O
reduce O
overfitting O
; O
and O
4 O
) O
to O
improve O
generalizability O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
data O
augmentation O
has O
been O
used O
successfully O
in O
computer O
vision O
( O
shorten O
and O
khoshgoftaar O
, O
2019 O
) O
and O
has O
recently O
become O
more O
popular O
in O
the O
field O
of O
nlp O
( O
wei O
and O
zou O
, O
2019 O
; O
min O
et O
al. O
, O
2020 O
; O
dai O
and O
adel O
, O
2020 O
; O
marivate O
and O
sefara O
, O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
we O
use O
data O
augmentation O
to O
improve O
the O
performance O
of O
systems O
for O
automatic O
scoring O
of O
children O
’ O
s O
performance O
on O
tests O
of O
mindreading O
( O
i.e. O
, O
the O
ability O
to O
reason O
about O
others O
’ O
thoughts O
, O
feelings O
and O
desires O
) O
( O
hughes O
and O
devine O
, O
2015 O
) O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
automatic O
scoring O
of O
mindreading O
was O
recently O
introduced O
by O
kovatchev O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
their O
corpus O
, O
mind-ca O
contains O
hand-scored O
data O
from O
more O
than O
1000 O
children O
aged O
7 O
to O
14 O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
collecting O
data O
on O
children O
’ O
s O
mindreading O
performance O
is O
complicated O
, O
time-consuming O
, O
and O
expensive O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
it O
requires O
in-person O
testing O
sessions O
led O
by O
trained O
researchers O
and O
children O
’ O
s O
open-ended O
responses O
must O
be O
rated O
by O
trained O
annotators O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
data O
augmentation O
could O
be O
very O
beneficial O
to O
improve O
the O
performance O
and O
consistency O
of O
the O
automated O
scoring O
systems O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
in O
this O
paper O
we O
aim O
to O
measure O
, O
in O
a O
systematic O
way O
, O
the O
quality O
and O
efficiency O
of O
the O
different O
augmentation O
strategies O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
we O
evaluate O
and O
compare O
the O
different O
strategies O
intrinsically O
and O
extrinsically O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
for O
the O
intrinsic O
evaluation O
, O
we O
recruit O
in-domain O
experts O
to O
re-annotate O
augmented O
examples O
and O
determine O
the O
extent O
to O
which O
each O
strategy O
preserves O
the O
original O
label O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
for O
the O
extrinsic O
evaluation O
, O
we O
measure O
the O
quantitative O
improvement O
( O
macro-f1 O
, O
f1-per-question O
, O
standard O
deviation O
) O
of O
automatic O
systems O
on O
the O
mind-ca O
corpus O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
furthermore O
, O
we O
create O
a O
new O
corpus O
, O
uk-mind-20 O
, O
containing O
10,320 O
question-answer O
pairs O
in O
english O
and O
we O
use O
it O
to O
evaluate O
the O
performance O
of O
automated O
systems O
on O
unseen O
data O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
we O
find O
that O
the O
intrinsic O
“ O
quality O
” O
of O
the O
augmentation O
strategies O
varies O
significantly O
, O
according O
to O
human O
raters O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
however O
, O
the O
extrinsic O
evaluation O
demonstrates O
that O
all O
strategies O
improve O
the O
performance O
of O
the O
automated O
systems O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
we O
systematically O
measure O
the O
importance O
of O
three O
factors O
in O
data O
augmentation O
: O
corpus O
size O
, O
sampling O
strategy O
, O
and O
augmentation O
strategy O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
we O
find O
corpus O
size O
to O
be O
the O
most O
important O
factor O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
however O
, O
the O
choice O
of O
sampling O
and O
augmentation O
strategies O
also O
significantly O
affects O
the O
performance O
of O
the O
automated O
systems O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
we O
report O
a O
correlation O
between O
the O
“ O
quality O
” O
of O
the O
augmentation O
and O
the O
performance O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
with O
the O
best O
configuration O
we O
obtain O
a O
new O
state-of-theart O
on O
mind-ca O
, O
improving O
macro-f1 O
score O
by O
6 O
points O
and O
f1-per-question O
by O
10.3 O
points O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
we O
demonstrate O
that O
the O
automated O
scoring O
systems O
can O
generalize O
well O
between O
mind-ca O
and O
uk-mind-20 O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
these O
findings O
indicate O
that O
the O
methodology O
for O
administering O
and O
scoring O
mindreading O
is O
consistent O
and O
the O
automatic O
solutions O
can O
be O
adopted O
in O
practice O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
the O
rest O
of O
this O
article O
is O
organized O
as O
follows O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
section O
2 O
discusses O
the O
related O
work O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
section O
3 O
presents O
the O
methodologies O
for O
data O
augmentation O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
section O
4 O
compares O
the O
quality O
of O
the O
augmentation O
strategies O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
section O
5 O
describes O
the O
machine O
learning O
experimental O
setup O
and O
evaluation O
criteria O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
section O
6 O
analyzes O
the O
effect O
of O
data O
augmentation O
on O
automated O
systems O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
section O
7 O
presents O
some O
follow-up O
experiments O
and O
discusses O
the O
implications O
of O
the O
findings O
. O

section 1
id pdf2json/2021.acl-long.96.pdf.json
section O
8 O
concludes O
the O
article O
and O
proposes O
directions O
for O
future O
work O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
mindreading O
( O
also O
known O
as O
“ O
theory O
of O
mind O
” O
) O
is O
the O
ability O
to O
understand O
others O
’ O
thoughts O
, O
feelings O
, O
and O
desires O
( O
hughes O
and O
devine O
, O
2015 O
) O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
for O
example O
, O
in O
the O
final O
scene O
of O
romeo O
and O
juliet O
, O
romeo O
holds O
a O
mistaken O
belief O
that O
juliet O
is O
dead O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
being O
able O
to O
understand O
the O
state O
of O
the O
world O
( O
“ O
juliet O
is O
alive O
” O
) O
and O
the O
mistaken O
belief O
( O
“ O
juliet O
is O
dead O
” O
) O
is O
important O
to O
understand O
the O
situation O
and O
the O
motivation O
of O
the O
characters O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
individual O
differences O
in O
children O
’ O
s O
mindreading O
are O
linked O
with O
both O
social O
and O
academic O
outcomes O
and O
children O
’ O
s O
wellbeing O
( O
banerjee O
et O
al. O
, O
2011 O
; O
fink O
et O
al. O
, O
2015 O
; O
devine O
et O
al. O
, O
2016 O
) O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
furthermore O
, O
difficulties O
with O
mindreading O
are O
linked O
with O
a O
range O
of O
mental O
health O
problems O
and O
neurodevelopmental O
conditions O
( O
cotter O
et O
al. O
, O
2018 O
) O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
the O
task O
of O
automatic O
scoring O
of O
mindreading O
was O
first O
proposed O
by O
kovatchev O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
they O
gathered O
the O
responses O
of O
1066 O
children O
aged O
7- O
14 O
on O
two O
standardized O
tests O
of O
mindreading O
: O
the O
strange O
story O
task O
( O
happé O
, O
1994 O
) O
and O
the O
silent O
film O
task O
( O
devine O
and O
hughes O
, O
2013 O
) O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
after O
digitalizing O
and O
manually O
scoring O
the O
responses O
, O
they O
created O
mind-ca O
, O
a O
corpus O
of O
11,311 O
questionanswer O
pairs O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
they O
trained O
and O
evaluated O
several O
automated O
systems O
( O
i.e. O
, O
svm O
, O
bilstm O
, O
transformer O
) O
and O
obtained O
promising O
initial O
results O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
data O
augmentation O
is O
a O
technique O
for O
artificially O
increasing O
the O
size O
of O
the O
dataset O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
it O
can O
also O
be O
seen O
as O
a O
type O
of O
regularization O
at O
the O
level O
of O
the O
data O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
data O
augmentation O
can O
be O
used O
to O
increase O
the O
number O
of O
instances O
of O
specific O
answer O
types O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
it O
can O
also O
introduce O
more O
variety O
, O
and O
can O
reduce O
the O
imbalance O
between O
classes O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
data O
augmentation O
is O
used O
to O
improve O
the O
performance O
of O
automated O
systems O
, O
to O
reduce O
the O
risk O
of O
overfitting O
, O
and O
to O
enhance O
the O
ability O
of O
automated O
systems O
to O
generalize O
to O
unseen O
data O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
it O
is O
widely O
used O
in O
computer O
vision O
( O
shorten O
and O
khoshgoftaar O
, O
2019 O
) O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
the O
specifics O
of O
natural O
languages O
make O
it O
more O
difficult O
to O
incorporate O
data O
augmentation O
in O
nlp O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
a O
subtle O
change O
to O
the O
text O
can O
often O
lead O
to O
a O
substantial O
difference O
in O
meaning O
and O
a O
change O
of O
the O
label O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
the O
last O
two O
years O
have O
seen O
an O
increase O
in O
the O
popularity O
of O
data O
augmentation O
in O
nlp O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
wei O
and O
zou O
( O
2019 O
) O
present O
a O
python O
library O
that O
uses O
simple O
augmentation O
methods O
for O
improving O
text O
classification O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
marivate O
and O
sefara O
( O
2020 O
) O
compare O
different O
strategies O
for O
augmentation O
in O
the O
context O
of O
short-text O
classification O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
dai O
and O
adel O
( O
2020 O
) O
compare O
different O
data O
augmentation O
strategies O
for O
the O
task O
of O
named O
entity O
recognition O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
several O
researchers O
propose O
more O
complex O
augmentation O
strategies O
for O
nlp O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
hou O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
( O
2018 O
) O
propose O
a O
sequence-to-sequence O
model O
for O
data O
augmentation O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
kobayashi O
( O
2018 O
) O
and O
gao O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
( O
2019 O
) O
use O
language O
models O
in O
what O
they O
call O
“ O
contextual O
augmentation O
” O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
min O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
use O
syntactic O
augmentation O
to O
improve O
the O
performance O
and O
generalizability O
on O
natural O
language O
inference O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
in O
this O
paper O
, O
we O
take O
a O
different O
approach O
towards O
data O
augmentation O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
we O
implement O
and O
compare O
seven O
different O
augmentation O
strategies O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
two O
of O
the O
strategies O
were O
designed O
specifically O
for O
the O
task O
of O
automatic O
scoring O
of O
mindreading O
, O
while O
the O
remaining O
five O
are O
task O
agnostic O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
we O
put O
the O
emphasis O
on O
a O
systematic O
evaluation O
of O
the O
augmentation O
strategies O
and O
some O
key O
parameters O
of O
the O
augmentation O
process O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
we O
recruit O
and O
train O
in-domain O
experts O
to O
provide O
intrinsic O
human O
evaluation O
of O
the O
data O
augmentation O
. O

section 2
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
annotate O
a O
new O
corpus O
that O
can O
measure O
the O
performance O
and O
improvement O
on O
unseen O
data O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
we O
used O
7 O
different O
strategies O
for O
automatic O
data O
augmentation O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
“ O
dictionary O
” O
and O
“ O
phrase O
” O
strategies O
make O
use O
of O
task-specific O
resources O
, O
created O
by O
in-domain O
experts O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
the O
other O
5 O
strategies O
( O
“ O
order O
” O
, O
“ O
wordnet O
” O
, O
“ O
ppdb O
” O
, O
“ O
glove O
” O
, O
“ O
fasttext O
” O
) O
make O
use O
of O
publicly O
available O
task-agnostic O
resources O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
for O
a O
source O
of O
the O
augmentation O
, O
we O
used O
the O
mind-ca O
corpus O
( O
kovatchev O
et O
al. O
, O
2020 O
) O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
it O
contains O
11,311 O
question-answer O
pairs O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
there O
are O
11 O
different O
questions O
, O
and O
an O
average O
of O
1,028 O
responses O
per O
question O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
there O
are O
three O
possible O
labels O
reflecting O
the O
degree O
to O
which O
the O
response O
shows O
context-appropriate O
mindreading O
: O
0 O
( O
fail O
) O
, O
1 O
( O
partial O
score O
) O
, O
and O
2 O
( O
pass O
) O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
the O
label O
distribution O
for O
the O
full O
corpus O
is O
balanced O
, O
however O
the O
label O
distribution O
for O
the O
individual O
questions O
vary O
1 O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
we O
sought O
to O
use O
data O
augmentation O
to O
create O
a O
well-balanced O
dataset O
in O
terms O
of O
questions O
and O
labels O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
to O
achieve O
this O
, O
we O
created O
a O
policy O
for O
sampling O
examples O
that O
we O
used O
in O
the O
augmentation O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
we O
split O
the O
mind-ca O
corpus O
per O
question O
and O
per O
label O
, O
resulting O
in O
33 O
question-label O
sub O
corpora O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
the O
average O
size O
of O
each O
sub-corpora O
is O
343 O
, O
and O
the O
smallest O
number O
of O
instances O
in O
a O
sub O
corpora O
is O
160 O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
we O
sampled O
125 O
examples O
from O
each O
question-label O
sub-corpus O
, O
375 O
from O
each O
question O
, O
for O
a O
total O
4,125 O
examples O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
our O
sampling O
strategy O
ensures O
that O
each O
question-label O
combination O
is O
well O
represented O
in O
the O
augmentation O
process O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
in O
the O
original O
mindca O
corpus O
, O
nine O
question-label O
pairs O
had O
less O
than O
125 O
instances O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
as O
a O
preliminary O
step O
in O
the O
data O
augmentation O
process O
, O
our O
in-domain O
experts O
rewrote O
existing O
responses O
to O
improve O
the O
balance O
of O
the O
corpus O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
we O
used O
strategy O
similar O
to O
the O
one O
used O
in O
hossain O
et O
al O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
we O
ran O
statistical O
and O
machine O
learning O
experiments O
to O
ensure O
that O
the O
additional O
examples O
do O
not O
introduce O
biases O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
1for O
more O
details O
, O
please O
refer O
to O
kovatchev O
et O
al O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
for O
our O
experiments O
we O
initially O
chose O
a O
conservative O
number O
of O
examples O
( O
each O
augmentation O
increases O
the O
original O
corpus O
size O
by O
36 O
% O
) O
, O
to O
avoid O
overfitting O
on O
the O
underrepresented O
question-label O
pairs O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
we O
used O
a O
different O
random O
state O
for O
each O
augmentation O
strategy O
and O
we O
ensured O
that O
each O
sample O
is O
representative O
in O
terms O
of O
demographic O
distribution O
( O
age O
and O
gender O
of O
the O
participants O
) O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
in O
a O
complementary O
set O
of O
experiments O
, O
we O
applied O
data O
augmentation O
directly O
without O
the O
custom O
sampling O
strategy O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
experimented O
with O
generating O
larger O
number O
of O
augmented O
examples O
( O
up O
to O
140 O
% O
of O
the O
original O
corpus O
size O
) O
via O
oversampling O
( O
see O
section O
7 O
) O
. O

section 3
id pdf2json/2021.acl-long.96.pdf.json
in O
the O
following O
subsections O
, O
we O
discuss O
in O
more O
details O
the O
different O
augmentation O
strategies O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
the O
“ O
dictionary O
” O
augmentation O
strategy O
is O
a O
taskspecific O
synonym O
substitution O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
we O
automatically O
extract O
the O
20 O
most O
frequent O
words O
for O
each O
of O
the O
11 O
questions O
, O
a O
total O
of O
220 O
words O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
we O
then O
ask O
trained O
corpus O
annotators O
to O
propose O
a O
list O
of O
synonyms O
for O
each O
word O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
the O
synonyms O
have O
the O
same O
meaning O
in O
the O
context O
of O
the O
particular O
question O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
the O
meaning O
of O
the O
contextual O
synonyms O
may O
not O
be O
the O
same O
outside O
of O
the O
context O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
for O
example O
, O
in O
silent O
film O
question O
# O
1 O
, O
“ O
men O
” O
can O
be O
replaced O
with O
“ O
burglars O
” O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
we O
instruct O
the O
experts O
to O
create O
as O
many O
synonyms O
as O
possible O
for O
each O
word O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
some O
words O
do O
not O
have O
appropriate O
contextual O
synonyms O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
the O
final O
synonym O
dictionary O
contains O
626 O
synonyms O
for O
148 O
words O
2 O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
the O
dictionary O
augmentation O
algorithm O
replaces O
up O
to O
two O
words O
in O
each O
response O
with O
their O
contextual O
synonyms O
. O

section 4
id pdf2json/2021.acl-long.96.pdf.json
the O
words O
and O
their O
synonyms O
are O
selected O
at O
random O
from O
the O
available O
options O
. O

section 5
id pdf2json/2021.acl-long.96.pdf.json
the O
task-specific O
“ O
phrase O
” O
augmentation O
strategy O
adds O
a O
short O
phrase O
at O
the O
beginning O
of O
the O
response O
. O

section 5
id pdf2json/2021.acl-long.96.pdf.json
the O
appended O
phrases O
should O
not O
modify O
the O
meaning O
( O
or O
score O
) O
of O
the O
response O
. O

section 5
id pdf2json/2021.acl-long.96.pdf.json
an O
example O
for O
such O
phrase O
is O
“ O
i O
think O
( O
that O
) O
” O
. O

section 5
id pdf2json/2021.acl-long.96.pdf.json
our O
experts O
create O
phrases O
that O
contain O
mental O
state O
words O
, O
such O
as O
“ O
think O
” O
, O
“ O
know O
” O
, O
and O
“ O
believe O
” O
, O
as O
this O
category O
of O
words O
is O
important O
when O
scoring O
children O
’ O
s O
mindreading O
ability O
. O

section 5
id pdf2json/2021.acl-long.96.pdf.json
our O
corpus O
annotators O
proposed O
a O
2the O
implementation O
of O
all O
augmentation O
strategies O
and O
all O
resources O
used O
( O
lists O
of O
synonyms O
and O
introductory O
phrases O
) O
can O
be O
found O
online O
at O
https O
: O
//github.com/ O
venelink/augment-acl21/ O
list O
of O
15 O
such O
phrases O
. O

section 5
id pdf2json/2021.acl-long.96.pdf.json
we O
further O
modify O
the O
15 O
phrases O
with O
3 O
optional O
conjunctions O
, O
resulting O
in O
60 O
different O
combinations.the O
“ O
phrase O
” O
augmentation O
appends O
a O
random O
phrase O
at O
the O
beginning O
of O
each O
response O
, O
if O
the O
response O
does O
not O
already O
begin O
with O
such O
a O
phrase O
. O

section 6
id pdf2json/2021.acl-long.96.pdf.json
word O
replacement O
augmentation O
is O
a O
strategy O
that O
automatically O
replaces O
up O
to O
two O
randomly O
selected O
words O
with O
semantically O
similar O
words O
or O
phrases O
. O

section 6
id pdf2json/2021.acl-long.96.pdf.json
the O
“ O
wordnet O
” O
and O
“ O
ppdb O
” O
augmentations O
replace O
the O
selected O
words O
with O
a O
synonym O
from O
wordnet O
( O
fellbaum O
, O
1998 O
) O
or O
ppdb O
( O
pavlick O
et O
al. O
, O
2015 O
) O
respectively O
. O

section 6
id pdf2json/2021.acl-long.96.pdf.json
the O
“ O
glove O
” O
and O
“ O
fasttext O
” O
augmentations O
replace O
the O
selected O
words O
with O
the O
most O
similar O
words O
( O
or O
phrases O
) O
using O
pre-trained O
glove O
( O
pennington O
et O
al. O
, O
2014 O
) O
or O
fasttext O
( O
joulin O
et O
al. O
, O
2016 O
) O
word O
embeddings O
. O

section 6
id pdf2json/2021.acl-long.96.pdf.json
we O
implement O
the O
four O
“ O
word O
replacement O
” O
augmentations O
using O
the O
nlp O
augmentation O
python O
library O
( O
ma O
, O
2019 O
) O
. O

section 6
id pdf2json/2021.acl-long.96.pdf.json
for O
this O
set O
of O
experiments O
we O
decided O
not O
to O
use O
bert-based O
contextual O
word O
embeddings O
for O
augmentation O
, O
since O
we O
are O
using O
a O
distilbert O
classifier O
. O

section 7
id pdf2json/2021.acl-long.96.pdf.json
the O
“ O
order O
” O
augmentation O
strategy O
changes O
the O
position O
of O
two O
words O
in O
the O
sentence O
. O

section 7
id pdf2json/2021.acl-long.96.pdf.json
previous O
work O
on O
data O
augmentation O
for O
nlp O
( O
wei O
and O
zou O
, O
2019 O
; O
ma O
, O
2019 O
) O
implement O
the O
“ O
order O
” O
augmentation O
by O
changing O
the O
position O
of O
the O
two O
randomly O
selected O
words O
. O

section 7
id pdf2json/2021.acl-long.96.pdf.json
we O
enforce O
a O
more O
stringent O
rule O
for O
our O
algorithm O
. O

section 7
id pdf2json/2021.acl-long.96.pdf.json
specifically O
, O
we O
select O
one O
word O
at O
random O
and O
change O
its O
position O
with O
one O
of O
its O
neighbouring O
words O
. O

section 7
id pdf2json/2021.acl-long.96.pdf.json
this O
change O
is O
more O
conservative O
than O
picking O
two O
words O
at O
random O
. O

section 7
id pdf2json/2021.acl-long.96.pdf.json
it O
also O
reflects O
the O
naturally O
occurring O
responses O
from O
7- O
to O
14-year-old O
children O
in O
the O
database O
. O

section 7
id pdf2json/2021.acl-long.96.pdf.json
the O
reorder O
process O
is O
repeated O
up O
to O
two O
times O
. O

section 8
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
experimented O
with O
applying O
multiple O
augmentation O
strategies O
together O
. O

section 8
id pdf2json/2021.acl-long.96.pdf.json
for O
example O
the O
“ O
dictionary O
+ O
phrase O
” O
augmentation O
first O
replaces O
up O
to O
two O
words O
with O
contextual O
synonyms O
and O
then O
adds O
a O
phrase O
at O
the O
beginning O
of O
the O
response O
. O

section 8
id pdf2json/2021.acl-long.96.pdf.json
the O
data O
obtained O
by O
“ O
combination O
” O
augmentations O
was O
included O
in O
the O
the O
“ O
all-lq O
” O
and O
“ O
all-hq O
” O
corpora O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
the O
quality O
of O
data O
augmentation O
models O
in O
nlp O
research O
is O
typically O
evaluated O
extrinsically O
, O
by O
measuring O
the O
performance O
of O
automated O
systems O
trained O
on O
augmented O
data O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
wei O
and O
zou O
( O
2019 O
) O
propose O
an O
intrinsic O
evaluation O
inspired O
by O
the O
data O
augmentation O
research O
in O
computer O
vision O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
they O
compare O
the O
latent O
space O
representations O
of O
the O
original O
and O
the O
augmented O
sentences O
and O
assume O
that O
the O
proximity O
in O
latent O
space O
indicates O
that O
the O
original O
labels O
are O
conserved O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
we O
argue O
that O
a O
direct O
comparison O
of O
the O
representation O
of O
the O
texts O
is O
not O
sufficient O
to O
determine O
the O
quality O
of O
the O
augmentation O
and O
the O
extent O
to O
which O
each O
strategy O
preserves O
the O
original O
labels O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
in O
natural O
language O
, O
unlike O
in O
computer O
vision O
, O
a O
minor O
difference O
in O
the O
text O
and O
the O
corresponding O
representation O
can O
cause O
a O
significant O
difference O
in O
the O
meaning O
of O
the O
complex O
expression O
and O
ultimately O
the O
label O
or O
score O
assigned O
to O
that O
answer O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
we O
propose O
a O
manual O
evaluation O
of O
the O
different O
strategies O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
for O
each O
augmentation O
strategy O
, O
we O
selected O
5 O
random O
examples O
from O
each O
questionlabel O
sub-corpus O
, O
adding O
up O
to O
165 O
examples O
per O
strategy O
( O
4 O
% O
of O
the O
full O
sample O
) O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
two O
trained O
annotators O
independently O
rate O
the O
augmented O
pairs O
for O
the O
7 O
different O
augmentation O
strategies O
( O
a O
total O
of O
1,155 O
question-answer O
pairs O
) O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
to O
ensure O
a O
fair O
evaluation O
, O
the O
annotators O
receive O
a O
single O
file O
with O
the O
examples O
for O
all O
augmented O
strategies O
shuffled O
at O
random O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
the O
inter-annotator O
agreement O
was O
87 O
% O
with O
a O
cohen O
’ O
s O
kappa O
of O
.83 O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
table O
1 O
shows O
the O
results O
of O
the O
re-annotation O
for O
each O
augmentation O
strategy O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
we O
define O
“ O
quality O
” O
as O
the O
% O
of O
examples O
where O
the O
re-annotated O
label O
was O
the O
same O
as O
the O
original O
label O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
measure O
the O
% O
of O
“ O
invalid O
” O
examples O
, O
where O
both O
annotators O
agreed O
not O
to O
assign O
a O
label O
due O
to O
a O
semantically O
incoherent O
response O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
an O
example O
for O
an O
incoherent O
response O
can O
be O
seen O
in O
( O
1 O
) O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
( O
1 O
) O
why O
did O
the O
men O
hide O
? O

section 9
id pdf2json/2021.acl-long.96.pdf.json
so O
telling O
does O
’ O
nt O
get O
told O
his O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
based O
on O
the O
analysis O
, O
we O
distinguish O
between O
“ O
high O
quality O
” O
augmentation O
strategies O
( O
“ O
phrase O
” O
, O
“ O
order O
” O
, O
and O
“ O
dictionary O
” O
) O
and O
“ O
low O
quality O
” O
augmentations O
( O
“ O
wordnet O
” O
, O
“ O
fasttext O
” O
, O
“ O
ppdb O
” O
, O
and O
“ O
glove O
” O
) O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
the O
“ O
high O
quality O
” O
augmentations O
preserve O
the O
label O
in O
over O
94 O
% O
of O
the O
instances O
and O
contain O
less O
than O
4 O
% O
invalid O
responses O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
the O
“ O
low O
quality O
” O
augmentations O
preserve O
the O
label O
in O
less O
than O
83 O
% O
of O
the O
instances O
and O
contain O
more O
than O
10 O
% O
invalid O
responses O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
according O
to O
our O
raters O
, O
glove O
is O
the O
worst O
of O
all O
augmentation O
strategies O
with O
68 O
% O
quality O
and O
17 O
% O
invalid O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
the O
expert O
analysis O
indicates O
that O
, O
at O
least O
in O
our O
data O
, O
there O
is O
a O
substantial O
difference O
in O
the O
quality O
of O
the O
different O
augmentation O
strategies O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
the O
taskspecific O
strategies O
perform O
much O
better O
than O
the O
task-agnostic O
ones O
, O
with O
the O
exception O
of O
“ O
change O
of O
order O
” O
augmentation O
. O

section 9
id pdf2json/2021.acl-long.96.pdf.json
in O
the O
following O
sections O
, O
we O
perform O
a O
number O
of O
machine O
learning O
experiments O
to O
determine O
if O
the O
quality O
of O
the O
data O
affects O
the O
performance O
of O
the O
automated O
systems O
. O

section 10
id pdf2json/2021.acl-long.96.pdf.json
in O
our O
experiments O
, O
we O
used O
the O
two O
best O
systems O
reported O
by O
kovatchev O
et O
al O
. O

section 10
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
- O
a O
bilstm O
neural O
network O
and O
a O
distilbert O
transformer O
. O

section 10
id pdf2json/2021.acl-long.96.pdf.json
these O
systems O
obtained O
good O
results O
on O
the O
original O
mind-ca O
corpus O
and O
at O
the O
same O
time O
were O
lightweight O
enough O
to O
be O
implemented O
in O
a O
practical O
end-to-end O
application O
for O
automatic O
scoring O
. O

section 10
id pdf2json/2021.acl-long.96.pdf.json
we O
used O
the O
same O
configuration O
and O
hyperparameters O
as O
reported O
by O
kovatchev O
et O
al O
. O

section 10
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
. O

section 10
id pdf2json/2021.acl-long.96.pdf.json
we O
modified O
the O
existing O
classes O
to O
incorporate O
and O
keep O
track O
of O
data O
augmentation O
and O
to O
implement O
additional O
evaluation O
on O
uk-mind-20 O
. O

section 10
id pdf2json/2021.acl-long.96.pdf.json
all O
of O
our O
code O
and O
data O
are O
available O
online O
3 O
. O

section 11
id pdf2json/2021.acl-long.96.pdf.json
we O
trained O
each O
of O
the O
automated O
systems O
on O
13 O
different O
training O
sets O
, O
shown O
in O
table O
2 O
. O

section 11
id pdf2json/2021.acl-long.96.pdf.json
each O
set O
includes O
the O
original O
corpus O
( O
mind-ca O
) O
and O
a O
number O
of O
augmented O
samples O
. O

section 11
id pdf2json/2021.acl-long.96.pdf.json
for O
example O
, O
the O
phrase O
dataset O
contained O
the O
11,311 O
examples O
3https O
: O
//github.com/venelink/ O
augment-acl21/ O
from O
mind-ca O
+ O
4,125 O
from O
the O
“ O
phrase O
” O
augmentation O
, O
for O
a O
total O
of O
15,436 O
examples O
. O

section 11
id pdf2json/2021.acl-long.96.pdf.json
in O
addition O
to O
the O
7 O
“ O
basic O
” O
augmented O
training O
sets O
( O
one O
for O
each O
augmentation O
strategy O
) O
, O
we O
also O
created O
4 O
larger O
training O
sets O
, O
containing O
augmented O
samples O
from O
multiple O
different O
strategies O
. O

section 11
id pdf2json/2021.acl-long.96.pdf.json
the O
“ O
all O
bassic O
hq O
” O
( O
ab-hq O
) O
dataset O
contains O
the O
11,311 O
examples O
from O
mind-ca O
+ O
4,125 O
from O
“ O
phrase O
” O
+ O
4,125 O
from O
“ O
dictionary O
” O
+ O
4,125 O
from O
“ O
order O
” O
for O
a O
total O
of O
23,686 O
examples O
. O

section 11
id pdf2json/2021.acl-long.96.pdf.json
similarly O
, O
the O
“ O
all O
basic O
lq O
” O
( O
ab-lq O
) O
dataset O
contains O
27,811 O
examples O
from O
mind-ca O
+ O
“ O
wordnet O
” O
, O
“ O
fasttext O
” O
, O
“ O
ppdb O
” O
, O
and O
“ O
glove O
” O
. O

section 11
id pdf2json/2021.acl-long.96.pdf.json
the O
two O
largest O
datasets O
, O
the O
all-lq O
and O
the O
allhq O
datasets O
contain O
the O
corresponding O
“ O
all O
basic O
” O
datasets O
and O
additional O
examples O
obtained O
by O
consecutively O
applying O
more O
than O
one O
augmentation O
strategy O
to O
the O
same O
original O
data O
( O
the O
“ O
combined O
” O
augmentations O
described O
in O
section O
3.5 O
) O
. O

section 11
id pdf2json/2021.acl-long.96.pdf.json
we O
kept O
the O
“ O
low O
quality O
” O
and O
the O
“ O
high O
quality O
” O
data O
separated O
, O
so O
we O
can O
measure O
the O
correlation O
between O
the O
“ O
quality O
” O
and O
the O
performance O
of O
the O
automated O
systems O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
one O
of O
the O
objectives O
behind O
data O
augmentation O
is O
to O
improve O
the O
capabilities O
of O
automated O
systems O
to O
generalize O
to O
unseen O
data O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
however O
, O
finding O
unseen O
data O
for O
the O
same O
task O
is O
often O
non-trivial O
, O
so O
researchers O
typically O
use O
train-test O
split O
or O
10- O
fold O
cross O
validation O
to O
evaluate O
the O
models O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
to O
provide O
a O
fair O
evaluation O
benchmark O
for O
generalizability O
, O
we O
created O
a O
new O
corpus O
of O
children O
’ O
s O
mindreading O
ability O
, O
the O
uk-mind-20 O
corpus O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
the O
data O
for O
the O
corpus O
is O
part O
of O
our O
own O
research O
on O
children O
’ O
s O
mindreading O
in O
large-scale O
study O
involving O
1020 O
8- O
to O
13-year-old O
children O
( O
556 O
girls O
, O
453 O
boys O
, O
11 O
not O
disclosed O
) O
from O
the O
united O
kingdom O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
children O
completed O
three O
mindreading O
tasks O
during O
whole-class O
testing O
sessions O
led O
by O
trained O
research O
assistants O
: O
strange O
stories O
task O
( O
happé O
, O
1994 O
) O
, O
silent O
film O
task O
( O
devine O
and O
hughes O
, O
2013 O
) O
, O
and O
triangles O
task O
( O
castelli O
et O
al. O
, O
2000 O
) O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
each O
child O
answered O
14 O
questions O
: O
five O
from O
the O
strange O
story O
task O
, O
six O
from O
the O
silent O
film O
task O
, O
and O
three O
from O
the O
triangles O
task O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
we O
do O
not O
use O
the O
responses O
for O
the O
triangles O
task O
for O
the O
evaluation O
of O
data O
augmentation O
, O
since O
that O
task O
is O
not O
part O
of O
the O
mind-ca O
corpus O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
we O
obtained O
a O
total O
of O
10,320 O
question-answer O
pairs O
for O
the O
strange O
stories O
and O
the O
silent O
film O
portion O
of O
the O
corpus O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
similar O
to O
mind-ca O
, O
uk-mind-20 O
also O
includes O
the O
age O
and O
gender O
of O
the O
participants O
and O
responses O
to O
a O
standardized O
verbal O
ability O
test O
( O
raven O
, O
2008 O
) O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
the O
children O
’ O
s O
responses O
were O
scored O
by O
two O
trained O
research O
assistants O
, O
the O
same O
assistants O
that O
measured O
the O
augmentation O
quality O
in O
section O
4 O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
each O
response O
was O
scored O
by O
one O
annotator O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
the O
inter-annotator O
agreement O
was O
measured O
on O
a O
heldout O
set O
of O
questions O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
we O
report O
an O
inter-annotator O
agreement O
of O
94 O
% O
and O
a O
fleiss O
kappa O
score O
of O
.91 O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
when O
creating O
uk-mind-20 O
, O
we O
used O
the O
same O
procedures O
for O
administering O
, O
scoring O
, O
and O
digitalizing O
the O
children O
responses O
as O
the O
ones O
used O
by O
kovatchev O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
. O

section 12
id pdf2json/2021.acl-long.96.pdf.json
the O
data O
for O
the O
ukmind-20 O
corpus O
is O
gathered O
in O
a O
different O
timeframe O
( O
oct O
2019 O
– O
feb O
2020 O
) O
and O
from O
different O
locations O
than O
mind-ca O
( O
2014 O
– O
2019 O
) O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
the O
task O
defined O
by O
kovatchev O
et O
al O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
consists O
of O
scoring O
the O
children O
’ O
s O
mindreading O
abilities O
based O
on O
the O
open-text O
responses O
to O
11 O
different O
questions O
from O
the O
strange O
stories O
task O
and O
the O
silent O
film O
task O
using O
three O
categories O
( O
i.e. O
, O
fail O
, O
partial O
, O
pass O
) O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
a O
single O
automated O
system O
has O
to O
score O
all O
11 O
questions O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
in O
this O
paper O
we O
evaluate O
the O
system O
performance O
in O
three O
ways O
: O
overall O
f1 O
: O
the O
macro-f1 O
on O
the O
full O
test O
set O
, O
containing O
all O
11 O
questions O
, O
shuffled O
at O
random O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
f1-per-q O
: O
we O
split O
the O
test O
set O
on O
11 O
parts O
, O
one O
for O
each O
question O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
we O
obtain O
the O
macro-f1 O
score O
on O
each O
question O
and O
calculate O
the O
average O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
std-per-q O
: O
similar O
to O
f1-per-q O
, O
we O
obtain O
the O
macro-f1 O
for O
each O
question O
and O
then O
calculate O
the O
standard O
deviation O
of O
the O
performance O
per O
question O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
the O
overall O
f1 O
measures O
the O
performance O
of O
the O
system O
on O
the O
full O
task O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
f1-per-q O
and O
std-per-q O
measure O
the O
consistency O
of O
the O
system O
across O
the O
different O
questions O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
a O
practical O
end-to-end O
system O
needs O
to O
obtain O
good O
results O
in O
both O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
the O
additional O
data O
facilitates O
the O
statistical O
analysis O
of O
the O
system O
performance O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
this O
evaluation O
methodology O
was O
proposed O
by O
kovatchev O
et O
al O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
( O
2019 O
) O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
for O
each O
system O
we O
performed O
a O
10-fold O
cross O
validation O
using O
each O
corpus O
from O
table O
2 O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
for O
each O
fold O
, O
we O
evaluated O
on O
both O
the O
corresponding O
test O
set O
and O
on O
the O
full O
uk-mind-20 O
corpus O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
our O
code O
dynamically O
removes O
from O
the O
current O
training O
set O
any O
augmented O
examples O
that O
are O
based O
on O
the O
current O
test O
set O
to O
ensure O
a O
fair O
evaluation O
. O

section 13
id pdf2json/2021.acl-long.96.pdf.json
all O
test O
sets O
contain O
only O
gold-standard O
human-labeled O
examples O
and O
do O
not O
include O
any O
augmented O
data O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
table O
3 O
presents O
the O
results O
of O
the O
13 O
different O
training O
configurations O
with O
the O
distilbert O
transformer O
, O
using O
both O
question O
and O
answer O
as O
input4 O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
numbers O
are O
the O
average O
across O
10-fold O
cross O
validation O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
for O
reference O
, O
we O
also O
include O
the O
results O
obtained O
by O
training O
the O
system O
on O
uk-mind20 O
and O
testing O
on O
mind-ca O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
distilbert O
architecture O
is O
the O
best O
performing O
system O
from O
kovatchev O
et O
al O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
( O
2020 O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
baseline O
system O
, O
trained O
on O
the O
original O
data O
already O
obtained O
very O
good O
results O
: O
.925 O
f1 O
and O
.877 O
f1per-q O
on O
the O
mind-ca O
corpus O
and O
.889 O
f1 O
and O
.839 O
f1-per-q O
on O
the O
uk-mind-20 O
corpus O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
we O
demonstrate O
that O
systems O
trained O
on O
either O
of O
the O
two O
datasets O
can O
generalize O
well O
on O
the O
other O
one O
4we O
carried O
out O
4 O
different O
sets O
of O
experiments O
: O
two O
classifiers O
( O
bilstm O
and O
distilbert O
) O
and O
two O
different O
input O
setups O
( O
i.e. O
, O
only O
the O
answer O
or O
both O
question O
and O
answer O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
due O
to O
space O
restrictions O
, O
we O
report O
only O
the O
results O
for O
the O
best O
system O
, O
distilbert O
( O
question O
+ O
answer O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
findings O
apply O
to O
all O
sets O
of O
experiments O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
code O
and O
results O
for O
all O
experiments O
are O
available O
online O
at O
https O
: O
//github.com/venelink/augment-acl21/ O
( O
f1 O
of O
.89 O
and O
f1-per-q O
of O
.84 O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
this O
indicates O
that O
the O
two O
corpora O
are O
compatible O
and O
that O
automated O
systems O
can O
generalize O
to O
unseen O
data O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
it O
is O
evident O
in O
the O
table O
that O
all O
of O
the O
augmentation O
strategies O
successfully O
improved O
the O
performance O
of O
the O
automated O
systems O
across O
all O
evaluation O
criteria O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
for O
the O
mind-ca O
corpus O
: O
f1 O
improved O
between O
1.7 O
points O
( O
fasttext O
) O
and O
6 O
points O
( O
all-hq O
) O
; O
f1-per-qiestion O
improved O
between O
4.7 O
points O
( O
fasttext O
) O
and O
10.3 O
points O
( O
all-hq O
) O
; O
stdper-question O
was O
reduced O
by O
between O
1.6 O
points O
( O
wordnet O
) O
and O
4.8 O
points O
( O
all-hq O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
for O
the O
ukmind-20 O
corpus O
: O
f1 O
improved O
between O
0.1 O
point O
( O
fasttext O
) O
and O
0.9 O
point O
( O
all-hq O
) O
; O
f1-per-question O
improved O
between O
1 O
point O
( O
glove O
) O
and O
1.9 O
points O
( O
all-hq O
) O
; O
std-per-question O
was O
reduced O
between O
3.9 O
points O
( O
dictionary O
) O
and O
4.2 O
points O
( O
ab-hq O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
based O
on O
these O
results O
, O
we O
can O
draw O
two O
conclusions O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
first O
, O
data O
augmentation O
can O
successfully O
be O
used O
to O
improve O
the O
performance O
of O
the O
systems O
on O
the O
mind-ca O
corpus O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
second O
, O
data O
augmentation O
also O
improves O
the O
performance O
of O
the O
automated O
systems O
on O
the O
unseen O
examples O
from O
uk-mind20 O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
while O
the O
improvement O
is O
not O
as O
substantial O
as O
seen O
on O
mind-ca O
, O
the O
improvement O
on O
all O
three O
criteria O
on O
uk-mind-20 O
indicates O
that O
the O
systems O
are O
not O
just O
overfitting O
to O
mind-ca O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
we O
use O
the O
autorank O
python O
library O
( O
herbold O
, O
2020 O
) O
to O
carry O
out O
a O
statistical O
analysis O
on O
the O
results O
and O
compare O
the O
performance O
gain O
from O
each O
of O
the O
augmentation O
strategies O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
we O
use O
the O
data O
from O
both O
algorithms O
and O
input O
formats O
, O
a O
total O
of O
480 O
machine O
learning O
models O
, O
40 O
for O
each O
dataset O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
based O
on O
the O
provided O
data O
, O
autorank O
determines O
that O
the O
most O
appropriate O
statistical O
test O
is O
the O
friedman-nemeyni O
test O
( O
demšar O
, O
2006 O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
friedman O
test O
reports O
that O
there O
is O
a O
statistically O
significant O
difference O
between O
the O
median O
values O
of O
the O
populations O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
that O
means O
that O
some O
training O
sets O
are O
consistently O
performing O
better O
( O
or O
worse O
) O
than O
others O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
post-hoc O
nemenyi O
test O
can O
be O
used O
to O
determine O
and O
visualise O
which O
training O
sets O
are O
better O
and O
which O
are O
worse O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
figure O
1 O
shows O
the O
critical O
difference O
diagram O
of O
the O
post-hoc O
nemenyi O
test O
for O
all O
training O
sets O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
each O
set O
is O
plotted O
with O
its O
average O
ranking O
across O
all O
systems O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
difference O
between O
systems O
connected O
with O
a O
line O
is O
not O
statistically O
significant O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
original O
corpus O
is O
the O
worst O
performing O
of O
all O
datasets O
with O
an O
average O
rank O
of O
9 O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
7 O
“ O
basic O
” O
training O
sets O
are O
grouped O
in O
the O
middle O
( O
rank O
6.5 O
to O
8 O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
that O
is O
, O
they O
are O
all O
better O
than O
the O
original O
corpus O
, O
but O
worse O
than O
the O
combined O
training O
sets O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
there O
is O
a O
significant O
difference O
between O
“ O
all-hq O
” O
, O
“ O
all-lq O
” O
, O
“ O
ab-hq O
” O
, O
and O
“ O
ab-lq O
” O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
collectively O
they O
are O
also O
better O
than O
the O
original O
training O
set O
and O
the O
“ O
basic O
” O
training O
sets O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
figure O
2 O
shows O
the O
critical O
difference O
diagram O
of O
the O
post-hoc O
nemenyi O
test O
applied O
only O
to O
the O
7 O
“ O
basic O
” O
augmentations O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
after O
removing O
the O
outliers O
( O
the O
original O
corpus O
and O
the O
collections O
of O
multiple O
augmentation O
) O
, O
we O
can O
observe O
a O
clear O
, O
statistically O
significant O
distinction O
between O
“ O
high O
quality O
” O
augmentations O
( O
“ O
dictionary O
” O
, O
“ O
phrase O
” O
, O
and O
“ O
order O
” O
) O
and O
“ O
low O
quality O
” O
augmentations O
( O
“ O
glove O
” O
, O
“ O
fasttext O
” O
, O
“ O
wordnet O
” O
, O
and O
“ O
ppdb O
” O
) O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
based O
on O
the O
statistical O
analysis O
, O
we O
can O
draw O
two O
additional O
conclusions O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
third O
, O
we O
found O
that O
the O
most O
important O
factor O
affecting O
the O
system O
performance O
is O
the O
number O
of O
training O
examples O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
we O
obtain O
the O
best O
results O
by O
combining O
the O
examples O
from O
various O
different O
augmentation O
strategies O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
fourth O
, O
we O
demonstrated O
that O
when O
the O
training O
size O
is O
comparable O
, O
the O
high O
quality O
augmentations O
improve O
the O
performance O
more O
than O
the O
low O
quality O
ones O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
the O
difference O
is O
significant O
and O
is O
consistent O
both O
in O
“ O
basic O
” O
datasets O
and O
in O
“ O
combined O
” O
datasets O
. O

section 14
id pdf2json/2021.acl-long.96.pdf.json
vector O
based O
augmentations O
( O
glove O
and O
fasttext O
) O
are O
performing O
worse O
than O
augmentations O
based O
on O
task-specific O
or O
task-agnostic O
knowledge O
bases O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
the O
intrinsic O
and O
extrinsic O
evaluation O
presented O
in O
section O
4 O
and O
section O
6 O
answered O
the O
main O
research O
questions O
posed O
in O
this O
paper O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
we O
demonstrated O
that O
data O
augmentation O
can O
improve O
the O
performance O
of O
automated O
systems O
including O
on O
novel O
, O
unseen O
data O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
we O
found O
that O
the O
data O
augmentation O
strategies O
vary O
in O
preserving O
the O
original O
label O
and O
in O
how O
much O
they O
improve O
the O
machine O
learning O
systems O
trained O
on O
them O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
showed O
that O
automated O
scoring O
systems O
can O
generalize O
well O
from O
mind-ca O
corpus O
to O
uk-mind-20 O
and O
the O
other O
way O
around O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
all O
these O
findings O
are O
important O
for O
further O
research O
on O
mindreading O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
at O
the O
same O
time O
, O
our O
data O
augmentation O
strategies O
and O
evaluation O
methodology O
can O
also O
be O
extended O
to O
other O
tasks O
and O
domains O
, O
contributing O
to O
the O
research O
of O
data O
augmentation O
in O
nlp O
in O
general O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
in O
this O
section O
we O
present O
additional O
experiments O
and O
an O
analysis O
of O
the O
impact O
of O
several O
different O
factors O
in O
the O
process O
of O
data O
augmentation O
5 O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
corpus O
size O
our O
experiments O
indicated O
that O
the O
most O
important O
factor O
for O
improving O
the O
system O
performance O
is O
the O
corpus O
size O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
in O
table O
3 O
the O
systems O
that O
perform O
best O
are O
trained O
on O
the O
largest O
possible O
amount O
of O
data O
( O
all-lq/all-hq O
) O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
to O
further O
explore O
the O
impact O
of O
corpus O
size O
, O
we O
ran O
an O
additional O
set O
of O
experiments O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
we O
sampled O
500 O
examples O
for O
each O
question-label O
subcorpora O
instead O
of O
the O
original O
125 O
, O
increasing O
the O
corpus O
size O
four O
times O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
for O
each O
augmentation O
strategy O
this O
resulted O
in O
a O
corpus O
approximately O
the O
same O
size O
as O
ab-lq O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
as O
expected O
, O
the O
performance O
of O
each O
system O
increased O
with O
corpus O
size O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
the O
ranking O
of O
the O
individual O
systems O
remained O
similar O
to O
the O
one O
reported O
with O
125 O
base O
examples O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
“ O
high O
quality O
” O
augmentations O
still O
performed O
better O
than O
“ O
low O
quality O
” O
ones O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
the O
f1 O
, O
f1-per-q O
, O
and O
std-per-q O
for O
the O
“ O
basic O
low O
quality O
” O
strategies O
was O
approximately O
the O
same O
as O
the O
performance O
for O
ab-lq O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
the O
f1 O
, O
f1-per-q O
, O
and O
std-per-q O
for O
the O
“ O
basic O
high O
quality O
” O
strategies O
was O
approximately O
the O
same O
as O
the O
performance O
for O
ab-hq O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
this O
new O
set O
of O
experiments O
confirmed O
the O
importance O
of O
corpus O
size O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
even O
strategies O
that O
human O
experts O
perceive O
as O
“ O
low O
quality O
” O
are O
improving O
the O
performance O
of O
the O
automated O
systems O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
and O
while O
the O
ranking O
consistently O
favors O
the O
“ O
high O
quality O
” O
augmentations O
, O
the O
absolute O
difference O
is O
relatively O
small O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
this O
is O
in O
line O
with O
the O
findings O
on O
noisy O
learning O
which O
show O
that O
machine O
learning O
models O
can O
be O
very O
noise-tolerant O
( O
natarajan O
et O
al. O
, O
2013 O
) O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
we O
performed O
one O
final O
experiment O
by O
combining O
the O
all-lq O
and O
all-hq O
data O
together O
, O
but O
found O
no O
increase O
or O
decrease O
of O
performance O
compared O
with O
using O
only O
the O
all-hq O
data O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
sampling O
strategy O
in O
our O
experiments O
, O
we O
designed O
a O
sampling O
strategy O
to O
ensure O
that O
each O
5due O
to O
space O
restrictions O
, O
we O
only O
discuss O
the O
overall O
tendencies O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
the O
actual O
results O
are O
available O
online O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
question-response O
combination O
appears O
in O
the O
training O
data O
with O
sufficient O
frequency O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
in O
a O
complementary O
set O
of O
experiments O
, O
we O
evaluated O
the O
importance O
of O
the O
sampling O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
for O
each O
augmentation O
strategy O
, O
we O
created O
an O
augmented O
dataset O
with O
1500 O
examples O
for O
each O
question O
, O
using O
a O
standard O
sampling O
that O
keeps O
the O
original O
ratio O
of O
the O
responses O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
the O
size O
of O
the O
dataset O
is O
the O
same O
as O
sampling O
500 O
examples O
for O
each O
of O
the O
3 O
labels O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
we O
found O
that O
for O
all O
strategies O
, O
the O
sampling O
improves O
test-f1q O
between O
.6 O
and O
1 O
point O
and O
reduces O
std-per-q O
by O
1 O
point O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
this O
finding O
validates O
our O
choice O
of O
sampling O
strategy O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
augmentation O
strategy O
in O
section O
6 O
we O
demonstrated O
that O
when O
all O
parameters O
( O
sampling O
, O
corpus O
size O
) O
are O
equal O
the O
“ O
high-quality O
” O
strategies O
rank O
higher O
than O
the O
“ O
low-quality O
” O
ones O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
while O
the O
absolute O
difference O
in O
f1 O
and O
std O
is O
relatively O
small O
on O
our O
datasets O
, O
the O
consistency O
of O
the O
performance O
of O
the O
“ O
high-quality O
” O
strategies O
has O
to O
be O
taken O
into O
consideration O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
furthermore O
, O
the O
quantitative O
performance O
is O
only O
one O
factor O
that O
has O
to O
be O
considered O
when O
choosing O
a O
strategy O
for O
data O
augmentation O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
reducing O
the O
noise O
in O
the O
training O
data O
can O
be O
a O
desirable O
characteristic O
when O
interpreting O
the O
performance O
of O
the O
neural O
network O
models O
, O
or O
when O
working O
with O
sensitive O
data O
, O
such O
as O
( O
e.g O
. O
) O

section 15
id pdf2json/2021.acl-long.96.pdf.json
in O
the O
health O
domain O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
the O
task-specific O
augmentations O
that O
we O
proposed O
and O
used O
may O
require O
in-domain O
experts O
, O
however O
the O
design O
is O
rather O
simple O
and O
the O
process O
is O
not O
time O
or O
labour O
intensive O
. O

section 15
id pdf2json/2021.acl-long.96.pdf.json
after O
the O
task-specific O
resource O
( O
dictionary O
, O
list O
of O
phrases O
) O
is O
created O
, O
it O
can O
be O
reused O
for O
multiple O
examples O
and O
scales O
very O
well O
with O
corpus O
size O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
presented O
a O
systematic O
comparison O
of O
multiple O
data O
augmentation O
strategies O
for O
the O
task O
of O
automatic O
scoring O
of O
children O
’ O
s O
mindreading O
ability O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
argued O
that O
the O
nature O
of O
natural O
language O
requires O
a O
more O
in-depth O
analysis O
of O
the O
quality O
and O
performance O
of O
the O
different O
data O
augmentation O
strategies O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
recruited O
in-domain O
experts O
and O
incorporated O
them O
in O
the O
process O
of O
evaluation O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
demonstrated O
that O
, O
for O
some O
of O
the O
augmentation O
strategies O
( O
“ O
glove O
” O
, O
“ O
fasttext O
” O
, O
“ O
ppdb O
” O
) O
there O
is O
a O
substantial O
portion O
of O
the O
examples O
( O
over O
20 O
% O
) O
where O
the O
rating O
changes O
or O
can O
not O
be O
assigned O
due O
to O
semantically O
incoherent O
text O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
these O
differences O
in O
the O
datasets O
can O
not O
be O
captured O
trivially O
via O
the O
visualisation O
techniques O
that O
are O
typically O
used O
for O
intrinsic O
evaluation O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
found O
that O
the O
difference O
in O
augmentation O
quality O
corresponds O
to O
a O
difference O
in O
the O
performance O
of O
automated O
systems O
trained O
on O
the O
data O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
to O
the O
best O
of O
our O
knowledge O
, O
this O
is O
the O
first O
evaluation O
of O
data O
augmentation O
in O
nlp O
that O
involves O
both O
expert O
evaluation O
and O
automatic O
metrics O
and O
the O
first O
study O
that O
demonstrates O
the O
connection O
between O
the O
two O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
carried O
out O
further O
experiments O
measuring O
the O
importance O
of O
factors O
such O
as O
corpus O
size O
and O
sampling O
strategy O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
our O
findings O
on O
the O
quality O
and O
efficiency O
of O
data O
augmentation O
strategies O
and O
on O
the O
use O
of O
task-specific O
resources O
are O
relevant O
for O
researchers O
in O
the O
area O
of O
data O
augmentation O
, O
specifically O
in O
domains O
where O
the O
quality O
of O
the O
training O
gold O
examples O
is O
important O
or O
where O
the O
amount O
of O
data O
is O
very O
limited O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
for O
the O
purpose O
of O
evaluation O
, O
we O
also O
created O
a O
new O
corpus O
: O
uk-mind-20 O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
it O
is O
the O
second O
corpus O
for O
automatic O
scoring O
of O
mind O
reading O
in O
children O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
demonstrated O
that O
systems O
trained O
on O
mind-ca O
generalize O
well O
on O
uk-mind-20 O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
showed O
that O
data O
augmentation O
improves O
the O
performance O
on O
unseen O
data O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
these O
findings O
are O
promising O
both O
for O
the O
task O
of O
scoring O
children O
’ O
s O
mindreading O
and O
for O
the O
use O
of O
data O
augmentation O
in O
nlp O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
to O
the O
best O
of O
our O
knowledge O
, O
this O
is O
the O
first O
work O
where O
augmentation O
is O
evaluated O
on O
novel O
, O
unseen O
data O
for O
the O
same O
task O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
this O
work O
opens O
several O
directions O
of O
future O
work O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
as O
a O
direct O
continuation O
of O
this O
research O
, O
we O
will O
incorporate O
the O
best O
performing O
automated O
systems O
and O
data O
augmentation O
techniques O
in O
the O
work O
of O
developmental O
psychologists O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
this O
will O
facilitate O
a O
large-scale O
studies O
on O
mindreading O
in O
children O
and O
adolescents O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
we O
are O
also O
exploring O
the O
possibility O
of O
using O
nlp O
to O
address O
other O
time O
and O
labour O
intensive O
problems O
within O
psychology O
. O

section 16
id pdf2json/2021.acl-long.96.pdf.json
open-ended O
short O
text O
responses O
are O
widely-used O
within O
psychological O
research O
and O
the O
good O
results O
obtained O
in O
this O
paper O
can O
be O
replicated O
in O
other O
similar O
tasks O
. O

section 17
id pdf2json/2021.acl-long.96.pdf.json
we O
would O
like O
to O
thank O
imogen O
grumley O
traynor O
and O
irene O
luque O
aguilera O
for O
the O
annotation O
and O
the O
creation O
of O
the O
lists O
of O
synonyms O
and O
phrases O
. O

section 17
id pdf2json/2021.acl-long.96.pdf.json
we O
also O
want O
to O
thank O
the O
anonymous O
reviewers O
for O
their O
feedback O
and O
suggestions O
. O

section 17
id pdf2json/2021.acl-long.96.pdf.json
this O
project O
was O
funded O
by O
a O
grant O
from O
wellcome O
to O
r. O
t. O
devine O
. O

section 17
id pdf2json/2021.acl-long.96.pdf.json
ethical O
statement O
the O
study O
was O
approved O
by O
the O
university O
of O
birmingham O
stem O
research O
ethics O
committee O
and O
complies O
with O
the O
british O
psychological O
society O
code O
of O
human O
research O
ethics O
( O
2014 O
) O
. O

section 17
id pdf2json/2021.acl-long.96.pdf.json
parents O
and O
caregivers O
were O
provided O
with O
detailed O
information O
about O
the O
study O
at O
least O
one O
week O
in O
advance O
of O
data O
collection O
and O
given O
the O
opportunity O
to O
opt O
out O
of O
the O
study O
. O

section 17
id pdf2json/2021.acl-long.96.pdf.json
children O
were O
also O
permitted O
to O
opt O
out O
of O
the O
study O
on O
the O
day O
of O
data O
collection O
without O
consequence O
. O

section 17
id pdf2json/2021.acl-long.96.pdf.json
data O
were O
anonymous O
at O
source O
as O
children O
did O
not O
provide O
names O
or O
contact O
information O
to O
the O
research O
team O
. O

