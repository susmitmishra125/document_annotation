tat-qa: a question answering benchmark on a hybrid of tabular andtextual content in finance.
fengbin zhu1,2, wenqiang lei1∗, youcheng huang 3, chao wang2, shuo zhang4,jiancheng lv3, fuli feng1, tat-seng chua11national university of singapore, 26estates pte ltd, 3sichuan university, 4bloomberg{zhfengbin, wenqianglei}@gmail.com, wangchao@6estates.com.
abstract.
hybrid data combining both tabular and tex-tual content (e.g., ﬁnancial reports) are quitepervasive in the real world.
however, ques-tion answering (qa) over such hybrid data islargely neglected in existing research.
in thiswork, we extract samples from real ﬁnancialreports to build a new large-scale qa datasetcontaining both tabular and textual data,named tat-qa, where numerical reasoningis usually required to infer the answer, suchas addition, subtraction, multiplication, divi-sion, counting, comparison/sorting, and theircompositions.
we further propose a novel qamodel termed tagop, which is capable of rea-soning over both tables and text.
it adopts se-quence tagging to extract relevant cells fromthe table along with relevant spans from thetext to infer their semantics, and then appliessymbolic reasoning over them with a set ofaggregation operators to arrive at the ﬁnal an-swer.
tagop achieves 58.0% in f1, whichis an 11.1% absolute increase over the pre-vious best baseline model, according to ourexperiments on tat-qa.
but this result stilllags far behind the performance of humanexpert, i.e.
it demonstratesthat our tat-qa is very challenging and canserve as a benchmark for training and test-ing powerful qa models that address hybriddata.
our dataset is publicly available for non-commercial use at https://nextplusplus.
github.io/tat-qa/..90.8% in f1..1.introduction.
existing qa systems largely focus on only unstruc-tured text (hermann et al., 2015; rajpurkar et al.,2016; dua et al., 2019; yang et al., 2018; li et al.,2020; nie et al., 2020), structured knowledge base(kb) (berant et al., 2013; yih et al., 2015; talmorand berant, 2018), or semi-structured tables (pasu-pat and liang, 2015; zhong et al., 2017; yu et al.,.
∗∗corresponding author.
2018; zhang and balog, 2019; zhang et al., 2020).
though receiving growing interests (das et al.,2017; sun et al., 2019; chen et al., 2020b, 2021),works on hybrid data comprising of unstructuredtext and structured or semi-structured kb/tablesare rare.
recently, chen et al.
(2020b) attempt tosimulate a type of hybrid data through manuallylinking table cells to wiki pages via hyperlinks.
however, such connection between table and textis relatively loose..in the real world, a more common hybrid dataform is, the table (that usually contains numbers)is more comprehensively linked to text, e.g., se-mantically related or complementary.
such hybriddata are very pervasive in various scenarios likescientiﬁc research papers, medical reports, ﬁnan-cial reports, etc.
the left box of figure 1 showsa real example from some ﬁnancial report, wherethere is a table containing row/column header andnumbers inside, and also some paragraphs describ-ing it.
we call the hybrid data like this examplehybrid context in qa problems, as it contains bothtabular and textual content, and call the paragraphsassociated paragraphs to the table.
to comprehendand answer a question from such hybrid contextrelies on the close relation between table and para-graphs, and usually requires numerical reasoning.
for example, one needs to identify “revenue fromthe external customers” in the describing text so asto understand the content of the table.
as for “howmuch does the commercial cloud revenue accountfor the total revenue in 2019?”, one needs to getthe total revenue in 2019, i.e.
“125, 843 million”from the table and commercial cloud revenue, i.e.
“38.1 billion”, from the text to infer the answer..to stimulate progress of qa research over suchhybrid data, we propose a new dataset, named tat-qa (tabular and textual dataset for questionanswering).
the hybrid contexts in tat-qa areextracted from real-world ﬁnancial reports, each.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3277–3287august1–6,2021.©2021associationforcomputationallinguistics3277figure 1: an example of tat-qa.
the left dashed line box shows a hybrid context.
the rows with blue back-ground are row header while the column with grey is column header.
the right solid line box shows correspondingquestion, answer with its scale, and derivation to arrive at the answer..composed of a table with row/col header and num-bers, as well as at least two paragraphs that de-scribe, analyse or complement the content of thistable.
given hybrid contexts, we invite annotatorswith ﬁnancial knowledge to generate questions thatare useful in real-world ﬁnancial analyses and pro-vide answers accordingly.
it is worth mentioningthat a large portion of questions in tat-qa de-mand numerical reasoning, for which derivationof the answer is also labeled to facilitate develop-ing explainable models.
in total, tat-qa con-tains 16, 552 questions associated with 2, 757 hy-brid contexts from 182 reports..we further propose a novel tagop model basedon tat-qa.
taking as input the given question,table and associated paragraphs, tagop appliessequence tagging to extract relevant cells from thetable and relevant spans from text as the evidences.
then it applies symbolic reasoning over them witha set of aggregation operators to arrive at the ﬁnalanswer.
predicting the magnitude of a number isan important aspect when tackling hybrid data intat-qa, including thousand, million, billion, etc.
that are often omitted or shown only in headers orassociated paragraphs of the table for brevity.
weterm such magnitude of a number as its scale.
takequestion 6 in figure 1 as an example: “how muchof the total revenue in 2018 did not come fromdevices?” the numerical value in the answer isobtained by subtraction: “110, 360 - 5, 134”, whilethe scale “million” is identiﬁed from the ﬁrst-rowheader of the table.
in tagop, we incorporate amulti-class classiﬁer for scale prediction..we test three types of qa models on tat-qa,.
specially addressing tabular, textual, and hybriddata.
our tagop achieves 58.0% in terms of f1,which is a 11.1% absolute increase over the bestbaseline model, according to our experiments ontat-qa.
it is worth noting that the results stilllag far behind performance of human experts, i.e.
90.8% in f1.
we can see that to tackle the qa taskover the hybrid data as in tat-qa is challeng-ing and more effort is demanded.
we expect ourtat-qa dataset and tagop model to serve as abenchmark and baseline respectively to contributeto the development of qa models for hybrid data,especially those requiring numerical reasoning..2 dataset construction and analysis.
we here explain how we construct tat-qa andanalyze its statistics to better reveal its proprieties..2.1 data collection and preprocessing.
in tat-qa there are two forms of data: tablesand their relevant text, which are extracted fromreal-world ﬁnancial reports..in particular, we ﬁrst download about 500 ﬁnan-cial reports released in the past two years froman online website1.
we adopt the table detectionmodel in (li et al., 2019) to detect tables in thesereports, and apply apache pdfbox2 library to ex-tract the table contents to be processed with ourannotation tool.
we only keep those tables with3 ∼ 30 rows and 3 ∼ 6 columns.
finally, about20, 000 candidate tables are retained, which haveno standard schema and lots of numbers inside..1https://www.annualreports.com/2https://pdfbox.apache.org/.
3278#reasoningquestionanswerscalederivation1word matching (38.06%)how much revenue came from linkedin in2018?5,259million-2set of spans(11.94%)which were the bottom 2 revenue items for2017?
linkedin, other--3comparison(5.65%)which year has the lowest revenue?2017--4counting(2.28%)how many revenue items are between 6,000million and 6,500 million in 2019?2-devices ##enterprise services5addition (2.37%)what is the total revenue of commercial cloudfrom 2017 to 2018?42.8billion26.6  + 16.2 6subtraction(16.17%)how much of the total revenue in 2018 did notcome from devices?105,226million110,360 - 5,1347division (3.84%)how much does the commercial cloudrevenue account for the total revenue in 2019?30.28%38.1 billion / 125,843million8composition(19.69%)what was the percentage change in gamingbetween 2018 and 2019?9.98%(11,386 - 10,353) /10,353(in millions)year ended june 30,201920182017server products and cloud services32,62226,129 21,649office products and cloud services31,76928,31625,573windows20,39519,51818,593gaming11,38610,3539,051search advertising7,6287,0126,219linkedin6,7545,2592,271enterprise services6,1245,8465,542devices6,0955,1345,062other3,0702,7932,611total$125,843$110,360$96,571revenue from external customers, classified by significant productand service offerings, was as follows:our commercial cloud revenue, which includes office 365commercial, azure, the commercial portion of linkedin, dynamics365, and other commercial cloud properties, was $38.1 billion, $26.6billion and $16.2 billion in fiscal years 2019, 2018, and 2017,respectively.
these amounts are primarily included in office productsand cloud services, server products and cloud services, andlinkedin in the table above.
the corresponding reports with selected tables arealso kept.
note that these candidate tables maystill contain errors, such as containing too few ormany rows/cols, mis-detected numbers, which willbe manually picked out and deleted or ﬁxed duringthe annotation process..2.2 dataset annotation.
the annotation is done with our self-developed tool.
all the annotators are with ﬁnancial backgroundknowledge.
adding relevant paragraphs to tables we buildvalid hybrid contexts based on the original reportskept in the previous step.
a valid hybrid context intat-qa consists of a table and at least two asso-ciated paragraphs surrounding it, as shown in theleft box in figure 1. to associate enough relevantparagraphs to a candidate table, the annotators ﬁrstcheck whether there are ≥ 2 paragraphs aroundthis table, and then check whether they are rele-vant, meaning the paragraphs should be describing,analysing or complementing the content in the ta-ble.
if yes, then all the surrounding paragraphs willbe associated to this table.
otherwise, the table willbe skipped (discarded).3question-answer pair creation based on thevalid hybrid contexts, the annotators are then askedto create question-answer pairs, where the ques-tions need to be useful in real-world ﬁnancial anal-yses.
in addition, we encourage them to createquestions that can be answered by people withoutmuch ﬁnance knowledge and use common wordsinstead of the same words appeared in the hybridcontext (rajpurkar et al., 2016).
given one hy-brid context, at least 6 questions are generated,including extracted and calculated questions.
forextracted questions, the answers can be a singlespan or multiple spans from either the table or theassociated paragraphs.
for calculated questions,numerical reasoning is required to produce the an-swers, including addition, subtraction, multiplica-tion, division, counting, comparison/sorting andtheir compositions.
furthermore, we particularlyask the annotators to annotate the right scale forthe numerical answer when necessary.
answer type and derivation annotation theanswers in tat-qa have three types: a single spanor multiple spans extracted from the table or text,as well as a generated answer (usually obtainedthrough numerical reasoning).
the annotators will.
3about two thirds of candidate tables were discarded..also need to label its type after they generate ananswer.
for generated answers, the correspondingderivations are provided to facilitate the develop-ment of explainable qa models, including twotypes: 1) an arithmetic expression, like (11, 386 -10, 353)/10, 353) for question 8 in figure 1, whichcan be executed to arrive at the ﬁnal answer; and2) a set of items separated with “##”, like “device## enterprise services” for question 4 in figure 1where the count of items equals the answer.
we fur-ther divide questions in tat-qa into four kinds:span, spans, arithmetic and counting, where thelatter two kinds correspond to the above two typesof deviations, to help us better investigate the nu-merical reasoning capability of a qa model.
answer source annotation for each answer, an-notators are required to specify the source(s) it isderived from, including table, text, and table-text(both).
this is to force the model to learn to ag-gregate information from hybrid sources to inferthe answer, thus lift its generalizability.
for exam-ple, to answer question 7 in figure 1: “how muchdoes the commercial cloud revenue account for thetotal revenue in 2019?”, we can observe from thederivation that “125, 843 million” comes from thetable while “38.1 billion” from text..2.3 quality control.
to ensure the quality of annotation in tat-qa, weapply strict quality control procedures.
competent annotators to build tat-qa, ﬁnan-cial domain knowledge is necessary.
hence, weemploy about 30 university students majored in ﬁ-nance or similar disciplines as annotators.
we giveall candidate annotators a minor test and only thosewith 95% correct rate are hired.
before startingthe annotation work, we give a training session tothe annotators to help them fully understand ourannotation requirements and also learn the usageof our annotation system.
two-round validation for each annotation, weask two different veriﬁers to perform a two-roundvalidation after it is submitted, including check-ing and approval, to ensure its quality.
we haveﬁve veriﬁers in total, including two annotators whohave good performance on this project and threegraduate students with ﬁnancial background.
inthe checking phase, a veriﬁer checks the submittedannotation and asks the annotator to ﬁx it if anymistake or problem is found.
in the approval phase,a different veriﬁer inspects the annotation again.
3279that has been conﬁrmed by the ﬁrst veriﬁer, andthen approves it if no problem is found..2.4 dataset analysis.
averagely, an annotator can label two hybrid con-texts per hour; the whole annotation work lastsabout three months.
finally, we attain a total of2, 757 hybrid contexts and 16, 552 correspondingquestion-answer pairs from 182 ﬁnancial reports.
the hybrid contexts are randomly split into train-ing set (80%), development set (10%) and test set(10%); hence all questions about a particular hybridcontext belong to only one of the splits.
we showthe basic statistics of each split in table 1, and thequestion distribution regarding answer source andanswer type in table 2. in figure 1, we give anexample from tat-qa, demonstrating the variousreasoning types and percentage of each reasoningtype over the whole dataset..statistic.
train.
dev.
test.
# of hybrid contexts# of questionsavg.
rows / tableavg.
cols / tableavg.
paragraphs / tableavg.
paragraph len [words]avg.
question len [words]avg.
answer len [words].
2,20113,2159.44.04.843.612.54.1.
2781,6689.73.94.944.812.44.1.
2781,6699.34.04.642.612.44.3.table 1: basic statistics of each split in tat-qa.
3 tagop model.
we introduce a novel qa model, named tagop,which ﬁrst applies sequence tagging to extract rel-evant cells from the table and text spans from theparagraphs inspired by (li et al., 2016; sun et al.,2016; segal et al., 2020).
this step is analogy toslot ﬁlling or schema linking, whose effectivenesshas been demonstrated in dialogue systems (leiet al., 2018; jin et al., 2018) and semantic pars-ing (lei et al., 2020).
and then tagop performssymbolic reasoning over them with a set of aggre-gation operators to arrive at the ﬁnal answer.
theoverall architecture is illustrated in figure 2..3.1 sequence tagging.
given a question, tagop ﬁrst extracts support-ing evidences from its hybrid context (i.e.
the ta-ble and associated paragraphs) via sequence tag-ging with the inside–outside tagging (io) ap-proach (ramshaw and marcus, 1995).
in particular,it assigns each token either i or o label and takes.
table.
text.
table-text.
total.
spanspanscountingarithmetictotal.
1,8017771064,7477,431.
3,49625851433,902.
1,8421,0372662,0745,219.
7,1392,0723776,96416,552.table 2: question distribution regarding different an-swer types and sources in tat-qa.
those tagged with i as the supporting evidences forproducing the answer.
the given question, ﬂattenedtable by row (herzig et al., 2020) and associatedparagraphs are input sequentially to a transformer-based encoder like roberta (liu et al., 2019), asshown in the bottom part of figure 2, to obtaincorresponding representations.
each sub-token istagged independently, and the corresponding cellin the table or word in the paragraph would be re-garded as positive if any of its sub-tokens is taggedwith i. for the paragraphs, the continuous wordsthat are predicted as positive are combined as aspan.
during testing, all positive cells and spansare taken as the supporting evidences.
formally, foreach sub-token t in the paragraph, the probabilityof the tag is computed as.
ptag.
t = softmax(ffn(ht)).
(1).
where ffn is a two-layer feed-forward networkwith gelu (hendrycks and gimpel, 2016) activa-tion and ht is the representation of sub-token t..3.2 aggregation operator.
next, we perform symbolic reasoning over ob-tained evidences to infer the ﬁnal answer, for whichwe apply an aggregation operator.
in our tagop,there are ten types of aggregation operators.
foreach input question, an operator classiﬁer is ap-plied to decide which operator the evidences wouldgo through; for some operators sensitive to the or-der of input numbers, an auxiliary number orderclassiﬁer is used.
the aggregation operators areexplained as below, covering most reasoning typesas listed in figure 1..• span-in-text: to select the span with the highestprobability from predicted candidate spans.
theprobability of a span is the highest probability ofall its sub-tokens tagged i..• cell-in-table: to select the cell with the highestprobability from predicted candidate cells.
theprobability of a cell is the highest probability ofall its sub-tokens tagged i..3280figure 2:hybrid context is also shown, tagop supports 10 operators, which are described in section 3.2..illustration of the architecture of proposed tagop model.
given question 6 in figure 1 where the.
• spans: to select all the predicted cell and span.
after them, formulated as.
candidates;.
• sum: to sum all predicted cells and spans purely.
consisting of numbers;.
• count: to count all predicted cells and spans;• average: to average over all the predicted cells.
and spans purely consisting of numbers;.
• multiplication: to multiply all predicted cells.
and spans purely consisting of numbers;.
• division: to ﬁrst rank all the predicted cellsand spans purely consisting of numbers basedon their probabilities, and then apply divisioncalculation to top-two;.
• difference: to ﬁrst rank all predicted numericalcells and spans based on their probabilities, andthen apply subtraction calculation to top-two.
• change ratio: for the top-two values after rank-ing all predicted numerical cells and spans basedon their probabilities, compute the change ratioof the ﬁrst value compared to the second one..operator classiﬁer to predict the right aggrega-tion operator, a multi-class classiﬁer is developed.
in particular, we take the vector of [cls] as inputto compute the probability:.
pop = softmax(ffn([cls]).
(2).
where ffn denotes a two-layer feed-forward net-work with the gelu activation.
number order classiﬁer for operators of differ-ence, division and change ratio, the order of theinput two numbers matters in the ﬁnal result.
hencewe additionally append a number order classiﬁer.
porder = softmax(ffn(avg(ht1, ht2)).
(3).
where ffn denotes a two-layer feed-forward net-work with the gelu activation, ht1, ht2 are rep-resentations of the top two tokens according toprobability, and “avg” means average.
for a token,its probability is the highest probability of all itssub-tokens tagged i, and its representation is theaverage over those of its sub-tokens..3.3 scale prediction.
till now we have attained the string or numericalvalue to be contained in the ﬁnal answer.
however,a right prediction of a numerical answer shouldnot only include the right number but also the cor-rect scale.
this is a unique challenge over tat-qa and very pervasive in the context of ﬁnance.
we develop a multi-class classiﬁer to predict thescale.
generally, the scale in tat-qa may benone, thousand, million, billion, and percent.
tak-ing as input the concatenated representation of[cls], the table and paragraphs sequentially, themulti-class classiﬁer computes the probability ofthe scale as.
pscale = softmax(ffn([[cls]; htab; hp]).
(4).
where htab and hp are the representations of thetable and the paragraphs respectively, which are ob-tained by applying an average pooling over the rep-resentations of their corresponding tokens,“;” de-notes concatenation, and ffn denotes a two-layerfeed-forward network with the gelu activation.
after obtaining the scale, the numerical or stringprediction is multiplied or concatenated with the.
3281diffroberta[cls]...operator classfication layerhow...much2018inmillionsrevenuefrom[sep][sep][sep]...51##34$...110##360......[cls]...how...much2018inmillionsrevenuefrom[sep][sep][sep]...51##34$...110##360...iooiooiiiiquestionflattened tableparagraph5,134$ 110,360spanscell-in-tablesumdiff...number order classification layer105,226 millionscale classfication layermillion5,134$ 110,360,diff ()yevidence extraction answer reasoningordersensitivecorresponding scale as the ﬁnal prediction to com-pare with the ground-truth answer respectively..3.4 training.
to optimize tagop, the overall loss is the sum ofthe loss of the above four classiﬁcation tasks:.
l = nll(log(ptag), gtag) +nll(log(pop), gop) +nll(log(pscale), gscale) +nll(log(porder), gorder).
(5).
where nll(·) is the negative log-likelihood loss,gtag and gop come from the supporting evidenceswhich are extracted from the annotated answer andderivation.
we locate the evidence in the table ﬁrstif it is among the answer sources, and otherwise inits associated paragraphs.
note we only keep theﬁrst found if an evidence appears multiple times inthe hybrid context.
gscale uses the annotated scaleof the answer; gorder is needed when the ground-truth operator is one of difference, division andchange ratio, which is obtained by mapping thetwo operands extracted from their correspondingground-truth deviation in the input sequence.
iftheir order is the same as that in the input sequence,gorder = 0; otherwise it is 1..4 experiments and results.
4.1 baselines.
textual qa models we adopt two reading com-prehension (rc) models as baselines over textualdata: bert-rc (devlin et al., 2018), which is asquad-style rc model; and numnet+ v2 4 (ranet al., 2019), which achieves promising perfor-mance on drop that requires numerical reasoningover textual data.
we adapt them to our tat-qa asfollows.
we convert the table to a sequence by row,also as input to the models, followed by tokensfrom the paragraphs.
besides, we add a multi-classclassiﬁer, exactly as in our tagop, to enable thetwo models to predict the scale based on eq.
(4).
tabular qa model we employ tapas for wik-itablequestion (wtq) (herzig et al., 2020) asa baseline over tabular data.
tapas is pretrainedover large-scale tables and associated text fromwikipedia jointly for table parsing.
to train it, weheuristically locate the evidence in the table withthe annotated answer or derivation, which is the.
ﬁrst matched one if a same value appears multipletimes.
in addition, we remove the “numerical rankid” feature in its embedding layer, which ranks allvalues per numerical column in the table but doesnot make sense in tat-qa.
similar to above tex-tual qa setting, we add an additional multi-classclassiﬁer to predict the scale as in eq.
(4).
hybrid qa model we adopt hybrider (chenet al., 2020b) as our baseline over hybrid data,which tackles tabular and textual data fromwikipedia.
we use the code released in the originalpaper5, but adapt it to tat-qa.
concretely, eachcell in the table of tat-qa is regarded as “linked”with associated paragraphs of this table, like hyper-links in the original paper, and we only use its cellmatching mechanism to link the question with thetable cells in its linking stage.
the selected cellsand paragraphs are fed into the rc model in the laststage to infer the answer.
for ease of training ontat-qa, we also omit the prediction of the scale,i.e.
we regard the predicted scale by this model asalways correct..4.2 evaluation metrics.
we adopt the popular exact match (em) andnumeracy-focused f1 score (dua et al., 2019) tomeasure model performance on tat-qa.
how-ever, the original implementation of both metrics isinsensitive to whether a value is positive or negativein the answer as the minus is omitted in evaluation.
since this issue is crucial for correctly interpretingnumerical values, especially in the ﬁnance domain,we keep the plus-minus of a value when calculatingthem.
in addition, the numeracy-focused f1 scoreis set to 0 unless the predicted number multipliedby predicted scale equals exactly the ground truth..4.3 results and analysis.
in the following, we report our experimental resultson dev and test sets of tat-qa.
comparison with baselines we ﬁrst compare ourtagop with three types of previous qa modelsas described in section 4.1. the results are sum-marized in table 3. it can be seen that our modelis always superior to other baselines in terms ofboth metrics, with very large margins over the sec-ond best, namely 50.1/58.0 vs. 37.0/46.9 in em/f1on test set of tat-qa respectively.
this well re-veals the effectiveness of our method that reasonsover both tabular and textual data involving lots.
4https://github.com/llamazing/numnet plus.
5https://github.com/wenhuchen/hybridqa.
3282of numerical contents.
for two textual qa base-lines, numnet+ v2 performs better than bert-rc,which is possibly attributed to the stronger capa-bility of numerical reasoning of the latter, but it isstill worse than our method.
the tabular qa base-line tapas for wtq is trained with only tabulardata in tat-qa, showing very limited capabil-ity to process hybrid data, as can be seen from itsperformance.
the hybrider is the worst amongall baseline models, because it is designed for hy-bridqa (chen et al., 2020b) which does not focuson the comprehensive interdependence of table andparagraphs, nor numerical reasoning..however, all the models perform signiﬁcantlyworse than human performance6, indicating tat-qa is challenging to current qa models and moreefforts on hybrid qa are demanded.
answer type and source analysis furthermore,we analyze detailed performance of tagop w.r.tit can beanswer type and source in table 4.seen that tagop performs better on the questionswhose answers rely on the tables compared tothose from the text.
this is probably because tablecells have clearer boundaries than text spans to themodel, thus it is relatively easy for the model toextract supporting evidences from the tables lever-aging sequence tagging techniques.
in addition,tagop performs relatively worse on arithmeticquestions compared with other types.
this may bebecause the calculations for arithmetic questionsare diverse and harder than other types, indicat-ing the challenge of tat-qa, especially for therequirement of numerical reasoning.
results of tagop with different operators wehere investigate the contributions of the ten aggre-gation operators to the ﬁnal performance of tagop.
as shown in table 5, we devise nine variants ofthe full model of tagop; based on the variant oftagop with only one operator (e.g.
span-in-text),for each of other variants, we add one more op-erator back.
as can be seen from the table, alladded operators can beneﬁt the model performance.
furthermore, we ﬁnd that some operators like span-in-text, cell-in-table, difference and average make.
6the human performance is evaluated by asking annotatorsto answer 50 randomly sampled hybrid contexts (containing301 questions) from our test set.
note the human performanceis still not 100% correct because our questions require rela-tively heavy cognitive load like tedious numerical calculations.
comparing human performance of f1 in squad (rajpurkaret al., 2016) (86.8%) and drop (dua et al., 2019)) (96.4%),the score (90.8%) in our dataset already indicates a goodquality and annotation consistency in our dataset..method.
human.
textual qabert-rcnumnet+ v2.
dev.
test.
em.
-.
f1.
-.
em.
f1.
84.1.
90.8.
9.538.1.
17.948.3.
9.137.0.
18.746.9.tabular qatapas for wtq 18.9.
26.5.
16.6.
22.8.hybrid qahybrider.
6.6.
8.3.
6.3.
7.5.tagop.
55.2.
62.7.
50.1.
58.0.table 3: performance of different models on dev andtest set of tat-qa.
best results are marked in bold..table.
text.
table-text.
total.
em/f1.
em/f1.
em/f1.
em/f1.
56.5/57.8 45.2/70.6 68.2/71.7span66.3/77.0 19.0/59.1 63.2/76.9spanscounting62.1/62.1-/-63.6/63.6arithmetic 41.1/41.1 27.3/27.3 46.5/46.547.8/49.3 43.3/68.7 58.3/62.2total.
54.1/67.960.0/75.162.5/62.542.5/42.550.1/58.0.
table 4: detailed experimental results of tagop w.r.t.
answer types and sources on test set..more contributions than others.
in comparison,sum and multiplication bring little gain or evendecline.
after analysis, we ﬁnd this is because theinstances of sum or multiplication are minor in ourtest set, which are easily inﬂuenced by randomness.
error analysis we furtherinvestigate ourtagop by analysing error cases.
we randomlysample 100 error instances from the test set, andclassify them into ﬁve categories as shown in ta-ble 6, each with an example: (1) wrong evidence(55%), meaning the model obtained wrong support-ing evidence from the hybrid context; (2) missing.
model.
+ span-in-text+ cell-in-table+ spans+ sum+ count+ average+ multiplication+ division+ difference+ change ratio (full).
dev.
test.
em.
13.425.433.633.835.943.344.245.051.455.2.f1.
20.536.041.341.343.550.651.452.558.762.7.em.
14.124.131.331.232.738.237.939.245.150.1.f1.
21.835.339.439.140.645.946.047.553.358.0.table 5: performance with different aggregation opera-tors of tagop model..3283evidence (29%), meaning the model failed to ex-tract the supporting evidence for the answer; (3)wrong calculation (9%), meaning the model failedto compute the answer with the correct support-ing evidence; (4) unsupported calculation (4%),meaning the ten operators deﬁned cannot supportthis calculation; (5) scale error (3%), meaning themodel failed to predict the scale of the numericalvalue in an answer..we can then observe about 84% error is causedby the failure to extract the supporting evidencefrom the table and paragraphs given a question.
this demonstrates more efforts are needed tostrengthen the model’s capability of precisely ag-gregating information from hybrid contexts..after instance-level analysis, we ﬁnd anotherinteresting error resource is the dependence on do-main knowledge.
while we encourage annotatorsto create questions answerable by humans with-out much ﬁnance knowledge, we still ﬁnd domainknowledge is required for some questions.
for ex-ample, given the question “what is the gross proﬁtmargin of the company in 2015?”, the model needsto extract the gross proﬁt and revenue from the hy-brid context and compute the answer according tothe ﬁnance formula (“gross proﬁt margin = grossproﬁt / revenue”).
how to integrate such ﬁnanceknowledge into qa models to answer questions intat-qa still needs further exploration..wrongevidence(55%).
missingevidence(29%).
wrongcalculation(9%).
unsupportedcalculation(4%).
scaleerror(3%).
q: how much did the level 2 ofa changeby from 2018 year end to 2019 year end?
g: 375 - 2,032p: 1,941 - 2,032.q: how many years did adjustedebitda exceed $4,000 million?
g: count(2017, 2018, 2019)p: count(2017, 2018).
q: what is the change in the % of pre-taxloss from 2018 to 2019?
g: 39% - 20%p: 20% - 39%.
q: what is the proportion of investorrelations and consultants over the totaloperating expense in 2019?
g: (105,639 + 245,386) /19,133,139p: 245,386 / 19,133,139.q: what is the closing price in march,2020?
g: 0.22p: 0.22 million.
table 6: examples of error and corresponding percent-age.
q, g, p denote question, ground truth, prediction..5 related work.
qa datasets currently, there are many datasetsfor qa tasks, focusing on text, or kb/table.
tex-tual ones include cnn/daily mail (hermann et al.,2015), squad (rajpurkar et al., 2016), etc.
re-cently deep reasoning over textual data has gainedincreasing attention (zhu et al., 2021), e.g.
multi-hop reasoning (yang et al., 2018; welbl et al.,2018).
drop (dua et al., 2019) is built to de-velop numerical reasoning capability of qa mod-els, which in this sense is similar to tat-qa,but only focuses on textual data.
kb/tabular qaaims to automatically answer questions via well-structured kb (berant et al., 2013; talmor andberant, 2018; yih et al., 2015) or semi-structuredtables (pasupat and liang, 2015; zhong et al., 2017;yu et al., 2018).
comparably, qa over hybrid datareceives limited efforts, focusing on mixture ofkb/tables and text.
hybridqa (chen et al., 2020b)is one existing hybrid dataset for qa tasks, wherethe context is a table connected with wiki pagesvia hyperlinks.
numerical reasoning numerical reasoning is keyto many nlp tasks like question answering (duaet al., 2019; ran et al., 2019; andor et al., 2019;chen et al., 2020a; pasupat and liang, 2015;herzig et al., 2020; yin et al., 2020; zhang andbalog, 2020) and arithmetic word problems (kush-man et al., 2014; mitra and baral, 2016; huanget al., 2017; ling et al., 2017).
to our best knowl-edge, no prior work attempts to develop modelsable to perform numerical reasoning over hybridcontexts..6 conclusion.
we propose a new challenging qa dataset tat-qa, comprising real-word hybrid contexts wherethe table contains numbers and has comprehen-sive dependencies on text in ﬁnance domain.
toanswer questions in tat-qa, the close relation be-tween table and paragraphs and numerical reason-ing are required.
we also propose a baseline modeltagop based on tat-qa, aggregating informa-tion from hybrid context and performing numeri-cal reasoning over it with pre-deﬁned operators tocompute the ﬁnal answer.
experiments show tat-qa dataset is very challenging and more effort isdemanded for tackling qa tasks over hybrid data.
we expect our tat-qa dataset and tagop modelwould serve as a benchmark and baseline respec-tively to help build more advanced qa models,.
3284facilitating the development of qa technologiesto address more complex and realistic hybrid data,especially those requiring numerical reasoning..drop: a reading comprehension benchmark requir-ing discrete reasoning over paragraphs.
in proc.
ofnaacl..acknowledgments.
the authors gratefully acknowledge zhuyun daifor giving valuable suggestions on this study, xin-nan zhang for developing the data annotation tool,and tong ye and ming wei chan for their work onchecking the annotation quality.
our thanks alsogo to all the anonymous reviewers for their positivefeedback.
this research is supported by the nextresearch centre, singapore..references.
daniel andor, luheng he, kenton lee, and emilypitler.
2019. giving bert a calculator: finding op-erations and arguments with reading comprehension.
in emnlp-ijcnlp, pages 5947–5952.
acl..jonathan berant, andrew chou, roy frostig, and percyliang.
2013. semantic parsing on freebase fromquestion-answer pairs.
in proceedings of the 2013conference on empirical methods in natural lan-guage processing, pages 1533–1544, seattle, wash-ington, usa.
acl..kunlong chen, weidi xu, xingyi cheng, zou xi-aochuan, yuyu zhang, le song, taifeng wang,yuan qi, and wei chu.
2020a.
question directedgraph attention network for numerical reasoningin emnlp-ijcnlp, pages 6759–6768.
over text.
acl..wenhu chen, ming-wei chang, eva schlinger,william yang wang, and william w. cohen.
2021.open question answering over tables and text.
iniclr..wenhu chen, hanwen zha, zhiyu chen, wenhanxiong, hong wang, and william yang wang.
2020b.
hybridqa: a dataset of multi-hop question answer-ing over tabular and textual data.
in findings of theassociation for computational linguistics: emnlp,pages 1026–1036.
acl..rajarshi das, manzil zaheer, siva reddy, and andrewmccallum.
2017. question answering on knowl-edge bases and text using universal schema andmemory networks.
in proceedings of the 55th an-nual meeting of the association for computationallinguistics, pages 358–365.
acl..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training ofdeep bidirectional transformers for language under-standing.
corr, abs/1810.04805..dheeru dua, yizhong wang, pradeep dasigi, gabrielstanovsky, sameer singh, and matt gardner.
2019..dan hendrycks and kevin gimpel.
2016. bridgingnonlinearities and stochastic regularizers with gaus-sian error linear units.
corr, abs/1606.08415..karl moritz hermann, tom´aˇs koˇcisk´y, edward grefen-stette, lasse espeholt, will kay, mustafa suleyman,and phil blunsom.
2015. teaching machines to readand comprehend.
in proceedings of the 28th inter-national conference on neural information process-ing systems, pages 1693–1701.
mit press..jonathan herzig, pawel krzysztof nowak, thomasm¨uller, francesco piccinno, and julian eisenschlos.
2020. tapas: weakly supervised table parsing viain proceedings of the 58th annualpre-training.
meeting of the association for computational lin-guistics, pages 4320–4333.
acl..danqing huang, shuming shi, chin-yew lin, and jianyin.
2017. learning ﬁne-grained expressions toin proceedings of thesolve math word problems.
2017 conference on empirical methods in naturallanguage processing, pages 805–814.
acl..xisen jin, wenqiang lei, zhaochun ren, hongshenchen, shangsong liang, yihong zhao, and daweiexplicit state tracking with semi-yin.
2018.in pro-supervisionfor neural dialogue generation.
ceedings of the 27th acm international conferenceon information and knowledge management, pages1403–1412..nate kushman, yoav artzi, luke zettlemoyer, andregina barzilay.
2014. learning to automaticallysolve algebra word problems.
in proceedings of the52nd annual meeting of the association for compu-tational linguistics, pages 271–281.
acl..wenqiang lei, xisen jin, min-yen kan, zhaochunren, xiangnan he, and dawei yin.
2018. sequicity:simplifying task-oriented dialogue systems with sin-gle sequence-to-sequence architectures.
in proceed-ings of the 56th annual meeting of the associationfor computational linguistics (volume 1: long pa-pers), pages 1437–1447..wenqiang lei, weixin wang, zhixin ma, tian gan,wei lu, min-yen kan, and tat-seng chua.
2020.re-examining the role of schema linking in text-in proceedings of the 2020 conference onto-sql.
empirical methods in natural language processing(emnlp), pages 6943–6954..jiaqi li, ming liu, min-yen kan, zihao zheng, zekunwang, wenqiang lei, ting liu, and bing qin.
2020.molweni: a challenge multiparty dialogues-basedmachine reading comprehension dataset with dis-course structure.
corr, abs/2004.05080..minghao li, lei cui, shaohan huang, furu wei, mingzhou, and zhoujun li.
2019. tablebank: a bench-mark dataset for table detection and recognition..3285peng li, wei li, zhengyan he, xuguang wang, yingcao, jie zhou, and wei xu.
2016. dataset andneural recurrent sequence labeling model for open-domain factoid question answering..wang ling, dani yogatama, chris dyer, and phil blun-som.
2017. program induction by rationale genera-tion: learning to solve and explain algebraic wordproblems.
in proceedings of the 55th annual meet-ing of the association for computational linguistics,pages 158–167.
acl..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
corr, abs/1907.11692..arindam mitra and chitta baral.
2016. learning touse formulas to solve simple arithmetic problems.
inproceedings of the 54th annual meeting of the asso-ciation for computational linguistics, pages 2144–2153. acl..liqiang nie, yongqi li, fuli feng, xuemeng song,meng wang, and yinglong wang.
2020. large-scale question tagging via joint question-topic em-bedding learning.
acm transactions on informa-tion systems (tois), 38(2):1–23..panupong pasupat and percy liang.
2015. composi-tional semantic parsing on semi-structured tables.
inproceedings of the 53rd annual meeting of the asso-ciation for computational linguistics and the 7th in-ternational joint conference on natural languageprocessing, pages 1470–1480.
acl..pranav rajpurkar, jian zhang, konstantin lopyrev, andpercy liang.
2016. squad: 100,000+ questionsin emnlp-for machine comprehension of text.
ijcnlp, pages 2383–2392.
acl..lance ramshaw and mitch marcus.
1995. text chunk-in third.
ing using transformation-based learning.
workshop on very large corpora..qiu ran, yankai lin, peng li, jie zhou, and zhiyuanliu.
2019. numnet: machine reading comprehen-sion with numerical reasoning.
in emnlp-ijcnlp,pages 2474–2484..elad segal, avia efrat, mor shoham, amir globerson,and jonathan berant.
2020. a simple and effec-tive model for answering multi-span questions.
inemnlp-ijcnlp, pages 3074–3080.
acl..haitian sun, tania bedrax-weiss, and william cohen.
2019. pullnet: open domain question answeringwith iterative retrieval on knowledge bases and text.
in emnlp-ijcnlp, pages 2380–2390.
acl..huan sun, hao ma, xiaodong he, wen-tau yih, yu su,and xifeng yan.
2016. table cell search for ques-tion answering.
in proceedings of the 25th interna-tional conference on world wide web, www ’16,page 771–782.
international world wide web con-ferences steering committee..alon talmor and jonathan berant.
2018. the web asa knowledge-base for answering complex questions.
in proceedings of the 2018 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long papers), pages 641–651..johannes welbl, pontus stenetorp, and sebastianriedel.
2018. constructing datasets for multi-hopreading comprehension across documents.
transac-tions of the association for computational linguis-tics, pages 287–302..zhilin yang, peng qi, saizheng zhang, yoshua bengio,william cohen, ruslan salakhutdinov, and christo-pher d. manning.
2018. hotpotqa: a dataset fordiverse, explainable multi-hop question answering.
in proceedings of the 2018 conference on empiri-cal methods in natural language processing.
acl..wen-tau yih, ming-wei chang, xiaodong he, andjianfeng gao.
2015. semantic parsing via stagedquery graph generation: question answering withknowledge base.
in proceedings of the 53rd annualmeeting of the association for computational lin-guistics and the 7th international joint conferenceon natural language processing, pages 1321–1331..pengcheng yin, graham neubig, wen-tau yih, and se-bastian riedel.
2020. tabert: pretraining for jointunderstanding of textual and tabular data.
in acl,pages 8413–8426.
acl..tao yu, rui zhang, kai yang, michihiro yasunaga,dongxu wang, zifan li, james ma, irene li, qingn-ing yao, shanelle roman, et al.
2018. spider: alarge-scale human-labeled dataset for complex andcross-domain semantic parsing and text-to-sql task.
in proceedings of the 2018 conference on empiri-cal methods in natural language processing, pages3911–3921..shuo zhang and krisztian balog.
2019..auto-completion for data cells in relational tables.
in pro-ceedings of the 28th acm international conferenceon information and knowledge management, cikm’19, pages 761–770..shuo zhang and krisztian balog.
2020. web tableextraction, retrieval, and augmentation: a survey.
acm trans.
intell.
syst.
technol., 11(2):13:1–13:35..shuo zhang, zhuyun dai, krisztian balog, and jamiecallan.
2020. summarizing and exploring tabulardata in conversational search.
sigir ’20, pages1537–1540..victor zhong, caiming xiong, and richard socher.
2017.seq2sql: generating structured queriesfrom natural language using reinforcement learning.
corr, abs/1709.00103..fengbin zhu, wenqiang lei, chao wang, jianmingzheng, soujanya poria, and tat-seng chua.
2021.retrieving and reading: a comprehensive sur-vey on open-domain question answering.
corr,abs/2101.00774..3286a.3 scale prediction.
we report the proportion of the ground truth scalein an answer and also the performance of our scalepredictor on dev and test set in table 9..scale.
nonethousandmillionbillionpercent.
dev.
test.
% acc.
% acc.
47.620.715.20.416.1.
92.496.892.128.695.9.
50.319.212.9-17.7.
90.195.390.2-95.9.table 9: the proportion of ground truth scale on devand test set of tat-qa with prediction accuracy byscale predictor of tagop..a appendix.
a.1 table analysis.
to maintain the semi-structured nature of ﬁnancialtables, we almost keep the same table structure intat-qa as that in the original ﬁnancial reports.
we sample 100 hybrid contexts from the trainingset to conduct a manual evaluation to assess thecomplexity of the table structures.
speciﬁcally, weanalyze the distribution w.r.t.
the number of rowheaders, as shown in table 7. it can be seen thataround 79% of the tables have two or more row-headers, indicating large difﬁculty in interpretingﬁnancial tables.
in addition, we have also foundthat all sampled tables all have one column header..# of row header proportion (%).
123more than 3.
216892.table 7: distribution of no.
of row-headers in tat-qa..a.2 operator classiﬁer.
we present the proportion of questions that shouldgo through each aggregation operator (groundtruth), as well as the performance of our operatorclassiﬁer on dev and test set in table 8..operator.
dev.
test.
%.
acc.
%.
acc.
span-in-textcell-in-tablespanssumcountaveragemultiplicationdivisiondifferencechange ratioother.
20.921.113.03.41.98.50.21.014.19.36.6.
92.391.296.886.093.8100.033.376.596.696.10.0.
21.321.612.62.52.45.90.11.015.910.26.6.
91.686.793.876.2100.0100.00.087.596.695.30.0.table 8: ground truth proportion of questions thatshould be fed to different operators and prediction ac-curacy by operator classiﬁer of tagop on dev and testset of tat-qa..3287