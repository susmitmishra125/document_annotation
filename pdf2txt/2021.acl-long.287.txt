neuralwoz: learning to collect task-oriented dialoguevia model-based simulation.
sungdong kim1,2 minsuk chang1,2.
sang-woo lee1,2.
naver ai lab1 naver clova2{sungdong.kim, minsuk.chang, sang.woo.lee}@navercorp.com.
abstract.
we propose neuralwoz, a novel dialoguecollection framework that uses model-baseddialogue simulation.
neuralwoz has twopipelined models, collector and labeler.
col-lector generates dialogues from (1) user’s goalinstructions, which are the user context andtask constraints in natural language, and (2)system’s api call results, which is a list ofpossible query responses for user requestsfrom the given knowledge base.
labeler an-notates the generated dialogue by formulatingthe annotation as a multiple-choice problem,in which the candidate labels are extractedfrom goal instructions and api call results.
wedemonstrate the effectiveness of the proposedmethod in the zero-shot domain transfer learn-ing for dialogue state tracking.
in the evalua-tion, the synthetic dialogue corpus generatedfrom neuralwoz achieves a new state-of-the-art with improvements of 4.4% point joint goalaccuracy on average across domains, and im-provements of 5.7% point of zero-shot cover-age against the multiwoz 2.1 dataset.1.
1.introduction.
for a task-oriented dialogue system to be scalable,the dialogue system needs to be able to quicklyadapt and expand to new scenarios and domains.
however, the cost and effort in collecting and an-notating an expanding dataset is not only labor-intensive but also proportional to the size and vari-ety of the unseen scenarios..there are three types of dialogue system expan-sions.
(1) the simplest expansion is the addition ofnew instances in the knowledge base (kb) underthe identical schema.
for example, the addition ofnewly opened restaurants in the kb of restaurantdomain falls under this category.
(2) a slightlymore complicated expansion involves modiﬁca-tions to the kb schema, and possibly the related.
1the code is available at github.com/naver-ai/neuralwoz..figure 1: overview of neuralwoz.
the neuralwoztakes goal instruction for the user side (u) and api callresults for the system side (s) to synthesize dialogue.
first, it generates dialogue from the inputs and then la-bels dialogue state (bt) and active domain (domaint)by turn t on the dialogue..instances.
for example, additions of new constrainttypes to access the kb due to the change in needs ofthe user often require a restructuring of the kb.
ifa dialogue system built with only restaurant searchin mind observes user’s requests about not only“restaurant location” and but also “trafﬁc informa-tion” for navigating, the system now needs a newknowledge base including the additional differentdomain.
(3) the most complex expansion is theone that expands across multiple domains.
for ex-ample, imagine an already built dialogue system.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3704–3717august1–6,2021.©2021associationforcomputationallinguistics3704supported restaurant and hotel reservation domains,but now needs to expand to points of interest orother domains.
it is difﬁcult to expand to new do-main without collecting new data instances andbuilding a new knowledge base, if the schema be-tween the source (restaurant and hotel in this case)and target domain (point of interest) look different.
to support development of scalable dialogue sys-tems, we propose neuralwoz, a model-based dia-logue collection framework.
neuralwoz uses goalinstructions and kb instances for synthetic dia-logue generation.
neuralwoz mimics the mecha-nism of a wizard-of-oz (kelley, 1984; dahlb¨acket al., 1993) and figure 1 illustrates our approach.
neuralwoz has two neural components, collec-tor and labeler.
collector generates a dialogue byusing the given goal instruction and candidate rel-evant api call results from the kb as an input.
labeler annotates the generated dialogue with ap-propriate labels by using the schema structure ofthe dialogue domain as meta information.
morespeciﬁcally, labeler selects the labels from candi-date labels which can be obtained from the goalinstruction and the api call results.
as a result,neuralwoz is able to generate a dialogue corpuswithout training data of the target domain..we evaluate our method for zero-shot domaintransfer task (wu et al., 2019; campagna et al.,2020) to demonstrate the ability to generate corpusfor unseen domains, when no prior training dataexists.
in dialogue state tracking (dst) task withmultiwoz 2.1 (eric et al., 2019), the syntheticdata generated with neuralwoz achieves 4.4%point higher joint goal accuracy and 5.7% pointhigher zero-shot coverage than the existing base-line.
additionally, we examine few-shot and fulldata augmentation tasks using both training dataand synthetic data.
we also illustrate how to collectsynthetic data beyond multiwoz domains, and dis-cuss the effectiveness of the proposed approach asa data collection strategy..our contributions are as follows:.
2 related works.
2.1 wizard-of-oz.
wizard-of-oz (woz) is a widely used approachfor constructing dialogue data (henderson et al.,2014a,b; el asri et al., 2017; eric and manning,2017; budzianowski et al., 2018).
it works by fa-cilitating a role play between two people.
“user”utilizes a goal instruction that describes the contextof the task and details of request and “system” hasaccess to a knowledge base, and query results fromthe knowledge base.
they take turns to converse,while the user makes requests one by one followingthe instructions, the system responds according tothe knowledge base, and labels user’s utterances..2.2 synthetic dialogue generation.
other studies on dialogue datasets use the usersimulator-based data collection approaches (schatz-mann et al., 2007; li et al., 2017; bordes et al.,2017; shah et al., 2018; zhao and eskenazi, 2018;shah et al., 2018; campagna et al., 2020).
they de-ﬁne domain schema, rules, and dialogue templatesto simulate user behavior under certain goals.
theingredients to the simulation are designed by devel-opers and the dialogues are realized by predeﬁnedmapping rules or paraphrasing by crowdworkers..if a training corpus for the target domain ex-ists, neural models that synthetically generates dia-logues can augment the training corpus (hou et al.,2018; yoo et al., 2019).
for example, yoo et al.
(2020) introduce variational hierarchical dialogautoencoder (vhda), where hierarchical latentvariables exist for speaker identity, user’s request,dialog state, and utterance.
they show the effective-ness of their model on single-domain dst tasks.
simulatedchat (mohapatra et al., 2020) also usesgoal instruction for dialogue augmentation.
al-though it does not solve zero-shot learning taskwith domain expansion in mind, we run auxiliaryexperiments to compare with neuralwoz, and theresults are in the appendix d..• neuralwoz, a novel method for generatingdialogue corpus using goal instruction andknowledge base information.
• new state-of-the-art performance on the zero-.
shot domain transfer task.
• analysis results highlighting the potential syn-ergy of using the data generated from neural-woz together with human-annotated data.
2.3 zero-shot domain transfer.
in zero-shot domain transfer tasks, there is no datafor target domain, but there exists plenty of datafor other domains similar to target domain.
solv-ing the problem of domain expansion of dialoguesystems can be quite naturally reducted to solvingzero-shot domain transfer.
wu et al.
(2019) con-duct a landmark study on the zero-shot dst.
they.
3705the training of the dst baselines, trade (wuet al., 2019) and sumbt (lee et al., 2019) in ourexperiments..3.1 problem statement.
domain schema in task-oriented dialogues, thereare two slot types; inf ormable and requestableslots(henderson et al., 2014a; budzianowskiet al., 2018).
the inf ormable slots are thetask constraints to ﬁnd relevantinformationfrom user requests, for example, “restaurant-pricerange”, “restaurant-food”, “restaurant-name”,and “restaurant-book people” in figure 1. therequestable slots are the additional details of userrequests, like “reference number” and “address” infigure 1. each slot s can have its correspondingvalue v in a scenario.
in multi-domain scenarios,each domain has a knowledge base kb, whichconsists of slot-value pairs corresponding to its do-main schema.
the api call results in figure 1 arethe examples of the kb instances of the restaurantdomain..goal instruction the goal instruction, g, is a nat-ural language text describing constraints of userbehavior in the dialogue d including informableand requestable slots.
the paragraph consists offour sentences at the top of figure 1 is an ex-ample.
we deﬁne a set of informable slot-valuepairs that explicitly expressed on the g as cg,which we formally deﬁne as cg = {(sgi ) |1 ≤ i ≤ |cg|, sgi ∈ inf ormable}.
(“restaurant-pricerange”, “expensive”) and (“restaurant-food”,“british”) are examples of the elements of cg (fig-ure 1)..i , v g.api call results the api call results, a, are corre-sponding query results of the cg from kb.
we for-mally deﬁne a = {ai | 1 ≤ i ≤ |a|, ai ∈ kb}.
each ai is associated with its domain, domainai,and with slot-value pairs, cai = {(saik ) | 1 ≤k ≤ |cai|}.
a slot saik can be either informableor requestable slot.
for example, the restaurantinstance, “grafﬁti” in figure 1, is a query resultfrom (“restaurant-pricerange”, “expensive”) and(“restaurant-food”, “british”) described in the goalinstruction..k , v ai.
figure 2: illustration of collector and labeler.
collec-tor takes goal instruction g and api call results a asthe input, and outputs dialogue dt which consists oft turns.
the state candidate c is prepopulated fromthe g and a as a full set for labeling.
finally, labelertakes its value’s subset osi and question q for each slottype si and dialogue context dt from collector, andchooses answer ˜o from the osi ..suggest a model, transferable dialogue state gen-erator (trade), which is robust to a new domainwhere few or no training data for the domain ex-ists.
kumar et al.
(2020) and li et al.
(2021) followthe same experimental setup, and we also compareneuralwoz in the same experiment setup.
ab-stract transaction dialogue model (atdm) (cam-pagna et al., 2020), another method for synthesiz-ing dialogue data, is another baseline for zero-shotdomain transfer tasks we adopt.
they use rules, ab-stract state transition, and templates to synthesizethe dialogue, which is then fed into a model-basedzero-shot learner.
they achieved state-of-the-artin the task using the synthetic data on sumbt(lee et al., 2019), a pretrained bert (devlin et al.,2019) based dst model..3 neuralwoz.
in this section, we describe the components of neu-ralwoz in detail, and how they interact with eachother.
figure 2 illustrates the input and output oftwo modules in neuralwoz.
the synthetic corpus,which collector and labeler made, are used for.
state candidate we deﬁne informable slot-valuepairs that are not explicit in g but accessible by ain d as ca = {(sai ∈inf ormable}.
it contains all informable slot-valuepairs from ca1 to ca|a|.
the elements of ca are.
i ) | 1 ≤ i ≤ |ca|, sa.
i , v a.
3706likely to be uttered by summaries of current statesor recommendations of kb instances by the systemside in d. the system utterance of the second turnin figure 1 is an example (“i recommend grafﬁti.”).
in this case, the slot-value pair (“restaurant-name”,“grafﬁti”) can be obtained from the a, not from theg. finally, state candidate c is the union of cgand ca.
it is a full set of the dialogue state for thedialogue d from given g and a. thus, it can beused as label candidates of dialogue state trackingannotation..3.2 collector.
collector is a sequence-to-sequence model, whichtakes a goal instruction g and api call results aas the input and generates dialogue dt .
the gener-ated dialogue dt = (r1, u1, ..., rt , ut ) is the se-quence of system response r and user utterance u.they are represented by n tokens (w1, ..., wn )2..p(dt |g, a) =.
p(wi|w<i, g, a).
n(cid:89).
i=1.
we denote the input of collector as <s> ⊕ g ⊕</s> ⊕ a, where the ⊕ is concatenate opera-tion.
the <s> and </s> are special tokens toindicate start and seperator respectively.
the to-kenized natural language description of g is di-rectly used as the tokens.
the a takes concate-nation of each ai (a1 ⊕ · · · ⊕ a|a|)3. for eachai, we ﬂatten the result to the token sequence,<domain>⊕domainai ⊕<slot>⊕sai1 ⊕· · · ⊕ <slot> ⊕ sai|cai | ⊕ v ai|cai |.
the <domain>and <slot> are other special tokens as separators.
the objective function of collector is.
1 ⊕v ai.
lc = −.
1mc.
mc(cid:88).
nj(cid:88).
j=1.
i=1.
log p(wj.
i |wj.
<i, gj, aj)..our collector model uses the transformer archi-tecture (vaswani et al., 2017) initialized with pre-trained bart (lewis et al., 2020).
collector istrained using negative log-likelihood loss, wheremc is the number of training dataset for collectorand nj is target length of the j-th instance.
fol-lowing lewis et al.
(2020), label smoothing is usedduring the training with the smoothing parameterof 0.1..2following hosseini-asl et al.
(2020), we also utilize role-speciﬁc special tokens <system> and <user> for the r andu respectively..3we limit the |a| to a maximum 3.
3.3 labeler.
we formulate labeling as a multiple-choice prob-lem.
speciﬁcally, labeler takes a dialogue contextdt = (r1, u1, ..., rt, ut), question q, and a set ofanswer options o = {o1, o2, ..., o|o|}, and selectsone answer ˜o ∈ o. labeler encodes the inputs foreach oi separately, and soi ∈ r1 is the correspond-ing logit score from the encoding.
finally, the logitscore is normalized via softmax function over theanswer option set o..p(oi|dt, q, o) =.
exp(soi).
(cid:80)|o|j.exp(soj ).
,.
soi = labeler(dt, q, oi), ∀i..the input of labeler is a concatenation of dt, q,and oi, <s>⊕dt ⊕</s>⊕q ⊕</s>⊕oi ⊕</s>,with special tokens.
for labeling dialogue statesto dt, we use the slot description for each corre-sponding slot type, si, as the question, for example,“what is area or place of hotel?” for “hotel-area” infigure 2. we populate corresponding answer op-tions osi = {vj|(sj, vj) ∈ c, sj = si} fromthe state candidate set c. there are two specialvalues, dontcare to indicate the user has no pref-erence and n one to indicate the user is yet to spec-ify a value for this slot (henderson et al., 2014a;budzianowski et al., 2018).
we include these val-ues in the osi..for labeling the active domain of dt, whichis the domain at t-th turn of dt, we deﬁne do-main question, for example “what is the domain ortopic of current turn?”, for q and use predeﬁned do-main set odomain as answer options.
in multiwoz,odomain = {“attraction”, “hotel”, “restaurant”,“taxi”, “train”}..our labeler model employs a pretrainedroberta model (liu et al., 2019) as the initialweight.
dialogue state and domain labeling aretrained jointly based on the multiple choice setting.
preliminary result shows that the imbalanced classproblem is signiﬁcant in the dialogue state labels.
most of the ground-truth answers is n one givenquestion4.
therefore, we revise the negative log-likelihood objective to weight other (not-n one)answers by multiplying a constant β to the log-likelihood when the answer of training instance is.
4the number of n one in the training data is about 10.times more than the number of others.
3707not n one.
the objective function of labeler is.
ll = −.
1ml.
ml(cid:88).
t(cid:88).
nq(cid:88).
ljt,i.
t=1.
i=1.
(cid:40).
j=1β log p(˜ojlog p(˜oj.
lj.
t,i =.
t,i|djt , qj.
i , ojt , qji ),i , oji ),.
t,i|dj.
t,i (cid:54)= n one.
if ˜ojotherwise.
, where ˜ojt,i denotes the answer of i-th questionfor j-th training dialogue at turn t, the nq is thenumber of questions, and ml is the number oftraining dialogues for labeler.
we empirically setβ to a constant 5..3.4 synthesizing a dialoguewe ﬁrst deﬁne goal template g.5 g is a delexical-ized version of g by changing each value v gi ex-pressed on the instruction to its slot sgi .
for ex-ample, the “expensive” and “british” of goal in-struction in figure 1 are replaced with “restaurant-pricerange” and “restaurant-food”, respectively.
asa result, domain transitions in g becomes conve-nient..first, g is sampled from a pre-deﬁned set of goaltemplate.
api call results a, which correspondto domain transitions in g, are randomly selectedfrom the kb.
especially, we constrain the sam-pling space of a when the consecutive scenarioamong domains in g have shared slot values.
forexample, the sampled api call results for restaurantand hotel domain should share the value of “area”to support the following instruction “i am lookingfor a hotel nearby the restaurant”.
g and a arealigned to become ga. in other words, each valuefor sgin g is assigned using the correspondingivalues in a.6 then, collector generates dialogued, of which the total turn number is t , given gaand a. more details are in appendix a. nucleussampling (holtzman et al., 2020) is used for thegeneration..we denote dialogue state and active domain atturn t as bt and domaint respectively.
the bt,{(sj, vj,t) | 1 ≤ j ≤ j}, has j number of pre-deﬁned slots and their values at turn t. it meanslabeler is asked j (from slot descriptions) + 1(from domain question) questions regarding dia-logue context dt from collector.
finally, the out-.
5in budzianowski et al.
(2018), they also use templateslike ours when allocating goal instructions to the user in thewizard-of-oz setup..6booking-related slots, e.g., the number of people, time,day, and etc., are randomly sampled for their values since theyare independent of the a..put of labeler is a set of dialogue context, dia-logue state, and active domain at turn t triples{(d1, b1, domain1), ..., (dt , bt , domaint )}..4 experimental setups.
4.1 datasetwe use multiwoz 2.1 (eric et al., 2019) dataset7for our experiments.
it is one of the largest publiclyavailable multi-domain dialogue data and it con-tains 7 domains related to travel (attraction, hotel,restaurant, taxi, train, police, hospital), includingabout 10,000 dialogues.
the multiwoz data is cre-ated using woz so it includes goal instruction pereach dialogue and domain-related knowledge baseas well.
we train our neuralwoz using the goalinstructions and the knowledge bases ﬁrst.
thenwe evaluate our method on dialogue state track-ing with and without synthesized data from theneuralwoz using ﬁve domains (attraction, restau-rant, hotel, taxi, train) in our baseline, and followthe same preprocessing steps of wu et al.
(2019);campagna et al.
(2020)..4.2 training neuralwoz.
we use the pretrained bart-large (lewis et al.,2020) for collector and roberta-base (liu et al.,2019) for labeler.
they share the same byte-levelbpe vocab (sennrich et al., 2016) introduced byradford et al.
(2019).
we train the pipelined modelsusing adam optimizer (kingma and ba, 2017) withlearning rate 1e-5, warming up steps 1,000, andbatch size 32. the number of training epoch is setto 30 and 10 for collector and labeler respectively.
for the training phase of labeler, we use a statecandidate set from ground truth dialogue statesb1:t for each dialogue, not like the synthesizingphase where the options are obtained from goalinstruction and api call results.
we also evaluatethe performance of labeler itself like the train-ing phase with validation data (table 5).
beforetraining labeler on the multiwoz 2.1 dataset, wepretrain labeler on dream8 (sun et al., 2019)to boost labeler’s performance.
this is similar tocoarse-tuning in jin et al.
(2019).
the same hyperparameter setting is used for the pretraining..for the zero-shot domain transfer task, we ex-clude dialogues which contains target domain from.
7https://github.com/budzianowski/multiwoz8the dream is a multiple-choice question answeringdataset in dialogue and includes about 84% of non-extractiveanswers..3708model.
training.
hotel.
restaurant.
attraction.
train.
taxi.
average.
full dataset.
50.5 / 91.4.
61.8 / 92.7.
67.3 / 87.6.
74.0 / 94.0.
72.7 / 88.9.
65.3 / 89.8.trade.
zero-shot (wu)zero-shot (campagna)zero-shot + atdmzero-shot + neuralwoz.
13.7 / 65.619.5 / 62.628.3 / 74.526.5 / 75.1.
13.4 / 54.516.4 / 51.535.9 / 75.642.0 / 84.2.
20.5 / 55.522.8 / 50.034.9 / 62.239.8 / 65.7.
21.0 / 48.922.9 / 48.037.4 / 74.548.1 / 83.9.
60.2 / 73.559.2 / 72.065.0 / 79.965.4 / 79.9.
25.8 / 59.628.2 / 56.840.3 / 73.344.4 / 77.8.zero-shot coverage.
52.5 / 82.2.
68.0 / 90.8.
59.1 / 75.0.
65.0 / 89.3.
90.0 / 89.9.
66.9 / 85.4.full dataset.
51.8 / 92.2.
64.2 / 93.1.
71.1 / 89.1.
77.0 / 95.0.
68.2 / 86.0.
66.5 / 91.1.sumbt.
zero-shotzero-shot + atdmzero-shot + neuralwoz.
19.8 / 63.336.3 / 83.731.3 / 81.7.
16.5 / 52.145.3 / 82.848.9 / 88.4.
22.6 / 51.552.8 / 78.953.0 / 79.0.
22.5 / 49.246.7 / 84.266.9 / 92.4.
59.5 / 74.962.6 / 79.466.7 / 83.9.
28.2 / 58.248.7 / 81.853.4 / 85.1.zero-shot coverage.
60.4 / 88.6.
76.2 / 95.0.
74.5 / 88.7.
86.9 / 97.3.
97.8 / 97.6.
79.2 / 93.4.table 1: experimental results of zero-shot domain transfer on the test set of multiwoz 2.1. joint goal accuracy/ slot accuracy are reported.
the wu indicates original zero-shot scheme of the trade suggested by wu et al.
(2019) and reproduced by campagna et al.
(2020).
the campagna indicates a revised version of the original bycampagna et al.
(2020).
the + indicates the synthesized dialogue is used together for the training..the training data for both collector and labeler.
this means we train our pipelines for every targetdomain separately.
we use the same seed data fortraining as campagna et al.
(2020) did in the few-shot setting.
all our implementations are conductedon naver smart machine learning (nsml) plat-form (sung et al., 2017; kim et al., 2018) using hug-gingface’s transformers library (wolf et al., 2020).
the best performing models, collector and labeler,are selected by evaluation results from the valida-tion set..4.3 synthetic data generation.
we synthesize 5,000 dialogues for every target do-main for both zero-shot and few-shot experiments9,and 1,000 dialogues for full data augmentation.
forzero-shot experiment, since the training data areunavailable for a target domain, we only use goaltemplates that contain the target domain scenario inthe validation set similar to campagna et al.
(2020).
we use nucleus sampling in collector with parame-ters top p ratio in the range {0.92, 0.98} and tem-perature in the range {0.7, 0.9, 1.0}.
it takes abouttwo hours to synthesize 5,000 dialogues using onev100 gpu.
more statistics is in appendix b..4.4 baselines.
use synthetic data (wu et al., 2019).
for data aug-mentation, we use atdm and vhda..atdm refers to a rule-based synthetic data aug-mentation method for zero-shot learning suggestedby campagna et al.
(2020).
it deﬁnes rules includ-ing state transitions and templates for simulatingdialogues and creates about 10,000 synthetic dia-logues per ﬁve domains in the multiwoz dataset.
campagna et al.
(2020) feed the synthetic dialoguesinto zero-shot learner models to perform zero-shottransfer task for dialogue state tracking.
we alsoemploy trade (wu et al., 2019) and sumbt(lee et al., 2019) as baseline zero-shot learners forfair comparisons with the atdm..vhda refers to model-based generation methodusing hierarchical variational autoencoder (yooet al., 2020).
it generates dialogues incorporatinginformation of speaker, goal of the speaker, turn-level dialogue acts, and utterance sequentially.
yooet al.
(2020) augment about 1,000 dialogues forrestaurant and hotel domains in the multiwozdataset.
for a fair comparison, we use tradeas the baseline model for the full data augmenta-tion experiments.
also, we compare ours with thevhda on the single-domain augmentation settingfollowing their report..5 experimental results.
we compare neuralwoz with baseline methodsboth zero-shot learning and data augmentation us-ing multiwoz 2.1 in our experiments.
we use abaseline zero-shot learning scheme which does not.
9in campagna et al.
(2020), the average number of synthe-.
sized dialogue over domains is 10,140..we use both joint goal accuracy (jga) and slotaccuracy (sa) as the performance measurement.
the jga is an accuracy which checks whether allslot values predicted at each turn exactly matchthe ground truth values, and the sa is the slot-wise accuracy of partial match against the grouth.
3709synthetic.
trade.
sumbt.
synthetic.
restaurant.
hotel.
no synatdm.
44.2 / 96.543.0 / 96.4neuralwoz 45.8 / 96.7.
46.7 / 96.746.9 / 96.647.1 / 96.8.no synvhda.
64.1 / 93.164.9 / 93.4neuralwoz 65.8 / 93.6.
52.3 / 91.952.7 / 92.053.5 / 92.1.table 2: full data augmentation on multi-domain dst.
joint goal accuracy / slot accuracy are reported..table 3: full data augmentation on single-domaindst.
joint goal accuracy / slot accuracy are reported.
trade is used for evaluation..truth values.
especially for zero and few-shot set-ting, we follow the previous setup (wu et al.,2019; campagna et al., 2020).
following cam-pagna et al.
(2020), the zero-shot learner modelshould be trained on data excluding the target do-main, and tested on the target domain.
we also addsynthesized data from our neuralwoz which istrained in the same way, i.e., leave-one-out setup,to the training data in the experiment..5.1 zero-shot domain transfer learning.
our method achieves new state-of-the-art of zero-shot domain transfer learning for dialogue statetracking on the multiwoz 2.1 dataset (table 1).
except for the hotel domain, the performance overall target domains is signiﬁcantly better than theprevious sota method.
we discuss the lower per-formance in hotel domain in the analysis section.
following the work of campagna et al.
(2020),we also measure zero-shot coverage, which refersto the accuracy ratio between zero-shot learningover target domain, and fully trained model includ-ing the target domain.
our neuralwoz achieves66.9% and 79.2% zero-shot coverage on tradeand sumbt, respectively, outperforming previousstate-of-the-art, atdm, which achieves 61.2% and73.5%, respectively..5.2 data augmentation on full data setting.
for full data augmentation, our synthesized datacome from fully trained model including all ﬁvedomains in this setting.
table 2 shows that ourmodel still consistently outperforms in full dataaugmentation of multi-domain dialogue state track-ing.
speciﬁcally, our neuralwoz performs 2.8%point better on the joint goal accuracy of tradethan atdm.
our augmentation improves the per-formance by a 1.6% point while atdm degrades.
we also compare neuralwoz with vhda, aprevious model-based data augmentation methodfor dialogue state tracking (yoo et al., 2020).
sincethe vhda only considers single-domain simu-lation, we use single-domain dialogue in hotel.
collector ↓ labeler ↑.
domain.
full.
w/o hotelw/o restaurantw/o attractionw/o trainw/o taxi.
5.0.
5.45.35.35.65.2.
86.8.
79.281.383.483.283.1.table 4: intrinsic evaluation results of neuralwoz onthe validation set of multiwoz 2.1. perplexity andjoint goal accuracy are used for measurement respec-tively.
the “w/o” means the domain is excluded fromthe full data.
different from the zero-shot experiments,the joint goal accuracy is computed by regarding allﬁve domains..and restaurant domains for the evaluation.
table 3shows that our method still performs better thanthe vhda in this setting.
neuralwoz has morethan twice better joint goal accuracy gain than thatof vhda..5.3.intrinsic evaluation of neuralwoz.
table 4 shows the intrinsic evaluation results fromtwo components (collector and labeler) of theneuralwoz on the validation set of multiwoz2.1. we evaluate each component using perplexityfor collector and joint goal accuracy for labeler,respectively.
note that the joint goal accuracy isachieved by using state candidate set, prepopulatedas the multiple-choice options from the groundtruth, b1:t , as the training time of labeler.
it canbe seen as using meta information since its purposeis accurate annotation but not the dialogue statetracking itself.
we also report the results by ex-cluding target domain from full dataset to simulatezero-shot environment.
surprisingly, synthesizeddata from ours performs effectively even though theannotation by labeler is not perfect.
we conductfurther analysis, the responsibility of each model,in the following section..3710figure 3: breakdown of accuracy by slot of hotel do-main in the zero-shot experiments when using syntheticdata.
the analysis is conducted based on trade..6 analysis.
6.1 error analysis.
figure 3 shows the slot accuracy for each slot typein the hotel domain, which is the weakest domainfrom ours.
different from other four domains, onlythe hotel domain has two boolean type slots, “park-ing” and “internet”, which can have only “yes”or “no” as their value.
since they have abstractproperty for the tracking, labeler’s labeling perfor-mance tends to be limited to this domain.
however,it is noticeable that our accuracy of booking relatedslots (book stay, book people, book day) are muchhigher than the atdm’s.
moreover, the model us-ing synthetic data from the atdm totally fails totrack the “book stay” slot.
in the synthesizing pro-cedures of campagna et al.
(2020), they create thedata with a simple substitution of a domain nounphrase when the two domains have similar slots.
for example, “ﬁnd me a restaurant in the city cen-ter” can be replaced with “ﬁnd me a hotel in thecity center” since the restaurant and hotel domainsshare “area” slot.
we presume it is why they out-perform over slots like “pricerange” and “area”..6.2 few-shot learning.
we further investigate how our method is comple-mentary with human-annotated data.
figure 4 il-lustrates our neuralwoz shows a consistent gainin the few-shot domain transfer setting.
unlike theperformance with atdm is saturated as few-shotratio increases, the performance using our neu-ralwoz is improved continuously.
we get about5.8% point improvement from the case which doesnot use synthetic data when using 10% of human-annotated data for the target domain.
it implies ourmethod could be used more effectively with the.
figure 4: few-shot learning result in multiwoz 2.1.the score indicates average across domain.
trade isused for the baseline model..collector.
labeler.
hotel’s jga.
fullw/o hotel.
fullfullw/o hotel fullw/o hotel w/o hotel.
53.530.827.326.5.table 5: result of responsibility analysis.
we comparethe performances of each model with and without thehotel domain in the training data..human-annotated data in a real scenario..6.3 ablation study.
we discover whether collector and labeler aremore responsible for the quality of synthesizing.
table 5 shows ablation results where each modelof neuralwoz is trained the data including orwithholding the hotel domain.
except for the train-ing data for each model, the pipelined models aretrained and dialogues are synthesized in the sameway.
then, we train trade model using the syn-thesized data and evaluate it on hotel domain likethe zero-shot setting.
the performance gain fromcollector which is trained including the target do-main is 4.3% point, whereas the gain from labeleris only 0.8% point.
it implies the generation qualityfrom collector is more responsible for the perfor-mance of the zero-shot learner than accurate anno-tation of labeler..6.4 qualitative analysis.
figure 5 is an qualitative example generated byneuralwoz.
it shows the neuralwoz can gener-ate an unseen movie domain which has a differentschema from the traveling, the meta domain of themultiwoz dataset, even if it is trained on only the.
3711acknowledgments.
we thank sohee yang, gyuwan kim, jung-wooha, and other members of naver ai for theirvaluable comments.
we also thank participants whohelped our preliminary experiments for buildingdata collection protocol..references.
antoine bordes, y-lan boureau, and jason weston.
2017. learning end-to-end goal-oriented dialog..paweł budzianowski, tsung-hsien wen, bo-hsiangtseng, i˜nigo casanueva, stefan ultes, osman ra-madan, and milica gaˇsi´c.
2018. multiwoz - alarge-scale multi-domain wizard-of-oz dataset fortask-oriented dialogue modelling.
in proceedings ofthe 2018 conference on empirical methods in nat-ural language processing, pages 5016–5026, brus-sels, belgium.
association for computational lin-guistics..giovanni campagna, agata foryciarz, mehrad morad-shahi, and monica lam.
2020. zero-shot transferlearning with synthesized data for multi-domain dia-logue state tracking.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 122–132, online.
association forcomputational linguistics..nils dahlb¨ack, arne j¨onsson, and lars ahrenberg.
1993. wizard of oz studies: why and how.
in pro-ceedings of the 1st international conference on intel-ligent user interfaces, pages 193–200..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..layla el asri, hannes schulz, shikhar sharma,jeremie zumer, justin harris, emery fine, rahulmehrotra, and kaheer suleman.
2017. frames: acorpus for adding memory to goal-oriented dialoguein proceedings of the 18th annual sig-systems.
dial meeting on discourse and dialogue, pages 207–219, saarbr¨ucken, germany.
association for com-putational linguistics..mihail eric, rahul goel, shachi paul, adarsh ku-mar, abhishek sethi, peter ku, anuj kumargoyal, sanchit agarwal, shuyang gao, and dilekhakkani-tur.
2019. multiwoz 2.1: a consolidatedmulti-domain dialogue dataset with state correc-tions and state tracking baselines.
arxiv preprintarxiv:1907.01669..figure 5: unseen domain dialogue generation fromneuralwoz.
the movie domain is an example.
it hasvery different domain schema from the domains in mul-tiwoz dataset..dataset.
it is harder to generalize when the schemastructure of the target domain is different from thesource domain.
other examples can be found inappendix c. we would like to extend the neural-woz to more challenging expansion scenario likethese in future work..6.5 comparison on end-to-end task.
to show that our framework can be used for otherdialogue tasks, we test our data augmentationmethod on end-to-end task in multiwoz 2.1. wedescribe the result in appendix d with discussion.
in full data setting, our method achieves 17.46blue, 75.1 inform rate, 64.6 success rate, and87.31 combine rate, showing performance gain us-ing the synthetic data.
appendix d also includesthe comparison and discussion on simulatedchat(mohapatra et al., 2020)..7 conclusion.
we propose neuralwoz, a novel dialogue collec-tion framework, and we show our method achievesstate-of-the-art performance on zero-shot domaintransfer task.
we ﬁnd the dialogue corpus fromneuralwoz is synergetic with human-annotateddata.
finally, further analysis shows that neural-woz can be applied for scaling dialogue system.
we believe neuralwoz will spark further researchinto dialogue system environments where expan-sion target domains are distant from the sourcedomains..3712mihail eric and christopher d. manning.
2017. key-value retrieval networks for task-oriented dialogue..matthew henderson, blaise thomson, and jason d.williams.
2014a.
the second dialog state trackingchallenge.
in proceedings of the 15th annual meet-ing of the special interest group on discourse anddialogue (sigdial), pages 263–272, philadelphia,pa, u.s.a. association for computational linguis-tics..matthew henderson, blaise thomson, and jason dwilliams.
2014b.
the third dialog state trackingchallenge.
in 2014 ieee spoken language technol-ogy workshop (slt), pages 324–329.
ieee..ari holtzman, jan buys, li du, maxwell forbes, andyejin choi.
2020. the curious case of neural textdegeneration..ehsan hosseini-asl, bryan mccann, chien-sheng wu,semih yavuz, and richard socher.
2020. a simplelanguage model for task-oriented dialogue..yutai hou, yijia liu, wanxiang che, and ting liu.
2018. sequence-to-sequence data augmentation forin proceedingsdialogue language understanding.
of the 27th international conference on computa-tional linguistics, pages 1234–1245, santa fe, newmexico, usa.
association for computational lin-guistics..di jin, shuyang gao, jiun-yu kao, tagyoung chung,and dilek hakkani-tur.
2019. mmm: multi-stagemulti-task learning for multi-choice reading compre-hension..john f kelley.
1984. an iterative design methodologyfor user-friendly natural language ofﬁce informationapplications.
acm transactions on information sys-tems (tois), 2(1):26–41..hanjoo kim, minkyu kim, dongjoo seo, jinwoongkim, heungseok park, soeun park, hyunwoo jo,kyunghyun kim, youngil yang, youngkwan kim,the mlaas platformet al.
2018.arxiv preprintwith a real-world case study.
arxiv:1810.09957..nsml: meet.
diederik p. kingma and jimmy ba.
2017. adam: a.method for stochastic optimization..adarsh kumar, peter ku, anuj kumar goyal, angelikimetallinou, and dilek hakkani-tur.
2020. ma-dst:multi-attention based scalable dialog state tracking..hwaran lee, jinsik lee, and tae-yoon kim.
2019.sumbt: slot-utterance matching for universal andscalable belief tracking.
in proceedings of the 57thannual meeting of the association for computa-tional linguistics, pages 5478–5483, florence, italy.
association for computational linguistics..mike lewis, yinhan liu, naman goyal, mar-jan ghazvininejad, abdelrahman mohamed, omer.
levy, veselin stoyanov, and luke zettlemoyer.
2020. bart: denoising sequence-to-sequence pre-training for natural language generation, translation,and comprehension.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 7871–7880, online.
associationfor computational linguistics..shuyang li, jin cao, mukund sridhar, henghui zhu,shang-wen li, wael hamza, and julian mcauley.
2021. zero-shot generalization in dialog state track-ing through generative question answering.
in pro-ceedings of the 16th conference of the europeanchapter of the association for computational lin-guistics: main volume, pages 1063–1074, online.
association for computational linguistics..xiujun li, zachary c. lipton, bhuwan dhingra, li-hong li, jianfeng gao, and yun-nung chen.
2017.a user simulator for task-completion dialogues..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach..biswesh mohapatra, gaurav pandey, danish con-tractor, and sachindra joshi.
2020.simulatedchats for task-oriented dialog: learning to gener-ate conversations from instructions.
arxiv preprintarxiv:2010.10216..alec radford, jeff wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners..jost schatzmann, blaise thomson, karl weilhammer,hui ye, and steve young.
2007. agenda-baseduser simulation for bootstrapping a pomdp dia-in human language technologieslogue system.
2007: the conference of the north american chap-ter of the association for computational linguis-tics; companion volume, short papers, pages 149–152, rochester, new york.
association for compu-tational linguistics..rico sennrich, barry haddow, and alexandra birch.
2016. neural machine translation of rare wordswith subword units.
in proceedings of the 54th an-nual meeting of the association for computationallinguistics (volume 1: long papers), pages 1715–1725, berlin, germany.
association for computa-tional linguistics..pararth shah, dilek hakkani-t¨ur, gokhan t¨ur, ab-hinav rastogi, ankur bapna, neha nayak, andlarry heck.
2018. building a conversational agentovernight with dialogue self-play.
arxiv preprintarxiv:1801.04871..kai sun, dian yu, jianshu chen, dong yu, yejinchoi, and claire cardie.
2019. dream: a challengedataset and models for dialogue-based reading com-prehension..3713nako sung, minkyu kim, hyunwoo jo, youngil yang,jingwoong kim, leonard lausen, youngkwan kim,gayoung lee, donghyun kwak, jung-woo ha, et al.
2017. nsml: a machine learning platform that en-ables you to focus on your models.
arxiv preprintarxiv:1712.05902..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, remi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander rush.
2020. trans-formers: state-of-the-art natural language process-ing.
in proceedings of the 2020 conference on em-pirical methods in natural language processing:system demonstrations, pages 38–45, online.
asso-ciation for computational linguistics..chien-sheng wu, andrea madotto, ehsan hosseini-asl, caiming xiong, richard socher, and pascalefung.
2019. transferable multi-domain state gener-ator for task-oriented dialogue systems.
in proceed-ings of the 57th annual meeting of the association.
for computational linguistics, pages 808–819, flo-rence, italy.
association for computational linguis-tics..kang min yoo, hanbit lee, franck dernoncourt,trung bui, walter chang, and sang-goo lee.
2020.variational hierarchical dialog autoencoder for dia-in proceed-log state tracking data augmentation.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages3406–3425, online.
association for computationallinguistics..kang min yoo, youhyun shin, and sang-goo lee.
2019. data augmentation for spoken language un-derstanding via joint variational generation.
in pro-ceedings of the aaai conference on artiﬁcial intelli-gence, volume 33, pages 7402–7409..yichi zhang, zhijian ou, and zhou yu.
2020. task-oriented dialog systems that consider multiple ap-propriate responses under the same context.
in pro-ceedings of the aaai conference on artiﬁcial intel-ligence, volume 34, pages 9604–9611..tiancheng zhao and maxine eskenazi.
2018. zero-shot dialog generation with cross-domain latent ac-in proceedings of the 19th annual sigdialtions.
meeting on discourse and dialogue, pages 1–10..3714a goal instruction sampling for synthesizing in neuralwoz.
figure 6: an example of sampling goal instruction ga using goal template g and randomly selected api callresults a..b data statistics.
domain.
slots.
attraction.
area, name, type.
hotel.
price range, type, parking, book stay, book day,book people, area, stars, internet, name.
restaurant.
food, price range, area, name, book time, bookday, book people.
taxi.
train.
leave at, destination, departure, arrive by.
destination, day, departure, arrive by, book people,leave at.
# of dialogues.
# of turns.
train valid.
test.
train.
valid.
test.
2,717.
3,381.
401.
416.
395.
394.
8,073.
1,220.
1,256.
14,793.
1,781.
1,756.
3,813.
438.
437.
15,367.
1,708.
1,726.
1,654.
3,103.
207.
484.
195.
494.
4,618.
690.
654.
12,133.
1,972.
1,976.table 6: data statistics of multiwoz 2.1..c additional qualitative examples.
figure 7 shows other examples from our neuralwoz.
the left subﬁgure shows an example of synthesizeddialogue from neuralwoz in a restaurant, which is seen domain and has the same schema from the.
3715# goal template# synthesized dialogues# synthesized turns# synthesized tokens.
attraction4115,00038,655947,791.hotel restaurant4555,00037,230918,065.
4285,00038,112950,272.taxi2155,00045,5421,098,917.train4825,00037,863873,671.full1,0001,00035,053856,581.table 7: statistics of the synthesized data used in neuralwoz using for zero-shot and full augmentation experi-ments..figure 7: qualitative examples of synthesized dialogues from neuralwoz in the restaurant domain..model.
belief state bleu inform success combined.
damd (zhang et al., 2020)simpletod (hosseini-asl et al., 2020)gpt2 (mohapatra et al., 2020)gpt2 + simulatedchat (mohapatra et al., 2020)gpt2 (ours)gpt2 + neuralwoz (ours).
oracleoracleoracleoracleoracleoracle.
damd (zhang et al., 2020)simpletod (hosseini-asl et al., 2020)gpt2 (mohapatra et al., 2020)gpt2 + simulatedchat (mohapatra et al., 2020)gpt2 (ours)gpt2 + neuralwoz (ours).
generatedgeneratedgeneratedgeneratedgeneratedgenerated.
17.316.2215.9515.0617.2717.69.
18.014.9915.9414.6217.3817.46.
80.385.172.880.477.178.1.
72.483.466.272.574.675.1.
65.173.563.762.267.867.6.
57.767.155.453.764.464.6.
9095.5284.286.3689.7290.54.
83.0590.2476.7477.7286.8887.31.table 8: performance of the end-to-end task model..restaurant domain in multiwoz dataset.
however, the “spicy club” is an unseen instance which is newlyadded to the schema for the synthesizing.
the right subﬁgure shows other synthetic dialogue in restaurant,which is a seen domain but has different schema from restaurant domain in multiwoz dataset.
it describesnavigation in-car scenario which is borrowed from kvret dataset (eric and manning, 2017).
it is anon-trivial problem to adapt to unseen scenario, even if it is in the same domain..d additional explanation on comparison in end-to-end task.
to compare our model with the model of (mohapatra et al., 2020), we conduct end-to-end task experimentsthe previous work did.
table 8 illustrates the result.
though the performance of baseline implementation.
3716is different, we can see that the trend of performance improvement is comparable to the report ofsimulatedchat..two studies are also different in terms of modeling.
in our method, all utterances in the dialogue areﬁrst collected based on goal instruction and kb information by collector.
after that, labeler selectsannotations from candidate labels, which can be inducted from goal instruction and kb information.
on the other hand, simulatedchat creates utterance and label sequentially with knowledge base access,for each turn.
thus, each generation of utterance is affected by the generated utterance of labels of theprevious turn..in detail, the two methods also differ in terms of complexity.
simulatedchat creates a model for eachdomain separately, and for each domain, it creates ﬁve neural modules: user response generation, userresponse selector, agent query generator, agent response generator, and agent response selector.
this results25 neural models for data augmentation in the multiwoz experiments.
on the contrary, neuralwoz onlyneeds two neural models for data augmentation: collector and labeler..another notable difference is that simulatedchat does not generate multi-domain data in a natural way.
the strategy of creating a model for each domain not only makes it difﬁcult to transfer the knowledgeto a new domain, but also makes it difﬁcult to create multi-domain data.
in simulatedchat, the dialogueis created for each domain and then concatenated.
our model can properly reﬂect the information of alldomains included in the goal instruction to generate synthetic dialogues, regardless of the number ofdomains..e other experiment details.
the number of parameters of our models is 406m for collector and 124m for labeler, respectively.
bothmodels are trained on two v100 gpus with mixed precision ﬂoating point arithmetic.
it takes about 4 (10epochs) and 24 hours (30 epochs) for the training, respectively.
we optimize hyperparameters of eachmodel, learning rate {1e-5, 2e-5, 3e-5} and batch size {16, 32, 64}, based on greedy search.
we set themaximum sequence length of collector to 768 and the labeler to 512..for the main experiments, we ﬁx hyperparameter settings of trade (learning rate 1e-4 and batch size32) and sumbt (learning rate 5e-5 and batch size 4) same with previous works.
we use the script ofcampagna et al.
(2020) for converting the trade’s data format to the sumbt’s..for gpt2 (radford et al., 2019) based model for the end2end task, we re-implement the model similarwith simpletod (hosseini-asl et al., 2020) but not using action.
thus, it generates dialogue context,dialogue state, database results, and system response in an autoregressive manner.
we also use specialtokens in the simpletod (without special tokens for the action).
we follow preprocessing procedure forthe end2end task, including delexicalization suggested by (budzianowski et al., 2018).
we use 8 for batchsize and 5e-5 for learning rate.
note that we also train our neuralwoz using 30% of training data andsynthesize 5000 dialogues for the end2end experiments.
however, we could not ﬁnd detailed experimentssetup of mohapatra et al.
(2020) including hyperparameter, the seed of each portion of training data, andevaluation, so it is not a fair comparison..3717