bilingual lexicon inductionvia unsupervised bitext construction and word alignment.
haoyue shi âˆ—tti-chicagofreda@ttic.edu.
luke zettlemoyeruniversity of washingtonfacebook ai researchlsz@fb.com.
sida i. wangfacebook ai researchsida@fb.com.
abstract.
bilingual lexicons map words in one languageto their translations in another, and are typi-cally induced by learning linear projections toalign monolingual word embedding spaces.
inthis paper, we show it is possible to producemuch higher quality lexicons with methodsthat combine (1) unsupervised bitext miningand (2) unsupervised word alignment.
directlyapplying a pipeline that uses recent algorithmsfor both subproblems signiï¬cantly improvesinduced lexicon quality and further gains arepossible by learning to ï¬lter the resulting lex-ical entries, with both unsupervised and semi-supervised schemes.
our ï¬nal model outper-forms the state of the art on the bucc 2020shared task by 14 f1 points averaged over 12language pairs, while also providing a more in-terpretable approach that allows for rich rea-soning of word meaning in context.
furtheranalysis of our output and the standard refer-ence lexicons suggests they are of comparablequality, and new benchmarks may be neededto measure further progress on this task.1.
1.introduction.
bilingual lexicons map words in one language totheir translations in another, and can be automati-cally induced by learning linear projections to alignmonolingual word embedding spaces (artetxeet al., 2016; smith et al., 2017; lample et al., 2018,inter alia).
although very successful in practice,the linear nature of these methods encodes unrealis-tic simplifying assumptions (e.g.
all translations ofa word have similar embeddings).
in this paper, weshow it is possible to produce much higher qualitylexicons without these restrictions by introducingnew methods that combine (1) unsupervised bitextmining and (2) unsupervised word alignment..âˆ—work done during internship at facebook ai research.
1code is publicly available at https://github.com/.
facebookresearch/bitext-lexind..we show that simply pipelining recent algo-rithms for unsupervised bitext mining (tran et al.,2020) and unsupervised word alignment (sabetet al., 2020) signiï¬cantly improves bilingual lexi-con induction (bli) quality, and that further gainsare possible by learning to ï¬lter the resulting lexi-cal entries.
improving on a recent method for doingbli via unsupervised machine translation (artetxeet al., 2019), we show that unsupervised miningproduces better bitext for lexicon induction thantranslation, especially for less frequent words..these core contributions are established by sys-tematic experiments in the class of bitext construc-tion and alignment methods (figure 1).
our fullinduction algorithm ï¬lters the lexicon found viathe initial unsupervised pipeline.
the ï¬ltering canbe either fully unsupervised or weakly-supervised:for the former, we ï¬lter using simple heuristics andglobal statistics; for the latter, we train a multi-layerperceptron (mlp) to predict the probability of aword pair being in the lexicon, where the featuresare global statistics of word alignments..in addition to bli, our method can also be di-rectly adapted to improve word alignment andreach competitive or better alignment accuracy thanthe state of the art on all investigated languagepairs.
we ï¬nd that improved alignment in sentencerepresentations (tran et al., 2020) leads to bettercontextual word alignments using local similarity(sabet et al., 2020)..our ï¬nal bli approach outperforms the previ-ous state of the art on the bucc 2020 shared task(rapp et al., 2020) by 14 f1 points averaged over12 language pairs.
manual analysis shows thatmost of our false positives are due to the incom-pleteness of the reference and that our lexicon iscomparable to the reference lexicon and the out-put of a supervised system.
because both of ourkey building blocks make use of the pretraininedcontextual representations from mbart (liu et al.,.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages813â€“826august1â€“6,2021.Â©2021associationforcomputationallinguistics813figure 1: overview of the proposed retrievalâ€“based supervised bli framework.
best viewed in color..2020) and criss (tran et al., 2020), we can alsointerpret these results as clear evidence that lexiconinduction beneï¬ts from contextualized reasoningat the token level, in strong contrast to nearly allexisting methods that learn linear projections onword types..2 related work.
bilingual lexicon induction (bli).
the task ofbli aims to induce a bilingual lexicon (i.e., wordtranslation) from comparable monolingual corpora(e.g., wikipedia in different languages).
followingmikolov et al.
(2013), most methods train a linearprojection to align two monolingual embeddingspaces.
for supervised bli, a seed lexicon is usedto learn the projection matrix (artetxe et al., 2016;smith et al., 2017; joulin et al., 2018).
for un-supervised bli, the projection matrix is typicallyfound by an iterative procedure such as adversariallearning (lample et al., 2018; zhang et al., 2017),or iterative reï¬nement initialized by a statisticalheuristics (hoshen and wolf, 2018; artetxe et al.,2018).
artetxe et al.
(2019) show strong gains overprevious works by word aligning bitext generatedwith unsupervised machine translation.
we showthat retrieval-based bitext mining and contextualword alignment achieves even better performance..word alignment.
word alignment is a funda-mental problem in statistical machine translation,of which the goal is to align words that are transla-tions of each in within parallel sentences (brownet al., 1993).
most methods assume parallel sen-tences for training data (och and ney, 2003; dyeret al., 2013; peter et al., 2017, inter alia).
incontrast, sabet et al.
(2020) propose simalign,which does not train on parallel sentences but in-stead aligns words that have the most similar pre-.
trained multilingual representations (devlin et al.,2019; conneau et al., 2019).
simalign achievescompetitive or superior performance than conven-tional alignment methods despite not using parallelsentences, and provides one of the baseline com-ponents for our work.
we also present a simpleyet effective method to improve performance oversimalign (section 5)..bitext mining/parallel corpus mining.
bitextmining has been a long studied task (resnik, 1999;shi et al., 2006; abdul-rauf and schwenk, 2009,inter alia).
most methods train neural multilingualencoders on bitext, which are then used with efï¬-cent nearest neighbor search to expand the trainingset (espana-bonet et al., 2017; schwenk, 2018;guo et al., 2018; artetxe and schwenk, 2019a, in-ter alia).
recent work has also shown that unsuper-vised mining is possible (tran et al., 2020; keunget al., 2020).
we use criss (tran et al., 2020)2 asone of our component models..3 baseline components.
we build on unsupervised methods for word align-ment and bitext construction, as reviewed below..3.1 unsupervised word alignment.
simalign (sabet et al., 2020) is an unsupervisedword aligner based on the similarity of contextu-alized token embeddings.
given a pair of parallelsentences, simalign computes embeddings us-ing pretrained multilingual language models suchas mbert and xlm-r, and forms a matrix whoseentries are the cosine similarities between everysource token vector and every target token vector..2https://github.com/pytorch/fairseq/.
tree/master/examples/criss.
814gutenmorgen .good morning .danke.thank you .â€¦2200.81.822monolingual corporagutenmorgen.gutenabend.das isteinekatze.
danke.hallo.dasistgut.
â€¦good evening.thank you.
goodbye.this is a cat.howareyou?good morning.â€¦bitext constructiongutenmorgen.
good morning.gutenabend.
good evening.das isteinekatze.
this is a cat.danke.
thank you.â€¦                                      â€¦ word alignmentstatistical feature extractioncooccurrence(good,guten)=2one-to-one align(good, guten) = 2many-to-one align(good, guten) = 0cosine_similarity(good, guten) = 0.8inner_product(good, guten) = 1.8count(good) = 2count(guten) = 2lexicon inductionmulti-layerperceptronğ‘ƒgood,guten=0.95based on the similarity matrix, the argmax algo-rithm aligns the positions that are the simultaneouscolumn-wise and row-wise maxima.
to increaserecall, sabet et al.
(2020) also propose itermax,which applies argmax iteratively while excludingpreviously aligned positions..3.2 unsupervised bitext construction.
we consider two methods for bitext construc-tion: unsupervised machine translation (generation;artetxe et al., 2019, section 3.2) and bitext retrieval(retrieval; tran et al., 2020, section 3.2)..generation artetxe et al.
(2019) train an unsu-pervised machine translation model with mono-lingual corpora, generate bitext with the obtainedmodel, and further use the generated bitext to in-duce bilingual lexicons.
we replace their statisticalunsupervised translation model with criss, a re-cent high quality unsupervised machine translationmodel which is expected to produce much higherquality bitext (i.e., translations).
for each sentencein the two monolingual corpora, we generate atranslation to the other language using beam searchor nucleus sampling (holtzman et al., 2020)..retrieval tran et al.
(2020) show that the crissencoder module provides as a high-quality sentenceencoder for cross-lingual retrieval: they take theaverage across the contextualized embeddings oftokens as sentence representation, perform near-est neighbor search with faiss (johnson et al.,2019),3 and mine bitext using the margin-basedmax-score method (artetxe and schwenk, 2019a).4the score between sentence representations s.and t is deï¬ned by.
score(s, t).
(1).
=.
(cid:80).
cos(s,t(cid:48)).
t(cid:48)âˆˆnnk(t).
cos (s, t)2k + (cid:80)where nnk(Â·) denotes the set of k nearest neigh-bors of a vector in the corresponding space.
in thiswork, we keep the top 20% of the sentence pairswith scores larger than 1 as the constructed bitext..cos(s(cid:48),t)2k.
s(cid:48)âˆˆnnk(s).
,.
4 proposed framework for bli.
our framework for bilingual lexicon inductiontakes separate monolingual corpora and the pre-trained criss model as input, and outputs a list of.
3https://github.com/facebookresearch/.
faiss.
4we used max-score (artetxe and schwenk, 2019a) as it.
strongly outperforms the other methods they proposed..bilingual word pairs as the induced lexicon.
theframework consists of two parts: (i) an unsuper-vised bitext construction module which generatesor retrieves bitext from separate monolingual cor-pora without explicit supervision (section 3.2), and(ii) a lexicon induction module which induces bilin-gual lexicon from the constructed bitext based onthe statistics of cross-lingual word alignment.
forthe lexicon induction module, we compare twoapproaches:fully unsupervised induction (sec-tion 4.1) which does not use any extra supervision,and weakly supervised induction (section 4.2) thatuses a seed lexicon as input..4.1 fully unsupervised induction.
we align the constructed bitext with criss-basedsimalign, and propose to use smoothed matchedratio for a pair of bilingual word type (cid:104)s, t(cid:105).
Ï(s, t) =.
mat(s, t)coc(s, t) + Î».as the metric to induce lexicon, where mat(s, t)and coc(s, t) denote the one-to-one matching count(e.g., guten-good; figure 1) and co-occurrencecount of (cid:104)s, t(cid:105) appearing in a sentence pair respec-tively, and Î» is a non-negative smoothing term.5.
during inference, we predict the target wordt with the highest Ï(s, t) for each source words. like most previous work (artetxe et al., 2016;smith et al., 2017; lample et al., 2018, inter alia),this method translates each source word to exactlyone target word..4.2 weakly supervised induction.
we also propose a weakly supervised method,which assumes access to a seed lexicon.
this lexi-con is used to train a classiï¬er to further ï¬lter thepotential lexical entries..for a pair of word type (cid:104)s, t(cid:105), our classiï¬er uses.
the following global features:.
â€¢ count of alignment: we consider both one-to-one alignment (section 4.1) and many-to-onealignment (e.g., danke-you and danke-thank;figure 1) of s and t separately as two features,since the task of lexicon induction is arguablybiased toward one-to-one alignment..â€¢ count of co-occurrence used in section 4.1..5we use Î» = 20. this reduces the effect of noisy align-the most extreme case is that both mat(s, t) andment:coc(s, t) are 1, but it is probably not desirable despite thehigh matched ratio of 1..815â€¢ the count of s in the source language and t in.
the target language.6.
â€¢ non-contextualized word similarity: we feedthe word type itself into criss, use the av-erage pooling of the output subword embed-dings, and consider both cosine similarity anddot-product similarity as features..for a counting feature c, we take log (c + Î¸c),where Î¸ consists of learnable parameters.
there are7 features in total, which is denoted by x(cid:104)s,t(cid:105) âˆˆ r7.
we compute the probability of a pair of words(cid:104)s, t(cid:105) being in the induced lexicon pÎ¸(s, t)7 by arelu activated multi-layer perceptron (mlp):.
end.
algorithm 1:weakly-supervised lexicon induction..inference algorithm for.
input: thresholds Î´, n,.
model parameters Î¸, source words s.output: induced lexicon ll â† âˆ…for s âˆˆ s do.
((cid:104)s, t1(cid:105), .
.
.
, (cid:104)s, tk(cid:105)) â† bilingual word.
pairs sorted by the descending order ofpÎ¸(s, ti)k(cid:48) = max{j | pÎ¸(s, tj) â‰¥ Î´, j âˆˆ [k]}m = min(n, k(cid:48))l â† l âˆª {(cid:104)s, t1(cid:105), .
.
.
, (cid:104)s, tm(cid:105)}.
Ë†h(cid:104)s,t(cid:105) = relu (cid:0)w1x(cid:104)s,t(cid:105) + b1,.
w2 Â· Ë†h(cid:104)s,t(cid:105) + b2.
pÎ¸(s, t) = Ïƒ.
(cid:17).
(cid:16).
(cid:1).
where Ïƒ(Â·) denotes the sigmoid function, and Î¸ ={w1, b1, w2, b2} denotes the learnable parame-ters of the model..recall that we are able to access a seed lexicon,which consists of pairs of word translations.
inthe training stage, we seek to maximize the loglikelihood:.
Î¸âˆ— = arg max.
(cid:88).
log pÎ¸(s, t).
Î¸.
+.
(cid:104)s,t(cid:105)âˆˆd+(cid:88).
(cid:104)s(cid:48),t(cid:48)(cid:105)âˆˆdâˆ’.
log (cid:0)1 âˆ’ pÎ¸(s(cid:48), t(cid:48))(cid:1) ,.
where d+ and dâˆ’ denotes the positive training set(i.e., the seed lexicon) and the negative training setrespectively.
we construct the negative trainingset by extracting all bilingual word pairs that co-occurred but are not in the seed word pairs..we tune two hyperparameters Î´ and n to max-imize the f1 score on the seed lexicon and usethem for inference, where Î´ denotes the predictionthreshold and n denotes the maximum number oftranslations for each source word, following lavilleet al.
(2020) who estimate these hyperparametersbased on heuristics.
the inference algorithm issummarized in algorithm 1..5 extension to word alignment.
the idea of using an mlp to induce lexicon withweak supervision (section 4.2) can be directly ex-tended to word alignment.
let b = {(cid:104)si, ti(cid:105)}n.i=1.
6simalign sometimes mistakenly align rare words to.
punctuation, and such features can help exclude such pairs..7not to be confused with joint probability..denote the constructed bitext in section 3.2, wheren denotes the number of sentence pairs, and siand ti denote a pair of sentences in the source andtarget language respectively.
in a pair of bitext(cid:104)s, t (cid:105), s = (cid:104)s1, .
.
.
, s(cid:96)s(cid:105) and t = (cid:104)t1, .
.
.
, t(cid:96)s(cid:105)denote sentences consist of word tokens si or ti..for a pair of bitext, simalign with a speci-ï¬ed inference algorithm produces word alignmenta = {(cid:104)ai, bi(cid:105)}i, denoting that the word tokens saiand tbi are aligned.
sabet et al.
(2020) has proposeddifferent algorithms to induce alignment from thesame similarity matrix, and the best method variesacross language pairs.
in this work, we considerthe relatively conservative (i.e., having higher pre-cision) argmax and the higher recall itermax al-gorithm (sabet et al., 2020), and denote the align-ments by aargmax and aitermax respectively..we substitute the non-contextualized word sim-ilarity feature (section 4.2) with contextualizedword similarity where the corresponding word em-bedding is computed by averaging the ï¬nal-layercontextualized subword embeddings of criss.
the cosine similarities and dot-products of theseembeddings are included as features..instead of the binary classiï¬cation in section 4.2,we do ternary classiï¬cation for word alignments.
for a pair of word tokens (cid:104)si, tj(cid:105), the gold labely(cid:104)si,tj (cid:105) is deï¬ned as.
1[(cid:104)i, j(cid:105) âˆˆ aargmax] + 1[(cid:104)i, j(cid:105) âˆˆ aitermax]..intuitively, the labels 0 and 2 represents conï¬-dent alignment or non-alignment by both methods,while the label 1 models the potential alignment.
the mlp takes the features x(cid:104)si,tj (cid:105) âˆˆ r7 of theword token pair, and compute the probability of.
816each label y by.
Ë†h = relu.
(cid:16).
w1x(cid:104)si,tj (cid:105) + b1.
(cid:17).
pÏ†(y | si, tj, s, t ) =.
g = w2 Â· Ë†h + b2exp (gy)y(cid:48) exp (cid:0)gy(cid:48).
(cid:80).
(cid:1) ,.
where Ï† = {w1w2, b1, b2}.
on the trainingstage, we maximize the log-likelihood of ground-truth labels:Ï†âˆ— = arg max.
(cid:88).
Ï†(cid:88).
(cid:88).
(cid:104)s,t (cid:105)âˆˆb.
siâˆˆs.
tj âˆˆt.
log pÏ†(y(cid:104)si,tj (cid:105) | si, tj, s, t )..on the inference stage, we keep all word tokenpairs (cid:104)si, tj(cid:105) that have.
ep [y] :=.
y Â· p (y | si, tj, s, t ) > 1.
(cid:88).
y.vecmap.
popular and robust method for align-ing monolingual word embeddings via a linear pro-jection and extracting lexicons.
here, we use thestandard implementation9 with fasttext vectors(bojanowski et al., 2017)10 trained on the unionof wikipedia and common crawl corpus for eachlanguage.11 we include both supervised and unsu-pervised versions..wm.
wikimatrix (schwenk et al., 2019)12 isa dataset of mined bitext.
the mining methodlaser (artetxe and schwenk, 2019b) is trainedon real bitext and then used to mine more bitextfrom the wikipedia corpora to get the wikimatrixdataset.
we test our lexicon induction method withwikimatrix bitext as the input and compare to ourmethods that do not use bitext supervision..7 bli results and analysis.
as the prediction..7.1 main results.
6 experimental setup and baselines.
throughout our experiments, we use a two-layerperceptron with the hidden size of 8 for both lexi-con induction and word alignment.
we optimize allof our models using adam (kingma and ba, 2015)with the initial learning rate 5 Ã— 10âˆ’4.
for ourbitext construction methods, we retrieve the bestmatching sentence or translate the sentences in thesource language wikipedia; for baseline models,we use their default settings..for evaluation, we use the bucc 2020 blishared task dataset (rapp et al., 2020) and met-ric (f1).
like most recent work, this evaluation isbased on muse (lample et al., 2018).8 we primar-ily report the bucc evaluation because it considersrecall in addition to precision.
however, becausemost recent work only evaluates on precision, weinclude those evaluations in appendix d.we compare the following baselines:.
bucc.
best results from the bucc 2020 (rappet al., 2020) for each language pairs, we take themaximum f1 score between the best closed-trackresults (severini et al., 2020; laville et al., 2020)and open-track ones (severini et al., 2020).
ourmethod would be considered open track since thepretrained models used a much larger data set(common crawl 25) than the bucc 2020 closed-track (wikipedia or wacky; baroni et al., 2009)..we evaluate bidirectional translations from beamsearch (gen; section 3.2), bidirectional transla-tions from nucleus sampling (gen-n; holtzmanet al., 2020),13 and retrieval (rtv; section 3.2).
inaddition, it is natural to concatenate the global sta-tistical features (section 4.2) from both gen andrtv and we refer to this approach by gen-rtv..our main results are presented in table 1. all ofour models (gen, gen-n, rtv, gen-rtv) outper-form the previous state of the art (bucc) by a sig-niï¬cant margin on all language pairs.
surprisingly,rtv and gen-rtv even outperform wikimatrix byaverage f1 score, indicating that we do not needbitext supervision to obtain high-quality lexicons..7.2 automatic analysis.
bitext quality.
since rtv achieves surprisinglyhigh performance, we are interested in how muchthe quality of bitext affects the lexicon inductionperformance.
we divide all retrieved bitexts withscore (eq.
1) larger than 1 equally into ï¬ve sectionswith respect to the score, and compare the lexicon.
9https://github.com/artetxem/vecmap10https://github.com/facebookresearch/.
fasttext.
11https://github.com/facebookresearch/fasttext/blob/master/docs/crawl-vectors.
md;that is, our vecmap baselines have the same dataavailability with our main results..12https://github.com/facebookresearch/.
laser/tree/master/tasks/wikimatrix.
8https://github.com/facebookresearch/.
13we sample from the smallest word set whose cumulative.
muse.
probability mass exceeds 0.5 for next words..817languagepair.
bucc vecmap wm.
weakly-supervisedgen.gen-n.gen-rtv vecmap.
gen.rtv.
unsupervised.
de-ende-fren-deen-esen-fren-ruen-zhes-enfr-defr-enru-enzh-en.
average.
61.576.854.562.665.141.449.571.171.053.757.136.9.
58.4.
37.143.233.245.345.429.231.055.546.251.544.836.1.
41.5.
71.679.862.171.874.454.467.782.382.180.372.764.1.
72.0.de-ende-fren-deen-esen-fren-ruen-zhes-enfr-defr-enru-enzh-en.
avg..73.078.964.477.073.453.169.982.880.980.072.762.5.
72.4.
67.974.259.776.570.548.059.682.476.979.066.858.0.
68.3.
62.679.451.060.261.928.451.571.476.472.751.834.3.
58.5.
66.880.356.265.666.345.451.776.477.375.968.048.1.
64.8.rtv.
73.078.964.477.073.453.169.982.880.980.072.762.5.
72.4.
63.167.357.266.165.541.061.372.374.571.654.049.3.
61.9.
67.779.259.369.669.937.956.875.878.776.159.250.6.
65.1.
64.569.556.668.465.740.860.174.274.772.655.850.9.
62.8.
70.279.162.773.773.143.564.380.380.079.761.152.6.
68.4.
65.870.858.173.767.944.266.179.673.274.260.554.1.
65.7.
74.283.266.075.376.353.168.382.681.783.272.962.5.
73.3.
37.860.636.543.347.815.048.244.464.750.114.713.6.
39.7.
22.127.133.744.144.824.612.852.446.050.442.134.4.
36.2.
70.979.462.575.368.351.367.681.179.179.471.061.3.
70.6.table 1: f1 scores (Ã—100) on the bucc 2020 test set (rapp et al., 2020).
the best number in each row is bolded..lang..rtv-1.
rtv-2.
rtv-3.
rtv-4.
rtv-5.
random rtv-all.
bitext quality: high â†’ low.
table 2: f1 scores (Ã—100) on the test set of the bucc 2020 shared task (rapp et al., 2020).
we use the weaklysupervised algorithm (section 4.2).
the best number in each row is bolded.
rtv-1 is the same as rtv in table 1..induction performance (table 2).
in the table, rtv-1 refers to the bitext of the highest quality and rtv-5 refers to the ones of the lowest quality, in terms ofthe margin score (eq 1).14 we also add a randompseudo bitext baseline (random), where all thebitext are randomly sampled from each languagepair, as well as using all retrieved sentence pairsthat have scores larger than 1 (rtv-all)..in general, the lexicon induction performanceof rtv correlates well with the quality of bitext.
even using the bitext of the lowest quality (rtv-5),it is still able to induce reasonably good bilinguallexicon, outperforming the best numbers reportedby bucc 2020 participants (table 1) on average.
however, rtv achieves poor performance with ran-dom bitext (table 2), indicating that it is only robustto a reasonable level of noise.
while this is a lower-bound on bitext quality, even random bitext doesnot lead to 0 f1 since the model may align any.
14see appendix c for examples from each tier..co-occurrences of correct word pairs even whenthey appear in unrelated sentences..word alignment quality.
we compare the lexi-con induction performance using the same set ofconstructed bitext (rtv) and different word align-ers (table 3).
according to sabet et al.
(2020),simalign outperforms fast align in termsof word alignment.
we observe that such a trendtranslates to resulting lexicon induction perfor-mance well: a signiï¬cantly better word aligner canusually lead to a better induced lexicon..bitext quantity.
we investigate how the bliperformance changes when the quantity of bitextchanges (figure 2).
we use criss with nucleussampling (gen-n) to create different amount ofbitext of the same quality.
we ï¬nd that with only1% of the bitext (160k sentence pairs on average)used by gen-n, our weakly-supervised frameworkoutperforms the previous state of the art (bucc;.
818languages.
simalign.
fast align.
de-ende-fren-deen-esen-fren-ruen-zhes-enfr-defr-enru-enzh-en.
average.
73.078.964.477.073.453.169.982.880.980.072.762.5.
72.4.
69.769.161.272.868.550.766.079.875.877.370.260.2.
68.4.table 3: f1 scores (Ã—100) on the bucc 2020 testset.
models are trained with the retrievalâ€“based bitext(rtv), in the weakly-supervised setting (section 4.2.the best number in each row is bolded..figure 2: f1 scores (Ã—100) on the bucc 2020 testset, produced by our weakly-supervised framework us-ing different amount of bitext generated by criss withnucleus sampling.
100% is the same as gen-n in ta-ble 1. for less than 100%, we uniformly sample thecorresponding amount of bitext; for greater, we gener-ate multiple translations for each source sentence..table 1).
the model reaches its best performanceusing 20% of the bitext (3.2m sentence pairs onaverage) and then drops slightly with even more bi-text.
this is likely because more bitext introducesmore candidates word pairs..dependence on word frequency of gen vs. rtv.
we observe that retrieval-based bitext construction(rtv) works signiï¬cantly better than generation-based ones (gen and gen-n), in terms of lexiconinduction performance (table 1).
to further inves-tigate the source of such difference, we comparethe performance of the rtv and gen as a func-tion of source word frequency or target word fre-quency, where the word frequency are computedfrom the lower-cased wikipedia corpus.
in fig-ure 3, we plot the f1 of rtv and gen when themost frequent k% of words are considered.
whenall words are considered rtv outperform gen for.
(a).
(b).
figure 3: average f1 scores (Ã—100) with our weakly-supervised framework across the 12 language pairs (ta-ble 1) on the ï¬ltered bucc 2020 test set.
results onentries with (a) the k% most frequent source words, and(b) the k% most frequent target words..11 of 12 language pairs except de-fr.
in 6 of 12language pairs, gen does better than rtv for highfrequency source words.
as more lower frequencywords are included, gen eventually does worsethan rtv.
this helps explain why the combinedmodel gen-rtv is even better since gen can havean edge in high frequency words over rtv.
thetrend that f1(rtv) âˆ’ f1(gen) increases as morelower frequency words are included seems true forall language pairs (appendix a)..on average and for the majority of languagepairs, both methods do better on low-frequencysource words than high-frequency ones (figure 3a),which is consistent with the ï¬ndings by bucc2020 participants (rapp et al., 2020)..vecmap.
while bli through bitext construc-tion and word alignment clearly achieves superiorperformance than that through vector rotation (ta-ble 1), we further show that the gap is larger onlow-frequency words (figure 3)..7.3 ground-truth analysis.
following the advice of kementchedjhieva et al.
(2019) that some care is needed due to the in-completeness and biases of the evaluation, weperform manual analysis of selected results.
forchineseâ€“english translations, we uniformly sam-ple 20 wrong lexicon entries according to the eval-uation for both gen-rtv and weakly-supervisedvecmap.
our judgments of these samples areshown in table 4. for gen-rtv, 18/20 of thesesampled errors are actually acceptable translations,whereas for vecmap, only 11/20 are acceptable.
this indicates that the improvement in quality maybe partly limited by the incompleteness of the ref-erence lexicon and the ground truth performanceof our method might be even better.
the sameanalysis for englishâ€“chinese is in appendix b..81915102050100300bitext size6263646566f1(%)020406080100% of source words40455055606570f1rtvgenvecmap020406080100% of target words40455055606570f1rtvgenvecmapgen-rtv.
vecmap.
model.
de-en.
en-fr.
en-hi.
ro-en.
depot (cid:51) ç”³æ˜ endorsingå€‰åº«(cid:55)wasting (cid:51) æ¢ä»¶ preconditionsæµªè²»?
reverse (cid:51) ç§»å‹•moving (cid:51)èƒŒé¢mouths (cid:51) å¤©æ´¥(cid:55)å˜´å·´shanghaiå¯ç¬‘ laughable (cid:51) å€‹æ¡ˆcases (cid:51)conceal (cid:51) ç™¾åˆéš±è—(cid:55)peonydevout (cid:51) ç”³å ±ï¬ling (cid:51)è™”èª ?
è»Šå»‚carriages (cid:51)ç´”æ·¨puriï¬eddeadline (cid:51) æµ·è‰seaweed (cid:51)æˆªæ­¢rÂ´esumÂ´e (cid:51)å°å¤–?
å±¥æ­·foreignclocks (cid:51) æ”¶å®¹æ‰€ asylums (cid:51)é¾(cid:55)effort (cid:51) é–‹å¹• soft-openedåŠªåŠ›ships (cid:51) æœ‰å½¢ intangibleè‰¦(cid:55)penknife (cid:51)states (cid:51) å°åˆ€å·wounded (cid:51) é»‘å±± carpathian (cid:51)å—å‚·sliding (cid:51) è±¡å¾µ symbolise (cid:51)æ»‘å‹•æ¯’ç†å­¸ toxicology (cid:51) ç²¾è¯(cid:55)æ¨ç¿» overthrown (cid:51) åŒè¬€ conspirator (cid:51)(cid:55)ç©¿(cid:55)ç¦®è²Œ courteous (cid:51) åˆ®åˆ€.
wore (cid:51) ç±Œç¢¼ bargainingrollers.
ï¬‚uff-free.
table 4: manually labeled acceptability judgments forrandom 20 error cases made by gen-rtv (left) andvecmap (right).
(cid:51) and (cid:55) denote acceptable and unac-ceptable translation respectively.
?
denotes word pairsthat may be acceptable in rare or speciï¬c contexts..data source.
precision.
recall.
musegen-rtv.
93.496.6.
78.871.9.f1.
85.582.5.table 5: comparison of chinese-english lexiconsagainst manually labeled ground truth.
the best num-ber in each column is bolded..furthermore, we randomly sample 200 sourcewords from the muse zh-en test set, and com-pare the quality between muse translation andthose predicted by gen-rtv.
this comparison ismuse-favored since only muse source wordsare included.
concretely, we take the union ofword pairs, construct the new ground-truth by man-ual judgments (i.e., removing unacceptable pairs),and evaluate the f1 score against the constructedground-truth (table 5).
the overall gap of 3 f1means that a higher quality benchmark is necessaryto resolve further improvements over gen-rtv.
the word pairs and judgments are included in thesupplementary material (section f)..8 word alignment results.
we evaluate different word alignment methods(table 6) on existing word alignment datasets,15.
15http://www-i6.informatik.rwth-aachen.
de/goldalignment (de-en); https://web.eecs..simalign (sabet et al., 2020).
giza++â€ fast alignâ€ garg et al.
(2019)zenkel et al.
(2019).
xlm-r-argmaxâ€ mbart-argmaxcriss-argmaxâˆ—criss-itermaxâˆ—.
mlp (ours)âˆ—.
0.220.300.160.21.
0.190.200.170.180.15.
0.090.160.050.10.
0.070.090.050.080.04.
0.520.62n/an/a.
0.390.450.320.300.28.
0.320.320.230.28.
0.290.290.250.230.22.table 6: average error rate (aer) for word alignment(lower is better).
the best numbers in each column arebolded.
models in the top section require ground-truthbitext, while those in the bottom section do not.
âˆ—: mod-els that involve unsupervised bitext construction.
â€ : re-sults copied from sabet et al.
(2020)..following sabet et al.
(2020).
we investigatefour language pairs: germanâ€“english (de-en),englishâ€“french (en-fr), englishâ€“hindi (en-hi)and romanianâ€“english (ro-en).
we ï¬nd thatthe criss-based simalign already achievescompetitive performance with the state-of-the-artmethod (garg et al., 2019) which requires realbitext for training.
by ensembling the argmaxand itermax criss-based simalign results (sec-tion 5), we set the new state of the art of wordalignment without using any bitext supervision..however, by substituting the criss-basedsimalign in the bli pipeline with our aligner,we obtain an average f1 score of 73.0 for gen-rtv, which does not improve over the result of73.3 achieved by criss-based simalign (ta-ble 1), indicating that further effort is required totake the advantage of the improved word aligner..9 discussion.
we present a direct and effective framework forbli with unsupervised bitext mining and wordalignment, which sets a new state of the art on thetask.
from the perspective of pretrained multilin-gual models (conneau et al., 2019; liu et al., 2020;tran et al., 2020, inter alia), our work shows thatthey have successfully captured information aboutword translation that can be extracted using simi-larity based alignment and reï¬nement.
althoughbli is only about word types, it strongly beneï¬tsfrom contextualized reasoning at the token level..umich.edu/Ëœmihalcea/wpt (en-fr and ro-en); https://web.eecs.umich.edu/Ëœmihalcea/wpt05(en-hi).
820acknowledgment.
we thank chau tran for help with pretrainedcriss models, as well as mikel artetxe, kevingimpel, karen livescu, jiayuan mao and anony-mous reviewers for their valuable feedback on thiswork..references.
sadaf abdul-rauf and holger schwenk.
2009. on theuse of comparable corpora to improve smt perfor-mance.
in proc.
of eacl..mikel artetxe, gorka labaka, and eneko agirre.
2016.learning principled bilingual mappings of word em-beddings while preserving monolingual invariance.
in proc.
of emnlp..mikel artetxe, gorka labaka, and eneko agirre.
2018.a robust self-learning method for fully unsupervisedcross-lingual mappings of word embeddings.
inproc.
of acl..mikel artetxe, gorka labaka, and eneko agirre.
2019.bilingual lexicon induction through unsupervisedmachine translation.
in proc.
of acl..mikel artetxe and holger schwenk.
2019a.
margin-based parallel corpus mining with multilingual sen-tence embeddings.
in proc.
of acl..mikel artetxe and holger schwenk.
2019b.
mas-sively multilingual sentence embeddings for zero-tacl,shot cross-lingual7:597â€“610..transfer and beyond..marco baroni, silvia bernardini, adriano ferraresi,and eros zanchetta.
2009. the wacky wide web: acollection of very large linguistically processed web-crawled corpora.
language resources and evalua-tion, 43(3):209â€“226..piotr bojanowski, edouard grave, armand joulin, andtomas mikolov.
2017. enriching word vectors withsubword information.
tacl, 5:135â€“146..peter f. brown, stephen a. della pietra, vincent j.della pietra, and robert l. mercer.
1993. the math-ematics of statistical machine translation: parameterestimation.
computational linguistics, 19(2):263â€“311..alexis conneau, kartikay khandelwal, naman goyal,vishrav chaudhary, guillaume wenzek, franciscoguzmÂ´an, edouard grave, myle ott, luke zettle-moyer, and veselin stoyanov.
2019. unsupervisedcross-lingual representation learning at scale.
arxivpreprint arxiv:1911.02116..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in proc.
of naacl-hlt..georgiana dinu, angeliki lazaridou, and marco ba-roni.
2015. improving zero-shot learning by mitigat-ing the hubness problem.
in proc.
of iclr..chris dyer, victor chahuneau, and noah a. smith.
2013. a simple, fast, and effective reparameteriza-tion of ibm model 2. in proc.
of naacl-hlt..cristina espana-bonet, adÂ´am csaba varga, albertobarrÂ´on-cedeno, and josef van genabith.
2017. anempirical analysis of nmt-derived interlingual em-beddings and their use in parallel sentence identiï¬-ieee journal of selected topics in signalcation.
processing, 11(8):1340â€“1350..sarthak garg, stephan peitz, udhyakumar nallasamy,and matthias paulik.
2019. jointly learning to alignand translate with transformer models.
in proc.
ofemnlp..mandy guo, qinlan shen, yinfei yang, hemingge, daniel cer, gustavo hernandez abrego, keithstevens, noah constant, yun-hsuan sung, brianstrope, and ray kurzweil.
2018. effective parallelcorpus mining using bilingual sentence embeddings.
in proc.
of wmt..ari holtzman, jan buys, li du, maxwell forbes, andyejin choi.
2020. the curious case of neural textdegeneration.
in proc.
of iclr..yedid hoshen and lior wolf.
2018. non-adversarialunsupervised word translation.
in proc.
of emnlp..jeff johnson, matthijs douze, and hervÂ´e jÂ´egou.
2019.ieee.
billion-scale similarity search with gpus.
trans.
on big data..armand joulin, piotr bojanowski, tomas mikolov,herve jegou, and edouard grave.
2018. loss intranslation: learning bilingual word mapping witha retrieval criterion.
in proc.
of emnlp..yova kementchedjhieva, mareike hartmann, and an-ders sÃ¸gaard.
2019. lost in evaluation: misleadingbenchmarks for bilingual dictionary induction.
inproc.
of emnlp..phillip keung, julian salazar, yichao lu, and noah a.unsupervised bitext mining andsmith.
2020.translation via self-trained contextual embeddings.
tacl, 8:828â€“841..diederik p. kingma and jimmy ba.
2015. adam:in proc.
of.
a method for stochastic optimization.
iclr..guillaume lample, alexis conneau, marcâ€™aurelioranzato, ludovic denoyer, and hervÂ´e jÂ´egou.
2018.word translation without parallel data.
in proc.
oficlr..martin laville, amir hazem, and emmanuel morin.
the bucctaln/ls2n participation at2020.shared task: bilingual dictionary induction fromcomparable corpora.
in proc.
of workshop on build-ing and using comparable corpora..821meng zhang, yang liu, huanbo luan, and maosongsun.
2017. adversarial training for unsupervisedbilingual lexicon induction.
in proc.
of acl..yinhan liu, jiatao gu, naman goyal, xian li, sergeyedunov, marjan ghazvininejad, mike lewis, andluke zettlemoyer.
2020. multilingual denoisingpre-training for neural machine translation.
arxivpreprint arxiv:2001.08210..tomas mikolov, quoc v. le, and ilya sutskever.
2013.exploiting similarities among languages for ma-chine translation..franz josef och and hermann ney.
2003. a systematiccomparison of various statistical alignment models.
computational linguistics, 29(1):19â€“51..jan-thorsten peter, arne nix, and hermann ney.
2017. generating alignments using target fore-sight in attention-based neural machine translation.
the prague bulletin of mathematical linguistics,108(1):27â€“36..reinhard rapp, pierre zweigenbaum, and sergesharoff.
2020. overview of the fourth bucc sharedtask: bilingual dictionary induction from compara-ble corpora.
in proc.
of workshop on building andusing comparable corpora..philip resnik.
1999. mining the web for bilingual text..in proc.
of acl..masoud jalili sabet, philipp dufter, and hinrichschutze.
2020. simalign: high quality word align-ments without parallel training data using static andcontextualized embeddings.
in findings of emnlp..holger schwenk.
2018. filtering and mining paralleldata in a joint multilingual space.
in proc.
of acl..holger schwenk, vishrav chaudhary, shuo sun,hongyu gong, and francisco guzmÂ´an.
2019. wiki-matrix: mining 135m parallel sentences in 1620arxiv preprintlanguage pairs from wikipedia.
arxiv:1907.05791..silvia severini, viktor hangya, alexander fraser, andhinrich schÂ¨utze.
2020. lmu bilingual dictionaryinduction system with word surface similarity scoresfor bucc 2020. in proc.
of workshop on buildingand using comparable corpora..lei shi, cheng niu, ming zhou, and jianfeng gao.
2006. a dom tree alignment model for mining par-allel data from the web.
in proc.
of acl..samuel l smith, david hp turban, steven hamblin,and nils y hammerla.
2017. ofï¬‚ine bilingual wordvectors, orthogonal transformations and the invertedsoftmax.
in proc.
of iclr..chau tran, yuqing tang, xian li, and jiatao gu.
2020.cross-lingual retrieval for iterative self-supervisedtraining.
in proc.
of neurips..thomas zenkel, joern wuebker, and john denero.
2019. adding interpretable attention to neural trans-arxivlation models improves word alignment.
preprint arxiv:1901.11359..822vided into 5 sections with respect to the similarity-based margin score (eq 1).
the chinese sentencesare automatically converted to traditional chi-nese alphabets using chinese converter,16to keep consistent with the muse dataset..based on our knowledge about these languages,we see that the rtv-1 mostly consists of correcttranslations.
while the other sections of bitext areof less quality, sentences within a pair are highly re-lated or can be even partially aligned; therefore ourbitext mining and alignment framework can stillextract high-quality lexicon from such imperfectbitext..d results: p@1 on the muse dataset.
precision@1 (p@1) is a widely applied metric toevaluate bilingual lexicon induction (smith et al.,2017; lample et al., 2018; artetxe et al., 2019, interalia), therefore we compare our models with exist-ing approaches in terms of p@1 as well (table 9).
our fully unsupervised method with retrieval-basedbitext outperforms the previous state of the art(artetxe et al., 2019) by 4.1 average p@1, andachieve competitive or superior performance on allinvestigated language pairs..e error analysis.
to understand the remaining errors, we randomlysampled 400 word pairs from the induced lexi-con and compare them to ground truth as andgoogle translate via =googletranslate(a1,"zh", "en").
all error cases are included in ta-ble 10. in overall precision, our induced lexicon iscomparable to the output of google translate apiwhere there are 17 errors for gen-rtv 14 errorsfor google and 4 common errors..appendices.
a language-speciï¬c analysis.
while figure 3 shows the average trend of f1scores with respect to the portion of source wordsor target words kept, we present such plots for eachlanguage pair in figure 4 and 5. the trend of eachseparate method is inconsistent, which is consistentto the ï¬ndings by bucc 2020 participants (rappet al., 2020).
however, the conclusion that rtvgains more from low-frequency words still holdsfor most language pairs..b acceptability judgments for en â†’ zh.
gen-rtv.
vecmap.
(cid:55).
viewing.
hubbard.
incredible.
0 (cid:51) tons.
è©±é¡Œ (cid:51) danny.
æ‰¶ç®• (cid:55)southwestern è¥¿å—éƒ¨ (cid:51) spiritism(cid:55)johnsubjectå¨å»‰æ–¯ (cid:55)screenwriter åŠ‡ä½œå®¶ ?
(cid:55)preschool å­¸é½¡å‰ (cid:51) swizzè§€è³ ?
palestinepalestineç¦ä»¤ (cid:51)strengthening å¼·åŒ– (cid:51) prohibitionæ»¿è¼‰ (cid:55)zeroinsurance ä¿éšªå…¬å¸ (cid:55)å¸•æ–¯å¡ (cid:51)(cid:55)christinalineså·¨å¤§ (cid:51)suburbanä¼°å€¼ (cid:55)honorableæ²™è³ª (cid:51)placementä¸éå¾Œ (cid:55)lesothoç…è»Šç‡ˆ ?
shanxiregistration æ³¨å†Š (cid:51) horoscope ç”Ÿè¾°å…«å­— (cid:55)protestors æŠ—è­°è€… (cid:51) busanä»å· (cid:55)èº²è— (cid:51)å‰· (cid:51) hidingshovelä¸€æ–¹ (cid:51) entryé—œæ™‚ (cid:55)sideæ¹æµ (cid:51) weekends é›™ä¼‘æ—¥ ?
turbulenceæŒæ—— (cid:51)ï¬‚agbeareromnibus.
pascalç·šè·¯ (cid:51) claudiaå¸‚éƒŠ (cid:51) massiveå°Šè²´ ?
equityç½®å…¥ (cid:51) sandy.
èŠç´¢æ‰˜ (cid:51) fwdshanxi.
omnibus.
taillight.
(cid:55).
(cid:55).
table 7: manually labeled acceptability judgments forrandom 20 error cases in english to chinese translationmade by gen-rtv and vecmap..we present error analysis for the induced lexiconfor english to chinese translations (table 7) us-ing the same method as table 4. in this direction,many of the unacceptable cases are copying en-glish words as their chinese translations, which isalso observed by rapp et al.
(2020).
this is due toan idiosyncrasy of the evaluation data where manyenglish words are considered acceptable chinesetranslations of the same words..c examples for bitext in different.
sections.
we show examples of mined bitext with differentquality (table 8), where the mined bitexts are di-.
16https://pypi.org/project/.
chinese-converter/.
823figure 4: f1 scores with respect to portion of source words kept for each investigated language pair, analogous tofigure 3a..figure 5: f1 scores with respect to portion of target words kept for each investigated language pair, analogous tofigure 3b..824020406080100% of source words (de-en)3540455055606570f1rtvgenvecmap020406080100% of source words (de-fr)4550556065707580f1rtvgenvecmap020406080100% of source words (en-de)253035404550556065f1rtvgenvecmap020406080100% of source words (en-fr)45505560657075f1rtvgenvecmap020406080100% of source words (en-es)45505560657075f1rtvgenvecmap020406080100% of source words (en-ru)303540455055f1rtvgenvecmap020406080100% of source words (en-zh)303540455055606570f1rtvgenvecmap020406080100% of source words (fr-de)4050607080f1rtvgenvecmap020406080100% of source words (fr-en)50556065707580f1rtvgenvecmap020406080100% of source words (es-en)556065707580f1rtvgenvecmap020406080100% of source words (ru-en)45505560657075f1rtvgenvecmap020406080100% of source words (zh-en)3540455055606570f1rtvgenvecmap020406080100% of target words (de-en)3540455055606570f1rtvgenvecmap020406080100% of target words (de-fr)4550556065707580f1rtvgenvecmap020406080100% of target words (en-de)253035404550556065f1rtvgenvecmap020406080100% of target words (en-fr)45505560657075f1rtvgenvecmap020406080100% of target words (en-es)45505560657075f1rtvgenvecmap020406080100% of target words (en-ru)303540455055f1rtvgenvecmap020406080100% of target words (en-zh)303540455055606570f1rtvgenvecmap020406080100% of target words (fr-de)4050607080f1rtvgenvecmap020406080100% of target words (fr-en)50556065707580f1rtvgenvecmap020406080100% of target words (es-en)556065707580f1rtvgenvecmap020406080100% of target words (ru-en)4550556065707580f1rtvgenvecmap020406080100% of target words (zh-en)35404550556065f1rtvgenvecmapzh-en è¨±å¤šè‡ªç„¶çš„å•é¡Œå¯¦éš›ä¸Šæ˜¯æ‰¿è«¾å•é¡Œã€‚rtv-1 å¯’å†·æ°£å€™å¯èƒ½æœƒå¸¶ä¾†ç‰¹æ®ŠæŒ‘æˆ°ã€‚.
many natural problems are actually promise problems.
cold climates may present special challenges.
å¾ˆé¡¯ç„¶,æ›¾ç¶“åœ¨æŸå€‹å ´åˆé”æˆäº†å…¶æ‰€ä¸çŸ¥é“çš„æŸç¨®å”è­°ã€‚i thought theyâ€™d come to some kind of an agreement.
åŠ‡æƒ…ç™¼å±•é †åºèˆ‡åŸä½œæ¼«ç•«æœ‰äº›ä¸åŒã€‚the plotline is somewhat different from the ï¬rst series.
ä»–ä¹Ÿå‰µä½œéæ²¹ç•«å’Œå£ç•«ã€‚he also made sketches and paintings..zh-en æ­¤ç¯€ç›®è¢«æ‰¹è©•ç‚ºå®£æšå½ç§‘å­¸å’Œé‡å²ã€‚rtv-2 å¨è—ç”ºé«”è‚²é‹å‹•å ´.
ä»–æ˜¯å¥¹çš„ç¥è–é†«å¸«å’Œä¿è­·è€…ã€‚å…¶å¾Œä»¥5,000è‹±éŠè½‰æœƒåˆ°ç›§é “ã€‚æ»¬ç”Ÿå’Œé˜¿å¯¶æ˜¯å°èªªçš„å…©å€‹ä¸»è¦äººç‰©ã€‚.
the book was criticized for misrepresenting nutritional science.
kawagoe sports park athletics stadiumheâ€™s her protector and her provider.
he later returned to morton for Â£15,000.
lawrence and joanna are the playâ€™s two major characters..voters do not register as members of political parties.
he was formerly an editor of â€œthe new york times book reviewâ€ .
the m120 mortar system consists of the following major components:he later returned to morton for Â£15,000.
and arrived at hobart town on 8 november..zh-en ä¸€èˆ¬ä¸Šæ²’æœ‰æœƒå“¡åŠ å…¥åˆ°æ¯æ”¿é»¨ã€‚rtv-3 æ›¾ä»»ã€Šç´ç´„æ™‚å ±ã€‹æ›¸è©•äººã€‚.
48vå¾®æ··ç³»çµ±ä¸»è¦ç”±ä»¥ä¸‹çµ„ä»¶æ§‹æˆ:å…¶å¾Œä»¥5,000è‹±éŠè½‰æœƒåˆ°ç›§é “ã€‚2æœˆ25æ—¥å¾é¦™æ¸¯æŠµé”æ±•é ­1261å¹´,æ‹‰ä¸å¸åœ‹è¢«æ¨ç¿»,æ±ç¾…é¦¬å¸åœ‹å¾©åœ‹ã€‚.
zh-enrtv-4 è€Œé€™æ¬¡èˆªè¡Œä¹Ÿè­‰æ˜ä»–çš„æŒ‡è²¬æ˜¯æ­£ç¢ºçš„ã€‚ä¸¦å·²ç¶“æ”¾å‡ºæˆªé¢å’Œè©¦ç”¨ç‰ˆã€‚å®ƒé‡370å…‹,ç”±ä¸€æ ¹æŠŠå’Œä¹æ ¹ç´¢çµ„æˆã€‚æ´¾è·¯åœ¨éšŠä¸­çš„å‰µé€ åŠ›å¯è¬‚ç„¡å‡ºå…¶å³,åŠŸä¸å¯æŠ¹ã€‚.
zh-en æ­¤è¦å¡ä¹Ÿç”¨ä»¥é®å£“çš„éƒ¨è½ã€‚rtv-5 ä¸é,é€™31æ¬¡å‡ºå ´åªæœ‰11æ¬¡æ˜¯é¦–ç™¼ã€‚ç”Ÿæ–¼ç¾åœ‹ç´ç´„å·å¸ƒé­¯å…‹æ—ã€‚2014å¹´7æœˆ14æ—¥,çµ„åœ˜æˆç‚ºä¸€å“¡ã€‚ç›¾ä¸Šæœ‰å¥”èµ°ä¸­çš„ç…å­ã€‚.
de-envon 1988 bis 1991 lebte er in venedig.
rtv-1 der film beginnt mit folgendem zitat:.
geschichte von saint vincent und den grenadinendie spuren des kriegs sind noch allgegenwÂ¨artig.
saint-paul (savoie).
de-enrtv-2 dort begegnet sie raymond und seiner tochter sarah..nanderbarsche sind nicht brutpï¬‚egend..armansperg wurde zum premierminister ernannt.
diese arbeit wird von den mÂ¨annchen ausgefÂ¨uhrt.
august von limburg-stirum.
es gibt mehrere anbieter der komponenten..de-enrtv-3 doch dann werden sie von piraten angegriffen.
wird nicht die tiefste â€“ also meist 6.ihre blÂ¨ute hatte sie zwischen 1976 und 1981.er brachte reliquien von der hl..de-enrtv-4.
de-enrtv-5.
gespielt wird meistens mitte juni.
schuppiger schlangensterndas artwork stammt von dave field.
ammonolyse ist eine der hydrolyse analoge reaktion,die pellenz gliedert sich wie folgt:.
auch nicolau war praktizierender katholik.
im jahr 2018 lag die mitgliederzahl bei 350.er trÂ¨agt die fahrgestellnummer tnt 102.als moderator war benjamin jaworskyj angereist.
benachbarte naturrÂ¨aume und landschaften sind:.
the byzantine empire was fully reestablished in 1261.this proved that he was clearly innocent of the charges.
a cut-down version was made available for downloading.
it consists of 21 large gears and a 13 meters pendulum.
still, the german performance was not ï¬‚awless..that were used by nomads in the region.
in those 18 games, the visiting team won only three times.
he was born in frewsburg, new york, usa.
roy joined the group on 4/18/98.
far above, the lonely hawk ï¬‚oating..from 1988-1991 he lived in venice.
the movie begins with the following statement:history of saint vincent and the grenadinessome signs of the people are still there.
saint-paul, savoie.
oxpeckers are fairly gregarious.
there she meets sara and her husband.
mansur was appointed the prime minister.
parental care is performed by males.
house of limburg-stirum.
there are several components to the site.
they are attacked by saracen pirates.
the shortest, probably ï¬ve.
the crop trebled between 1955 and 1996.eulogies were given by the rev..it is played principally on weekends.
plains garter snakethe artwork is by mike egan.
hydroxylation is an oxidative process.
the pellenz is divided as follows:.
cassar was a practicing roman catholic.
the membership in 2017 numbered around 1,000.it carries the registration number awk 230.dmitry nagiev appeared as the presenter.
neighboring hydrographic watersheds are:.
table 8: examples of bitext in different sections (section 7.2).
we see that tier 1 has majority parallel sentenceswhereas lower tiers have mostly similar but not parallel sentences..825en-es.
en-fr.
en-de.
en-ru.
â†’ â†.
â†’ â†.
â†’ â†.
â†’ â†.
nearest neighborâ€ inv.
nearest neighbor (dinu et al., 2015)â€ inv.
softmax (smith et al., 2017)â€ csls (lample et al., 2018)â€ .
81.980.681.782.5.
82.877.682.784.7.
81.681.381.783.3.
81.779.081.783.4.
73.369.873.575.6.
72.369.772.375.3.
44.343.744.447.4.
65.654.165.567.2.artetxe et al.
(2019)â€ .
rtv (ours)gen (ours).
87.0.
87.9.
86.0.
86.2.
81.9.
80.2.
50.4.
71.3.
89.981.5.
93.588.7.
84.581.6.
89.588.6.
83.078.9.
88.683.7.
54.535.4.
80.768.2.avg..72.969.572.974.9.
78.9.
83.075.8.table 9: p@1 of our lexicon inducer and previous methods on the standard muse test set (lample et al., 2018),where the best number in each column is bolded.
the ï¬rst section consists of vector rotationâ€“based methods, whileartetxe et al.
(2019) conduct unsupervised machine translation and word alignment to induce bilingual lexicons.
all methods are tested in the fully unsupervised setting.
â€ : numbers copied from artetxe et al.
(2019)..src.
gen-rtv.
google trans..writerslaughingauthoritariancoupletstattooedhomeownersgrandeheadereditorialwindsï¬rewoodbowl.
ç·¨åŠ‡å¯ç¬‘æ¥µæ¬ŠæŠ¼éŸ»çƒ™å°æ¥­ä¸»å®‰å¨œåŒ…é ­ç·¨è¼¯é™£é¢¨ç«æŸ´ç›ƒæ­¦å£«é“ samuraiè©©å¥è‚šè‡ç¾ä»£åŒ– modernæ„Ÿå†’.
poembelly.
ï¬‚u.
< screenwriter< ridiculous< totalitarian< rhyme< brand< owner< anna< baotou< edit< gust< matches< cup< bushido< verse< belly button< modernization< cold.
negotiatenanometer.
å”å•†ç´ç±³é¡äººçŒ¿ apesé…ä»¶åŒ¯è²¸æ–¹é€†å·®å¦‚æœé™„ä»¶å¯¦ç¿’åŠ å†•åŠ©ç†è¦ªå’Œæ€§ agreeableness > afï¬nityåœ‹åœŸ.
> consult> nano> anthropoid> fitting> exchange> credit> trade deï¬cit> in case> annex> practice> crown> assistant manager.
accessoriesaggregatedlendersdeï¬citifaccessoriesinternshipcrownedassistant.
homeland.
> land.
éå¢ƒç’°æµç¾Šç¾¤.
crossingscirculationsheep.
(cid:55)(cid:55)(cid:55).
transitcircumï¬‚uenceherd.
table 10: all errors cases among 400 random outputs of gen-rtv compared to both our judgement and googletranslate for reference.
>: gen-rtv unacceptable while google trans acceptable.
<: gen-rtv acceptable whilegoogle trans unacceptable.
(cid:55): both unacceptable..826