on the efﬁcacy of adversarial data collection for question answering:results from a large-scale randomized study.
divyansh kaushik†, douwe kiela‡, zachary c. lipton†, wen-tau yih‡† carnegie mellon university; ‡ facebook ai research{dkaushik,zlipton}@cmu.edu, {dkiela,scottyih}@fb.com.
abstract.
in adversarial data collection (adc), a hu-man workforce interacts with a model in realtime, attempting to produce examples thatelicit incorrect predictions.
researchers hopethat models trained on these more challeng-ing datasets will rely less on superﬁcial pat-terns, and thus be less brittle.
however, de-spite adc’s intuitive appeal, it remains un-clear when training on adversarial datasets pro-duces more robust models.
in this paper, weconduct a large-scale controlled study focusedon question answering, assigning workers atrandom to compose questions either (i) adver-sarially (with a model in the loop); or (ii) inthe standard fashion (without a model).
acrossa variety of models and datasets, we ﬁnd thatmodels trained on adversarial data usually per-form better on other adversarial datasets butworse on a diverse collection of out-of-domainevaluation sets.
finally, we provide a qualita-tive analysis of adversarial (vs standard) data,identifying key differences and offering guid-ance for future research.1.
1.introduction.
across such diverse natural language processing(nlp) tasks as natural language inference (nli;poliak et al., 2018; gururangan et al., 2018), ques-tion answering (qa; kaushik and lipton, 2018),and sentiment analysis (kaushik et al., 2020), re-searchers have discovered that models can succeedon popular benchmarks by exploiting spurious as-sociations that characterize a particular dataset butdo not hold more widely.
despite performing wellon independent and identically distributed (i.i.d.)
data, these models are liable under plausible do-main shifts.
with the goal of providing more chal-lenging benchmarks that require this stronger formof generalization, an emerging line of research has.
1data collected during this study is publicly available at.
https://github.com/facebookresearch/aqa-study..investigated adversarial data collection (adc), ascheme in which a worker interacts with a model(in real time), attempting to produce examples thatelicit incorrect predictions (e.g., dua et al., 2019;nie et al., 2020).
the hope is that by identifyingparts of the input domain where the model fails onemight make the model more robust.
researchershave shown that models trained on adc performbetter on such adversarially collected data and thatwith successive rounds of adc, crowdworkers areless able to fool the models (dinan et al., 2019)..while adversarial data may indeed provide morechallenging benchmarks, the process and its actualbeneﬁts vis-a-vis tasks of interest remain poorlyunderstood, raising several key questions: (i) dothe resulting models typically generalize better outof distribution compared to standard data collection(sdc)?
; (ii) how much can differences betweenadc and sdc be attributed to the way workersbehave when attempting to fool models, regardlessof whether they are successful?
and (iii) what is theimpact of training models on adversarial data only,versus using it as a data augmentation strategy?.
in this paper, we conduct a large-scale ran-domized controlled study to address these ques-tions.
focusing our study on span-based ques-tion answering and a variant of the natural ques-tions dataset (nq; lee et al., 2019; karpukhinet al., 2020), we work with two popular pretrainedtransformer architectures—bertlarge (devlin et al.,2019) and electralarge (clark et al., 2020)—each ﬁne-tuned on 23.1k examples.
to eliminateconfounding factors when assessing the impactof adc, we randomly assign the crowdworkerstasked with generating questions to one of threegroups: (i) with an incentive to fool the bertmodel; (ii) with an incentive to fool the electramodel; and (iii) a standard, non-adversarial setting(no model in the loop).
the pool of contexts is thesame for each group and each worker is asked to.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6618–6633august1–6,2021.©2021associationforcomputationallinguistics6618figure 1: platform shown to workers generating questions in the adc setting..generate ﬁve questions for each context that theysee.
workers are shown similar instructions (withminimal changes), and paid the same base amount.
we ﬁne-tune three models (bert, roberta,and electra) on resulting datasets and eval-uate them on held-out test sets, adversarial testsets from prior work (bartolo et al., 2020), and 12mrqa (fisch et al., 2019) datasets.
for all mod-els, we ﬁnd that while ﬁne-tuning on adversarialdata usually leads to better performance on (previ-ously collected) adversarial data, it typically leadsto worse performance on a large, diverse collectionof out-of-domain datasets (compared to ﬁne-tuningon standard data).
we observe a similar patternwhen augmenting the existing dataset with the ad-versarial data.
results on an extensive collectionof out-of-domain evaluation sets suggest that adctraining data does not offer clear beneﬁts vis-`a-visrobustness under distribution shift..to study the differences between adversarial andstandard data, we perform a qualitative analysis,categorizing questions based on a taxonomy (hovyet al., 2000).
we notice that more questions inthe adc dataset require numerical reasoning com-pared to the sdc sample.
these qualitative in-sights may offer additional guidance to future re-searchers..2 related work.
in an early example of model-in-the-loop data col-lection, zweig and burges (2012) use n-gram lan-.
guage models to suggest candidate incorrect an-swers for a ﬁll-in-the-blank task.
richardson et al.
(2013) suggested adc for qa as proposed futurework, speculating that it might challenge state-of-the-art models.
in the build it break it, the lan-guage edition shared task (ettinger et al., 2017),teams worked as builders (training models) andbreakers (creating challenging examples for subse-quent training) for sentiment analysis and qa-srl.
research on adc has picked up recently,with chen et al.
(2019) tasking crowdworkersto construct multiple-choice questions to fool abert model and wallace et al.
(2019) employingquizbowl community members to write jeopardy-style questions to compete against qa models.
zhang et al.
(2018) automatically generated ques-tions from news articles, keeping only those ques-tions that were incorrectly answered by a qamodel.
dua et al.
(2019) and dasigi et al.
(2019)required crowdworkers to submit only questionsthat qa models answered incorrectly.
to con-struct fever 2.0 (thorne et al., 2019), crowd-workers were required to fool a fact-veriﬁcationsystem trained on the fever (thorne et al., 2018)dataset.
some works explore adc over multiplerounds, with adversarial data from one round usedto train models in the subsequent round.
yanget al.
(2018b) ask workers to generate challengingdatasets working ﬁrst as adversaries and later ascollaborators.
dinan et al.
(2019) build on theirwork, employing adc to address offensive lan-.
6619guage identiﬁcation.
they ﬁnd that over successiverounds of training, models trained on adc dataare harder for humans to fool than those trained onstandard data.
nie et al.
(2020) applied adc foran nli task over three rounds, ﬁnding that train-ing for more rounds improves model performanceon adversarial data, and observing improvementson the original evaluations set when training on amixture of original and adversarial training data.
williams et al.
(2020) conducted an error analysisof model predictions on the datasets collected bynie et al.
(2020).
bartolo et al.
(2020) studied theempirical efﬁcacy of adc for squad (rajpurkaret al., 2016), observing improved performance onadversarial test sets but noting that trends vary de-pending on the models used to collect data and totrain.
previously, lowell et al.
(2019) observedsimilar issues in active learning, when the modelsused to acquire data and for subsequent trainingdiffer.
yang et al.
(2018a); zellers et al.
(2018,2019) ﬁrst collect datasets and then ﬁlter exam-ples based on predictions from a model.
papernoet al.
(2016) apply a similar procedure to generate alanguage modeling dataset (lambada).
kaushiket al.
(2020, 2021) collect counterfactually aug-mented data (cad) by asking crowdworkers toedit existing documents to make counterfactual la-bels applicable, showing that models trained oncad generalize better out-of-domain..absent further assumptions, learning classiﬁersrobust to distribution shift is impossible (ben-david et al., 2010).
while few nlp papers on thematter make their assumptions explicit, they typi-cally proceed under the implicit assumptions thatthe labeling function is deterministic (there is oneright answer), and that covariate shift (shimodaira,2000) applies (the labeling function p(y|x) is in-variant across domains).
note that neither condi-tion is generally true of prediction problems.
forexample, faced with label shift (sch¨olkopf et al.,2012; lipton et al., 2018) p(y|x) can change acrossdistributions, requiring one to adapt the predictorto each environment..3 study design.
in our study of adc for qa, each crowdworker isshown a short passage and asked to create 5 ques-tions and highlight answers (spans in the passage,see fig.
1).
we provide all workers with the samebase pay and for those assigned to adc, pay outan additional bonus for each question that fools.
the qa model.
finally, we ﬁeld a different set ofworkers to validate the generated examples..context passages for context passages, we usethe ﬁrst 100 words of wikipedia articles.
truncat-ing the articles keeps the task of generating ques-tions from growing unwieldy.
these segments typ-ically contain an overview, providing ample ma-terial for factoid questions.
we restrict the poolof candidate contexts by leveraging a variant ofthe natural questions dataset (kwiatkowski et al.,2019; lee et al., 2019).
we ﬁrst keep only a subsetof 23.1k question/answer pairs for which the con-text passages are the ﬁrst 100 words of wikipediaarticles2.
from these passages, we sample 10k atrandom for our study..models in the loop we use bertlarge (devlinet al., 2019) and electralarge (clark et al., 2020)models as our adversarial models in the loop, us-ing the implementations provided by wolf et al.
(2020).
we ﬁne-tune these models for span-basedquestion-answering, using the 23.1k training exam-ples (subsampled previously) for 20 epochs, withearly-stopping based on word-overlap f13 overthe validation set.
our bert model achieves anem score of 73.1 and an f1 score of 80.5 on ani.i.d.
validation set.
the electra model per-forms slightly better, obtaining an 74.2 em and81.2 f1 on the same set..crowdsourcing protocol we build our crowd-sourcing platform on the dynabench inter-face (kiela et al., 2021) and use amazon’s me-chanical turk to recruit workers to write questions.
to ensure high quality, we restricted the pool tou.s. residents who had already completed at least1000 hits and had over 98% hit approval rate.
for each task, we conducted several pilot studiesto gather feedback from crowdworkers on the taskand interface.
we identiﬁed median time taken byworkers to complete the task in our pilot studies andused that to design the incentive structure for themain task.
we also conducted multiple studies withdifferent variants of instructions to observe trendsin the quality of questions and reﬁned our instruc-tions based on feedback from crowdworkers.
feed-back from the pilots also guided improvements to.
2we used the data prepared by karpukhin et al.
(2020),available at https://www.github.com/facebookresearch/dpr.
3word-overlap f1 and exact match (em) metrics intro-duced in rajpurkar et al.
(2016) are commonly used to eval-uate performance of passage-based qa systems, where thecorrect answer is a span in the given passage..6620resource.
num.
passages.
train val.
test.
num.
qa pairsval.
train.
test.
bert.
1,056 11,330 1,130 1,130electra 3,925 1,352 1,352 14,556 1,456 1,456.
3,412.
992.table 1: number of unique passages and question-answer pairs for each data resource..our crowdsourcing interface.
in total, 984 workerstook part in the study, with 741 creating questions.
in our ﬁnal study, we randomly assigned workersto generate questions in the following ways: (i)to fool the bert baseline; (ii) to fool the elec-tra baseline; or (iii) without a model in the loop.
before beginning the task, each worker completesan onboarding process to familiarize them withthe platform.
we present the same set of passagesto workers regardless of which group they are as-signed to, tasking them with generating 5 questionsfor each passage..incentive structure during our pilot studies, wefound that workers spend ≈ 2–3 minutes to gener-ate 5 questions.
we provide workers with the samebase pay—$0.75 per hit—(to ensure compensa-tion at a $15/hour rate).
for tasks involving a modelin the loop, we deﬁne a model prediction to be in-correct if its f1 score is less than 40%, followingthe threshold set by bartolo et al.
(2020).
workerstasked with fooling the model receive bonus pay of$0.15 for every question that leads to an incorrectmodel prediction.
this way, a worker can doubletheir pay if all 5 of their generated questions induceincorrect model predictions..quality control upon completion of each batchof our data collection process, we presented ≈ 20%of the collected questions to a fourth group ofcrowdworkers who were tasked with validatingwhether the questions were answerable and theanswers were correctly labeled.
in addition, wemanually veriﬁed a small fraction of the col-lected question-answer pairs.
if validations of atleast 20% of the examples generated by a particularworker were incorrect, their work was discardedin its entirety.
the entire process, including thepilot studies cost ≈ $50k and spanned a period ofseven months.
through this process, we collectedover 150k question-answer pairs corresponding tothe 10k contexts (50k from each group) but the ﬁ-nal datasets are much smaller, as we explain below..4 experiments and results.
our study allows us to answer three questions: (i)how well do models ﬁne-tuned on adc data gen-eralize to unseen distributions compared to ﬁne-tuning on sdc?
(ii) among the differences be-tween adc and sdc, how many are due to work-ers trying to fool the model regardless of whetherthey are successful?
and (iii) what is the impact oftraining on adversarial data only versus using it asa data augmentation strategy?.
datasets for both bert and electra, weﬁrst identify contexts for which at least one ques-tion elicited an incorrect model prediction.
notethat this set of contexts is different for bert andelectra.
for each such context c, we iden-tify the number of questions kc (out of 5) thatsuccessfully fooled the model.
we then create3 datasets per model by, for each context, (i)choosing precisely those kc questions that fooledthe model (bertfooled and electrafooled); (ii)randomly choosing kc questions (out of 5) fromadc data without replacement (bertrandom andelectrarandom)—regardless of whether theyfooled the model; and (iii) randomly choosing kcquestions (out of 5) from the sdc data without re-placement.
thus, we create 6 datasets, where all 3bert datasets have the same number of questionsper context (and 11.3k total training examples),while all 3 electra datasets likewise share thesame number of questions per context (and 14.7ktotal training examples).
see table 1 for details onthe number of passages and question-answer pairsused in the different splits..models for our empirical analysis, we ﬁne-tunebert (devlin et al., 2019), roberta (liu et al.,2019), and electra (clark et al., 2020) modelson all six datasets generated as part of our study(four datasets via adc: bertfooled, bertrandom,electrafooled, electrarandom, and the twodatasets via sdc).
we also ﬁne-tune these mod-els after augmenting the original data to collecteddatasets.
we report the means and standard devia-tions (in subscript) of em and f1 scores following10 runs of each experiment.
models ﬁne-tuned onall adc datasets typically perform better on theirheld-out test sets than those trained on sdc dataand vice-versa (table 2 and appendix table 5).
roberta ﬁne-tuned on the bertfooled training setobtains em and f1 scores of 49.2 and 71.2, respec-tively, on the bertfooled test set, outperforming.
6621evaluation set →training set ↓.
bertfooled.
em.
f1.
bertrandom.
em.
f1.
sdc.
original dev..em.
f1.
em.
f1.
original (o; 23.1k)original (11.3k).
bertfooled (f; 11.3k)bertrandom (r; 11.3k)sdc (11.3k).
o + f (34.4k)o + r (34.4k)o + sdc (34.4k).
original (o; 23.1k)original (11.3k).
bertfooled (f; 11.3k)bertrandom (r; 11.3k)sdc (11.3k).
o + f (34.4k)o + r (34.4k)o + sdc (34.4k).
original (o; 23.1k)original (11.3k).
bertfooled (f; 11.3k)bertrandom (r; 11.3k)sdc (11.3k).
o + f (34.4k)o + r (34.4k)o + sdc (34.4k).
0.08.40.9.
34.45.137.72.733.60.3.
39.90.838.10.533.40.4.
7.34.50.4.
49.20.548.00.442.90.9.
49.50.547.60.741.50.4.
7.58.40.9.
40.24.642.12.739.20.3.
40.93.441.55.638.00.6.finetuned model: bertlarge.
finetuned model: robertalarge.
29.628.80.5.
44.08.857.04.557.60.6.
50.60.957.91.060.64.4.
28.617.50.9.
64.91.370.30.767.00.6.
61.60.869.20.567.30.6.
29.628.80.5.
50.74.758.82.259.60.7.
52.62.558.64.659.40.6.
45.242.70.9.
61.78.273.93.574.50.4.
68.50.974.80.577.23.6.
44.526.72.0.
81.31.185.30.483.60.5.
79.50.684.60.584.30.4.
45.242.70.9.
68.54.876.01.576.10.6.
70.82.175.04.476.10.4.
32.533.10.7.
47.510.062.44.568.60.5.
52.61.462.60.569.00.3.
32.719.52.1.
67.91.572.50.474.40.5.
58.32.071.10.775.00.6.
32.533.10.7.
56.14.465.81.969.30.7.
55.44.564.44.170.90.4.finetuned model: electralarge.
17.118.70.6.
57.05.758.92.554.40.4.
61.70.558.80.654.50.6.
16.710.81.1.
71.20.769.80.465.30.8.
71.10.669.50.564.20.4.
17.118.70.6.
63.43.263.52.140.30.4.
63.72.361.95.758.70.6.
49.148.61.1.
66.88.679.73.184.20.3.
71.81.180.20.384.30.3.
50.130.03.2.
84.81.087.80.188.90.3.
78.51.286.80.388.90.2.
49.148.61.1.
75.63.081.71.384.20.5.
74.44.180.43.385.10.3.
73.366.10.3.
34.52.646.43.148.61.6.
72.20.472.50.572.10.2.
73.570.60.3.
41.41.050.60.851.00.5.
72.60.472.80.673.00.2.
74.271.80.1.
41.04.852.61.955.70.7.
72.71.272.62.073.60.7.
80.574.20.4.
47.93.360.63.862.31.9.
79.80.680.20.379.80.2.
80.578.50.4.
55.11.164.91.062.80.6.
80.00.480.30.580.40.1.
81.279.60.1.
56.64.267.51.469.50.5.
80.51.080.32.181.20.4.table 2: em and f1 scores of various models evaluated on adversarial and non-adversarial datasets.
adversarialresults in bold are statistically signiﬁcant compared to sdc setting and vice versa with p < 0.05..roberta models ﬁne-tuned on bertrandom (em:48.0, f1: 69.8) and sdc (em: 42.0, f1: 65.3).
per-formance on the original dev set (karpukhin et al.,2020) is generally comparable across all models..out-of-domain generalization to adversarialdata we evaluate these models on adversarialtest sets constructed with bidaf (dbidaf), bert(dbert) and roberta (droberta) in the loop (bar-tolo et al., 2020).
prior work suggests that trainingon adc data leads to models that perform bet-ter on similarly constructed adversarial evaluationsets.
both bert and roberta models ﬁne-tunedon adversarial data generally outperform modelsﬁne-tuned on sdc data (or when either datasetsare augmented to the original data) on all threeevaluation sets (table 3 and appendix table 6).
a roberta model ﬁne-tuned on bertfooled out-performs a roberta model ﬁne-tuned on sdcby 9.1, 9.3, and 6.2 em points on droberta, dbert,and dbidaf, respectively.
we observe similartrends on electra models ﬁne-tuned on adcdata versus sdc data, but these gains disappearwhen the same models are ﬁnetuned on augmenteddata.
for instance, while electra ﬁne-tunedon bertrandom obtains an em score of 14.8 ondroberta, outperforming an electra ﬁne-tunedon sdc data by ≈ 3 pts, the difference is no longersigniﬁcant when respective models are ﬁne-tuned.
after original data is augmented to these datasets.
electra models ﬁne-tuned on adc data withelectra in the loop perform no better than thosetrained on sdc.
fine-tuning electra on sdcaugmented to original data leads to an ≈ 1 pt im-provement on both metrics compared to augment-ing adc.
overall, we ﬁnd that models ﬁne-tunedon adc data typically generalize better to out-of-domain adversarial test sets than models ﬁne-tunedon sdc data, conﬁrming the ﬁndings by dinanet al.
(2019)..out-of-domain generalization to mrqa wefurther evaluate these models on 12 out-of-domaindatasets used in the 2019 mrqa shared task4 (ta-ble 4 and appendix table 7).5 notably, for bert,ﬁne-tuning on sdc data leads to signiﬁcantly bet-ter performance (as compared to ﬁne-tuning on.
4the mrqa 2019 shared task includes hotpotqa (yanget al., 2018a), natural questions (kwiatkowski et al., 2019),searchqa (dunn et al., 2017), squad (rajpurkar et al.,2016), triviaqa (joshi et al., 2017), bioasq (tsatsaroniset al., 2015), drop (dua et al., 2019), duorc (saha et al.,2018), relationextraction (levy et al., 2017), race (laiet al., 2017), and textbookqa (kembhavi et al., 2017)..5interestingly, roberta appears to perform better com-pared to bert and electra.
prior works have hypothe-sized that the bigger size and increased diversity of the pre-training corpus of roberta (compared to those of bert andelectra) might somehow be responsible for roberta’sbetter out-of-domain generalization, (baevski et al., 2019;hendrycks et al., 2020; tu et al., 2020)..6622evaluation set →training set ↓.
droberta.
em.
f1.
dbert.
dbidaf.
em.
f1.
em.
f1.
finetuned model: bertlarge.
finetuned model: robertalarge.
original (23.1k)original (11.3k).
bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
orig + bertfooled (34.4k)orig + bertrandom (34.4k)orig + sdc (34.4k).
original (23.1k)original (11.3k).
bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
orig + bertfooled (34.4k)orig + bertrandom (34.4k)orig + sdc (34.4k).
original (23.1k)original (11.3k).
bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
orig + bertfooled (34.4k)orig + bertrandom (34.4k)orig + sdc (34.4k).
6.05.40.3.
11.02.612.41.69.10.7.
15.20.816.90.59.40.6.
15.714.60.3.
21.91.621.31.312.81.2.
25.20.924.61.516.10.8.
8.28.50.4.
13.83.714.81.811.60.6.
16.53.818.44.215.61.1.
13.512.20.1.
21.03.022.12.220.40.7.
25.10.623.90.520.20.5.
25.023.80.5.
32.21.631.61.523.41.3.
36.41.035.21.527.61.1.
17.416.70.5.
24.35.625.91.122.70.7.
28.03.828.95.027.01.1.
8.17.00.6.
14.63.716.43.014.01.0.
20.40.420.50.615.31.0.
26.522.51.2.
30.21.631.32.220.01.8.
35.90.935.71.026.60.8.
15.714.31.0.
18.86.022.32.917.81.2.
23.13.925.95.922.70.6.finetuned model: electralarge.
14.213.60.8.
24.74.026.22.724.60.7.
31.00.431.20.925.81.1.
37.032.61.5.
42.51.643.62.332.12.2.
48.50.848.01.239.70.6.
24.223.00.9.
31.18.134.62.530.41.3.
35.64.237.26.936.00.8.
12.611.00.9.
25.16.529.63.730.11.2.
32.40.634.10.432.71.2.
37.936.01.1.
46.31.648.01.440.02.0.
49.60.750.61.543.40.4.
22.420.71.4.
29.19.034.83.432.51.8.
34.85.137.27.534.50.9.
21.419.40.7.
39.16.943.74.043.81.2.
47.00.647.80.747.21.0.
50.448.91.2.
61.91.563.41.355.01.8.
65.11.165.81.259.40.3.
34.332.01.3.
44.311.050.52.749.31.6.
50.25.751.19.149.51.2.table 3: em and f1 scores of various models evaluated on dev datasets of bartolo et al.
(2020).
adversarial resultsin bold are statistically signiﬁcant compared to sdc setting and vice versa with p < 0.05..adc data collected with bert) on 9 out of 12mrqa datasets, with gains of more than 10 empts on 6 of them.
on bioasq, bert ﬁne-tuned onbertfooled obtains em and f1 scores of 23.5 and30.3, respectively.
by comparison, ﬁne-tuning onsdc data yields markedly higher em and f1 scoresof 35.1 and 55.7, respectively.
similar trends holdacross models and datasets.
interestingly, adcﬁne-tuning often improves performance on dropcompared to sdc.
for instance, roberta ﬁne-tuned on electrarandom outperforms robertaﬁne-tuned on sdc by ≈ 7 pts.
note that dropitself was adversarially constructed.
on naturalquestions, models ﬁne-tuned on adc data gen-erally perform comparably to those ﬁne-tuned onsdc data.
roberta ﬁne-tuned on bertrandomobtains em and f1 scores of 48.1 and 62.6, respec-tively, whereas roberta ﬁne-tuned on sdc dataobtains scores of 47.9 and 61.7, respectively.
itis worth noting that passages sourced to constructboth adc and sdc datasets come from the natu-ral questions dataset, which could be one reasonwhy models ﬁne-tuned on adc datasets performsimilar to those ﬁne-tuned on sdc datasets whenevaluated on natural questions..on the the adversarial process versus adversar-ial success we notice that models ﬁne-tuned on.
bertrandom and electrarandom typically out-perform models ﬁne-tuned on bertfooled andelectrafooled, respectively, on adversarial testdata collected in prior work (bartolo et al., 2020),as well as on mrqa.
similar observation can bemade when the adc data is augmented with theoriginal training data.
these trends suggest thatthe adc process (regardless of the outcome) ex-plains our results more than successfully foolinga model.
furthermore, models ﬁne-tuned only onsdc data tend to outperform adc-only ﬁne-tunedmodels; however, following augmentation, adcﬁne-tuning achieves comparable performance onmore datasets than before, showcasing generaliza-tion following augmentation.
notice that augment-ing adc data to original data may not alwayshelp.
bert ﬁne-tuned on original 23.1k exam-ples achieves an em 11.3 on searchqa.
whenﬁne-tuned on bertfooled augmented to the orig-inal data, this drops to 8.7, and when ﬁne-tunedon bertrandom augmented to the original data, itdrops to 11.2. fine-tuning on sdc augmented tothe original data, however, results in em of 13.6..5 qualitative analysis.
finally, we perform a qualitative analysis over thecollected data, revealing profound differences withmodels in (versus out of) the loop.
recall that be-.
6623finetuned model: bertlarge.
evaluation set →training set ↓.
original (23.1k)original (11.3k).
bioasq.
drop.
duorc.
em.
f1.
em.
f1.
em.
f1.
relation extractionem.
f1.
race.
em.
f1.
textbookqa.
em.
f1.
19.420.81.7.
32.536.03.4.
7.86.21.4.bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
30.33.523.56.030.33.546.82.835.12.1 55.71.1.
11.53.214.42.014.60.4.
16.212.71.8.
22.23.425.12.524.70.6.
14.513.11.1.
22.819.81.6.
28.25.020.34.526.73.335.33.031.70.7 41.20.7.orig + fooled (34.4k)orig + random (34.4k)orig + sdc (34.4k).
48.21.231.71.234.91.251.80.938.81.5 56.01.3.
19.90.931.00.821.40.6 33.10.431.11.019.40.9.
33.11.424.40.927.11.236.11.231.90.4 41.60.6.
32.042.40.4.
51.58.261.35.863.21.2.
55.01.762.30.962.40.7.
47.155.90.1.
68.96.675.94.577.70.7.
71.51.277.10.777.80.2.
11.410.30.6.
15.13.118.41.819.70.6.
19.21.321.01.420.71.4.
18.818.30.4.
26.14.329.92.031.00.6.
31.01.133.01.332.71.2.
25.020.00.9.
33.427.90.7.
24.74.616.73.821.93.130.93.826.04.3 35.54.7.
22.24.727.73.929.02.4.
30.95.437.14.038.83.1.hotpotqa.
em.
f1.
natural questionsf1em.
newsqa.
em.
f1.
searchqa.
squad.
triviaqa.
em.
f1.
em.
f1.
em.
f1.
original (23.1k)original (11.3k).
19.420.10.3.
33.932.60.6.bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
43.27.527.26.437.53.154.43.141.20.9 57.91.0.orig + fooled (34.4k)orig + random (34.4k)orig + sdc (34.4k).
51.10.834.41.041.00.757.30.743.30.2 60.00.3.
36.338.40.5.
28.05.736.73.939.31.2.
39.91.344.50.445.60.9.
48.750.60.6.
42.86.551.23.553.61.1.
54.10.858.20.258.71.1.
16.215.01.0.
25.624.91.7.
11.311.10.7.
19.318.61.2.
32.529.60.4.
46.043.00.7.
16.815.31.0.
25.323.91.4.
24.35.422.74.729.61.934.43.032.00.8 48.01.1 10.61.4 18.01.3 56.40.4 72.50.4 28.60.8 39.90.9.
37.56.444.91.9.
11.82.214.61.8.
42.67.651.92.6.
60.67.969.32.1.
16.14.624.72.8.
6.11.78.61.4.
30.90.826.30.930.00.538.61.432.00.8 48.61.1 13.60.4 22.20.5 57.00.3 73.20.3 30.91.0 42.40.9.
14.51.717.70.9.
47.60.553.40.4.
66.30.570.80.4.
21.90.728.61.3.
42.81.145.90.6.
8.71.511.20.7.finetuned model: robertalarge.
evaluation set →training set ↓.
original (23.1k)original (11.3k).
bioasq.
drop.
duorc.
em.
f1.
em.
f1.
em.
f1.
relation extractionem.
f1.
race.
em.
f1.
textbookqa.
em.
f1.
47.746.30.1.
63.562.71.0.
37.234.70.3.
48.146.50.8.
38.636.61.8.
49.146.92.1.
74.472.30.8.
33.730.70.2.
44.942.20.3.
36.434.90.4.
4644.40.2.bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
51.01.235.61.340.41.257.41.241.31.0 59.71.0.
34.12.546.82.438.12.2 51.22.038.92.924.42.2.
67.01.039.73.031.42.536.71.671.00.545.51.741.10.8 51.80.5 72.60.6.
28.21.341.41.131.61.3 45.31.143.31.229.51.1.
35.12.425.42.429.81.439.31.635.61.8 46.11.7.
54.71.6orig + fooled (34.4k)orig + random (34.4k) 45.71.0 62.20.8 46.51.4 58.01.253.80.8orig + sdc (34.4k).
41.21.2.
56.70.9.
43.31.4.
43.10.8.
60.90.4.
40.21.4.
78.31.232.00.738.90.982.60.940.01.4 51.91.5 70.90.4 83.30.4.
61.32.367.61.2.
41.51.048.90.8.
31.70.633.61.132.90.8.
45.71.047.10.745.70.7.
37.62.540.01.640.91.1.
48.02.650.31.751.91.3.
85.984.50.3.
81.90.584.40.384.60.3.hotpotqa.
em.
f1.
natural questionsf1em.
newsqa.
searchqa.
squad.
em.
f1.
em.
f1.
em.
f1.
triviaqa.
em.
f1.
original (23.1k)original (11.3k).
bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
orig + fooled (34.4k)orig + random (34.4k)orig + sdc (34.4k).
48.146.60.3.
46.50.850.70.652.01.3.
47.21.153.20.553.90.9.
63.563.20.3.
63.30.867.70.768.71.4.
64.71.170.10.570.70.9.
55.354.60.4.
41.61.248.10.947.91.2.
67.666.90.4.
56.61.162.60.861.71.3.
38.636.31.0.
54.451.61.2.
39.733.80.8.
49.343.00.6.
61.960.10.4.
76.775.30.3.
47.544.90.6.
59.657.20.7.
45.92.133.81.239.50.852.51.244.00.9 61.90.7 24.92.0 33.02.0 66.40.6 82.20.5 47.00.6 58.30.7.
50.71.656.11.1.
15.31.917.01.7.
21.51.923.61.8.
60.00.665.40.4.
77.60.581.40.3.
37.01.743.31.1.
48.61.053.20.754.80.457.10.955.90.4 68.70.5 44.20.3 62.50.4 36.01.3 45.21.6 66.60.4 82.70.2 48.00.8 59.80.7.
66.80.668.20.3.
33.90.741.60.6.
52.00.758.90.7.
28.22.130.61.9.
35.32.538.32.0.
58.20.865.30.5.
76.90.681.80.3.
38.80.946.71.0.finetuned model: electralarge.
evaluation set →training set ↓.
original (23.1k)original (11.3k).
bioasq.
drop.
duorc.
em.
f1.
em.
f1.
em.
f1.
relation extractionem.
f1.
race.
textbookqa.
em.
f1.
em.
f1.
29.133.11.4.
42.849.42.5.
17.615.51.8.
26.926.51.1.
18.921.20.8.
27.129.40.6.bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
50.23.632.44.637.12.955.12.140.61.7 59.21.4.
19.94.333.43.521.11.9 35.01.630.71.117.50.9.
35.13.725.24.230.52.140.31.633.32.1 43.61.9.orig + fooled (34.4k)orig + random (34.4k)orig + sdc (34.4k).
48.21.331.71.337.85.254.45.440.00.9 57.60.9.
19.90.931.00.827.66.8 39.48.131.11.019.40.9.
33.11.424.50.928.45.138.25.731.90.4 41.60.6.
67.469.41.1.
74.63.178.71.379.60.8.
71.51.277.25.276.80.2.
19.618.00.8.
20.62.523.31.523.41.1.
28.528.40.7.
34.02.536.51.535.51.0.
32.529.20.5.
19.53.325.73.327.42.7.
41.837.80.3.
28.54.035.13.536.82.9.
31.01.1.
19.21.330.95.424.34.6 37.45.3 34.06.1 43.56.238.83.119.51.4.
31.71.2.
29.02.4.
22.24.7.hotpotqa.
em.
f1.
natural questionsf1em.
newsqa.
em.
f1.
searchqa.
squad.
em.
f1.
em.
f1.
triviaqa.
em.
f1.
original (23.1k)original (11.3k).
bertfooled (11.3k)bertrandom (11.3k)sdc (11.3k).
29.626.80.2.
36.74.041.42.443.01.4.
4339.70.2.
54.22.958.41.659.61.1.
40.938.70.9.
55.354.20.9.
20.421.01.0.
32.233.21.1.
45.12.435.13.843.21.749.81.646.11.0 60.40.8 35.31.1 51.91.1.
51.73.158.51.3.
28.52.433.31.6.
30.324.81.6.
39.940.51.2.
54.855.91.2.
67.53.448.34.213.91.716.82.172.91.755.42.319.01.6 58.61.4 74.91.0.
2123.91.8.
23.82.928.91.429.01.6.
31.233.51.8.
34.52.339.91.060.71.3.orig + fooled (34.4k)orig + random (34.4k)orig + sdc (34.4k).
51.10.834.41.041.44.757.44.543.90.5 60.40.3.
45.42.946.23.849.40.5.
59.92.660.03.563.00.7.
42.81.126.30.931.74.247.55.232.40.7 49.00.8.
14.51.723.12.222.20.5.
30.90.847.60.555.24.640.25.257.61.0 74.01.0 31.70.8 43.40.6.
66.30.572.14.6.
21.90.729.85.2.
53.454.90.9.
57.04.964.32.965.91.4.
55.01.762.96.862.40.7.
21.517.21.5.
7.01.39.21.510.51.4.
8.71.514.92.213.60.4.table 4: em and f1 scores of various models evaluated on mrqa dev and test sets.
adversarial results in boldare statistically signiﬁcant compared to sdc setting and vice versa with p < 0.05..cause these datasets were constructed in a random-ized study, any observed differences are attributableto the model-in-the loop collection scheme..to begin, we analyze 100 questions from each.
dataset and categorize them using the taxonomyintroduced by hovy et al.
(2000).6 we also look at.
6this taxonomy can be accessed at https://www.isi.edu/nat.
ural-language/projects/webclopedia/taxonomy/taxonomy.
6624(a) bertfooled.
(b) bertrandom.
(c) sdc-bert.
(d) electrafooled.
(e) electrarandom (f) sdc-electra.
figure 2: frequency of wh-questions generated..(a) bertfooled.
(b) bertrandom.
(c) sdc-bert.
(d) electrafooled.
(e) electrarandom.
(f) sdc-electra.
figure 3: frequency of question types based on the taxonomy introduced by hovy et al.
(2000)..the ﬁrst word of the wh-type questions in each devset (fig.
3) and observe key qualitative differencesbetween data via adc and sdc for both models.
in case of adc with bert (and associatedsdc), while we observe that most questions inthe dev sets start with what, adc has a higherproportion compared to sdc (587 in bertfooledand 492 in bertrandom versus 416 in sdc).
fur-thermore, we notice that compared to bertfooleddev set, sdc has more when- (148) and who-type(220) questions, the answers to which typically re-fer to dates, places and people (or organizations),respectively.
this is also reﬂected in the taxonomycategorization.
interestingly, the bertrandom devset has more when- and who-type questions thanbertfooled (103 and 182 versus 50 and 159, respec-tively).
this indicates that the bert model couldhave been better at answering questions related todates and people (or organizations), which couldhave further incentivized workers not to generate.
toplevel.html.
such questions upon observing these patterns.
sim-ilarly, in the 100-question samples, we ﬁnd that alarger proportion of questions in adc are catego-rized as requiring numerical reasoning (11 and 18in bertfooled and bertrandom, respectively) com-pared to sdc (7).
it is possible that the model’s per-formance on numerical reasoning (as also demon-strated by its lower performance on drop com-pared to ﬁne-tuning on adc or sdc) would haveincentivized workers to generate more questions re-quiring numerical reasoning and as a result, skewedthe distribution towards such questions..similarly, with electra, we observe thatwhat-type questions constitute most of the ques-tions in the development sets for both adc andsdc, although data collected via adc has a higherproportion of these (641 in electrafooled and619 in electrarandom versus 542 in sdc).
wealso notice more how-type questions in adc (126in electrarandom) vs 101 in sdc, and thatthe sdc sample has more questions that relate.
6625whowhatwhenwherewhichhow050100150200250300350400450500550600whowhatwhenwherewhichhow050100150200250300350400450500whowhatwhenwherewhichhow050100150200250300350400whowhatwhenwherewhichhow050100150200250300350400450500550600650whowhatwhenwherewhichhow050100150200250300350400450500550600whowhatwhenwherewhichhow050100150200250300350400450500550numerical-quantityoccupation-personbody-partdefinitionnamewhy-famoustitled-workproper-placepersonmethod-meansgroup-of-peopledatecircumstance-meansanimaltemporal-quantityexpression-originsubstanceproper-personadjectivespatial-quantityproper-organizationlocatortextinstrumentdate-rangeinfluenceantecedent051015numerical-quantitypersondategroup-of-peopledate-rangewhy-famousnameproper-placeproper-organizationtemporal-quantityproper-personsubstancedefinitioninfluenceantecedenttitled-workexpression-originbody-partmethod-meansabstractanimalcolor051015definitionproper-personproper-placedatemonetary-quantityproper-organizationdate-rangetitled-workwhy-famousbody-partnumerical-quantitynamediseasesubstanceanimaltemporal-quantitydefinition  expression-origintextgroup-of-peopleinstrumentadjective051015numerical-quantityinfluenceproper-persondefinitiontitled-workproper-placeratingmethod-meansdate-rangeproper-organizationdatelocatormass-quantitywhy-famousnamegroup-of-peoplepro-concontrast05101520definitionproper-personproper-placeproper-organizationdate-rangewhy-famousdatenametitled-workbody-partnumerical-quantityyes:nomass-quantityinfluencemethod-meanscounsel-advicecircumstance-meansgroup-of-people05101520numerical-quantityproper-organizationtitled-workdatebody-partproper-personwhy-famousdate-rangeproper-placetemporal-quantitynamesubstanceinstrumentspatial-quantityantecedentlocatorexpression-originanimaldefinition0510152025to dates (223) but the number is lower in theadc samples (157 and 86 in electrarandom andelectrafooled, respectively).
as with bert, theelectra model was likely better at identifyinganswers about dates or years which could havefurther incentivized workers to generate less ques-tions of such types.
however, unlike with bert,we observe that the electra adc and sdc100-question samples contain similar numbers ofquestions involving numerical answers (8, 9 and10 in electrafooled, electrarandom and sdcrespectively)..lastly, despite explicit instructions not to gen-erate questions about passage structure (fig.
1),a small number of workers nevertheless createdsuch questions.
for instance, one worker wrote,“what is the number in the passage that is onedigit less than the largest number in the passage?”while most such questions were discarded duringvalidation, some of these are present in the ﬁnaldata.
overall, we notice considerable differencesbetween adc and sdc data, particularly vis-a-vis what kind of questions workers generate.
ourqualitative analysis offers additional insights thatsuggest that adc would skew the distribution ofquestions workers create, as the incentives alignwith quickly creating more questions that can foolthe model.
this is reﬂected in all our adc datasets.
one remedy could be to provide workers withinitial questions, asking them to edit those ques-tions to elicit incorrect model predictions.
similarstrategies were employed in (ettinger et al., 2017),where breakers minimally edited original data toelicit incorrect predictions from the models builtby builders, as well as in recently introduced ad-versarial benchmarks for sentiment analysis (pottset al., 2020)..6 conclusion.
in this paper, we demonstrated that across a vari-ety of models and datasets, training on adversar-ial data leads to better performance on evaluationsets created in a similar fashion, but tends to yieldworse performance on out-of-domain evaluationsets not created adversarially.
additionally, ourresults suggest that the adc process (regardless ofthe outcome) might matter more than successfullyfooling a model.
we also identify key qualitativedifferences between data generated via adc andsdc, particularly the kinds of questions created..overall, our work investigates adc in a con-.
trolled setting, offering insights that can guide fu-ture research in this direction.
these ﬁndings areparticularly important given that adc is more time-consuming and expensive than sdc, with workersrequiring additional ﬁnancial incentives.
we be-lieve that a remedy to these issues could be to askworkers to edit questions rather than to generatethem.
in the future, we would like to extend thisstudy and investigate the efﬁcacy of various con-straints on question creation, and the role of otherfactors such as domain complexity, passage length,and incentive structure, among others..acknowledgements.
the authors thank max bartolo, robin jia, tanyamarwah, sanket vaibhav mehta, sina fazelpour,kundan krishna, shantanu gupta, simran kaur,and aishwarya kamath for their valuable feedbackon the crowdsourcing platform and the paper..ethical considerations.
the passages in our datasets are sourced from thedatasets released by karpukhin et al.
(2020) un-der a creative commons license.
as describedin main text, we designed our incentive structureto ensure that crowdworkers were paid $15/hour,which is twice the us federal minimum wage.
ourdatasets focus on the english language, and are notcollected for the purpose of designing nlp appli-cations but to conduct a human study.
we shareour dataset to allow the community to replicate ourﬁndings and do not foresee any risks associatedwith the use of this data..references.
alexei baevski, sergey edunov, yinhan liu, lukezettlemoyer, and michael auli.
2019. cloze-drivenin proceed-pretraining of self-attention networks.
ings of the 2019 conference on empirical meth-ods in natural language processing and the 9th in-ternational joint conference on natural languageprocessing, emnlp-ijcnlp 2019, hong kong,november 3-7, 2019, pages 5359–5368.
associationfor computational linguistics..max bartolo, alastair roberts, johannes welbl, sebas-tian riedel, and pontus stenetorp.
2020. beat theai: investigating adversarial human annotation forreading comprehension.
transactions of the associ-ation for computational linguistics, 8:662–678..shai ben-david, tyler lu, teresa luu, and d´avid p´al.
2010. impossibility theorems for domain adaptation.
in artiﬁcial intelligence and statistics (aistats)..6626michael chen, mike d’arcy, alisa liu, jared fer-nandez, and doug downey.
2019. codah: anadversarially-authored question answering datasetfor common sense.
in proceedings of the 3rd work-shop on evaluating vector space representationsfor nlp, pages 63–69, minneapolis, usa.
associ-ation for computational linguistics..kevin clark, minh-thang luong, quoc v. le, andchristopher d. manning.
2020. electra: pre-training text encoders as discriminators rather thanin 8th international conference ongenerators.
learning representations, iclr 2020, addis ababa,ethiopia, april 26-30, 2020..pradeep dasigi, nelson f. liu, ana marasovi´c,noah a. smith, and matt gardner.
2019. quoref:a reading comprehension dataset with questions re-in proceedings ofquiring coreferential reasoning.
the 2019 conference on empirical methods in nat-ural language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 5925–5932, hong kong.
association for computational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..emily dinan, samuel humeau, bharath chintagunta,and jason weston.
2019. build it break it ﬁx it fordialogue safety: robustness from adversarial humanin proceedings of the 2019 conference onattack.
empirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages4537–4546, hong kong.
association for computa-tional linguistics..dheeru dua, yizhong wang, pradeep dasigi, gabrielstanovsky, sameer singh, and matt gardner.
2019.drop: a reading comprehension benchmark requir-ing discrete reasoning over paragraphs.
in proceed-ings of the 2019 conference of the north americanchapter of the association for computational lin-guistics: human language technologies, volume 1(long and short papers), pages 2368–2378, min-neapolis, minnesota.
association for computationallinguistics..matthew dunn, levent sagun, mike higgins, v ugurguney, volkan cirik, and kyunghyun cho.
2017.searchqa: a new q&a dataset augmented witharxiv preprintcontext from a search engine.
arxiv:1704.05179..allyson ettinger, sudha rao, hal daum´e iii, andemily m. bender.
2017. towards linguistically gen-eralizable nlp systems: a workshop and shared.
in proceedings of the first workshop ontask.
building linguistically generalizable nlp systems,pages 1–10, copenhagen, denmark.
association forcomputational linguistics..adam fisch, alon talmor, robin jia, minjoon seo, eu-nsol choi, and danqi chen.
2019. mrqa 2019shared task: evaluating generalization in readingin proceedings of the 2nd work-comprehension.
shop on machine reading for question answering,pages 1–13, hong kong.
association for computa-tional linguistics..suchin gururangan, swabha swayamdipta, omerlevy, roy schwartz, samuel bowman, and noah a.smith.
2018. annotation artifacts in natural lan-in proceedings of the 2018guage inference data.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 2 (short papers),pages 107–112, new orleans, louisiana.
associa-tion for computational linguistics..dan hendrycks, xiaoyuan liu, eric wallace, adamdziedzic, rishabh krishnan, and dawn song.
2020.pretrained transformers improve out-of-distributionrobustness.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,pages 2744–2751, online.
association for computa-tional linguistics..eduard hovy, laurie gerber, ulf hermjakob, michaeljunk, and chin-yew lin.
2000. question answeringin webclopedia.
in trec, volume 52..mandar joshi, eunsol choi, daniel weld, and lukezettlemoyer.
2017. triviaqa: a large scale dis-tantly supervised challenge dataset for reading com-prehension.
in proceedings of the 55th annual meet-ing of the association for computational linguistics(volume 1: long papers), pages 1601–1611, van-couver, canada.
association for computational lin-guistics..vladimir karpukhin, barlas oguz, sewon min, patricklewis, ledell wu, sergey edunov, danqi chen, andwen-tau yih.
2020. dense passage retrieval foropen-domain question answering.
in proceedings ofthe 2020 conference on empirical methods in nat-ural language processing (emnlp), pages 6769–6781, online.
association for computational lin-guistics..divyansh kaushik,.
eduard h. hovy,.
andzachary chase lipton.
2020. learning the differ-ence that makes a difference with counterfactually-in 8th international conferenceaugmented data.
on learning representations, iclr 2020, addisababa, ethiopia, april 26-30, 2020..divyansh kaushik and zachary c. lipton.
2018. howmuch reading does reading comprehension require?
a critical investigation of popular benchmarks.
inproceedings of the 2018 conference on empiricalmethods in natural language processing, pages.
66275010–5015, brussels, belgium.
association forcomputational linguistics..proceedings of machine learning research, pages3128–3136.
pmlr..divyansh kaushik, amrith setlur, eduard hovy, andzachary c lipton.
2021. explaining the efﬁcacyinternationalof counterfactually-augmented data.
conference on learning representations (iclr)..aniruddha kembhavi, min joon seo, dustin schwenk,jonghyun choi, ali farhadi, and hannaneh ha-jishirzi.
2017. are you smarter than a sixth grader?
textbook question answering for multimodal ma-in 2017 ieee conferencechine comprehension.
on computer vision and pattern recognition, cvpr2017, honolulu, hi, usa, july 21-26, 2017, pages5376–5384.
ieee computer society..douwe kiela, max bartolo, yixin nie, divyanshkaushik, atticus geiger, zhengxuan wu, bertie vid-gen, grusha prasad, amanpreet singh, pratik ring-shia, zhiyi ma, tristan thrush, sebastian riedel,zeerak waseem, pontus stenetorp, robin jia, mo-hit bansal, christopher potts, and adina williams.
2021. dynabench: rethinking benchmarking innlp.
in proceedings of the 2021 conference of thenorth american chapter of the association for com-putational linguistics: human language technolo-gies, pages 4110–4124..tom kwiatkowski, jennimaria palomaki, olivia red-ﬁeld, michael collins, ankur parikh, chris al-berti, danielle epstein, illia polosukhin, jacob de-vlin, kenton lee, kristina toutanova, llion jones,matthew kelcey, ming-wei chang, andrew m. dai,jakob uszkoreit, quoc le, and slav petrov.
2019.natural questions: a benchmark for question an-swering research.
transactions of the associationfor computational linguistics, 7:452–466..guokun lai, qizhe xie, hanxiao liu, yiming yang,and eduard hovy.
2017. race: large-scale read-ing comprehension dataset from examinations.
inproceedings of the 2017 conference on empiricalmethods in natural language processing, pages785–794, copenhagen, denmark.
association forcomputational linguistics..kenton lee, ming-wei chang, and kristina toutanova.
2019. latent retrieval for weakly supervised opendomain question answering.
in proceedings of the57th annual meeting of the association for com-putational linguistics, pages 6086–6096, florence,italy.
association for computational linguistics..omer levy, minjoon seo, eunsol choi, and lukezettlemoyer.
2017. zero-shot relation extraction viareading comprehension.
in proceedings of the 21stconference on computational natural languagelearning (conll 2017), pages 333–342..zachary c. lipton, yu-xiang wang, and alexander j.smola.
2018. detecting and correcting for labelin proceedingsshift with black box predictors.
of the 35th international conference on machinelearning, icml 2018, stockholmsm¨assan, stock-holm, sweden, july 10-15, 2018, volume 80 of.
yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
arxiv preprint arxiv:1907.11692..david lowell, zachary c. lipton, and byron c. wal-lace.
2019. practical obstacles to deploying activelearning.
in proceedings of the 2019 conference onempirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages21–30..yixin nie, adina williams, emily dinan, mohitbansal, jason weston, and douwe kiela.
2020. ad-versarial nli: a new benchmark for natural lan-guage understanding.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 4885–4901, online.
associationfor computational linguistics..denis paperno, germ´an kruszewski, angeliki lazari-dou, ngoc quan pham, raffaella bernardi, san-dro pezzelle, marco baroni, gemma boleda, andraquel fern´andez.
2016. the lambada dataset:word prediction requiring a broad discourse context.
in proceedings of the 54th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 1525–1534, berlin, germany.
association for computational linguistics..adam poliak, jason naradowsky, aparajita haldar,rachel rudinger, and benjamin van durme.
2018.hypothesis only baselines in natural language in-in proceedings of the seventh joint con-ference.
ference on lexical and computational semantics,pages 180–191, new orleans, louisiana.
associa-tion for computational linguistics..christopher potts, zhengxuan wu, atticus geiger,and douwe kiela.
2020. dynasent: a dynamicbenchmark for sentiment analysis.
arxiv preprintarxiv:2012.15349..pranav rajpurkar, jian zhang, konstantin lopyrev, andpercy liang.
2016. squad: 100,000+ questions formachine comprehension of text.
in proceedings ofthe 2016 conference on empirical methods in natu-ral language processing, pages 2383–2392, austin,texas.
association for computational linguistics..matthew richardson, christopher j.c. burges, anderin renshaw.
2013. mctest: a challenge datasetfor the open-domain machine comprehension of text.
in proceedings of the 2013 conference on empiri-cal methods in natural language processing, pages193–203, seattle, washington, usa.
association forcomputational linguistics..amrita saha, rahul aralikatte, mitesh m. khapra, andkarthik sankaranarayanan.
2018. duorc: towards.
6628teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander rush.
2020. trans-formers: state-of-the-art natural language process-ing.
in proceedings of the 2020 conference on em-pirical methods in natural language processing:system demonstrations, pages 38–45, online.
asso-ciation for computational linguistics..zhilin yang, peng qi, saizheng zhang, yoshua bengio,william cohen, ruslan salakhutdinov, and christo-pher d. manning.
2018a.
hotpotqa: a datasetfor diverse, explainable multi-hop question answer-ing.
in proceedings of the 2018 conference on em-pirical methods in natural language processing,pages 2369–2380, brussels, belgium.
associationfor computational linguistics..zhilin yang, saizheng zhang, jack urbanek, willfeng, alexander h. miller, arthur szlam, douwekiela, and jason weston.
2018b.
mastering the dun-geon: grounded language learning by mechanicalturker descent.
in 6th international conference onlearning representations, iclr 2018, vancouver,bc, canada, april 30 - may 3, 2018, conferencetrack proceedings..rowan zellers, yonatan bisk, roy schwartz, andyejin choi.
2018. swag: a large-scale adversar-ial dataset for grounded commonsense inference.
inproceedings of the 2018 conference on empiricalmethods in natural language processing, pages 93–104, brussels, belgium.
association for computa-tional linguistics..rowan zellers, ari holtzman, yonatan bisk, alifarhadi, and yejin choi.
2019. hellaswag: can ain proceed-machine really ﬁnish your sentence?
ings of the 57th annual meeting of the associationfor computational linguistics, pages 4791–4800..sheng zhang, xiaodong liu, jingjing liu, jianfenggao, kevin duh, and benjamin van durme.
2018.record: bridging the gap between human and ma-chine commonsense reading comprehension.
arxivpreprint arxiv:1810.12885..geoffrey zweig and chris j.c. burges.
2012. a chal-lenge set for advancing language modeling.
in pro-ceedings of the naacl-hlt 2012 workshop: willwe ever really replace the n-gram model?
onthe future of language modeling for hlt, pages29–36, montr´eal, canada.
association for compu-tational linguistics..a appendix.
complex language understanding with paraphrasedreading comprehension.
in proceedings of the 56thannual meeting of the association for computa-tional linguistics (volume 1: long papers), pages1683–1693, melbourne, australia.
association forcomputational linguistics..bernhard sch¨olkopf, dominik janzing, jonas peters,eleni sgouritsa, kun zhang, and joris m. mooij.
in pro-2012. on causal and anticausal learning.
ceedings of the 29th international conference onmachine learning, icml..hidetoshi shimodaira.
2000. improving predictive in-ference under covariate shift by weighting the log-likelihood function.
journal of statistical planningand inference, 90(2):227–244..james.
andreas vlachos,.
and arpit mittal..christosthorne,christodoulopoulos,2018.fever: a large-scale dataset for fact extractionin proceedings of the 2018and veriﬁcation.
conference ofthe north american chapter ofthe association for computational linguistics:human language technologies, volume 1 (longpapers), pages 809–819, new orleans, louisiana.
association for computational linguistics..james thorne, andreas vlachos, oana cocarascu,christos christodoulopoulos, and arpit mittal.
2019.the fever2.0 shared task.
in proceedings of thesecond workshop on fact extraction and veriﬁca-tion (fever), pages 1–6, hong kong.
associationfor computational linguistics..george tsatsaronis, georgios balikas, prodromosmalakasiotis, ioannis partalas, matthias zschunke,michael r alvers, dirk weissenborn, anastasiakrithara, sergios petridis, dimitris polychronopou-los, et al.
2015. an overview of the bioasq large-scale biomedical semantic indexing and question an-swering competition.
bmc bioinformatics, 16(1)..lifu tu, garima lalwani, spandana gella, and he he.
2020. an empirical study on robustness to spuri-ous correlations using pre-trained language models.
transactions of the association for computationallinguistics, 8:621–633..eric wallace, pedro rodriguez, shi feng, ikuya ya-mada, and jordan boyd-graber.
2019. trick meif you can: human-in-the-loop generation of adver-sarial examples for question answering.
transac-tions of the association for computational linguis-tics, 7:387–401..adina williams, tristan thrush, and douwe kiela.
2020. anlizing the adversarial natural language in-ference dataset.
arxiv preprint arxiv:2010.12729..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, remi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,.
6629evaluation set →training set ↓.
electrafooledf1em.
electrarandomf1em.
sdc.
em.
f1.
original dev.
f1.
em.
finetuned model: bertlarge.
original (o; 23.1k)original (14.6k).
23.336.70.4.
31.950.70.3.
56.748.20.4.electrafooled (f; 14.6k)electrarandom (r; 14.6k)sdc (14.6k).
25.11.0 42.41.042.01.025.41.140.81.323.11.0.
35.41.538.40.936.31.3.o + f (37.7k)o + r (37.7k)o + sdc (37.7k).
26.71.7 43.10.942.90.626.00.841.70.724.50.7.
40.11.341.70.541.40.9.
72.664.40.2.
54.31.156.80.856.31.3.
58.71.560.30.660.70.4.
63.855.70.1.
78.570.50.3.
59.31.739.12.442.01.461.71.345.21.8 65.41.5.
73.367.10.2.
31.97.946.43.148.61.6.
80.575.20.1.
45.09.260.63.862.31.9.
64.21.244.60.947.11.466.51.350.91.0 69.70.3.
72.10.579.70.773.00.5 80.50.279.70.172.00.1.finetuned model: robertalarge.
original (o; 23.1k)original (14.6k).
49.248.30.9.
64.463.31.4.
59.158.70.9.
75.874.91.0.
64.562.70.4.
79.879.00.7.
73.571.50.5.
80.579.30.6.electrafooled (f; 14.6k)electrarandom (r; 14.6k)sdc (14.6k).
65.30.5 79.90.579.40.464.60.577.10.361.00.2.
69.40.684.60.570.40.5 85.40.384.10.467.90.4.
89.00.375.80.676.50.589.40.377.30.5 89.90.3.
55.91.267.51.059.81.2 70.60.968.80.855.71.0.o + f (37.7k)o + r (37.7k)o + sdc (37.7k).
65.00.3 79.90.378.80.364.30.377.20.361.50.5.
70.10.585.20.470.70.2 85.80.284.70.469.00.4.
89.70.276.20.376.50.689.70.377.60.4 90.50.2.
73.30.373.40.573.60.5.
80.70.280.80.380.90.4.finetuned model: electralarge.
original (o; 23.1k)original (14.6k).
electrafooled (f; 14.6k)electrarandom (r; 14.6k)sdc (14.6k).
o + f (37.7k)o + r (37.7k)o + sdc (37.7k).
025.90.2.
26.41.523.44.924.52.4.
25.31.921.71.124.51.8.
10.840.90.4.
44.01.640.55.643.73.5.
43.72.040.11.143.41.6.
40.237.30.6.
41.21.542.36.940.63.5.
40.21.942.22.342.81.5.
57.863.90.7.
60.81.362.37.061.53.8.
60.61.964.81.963.51.0.
44.853.61.3.
42.74.042.18.046.95.4.
60.974.71.1.
63.53.262.97.568.24.7.
63.43.641.73.938.03.660.82.949.61.9 70.31.5.
74.271.90.3.
57.50.957.60.854.91.8.
73.60.574.40.374.20.2.
81.279.50.3.
68.80.769.31.068.31.2.
81.10.481.70.181.50.1.table 5: em and f1 scores of various models evaluated on adversarial datasets collected with an electralargemodel and non-adversarial datasets.
adversarial results in bold are statistically signiﬁcant compared to sdc settingand vice versa with p < 0.05..evaluation set →training set ↓.
droberta.
em.
f1.
dbert.
dbidaf.
em.
f1.
em.
f1.
finetuned model: bertlarge.
original (23.1k)original (14.6k).
electrafooled14.6k)electrarandom14.6k)sdc (14.6k).
orig + electrafooled (37.7k)orig + electrarandom (37.7k)orig + sdc (37.7k).
6.05.30.2.
3.80.54.30.53.90.4.
6.40.56.60.65.80.2.
13.511.40.2.
13.30.713.70.713.20.4.
16.10.316.10.315.60.4.
8.16.80.8.
6.20.76.40.45.40.4.
7.80.88.50.68.70.5.
14.213.90.5.
12.612.10.4.
21.420.60.2.
16.40.526.21.012.61.216.40.8 13.60.8 27.11.223.80.810.80.715.10.5.
18.00.618.40.518.70.6.
17.00.216.90.317.40.7.
31.00.630.80.430.00.8.finetuned model: robertalarge.
original (23.1k)original (14.6k).
electrafooled14.6k)electrarandom14.6k)sdc (14.6k).
15.714.30.2.
25.023.70.3.
26.525.10.3.
37.035.40.7.
37.937.40.7.
50.450.20.5.
16.40.9 27.71.227.21.415.81.423.91.312.11.0.
40.81.5.
62.41.127.41.328.11.6 41.51.8 48.00.9 63.00.656.81.322.71.1.
40.51.3.
46.81.1.
35.41.5.orig + electrafooled (37.7k)orig + electrarandom (37.7k)orig + sdc (37.7k).
18.90.818.00.418.21.0.
30.40.929.60.329.70.9.
33.20.8 46.40.6 49.20.9 65.10.863.50.632.30.660.90.628.20.3.
48.20.845.00.9.
45.11.241.40.5.finetuned model: electralarge.
original (23.1k)original (14.6k).
electrafooled14.6k)electrarandom14.6k)sdc (14.6k).
orig + electrafooled (37.7k)orig + electrarandom (37.7k)orig + sdc (37.7k).
8.29.50.2.
10.20.310.40.510.30.8.
10.20.310.40.510.30.8.
17.418.00.5.
21.70.521.30.521.60.7.
21.70.521.30.521.60.7.
15.715.40.5.
17.00.716.50.215.81.1.
17.00.716.50.215.81.1.
24.224.20.6.
29.70.628.60.828.51.2.
29.70.628.60.828.51.2.
22.421.70.2.
21.71.719.95.019.34.8.
34.333.10.1.
36.61.134.45.933.37.8.
39.20.724.00.723.50.538.40.424.50.6 39.90.6.table 6: em and f1 scores of various models evaluated on dev datasets of bartolo et al.
(2020).
adversarial resultsin bold are statistically signiﬁcant compared to sdc setting and vice versa with p < 0.05..663016.212.40.3.
11.90.710.50.910.10.9.
16.11.717.11.016.10.7.
48.747.70.7.
43.11.443.82.343.51.4.
52.21.152.60.752.40.1.bioasq.
drop.
duorc.
em.
f1.
em.
f1.
em.
f1.
relation extractionem.
f1.
race.
em.
f1.
textbookqa.
em.
f1.
finetuned model: bertlarge.
evaluation set →training set ↓.
original (23.1k)original (14.6k).
19.420.40.3.
32.535.90.7.electrafooled (14.6k)electrarandom (14.6k)sdc (14.6k).
29.11.113.60.915.90.832.01.717.10.7 34.51.0.orig + fooled (37.7k)orig + random (37.7k)orig + sdc (37.7k).
33.52.017.81.020.01.136.41.621.80.6 39.21.1.
7.85.10.3.
3.20.43.10.42.60.3.
6.11.16.80.96.10.5.
14.511.60.4.
11.00.912.10.911.90.8.
22.817.80.6.
19.30.620.41.421.21.2.
32.033.00.9.
33.62.235.73.134.23.4.
42.02.222.91.914.21.414.61.044.01.323.51.516.70.9 25.91.0 43.40.7.
47.144.22.0.
52.52.355.63.753.74.1.
59.62.561.81.361.01.1.
11.410.40.6.
7.90.79.50.79.21.0.
12.00.912.00.911.90.7.
18.817.70.9.
17.70.819.10.819.00.7.
22.20.922.00.922.50.7.
25.019.50.6.
33.427.30.7.
21.21.812.21.714.61.823.91.817.51.1 27.41.3.
33.71.224.61.023.90.833.51.025.40.5 35.50.6.hotpotqa.
em.
f1.
natural questionsf1em.
newsqa.
em.
f1.
searchqa.
squad.
triviaqa.
em.
f1.
em.
f1.
em.
f1.
original (23.1k)original (14.6k).
19.417.40.9.
33.928.71.2.electrafooled (14.6k)electrarandom (14.6k)sdc (14.6k).
33.40.819.10.721.21.035.51.323.51.2 37.81.3.orig + fooled (37.7k)orig + random (37.7k)orig + sdc (37.7k).
25.51.426.71.229.01.0.
40.81.541.91.242.60.8.
36.335.00.7.
28.01.429.02.328.41.7.
38.51.138.61.038.70.3.
16.212.80.2.
25.622.60.1.
25.90.812.90.813.80.827.11.315.60.8 30.31.0.
11.39.00.1.
4.00.34.20.45.00.5.
19.313.80.4.
32.526.00.3.
46.039.20.7.
9.10.59.10.69.90.7.
46.41.426.91.448.32.229.21.631.50.7 50.50.8.
16.811.80.5.
9.20.810.00.710.00.9.
25.318.20.7.
16.31.117.31.219.11.3.
17.00.722.61.822.71.117.00.418.70.6 33.90.5 11.10.7 16.60.9 36.10.7 54.90.5 15.10.3 24.20.2.
30.91.230.70.7.
15.80.814.61.2.
32.71.534.30.6.
51.71.553.30.8.
14.21.614.10.7.
9.90.49.20.9.finetuned model: robertalarge.
evaluation set →training set ↓.
original (23.1k)original (14.6k).
bioasq.
drop.
duorc.
em.
f1.
em.
f1.
em.
f1.
relation extractionem.
f1.
race.
em.
f1.
textbookqa.
em.
f1.
47.745.41.7.
41.21.443.31.443.71.0.
63.561.81.0.
37.237.51.7.
48.148.72.0.
38.637.80.7.
49.148.70.8.electrafooled (14.6k)electrarandom (14.6k)sdc (14.6k).
57.21.160.01.562.50.7.
30.31.744.91.834.12.4 48.82.043.42.927.52.6.
47.22.337.92.139.21.548.81.642.30.9 53.51.1.orig + fooled (37.7k)orig + random (37.7k)orig + sdc (37.7k).
61.21.045.01.246.31.062.60.847.50.5 64.00.5.
45.91.6 58.11.357.80.845.51.255.51.042.71.1.
47.21.736.81.439.11.349.31.342.11.3 53.71.1.
74.475.00.6.
74.10.875.50.574.90.8.
73.90.474.70.574.70.9.
85.986.00.2.
86.00.485.90.285.30.7.
86.30.386.60.286.90.5.
33.732.40.7.
31.71.332.60.731.50.9.
33.70.934.10.233.91.2.
44.943.40.9.
45.41.046.30.546.01.0.
47.30.947.20.447.31.0.
36.436.81.1.
4646.21.3.
40.51.830.81.732.21.242.21.436.32.0 47.22.0.
48.31.238.50.939.91.549.91.941.90.4 52.50.3.hotpotqa.
em.
f1.
natural questionsf1em.
newsqa.
searchqa.
squad.
em.
f1.
em.
f1.
em.
f1.
triviaqa.
em.
f1.
original (23.1k)original (14.6k).
electrafooled (14.6k)electrarandom (14.6k)sdc (14.6k).
19.447.00.3.
51.90.954.50.855.80.8.
33.962.70.3.
67.91.071.00.871.80.8.orig + fooled (37.7k)orig + random (37.7k)orig + sdc (37.7k).
71.70.955.60.856.00.271.90.357.50.7 72.80.6.
36.355.60.4.
49.60.651.60.651.70.5.
57.10.356.50.256.90.3.
48.767.50.5.
64.10.765.90.665.80.5.
69.60.369.10.369.40.3.
16.238.20.2.
25.653.60.3.
54.91.037.80.940.21.157.71.243.90.8 62.11.0.
57.71.840.61.542.30.359.30.744.30.7 62.70.7.
11.334.50.8.
24.02.024.32.624.42.4.
38.32.439.41.639.31.0.
19.343.80.6.
31.32.232.92.632.92.4.
47.32.748.51.748.61.1.
32.560.50.4.
46.075.60.5.
16.846.50.5.
25.358.50.7.
55.21.166.20.456.21.066.90.268.40.5 84.30.3 47.30.7 59.10.7.
82.00.382.60.2.
45.11.145.80.8.
57.51.067.00.558.80.368.00.269.90.4 84.30.2 48.60.5 60.10.5.
82.70.483.30.2.
46.71.047.80.3.bioasq.
drop.
duorc.
em.
f1.
em.
f1.
em.
f1.
relation extractionem.
f1.
race.
textbookqa.
em.
f1.
em.
f1.
finetuned model: electralarge.
evaluation set →training set ↓.
original (23.1k)original (14.6k).
electrafooled (14.6k)electrarandom (14.6k)sdc (14.6k).
orig + fooled (37.7k)orig + random (37.7k)orig + sdc (37.7k).
29.135.40.4.
25.31.125.54.925.07.5.
28.42.028.61.629.71.9.
42.851.00.8.
41.01.641.65.541.01.7.
45.22.644.92.047.02.2.original (23.1k)original (14.6k).
electrafooled (14.6k)electrarandom (14.6k)sdc (14.6k).
19.423.21.0.
26.20.924.75.524.43.3.
33.940.21.1.
42.20.940.96.941.75.2.orig + fooled (37.7k)orig + random (37.7k)orig + sdc (37.7k).
45.81.328.50.928.11.545.91.330.51.1 47.80.8.
17.616.20.5.
7.60.97.82.65.92.1.
15.60.816.30.615.60.8.
36.333.40.8.
31.51.427.96.828.86.2.
35.00.834.11.135.81.1.
26.926.60.8.
18.91.419.25.317.94.4.
28.61.029.01.229.11.3.
48.749.80.5.
49.71.145.77.646.78.3.
52.51.051.71.153.40.8.
18.918.80.4.
12.31.512.12.313.23.0.
27.126.70.8.
20.52.019.72.922.54.9.
53.446.21.3.
42.12.040.37.742.76.6.
67.461.11.7.
61.42.357.79.461.97.5.
19.617.30.9.
13.50.613.02.713.42.7.
28.527.90.6.
25.11.024.03.724.74.0.
32.529.60.6.
20.82.520.33.520.83.8.
41.837.80.7.
29.52.928.83.429.53.4.
13.31.041.61.142.20.512.81.016.40.7 27.10.8 48.01.8 67.01.5 19.00.6 32.10.8 33.70.4 43.80.9.
21.21.720.91.6.
41.52.839.43.3.
60.53.358.83.6.
17.60.716.61.3.
29.60.929.01.1.
32.20.932.40.4.
16.217.90.5.
18.71.217.23.119.23.6.
25.631.10.9.
11.316.00.5.
19.322.31.1.
32.11.630.83.835.53.2.
6.50.76.41.68.30.9.
10.41.010.32.112.81.6.
32.531.10.4.
34.51.334.15.834.74.2.
46.050.10.5.
53.71.553.16.254.15.1.
16.821.00.9.
13.21.012.43.413.42.0.
25.329.81.3.
21.51.320.14.522.73.5.
24.32.020.30.719.21.124.52.023.00.7 40.20.7 16.50.6 22.81.1 40.60.6 60.70.4 18.80.8 30.00.8.
34.91.034.11.8.
14.31.014.30.8.
19.81.420.11.3.
36.71.335.61.7.
56.51.555.31.4.
15.31.615.01.4.hotpotqa.
em.
f1.
natural questionsf1em.
newsqa.
searchqa.
squad.
em.
f1.
em.
f1.
em.
f1.
triviaqa.
em.
f1.
table 7: em and f1 scores of various models evaluated on mrqa dev and test sets.
adversarial results in boldare statistically signiﬁcant compared to sdc setting and vice versa with p < 0.05..6631resource.
examples.
lothal [sep] lothal ( ) is one of the southernmost cities of the ancient indus valley civilization , located in thebh¯al region ( ahammedabad district , dholka taluk)of the modern state of gujar¯at and ﬁrst inhabited 3700 bce.
the meaning of the word lothal is “ the mount of the dead ” exactly same as that of mohenjodaro anotherfamous site of indus valley civilization .
discovered in 1954 , lothal was excavated from 13 february 1955to 19 may 1960 by the archaeological survey of india ( asi ) , the ofﬁcial indian government agency for thepreservation of ancient monuments .
according to the asi , lothal had the world ’s earliestwhat is lothal and its ancient location?.
bertfooled one way or another [sep] “ one way or another ” is a song by american new wave band blondie from thealbum “ parallel lines ” .
the song was released as the fourth single in the us and canada as the follow - up tothe no .
1 hit “ heart of glass ” .
” one way or another ” reached no .
24 on the “ billboard ” hot 100 and no .
7 on the “ rpm ” 100 singles .
written by debbie harry and nigel harrison for the band ’s third studio album , “parallel lines ” ( 1978 ) , the song was inspired by one of harry ’s ex - boyfriends who stalked her after theirbreakup .
the song wasnot only did one way or another chart on billboard hot 100 but it also climbed what other chart?
india international exchange [sep] the india international exchange ( inx ) is india ’s ﬁrst international stockexchange , opened in 2017 .
it is located at the international financial services centre ( ifsc ) , gift cityin gujarat .
it is a wholly owned subsidiary of the bombay stock exchange ( bse ) .
the inx will be initiallyheaded by v. balasubramanian with other staff from the bse .
it was inaugurated on 9 january 2017 by indianprime minister narendra modi , the trading operations were scheduled to begin on 16 january 2017 .
it wasclaimed to be the world ’s most advanced technological platform with a turn - around time of 4 microwhere will the workers of the inx come from?.
true detective ( season 2 ) [sep] the second season of “ true detective ” , an american anthology crime dramatelevision series created by nic pizzolatto , began airing on june 21 , 2015 , on the premium cable network hbo .
with a principal cast of colin farrell , rachel mcadams , taylor kitsch , kelly reilly , and vince vaughn , theseason comprises eight episodes and concluded its initial airing on august 9 , 2015 .
the season ’s story takesplace in california and follows the interweaving stories of ofﬁcers from three cooperating police departments ;when california highway patrol ofﬁcer and war veteran paul woodrugh ( kitsch )who created true detective?.
bertrandom history of time in the united states [sep] the history of standard time in the united states began november 18 ,1883 , when united states and canadian railroads instituted standard time in time zones .
before then , time ofday was a local matter , and most cities and towns used some form of local solar time , maintained by some well -known clock ( for example , on a church steeple or in a jeweler ’s window ) .
the new standard time system wasnot immediately embraced by all .
use of standard time gradually increased because of its obvious practicaladvantages for communication and travel .
standard time in timewhat form of time did most cities and towns use before standard?
one call away ( charlie puth song ) [sep] “ one call away ” is a song by american singer charlie puth forhis debut album “ nine track mind ” .
it was released on august 20 , 2015 by atlantic records as the secondsingle from the album , after the lead single “ marvin gaye ” .
“ one call away ” is a gospel - infused pop soulsong .
it reached number 12 on the “ billboard ” hot 100 , making it puth ’s third top 40 single in the us and histhird highest - charting single as a lead artist to date , behind “ we do n’t talk anymore ” andwhat is charlie puth’s ﬁrst album?.
sdc.
cap of invisibility [sep] in classical mythology , the cap of invisibility ( “ ( h)a¨ıdos kune¯en ” in greek , lit .
dog - skin of hades ) is a helmet or cap that can turn the wearer invisible .
it is also known as the cap of hades, helm of hades , or helm of darkness .
wearers of the cap in greek myths include athena , the goddess ofwisdom , the messenger god hermes , and the hero perseus .
the cap of invisibility enables the user to becomeinvisible to other supernatural entities , functioning much like the cloud of mist that the gods surround themselvesin to become undetectable .
one ancientwhat is the name given to a cap or helmet that renders the wearer unable to be seen in classical mythol-ogy?
the dark side of the moon [sep] the dark side of the moon is the eighth studio album by english rock bandpink floyd , released on 1 march 1973 by harvest records .
it built on ideas explored in pink floyd ’s earlierrecordings and performances , but without the extended instrumentals that characterised their earlier work .
aconcept album , its themes explore conﬂict , greed , time , and mental illness , the latter partly inspired by thedeteriorating health of founding member syd barrett , who left in 1968 .
developed during live performances ,pink floyd premiered an early version of “ the dark side of the moonwhich company released the album “the dark side of the moon”?
the boy in the striped pyjamas [sep] the boy in the striped pyjamas is a 2006 holocaust novel by irish novelistjohn boyne .
unlike the months of planning boyne devoted to his other books , he said that he wrote the entireﬁrst draft of “ the boy in the striped pyjamas ” in two and a half days , barely sleeping until he got to the end .
he did , however , commit to nearly 20 years of research , reading and researching about the holocaust as ateenager before the idea for the novel even came to him .
as of march 2010 , the novel had soldhow many days did it take john boyne to write the ﬁrst draft of the boy in the striped pyjamas?.
table 8: validation set examples of questions in different resources.
correct answers are highlighted in red..6632resource.
examples.
six ( tv series ) [sep] six ( stylized as six ) is an american television drama series .
the series was orderedby the history channel with an eight - episode initial order .
the ﬁrst two episodes were directed by leslilinka glatter .
“ six ” premiered on january 18 , 2017 .
“ six ” was renewed for a second season of 10episodes on february 23 , 2017 , which premiered on may 28 , 2018 , with the second new episode airingduring its regular timeslot on may 30 , 2018 .
on june 29 , history announced they had cancelled the seriesafter two seasons .
the series chronicles the operations and daily lives of operatorswho directed the ﬁrst two episodes of six?.
electrafooled outer space [sep] outer space , or just space , is the expanse that exists beyond the earth and betweencelestial bodies .
outer space is not completely empty — it is a hard vacuum containing a low density ofparticles , predominantly a plasma of hydrogen and helium as well as electromagnetic radiation , magneticﬁelds , neutrinos , dust , and cosmic rays .
the baseline temperature , as set by the background radiationfrom the big bang , is .
the plasma between galaxies accounts for about half of the baryonic ( ordinary )matter in the universe ; it has a number density of less than one hydrogen atom per cubichalf of the ordinary matter in the universe is comprised of what?
ode to billie joe [sep] “ ode to billie joe ” is a song written and recorded by bobbie gentry , a singer -songwriter from chickasaw county , mississippi .
the single , released on july 10 , 1967 , was a number -one hit in the us and a big international seller .
“ billboard ” ranked the record as the no .
3 song of theyear .
it generated eight grammy nominations , resulting in three wins for gentry and one for arrangerjimmie haskell .
“ ode to billie joe ” has since made “ rolling stone” ’s lists of the “ 500 greatest songsof all time ” and the “ 100 greatest country songs of all time ” and “ pitchfork”what did “billboard” rank as the no.
3 song of the year in 1967?.
sagrada fam´ılia [sep] the (; ; ) is a large unﬁnished roman catholic church in barcelona , designed bycatalan architect antoni gaud´ı ( 1852–1926 ) .
gaud´ı ’s work on the building is part of a unesco worldheritage site , and in november 2010 pope benedict xvi consecrated and proclaimed it a minor basilica ,as distinct from a cathedral , which must be the seat of a bishop .
in 1882 , construction of sagrada fam´ıliastarted under architect francisco de paula del villar .
in 1883 , when villar resigned , gaud´ı took over aschief architect , transforming the project with his architectural and engineering stylewhat kind of unﬁnished church is the sagrada fam´ılia?.
electrarandom loyola ramblers men ’s basketball [sep] the loyola ramblers men ’s basketball team represents loyolauniversity chicago in chicago , illinois .
the ramblers joined the missouri valley conference on july 1 ,2013 , ending a 34-season tenure as charter members of the horizon league .
in 1963 , loyola won the1963 ncaa men ’s division i basketball tournament ( then the “ ncaa university division ” ) men ’sbasketball national championship under the leadership of all - american jerry harkness , defeating two -time defending champion cincinnati 60–58 in overtime in the title game .
all ﬁve starters for the ramblersplayed the entire championship game without substitution .
surviving team members werewhen did the ramblers join the missouri valley conference?
the walking dead ( season 7 ) [sep] the seventh season of “ the walking dead ” , an american post -apocalyptic horror television series on amc , premiered on october 23 , 2016 , and concluded on april 2 ,2017 , consisting of 16 episodes .
developed for television by frank darabont , the series is based on theeponymous series of comic books by robert kirkman , tony moore , and charlie adlard .
the executiveproducers are kirkman , david alpert , scott m. gimple , greg nicotero , tom luse , and gale anne hurd ,with gimple as showrunner for the fourth consecutive season .
the seventh season receivedwhat was the walking dead’s original source material?.
sdc.
southern california edison [sep] southern california edison ( or sce corp ) , the largest subsidiaryof edison international , is the primary electricity supply company for much of southern california .
itprovides 14 million people with electricity across a service territory of approximately 50,000 square miles .
however , the los angeles department of water and power , san diego gas & electric , imperial irrigationdistrict , and some smaller municipal utilities serve substantial portions of the southern california territory.
the northern part of the state is generally served by the paciﬁc gas & electrichow many people does sce corp provide with electricity?
do n’t go away [sep] “ do n’t go away ” is a song by the english rock band oasis from their third album, “ be here now ” , written by the band ’s lead guitarist noel gallagher .
the song was released as acommercial single only in japan , peaking at number 48 on the oricon chart , and as a promotional single inthe united states , japan and europe .
in the united states it was a success , hitting # 5 on the “ billboard ”hot modern rock tracks chart in late 1997 .
it was the band ’s last major hit in the unitedwhat oasis album is “don’t go away” from?
india national cricket team [sep] the india national cricket team , also known as team india and menin blue , is governed by the board of control for cricket in india ( bcci ) , and is a full member of theinternational cricket council ( icc ) with test , one day international ( odi ) and twenty20 international( t20i ) status .
although cricket was introduced to india by european merchant sailors in the 18th century, and the ﬁrst cricket club was established in calcutta ( currently known as kolkata ) in 1792 , india ’snational cricket team did not play its ﬁrst test match until 25 june 1932 at lord ’swhat does odi stand for?.
table 9: validation set examples of questions in different resources.
correct answers are highlighted in red..6633