regression bugs are in your model!
measuring, reducing and analyzing regressions in nlp model updates.
yuqing xie∗∗1, yi-an lai2, yuanjun xiong2, yi zhang2, stefano soatto21university of waterloo2amazon aws aiyuqing.xie@uwaterloo.ca{yianl,yuanjx,yizhngn,soattos}@amazon.com.
abstract.
behavior of deep neural networks can beinconsistent between different versions.
re-gressions1during model update are a commoncause of concern that often over-weigh thebeneﬁts in accuracy or efﬁciency gain.
thiswork focuses on quantifying, reducing andanalyzing regression errors in the nlp modelupdates.
using negative ﬂip rate as regres-sion measure, we show that regression has aprevalent presence across tasks in the gluebenchmark.
we formulate the regression-freemodel updates into a constrained optimiza-tion problem, and further reduce itinto arelaxed form which can be approximately op-timized through knowledge distillation train-ing method.
we empirically analyze howmodel ensemble reduces regression.
finally,we conduct checklist behavioraltestingto understand the distribution of regressionsacross linguistic phenomena, and the efﬁcacyof ensemble and distillation methods..1.introduction.
regression-free model update is a desirable systemproperty which guarantees interoperability of anew system with a legacy version, also known asbackward compatibility.
regression occurs whenthe newly updated system stops functioning asintended..as advances in deep learning spark industrialapplications in ai areas such as natural languageprocessing, the long-term maintenance of suchsystems is becoming ever more challenging.
whilemodels with complex neural architectures andhuge parameter space continue to reach higheraccuracy, the lack of interpretability and functionaldecomposibility in these models make it infeasibleto apply traditional software regression testing.
∗∗ work done while at amazon aws ai.
1here regression refers to bugs in software testing instead.
of the statistical estimation method..figure 1: prediction ﬂip scenarios on nlp classiﬁ-cation tasks when updating from old to new models.
examples from paraphrase classiﬁcation task..methods such as unit tests.
as result, validatingand mitigating regressions during model update isoften a long and painful engineering process, whichoften over-shadows the beneﬁts of a new model..the model regression issue in deep learningﬁrst comes into sight in shen et al.
(2020), wherethey inspect compatible representation learningfor image retrieval.
yan et al.
(2020) proposedthe positive-congruent training (pct) for imageclassiﬁcation that minimizes prediction errors andmodel regression at the same time.
to our bestknowledge, the model update regression has notbeen studied on nlp tasks..following yan et al.
(2020), in this work wemeasure the model update regression in nlpby negative ﬂips.
in figure 1, we demonstrateprediction ﬂip scenarios.
negative ﬂips are shownin the upper-right quadrant where the old modelmakes correct predictions and the new modelpredictions are wrong.
as we will show insection 2, regression are prevalent in nlu modelupdates even with the slightest changes in the newmodel training process..to develop a model with minimum regres-sion, we ﬁrst formulate the learning task into aconstrained optimization problem by taking theregression-free conditions as constraints.
we applythe lagrangian relaxation to bring the regression-free constraint into the optimization objective as an.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6589–6602august1–6,2021.©2021associationforcomputationallinguistics6589negative no flippositive flipnegative flippositive no flipi can become more lovely.≠ i can become less lovely.i can become more brave.= i can become more courageous.alice is proposing to bob.≠ bob is proposing to alice.sare took the castle.≠ sara was taken by the castle.new correctnew wrongoldcorrectold wrongnew: ≠old: ≠new: ≠old: =old: =old: =new: =new:  ≠additional penalty loss, and provide approximatesolution via knowledge distillation.
yan et al.
(2020) also observed that model ensemble can alsoreduce negative ﬂips without explicit input fromthe old model.
we evaluate both distillation andensemble based methods on a diverse set of nlptasks..to further understand how the above methodscontribute to reducing it, we utilize checklist(ribeiro et al., 2020) to quantify linguistic behav-ioral changes before and after applying proposedmethods.
we ﬁnd that regressions are prevalent innlp tasks, and their distribution correlates withdifferent linguistic phenomena..our main contributions are as follows:.
• we provide empirical evidence to show thatthe model update regression occurs across textclassiﬁcation tasks in nlp;.
• we formulate the regression-free model up-dates into a constrained optimization problem,and further reduce into a relaxed form whichcan be approximately optimized throughknowledge distillation training method;.
• we also explore the model ensemble asanother method to reduce regression, andanalyzed its efﬁcacy;.
• we analyze the source of the regressionsin nlp tasks through linguistic behaviouraltesting, compare reduction in both distillationand ensemble methods..2 measuring regression in nlp model.
update.
in this section, we ﬁrst formulate the measure ofmodel update regression on classiﬁcation tasks.
then we benchmark on glue tasks (wang et al.,2018) and show that there is a prevalent presenceof regression when updating models in nlp..2.1 regression measurement on.
classiﬁcation tasks.
similar to software regression testing, we needto collect a group of test cases when measuringregression.
we start from a regression set: dreg ={xi, yi}ni=1, yi ∈ {l1, l2, ..., lc}, where li is thei-th label and c is the number of classes.
inpractice, we can use the development set or compilea collection of critical use cases as dreg..in a classiﬁcation task, given a input xi, aneural network model f , parameterized by φ,.
approximates the posterior probabilistic distribu-tion p(yi|xi) over all possible labels: (cid:126)fφ(xi) =(pφ(y = l1|xi), ..., pφ(y = lc|xi))(cid:62).
to simplify,we denote the ﬁnal prediction of a model to befφ(x) = arg maxlj pφ(lj|x)..the regression rn f between two models fφoldand fφnew on dreg can be deﬁned as the portion ofnegative ﬂip cases:.
rn f (dreg, (cid:126)fφold , (cid:126)fφnew )|{x|fφold = y, fφnew (cid:54)= y}||dreg|.
..=.
we use negative ﬂip rn f as our regressionmeasurement for classiﬁcation tasks.
lower rn ffor a new models means better compatibility withthe old model..2.2 benchmark severity of regression.
the success of transformer (vaswani et al., 2017)and bert (devlin et al., 2019) have made pre-training then ﬁne-tuning a standard paradigm innlp systems.
when updating these systems,differences can come from various aspects:.
• changes in the ﬁne-tuning hyperparametersrandom seed, learning rate schedule,.
(e.g.
epoch, etc.).
• changes in model size or architecture (e.g..from bertbase to bertlarge).
• changes in pre-training procedure or objective(e.g.
bert to roberta (liu et al., 2020),to bertwhole-word-masking or to electra(clark et al., 2020)).
• changes in pre-trained model architecture(e.g.
bert to albert (lan et al., 2020)).
while accuracy or efﬁcient improvements arestrong motivations for these model updates, theycould also introduce behavioral incongruence whencompared to the previous model.
to benchmarkthe severity of regression, we apply a general setup:fine-tune various pre-trained language models(lm) on glue and calculate rn f when updatingfrom bertbase to other lms .
we use dev sets asdreg.
results in table 1 show that:.
1. model update regression is prevalent on nlutasks.
a minimum of 1.98% rn f is observedacross diverse classiﬁcation tasks and modelupdate scenarios, while the average accuracygain is only 1.4%..2. minor changes such as random seeds canintroduce signiﬁcant regression.
shown in.
6590train sizedev size.
old: bertbase.
acc.
→ bertbase.
→ bertlarge.
→ robertabase.
accrn faccrn faccrn f→ electrabase accrn faccrn f.→albertbase.
cola.
8.6k1k.
82.84%.
mrpc.
3.7k0.4k.
qqp.
360k40k.
86.03%.
90.76%.
mnli-m.390k9.8k.
83.82%.
83.80%(+0.96%)←(cid:45)3.36%85.43%(+2.59%)←(cid:45) 3.16%84.85%(+2.01%)←(cid:45)4.67%85.81%(+2.97%)←(cid:45) 5.18%76.51%(-6.33%)←(cid:45)10.74%.
86.03%(-0.00%)←(cid:45) 4.17%87.75%(+1.72%)←(cid:45) 5.88%89.22%(+3.19%)←(cid:45) 4.66%86.03%(+0.00%)←(cid:45) 5.39%86.27%(+0.24%)←(cid:45) 6.86%.
90.56%(-0.20%)←(cid:45)2.32%91.11%(+0.35%)←(cid:45)2.82%91.25%(+0.52%)←(cid:45)1.98%91.35%(+0.59%)←(cid:45) 3.20%90.73%(-0.03%)←(cid:45) 3.78%.
83.55%(-0.27%)←(cid:45) 3.56%86.10%(+1.97%)←(cid:45) 3.95%87.58% (+4.42%)←(cid:45) 2.64%88.87%(5.05%)←(cid:45)3.50%85.26%(+1.44%)←(cid:45) 5.22%.
table 1: regression measurement when performing different model updates on glue benchmark.
old: bertbaseis our base version of model and we update it to other new models.
we also show the accuracy gain in theparenthesis.
all numbers are 5-seed average.2.
→bertbase, even when we only alter theinitialization random seed, this can lead to upto 3.56% negative ﬂip..3. negative ﬂip rates are often much higherthan the accuracy gains.
when updating tobertlarge on qqp, rn f is about 8x theaccuracy gain.
this implies reducing errorrate alone does not ensure the decrease inregression..4. pre-training objective or architecture updatesoften lead to higher regressions than thosecaused by model size or random seeds.
theregressions are higher when updating toalberta, compared with updating to alarger model bertlarge or a different randomseed.
this implies systematic regression couldbe introduced if the backbone models aredifferent..3 reducing regression in model update.
in this section, we ﬁrst formulate regression-free model update as a constrained optimizationto a jointthen further reducing itproblem,optimization objective combining the training losson the original task and a distillation loss withrespect to the old model’s behavior..unlike typical optimizations in neural modeltraining where we minimizes a loss function ona training set, the regression-free model updaterequires the model to learn the target task as wellas comply with conditions posed by the old model..2full results on glue can be found in appendix a.we can cast the regression-free model update as aconstrained optimization problem by writing downthe classiﬁcation loss as the optimization objectiveand the regression-free conditions as constraints:.
minφnew.
(cid:88).
x∈dtrain.
lce(x, φnew).
s.t.
rn f (fφold, fφnew , dreg) = 0..(1).
where dtrain, dreg representregression sets, respectively..the training and.
the constraint in equation 1 asks for zeroregression on dreg.
it would be difﬁcult to ensurethe constraint is satisﬁed along the model training.
we instead relax the hard constraint into a softinequality condition that allows the regressionmeasure to be less than a constant c:.
minφnew.
(cid:88).
x∈dtrain.
lce(x, φnew).
(2).
s.t.
c − rn f (fφold, fφnew , dreg) ≥ 0..training a model directly with the regression-free constraint still remains difﬁcult in that signalsfrom old predictions are sparse and rn f is non-differentiable.
here, we propose two proxies ofrn f to measure regression in continuous space.
proxy from prediction probabilities.
we use thekl divergence between the predicted probabilitiesof both models as one soft regression measure:.
rkl-div(fφold, fφnew , dreg).
dkl(pφold(y|x)||pφnew (y|x))..(3).
(cid:88).
=.
x∈dreg.
6591proxy from deep representations.
we can alsouse the l2 distance between models’ sentencerepresentations, e.g.
[cls] embedding in bertas another soft regression measure:.
rl2(fφold, fφnew , dreg).
l2( (cid:126)fφold(x), (cid:126)fφnew (x))..(4).
(cid:88).
=.
x∈dreg.
a linear projection is used to align the representa-tions if they initially lie in different spaces..reduce to knowledge distillation.
finally, weapply the lagrangian relaxation to bring theregression-free constraint into the optimizationobjective as an additional penalty loss:.
model artifacts and the glue dataset processingprocedures are brought from hugging face3 andexperiments are done in pytorch (paszke et al.,2019) with tesla v100 gpus.
cross-entropy isused for ﬁne-tuning on target tasks with batch size16 for 4 to 6 epochs.
the learning rate is searchedamong 2e−5, 3e−5 and 5e−5..during joint training of classiﬁcation and knowl-edge distillation, we take the ﬁne-tuned old modelsas the teacher, and distill with batch size 16for 6 to 8 epochs.
we set dreg = dtrainwhen training models with the constraint and usedreg = ddev for reporting results.
to encourageconstraint satisfaction and reduce regression, weonly include the distillation penalty into our losson the examples where the current model makesnegative ﬂips..minφnew.
(cid:88).
x∈dtrain.
lce(x, φnew).
− α ∗ (c − rsof t(fφold, fφnew , dreg)),.
(5).
4.2 ensemble.
where α is a positive penalty scaling parameterand rsof t can be chosen from rkl-div or rl2.
then, the above optimization problem can be castinto a joint learning of the original target task andknowledge distillation from the old model.
thedistillation loss acts as a surrogate of the modelupdate regression measure.
the joint learningprocess minimizes this term as an approximationof minimizing the overall model update regression..yan et al.
(2020) reported an intriguing ﬁnding onimage classiﬁcation tasks that model ensemble canreduce model update regressions without explicitregularization from the old model.
this wasattributed to the reduction of variance in ensemblemodel predictions, making it less prone to over-ﬁtting and indirectly reducing regressions.
here weinclude model ensemble as an alternative approachto reduce regression, with further analysis on howensemble reduces regression in section 5.1..4 experiments.
4.3 main results.
4.1.implementation details.
since we usually update models from elementaryones to improved ones, in the experiments wetake origin bertbase (12-layer, 768-hidden, 12-heads, 110m parameters) (devlin et al., 2019)as the old model’s backbone and update it toa homogeneous model, e.g.
bertbase withdifferent ﬁne-tuning random seeds or parameters,or a heterogeneous models with improvementssuch as bertlarge (24-layer, 1024-hidden, 16-heads, 340m parameters).
we ﬁne-tune the pre-trained lms without any constraint as our baselines.
we use the glue datasets to benchmark theeffectiveness of proposed techniques.
details ofeach glue task can be found in appendix d. forinvestigative experiments, we use the microsoftresearch paraphrase corpus (mrpc) (dolanand brockett, 2005), a paraphrase identiﬁcationdataset that aims to classify whether two sentencesare the paraphrase of each other.
pre-trained.
table 2 shows the efﬁcacy of distillation methodand model ensemble on reducing nlp classiﬁca-tion task model update regressions.
on average,the distillation method reduces rn f by 30.6%and 36.3% while the ensemble method reducesrn f by 55.9% and 20.6% when updating tobertbase and to bertlarge, respectively.
bothdistillation and ensemble methods can signiﬁcantlybring down negative ﬂips across glue taskscompared with the baselines.
the ensemble seemsto work better when the old and new modelsshare the same underlying pre-trained lm.
inthe update bertbase →bertbase, the ensemblemethod outperforms the distillation on reducingthe regression.
on the other hand, the distillationmethod seems to be more effective on reducingregression under the heterogeneous model updatein the update bertbase →bertlarge,setting.
distillation reduce more regression, with especially.
3https://huggingface.co.
6592cola.
sst-2 mrpc.
qqp mnli-m qnli.
rte.
average.
train sizedev size.
8.6k1k.
67k0.9k.
3.7k0.4k.
360k40k.
390k9.8k.
100k5.5k.
2.5k0.3k.
old: bertbase.
acc.
82.26% 91.17% 86.03% 90.76%.
83.82%.
91.07% 67.15% 84.61%.
→bertbase - baseline.
→bertbase - distillation.
→bertbase - ensemble.
→bertlarge - baseline.
→bertlarge - distillation.
→bertlarge - ensemble.
accrn faccrn faccrn f.accrn faccrn faccrn f.1.95%.
4.17%.
82.93% 91.63% 86.03% 90.56%4.41%2.32%84.47% 92.09% 87.01% 91.14%1.92%1.69%82.17% 91.63% 86.03% 91.06%1.18%2.59%.
0.80%.
1.23%.
1.72%.
0.92%.
83.55%3.56%83.77%4.32%84.35%1.66%.
90.65% 63.18% 84.08%2.35% 11.43%4.31%91.16% 68.95% 85.81%2.47%2.99%8.30%91.62% 70.76% 85.37%1.90%4.69%1.06%.
1.72%.
5.88%.
92.53% 66.43% 86.06%85.62% 92.89% 87.75% 91.11%2.68%4.57%2.64% 12.27%2.82%85.62% 92.89 % 88.73% 91.50% 86.73 % 92.15% 73.65% 87.33%2.91%2.49%5.42%2.46%2.54 %93.08% 67.87% 86.74%84.95% 93.12% 89.46% 91.66%2.27% 10.83%2.20%3.63%2.78%.
3.76%87.05%3.24%.
86.10%3.95%.
1.26%.
2.45%.
2.45%.
1.61%.
table 2: results of ﬁne-tuning with distillation and ensemble on glue benchmark.
baseline denotes directlyﬁne-tuning new pre-trained models on target tasks.
we show the distillation results with rkl-div, and the ensembleresults with 5 model majority vote.
due to page limitation, we only show the matched results on mnli (williamset al., 2018)..large reductions on small datasets such as colaand sst-2.
we hypothesize that it’s becausethe ensemble focuses on reducing the variance inmodel predictions, while distillation enables theexplicit alignment in either probability distributionor representation space between the old and the newmodel.
when the new model is very different fromthe old one, it can implicitly align new model’sbehavior with the old one..4.4 variants in distillation objective.
as introduced in section 3, we can have severalvariants of distillation loss to be used to constrainnew model training on the old model.
we exploreand benchmark the following variants on themrpc task:.
• distillation - rkl-div, logits calculates thedistillation loss as the kl divergence betweenthe two bernoulli distributions set by the oldand new model prediction probabilities;.
• distillation - rl2, [cls] uses the [cls]token embedding from the ﬁnal layer assentence representations and calculates thedistillation loss as the euclidean distancebetween the two vectors;.
• distillation - rl2, all [cls] also calculatesthe euclidean distance between the old andnew sentence representation vectors, but withconcatenated [cls] token embeddings fromall layers instead of the ﬁnal layer..pre-trained models could have different layers.
for bertbase →bertlarge in the all [cls]setup, we align representations from bertlarge’seven layers with the corresponding bertbaselayers, e.g.
14-th layer in bertlarge is alignedwith 7-th in bertbase..table 3 shows the results.
in the homogeneoussetup, the most effective variant is to align theprediction probabilities via rkl-div, where itachieves up to 58% rn f reduction, i.e.
from4.17% to 1.72%.
for rl2 setup, aligning at alllayers can further reduce rn f compared with onlyaligning at the ﬁnal layer.
this implies a deeperalignment can help the new model more effectivelylearn to behave similarly as the old one whenﬁne-tuning the same architecture with a differentrandom seed..in the heterogeneous setup, rl2, [cls] worksthe best for bertlarge that achieves 62% rn freduction, with rkl-div having a comparableperformance.
overall, rkl-div produces consistentregression reductions across different setups, whichwe pick it as our default setting in the distillationmethod..from table 3, we can also observe that thedeeper alignment seems to hurt rn f in theheterogeneous update setup.
the reason mightbe that differences between pre-trained modelsare too signiﬁcant.
the distillation with simpleall-layer alignment could mess up pre-trainedrepresentations rather than effectively encourage.
6593old: bertbase.
acc: 86.03%.
new:.
baseline.
distillation - rkl-div, logitsdistillation - rl2 , [cls]distillation - rl2 , all [cls]ensemble.
→bertbasern facc.
→bertlargern facc.
86.03% 4.17% 87.75% 5.88%.
87.01% 1.72% 88.73% 2.45%85.54% 3.19% 88.73% 2.21%85.54% 2.45% 87.99% 4.90%.
86.0% 1.23% 89.46% 2.45%.
table 3: accuracy and regression results on mrpc with bertbase →bertbase and bertbase →bertlargeupdates using variants of distillation and ensemble methods.
baseline is ﬁne-tuning with different random seeds.
model accuracy and negative ﬂip rates are averaged across 5 seeds..single, average rn f = 4.00%ensemble, average rn f = 2.79%.)
004.latot(.
stnuoc.60.
50.
40.
30.
20.
10.
0.new models to learn where the old model performswell..another interesting ﬁnding is that the sim-ple model ensemble is a competitive solutioncomparing to the distillation.
in the bertbase→bertbase setup, the ensemble even outperformsall the other distillation variants.
this is indeed abit counter-intuitive as the distillation explicitlyencourages the new model to pick up old models’correct predictions while the ensemble does notinvolve the old model in the process.
we conductdeeper analysis trying to understand on whichaspects that these methods work to reduce theregression in the next section..5 analyzing regression in model.
updates.
in this section, we ﬁrst analyze the model ensembleand present our hypothesis on how it reducesregression.
next, we conduct behavioral testingacross diverse linguistic phenomena to see wherethe reduced and remaining regressions reside..5.1 analysis of updating to model ensemble.
similar to the ﬁndings of yan et al.
(2020), weobserve in table 2 and 3 that a simple ensemble ofmodels trained with different random initializationbefore ﬁnetuning can reduce regression in somecases.
we ﬁne-tune bertbase on mrpc with 20random seeds as our old base models, and another20 seeds as our new single models, and another 100seeds for building 20 ensemble models.
next, wecalculate rn f on the dev set in each model updatesetup, i.e.
400 update pairs.
figure 2 plots theirmodel update regression rn f distributions.
weobserve that the ensemble can not only bring downrn f but also reduce its variance..from figure 2, we conjecture that each single.
1.
2.
3.
4.
5.
6.
7.
8.rn f (%).
figure 2: pair-wise rn f distributions of updatebertbase →bertbase on mrpc, with new modelbeing single models ﬁne-tuned with different seeds(blue) or ensemble models (red).
we train 20 old and20 new models to calculate 400 pair-wise rn f ..model could learn a subset of all possible patternsin the data to achieve comparable accuracy on thetask.
models ﬁne-tuned with different seeds couldrely on different sets of patterns for predictions,leading to behavioral difference and regression.
onthe other hand, ensemble aggregates distinct andcomplementary behaviors from individual models,leading to less eccentric behavior and increasedcompatible with individual models on average.
ina parallel work, zeyuan and li (2020) providesa theoretical framework of how ensemble worksfrom the multi-view perspective.
they show thatsingle models can pick up multiple but differentviews of the data, and the ensemble naturallycollects more view features, leading to a higheraccuracy.
our hypothesis concurs with theirﬁndings..however, ensemble is not required to achievemoderate model behavior.
to verify this, wedesigned the following simple model selection.
6594old: bertbase.
single.
85.81(±1.07)%.
behavioral testing.
acc.
5.2 analyzing regression with linguistic.
rn f.-.
→bertbase.
→bertlarge.
singleensemblecentric.
singleensemblecentric.
85.39(±1.43)% 4.30(±1.53)%86.18(±1.12)% 3.08(±1.14)%2.79(±0.69)%.
87.75%.
86.32(±2.50)% 5.37(±2.69)%87.65(±1.34)% 3.64(±1.21)%4.24(±0.78)%.
87.25%.
table 4: the selected single model centric can achievesimilar accuracy and negative ﬂip as ensemble..to further understand where the regression happensand how the above methods contribute to reducingregression, we conduct qualitative analysis acrossdiverse linguistic phenomena.
more precisely, weleverage the checklist (ribeiro et al., 2020)behavioral testing and construct regression setsfor relevant linguistic capabilities and tests basedon perturbations and provided templates.
forexample, to test the capability of dealing withlexical taxonomy in the paraphrase detection task,we replace adjectives in one sentence with theirsynonyms with the label unchanged and expect themodel can still predict correctly.
we manually setthe templates, apply checklist to automaticallygenerate testing sentence pairs, and calculatern f for each linguistic test.
detailed linguisticbehavioral testing setups with examples can befound in appendix c..table 5 shows the linguistic behavioral testingresults when updating from bertbase - 1 seedto bertlarge.
each row denotes one speciﬁcbehavioral test and 500 cases are sampled ineach test.
we focus on negative ﬂips where thenew model fails the test while the old modelpasses.
we can observe that the vanilla ﬁne-tuned bertlarge has signiﬁcant regressions onswitching with synonyms, asymmetric ordering,and active-passive swap related to people names(see appendix c).
also, we observe that modelstend to either fail or pass almost all cases in a test,which leads to high variances in rn f .
this impliesthat models ﬁne-tuned with different seeds can havedifferent behavioral patterns, which could be onesource of regression..furthermore, table 5 shows that the distillationcan effectively reduce regressions across almostall types of behavioral tests.
this demonstratesthat minimizing the surrogate regression measure,formulated as a knowledge distillation objective,reduces the regression through actually aligningnew model’s behavior with the old model..for the ensemble, although it can reduce signiﬁ-cant regressions in the benchmark, we observe thatit can only improve the model update compatibilityon a handful of capabilities.
we hypothesize thatthe ensemble mostly improves the compatibilitywith the underlying constituent models.
without anexplicit alignment, it cannot proactively reduce theregression on certain behavior tests when updating.
figure 3: 2d visualization by pca of old, new single,and new ensemble models based on dev set predictions..procedure.
we ﬁrst train 20 new single models,among which we compute for each model theaverage rn f on the ﬁrst half of dev set whenupdating from the other 19 models.
we then selectthe single model with the lowest average rn f asthe centric.
results in table 4 show the accuracyand rn f on the second half of the dev set.
indeedthe single centric model achieves substantialreduction in rn f comparable to model ensemble.
we further plot all the bertbase models basedon their class predictions down-projected by pca(hotelling, 1933).
figure 3 shows that singlemodels tend to spread while ensembles are moreconcentrated and close together.
we can alsosee that the centric indeed sits near the centerin essence, the centricof single model cluster.
model is a single model that requires much lesscompute resource than the ensemble model duringinference, yet can achieve comparable performanceand reductions in regression..6595432101232101234centriclabelold: bert basenew: bert basenew: bert ensembleground truthold: bertbase(error %).
new: bertlarge (rn f ).
1 seed.
1 seed kd 1 seed.
5 seeds.
kd 5 seeds.
centric.
ensemble.
coref - he/shevocab - peoplevocab - more/lesstaxonomy - synonymsrl - pharaphrasesrl - asymmetric ordersrl - active/passive 1srl - active/passive 2srl - active/passive 3temporal - before/afteraverage.
0.0%0.0%100.0%0.0%0.0%0.0%0.1%0.1%99.9%100.0%38.5%.
13.4%13.8%0.0%42.3%12.5%47.1%9.3%90.0%0.1%0.0%19.9%.
22.4%1.9%0.0%0.0%99.9%0.0%65.2%0.7%0.0%0.0%14.8%.
0.0.
0.0(±0.0)%.
0.0(±0.0)%12.3(±16.1)% 41.2(±47.0)%55.2(±50.8)%59.5(±34.8)% 34.1(±47.1)% 89.0%0.0(±0.0)%0.0(±0.0)%0.0%77.0(±26.2)% 20.3(±44.5)% 73.1%61.9(±54.1)%63.2(±43.4)% 42.0(±48.3)% 26.9% 61.9(±54.1))%58.6(±52.2)%70.7(±20.0)% 22.3(±43.7)% 92.0%42.4(±51.5)%58.0(±43.2)% 52.7(±50.1)% 98.5%65.2(±56.5)%95.5(±4.8)% 23.8(±43.3)% 99.6%0.1(±0.1)%0.1(±0.0)%0.1%0.0(±0.0)%0.0%0.0%33.3%43.8%38.2%.
0.0(±0.0)%0.0(±0.0)%20.3%.
table 5: behavioral tests with checklist.
second column shows the error rate of the old model.
remainingcolumns are rn f compared with the old model.
the columns with 1 seed represent the results with random seedequals to 0, while columns with 5 seeds represent 5 seed average.
the columns with kd are the models afterdistillation.
the columns with centric means the single selected with the method mentioned in section 5.1..from other distinct models..6 related work.
6.1 model update regression and solutions.
the backward compatibility representation learn-ing ﬁrst comes into sight in shen et al.
(2020)on learning inter-operabile visual embeddings forimage retrieval tasks.
later, yan et al.
(2020)formalize the model update regression problem inmachine learning and explore solutions on imageclassiﬁcation tasks.
they suggest negative ﬂip (nf)as the empirical measurement of regression andpropose a specialized knowledge distillation loss(hinton et al., 2015) as a surrogate of regressionfor joint optimizations.
our work investigatesthe model update regression in nlp classiﬁcationtasks, which involve discrete signals and richlinguistic structures.
we formulate our solutionsfrom the perspective of constraint satisfaction andverify their efﬁcacy on scenarios including updateto distinct architectures..6.2 transfer learning, lifelong learning.
and concept drifting.
pre-training a model on large corpora and ﬁne-tuning on downstream tasks has emerged as astandard paradigm in nlp (devlin et al., 2019; lanet al., 2020; conneau and lample, 2019; raffelet al., 2020; brown et al., 2020; clark et al., 2020).
our work follows this transfer learning paradigmbut our main focus is to investigate the regressionphenomenon when updating backbone pre-trainedmodels.
another related stream of research islifelong learning (lopez-paz and ranzato, 2017;.
yoon et al., 2018; delange et al., 2021; sunet al., 2019; chuang et al., 2020), incrementallearning (rebufﬁ et al., 2017; chaudhry et al.,2018; prabhu et al., 2020), or concept drifting(schlimmer and granger, 1986; tsymbal, 2004;klinkenberg, 2005; žliobait˙e i., 2016) which aimsto accumulate knowledge learned either in previoustasks or from data with changing distribution.
themodel update regression problem differs in thatmodels are trained on the same task and dataset,but we update from one model to another..6.3 behavioral testing of nlp models.
to analyze whether a ﬁne-tuned model can handlelinguistic phenomena for a speciﬁc end task,perturbation techniques are often used (belinkovand bisk, 2018; ribeiro et al., 2018; prabhakaranet al., 2019; wu et al., 2019; talmor et al.,2020).
in particular, checklist (ribeiro et al.,2020) leverages and expands those techniquesto efﬁciently evaluate a wide range of linguisticbehavioral capabilities of nlp models.
ourwork applies checklist to inspect where themodel update regressions come from and on whichlinguistic phenomena our proposed solutions helpto reduce regressions..7 conclusion.
in this work, we investigated the regression in nlpmodel updates on classiﬁcation tasks and show thatit has a prevalent presence across tasks and models.
we formulated the regression-free model updateproblem as a constrained optimization problem andreduce it into a joint learning objective on target.
6596task while distilling from the old model.
togetherwith the ensemble, these methods can cut downthe regression by 60% at best.
experiments on theglue benchmark showed that ensemble can beeffective in reducing the regression when updatingto homogeneous models.
on the other hand,knowledge distillation produced more signiﬁcantregression reductions under the heterogeneoussetting.
through linguistic behavioral testing weshowed that distillation can reduce the regressionacross a wider range of linguistic phenomena thanensemble method.
while the regression reductionachieved by the discussed methods are promising,they are far from reaching regression-free.
weleave the design of more advanced regression-reduction methods as future works..acknowledgments.
the authors would like to acknowledge the awsai team for inspiring discussions, honest feedback,and full support.
we are also very grateful tothe reviewers for insightful comments and helpfulsuggestions..references.
yonatan belinkov and yonatan bisk.
2018. syntheticand natural noise both break neural machine trans-in international conference on learninglation.
representations..luisa bentivogli, ido dagan, hoa trang dang, danilogiampiccolo, and bernardo magnini.
2009. theﬁfth pascal recognizing textual entailment challenge.
in proceedings of tac..tom brown, benjamin mann, nick ryder, melaniesubbiah,jared d kaplan, prafulla dhariwal,arvind neelakantan, pranav shyam, girish sastry,amanda askell, sandhini agarwal, ariel herbert-voss, gretchen krueger, tom henighan, rewonchild, aditya ramesh, daniel ziegler, jeffrey wu,clemens winter, chris hesse, mark chen, ericsigler, mateusz litwin, scott gray, benjamin chess,jack clark, christopher berner, sam mccandlish,alec radford, ilya sutskever, and dario amodei.
2020. language models are few-shot learners.
inadvances in neural information processing systems,volume 33, pages 1877–1901.
curran associates,inc..daniel cer, mona diab, eneko agirre, iñigo lopez-gazpio, and lucia specia.
2017. semeval-2017task 1: semantic textual similarity multilingual andin proceedingscrosslingual focused evaluation.
of the 11th international workshop on semanticevaluation (semeval-2017), pages 1–14..arslan chaudhry, puneet k dokania, thalaiyasingamajanthan, and philip hs torr.
2018. riemannianwalk for incremental learning: understanding for-in proceedings of thegetting and intransigence.
european conference on computer vision (eccv),pages 532–547..z. chen, h. zhang, x. zhang, and l. zhao.
2018..quora question pairs..yung-sung chuang, shang-yu su, and yun-nungchen.
2020. lifelong language knowledge distil-in proceedings of the 2020 conference onlation.
empirical methods in natural language processing(emnlp), pages 2914–2924, online.
associationfor computational linguistics..kevin clark, minh-thang luong, quoc v. le, andchristopher d. manning.
2020.electra: pre-training text encoders as discriminators rather thanin international conference on learn-generators.
ing representations..alexis conneau and guillaume lample.
2019.in ad-cross-lingual language model pretraining.
vances in neural information processing systems,volume 32. curran associates, inc..matthias delange, rahaf aljundi, marc masana, sarahparisot, xu jia, ales leonardis, greg slabaugh,and tinne tuytelaars.
2021. a continual learningsurvey: defying forgetting in classiﬁcation tasks.
ieee transactions on pattern analysis and machineintelligence, pages 1–1..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186..william b. dolan and chris brockett.
2005. automati-cally constructing a corpus of sentential paraphrases.
in proceedings of the third international workshopon paraphrasing (iwp2005)..geoffrey hinton, oriol vinyals, and jeffrey dean.
2015. distilling the knowledge in a neural network.
in nips deep learning and representation learn-ing workshop..harold hotelling.
1933..analysis of a complexof statistical variables into principal components.
journal of educational psychology, 24(6):417..gama j. žliobait˙e i., pechenizkiy m. 2016. chapterin stefanowski j. japkowicz n.,1 - introduction.
editor, an overview of concept drift applications.,volume 16 of big data analysis: new algorithmsfor a new society.
studies in big data.
springer..6597xiaoqi jiao, yichun yin, lifeng shang, xin jiang,xiao chen, linlin li, fang wang, and qun liu.
2020.tiny{bert}: distilling {bert} for naturallanguage understanding..ralf klinkenberg.
2005. meta-learning, model se-lection, and example selection in machine learningdomains with concept drift..zhenzhong lan, mingda chen, sebastian goodman,kevin gimpel, piyush sharma, and radu soricut.
2020. albert: a lite bert for self-supervised learningin international con-of language representations.
ference on learning representations..yinhan liu, myle ott, naman goyal, jingfei du,mandar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2020.roberta: a robustly optimized bert pretrainingapproach..david lopez-paz and marc’aurelio ranzato.
2017.gradient episodic memory for continual learning.
inadvances in neural information processing systems,pages 6467–6476..adam paszke, sam gross, francisco massa, adamlerer, james bradbury, gregory chanan, trevorkilleen, zeming lin, natalia gimelshein, lucaantiga, alban desmaison, andreas kopf, edwardyang, zachary devito, martin raison, alykhan te-jani, sasank chilamkurthy, benoit steiner, lu fang,junjie bai, and soumith chintala.
2019. pytorch:an imperative style, high-performance deep learn-in advances in neural informationing library.
processing systems 32, pages 8024–8035..vinodkumar prabhakaran, ben hutchinson, and mar-garet mitchell.
2019. perturbation sensitivity analy-sis to detect unintended model biases.
in proceed-ings of the 2019 conference on empirical methodsin natural language processing and the 9th in-ternational joint conference on natural languageprocessing (emnlp-ijcnlp), pages 5744–5749..ameya prabhu, philip hs torr, and puneet k dokania.
2020. gdumb: a simple approach that questionsin europeanour progress in continual learning.
conference on computer vision, pages 524–540.
springer..colin raffel, noam shazeer, adam roberts, katherinelee, sharan narang, michael matena, yanqi zhou,wei li, and peter j. liu.
2020. exploring thelimits of transfer learning with a uniﬁed text-to-journal of machine learningtext transformer.
research, 21(140):1–67..sylvestre-alvise rebufﬁ, alexander kolesnikov,georg sperl, and christoph h lampert.
2017. icarl:incremental classiﬁer and representation learning.
in proceedings of the ieee conference on computervision and pattern recognition, pages 2001–2010..marco tulio ribeiro, sameer singh, and carlosguestrin.
2018. semantically equivalent adversarialin proceedingsrules for debugging nlp models.
of the 56th annual meeting of the association forcomputational linguistics (volume 1: long papers),pages 856–865..marco tulio ribeiro, tongshuang wu, carlos guestrin,and sameer singh.
2020. beyond accuracy: be-havioral testing of nlp models with checklist.
in proceedings of the 58th annual meeting of theassociation for computational linguistics, pages4902–4912, online.
association for computationallinguistics..jeffrey c. schlimmer and richard h. granger.
1986.beyond incremental processing: tracking conceptin proceedings of the fifth aaai nationaldrift.
conference on artiﬁcialintelligence, aaai’86,page 502–507.
aaai press..yantao shen, yuanjun xiong, wei xia, and stefanosoatto.
2020. towards backward-compatible repre-sentation learning.
in proceedings of the ieee/cvfconference on computer vision and pattern recog-nition (cvpr)..richard socher, alex perelygin, jean wu, jasonchuang, christopher d. manning, andrew ng, andchristopher potts.
2013. recursive deep modelsfor semantic compositionality over a sentiment tree-in proceedings of the 2013 conference onbank.
empirical methods in natural language processing,pages 1631–1642..fan-keng sun, cheng-hao ho, and hung-yi lee.
2019.lamol: language modeling for lifelonglanguage learning.
in international conference onlearning representations..alon talmor, yanai elazar, yoav goldberg, andjonathan berant.
2020. olmpics-on what languagemodel pre-training captures.
transactions of theassociation for computational linguistics, 8:743–758..a. tsymbal.
2004. the problem of concept drift:.
deﬁnitions and related work..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, ł ukaszkaiser, and illia polosukhin.
2017. attention isin advances in neural informationall you need.
processing systems, volume 30, pages 5998–6008..alex wang, amanpreet singh, julian michael, felixhill, omer levy, and samuel bowman.
2018.glue: a multi-task benchmark and analysis plat-in pro-form for natural language understanding.
the 2018 emnlp workshop black-ceedings ofboxnlp: analyzing and interpreting neural net-works for nlp, pages 353–355..alex warstadt, amanpreet singh, and samuel r. bow-man.
2019. neural network acceptability judgments.
transactions of the association for computationallinguistics, 7:625–641..6598adina williams, nikita nangia, and samuel bow-man.
2018. a broad-coverage challenge corpusfor sentence understanding through inference.
inproceedings of the 2018 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long papers), pages 1112–1122..tongshuang wu, marco tulio ribeiro, jeffrey heer,and daniel s weld.
2019. errudite: scalable, repro-ducible, and testable error analysis.
in proceedingsof the 57th annual meeting of the association forcomputational linguistics, pages 747–763..sijie yan, yuanjun xiong, kaustav kundu, shuo yang,siqi deng, meng wang, wei xia, and stefanosoatto.
2020. positive-congruent training: towardsarxiv preprintregression-free model updates.
arxiv:2011.09161..jaehong yoon, eunho yang, jeongtae lee, and sung juhwang.
2018. lifelong learning with dynamicallyexpandable networks.
in international conferenceon learning representations..zhu zeyuan and yuanzhi li.
2020..towards un-derstanding ensemble, knowledge distillation andarxiv preprintself-distillation in deep learning.
arxiv:2012.09816..6599a full results of regression between.
sota model updates.
due to the page limitation, we present the fullregression update comparison between commonlyused pre-trained model pairs (devlin et al., 2019;liu et al., 2020; lan et al., 2020; clark et al., 2020)in table 6.we.
show regression in model updatesto the other common usedshow thealsotoand updating.
from bertbasepre-trained models;regression in updatesbertlarge−whole−word−maskingfrom robertabase to electrabase..wefrom bertlarge.
other than the universal presence of the regres-.
sion, table 6 shows that:.
1. the more difference.
in pre-trainingmethod,the higher regression can beobserved.
from the results of updatingexperiment group wefrom bertbasecan have this conclusion: the updatingfactors can increase regression in ascendinghyperparameters (to bertbase),order:pre-train settings(to robertabase), modelsize (to bertlarge), pre-train objection(to electrabase), modelstructure(toalbertbase).
2. similar updating factor results in simi-lar level of regression.
updating frombertlarge to bertlarge−wwm have sim-ilar regression level as in updating frombertbase to electrabase, both are updat-ing in the pre-training objective.
similarly,updating from robertabase to elec-trabase have similar regression as in updat-ing from bertbase to electrabase..b selection of regression set during.
training.
here, we explore the difference of regressing setselection during knowledge distillation..for the regression set used in the model training.
process, we propose several options:.
1. take the entire training set as our the regres-.
sion set in training dreg = dtrain.
2. training examples where the old model makes.
correct predictions dreg = dcorrect.
3. training examples where the old model getsa higher predict probability on the ground-truth class than the new model dreg =.
dbetter, equivalent to adjusting α dynamicallyaccording to the performance of the twomodels, we set α to zero when pφold(y|x) <pφnew (y|x).
4. extra data from other tasks dreg = dextra5. user-provided regression set, which includesexamples with high-stakes dreg = duserwe experiment with all options except for the user-provided regression set, see table 7..dynamically adapting the regression set accord-ing to the current performance of the new modelin distillation (rkl-div, dbetter) offers the mostreduction in the regression without sacriﬁcing theaccuracy.
we conjecture that it’s because we applythe soft regression-free constraint loss precisely onexamples where the new model’s performance isbehind..c linguistic behaviour test settings.
in the linguistic behaviour tests, we go througha variety range of linguistic aspects and designtest examples following checklist(ribeiro et al.,2020)..in table 8 we show the tests for linguisticbehaviour tests.
please ﬁnd the example test casesin the third column for each testing..d glue details.
the glue datasets are described as follows(jiaoet al., 2020):mnli.
multi-genre natural language inferenceis a large-scale, crowd-sourced entailment clas-siﬁcation task (williams et al., 2018).
givena pair of (cid:104)premise, hypothesis(cid:105), the goal is topredict whether the hypothesis is an entailment,contradiction, or neutral with respectto thepremise.
qqp.
quora question pairs is a collection ofquestion pairs from the website quora.
thetask is to determine whether two questions aresemantically equivalent (chen et al., 2018).
qnli.
question natural language inference isa version of the stanford question answeringdataset which has been converted to a binarysentence pair classiﬁcation task by wang et al.
(2018).
given a pair (cid:104)question, context(cid:105).
thetask is to determine whether the context containsthe answer to the question.
sst-2.
the stanford sentiment treebank is abinary single-sentence classiﬁcation task, where.
6600cola.
sst-2 mrpc.
qqp mnli-m mnli-mm qnli.
rte.
train sizedev size.
8.6k1k.
67k0.9k.
3.7k0.4k.
360k40k.
390k9.8k.
390k9.8k.
100k5.5k.
2.5k0.3k.
old: bertbase.
acc.
82.84% 92.20% 86.03% 90.76%.
83.82%.
84.13%.
91.07% 67.15%.
→bertbase.
→bertlarge.
→robertabase.
→electrabase.
→albertabase.
accrn f.accrn f.accrn f.accrn f.accrn f.83.80% 91.93% 86.03% 90.56%2.32%3.36%.
4.17%.
2.10%.
85.43% 93.23% 87.75% 91.11%2.82%3.16%.
1.95%.
5.88%.
84.85% 94.11% 89.22% 91.25%1.98%4.67%.
1.22%.
4.66%.
85.81% 95.41% 86.03% 91.35%3.20%5.18%.
1.38%.
5.39%.
76.51% 91.86% 86.27% 90.73%3.78%10.74% 3.67%.
6.86%.
83.55%3.56%.
86.10%3.95%.
87.58%2.64%.
88.87%3.50%.
85.26%5.22%.
83.94%3.67%.
86.49%3.69%.
87.74%2.38%.
88.67%3.57%.
85.14%5.24%.
90.65% 63.18%2.35% 11.43%.
92.53% 66.43%2.64% 12.27%.
92.71% 63.17%13.1%1.74%.
93.30% 72.92%7.58%2.65%.
91.67% 74.73%9.03%3.70%.
old: bertlarge.
acc.
85.43% 93.23% 87.75% 91.11%.
86.10%.
86.49%.
92.53% 66.43%.
→bertlarge−wwm.
accrn f.85.14% 94.15% 87.01% 91.52%3.03%5.05%.
1.60%.
7.82%.
86.75%5.08%.
87.24%4.67%.
93.34% 70.76%2.75% 15.22%.
old: robertabase.
acc.
84.85% 94.38% 87.25% 91.28%.
88.24%.
87.63%.
92.51% 70.76%.
→electrabase.
accrn f.85.81% 95.41% 86.03% 91.35%2.77%4.31%.
6.62%.
1.49%.
88.87%3.47%.
88.67%3.48%.
93.30% 72.92%7.58%2.62%.
table 6: accuracy and regression measures of different model update variants on glue benchmark.
bertlarge−wwm represents the whole-word-masking version..old: bertbase.
new:.
acc: 86.03%.
→bertbasern facc.
→bertlargern facc.
baseline.
86.03% 4.17% 87.75% 5.88%.
distillation(rkl-div, dtrain)distillation(rkl-div, dcorrect)distillation(rkl-div, dbetter)distillation(rl2, dbetter).
87.25% 2.94% 88.73% 3.68%87.01% 3.92% 88.48% 4.90%87.01% 1.72% 88.73% 2.45%85.29% 2.45% 88.73% 2.21%.
table 7: results on mrpc of our proposed techniques towards regression-free model updates.
the model isupdated frombertbase to bertbase, e.g.
change ﬁne-tune setups, or bertlarge.
d(·) denotes the regression setfor joint training with distillation and classiﬁcation..the goal is to predict the sentiment of moviereviews (socher et al., 2013).
cola.
the corpus of linguistic acceptability isa task to predict whether an english sentence is agrammatically correct one (warstadt et al., 2019).
sts-b.
the semantic textual similarity bench-mark is a collection of sentence pairs drawn fromnews headlines and many other domains (cer et al.,2017).
the task aims to evaluate how similar twopieces of texts are by a score from 1 to 5.mrpc.
microsoft research paraphrase corpus is.
a paraphrase identiﬁcation dataset where systemsaim to identify if two sentences are paraphrases ofeach other (dolan and brockett, 2005).
rte.
recognizing textual entailment is a binaryentailment task with a small training dataset (ben-tivogli et al., 2009)..6601category.
description.
example.
coref - he/she.
reverse he or she..vocab - people.
add modiﬁers that preserve sentencesemantics..wendy is friendly to kevin.
wendy is truely friendly to kevin..vocab - more/less.
swap more with less..taxonomy - synonym.
replace synonym..srl - pharaphrase.
somebody think → according to some-body..if charles and jessica were alone , do you think hewould reject her?
if charles and jessica were alone , do you think shewould reject him?.
i can become more passive.
i can become less passive..i can become more courageous.
i can become more brave..who do conservatives think is the happiest surgeonin the world ?
who is the happiest surgeon in the world accordingto conservatives ?.
srl - asymmetric order order does matter for asymmetric.
relations..srl - active/passive 1.traditional srl: active / passive swap.
shannon is proposing to samantha.
samantha is proposing to shannon..jeremy missed the game.
the game was missed by jeremy..srl - active/passive 2.traditional srl: active / passive swap.
christian remembers alyssa.
with people..alyssa is remembered by christian..srl - active/passive 3.traditional srl: wrong active / passiveswap..sara took the castle.
sara was taken by the castle..temporal - before/after.
before becoming somebody → afterbecoming somebody..what was noah myers ’s life before becoming anarchitect ?
what was noah myers ’s life after becoming anarchitect ?.
table 8: regression tests details with checklist..label.
false.
true.
true.
true.
true.
false.
true.
true.
false.
false.
6602