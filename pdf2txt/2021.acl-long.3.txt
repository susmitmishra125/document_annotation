engage the public: poll question generation for social media posts.
zexin lu1 keyang ding1 yuji zhang1 jing li1∗ baolin peng2 lemao liu31department of computing, the hong kong polytechnic university, hksar, china2microsoft research, redmond, wa 3tencent ai lab, shenzhen, china1{zexin.lu, keyang.ding, yu-ji.zhang}@connect.polyu.hk.
1jing-amelia.li@polyu.edu.hk.
2bapeng@microsoft.com.
3redmondliu@tencent.com.
abstract.
this paper presents a novel task to generatepoll questions for social media posts.
it offersan easy way to hear the voice from the pub-lic and learn from their feelings to importantsocial topics.
while most related work tack-les formally-written texts (e.g., exam papers),we generate poll questions for short and collo-quial social media messages exhibiting severedata sparsity.
to deal with that, we propose toencode user comments and discover latent top-ics therein as contexts.
they are then incorpo-rated into a sequence-to-sequence (s2s) archi-tecture for question generation and its exten-sion with dual decoders to additionally yieldpoll choices (answers).
for experiments, wecollect a large-scale chinese dataset from sinaweibo containing over 20k polls.
the resultsshow that our model outperforms the popu-lar s2s models without exploiting topics fromcomments and the dual decoder design can fur-ther beneﬁt the prediction of both questionsand answers.
human evaluations further ex-hibit our superiority in yielding high-qualitypolls helpful to draw user engagements..1.introduction.
social media is a crucial outlet for people to ex-change ideas, share viewpoints, and keep con-nected with the world.
it allows us to hear thepublic voice for decision making and better under-standing our society.
nevertheless, for the silentmajority, they tend to read others’ messages insteadof voicing their own opinions with words, possiblybecause of the introvert personality, busy schedule,and others.
how shall we better engage them intothe discussions and learn from their thoughts?.
in this work, we present a novel application toautomatically generate a poll question for a socialmedia post.
it will encourage public users, espe-cially those reluctant to comment with words, to.
[p1]: ...b站市值超过爱奇艺 (the market value of b siteexceeds iqiyi)...[q1]: 你们平时常用那个app看视频？ (which app doyou usually use to watch videos?)
[a1]: 腾讯视频 (tencent video); 优酷 (youku); 爱奇艺(iqiyi); b站 (b site)...理 性 分 析 一 下 赵 粤 和 希 林 娜 依 高 ： 希[p2]:林vocal确实厉害，但是...舞蹈实力有点不够看；赵粤呢舞蹈厉害...但是唱歌实力较弱些... (a rationalanalysis of akira and curley g: curley’s vocal is indeedgreat, but ... her dancing is not that good; akira danceswell ... but her singing is weaker...)[q2]: 谁更适合当c位？ (who should take the centerposition?)
[a2]: 赵粤 (akira); 希林娜依高 (curley g).
figure 1: example polls from sina weibo.
pi, qi, andai (i = 1, 2) refer to the i-th source post, its poll ques-tion, and the corresponding poll choices (answers).
dif-ferent choices are separated by the “;”.
italic words in“()” are the english translation of the original chinesetexts on their left.
in the source posts, we fold the wordsirrelevant to polls in “...” for easy reading..input their reﬂections via voting.
for example, thestatistics of our dataset show that 13k users onaverage engaged in a poll compared with 173 com-mented to a post.
for a better illustration of thetask, figure 1 shows two example poll questions onsina weibo1, henceforth weibo, a popular chinesemicroblog.
the goal of our task is to output anopinion question, such as q1 and q2, and inviteother users to engage in the discussion to a sourcepost (e.g., p1 and p2); poll choices (answers likea1 and a2) can be produced together to allow easypublic engagement (via voting)..to date, most progress made in question gener-ation is built upon the success of encoder-decoderframeworks (du et al., 2017).
despite of the ex-tensive efforts made in this line (sun et al., 2018;yao et al., 2018; chai and wan, 2020; sun et al.,2020), most previous work focus on the processingof formally-written texts, such as exam questions.
∗jing li is the corresponding author..1weibo.com.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages29–40august1–6,2021.©2021associationforcomputationallinguistics29in reading comprehension tests.
the existing meth-ods are therefore suboptimal to handle social medialanguages with short nature and informal styles,which might present challenges to make sense ofthe source posts and decide what to ask.
for ex-ample, from the limited words in p1, it is hard tocapture the meanings of “b站” (b site) and “爱奇艺” (iqiyi) as video apps, which is neverthelesscrucial to predict q1.
moreover, the question itself,being in social media fashion, is likely to containfresh words, such as “c位” (center position) in q2,which may further hinder the models’ capability topredict the poll questions in social media style..to tackle these challenges, we ﬁrst enrich theshort contexts of source posts with other users’comments; a neural topic model is employed todiscover topic words therein and help identify thekey points made in source posts.
it is based onthe assumption that the salient words in a sourcepost are likely to be echoed in its comments (wanget al., 2019b), potentially useful to learn the mapfrom posts to poll questions.
for example, thecore words in q1 — “app” and “视频” (video) —co-occur frequently in the comments with “b站”(b site) and “爱奇艺” (iqiyi), which may helpthe model to link their meanings together.
thetopic representations are then incorporated into asequence-to-sequence (s2s) architecture to decodepoll questions word by word.
furthermore, we ex-tend the basic s2s to a version with dual decodersto generate questions and answers in a multi-tasklearning setting and further exploit their correla-tions.
for example, modeling answers in a2 mighthelp indicate that p2 centers around “赵粤” (akira)and “希林娜依高” (curley g), two celebrities..to the best of our knowledge, this work is theﬁrst to study poll questions on social media, wheretheir interactions among answer choices, sourceposts, and reader users’ comments are comprehen-sively explored.
as a pilot study over social mediapolls, we also contribute the very ﬁrst dataset con-taining around 20k weibo polls associated withtheir source posts and user comments.2 we believeour dataset, being the ﬁrst of its kind, will largelybeneﬁt the research on social media polls and howthey help promote the public engagements..on our dataset, we ﬁrst compare the model per-formance on poll question generation in terms ofautomatic evaluation and human evaluation.
the.
2our dataset and code are publicly available in.
https://github.com/polyusmart/poll-question-generation.
automatic evaluation results show that the latenttopics learned from the ﬁrst few pieces of user com-ments is already helpful — they result in our mod-els’ signiﬁcantly better performance than the s2sbaselines and their trendy extensions proposed forother tasks.
for example, our full model achieves38.24 rouge-1 while s2s with roberta (liuet al., 2019) yields 34.08. human evaluation fur-ther demonstrates our models’ capability to gener-ate poll questions relevant to the source post, ﬂuentin language, and particularly engaging to draw userattentions for discussions.
we then quantify mod-els’ sensitivities to the length of varying sourceposts and poll questions, where the scores of ourmodel are consistently better.
next, we ﬁnd ourmodel exhibits an increasing trend in predictingpoll questions that will engage more comments inthe future, which suggests the potential helpfulnessof comments to indicate engaging questions.
atlast, the performance of dual decoder designs arediscussed and it is shown that joint prediction ofquestions and their answers can beneﬁt both tasks..2 study design.
2.1 task formulation.
our major input is a social media post (i.e., sourcepost) and the main output a poll question that con-tinue the senses of the source post and encouragepublic users to voice opinions.
for each question,possible answer choices (i.e., answers) may also beyielded as a side product to enable participants toeasily input their thoughts.
to enrich the contextsof source posts, their reply messages (i.e., usercomments) are also encoded as external features..2.2 data description.
here we describe the dataset we collect to empiri-cally study social media polls..data collection.
weibo allows users to createpolls, asking questions to the public and invitingothers to share their thoughts via voting.
it enablesthe construction of a dataset with user-generatedpolls.
at the beginning, we gathered around 100krandom weibo posts, whereas less than 0.1% ofthem contain polls.
the sparse distribution of pollspresents the challenge to scale up the dataset.
todeal with that, we looked in to the sampled pollsand draw two interesting points: ﬁrst, many pollscarry trendy hashtags (user-annotated topic labelslike #covid19) to draw user attentions; second, auser who once created a poll is likely to do it again..30post.
comment.
num len num len16.9.
54.0.
173.
20,252.qsans choicelen num len5.93.411.0.voternum13,004.table 1: statistics of our dataset.
num: number; num:average number per post.
len: average count of wordsper post; qs: question; ans: answer..inspired by these observations, we ﬁrst obtainedthe popular hashtags since nov 2019.3 then, wegathered the posts under the hashtag through theweibo search api, from which the ones contain-ing polls are picked out.4 next, we examined theauthors of these polls and access their posting his-tory to gather more polls they created from weibouser timeline api.5 afterwards, for each post, wecrawled its comments via the comment api.6 fi-nally, 20,252 polls were obtained from 1,860 users..data analysis.
the statistics of the dataset isdisplayed in table 1. as can be seen, commentsare shorter than posts, probably because users tendto put more efforts in crafting original posts thanreplying to others and hence comments may berelatively nosier than original posts; both questionsand answers are short, which follow the fashion ofuser-generated contents on social media..to further investigate the data sparsity in socialmedia contents, we sample some texts from ldcnews corpus (formally-written texts) (ahtaridiset al., 2012) — the samples contain the same tokennumber as our social media texts.
our corpus’svocabulary size and entropy are 24,884 and 7.46,while those for news corpus are 9,891 and 5.98.this suggests the sparsity of social media data..we also observe that each post exhibits morevoters than comments, implying that users mayprefer to voice opinions via voting, which is easierthan commenting with words.
we further analyzethe effects of polls on user engagements and drawan interesting ﬁnding.
for the same author, theirposts with polls exhibit 1.65, 22.2, and 1.80 timescomments, likes, and reposts on average comparedto posts without polls.7 this implies that addingpolls indeed help to draw user engagements to apost..3https://open.weibo.com/wiki/trends/en4https://open.weibo.com/wiki/c/2/.
search/statuses/limited.
5https://open.weibo.com/wiki/c/2/.
statuses/user_timeline_batch.
6https://open.weibo.com/wiki/2/.
comments/show.
polls for comparison..7for each author, we additionally sample 500 posts without.
(a) choice number statistics.
(b) topic categories.
figure 2: the left ﬁgure shows the count of polls overvarying choice number in their answers (x-axis: choicenumber; y-axis: vote count).
the right one displays thedistribution of the polls’ topic categories..for each poll, there are less than 4 answerchoices on average.
to further characterize that,figure 2(a) shows the count of polls over varyingnumbers of answer choices appearing in them andthe statistics suggest that most users are not willingto craft over 5 poll choices, which, interestingly,exhibit similar statistics in exam questions.
in ad-dition, we probe into what types of topics are morelikely to contain polls.
to that end, we examinedsource posts with hashtags and manually catego-rized the hashtags into 11 topics.
figure 2(b) showsthe poll distribution over topics.
most polls fall in“social events” category, which mostly concern pub-lic emergency and in our dataset tremendous postsfocus on the outbreak of covid-19.
there are alsoa large proportion of polls concern entertainmenttopics such as celebrities and tv shows, probablyinitiated for advertising purpose..3 poll question generation framework.
this section introduces our framework with twovariants: one based on a basic s2s (single decoder)and the other is its extension with dual decodersto predict poll questions and answer choices in amultitask learning setting.
the model architectureof the dual decoder model is shown in figure 3..3.1 source posts and comments encoding.
following the common practice in s2s (du et al.,2017), we encode a source post p in the form ofword sequence (cid:104)w1, w2, ..., w|p |(cid:105), where |p | is thenumber of words in the post.
for user comments c,bag of words (bow) representations are employedfor topic modeling, henceforth cbow over bowvocabulary.
more details are provided below..source post encoding.
to encode the post se-quence p , a bidirectional gated recurrent unit (bi-gru) (cho et al., 2014) is adopted.
for the i-thword wi ∈ p , we ﬁrst convert it into an embed-ding vector νi, which is later processed into hidden.
31at last, the decoder reconstructs comments andproduces a bow vector c(cid:48)bow (conditioned on thelatent topic θ) through another neural perception..3.2 poll decoding.
here we further describe how we generate ques-tions (and answers in the dual decoders settings)with the encoded source posts and comments..question generation.
to handle the output of aquestion q, the corresponding decoder (i.e., ques-tion decoder) is formed with a uni-directionalgru and fed with the memory bank m fromsource post encoding and the topic distribution θfrom user comment modeling.
the words in q arepredicted sequentially with the following formula:.
p r(q | p, cbow) =.
p r (qj | q<j, m, θ).
(1).
|q|(cid:89).
j=1.
where qj means the j-th word in q and q<j refersto q’s predicted word sequence from slot 1 to j − 1.to leverage comment modeling results in the de-coding, we incorporate θ into the attention weights(deﬁned below) over source posts and concentrateon topic words therein for question generation..αij =.
exp (fα (hi, sj, θ))i(cid:48)=1 exp (fα (hi(cid:48) , sj, θ)).
(cid:80)|p |.
(2).
sj is the gru decoder’s j-th hidden states and:.
fα (hi, sj, θ) = vt.α tanh (wα [hi; sj; θ] + bα).
(3).
in addition, we adopt copy mechanism (seeet al., 2017) to allow the generated questions tocontain the keywords from the source posts:.
pj = λj · pgen + (1 − λj) · pcopy.
(4).
pgen refers to the likelihood to generate a wordwhile pcopy is the extractive distribution derivedfrom the attention weights over the source in-put.
the soft switcher λj ∈ [0, 1] can determinewhether to copy a word or generate a new one inaware of the comments’ topics:.
λj = sigmoid (wλ [uj; sj; tj; θ] + bλ).
(5).
tj is the context vector (weighted sum) of the atten-tion to predict the q’s j-th word, whose embeddingis uj.
wλ and bλ are both learnable parameters..figure 3: the architecture of the dual decoder s2s(sequence-to-sequence) model to jointly generate ques-tions and answers.
it contains a neural topic model forcontext modeling (in the bottom), a sequence encoderfed with the source post (in the center), and two se-quence decoders to handle the output, where the leftone predicts questions (q) and the right answers (a)..−→hi) and backward (.
←−hi) direc-states in the forward (tions, respectively.
they are then concatenated as←−hi = [hi] and sequentially put into a memorybank m = (cid:104)h1, h1, ..., h|p |(cid:105), which will be furtherdelivered to decoders for their attentive retrieval..−→hi;.
user comments modeling.
considering thenoisy nature of user comments, latent topics areemployed to recognize the salient contents therein.
they are explored based on word statistics and rep-resented as clusters of words tending to co-occur inthe comments of some posts (probably concerningsimilar topics), such as the names of video appsin figure 1. in topic modeling, we assume thereare k topics and each topic k is represented with atopic-word distribution over the bow vocabulary.
a post p has a topic mixture θ, which is learnedfrom the words appearing in its comments cbow..our topic learning methods (from comments) areinspired by the neural topic model (ntm) based onvariational auto-encoder (vae) (miao et al., 2017;zeng et al., 2018), which allows the end-to-endtraining of ntm with other modules in an uniﬁedneural architecture.
it employs an encoder and adecoder to resemble the data reconstruction processof the comment words in bow..concretely, the input cbow is ﬁrst encoded intoprior parameters µ and σ using neural perceptrons.
then, through gaussian transformation, they areapplied to draw a latent variable: z = n (µ, σ2),which is further taken to produce the topic composi-tion of comments (θ) with softmax transformation..32answer generation.
to further explore the re-lations between questions (q) and answers (a),we “replicate” the question decoder’s architectureand form another decoder to handle answer gen-eration (answer decoder).
the answer choicesare concatenated to form an answer sequence andneighboring choices are separated with a special to-ken “<sep>”.
the answer decoder also adopts thesame topic-aware attentions (eq.
2) as the questiondecoder (denoted as βij here) and copy mecha-nisms (eq.
4) to be able to put topic words fromthe source into the answer choices, such as “赵粤”(akira) and “希林娜依高” (curley g) in figure 1.question decoder and answer decoder work to-gether in a dual decoders setting, whose parametersare updated simultaneously to exploit the essentialcorrelations of poll questions and their answers..3.3 model training.
this subsection describes how we jointly train theneural topic model (henceforth ntm) for commentmodeling and the decoders for question and an-swer generation with multi-task learning.
the lossfunction for ntm is deﬁned as:.
ln t m = dkl(p(z) || q(z | c)) − eq(z|c)[p(c|z)].
(6).
the c above refers to cbow.
the ﬁrst term is thekl divergence loss and the second is the recon-struction loss in vae.
for question generation, theloss is:.
lqg = −.
log (p r (qn | pn, θn)).
(7).
n(cid:88).
n=1.
n is the number of training samples; qn, pn, andθn are the target poll question, source post, andtopic distribution of the n-th training sample.
an-swer generation loss lag is deﬁned similarly.
thetraining loss of the entire model are deﬁned as:.
l = ln t m + γq · lqg + γa · lag.
(8).
where γq and γa balance the weights over ntmand the two decoders..4 experimental setup.
data preprocessing.
first, we removed metadata (e.g., author’s locations and emoji labels) andreplaced links, mentions (@username), and digitswith generic tags “url”, “ment”, and “digit”..then, for some poll questions echoed in the sourceposts, we took them away for fair experiments.
next, an open-source toolkit jieba is employedfor chinese word segmentation.8 afterwards, weﬁltered out stop words and for the remaining, wemaintained two vocabularies with the most frequent50k words for sequences (input and output) andanother 100k words for bow.
finally, commentsare capped at the ﬁrst 100 words to examine pollquestion generation with the early comments andtheir potential to draw future user engagements..in evaluations, we split our data into 80% for.
training, 10% for validation and 10% for test..baselines and comparisons.
for baselines, weﬁrst consider the basic s2s (sutskever et al., 2014)(i.e., base); also compared are the s2s with pre-trained models from the bert family — tiny er-ine (sun et al., 2019) (i.e., erine), bert (de-vlin et al., 2019) (i.e., bert), and roberta (liuet al., 2019) (i.e., roberta), which were imple-mented with the paddle hub platform9.
for all s2swith pre-trained models, their pre-trained parame-ters were further ﬁne-tuned on our training data..then, we consider the following s2s exten-sions with copy mechanism (i.e., copy) (menget al., 2017),topic modeling from posts (i.e.,(wang et al., 2019a), and bidirec-topic)tional attentions over posts and comments (i.e.,cmt (biatt)) (wang et al., 2019b).
all of themwere proposed for keyphrase generation tasks andset up following their original papers..for our models, we consider two variants —cmt (ntm) in the single decoder archetectureand its dual decoder version dual dec.10.
model settings.
all the hyperparameters aretuned on the validation set via grid search.
forntm, it is pre-trained for 50 epochs before jointtraining and afterwards different modules take turnsto update parameters.
we adopt two-layers bidi-rectional gru to build source post encoder andone-layer unidirectional gru question and answerdecoders.
the hidden size of each gru is 300..8https://github.com/fxsjy/jieba9https://www.paddlepaddle.org.cn/hub10we also ﬁnetuned bert with our models yet cannot ob-serve much performance gain.
it is because ntm is able tolearn essential features from the input and bert cannot pro-vide additional beneﬁts.
another possible reason is that socialmedia bert is unavailable in chinese and that trained onout-domain data (e.g., news) might not ﬁt well with weibolanguages.
large-scale weibo data might be acquired for con-tinue pre-training (gururangan et al., 2020), which is beyondthe scope of this paper and will be explored in future work..33for a word embedding, the size is set to 150 andrandomly initialized.
in training, we apply adamoptimizer with initial learning rate as 1e-3, gra-dient clipping as 1.0, and early-stopping strategyadopted.
the weights to trade off losses in multi-task learning is set to γq = γa = 1 (eq.
8)..evaluation metrics.
we adopt both automaticmeasures and human ratings for evaluations.
forthe former, we examine two popular metrics forlanguage generation tasks — rouge (lin, 2004)and bleu (papineni et al., 2002).
for the latter, hu-man annotators rates with 4 point likert scale (i.e.,{0, 1, 2, 3}) and over three criteria are considered:the relevance to the source posts (relevance), howﬂuent the generated language reads (ﬂuency), theattractiveness degree of the questions in drawingpeople’s engagements (engagingness)..5 experimental results.
in this section, we ﬁrst show the main compari-son results on poll question generation involvingboth automatic evaluations and human ratings (in§5.1).
then, model sensitivity to varying lengthsof source posts and poll questions are discussedin §5.2, followed by the analyses of models’ capa-bility to handle poll questions exhibiting varyingdegrees of user engagements (§5.3).
next, §5.4discusses the performance of dual decoders thatjointly generate questions and answers.
a casestudy is presented at last (in §5.5) to interpret thesample outputs..5.1 comparison on poll question generation.
we ﬁrst show the comparison results on poll ques-tion generation, where we will discuss automaticevaluations and human ratings in turn below..automatic evaluations.
table 2 reports the au-tomatic measured results on question generation.
as can be seen, our task is challenging and basics2s performs poorly.
pre-trained models from thebert family can offer some help though limited.
it is probably because the pre-training data is fromother domains (e.g., news and online encyclope-dia), where the representations learned cannot fullyreﬂect the styles of social media languages..we then observe copy mechanism and latent top-ics (learn from posts) are both useful, where theformer allows the keyword extracted from the postto form a question while the latter further helpsﬁnd topic words to be copied.
on the contrary, user.
models2s baselinesbase+ernie+bert+robertas2s extensions+copy+topic+cmt (biatt)our models+cmt (ntm)+dual dec.rouge-1 rouge-l.bleu-1 bleu-3.
21.62±0.729.62±0.533.62±1.234.08±1.3.
20.64±0.727.82±0.431.57±1.131.98±1.2.
20.35±0.721.66±0.524.43±0.724.88±1.0.
2.11±0.53.25±0.44.54±0.44.85±0.5.
35.13±0.436.65±0.627.74±0.4.
33.20±0.434.70±0.626.21±0.4.
30.27±0.431.11±0.523.97±0.3.
7.95±0.38.66±0.54.15±0.2.
37.95±0.438.24±0.3.
35.97±0.336.14±0.3.
32.07±0.232.27±0.4.
8.89±0.39.04±0.3.
table 2: main comparison results for poll question gen-eration.
the underlined scores are the best in each col-umn.
average scores are before ± and the numbersafter are the standard deviation over 5 runs initializedwith different seeds.
our models cmt (ntm) anddual dec signiﬁcantly outperforms all the other com-parison models (paired t-test; p-value < 0.05)..comments, though able to provide useful informa-tion, are noisy (also implied by table 1).
so, itis important to encode the comments in an appro-priate way — cmt (ntm) captures salient topicfeatures from the comments and performs muchbetter than cmt (biatt), which might be hinderedby the noise and exhibit the second worst results..in addition, we notice dual dec slightly out-performs its single decoder variant cmt(ntm),though the gain is small.
to better examine theirprediction results, we conduct human evaluations..human ratings.
here we sampled 400 sourceposts (and their outputs), and invited four nativechinese speakers to rate the poll questions in a 4point likert scale — 0 for extremely bad, 1 for bad,2 for good, and 3 for extremely good — withoutknowing where the results come from.
each anno-tator reviews 100 samples and one’s assignmentsvary with others’ and table 3 shows the averageratings over the four annotators..all the models are rated worse than the goldstandard, which means automatic poll questiongeneration still has a long way to go.
we alsoobserve that models with latent topics exhibit rela-tively better relevance.
this may be because topicmodels allow the capture of salient contents fromthe input and detail injection to the output.
be-sides, cmt (ntm) and dual dec perform thebest in engagingness, probably because user com-ments and poll answers might provide implicitclues (e.g., fresh words) helpful to predict engag-ing questions.
for ﬂuency, base outperforms ourmodels by a small margin, as it tends to yield shortand generic questions, such as “你怎么看” (what’syour viewpoint?)
based on our observation.
more-.
34gold standardbaserobertatopiccmt (ntm)dual dec.relevance2.791.261.331.811.912.02.fluency2.842.141.061.661.671.87.engagingness2.741.350.961.501.551.67.table 3: average human ratings.
higher scores indi-cate better results.
dual dec exhibits good potentialgenerate questions likely to draw user engagements..over, we measure the length of questions generatedby base and dual (our full model) and ﬁnd that11.0% questions generated by base contain lessthan 5 words whereas the number for dual isonly 1.6%.
this again demonstrates our potentialto generate longer questions with richer details..5.2 effects of post and question length.
we further quantify the question generation re-sults over varying lengths of source posts and pollquestions and show the corresponding rouge-1scores in figure 4. here, we compare base androberta, topic, and our cmt (ntm).11.figure 4: rouge-1 scores (y-axis) over varyinglength (word count in x-axis) of source posts (on theleft) and poll questions (on the right).
for both subﬁg-ures, the bars from the left to right shows the results ofbase, roberta, topic, and cmt (ntm)..post length seems not to affect much on the mod-els’ performance, probably attributed to the lengthlimitation in weibo — even the relatively longerposts contain limited words.
on the contrary, forthe question length, the two s2s baselines both ex-hibit obvious performance drops when generatinglong questions, while topic and cmt (ntm)perform steadily.
this suggests that latent topics,either captured from posts or comments, may havethe potential to enrich questions with detailed de-scriptions, and hence can better tackle long ques-tions.
nevertheless, cmt (ntm) presents consis-tently better rouge-1 in diverse scenarios..11in §5.2 and §5.3, we experiment in the single decodersettings so as to focus on the quality of generated questions.
we will further discuss the dual decoders in §5.4..5.3 polls questions vs. user engagements.
as shown in the human ratings (§5.1), commentsmight help to generate engaging poll questions.
fora further discussion, figure 5 shows the rouge-1of roberta, topic, and cmt (ntm) in han-dling questions for polls that later engage vary-ing user comment numbers.
interestingly, cmt(ntm) performs better when predicting questionsthat engage more comments at the end.
this meansthat early comments might provide useful clues formodels to distinguish attractive questions with thepotential to draw more public engagements in thefuture.
lacking the ability to learn from comments,topic exhibits relatively more stable trends..figure 5: model performance in handling polls thatin varying comment numbers (x-axis).
y-resultaxis: rouge-1.
bars from left to right representroberta, topic, and cmt (ntm)..5.4 discussion on dual decoders.
the previous two subsections are discussed in thesingle decoder setting and here we further examinethe effectiveness to jointly predict questions andanswers.
base, copy, topic, and cmt (ntm)with single and dual decoders are discussed..we ﬁrst compare question generation results andfigure 6 shows the rouge-1 scores.
it is seenthat dual decoders can boost the results of baseand copy, implying that questions and answersare indeed related and exploiting their interactionscan successfully bring performance gain.
however,we cannot observe large-margin improvements intopic and cmt (ntm), probably because manywords in answers, such as “赵粤” (akira) and “希林娜依高” (curley g) in figure 1, are also topicwords that can be discovered with topic models.
therefore, jointly generating answers only provideslimited help to their question generation results..then, we analyze how the multitask learningability of dual decoders inﬂuence the predictionof poll answers.
table 4 displays the comparisonresults with pipeline models that sequentially gener-ate questions and then answers.
by examining thepipeline results, we ﬁrst ﬁnd that source posts are.
35amine the output of varying models in table 5.12unsurprisingly, base tends to yield generic ques-tions as limited features are encoded from the noisysource.
roberta sometimes produces repeatedwords (e.g., its output to p1), hindering its capabil-ity to generate ﬂuent language (also indicated bytable 3).
this is possibly caused by the overﬁttingproblem as roberta might rely on large-scalein-domain data for ﬁne-tuning..we also ﬁnd that modeling topics and user com-ments may enable the output to contain trendywordings, making it more engaging, such as “c位”(center point) in cmt (ntm)’s output questionfor p2 and the names of many new video appsin dual dec’s generated answer choices for p1.
furthermore, the dual decoders might learn the co-hesive relations between questions and answers,such as the akira and curley g occurring in boththe generated questions and answer choices (p2)..6 related work.
our work is in the line with question generation,where most prior efforts focus on how to ask goodexam questions given an article and the pre-deﬁnedanswers.
some adopt manually-crafted rules orfeatures (labutov et al., 2015; dhole and manning,2020; fabbri et al., 2020), largely relying on thelabor-intensive process for rule design or featureengineering.
to simplify the training, automaticfeature learning hence becomes popular.
for ex-ample, chali and hasan (2015) ﬁrst employs abayesian model to learn topic features and thenleverages them to yield questions.
these pipelinemethods require the expertise involvement to man-ually customize the model inference algorithms,while our neural network design allows end-to-endtraining of topic modeling and question generation.
recently, s2s-based question generation archi-tecture has demonstrated promising results (duet al., 2017; chai and wan, 2020).
to better en-code the input, researchers adopt successful train-ing design from other tasks, such as self-attentionmechanism (zhao et al., 2018; scialom et al., 2019),language model pre-training (pan et al., 2019), vari-ational inference (yao et al., 2018), and reinforce-ment learning (yuan et al., 2017; pan et al., 2019).
heuristic features, e.g., the answers’ positions inthe article (zhou et al., 2017; sun et al., 2018;.
figure 6: rouge-1 scores of base, copy, topic,and cmt (ntm) from left to right.
for each model,left bars (in blue) shows them in single decoder settingwhile the right bars (in orange) dual decoders..modelpipeline modelsqs only (pred)qs only (gold)pt+qs (pred)pt+qs (gold)dual decodersbase+copy+topic+cmt (ntm).
rouge-1 rouge-l bleu-1 bleu-3.
26.65±0.225.51±0.531.29±0.631.78±0.6.
24.68±0.730.03±0.530.56±0.831.72±0.7.
25.09±0.224.17±0.429.18±0.529.63±0.6.
22.59±0.528.02±0.528.49±0.829.54±0.7.
22.50±0.822.43±0.326.35±0.126.39±0.6.
21.38±0.325.55±0.526.00±0.526.55±0.2.
4.27±0.53.76±0.38.15±0.38.14±0.3.
3.22±0.48.28±0.38.26±0.48.65±0.2.
table 4: the comparison results of models with dualdecoders (on the bottom half) and pipeline models (onthe top).
for the pipeline models, we ﬁrst produce ques-tions (qs) using cmt (ntm), from which we furthergenerate answers with the s2s model.
qs only is fedwith qs only while pt+qs the concatenated sequenceof posts (pt) and qs.
in the training of answer genera-tion, pred means the predicted questions are employedas input while for gold, we adopt gold standard ques-tions (they are assumed to be unavailable for test)..helpful in answer generation, which results in theoutperformance of pt+qs over qs only.
besides,answer generation trained with predicted questionsor the gold standards do not make much differ-ence.
gold standard questions might exhibit higherquality while predicted questions may better ﬁt thetests (answer choices should be predicted withoutknowing the human-crafted questions)..for dual decoders, cmt (ntm) still performsthe best, implying that latent topics from user com-ments can also contribute to better prediction ofpoll answers.
in comparison with the best pipelinemodel (pt+qs), the scores from cmt (ntm) arecompetitive, though the dual decoder allows end-to-end training and is easier to be used (with lessmanual efforts in model training and application)..5.5 case study.
to provide more insights, we further take the twoweibo posts in figure 1 as the input cases and ex-.
12here we analyze the case with two examples while similarobservations can be drawn from many output cases.
morecases will be discussed in figure 6 (in the appendix)..36cmt (ntm) 你平时在哪个视频网站 (which video.
baseroberta.
topic.
dual dec.base.
roberta.
topic.
你会看吗 (would you watch)你 平 时 喜 欢 哪 个 视 频 频 频 (whichvideooooo do you usually like)你平时常用哪个视频 (which video doyou usually use).
site are you on)你平时用哪个视频 app (which videoapp do you usually use)>bili 哔哩 (bilibili); 爱奇艺 (iqiyi); 腾讯视频 (tencent video); 芒果tv (mangotv); 优酷 (youku); 其他评论区补充(comment with other choices)你觉得谁的表现更强 (who do youthink is better)你觉得谁更好 (who do you think isbetter)你觉得谁出道了 (who do you thinkdebuted).
cmt (ntm) 你觉得谁更适合c位 (who do you thinkis more suitable for the center position)你 觉 得 赵 粤 和 希 林 娜 依 高 谁 更 可(who do you prefer, akira or curley g)>赵粤 (akira); 希林娜依高 (curley g).
dual dec.table 5: questions generated for the source posts infigure 1: p1 (top) and p2 (bottom).
for dual dec(i.e., cmt (ntm) with dual decoders), the question isfollowed by the answer in the next row..kim et al., 2019; liu, 2020) are sometimes con-sidered.
for question decoding, certain constraintsare added to control the generation, such as someaspects to be contained (hu et al., 2018), varyinglevels of difﬁculty (gao et al., 2018) and speci-ﬁcity (cao et al., 2019)..we are also related with previous work handlingthe generation of questions and answers in a multi-task learning setting (wang et al., 2017; tang et al.,2017; sun et al., 2020).
nonetheless, none of theaforementioned research concerns poll questionsand answers on social media, which exhibit verydifferent language styles compared with any exist-ing studies and has not been extensively explored..7 conclusion.
we have presented a novel task to generate socialmedia poll questions.
user comments encoded witha neural topic model are leveraged in a s2s frame-work; dual decoder architecture is further adoptedto explore the interactions between questions andanswers.
extensive experiments on a large-scaledataset newly collected from weibo have demon-strated the effectiveness of our proposed model..acknowledgments.
rhino-bird young faculty open research fund(r-zdcj).
the research is also supported by nsfcyoung scientists fund (62006203) and polyu inter-nal funds (1-be2w, 4-zzkm, and 1-zvrh).
theauthors would like to thank lida li, yue wang,yubo zhang, zhe wang, and anonymous review-ers from acl-ijcnlp 2021 for their insightfulsuggestions on various aspects of this work..ethical considerations.
the task will not pose ethical problems.
first, thepolls are open access to the public users (so asto collect their opinions).
second, weibo allowsany users to report suspicious cases with ethicalconcerns and the reported contents will be removedimmediately.
third, the polls are running in ananonymous way to protect the privacy of voters..the dataset is collected through the ofﬁcial apisof weibo and is consistent with the weibo termsof use.
we also manually examined the data toensure the following points.
first, we conduct dataanonymization and manually examined the data toensure there are no privacy and ethical concerns,e.g., personal information, toxic language, and hatespeech.
in the generated polls, we didn’t spot anycases that might have the concern.
second, theinvolved weibo users are all public ones.
to thatend, we automatically ﬁltered out personal userswithout the ofﬁcial conﬁrmation of weibo (the con-ﬁrmed public users can be identiﬁed with a “vip”tag).
the user list is manually checked again tomitigate the ethical concern..for the annotation, we recruited part-time re-search assistants to work with the pay 15.7usd/hour and at most 20 hours per week..references.
eleftheria ahtaridis, christopher cieri, and denisedipersio.
2012. ldc language resource database:in proceedingsbuilding a bibliographic database.
of the eighth international conference on languageresources and evaluation, lrec 2012, istanbul,turkey, may 23-25, 2012, pages 1723–1728.
euro-pean language resources association (elra)..yang trista cao, sudha rao, and hal daum´e iii.
2019.controlling the speciﬁcity of clariﬁcation questiongeneration.
in proceedings of the 2019 workshop onwidening nlp@acl 2019, florence, italy, july 28,2019, pages 53–56.
association for computationallinguistics..this work was partially done when zexin lu wasan intern at tencent ai lab under ccf-tencent.
zi chai and xiaojun wan.
2020. learning to ask more:semi-autoregressive sequential question generation.
37under dual-graph interaction.
in proceedings of the58th annual meeting of the association for com-putational linguistics, acl 2020, online, july 5-10, 2020, pages 225–237.
association for compu-tational linguistics..inadapt language models to domains and tasks.
thethe 58th annual meeting ofproceedings ofassociation for computational linguistics, acl2020, online, july 5-10, 2020, pages 8342–8360.
association for computational linguistics..yllias chali and sadid a. hasan.
2015. towardstopic-to-question generation.
comput.
linguistics,41(1):1–20..kyunghyun cho, bart van merrienboer, c¸ aglarg¨ulc¸ehre, dzmitry bahdanau, fethi bougares, hol-ger schwenk, and yoshua bengio.
2014. learningphrase representations using rnn encoder-decoderfor statistical machine translation.
in proceedings ofthe 2014 conference on empirical methods in nat-ural language processing, emnlp 2014, october25-29, 2014, doha, qatar, a meeting of sigdat, aspecial interest group of the acl, pages 1724–1734.
acl..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, naacl-hlt 2019, minneapolis, mn,usa, june 2-7, 2019, volume 1 (long and short pa-pers), pages 4171–4186.
association for computa-tional linguistics..kaustubh d. dhole and christopher d. manning.
2020.syn-qg: syntactic and shallow semantic rules forquestion generation.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, acl 2020, online, july 5-10, 2020,pages 752–765.
association for computational lin-guistics..xinya du, junru shao, and claire cardie.
2017. learn-ing to ask: neural question generation for readingcomprehension.
in proceedings of the 55th annualmeeting of the association for computational lin-guistics, acl 2017, vancouver, canada, july 30 -august 4, volume 1: long papers, pages 1342–1352.
association for computational linguistics..alexander r. fabbri, patrick ng, zhiguo wang,ramesh nallapati, and bing xiang.
2020. template-based question generation from retrieved sentencesfor improved unsupervised question answering.
inproceedings of the 58th annual meeting of the as-sociation for computational linguistics, acl 2020,online, july 5-10, 2020, pages 4508–4513.
associa-tion for computational linguistics..yifan gao, jianan wang, lidong bing, irwin king, andmichael r. lyu.
2018. difﬁculty controllable ques-tion generation for reading comprehension.
corr,abs/1807.03586..suchin gururangan, ana marasovic,.
swabhaswayamdipta, kyle lo, iz beltagy, doug downey,and noah a. smith.
2020. don’t stop pretraining:.
wenpeng hu, bing liu, jinwen ma, dongyan zhao,and rui yan.
2018. aspect-based question gener-in 6th international conference on learn-ation.
ing representations, iclr 2018, vancouver, bc,canada, april 30 - may 3, 2018, workshop trackproceedings.
openreview.net..yanghoon kim, hwanhee lee, joongbo shin, and ky-omin jung.
2019. improving neural question gener-ation using answer separation.
in the thirty-thirdaaai conference on artiﬁcial intelligence, aaai2019, the thirty-first innovative applications ofartiﬁcial intelligence conference, iaai 2019, theninth aaai symposium on educational advancesin artiﬁcial intelligence, eaai 2019, honolulu,hawaii, usa, january 27 - february 1, 2019, pages6602–6609.
aaai press..igor labutov, sumit basu, and lucy vanderwende.
2015. deep questions without deep understanding.
in proceedings of the 53rd annual meeting of theassociation for computational linguistics and the7th international joint conference on natural lan-guage processing of the asian federation of naturallanguage processing, acl 2015, july 26-31, 2015,beijing, china, volume 1: long papers, pages 889–898. the association for computer linguistics..chin-yew lin.
2004. rouge: a package for auto-matic evaluation of summaries.
in text summariza-tion branches out, pages 74–81, barcelona, spain.
association for computational linguistics..bingran liu.
2020. neural question generation basedin proceedings of the 2020 5th inter-on seq2seq.
national conference on mathematics and artiﬁcialintelligence, pages 119–123..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
arxiv preprint, abs/1907.11692..rui meng, sanqiang zhao, shuguang han, daqinghe, peter brusilovsky, and yu chi.
2017. deepin proceedings of the 55thkeyphrase generation.
annual meeting of the association for computa-tional linguistics, acl 2017, vancouver, canada,july 30 - august 4, volume 1: long papers, pages582–592.
association for computational linguis-tics..yishu miao, edward grefenstette, and phil blunsom.
2017. discovering discrete latent topics with neuralvariational inference.
in proceedings of the 34th in-ternational conference on machine learning, icml2017, sydney, nsw, australia, 6-11 august 2017,volume 70 of proceedings of machine learning re-search, pages 2410–2419.
pmlr..38boyuan pan, hao li, ziyu yao, deng cai, and huansun.
2019. reinforced dynamic reasoning for con-versational question generation.
in proceedings ofthe 57th conference of the association for compu-tational linguistics, acl 2019, florence, italy, july28- august 2, 2019, volume 1: long papers, pages2114–2124.
association for computational linguis-tics..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2002. bleu: a method for automatic eval-uation of machine translation.
in proceedings of the40th annual meeting of the association for compu-tational linguistics, july 6-12, 2002, philadelphia,pa, usa, pages 311–318.
acl..thomas scialom, benjamin piwowarski, and jacopostaiano.
2019.self-attention architectures foranswer-agnostic neural question generation.
in pro-ceedings of the 57th conference of the associationfor computational linguistics, acl 2019, florence,italy, july 28- august 2, 2019, volume 1: long pa-pers, pages 6027–6032.
association for computa-tional linguistics..abigail see, peter j. liu, and christopher d. manning.
2017. get to the point: summarization with pointer-generator networks.
in proceedings of the 55th an-nual meeting of the association for computationallinguistics, acl 2017, vancouver, canada, july 30 -august 4, volume 1: long papers, pages 1073–1083.
association for computational linguistics..xingwu sun, jing liu, yajuan lyu, wei he, yanjunma, and shi wang.
2018. answer-focused andin pro-position-aware neural question generation.
ceedings of the 2018 conference on empirical meth-ods in natural language processing, brussels, bel-gium, october 31 - november 4, 2018, pages 3930–3939. association for computational linguistics..yibo sun, duyu tang, nan duan, tao qin, shujieliu, zhao yan, ming zhou, yuanhua lv, wen-peng yin, xiaocheng feng, bing qin, and ting liu.
2020. joint learning of question answering and ques-ieee trans.
knowl.
data eng.,tion generation.
32(5):971–982..yu sun, shuohuan wang, yu-kun li, shikun feng,xuyi chen, han zhang, xin tian, danxiang zhu,hao tian, and hua wu.
2019.ernie: en-hanced representation through knowledge integra-tion.
corr, abs/1904.09223..ilya sutskever, oriol vinyals, and quoc v. le.
2014.sequence to sequence learning with neural networks.
in advances in neural information processing sys-tems 27: annual conference on neural informa-tion processing systems 2014, december 8-13 2014,montreal, quebec, canada, pages 3104–3112..duyu tang, nan duan, tao qin, and ming zhou.
2017.question answering and question generation as dualtasks.
corr, abs/1706.02027..tong wang, xingdi yuan, and adam trischler.
2017.a joint model for question answering and questiongeneration.
corr, abs/1706.01450..yue wang, jing li, hou pong chan, irwin king,michael r. lyu, and shuming shi.
2019a.
topic-aware neural keyphrase generation for social medialanguage.
in proceedings of the 57th conference ofthe association for computational linguistics, acl2019, florence, italy, july 28- august 2, 2019, vol-ume 1: long papers, pages 2516–2526.
associationfor computational linguistics..yue wang, jing li, irwin king, michael r. lyu, andshuming shi.
2019b.
microblog hashtag generationvia encoding conversation contexts.
in proceedingsof the 2019 conference of the north american chap-ter of the association for computational linguistics:human language technologies, naacl-hlt 2019,minneapolis, mn, usa, june 2-7, 2019, volume 1(long and short papers), pages 1624–1633.
associ-ation for computational linguistics..kaichun yao, libo zhang, tiejian luo, lili tao, andyanjun wu.
2018. teaching machines to ask ques-in proceedings of the twenty-seventh inter-tions.
national joint conference on artiﬁcial intelligence,ijcai 2018, july 13-19, 2018, stockholm, sweden,pages 4546–4552.
ijcai.org..xingdi yuan, tong wang, c¸ aglar g¨ulc¸ehre, alessan-dro sordoni, philip bachman, saizheng zhang,sandeep subramanian, and adam trischler.
2017.machine comprehension by text-to-text neural ques-the 2ndtion generation.
workshop on representation learning for nlp,rep4nlp@acl 2017, vancouver, canada, august3, 2017, pages 15–25.
association for computa-tional linguistics..in proceedings of.
jichuan zeng,.
jing li, yan song, cuiyun gao,michael r. lyu, and irwin king.
2018. topic mem-in pro-ory networks for short text classiﬁcation.
ceedings of the 2018 conference on empirical meth-ods in natural language processing, brussels, bel-gium, october 31 - november 4, 2018, pages 3120–3131. association for computational linguistics..yao zhao, xiaochuan ni, yuanyuan ding, and qifake.
2018. paragraph-level neural question gener-ation with maxout pointer and gated self-attentionin proceedings of the 2018 conferencenetworks.
on empirical methods in natural language process-ing, brussels, belgium, october 31 - november 4,2018, pages 3901–3910.
association for computa-tional linguistics..qingyu zhou, nan yang, furu wei, chuanqi tan,hangbo bao, and ming zhou.
2017. neural ques-tion generation from text: a preliminary study.
innatural language processing and chinese comput-ing - 6th ccf international conference, nlpcc2017, dalian, china, november 8-12, 2017, pro-ceedings, volume 10619 of lecture notes in com-puter science, pages 662–671.
springer..39[p ost]: #2020百大最美女星#刘亦菲和迪丽热巴都上榜啦！！！都是天然美女啊～两个人一个人演过电影版的三生三世，一个演过剧版的三生三世。 (#100 most beautiful women in the world 2020# liu yifei and dilrabadilmurat are both on the list!!!
both of them are natural beauties˜one of them played in the movie eternal love whilethe other played in its tv series version)[question]: 谁的颜让你心动呢 (whose face makes you heart ﬂip)[answer]: 刘亦菲 (liu yifei); 迪丽热巴 (dilraba dilmurat)[base]: 你最喜欢谁 (who do you like the best)[robert a]: 你更喜欢谁 (who do you prefer)[t opic]: 你更喜欢哪一个(which one do you prefer)[cmt(n t m )]: 你更喜欢谁的造型 (whose look do you prefer)[dualdec]: 你觉得谁更有cp感 (who do you think is better coupled with the leading man)>刘亦菲 (liu yifei); 迪丽热巴 (dilraba dilmurat)[p ost]: 有意见建议同性婚姻合法化写入民法典 (some people suggest that same-sex marriage be legalized into thecivil code)[question]: 你支持同性恋结果合法化吗 (do you support the legalization of same-sex marriage)[answer]: 同意 (agree); 不同意 (disagree)[base]: 你怎么看 (what do you think)[robert a]: 你支持同性结婚化吗 (do you support the same-sex marriage)[t opic]: 你支持同性恋合法化吗 (do you support the legalization of homosexuality)[cmt(n t m )]: 你支持同性恋婚姻合法化吗 (do you support the legalization of the same-sex marriage)[dualdec]: 你支持同性恋婚姻合法化吗(do you support the legalization of the same-sex marriage)>支持 (support); 不支持 (objection)[p ost]: #瑞幸咖啡伪造交易22亿# 在否认业绩造假两个月后，瑞幸今日盘前发布公告：内部调查显示，从2019年第二季度到2019年第四季度与虚假交易相关的总销售金额约为22亿元。于是，#瑞幸暴跌# 。 (#ruix-ing coffee forged 2.2 billion transactions# two months after denying fraud, luckin released an announcement before themarket today: an internal investigation showed that total sales related to invalid transactions from the second quarter of2019 to the fourth quarter of 2019 amounted to about 2.2 billion yuan.
consequently, #luckin coffee stock plummet#)[question]: 你还会喝瑞幸咖啡吗 (will you still drink luckin coffee)[answer]: 会，我券还没用完呢 (yes.
i still have the coupons to use); 不会，没券就不喝 (no.
no coupon, nocoffee.
); 从来就没有喝过 (i’ve never drunk the coffee there); 不管如何都是死忠粉 (die-hard fan no matter what)[base]: 你会买 iphone 吗 (would you buy an iphone)[robert a]: 你喝过瑞幸咖啡吗 (have you ever drunk luckin coffee)[t opic]: 你会买瑞幸咖啡吗 (would you buy luckin coffee)[cmt(n t m )]: 你觉得瑞幸咖啡合理吗 (do you think luckin coffee is reasonable)[dualdec]: 你还会买瑞幸咖啡吗 (will you still buy luckin coffee)>会 (yes); 不会 (no); 看情况 (it depends)[p ost]: 杨丽萍因为没有结婚生孩子，过着与花草舞蹈为伴的生活，被网友diss是一个失败的范例，真正的女人应该要儿孙满堂，才是幸福的。 (yang liping, who has no marriage or children, lives a life with ﬂowers anddancing.
however, she has been ridiculed by netizens and viewed as a typical loser — a real woman should have a largefamily of children and grandchildren to live in happiness.)
[question]: 如何定义成功女性(how to deﬁne a successful woman)[answer]: 事业有成 (success in career); 儿孙满堂 (have children and grandchildren); 家庭事业双丰收(success infamily and career); 充实的灵魂 (interesting soul)[base]: 你觉得哪种行为有问题 (what kind of behavior do you think is problematic)[robert a]: 女女是女人是女人是什么 (what is woman is woman)[t opic]: 你觉得结婚应该定义成功吗 (do you think marriage should come to deﬁne success)[cmt(n t m )]: 你怎么看待成功的女性杨丽萍 (how do you think of the successful woman yang liping)[dualdec]: 你觉得如何定义成功女性 (how would you deﬁne successful women)> 应该 (should); 不支持(objection); 评论区补充 (add more details in comments)[p ost]: #杨幂魏大勋恋情实锤# 杨幂魏大勋恋情再次被实锤，现在已经成了圈子内外不是秘密的秘密了。(#smoking gun of yang mi and wei daxun# yang mi and wei daxun’s love affair has been veriﬁed again, and it has nowbecome a secret inside and outside the circle.)
[question]: 你看好杨幂魏大勋的恋情吗(are you optimistic about yang mi’s romantic relationship with wei daxun)[answer]: 看好 (optimistic); 不看好 (pessimistic); 有波折终能修成正果 (there will be twists and turns but theending will be good)[base]: 你觉得这个做法怎么样 (what do you think of this approach)[robert a]: 你觉得魏魏勋勋恋爱吗(do you think wei wei xun xun is in love)[t opic]: 你觉得谁更渣 (who do you think is more scummy)[cmt(n t m )]: 你怎么看待这恋情的 (what do you think of the romantic relationship)[dualdec]: 你觉得杨幂魏大勋有必要吗 (do you think yang mi and daxun wei are necessary to do so)>杨幂 (yang mi); 魏大勋 (wei daxun); 都不喜欢 (do not like either of them); 吃瓜 (i’m an onlooker).
table 6: five additional cases.
one block refers to one case, including its source post (p ost), ground truth question(question) and answer (answer), followed by and the results generated by varying models (model names are in[]).
for answers, different choices are separated by “;” and the outputs of dualdec appear after a >.
italic wordsin “()” are the english translation of the original chinese texts on their left..40