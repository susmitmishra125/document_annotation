argument pair extraction via attention-guided multi-layermulti-cross encoding.
liying cheng∗1,2 tianyu wu1 lidong bing2 luo si21singapore university of technology and design 2damo academy, alibaba group{liying.cheng, l.bing, luo.si}@alibaba-inc.comtianyu wu@alumni.sutd.edu.sg.
abstract.
argument pair extraction (ape) is a researchtask for extracting arguments from two pas-sages and identifying potential argument pairs.
prior research work treats this task as a se-quence labeling problem and a binary clas-siﬁcation problem on two passages that aredirectly concatenated together, which has alimitation of not fully utilizing the uniquecharacteristics and inherent relations of twodifferent passages.
this paper proposes anovel attention-guided multi-layer multi-crossencoding scheme to address the challenges.
the new model processes two passages withtwo individual sequence encoders and updatestheir representations using each other’s repre-sentations through attention.
in addition, thepair prediction part is formulated as a table-ﬁlling problem by updating the representationsof two sequences’ cartesian product.
further-more, an auxiliary attention loss is introducedto guide each argument to align to its paired ar-gument.
an extensive set of experiments showthat the new model signiﬁcantly improves theape performance over several alternatives 1..1.introduction.
mining argumentation structures within a corpusis a crucial task in argument mining research ﬁeld(palau and moens, 2009).
there are usually twomain components in learning natural language argu-ment structures: (1) detecting argumentative units,(2) predicting relations between the identiﬁed argu-ments.
it has been widely studied by natural lan-guage processing (nlp) researchers (cabrio andvillata, 2018) and applied to domains such as: webdebating platforms (boltuˇzi´c and ˇsnajder, 2015;swanson et al., 2015; chakrabarty et al., 2019),.
∗liying cheng is under the joint ph.d. program betweenalibaba and singapore university of technology and design.
1our code and data are available at https://github..com/tianyuterry/mlmc..persuasive essays (stab and gurevych, 2014; pers-ing and ng, 2016), social media (abbott et al.,2016), etc.
unlike traditional argument extractiontasks that are mainly from monologues, cheng et al.
(2020) propose a new task - argument pair extrac-tion (ape) from two passages in a new domain,namely peer review process, focusing on exploit-ing the interactions between reviewer commentsand author rebuttals.
as shown in figure 1, apetask aims to extract the argument pairs from twopassages.
speciﬁc suggestions, questions or chal-lenges in reviews are considered as review argu-ments.
response sentences that answer or explainthe speciﬁc review argument are its paired rebut-tal arguments.
for example in the pink area, thereviewer points out the lack of literature reviewin submission (i.e., review sentences 11-12).
asa response, the authors argue that they select theliterature based on the special focus of their work(i.e., rebuttal sentence 6-7)..similar to the two components in the traditionalargumentation structure mining, the ape task canbe divided into two subtasks: (1) extracting the re-view and rebuttal arguments from two passages, (2)predicting if an extracted review argument and arebuttal argument form an argument pair.
the ﬁrstsubtask can be cast as a sequence labeling problemand the second one can be cast as a binary classiﬁ-cation problem.
one straightforward approach isto couple the two subtasks in a pipeline.
however,such a pipeline approach learns two subtasks inde-pendently without sharing ample information.
toaddress this limitation, the pioneering work (chenget al., 2020) employs a multi-task learning frame-work to train two subtasks simultaneously..however, there are several shortcomings in themulti-task model.
first, the review passage andits rebuttal passage are concatenated as a singlepassage to perform the argument extraction subtaskwith sequence labeling.
it is obvious to see from.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6341–6353august1–6,2021.©2021associationforcomputationallinguistics6341figure 1: an example of ape task.
the review and rebuttal passage pair is shown on the left.
the grey area refersto non-arguments, while the blue and pink areas refer to two paired arguments.
the table representing the pairingrelation is shown on the right (ﬁlled entries: paired; unﬁlled entries: unpaired).
review and rebuttal sentenceindices are on the left and the top of the table.
review and rebuttal sequence labels for argument extraction are onthe right and the bottom of the table..figure 1 that the review and rebuttal passages havetheir own styles in terms of structure and wording.
hence, it is not suitable to concatenate them asone long sequence, which is against the fact thatthey are two unique sequences in essence and hin-ders the model from well-utilizing their differentcharacteristics.
to overcome this limitation, wetreat review and rebuttal passages as two individualsequences and design two sequence encoders forthem respectively.
in each sequence encoder, thesequence representations will be updated by theother’s representations through mutual attention.
itallows us to better distinguish two passages, andmeanwhile, to conveniently exchange informationbetween them through the attention mechanism..second, the subtask coordination capability oftheir multi-task framework is weak as two subtasksonly coordinate with each other via the shared fea-ture encoders, i.e., the sentence encoder for the se-quence of word tokens and the passage encoder forthe concatenation of sentences.
thus, the sharedinformation between two subtasks is only learnedimplicitly.
to overcome this limitation, we pro-pose an attention-guided multi-layer multi-cross(mlmc) encoding mechanism.
inspired by thetable-ﬁlling approach (miwa and sasaki, 2014), weform a table that represents features for the carte-sian product of review and rebuttal sequences by.
utilizing both of their embeddings, as shown inthe right portion of figure 1. the table represen-tations will be updated with the incorporation ofthe two sequence representations, and in return, itwill also help to update the mutual attention men-tioned above.
it is named as multi-cross encoderbecause these three encoding components (i.e., onetable and two sequences) interact with each otherexplicitly and extensively.
by stacking multipleencoder layers, the two subtasks can further beneﬁteach other.
in addition, we also design an auxiliaryattention loss to guide each argument to refer toits paired arguments.
this additional loss not onlyenhances the model performance, but also signiﬁ-cantly improves the attention interpretability..to summarize, the contributions of this paperare three-fold.
firstly, we apply the table-ﬁllingapproach to model the sentence-level correlationbetween two passages with multiple sentences forthe ﬁrst time.
secondly, on the model side, wepropose an mlmc encoder to explicitly learn theuseful shared information in the two passages.
fur-thermore, we introduce an auxiliary attention loss,which is able to further improve the efﬁcacy of themutual attentions.
thirdly, we evaluate our modelon the benchmark dataset (cheng et al., 2020), andthe results show that our model achieves a newstate-of-the-art performance on the ape task..6342128 rebuttal review12345671234567oooooob91011iibiiibobii1  this relatively novel work proposes to augment currentrl models by adding self-supervised tasks encouragingbetter internal representations.2 - 6  the proposed tasks are depth prediction and loopclosure detection.
[...]7  it is original, clearly presented, and strongly supp-ortedby empirical evidence.8 one small downside of the experimental method (ormaybe just the results shown) is that by picking top-5 runs,it is hard to judge whether such a model is better suited tothe particular hyperparameter range that was chosen, or issimply more robust to these hyperparameter settings.9 maybe an analysis of performance as a function ofhyperparameters would help confirm the superiority of theapproach to the baselines.10 my own suspicion is that adding auxiliary tasks wouldmake the model robust to bad hyperparameters.11  another downside is that the authors dismiss navigationliterature as "not rl".12  i sympathize with the limit on the number of things thatcan fit in a paper, but some experimental comparison withsuch literature may have proven insightful, if just inmeasuring the quality of the learned representations.o1   thank you for your comments.2   we provided additional analysis, in appendix section c.4,to address your comments.3   for each of the experiments in this paper, 64 replicas wererun with hyperparameters (learning rate, entropy cost)sampled from the same interval.4    figure 12 shows that the nav architectures with auxiliarytasks achieve higher results for a comparatively largernumber of replicas, suggesting that auxiliary tasks makelearning more robust to the choice of hyperparameters - inline with the reviewer's intuition.5    this observation is particularly strong for the small staticmaze (more than a third of the replicas for ff a3c andlstm a3c baselines do not even reach the goal, whereasless than 10 nav agents out of 64 replicas suffer from this).6   in this paper we focused on the potential benefits ofauxiliary tasks in enhancing the navigational capacities ofagents that use deep rl to map pixels directly to actions -rather than designing a new state-of-the-art navigationsystem.7   our discussion of the literature reflected this focus, butwas not intended to be dismissive of other navigationapproaches such as slam.
2 related work.
argument mining has wide applications in educa-tional domain, including persuasive essays (staband gurevych, 2017; eger et al., 2017), scientiﬁc ar-ticles (teufel et al., 2009; guo et al., 2011), writingassistance (zhang and litman, 2016), essay scor-ing (persing and ng, 2015; somasundaran et al.,2016), peer reviews (hua et al., 2019), etc.
unlikeprevious works, cheng et al.
(2020) introduce anew task named ape in the domain of peer reviewand rebuttal, which intends to extract the argumentpairs from two passages simultaneously..table-ﬁlling approaches (miwa and sasaki,2014; gupta et al., 2016; zhang et al., 2017) havebeen proposed to work towards the joint task ofname entity recognition (ner) and relation ex-traction (re).
in their work, the diagonal entriesof the table show the words’ entity types and theoff-diagonal entries show the relation types withother words.
more recently, there are more researchworks to propose various table-ﬁlling models ondifferent tasks.
wang and lu (2020) propose tolearn two separate encoders (a table encoder and asequence encoder) by interacting with each otherfor joint ner and re task.
wu et al.
(2020) pro-pose a grid tagging scheme to address the aspect-oriented ﬁne-grained opinion extraction task.
com-pared to our model, one major difference is thetable shape.
in their tables, the row and columnrepresent the same sequence, and thus in squareshape.
in our model, the table is in a rectangleshape where the row and column represent two dif-ferent sequences with different lengths.
anotherclear difference is that each entry in their table is forword-pair relation, whereas each entry in our tablecaptures sentence-pair relation.
as we can see fromfigure 1, the review/rebuttal sequence consists ofa list of sentences.
thus, it requires extra effort tolearn comprehensive sentence representations..3 task formulation.
in this paper, we tackle the ape task, which aims tostudy the internal structure and relations betweentwo passages, e.g., review and rebuttal passages.
for example, as shown in figure 1, given a pair ofreview passage srv = [srv,1, · · · , srv,12] (in the redbox) and rebuttal passage srb = [srb,1, · · · , srb,7](in the orange box), we intend to automaticallyextract all argument pairs between them.
first,for the argument mining subtask, we cast it as asentence-level sequence labeling problem follow-.
ing the work (cheng et al., 2020) using the stan-dard bio scheme (ramshaw, 1995; ratinov androth, 2009).
this subtask segments the argumen-tative units (highlighted in blue/pink) from non-argumentative units (highlighted in grey) for eachpassage.
the label sequences for the review pas-sage and the rebuttal passage are shown in the rightportion of figure 1. second, the sentence pairingsubtask predicts whether the two sentences belongto one argument pair.
here, we formulate it as atable-ﬁlling problem following the work (miwa andsasaki, 2014).
take the 8th review sentence srv,8in the ﬁrst review argument as an example, the re-buttal argument sentences {srb,2, srb,3, srb,4, srb,5}forming sentence pairs with it are ﬁlled with green,as shown in the table.
with the collaboration ofthese two subtasks, we can perform the overallargument pair extraction task.
in this case, twoargument pairs (highlighted in blue/pink from twopassages) are extracted, which correspond to thetwo green rectangles shown in the table..4 model.
figure 2 shows our proposed attention-guidedmulti-layer multi-cross (mlmc) encoding basedmodel.
the model mainly consists of three parts: asentence embedder, an n-layer multi-cross encoder,and a predictor.
the review sentences and rebuttalsentences ﬁrst go through the sentence embedderseparately to obtain their sentence embeddings re-spectively.
we then utilize the representations fromreview and rebuttal sequences to form a table asshown earlier in figure 1. next, the representa-tions of the table and two sequences are updatedthrough n multi-cross encoder layers.
finally, themodel predicts the review and rebuttal argumentsthrough a conditional random ﬁeld (crf) (laf-ferty et al., 2001) layer based on two sequencerepresentations, and extracts the pairing informa-tion through a multi-layer perceptron (mlp) basedon the table representations..4.1 sentence embedder.
the bottom left part of figure 2 shows our sen-tence embedder, the input of which is a reviewsentence or a rebuttal sentence with l tokenss = [t0, t1, · · · , tl−1].
we obtain the pre-trainedbert (devlin et al., 2019) token embeddings[x0, x1, · · · , xl−1] for all word tokens in the sen-tence, after which all token embeddings are fed intoa bidirectional long short-term memory (bilstm).
6343figure 2: overview of our model architecture with n multi-cross encoder layers (shown on the left).
the sentenceembedder (in the grey dotted box at the bottom left) shows the process of obtaining initial review and rebuttalsentence embeddings from pre-trained bert token embeddings with bilstm.
the kth multi-cross encoder layer(in the blue dotted box on the right) shows the process of getting the sentence representations of review and rebuttaland the pair representations for the next layer..(hochreiter and schmidhuber, 1997) layer.
the lasthidden states from both directions are concatenatedas the sentence embedding s(0).
a more commonpractice is to use the [cls] token embedding torepresent the sentence embedding.
however, giventhe high density of scientiﬁc terms and the corre-spondence between review and rebuttal, token-levelinformation is naturally crucial for the task.
thesame conclusion is drawn by the experimental re-sults in the previous work (cheng et al., 2020)..4.2 multi-cross encoder.
the entire multi-cross encoder consists of n lay-ers.
the details of each multi-cross encoder layerare shown in the blue dotted box on the right offigure 2. the input of the layer includes table rep-resentations and two sequence representations, i.e.,review and rebuttal sequence representations.
ineach layer, table features are updated by sequencefeatures and vice versa..rv.
and s(k−1)rb.
sequence encoder phase i to well-utilize dif-ferent characteristics of review and rebuttal, weregard them as two individual sequences.
two se-quence embeddings s(k−1)of lengthi and j respectively (i.e., the output from the pre-vious layer) are passed through the same bilstmlayer colored light yellow in figure 2. take reviewsequence as an example, the review hidden statesat position i are updated as follows:s(k)(cid:48)[1]rv,i = lstmforward(s(k−1).
, s(k)(cid:48)[1].
rv,i−1),.
rv,i.
, s(k)(cid:48)[2].
s(k)(cid:48)[2]rv,i = lstmbackward(s(k−1)rv,is(k)(cid:48), s(k)(cid:48)[2]rv,i = [s(k)(cid:48)[1]rv,ithe rebuttal hidden states s(k)(cid:48)rb in layer k is ob-tained from the same bilstm in the same manner..rv,i+1),.
rv,i.
]..table encoder to capture the pairing informa-tion explicitly, we adopt the table-ﬁlling approach.
at layer k, we update the table t(k−1)rv×rb throughthe table encoder.
the table input t(0)rv×rb beforethe ﬁrst encoder layer are set as 0. at each layerk, in order to incorporate the information extractedrb , we form another table t(k−1)(cid:48)(cid:48)in s(k)(cid:48)rv×rbwith them through concatenation and linear projec-tion as follows:.
rv and s(k)(cid:48).
i,j.
rb )..rv ⊗ s(k)(cid:48).
rv×rb = layernorm(t(k−1).
rv×rb = linear(s(k)(cid:48)t(k−1)(cid:48)(cid:48)the table features from previous layer t(k−1)then updated by t(k−1)(cid:48)(cid:48).
rv×rb arerv×rb with layer normalization:t(k−1)(cid:48)rv×rb ⊕ t(k−1)(cid:48)(cid:48)rv×rb ).
the entry t (k−1)(cid:48)at row i and column j representsspeciﬁc features between review sentence at posi-tion i and rebuttal sentence at position j. the tablehidden states t (k)i,j are updated through 2d-gru:i−1,j , t (k)[1]i+1,j , t (k)[2], t (k)[2]i,j.
i,j = gruforward(t (k)[1]t (k)[1]i,j = grubackward(t (k)[2]t (k)[2]i,j = [t (k)[1]t (k).
i,j−1 , t (k−1)(cid:48)i,j+1 , t (k−1)(cid:48).
),.
),.
i,j.
i,j.
i,j.
]..6344bert............multi-cross encoder layer 1multi-cross encoder layer ncrfmlppairsreviewargumentsrebuttalargumentsbilstmreviewattentionrebuttalattentionlinearlayernorm2d-grubilstmbilstmlayernormlayernormcrfmulti-cross encoder layer ksentence embeddingthe 2d-gru settings are similar to the previouswork (wang and lu, 2020) except that the table tobe processed is not necessarily a square (i (cid:54)= jin general).
therefore, the 2d-gru implementedhere is more general.
the previous hidden states fortable boundaries (t (k)[1], t (k)[1]i+1,j, t (k)[2], t (k)[2]i,j+1)i,0are set as 0. the outputs t(k)rv×rp of layer k arefurther exploited by the mutual attention mecha-nism explained below to update review and rebuttalsequence embeddings..0,j.
mutual attention the mutual attention mecha-nism (shown as review attention and rebuttal atten-tion modules in figure 2) links review embedding,rebuttal embedding and table embedding together,through which review embedding and rebuttal em-bedding update each other with the help of tablefeatures.
the attention weights α(k)i,j and β(k)i,j atposition (i, j) in layer k are updated as follows:β · t (k)i,j ), β(k)i,j ),where vα and vβ are learnable vectors.
we furthernormalize the attention weights:exp(α(k)i,j )exp(α(k)i,j.
exp(β(k)i,j )exp(β(k),j.α(k)i,j = tanh(vt.i,j = tanh(vt.α · t (k).
a(k)i,j =.
b(k)i,j =.
(cid:80)j(cid:48)j.
(cid:80)i(cid:48)i.
(cid:48) ).
=1.
=1.
,.
..).
i.
(cid:48).
i,j and b(k).
here, a(k)i,j are the normalized attentionweights ranging from 0 to 1. we then get theweighted average of sentence representations s(k)(cid:48)(cid:48)rv,irb and s(k)(cid:48)and s(k)(cid:48)(cid:48)rb,j , s(k)(cid:48)(cid:48).
rb,j from s(k)(cid:48)j(cid:80)j=1.
rv respectively..i,j · s(k)(cid:48)b(k)rv,i ..i,j · s(k)(cid:48)a(k).
s(k)(cid:48)(cid:48)rv,i =.
rb,j =.
i(cid:80)i=1.
and s(k)(cid:48)(cid:48).
here, s(k)(cid:48)(cid:48)rb are the updated review em-rvbedding and rebuttal embedding.
information inreview and rebuttal sequences is exchanged viamutual attention..sequence encoder phase ii the addition andlayer normalization used to combine s(k)(cid:48)ands(k)(cid:48)(cid:48)in the sequence encoder are similar to the onein table encoder.
we obtain the review sequenceembedding s(k)rv and rebuttal sequence embeddings(k)rb as the sequence outputs of layer k as follows:.
rv = layernorm(s(k)(cid:48)s(k)rb = layernorm(s(k)(cid:48)s(k).
rv ⊕ s(k)(cid:48)(cid:48)rv ),rb ⊕ s(k)(cid:48)(cid:48)rb )..stacking multi-cross encoder layers the up-dating process described above continues as layergrows from 1 to n. the table feature is updatedby both review and rebuttal sequences, and eachsequence updates the other via the table later on..there are also residual connections between adja-cent layers which accept the previous layer’s outputas the current layer’s input and include it as partof the new embedding, making the system morerobust.
all three features (i.e., review sequence,rebuttal sequence, table) are intertwined with eachother and information ﬂows across different com-ponents of the encoder.
this is also the reason whythe encoder is described as mlmc..4.3 argument pair predictor.
after the ﬁnal multi-cross encoder layer, sequencefeatures are used for argument mining and tablefeatures are used for pair prediction..argument predictor we adopt crf to predictargument sequence labels.
the sequence labelingloss lseq for both review sequence srv and rebuttalsequence srb in each instance is deﬁned as:.
lseq = −(cid:0) log p(yrv|srv) + log p(yrb|srb)(cid:1),where yrv and yrb are the review and rebuttal se-quence labels 2..during inference, the predicted sequence labelis the one with the highest conditional probabilitygiven the original sequence:.
y∗.
rv = arg max.
p(y|srv), y∗.
rb = arg max.
p(y|srb)..y.y.pair predictor we use mlp to predict sentencepairs 3. the pairing loss lpair for each instance is:.
lpair = − (cid:80).
i,j.
ypairi,j.
log p(ypair.
(cid:16).
+ (1 − ypair.
i,j ) log p(ypair.
i,j = 1|srv, srb)(cid:17).
i,j = 0|srv, srb).
,.
where ypairi,jis 0 otherwise 4..is 1 when srv,i and srb,j are paired, and.
following (cheng et al., 2020), during evalua-tion, a pair of candidate spans ([srv,i1, · · · , srv,i2]and [srb,j1, · · · , srb,j2]) form a pair if they satisfythe following criterion:(cid:80)j2.
(cid:80)i2.
1.i=i1.
j=j1.
{p(y.
=1)>0.5}.
pairi,j.
(i2−i1+1)×(j2−j1+1).
× 100% (cid:62) 50%.
attention loss attention loss is a loss termspeciﬁcally designed for the task.
it aims to in-crease the effectiveness of review attention andrebuttal attention discussed above.
even without.
2we provide the detailed steps of deriving the loss lseq in.
appendix a.1..3mlp is chosen because more complex structures like con-volutional neural networks (cnn) demonstrate no superiority.
the comparison results are attached in appendix b.3..4we provide the detailed steps of deriving the pairing loss.
lpair in appendix a.2..6345this auxiliary loss term, sentences in review are sup-posed to attend to relevant sentences in rebuttal andvice versa.
the auxiliary loss is thus aimed at aug-menting the effect of mutual reference explicitly byguiding the paired arguments to refer to each other.
intuitively, under the settings of argument miningand pairing, it is natural that review arguments re-fer to the paired rebuttal arguments to update theirembedding and vice versa during mutual attention.
hence, we introduce an auxiliary loss term to in-crease the attention weights computed for pairedarguments and decrease the attention weights oth-erwise for both review and rebuttal attentions in alllayers.
for each instance, lattn is deﬁned as:.
lattn = (cid:80)i,j.
(1 − 2ypair.
i,j ) ·.
(cid:16) n(cid:80)k=1.
γn−k · (a(k).
(cid:17)i,j + b(k)i,j ).
,.
where γ is the decaying parameter used to com-pute exponential moving average for the sum ofattention.
larger weights are assigned to layerscloser to the ﬁnal predictor as they are more relatedto the prediction in the end.
the attention loss isdeﬁned in the form of summation across all layersto increase the accuracy and interpretability of bothreview and rebuttal attentions in all layers.
if thetendency to attend to the paired argument is aug-mented, the beneﬁts of attention mechanism can befurther exploited (e.g., learning better sentence rep-resentations, increasing pair prediction accuracy).
the overall loss l is then deﬁned by summing.
up three losses together:.
l = lseq + λ1 · lpair + λ2 · lattn,.
where λ1 and λ2 are tuned hyperparameters..5 experiments.
5.1 data.
we conduct experiments on the benchmark dataset,i.e., rr dataset (cheng et al., 2020) to evalu-ate the effectiveness of our proposed model.
rrdataset includes 4,764 pairs of peer reviews and au-thor rebuttals collected from iclr 2013 to iclr2020. there are two dataset versions provided:rr-submission-v1 and rr-passage-v1.
in rr-submission-v1, multiple review-rebuttal passagepairs of the same paper submission are in the sameset of train, dev or test; while in rr-passage-v1,different review-rebuttal passage pairs of the samesubmission could be put into different sets.
wefurther modify the rr-submission-v1 dataset byﬁxing some minor bugs in the labels, and name itrr-submission-v2.
the data are split into train,.
dev and test sets by a ratio of 8:1:1 for all threedataset versions..5.2 baselines.
we compare our model with two baselines:.
• the pipeline approach is used as a baselinemodel in the previous work (cheng et al., 2020).
it independently trains two subtasks and thenpipes them together to extract argument pairs.
• the multi-task learning model proposed by(cheng et al., 2020) trains two subtasks simul-taneously via the shared feature encoders..5.3 experimental settings.
we implement our attention-guided mlmc encod-ing based model in pytorch.
the dimension ofpre-trained bert sentence embeddings is 768 bydefault.
maximum number of bert tokens foreach sentence is set as 200. mlp layer is com-posed of 3 linear functions and 2 relu functions.
we use adam (kingma and ba, 2014) with an ini-tial learning rate of 0.0002, and update parameterswith a batch size of 1 and dropout rate of 0.5. wetrain our model for 25 epochs at most.
we selectthe best model parameters based on the best overallf1 score on the development set and apply it tothe test set for evaluation.
all models are run withv100 gpu.
note that in this paper, the parametersare mainly tuned based on rr-submission-v1 5.following the previous work (cheng et al., 2020),we report the precision (prec.
), recall (rec.)
andf1 scores for the performance on both subtasks aswell as the overall extraction performance..5.4 main results on rr dataset.
table 1 shows the performance comparison be-tween our proposed models and the perviouswork on rr-submission-v1 and rr-passage-v1datasets 6. besides the two baseline models men-tioned before, we implement a bi-cross encodingscheme (bi-cross) for comparisons as well.
thekey difference between the bi-cross encoder and themulti-cross encoder is that in the bi-cross encoder,.
5more details about hyperparameter settings (e.g.
weightfor pair loss λ1, weight for attention loss λ2, decaying parame-ter γ of exponential moving average) and experimental results(e.g.
running time, number of parameters, performance on thedevelopment set) could be found in appendix b..6the previous work adopts negative sampling techniquefor sentence pairing subtask and evaluates the performance onthe partial test set.
in this work, we re-evaluate the previouswork’s sentence pairing subtask on the whole test dataset for afair comparison.
those results are marked with * in table 1..6346data models.
argument mining.
sentence pairing.
ape.
prec.
rec..f1.
prec..rec..f1.
prec.
rec..f1.
1v-noissimbus-rr.1v-egassap-rr.pipeline (cheng et al., 2020)67.63 68.51 68.06 *50.05* *47.15* *48.56* 19.86 19.94 19.90multi-task (cheng et al., 2020) 70.09 70.14 70.12 *53.44* *42.71* *47.48* 26.69 26.24 26.46bi-cross (n=1)35.56 22.95 27.90bi-cross (n=2)38.36 23.34 29.02bi-cross (n=3)39.43 24.45 30.18bi-cross (n=4)36.59 25.28 29.90bi-cross (n=5)36.37 24.06 28.96multi-cross (n=1)36.56 23.62 28.70multi-cross (n=2)37.50 25.39 30.28multi-cross (n=3)38.70 27.93 32.44multi-cross (n=4)35.98 26.33 30.41multi-cross (n=5)36.32 27.82 31.51.
68.13 69.69 68.9070.38 68.12 69.2368.04 71.65 69.8067.45 71.48 69.4168.47 70.30 69.3767.64 69.27 68.4567.23 70.55 68.8569.52 70.03 69.7765.84 70.60 68.1465.52 70.79 68.05.
42.2843.5642.3343.8841.3044.3343.7147.1440.5944.90.
48.6051.1550.5551.1148.0051.0151.4653.1148.4551.61.
57.1461.9362.7361.1957.2960.0862.5760.8160.0760.69.pipeline (cheng et al., 2020)73.10 67.65 70.27 *51.34* *42.08* *46.25* 21.24 19.30 20.23multi-task (cheng et al., 2020) 71.85 71.01 71.43 *54.28* *43.24* *48.13* 30.08 29.55 29.81bi-cross (n=1)40.72 25.74 31.54bi-cross (n=2)41.48 27.53 33.09bi-cross (n=3)39.04 26.89 31.85bi-cross (n=4)42.02 27.32 33.11bi-cross (n=5)40.85 25.26 31.22multi-cross (n=1)38.82 29.32 33.40multi-cross (n=2)40.13 29.11 33.74multi-cross (n=3)40.27 29.53 34.07multi-cross (n=4)38.96 27.32 32.12multi-cross (n=5)39.60 26.95 32.07.
67.77 70.91 69.3169.44 71.59 70.5066.79 71.97 69.2867.55 71.95 69.7066.32 71.35 68.7467.18 72.29 69.6468.28 72.12 70.1566.79 72.17 69.3765.77 73.54 69.4467.84 71.42 69.58.
41.2743.2643.0239.9837.7045.9444.2342.3339.9841.08.
49.5750.3450.5348.7247.0952.5251.4750.5348.8649.08.
62.0560.2061.2262.3562.7261.2961.5462.6962.8060.94.table 1: main results on rr-submission-v1 and rr-passage-v1.
the results with * are re-evaluated..data models.
argument mining.
sentence pairing.
ape.
prec.
rec..f1.
prec.
rec..f1.
prec.
rec..f1.
2v-noissimbus-rr.multi-task (cheng et al., 2020) 70.74 69.46 70.09 52.05 46.74 49.25 27.24 26.00 26.61bi-cross (n=1)68.46 70.47 69.45 66.10 41.25 50.80 37.86 24.78 29.95bi-cross (n=2)68.69 72.54 70.56 59.40 47.61 52.86 35.17 27.42 30.81bi-cross (n=3)69.04 72.35 70.66 58.87 44.10 50.43 35.68 26.26 30.25bi-cross (n=4)68.78 72.54 70.61 61.72 43.87 51.28 35.54 26.68 30.48multi-cross (n=1)69.20 72.30 70.72 60.92 43.10 50.48 36.18 26.68 30.71multi-cross (n=2)69.13 72.66 70.85 59.94 47.60 53.06 34.97 29.01 31.71multi-cross (n=3)69.53 73.27 71.35 60.01 46.82 52.60 37.15 29.38 32.81multi-cross (n=4)69.73 71.36 70.54 62.87 48.15 54.53 36.17 28.53 31.90multi-cross (n=5)67.80 71.36 69.54 64.31 43.91 52.19 39.56 27.69 32.58.table 2: main results on rr-submission-v2..the review sentences and rebuttal sentences are con-catenated as one sequence, and thus it only hasone sequence encoder.
in contrast, there are twoindividual sequence encoders in our multi-crossencoder.
with the same number of layers, ourmulti-cross model outperforms the bi-cross modelon both datasets except for rr-passage-v1 with 4layers.
this is especially conspicuous when thenumber of layers is 3. the superiority of the multi-cross model demonstrates the importance and ro-bustness of learning review and rebuttal sequencesseparately.
our model achieves the highest f1 scorewhen the number of layers increases to 3. addingmore layers hurts the performance, probably be-cause the model overﬁts with too many layers.
ta-.
ble 2 shows the performance on rr-submission-v2 7. the main conclusion is consistent with theperformace on rr-submission-v1.
both the bi-cross and multi-cross models outperform the multi-task model, and the multi-cross models further out-perform the bi-cross models..although the baselines achieve slightly betterperformance on the argument mining subtask thanboth the bi-cross model and the multi-cross model,they still perform worse than our models on thesentence pairing subtask and the overall ape task.
this is plausibly because of two main reasons.
first, in the multi-task model, the subtask coordi-.
7we encourage the researchers to use rr-submission-v2.
and compare to its performance in the future..6347multi-task model multi-cross (n=3) model.
73.4.
71.1.
70.1.
69.8.
75.
70.
65.
68.9.
66.2.review.
rebuttal.
both.
figure 3: f1 scores of the argument mining subtask..nation capability is weak as the shared informationbetween two subtasks is learned implicitly.
how-ever, in our model, the three encoding componentsare explicitly mingled with each other through themutual attention mechanism and the table encoder.
on one hand, the better sentence pairing subtaskperformance demonstrates the effectiveness of thetable-ﬁlling approach.
on the other hand, the betteroverall ape performance demonstrates the strongsubtask coordination capability of our model archi-tecture.
second, we further analyze the breakdownperformance of the multi-task model and our multi-cross (n=3) model on the argument mining subtask.
figure 3 shows the subtask performance on rr-submission-v1 dataset for reviews, rebuttals, andboth of them.
we can observe that the differenceof f1 scores between reviews and rebuttals of ourmodel is smaller than the multi-task model.
de-spite the slight decrease in the overall argumentmining performance, a more balanced argumentextraction performance on reviews and rebuttalsbrings in better overall ape performance, whichis because more accurate review argument extrac-tion increases the chance for the extracted rebuttalarguments to be paired correctly..5.5 ablation study.
we conduct an ablation study of the multi-cross(n=3) model on rr-submission-v1 dataset fromthree perspectives, as presented in table 3. firstly,we evaluate the effect of sharing the bilstm layer(the light yellow modules in figure 2) and the crflayer.
we can notice that the f1 drops 1.92 withoutsharing the bilstm layer, drops 1.75 without shar-ing the crf layer, and drops 1.02 when sharingneither.
it is interesting to notice that when twosequences use their own bilstms and crf simul-taneously (i.e., w/o sharing both), the f1 drops lesscompared to the models without sharing only oneof them.
this suggests that having an individualset of bilstm and crf layers for each type ofsequence is plausibly a worthwhile setting, but it.
model settings.
ape.
prec.
rec..f1 ∆ (f1).
multi-cross (n=3)38.70 27.93 32.44w/o sharing bilstm 36.95 26.00 30.5233.80 28.10 30.69w/o sharing crf36.86 27.38 31.42w/o sharing both38.31 25.55 30.66w/o cross update37.15 24.56 29.57w/o attention loss.
--1.92-1.75-1.02-1.78-2.87.table 3: ablation study of multi-cross (n=3) model onrr-submission-v1 dataset..is not as effective as sharing both.
one possiblereason is that the advantage brought in by sucha tailor-made sequential tagging conﬁguration foreach type is overwhelmed by the disadvantage offewer training instances.
secondly, without crossupdates between the review and rebuttal embed-dings (the mutual attention modules still exist), thef1 drops 1.78. this result again demonstrates theeffectiveness of explicitly blending two sequenceembeddings via the mutual attention mechanismspeciﬁcally designed for this task.
thirdly, we alsoinvestigate the effect of attention loss term by re-moving it from the overall loss.
the performancedrops about 2.87 f1 points.
we will elaborate morewith the attention visualization below..5.6 attention visualization.
to examine the effectiveness of the auxiliary atten-tion loss, we visualize the sum of attention weightsof all layers for four test samples, as shown infigure 4. the sum is computed for visualizationbecause attention weights in all layers are guidedby the attention loss.
the distribution of attention issigniﬁcantly improved as the colors for argumentsin column (c) are considerably darker.
in column(b) without the guidance of attention loss, despitesome patterns, attention weights are distributed ina quite haphazard manner.
therefore, the inter-pretability of our model is much better as we caneasily understand which part of the discourse eachsentence refers to.
speciﬁcally, the boundary ofmost attention blocks in column (c) matches wellwith the start and end positions of the ground truthreview and rebuttal arguments.
the gold and pre-dicted argument spans and argument pairs of thesefour samples are shown in appendix c.1, and morediscussions are given regarding the reason for somemistakenly predicted boundaries.
the effectivenessof the auxiliary attention loss is also quantitativelyillustrated by a higher f1 score after its incorpora-tion (32.44 v.s.
29.57) in table 3..6348(a)ground truth.
(b)w/o attention loss.
(c)w/ attention loss.
figure 4: visualization of attention weights in four test data samples.
in each plot, the y-axis corresponds to thereview sentences and the x-axis corresponds to the rebuttal sentences.
each pixel shows the attention weight ofa review and rebuttal sentence.
(a) ground truth: the gold labels of argument pairs; (b) w/o attention loss: theattention weights of the model trained without the auxiliary attention loss; (c) w/ attention loss:the attentionweights with the attention loss..6 conclusions.
in this paper, we adopt the table-ﬁlling approach formodeling the sentence-level correlation betweentwo passages, and propose the attention-guidedmulti-layer multi-cross (mlmc) encoding schemefor the argument pair extraction (ape) task.
ourmodel can better capture the internal relations be-.
tween a review and its rebuttal with two sequenceencoders and a table encoder via mutual attentionmechanism.
we also introduce an auxiliary at-tention loss to further improve the efﬁcacy of themutual attentions.
extensive experiments on thebenchmark dataset demonstrate the effectivenessof our model architecture, which is potentially ben-eﬁcial for other nlp tasks..6349oooooobiibiiboobiiiiiiiiobiiobiiiiiiiiooo1234567891011121314151617181920212223242526271234567891011121314oooooobiibiiboobiiiiiiiiobiiobiiiiiiiiooo1234567891011121314151617181920212223242526271234567891011121314oooooobiibiiboobiiiiiiiiobiiobiiiiiiiiooo1234567891011121314151617181920212223242526271234567891011121314oooooobbiiibiibiioobiobiiobiiobiiiioo12345678910111213141516171819201234567891011121314151617oooooobbiiibiibiioobiobiiobiiobiiiioo12345678910111213141516171819201234567891011121314151617oooooobbiiibiibiioobiobiiobiiobiiiioo12345678910111213141516171819201234567891011121314151617oooooooobibiibibbibbiooooooobiobiioobibiiiiiiiiiiiioobiibioobii123456789101112131415161718192021222324252627282930313233343536373812345678910111213141516171819202122232425oooooooobibiibibbibbiooooooobiobiioobibiiiiiiiiiiiioobiibioobii123456789101112131415161718192021222324252627282930313233343536373812345678910111213141516171819202122232425oooooooobibiibibbibbiooooooobiobiioobibiiiiiiiiiiiioobiibioobii123456789101112131415161718192021222324252627282930313233343536373812345678910111213141516171819202122232425ooooooobibiibbbbbbbibobiiibibibbibiiibiobibo1234567891011121314151617181920212223123456789101112131415161718192021ooooooobibiibbbbbbbibobiiibibibbibiiibiobibo1234567891011121314151617181920212223123456789101112131415161718192021ooooooobibiibbbbbbbibobiiibibibbibiiibiobibo1234567891011121314151617181920212223123456789101112131415161718192021references.
rob abbott, brian ecker, pranav anand, and marilynwalker.
2016. internet argument corpus 2.0: an sqlschema for dialogic social media and the corpora togo with it.
in proceedings of lrec..filip boltuˇzi´c and jan ˇsnajder.
2015..identifyingprominent arguments in online debates using seman-in proceedings of the 2ndtic textual similarity.
workshop on argumentation mining..elena cabrio and serena villata.
2018. five years ofargument mining: a data-driven analysis.
in ijcai..tuhin chakrabarty, christopher hidey, smarandamuresan, kathy mckeown, and alyssa hwang.
2019. ampersand: argument mining for per-in proceedings ofsuasive online discussions.
emnlp-ijcnlp..liying cheng, lidong bing, qian yu, wei lu, and luosi.
2020. argument pair extraction from peer reviewand rebuttal via multi-task learning.
in proceedingsof emnlp..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training of deepbidirectional transformers for language understand-ing.
in proceedings of naacl..steffen eger,.
and irynajohannes daxenberger,gurevych.
2017. neural end-to-end learning forin proceed-computational argumentation mining.
ings of acl..yufan guo, anna korhonen, and thierry poibeau.
2011. a weakly-supervised approach to argumenta-tive zoning of scientiﬁc documents.
in proceedingsof emnlp..pankaj gupta, hinrich sch¨utze, and bernt andrassy.
2016. table ﬁlling multi-task recurrent neural net-work for joint entity and relation extraction.
in pro-ceedings of coling..sepp hochreiter and j¨urgen schmidhuber.
1997. long.
short-term memory.
neural computation..xinyu hua, mitko nikolov, nikhil badugu, andlu wang.
2019. argument mining for understand-ing peer reviews.
in proceedings of naacl..diederik p kingma and jimmy ba.
2014. adam: amethod for stochastic optimization.
technical re-port..john lafferty, andrew mccallum, and fernando cnpereira.
2001. conditional random ﬁelds: prob-abilistic models for segmenting and labeling se-quence data.
in proceedings of icml..raquel mochales palau and marie-francine moens.
the detection, clas-2009. argumentation mining:siﬁcation and structure of arguments in text.
in pro-ceedings of the 12th international conference on ar-tiﬁcial intelligence and law..isaac persing and vincent ng.
2015. modeling argu-ment strength in student essays.
in proceedings ofacl..isaac persing and vincent ng.
2016. end-to-end argu-mentation mining in student essays.
in proceedingsof naacl..la ramshaw.
1995..texttransformation-based learning.
of third workshop on very large corpora..chunking usingin proceedings.
lev ratinov and dan roth.
2009. design challengesand misconceptions in named entity recognition.
inproceedings of conll..swapna somasundaran, brian riordan, binod gyawali,and su-youn yoon.
2016. evaluating argumentativeand narrative essays using graphs.
in proceedings ofcoling..christian stab and iryna gurevych.
2014. identifyingargumentative discourse structures in persuasive es-says.
in proceedings of emnlp..christian stab and iryna gurevych.
2017. parsing ar-gumentation structures in persuasive essays.
com-putational linguistics..reid swanson, brian ecker, and marilyn walker.
2015.argument mining: extracting arguments from on-line dialogue.
in proceedings of sigdial..simone teufel, advaith siddharthan, and colin batch-elor.
2009. towards domain-independent argumen-tative zoning: evidence from chemistry and compu-tational linguistics.
in proceedings of emnlp..jue wang and wei lu.
2020. two are better thanone: joint entity and relation extraction with table-sequence encoders.
in proceedings of emnlp..zhen wu, chengcan ying, fei zhao, zhifang fan,xinyu dai, and rui xia.
2020. grid tagging schemefor aspect-oriented ﬁne-grained opinion extraction.
in findings of emnlp..fan zhang and diane litman.
2016. using contextto predict the purpose of argumentative writing re-visions.
in proceedings of naacl..makoto miwa and yutaka sasaki.
2014. modelingjoint entity and relation extraction with table repre-sentation.
in proceedings of emnlp..meishan zhang, yue zhang, and guohong fu.
2017.end-to-end neural relation extraction with global op-timization.
in proceedings of emnlp..6350a details of argument pair predictor.
a.1 argument predictor.
we cast the task of predicting argument spans as asequence labeling problem.
we adopt conditionalrandom ﬁeld (crf) (lafferty et al., 2001) that as-signs each label sequence a score.
the probabilityfor each sequence (both review and reply) is de-ﬁned as following:.
p(y|s) = exp(score(s,y))(cid:80).
y exp(score(s,y)) ,.
where s represents the original sequence and y isthe gold sequence label encoding argument spansunder the bio scheme (ramshaw, 1995; ratinovand roth, 2009).
the score function is deﬁned as:.
score(s, y) =.
ayi,yi+1 +.
fθ1(s, yi)..n(cid:80)i=0.
n(cid:80)i=1.
a is the matrix with trainable parameters repre-senting transition scores within the crf layer andfθ1 represents the emission scores obtained afterfeeding review sequence and rebuttal sequence intothe multi-cross encoder with parameters θ1.
thenegative log-likelihood loss for both review andreply sequence in each instance is then deﬁned as:.
lseq(a, θ1) = −(cid:0) log p(yrv|srv) + log p(yrb|srb)(cid:1)..a.2 pair predictorgiven table features t(k) and an mlp layer, theprobability that two sentences are from an argu-ment pair can be expressed as following:.
p(ypair = 1|(srv, srb)) =.
11+exp (−fθ2 (t(k))).
..fθ2 is a composite function of linear and relufunctions, the ﬁnal linear function among whichhas an output dimension of 1. the pairing losslpair(θ2, θ1) for each instance is then deﬁned as:.
lpair(θ2, θ1) =.
(cid:16).
− (cid:80).
i,j.
ypairi,j.
log p(ypair.
i,j = 1|srv, srb).
+ (1 − ypair.
(cid:17)i,j ) log(1 − p(ypairi,j = 1|srv, srb))where θ2 are parameters within the mlp layer..,.
note that the attention loss is a function of θ1and the overall loss is a function of θ1, a and θ2.
the formulae provided in the main paper omit therelated parameters for brevity..b more experimental details.
b.1 hyperparameters.
we manually tune the hyperparameter values (e.g.
weight for pair loss λ1, weight for attention loss.
λ2, decaying parameter γ of exponential movingaverage) for our proposed multi-layer multi-crossmodel.
we manually tune the weight for pair lossλ1 from 0.3 to 0.7 with step size of 0.1 (table 4),the weight for attention loss λ2 from 0.5 to 2.5with step size of 0.5 (table 5) and the decayingparamter γ of exponential moving average from0.7 to 1 with step size of 0.1 (table 6) for ourproposed multi-layer multi-cross model.
we selectthe best hyperparameters based on the best f1 scoreachieved on the development set and apply them tothe test set for evaluation.
speciﬁcally, λ1 is set as0.5, λ2 is set as 2, γ is set as 0.9..b.2 running time, number of parametersand results on development set.
table 8 shows the running time, the number of pa-rameters, and the results on the development set ofour models on rr-submission-v1 dataset.
for thebi-cross models, as review sentences and rebuttalsentences are concatenated as one sequence in onesequence encoder during training, the sequencesare generally longer.
thus, the bi-cross modelsrequire a longer running time.
as the number oflayers increases, the performance on the develop-ment set improves yet the performance on the testset becomes worse.
it is plausibly because that themodel might face the overﬁtting issue..b.3 mlp v.s.
cnn.
we replace the mlp module with convolutionalneural networks (cnn) to predict the pairs andcompare their performance on rr-submission-v1dataset.
the comparison results are presented in ta-ble 7. the theoretical advantage of cnn over mlpis that cnn is able to capture surrounding informa-tion with the help of kernels.
however, the experi-ment results show that the convolutional structureperforms worse than the simple mlp structure.
byexamining the kernel weight of the convolutionlayers, we observe no signiﬁcant magnitude differ-ence between the center weights and the peripheralweights.
take a 3x3 kernel as an example, thecenter weights are the weights at the center grid,while the weights located in the rest of the 8 gridsare peripheral weights.
this indicates that cnnaccords way more importance to the surroundinginformation (8 times more important in the case ofa 3x3 kernel) than to the original grid.
the over-emphasis on surrounding information brings toomuch noise to the pair prediction..6351table 4: performance of multi-cross (n=3) when applying different pair loss weights λ1..models.
λ1=0.3λ1=0.4λ1=0.5λ1=0.6λ1=0.7.
models.
λ2=0.5λ2=1λ2=1.5λ2=2λ2=2.5.
models.
γ=1γ=0.9γ=0.8γ=0.7.
argument mining.
sentence pairing.
prec..rec..f1.
prec..rec..f1.
prec..rec..f1.
68.4768.5069.5266.5668.62.
70.6770.6770.0371.8770.20.
69.5569.5769.7769.1269.40.
59.0960.0260.8159.3257.39.
43.0546.0747.1444.9346.39.
49.8152.1353.1151.1351.31.
38.0639.1338.7036.5936.44.argument mining.
sentence pairing.
prec..rec..f1.
prec..rec..f1.
prec..rec..f1.
67.6868.8367.8369.5266.60.
70.2070.1871.0170.0370.72.
68.9269.5069.3969.7768.60.
58.2862.3957.2660.8160.15.
45.8244.8646.4547.1444.72.
51.3052.2051.2953.1151.30.
35.2040.2335.5238.7036.64.argument mining.
sentence pairing.
prec..rec..f1.
prec..rec..f1.
prec..rec..f1.
67.4069.5266.1767.40.
71.1470.0370.7770.18.
69.2269.7768.3968.76.
60.0960.8158.9260.21.
45.1947.1447.4646.43.
51.5953.1152.5852.43.
37.7638.7034.1236.36.ape.
24.9426.9927.9326.2727.27.ape.
26.8326.9927.8827.9326.33.ape.
25.7727.9326.4426.11.
30.1431.9532.4430.5931.19.
30.4532.3131.2432.4430.64.
30.6432.4429.7930.39.table 5: performance of multi-cross (n=3) when applying different attention loss weights λ2..table 6: performance of multi-cross (n=3) when applying different values for the decaying parameter γ of expo-nential moving average..models.
argument mining.
sentence pairing.
ape.
prec..rec..f1.
prec..rec..f1.
prec..rec..f1.
with cnn 65.9169.52with mlp.
71.6870.03.
68.6769.77.
59.5660.81.
44.0147.14.
50.6253.11.
36.7738.70.
26.4427.93.
30.7632.44.table 7: performance of multi-cross (n=3) when adopting cnn or mlp for pair prediction..models.
rt (min) # params ape f1 (dev).
bi-cross (n=1)bi-cross (n=2)bi-cross (n=3)bi-cross (n=4)bi-cross (n=5)multi-cross (n=1)multi-cross (n=2)multi-cross (n=3)multi-cross (n=4)multi-cross (n=5).
3361861041152233445566.
5.7m7.4m9.1m10.8m12.5m5.8m7.4m9.1m10.8m12.5m.
36.2737.2337.1637.1138.3535.0736.6036.6535.2636.72.table 8: running time (rt) per epoch (minutes), num-ber of parameters and the ape f1 score of our modelson rr-submission-v1 dataset..c more experimental analysis.
c.1 case study on attention weights.
each row in table 9 in which the exact gold andpredicted results are shown corresponds to the re-.
spective row in figure 4 in the main paper.
we cansee that instance (1) and instance (2) are perfectlypredicted whereas one predicted reply argumentis shorter than the gold argument in instance (3)and some argument pairs are identiﬁed wrongly ininstance (4)..attention distribution turns out to be stronglyconnected with the ﬁnal output of the model, asattention weights exhibit exactly the same error asthe wrongly predicted argument spans and argu-ment pairs.
in instance (3), we can see from theattention visualization that the review argument atposition 15 only refers to the reply sentences fromposition 14 to 16. the wrong prediction of replyspan (14, 16) (gold: (14, 26)) directly results fromthe inaccurate distribution of attention weights.
forinstance in figure 4 row (4) as highlighted in red,it can also be noticed that some review arguments.
6352sample.
gold reviewarguments.
pred reviewarguments.
gold rebuttalarguments.
pred rebuttalarguments.
gold argumentpairs.
pred argumentpairs.
(1).
(2).
(3).
(4).
(7,9)(10,12)(13,13).
(7,7)(8,11)(12,14)(15,17).
(9,10)(11,13)(14,15)(16,16)(17,18)(19,19)(20,21).
(8,9)(10,12)(13,13)(14,14)(15,15)(16,16)(17,17)(18,18)(19,20)(21,21).
(7,9)(10,12)(13,13).
(7,7)(8,11)(12,14)(15,17).
(9,10)(11,13)(14,15)(16,16)(17,18)(19,19)(20,21).
(8,9)(10,12)(13,13)(14,14)(15,15)(16,16)(17,17)(18,18)(19,20)(21,21).
(2,10)(12,14)(16,24).
(3,4)(6,8)(10,12)(14,18).
(4,5)(7,9)(12,13)(14,26)(29,31)(32,33)(36,38).
(2,5)(6,7)(8,9)(10,10)(11,12)(13,16)(17,18).
(20,21)(22,22).
(2,10)(12,14)(16,24).
(3,4)(6,8)(10,12)(14,18).
(4,5)(7,9)(12,13)(14,16)(29,31)(32,33)(36,38).
(2,7).
(8,9)(10,10)(11,12)(13,16)(17,18).
(20,21)(22,22).
(7,9) - (2,10)(10,12) - (12,14)(13,13) - (16,24).
(7,9) - (2,10)(10,12) - (12,14)(13,13) - (16,24).
(7,7) - (3,4)(8,11) - (5,8)(12,14) - (10,12)(15,17) - (14,18).
(7,7) - (3,4)(8,11) - (6,8)(12,14) - (10,12)(15,17) - (14,18).
(9,10) - (4,5)(11,13) - (7,9)(14,15) - (12,13)(16,16) - (14,26)(17,18) - (29,31)(19,19) - (32,33)(20,21) - (36,38).
(8,9) - (2,5)(10,12) - (6,7)(13,13) - (8,9)(14,14) - (10,10)(15,15) - (11,12)(16,16) - (13,16)(17,17) - (17,18).
(9,10) - (4,5)(11,13) - (7,9)(14,15) - (12,13)(16,16) - (14,16)(17,18) - (29,31)(19,19) - (32,33)(20,21) - (36,38).
(8,9) - (2,7)(10,12) - (8,9)(13,13) - (10,10).
(15,15) - (11,12)(16,16) - (13,16)(17,17) - (17,18).
(19,20) - (20,21)(21,21) - (22,22).
(19,20) - (20,21)(21,21) - (22,22).
table 9: gold and predicted review arguments, rebuttal arguments and argument pairs for four test data samples..review argument.
rebuttal argument.
ape.
80.
60.
40.
20.
1.
2.
3.
4.
5.
6.
>=7.
figure 5: f1(%) scores (y-axis) with different numberof argument pairs (x-axis)..attend to the wrong rebuttal argument and somerebuttal arguments attend to the wrong review argu-ment.
the attention blocks in figure 4 row (4) are(8, 9) - (2, 7), (10, 12) - (8, 9), (13, 13) - (10, 10)and the wrongly predicted argument pairs are also(8, 9) - (2, 7), (10, 12) - (8, 9), (13, 13) - (10, 10).
together with all 4 test instances, the conclusioncan be reached that one-to-one correspondence canbe found in the predicted paired arguments andthe distribution of attention weights.
therefore,the hindrance to further improve the model per-formance comes from the inaccurately allocatedattention weights..c.2 breakdown by argument density.
we further evaluate the multi-cross (n=3) modelperformance on rr-submission-v1 among differ-.
ent numbers of argument pairs in each instance.
figure 5 shows the argument mining performanceon review and rebuttal separately and the overallape performance.
their f1 scores all increase asthe number of argument pairs grows from 1 to 4and reach plateaus afterwards.
the reason is likelyto be that most of the review and rebuttal pairs withabout 4 argument pairs are written in a more for-matted manner and are hence easier to be extracted.
when the number of argument pairs is smaller than3, it is highly likely that authors only reply to one ortwo review arguments.
the irregular format mightincrease the difﬁculty of pair extraction.
whenthe number of argument pairs is larger than aver-age, the f1 score of ape decreases slightly as thestructure becomes more complicated..in addition, we can see from figure 5 that whenthe number of argument pairs is from 2 to 6, thef1 scores of the argument mining subtask betweenreview and rebuttal are very close.
compare to themulti-task model in the previous work (cheng et al.,2020), our model’s performance on the argumentmining subtask between review and rebuttal is morebalanced, which leads to the better overall apeperformance..6353