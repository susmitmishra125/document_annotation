a hierarchical vae for calibrating attributes while generating textusing normalizing flow.
bidisha samantaiit kharagpurbidisha@iitkgp.ac.in.
mohit agrawaliit kharagpurmohit@iitkgp.ac.in.
niloy gangulyiit kharagpurniloy@cse.iitkgp.ac.in.
abstract.
in this digital age, online users expect person-alized content.
to cater to diverse group of au-diences across online platforms it is necessaryto generate multiple variants of same contentwith differing degree of characteristics (senti-ment, style, formality, etc.).
though text-styletransfer is a well explored related area, it fo-cuses on ﬂipping the style attribute polarityinstead of regulating a ﬁne-grained attributetransfer.
in this paper we propose a hierarchi-cal architecture for ﬁner control over the at-tribute, preserving content using attribute dis-entanglement.
we demonstrate the effective-ness of the generative process for two differentattributes with varied complexity, namely sen-timent and formality.
with extensive experi-ments and human evaluation on ﬁve real-worlddatasets, we show that the framework can gen-erate natural looking sentences with ﬁner de-gree of control of intensity of a given attribute..1.introduction.
the ubiquity of online social networks and worldwide web has brought in diverse and often conﬂict-ing groups of users consuming similar informationbut from different perspectives.
so the onus falls onthe content producer to cater customized contentbased on the users’ proﬁle.
consider an exam-ple related to a spanish football (soccer) league.
say the news is “barcelona has defeated realmadrid”.
this news needs to be presented in differ-ent tones to a barcelona fan - “barcelona smashedreal-madrid”, a real-madrid fan - “real madridlost the epic battle” and a (say) villarreal fan -“barcelona wins three points against real-madrid”.
automatic generation of content with ﬁne regu-lation of attributes like sentiment and style is ex-tremely beneﬁcial in this context.
there are severalrelated works in similar space of text-style-transfertechniques (hu et al., 2017; logeswaran et al.,.
2018; shen et al., 2017; singh and palod, 2018)which attempt to switch polarity of a text from,e.g., formal to casual, or positive to negative senti-ment.
however, none of the work focuses on moreinvolved problem of ﬁne-grained regulation of at-tributes to generate multiple variants of a sentence.
several of the existing style-transfer methods (fuet al., 2018; john et al., 2018) convert a continu-ous entangled generative representation space ob-tained using variational auto-encoder (bowmanet al., 2015) into disentangled attribute and contentspace.
it facilitates attribute polarity switch by per-turbing attribute representation without interferingwith context.
however, a disentangled generativerepresentation may result in a loss of informationabout complex inter-dependency of content andattributes otherwise captured in an unmodiﬁed en-tangled generative space.
hence, trivial extensionof the variational inference (encoding) mechanismfor ﬁner attribute control by allowing incrementalperturbation of the attribute representation in thedisentangled generative space often leads to gener-ation of ‘not-so-natural’ sentence mostly unrelatedto the original content..more speciﬁcally, there are two design chal-lenges which need to be tackled to achieve ﬁnegrained attribute control (a) smooth regulation ofattributes via disentangled attribute space perturba-tion and (b) natural sentence generation preservingthe content.
this paper builds up a layered vae totackle these problems simultaneously.
speciﬁcally,we propose the model control text vae (ctvae),that transforms a derived representation of entan-gled and enriched text embedding (obtained usingthe bert encoder) into a disentangled representa-tion of attribute and context using a transformationmodule followed by a factored prior imposition toensure independence between context and attributedimensions.
further using attribute supervisionon the dimension designated for a given attribute,.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2405–2415august1–6,2021.©2021associationforcomputationallinguistics2405we establish a correlation between the continuousrepresentation to the discrete attribute value facil-itating smooth interpolation as intended in (a).
itpreserves both the disentangled and entangled rep-resentations in different hierarchy of inference mod-ule.
designing the transformation network as re-versible, it restores the original entangled sentencerepresentation which is our generative space, fromthe disentangled space to achieve (b)..we demonstrate the effectiveness of ctvae togenerate controlled text by ﬁne tuning two differentattributes namely sentiment and formality.
usingﬁve publicly available datasets, we show that ct-vae improves the performance signiﬁcantly overprevious controlled text generative models whileperforming content preserving style transfer andﬁne tuning of the target attribute.
with human eval-uation on generated sentences, for three differentmetrics - meaning preservation, degree of targetattribute transfer and naturalness - we show thatctvae can generate attribute regulated contentpreserving natural sentences.
1.
2 related work.
unlike style-transfer, ﬁne grained attribute regu-lated text generation is less explored yet extremelynecessary.
state-of-the-art methods for style trans-fer are categorized as supervised and unsupervisedtechniques.
if parallel examples are available forany attribute, i.e., training data consisting of origi-nal and corresponding attribute ﬂipped sentences,then supervised techniques (bahdanau et al., 2014;vaswani et al., 2017) could be used to performstyle transfer.
the papers (xu et al., 2012; jham-tani et al., 2017; rao and tetreault, 2018) intro-duced parallel corpora consisting of formal andcorresponding informal sentences and showed thatcoarse-grained formality transfer is possible andbenchmarked various neural frameworks for thesame.
generating parallel training corpus for ﬁnegrained attribute transfer is expensive and impracti-cal as for one sentence we need to generate multiplestyle transferred text bearing ﬁne-grained attribute.
some recent works focus on semi-supervised ap-proaches incorporating attribute informations withnon-parallel datasets.
these techniques mainly fo-cus on disentangling the attribute and content repre-sentation in the latent space (fu et al., 2018; johnet al., 2018; logeswaran et al., 2018; shen et al.,.
1https://github.com/bidishasamantakgp/.
ctvae.
2017; singh and palod, 2018) by using differentencoding modules along with feature supervision.
a recent work (john et al., 2018) uses adversarialsetup in a multitasking setting to achieve attributerepresentation independent of the content.
as thiswork disentangles context and attribute in multi-dimensional spaces it limits interpolation of theattribute space to desired degree.
moreover, thedisentangled generative space causes loss in im-portant context.
similarly, the paper (hu et al.,2017) uses attribute information as a structured orone-hot vector, which is not continuous restrictinginterpolation.
they replace the attribute representa-tion to a desired value (corresponding to oppositepolarity) and generate sentences from this disen-tangled space.
however, a naive extension for ﬁnegrained control by perturbing the attribute spaceby a small amount is difﬁcult as the representationis multidimensional moreover, leads to unnatural,poorly readable sentence..from a different perspective, a recent work (heet al., 2020) proposed an unsupervised frameworkto achieve style transfer.
they propose a generativeprobabilistic model that assumes non-parallel cor-pus as partially observed parallel corpus.
they donot infer posterior distribution of the observed data,hence ﬁne grained attribute transfer is difﬁcult..as the extensions of current style transfer meth-ods are non-trivial, a recent work (wang et al.,2019) has proposed ﬁne grained sentiment regula-tion keeping the content intact.
it gradually updatesthe entangled latent representation using costly fast-gradient-iterative modiﬁcation until it can gener-ate a sentence entailing target attribute from that .
however, overemphasis on content preservation of-ten results in generation of the original unmodiﬁedsentence followed by new phrases bearing targetattribute.
this is not ideal to extend them for moredifﬁcult attributes like casual to formal transforma-tion.
understanding the criticality of ﬁne grainedattribute transfer, we propose a new framework to-wards this direction, which does not only facilitateﬁne-grained control even for complex attributes,but is also able to mitigate the existing problems ofdisentangled generative space..3 ctvae for fine grained control.
we propose a hierarchical model using variational(kingma and welling, 2013) toautoencodersachieve ﬁne grained control over attribute spacewhile maintaining the quality of the generated sen-.
2406figure 1: the architecture of ctvae.
the encoder module (a) takes a word sequence x and converts obtainedbert embedding to a continuous space zs.
using t transformation modules zs is converted to zf and assignsthe last dimension of zf for attribute representation za.
the decoder (d) samples zf from prior or posterior.
itdecodes categorical attribute from za and reverse transforms zf to zs.
and use it to generate word sequence x.the grey block indicates a single transformation step which is reversible (b indicates forward and c reverse)..tences.
we provide a high level overview of ct-vae along with key technical aspects of the indi-vidual components followed by training procedure..3.1 model overview.
we consider an input set x = {x0, · · · , xm −1} ofm observed sentences sampled from some under-lying unknown data distribution pd.
along withthe sentences, we observe ground truth attribute,f = {f0, · · · , fm −1} where fi is associated tosentence xi.
for ease of reference, we will hence-forth denote a training instance xi and fi by x andf respectively.
detailed architectural overview ofctvae is depicted in figure 1, which can be di-vided into two modules consisting of a hierarchicalencoder and a corresponding hierarchical decoder.
we start by describing the inference model (en-coder) followed by the generation model (decoder)..3.2.inference model.
the inference model is designed as a bottom-up hi-erarchical encoder with two distinct layers for mod-elling word sequence representation zs, and featurerepresentation zf .
we model an enriched sentencerepresentation zs ∈ rd with latent dimension sized from word sequence x as follows.
we ﬁrst obtainthe contextual word embeddings for each word win x from the bert pre-trained model (turc et al.,2019).
then, we generate an aggregated encodinges by taking an average of them.
finally, we trans-form it into a continuous d dimensional gaussianspace using a fully connected neural network gφ bythe following two steps..[µs, σs] = gφ(es)qφ(zs|x) = n (µs, diag(σ2.
s )),.
(1).
(2).
the sentence representation zs is sampled fromthis posterior distribution qφ(zs|x).
it is an entan-gled complex manifold of different salient featurespresent in multiple dimensions.
this enriched rep-resentation is the generative representation as wedecode sentences from zs for better quality..next, we transform the sentence representationzs into another representation zf on which weimpose disentanglement constraints followed byattribute supervision such that zf could be de-composed into independent space of context andattribute.
we need an efﬁcient transformation tomaintain the inherent dependencies between thecontext and attribute during this process.
also it isimportant to restore enriched zs from decomposedzf i.e.
to capture the reverse dependency.
insteadof modeling two different transformation networksto capture the dependency in both ways, we designa single reversible transformation module.
it guar-antees that given a zf , we getback an appropriateentangled zs useful for natural sentence generation..hence, we build our transformation networkextending r-nvp (dinh et al., 2016) which isa reversible auto-regressive normalizing ﬂow toachieve mentioned interdependency and inversion.
speciﬁcally, we split zs into two parts.
the ﬁrstd − 1 dimensions of the zs is dedicated to modellatent factors important for context modelling.
therest of the (last) dimension is used to derive a rep-resentation for the speciﬁed attribute.
the detailedinterconnection between them in one transforma-tion step is depicted in figure 1(b).
we obtainzf by t transformation steps, where t is a hyperparameter.
in a transformation step t we obtaina representation distribution qt(zt|zt−1), which ischaracterized as the ordered set of following opera-.
2407𝝁𝝈𝓧𝒘𝒘𝐳𝐳𝐳𝒇𝒇𝒇𝐳𝐳𝐳𝒇𝒇𝒇𝐳𝐳𝐳𝒇x,+𝜓1𝜓2x,+𝐳𝐳/,-𝜓2/,-𝒇𝜓1tions:.
1, σt.
t (zt−1(1:d−1)).
[µt1] = ψ1zt(d) = zt−1(d) · σt2] = ψ2[µtt (zt(d))zt(1:d−1) = zt−1(1:d−1).σt.
1 + µt1.
2, σt.
2 + µt2,.
(3).
(4).
(5).
(6).
the eq.
(4) describes intuitively that the attributerepresentation ﬁeld is dependent on ﬁrst d − 1 di-mensions or context.
the eq.
(6) encodes howcontext is inﬂuenced by the attribute.
here, ψ1tand ψ2t are designed as multilayer fully connectedfeed-forward networks which are not invertible.
however, a careful inspection of eqs.
(4) and (6)reveals that given a zt, the input zt−1 can be fullyrecovered.
we provide the reverse transforma-tions in the next subsection.
thus, we can getqφ(zf |zs) := qφ(zt |zs) and we assign zf := zt .
we pick the dth (last) dimension of zf to modelspeciﬁed attribute representation za.
to facilitatesmooth interpolation in this attribute space, wekeep za as unidimensional.
we further use attributesupervision to establish the correlation with cate-gorical values of the attribute.
we will discussthe process in the next subsection.
the rest ofthe dimensions of zf are kept for other contextualfeatures zu.
we discuss about disentanglement ofzf in sec.
3.4. the overall posterior distributionachieved by the hierarchical inference mechanism:.
qφ(z|x) = qφ(zs|x)(cid:124)(cid:125)(cid:123)(cid:122)entangled.
qφ(zf |zs)(cid:124)(cid:125)(cid:123)(cid:122)disentangled.
(7).
3.3 generative model.
we design our generative model pθ using a top-down hierarchy, with two different variables zs andzf .
the overall distribution of the latent variablesfor the generation is deﬁned as:.
pθ(z) = pπ(zf )(cid:124) (cid:123)(cid:122) (cid:125)disentangled.
pθ(zs|zf )(cid:123)(cid:122)(cid:125)(cid:124)entangled.
(8).
i=1 pπ(zi.
here pπ(zf ) is a factored prior of the feature repre-sentation zf , which can be expressed as pπ(zf ) =(cid:81)df ).
we use a standard normal distribu-tion, which is a factored isotropic distribution, asprior, i.e., pπ(zf ) = n (0, i).
imposing this fac-tored prior enforces disentanglement(kim andmnih, 2018) on the derived space qφ(zf |zs).
asdiscussed in the previous section, we have desig-nated the last dimension of the zf to capture any.
attribute of interest, and remaining dimensions forother contextual features.
henceforth, attribute rep-resentation prior can be sampled from pπ(zdf ) andother contextual features prior representations canbe sampled from (cid:81)d−1i=1 pπ(zif ).
we use feature su-pervision on za to increase the correlation betweenthe representation and the attribute value as follows.
given za, we decode the categorical attribute valueof the given sentence x and back propagate theloss of prediction to modify the network parame-ters.
more speciﬁcally, the decoding distributionfor the ground truth attribute is.
pθ(f |za) = categorical(ξ(za)).
(9).
here ξ is a scaling network to convert the singu-lar value za into a logit vector corresponding tocategorical values of ground-truth attribute.
next,the network tries to decode the entangled distribu-tion zs from the disentangled distribution zf .
weapply the reverse transformation ﬂow to recoverzs using t inverse transformations.
starting fromzf (zt ), we recover zs by reverse transformationsteps pt(zt−1|zt), as a set of ordered operations:.
[µt.
2, σt.
2] = ψ2.
t (zt(d)).
zt−1(1:d−1) =.
[µt.
1, σt.
1] = ψ1.
zt−1(d) =.
zt(1:d−1) − µt2σt2.,.
t (zt−1(1:d−1))zt(d) − µt1σt1.
(10).
(11).
(12).
(13).
t , σ2t , ψ2.
the eq.
(11) is the reverse transformation corre-sponding to the eq.
(6).
similarly eq.
(13) de-ﬁnes the reverse ﬂow of eq.
(4).
it may be notedthat µ1t and σ1t , µ2t are derived from the sameneural network ψ1t as eqs.
(3), (5).
hence,given a zt we can easily get back zt−1 without anyloss of information.
thus we get zs := z1.
fol-lowing the density estimation theory (dinh et al.,2016), the log probability density of pθ(zs|zf ), i.e.,log pt (zs|zf ) denoted as:.
log pπ(zf ) −.
log det.
(14).
t(cid:88).
t=1.
dftdft−1.
where ft denotes transformation function at step tdescribed in eqs.
(3)- (6).
finally, with the decodedzs, we sample the word sequence x(j) using arecurrent unit as follows:.
x(j) ∼ softmax(mθ(h(j))).
(15).
2408here h(j) = rθ(x(j − 1), zs) is the hidden stateof gated recurrent unit rθ which takes the previ-ously generated token x(j − 1) and the sentencerepresentation zs.
then we pass this hidden stateinformation to a feedforward network mθ to gener-ate logits.
subsequently, we sample words basedon the softmax distribution of the generated logits.
the joint likelihood of the sentence, features, andthe latent variables pθ(x, f , zs, zf ):.
= pθ(x|zs)pθ(f |za)pθ(zs|zf )pπ(zf ).
(16).
3.4 training.
we can learn the model parameters by optimizingthe joint likelihood given in eq.(16).
to learn thecomplex transformation of disentangled attributeand context in zf from entangled zs precisely, weneed to ﬁrst estimate the approximate posteriorqφ(zs|x) accurately.
however, in the initial it-erations of training the encoder fails to approxi-mate the posterior distribution (he et al., 2019).
hence, we ﬁrst train the lower layer by maximizingelbo (kingma and welling, 2013) :.
eqφ(zs|x)log pθ(x|zs) − kl(qφ(zs|x)||pθ(zs|zf ))(17).
this is an unsupervised training as we are not usingany attribute information and this objective helpsto update encoder parameters to generate entangledzs.
once the lower layer is trained, we update thetransformation parameters (eq.
(14)) and imposefeature supervision by maximizing the marginallikelihood of zf given below:.
(cid:104)βlog pθ(f |za) + log pπ(zf )− (18).
eqφ(zf |zs)t(cid:88).
log det.
t=1.
(cid:105).
dftdft−1.
− αkl(qφ(zf |zs)||pπ(zf )).
where α and β are regularizing parameters to en-force disentanglement of zf and emphasize onattribute supervision respectively.
if we break-down the kl term of the above objective func-tion as ez∼qφ(zs)i(zs, zf ) + kl(qφ(zf )||pπ(zf )),we get total correlation loss kl(qφ(zf )||pπ(zf )),minimizing which the model achieves disentangle-ment on zf along the dimensions (higgins et al.,2017).
also, the mutual information i(f, za) be-tween speciﬁed attribute and za can be computedusing entropy function h(.)
as h(f )−h(f |za) ≥.
dataset.
attributesentiment yelp (wang et al., 2019)sentiment amazon (wang et al., 2019)sentiment gab (qian et al., 2019)formalityfamily (rao and tetreault, 2018)formality music (rao and tetreault, 2018).
# sentences avg.
len vocab16k443k18k554k29k36k41k1m35k1m.
1535352525.table 1: the statistics of different datasets..ex∼pd [eqφ(zs|x)qφ(za|zs)log pθ(f |za)],is lowerbounded by the likelihood pθ(f |za), hence, weemphasise on the likelihood term in the objectivefunction using β to maintain higher correlationbetween za and f .
thus we update the networkparameters phase by phase using eqs.
(17) and(18)..4 experiments.
we broadly looked into two evaluation criteria tocompare the performance of different generativemodels (a) attribute control: efﬁciency in gener-ating sentences entailing target attribute of interest(b) fine-grained transfer: efﬁciency of contentpreserving ﬁne-grained attribute regulated text gen-eration.
in this section we discuss datasets, base-lines followed by the performance across datasets..4.1 datasets.
we focused on two attributes of varied complexity,namely, (a) sentiment and (b) formality.
in table 1we describe the datasets in detail.
for sentiment weinclude two review datasets and one hate-speechdataset.
the gab dataset is designed for counter-hatespeech learning and every hateful sentence hasa candidate counter hate-speech.
we consider themas non-hateful (nh) class of content.
thus we havetraining examples with hateful (h) and non-hateful(nh) contents.
the formality datasets have formal(f) and corresponding casual (c) instances.
wereport all the results on the test data provided..4.2 baseline methods.
we compare ctvae performance with semi-supervised method - (a) ctrlgen (hu et al., 2017),supervised method -(b) dae (john et al., 2018)that focus on text-style-transfer using disentangle-ment, and unsupervised method (c) probstyle-transfer (he et al., 2020).
we also compare with(d) entanglegen (wang et al., 2019) which focuseson ﬁne-grained style transfer using entangled rep-resentation.
apart from these state-of-the-art base-lines, we inspect (e) ctvae-nr (ctvae non-reversible transformation) where we replace the in-vertible transformations of ctvae with two sepa-rate transformation networks responsible to captureqφ(zf |zs) and pθ(zs|zf ).
for different evaluation.
2409yelp.
sentiment.
amazon.
methods.
controlgen..styleinversion.
controlgen..styleinversion.
controlgen..ctrlgendaeprobtransentanglegenctvae -nrctvae.
0.720.95--0.820.95.
0.52 (0.71)0.49 (0.55)0.63 (0.80)0.83 (0.86)0.51 (0.60)0.72 (0.88)*.
0.620.84--0.69*0.84.
0.65 (0.66)0.32 (0.43)0.40 (0.98)0.67 (0.95)*0.40 (0.57)0.72 (0.97).
0.500.98*---0.98.formality.
gab.
style inversion.
h - nh0.22 (0.52)0.12 (0.51)0.02 (0.02)0.55 (0.97)*-0.58 (0.93).
nh-h0.30 (0.73)*0.05 (0.05)0.01 (0.05)0.16 (0.72)-0.31 (0.98).
controlgen..0.630.69*---0.79.music.
style inversion.
c - f0.18 (0.40)0.07 (0.30)0.22 (0.62)*0.11 (0.54)-0.40 (0.62).
f-c0.21 (0.52)0.24 (0.32)0.44 (0.68)*0.34(0.54)-0.53 (0.77).
controlgen..0.600.71*---0.87.family.
style inversion.
c -f0.21 (0.50)*0.12 (0.39)0.19 (0.71)0.19 (0.45)-0.28 (0.73).
f-c0.38 (0.65)0.30 (0.31)0.55 (0.64)*0.37 (0.61)-0.58 (0.85).
table 2: controlled generation and style inversion (related content) accuracy achieved by different methodsacross datasets for τ = 0.71. the best performer is highlighted in bold, second best indicated by *..criteria we compare ctvae with different subsetsof these methods described in relevant sections..4.3 performance on attribute control.
experimental setup: we estimate the average rep-resentation value of za corresponding to each cat-egorical (binary) value for an attribute of interestas zmax and zmin from training data.
we generateattribute controlled sentences in two ways.
first wesample a generative representation vector from theprior distribution (i.e., pθ(zs|zf ∼ n (0, i)) andassign either zmax or zmin to za.
we sample 10sentences from a representation and select the onewhich bears the target attribute.
if there is no suchsample generated we consider it as a failure case.
similarly, we assign zmax or zmin to za dependingon the target attribute to posterior representation ofa given sentence x. we sample 10 sentences fromthat and select the one most similar with x (bertembeddings having cosine similarity greater thanτ = 0.71) and entails the target attribute.
if we failto ﬁnd any candidate following both the criteria weconsider that a miss.
we identify the generated sen-tences with target attribute using a classiﬁer buildby extending bert and train on different datasets.
we investigate multiple cosine similarity thresh-olds τ (0.65 to 0.75 with granularity 0.01).
weobserve the generated sentences having cosine sim-ilarity with original sentence less than 0.7, don’tcontain important context words.
on contrary, weobserve all methods except ctvae and entan-gledgen were able to generate only a very smallnumber of candidates with high similarity scores(>0.73).
to provide a fair comparison we keep τat 0.71 for all datasets across all methods.
metrics: we report controlled generation accu-racy, i.e., percentage of generated sentences fromprior bearing target attribute and style inversion ac-curacy, i.e., the percentage of generated sentencesfrom posterior bearing target attribute and relatedcontent.
we also report percentages of related con-tent generation for style inversion.
we report meanperformance of each model trained with three ran-.
dom initialization.
baselines: we report ctrlgen and dae for bothmetrics as they can sample generative representa-tion from both prior and posterior.
whereas en-tanglegen and probtrans can only generate sen-tences corresponding to a given posterior, we com-pare them only for style inversion..4.3.1 sentiment control.
we report controlled generation accuracy and styleinversion accuracy for yelp, amazon and gab intable 2. it can be observed that ctvae outper-forms all competing methods across three datasetsfor controlled generation.
the superior perfor-mance of ctvae stems from the fact that attributesupervision on disentangled representation helps toachieve better control of attributes than the semi su-pervised ctrlgen.
dae which is also an attributesupervised technique performs exactly same likeours.
ctvae effectively generates more relatedcontent than others and achieves best accuracy forstyle inversion in amazon and both hateful to non-hateful (h-nh) and non-hateful to hateful (nh-h)transitions for gab.
it is the second best in yelp.
dae, along with ctrlgen, uses disentangled gener-ative space which often causes content informationloss.
hence, they generate less related content withrespect to other methods which leads to a dropin accuracy for style inversion.
entanglegen per-forms best for style inversion for yelp and secondbest in other datasets.
it achieves relatively lowaccuracy even after producing larger amount of re-lated content.
it uses bert embedding space tosearch for a candidate embedding closest to theoriginal sentence for style inversion.
as yelp con-tains shorter coherent sentences it is easy to ﬁndrelated yet opposite polarity sentence embeddingwhereas for gab the h and nh sets are quite dif-ferent and their representation spaces are far fromeach other causing poor performance.
the unsu-pervised method probtrans performs well in rel-atively simpler dataset yelp and amazon however,fails to generate related content for complex gab.
2410(a) sentiment (yelp).
(b) sentiment (amazon).
(c) sentiment (gab).
(d) formality (music).
(e) formality (family).
figure 2: the variation of relatedness (r) and attribute polarity scores (ap) with respect to attribute controlgrades in f across datasets.
as we move from f1 to right ctvae generate sentences with monotonic increase inap maintaining high r. −f1 the ap decreases monotonically.
for m usic the variation of ap is not consistent..and scores the lowest.
as converting a counter-hatespeech to hateful content is difﬁcult, all meth-ods perform poorly.
the performance of ctvae-nr is signiﬁcantly inferior compared to ctvae.
close inspection reveals that even though at train-ing we achieve very low kl between qφ(zf |zs)and pθ(zs|zf ), the decoded zs is not exactly thesame as the encoded distribution.
thus, it performspoorly in style inversion..4.3.2 formality control.
from the table 2, we can see that ctvae per-forms best in both m usic and f amily datasets forall metrics.
conversion of a casual sentence intoformal (c-f) is more difﬁcult as it would requiresome structural change of the sentence, whereasthe reverse transformation (f-c) is easy.
thoughthe disentangled based methods perform better forc-f relatively than f-c conversion, overall theyperform poorly as they are unable to generate re-lated content after perturbing disentangled gener-ative space for the same.
entanglegen also per-forms poorly in both the datasets for both c-f andf-c. as a pair of formal and corresponding infor-mal sentences have very high content overlap, onlystructure, capitalization etc are different, in thebert representation space they become very close.
the generative model for entanglegen generatessentences from this representation space, hence itcannot distinguish much on smaller change of rep-resentation.
it confuses the generative model and itgenerates the original sentence as it is very often.
unlike gab, probtrans performs better than allsemi-supervised methods along with entanglegeneven though formality is a difﬁcult attribute like.
hatred.
as the formality datasets are parallel data,probtrans can accurately estimate the latent vari-ables for them which otherwise is difﬁcult.
hence,they learn to successfully generate style invertedtext given parallel sentence..4.4 signiﬁcance test.
we perform student t-test with signiﬁcance level0.05 and report expected p-values with closestbaseline following reimers et al.
(reimers andgurevych, 2018) for two tasks i.e controlled gener-ation and style inversion..for controlled generation we ﬁnd the p-valuesper dataset as follows.
for yelp the p-value is 0.009compared against ctrlgen, for amazon 0.019 withrespect to ctrlgen, gab 0.015 with ctrlgen, mu-sic 0.012 against dae and for family the p-valueis 0.008 compared with dae.
in ﬁrst three datasets,dae and ctvae performs exactly same.
simi-larly, for style transfer we obtain the p-values asfollows.
for amazon it is 0.028 in comparison toentanglegen, in gab for (h-nhs) we get 0.028compared against entanglegen and for (nhs-hs)it is 0.032 in comparison to ctrlgen.
music (c-f) yields 0.002 and (f-c) yields 0.017 with prob-trans, for family (c-f) for 0.024 against ctrlgenand for (f-c) 0.030 compared against probtrans..4.5 fine grained attribute control.
experimental setup: we evaluate the perfor-mance of ﬁne grained attribute control as follows.
we create a set with n equidistant values betweenzmin to zero denoted as {−fi} and another n val-ues between zero to zmax denoted as {fi}.
the.
2411entanglegenapentanglegenrctrlgenapctrlgenrctvaeapctvaer-f4(negative)-f3-f2-f1f1f2f3f4(positive)f0.100.150.200.250.300.35r0.00.10.20.30.40.50.60.70.80.9ap-f4(negative)-f3-f2-f1f1f2f3f4(positive)f0.100.150.200.250.300.350.40r0.00.20.40.60.81.0ap-f4(non-hateful)-f3-f2-f1f1f2f3f4(hateful)f0.30.40.50.60.70.80.91.0r1.01.52.02.53.03.5ap-f3(casual)-f2-f1f1f2f3(formal)f0.00.10.20.30.40.50.60.70.80.9r1.41.61.82.02.22.42.62.8ap-f3(casual)-f2-f1f1f2f3(formal)f0.00.10.20.30.40.50.60.70.80.9r0.51.01.52.02.5apentanglegen.
ctrlgen.
ctvae.
f original sentence: every encounter i have had with her ... she is always rude or angry.
..attribute transfer: negative to positive sentimentf1 every encounter i have had with her ... she is always.
f2 i love purchasing i have easy with her who has al-.
i always get the burger because i haveliked it.
i have always have vegetarian suite..f3 i love purchasing i have easy with her who has al-.
excellent, their food is always...friendly or angry..ways friendly and fun..ways friendly and fun..she is always angry and she has with her ... andshe is rude.
she is always friendly and she is her ... i thinkthat it is absolutely outstanding ..she is always outstanding and i completely rec-ommend her ... with her food..f original sentence: yep, full retard .. political grandstanding.
f1.
f2.
attribute transfer: hateful to non-hateful.. in order for little, the biggest straight humanswho think it really does n’t help anyone to clean uptheir offensive terms.
.. in order for little, the biggest straight humanswho think it really does n’t help anyone to clean uptheir offensive terms..f3 .. in order for little, the biggest straight humans whothink it really does n’t help anyone to clean up theiroffensive terms..its inappropriate behavior prior to usethose phrases that..lol, full retard on politics ... thanks..its inappropriate behavior prior to use ’retarded ’ ...lol, no.
please know your political opinions.
thanks..a word is highly offensive to those com-pletely uncalled for..not sure of your political points.
thanks..table 3: sentences generated corresponding to sentiment control grades f. greater i denotes greater perturbation..union set f represents attribute control grades.
greater indices indicate higher perturbation in theattribute representation space and the sign denotesthe direction.
given a posterior representation zfof a sentence x, we assign za to a value from fkeeping zu ﬁxed and decode a zs from that.
wegenerate 10 sentences from it and select the sen-tence whose bert embedding is closest to the orig-inal sentence as well as bears target attribute value.
we repeat this for all values in f. we considerequivalent set f with n values for entanglegenwith different increasing modiﬁcation weights wwhich they used for ﬁne grained attribute controlin the original paper and generate sentences corre-sponding to that.
though ctrlgen does not supportﬁne-grained transfer, we extended it by interpolat-ing between two structured attribute representationvector [0,1] and [1, 0] and generating real valuedvectors in f where each vector summed to one.
foreach attribute representation vector, we generatesentences from them similar to ctvae.
as, othermodels cannot be extended for the same, we do notcompare their performance here.
metrics: we report attribute polarity score apwhich estimates degree of attribute polarity of agenerated sentence and a relatedness score r cap-turing the relatedness with the original sentence..for review datasets yelp and amazon, ap isobtained from a pre-trained stanford regressormodel (socher et al., 2013) normalized between0 (most negative) and 1 (most positive).
a pi-lot study on randomly picked 25 sentences showsthat the pre-trained regression score is highly co-related (spearman’s rank correlation 0.68) with hu-man judgements.
we report r as jaccard overlap(tustison and gee, 2009) of unigrams between orig-inal and generated sentence excluding stop words.
for these datasets.
however, for other three datasetsthe correlation observed is low.
hence, we resortto human evaluation via crowdﬂower platform 2.given a test sentence, we generate n sentencescorresponding to n different grades in the set fand ask three annotators to rank these sentencesfrom 1 to n. we get the average rank for this in-stance and repeat for all test sentences to obtainaverage ranks as ap corresponding to each of then values.
we ask them to provide an absolute scorefor relatedness (r) of the generated sentences withrespect to the original sentence in a scale of 1 to10, 1 being least related, we rescale it and presentthe result in the scale of 0 to 1. a coherent schemewould see monotonic change in value of ap withattribute control grades varying from −fn to fnand the value of r staying close to one throughout..4.5.1 fine-grained sentiment controlwe demonstrate the performance of generativemodels on one review dataset yelp and hatespeechdataset gab in figure 2(a), (b) respectively.
weshow the variation of attribute polarity ap and re-latedness score r with n = 4. we can observe thatthere is a smooth increase in ap as we move fromf1 to f4 (denoting greater shift from original zavalues towards zmax ) while achieving consistentlyhigh r for ctvae in both the datasets.
simi-larly as we move from −f1 to −f4 ctvae showsmonotonic decrease in ap still achieving highestr. though a similar pattern is observed in ctrl-gen in yelp, it has extremely poor r score whichdenotes that it generates unrelated sentences in theprocess of ﬁne-grained attribute regulation.
more-over, it shows minimum variation in sentimentscore thoughout the process.
in contrast, entan-.
2www.appen.com.
2412glegen achieves highest r score as they focus oncontent preservation, however, the sentiment scoretransition is uneven and doesn’t follow the desiredcoherency.
ctrlgen shows minimum variation insentiment score thoughout the process.
in contrast,ctvae successfully maintains a balance for re-latedness and attribute control.
it can be observedthat ctvae shows a monotonic transition as wemove from left to right denoting higher degree ofattribute representation change for amazon whileother methods show haphazard changes..in gab ctrlgen shows abrupt change in apand lowest score for r which demonstrates veryless control towards ﬁne-tuned attribute regulationfor hatred ﬁltering.
though entanglegen achievedlowest score in ap, signifying it can more accu-rately remove hateful content than ctvae, thevariation is not monotonic.
further inspection re-veals that entanglegen mostly generates counterhate-speech as bert representation clusters h andnh for gab locate in two distant spaces.
hence,the relatedness r of the generated sentences is low.
in contrast, ctvae successfully maintains a bal-ance for relatedness and attribute control in both..4.5.2 fine-grained formality control.
we experiment with n = 3 equidistant values ineach direction in f and report the performance onm usic and f amily dataset in figure 2 (d,e).
itcan be observed from the ﬁgure that all the methodsreceived a similar ap score, around 2.0, for c-ftransformation from f1 to f3.
also, as we move toright after f1, the changes in ap are inconsistentfor ctvae and entanglegen.
however ctvaeachieves relatively better formality score thoughout.
entanglegen achieves best r and low ap due togeneration of original content verbatim very often.
ctrlgen shows lowest relatedness and achieves atransfer score ap = 1.5 on average, that is, overallit fails to generate formal sentences.
moving to-wards casual transition, i.e., from −f1 to −f3 weobserve a similar trend for ctvae and entangle-gen. though the variation with respect to attributecontrol grades in f is abrupt, we achieve the low-est ap, i.e., most informal sentences.
ctrlgenperforms very poor with respect to all the methods.
for f amily there is no trend in ap found.
ct-vae maintains high r, whereas ctrlgen was ableto achieve lowest relatedness score..4.6 fluency.
we also investigate the ﬂuency of these methodsacross datasets reported in table 4 and found thatctvae produces very high percentage ﬂuent sen-tences similar to entanglegen.
as we have ob-served, entanglegen tends to copy the content forformality datasets because the formal and casualsentences lie close in the representation space, theﬂuency is high.
similarly for gab dataset, as ittends to generate counter-hatespeech the ﬂuencyremains high..methodsctrlgenentanglegenctvae.
yelp amazon gab music0.600.700.800.800.800.79.
0.590.710.71.
0.430.640.58.family0.320.800.75.table 4: percentage of ﬂuent sentences generated in theﬁne grained attribute transition process.
finally, table 3 provides examples of ﬁnegrained sentiment and hatred regulated sentencesgenerated by ctvae, entanglegen, and ctrlgen.
we observe that entanglegen generally produceslong sentences, sometimes copies the original con-it produces same sentence multiple times.
tent.
on the other hand, ctrlgen mostly generates sen-tences hardly related with the original content.
incontrast, ctvae can generate related sentencesand provides ﬁner attribute variation, controlled byfi..5 conclusion.
the major contribution of this paper is to proposectvae which consists of a carefully designedhierarchical architecture facilitating disentangledrepresentation to control attribute without affectingcontext as well as enriched entangled generativerepresentation for meaningful sentence generation.
the invertible normalizing ﬂow as a transforma-tion module between the two representation of ct-vae enables learning of complex interdependencybetween attribute and context without the loss ofinformation.
such a design choice is key to achiev-ing accurate ﬁne tuning of attributes (be it senti-ment or formality) while keeping the content intact.
this is a key achievement considering the difﬁ-culty of the problem and modest performance ofstate-of-the-art techniques.
extensive experimentson real-world datasets emphatically establish thewell-rounded performance of ctvae and its su-periority over the baselines..2413sudha rao and joel tetreault.
2018. dear sir ormadam, may i introduce the gyafc dataset: corpus,benchmarks and metrics for formality style transfer.
in proceedings of the 2018 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long papers), pages 129–140..nils reimers and iryna gurevych.
2018. why com-paring single performance scores does not allowto draw conclusions about machine learning ap-proaches.
arxiv preprint arxiv:1803.09578..tianxiao shen, tao lei, regina barzilay, and tommijaakkola.
2017. style transfer from non-parallel textby cross-alignment.
in advances in neural informa-tion processing systems, pages 6830–6841..ayush singh and ritu palod.
2018. sentiment trans-fer using seq2seq adversarial autoencoders.
arxivpreprint arxiv:1804.04003..richard socher, alex perelygin, jean wu, jasonchuang, christopher d manning, andrew ng, andchristopher potts.
2013. recursive deep modelsfor semantic compositionality over a sentiment tree-in proceedings of the 2013 conference onbank.
empirical methods in natural language processing,pages 1631–1642..iulia turc, ming-wei chang, kenton lee, and kristinatoutanova.
2019. well-read students learn better:on the importance of pre-training compact models.
arxiv preprint arxiv:1908.08962v2..nj tustison and jc gee.
2009. introducing dice, jac-card, and other label overlap measures to itk.
insightj, 2..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allin advances in neural information pro-you need.
cessing systems, pages 5998–6008..ke wang, hang hua, and xiaojun wan.
2019. control-lable unsupervised text attribute transfer via editingentangled latent representation.
in advances in neu-ral information processing systems, pages 11034–11044..wei xu, alan ritter, bill dolan, ralph grishman, andcolin cherry.
2012. paraphrasing for style.
in pro-ceedings of coling 2012, pages 2899–2914..references.
dzmitry bahdanau, kyunghyun cho, and yoshua ben-gio.
2014. neural machine translation by jointlyarxiv preprintlearning to align and translate.
arxiv:1409.0473..samuel r bowman, luke vilnis, oriol vinyals, anddai.
2015. generating sentences from a continuousspace.
arxiv preprint arxiv:1511.06349..laurent dinh, jascha sohl-dickstein, and samy ben-gio.
2016. density estimation using real nvp.
arxivpreprint arxiv:1605.08803..zhenxin fu, xiaoye tan, nanyun peng, dongyan zhao,and rui yan.
2018. style transfer in text: explo-ration and evaluation.
in thirty-second aaai con-ference on artiﬁcial intelligence..junxian he, daniel spokoyny, graham neubig, andtaylor berg-kirkpatrick.
2019. lagging inferencenetworks and posterior collapse in variational au-toencoders.
arxiv preprint arxiv:1901.05534..junxian he, xinyi wang, graham neubig, and taylorberg-kirkpatrick.
2020. a probabilistic formulationof unsupervised text style transfer.
arxiv preprintarxiv:2002.03912..irina higgins, loic matthey, arka pal, christopherburgess, xavier glorot, matthew botvinick, shakirmohamed, and alexander lerchner.
2017. beta-vae:learning basic visual concepts with a constrainedvariational framework.
iclr, 2(5):6..zhiting hu, zichao yang, xiaodan liang, ruslansalakhutdinov, and eric p xing.
2017. towardin proceedingscontrolled generation of text.
of the 34th international conference on machinelearning-volume 70, pages 1587–1596.
jmlr.
org..harsh jhamtani, varun gangal, eduard hovy, and ericnyberg.
2017. shakespearizing modern languageusing copy-enriched sequence-to-sequence models.
arxiv preprint arxiv:1707.01161..vineet john, lili mou, hareesh bahuleyan, and olgavechtomova.
2018. disentangled representationlearning for non-parallel text style transfer.
arxivpreprint arxiv:1808.04339..hyunjik kim and andriy mnih.
2018. disentanglingby factorising.
arxiv preprint arxiv:1802.05983..diederik p kingma and max welling.
2013. auto-arxiv preprint.
encoding variational bayes.
arxiv:1312.6114..lajanugen logeswaran, honglak lee, and samy ben-gio.
2018. content preserving text generation within advances in neural informa-attribute controls.
tion processing systems, pages 5103–5113..jing qian, anna bethke, yinyin liu, elizabeth beld-ing, and william yang wang.
2019. a bench-mark dataset for learning to intervene in online hatespeech.
arxiv preprint arxiv:1909.04251..2414original sentence: i ’ve got a crush on him, like, forever !
attribute transfer: casual to formal transfer.
f entanglegenf1 i ’ve got a crush on him, like forever, which is wrong !
f2 i ’ve got a crush on him, like forever, which is wrong !
f3 i ’ve got a crush on him, like forever, because in real.
f1 you would have to say yes, but you are such a favorite.
f2 he is great, unfortunately.
f3 you would have to say yes, but you are such a favorite.
movie.
ctrlgen.
artists..artists.
ctvae.
f1 i have a crush, about him, so i have a crush on him !
f2 i have a crush on him, like an crush on him.
f3 i have a crush on him, like a crush..table 5: sentences generated corresponding to attributecontrol grades fi.
greater i denotes larger change inrepresentation..(a) training time.
(b) generation time.
figure 3: (a) the time taken (per epoch) for training byctvae and entanglegen on different datasets.
(b) thetime taken to generate 1k sentences by ctvae andentanglegen on different datasets..d training time comparison.
in this section we provide a comparative analysisof training time and sampling time of ctvae withentanglegen.
fig 3 shows that ctvae is muchfaster than that of entanglegen for both cases..a analysis of attribute supervision.
here we perform an ablation study by demonstrat-ing the importance of the last dimension za of therepresentation zf in capturing sentiment.
as weensure independence of every dimension, we calcu-late the correlation of every dimension of zf withthe sentiment labels in the test data.
we observethat za achieves the highest correlation of 0.72 inyelp and 0.42 in amazon.
we further train a logis-tic regression classiﬁer with za of training data as afeature to predict sentiment labels, and we achievea high accuracy of 0.85 and 0.64 on test data inyelp and amazon respectively.
while training withthe most correlated dimension of zf other than za,with a correlation of 0.12 for yelp and 0.14 foramazon, we achieve an accuracy of only 0.52 and0.58 respectively.
this implies that za is the mostexpressive dimension for capturing sentiment incomparison to any other dimension..b parameter setting.
the sentence encoder is designed using pre-trainedbert-base-uncased model (embedding dim = 768)followed by 2-layer feed-forward network with hid-den dim 200. the output of the same is the sen-tence embedding which is of dimension 256 forevery dataset.
the ﬂow network is designed as r-nvp with t = 3 and each ψt is designed as threelayer feed forward network with tanh activationfunction for the initial two layers and hidden di-mension is 100 for the intermediate layers.
thescaling network for sentiment classiﬁcation is de-signed as a two dimensional vector [−1, 1].
thesentence decoder is designed as a gated recurrentunit where output of each step is passed througha fully connected feed-forward network to convertit to a logit of length of the vocabulary size.
theweighing parameters β and γ are set to 10 for fea-ture supervision and disentanglement..c qualitative examples.
in table 5 we provide some examples of casual toformal conversion.
we can see with increase ofthe perturbation ctvae introduces more formalnotions to the sentences as proper capitalization ornot using any abbreviation etc.
whereas entangle-gen fails to introduce such changes to keep contentintact and ctrlgen generates unrelated content..2415amazonyelp0.02.55.07.510.012.515.017.520.0time (mins per epoch)ctvaeentanglegenamazonyelp0.02.55.07.510.012.515.017.520.0time (mins per 1k sentences)ctvaeentanglegen