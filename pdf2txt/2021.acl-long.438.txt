learning to ask conversational questionsby optimizing levenshtein distance.
zhongkun liu1, pengjie ren1∗, zhumin chen1∗, zhaochun ren1,maarten de rijke2, ming zhou31school of computer science and technology, shandong university, china2university of amsterdam & ahold delhaize3sinovation ventures, china{liuzhongkun,renpengjie,chenzhumin, zhaochun.ren}@sdu.edu.cnm.derijke@uva.nl; mingzhou926@hotmail.com.
abstract.
conversational question simpliﬁcation (cqs)aims to simplify self-contained questions intoconversational ones by incorporating someconversational characteristics, e.g., anaphoraand ellipsis.
existing maximum likelihood es-timation based methods often get trapped ineasily learned tokens as all tokens are treatedequally during training.
in this work, we intro-duce a reinforcement iterative sequence edit-ing (rise) framework that optimizes the min-imum levenshtein distance through explicitediting actions.
rise is able to pay atten-tion to tokens that are related to conversa-tional characteristics.
to train rise, we de-vise an iterative reinforce training (irt) al-gorithm with a dynamic programming basedsampling (dps) process to improve explo-ration.
experimental results on two bench-mark datasets show that rise signiﬁcantlyoutperforms state-of-the-art methods and gen-eralizes well on unseen data..figure 1: an example for conversational questionsimpliﬁcation and its reverse, conversational questionrewriting.
q1–a3 is the context, sq4 is the self-contained question, and cq4 is the conversational ques-tion..1.introduction.
conversational information seeking (cis) (zamaniand craswell, 2020; ren et al., 2021b) has receivedextensive attention.
it introduces a new way toconnect people to information through conversa-tions (qu et al., 2020; gao et al., 2021; ren et al.,2020).
one of the key features of cis is mixedinitiative behavior, where a system can improveuser satisfaction by proactively asking clariﬁcationquestions (zhang et al., 2018; aliannejadi et al.,2019; xu et al., 2019), besides passively providinganswers (croft et al., 2010; radlinski and craswell,2017; lei et al., 2020)..previous studies on asking clariﬁcation questionscan be grouped into two categories: conversationalquestion generation (duan et al., 2017) and conver-sational question ranking (aliannejadi et al., 2019)..∗∗ corresponding authors..the former directly generates conversational ques-tions based on the dialogue context.
however, thegenerated questions may be irrelevant and mean-ingless (rosset et al., 2020).
a lack of explicitsemantic guidance makes it difﬁcult to produceeach question token from scratch while preservingrelevancy and usefulness at the same time (wanget al., 2018; chai and wan, 2020).
instead, thelatter proposes to retrieve questions from a col-lection for the given dialogue context, which canusually guarantee that the questions are relevantand useful (shen et al., 2018; rosset et al., 2020).
however, question ranking methods do not leadto a natural communication between human andmachine (pulman, 1995), as they neglect importantcharacteristics in conversations, e.g., anaphora andellipsis.
as shown in fig.
1, the self-containedquestion (sq4) lacks these characteristics, whichmakes it look unnatural..in this work, we study the task of conversa-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5638–5650august1–6,2021.©2021associationforcomputationallinguistics5638ira hayes    him→revealing...   this→was anyone opposed to ira hayes revealing thetruth about harlon and the rosenthal photograph?was anyone opposed to him (in) this?anaphoraellipsisabout ...influentmlewas opposedtohimmldanaphoracqrcqsanyoneq1a1q3a3what was ira hayes doing after the war?hayes attempted to lead a normal civilian life after the war.what truth is he wanting to reveal?to block's family about their son harlon being in therosenthal photograph.sq4cq4...was anyone opposed to ira hayes ...was anyone opposed to him ...tional question simpliﬁcation (cqs).
given a dia-logue context and self-contained question as input,cqs aims to transform the self-contained questioninto a conversational one by simulating conversa-tional characteristics, such as anaphora and ellip-sis.
for example, in fig.
1, four simpliﬁcationoperations are applied to obtain the conversationalquestion (cq4), which is context-dependent andsuperior to its origin one (sq4) in terms of natu-ralness and conveying.
the reverse process, i.e.,conversational question rewriting (cqr) (elgo-hary et al., 2019; voskarides et al., 2020) whichrewrites cq4 into sq4, has been widely exploredin the literature (vakulenko et al., 2020; yu et al.,2020).
although the proposed methods for cqrcan be easily adopted for cqs, they do not al-ways generate satisfactory results as they are alltrained to optimize a maximum likelihood estima-tion (mle) objective, which gives equal attentionto generate each question token.
therefore, theyoften get stuck in easily learned tokens, i.e., tokensappearing in input, ignoring conversational tokens,e.g., him, which is a small but important portion ofoutput..to address the above issue, we propose a newscheme for cqs, namely minimum levenshtein dis-tance (mld).
it minimizes the differences betweeninput and output, forcing the model to pay attentionto contributing tokens that are related to conversa-tional tokens, e.g., “ira hay” and “him” in fig.
1.therefore, mld is expected to outperform mlefor cqs.
however, mld cannot be minimizedby direct optimization due to the discrete nature,i.e., minimizing the number of discrete edits.
wepresent an alternative solution, a reinforcementiterative sequence editing (rise) framework forthe optimization of mld..we formulate rise as a hierarchical combina-torial markov decision process (hcmdp) consist-ing of an editing markov decision process (mdp)to predict multiple edits for all tokens in the self-contained question, e.g., ‘keep (k)’ to keep a to-ken, and a phrasing mdp to predict a phrase ifthe edit is ‘insert (i)’ or ‘substitute (s)’.
we onlyhave the self-contained and conversational questionpairs in the dataset while the demonstrations of theediting iterations are lacked.
thus, we cannot traineach editing iteration of rise with teacher forcing.
to this end, we devise an iterative reinforce train-ing (irt) algorithm that allows rise to do someexploration itself.
the exploration can be rewarded.
according to its levenshtein distance (ld) with thedemonstrated conversational question.
traditionalexploration methods like (cid:15)-sampling (sutton andbarto, 1998) neglect the interdependency betweenedits for all tokens, resulting in poor exploration.
thus, we further introduce a dynamic program-ming based sampling (dps) process that adoptsa dynamic programming (dp) algorithm to trackand model the interdependency in irt.
experi-ments on the canard (elgohary et al., 2019) andcast (dalton et al., 2019) datasets show that risesigniﬁcantly outperforms state-of-the-art methodsand generalizes well to unseen data..2 conversational question.
simpliﬁcation: from maximumlikelihood estimation to minimumlevenshtein distance.
2.1 cqs.
given a dialogue context c representing the previ-ous conversation utterances and the self-containedclariﬁcation question candidate x = {x1, .
.
.
, x|x|}to be asked next (e.g., from a conversationalquestion ranking model), the goal of conversa-tional question simpliﬁcation (cqs) is to refor-mulate question x to a conversational questiony = {y1, .
.
.
, y|y|} by simulating conversationalcharacteristics, e.g., anaphora and ellipsis.
a tar-get conversational question y∗ = {y∗|y∗|} isprovided during the training phase..1, .
.
.
, y∗.
2.2 maximum likelihood estimation for cqs.
a commonly adopted paradigm for tasks similarto cqs, e.g., cqr, is to model the task as a condi-tional sequence generation process parameterizedby θ, which is usually optimized by mle:lθ = − log pθ(y∗|x, c).
|y∗|(cid:88).
= −.
log pθ(y∗.
t |y∗.
<t, x, c),.
(1).
1, y∗.
t=1where y∗ is the target question and y∗<t denotesthe preﬁx y∗2, .
.
.
, y∗t−1.
as we can see, mlegives equal weight to each token and falls in easilylearned tokens, the overwhelming duplicate tokensbetween x and y, while underestimating subtle dif-ferences of tokens related to conversational charac-teristics..2.3 minimum levenshtein distance for cqs.
inspired by arjovsky et al.
(2017), to minimizethe distance between two distributions, we propose.
5639to minimize the ld between the target questiony∗ and the model output y so as to leverage thehigh overlap between x and y and focus on subtledifferent tokens:.
lθ = ld(y, y∗)..(2).
unfortunately, it is impossible to directly optimizeeq.
2 because the ld between y and y∗ is the mini-mum number of single-token edits (insertions, dele-tions or substitutions) required to change y into y∗,which is discrete and non-differentiable..3 rise.
to optimize mld in eq.
2, we devise the re-inforcement iterative sequence editing (rise)framework, which reformulates the optimization ofmld as a hierarchical combinatorial markov de-cision process (hcmdp).
next, we ﬁrst describeour hcmdp formulation of rise.
we then detailthe modeling of each ingredient in rise.
finally,we present the training process of rise..3.1 hcmdp formulation for rise.
rise produces its output y by iteratively editingx with four types of edit, i.e., ‘k’ to keep a to-ken, ‘delete (d)’ to delete a token, ‘i’ to insert aphrase (a sequence of tokens) after a token, and‘s’ to substitute a phrase by a new one.
if a to-ken is predicted as ‘i’ or ‘s’, we need to furtherpredict a corresponding phrase.
note that we onlypredict one phrase for successive ‘s’ edits.
weformulate rise as a hierarchical combinatorialmarkov decision process (hcmdp) consisting of(1) an editing mdp to predict multiple edits for alltokens, and (2) a phrasing mdp to predict a phraseif the edit is ‘i’ or ‘s’..the editing mdp can be formulated as a tuplet ∈ s e denotes the(cid:104)s e, ae, t e, r, πe(cid:105).
here, sequestion at t-th iteration yt together with the con-t = (yt, c).
note that setext c, i.e., se0 = (x, c).
t,|yt|] ∈ ae is a combinato-t,2, .
.
.
, aet,1, aet = [aeaerial action consisting of several interdependent ed-its.
the number of edits corresponds to the lengthof yt.
for example, in fig.
2, aet = [‘k’, ‘k’,‘k’, ‘k’, ‘s’, ‘s’, ‘k’, ‘k’].
in our case, the tran-sition function t e is deterministic, which meansthat the next state set+1 is obtained by applying thepredicted actions from both the editing mdp andphrasing mdp to the current state set .
rt ∈ r is thereward function, which estimates the joint effectof taking the predicted actions from both the edit-.
ing and phrasing mdps.
πe is the editing policynetwork..t,1, ap.
t = [ap.
t , and the context c, i.e., sp.
the phrasing mdp can be formulated as a tuple(cid:104)s p, ap, t p, r, πp(cid:105).
here, spt ∈ s p consists ofthe current question yt, the predicted action fromthe editing mdp aet =t , c).
apt,2, .
.
.]
∈ ap is also a(yt, aecombinatorial action, where apt,i denotes a phrasefrom a predeﬁned vocabulary and i correspondsto the index of the ‘i’ or ‘s’ edits, e.g., in fig.
2,‘apt,1 = him’ is the predicted phrase for the ﬁrst ‘s’edit.
the length of the action sequence correspondsto the number of ‘i’ or ‘s’ edits.
the transitionfunction t p returns the next state spt+1 by applyingthe predicted actions from the phrasing mdp tothe current state spt .
rt ∈ r is the shared rewardfunction.
πp is the phrasing policy network..rise tries to maximize the expected reward:.
j(θ) = eae.
t ∼πe,ap.
t ∼πp[rt],.
(3).
where θ is the model parameter which is optimizedwith the policy gradient:.
∇j(θ) = eae.
t ∼πe,ap.
t ∼πp[rt(∇ log πe(ae∇ log πp(ap.
t |set |sp.
t ) +t ))],.
(4).
next, we will show how to model πe(aeπp(ap.
t ), and rt..t |sp.
t |se.
t ),.
3.2 policy networks.
we implement the editing and phrasing policy net-works (πe and πp) based on bert2bert (rotheet al., 2020) as shown in fig.
2. the editing pol-icy network is implemented by the encoder to pre-dict combinatorial edits, and the phrasing policynetwork is implemented by the decoder to predictphrases..3.2.1 editing policy network.
we unfold all tokens of the utterances in the con-text into a sequence c = (w1, .
.
.
, wc), where widenotes a token and we add “[sep]” to separate dif-ferent utterances.
then the context and input ques-tion in t-th iteration are concatenated with “[sep]”as the separator.
finally, we feed them into theencoder of bert2bert to obtain hidden represen-tations for tokens in question h t = (ht|yt|)and apply a linear layer with parameter w e to pre-dict aet :.
1, .
.
.
, ht.
πe(ae.
t |se.
t = (yt, c)) = softmax(w eh t)..(5).
5640figure 2: architecture of our policy network.
a combinatorial of all tokens edits is predicted by editing policy,and for each ‘i’ or ‘s’ edit, a phrase will be predicted by phrasing policy..i = [yt.
j, .
.
.
, yt.
k], where ae.
3.2.2 phrasing policy networkwe ﬁrst extract the spans corresponding to the ‘i’or ‘s’ edits from the question.
if the edit is ‘i’,the question span spanti consists of tokens beforeand after this insertion, i.e., spanti = [ytj, ytj+1];if the edit is ‘s’, the question span spanti consistsof successive tokens corresponding to the ‘s’ edit,i.e., spantt,j:k =‘s’ andaet,k+1 (cid:54)= ‘s’.
we only predict once for successive‘s’ edits, e.g., in fig.
2, the phrase ‘him’ is pre-dicted to substitute question span [“ira”, “hayes”].
for the i-th ‘i’ or ‘s’ edit with a question spanspanti, we concatenate the span and “[cls]” tokenas input tokens, and feed them into the decoder ofbert2bert to obtain a hidden representation ofi. we obtain st by concatenating“[cls]” token steach sti and predict the phrases for all ‘s’ and ‘i’edits by a linear layer with parameter w p:.
πp(ap.
t |sp3.3 reward r.t ) = softmax(w pst)..(6).
t , ap.
we devise the reward rt to estimate the effect oftaking the joint action (aet ) by encouraging ac-tions that can result in low ld values between yt+1and y∗, i.e., minimizing eq.
2. besides, we discour-age those actions to achieve same yt+1 with extranon ‘k’ edits:.
3.4 training.
t , ae.
t , ap.
to train rise, we need training samples in thet , spform of a tuple (set , rt).
however, weonly have (y0 = x, y∗) in our dataset.
traditionalexploration methods like (cid:15)-greedy sampling sam-ple edits for all tokens independently, ignoring theinterdependency between them.
instead, we devisean iterative reinforce training (irt) algorithm tosample an edit for each token by considering itsfuture expectation, i.e., sampling aet,i based on ex-pectation of aet,:i−1 from i = |yt| to 1. we maintaina matrix m t for this expectation based on bothyt and y∗, which is computed by a dynamic pro-gramming based sampling (dps) process due tothe exponential number of edit combinations ofaet,:i. the details of irt are provided in alg.
1; itcontains a dps process that consists of two parts:computing the matrix m t (line 4–8) and samplingt ) (line 10) based on m t.actions (ae.
t , ap.
3.4.1 computing the matrix m tgiven (yt, y∗) with length m and n, we maintaina matrix m t ∈ r(m+1)×(n+1) (including ‘[sep]’,see the upper right part in fig.
3) where each ele-i,j tracks the expectation of aement m tt,:i to convert:i to y∗yt:j:.
m t.i,j = epi,j (ae.
t,:i−1)πyt.
:i−>y∗:j.
(ae.
t,:i)].
t,i)[ep(ae.
rt =.
11 + ld(yt+1, y∗)(cid:32).
×.
(cid:33).
(cid:88).
l −.
t.(ae.
t (cid:54)= ‘k’) + 1.,.
(7).
= epi,j (ae.
t,i).
πe(ae.
t,i|yt, c) ×.
.
l = ld(yt, y∗) − ld(yt+1, y∗),.
1.where1+ld(yt+1,y∗) will reward actions that re-sult in low ld values between yt+1 and y∗ and(l − (cid:80)t (cid:54)= ‘k’)) will punish those actions withunnecessary non ‘k’ edits..t(ae.
(8).
t,i = ‘k’.
.
m tm tm tm t.i−1,j−1, if aei−1,j, if aei,j−1, if aei−1,j−1, if ae.
t,i = ‘d’t,i = ‘i’.
t,i = ‘s’.
.
,.
5641......himediting policyphrasing policycross attentionapt,1was anyone opposed to ira hayes revealing ...  was anyone opposed tohimrevealing ...aetkkkksskkytyt+1editing iteration twasirahayescontextirahayes[cls]anyoneopposedtorevealing...[sep]bert2bertbert2bert(ae.
t,:i is the combinational edits for tokens yt:it,i|yt, c) is calculated by eq.
5 (see the0,0 is initialized to 1.t,i) and then introduce.
where aeand πe(aeupper left part in fig.
3).
m twe will ﬁrst introduce pi,j(aeπyt.
:i−>y∗:jtraditional sampling methods sample each editindependently, based on model likelihoodt,i|yt, c).
instead, we sample each edit witht,i) based on edits expectation.
aet,iπe(aeprobability pi,j(aem t, which is modeled as:.
t,:i) in eq.
8..pi,j(ae.
t,i) =.
π(ae.
t,i|yt, c)×.
1zti,jm tm tm tm t.t,i = ‘k’.
i−1,j−1, if aei−1,j, if aei,j−1, if aei−1,j−1, if ae.
t,i = ‘d’t,i = ‘i’.
t,i = ‘s’,.
(9).
where zti,j is the normalization term.
we give anexample on computing m t1,2 in the bottom part offig.
3. for edit ‘i’ in m t1,2, its probability is 1, andits value is πe(ae1,1 = 0.008.for the other edits, the probability is 0. therefore,m t.t,i = ‘i’|yt, c) × m t.t,:i) is the probability of conducting.
1,2 = 0.008.
(aeπyt:i−>y∗:jt,:i to convert ytedits ae.
:i to y∗:j:.
t,:i−1), if ae.
t,i−1 = ‘k’.
t,i|yt, c)×.
(ae.
:i−>y∗:j.πyt.
.
πytπytπytπyt.
:j−1.
t,:i) = πe(ae(aet,:i−1), if aet,:i), if ae(ae.
(ae(ae.
:i−1−>y∗.
:i−1−>y∗:j.:i−>y∗.
:j−1.
t,i = ‘i’.
:i−1−>y∗.
:j−1.
t,:i−1), if ae.
t,i−1 = ‘s’,.
t,i−1 = ‘d’.
(10).
:j−1.
t,:i−1)..i when yt.
i = y∗(ae.
i when yt:i−1−>y∗.
to convert yt:i to y∗:j, we need to make sure thatytj and that yti can convert to y∗:i−1 can convert toy∗:j−1, which can be calculated recursively.
notethat we only allow ‘s’ and ‘d’ for yti (cid:54)=j and ‘k’ and ‘i’ for yty∗j .
andm tt,:i−1)πyti−1,j−1 = ep(aet , apt ).
3.4.2 sampling (aewe sample (aet ) based on matrix m t by back-tracking from i = m, j = n. for example, asshown in the upper right in fig.
3, we backtrackalong the blue arrows.
in this truncated sample, westart from m t7,6, sample an edit ‘k’ to keep ‘reveal-ing’ based on p7,6(ae6,5.then, we sample ‘s’ to substitute ‘ira hayes’ to‘him’ and move to m t4,4. finally, we sample ‘k’.
t,7) in eq.
9, and move to m t.t , ap.
algorithm 1: training process of riseinput: the origin data d = {(x, y∗)}, the.
number of samples l;.
output: the model parameters θ;.
1 while not coverage do.
sample (yt, y∗) from d ;m tfor i in 0,. .
.
, m do.
0,0 = 1;.
for j in 0,. .
.
, n docompute m teq.
8;.
end.
i,j according to.
t , apt , ap.
endsample aet according to eq.
11 ;apply aet to obtain yt+1 ;obtain rt according to eq.
7 ;update θ according to eq.
4 ;add (yt+1, y∗) to d..2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
1314 end.
figure 3: the dps process consists of computing ma-trix m (red box) and sampling (aep) (blue arrowsand box)..t , at.
2,2m t.3,3, m t.4,4, m t.t = [k, k, k, k, k, s, s, k], ap.
1,1, m tin [m t0,0] to keep [‘to’, ‘op-posed’, ‘anyone’, ‘was’, ‘[sep]’].
therefore, wecan obtain aet =[‘him’].
note that we obtain apt by merging allcorresponding tokens y∗j as the phrase for each ‘i’edit and successive ‘s’ edits and we only substituteonce.
the backtracking rule can be formulated as:.
m t.i,j →.
t,i ∈ [‘k’, ‘s’].
.
.
m tm tm t.i−1,j−1, if aei−1,j, if aei,j−1, if ae.
t,i = ‘d’t,i = ‘i’..(11).
3.5.inference.
during inference, rise iteratively edits x until itpredicts ‘k’ edits for all tokens or it achieves the.
5642[sep]wasanyoneopposedtoirahayesrevealing...0.900000000.090.810000000.010.080.73000000mt1,20.070.660000000.010.070.520.050.0100000.010.10.460.05000000.020.090.410.04................................................[sep]wasanyoneopposedtohimrevealing...y∗kkkkkssk...himaetapt0.90.90.90.90.8000.90.10.10.10.10.2000.1000000.10.10000000.90.90............idskytkids0.1.0.0.0.90.10.0.mt0,1mt1,1mt0,2mt0,10.010.080.0.01=mt1,2××=0.008π(|,c)aet,1yt()p1,2aet,1∑kkkkksdk...mtinfectmaximum iteration limit.
for example, for editingiteration t in figure 2, it predicts ‘s’ for ‘ira’ and‘hayes’ to substitute it to ‘him’ and ‘k’ for othertokens, which results in ‘was anyone opposed tohim revealing .
.
.
’ as output.
the output in iterationt is the input of iteration t + 1. the actual editingiteration times vary with different samples..4 experiments.
4.1 datasets.
as with previous studies (elgohary et al., 2019;yu et al., 2020; vakulenko et al., 2020; linet al., 2020a), we conduct experiments on thecanard1 (elgohary et al., 2019) dataset, whichis a large open-domain dataset for conversationalquestion answering (with over 30k training sam-ples).
each sample in the canard dataset in-cludes a conversational context (historical ques-tions and answers), an self-contained question, andits corresponding conversational question underthe context.
the questions always have clear an-swers, e.g., ‘did he win the lawsuit?’ we followthe canard splits for training and evaluation..in addition, we evaluate the model performanceon the cast2 dataset (dalton et al., 2019), whichis built for conversational search.
different fromcanard, its context only contains questions with-out corresponding answers.
besides, most ques-tions in the cast dataset are exploring questionsto explore relevant information, e.g., ‘what aboutfor great whites?’ since the cast dataset onlycontains 479 samples from different domains com-pared to canard, we use it for testing..4.2 evaluation metrics.
following su et al.
(2019); xu et al.
(2020), weuse bleu-1, bleu-2, bleu-3, bleu-4 (pap-ineni et al., 2002), rouge-l (lin, 2004), andcider (vedantam et al., 2015) for automatic evalu-ation.
bleu-n and rouge-l measure the wordoverlap between the generated and golden ques-tions.
cider measures the extent to which impor-tant information is missing.
elgohary et al.
(2019);lin et al.
(2020a); xu et al.
(2020) have shown thatautomatic evaluation has a high correlation with hu-man judgement on this task, so we do not conducthuman evaluation in this paper..1http://canard.qanta.org2http://www.treccast.ai.
4.3 baselines.
we compare with several recent state-of-the-artmethods for this task or closely related tasks:• origin uses the original self-contained question.
as output..• rule (yu et al., 2020) employs two simplerules to mimic two conversational characteris-tics: anaphora and ellipsis..• qgdiv (sultan et al., 2020) uses roberta (liuet al., 2019) with beam search (wiseman andrush, 2016) for generation..• trans++ (vakulenko et al., 2020) predicts sev-eral word distributions, and combines them toobtain the ﬁnal word distribution when generat-ing each token..• querysim (yu et al., 2020) adopts a gpt-2 (radford et al., 2019) model to generate con-versational question..we also found some methods from related tasks.
but they do not work on this task for various rea-sons.
for example, due to the lack of labels neededfor training, we cannot compare with the meth-ods proposed by rosset et al.
(2020) and xu et al.
(2020).
su et al.
(2019) propose a model that canonly copy tokens from input; it works well on thereverse task (i.e., cqr), but not on cqs..4.4.implementation details.
we use bert2bert for the modeling of the edit-ing and phrasing parts (rothe et al., 2020), as otherpretrained models like gpt-2 (radford et al., 2019)cannot work for both.
the hidden size is 768 andphrase vocabulary is 3461 following (malmi et al.,2019).
we use the bert vocabulary (30,522 to-kens) for all bert-based or bert2bert-basedmodels.
we use the adam optimizer (learning rate5e-5) (kingma and ba, 2015) to train all models.
inparticular, we train all models for 20,000 warm-upsteps, 5 epochs with pretrained model parametersfrozen, and 20 epochs for all parameters.
for rise,the maximum editing iteration times is set to 3. weuse gradient clipping with a maximum gradientnorm of 1.0. we select the best models based onthe performance on the validation set.
during in-ference, we use greedy decoding for all models..4.5 results.
we list the results of all methods on both canardand cast in table 1. from the results, we havetwo main observations..first, rise signiﬁcantly outperforms all base-.
5643table 1: overall performance (%) on canard and cast.
bold face indicates the best results in terms of thecorresponding metrics.
signiﬁcant improvements over the best baseline results are marked with ∗ (t-test, p < 0.01).
note that we denote bleu-n as b-n and rouge-l as r-l..canard (%).
cast (%) (unseen).
method.
b-1.
b-2.
b-3.
b-4 r-l cider b-1.
b-2.
b-3.
b-4 r-l cider.
originrule.
54.755.0.
47.047.0.
40.640.2.
35.334.8.
70.970.5.
84.3trans++qgdiv85.2querysim 83.1.
77.572.178.673.378.574.586.3∗ 80.5∗ 75.6.rise.
67.584.668.985.271.082.771.6∗ 86.2∗.
3.4603.420.
6.3486.4696.585.
6.759.
75.978.0.
69.271.4.
76.064.375.965.380.675.385.1∗ 78.4.
62.965.3.
54.856.770.2.
57.660.0.
47.259.665.5.
72.2.
66.8.
85.086.1.
76.578.083.387.8∗.
5.9466.220.
4.2584.6946.345.
6.543.lines on both datasets.
speciﬁcally, rise outper-forms the strongest baseline querysim by ˜4% interms of rouge-l. the reason is that rise en-hanced by dps has a better ability to emphasizeconversational tokens, rather than treating all to-kens equally..second, rise is more robust, which general-izes better to unseen data of cast.
the resultsof the neural methods on canard are much bet-ter than those on cast.
but, rise is more stablethan the other neural models.
for example, riseoutperforms querysim by 0.6% in bleu-4 oncanard, while 1.3% on cast.
the reason isthat rise learns to cope with conversational to-kens only, while other models need to generateeach token from scratch..5 analysis.
5.1 ablation study.
to analyze where the improvements of risecome from, we conduct an ablation study on thecanard and cast datasets (see table 2).
weconsider two settings:• -dps.
here, we replace dps by (cid:15)-greedy sam-.
pling ((cid:15) = 0.2) (sutton and barto, 1998)..• -mld.
here, we replace mld by mle in.
rise..the results show that both parts (dps and mld)are helpful to rise as removing either of themleads to a decrease in performance.
without mld,the performance drops a lot in terms of all metrics,e.g., 3% and 7% in bleu-4 on canard andcast, respectively.
this indicates that optimizingmld is more effective than optimizing mle.
be-sides, mld generalizes better on unseen cast asit drops slightly in all metrics, while with mle, wesee a drop of 10% in bleu-1..figure 4: average number of editing iteration of riseconditioned on number of tokens in x - y and y - x..without dps,.
the results drop dramatically,which indicates that dps can do better explorationthan (cid:15)-greedy and is of vital importance for rise.
for example, -dps tends to sample more non ‘k’edits (rise vs -dps: 10% vs 22% on canard),which is redundant and fragile.
the performance of-dps is even worse than origin in cast in bleu-4. this may be because cast is unseen..5.2 editing iterations.
to analyze the relation between the number of edit-ing iterations of rise and the editing difﬁculty, weplot a heatmap in fig.
4, where the deeper color rep-resents a larger number of editing iterations.
thex-axis denotes the number of tokens shown in inputx but not shown in output y and the y-axis denotesthe number of tokens shown in y but not in x..as the number of different tokens between xand y increases, the number of editing iterationsincreases too.
for example, when the y-axis is 1,as the x-axis ranges from 1 to 10, the number of.
5644table 2: ablation study (%) on canard and cast..canard (%).
cast (%) (unseen).
method b-1.
b-2.
b-3.
b-4 r-l cider b-1.
b-2.
b-3.
b-4 r-l cider.
origin.
54.7.
47.0.
40.6.
35.3.
70.9.
3.460.
75.9.
69.2.
62.9.
57.6.
85.0.
5.946.
-dps-mld.
rise.
67.585.2.
86.3.
47.373.3.
56.473.978.685.280.5∗ 75.6∗ 71.6∗ 86.2∗.
39.968.9.
3.7436.4696.759∗.
70.065.3.
80.960.681.275.956.778.085.1∗ 78.4∗ 72.2∗ 66.8∗ 87.8∗.
53.359.6.
4.7134.6946.543∗.
editing iterations increases from 1.2 to 2.6 becausemore ‘d’ edits are needed.
we also found thatwhen the x-axis is between 3 and 7 and the y-axisis between 1 and 4, only 1–2 editing iterations areneeded.
usually, this is because rise only needs 1or 2 successive ‘s’ edits for simulating anaphora..5.3.inﬂuence of the number of editingiterations.
the overall performance of rise improves asthe number of editing iterations increases.
riseachieves 70.5% in bleu-4 in the ﬁrst iteration(even worse than querysim in table 1) but 71.5%and 71.6% in the second and third iterations.
thisshows that some samples are indeed more difﬁcultto be directly edited into conversational ones, andthus need more editing iterations..even though it will not hurt the performance alot, more editing iterations are not always helpful.
about 5% of the samples achieve worse bleu-4scores as the number of editing iterations increases.
for example, rise edits ‘where did humphrey lyt-telton go to school at?’ into ‘where did he go toschool at?’ in the ﬁrst iteration, which is perfect.
but rise continues to edit it into ‘where did hego to school?’ in the second iteration, which isundesirable.
this is because rise fails to decidewhether to stop or continue editing..5.4 case study.
in table 3 we present two examples of the out-put of rise.
we present the context, the originalself-contained question, the target conversationalquestion, and the output of rise in the n-th iter-ation, denoted as ‘context’, ‘question’, ‘target’and ‘rewrite#n’, respectively.
we have two mainobservations.
first, it is helpful to edit iteratively.
as shown in example 1, rise ﬁrst replaces ‘abu’as ‘he’ in the ﬁrst iteration and then deletes ‘bakr’in the second iteration, which simulates anaphoraby editing twice.
in example 2, rise simulates el-.
table 3: examples generated by rise on canard.
here, ‘question’ means the self-contained question,and ‘target’ means the desired conversational question.
‘rewrite#n’ denotes the output of rise in n-th itera-tion..example 1.context.
1. at tabuk the standard of the armywas entrusted to abu bakr.
2. where was tabuk located?
3. tabuk on the syrian border..question.
what did abu bakr do during theexpedition of tabuk?
rewrite#1 what did he bakr do during expedi-.
tion?.
rewrite#2 what did he do during expedition?
target.
what did abu bakr do during the ex-pedition?.
example 2.context.
question.
rewrite#1rewrite#2target.
1. when did clift start his ﬁlm ca-reer?
2. his ﬁrst movie role was oppositejohn wayne in red river, which wasshot in 1946 and released in 1948..did montgomery clift win anyawards for any of his ﬁlms?
did he win any awards for and?
did he win any awards?
did he win any awards for any of hisﬁlms?.
lipsis by deleting multiple words and achieves poorgrammar after the ﬁrst iteration but corrects thisby deleting some of the leftover words.
rise mayhave learned to check the grammar and removeredundant words..second, rise can simulate more conversationalcharacteristics than human, and sometimes it canachieve a better result, sometimes not.
as we cansee, rise results a better conversational questionby additionally simulating anaphora for ‘abu bakr’in example 1. however, rise leaves out necessaryinformation in example 2. here, rise tries tosimulate conversational characteristics as much as.
5645possible, where the result may be uncontrollable.
in future work, we will add a discriminator to checkthe necessary information..6 related work.
studies on asking conversational question can be di-vided into two categories: conversational questiongeneration and conversational question ranking..conversational question generation aims to di-rectly generate conversational questions condi-tioned on the dialogue context (sultan et al., 2020;ren et al., 2021a).
zamani et al.
(2020) and qiet al.
(2020) deﬁne a question utility function toguide the generation of conversational questions.
nakanishi et al.
(2019); jia et al.
(2020) incorporateknowledge with auxiliary tasks.
these methodsmay generate irrelevant questions due to their puregeneration nature..conversational question ranking (aliannejadiet al., 2019) retrieves questions from a collectionbased on the given context, so the questions aremostly relevant to the context.
kundu et al.
(2020)propose a pair-wise matching network between con-text and question to do question ranking.
somestudies also use auxiliary tasks to improve rank-ing performance, such as natural language infer-ence (kumar et al., 2020) and relevance classiﬁca-tion (rosset et al., 2020).
the retrieved questionsare often unnatural without considering the conver-sational characteristics, e.g., anaphora and ellipsis.
cqs rewrites the retrieved self-contained ques-tions into conversational ones by incorporating theconversational characteristics.
existing applicablemethods for cqs are all mle based (xu et al.,2020; yu et al., 2020; lin et al., 2020b; vakulenkoet al., 2020), which often get stuck in easily learnedtokens as each token is treated equally by mle.
in-stead, we propose a mld based rise frameworkto formulate cqs as a hcmdp, which is able todiscriminate different tokens through explicit edit-ing actions, so that it can learn to emphasize theconversational tokens and generate more naturaland appropriate questions..7 conclusion.
in this paper, we have proposed a minimum lev-enshtein distance (mld) based reinforcement it-erative sequence editing (rise) framework forconversational question simpliﬁcation (cqs).
totrain rise, we have devised an iterative reinforcetraining (irt) algorithm with a novel dynamic.
programming based sampling (dps) process.
ex-tensive experiments show that rise is more effec-tive and robust than several state-of-the-art cqsmethods.
a limitation of rise is that it may fail todecide whether to stop or continue editing and leaveout necessary information.
in future work, we planto address this issue by learning a reward functionthat considers the whole editing process throughadversarial learning (goodfellow et al., 2014)..code.
to facilitate the reproducibility of the results, weshare the codes of all methods at https://github.
com/lzksky/case_rise..acknowledgments.
we thank the reviewers for their valuable feedback.
this research was partially supported by the na-tional key r&d program of china with grant no.
2020yfb1406704, the natural science foundationof china (61972234, 61902219, 62072279), thekey scientiﬁc and technological innovation pro-gram of shandong province (2019jzzy010129),the tencent wechat rhino-bird focused researchprogram (jr-wxg-2021411), the fundamentalresearch funds of shandong university, andthe hybrid intelligence center, a 10-year pro-gram funded by the dutch ministry of educa-tion, culture and science through the nether-lands organisation for scientiﬁc research, https://hybrid-intelligence-centre.nl..all content represents the opinion of the authors,which is not necessarily shared or endorsed by theirrespective employers and/or sponsors..references.
mohammad aliannejadi, hamed zamani, fabiocrestani, and w. bruce croft.
2019. asking clarify-ing questions in open-domain information-seekingin proceedings of the 42nd inter-conversations.
national acm sigir conference on research anddevelopment in information retrieval, sigir 2019,pages 475–484..martin arjovsky, soumith chintala, and l´eon bot-arxiv preprint.
tou.
2017. wasserstein gan.
arxiv:1701.07875..zi chai and xiaojun wan.
2020. learning to ask more:semi-autoregressive sequential question generationunder dual-graph interaction.
in proceedings of the58th annual meeting of the association for compu-tational linguistics, acl 2020, pages 225–237..5646w bruce croft, donald metzler, and trevor strohman.
2010. search engines: information retrieval in prac-tice, volume 520. addison-wesley reading..jeffrey dalton, chenyan xiong, and jamie callan.
2019. cast 2019: the conversational assistancetrack overview.
in proceedings of the 28th text re-trieval conference, trec 2019, pages 13–15..nan duan, duyu tang, peng chen, and ming zhou.
2017. question generation for question answering.
in proceedings of the 2017 conference on empiricalmethods in natural language processing, emnlp2017, pages 866–874..ahmed elgohary, denis peskov, and jordan l. boyd-graber.
2019. can you unpack that?
learningin proceedings ofto rewrite questions-in-context.
the 2019 conference on empirical methods in nat-ural language processing and the 9th internationaljoint conference on natural language processing,emnlp-ijcnlp 2019, pages 5917–5923..chongming gao, wenqiang lei, xiangnan he,maarten de rijke, and tat-seng chua.
2021. ad-vances and challenges in conversational recom-arxiv preprintmender systems: a survey.
arxiv:2101.09459..ian j. goodfellow, jean pouget-abadie, mehdi mirza,bing xu, david warde-farley, sherjil ozair,aaron c. courville, and yoshua bengio.
2014.arxiv arxivgenerative adversarial networks.
arxiv:1406.2661..xin jia, wenjie zhou, xu sun, and yunfang wu.
2020.how to ask good questions?
try to leverage para-in proceedings of the 58th annual meet-phrases.
ing of the association for computational linguistics,acl 2020, pages 6130–6140..diederik p. kingma and jimmy ba.
2015. adam: amethod for stochastic optimization.
in proceedingsof the 3rd international conference on learningrepresentations, iclr 2015..vaibhav kumar, vikas raunak, and jamie callan.
2020.ranking clariﬁcation questions via natural languagein proceedings of the 29th acm inter-inference.
national conference on information and knowledgemanagement, cikm 2020, pages 2093–2096..souvik kundu, qian lin, and hwee tou ng.
2020.learning to identify follow-up questions in conver-sational question answering.
in proceedings of the58th conference of the association for computa-tional linguistics, acl 2020, pages 959–968..wenqiang lei, xiangnan he, yisong miao, qingyunwu, richang hong, min-yen kan, and tat-sengchua.
2020. estimation-action-reﬂection: towardsdeep interaction between conversational and recom-mender systems.
in proceedings of the 13th interna-tional conference on web search and data mining,wsdm 2020, pages 304–312..chin-yew lin.
2004. rouge: a package for auto-in proceedings ofmatic evaluation of summaries.
the 42nd annual meeting of the association for com-putational linguistics, acl 2002, pages 74–81..sheng-chieh lin,.
jheng-hong yang, rodrigonogueira, ming-feng tsai, chuan-ju wang, andjimmy lin.
2020a.
conversational question refor-mulation via sequence-to-sequence architecturesarxiv preprintand pretrained language models.
arxiv:2004.01909..sheng-chieh lin,.
jheng-hong yang, rodrigonogueira, ming-feng tsai, chuan-ju wang, andjimmy lin.
2020b.
query reformulation usingquery history for passage retrieval in conversationalsearch.
arxiv preprint arxiv:2005.02230..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
arxiv preprint arxiv:1907.11692..eric malmi, sebastian krause, sascha rothe, daniilmirylenka, and aliaksei severyn.
2019. encode,tag, realize: high-precision text editing.
in proceed-ings of the 2019 conference on empirical methodsin natural language processing and the 9th inter-national joint conference on natural language pro-cessing, emnlp-ijcnlp 2019, pages 5053–5064..mao nakanishi, tetsunori kobayashi, and yoshihikohayashi.
2019. towards answer-unaware conversa-in proceedings of thetional question generation.
2nd workshop on machine reading for question an-swering, mrqa@emnlp 2019, pages 63–71..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2002. bleu: a method for automatic eval-uation of machine translation.
in proceedings of the40th annual meeting of the association for compu-tational linguistics, acl 2002, pages 311–318..stephen g pulman.
1995. anaphora and ellipsis in ar-tiﬁcial languages.
natural language engineering,1(3):217–234..peng qi, yuhao zhang, and christopher d. manning.
2020. stay hungry, stay focused: generating infor-mative and speciﬁc questions in information-seekingin proceedings of the 2020 confer-conversations.
ence on empirical methods in natural languageprocessing, emnlp 2020, pages 25–40..chen qu, liu yang, cen chen, minghui qiu, w. brucecroft, and mohit iyyer.
2020. open-retrieval con-in proceedings ofversational question answering.
the 43rd international acm sigir conference onresearch and development in information retrieval,sigir 2020, pages 539–548..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners.
openaiblog, 1(8):9..5647filip radlinski and nick craswell.
2017. a theoreticalin proceed-framework for conversational search.
ings of the 2017 conference on conference humaninformation interaction and retrieval, chiir 2017,pages 117–126..ramakrishna vedantam, c lawrence zitnick, and deviparikh.
2015. cider: consensus-based image de-in proceedings of the ieeescription evaluation.
conference on computer vision and pattern recog-nition, cvpr, pages 4566–4575..pengjie ren, zhumin chen, christof monz, jun ma,and maarten de rijke.
2020. thinking globally,acting locally: distantly supervised global-to-localknowledge selection for background based conver-in the thirty-fourth aaai conference onsation.
artiﬁcial intelligence, aaai, pages 8697–8704..nikos voskarides, dan li, pengjie ren, evangeloskanoulas, and maarten de rijke.
2020. query reso-lution for conversational search with limited supervi-sion.
in proceedings of the 43rd international acmsigir conference on research and development ininformation retrieval, sigir 2020, pages 921–930..pengjie ren, zhumin chen, zhaochun ren, evange-los kanoulas, christof monz, and maarten de rijke.
2021a.
conversations with search engines: serp-based conversational response generation.
acmtransactions on information systems (tois), 2021..pengjie ren, zhongkun liu, xiaomeng song, hong-tao tian, zhumin chen, zhaochun ren, and maartende rijke.
2021b.
wizard of search engine: accessto information through conversations with search en-in proceedings of the 44rd internationalgines.
acm sigir conference on research and develop-ment in information retrieval, sigir 2021..corbin rosset, chenyan xiong, xia song, daniel cam-pos, nick craswell, saurabh tiwary, and paul n.bennett.
2020. leading conversational search bysuggesting useful questions.
in proceedings of theweb conference, www 2020, pages 1160–1170..sascha rothe, shashi narayan, and aliaksei severyn.
2020. leveraging pre-trained checkpoints for se-quence generation tasks.
trans.
assoc.
comput.
lin-guistics, 8:264–280..ying shen, yang deng, min yang, yaliang li, nan du,wei fan, and kai lei.
2018. knowledge-aware at-tentive neural network for ranking question answerpairs.
in proceedings of the 41st international acmsigir conference on research and development ininformation retrieval, sigir 2020, pages 901–904..hui su, xiaoyu shen, rongzhi zhang, fei sun, peng-wei hu, cheng niu, and jie zhou.
2019.improv-ing multi-turn dialogue modelling with utterancerewriter.
in proceedings of the 57th conference ofthe association for computational linguistics, acl2019, pages 22–31..md.
arafat sultan, shubham chandel, ram´on fernan-dez astudillo, and vittorio castelli.
2020. on theimportance of diversity in question generation forqa.
in proceedings of the 58th annual meeting ofthe association for computational linguistics, acl2020, pages 5651–5656..richard s. sutton and andrew g. barto.
1998. rein-forcement learning: an introduction.
mit press..svitlana vakulenko, shayne longpre, zhucheng tu,and raviteja anantha.
2020. question rewriting forconversational question answering.
arxiv preprintarxiv:2004.14652..yansen wang, chenyi liu, minlie huang, and liqiangnie.
2018.learning to ask questions in open-domain conversational systems with typed decoders.
in proceedings of the 56th annual meeting of the as-sociation for computational linguistics, acl 2018,pages 2193–2203..sam wiseman and alexander m. rush.
2016.sequence-to-sequence learning as beam-search opti-mization.
in proceedings of the 2016 conference onempirical methods in natural language processing,emnlp 2016, pages 1296–1306..jingjing xu, yuechen wang, duyu tang, nan duan,pengcheng yang, qi zeng, ming zhou, and xu sun.
2019. asking clariﬁcation questions in knowledge-in proceedings of thebased question answering.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing,emnlp-ijcnlp 2019, pages 1618–1629..kun xu, haochen tan, linfeng song, han wu,haisong zhang, linqi song, and dong yu.
2020.semantic role labeling guided multi-turn dialoguerewriter.
in proceedings of the 2020 conference onempirical methods in natural language processing,emnlp 2020, pages 6632–6639..shi yu, jiahua liu, jingqin yang, chenyan xiong,paul n. bennett, jianfeng gao, and zhiyuan liu.
2020.few-shot generative conversational queryrewriting.
in proceedings of the 43rd internationalacm sigir conference on research and develop-ment in information retrieval, sigir 2020, pages1933–1936..hamed zamani and nick craswell.
2020. macaw: anextensible conversational information seeking plat-form.
in proceedings of the 43rd international acmsigir conference on research and developmentin information retrieval, sigir 2020, pages 2193–2196..hamed zamani, susan t. dumais, nick craswell,paul n. bennett, and gord lueck.
2020. gener-ating clarifying questions for information retrieval.
in proceedings of the web conference 2020, www2020, pages 418–428..yongfeng zhang, xu chen, qingyao ai, liu yang,and w bruce croft.
2018. towards conversational.
5648search and recommendation: system ask, user re-in proceedings of the 27th acm interna-spond.
tional conference on information and knowledgemanagement, cikm 2018, pages 177–186..5649appendix.
for reproducibility for all reported experimental re-sults, we report the following information.
the av-erage running time for rise, querysim, trans++,qgdiv, -mld, -dps are 15 hours, 5 hours, 9.5hours, 9 hours, 9 hours, 15 hours, respectively.
the number of parameters in rise, trans++, qg-div, -mld, -dps are 221m and the number ofparameters in querysim is 125m.
we list the val-idation performance on canard in table.
4, asonly canard is used for validation.
as we cansee, it has high correlation to test performance oncanard.
we use this script 3 for evaluation..table 4: overall performance (%) on validation set ofcanard.
note that we denote bleu-n as b-n androuge-l as r-l..canard (%).
method.
b-1 b-2 b-3 b-4 r-l cider.
86.5 80.3 75.4 71.3 86.2trans++qgdiv87.0 80.9 75.9 61.8 86.8querysim 83.9 79.7 75.9 72.5 83.2.
-dps-mldrise.
67.2 55.9 46.8 39.4 74.387.0 80.9 75.9 61.8 86.888.0 82.6 78.3 74.6 87.5.
6.7046.7866.737.
3.7456.7867.050.for reproducibility for experiments with hyper-parameter search, we report the following infor-mation.
the hyperparameter for rise is the maxediting iteration times.
we search it in range of 1to 5 and ﬁnd 3 can perform best on bleu-4.
theresults in range of 1 to 5 on bleu-4 are 70.5%,71.5%, 71.6%, 71.6% and 71.6%, respectively..3https://github.com/maluuba/nlg-eval.
5650