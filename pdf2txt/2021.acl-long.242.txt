online learning meets machine translation evaluation: finding the bestsystems with the least human effortvˆania mendonc¸a1,2, ricardo rei1,2,3, lu´ısa coheur1,2,alberto sardinha1,2, ana l ´ucia santos4,51 inesc-id lisboa, portugal2 instituto superior t´ecnico, universidade de lisboa, portugal3 unbabel ai, lisboa, portugal4 centro de lingu´ıstica da universidade de lisboa, portugal5 faculdade de letras da universidade de lisboa, portugal{vania.mendonca, luisa.coheur, jose.alberto.sardinha}@tecnico.ulisboa.pt,ricardo.rei@unbabel.com, als@letras.ulisboa.pt.
abstract.
in machine translation, assessing the qualityof a large amount of automatic translations canbe challenging.
automatic metrics are not re-liable when it comes to high performing sys-tems.
in addition, resorting to human evalua-tors can be expensive, especially when evalu-ating multiple systems.
to overcome the latterchallenge, we propose a novel application ofonline learning that, given an ensemble of ma-chine translation systems, dynamically con-verges to the best systems, by taking advantageof the human feedback available.
our experi-ments on wmt’19 datasets show that our on-line approach quickly converges to the top-3ranked systems for the language pairs consid-ered, despite the lack of human feedback formany translations..1.introduction.
in machine translation (mt), measuring the qual-ity of a large amount of automatic translations canbe a challenge.
automatic metrics like bleu (pap-ineni et al., 2002) remain popular due to their fastand free computations.
yet, in the last few yearswe have seen that, as mt quality improves, auto-matic metrics become less reliable (ma et al., 2019;mathur et al., 2020).
for example, in the con-ference on machine translation (wmt)’19 newstranslation shared task, the winning system accord-ing to human annotators was not even in the top-5according to bleu (barrault et al., 2019).
on theother hand, using human assessments can be expen-sive, especially when evaluating multiple systems.
in a real world scenario, given an arbitrary numberof mt systems, one would need to evaluate themindividually to ﬁnd the best systems for a given lan-guage pair.
however, that requires a considerableeffort and there may not be enough human anno-tators to evaluate all the systems’ translations.
for.
instance, in the aforementioned wmt’19 sharedtask, many translations from the competing sys-tems did not receive any human assessment..given an ensemble of competing, independentmt systems, how can we dynamically ﬁnd the bestones for a given language pair, while making themost of existing human feedback?
to address thisquestion, we present a novel application of onlinelearning to mt: each mt system in the ensembleis assigned to a weight, and the systems’ weightsare updated considering human feedback regardingthe quality of their translations at each iteration.
we use online learning algorithms with theoreticalperformance guarantees, under the frameworks ofprediction with expert advice (cesa-bianchi andlugosi, 2006) and multi-armed bandits (robbins,1952; lai and robbins, 1985)..we contribute with an online mt ensemble thatallows to reduce human effort by immediately in-corporating human feedback in order to dynam-ically converge to the best systems1.
our experi-ments on wmt’19 news translation test sets showthat our online approaches indeed converge to theshared task’s ofﬁcial top-3 systems (or to a subsetof them) in just a few hundred iterations for all thelanguage pairs experimented.
moreover, it doesso while coping with the aforementioned lack ofhuman assessments for many translations, throughthe use of fallback metrics..2 online learning frameworks.
to provide some background on our proposal, westart by describing the online learning frameworksthat we apply in this paper: prediction with expertadvice and multi-armed bandits..a problem of prediction with expert advice canbe described as an iterative game between a fore-.
1the code for our experiments can be found in https:.
//github.com/vania-mendonca/mtol.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3105–3117august1–6,2021.©2021associationforcomputationallinguistics3105caster and the environment, in which the forecasterseeks advice from different sources (experts) in or-der to provide the best forecast (cesa-bianchi andlugosi, 2006).
at each iteration t, the forecasterconsults the predictions ˆpj,t, j = 1 .
.
.
j, made bya set of j weighted experts, in the decision spaced. considering these predictions, the forecastermakes its own prediction, ˆpf,t ∈ d. at the sametime, the environment reveals an outcome yt in thedecision space y (which may not necessarily bethe same as d)..a well-established algorithm to learn the ex-perts’ weights in this framework is exponen-tially weighted average forecaster (ewaf) (cesa-bianchi and lugosi, 2006).
in ewaf, the predic-tion made by the forecaster is randomly selectedfollowing the probability distribution based on theexperts’ weights ω1,t−1 .
.
.
ωj,t−1:.
ˆpf,t =.
(cid:80)j.j=1 ωj,t−1pj,t(cid:80)jj=1 ωj,t−1.
..(1).
at the end of each iteration, the forecaster andeach of the experts receive a non-negative lossbased on the outcome yt revealed by the environ-ment ((cid:96)f,t and (cid:96)j,t, respectively).
the weight ωj,t ofeach expert j = 1 .
.
.
j is then updated accordingto the loss received by each expert, as follows:.
ωj,t = ωj,t−1e−η(cid:96)j,t.
(2).
(cid:113) 8 log jt.if the parameter η is set to.
, it can beshown that the forecaster quickly converges to theperformance of the best expert after t iterations(cesa-bianchi and lugosi, 2006)..prediction with expert advice assumes that boththe forecaster and all the experts receive a lossonce the environment’s outcome is revealed.
how-ever, this assumption may not always hold (i.e.,there may not always be an environment’s explicitfeedback or a way to obtain the loss for all theexperts).
thus, we consider a related class of prob-lems, multi-armed bandits, in which the environ-ment’s outcome is unknown (robbins, 1952; laiand robbins, 1985).
in this class of problems, onestarts by attempting to estimate the means of theloss distributions for each expert (also known asarm) in the ﬁrst iterations (the exploration phase),and when the forecaster has a high level of conﬁ-dence in the estimated values, one may keep choos-ing the prediction with the smallest estimated loss(the exploitation phase)..a popular online algorithm for adversarial multi-armed bandits is exponential-weighting for explo-ration and exploitation (exp3) (auer et al., 1995).
at each iteration t, the forecaster’s action is ran-domly selected according to the probability distri-bution given by the weights of each arm j:.
ˆpf,t =.
ωjj(cid:48)=1 ωj(cid:48).
(cid:80)j.
(3).
in this framework, the forecaster is only ableto measure the loss of the action it selects at eachiteration, but it cannot measure the loss of otherpossible actions.
thus, only the weight of the armassociated with this action is updated, as follows:.
ωj,t = ωj,t−1e−η ˆ(cid:96)j,t.
(4).
where ˆ(cid:96)j,t = (cid:96)j,tand pj,t is the probability ofpj,tchoosing arm j at iteration t. by setting η to(cid:113) 2logjt |a| (where |a| is the number the actions avail-able, and may be the same as the number of armsj), it can be shown that the forecaster quickly con-verges to the performance of the best arm..both of these frameworks are relatively under-explored in nlp, despite their potential to convergeto the best performing approach available in scenar-ios where feedback is naturally present.
therefore,we propose to apply them in order to ﬁnd the bestmt models with little human feedback..3 machine translation with online.
learning.
in this work, we consider the following scenarioas the starting point: there is an ensemble com-posed of an arbitrary number of mt systems; givena segment from a source language corpus, eachsystem outputs a translation in the target language;then, the quality of the translations produced byeach of the available systems is assessed by one ormore human evaluators with a score reﬂecting theirquality..we frame this scenario as an online learningproblem under two different frameworks: (i) predic-tion with expert advice (using ewaf as the learn-ing algorithm), and (ii) multi-armed bandits (usingexp3 as the learning algorithm).
the decision onwhether to use one or another framework in an mtscenario depends on whether there is human feed-back available for the translations outputted by allthe available systems or only for the ﬁnal choice ofthe ensemble of systems..31064.1 datasets.
we used the test datasets made available by thewmt’19 news translation shared task (barraultet al., 2019).
for each language pair, each sourcesegment is associated with the following informa-tion:.
• a reference translation in the target language.
(produced speciﬁcally for the task);.
• the automatic translation outputted by eachsystem competing in the task for that languagepair;.
• the average score obtained by each automatictranslation, according to human assessmentsmade by one or more human evaluators, intwo formats: a raw score in [0;100] and a z-score in [−∞; +∞].
not all the automatictranslations received a human assessment;.
• the number of human evaluators for each au-.
tomatic translation (if there were any)..for brevity, we focused on ﬁve language pairs,listed in table 1. the ofﬁcial top 3 systems for eachpair, according to the average z-score, are shown intable 2. our choice of language pairs attempts tocapture as many different phenomena as possiblewith the fewest pairs:.
• english → german (en-de): this is the lan-guage pair with the most competitors and doesnot have a clear winning system (the winnerdiffers depending on whether one considersthe z-score or the raw score);.
• french → german (fr-de): unlike mostlanguage pairs, this pair features two lan-guages other than english.
moreover, there isa strong imbalance between translations lack-ing human assessments and translations thatreceived at least one assessment;.
• german → czech (de-cs): besides featur-ing two languages other than english, thispair stands out as it was devised as an unsu-pervised task (i.e., english was used as a “hub”language);.
• gujarati → english (gu-en): this is one ofthe task’s low-resource language pairs (i.e.,whose test set is half the size of most language-pairs in the task), and is one where there may.
figure 1: overview of the online learning process ap-plied to mt, at each iteration t. the grey dashed arrowsrepresent ﬂows that only occur when using predictionwith expert advice..an overview of the online learning process isshown in fig.1, and can be summed up as follows.
each mt system is an expert (or arm) j = 1 .
.
.
j,associated with a weight ωj (all the systems startwith same weights).
at each iteration t, a seg-ment srct is selected from the source languagecorpus and handed to all the mt systems.
eachsystem outputs a translation translj,t in the targetlanguage, and one of these translations is selectedas the forecaster’s action according to the proba-bility distribution given by the systems’ weights(eq.1 for ewaf and eq.
3 for exp3).
the cho-sen translation translf,t (when using exp3) orthe translations outputted by all the systems (whenusing ewaf) receive a human assessment score2scorej,t, from which the loss (cid:96)j,t is derived for therespective mt system.
finally, the weight of thechosen system or the weights of all the systems areupdated as a function of the loss received, accord-ing to eq.4 (when using exp3) and eq.2 (when us-ing ewaf), respectively (where (cid:96)j,t = −scorej,t)..4 experimental setup.
to validate our proposal, we designed an exper-iment using data from an mt shared task.
themain questions addressed by our experiment are:(i) whether an online learning approach can give agreater weight to the top performing systems foreach language pair according to the shared task’sofﬁcial ranking, and (ii) if so, how quickly (i.e.,how many translations need to be assessed by hu-man evaluators in order to ﬁnd the best system)..below we detail the datasets used (section 4.1)and the feedback sources considered (section 4.2),as well as other experimental decisions (sec-tion 4.3)..2if multiple human assessments were made for the same.
translation, scorej,t is the average of the scores received..3107mt1mtjmt2ω1 ω2 ωj ... ℓj,t  ℓ2,t  ℓ1,t ...transl1,ttransl2,ttranslj,t...humanevaluatorssrctscore1,tscore2,tscorej,t...translf,tscoref,t ℓf,t en-de fr-de de-cs gu-en lt-en.
test set size (# segments)competing systemshuman assessments coverage.
199722.
19971186.80% 23.52% 62.94% 75.00% 100.00%.
170110.
101612.
100011.table 1: overview of the language pairs considered in our experiments..top 3.z-score raw score.
e facebook-fair (ng et al., 2019)d-ne.microsoft-sent-doc (junczys-dowmunt, 2019)microsoft-doc-level (junczys-dowmunt, 2019).
e msra-madl (xia et al., 2019)d-rf.etranslation (oravecz et al., 2019)lium (bougares et al., 2019).
s online-yconline-b-enict (dabre et al., 2019)d.n neu (li et al., 2019)e-ug.uedin (bawden et al., 2019)gtcom-primary (bei et al., 2019).
n gtcom-primary (bei et al., 2019)etilde-nc-nmt (pinnis et al., 2019)-tneu (li et al., 2019)l.0.3470.3110.296.
0.2670.2460.082.
0.4260.3860.367.
0.2100.1260.100.
0.2340.2160.213.
90.393.092.6.
82.481.578.5.
63.962.761.4.
64.861.759.4.
77.477.577.0.table 2: top 3 performing systems for each language pair in the wmt’19 news translation shared task (barraultet al., 2019).
the systems named “online-[letter]” correspond to publicly available translation services and wereanonimized in the shared task..be more linguistic differences between thesource and the target languages (e.g., differentwriting systems).
unlike en-de, there is aclear winner considering both raw and z-score.
moreover, three of the competing systems didnot receive any human assessment on theirtranslations;.
• lithuanian → english (lt-en): this is an-other low-resource language pair, with a rathercompetitive top 3. unlike most language pairs,all the translations submitted by the compet-ing systems for this pair received a humanassessment..for all these language pairs (except english →german), each segment was given an assessmentscore considering only the reference translation(and without access to the segment’s context withinthe document to which it belongs).
for english →german, scores were given considering the sourcesegment instead of the reference, and evaluators.
had access to the segment’s context within the doc-ument..4.2 human feedback.
a key condition for applying online learning tothis scenario is the availability of feedback.
weuse the human assessment raw scores3 present inthe test sets as a feedback source to compute theloss and update the weight of each mt system,as already suggested in section 3. however, notall translations received human assessments (recalltable 1).
to cope with this issue, we designeddifferent variants of this loss function, followingdifferent fallback strategies:.
• human-zero: if there is no human assess-ment for the current translation, a score of zerois returned (leading to an unchanged weighton that iteration);.
3although we assume an absolute scale of scores in [0;100]in our experiments, our approach could be applied to any otherlevel of granularity..3108• human-avg: if there is no human assess-ment for the current translation, the averageof the previous scores received by the systembehind that translation is returned as the cur-rent score;.
• human-comet: if there is no human assess-ment for the current translation, the cometscore (rei et al., 2020a) between the transla-tion and the pair source/reference availablein the corpus is returned as the current score.
we pre-trained4 this automatic metric on thedatasets of previous shared tasks (wmt’17(bojar et al., 2017) and wmt’18 (bojar et al.,2018)).
thus, for most translations, it displaysa small difference regarding the existing hu-man scores (see fig.
2 for the case of en-de).
moreover, this metric correlates better withratings by professional translators than thewmt scores (freitag et al., 2021)..figure 2: distribution of the difference between the (ex-isting) human assessments and comet scores for thesame translations, on the en-de test set..4.3 experimental design.
for each language pair, we shufﬂed the test setonce, so that the performance of the online algo-rithms would not be biased by the original order ofthe segments in the test set.
we ran ewaf oncefor each loss function, and we ran exp3 10 timesper loss function and report the average weightsobtained across runs, since exp3’s weight evolu-tion is critically inﬂuenced by the random choice ofan arm at each iteration.
we normalized the trans-lation scores scorej,t to be in the interval [0, 1]and rounded them to two decimal places, to avoidexploding weight values due to the exponential up-date rule..4we trained this metric from scratch following the hyper-parameters described in rei et al.
(2020b), except that we usedthe raw scores instead of the z-normalized scores..5 results and discussion.
in order to observe whether (and how soon) ouronline approach converges to the best systems, wereport the overlap between the top n = 1, 3 systemswith greatest weights according to our approaches,ˆsn, and the top n = 1, 3 systems according tothe shared task’s ofﬁcial ranking, s∗n, at speciﬁciterations:.
topn =.
| ˆsn ∩ s∗n|n., n = 1, 3.
(5).
we preferred this metric over a rank correlationmetric, as we are focused on whether our onlineapproach follows the performance of the best mtsystems.
in a realistic scenario (e.g., a web mtservice), a user would most likely rely solely onthe main translation returned, or would at mostconsider one or two alternative translations.
more-over, due to the lack of a large enough coverageof human assessments, the scores obtained in theshared task are not reliable enough to discriminatebetween similarly performing systems..starting with en-de (table 3), this was the lan-guage pair for which our approach appears to bethe least successful, since, for most of the itera-tions examined, it failed to converge to the bestsystem.
even so, it managed to converge to the top3 systems, doing so particularly early in the learn-ing process (50 iterations) when using ewaf withhuman-avg and human-comet as loss func-tions (i.e., when using fallback scores).
recall that,for this language pair, there were different ofﬁcialwinning systems depending on whether one con-siders the z-score or the raw score (recall table 2);since we use the raw score as the loss function, it isexpectable that our approach does not necessarilyconverge to the winner according to the z-score..for fr-de (table 4), our online approach oftenconverges to the top 3 systems (or a subset of them)throughout the learning process (even at just 10iterations), and it also converges to the best systemwhen using ewaf with human-comet.
this isa particularly interesting result if we recall that,out of the ﬁve pairs considered, fr-de had thelowest coverage of human assessments by far (seetable 1), thus suggesting that using comet maybe an adequate fallback strategy..for de-cs (table 5), we can see that, regardlessof the algorithm and loss function used, there is anoverlap of at least one system between our top 3 andthe shared task’s ofﬁcial top 3, after going through.
31091.000.750.500.250.000.250.500.751.00| comet - human |0.00.51.01.52.02.5probability densityiteration.
10.
50.
100.
500.
1000.
1997.top.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.f human-zeroahuman-avgwehuman-comet.
3pxe.human-zerohuman-avghuman-comet.
0.000.000.00.
0.000.000.00.
0.330.000.33.
0.330.000.00.
0.001.000.00.
0.000.000.00.
0.000.671.00.
0.000.330.00.
0.001.000.00.
0.000.000.00.
0.330.330.67.
0.000.670.33.
1.000.000.00.
0.000.000.00.
0.671.001.00.
0.330.330.00.
1.000.000.00.
1.000.000.00.
0.671.001.00.
0.330.330.00.
0.000.000.00.
1.000.000.00.
0.671.001.00.
0.330.330.33.table 3: overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcialranking for en-de.
recall that, for this pair, the ofﬁcial ranking differed depending on whether the z-score or theraw score was considered..iteration.
10.
50.
100.
500.
1000.
1701.top.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.f human-zeroahuman-avgwehuman-comet.
3pxe.human-zerohuman-avghuman-comet.
0.000.001.00.
0.000.000.00.
0.670.671.00.
0.670.330.33.
0.000.001.00.
0.000.000.00.
0.330.670.67.
0.330.330.67.
0.000.001.00.
0.000.000.00.
0.330.671.00.
0.330.330.67.
0.000.001.00.
0.000.000.00.
0.670.331.00.
0.330.330.33.
0.000.001.00.
1.000.000.00.
0.670.331.00.
0.670.330.67.
1.000.001.00.
1.000.000.00.
0.670.331.00.
0.670.330.67.table 4: overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcialranking for fr-de.
recall that this was the language pair with the lowest coverage of human assessments..iteration.
10.
50.
100.
500.
1000.
1997.top.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.f human-zeroahuman-avgwehuman-comet.
3pxe.human-zerohuman-avghuman-comet.
0.000.000.00.
0.000.000.00.
0.330.330.33.
0.330.330.33.
1.000.001.00.
0.000.001.00.
0.670.330.67.
0.670.330.33.
1.001.001.00.
0.000.001.00.
0.670.670.67.
0.670.330.33.
0.001.001.00.
0.000.001.00.
0.670.671.00.
0.670.670.67.
1.001.001.00.
0.001.001.00.
1.000.671.00.
0.670.670.67.
0.001.001.00.
1.001.001.00.
1.001.001.00.
1.000.670.67.table 5: overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcialranking for de-cs..only as few as 10 iterations (despite a considerablelack of human assessments in this language pair).
we can also see that the human-comet loss func-tion is the most successful overall, which reinforcesthe idea that comet may be an appropriate fall-back metric in the absence of human scores for agiven translation.
since this is the language pairfor which there seems to be a more similar perfor-mance across different algorithms and loss func-tions, we also report the weight evolution plots forthis pair in order to inspect what changes depending.
on the algorithm and fallback strategy used5.
look-ing at ewaf combined with the human-zeroloss function (fig.
3), one can see a rather irreg-ular evolution for the weights of the top systems,which may be explained by the distribution of thetranslations lacking human assessments across dif-ferent systems and learning iterations.
using thehuman-avg loss function (fig.4) allows for amore monotonous evolution, by rewarding the sys-.
5the plots for the remaining pairs can be found in app.
a..3110iteration.
10.
50.
100.
500.
1000.
1016.top.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.f human-zeroawe.human-comet.
3 human-zeropxe.human-comet.
1.001.00.
0.000.00.
0.670.67.
0.330.33.
1.000.00.
0.001.00.
1.000.67.
0.670.33.
1.000.00.
0.001.00.
1.000.67.
0.330.33.
1.000.00.
0.001.00.
0.670.67.
0.330.33.
1.000.00.
0.000.00.
0.670.33.
0.330.67.
1.000.00.
0.000.00.
0.670.33.
0.330.67.table 6: overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcialranking for gu-en.
recall that there were three systems competing on this language pair that did not receivehuman assessments at all (thus, using human-avg yields the same results as using human-zero)..iteration.
10.
50.
100.
500.
1000.top.
1.
3.
1.
3.
1.
3.
1.
3.
1.
3.ewaf.
human-zero.
0.00.
0.00.
0.00.
0.67.
0.00.
0.67.
1.00.
0.67.
0.00.
1.00.exp3.
human-zero.
0.00.
0.33.
0.00.
0.00.
0.00.
0.33.
1.00.
0.67.
1.00.
0.67.table 7: overlap ratios of top 1 and top 3 systems in common between the online approaches and the ofﬁcialranking for lt-en.
recall that this was the only language pair for which all the translations received at least onehuman assessment, thus there is no need to use a fallback loss function..tems that were doing better overall in the absenceof human assessments.
using the human-cometloss function (fig.
5) paints a similar picture, asthe comet scores for this language pair seem tobe in line with the ofﬁcial ranking (although theyappear to beneﬁt the third best system in detrimentof the second best).
finally, using exp3 insteadof ewaf (fig.
6), combined with human-zero,leads to much less pronounced weights, but stillin line with the ofﬁcial ranking.
recall that, forexp3, these weights are averaged across differentruns: since each run may lead to different top sys-tems, the difference between the averaged weightsends up being more smooth, i.e., there is a greatvariance across runs (this happens regardless of thelanguage pair or loss function)..as for gu-en (table 6), our approach (usingewaf with human-zero) converges to the bestsystem and to a subset of the top 3 within just 10 it-erations; on the other hand, using human-cometdoes not do as well as not using a fallback strategy,at least when combined with ewaf.
however,recall that, for this pair, there were systems thatdid not receive any human assessments at all fortheir translations (that being the reason why wedo not report human-avg for this pair: the result-ing weights end up being the same as when usinghuman-zero).
one of the systems that did not re-ceive any human assessments, online-b, ended.
up receiving high comet scores, thus leading to aweaker overlap between the online approach rank-ing and the ofﬁcial ranking..finally, for lt-en (table 7) we only report thehuman-zero loss function, since this is the onlypair for which there are human assessments for alltranslations.
interestingly, the online approachesdo not do well as quickly as for other pairs, buteventually get there (within 100 to 500 iterations).
to sum up these results: although factors likethe coverage of human assessments or the combi-nations of online algorithm and loss function usedinﬂuence how well our approach does, we can stillconclude that using an online learning approachallows to converge to the top 3 systems accordingto the ofﬁcial ranking (or at least to a subset ofthem) in just a few hundred iterations (and, in somecases, in just a few dozens of iterations) for all thelanguage pairs considered..6 related work.
6.1 wmt’19 news translation shared task.
every year, since 2006, the conference on ma-chine translation (wmt) is responsible for orga-nizing several shared tasks where participants pushthe limits of mt and mt evaluation (koehn andmonz, 2006; barrault et al., 2020).
in the newstranslation shared task, participants submit the out-.
3111figure 3: weight evolution per mt system when using ewaf and human-zero as the loss function (de-cs).
recall that, for this language pair, the ofﬁcial top 3 systems were online-y, online-b, and nict..figure 4: weight evolution per mt system when using ewaf and human-avg as the loss function (de-cs)..figure 5: weight evolution per mt system when using ewaf and human-comet as the loss function (de-cs)..figure 6: weight evolution per mt system when using exp3 and human-zero as the loss function (de-cs),averaged across 10 runs (the error bars represent the weights’ variance across the 10 runs)..puts of their systems that are then evaluated by acommunity of human evaluators using direct as-sessment scores (graham et al., 2013).
thus, thewinner is the system that achieves the highest av-erage score.
for wmt’19 (barrault et al., 2019),most of the competing systems followed a trans-former architecture (vaswani et al., 2017), with the.
main differences among them being: (i) whetherthey considered document-level or only sentence-level information; (ii) whether they were trainedonly on the training data provided by the sharedtask, or on additional sources as well; (iii) whetherthey consisted of a single model or an ensemble..311201002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-b.0nict.6938caire.6949online-g.0online-a.0lmu-unsup-nmt-de-cs.6845neu_kingsoft.6766cuni-unsupervised-ner-post.6934unsupervised.de-cs.6935unsupervised.de-cs.692901002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-b.0nict.6938caire.6949online-g.0online-a.0lmu-unsup-nmt-de-cs.6845neu_kingsoft.6766cuni-unsupervised-ner-post.6934unsupervised.de-cs.6935unsupervised.de-cs.692901002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-b.0nict.6938caire.6949online-g.0online-a.0lmu-unsup-nmt-de-cs.6845neu_kingsoft.6766cuni-unsupervised-ner-post.6934unsupervised.de-cs.6935unsupervised.de-cs.692901002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-b.0nict.6938caire.6949online-g.0online-a.0lmu-unsup-nmt-de-cs.6845neu_kingsoft.6766cuni-unsupervised-ner-post.6934unsupervised.de-cs.6935unsupervised.de-cs.69296.2 online learning for machine translation.
there has been a number of online learning ap-proaches applied to mt in the past, mainly ininteractive mt and/or post-editing mt systems.
however, most approaches aim at learning theparameters or feature weights of an mt model(mathur et al., 2013; denkowski et al., 2014; ortiz-mart´ınez, 2016; sokolov et al., 2016; nguyenet al., 2017; lam et al., 2018) or ﬁne-tuning a pre-trained model for domain adaptation (turchi et al.,2017; karimova et al., 2018; peris and casacuberta,2019).
even in cases where the mt model is com-posed of several sub-models (e.g., ortiz-mart´ınez(2016)), the goal is to online learn each sub-model’sspeciﬁc parameters (while our learning goal is theweights of each system in an ensemble).
anotherkey difference between these approaches and oursis that most of them use human post-edited trans-lations as a source of feedback.
the exceptions tothis are the systems competing for wmt’17 sharedtask on online bandit learning for mt (sokolovet al., 2017), as well as lam et al.
(2018), who use(simulated) quality judgments..the most similar proposal to ours is that ofnaradowsky et al.
(2020), who ensemble differentmt systems and dynamically select the best one fora given mt task or domain using stochastic multi-armed bandits and contextual bandits.
the banditalgorithms learn from feedback simulated using asentence-level bleu score between the selectedautomatic translation and a reference translation..thus, to the best of our knowledge, we are theﬁrst to frame the mt problem as a problem ofprediction with expert advice and adversarial multi-armed bandits in order to combine different sys-tems into an ensemble that converges to the perfor-mance of the best individual systems, simulatingthe human-in-the-loop by using actual human as-sessments (when available)..7 conclusions and future work.
we proposed an online learning approach to ad-dress the issue of ﬁnding the best mt systemsamong an ensemble, while making the most ofexisting human feedback.
in our experiments onwmt’19 news translation datasets, our approachconverged to the top-3 systems (or a subset of them)according to the ofﬁcial shared task’s ranking injust a few hundred iterations for all the languagepairs considered (and just a few dozens in somecases), despite the lack of human assessments for.
many translations.
this is a promising result, notonly for the purpose of reducing the human evalua-tions required to ﬁnd the best systems in a sharedtask, but also for any mt application that has ac-cess to an ensemble of multiple independent sys-tems and to a source of feedback from which it canlearn iteratively (e.g., web translation services)..yet, our approach is limited by the quality of thecollected human judgments.
for future work, weplan to combine online learning with a more reli-able human metric, such as the multidimensionalquality metric (mqm) (lommel et al., 2014), sothat we can focus on the quality of the assessmentsinstead of their quantity..acknowledgments.
this work was supported by: fundac¸ ˜ao paraa ciˆencia e a tecnologia (fct) under refer-ences uidb/50021/2020 (inesc-id multi-annualfunding) and uidb/00214/2020 (clul), as wellas under the hotspot project with referenceptdc/cci-com/7203/2020; air force ofﬁce ofscientiﬁc research under award number fa9550-19-1-0020; p2020 program, supervised by agˆencianacional de inovac¸ ˜ao (ani), under the projectcmu-pt ref.
045909 (maia).
vˆania mendonc¸awas funded by an fct grant with referencesfrh/bd/121443/2016..the authors would like to thank the reviewers fortheir valuable comments, and to soraia m. alarc˜aofor kindly proof-reading this document..references.
peter auer, nicolo cesa-bianchi, yoav freund, androbert e. schapire.
1995. gambling in a riggedcasino: the adversarial multi-armed bandit problem.
in annual symposium on foundations of computerscience - proceedings, pages 322–331..lo¨ıc barrault, magdalena biesialska, ondˇrej bojar,marta r. costa-juss`a, christian federmann, yvettegraham, roman grundkiewicz, barry haddow,matthias huck, eric joanis, tom kocmi, philippkoehn, chi-kiu lo, nikola ljubeˇsi´c, christofmonz, makoto morishita, masaaki nagata, toshi-aki nakazawa, santanu pal, matt post, and marcoszampieri.
2020. findings of the 2020 conference onin proceedings ofmachine translation (wmt20).
the fifth conference on machine translation, pages1–55, online.
association for computational lin-guistics..lo¨ıc barrault, ondˇrej bojar, marta r. costa-juss`a,christian federmann, mark fishel, yvette gra-ham, barry haddow, matthias huck, philipp koehn,.
3113shervin malmasi, christof monz, mathias m¨uller,santanu pal, matt post, and marcos zampieri.
2019.findings of the 2019 conference on machine trans-lation (wmt19).
in proceedings of the fourth con-ference on machine translation (volume 2: sharedtask papers, day 1), pages 1–61, stroudsburg, pa,usa.
association for computational linguistics..rachel bawden, nikolay bogoychev, ulrich germann,roman grundkiewicz, faheem kirefu, antonio va-lerio miceli barone, and alexandra birch.
2019.the university of edinburgh’s submissions to thewmt19 news translation task.
in proceedings ofthe fourth conference on machine translation (vol-ume 2: shared task papers, day 1), pages 103–115, stroudsburg, pa, usa.
association for com-putational linguistics..chao bei, hao zong, conghu yuan, qingming liu,and baoyong fan.
2019. gtcom neural machinein proceedingstranslation systems for wmt19.
of the fourth conference on machine translation(volume 2: shared task papers, day 1), pages 116–121, stroudsburg, pa, usa.
association for compu-tational linguistics..ondˇrej bojar, rajen chatterjee, christian federmann,yvette graham, barry haddow, shujian huang,matthias huck, philipp koehn, qun liu, varvara lo-gacheva, christof monz, matteo negri, matt post,raphael rubino, lucia specia, and marco turchi.
2017. findings of the 2017 conference on machinein proceedings of the sec-translation (wmt17).
ond conference on machine translation, pages 169–214, stroudsburg, pa, usa.
association for compu-tational linguistics..ondˇrej bojar, christian federmann, mark fishel,yvette graham, barry haddow, philipp koehn, andchristof monz.
2018. findings of the 2018 con-ference on machine translation (wmt18).
in pro-ceedings of the third conference on machine trans-lation: shared task papers, pages 272–303, strouds-burg, pa, usa.
association for computational lin-guistics..fethi bougares, jane wottawa, anne baillot, lo¨ıc bar-rault, and adrien bardet.
2019. lium’s contribu-tions to the wmt2019 news translation task: dataand systems for german-french language pairs.
inproceedings of the fourth conference on machinetranslation (volume 2: shared task papers, day 1),pages 129–133, stroudsburg, pa, usa.
associationfor computational linguistics..n. cesa-bianchi and g. lugosi.
2006. prediction,learning and games.
cambridge university press..raj dabre, kehai chen, benjamin marie, rui wang,atsushi fujita, masao utiyama, and eiichiro sumita.
2019. nict’s supervised neural machine trans-lation systems for the wmt19 news translationtask.
in proceedings of the fourth conference onmachine translation (volume 2: shared task papers,day 1), pages 168–174, stroudsburg, pa, usa.
as-sociation for computational linguistics..michael denkowski, chris dyer, and alon lavie.
2014.learning from post-editing: online model adapta-tion for statistical machine translation.
in proceed-ings of the 14th conference of the european chap-ter of the association for computational linguistics2014, pages 395–404..markus freitag, george foster, david grangier, vireshratnakar, qijun tan, and wolfgang macherey.
2021.experts, errors, and context: a large-scale studyof human evaluation for machine translation..yvette graham, timothy baldwin, alistair moffat, andjustin zobel.
2013. continuous measurement scalesin human evaluation of machine translation.
in pro-ceedings of the 7th linguistic annotation workshopand interoperability with discourse, pages 33–41,soﬁa, bulgaria.
association for computational lin-guistics..marcin junczys-dowmunt.
2019. microsoft transla-tor at wmt 2019: towards large-scale document-level neural machine translation.
in proceedingsof the fourth conference on machine translation(volume 2: shared task papers, day 1), pages 225–233, stroudsburg, pa, usa.
association for compu-tational linguistics..sariya karimova, patrick simianer, and stefan riezler.
2018. a user-study on online adaptation of neuralmachine translation to human post-edits.
machinetranslation, 32(4):309–324..philipp koehn and christof monz.
2006. manual andautomatic evaluation of machine translation betweenin proceedings on the work-european languages.
shop on statistical machine translation, pages 102–121, new york city.
association for computationallinguistics..t. l. lai and herbert robbins.
1985. asymptoticallyefﬁcient adaptive allocation rules.
advances in ap-plied mathematics, 6(1):4–22..tsz kin lam, julia kreutzer, and stefan riezler.
2018.a reinforcement learning approach to interactive-predictive neural machine translation..bei li, yinqiao li, chen xu, ye lin, jiqiang liu,hui liu, ziyang wang, yuhao zhang, nuo xu,zeyang wang, kai feng, hexuan chen, tengbo liu,yanyang li, qiang wang, tong xiao, and jingbozhu.
2019. the niutrans machine translation sys-tems for wmt19.
in proceedings of the fourth con-ference on machine translation (volume 2: sharedtask papers, day 1), pages 257–266, stroudsburg,pa, usa.
association for computational linguis-tics..arle lommel, aljoscha burchardt, and hans uszkoreit.
2014. multidimensional quality metrics (mqm): aframework for declaring and describing translationquality metrics.
tradum`atica: tecnologies de la tra-ducci´o, 0:455–463..3114qingsong ma, johnny wei, ondˇrej bojar, and yvettegraham.
2019. results of the wmt19 metricsshared task: segment-level and strong mt sys-in proceedings of thetems pose big challenges.
fourth conference on machine translation (volume2: shared task papers, day 1), pages 62–90, flo-rence, italy.
association for computational linguis-tics..nitika mathur, timothy baldwin, and trevor cohn.
2020. tangled up in bleu: reevaluating the eval-uation of automatic machine translation evaluationin proceedings of the 58th annual meet-metrics.
ing of the association for computational linguistics,pages 4984–4997, online.
association for computa-tional linguistics..prashant mathur, mauro cettolo, and marcello fed-erico.
2013. online learning approaches in com-in proceedings of theputer assisted translation.
eighth workshop on statistical machine translation,pages 301–308..jason naradowsky, xuan zhang, and kevin duh.
2020.machine translation system selection from banditfeedback.
in proceedings of the 14th conference ofthe association for machine translation in the amer-icas, pages 50–63..nathan ng, kyra yee, alexei baevski, myle ott,michael auli, and sergey edunov.
2019. facebookfair’s wmt19 news translation task submission.
in proceedings of the fourth conference on ma-chine translation (volume 2: shared task papers,day 1), pages 314–319, stroudsburg, pa, usa.
as-sociation for computational linguistics..khanh nguyen, hal daum´e iii, and jordan boyd-graber.
2017. reinforcement learning for banditneural machine translation with simulated humanfeedback.
in proceedings of the 2017 conferenceon empirical methods in natural language process-ing, pages 1464–1474, stroudsburg, pa, usa.
asso-ciation for computational linguistics..csaba oravecz, katina bontcheva, adrien lardilleux,l´aszl´o tihanyi, and andreas eisele.
2019. etransla-tion’s submissions to the wmt 2019 news transla-tion task.
in proceedings of the fourth conferenceon machine translation (volume 2: shared task pa-pers, day 1), pages 320–326, stroudsburg, pa, usa.
association for computational linguistics..daniel ortiz-mart´ınez.
2016. online learning for sta-tistical machine translation.
computational lin-guistics, 42(1):121–161..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2002. bleu: a method for automatic eval-in proceedings ofuation of machine translation.
the 40th annual meeting of the association for com-putational linguistics, pages 311–318, philadelphia,pennsylvania, usa.
association for computationallinguistics..´alvaro peris and francisco casacuberta.
2019. onlinelearning for effort reduction in interactive neural ma-chine translation.
computer speech and language,58:98–126..marcis pinnis, rihards kriˇslauks, and mat¯ıss rikters.
tilde’s machine translation systems for2019.in proceedings of the fourth confer-wmt 2019.ence on machine translation (volume 2: sharedtask papers, day 1), pages 327–334, stroudsburg,pa, usa.
association for computational linguis-tics..ricardo rei, craig stewart, ana c farinha, and alonlavie.
2020a.
comet: a neural framework for mtevaluation.
in proceedings of the 2020 conferenceon empirical methods in natural language process-ing (emnlp), pages 2685–2702, online.
associa-tion for computational linguistics..ricardo rei, craig stewart, ana c farinha, andalon lavie.
2020b.
unbabel’s participation in thein proceedings ofwmt20 metrics shared task.
the fifth conference on machine translation, pages911–920, online.
association for computationallinguistics..herbert robbins.
1952. some aspects of the sequen-tial design of experiments.
bulletin of the ameri-can mathematical society, 58(5):527–535..artem sokolov, julia kreutzer, christopher lo, andstefan riezler.
2016. learning structured predic-tors from bandit feedback for interactive nlp.
inproceedings of the 54th annual meeting of the asso-ciation for computational linguistics, pages 1610–1620..artem sokolov, julia kreutzer, kellen sunderland,pavel danchenko, witold szymaniak, hagen f¨urste-nau, and stefan riezler.
2017. a shared task onin pro-bandit learning for machine translation.
ceedings of the conference on machine translation(wmt), volume 2, pages 514–524..marco turchi, matteo negri, m. amin farajian, andmarcello federico.
2017. continuous learningfrom human post-edits for neural machine transla-tion.
the prague bulletin of mathematical linguis-tics, 108(1):233–244..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in 31st conference on neural informationprocessing systems (nips 2017), pages 5999–6009..yingce xia, xu tan, fei tian, fei gao, weicongchen, yang fan, linyuan gong, yichong leng, ren-qian luo, yiren wang, lijun wu, jinhua zhu, taoqin, and tie-yan liu.
2019. microsoft researchasia’s systems for wmt19.
in proceedings of thefourth conference on machine translation (volume2: shared task papers, day 1), pages 424–433,stroudsburg, pa, usa.
association for computa-tional linguistics..3115a weight evolution (all language pairs).
here we present the weight evolution per mtsystem for allthe combinations of languagepairs, learning algorithms (ewaf or exp3), andloss functions (human-zero, human-avg, orhuman-comet, when applicable) – except forthose combinations that are already part of the maindocument..a.1 english → german (en-de).
figure 11: exp3 with human-avg loss..figure 12: exp3 with human-comet loss..a.2 french → german (fr-de).
figure 7: ewaf with human-zero loss.
recallthe ofﬁcial top 3 sys-that, for this language pair,tems were facebook-fair, microsoft-sent-doc, andmicrosoft-doc-level..figure 13: ewaf with human-zero loss.
recall that,for this language pair, the ofﬁcial top 3 systems weremsra-madl, etranslation, and lium..figure 8: ewaf with human-avg loss..figure 14: ewaf with human-avg loss..figure 9: ewaf with human-comet loss..figure 15: ewaf with human-comet loss..figure 10: exp3 with human-zero loss..figure 16: exp3 with human-zero loss..311601002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsmicrosoft-wmt19-document-level.6808uds-dfki.6871jhu.6819mllp-upv.6651facebook_fair.6862en_de_task.6790ucam.6731neu.6763microsoft-wmt19-sentence_document.6974online-g.0online-x.0etranslation.6823online-b.0dfki-nmt.6479microsoft-wmt19-sentence-level.6785helsinki-nlp.6820online-y.0lmu-ctx-tf-single-en-de.6981msra.madl.6926promt_nmt_en-de.6674online-a.0tartunlp-c.650801002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsmicrosoft-wmt19-document-level.6808uds-dfki.6871jhu.6819mllp-upv.6651facebook_fair.6862en_de_task.6790ucam.6731neu.6763microsoft-wmt19-sentence_document.6974online-g.0online-x.0etranslation.6823online-b.0dfki-nmt.6479microsoft-wmt19-sentence-level.6785helsinki-nlp.6820online-y.0lmu-ctx-tf-single-en-de.6981msra.madl.6926promt_nmt_en-de.6674online-a.0tartunlp-c.650801002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsmicrosoft-wmt19-document-level.6808uds-dfki.6871jhu.6819mllp-upv.6651facebook_fair.6862en_de_task.6790ucam.6731neu.6763microsoft-wmt19-sentence_document.6974online-g.0online-x.0etranslation.6823online-b.0dfki-nmt.6479microsoft-wmt19-sentence-level.6785helsinki-nlp.6820online-y.0lmu-ctx-tf-single-en-de.6981msra.madl.6926promt_nmt_en-de.6674online-a.0tartunlp-c.650801002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsmicrosoft-wmt19-document-level.6808uds-dfki.6871jhu.6819mllp-upv.6651facebook_fair.6862en_de_task.6790ucam.6731neu.6763microsoft-wmt19-sentence_document.6974online-g.0online-x.0etranslation.6823online-b.0dfki-nmt.6479microsoft-wmt19-sentence-level.6785helsinki-nlp.6820online-y.0lmu-ctx-tf-single-en-de.6981msra.madl.6926promt_nmt_en-de.6674online-a.0tartunlp-c.650801002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsmicrosoft-wmt19-document-level.6808uds-dfki.6871jhu.6819mllp-upv.6651facebook_fair.6862en_de_task.6790ucam.6731neu.6763microsoft-wmt19-sentence_document.6974online-g.0online-x.0etranslation.6823online-b.0dfki-nmt.6479microsoft-wmt19-sentence-level.6785helsinki-nlp.6820online-y.0lmu-ctx-tf-single-en-de.6981msra.madl.6926promt_nmt_en-de.6674online-a.0tartunlp-c.650801002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsmicrosoft-wmt19-document-level.6808uds-dfki.6871jhu.6819mllp-upv.6651facebook_fair.6862en_de_task.6790ucam.6731neu.6763microsoft-wmt19-sentence_document.6974online-g.0online-x.0etranslation.6823online-b.0dfki-nmt.6479microsoft-wmt19-sentence-level.6785helsinki-nlp.6820online-y.0lmu-ctx-tf-single-en-de.6981msra.madl.6926promt_nmt_en-de.6674online-a.0tartunlp-c.6508010020030040050060070080090010001100120013001400150016001700iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-a.0tartunlp-c.6514online-g.0lium.6720online-x.0online-b.0etranslation.6262msra.madl.6893mllp-upv.6654010020030040050060070080090010001100120013001400150016001700iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-a.0tartunlp-c.6514online-g.0lium.6720online-x.0online-b.0etranslation.6262msra.madl.6893mllp-upv.6654010020030040050060070080090010001100120013001400150016001700iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-a.0tartunlp-c.6514online-g.0lium.6720online-x.0online-b.0etranslation.6262msra.madl.6893mllp-upv.6654010020030040050060070080090010001100120013001400150016001700iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-a.0tartunlp-c.6514online-g.0lium.6720online-x.0online-b.0etranslation.6262msra.madl.6893mllp-upv.6654figure 17: exp3 with human-avg loss..figure 23: exp3 with human-zero loss..figure 18: exp3 with human-comet loss..figure 24: exp3 with human-comet loss..a.3 german → czech (de-cs).
a.5 lithuanian → english (lt-en).
figure 19: exp3 with human-avg loss.
recall that,for this language pair, the ofﬁcial top 3 systems wereonline-y, online-b, and nict..figure 25: ewaf with human-zero loss.
recall that,for this language pair, the ofﬁcial top 3 systems weregtcom-primary, tilde-nc-nmt, and neu..figure 20: exp3 with human-comet loss..a.4 gujarati → english (gu-en).
figure 26: exp3 and human-zero loss..figure 21: ewaf with human-zero loss.
recall that,for this language pair, the ofﬁcial top 3 systems wereneu, uedin, and gtcom-primary..figure 22: ewaf with human-comet loss..3117010020030040050060070080090010001100120013001400150016001700iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-a.0tartunlp-c.6514online-g.0lium.6720online-x.0online-b.0etranslation.6262msra.madl.6893mllp-upv.6654010020030040050060070080090010001100120013001400150016001700iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-a.0tartunlp-c.6514online-g.0lium.6720online-x.0online-b.0etranslation.6262msra.madl.6893mllp-upv.665401002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-b.0nict.6938caire.6949online-g.0online-a.0lmu-unsup-nmt-de-cs.6845neu_kingsoft.6766cuni-unsupervised-ner-post.6934unsupervised.de-cs.6935unsupervised.de-cs.692901002003004005006007008009001000110012001300140015001600170018001900iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-y.0online-b.0nict.6938caire.6949online-g.0online-a.0lmu-unsup-nmt-de-cs.6845neu_kingsoft.6766cuni-unsupervised-ner-post.6934unsupervised.de-cs.6935unsupervised.de-cs.692901002003004005006007008009001000iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsuds-dfki.6861uedin.6534cuni-t2t-transfer-guen.6431neu.6756iitp-mt.6824online-g.0gtcom-primary.6969iiith-mt.6688nict.6603online-b.0ju_saarland.6525aylien_mt_gu-en_multilingual.682601002003004005006007008009001000iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsuds-dfki.6861uedin.6534cuni-t2t-transfer-guen.6431neu.6756iitp-mt.6824online-g.0gtcom-primary.6969iiith-mt.6688nict.6603online-b.0ju_saarland.6525aylien_mt_gu-en_multilingual.682601002003004005006007008009001000iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsuds-dfki.6861uedin.6534cuni-t2t-transfer-guen.6431neu.6756iitp-mt.6824online-g.0gtcom-primary.6969iiith-mt.6688nict.6603online-b.0ju_saarland.6525aylien_mt_gu-en_multilingual.682601002003004005006007008009001000iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsuds-dfki.6861uedin.6534cuni-t2t-transfer-guen.6431neu.6756iitp-mt.6824online-g.0gtcom-primary.6969iiith-mt.6688nict.6603online-b.0ju_saarland.6525aylien_mt_gu-en_multilingual.682601002003004005006007008009001000iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-a.0tilde-c-nmt.6876neu.6759online-x.0gtcom-primary.6998online-b.0tilde-nc-nmt.6881online-g.0msra.mass.6945tartunlp-c.6908jumt.661601002003004005006007008009001000iteration #0.00.10.20.30.40.50.60.70.80.91.0weightsonline-a.0tilde-c-nmt.6876neu.6759online-x.0gtcom-primary.6998online-b.0tilde-nc-nmt.6881online-g.0msra.mass.6945tartunlp-c.6908jumt.6616