a dqn-based approach to finding precise evidences for fact veriﬁcation.
hai wan1, haicheng chen1, jianfeng du2,3∗, weilin luo1, rongzhen ye11 school of computer science and engineering,sun yat-sen university, guangzhou 510006, p.r.china2 guangzhou key laboratory of multilingual intelligent processing,guangdong university of foreign studies, guangzhou 510006, p.r.china3 pazhou lab, guangzhou 510330, p.r.chinawanhai@mail.sysu.edu.cn, jfdu@gdufs.edu.cn,{chenhch8, luowlin3, yerzh}@mail2.sysu.edu.cn.
abstract.
computing precise evidences, namely mini-mal sets of sentences that support or refute agiven claim, rather than larger evidences is cru-cial in fact veriﬁcation (fv), since larger ev-idences may contain conﬂicting pieces someof which support the claim while the otherrefute, thereby misleading fv.
despite beingimportant, precise evidences are rarely stud-ied by existing methods for fv.
it is challeng-ing to ﬁnd precise evidences due to a largesearch space with lots of local optimums.
in-spired by the strong exploration ability of thedeep q-learning network (dqn), we propose adqn-based approach to retrieval of precise ev-idences.
in addition, to tackle the label bias onq-values computed by dqn, we design a post-processing strategy which seeks best thresh-olds for determining the true labels of com-puted evidences.
experimental results conﬁrmthe effectiveness of dqn in computing pre-cise evidences and demonstrate improvementsin achieving accurate claim veriﬁcation.1.
1.introduction.
with the growing false information, such as fakenews, political deception and online rumors, auto-matic fact-checking systems have emerged to auto-matically identify and ﬁlter this information.
factveriﬁcation (fv) is a special fact-checking taskthat aims to retrieve related evidences from a textcorpus to verify a textual claim..taking figure 1 as example, an existing methodfor fv ﬁrst retrieves related documents from thegiven corpus at stage 1 (namely the document re-trieval stage), then ﬁnds key sentences from thedocuments at stage 2 (namely the sentence selec-tion stage), and ﬁnally treats the set of key sen-tences as an evidence to verify the claim at stage.
∗corresponding author1source code and data are available at https://.
github.com/sysulic/dqn-fv..figure 1: the pipeline for fv on fever.
underlinedwords in blue italics given in evidence provide key in-formation to determine the truthfulness of the claim.
“supports” / “refutes” / “not enough info”indicates that the evidence can support / refute / is in-sufﬁcient for supporting or refuting the claim.
both theevidence and label are output by fv..3 (namely the claim veriﬁcation stage).
as can beseen in this example, it is desirable to retrieve anevidence consisting of the ﬁrst two sentences only,since it does not contain unnecessary sentences todetermine the truthfulness of the claim and can alle-viate human efforts to further validate the evidence.
more importantly, an evidence containing unneces-sary sentences may involve conﬂicting pieces someof which support the claim while the other refutethe claim.
thus, it is crucial to compute minimalsets of sentences that can determine the truthfulnessof the claim.
in this paper, we refer to a minimal setof sentences that supports or refutes a given claimas a precise evidence..existing methods for fv do not target the re-trieval of precise evidences.
most existing stud-ies (thorne et al., 2018b; nie et al., 2019; zhouet al., 2019; liu et al., 2020; zhong et al., 2020;ye et al., 2020; subramanian and lee, 2020; wanget al., 2020) formulate fv as a three-stage pipeline.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1030–1039august1–6,2021.©2021associationforcomputationallinguistics1030task as illustrated in figure 1. this way makesthe retrieval of precise evidences extremely difﬁ-cult since the sentence selection stage is requiredto select a precise set of relevant sentences ratherthan a ﬁxed number of sentences as in existingmethods.
to the best of our knowledge, twowin-gos (yin and roth, 2018) is the only method bynow which does not follow the three-stage pipeline.
instead, it exploits a supervised training schemeto train the last two stages jointly and is able tocompute precise evidences.
however, it exhibits asigniﬁcantly worse performance than other state-of-the-art methods for fv, especially in terms of therecall of evidences.
therefore, there is still a needfor designing new methods to compute precise ev-idences.
these methods are expected to achievebetter performance than twowingos..it is challenging to compute precise evidences.
on one hand, the search space for precise evi-dences is very large.
for example, in the bench-mark fact extraction and veriﬁcation (fever)dataset (thorne et al., 2018b) the average num-ber of sentences for each claim input to the sen-tence selection stage is 40, and an output evidencehas up to 5 sentences.
hence there are up to(cid:80)540 = 760, 098 candidates in the searchspace.
on the other hand, greedy search of pre-cise evidences easily falls into a local optimum.
asshown in our experiments (see table 6), a greedysearch method does not perform well..i=1 ci.
inspired by the strong exploration ability of thedeep q-learning network (dqn) (mnih et al.,2015), we develop a dqn-based approach to re-trieval of precise evidences.
in this approach, weﬁrst employ dqn to compute candidate pairs ofprecise evidences and their labels, and then use apost-processing strategy to reﬁne candidate pairs.
we notice that q-values computed by dqn haslabel bias due to two reasons.
on one hand, thelabel “not enough info” does not locate atthe same concept level as “supports” or “re-futes”.
on the other hand, there is not a ﬁxedrange for q-values, making q-values hard to accu-rately estimate.
thus, a post-processing strategyis needed to tackle the label bias on q-values.
wedevelop such a strategy to seek best thresholds indetermining the true labels of computed evidences..our experimental results on fever (thorneet al., 2018b) conﬁrm that our dqn-based ap-proach is effective in ﬁnding precise evidences.
more importantly, the approach is shown to outper-.
form state-of-the-art methods for fv..2 related work.
2.1 fact extraction and claim veriﬁcation.
the fever 1.0 shared task (thorne et al., 2018b)aims to develop an automatic fact veriﬁcationsystem to determine the truthfulness of a tex-tual claim by extracting related evidences fromwikipedia.
thorne et al.
(2018a) has formalizedthis task, released a large-scale benchmark datasetfever (thorne et al., 2018b), and designed thethree-stage pipeline framework for fv, which con-sists of the document retrieval stage, the sentenceselection stage and the claim veriﬁcation stage.
most existing methods follow this framework andmainly focus on the last stage (liu et al., 2020).
for the document retrieval stage, most methodsreuse the document retrieval component of top-performing systems (hanselowski et al., 2018;yoneda et al., 2018; nie et al., 2019).
for the sen-tence selection stage, there are three approachescommonly used, including keyword matching, su-pervised classiﬁcation, and sentence similarity scor-ing (thorne et al., 2018b).
for the claim veriﬁca-tion stage, most recent studies formulate this taskas a graph reasoning task (zhou et al., 2019; liuet al., 2020; ye et al., 2020; zhong et al., 2020;subramanian and lee, 2020; wang et al., 2020).
different from most existing methods that focus onclaim veriﬁcation, yin and roth (2018) proposed asupervised training method named twowingos tojointly conduct sentence selection and claim veriﬁ-cation..nowadays pre-trained language models likebert (devlin et al., 2019) have been widely usedin claim veriﬁcation (li et al., 2019; zhou et al.,2019; soleimani et al., 2020).
following this waywe employed roberta (liu et al., 2019), an en-hanced version of bert, as the sentence encoderin our dqn-based approach in experiments..2.2 deep q-learning network.
reinforcement learning (rl) is about an agent in-teracting with the environment, objective to max-imize the cumulative rewards of a sequence ofstates and actions by adjusting its policies.
q-learning (mnih et al., 2015) is a popular reinforce-ment learning technique.
it aims to approximatethe optimal value function q∗(o, a) to measure theexpected long-term rewards for a given pair of stateo and action a. deep q-learning network (dqn).
1031(mnih et al., 2015) is a combination of deep learn-ing and q-learning.
it typically uses the followingequation (1) derived from the bellman equation(cao and zhimin, 2019) to approximate the opti-mal q-value function:q(o(t), a(t)) = e.q(o(t+1), a(cid:48))],(1)where o(t), a(t), r(t) respectively denote the state,action and reward at step t, and λ ∈ [0, 1] is adiscounted factor for future rewards..o(t+1)[r(t)+λ maxa(cid:48).
3 approach.
3.1 problem setting.
given a set of candidate sentences s = {s1, s2,.
.
.
}, a claim c, a set of precise evidences e ⊂ 2s,and a true label y ∈ y = {t,f,n} that deter-mines whether every precise evidence supports orrefutes the claim, where t/f/n denotes “sup-ports”/“refutes”/“not enough info”,we aim to train a model to predict a precise evi-dence; more precisely, to train a model for retriev-ing an evidence ˆe ⊂ s and predicting a labelˆy ∈ y such that ˆy = y and ˆe = e for somee ∈ e. this goal is different from the goal tar-geted by existing methods, which aim to retrievean evidence ˆe ⊂ s and predict a label ˆy ∈ y suchthat ˆy = y and e ⊆ ˆe for some e ∈ e..we deﬁne the four ingredients of dqn namelystates, actions, transitions and rewards as follows:• state.
a state o is a tuple (c, ˆe, ˆy) for c aclaim, ˆe a set of sentences and ˆy a label..• action.
an action a is a sentence in s..• transition.
a transition at step t is a tuple(o(t), a(t), o(t+1)), where o(t) = (c, ˆe(t), ˆy),o(t+1) = (c, ˆe(t+1), ˆy) and ˆe(t+1) = ˆe(t) ∪{a(t)}..• reward.
the reward r for a transition.
(o(t), a(t), o(t+1)) is deﬁned as.
r(t)=.
1, ˆy = y∧(y = n∨∃e ∈ e : a(t) ∈ e)−1, ˆy (cid:54)= y∧| ˆe(t+1)| = k0, otherwise.
(2)where the number k is a hyper-parameter, and|s| denotes the cardinality of a set s..3.2 the dqn-based model.
the core of our proposed approach is the dqn-based model, illustrated in figure 2..3.2.1 sentence encoding module.
we employ roberta in this module to extract theﬁnal hidden state of (cid:104)s(cid:105) as the sentence representa-tion, where (cid:104)s(cid:105) and (cid:104)/s(cid:105) mentioned in the followingare the special classiﬁcation tokens in roberta.
speciﬁcally, following kgat (liu et al., 2020),we ﬁrst concatenate the claim c, the documenttitle l, and a sentence s (resp.
an action a) as“(cid:104)s(cid:105)c(cid:104)/s(cid:105)l(cid:104)/s(cid:105)s(cid:104)/s(cid:105)” (resp.
“(cid:104)s(cid:105)c(cid:104)/s(cid:105)l(cid:104)/s(cid:105)a(cid:104)/s(cid:105)”) andthen feed it into roberta to obtain the sentencerepresentation hs ∈ rd0 (resp.
the action represen-tation ha ∈ rd0), where d0 is the dimension of therepresentation.
we also feed the claim “(cid:104)s(cid:105)c(cid:104)/s(cid:105)”alone to obtain the claim representation hc ∈ rd0..3.2.2 evidence encoding module.
this module is used to get an aggregated evidencerepresentation.
it consists of two sub-modules.
context sub-module.
it is obvious that the sen-tences in an evidence are always contextual depen-dent, so we apply two different networks bilstm(nguyen et al., 2016) and transformer (vaswaniet al., 2017) for comparison.
these two differentnetworks are widely used to encode contextual-aware information of sequential text in the nlpcommunity.
formally, we either deﬁne.
[h(cid:48).
ˆe0.
, .
.
.
, h(cid:48).
ˆe| ˆe|−1.]
= bilstm(ha, h ˆe).
(3).
if the bilstm network is used, or deﬁne.
[h(cid:48).
ˆe0.
, .
.
.
, h(cid:48).
ˆe| ˆe|−1.]
= transformer(ha, h ˆe) (4).
if the transformer is used, where h ˆe = [h ˆe0, .
.
.
,∈ rd0 is the i-th sentence repre-], h ˆeih ˆe| ˆe|−1sentation in ˆe, h(cid:48)∈ rd1 is the correspondingˆeicontext-aware sentence representation in ˆe, and d1is the dimension of the representation.
aggregation sub-module.
this sub-module isused to fuse the sentence representations in evi-dences to obtain an aggregated evidence represen-tation.
we also apply two different networks in thissub-module: transformer and attention.
unlikethe transformer with self-attention in the ﬁrst sub-module, the query in this sub-module is the claimand the key/value is the context-aware sentencerepresentation from the ﬁrst sub-module.
for the.
1032figure 2: the architecture of the dqn-based model.
the input is a state and an action, and the output is the q-value of each label.
the sentence encoding module is used to compute the sentence representation.
the evidenceencoding module is used to compute the evidence representation.
the value module is used to predict the q-valuefor each label..attention network, we deﬁne.
model through the temporal difference error (mnihet al., 2015).
this error δ is formally deﬁned as.
e =.
αi · h(cid:48)i.δ = qˆy(o(t), a(t); θ) − v(o(t+1), r(t)).
(8).
αi =.
exp(mlp([hc; h(cid:48).
i])).
exp(mlp([hc; h(cid:48).
j])).
where v(·) denotes the target value deﬁned as.
v(o, r) =.
(cid:40).
if | ˆe| = kr,r+λ ˆqˆy(o, a∗; ˆθ) otherwise.
(9).
(5).
(6).
| ˆe|−1(cid:88).
i=0.
| ˆe|−1(cid:88).
j=0.
where e ∈ rd1 is the aggregated evidence repre-sentation, mlp(·) = linear(relu(linear(·))) isa two-layer fully connected network using recti-ﬁed linear unit as the activation function, and [; ]denotes the concatenation of two vectors..3.2.3 value module.
this module is used to obtain the q-value vectorfor all labels, simply written as q(o, a; θ) for θdenoting the set of learnable parameters, which isformally deﬁned as.
for a∗ = arg maxa∈s\ ˆe.
qˆy(o, a; θ)..in the above equation, ˆq(·; ˆθ) is the target net-work in ddqn, qˆy denotes the q-value of ˆy forˆy the predicted label in o, ˆe is the predicted ev-idence in o, and λ ∈ [0, 1] is a hyper-parameterrepresenting the discount factor..we use the huber loss to minimise δ:.
l =.
1|b|.
(cid:88).
l(δ).
(10).
((o(t),a(t),o(t+1)),r(t))∈b.
q(o, a; θ) = mlp([hcw; e]).
(7).
where mlp(·) = linear(relu(linear(·))) is sim-ilar to mlp(·) used in equation (6) except thatdifferent parameters in linear layers are used, w ∈rd0×d0 is a learnable matrix, and q(o, a; θ) ∈ rd2for d2 the number of different labels..3.3 objective functiongiven a transition (o(t), a(t), o(t+1)) and its rewardr(t), we use the double deep q-learning network(ddqn) (mnih et al., 2015) technique to train our.
l(δ) =.
.
.
δ2.
12|δ| −.
12.if |δ| ≤ 1.otherwise.
(11).
where b is a batch of transition-reward pairs..3.4 algorithms.
3.4.1 model trainingalgorithm 1 shows how to train the dqn-basedmodel.
first, we initialize three replay memories,the dqn-based model, and the target network inline 1-3. then, in line 9-17, we obtain the training.
1033algorithm 1: model training for dqn,where the memory capacity m , the max-imum evidence size k, the maximum num-ber of epochs t and the reset interval c arehyper-parameters.
1 initialize a replay memory with a capacity m for each.
label: rˆy = ∅, ∀ˆy ∈ {t, f, n}..2 initialize dqn q(o, a; θ) with random weights θ.
3 initialize the target network ˆq(o, a; ˆθ) with ˆθ = θ.
4 for e = 1 → t do5.shufﬂe the training set d.foreach (c, y, e, s) ∈ d do.
initialize one state for each label:ˆy = (c, ˆe(0), ˆy), ∀ˆy ∈ {t, f, n},o(0)where ˆe(0) = ∅.
for t = 0 → k − 1 do.
foreach ˆy ∈ {t, f, n} do.
if random() < (cid:15)-greedy then.
a(t) =random select(s \ ˆe(t)),where ˆe(t) comes from o(t)ˆy ..else.
a(t) =.
qˆy(o(t).
ˆy , a; θ),.
arg maxa∈s\ ˆe(t)where q(·) is deﬁned ineq.
(7) and qˆy denotes theq-value of ˆy..end= (c, ˆe(t+1), ˆy), whereo(t+1)ˆyˆe(t+1) = ˆe(t) ∪ {a(t)} andˆe(t) comes from o(t)ˆy .
calculate r(t) based on eq.
(2).
store ((o(t)ˆy , a(t), o(t+1)), r(t))into ry..ˆy.
endsample a mini-batch of.
transition-reward pairs from rt, rf,rn and update q(o, a; θ) based oneq.
(8)–(11)..for every c steps reset the targetnetwork ˆq(o, a; ˆθ) by ˆθ = θ..6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.endfor.
end.
2223 endfor24 return q(o, a; θ).
algorithm 2: candidate retrieval for aclaim c from a set s of sentences, where kis the maximum evidence size.
1 initialize ˆeˆy = [], qˆy = [], ∀ˆy ∈ {t, f, n}.
2 initialize one state for each label:.
ˆy = (c, ˆe(0), ˆy), ∀ˆy ∈ {t, f, n}, whereo(0)ˆe(0) = ∅..3 for t = 0 → k − 1 do4.qˆy(o(t).
ˆy , a; θ).
foreach ˆy ∈ {t, f, n} doa(t) = arg maxa∈s\ ˆe(t)q(t) = qˆy(o(t)o(t+1)ˆyˆe(t+1) = ˆe(t) ∪ {a(t)} and ˆe(t) comesfrom o(t)ˆy .
store ˆe(t+1) into ˆeˆy and q(t) into qˆy..= (c, ˆe(t+1), ˆy), where.
ˆy , a(t)).
5.
6.
7.
8.end.
910 endfor.
11 return.
(cid:110).
( ˆeˆy, qˆy).
(cid:111).
ˆy∈{t,f,n}.
,.
ˆy∈{t,f,n}.
ˆy.
ˆy.
(cid:111)(cid:105)).
ˆy , .
.
.
, ˆe(k).
ˆy , .
.
.
,q(k−1).
algorithm 3: making ﬁnal prediction from(cid:110)(cid:105),(cid:104)q(0)((cid:104) ˆe(1)using thresholds αt, αf, αn for differentlabels.
1 let ty = arg max0≤t≤k−1(t ˆy +1)2 let ˆe = ˆeˆy.
q(t)y , ∀y ∈ {t, f, n}.., where ˆy = arg maxy∈{t,f}.
q(ty )y.
..n > max{q(tt)3 if q(tn), q(tf)} andtf(t ˆy )q(t)ˆy > αn thenqn − maxmin0≤t≤k−1ˆy∈{t,f}ˆy(cid:48) = n45 else if q(tt)if q(tt)6.t > q(tf)t − maxˆy∈{f,n}.
then.
f.q(tt)ˆy > αt then ˆy(cid:48) = t ;.
if q(tf).
f − maxˆy∈{t,n}.
q(tf)ˆy > αf then ˆy(cid:48) = f ;.
else ˆy(cid:48) = n ;.
78 else.
9.else ˆy(cid:48) = n ;.
1011 end12 return ( ˆe, ˆy(cid:48)).
transition-reward pairs by letting the dqn-basedmodel interact with the environment in an (cid:15)-greedyexploration-exploitation way (mnih et al., 2015).
finally, in line 19, we sample a mini-batch oftransition-reward pairs to update the dqn-basedmodel, while in line 20, for every c steps we resetthe target network to the dqn-based model..3.4.2 candidate retrieval.
algorithm 2 shows how to retrieve a pair (candi-date list, score list) for each label, where the can-.
didate list stores progressively enlarged sentencesets, where each sentence set is a candidate of thepredicted evidence, and the score list stores thestrengths that the corresponding candidates supportthe label.
we enlarge the two-list pair for each labelthrough a greedy-search way (line 3-10).
speciﬁ-cally, for each label, we ﬁrst select the action withthe largest q-value (line 5), then update the stateby adding the chosen action into its predicted ev-idence (line 7), and ﬁnally add the evidence andscore into the corresponding list (line 8)..1034algorithm 4: searching for best thresholds,where min qˆy is short for mint q(t)andˆymax qˆy for maxt q(t)ˆy , for all ˆy ∈ {t, f, n}.
1 construct v = {(qt, qf, qn, y)} from thedevelopment set by algorithm 2..ˆy = [], ∀ˆy ∈ {t, f, n}..2 initialize cˆy = lˆy = l(cid:48)3 foreach (qt, qf, qn, y) ∈ v do4.if max qn > max{max qt, max qf} thenv = min qn − max{max qt, max qf}store v into ln and (v, y) into cn..5.
6.end.
78 end9 sort ln in ascending order.
10 calculate the medians of adjacent values in ln and.
store them into l(cid:48)n.(cid:88).
11 αn = arg max.
α∈l(cid:48)n.(v,y)∈cn.
α ∧ y (cid:54)= n)).
1((v > α ∧ y = n) ∨ (v ≤.
12 foreach (qt, qf, qn, y) ∈ v do13.if max qn ≤ max{max qt, max qf} or.
min qn − max{max qt, max qf} ≤ αn then.
t.if q(tt).
q(t)ˆy , ∀ˆy ∈ {t, f}.
tˆy = arg maxt > q(tf)fv = q(tt)store v into lt and (v, y) into ct..thent − max{q(tt).
, q(tt)n }.
f.f − max{q(tf).
v = q(tf)store v into lf and (v, y) into cf.., q(tf)n }.
t.else.
end.
end.
2223 end24 foreach ˆy ∈ {t, f} do25.α∈l(cid:48)ˆy.
(v,y)∈c ˆy.
ˆy) − 1(v > α ∧ y = n).
28 end29 return (αt, αf, αn).
14.
15.
16.
17.
18.
19.
20.
21.
26.
27.
3.4.3 final prediction.
algorithm 3 shows how to compute the targetevidence-label pair from the (candidate list, scorelist) pairs obtained by algorithm 2, where thethresholds are determined by algorithm 4. in thisalgorithm, we ﬁrst use the condition given by al-gorithm 4 to predict n (line 3), and then reﬁne theprediction of t (line 6) and f (line 9) in turn.
inline 2, we focus on the evidences with the highestscore for t and f, while we ignore the evidencefor n, due to the following reasons: (1) there areno supporting sentences in the evidence for n; (2)we follow a strategy commonly used in existingmethods for fv, i.e., focusing only on the evidencefor t and f..split.
supports refutes.
nei.
train.
80,035.
29,775.
35,639.dev.
test.
6,666.
6,666.
6,666.
6,666.
6,666.
6,666.table 1: dataset statistics for fever.
3.4.4 threshold searchingalgorithm 4 shows how to search for the bestthresholds (αt, αf, αn) to maximize the labelaccuracy (la) over the development set.
weﬁrst call algorithm 2 to construct a set of tu-ples (qt, qf, qn, y) from the development set, eachof which corresponds to a development instance,where qt, qf and qn are respectively the outputscore lists for the three labels t, f and n, and y isthe corresponding true label (line 1).
we then gothrough the following two stages.
the ﬁrst stage(line 3-11) ﬁnds a threshold αn that can maximizela for label n, where maximizing la is amount tomaximizing the difference between the number ofcorrectly and incorrectly predicted instances.
thesecond stage (line 12-28) ﬁnds the thresholds αtand αf that can maximize la for label t and f,respectively, where those instances that satisfy theconditions for n are neglected (line 13)..4.1.1 datasetour experiments are conducted on the large-scalebenchmark dataset fever (thorne et al., 2018a),which consists of 185,455 annotated claims with aset of 5,416,537 wikipedia documents from thejune 2017 wikipedia dump.
all claims are la-beled as “supports”, “refutes”, or “notenough info”.
what’s more, each claim for“supports” and “refutes” is accompanied bysome evidences extracted from wikipedia docu-ments.
the dataset partition is kept the same withthorne et al.
(2018b) as shown in table 1..4.1.2 evaluation metricsthe task has ﬁve evaluation metrics: 1) fever, theprimary scoring metric that measures the accuracyof claim veriﬁcation with a requirement that thepredicted evidences fully covers the ground-trueevidences for supports and refutes claims;2) label accuracy (la), the accuracy of claimveriﬁcation without considering the validity of the.
sort lˆy in ascending order.
calculate the medians of adjacent values in lˆyand store them into l(cid:48)ˆy.
1(v > α ∧ y =.
αˆy = arg max.
(cid:88).
4 experiments.
4.1 experimental setting.
1035method.
αt.
αf.
αn.
t-t.t-a.
-1.23361155390739.
-1.26671668887138.
0.0153777748346328.
-0.0631487071514129.
0.0747150778770446.
-1.48811344802379.bilstm-t.0.184351719915866.
-0.64785711467266.
-0.465365642681717.bilstm-a -0.0904324240982532.
-0.795884847640991.
-0.403448916971683.the thresholds determined by algo-table 2:rithm 4. t-t, t-a, bilstm-t, and bilstm-a de-note the architectures of the evidence encoding mod-ule, which are respectively transformer-transformer,andtransformer-attention, bilstm-transformer,bilstm-attention..predicted evidences; 3) precision (pre), the macro-precision of the evidences for supports and re-futes claims; 4) recall, the macro-recall of theevidences for supports and refutes claims;5) f1, the f1-score of the evidences for supportsand refutes claims.
we choose f1 as our mainmetric because it can directly show the perfor-mance of methods on retrieval of precise evidences..implementation details.
4.1.3document retrieval.
the document retrieval stageis kept the same as previous work (hanselowskiet al., 2018; zhou et al., 2019; liu et al., 2020; yeet al., 2020).
given a claim, the method ﬁrst utilizesthe constituency parser from allennlp (gardneret al., 2018) to extract potential entities from theclaim.
then it uses the entities as search queriesto ﬁnd the relevant documents via the online me-diawiki api2.
the convinced articles are reserved(hanselowski et al., 2018).
sentence selection and claim veriﬁcation.
weimplement our dqn-based model with pytorchand train it with the adamw (loshchilov and hut-ter, 2019) optimizer while keeping the sentence en-coding module frozen and inheriting the robertaimplementation from wolf et al.
(2020)3. specif-ically, the learning rate is 5e-6, the batch size is128, the training epochs is 30, the iteration steps(or largest evidence size, i.e., k) is 5, the discountfactor λ is 0.95, and the layer number of the con-text sub-module is 3. prioritized experience replaymemory (schaul et al., 2016) with a capacity of10,000 is used to store transitions.
the target net-work is reset when dqn is updated every 10 times.
the probability of (cid:15)-greedy policy starts at 0.9 anddecays exponentially towards 0.05, and the rate of12000 .
table 2 shows the thresholdsthe decay is.
2https://www.mediawiki.org/wiki/api:.
main_page.
3https://github.com/huggingface/.
pytorch-transformers.
αt, αf and αn computed by algorithm 4. all ex-periments were conducted on an nvidia gtx2080ti 10gb gpu..4.1.4 baselines.
we compare our method with the following base-lines, including six methods that focus on claimveriﬁcation and one joint method twowingos(yin and roth, 2018).
the six methods include:(1) gear (zhou et al., 2019) uses two kinds ofattentions to conduct reasoning and aggregationin a graph model; (2) kgat (liu et al., 2020)employes the kernel graph attention network tocapture ﬁne-grained information over evidencesfor more accurate claim veriﬁcation; (3) dream(zhong et al., 2020) introduces semantic structuresfor evidences obtained by semantic role labelingin claim veriﬁcation; (4) corefbert (ye et al.,2020) extends kgat and can explicitly modelco-reference relationship in context; (5) hesm(subramanian and lee, 2020) is a framework thatcan encode and attend the claim and evidence setsat different levels of hierarchy; (6) dgat (wanget al., 2020) is a double graph attention networkthat performs well in multi-domain datasets.
thejoin method twowingos (yin and roth, 2018)exploits a two-wing optimization strategy that opti-mizes sentence selection and claim veriﬁcation ina jointly supervised training scheme..4.2 results and analysis.
as shown in table 3, we implement four versionsof the evidence encoding module and evaluate themon the dev set and the blind test set.
thefever metric of the top six methods is calculatedwith the imprecise evidences, so we introduce thefever@5 metric for a fair comparison.
we ana-lyze our method from the following four aspects.
comparison with the state-of-the-art methods.
results in table 3 show that all versions (exceptbilstm-a) with post-processing signiﬁcantly out-perform the state-of-the-art methods on fever,pre, and f1, especially for t-a on f1, which showsthe superiority of our method in retrival of pre-cise evidences.
however, none of the four ver-sions of our method can achieve the best result onfever@5, la, and recall.
the reason for lowrecall is that the number of sentences in preciseevidences is less than that in imprecise evidences,which means other methods have a higher proba-bility to recall the ground-true evidences than ours.
besides, the relatively low la is caused by the.
1036fever@5.fever.
pre.
recall.
f1.
fever@5.fever.
pre.
recall.
f1.
method.
gearkgatdreamcorefberthesmdgat.
twowingos.
ours.
t-t(w./o.).
t-a(w./o.).
bilstm-t(w./o.).
bilstm-a(w./o.).
70.6976.11--73.44-.
-.
72.8372.90.
73.3273.29.
73.1573.19.
72.9973.20.devla.
74.8478.29--75.77-.
78.1874.87.
78.3578.12.
73.9163.55.
77.7971.21.
------.
56.16.
71.5570.00.
72.7972.60.
63.7755.39.
70.8865.65.
24.0827.7926.60---.
86.7294.3787.33---.
37.6942.3440.79---.
-25.2125.63---.
-87.4785.57---.
36.8739.1439.4539.1452.78-.
78.90.
47.73.
53.81.
50.59.
-.
75.99.
44.68.
49.91.
47.15.
50.42.
81.82.
62.39.
48.76.
79.91.
60.56.
54.75.
79.92.
64.98.
52.24.
77.93.
62.55.
48.06.
71.06.
57.34.
45.97.
69.43.
55.32.
35.50.
76.54.
48.50.
33.76.
74.50.
46.46.testla.
71.6074.0776.85-74.6471.79.
75.7473.13.
76.1476.00.
70.2061.68.
75.5369.32.
------.
54.33.
68.9168.23.
70.2870.18.
61.5153.21.
68.2163.38.
67.1070.3870.6071.8071.4866.91.
70.1670.43.
70.8170.82.
70.5470.81.
70.1170.55.table 3: performance on dev set and blind test set of fever (%).
fever@5 and fever are computedbased on imprecise and precise evidences, repectively.
the result obtained with/without post-processing (namelythreshold searching and ﬁnal prediction) is displayed in each architecture’s ﬁrst/second row (“w.”/“o.”).
we directlyoutput the evidence with the highest score in the candidate list and its corresponding label if post-processing is notperformed.
pre, recall, and f1 keep unchanged because they are not affected by the post-processing.
‘-’ denotesa missing value..t-t.t-a.
bilstm-t.bilstm-a.
kgat.
width.
fever@5.fever.
la.
pre.
recall.
f1.
#.
lala*.
78.1882.82.
78.3582.48.
73.9184.93.
77.7983.95.
78.2979.08.table 4: comparison between our method and kgaton la (%).
la and la* are respectively evaluated onthe dev set and its subset constructed by selecting thesamples where the ground-true evidences are success-fully recalled..method.
three-stage pipelineour method (t-a).
avg..4.001.07.std..0.070.89.table 5: comparison of the number of unnecessary sen-tences in predicted evidences..low recall of precise evidences.
to further clarifythis point, we evaluate our method on a subset ofthe dev set where the ground-true evidences arerecalled successfully.
our method improves signif-icantly the performance on this subset, as shown intable 4, which justiﬁes our point of view.
feveris affected by the la and recall, thereby the lowfever@5 is also due to the low recall of preciseevidences.
in addition, the results reported in ta-ble 5 show that our method can signiﬁcantly reducethe number of unnecessary sentences in a predictedevidence.
comparison between different versions.
asshown in table 3, t-t and t-a perform respec-tively better than bilstm-t and bilstm-a onalmost all metrics except that t-t is slightly worse.
1(w./o.).
2(w./o.).
3(w./o.).
4(w./o.).
5(w./o.).
60.7350.09.
60.7450.09.
60.7050.10.
60.6750.09.
60.6850.09.
54.9146.55.
54.9446.53.
54.9646.54.
54.9546.54.
54.9546.54.
72.6953.00.
72.6953.00.
72.6953.00.
72.6953.00.
72.6953.00.
52.76.
58.57.
55.51.
52.84.
58.66.
55.59.
52.84.
58.67.
55.60.
52.81.
58.66.
55.58.
52.84.
58.68.
55.61.table 6: the beam-search result of kgat on the devset (%).
the width (k) means to select the top-k resultsat each search step.
the result obtained with/withoutpost-processing (namely threshold searching and ﬁnalprediction) is displayed in each width’s ﬁrst/second row(“w.”/“o.”).
we employed the kgat source code re-leased by liu et al.
(2020) to implement beam-searchfor ﬁnding precise evidences and the evaluation data forkgat was kept the same as ours..than bilstm-a on fever@5, which suggeststransformer can encode better context-aware repre-sentations than bilstm in our context sub-module.
moreover, we ﬁnd that t-a performs better thant-t on almost all metrics except recall and thatbilstm-a is worse than bilstm-t on pre andf1.
this contrary result shows that the performanceof the aggregation sub-module is impacted by thecontext sub-module.
thus, the choice betweentransformer and attention should depend on thecontext sub-module.
overall, t-a achieves the bestperformance among all the four versions of our.
1037#.
label.
claim.
ground-true evidences.
(savages(2012 ﬁlm), 3).
1.f.savages was exclusivelya german ﬁlm..2.t.ed gein murdered peoplearound plainﬁeld, wisconsin..3.t.marnie is a ﬁlm that wascreated in the united states..4.f.first motion picture unitproduced zero ﬁlms..(ed gein, 2)(ed gein, 1).
(marnie(ﬁlm), 0).
(first ... unit, 1)(first ... unit, 4)(first ... unit, 0).
gear.
predicted evidenceskgat.
(savages(2012 ﬁlm), 3)(savages(band), 0)(savages(2012 ﬁlm), 6)(savages(band), 2)(savages(band), 4).
(savages(2012 ﬁlm), 3)(savages(2012 ﬁlm), 6)(savages(2012 ﬁlm), 0)(savages(band), 5)(savages(band), 0).
(ed gein, 1)(ed gein, 0)(ed gein, 6)(ed gein, 2)(ed gein, 5).
(marnie(ﬁlm), 0)(marnie, 0)(marnie(ﬁlm), 2)(marnie(ﬁlm), 6)(marnie(dis...tion), 12).
(first ... unit, 0)(first ... unit, 4)(first ... unit, 1)(zero(2016 ﬁlm), 0)(first ... unit, 8).
(ed gein, 1)(ed gein, 2)(ed gein, 0)(ed gein(band), 2)(ed gein, 4).
(marnie(ﬁlm), 0)(marnie, 0)(marnie(ﬁlm), 2)(marnie(ﬁlm), 6)(marnie(ﬁlm), 5).
(first ... unit, 1)(first ... unit, 4)(first ... unit, 0)(first ... unit, 2)(zero(2016 ﬁlm), 0).
our method (t-a).
(savages(2012 ﬁlm), 3).
(ed gein, 2)(ed gein, 1).
(marnie(ﬁlm), 0)(marnie(ﬁlm), 5).
(first ... unit, 1)(first ... unit, 4)(first ... unit, 0)(first ... unit, 2).
(title, i) de-table 7: cases in fever.
we list the predicted evidences of gear, kgat and our method.
notes the i-th sentence in the corresponding wiki document.
in predicted evidences, the sentences highlightedin blue bold italics and underline are sentences in the target evidence while others in black are unnecessary ones..proposed method.
comparison on retrieval of precise evidences.
twowingos is a supervised-learning method thatcan also ﬁnd precise evidences.
although itachieves slightly better performance on la thanours, its f1 and other metrics are much worse, in-dicating that it performs worse than our methodexcept for bilstm-a in retrieval of precise-evidences.
we also enhance kgat to conductbeam-search for ﬁnding precise evidences and re-port the results in table 6. the f1 score of kgatis always higher than twowingos but is still lowerthan our method except for bilstm-a.
comparison between the methods with andwithout post-processing.
it can be seen from ta-ble 3 and table 6 that, post-processing (namelythreshold searching and ﬁnal prediction from can-didates) consistently improves fever and la.
al-though with post-processing, our method (exceptt-a) achieves slightly lower scores on fever@5,kgat still achieves signiﬁcantly higher scores onfever@5 as on other metrics.
these results showthat post processing is very important in retrievalof precise evidences..4.3 case study.
in table 7 we provide some cases to demonstratethe effectiveness of our method (t-a) in retriev-ing precise evidences.
in case#1 and case#2, ourmethod exactly ﬁnds ground-true evidences with-out introducing any unnecessary sentence, while.
geat and kgat cannot.
in case#3 and case#4,our method generates less unnessary sentences inprdicted evidents than geat and kgat do..5 conclusion and future work.
in this paper, we have proposed a novel dqn-basedapproach to ﬁnding precise evidences for fact veri-ﬁcation.
it provides a method to solve the precise-evidence problem by ﬁrst employing a dqn tocompute some candidates and then introducing apost-processing strategy to extract the target evi-dence and its label from the candidates.
exper-imental results show that the approach achievesstate-of-the-art performance in terms of retrievalof precise evidences.
besides, to the best of ourknowledge, it is the ﬁrst attempt to employ dqnin the fact veriﬁcation task..future work will incorporate external knowledge.
into our approach to improve the retrieval recall..acknowledgments.
this work is supported by the guangdongprovince science and technology plan projects(2017b010110011), the national natural sciencefoundation of china (no.
61876204, 61976232,and 51978675),the national key r&d pro-gram of china (no.2018yfc0830600), guang-dong province natural science foundation (no.
2018a030313086), all-china federation of re-turned over-seas chinese research project (no.
17bzqk216)..1038references.
lichun cao and zhimin.
2019. an overview of deepin cacre, pages 17:1–.
reinforcement learning.
17:9..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in naacl-hlt, pages 4171–4186..matt gardner, joel grus, mark neumann, oyvindtafjord, pradeep dasigi, nelson f. liu, matthew e.peters, michael schmitz, and luke zettlemoyer.
2018. allennlp: a deep semantic natural languageprocessing platform.
in nlp-oss workshop, pages1–6..andreas hanselowski, hao zhang, zile li, daniilsorokin, benjamin schiller, claudia schulz, andiryna gurevych.
2018. ukp-athene: multi-sentencetextual entailment for claim veriﬁcation.
in fever,pages 103–108..tianda li, xiaodan zhu, quan liu, qian chen, zhi-several experi-gang chen, and si wei.
2019.ments on investigating pretraining and knowledge-enhanced models for naturallanguage inference.
corr, abs/1904.12104..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
corr, abs/1907.11692..zhenghao liu, chenyan xiong, maosong sun, andzhiyuan liu.
2020. fine-grained fact veriﬁcationwith kernel graph attention network.
in acl, pages7342–7351..ilya loshchilov and frank hutter.
2019. decoupled.
weight decay regularization.
in iclr..volodymyr mnih, koray kavukcuoglu, david silver,andrei a. rusu, joel veness, marc g. bellemare,alex graves, martin a. riedmiller, andreas fid-jeland, georg ostrovski, stig petersen, charlesbeattie, amir sadik, ioannis antonoglou, helenking, dharshan kumaran, daan wierstra, shanelegg, and demis hassabis.
2015. human-level con-trol through deep reinforcement learning.
nature,518(7540):529–533..amir soleimani, christof monz, and marcel worring.
2020. bert for evidence retrieval and claim veriﬁ-cation.
in ecir, volume 12036, pages 359–366..shyam subramanian and kyumin lee.
2020. hierar-chical evidence set modeling for automated fact ex-in emnlp, pages 7798–traction and veriﬁcation.
7809..james.
andreas vlachos,.
christosthorne,and arpit mittal.
2018a.
christodoulopoulos,fever: a large-scale dataset for fact extraction andveriﬁcation.
in naacl-hlt, pages 809–819..james thorne, andreas vlachos, oana cocarascu,and arpit mittal.
the fact extraction and veriﬁcation.
christos christodoulopoulos,2018b.
(fever) shared task.
in fever, pages 1–9..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in neurips, pages 5998–6008..yongyue wang, chunhe xia, chengxiang si, beitongyao, and tianbo wang.
2020. robust reasoning overheterogeneous textual information for fact veriﬁca-tion.
ieee access, 8:157140–157150..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, r´emi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander m. rush.
2020.transformers: state-of-the-art natural language pro-cessing.
in emnlp, pages 38–45..deming ye, yankai lin, jiaju du, zhenghao liu, pengli, maosong sun, and zhiyuan liu.
2020. coref-erential reasoning learning for language representa-tion.
in emnlp, pages 7170–7186..wenpeng yin and dan roth.
2018. twowingos: a two-wing optimization strategy for evidential claim veri-ﬁcation.
in emnlp, pages 105–114..takuma yoneda, jeff mitchell, johannes welbl, pon-tus stenetorp, and sebastian riedel.
2018. ucl ma-chine reading group: four factor framework for factﬁnding (hexaf).
in fever, pages 97–102..ngoc-khuong nguyen, anh-cuong le, and hong thaipham.
2016. deep bi-directional long short-termmemory neural networks for sentiment analysis ofsocial data.
in iukm, volume 9978, pages 255–268..wanjun zhong, jingjing xu, duyu tang, zenan xu,nan duan, ming zhou, jiahai wang, and jian yin.
2020. reasoning over semantic-level graph for factchecking.
in acl, pages 6170–6180..yixin nie, haonan chen, and mohit bansal.
2019.combining fact extraction and veriﬁcation with neu-in aaai, pagesral semantic matching networks.
6859–6866..jie zhou, xu han, cheng yang, zhiyuan liu, lifengwang, changcheng li, and maosong sun.
2019.gear: graph-based evidence aggregating and rea-soning for fact veriﬁcation.
in acl, pages 892–901..tom schaul, john quan, ioannis antonoglou, anddavid silver.
2016. prioritized experience replay.
in iclr..1039