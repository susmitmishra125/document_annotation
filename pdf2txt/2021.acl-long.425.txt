article reranking by memory-enhanced key sentence matchingfor detecting previously fact-checked claims.
qiang sheng1,2, juan cao1,2, xueyao zhang1,2, xirong li3, lei zhong1,21 key laboratory of intelligent information processing,institute of computing technology, chinese academy of sciences2university of chinese academy of sciences3key lab of data engineering and knowledge engineering, renmin university of china{shengqiang18z,caojuan,zhangxueyao19s,zhonglei18s}@ict.ac.cnxirong@ruc.edu.cn.
abstract.
false claims that have been previously fact-checked can still spread on social media.
to mitigate their continual spread, detectingpreviously fact-checked claims is indispens-able.
given a claim, existing works retrievefact-checking articles (fc-articles) for detec-tion and focus on reranking candidate arti-cles in the typical two-stage retrieval frame-work.
however, their performance may belimited as they ignore the following charac-teristics of fc-articles: (1) claims are oftenquoted to describe the checked events, pro-viding lexical information besides semantics;and (2) sentence templates to introduce ordebunk claims are common across articles,in this paper,providing pattern information.
we propose a novel reranker, mtm (memory-enhanced transformers for matching), to rankfc-articles using key sentences selected us-ing event (lexical and semantic) and patterninformation.
for event information, we pro-pose to ﬁnetune the transformer with regres-sion of rouge.
for pattern information, wegenerate pattern vectors as a memory bank tomatch with the parts containing patterns.
byfusing event and pattern information, we se-lect key sentences to represent an article andthen predict if the article fact-checks the givenclaim using the claim, key sentences, and pat-terns.
experiments on two real-world datasetsshow that mtm outperforms existing methods.
human evaluation proves that mtm can cap-ture key sentences for explanations.
the codeand the dataset are at https://github.com/ictmcg/mtm..1.introduction.
social media posts with false claims have led toreal-world threats on many aspects such as pol-itics (fisher et al., 2016), social order (wangand li, 2011), and personal health (chen, 2020)..figure 1: (a) workﬂow of detecting a previously fact-checked claim.
our model mtm focuses on the secondstage, i.e., reranking the candidates.
(b) a claim andsentences in the candidate fact-checking articles (trans-lated from chinese).
s1 is on a similar topic but actu-ally irrelevant, while s2 and s3 which contain quota-tion or fact-checking patterns are relevant..to tackle this issue, over 300 fact-checkingprojects have been launched, such as snopes1 andjiaozhen2 (duke reporters’ lab, 2020).
mean-while, automatic systems have been developed fordetecting suspicious claims on social media (zhouet al., 2015; popat et al., 2018a).
this is howevernot the end.
a considerable amount of false claimscontinually spread, even though they are alreadyproved false.
according to a recent report (xinhuanet, 2019), around 12% of false claims publishedon chinese social media, are actually “old”, as theyhave been debunked previously.
hence, detect-ing previously fact-checked claims is an important.
1https://www.snopes.com2https://fact.qq.com/.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5468–5481august1–6,2021.©2021associationforcomputationallinguistics5468hot lemonade can kill cancer cells without hurting normal cells.stage1bm25sentences in candidate fact-checking articlessentencerelevant?contains quotation?containsfact-checkingpatterns?s1.lemon is not so-called acid food, and drinking lemonade does not lead to cancer.
(fromarticle 1)no,but onasimilartopicnonos2.the rumor saying hot lemonade can kill cancer cellshas spread over years.
(fromarticle 2)yesyes(underlined)yes(inboldface)s3.it is just a groundless inference thatlemon has a curative effect of cancer.
(fromarticle 3)yesnoyes(in boldface)claimfact-checkingarticlesstage2mtmmanualdisplaytofact-checkersautomaticmakerulesbasedonrelevancescoresthescopeofourworkclaimranked candidate articlesdetermineifaclaimhasbeenfact-checkedcandidate fact-checking articles(a)(b)task..according to the seminal work by shaar et al.
(2020), the task is tackled by a two-stage informa-tion retrieval approach.
its typical workﬂow is illus-trated in figure 1(a).
given a claim as a query, inthe ﬁrst stage a basic searcher (e.g., bm25 robert-son and zaragoza, 2009) searches for candidatearticles from a collection of fact-checking articles(fc-articles).
in the second stage, a more powerfulmodel (e.g., bert, devlin et al., 2019) reranksthe candidates to provide evidence for manual orautomatic detection.
existing works focus on thereranking stage: vo and lee (2020) model the in-teractions between a claim and the whole candidatearticles, while shaar et al.
(2020) extract severalsemantically similar sentences from fc-articles asa proxy.
nevertheless, these methods treat fc-articles as general documents and ignore charac-teristics of fc-articles.
figure 1(b) shows threesentences from candidate articles for the givenclaim.
among them, s1 is more friendly to se-mantic matching than s2 and s3 because the wholes1 focuses on describing its topic and does not con-tain tokens irrelevant to the given claim, e.g., ”hasspread over years” in s2.
thus, a semantic-basedmodel does not require to have strong ﬁltering ca-pability.
if we use only general methods on thistask, the relevant s2 and s3 may be neglected whileirrelevant s1 is focused.
to let the model focus onkey sentences (i.e., sentences as a good proxy ofarticle-level relevance) like s2 and s3, we need toconsider two characteristics of fc-articles besidessemantics: c1.
claims are often quoted to describethe checked events (e.g., the underlined text in s2);c2.
event-irrelevant patterns to introduce or de-bunk claims are common in fc-articles (e.g., boldtexts in s2 and s3)..based on the observations, we propose a novelreranker, mtm (memory-enhanced transformersfor matching).
the reranker identiﬁes key sen-tences per article using claim- and pattern-sentencerelevance, and then integrates information from theclaim, key sentences, and patterns for article-levelrelevance prediction.
in particular, regarding c1,we propose rouge-guided transformer (rot) toscore claim-sentence relevance literally and seman-tically.
as for c2, we obtain the pattern vectorsby clustering the difference of sentence and claimvectors for scoring pattern-sentence relevance andstore them in the pattern memory bank (pmb).
the joint use of rot and pmb allows us to iden-.
tify key sentences that reﬂect the two character-istics of fc-articles.
subsequently, ﬁne-grainedinteractions among claims and key sentences aremodeled by the multi-layer transformer and ag-gregated with patterns to obtain an article-levelfeature representation.
the article feature is fedinto a multi-layer perceptron (mlp) to predict theclaim-article relevance..to validate the effectiveness of our method, webuilt the ﬁrst chinese dataset for this task with11,934 claims collected from chinese weibo3 and27,505 fact-checking articles from multiple sources.
39,178 claim-article pairs are annotated as relevant.
experiments on the english dataset and the newlybuilt chinese dataset show that mtm outperformsexisting methods.
further human evaluation andcase studies prove that mtm ﬁnds key sentencesas explanations.
our main contributions are asfollows:.
• we propose a novel reranker mtm for fact-checked claim detection, which can betteridentify key sentences in fact-checking arti-cles by exploiting their characteristics..• we design rouge-guided transformer tocombine lexical and semantic information andpropose a memory mechanism to capture andexploit common patterns in fact-checking arti-cles..• experiments on two real-world datasets showthat mtm outperforms existing methods.
fur-ther human evaluation and case studies provethat our model ﬁnds key sentences as goodexplanations..• we built the ﬁrst chinese dataset for fact-checked claim detection with fact-checkingarticles from diverse sources..2 related work.
to defend against false information, researchersare mainly devoted to two threads: (1) automaticfact-checking methods mainly retrieve relevantfactual information from designated sources andjudge the claim’s veracity.
thorne et al.
(2018) usewikipedia as a fact tank and build a shared task forautomatic fact-checking, while popat et al.
(2018b)and wang et al.
(2018) retrieve webpages as evi-dence and use their stances on claims for veracityprediction.
(2) fake news detection methods of-ten use non-factual signals, such as styles (przy-byla, 2020; qi et al., 2019), emotions (ajao.
3https://weibo.com.
5469figure 2: architecture of mtm.
given a claim q and a candidate article d with l sentences, s1, ..., sl, mtm (cid:172) feeds(q, s) pairs into rouge-guided transformer (rot) to obtain claim-sentence scores in both lexical and semanticaspects; (cid:173) matches residual embeddings rs,q with vectors in pattern memory bank (pmb) (here, only four areshown) to obtain pattern-sentence scores; (cid:174) identiﬁes k2 key sentences by combining the two scores (here, k2 = 2,and si and sl are selected); (cid:175) models interaction among q(cid:48), s(cid:48), and the nearest memory vector m for each keysentence; and (cid:176) perform score-weighted aggregation and predict the claim-article relevance..et al., 2019; zhang et al., 2021), source credibil-ity (nguyen et al., 2020), user response (shu et al.,2019) and diffusion network (liu and wu, 2018;rosenfeld et al., 2020).
however, these methodsmainly aim at newly emerged claims and do not ad-dress those claims that have been fact-checked butcontinually spread.
our work is in a new thread, de-tecting previously fact-checked claims.
vo andlee (2020) models interaction between claims andfc-articles by combining glove (pennington et al.,2014) and elmo embeddings (peters et al., 2018).
shaar et al.
(2020) train a ranksvm with scoresfrom bm25 and sentence-bert for relevance pre-diction.
these methods ignore the characteristics offc-articles, which limits the ranking performanceand explainability..3 proposed method.
given a claim q and a candidate set of k1 fc-articles d obtained by a standard full-text retrievalmodel (bm25), we aim to rerank fc-articles trulyrelevant w.r.t.
q at the top by modeling ﬁne-grainedrelevance between q and each article d ∈ d. thisis accomplished by memory-enhanced transform-ers for matching (mtm), which conceptually hastwo steps, (1) key sentence identiﬁcation and (2)article relevance prediction, see figure 2. for anarticle of l sentences, let s = {s1, ..., sl} be its.
sentence set.
in step (1), for each sentence, we de-rive claim-sentence relevance score from rouge-guided transformer (rot) and pattern-sentencerelevance score from pattern memory bank (pmb).
the scores indicate how similar the sentence is tothe claim and pattern vectors, i.e., how possible tobe a key sentence.
top k2 sentences are selectedfor more complicated interactions and aggregationwith the claim and pattern vectors in step (2).
theaggregated vector is used for the ﬁnal prediction.
we detail the components and then summarize thetraining procedure below..3.1 key sentence identiﬁcation3.1.1 rouge-guided transformer (rot)rot (left top of figure.
2) is used to evaluatethe relevance between q and each sentence s in{si}k1i=1, both lexically and semantically.
inspiredby (gao et al., 2020), we choose to “inject” theability to consider lexical relevance into the seman-tic model.
as the bert is proved to capture andevaluate semantic relevance (zhang et al., 2020),we use a one-layer transformer initialized with theﬁrst block of pretrained bert to obtain the initialsemantic representation of q and s:.
zq,s = transformer ([cls] q [sep] s).
(1).
where [cls] and [sep] are preserved tokens andzq,s is the output representation..5470-guidedtransformer(rot)embedding layerone-layer transformerpatternmemory bank(pmb)······claim-sentencescoresclaim-sentence vectorsresidual embeddingspattern-sentencescoresnearestpatternvectors······multi-layertransformertotalscores······mlp······relevantirrelevantarticlerelevancepredictionkey sentence identificationaggregateclaim-sentencepairs12345⊕0.3···0.80.9···0.6···0.90.7···0.5···0.90.8···selectbyindexselectbyindexindexscore××vectorinembeddingspacevectorcomponent⊕weightedsumto force rot to consider the lexical relevance,we ﬁnetune the pretrained transformer with theguidance of rouge (lin, 2004), a widely-usedmetric to evaluate the lexical similarity of two seg-ments in summarization and translation tasks.
theintuition is that lexical relevance can be character-ized by token overlapping, which rouge exactlymeasures.
we minimize the mean square error be-tween the prediction and the precision and recall ofrouge-2 between q and s (r2 ∈ r2) to optimizethe rot:.
ˆr(q, s) = mlp(cid:0)zq,s([cls])(cid:1).
(2).
lr = (cid:107)ˆr(q, s) − r2(q, s)(cid:107)2.
2 + λr(cid:107)∆θ(cid:107)22.
(3).
where the ﬁrst term is the regression loss and thesecond is to constraint the change of parameters asthe ability to capture semantic relevance should bemaintained.
λr is a control factor and ∆θ repre-sents the change of parameters..3.1.2 pattern memory bank (pmb)the pattern memory bank (pmb) is to generate,store, and update the vectors which represent thecommon patterns in fc-articles.
the vectors inpmb will be used to evaluate pattern-sentence rel-evance (see section 3.1.3).
here we detail howto formulate, initialize, and update these patternsbelow.
formulation.
intuitively, one can summarize thetemplates, like “...has been debunked by...”, andexplicitly do exact matching, but the templates arecostly to obtain and hard to integrate into neuralmodels.
instead, we implicitly represent the com-mon patterns using vectors derived from embed-dings of our model, rot.
inspired by (wu et al.,2018), we use a memory bank m to store k com-mon patterns (as vectors), i.e., m = {mi}kinitialization.
we ﬁrst represent each q in the train-ing set and s in the corresponding articles by aver-aging its token embeddings (from the embeddinglayer of rot).
considering that a pattern vectorshould be event-irrelevant, we heuristically removethe event-related part in s as possible by calculat-ing the residual embeddings rs,q, i.e., subtractingq from s. we rule out the residual embeddings thatdo not satisfy tlow < (cid:107)rs,q(cid:107)2 < thigh, because theyare unlikely to contain good pattern information:(cid:107)rs,q(cid:107)2 ≤ tlow indicates q and s are highly simi-lar and thus leave little pattern information, while.
i=1..figure 3: illustration for memory vector update..(cid:107)rs,q(cid:107)2 ≥ thigh indicates s may not align with q interms of the event, so the corresponding rs,q is oflittle sense.
finally, we aggregate the valid residualembeddings into k clusters using k-means andobtain the initial memory bank m:.
m = k-means(cid:0){rvalid.
s,q }(cid:1) = {m1, ..., mk} (4).
s,q } is the set of valid residual embed-.
where {rvaliddings.
update.
as the initial k vectors may not accu-rately represent common patterns, we update thememory bank according to the feedbacks of resultsduring training: if the model predicts rightly, thekey sentence, say s, should be used to update itsnearest pattern vector m. to maintain stability, weuse an epoch-wise update instead of an iteration-wise update..take updating m as an example.
after an epoch,we extract all n key sentences whose nearest pat-tern vector is m and their n corresponding claims,which is denoted as a tuple set (s, q)m. then(s, q)m is separated into two subsets, rm andw m, which contain nr and nw sentence-claim tu-ples from the rightly and wrongly predicted sam-ples, respectively.
the core of our update mecha-nism (figure 3) is to draw m closer to the residualembeddings in rm and push it away from those inw m. we denote the ith residual embedding fromthe two subsets as rrmi., respectively..and rwmi.to determine the update direction, we calculatea weighted sum of residual embeddings accord-ing to the predicted matching scores.
for (s, q),suppose mtm output ˆys,q ∈ [0, 1] as the predictedmatching score of q and d (whose key sentence iss), the weight of rs,q is |ˆys,q − 0.5| (denoted asws,q).
weighted residual embeddings are respec-tively summed and normalized as the components.
5471residualembeddingfortherightly-predictedsampleresidualembeddingforthewrongly-predictedsampleweightedsumofpatternvectorpushawaydrawcloserof the direction vector (eq.
5):.
3.2 article relevance prediction (arp).
umr =.
wrmi.rrmi., umw =.
wwmi.rwmi.
(cid:19).
(cid:18) nw(cid:88).
i=1.
(cid:18) nr(cid:88).
i=1.
(5)where umr and umw are the aggregated residualembeddings.
the direction is determined by eq.
6:.
(cid:19).
sentence representation.
we model morecomplicated interactions between the claim andthe key sentences by feeding each zq,skey (de-rived from rot) into a multi-layer transformer(multitransformer):.
um = wr (umr − m)(cid:125)(cid:124).
(cid:123)(cid:122)draw closer.
+ww (m − umw)(cid:125).
(cid:123)(cid:122)push away.
(cid:124).
(6).
where wr and ww are the normalized sum of cor-responding weights used in eq.
5 (wr + ww = 1).
the pattern vector m is updated with:.
mnew = mold + λm(cid:107)mold(cid:107)2.
(7).
um(cid:107)um(cid:107)2.where mold and mnew are the memory vector mbefore and after updating; the constant λm and(cid:107)mold(cid:107)2 jointly control the step size..3.1.3 key sentence selection.
whether a sentence is selected as a key sentenceis determined by combining claim- and pattern-sentence relevance scores.
the former is calcu-lated with the distance of q and s trained with rot(eq.
8) and the latter uses the distance betweenthe nearest pattern vector in pmb and the residualembedding (eq.
9).
the scores are scaled to [0, 1].
for each sentence s in d, the relevance score withq is calculated by eq.
10:.
scrq(q, s) = scale((cid:107)rs,q(cid:107)2).
(8).
scrp (q, s) = scale((cid:107)mu − rs,q(cid:107)2).
(9).
scr(q, s) = λqscrq(q, s) + λp scrp (q, s) (10).
where scale(x) = 1 − x−minmax−min and max and minare the maximum and minimum distance of s in d,respectively.
u = arg mini (cid:107)mi − rs,q(cid:107)2, and λqand λp are hyperparameters whose sum is 1..finally, sentences with top-k2 scores, denotedi=1, are selected as the key.
as k = {skeysentences in d for the claim q..(q, d)}k2.
i.z(cid:48)q,skey = multitransformer(zq,skey ).
(11).
following (reimers and gurevych, 2019), we re-spectively compute the mean of all output tokenvectors of q and s in z(cid:48)q,skey to obtain the ﬁxed sizedsentence vectors q(cid:48) ∈ rdim and skey(cid:48) ∈ rdim,where dim is the dimension of a token in trans-formers.
weighted memory-aware aggregation.
for ﬁnalprediction, we use a score-weighted memory-awareaggregation.
to make the predictor aware of thepattern information, we append the correspondingnearest pattern vectors to the claim and key sen-tence vectors:.
vi = [q(cid:48), skey(cid:48).
i.
(q, d), mj].
(12).
i.,q.
(cid:13)(cid:13)(cid:13)mk −rskey.
where i = 1, ..., k2.
j = arg mink.
(cid:13)(cid:13).
(cid:13)2intuitively, a sentence with higher score shouldbe attended more.
thus, the concatenated vectors(eq.
12) are weighted by the relevance scores fromeq.
10 (normalized across the top-k2 sentences).
the weighted aggregating vector is fed into a mlpwhich outputs the probability that d fact-checks q:)(cid:1) (13).)
= normalize(cid:0)scr(q, skey.
scr(cid:48)(q, skey.
i.
ˆyq,d = mlp.
scr(cid:48)(q, skey.
)vi.
i.
(14).
(cid:16) k2(cid:88).
i=1.
where ˆyq,d ∈ [0, 1].
if ˆyq,d > 0.5, the model pre-dicts that d fact-checks q, otherwise does not.
theloss function is cross entropy:.
lm = crossentropy(ˆyq,d, yq,d).
(15).
where yq,d ∈ {0, 1} is the ground truth label.
yq,d = 1 if d fact-checks q and 0 otherwise.
thepredicted values are used to rank all k1 candidatearticles retrieved in the ﬁrst stage..3.3 training mtmwe summarize the training procedure of mtm inalgorithm 1, including the pretraining of rot, theinitialization of pmb, the training of arp, and theepoch-wise update of pmb..i.
(cid:17).
5472algorithm 1 mtm training procedureinput: training set t = [(q0, d00), ..., (q0, d0k1),..., (qn, dnk1)] where the k1 candidate articlesfor each claim are retrieved by bm25.
1: pre-train rouge-guided transformer.
2: initialize the pattern memory bank (pmb).
3: for each epoch do4:.
for (q, d) in t do.
// key sentence identiﬁcationcalculate scrq(q, s) via rot and.
scrp (q, s) via pmb..calculate scr(q, s) using eq.10.
select key sentences k.// article relevance prediction (arp)calculate v for each s in k and ˆyq,d.
update the arp to minimize lm ..5:.
6:.
7:.
8:.
9:.
10:.
11:.
12:.
end forupdate the pmb using eq.
7..13:14: end for.
4 experiments.
in this section, we mainly answer the followingexperimental questions:eq1: can mtm improve the ranking performanceof fc-articles given a claim?
eq2: how effective are the components ofmtm, including rouge-guided transformer, pat-tern memory bank, and weighted memory-awareaggregation in article relevance prediction?
eq3: to what extent can mtm identify key sen-tences in the articles, especially in the longer ones?.
4.1 data.
we conducted the experiments on two real-worlddatasets.
table 1 shows the statistics of the twodatasets.
the details are as follows:twitter dataset.
the twitter4 dataset is originated from (vo andlee, 2019) and processed by vo and lee (2020).
the dataset pairs the claims (tweets) with the cor-responding fc-articles from snopes.
for tweetswith images, it appends the ocr results to thetweets.
we remove the manually normalized claimsin snopes’ fc-articles to adapt to more general sce-narios.
the data split is the same as that in (vo andlee, 2020).
weibo dataset.
we built the ﬁrst chinese dataset for the task ofdetecting previously fact-checked claims in this ar-.
table 1: statistics of the twitter and the weibo dataset.
#: number of.
c-a pairs: claim-article pairs..dataset.
twittertesttraintestval8,002 1,000 1,0012,3861,703 1,697 1,697 17,385 8,353 11,7157,245.
#claim#articlesc-a pairs 8,025 1,002 1,005 28,596 3,337.weibotrainval8,356 1,192.relevant fact-checking articles per claim.
averagemediummaximum.
1.003 1.002 1.00412.
12.
12.
3.422 2.799118.
250.
3.036232.ticle.
the claims are collected from weibo and thefc-articles are from multiple fact-checking sourcesincluding jiaozhen, zhuoyaoji5, etc.
we recruitedannotators to match claims and fc-articles basedon basic search results.
appendix a introduce thedetails..4.2 baseline methods.
bert-based rankers from general ir tasks.
bert (devlin et al., 2019): a method of pre-training language representations with a familyof pretrained models, which has been used ingeneral document reranking to predict the rele-vance.
(nogueira and cho, 2019; akkalyoncu yil-maz et al., 2019).
duobert (nogueira et al., 2019): a popularbert-based reranker for multi-stage documentranking.
its input is a query and a pair of doc-uments.
the pairwise scores are aggregated forﬁnal document ranking.
our ﬁrst baseline, bert(trained with query-article pairs), provides the in-puts for duobert..bert(transfer): as no sentence-level labelsare provided in most document retrieval datasets,yang et al.
(2019) ﬁnetune bert with short textmatching data and then apply to score the relevancebetween query and each sentence in documents.
the three highest scores are combined with bm25score for document-level prediction.
rankers from related works of our task.
sentence-bert: shaar et al.
(2020) use pre-trained sentence-bert models to calculate cosinesimilarity between each sentence and the givenclaim.
then the top similarity scores are fed into aneural network to predict document relevance..ranksvm: a pairwise ranksvm model forreranking using the scores from bm25 andsentence-bert (mentioned above), which achievesthe best results in (shaar et al., 2020)..4https://twitter.com.
5https://piyao.sina.cn.
5473table 2: performance of baselines and mtm.
best results are in boldface..method.
bm25bertduobertbert(transfer)sentence-bertranksvmctmmtm.
selectingsentences?.
mrr.
weibo.
map@3.
1.
5.hit@53.mrr.
twitter.
map@3.
1.
5.hit@53.
0.709 0.355 0.496 0.546 0.741 0.760 0.522 0.460 0.489 0.568 0.527 0.5680.834 0.492 0.649 0.693 0.850 0.863 0.895 0.875 0.890 0.890 0.908 0.9090.885 0.541 0.713 0.756 0.886 0.887 0.923 0.921 0.922 0.922 0.923 0.9230.714 0.361 0.504 0.553 0.742 0.764 0.642 0.567 0.612 0.623 0.668 0.7190.750 0.404 0.543 0.589 0.810 0.861 0.794 0.701 0.775 0.785 0.864 0.9050.809 0.408 0.607 0.661 0.887 0.917 0.846 0.778 0.832 0.840 0.898 0.9300.856 0.356 0.481 0.525 0.894 0.935 0.926 0.889 0.919 0.922 0.952 0.9640.902 0.542 0.741 0.798 0.934 0.951 0.931 0.899 0.926 0.928 0.957 0.967.
(cid:88)(cid:88)(cid:88).
(cid:88).
table 3: ablation study of mtm.
best results are in boldface.
ag: ablation group..ag variant.
mrr.
weibo.
map@3.
1.
5.hit@53.mrr.
twitter.
map@3.
1.
5.hit@53.mtm.
0.902 0.542 0.741 0.798 0.934 0.951 0.931 0.899 0.926 0.928 0.957 0.967-1 w/o rouge guidance 0.892 0.535 0.729 0.786 0.925 0.943 0.929 0.905 0.924 0.926 0.945 0.9520.879 0.516 0.700 0.753 0.912 0.935 0.897 0.860 0.890 0.893 0.922 0.9380.898 0.541 0.736 0.790 0.935 0.948 0.925 0.897 0.860 0.890 0.922 0.9380.897 0.537 0.734 0.792 0.931 0.948 0.920 0.885 0.913 0.917 0.944 0.9600.901 0.540 0.739 0.796 0.938 0.958 0.923 0.892 0.917 0.919 0.944 0.9540.896 0.535 0.734 0.791 0.930 0.945 0.922 0.890 0.917 0.919 0.947 0.954.w/ rand mem initw/o mem updatew/o pmbw/ avg.
poolw/o pattern aggr..3.
2.ctm (vo and lee, 2020): this method lever-ages glove and elmo to jointly represent theclaims and the fc-articles for predicting the rel-evance scores.
its multi-modal version is not in-cluded as mtm focuses on key textual information..4.3 experimental setup.
evaluation metrics.
as this is a binary retrievaltask, we follow shaar et al.
(2020) and reportmean reciprocal rank (mrr), mean averageprecision@k (map@k, k = 1, 3, 5) and hit@k(k = 3, 5).
see equations in appendix b.implementation details.
in mtm, the rot andarp components have one and eleven transformerlayers, respectively.
the initial parameters areobtained from pretrained bert models6.
otherparameters are randomly initialized.
the dimen-sion of claim and sentence representation in arpand pattern vectors are 768. number of clustersin pmb k is 20. following (shaar et al., 2020)and (vo and lee, 2020), we use k1 = 50 candidatesretrieved by bm25.
k2 = 3 (weibo, hereafter, w) /5 (twitter, hereafter, t) key sentences are selected.
we use adam (p. kingma and ba, 2015) for op-timization with (cid:15) = 10−6, β1 = 0.9, β2 = 0.999.the learning rates are 5 × 10−6 (w) and 1 × 10−4(t).
the batch size is 512 for pretraining rot, 64for the main task.
according to the quantiles on.
6we use bert-base-chinese for weibo and.
bert-base-uncased for twitter..training sets, we set tlow = 0.252 (w) / 0.190 (t),thigh = 0.295 (w) / 0.227 (t).
the following hy-perparameters are selected according to the bestvalidation performance: λr = 0.01 (w) / 0.05 (t),λq = 0.6, λp = 0.4, and λm = 0.3. the maxi-mum epoch is 5. all experiments were conductedon nvidia v100 gpus with pytorch (paszkeet al., 2019).
the implementation details of base-lines are in appendix c..4.4 performance comparison.
to answer eq1, we compared the performance ofbaselines and our method on the two datasets, asshown in table 2. we see that: (1) mtm ourper-forms all compared methods on the two datasets(the exception is only the map@1 on twitter),which indicates that it can effectively ﬁnd relatedfc-articles and provide evidence for determiningif a claim is previously fact-checked.
(2) forall methods, the performance on weibo is worsethan that on twitter because the weibo datasetcontains more claim-sentence pairs (from multi-ple sources) than twitter and is more challeng-ing.
despite this, mtm’s improvement is signif-icant.
(3) bert(transfer), sentence-bert andranksvm use transferred sentence-level knowl-edge from other pretext tasks but did not outper-form the document-level bert.
this is because fc-articles have their own characteristics, which maynot be covered by transferred knowledge.
in con-.
5474trast, our observed characteristics help mtm achievegood performance.
moreover, mtm is also efﬁ-ciency compared to bert(transfer), which alsouses 12-layer bert and selects sentences, be-cause our model uses only one layer for all sen-tences (other 11 layers are for key sentences),while all sentences are fed into the 12 layers inbert(transfer)..4.5 ablation study.
to answer eq2, we evaluated three ablation groupsof mtm’s variants (ag1∼ag3) to investigate theeffectiveness of the model design.7 table 3 showsthe performance of variants and mtm..ag1: with vs. without rouge.
the variantremoves the guidance of rouge (mtm w/o rougeguidance) to check the effectiveness of rouge-guided ﬁnetuning.
the variant performs worse onweibo, but map@1 slightly increases on twitter.
this is probably because there are more lexicaloverlapping between claims and fc-articles in theweibo dataset, while most of the fc-articles in thetwitter dataset choose to summarize the claims tofact-check..ag2: cluster-based initialization vs. ran-dom initialization vs. without update vs. with-out pmb.
the ﬁrst variant (mtm w/ rand meminit) uses random initialization and the second(mtm w/o mem update) uses pattern vectors with-out updating.
the last one (mtm w/o pmb) re-moves the pmb.
we see that the variants all per-form worse than mtm on mrr, of which w/ randmem init performs the worst.
this indicates thatcluster-based initialization provides a good startand facilitates the following updates while the ran-dom one may harm further learning..ag3: score-weighted pooling vs. averagepooling, and with vs. without pattern vector.
the ﬁrst variant, mtm w/ avg.
pool, replace thescore-weighted pooling with average pooling.
thecomparison in terms of mrr and map shows theeffectiveness of using relevance scores as weights.
the second, mtm w/o pattern aggr., does not ap-pend the pattern vector to claim and sentence vec-tors before aggregation.
it yields worse results,indicating the patterns should be taken into consid-eration for ﬁnal prediction..7we do not run mtm without sentence selection due to itshigh computational overhead which makes it unfeasible fortraining and inference..figure 4: visualization of pattern vectors ((cid:78)) and nearresidual embeddings ((cid:54)).
the sentences are translatedfrom chinese..figure 5: results of human evaluation.
(a)the pro-portion of the fc-articles where mtm found {0, 1, 2, 3}key sentences.
(b) the proportion of key sentences atrank {1, 2, 3}.
(c) the positional distribution of keysentences in the fc-articles..4.6 visualization of memorized patterns.
to probe what the pmb summarizes and memo-rizes, we selected and analyzed the key sentencescorresponding to the residual embeddings aroundpattern vectors.
figure 4 shows example sentenceswhere highly frequent words are in boldface.
theseexamples indicate that the pattern vectors do clusterkey sentences with common patterns like “...spreadin wechat moments”..4.7 human evaluation and case study.
the quality of selected sentences cannot be auto-matically evaluated due to the lack of sentence-level labels.
to answer eq3, we conducted a hu-man evaluation.
we randomly sampled 370 claim-article pairs whose articles were with over 20 sen-tences from the weibo dataset.
then we showedeach claim and top three sentences selected fromthe corresponding fc-article by mtm.
three anno-.
5475★avideoofateenagerdrowningisspreading online,withthecontentthat... ★recently, a pieceofnewsabout the new driving test regulations spreadin wechat moments.★itisreportedthatthe video attached to this rumorrecordsthe scene of the 6.11 homicide in xihua, and istotallyunrelated to the rumorthat four monks killedpeopleforthe kidneys.★after investigation, the poststated that russia confirmed that mh370 was hijacked to a us military base.
butthere was no reportonthemainstream russian media.
the reportedpublisherwas judged to publish false information.★according tothe publisher, it just wanted to attractnetizens and increase its popularity.
itneverparticipated in marking forgaokao.★in the past two days, there was a picture onlinecalled  “the latest international gestureforpolicecalling”, which attracted many netizens to forwardit.★afterretrieving,theeditorfounditwasavariantofanoldrumorpublishedin2014thatclaimsukrainian embassy ishiring mercenaries in china.★the police verified thatthe newswas a rumor.
wehereremindthatyoushouldnotforward the messageas soon as yousee it, and not dial the phone number in the news.
(a)(b)(c)figure 6: cases in the set of human evaluation.
quota-tions are underlined and patterns are in boldface..broader impact statement.
acknowledgments.
the authors thank guang yang, tianyun yang,peng qi and anonymous reviewers for their in-sightful comments.
also, we thank rundongli, qiong nan, and other annotators for their ef-forts.
this work was supported by the nationalkey research and development program of china(2017yfc0820604), the national natural sciencefoundation of china (u1703261), and the funda-mental research funds for the central universitiesand the research funds of renmin university ofchina (no.
18xnlg19).
the corresponding au-thors are juan cao and xirong li..our work involves two scenarios that need theability to detect previously fact-checked claims:(1) for social media platforms, our method cancheck whether a newly published post containsfalse claims that have been debunked.
the platformmay help the users to be aware of the text’s verac-ity by providing the key sentences selected fromfact-checking articles and their links.
(2) for man-ual or automatic fact-checking systems, it can be aﬁlter to avoid redundant fact-checking work.
whenfunctioning well, it can assist platforms, users, andfact-checkers to maintain more credible cyberspace.
but in the failure cases, some well-disguised claimsmay escape.
this method functions with relianceon the used fact-checking article databases.
thus,authority and credibility need to be carefully con-sidered in practice.
we did our best to make thenew weibo dataset for academic purpose reliable.
appendix a introduces more details..references.
oluwaseun ajao, deepayan bhowmik, and shahrzadzargari.
2019. sentiment aware fake news detec-tion on online social networks.
in 2019 ieee inter-national conference on acoustics, speech and sig-nal processing (icassp), pages 2507–2511..zeynep akkalyoncu yilmaz, shengjin wang, weiyang, haotian zhang, and jimmy lin.
2019. apply-ing bert to document retrieval with birch.
in pro-ceedings of the 2019 conference on empirical meth-ods in natural language processing and the 9th in-ternational joint conference on natural languageprocessing (emnlp-ijcnlp): system demonstra-tions, pages 19–24, hong kong, china.
associationfor computational linguistics..wanxiang che, yijia liu, yuxuan wang, bo zheng,and ting liu.
2018. towards better ud parsing:.
tators were asked to check if an auto-selected sen-tence helped match the given query and the sourcearticle (i.e., key sentences).
figure 5 shows (a)mtm hit at least one key sentence in 83.0% of thearticles; (b) 73.0% of the sentences at rank 1 arekey sentences, followed by 65.1% at rank 2 and56.8% at rank 3. this proves that mtm can ﬁndthe key sentences in long fc-articles and providehelpful explanations.
we also show the positionaldistribution in figure 5(c), where key sentencesare scattered throughout the articles.
using mtm toﬁnd key sentences can save fact-checkers’ time toscan these long articles for determining whetherthe given claim was fact-checked..additionally, we exhibit two cases in the eval-uation set in figure 6. these cases prove thatmtm found the key sentences that correspond tothe characteristics described in section 1. pleaserefer to appendix d for further case analysis..5 conclusions.
we propose mtm to select from fact-checked arti-cles key sentences that introduce or debunk claims.
these auto-selected sentences are exploited in anend-to-end network for estimating the relevanceof the fact-checked articles w.r.t.
a given claim.
experiments on the public twitter dataset and theprivate weibo dataset show that mtm outperformsthe state of the art.
moreover, human evaluationand case studies demonstrate that the selected sen-tences provide helpful explanations of the results..5476claimisthistomaketheso-calledartificialeggs?surprising!#videokeysentencesks1.recently,ashortvideothatclaimsaproductionprocessoftheartificialfakeeggshaswidelyspreadinwechatgroups.ks2.thereporterofshanghaiobserverfoundthatthevideoactuallyrecordedmakingtoyeggs,whichwerenottopretendasrealeggsforsale.ks3.relatingthevideooftoyeggproductiontofoodsafetyissues is justa gimmickusedbyspreaders.claimstatefda:60%ofthedrugswillbestoppedsellingwithin2or3yearsandwillbereplacedbynutraceuticalindustry.statewillinvest8trillion!keysentencesks1.it’sbeenreportedthatfdahasproposedthat60%ofthedrugswillbestoppedsellingwithinthenext2or3yearsandreplacedbynutraceuticalsandfoods.ks2.thereportervisitedthewebsiteofthefdabutfoundnosuchofficialdocuments,indicatingthedetailsintheclaimwerepurelyfabricated.ks3.it’sverifiedthattheclaimthatnutraceuticalswillreplacedrugsisamaliciouspropagandabycompaniestoconfusethenetizens.
deep contextualized word embeddings, ensemble,in proceedings ofand treebank concatenation.
the conll 2018 shared task: multilingual pars-ing from raw text to universal dependencies, pages55–64, brussels, belgium.
association for computa-tional linguistics..qingqing chen.
coronavirus rumors trigger irrationalbehaviors among chinese netizens [online].
2020..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language un-derstanding.
in proceedings of the 2019 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..duke reporters’ lab.
fact-checking count tops 300.for the ﬁrst time [online].
2020..murhaf fares, andrey kutuzov, stephan oepen, anderik velldal.
2017. word vectors, reuse, and replica-bility: towards a community repository of large-textin proceedings of the 21st nordic con-resources.
ference on computational linguistics, pages 271–276, gothenburg, sweden.
association for compu-tational linguistics..marc fisher, john woodrow cox, and peter hermann.
2016. pizzagate: from rumor, to hashtag, to gunﬁrein dc.
washington post, 6..luyu gao, zhuyun dai, zhen fan, and jamiecallan.
2020. complementing lexical retrievalarxiv,with semantic residual embedding.
arxiv:2004.13969. version 2..thorsten joachims.
2006. training linear svms inin proceedings of the 12th acmlinear time.
sigkdd international conference on knowledgediscovery & data mining, pages 217–226, newyork, ny, usa.
association for computing machin-ery..shen li, zhe zhao, renfen hu, wensi li, tao liu, andxiaoyong du.
2018. analogical reasoning on chi-nese morphological and semantic relations.
in pro-ceedings of the 56th annual meeting of the associa-tion for computational linguistics (volume 2: shortpapers), pages 138–143, melbourne, australia.
as-sociation for computational linguistics..xirong li, tiberio uricchio, lamberto ballan, marcobertini, cees g. m. snoek, and alberto del bimbo.
2016. socializing the semantic gap: a compara-tive survey on image tag assignment, reﬁnement,and retrieval.
acm computing surveys, 49(1)..chin-yew lin.
2004. rouge: a package for auto-matic evaluation of summaries.
in text summariza-tion branches out, pages 74–81, barcelona, spain.
association for computational linguistics..jimmy lin, miles efron, yulu wang, and garrick sher-man.
2014. overview of the trec-2014 microblogtrack.
in twenty-third text retrieval conference(trec 2014) proceedings..xin liu, qingcai chen, chong deng, huajun zeng,jing chen, dongfang li, and buzhou tang.
2018.lcqmc:a large-scale chinese question matchingin proceedings of the 27th internationalcorpus.
conference on computational linguistics, pages1952–1962, santa fe, new mexico, usa.
associ-ation for computational linguistics..yang liu and yi-fang wu.
2018. early detectionof fake news on social media through propaga-tion path classiﬁcation with recurrent and convo-lutional networks.
in proceedings of the aaai con-ference on artiﬁcial intelligence, volume 32, pages354–361.
aaai press..van-hoang nguyen, kazunari sugiyama, preslavnakov, and min-yen kan. 2020. fang: lever-aging social context for fake news detection us-in proceedings of theing graph representation.
29th acm international conference on information& knowledge management, pages 1165–1174, newyork, ny, usa.
association for computing machin-ery..rodrigo nogueira and kyunghyun cho.
2019. passagere-ranking with bert.
arxiv, arxiv:1901.04085.version 5..rodrigo nogueira, wei yang, kyunghyun cho, andjimmy lin.
2019. multi-stage document rankingwith bert.
arxiv, arxiv:1910.14424. version 1..diederik p. kingma and jimmy ba.
2015. adam: ain interna-.
method for stochastic optimization.
tional conference on learning representations..adam paszke, sam gross, francisco massa, adamlerer, james bradbury, gregory chanan, trevorkilleen, zeming lin, natalia gimelshein, lucaantiga, alban desmaison, andreas kopf, edwardyang, zachary devito, martin raison, alykhan te-jani, sasank chilamkurthy, benoit steiner, lu fang,junjie bai, and soumith chintala.
2019. pytorch:an imperative style, high-performance deep learn-ing library.
in advances in neural information pro-cessing systems, volume 32, pages 8026–8037.
cur-ran associates, inc..jeffrey pennington, richard socher, and christophermanning.
2014. glove: global vectors for wordin proceedings of the 2014 con-representation.
ference on empirical methods in natural languageprocessing (emnlp), pages 1532–1543, doha,qatar.
association for computational linguistics..matthew peters, mark neumann, mohit iyyer, mattgardner, christopher clark, kenton lee, and lukezettlemoyer.
2018. deep contextualized word rep-in proceedings of the 2018 confer-resentations.
ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1 (long papers), pages.
54772227–2237, new orleans, louisiana.
associationfor computational linguistics..kashyap popat,.
subhabrata mukherjee,.
jannikstr¨otgen, and gerhard weikum.
2018a.
credeye:a credibility lens for analyzing and explainingin companion proceedings ofmisinformation.
the the web conference 2018, pages 155–158,republic and canton of geneva, che.
internationalworld wide web conferences steering committee..kashyap popat, subhabrata mukherjee, andrew yates,and gerhard weikum.
2018b.
declare: debunkingfake news and false claims using evidence-awarein proceedings of the 2018 con-deep learning.
ference on empirical methods in natural languageprocessing, pages 22–32, brussels, belgium.
asso-ciation for computational linguistics..piotr przybyla.
2020. capturing the style of fakein proceedings of the aaai conference onnews.
artiﬁcial intelligence, volume 34, pages 490–497.
aaai press..peng qi, juan cao, tianyun yang, junbo guo, and jin-tao li.
2019. exploiting multi-domain visual in-formation for fake news detection.
in 2019 ieeeinternational conference on data mining (icdm),pages 518–527.
ieee..radim ˇreh˚uˇrek and petr sojka.
2010. software frame-work for topic modelling with large corpora.
inproceedings of the lrec 2010 workshop on newchallenges for nlp frameworks, pages 45–50, val-letta, malta.
elra..nils reimers and iryna gurevych.
2019. sentence-bert: sentence embeddings using siamese bert-networks.
in proceedings of the 2019 conferenceon empirical methods in natural language process-ing and the 9th international joint conference onnatural language processing (emnlp-ijcnlp),pages 3982–3992, hong kong, china.
associationfor computational linguistics..nils reimers and iryna gurevych.
2020. makingmonolingual sentence embeddings multilingual us-in proceedings of theing knowledge distillation.
2020 conference on empirical methods in naturallanguage processing (emnlp), pages 4512–4525,online.
association for computational linguistics..stephen robertson and hugo zaragoza.
2009. theprobabilistic relevance framework: bm25 and be-yond.
foundations and trends in information re-trieval, 3(4):333–389..nir rosenfeld, aron szanto, and david c. parkes.
2020. a kernel of truth: determining rumor ve-inracity on twitter by diffusion pattern alone.
proceedings of the web conference 2020, page1018–1028, new york, ny, usa.
association forcomputing machinery..shaden.
shaar,.
nikolay babulkov,.
giovannida san martino, and preslav nakov.
2020. that isa known lie: detecting previously fact-checkedclaims.
in proceedings of the 58th annual meetingofthe association for computational linguis-tics, pages 3607–3618, online.
association forcomputational linguistics..kai shu, limeng cui, suhang wang, dongwon lee,and huan liu.
2019. defend: explainable fakein proceedings of the 25th acmnews detection.
sigkdd international conference on knowledgediscovery & data mining, page 395–405, newyork, ny, usa.
association for computing machin-ery..tensorflow.
classiﬁcation on imbalanced data [on-.
line].
2021..james thorne, andreas vlachos, oana cocarascu,christos christodoulopoulos, and arpit mittal.
2018.the fact extraction and veriﬁcation (fever)in proceedings of the first work-shared task.
shop on fact extraction and veriﬁcation (fever),pages 1–9, brussels, belgium.
association for com-putational linguistics..nguyen vo and kyumin lee.
2019. learning fromfact-checkers: analysis and generation of fact-in proceedings of the 42ndchecking language.
international acm sigir conference on researchand development in information retrieval, pages335–344.
association for computing machinery..nguyen vo and kyumin lee.
2020. where are thefacts?
searching for fact-checked information toin proceed-alleviate the spread of fake news.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages7717–7731, online.
association for computationallinguistics..jingqiong wang and xinzhu li.
2011. radiation fearsprompt panic buying of salt.
china daily, 18:2011–03..xuezhi wang, cong yu, simon baumgartner, and flipkorn.
2018. relevant document discovery for fact-in companion proceedings ofchecking articles.
the the web conference 2018, pages 525–533, lyon,france.
international world wide web conferencessteering committee..wikipedia.
mean reciprocal rank [online].
2021..zhirong wu, yuanjun xiong, stella x. yu, and dahualin.
2018. unsupervised feature learning viain 2018non-parametric instance discrimination.
ieee/cvf conference on computer vision and pat-tern recognition, pages 3733–3742..qizhe xie, zihang dai, eduard hovy, minh-thang lu-ong, and quoc v le.
2020. unsupervised data aug-mentation for consistency training.
in advances inneural information processing systems, volume 33.curran associates, inc..5478xinhua net.
three common types of internet rumorspresent a new trend of visual spread [online].
2019.in chinese..wei yang, haotian zhang, and jimmy lin.
2019. sim-ple applications of bert for ad hoc document re-trieval.
arxiv, arxiv:1903.10972. version 1..xiwang yang, harald steck, yang guo, and yong liu.
2012. on top-k recommendation using social net-works.
in proceedings of the sixth acm conferenceon recommender systems, pages 67–74, new york,ny, usa.
association for computing machinery..tianyi zhang, varsha kishore, felix wu, kilianq. weinberger, and yoav artzi.
2020. bertscore:evaluating text generation with bert.
in interna-tional conference on learning representations..xueyao zhang, juan cao, xirong li, qiang sheng, leizhong, and kai shu.
2021. mining dual emotionin proceedings of thefor fake news detection.
the web conference 2021. international world wideweb conferences steering committee..xing zhou, juan cao, zhiwei jin, fei xie, yu su,dafeng chu, xuehui cao, and junqiang zhang.
2015. real-time news certiﬁcation system onin proceedings of the 24th interna-sina weibo.
tional conference on world wide web, www ’15companion, pages 983–988, new york, ny, usa.
association for computing machinery..a constructing the new weibo dataset.
to construct datasets for fact-checked claim detec-tion on social media, we need to (1) collect thefact-checked claims (social media posts); (2) col-lect fact-checking articles (fc-articles); and (3)generate claim-article pairs..collection.
in step (1), we used posts whose la-bels are fake from the datasets for fake news detec-tion (zhang et al., 2021; zhou et al., 2015), becausetheir labels were determined by fact-checking.
instep (2), we crawled fact-checking articles frommultiple sources to enrich the article base.
thesources are partially listed in table 4 due to thespace limit.
for the claims and articles which con-tained much text in the attached images, we recog-nized the text using ocr service on baidu ai plat-form8.
note that we only crawled the claims andarticles that were publicly available at the crawlingtime.
to protect privacy, the publishers’ nameswere removed.
however, we preserved names andoffensive words in the main text because they werecrucial for summarizing the events and performingthe matching process..8https://ai.baidu.com/tech/ocr.
annotation.
in step (3), we performed a model-assisted human annotation.
we ﬁrst duplicated thedata collected in step (1) and (2) and then usedbm25 to retrieve the relevant fc-articles as candi-dates with the claims as queries.
twenty-six annota-tors (postgraduates) were instructed (by a chineseguideline with examples written by the ﬁrst author)to check whether the candidates did fact-check thegiven claims.
we dropped the claims that are an-notated as irrelevant to all candidates.
for claimsthat were with highly overlapping candidates butdifferent annotation results, the authors manuallychecked and corrected the wrongly annotated sam-ples..b calculation of evaluation metrics.
assume that query set q has |q| queries and the ithquery has ni relevant documents.
we calculate theevaluation metrics using the following equations:.
mrr =.
1|q|.
|q|(cid:88).
i=1.
1ranki.
(16).
where ranki refers to the rank position of the ﬁrstrelevant answer for the ith query in the correspond-ing retrieving result.
(wikipedia, 2021).
map@k =.
pi(j)reli(j).
(17).
1|q|.
|q|(cid:88).
ni(cid:88).
1ni.
i=1.
j=1.
where pi(j) is the proportion of returned docu-ments in the top-j set for the ith query that arerelevant.
reli(j) is an indicator function equaling1 if the document at rank j in the returned list forthe ith query is relevant and 0 otherwise.
(li et al.,2016).
hit@k =.
hasi(k).
(18).
1|q|.
|q|(cid:88).
i=1.
where hasi(k) is an indicator function equaling 1if ranki ≤ k and 0 otherwise.
(yang et al., 2012)note that we guarantee that a query has at leastone relevant document in its candidate list, so thecorner case of empty ground truth set is ignored..c implementation of bm25 and.
baselines.
bm25: thegensim ( ˇreh˚uˇrek and sojka, 2010)..articles were.
indexed with.
5479table 4: part of the sources of fact-checking articles in the weibo dataset..sourcejiaozhen.
descriptiona fact-checking platform operated by tencent..liuyanbaikebaidu piyao.
sciencefacts.
qiuzhen.
joint.
inter-rumor-busting.
dingxiang doctorchinanetplatformzhuoyaoji.
a debunking website operated by guokr.
a fact-checking account operated by baidu..a platform to fact-check scientiﬁc claims supportedby china association for science and technologya fact-checking column of people’s daily online.
a platform for doctors and experts in life sciencea platform operated by cyberspace administrationof china.
sina news ofﬁcial fact-checking account.
weibo piyao.
weibo ofﬁcial fact-checking account.
urlhttps://fact.qq.com/,https://new.qq.com/omn/author/5107513http://www.liuyanbaike.com/https://author.baidu.com/home?app_id=15060https://piyao.kepuchina.cn/.
http://society.people.com.
cn/gb/229589/index.htmlhttps://dxy.com/http://www.piyao.org.cn/.
http://piyao.sina.cn/, https://weibo.com/u/6590980486https://weibo.com/weibopiyao.
bert: we ﬁnetuned the last transformer layerof bert-base-chinese for chinese andbert-base-uncased for english.
followingthe commonly used strategy (e.g., xie et al., 2020),we truncated the sequences to the maximum lengthof 512. the maximum length of claims is the sameas mtm and the rest tokens are from articles..duobert : we used top 20 articles from theresults of bert as candidates to construct articlepairs.
for each article, the score is obtained bysumming its pairwise scores.
the used pretrainedmodels are the same as bert (mentioned above)and we ﬁnetuned the layers except the embeddinglayer and the ﬁrst transformer layer..bert(transfer): for the twitter data, we usedthe models provided in birch (akkalyoncu yil-maz et al., 2019) that was ﬁnetuned on trecmicroblog track data (lin et al., 2014); for theweibo data, we used lcqmc dataset (liu et al.,2018) containing 260,068 text pairs to ﬁnetunebert-based-chinese for 20 epochs.
con-sidering the value difference between bm25 andbert scores, the weight of bm25 score waslearned by grid search in [0, 1] but the weights ofothers were in [0, 5].
the step size was 0.1. we gotthe best results with bm25 weight = 0.2 (weibo)/ 0.1 (twitter) and the weights of top-3 sentences= 1.2, 0.4, 0.9 (weibo) / 4.8, 4, 2.5 (twitter), re-spectively..sentence-bert: we used the base versionsin sentence-transformers (reimers andgurevych, 2019) to obtain the embeddings againstspeciﬁcally, wethe claims and sentences..used stsb-xlm-r-multilingual (reimersand gurevych, 2020) for the weibo data andstsb-bert-base for twitter9 .
according toshaar et al.
(2020), we calculated the cosine simi-larity of each claim-sentence pair and fed the top-5scores into a simple neural network (20-relu-10-relu) for classiﬁcation.
we trained the model for20 epochs with class weighted cross entropy as theloss function.
the class weights were calculatedacross the dataset (tensorflow, 2021)..ranksvm: we combined the scores and theirreciprocal ranks obtained from sentence-bertmodels and bm25.
then we fed them into aranksvm10 (joachims, 2006) for classiﬁcation.
we used sentence-bert models trained with{3, 4, 5, 6} sentences for twitter and those trainedwith {6, 7, 8, 9} sentences for weibo.
we kept thedefault settings in the package..ctm: for the twitter dataset, we followed (voand lee, 2020) to use glove.6b11 (penning-ton et al., 2014) and the elmo original(5.5b)12 (peters et al., 2018); for the weibo data,we used sgns.weibo.bigram-char13 (liet al., 2018) and simplified-chinese.
9https://www.sbert.net/docs/.
pretrained_models.html.
10http://www.cs.cornell.edu/people/tj/.
svm_light/svm_rank.html.
11https://nlp.stanford.edu/projects/.
glove/.
12https://allennlp.org/elmo13https://github.com/embedding/.
chinese-word-vectors.
5480figure 7: a case with only one key sentence being hitby mtm.
patterns are in boldface..s1 is related to the claim.
s2 and s3 introducesimilar but irrelevant claims.
this is because thatthe fact-checking article is actually a collection ofrumors about south korea on the chinese socialmedia.
the claims in this article are all similar toeach other, and thus, to differentiate them needsmore delicate semantic understanding.
(2) figure 8shows a case where mtm found no key sentencefrom the article.
we append the key sentencesselected manually below.
we speculate that thefailure is due to the length of the given claim.
theclaim is longer than general posts on weibo andcontains many details, making the model lose focuson the key elements of the event description.
thus,s1 describing another news about mh370’s activ-ity in vietnam was selected, instead of the groundtruth sentences.
to achieve better performance, fu-ture work may consider improving the semanticmodeling and summarizing key information fromboth fact-checking articles and claims..figure 8: a case with no key sentence being hit bymtm..elmo14 (che et al., 2018; fares et al., 2017).
wekept the default settings provided by the authors15..d further case analysis.
we reviewed the fact-checking articles in the setfor human evaluation wherein mtm hit less thantwo key sentences.
we here exhibit two situa-tions that make mtm did not perform well: (1)in figure 7, the claim is about where cao caowas born.
mtm found three sentences with signiﬁ-cant patterns (shown in boldface).
however, only.
14https://github.com/hit-scir/.
elmoformanylangs.
15https://github.com/nguyenvo09/.
emnlp2020.
5481claimasreportedbykoreanpeople’sdaily,jae-seojung,professorofewhawomansuniversitykorean,refutestheclaimthatcaocao’stombisatanyang.accordingtohisresearchonchineseandkoreanhistory,professorjungfindsthatcaocaoisakorean.auto-selectedsentencesbymtms1.(theonlykeysentence)somechinesemediaquotedthekoreanpeople’sdailyassayingthatprofessorjae-seojungclaimedthatcaocaoisakorean.s2.
(notkeysentence)somechinesemediaquotedkoreandaily’snews,whichsaidthatprofessorhuanjingpark ofsungkyunkwanuniversitypublishedareportsayingthatsunyat-sen,the founding father of modern china,wasakorean.s3.
(notkeysentence)according to the report,cheng-soopark, a history professor at seoul university in south korea, said that after ten years of research, he believed that it was the korean people who first invented chinese characters.
later, the korean peoplebrought chinese characters to china, forming the present chinese culture.claimi noticed it in mywechatmoments.it was very sad,but istill hope thisisfake!
[the plane crashed in vietnam.all the people on boardwereprobablydead!]
cnn reported that the mh370 wasconfirmed to have fallen within 100 kilometers north of ho chi minh city, vietnam.
because of therainstorm, the local people thought it was a fallingmeteorite.
at present, it is still raininginthelocal area.asitis a mountainous area, so it is difficult to carry out the search and rescue work.auto-selectedsentencesbymtms1.
(notkeysentence)on the evening of the 8th, a short message purportedly from "vietnam news agency" said: "vietnam news agency express at 19:32 on march 8th: 17 hours after malaysia airlines flight mh370 lost contact, it was found by philippine maritime vessels carrying out search and rescue mission in the sea area of 06 55 15" n and 103 34 43 "e.s2.
(notkeysentence)since then, boeing china president deleted the weibopost, saying that "the plane has been found" is the wrong message, and the search continues.s3.
(notkeysentence)on the afternoon of the 8th, the south china sea rescue bureau said that it was a misunderstanding that the two search and rescue vessels previously reported by the media set out from xisha and haikou at 10:49 and 11:30 respectively.groundtruthkeysentencesgt1.cnn did not release thenewsthatthelosing-contact airplanecrashed.gt2.onthe8thofthismonth, it was spread onlinethat “cnn said that theflightmh370 crashed in vietnam".gt3.cnn’sofficialaccountontwitter is stillusingtheterm “lost contact”, and thetvlives also use "missing" to modify mh370.