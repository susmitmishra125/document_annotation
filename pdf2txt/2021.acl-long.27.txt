bridge-based active domain adaptation for aspect term extraction.
zhuang chen, tieyun qian∗school of computer science, wuhan university, china{zhchen18, qty}@whu.edu.cn.
abstract.
as a ﬁne-grained task, the annotation cost ofaspect term extraction is extremely high.
re-cent attempts alleviate this issue using domainadaptation that transfers common knowledgeacross domains.
since most aspect terms aredomain-speciﬁc, they cannot be transferred di-rectly.
existing methods solve this problemby associating aspect terms with pivot words(we call this passive domain adaptation be-cause the transfer of aspect terms relies on thelinks to pivots).
however, all these methodsneed either manually labeled pivot words orexpensive computing resources to build asso-ciations.
in this paper, we propose a novelactive domain adaptation method.
our goalis to transfer aspect terms by actively supple-menting transferable knowledge.
to this end,we construct syntactic bridges by recognizingsyntactic roles as pivots instead of as links topivots.
we also build semantic bridges by re-trieving transferable semantic prototypes.
ex-tensive experiments show that our method sig-niﬁcantly outperforms previous approaches..1.introduction.
aspect term extraction (ate) is a fundamental taskin aspect-based sentiment analysis.
given a re-view sentence “the pizza here is also absolutelydelicious.”, ate aims to extract the term pizza.
re-cent studies deﬁne ate as a sequence tagging taskand propose supervised taggers (wang et al., 2017;xu et al., 2018).
however, due to the high costof token-level annotation, the lack of labeled databecomes the main obstacle (chen and qian, 2019).
to alleviate the data deﬁciency issue, unsuper-vised domain adaptation is proposed to transferknowledge from the labeled source domain to theunlabeled target domain.
since ate is a token-level task, it is natural to conduct token-level do-main adaptation.
then a problem arises: many.
*corresponding author..figure 1: the proportion of source aspect terms thatappear in target data.
r (restaurant), l (laptop), andd (device) are three datasets from different domains..aspect terms are domain-speciﬁc and cannot betransferred directly.
we present the proportion ofsource aspect terms that also appear in target testdata in figure 1. as can be seen, in distant trans-fer pairs like r→l, only less than 10% of sourceaspect terms have appeared in target data.
evenin a close pair l → d, the proportion is no morethan 40%.
in other words, there is a wide discrep-ancy between the data from different domains, andmany aspect terms have to be transferred under theguidance of proper references..to solve this problem, previous studies try toassociate aspect terms with speciﬁc pivot words1.
we name these methods passive domain adaptationbecause the transfer of aspect terms is dependenton their links to the pivots.
there are two types ofmethods along this line.
(1) opinion terms as piv-ots.
since aspect and opinion terms usually appearin pairs, it is straightforward to extract aspect termswith the indication from opinion terms.
early stud-ies (li et al., 2012; ding et al., 2017) use commonopinion seeds (e.g., good, fancy) and pre-deﬁnedrules (e.g., good→amod→nn) to extract aspectterms across domains.
however, it is hard to col-lect a complete set of seeds or deﬁne high-qualityrules, and thus these methods often produce inferiorperformance.
several studies (wang and pan, 2018,2019b) manually annotate all opinion terms in re-views and design neural models to capture aspect-opinion relations via multi-task learning.
while.
1pivot words are words which behave in the same way fordiscriminative learning in both domains (blitzer et al., 2006)..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages317–327august1–6,2021.©2021associationforcomputationallinguistics317(cid:28)(cid:17)(cid:20)(cid:27)(cid:26)(cid:17)(cid:22)(cid:20)(cid:28)(cid:17)(cid:20)(cid:26)(cid:25)(cid:17)(cid:20)(cid:24)(cid:22)(cid:21)(cid:17)(cid:22)(cid:19)(cid:21)(cid:28)(cid:17)(cid:20)(cid:26)(cid:19)(cid:21)(cid:19)(cid:23)(cid:19)(cid:31)(cid:314)(cid:25)(cid:25)(cid:314)(cid:31)(cid:31)(cid:314)(cid:17)(cid:17)(cid:314)(cid:31)(cid:25)(cid:314)(cid:17)(cid:17)(cid:314)(cid:25)(cid:51)(cid:72)(cid:85)(cid:70)(cid:72)(cid:81)(cid:87)(cid:68)(cid:74)(cid:72)(cid:55)(cid:85)(cid:68)(cid:81)(cid:86)(cid:73)(cid:72)(cid:85)(cid:3)(cid:51)(cid:68)(cid:76)(cid:85)(cid:31)(cid:3)(cid:29)(cid:3)(cid:53)(cid:72)(cid:86)(cid:87)(cid:68)(cid:88)(cid:85)(cid:68)(cid:81)(cid:87)(cid:3)(cid:3)(cid:25)(cid:3)(cid:29)(cid:3)(cid:47)(cid:68)(cid:83)(cid:87)(cid:82)(cid:83)(cid:3)(cid:3)(cid:17)(cid:3)(cid:29)(cid:3)(cid:39)(cid:72)(cid:89)(cid:76)(cid:70)(cid:72)getting improvements, these methods induce ad-ditional annotation costs.
(2) context terms aspivots.
since pre-trained language models (plms)like bert represent words w.r.t their contexts, re-cent studies (xu et al., 2019; gong et al., 2020)leverage plms to transfer aspect terms with com-mon context terms2.
however, not all context termsqualify as pivots (e.g., eat).
in addition, plms likebert build word associations mainly based onsemantic similarity in co-occurring contexts.
foran aspect term like pizza, bert tends to link it tohamburger via a ﬂow like pizza→eat→hamburger.
consequently, it is hard for these methods to iden-tify keyboard in the target domain based on thelabeled term pizza in the source domain..figure 2: illustration of syntactic and semantic bridges..in this paper, we propose a novel active domainadaptation method.
concretely, we construct twotypes of bridges for all words, which can help trans-fer aspect terms across domains.
an example infigure 2 shows how to identify the unseen targetterm keyboard based on the source term pizza.
(1)the syntactic bridge aims to recognize transfer-able syntactic roles for the words across domains.
though pizza and keyboard have almost no seman-tic relatedness, they often play a similar role inparse trees.
in view of this, we treat the involvedsyntactic roles (including pos tag and dependencyrelations) of a certain word as its syntactic bridge.
previous studies also utilize dependency informa-tion.
however, we differ our method from existingones in that we do not use dependency relations toassociate pivot words with aspect terms.
instead,we treat syntactic roles themselves as pivot fea-tures and do not need any manually annotated pivotwords.
(2) the semantic bridge moves one stepfurther by retrieving transferable prototypes.
intu-itively, if we correlate pizza with some prototypetarget terms like {disk, os, mouse}, the domain dis-crepancy between the training and testing reviewscan be largely reduced.
hence we regard the proto-.
2context terms denote all words that are not aspect terms..hence opinion terms form a subset of context terms..types of a certain word as its semantic bridge anddesign a syntax-enhanced similarity metric to re-trieve them.
compared with previous opinion andcontext term-based methods, building a semanticbridge directly links aspect terms across domainsand only requires unlabeled source and target data.
based on the syntactic/semantic bridges, we thendevelop an end-to-end tagger to fuse reviews withthese transferable bridges.
we conduct extensiveexperiments on three datasets.
the results showthat our method achieves a new state-of-the-artperformance with a low computational cost..2 related work.
aspect term extraction early researches forate mainly involve pre-deﬁned rules (hu and liu,2004; popescu and etzioni, 2005; wu et al., 2009;qiu et al., 2011) and hand-crafted features (li et al.,2010; liu et al., 2012, 2013; chen et al., 2014).
with the development of deep learning, supervisedsequence taggers have become the mainstream dueto their promising performance (liu et al., 2015;wang et al., 2016, 2017; xu et al., 2018; ma et al.,2019; chen and qian, 2020a).
more recently,there emerge many studies that interact ate withother tasks like aspect-level sentiment classiﬁca-tion (wang et al., 2018; he et al., 2019; chen andqian, 2020b).
since these methods highly dependon abundant domain-speciﬁc training data, theycan hardly scale across the domains where labeleddata is absent.
hence it would be more practical todevelop unsupervised domain adaptation methodsfor ate..domain adaptation many domain adaptationmethods have been proposed to solve coarse-grained tasks like text classiﬁcation (blitzer et al.,2006; ganin and lempitsky, 2015; guo et al.,2020).
the basic idea in coarse-grained tasks is totransfer pivot words, which does not ﬁt ate wellsince most aspect terms are domain-speciﬁc non-pivot words.
there have been a few attempts to thisproblem, which fall into two lines.
(1) one is tomodel aspect-opinion relations.
early researchesuse common opinion seeds and pre-deﬁned depen-dency link rules to build manual features (jakoband gurevych, 2010), conduct bootstrapping (liet al., 2012), and create pseudo target labels (dinget al., 2017).
due to the incompleteness of seedsand the inﬂexibility of rules, they often produceinferior performance.
subsequent studies (wangand pan, 2018, 2019a,b; li et al., 2019) manually.
318(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:55)(cid:75)(cid:72)(cid:3)(cid:83)(cid:76)(cid:93)(cid:93)(cid:68)(cid:3)(cid:75)(cid:72)(cid:85)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:68)(cid:79)(cid:86)(cid:82)(cid:3)(cid:68)(cid:69)(cid:86)(cid:82)(cid:79)(cid:88)(cid:87)(cid:72)(cid:79)(cid:92)(cid:3)(cid:71)(cid:72)(cid:79)(cid:76)(cid:70)(cid:76)(cid:82)(cid:88)(cid:86)(cid:17)(cid:55)(cid:75)(cid:72)(cid:3)(cid:78)(cid:72)(cid:92)(cid:69)(cid:82)(cid:68)(cid:85)(cid:71)(cid:3)(cid:76)(cid:86)(cid:3)(cid:76)(cid:81)(cid:3)(cid:85)(cid:72)(cid:68)(cid:86)(cid:82)(cid:81)(cid:68)(cid:69)(cid:79)(cid:72)(cid:3)(cid:86)(cid:76)(cid:93)(cid:72)(cid:17)(cid:83)(cid:76)(cid:93)(cid:93)(cid:68)(cid:78)(cid:72)(cid:92)(cid:69)(cid:82)(cid:68)(cid:85)(cid:71)(cid:3)(cid:658)(cid:68)(cid:3)(cid:81)(cid:82)(cid:88)(cid:81)(cid:659)(cid:87)(cid:75)(cid:72)(cid:3)(cid:87)(cid:68)(cid:85)(cid:74)(cid:72)(cid:87)(cid:3)(cid:82)(cid:73)(cid:3)(cid:68)(cid:3)(cid:71)(cid:72)(cid:87)(cid:72)(cid:85)(cid:80)(cid:76)(cid:81)(cid:72)(cid:85)(cid:660)(cid:87)(cid:75)(cid:72)(cid:3)(cid:86)(cid:88)(cid:69)(cid:77)(cid:72)(cid:70)(cid:87)(cid:3)(cid:82)(cid:73)(cid:3)(cid:68)(cid:81)(cid:3)(cid:68)(cid:71)(cid:77)(cid:72)(cid:70)(cid:87)(cid:76)(cid:89)(cid:72)(cid:658)(cid:55)(cid:75)(cid:72)(cid:3)(cid:71)(cid:76)(cid:86)(cid:78)(cid:3)(cid:75)(cid:72)(cid:85)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:68)(cid:79)(cid:86)(cid:82)(cid:3)(cid:68)(cid:69)(cid:86)(cid:82)(cid:79)(cid:88)(cid:87)(cid:72)(cid:79)(cid:92)(cid:3)(cid:69)(cid:76)(cid:74)(cid:17)(cid:659)(cid:55)(cid:75)(cid:72)(cid:3)(cid:50)(cid:54)(cid:3)(cid:75)(cid:72)(cid:85)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:68)(cid:79)(cid:86)(cid:82)(cid:3)(cid:68)(cid:69)(cid:86)(cid:82)(cid:79)(cid:88)(cid:87)(cid:72)(cid:79)(cid:92)(cid:3)(cid:73)(cid:68)(cid:86)(cid:87)(cid:17)(cid:660)(cid:55)(cid:75)(cid:72)(cid:3)(cid:80)(cid:82)(cid:88)(cid:86)(cid:72)(cid:3)(cid:75)(cid:72)(cid:85)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:68)(cid:79)(cid:86)(cid:82)(cid:3)(cid:68)(cid:69)(cid:86)(cid:82)(cid:79)(cid:88)(cid:87)(cid:72)(cid:79)(cid:92)(cid:3)(cid:87)(cid:76)(cid:81)(cid:92)(cid:17)(cid:54)(cid:92)(cid:81)(cid:87)(cid:68)(cid:70)(cid:87)(cid:76)(cid:70)(cid:3)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:54)(cid:72)(cid:80)(cid:68)(cid:81)(cid:87)(cid:76)(cid:70)(cid:3)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:76)(cid:71)(cid:72)(cid:81)(cid:87)(cid:76)(cid:73)(cid:92)(cid:85)(cid:72)(cid:87)(cid:85)(cid:76)(cid:72)(cid:89)(cid:72)(cid:76)(cid:71)(cid:72)(cid:81)(cid:87)(cid:76)(cid:73)(cid:92)(cid:54)(cid:82)(cid:88)(cid:85)(cid:70)(cid:72)(cid:3)(cid:53)(cid:72)(cid:89)(cid:76)(cid:72)(cid:90)(cid:3)(cid:11)(cid:31)(cid:12)(cid:55)(cid:68)(cid:85)(cid:74)(cid:72)(cid:87)(cid:3)(cid:53)(cid:72)(cid:89)(cid:76)(cid:72)(cid:90)(cid:3)(cid:11)(cid:25)(cid:12)(cid:85)(cid:72)(cid:70)(cid:82)(cid:74)(cid:81)(cid:76)(cid:93)(cid:72)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)annotate all opinion terms in reviews and designtrainable neural models to capture the relations viamulti-task learning.
however, they induce extraannotation costs.
(2) the other aims to ﬁnd aspect-context relations.
xu et al.
(2019) post-trains berton the cross-domain corpus to enhance its domainadaptation ability.
gong et al.
(2020) and pereget al.
(2020) further incorporate external syntacticinformation into bert with auxiliary tasks or mod-iﬁed attention mechanisms, but they still rely onthe prior knowledge in bert.
these methods oftenhave more than 100m parameters and involve lotsof computing power.
unlike all the aforementionedmethods, we do not associate aspect terms withpivot words but actively transfer them via bridges..3 methodology.
in this section, we ﬁrst introduce the cross-domainate task.
we then illustrate how to construct syn-tactic and semantic bridges.
lastly, we present thebridge-based sequence tagging..3.1 problem statement.
given a review x = {x1, ..., xn}, we formulateate as a sequence tagging task that aims to predicta tag sequence y = {y1, ..., yn}, where each yi ∈{b, i, o} denotes the beginning of, inside of, andoutside of an aspect term.
in this paper, we focuson the unsupervised domain adaptation for ate,i.e., labeled training data is not available in thetarget domain.
speciﬁcally, given a set of labeleddata ds = {(xsj=1 from the source domainand a set of unlabeled data du = {(xuj=1 fromthe target domain, our goal is to predict labels ytj )}ntfor the unseen target test data dt = {(xtj=1..j )}nu.
j )}ns.
j , ys.
3.2 bridge construction.
given a review sentence x from either domain,we map it with a lookup table e ∈ rde×|v |, andgenerate word embeddings e = {e1, ..., en} ∈rde×n, where |v | is the vocabulary size, and de isthe embedding dimension.
for cross-domain ate,we construct bridges for reviews to help directlytransfer aspect terms across two domains..syntactic bridgein natural language, linguis-tic expressions are rich and ﬂexible.
in contrast,the syntactic structures are limited and are generalacross domains.
based on this observation, wepropose to build connections between source andtarget words based on their syntactic roles (pos.
several prior studies.
tags and dependency relations) rather than the lexi-cal items.
for example, from the parsing results inthe upper part of figure 3, the word pizza with apos tag nn and dependency relations {det, nsubj}might be an aspect term, while those with the rbtag and advmod relation might not.
note the sen-tence “the keyboard is in reasonable size.” in thetarget domain has similar parsing results.
hencethe syntactic roles can serve as supplementary evi-dence for recognizing aspect terms across domains.
(wang and pan, 2018,2019b; pereg et al., 2020) also make use of pars-ing results.
however, they only use dependencyrelations to link words or to propagate word rep-resentations.
for example, given a dependencynsubj−→ pizza in ds, where great is a knowngreatpivot and pizza is an aspect term, the goal is toextract keyboard as an aspect from the target re-view “the keyboard is great” in dt .
the typicalsyntax based method hier-joint (ding et al., 2017)ﬁrst locates the pivot great, then utilizes the nsubjdependency to identify the term keyboard.
othermethods like rnscn (wang and pan, 2018) com-bine the embedding of the child node (pizza) withthat of the parent node (great) according to the re-lation type, or reversely (depending on the speciﬁcdesign).
it can be seen that the dependency relationnsubj here is only used as a link to the pivot..figure 3: construction of the syntactic bridge.
if a postag or dependency relation is involved, its correspond-ing entry in the vector is set to 1, and otherwise 0..we start in the opposite direction, i.e., we aim tofully exploit syntactic roles by recognizing them-selves as pivots instead of treating them as linksto pivots.
to achieve this, we present a novel datastructure to encode the pos and dependency in-formation by grounding them into involved words.
as shown in the lower part of figure 3, for a wordxi, we use a one-hot vector bpos ∈ rnpos anda multi-hot vector bdep ∈ rndep to represent itspos tag and dependency relation(s), where nposand ndep are the number of tag/relation types.
for.
319(cid:50)(cid:81)(cid:72)(cid:16)(cid:75)(cid:82)(cid:87)(cid:3)(cid:51)(cid:50)(cid:54)(cid:3)(cid:57)(cid:72)(cid:70)(cid:87)(cid:82)(cid:85)(cid:48)(cid:88)(cid:79)(cid:87)(cid:76)(cid:16)(cid:75)(cid:82)(cid:87)(cid:3)(cid:39)(cid:72)(cid:83)(cid:72)(cid:81)(cid:71)(cid:72)(cid:81)(cid:70)(cid:92)(cid:3)(cid:57)(cid:72)(cid:70)(cid:87)(cid:82)(cid:85)(cid:39)(cid:55)(cid:49)(cid:49)(cid:53)(cid:37)(cid:57)(cid:37)(cid:61)(cid:45)(cid:45)(cid:17)(cid:71)(cid:72)(cid:87)(cid:68)(cid:71)(cid:89)(cid:80)(cid:82)(cid:71)(cid:81)(cid:86)(cid:88)(cid:69)(cid:77)(cid:70)(cid:82)(cid:83)(cid:85)(cid:82)(cid:82)(cid:87)(cid:83)(cid:88)(cid:81)(cid:70)(cid:87)(cid:3)(cid:3)(cid:3)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:3)(cid:3)(cid:83)(cid:76)(cid:93)(cid:93)(cid:68)(cid:3)(cid:3)(cid:3)(cid:75)(cid:72)(cid:85)(cid:72)(cid:3)(cid:3)(cid:3)(cid:3)(cid:76)(cid:86)(cid:3)(cid:3)(cid:3)(cid:3)(cid:68)(cid:79)(cid:86)(cid:82)(cid:3)(cid:3)(cid:68)(cid:69)(cid:86)(cid:82)(cid:79)(cid:88)(cid:87)(cid:72)(cid:79)(cid:92)(cid:3)(cid:71)(cid:72)(cid:79)(cid:76)(cid:70)(cid:76)(cid:82)(cid:88)(cid:86)(cid:3)(cid:3)(cid:3)(cid:17)(cid:39)(cid:55)(cid:49)(cid:49)(cid:53)(cid:37)(cid:57)(cid:37)(cid:61)(cid:53)(cid:37)(cid:53)(cid:37)(cid:45)(cid:45)(cid:17)(cid:282)(cid:286)(cid:410)(cid:258)(cid:282)(cid:448)(cid:373)(cid:381)(cid:282)(cid:374)(cid:400)(cid:437)(cid:271)(cid:361)(cid:393)(cid:437)(cid:374)(cid:272)(cid:410)(cid:258)(cid:282)(cid:448)(cid:373)(cid:381)(cid:282)(cid:258)(cid:282)(cid:448)(cid:373)(cid:381)(cid:282)(cid:272)(cid:381)(cid:393)(cid:54)(cid:92)(cid:81)(cid:87)(cid:68)(cid:70)(cid:87)(cid:76)(cid:70)(cid:3)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:54)(cid:42)(cid:54)(cid:42)(cid:42)(cid:42)(cid:54)(cid:42)(cid:54)(cid:42)(cid:54)(cid:54)(cid:54)(cid:54)(cid:42)(cid:42)(cid:42)(cid:42)(cid:42)(cid:42)(cid:42)(cid:42)(cid:54)(cid:42)bdep, we merge all relations involved with xi re-gardless of the direction (i.e., being the governoror dependent)3..to enlarge the learning capability, we projectbpos and bdep to the same dimensionality withlearnable weight matrices4 and concatenate themto form the syntactic bridge bsyn:.
bsyn = (wpos × bpos) ⊕ (wdep × bdep),(1)where bsyn ∈ rde has the same dimensionalitywith the word embedding e. in training, wpos andwdep get trained by labeled samples.
in testing, weﬁx them and obtain bsyn for dt .
by doing this,our proposed method well preserves two types ofsyntactic information throughout the entire learningprocess.
as a result, we can take full advantage oftheir transferable information..semantic bridge the semantic bridge takes thesyntactic roles above as a basis but moves onestep further to retrieve transferable prototypes.
un-like previous passive methods that construct in-formation ﬂows like pizza→good→keyboard viaopinion terms or pizza→offer→keyboard via con-text terms, we aim to construct a direct ﬂow likepizza→keyboard.
for example, to transfer knowl-edge from pizza in ds to keyboard in dt , we aimto introduce some supplementary target terms like{disk, os, mouse} in du for pizza and directlyimprove its semantic relatedness with keyboard.
we call these supplementary terms prototypes andwill retrieve them to build the semantic bridges5.
plms like bert can ﬁnd a set of semanticallysimilar terms like {hamburger, salad} for pizza,which can also serve as prototypes.
however, suchprototypes are not suitable for the domain adapta-tion task, because aspect terms in one domain areoften far away from those in another domain in thesemantic space.
to address this problem, we de-sign a syntax-enhanced similarity metric to retrievetransferable semantic prototypes..before starting, we ﬁlter the words in du byfrequency and only preserve those appearing morethan τ times.
we regard these words in unlabeledtarget data as candidate prototypes and build a pro-totype bank (cid:101)v from du accordingly.
we then con-duct retrieval following the procedure in figure 4.for a query word v ∈ v s (vocabulary of ds),.
3this simpliﬁcation almost has no side effects.
if a word.
has a nn tag and det relation, it must be the governer..4in all equations, w denotes a trainable weight matrix.
5we retrieve prototypes for all words in the review due to.
the existence of domain-speciﬁc context terms like eat..figure 4: construction of the semantic bridge.
for aquery word, the top-k prototypes are retrieved from theprototype bank and aggregated to its semantic bridge..we want to ﬁnd a prototype term (cid:101)v ∈ (cid:101)v that play asimilar syntactic role in the target domain.
speciﬁ-cally, we ﬁrst summarize the global usages of v bymerging its pos and dependency embeddings inall reviews where v appear in ds:.
(2).
pos, (cid:101)bg.
dep, (cid:101)bg.
pos and (cid:101)bg.
bgpos = {bpos,j=1 | bpos,j=2 |...| bpos,j=ns },bgdep = {bdep,j=1 | bdep,j=2 |...| bdep,j=ns },where | is the dimension-wise or operation andns is the number of reviews in ds.
similarly, wecan obtain (cid:101)bgdep for (cid:101)v. we then deﬁne thesyntax-enhanced similarity between v and (cid:101)v:s.sim(v, (cid:101)v) = c(bgpos) × c(bgdep) × c(e, (cid:101)e), (3)where e and (cid:101)e are word embeddings and c(·, ·) isthe cosine similarity.
here the pos and depen-dency similarities are used to ﬁnd similar syntacticroles, while the word similarity is used to reducethe noise of prototypes6.
consequently, we canobtain a s.sim score matrix ms∈r|v s |×| (cid:101)v |.
afterranking, for v, we select the top-k words { (cid:101)vk}kk=1with their s.sim scores { (cid:101)sk}kk=1 from the proto-type bank.
lastly, we aggregate these prototypesinto the semantic bridge bsem of v:.
bsem =.
(cid:101)sk · (cid:101)ek..k(cid:88).
k=1.
(4).
following the way for ds, we also retrievetransferable prototypes for du and dt using (cid:101)v .
in this way, source and target words with thesame prototypes can be directly correlated to eachother.
for du , we can generate a score matrixmu ∈ r|v u |×| (cid:101)v | by calculating the s.sim for allwords in du and all candidate prototypes in (cid:101)v .
then we can obtain the semantic bridge bsem foreach word in du in training.
in testing, dt isunseen and the global bgdep are not available.
therefore, for a word w in dt , we obtain bsemusing mu if w has appeared in du .
otherwise, wetemporarily use the local bpos/bdep of w in currenttesing sample to replace the global bgdep andcalculate the s.sim..pos/bg.
pos/bg.
6a domain-invariant word that appears frequently in bothdomains should preserve its own information.
it will have amaximum similarity score with itself since c(e, (cid:101)e) = 1..320(cid:85)(cid:72)(cid:87)(cid:85)(cid:76)(cid:72)(cid:89)(cid:72)(cid:87)(cid:82)(cid:83)(cid:16)(cid:46)(cid:68)(cid:74)(cid:74)(cid:85)(cid:72)(cid:74)(cid:68)(cid:87)(cid:72)(cid:51)(cid:85)(cid:82)(cid:87)(cid:82)(cid:87)(cid:92)(cid:83)(cid:72)(cid:37)(cid:68)(cid:81)(cid:78)(cid:52)(cid:88)(cid:72)(cid:85)(cid:92)(cid:58)(cid:82)(cid:85)(cid:71)(cid:53)(cid:72)(cid:87)(cid:85)(cid:76)(cid:72)(cid:89)(cid:72)(cid:71)(cid:51)(cid:85)(cid:82)(cid:87)(cid:82)(cid:87)(cid:92)(cid:83)(cid:72)(cid:86)(cid:54)(cid:72)(cid:80)(cid:68)(cid:81)(cid:87)(cid:76)(cid:70)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)3.3 bridge-based sequence tagging.
based on the syntactic and semantic bridges, wenow propose a lightweight end-to-end sequencetagger for aspect term extraction.
as shown infigure 5, the tagger receives a mixture of ds anddu for training and then makes predictions for dtin testing.
we then illustrate the details..figure 5: training of bridge-based sequence tagging..bridge fuser our constructed bridges have twoproperties.
(1) bridges are domain-invariant andshould be preserved.
(2) bridges can help extractdomain-invariant information from ei.
therefore,we propose to enhance the embedding ei of a wordxi with its transferable bridges bsyn,i and bsem,i.
speciﬁcally, we use a gating operation to fusebridges.
take the syntactic bridge as an example,we ﬁrst calculate a dimension-wise gate gsyn,i:.
gsyn,i = σ (wsyn(ei ⊕ bsyn,i)),(5)where wsyn ∈ r2de×2de, σ is the sigmoid func-tion, ⊕ is concatenation.
we then scale the con-catenated vector ei ⊕ bsyn,i with gsyn,i and obtainthe syntactic bridge enhanced embedding esyn,i:esyn,i = gsyn,i (cid:12) (ei ⊕ bsyn,i),.
(6).
where (cid:12) is an element-wise multiplication.
thesemantic bridge enhanced embedding esem,i canbe calculated similarly.
we term the model withei, esyn,i, and esem,i input as basetagger, syn-bridge, and sembridge, respectively.
three typesof embeddings are collectively called einput,i ..feature extractor previous studies (xu et al.,2018) show that low-level token features are insuf-ﬁcient for tagging terms.
therefore, we use a cnnencoder containing l stacked convolutional lay-ers with relu activation to extract the high-levelfeatures fi ∈ rdf :f l+1i = relu (f l.i−c:i+c ∗ kl + bl), f 0(7)where k ∈ rdf ×(dinput×ks) is the kernel group,ks = 2c + 1 is the kernel size..i = einput,i,.
token classiﬁer for recognizing aspect andopinion terms, we send f lin the last layer to aitoken classiﬁer:.
ˆyi = sof tmax(wa × f l.i ),.
(8).
domain classiﬁer besides bio tagging, wefurther enhance the domain-invariance of bridge-based features via domain adversarial training.
speciﬁcally, we ﬁrst aggregate f lto a global rep-iresentation fg:.
1:n)..fg = m axp ool(f l.(9)then we add a gradient reversal layer (grl)(ganin and lempitsky, 2015) to fg with the scalecoefﬁcient λ and train a domain classiﬁer to distin-guish the domain that fg belongs to:.
ˆyd = sof tmax(wo × mlp (grlλ(fg))),.
(10)where ˆyd is the domain prediction, and m lp con-tains ld layers with relu activation..training procedurein training, only samplesfrom ds have corresponding bio labels ys fortoken classiﬁcation.
the goal is to minimize thetagging loss for recognizing aspect terms:.
lbio = −.
(cid:96)(ˆyi, yi),.
(11).
(cid:88).
n(cid:88).
ds.
i=1.
where (cid:96) is the cross-entropy loss function.
on theother hand, the samples from ds and du are usedto train the domain classiﬁer and minimize the fol-lowing domain classiﬁcation loss:ldom = −.
(cid:96)(ˆyd, yd),.
(12).
(cid:88).
ds ∪duwhere yd = 0 for ds and yd = 1 for du .
the ﬁnalloss for training the end-to-end tagger is deﬁned asl = lbio + ldom .
notice that dt is only usedin testing.
there is no data leakage in training, andthe task setting is strictly inductive..4 experiment.
4.1 experimental setup.
datasets we use three conventional englishdatasets from different domains and construct sixdirected transfer pairs, where r and l are from se-meval 2014 and 2015 (pontiki et al., 2014, 2015),and d is collected by hu and liu (2004).
follow-ing previous studies (wang and pan, 2018, 2019b;pereg et al., 2020), we use three different splits andeach split has a ﬁxed train-test ratio 3:1. the de-tailed statistics of datasets are presented in table 17..table 1: the statistics of datasets..datasetrld.domainrestaurantlaptopdevice.
total584138453836.train438128842877.test1460961959.where ˆyi is the prediction of the word xi..nlpwm-whu/bridge..7our code and data are available at https://github.com/.
321(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:41)(cid:88)(cid:86)(cid:72)(cid:85)(cid:41)(cid:72)(cid:68)(cid:87)(cid:88)(cid:85)(cid:72)(cid:40)(cid:91)(cid:87)(cid:85)(cid:68)(cid:70)(cid:87)(cid:82)(cid:85)(cid:55)(cid:82)(cid:78)(cid:72)(cid:81)(cid:38)(cid:79)(cid:68)(cid:86)(cid:86)(cid:76)(cid:73)(cid:76)(cid:72)(cid:85)(cid:37)(cid:44)(cid:50)(cid:47)(cid:82)(cid:86)(cid:86)(cid:54)(cid:82)(cid:88)(cid:85)(cid:70)(cid:72)(cid:53)(cid:72)(cid:89)(cid:76)(cid:72)(cid:90)(cid:54)(cid:82)(cid:88)(cid:85)(cid:70)(cid:72)(cid:40)(cid:80)(cid:69)(cid:72)(cid:71)(cid:71)(cid:76)(cid:81)(cid:74)(cid:54)(cid:82)(cid:88)(cid:85)(cid:70)(cid:72)(cid:41)(cid:72)(cid:68)(cid:87)(cid:88)(cid:85)(cid:72)(cid:55)(cid:68)(cid:85)(cid:74)(cid:72)(cid:87)(cid:53)(cid:72)(cid:89)(cid:76)(cid:72)(cid:90)(cid:55)(cid:68)(cid:85)(cid:74)(cid:72)(cid:87)(cid:40)(cid:80)(cid:69)(cid:72)(cid:71)(cid:71)(cid:76)(cid:81)(cid:74)(cid:55)(cid:68)(cid:85)(cid:74)(cid:72)(cid:87)(cid:41)(cid:72)(cid:68)(cid:87)(cid:88)(cid:85)(cid:72)(cid:39)(cid:50)(cid:48)(cid:47)(cid:82)(cid:86)(cid:86)(cid:54)(cid:92)(cid:81)(cid:87)(cid:68)(cid:70)(cid:87)(cid:76)(cid:70)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:54)(cid:72)(cid:80)(cid:68)(cid:81)(cid:87)(cid:76)(cid:70)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:39)(cid:82)(cid:80)(cid:68)(cid:76)(cid:81)(cid:38)(cid:79)(cid:68)(cid:86)(cid:86)(cid:76)(cid:73)(cid:76)(cid:72)(cid:85)(cid:42)(cid:53)(cid:47)i.type.
modeltcrfrapsal.
table 2: comparison of different methods.
baselines with (cid:52) use annotated opinion terms.
the best scores are inbold and the second best ones are underlined.
averaged results with † and ‡ are signiﬁcantly better than bert-cross and basetagger (p < 0.05) based on one-tailed unpaired t-test, respectively.
the upper bounds of threedatasets (achieved by basetagger trained on in-domain labeled data) are 76.43 (r), 75.60 (l), and 57.10 (d).
avg.
21.6333.9436.9038.1544.7345.8846.3639.7347.0047.8748.1750.70†52.50†‡53.38†‡.
embeddingmanualmanualword2vechier-joint word2vecrnscn(cid:52) word2vectrnn(cid:52)word2vectimn(cid:52)word2vecbertbert-basebertudasa-exal(cid:52)bertbertbert-crossbasetagger word2vecsynbridge word2vecsembridge word2vec.
r→d21.0722.6322.8233.2035.1037.3335.4535.3040.0440.5043.6840.5642.7643.03.d→r6.5945.4438.8947.9748.3651.1753.8236.8653.3954.5453.1557.6759.4060.61.l→r28.1946.9044.5748.1052.9153.7854.1242.7450.5254.6751.6061.4263.9065.96.r→l19.7225.9229.0333.6640.4340.1543.6833.8944.2447.5946.3048.8651.5351.53.l→d29.9634.5438.8231.2540.4241.1938.6343.5441.4842.1944.2243.7544.9745.37.d→l24.2228.2247.2534.7451.1451.6652.4646.0652.3347.7250.0451.9552.4453.77.iii.
ii.
settings we pre-process each dataset by lowercas-ing all words.
we use the same word2vec vectorsas previous studies (wang and pan, 2018, 2019a,b)to generate word embeddings, and set the dimen-sionality de=100.
in the syntactic bridge, we usestanford corenlp (manning et al., 2014) for de-pendency parsing.
there are 45 classes of pos tagsand 40 classes of dependency relations in threedatasets.
in the semantic bridge, we set the fre-quency threshold τ =5, the number of prototypesk=10.
in the end-to-end tagger, we set the numberof convolution layers l=4, and the kernel size ksof each layer is 3, 5, 5, 5, respectively, the num-ber of mlp layers ld=3, and dropout (srivastavaet al., 2014) is applied to layers’ outputs with theprobability 0.5. the dimensionality of featuresdf =256, the scale coefﬁcient of grl λ=0.1.
wetrain the tagger for 100 epochs using adam opti-mizer (kingma and ba, 2015) with the learningrate 1e-4 and batch size 8 in a 1080ti gpu.
evaluation for each transfer pair, we use the la-beled training data from the source domain andunlabeled training data from the target domain totrain the tagger.
then we evaluate the tagger onunseen test data from the target domain.
we use themean f1-scores of aspect terms over three splitswith three random seeds (i.e., nine runs for eachtransfer pair) for evaluation8..4.2 compared methods.
we classify all models into three categories.
type-i denotes the opinion term-based methods.
tcrf (jakob and gurevych, 2010), rap (li et al.,2012), and hier-joint (ding et al., 2017) use man-ually deﬁned dependency rules.
rnscn and.
8the hyperparameter ranges are presented in appendix a..trnn (wang and pan, 2018, 2019a) model de-pendency trees with trainable recursive networks.
sal (li et al., 2019) and timn (wang and pan,2019b) replace the dependency tree with trainablememory interaction.
type-iidenotes context term-based methods.
bert-base uses vanilla base bert (devlin et al.,2019) for ate.
bert-cross (xu et al., 2019) post-trains bert on a combination of yelp and amazoncorpus.
uda (gong et al., 2020) and sa-exal(pereg et al., 2020) incorporate syntactic informa-tion into bert with auxiliary tasks and modiﬁedattention mechanisms9.
type-iii denotes the proposed active domain adap-tation strategy.
basetagger is the tagger withoutbridges, while synbridge and sembridge use syn-tactic and semantic bridges, respectively..4.3 main results.
the comparison results for all methods are shownin table 2.it is clear that our proposed modelachieves a new state-of-the-art performance interms of the average f1-scores.
for example, sem-bridge outperforms the best timn in type-i by7.02% and bert-cross in type-ii by 5.21%, re-spectively.
we also notice that our basetaggeralready outperforms all baselines.
we attribute thisto the design of cnn feature extractor and domainadversarial training (dat).
cnn focuses on the n-gram feature rather than a single word and reducesthe side effects of non-pivot aspect terms.
datis applied to the sentence-level features, such thatthey are not misled by the common n-grams thatare labeled both 0 and 1..9since sal and uda use extra aspect sentiment labels,we show how to make them fair competitors in appendix b..322synbridge and sembridge further improve base-tagger with a 1.80% and 2.68% absolute gain, re-spectively.
this proves the effectiveness of ourproposed active domain adaptation strategy.
mean-while, sembridge is a bit superior to synbridge.
the reasons are two-fold.
(1) the semantic bridgescome from prototype words that possess prior em-bedding knowledge and also contain syntactic in-formation, while the syntactic bridges are merelytrained from scratch.
(2) the retrieved top-k termsmake the supplementary information in sembridgemore diverse and abundant than that in synbridge.
among the baselines, early methods using com-mon opinion seeds and pre-deﬁned rules are in-ferior.
relying on annotated opinion terms, themethods like timn get some improvements butinduce extra annotation costs.
by incorporatingpre-trained bert with external dependency andcross-domain corpus, uda, sa-exal, and bert-cross outperform previous methods, but they needhigh computational resources.
in contrast, by usingthe static word2vec embeddings, our model canoutperform those with dynamic bert representa-tions.
this is instructive for other researches inthat there is still room for improvement by explor-ing the syntactic and semantic features beyond thepopular bert-based models10..5 analysis.
5.1 what if there is an ote task?.
with the proposed active domain adaptation strat-egy, we do not need any manually labeled opinionterms for ate.
however, this does not mean thatour method cannot handle opinion term extraction(i.e., ote).
in contrast, if the labeled opinion termsare provided in ds, we can also conduct the otetask for dt by simply modifying the tagger.
inspeciﬁc, we add an opinion term prediction layerin eq.8 and then extract aspect and opinion termssimultaneously.
the results are shown in table 3.obviously, our method again outperforms allbaselines11.
we ﬁnd a small performance decreasein avg-as compared with that in table 2. similarresults are also observed in bert-base.
the reasonis that the objective of ate and ote may interferewith each other without proper balancing and asophisticated multi-task learning framework..10we also make some explorations about combining syn-.
bridge and sembridge, please refer to appendix c..11please refer to appendix d for detailed results for all.
transfer pairs..table 3: comparison of different methods.
avg-asand avg-op are f1-scores for ate and ote averagedon all transfer pairs..modelrnscntrnn-grutimnbert-basesa-exalbert-crossbasetaggersynbridgesembridge.
avg-as44.7345.8846.3639.5247.8748.3550.1251.8652.53.avg-op67.4467.1268.2166.2269.1569.4771.7371.7372.08.
5.2 ablation study.
we conduct a series of ablation study to validatethe effectiveness of our method.
the results areshown in table 4..table 4: ablation study.
the scores denote the decreaseof performance after removing(−) or replacing(→) aspeciﬁc component.
index model.
variant.
123456789.basetagger.
synbridge.
sembridge.
− ldomcnn→bilstm− bpos− bdepbdep→tree-lstmbdep→gcn− c(e, (cid:101)e)− c(bpos, (cid:101)bpos)− c(bdep, (cid:101)bdep).
avg.
1.948.471.681.493.974.211.822.302.52.results 1∼2 conform to our previous discussionabout basetagger that both cnn and domain ad-versarial training contribute to overall good perfor-mance.
results 3∼6 show the effectiveness of posand dependency embeddings in synbridge.
specif-ically, in 5∼6, we replace our proposed structurefor dependency with frequently-used tree-lstmand gcn to model the dependency tree and ﬁnd asigniﬁcant drop in performance.
results 7∼9 showthe importance of all three types of similarity forretrieving prototypes in sembridge..5.3 parameter study.
there are three key hyperparameters in our method:the scale coefﬁcient of grl λ, the frequencythreshold τ , and the number of prototypes k. wevary λ in the range 10−4 ∼ 1.0 and τ /k in 1 ∼ 10to investigate their impacts and present the resultsin figure 6..in figure 6(a), when increasing λ from 10−4 to10−1, we enlarge the scale of domain adversarialtraining in grl and get small improvements.
how-ever, the performance does not keep rising when.
323table 5: case study.
the left columns present the selected target testing examples, and the words in red are aspectterms.
the right columns denote the extraction results of corresponding models..pair example.
r→ls1..l→rs2..it has usb ports, 1 sd memory card readerand an sd memory car expansion.
the asparagus, trufﬂe oil, parmesan bruschettais a winner!.
l→rs3.they showed up 15 minutes after the tuna melt.tuna melt (cid:55).
rnscn.
none (cid:55).
none (cid:55).
bert-crosscard reader,(cid:55)sd memory car expansionasparagus,bruschettanone (cid:55).
(cid:55).
synbridgeusb ports, sd memory card reader,sd memory car expansionasparagus,trufﬂe oilparmesan bruschettatuna melt (cid:55).
sembridgeusb ports, sd memory card reader,sd memory car expansionasparagus,trufﬂe oilparmesan bruschettatuna.
resist parsing errors for two reasons.
first, beyondsyntactic roles, we also incorporate embedding sim-ilarity when retrieving prototypes (for sembridgeonly).
second, the gating mechanism can furtherﬁlter useless syntactic information and maintainthe quality of word representations..to have a close look, we select a few samples fromtesting target data for a case study.
s1 and s2 showthe positive impacts of bridges.
due to the spacelimit, we illustrate s1 in detail.
since most wordsin s1 are domain-speciﬁc terms in l, rnscn failsto recognize any aspect terms by simply propagat-ing word representations with dependency.
bert-cross only extracts a part of aspect terms based onits prior knowledge.
for our bridge-based method,synbridge supplements syntactic roles {nummod,compound, obj, conj, nns} for port.
these syntac-tic roles also join the representation of usb and helpto extract usb ports correctly.
for sembridge, theanalysis is much straightforward.
usb is the proto-type of typical aspect terms in r like {garlic, thai,banana}, thus the tagger with semantic bridges caneasily recognize usb as an aspect term..s3 further illustrates how sembridge helps re-cover from the wrong parsing results.
such resultsmake two syntax based methods rnscn and syn-bridge stop working.
in contrast, tuna is the pro-totype of noun words like {nvidia, amd, blade} inl and melt has the verb prototype like {imagine,hang, relax} in r, thus sembridge correctly ex-tracts tuna and ﬁlters out melt in the same time..in table 6, we further present several sampleprototypes of the training data from the transferpairs r→l (upper three) and l→r (lower three)in sembridge, where three terms on the left areaspect term, opinion term, and context term, re-spectively.
for a source non-pivot term like pro-cessor in l, sembridge enhances it with typicaltarget words like soup and burger.
as a result, thedomain discrepancy between the source and targetdata is largely reduced with the help of prototypes..(a) impact of λ..(b) impact of τ /k..figure 6: impacts of hyperparameters λ, τ , and k..5.4 case study.
λ = 1.0. this result shows that simply forcingnon-pivots to transfer knowledge is not suitable fordomain adaptation.
in figure 6(b), τ is used tobalance diversity and accuracy.
a low τ meansthat prototypes are diverse, but some of them arelong-tail words and contribute little to the reduc-tion of domain discrepancy.
on the contrary, a highτ only preserves frequent prototypes, and somemeaningful prototypes are ﬁltered out.
therefore,a middle τ =5 is an appropriate choice.
for k, thecurve is generally upward when more prototypesare introduced.
this trend is reasonable since moreprototypes equal to more target information..(a) impact of pu ..(b) impact of pn ..figure 7: impacts of pu and pn ..in figure 7, we further analyze the impacts of thepercentage of unlabeled data pu and the percent-age of parsing noise pn .
for pu , the performanceis generally better when more unlabeled target datais introduced.
moreover, around 20%∼40% unla-beled data is enough to achieve satisfactory perfor-mance.
notice that sembridge without unlabeleddata will degenerate into basetagger since no pro-totypes can be retrieved.
for pn , we manually dis-turb the parsing results to observe the robustnessof our method.
clearly, after introducing noises onparsing, the performance begins to degrade, but notby a large margin.
our method has the ability to.
324(cid:24)(cid:21)(cid:17)(cid:19)(cid:3)(cid:24)(cid:21)(cid:17)(cid:24)(cid:3)(cid:24)(cid:22)(cid:17)(cid:19)(cid:3)(cid:24)(cid:22)(cid:17)(cid:24)(cid:3)(cid:16)(cid:23)(cid:16)(cid:22)(cid:16)(cid:21)(cid:16)(cid:20)(cid:19)(cid:41)(cid:20)(cid:79)(cid:74)(cid:540)(cid:54)(cid:92)(cid:81)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:54)(cid:72)(cid:80)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:24)(cid:19)(cid:17)(cid:19)(cid:3)(cid:24)(cid:20)(cid:17)(cid:19)(cid:3)(cid:24)(cid:21)(cid:17)(cid:19)(cid:3)(cid:24)(cid:22)(cid:17)(cid:19)(cid:3)(cid:24)(cid:23)(cid:17)(cid:19)(cid:3)(cid:20)(cid:21)(cid:22)(cid:23)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:20)(cid:19)(cid:41)(cid:20)(cid:306)(cid:18)(cid:46)(cid:306)(cid:46)(cid:23)(cid:28)(cid:17)(cid:19)(cid:3)(cid:24)(cid:19)(cid:17)(cid:19)(cid:3)(cid:24)(cid:20)(cid:17)(cid:19)(cid:3)(cid:24)(cid:21)(cid:17)(cid:19)(cid:3)(cid:24)(cid:22)(cid:17)(cid:19)(cid:3)(cid:24)(cid:23)(cid:17)(cid:19)(cid:3)(cid:19)(cid:21)(cid:19)(cid:23)(cid:19)(cid:25)(cid:19)(cid:27)(cid:19)(cid:20)(cid:19)(cid:19)(cid:41)(cid:20)(cid:51)(cid:56)(cid:54)(cid:92)(cid:81)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:54)(cid:72)(cid:80)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:23)(cid:28)(cid:17)(cid:19)(cid:3)(cid:24)(cid:19)(cid:17)(cid:19)(cid:3)(cid:24)(cid:20)(cid:17)(cid:19)(cid:3)(cid:24)(cid:21)(cid:17)(cid:19)(cid:3)(cid:24)(cid:22)(cid:17)(cid:19)(cid:3)(cid:24)(cid:23)(cid:17)(cid:19)(cid:3)(cid:19)(cid:21)(cid:19)(cid:23)(cid:19)(cid:25)(cid:19)(cid:27)(cid:19)(cid:20)(cid:19)(cid:19)(cid:41)(cid:20)(cid:51)(cid:49)(cid:54)(cid:92)(cid:81)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)(cid:54)(cid:72)(cid:80)(cid:37)(cid:85)(cid:76)(cid:71)(cid:74)(cid:72)table 6: top-10 prototypes in sembridge.
words areranked by their s.sim scores..references.
term.
food.
delicious.
cook.
processor.
efﬁcient.
prototypes.
machine,product,keyboard,netbook,service,computer,screen,value,touchpad,processoramazing,wonderful,awesome,great,good,nice,fantastic,beautiful,perfect,lightweightuse,load,plug,work,turn,break,charge,change,help,runsoup,burger,meal,sauce,ﬂavor,cheese,food,salad,seafood,fanattentive,impressive,affordable,friendly,reason-able,pleasant,simple,courteous,helpful,hungry.
freeze eat,hang,stop,die,bring,stay,leave,start,give,keep.
5.5 analysis on computational cost.
in practice, for any transfer pairs, the one-time con-struction of syntactic and semantic bridges can ﬁn-ish within 30 seconds.
therefore, we focus on theend-to-end training costs of synbridge/sembridge.
we run ﬁve top-performing methods on the trans-fer pair r→l and present the trainable parameternumber and running time per epoch of each methodin table 7. we can conclude that our proposedmethod maintains a quite low computational cost..table 7: computational cost of each method.
runtime132s84s11s12s.
timnbert-crossbasetaggersynbridge/sembridge.
parameter0.8m109m1.3m1.4m.
6 conclusion.
in this paper, we propose a novel active domainadaptation method for aspect term extraction.
un-like previous studies that conduct passive domainadaptation by associating aspect terms with piv-ots, we actively enhance the terms’ transferabil-ity by constructing syntactic and semantic bridgesfor them.
we then design a lightweight end-to-end tagger for bridge-based sequence tagging.
ex-periments on six transfer pairs demonstrate thatour method achieves a new state-of-the-art perfor-mance with a quite low computational cost..acknowledgments.
we thank the anonymous reviewers for their valu-able comments.
the work described in this pa-per is supported by the nsfc projects (61572376,91646206), and the 111 project (b07037)..john blitzer, ryan t. mcdonald, and fernando pereira.
2006. domain adaptation with structural correspon-dence learning.
in emnlp, pages 120–128..zhiyuan chen, arjun mukherjee, and bing liu.
2014.aspect extraction with automated prior knowledgelearning.
in acl, pages 347–358..zhuang chen and tieyun qian.
2019. transfer capsulenetwork for aspect level sentiment classiﬁcation.
inacl, pages 547–556..zhuang chen and tieyun qian.
2020a.
enhancingaspect term extraction with soft prototypes.
inemnlp, pages 2107–2117.
association for compu-tational linguistics..zhuang chen and tieyun qian.
2020b.
relation-awarecollaborative learning for uniﬁed aspect-based senti-ment analysis.
in acl, pages 3685–3694..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in naacl, pages 4171–4186..ying ding, jianfei yu, and jing jiang.
2017. recur-rent neural networks with auxiliary labels for cross-in aaai, pagesdomain opinion target extraction.
3436–3442..yaroslav ganin and victor s. lempitsky.
2015. unsu-pervised domain adaptation by backpropagation.
inicml, pages 1180–1189..chenggong gong, jianfei yu, and rui xia.
2020. uni-ﬁed feature and instance based domain adaptationin emnlp,for aspect-based sentiment analysis.
pages 7035–7045..han guo, ramakanth pasunuru, and mohit bansal.
2020. multi-source domain adaptation for text clas-in aaai, pagessiﬁcation via distancenet-bandits.
7830–7838..ruidan he, wee sun lee, hwee tou ng, and danieldahlmeier.
2019. an interactive multi-task learningnetwork for end-to-end aspect-based sentiment anal-ysis.
in acl, pages 504–515..minqing hu and bing liu.
2004. mining and summa-in sigkdd, pages 168–.
rizing customer reviews.
177..niklas jakob and iryna gurevych.
2010. extractingopinion targets in a single and cross-domain settingin emnlp, pageswith conditional random ﬁelds.
1035–1045..diederik p. kingma and jimmy ba.
2015. adam: a.method for stochastic optimization.
in iclr..fangtao li, chao han, minlie huang, xiaoyanzhu, yingju xia, shu zhang, and hao yu.
2010.structure-aware review mining and summarization.
in coling, pages 653–661..325fangtao li, sinno jialin pan, ou jin, qiang yang, andxiaoyan zhu.
2012. cross-domain co-extraction ofin acl, pages 410–sentiment and topic lexicons.
419..feixiang wang, man lan, and wenting wang.
2018.towards a one-stop solution to both aspect extrac-tion and sentiment analysis tasks with neural multi-task learning.
in ijcnn, pages 1–8..zheng li, xin li, ying wei, lidong bing, yu zhang,and qiang yang.
2019. transferable end-to-endaspect-based sentiment analysis with selective adver-in emnlp-ijcnlp, pages 4589–sarial learning.
4599..kang liu, heng li xu, yang liu, and jun zhao.
2013.opinion target extraction using partially-supervisedword alignment model.
in ijcai, pages 2134–2140..kang liu, liheng xu, and jun zhao.
2012. opiniontarget extraction using word-based translation model.
in emnlp, pages 1346–1356..pengfei liu, shaﬁq r. joty, and helen m. meng.
2015.fine-grained opinion mining with recurrent neuralnetworks and word embeddings.
in emnlp, pages1433–1443..dehong ma, sujian li, fangzhao wu, xing xie,and houfeng wang.
2019. exploring sequence-to-sequence learning in aspect term extraction.
in acl,pages 3538–3547..christopher d. manning, mihai surdeanu, john bauer,jenny rose finkel, steven bethard, and david mc-closky.
2014. the stanford corenlp natural languageprocessing toolkit.
in acl, pages 55–60..oren pereg, daniel korat, and moshe wasserblat.
2020.syntactically aware cross-domain aspect and opin-in coling, pages 1772–ion terms extraction.
1777..wenya wang and sinno jialin pan.
2018. recursiveneural structural correspondence network for cross-in acl,domain aspect and opinion co-extraction.
pages 2171–2181..wenya wang and sinno jialin pan.
2019a.
syntacti-cally meaningful and transferable recursive neuralnetworks for aspect and opinion extraction.
cl,45(4):705–736..wenya wang and sinno jialin pan.
2019b.
transfer-able interactive memory network for domain adap-in aaai,tation in ﬁne-grained opinion extraction.
pages 7192–7199..wenya wang, sinno jialin pan, daniel dahlmeier, andxiaokui xiao.
2016. recursive neural conditionalrandom ﬁelds for aspect-based sentiment analysis.
in emnlp, pages 616–626..wenya wang, sinno jialin pan, daniel dahlmeier, andxiaokui xiao.
2017. coupled multi-layer attentionsfor co-extraction of aspect and opinion terms.
inaaai, pages 3316–3322..yuanbin wu, qi zhang, xuanjing huang, and lide wu.
2009. phrase dependency parsing for opinion min-ing.
in emnlp, pages 1533–1541..hu xu, bing liu, lei shu, and philip s. yu.
2018. dou-ble embeddings and cnn-based sequence labeling foraspect extraction.
in acl, pages 592–598..maria pontiki, dimitris galanis, haris papageorgiou,suresh manandhar, and ion androutsopoulos.
2015.semeval-2015 task 12: aspect based sentiment anal-ysis.
in semeval, pages 486–495..hu xu, bing liu, lei shu, and philip s. yu.
2019.bert post-training for review reading compre-hension and aspect-based sentiment analysis.
innaacl-hlt, pages 2324–2335..maria pontiki, dimitris galanis, john pavlopoulos,harris papageorgiou,ion androutsopoulos, andsuresh manandhar.
2014. semeval-2014 task 4: as-in semeval, pagespect based sentiment analysis.
27–35..ana-maria popescu and oren etzioni.
2005. extract-ing product features and opinions from reviews.
inemnlp, pages 339–346..guang qiu, bing liu, jiajun bu, and chun chen.
2011. opinion word expansion and target extrac-tion through double propagation.
computationallinguistics, 37(1):9–27..nitish srivastava, geoffrey e. hinton, alexkrizhevsky, ilya sutskever, and ruslan salakhutdi-nov. 2014. dropout: a simple way to prevent neuraljmlr, 15(1):1929–networks from overﬁtting.
1958..a ranges of hyperparameters.
we present the hyperparameter ranges in table 8.we select all hyperparameters via manual tuning..table 8: ranges of hyperparameters..hyperparameter.
frequency threshold τnumber of prototypes knumber of cnn layers ldimension of cnn features dfkernel size ks of cnn layer 1kernel size ks of cnn layer 2kernel size ks of cnn layer 3kernel size ks of cnn layer 4number of mlp layers ldthe scale coefﬁcient of grl λ 10[−4,−3,−2,−1,0] 10−1.
range1,2,3,4,5,6,7,8,9,101,2,3,4,5,6,7,8,9,101,2,3,4,564, 128, 2563,5,7,93,5,7,93,5,7,93,5,7,91,2,3,4,5.best510425635553.
326table 9: comparison of different methods when there is an ote task.
the best scores are in bold and the secondbest ones are underlined.
as and op denote aspect and opinion f1-scores.
averaged results with * are signiﬁcantlybetter than the best baseline bert-cross (p < 0.01) based on one-tailed unpaired t-test..models.
r→l.
l→r.
r→d.
d→r.
l→d.
d→l.
avg..op.
as.
as.
op.
as.
op.
as.
op.
op.
as.
asoprnscn40.43 65.85 52.91 72.51 35.10 60.17 48.36 73.75 40.42 61.15 51.14 71.18trnn40.15 65.63 53.78 73.40 37.33 60.32 51.17 74.37 41.19 60.20 51.66 68.79timn43.68 68.44 54.12 73.69 35.45 59.05 53.82 76.52 38.63 62.22 52.46 69.32bert-base34.70 73.84 37.07 80.12 37.17 64.52 40.54 60.45 43.45 59.59 44.19 58.7747.59 75.79 54.67 80.05 40.50 63.33 54.54 71.57 42.19 60.19 47.72 63.98sa-exalbert-cross 44.00 75.38 54.31 81.97 43.12 66.57 51.97 70.58 44.35 58.49 50.01 63.8147.78 70.61 58.39 79.53 39.71 63.63 57.56 80.18 44.49 64.14 52.77 72.30basetagger50.59 70.74 60.94 79.86 42.42 63.37 59.92 79.88 45.30 64.22 51.97 72.33synbridge50.67 71.51 63.04 80.48 43.34 63.46 60.19 80.21 44.91 64.15 53.02 72.63sembridge.
as44.7345.8846.3639.5247.8748.3550.1251.86∗52.53∗.
op67.4467.1268.2166.2269.1569.4771.73∗71.73∗72.08∗.
c can we combine synbridge and.
ote task.
sembridge?.
b modiﬁcation of sal and uda.
since sal and uda are designed for end-to-endcross-domain aspect-based sentiment analysis, theyhave access to the aspect sentiment labels in train-ing.
as previous studies show, aspect term extrac-tion and aspect-level sentiment classiﬁcation canbeneﬁt each other.
therefore, it is unfair to directlycompare our method with sal and uda..we choose to modify sal and uda and makethem fair competitors.
we degrade the collapsedtags {b-pos, i-pos, b-neg, i-neg, b-neu, i-neu, o} to {b, i, o} thus remove the aspect-level sentiment classiﬁcation task.
following otherbert-based methods, we use bert-base as thebackbone of uda..since synbridge and sembridge contain transfer-able syntactic and semantic information, it is in-tuitive to combine them for a better performancethan either individual model.
here we apply a verysimple operation for combination..for a word xi with embedding ei, we ﬁrst obtainits syntactic and semantic bridges bsyn,i and bsem,i,and merge them into a combined bridge:.
bcom,i = (wsyn × bsyn,i) + (wsem × bsem,i),.
(13).
then we conduct a similar gating operation and getthe combined bridge enhanced embedding ecom,i:gcom,i = σ (wcom(ei ⊕ bcom,i))ecom,i = gcom,i (cid:12) (ei ⊕ bcom,i),lastly, we regard ecom,i as the input of tagger andmake predictions for aspect terms.
we term thismodel combridge and present the results in ta-ble 10..(14).
table 10: comparison of different bridge-based meth-ods.
the best scores are in bold and the second bestones are underlined..model.
r→l l→r r→d d→r l→d d→l avg.
basetagger 48.86 61.42 40.56 57.67 43.75 51.95 50.70synbridge 51.53 63.90 42.76 59.40 44.97 52.44 52.50sembridge 51.53 65.96 43.03 60.61 45.39 53.77 53.38combridge 53.32 66.20 42.56 60.99 44.74 53.32 53.52.combridge slightly outperforms sembridge andachieves the optimal results in all bridge-basedmethods.
the small improvement is explicablesince sembridge already contains most of the syn-tactic information in synbridge and we do not useany sophisticated methods in combination..d detailed results for an additional.
when opinion terms are labeled, our method canalso conduct aspect term extraction and opinionterm extraction simultaneously.
for recognizingaspect and opinion terms, we only need to add anopinion term prediction layer:.
ˆya,i = sof tmax(wa × f lˆyo,i = sof tmax(wo × f l.i ),.
i ),.
(15).
where ˆya,i / ˆyo,i are the predictions of {b, i, o}for the aspect / opinion terms.
and the resultedbio loss is calculated as follow:.
lbio = −.
(cid:96)(ˆya,i, ya,i) + (cid:96)(ˆyo,i, yo,i).
(16).
(cid:88).
n(cid:88).
ds.
i=1.
where (cid:96) is the cross-entropy loss function..we present the detailed results in table 9. ob-viously, our proposed synbridge and sembridgeoutperform other baselines in both aspect and opin-ion f1-scores..327