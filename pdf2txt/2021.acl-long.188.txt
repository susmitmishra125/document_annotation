a uniﬁed generative framework for aspect-based sentiment analysis.
hang yan1,∗, junqi dai1,∗, tuo ji1, xipeng qiu1,2†, zheng zhang31shanghai key laboratory of intelligent information processing, fudan university1school of computer science, fudan university2pazhou lab, guangzhou, china3new york university{hyan19,jqdai19,tji19,xpqiu}@fudan.edu.cnzz@nyu.edu.
abstract.
aspect-based sentiment analysis (absa)aims to identify the aspect terms, their corre-sponding sentiment polarities, and the opinionterms.
there exist seven subtasks in absa.
most studies only focus on the subsets ofthese subtasks, which leads to various compli-cated absa models while hard to solve thesesubtasks in a uniﬁed framework.
in this pa-per, we redeﬁne every subtask target as a se-quence mixed by pointer indexes and senti-ment class indexes, which converts all absasubtasks into a uniﬁed generative formulation.
based on the uniﬁed formulation, we exploitthe pre-training sequence-to-sequence modelbart to solve all absa subtasks in an end-to-end framework.
extensive experiments onfour absa datasets for seven subtasks demon-strate that our framework achieves substantialperformance gain and provides a real uniﬁedend-to-end solution for the whole absa sub-tasks, which could beneﬁt multiple tasks1..1.introduction.
aspect-based sentiment analysis (absa) is theﬁne-grained sentiment analysis (sa) task, whichaims to identify the aspect term (a), its correspond-ing sentiment polarity (s), and the opinion term (o).
for example, in the sentence “the drinks are al-ways well made and wine selection is fairly priced”,the aspect terms are “drinks” and “wine selection”,and their sentiment polarities are both “positive”,and the opinion terms are “well made” and “fairlypriced”.
based on the combination of the a, s, o,there exist seven subtasks in absa.
we summa-rize these subtasks in figure 1. speciﬁcally, theirdeﬁnitions are as follows:.
∗equal contribution.
† corresponding author.
1code is available at https://github.com/yhcc/.
bartabsa..figure 1: illustration of seven absa subtasks..• aspect term extraction(ae): extracting all the.
aspect terms from a sentence..• opinion term extraction (oe): extracting all.
the opinion terms from a sentence..• aspect-level sentiment classiﬁcation (alsc):predicting the sentiment polarities for every givenaspect terms in a sentence..• aspect-oriented opinion extraction (aoe):extracting the paired opinion terms for every givenaspect terms in a sentence..• aspect term extraction and sentiment clas-siﬁcation (aesc): extracting the aspect terms aswell as the corresponding sentiment polarities si-multaneously..• pair extraction (pair): extracting the aspectterms as well as the corresponding opinion termssimultaneously..• triplet extraction (triplet): extracting all as-pects terms with their corresponding opinion termsand sentiment polarity simultaneously..although these absa subtasks are strongly re-lated, most of the existing work only focus 1∼3subtasks individually.
the following divergencesmake it difﬁcult to solve all subtasks in a uniﬁedframework..1. input: some subtasks ( ae, oe, aesc, pair.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2416–2429august1–6,2021.©2021associationforcomputationallinguistics2416subtaskinputoutputtask typeaspect term extraction(ae)sa1, a2extractionopinion term extraction(oe)so1,o2extractionaspect-level sentiment classification(alsc)s+ a1s1classifications + a2s2aspect-oriented  opinion extraction(aoe)s+ a1o1extractions+ a2o2aspect term extraction and  sentiment classification(aesc)s(a1, s1), (a2, s2)extraction & classificationpairextraction(pair)s(a1, o1), (a2, o2)extractiontripletextraction(triplet)s(a1,o1, s1), (a2, o2,s2)extraction & classifications:the  drinksare always well madeand wine selectionis  fairly priced .
positivepositivea1o1a2o2s1s2and triplet) only take the text sentence as in-put, while the remained subtasks ( alsc andaoe) take the text and a given aspect term asinput..2. output: some tasks (ae, oe, alsc, aoe)only output a certain type from a, s or o, whilethe remained tasks (aesc, pair and triplet)return compound output as the combinationof a, s and o..3. task type: there are two kinds of tasks: ex-traction task (extracting aspect and opinion)and classiﬁcation task (predicting sentiment)..because of the above divergences, a myriad ofprevious works only focus on the subset of thesesubtasks.
however, the importance of solving thewhole absa subtasks in a uniﬁed framework re-mains signiﬁcant.
recently, several works makeattempts on this track.
some methods(peng et al.,2020; mao et al., 2021) apply the pipeline modelto output the a, s, o from the inside sub-modelsseparately.
however, the pipeline process is notend-to-end.
another line follows the sequence tag-ging method by extending the tagging schema (xuet al., 2020).
however, the compositionality ofcandidate labels hinders the performance.
in con-clusion, the existing methods can hardly solve allthe subtasks by a uniﬁed framework without re-lying on the sub-models or changing the modelstructure to adapt to all absa subtasks..motivated by the above observations, we pro-pose a uniﬁed generative framework to address allthe absa subtasks.
we ﬁrst formulate all thesesubtasks as a generative task, which could han-dle the obstacles on the input, output, and tasktype sides and adapt to all the subtasks withoutany model structure changes.
speciﬁcally, wemodel the extraction and classiﬁcation tasks as thepointer indexes and class indexes generation, re-spectively.
based on the uniﬁed task formulation,we use the sequence-to-sequence pre-trained modelbart (lewis et al., 2020) as our backbone to gen-erate the target sequence in an end-to-end process.
to validate the effectiveness of our method, weconduct extensive experiments on public datasets.
the comparison results demonstrate that our pro-posed framework outperforms most state-of-the-art(sota) models in every subtask..in summary, our main contributions are as fol-.
lows:.
• we formulate both the extraction task and clas-siﬁcation task of absa into a uniﬁed index gen-.
eration problem.
unlike previous uniﬁed models,our method needs not to design speciﬁc decodersfor different output types..• with our re-formulation, all absa subtaskscan be solved in sequence-to-sequence framework,which is easy-to-implement and can be built on thepre-trained models, such as bart..• we conduct extensive experiments on four pub-lic datasets, and each dataset contains a subset ofall absa subtasks.
to the best of our knowledge,it is the ﬁrst work to evaluate a model on all absatasks..• the experimental results show that our pro-posed framework signiﬁcantly outperforms recentsota methods..2 background.
2.1 absa subtasks.
in this section, we ﬁrst review the existing studieson single output subtasks, and then turn to studiesfocusing on the compound output subtasks..2.1.1 single output subtaskssome researches mainly focus on the single outputsubtasks.
the ae, oe, alsc and aoe subtasksonly output one certain type from a, s or o..ae most studies treat ae subtask as a se-quence tagging problem (li and lam, 2017; xuet al., 2018; li et al., 2018b).
recent works ex-plore sequence-to-sequence learning on ae sub-task, which obtain promissing results especiallywith the pre-training language models (ma et al.,2019; li et al., 2020)..oe most studies treat oe subtask as an auxiliarytask (wang et al., 2016a, 2017; wang and pan,2018; chen and qian, 2020; he et al., 2019).
mostworks can only extract the unpaired aspect andopinion terms2.
in this case, opinion terms areindependent of aspect terms..alsc tang et al.
(2016a) use the long short termmemory (lstm) network to enhance the interac-tions between aspects and context words.
wanget al.
(2016b); liu and zhang (2017); ma et al.
(2017); tay et al.
(2018) incorporate the attentionmechanism into the lstm-based neural networkmodels to model relations of aspects and their con-textual words.
other model structures such as con-volutional neural network (cnn) (li et al., 2018a;xue and li, 2018), gated neural network (zhanget al., 2016; xue and li, 2018), memory neural.
2it is also referred to as the ae-oe co-extraction..2417network (tang et al., 2016b; chen et al., 2017)have also been applied..aoe this subtask is ﬁrst introduced by fan et al.
(2019) and they propose the datasets for this sub-task.
most studies apply sequence tagging methodfor this subtask (wu et al., 2020; pouran ben vey-seh et al., 2020)..2.1.2 compound output subtasks.
some researchers pay more attention and effortsto the subtasks with compound output.
we reviewthem as follows:.
aesc.
one line follows pipeline method tosolve this problem.
other works utilize uniﬁedtagging schema (mitchell et al., 2013; zhang et al.,2015; li et al., 2019) or multi-task learning (heet al., 2019; chen and qian, 2020) to avoid theerror-propagation problem (ma et al., 2018).
span-based aesc works are also proposed recently (huet al., 2019), which can tackle the sentiment incon-sistency problem in the uniﬁed tagging schema..pairs zhao et al.
(2020) propose to extract all (a,o) pair-wise relations from scratch.
they proposea multi-task learning framework based on the span-based extraction method to handle this subtask..triplet this subtask is proposed by peng et al.
(2020) and gains increasing interests recently.
xuet al.
(2020) design the position-aware taggingschema and apply model based on crf (laffertyet al., 2001) and semi-markov crf (sarawagi andcohen, 2004).
however, the time complexity lim-its the model to detect the aspect term with long-distance opinion terms.
mao et al.
(2021) formulatetriplet as a two-step mrc problem, which appliesthe pipeline method..2.2 sequence-to-sequence models.
the sequence-to-sequence framework has beenlong studied in the nlp ﬁeld to tackle various tasks(sutskever et al., 2014; cho et al., 2014; vinyalset al., 2015; luong et al., 2015).
inspired by thesuccess of ptms (pre-trained models) (qiu et al.,2020; peters et al., 2018; devlin et al., 2019; brownet al., 2020), song et al.
(2019); raffel et al.
(2020);lewis et al.
(2020) try to pre-train sequence-to-sequence models.
among them, we use the bart(lewis et al., 2020) as our backbone, while theother sequence-to-sequence pre-training modelscan also be applied in our architecture to use thepointer mechanism (vinyals et al., 2015), such asmass (song et al., 2019)..bart is a strong sequence-to-sequence pre-trained model for natural language generation(nlg).
bart is a denoising autoencoder com-posed of several transformer (vaswani et al., 2017)encoder and decoder layers.
it is worth noting thatthe bart-base model contains a 6-layer encoderand 6-layer decoder, which makes it similar numberof parameters3 with the bert-base model.
bartis pretrained on denoising tasks where the inputsentence is noised by some methods, such as mask-ing and permutation.
the encoder takes the noisedsentence as input, and the decoder will restore theoriginal sentence in an autoregressive manner..3 methodology.
although there are two types of tasks among theseven absa subtasks, they can be formulated un-der a generative framework.
in this part, we ﬁrstintroduce our sequential representation for eachabsa subtask.
then we detail our method, whichutilizes bart to generate these sequential repre-sentations..3.1 task formulation.
as depicted in figure 1, there are two types of tasks,namely the extraction and classiﬁcation, whosetarget can be represented as a sequence of pointerindexes and class indexes, respectively.
therefore,we can formulate these two types of tasks in auniﬁed generative framework.
we use a, s, o, torepresent the aspect term, sentiment polarity,andopinion term, respectively.
moreover, we use thesuperscript s and e to denote the start index andend index of a term.
for example, os, ae representthe start index of an opinion term o and the endindex of an aspect term a. we use the sp to denotethe index of sentiment polarity class.
the targetsequence for each subtask is as follows:1, ae• ae : y = [as• oe : y = [os1, oe• aesc : y = [as• pair: y = [as1, ae• triplet : y = [asi , spoethe above subtasks only rely on the input sen-tence, while for the alsc and aoe subtasks, theyalso depend on a speciﬁc aspect term a. instead ofputting the aspect term on the input side, we put.
i , aei , ...],i , oei , ...],1, ..., as1, ..., as1, sp1, oe.
1, ..., as1, ..., os1, sp1, ae1, oe1, os1, os1, ae.
i , spi , aei , osi , ae1, ..., as.
i , ...],i , oei , ae.
i ,...],i , osi ,.
i , ...],.
3because of the cross-attention between encoder and de-coder, the number of parameters of bart is about 10% largerthan its counterpart of bert (lewis et al., 2020)..2418figure 2: overall architecture of the framework.
this shows an example generation process for the triplet subtaskwhere the source is “<s>the battery life is good </s>” and the target is “2 3 5 5 8 6”(only partial decoder sequenceis shown where the 6 (</s>) should be the next generation index).
the “index2token conversion” converts theindex to tokens.
speciﬁcally, the pointer index will be converted to its corresponding token in the source text,and the class index will be converted to corresponding class tokens.
embedding vectors in ll boxes are retrievedfrom same embedding matrix.
we use different position embeddings in the source and target for better generationperformance..[y1, ..., ym], where y0 is the start-of-the-sentencetoken.
therefore, different absa subtasks can beformulated as:.
p (y |x) =.
p (yt|x, y<t)..(1).
m(cid:89).
t=1.
to get the index probability distribution pt =p (yt|x, y<t) for each step, we use a model com-posed of two components: (1) encoder; (2) de-coder..encoder the encoder part is to encode x intovectors he.
we use the bart model, therefore,the start of sentence (<s>) and the end of sentence(</s>) tokens will be added to the start and endof x, respectively.
we ignore the <s> token inour equations for simplicity.
the encoder part is asfollows:.
he = bartencoder([x1, ..., xn]),.
(2).
where he ∈ rn×d, and d is the hidden dimension.
decoder the decoder part takes the encoder out-puts he and previous decoder outputs y<t as inputsto get pt.
however, the y<t is an index sequence.
therefore, for each yt in y<t, we ﬁrst need to usethe following index2token module to conduct a.figure 3: target sequences for different subtasks.
theunderlined indexes are given in advance.
we convertthe sentiment class index to the corresponding class to-ken for better understanding..them on the target side so that the target sequencesare as follows:.
• alsc : y = [as, ae, sp],1, oe• aoe : y = [as, ae, os.
1, ..., os.
i , oe.
i , ...],.
where the underlined tokens are given during infer-ence.
detailed target sequence examples for eachsubtask are presented in figure 3..3.2 our model.
as our discussion in the last section, all subtaskscan be formulated as taking the x = [x1, ..., xn]as input and outputting a target sequence y =.
2419igbartencoderbatterylifeisgoodthe<s>2position embeddings:battery3life5good5goodbartdecoderencoder input:token embeddings:+++++<s>+</s>+1234506igigigigig8+++++12340+++++123456sentiment class⨂prob.12345789⨂dot-productindex2token  conversionindex generatorembeddingdecoder input:target:neuposnegthebatteryislifegoodneuposneg</s>6pointer indexesclass indexes+the  wine listis  interestingand has good values ,buttheserviceis dreadfulpositivepositiveposition index:token:0  1   2  3  4   5  6    7  8   9  10     11   12 13   14positivesubtasktarget sequenceae1, 2, 12, 12,</s> oe4, 4, 7, 8, 14, 14, </s>alsc1, 2, pos, </s>12, 12, pos, </s>aoe1, 2, 4,4,7,8,</s>12, 12, 14, 14, </s>aesc1, 2, pos, 12, 12, neg, </s>pair1, 2, 4, 4, 1, 2, 7, 8, 12, 12, 14, 14, </s>triplet1, 2, 4, 4, pos, 1, 2, 7, 8, pos, 12, 12, 14, 14, pos, </s>dataset.
d17.
d19.
d20a.
d20b.
14res.
#s.#a.
#otrain 3044 3699 3484test800 1134 1008train 1627 2643500 865testtrain 1300323devtest496train 1266310dev492test.
--------.
------.
14lap#o#a#s3048 2373 2504800 654 6741158 1634343 482.
#p----.
15res.
#p----.
#o#a#s1315 1199 1210685 542 510754 1076325 436.
#p----.
--------.
2145 920524 228862 3392338 906577 219994 328.
------.
1265 5931483374903181460 605148346148543.
------.
#s--.
16res#a #o #p-------1079 1512 --329 457 -- 1289- 316- 465- 1394- 339- 514.
------.
923 842238 210455 3201013 857249 210485 326.
--------.
subtasks.
ae, oe, alsc,aesc.
aoe.
ae, oe, alsc, aoe,aesc, pair, triplet.
ae, oe, alsc, aoe,aesc, pair, triplet.
table 1: the statistics of four datasets, where the #s, #a, #o, #p denote the numbers of sentences, aspect terms,opinion terms, and the <a, o> pairs, respectively.
we use “-” to denote the missing data statistics of some datasets.
the “subtasks” column refers to the absa subtasks that can be applied on the corresponding dataset..conversion.
(cid:40).
ˆyt =.
xyt,cyt−n,.
if yt is a pointer index,if yt is a class index,.
(3).
where c = [c1, ..., cl] is the class token list4..after that, we use the bart decoder to get the.
last hidden state.
t = bartdecoder(he; ˆy<t),hd.
(4).
t ∈ rd.
with hdwhere hdprobability distribution pt as follows:.
t , we predict the token.
algorithm 1 decoding algorithm for the tripletsubtaskinput: number of tokens in the input sentencen, target sequence y = [y1, ..., ym] and yi ∈[1, n + |c|]output: target1, os1: l = {}, e = [], i = 12: while i <= m doyi = y [i]3:if yi > n then.
span1, s1), ..., (as.
=i , si), ...}.
li , oe.
seti , ae.
1, ae.
1, oe.
i , os.
{(as.
4:.
5:.
6:.
7:.
8:.
l.add((e, cyi−n))e = [].
else.
e.append(yi).
ee = barttokenembed(x),ˆhe = mlp(he),¯he = α ˆhe + (1 − α)ee,cd = barttokenembed(c),pt = softmax([ ¯he; cd]hd.
t ),.
(5).
(6).
(7).
(8).
(9).
9:.
end ifi+ = 110:11: end while12: return l.4 experiments.
4.1 datasets.
where ee, he, ˆhe, ¯he ∈ rn×d; cd ∈ rl×d; andpt ∈ r(n+l) is the ﬁnal distribution on all indexes.
during the training phase, we use the teacherforcing to train our model and the negative log-likelihood to optimize the model.
moreover, dur-ing the inference, we use the beam search to getthe target sequence y in an autoregressive manner.
after that, we need to use the decoding algorithmto convert this sequence into the term spans andsentiment polarity.
we use the triplet task as anexample and present the decoding algorithm in al-gorithm 1, the decoding algorithm for other tasksare much depicted in the supplementary material..we evaluate our method on four absa datasets.
all of them are originated from the semeval chal-lenges (pontiki et al., 2014a,b,c), where only theaspect terms and their sentiment polarities are la-beled..the ﬁrst dataset(d17.
5) is annotated by wanget al.
(2017), where the unpaire opinion terms are la-beled.
the second dataset(d19) is annotated by fanet al.
(2019), where they pair opinion terms with.
4in our implement, yt ∈ [1, n + l].
the x1 has the pointer.
index 1..5each dataset only contains a subset of all absa subtasks.
we use the published year of the dataset to distinguish them..2420baselines.
e2e.
task formulation backbone.
datasets.
ae oe alsc aoe aesc pair triplet.
span-bertimn-bertracl-bert.
ioglotnong.
rinante+cmla+li-uniﬁed+peng-two-stagejet-bertdual-mrc.
-(cid:51).
-.
(cid:51)(cid:51)(cid:51).
----(cid:51).
-.
(cid:51).
span.extractionseq.taggingseq.tagging.
seq.taggingseq.taggingseq.tagging.
seq.taggingseq.taggingseq.taggingseq.taggingseq.taggingspan.mrc.
bertbertbert.
lstmlstmbert.
d17d17d17.
d19d19d19.
(cid:51)(cid:51)(cid:51).
---.
lstm+crf d20a,d20bd20a,d20battentiond20a,d20blstmlstm+gcn d20a,d20bd20a,d20bbertbert.
(cid:51)(cid:51)(cid:51)(cid:51)(cid:51)d17,d19,d20a,d20b (cid:51)d17,d19,d20a,d20b (cid:51).
(cid:51)(cid:51)(cid:51).
---.
(cid:51)(cid:51)(cid:51)(cid:51)(cid:51)(cid:51).
---.
(cid:51)(cid:51)(cid:51).
-----(cid:51).
-(cid:51)(cid:51).
---.
(cid:51)(cid:51)(cid:51)(cid:51)(cid:51).
-.
(cid:51).
(cid:51)(cid:51)(cid:51).
---.
(cid:51)(cid:51)(cid:51)(cid:51)(cid:51)(cid:51).
(cid:51).
---.
---.
(cid:51)(cid:51)(cid:51)(cid:51)(cid:51)(cid:51).
(cid:51).
---.
---.
(cid:51)(cid:51)(cid:51)(cid:51)(cid:51)(cid:51).
(cid:51).
ours.
span.generation bart.
(cid:51).
(cid:51).
table 2: the baselines of our experiments.
to further demonstrate that our proposed method is a real uniﬁed end-to-end absa framework, we present our work in the last row.
“e2e” is short for end-to-end, which means themodel should output all the subtasks’ results synchronously rather than requiring any preconditions, e.g., pipelinemethods.
the “datasets” column refers to the datasets that this baseline is conducted..corresponding aspects.
the third dataset(d20a) isfrom peng et al.
(2020).
they reﬁne the data in <a,o, s> triplet form.
the fourth dataset(d20b) fromxu et al.
(2020) is the revised variant of peng et al.
(2020), where the missing triplets with overlappingopinions are corrected.
we present the statistics forthese four datasets in table 1..4.2 baselines.
to have a fair comparison, we summarize top-performing baselines of all absa subtasks.
givendifferent absa subtasks, datasets, and experimen-tal setups, existing baselines can be separated intothree groups roughly as shown in table 2..the baselines in the ﬁrst group are conducted ond17 dataset, covering the ae, oe, alsc, and aescsubtasks.
span-based method span-bert (huet al., 2019) and sequence tagging method, imn-bert (he et al., 2019) and racl-bert (chenand qian, 2020), are selected.
speciﬁcally, theimn-bert model is reproduced by chen and qian(2020).
all these baselines are implemented onbert-large..the baselines of the second group are conductedon d19 dataset, mainly focusing on aoe subtask.
interestingly, we ﬁnd that sequence tagging methodis the main solution for this subtask (fan et al.,2019; wu et al., 2020; pouran ben veyseh et al.,2020)..the baselines of the third group are mainly con-ducted on d20a and d20b datasets, which could.
cover almost all the absa subtasks except for onecertain subtask depending on the baseline struc-tures.
for the following baselines: rinante (daiand song, 2019), cmla (wang et al., 2017), li-uniﬁed (li et al., 2019), the sufﬁx “+” in table 2denotes the corresponding model variant modiﬁedby peng et al.
(2020) for being capable of aesc,pair and triplet..4.3.implement details.
following previous studies, we use different met-rics according to different subtasks and datasets.
speciﬁcally, for the single output subtasks ae, oe,and aoe, the prediction span would be consideredas correct only if it exactly matches the start and theend boundaries.
for the alsc subtask, we requirethe generated sentiment polarity of the given aspectshould be the same as the ground truth.
as forcompound output subtasks, aesc, pair and triplet,a prediction result is correct only when all the spanboundaries and the generated sentiment polarityare accurately identiﬁed.
we report the precision(p), recall (r), and f1 scores for all experiments6..4.4 main results.
on d17 dataset (wang et al., 2017), we compareour method for ae, oe, alsc, and aesc.
thecomparison results are shown in table 3. most ofour results achieve better or comparable results to.
6due to the limited space, we would present detailed ex-.
periments for each dataset in the supplementary material..2421model.
span-bertimn-bertracl-bertdual-mrcours.
14res.
14lap.
15res.
ae86.7184.0686.3886.6087.07.oe-85.1087.18-87.29.alsc aesc73.6871.7570.7275.6775.4281.6175.9582.04.
75.56.
73.56.ae82.3477.5581.7982.5183.52.oe-81.079.72-77.86.alsc aesc61.2562.561.7375.5663.4073.9165.9475.9767.3776.76.ae74.6369.9073.9975.0875.48.oe-73.2976.0-76.49.alsc aesc62.2950.2860.2270.1074.9166.0565.0873.5966.6173.91.table 3: comparison f1 scores for ae, oe, sc, and aesc on the d17 dataset (wang et al., 2017).
the baselineresults are retrieved from mao et al.
(2021).
we highlight the best results in bold.
it is worth noting that all thebaseline results are obtained via bert-large, while our results are obtained via bart-base..f180.2382.2182.3383.7385.38.p73.4377.0873.8778.2183.11.f170.9972.0275.7779.9080.55.p72.1976.6176.6377.1980.12.f171.9173.2978.8174.5080.52.p84.3686.5787.7286.0789.22.table 4: comparison results for aoe on the d19 dataset (fan et al., 2019).
baselines are from the original papers.
we highlight the best results in bold..triple.
aesc.
triple.
aesc.
triple.
aesc.
triple..43.1234.0351.6851.8963.9270.3272.46.
56.9036.7063.3862.34-64.5968.17.
32.9020.042.4743.5050.055.5857.59.
53.6041.3064.9565.79-65.1469.95.
35.9028.046.6946.7954.6757.2160.11.
61.2042.1070.2071.73-70.8475.69.table 5: comparison f1 scores for aesc, pair and triplet on the d20a dataset (peng et al., 2020).
the baselineresults with “†” are retrieved from mao et al.
(2021), and result with “(cid:93)” is from xu et al.
(2020).
we highlight thebest results in bold..model.
ioglotnongdual-mrcours.
model.
cmla+ †rinante+ †li-uniﬁed+ †peng-two-stage †jet-bert (cid:93)dual-mrc†ours.
model.
cmla+rinante+li-uniﬁed+peng-two-stagejet-bertours.
14resr78.2580.5281.4678.4384.76.
14respair.
48.9546.2955.3456.10-74.9377.68.
14resr47.1339.3867.3563.6655.9464.99.p82.3884.083.2389.79.
86.01.aesc.
70.6248.1573.7974.19-76.5778.47.p39.1831.4241.0443.2470.56.
65.52.
16resr79.0880.8984.3880.7786.67.
16respair.
50.0030.7053.7560.04-75.7177.38.
16resr42.122.354.5164.2458.3768.68.f181.6083.6286.0183.3387.92.
41.6023.3044.5153.6262.9867.4069.98.f141.7223.8744.3154.2163.8367.62.f142.7934.9551.051.4662.4065.25.p30.0921.7140.5637.3855.3961.41.f133.1620.0742.3442.8751.0458.69.p34.5629.8844.7248.0764.45.
59.14.f137.0129.9747.8252.3257.5359.26.p41.3425.6837.3346.9670.42.
66.6.
14lapr68.7467.6277.7881.66.
78.13.
14lappair.
44.1029.7052.5653.85-63.3766.11.
14lapr36.9218.6644.2850.3847.3356.19.
15resr71.7670.2981.1471.9880.93.
15respair.
44.6035.4056.8556.23-64.9767.98.
15resr39.8430.0651.3957.5151.9659.38.table 6: comparison results for triplet on the d20b dataset (xu et al., 2020).
baselines are from (xu et al., 2020).
we highlight the best results in bold..baselines.
however, these baselines yield competi-tive results based on the bert-large pre-trainedmodels.
while our results are achieved on thebart-base model with almost half parameters.
this shows that our framework is more suitable for.
these absa subtasks..on d19 dataset (fan et al., 2019), we compareour method for aoe.
the comparison results areshown in table 4. we can observe that our methodachieves signiﬁcant p/r/f1 improvements on 14res,.
242215res, and 16res.
additionally, we notice that ourf1 score on 14lap is close to the previous sotaresult.
this is probably caused by the dataset do-main difference as the 14lap is the laptop commentswhile the others are restaurant comments..on d20a dataset (peng et al., 2020), we com-pare our method for aesc, pair, and triplet.
thecomparison results are shown in table 5. we canobserve that our proposed method is able to outper-form other baselines on all datasets.
speciﬁcally,we achieve the better results for triplet, whichdemonstrates the effectiveness of our method oncapturing interactions among aspect terms, opinionterms, and sentiment polarities.
we also observethat the span-based methods show superior per-formance to sequence tagging methods.
this maybe caused by the higher compositionality of candi-date labels in sequence tagging methods (hu et al.,2019).
as the previous sota method, the dual-mrc shows competitive performance by utilizingthe span-based extraction method and the mrcmechanism.
however, their inference process isnot an end-to-end process..on d20b dataset (xu et al., 2020), we compareour method for triplet.
the comparison resultscan be found in table 6. our method achieves thebest results with nearly 7 f1 points improvementson 14res, 15res, and 16res.
our method achievesnearly 13, 9, 7, 12 points improvements on eachdataset for the recall scores compared with otherbaselines.
this also explains the drop performanceof the precision score.
since d20b is reﬁned fromd20a, we speciﬁcally compare the triplet results ofthe corresponding dataset in d20a and d20b.
inter-estingly, we discover that all baselines have a muchbigger performance change on 15res.
we conjec-ture the distribution differences may be the causereason.
in conclusion, all the experiment resultsconﬁrm that our proposed method, which uniﬁesthe training and the inference to an end-to-end gen-erative framework, provides a new sota solutionfor the whole absa task..mat like [as, ae, os, oe, sp], it is mandatory thatone valid triplet prediction should be in length5, noted as “5-len”, and obviously all end indexshould be larger than the corresponding start in-dex, noted as “ordered prediction”.
we calculatenumber of non−5−len, referred to as the “invalidtotal prediction.
total 5−len prediction.
size”, and the number of non−ordered prediction, re-ferred to as the “invalid order”.
the “invalid token”means the as is not the start of a token, instead,it is the index of an inside subword.
from table7, we can observe that bart could learn this taskform easily as the low rate for all the three metrics,which demonstrate that the generative frameworkfor absa is not only a theoretically uniﬁed taskform but also a realizable framework in practical.
we remove these invalid predictions in our imple-mentation of experiments..as shown in table 4, we give some analysis onthe impact of the beam size, as we are a generationmethod.
however, the beam size seems to havelittle impact on the f1 scores..errors.
14res 14lap 15res.
16res.
invalid size.
0.48% 0.77% 1.41% 1.40%.
invalid order.
1.75% 3.70% 3.26% 3.26%.
invalid token.
0.48% 0.78% 1.02% 1.02%.
table 7: the errors for triplet on the test set of thed20b..pair extraction f1 scores.
triplet extraction f1 scores.
erocs1f.75.
72.
69.
66.
63.erocs1f.69.
66.
63.
60.
57.
14lap14res15res16res.
1.
2.
3.
4.
1.
2.
3.
4.beam size.
beam size.
figure 4: the f1 change curve with the increment ofbeam size on the dev set of d20b.
the beam size seemsto have little effect on the f1 scores..5 framework analysis.
6 conclusion.
to better understand our proposed framework,we conduct analysis experiments on the d20bdataset (xu et al., 2020)..to validate whether our proposed frameworkcould adapt to the generative absa task, we met-ric the invalid predictions for the triplet.
speciﬁ-cally, since the triplet requires the prediction for-.
this paper summarizes the seven absa subtasksand previous studies, which shows that there existdivergences on all the input, output, and task typesides.
previous studies have limitations on han-dling all these divergences in a uniﬁed framework.
we propose to convert all the absa subtasks to auniﬁed generative task.
we implement the bart.
2423to generate the target sequence in an end-to-endprocess based on the uniﬁed task formulation.
weconduct massive experiments on public datasetsfor seven absa subtasks and achieve signiﬁcantimprovements on most datasets.
the experimentalresults demonstrate the effectiveness of our method.
our work leads to several promising directions,such as sequence-to-sequence framework on othertasks, and data augmentation..acknowledgements.
we would like to thank the anonymous reviewersfor their insightful comments.
the discussion withcolleagues in aws shanghai ai lab was quitefruitful.
we also thank the developers of fastnlp7and ﬁtlog8.
this work was supported by the na-tional key research and development program ofchina (no.
2020aaa0106700) and national nat-ural science foundation of china (no.
62022027)..ethical considerations.
for the consideration of ethical concerns, we wouldmake detailed description as follows:.
(1) all the experiments are conducted on existingdatasets, which are derived from public scientiﬁcpapers..(2) we describe the characteristics of the datasetsin a speciﬁc section.
our analysis is consistent withthe results..(3) our work does not contain identity character-.
istics.
it does not harm anyone..(4) our experiments do not need a lot of com-.
puter resources compared to pre-trained models..(5) we will open source all our code..references.
tom b. brown, benjamin mann, nick ryder, melaniesubbiah, jared kaplan, prafulla dhariwal, arvindneelakantan, pranav shyam, girish sastry, amandaaskell, sandhini agarwal, ariel herbert-voss,gretchen krueger, tom henighan, rewon child,aditya ramesh, daniel m. ziegler, jeffrey wu,clemens winter, christopher hesse, mark chen,eric sigler, mateusz litwin, scott gray, benjaminchess, jack clark, christopher berner, sam mc-candlish, alec radford, ilya sutskever, and darioamodei.
2020. language models are few-shot learn-ers..7https://github.com/fastnlp/fastnlp.
fastnlp is a natural language processing python package.
8https://github.com/fastnlp/fitlog..fit-.
log is an experiment tracking package.
peng chen, zhongqian sun, lidong bing, and weiyang.
2017. recurrent attention network on mem-ory for aspect sentiment analysis.
in proceedings ofthe 2017 conference on empirical methods in nat-ural language processing, pages 452–461, copen-hagen, denmark.
association for computationallinguistics..zhuang chen and tieyun qian.
2020. relation-awarecollaborative learning for uniﬁed aspect-based sen-timent analysis.
in proceedings of the 58th annualmeeting of the association for computational lin-guistics, pages 3685–3694, online.
association forcomputational linguistics..kyunghyun cho, bart van merri¨enboer, caglar gul-cehre, dzmitry bahdanau, fethi bougares, holgerschwenk, and yoshua bengio.
2014.learningphrase representations using rnn encoder–decoderfor statistical machine translation.
in proceedings ofthe 2014 conference on empirical methods in nat-ural language processing (emnlp), pages 1724–1734, doha, qatar.
association for computationallinguistics..hongliang dai and yangqiu song.
2019. neural as-pect and opinion term extraction with mined rulesas weak supervision.
in proceedings of the 57th an-nual meeting of the association for computationallinguistics, pages 5268–5277, florence, italy.
asso-ciation for computational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..zhifang fan, zhen wu, xin-yu dai, shujian huang,and jiajun chen.
2019. target-oriented opinionwords extraction with target-fused neural sequencein proceedings of the 2019 conferencelabeling.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 2509–2518, minneapolis, minnesota.
associ-ation for computational linguistics..ruidan he, wee sun lee, hwee tou ng, and danieldahlmeier.
2019. an interactive multi-task learn-ing network for end-to-end aspect-based sentimentanalysis.
in proceedings of the 57th annual meet-ing of the association for computational linguis-tics, pages 504–515, florence, italy.
association forcomputational linguistics..minghao hu, yuxing peng, zhen huang, dongshengli, and yiwei lv.
2019. open-domain targeted sen-timent analysis via span-based extraction and classi-in proceedings of the 57th annual meet-ﬁcation.
ing of the association for computational linguis-.
2424tics, pages 537–546, florence, italy.
association forcomputational linguistics..john d. lafferty, andrew mccallum, and fernandoc. n. pereira.
2001. conditional random ﬁelds:probabilistic models for segmenting and labeling se-quence data.
in proceedings of the eighteenth inter-national conference on machine learning (icml2001), williams college, williamstown, ma, usa,june 28 - july 1, 2001, pages 282–289.
morgankaufmann..mike lewis, yinhan liu, naman goyal, mar-jan ghazvininejad, abdelrahman mohamed, omerlevy, veselin stoyanov, and luke zettlemoyer.
2020. bart: denoising sequence-to-sequence pre-training for natural language generation, translation,and comprehension.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 7871–7880, online.
associationfor computational linguistics..kun li, chengbo chen, xiaojun quan, qing ling,and yan song.
2020. conditional augmentationfor aspect term extraction via masked sequence-to-sequence generation.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 7056–7066, online.
associationfor computational linguistics..xin li, lidong bing, wai lam, and bei shi.
2018a.
transformation networks for target-oriented senti-ment classiﬁcation.
in proceedings of the 56th an-nual meeting of the association for computationallinguistics (volume 1: long papers), pages 946–956, melbourne, australia.
association for compu-tational linguistics..xin li, lidong bing, piji li, and wai lam.
2019. auniﬁed model for opinion target extraction and targetsentiment prediction.
in the thirty-third aaai con-ference on artiﬁcial intelligence, aaai 2019, thethirty-first innovative applications of artiﬁcial in-telligence conference, iaai 2019, the ninth aaaisymposium on educational advances in artiﬁcialintelligence, eaai 2019, honolulu, hawaii, usa,january 27 - february 1, 2019, pages 6714–6721.
aaai press..xin li, lidong bing, piji li, wai lam, and zhimouyang.
2018b.
aspect term extraction with historyattention and selective transformation.
in proceed-ings of the twenty-seventh international joint con-ference on artiﬁcial intelligence, ijcai 2018, july13-19, 2018, stockholm, sweden, pages 4194–4200.
ijcai.org..xin li and wai lam.
2017. deep multi-task learningfor aspect term extraction with memory interaction.
in proceedings of the 2017 conference on empiri-cal methods in natural language processing, pages2886–2892, copenhagen, denmark.
association forcomputational linguistics..jiangming liu and yue zhang.
2017. attention mod-eling for targeted sentiment.
in proceedings of the.
15th conference of the european chapter of the as-sociation for computational linguistics: volume 2,short papers, pages 572–577, valencia, spain.
as-sociation for computational linguistics..thang luong, hieu pham, and christopher d. man-ning.
2015. effective approaches to attention-basedin proceedings of theneural machine translation.
2015 conference on empirical methods in natu-ral language processing, pages 1412–1421, lis-bon, portugal.
association for computational lin-guistics..dehong ma, sujian li, and houfeng wang.
2018. jointlearning for targeted sentiment analysis.
in proceed-ings of the 2018 conference on empirical methodsin natural language processing, pages 4737–4742,brussels, belgium.
association for computationallinguistics..dehong ma, sujian li, fangzhao wu, xing xie,and houfeng wang.
2019. exploring sequence-to-sequence learning in aspect term extraction.
in pro-ceedings of the 57th annual meeting of the asso-ciation for computational linguistics, pages 3538–3547, florence, italy.
association for computa-tional linguistics..dehong ma, sujian li, xiaodong zhang, and houfenginteractive attention networks forwang.
2017.in proceed-aspect-level sentiment classiﬁcation.
ings of the twenty-sixth international joint con-ference on artiﬁcial intelligence, ijcai 2017, mel-bourne, australia, august 19-25, 2017, pages 4068–4074. ijcai.org..yue mao, yi shen, chao yu, and longjun cai.
2021. ajoint training dual-mrc framework for aspect basedsentiment analysis.
corr, abs/2101.00816..margaret mitchell, jacqui aguilar, theresa wilson,and benjamin van durme.
2013. open domain tar-in proceedings of the 2013 con-geted sentiment.
ference on empirical methods in natural languageprocessing, pages 1643–1654, seattle, washington,usa.
association for computational linguistics..haiyun peng, lu xu, lidong bing, fei huang, weilu, and luo si.
2020. knowing what, how andwhy: a near complete solution for aspect-based sen-in the thirty-fourth aaai con-timent analysis.
ference on artiﬁcial intelligence, aaai 2020, thethirty-second innovative applications of artiﬁcialintelligence conference, iaai 2020, the tenth aaaisymposium on educational advances in artiﬁcial in-telligence, eaai 2020, new york, ny, usa, febru-ary 7-12, 2020, pages 8600–8607.
aaai press..matthew peters, mark neumann, mohit iyyer, mattgardner, christopher clark, kenton lee, and lukezettlemoyer.
2018. deep contextualized word rep-in proceedings of the 2018 confer-resentations.
ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1 (long papers), pages.
24252227–2237, new orleans, louisiana.
associationfor computational linguistics..maria pontiki, dimitris galanis, john pavlopoulos,harris papageorgiou,ion androutsopoulos, andsuresh manandhar.
2014a.
semeval-2014 task 4:aspect based sentiment analysis.
in proceedings ofthe 8th international workshop on semantic evalua-tion (semeval 2014), pages 27–35, dublin, ireland.
association for computational linguistics..maria pontiki, dimitris galanis, john pavlopoulos,harris papageorgiou,ion androutsopoulos, andsuresh manandhar.
2014b.
semeval-2014 task 4:aspect based sentiment analysis.
in proceedings ofthe 8th international workshop on semantic evalua-tion (semeval 2014), pages 27–35, dublin, ireland.
association for computational linguistics..maria pontiki, dimitris galanis, john pavlopoulos,harris papageorgiou,ion androutsopoulos, andsuresh manandhar.
2014c.
semeval-2014 task 4:aspect based sentiment analysis.
in proceedings ofthe 8th international workshop on semantic evalua-tion (semeval 2014), pages 27–35, dublin, ireland.
association for computational linguistics..amir pouran ben veyseh, nasim nouri, franck der-noncourt, dejing dou, and thien huu nguyen.
introducing syntactic structures into target2020.opinion word extraction with deep learning.
inproceedings of the 2020 conference on empiricalmethods in natural language processing (emnlp),pages 8947–8956, online.
association for computa-tional linguistics..xipeng qiu, tianxiang sun, yige xu, yunfan shao,ning dai, and xuanjing huang.
2020. pre-trainedlanguage processing: a sur-models for naturalscience china technological sciences,vey.
63(10):1872–1897..colin raffel, noam shazeer, adam roberts, katherinelee, sharan narang, michael matena, yanqi zhou,wei li, and peter j. liu.
2020. exploring the limitsof transfer learning with a uniﬁed text-to-text trans-former.
j. mach.
learn.
res., 21:140:1–140:67..sunita sarawagi and william w. cohen.
2004. semi-markov conditional random ﬁelds for informationextraction.
in advances in neural information pro-cessing systems 17 [neural information processingsystems, nips 2004, december 13-18, 2004, van-couver, british columbia, canada], pages 1185–1192..kaitao song, xu tan, tao qin, jianfeng lu, and tie-yan liu.
2019. mass: masked sequence to se-quence pre-training for language generation.
in pro-ceedings of the 36th international conference onmachine learning, icml 2019, 9-15 june 2019,long beach, california, usa, volume 97 of pro-ceedings of machine learning research, pages5926–5936.
pmlr..ilya sutskever, oriol vinyals, and quoc v. le.
2014.sequence to sequence learning with neural networks.
in advances in neural information processing sys-tems 27: annual conference on neural informa-tion processing systems 2014, december 8-13 2014,montreal, quebec, canada, pages 3104–3112..duyu tang, bing qin, xiaocheng feng, and ting liu.
2016a.
effective lstms for target-dependent sen-in proceedings of colingtiment classiﬁcation.
2016, the 26th international conference on compu-tational linguistics: technical papers, pages 3298–3307, osaka, japan.
the coling 2016 organizingcommittee..duyu tang, bing qin, and ting liu.
2016b.
aspectlevel sentiment classiﬁcation with deep memory net-in proceedings of the 2016 conference onwork.
empirical methods in natural language processing,pages 214–224, austin, texas.
association for com-putational linguistics..yi tay, luu anh tuan, and siu cheung hui.
2018.learning to attend via word-aspect associative fu-in pro-sion for aspect-based sentiment analysis.
ceedings of the thirty-second aaai conference onartiﬁcial intelligence, (aaai-18), the 30th innova-tive applications of artiﬁcial intelligence (iaai-18),and the 8th aaai symposium on educational ad-vances in artiﬁcial intelligence (eaai-18), new or-leans, louisiana, usa, february 2-7, 2018, pages5956–5963.
aaai press..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in advances in neural information pro-cessing systems 30: annual conference on neuralinformation processing systems 2017, december 4-9, 2017, long beach, ca, usa, pages 5998–6008..oriol vinyals, meire fortunato, and navdeep jaitly.
in advances in neural2015. pointer networks.
information processing systems 28: annual con-ference on neural information processing systems2015, december 7-12, 2015, montreal, quebec,canada, pages 2692–2700..wenya wang and sinno jialin pan.
2018. recursiveneural structural correspondence network for cross-in pro-domain aspect and opinion co-extraction.
ceedings of the 56th annual meeting of the associa-tion for computational linguistics (volume 1: longpapers), pages 2171–2181, melbourne, australia.
association for computational linguistics..wenya wang, sinno jialin pan, daniel dahlmeier, andxiaokui xiao.
2016a.
recursive neural conditionalrandom ﬁelds for aspect-based sentiment analysis.
in proceedings of the 2016 conference on empiri-cal methods in natural language processing, pages616–626, austin, texas.
association for computa-tional linguistics..wenya wang, sinno jialin pan, daniel dahlmeier, andxiaokui xiao.
2017. coupled multi-layer attentions.
2426meeting of the association for computational lin-guistics, pages 3239–3248, online.
association forcomputational linguistics..for co-extraction of aspect and opinion terms.
inproceedings of the thirty-first aaai conference onartiﬁcial intelligence, february 4-9, 2017, san fran-cisco, california, usa, pages 3316–3322.
aaaipress..yequan wang, minlie huang, xiaoyan zhu, andli zhao.
2016b.
attention-based lstm for aspect-in proceedings oflevel sentiment classiﬁcation.
the 2016 conference on empirical methods in nat-ural language processing, pages 606–615, austin,texas.
association for computational linguistics..zhen wu, fei zhao, xin-yu dai, shujian huang, andjiajun chen.
2020. latent opinions transfer networkfor target-oriented opinion words extraction.
in thethirty-fourth aaai conference on artiﬁcial intelli-gence, aaai 2020, the thirty-second innovative ap-plications of artiﬁcial intelligence conference, iaai2020, the tenth aaai symposium on educationaladvances in artiﬁcial intelligence, eaai 2020, newyork, ny, usa, february 7-12, 2020, pages 9298–9305. aaai press..hu xu, bing liu, lei shu, and philip s. yu.
2018. dou-ble embeddings and cnn-based sequence labelingfor aspect extraction.
in proceedings of the 56th an-nual meeting of the association for computationallinguistics (volume 2: short papers), pages 592–598, melbourne, australia.
association for compu-tational linguistics..lu xu, hao li, wei lu, and lidong bing.
2020.position-aware tagging for aspect sentiment tripletextraction.
in proceedings of the 2020 conferenceon empirical methods in natural language process-ing (emnlp), pages 2339–2349, online.
associa-tion for computational linguistics..wei xue and tao li.
2018. aspect based sentimentanalysis with gated convolutional networks.
in pro-ceedings of the 56th annual meeting of the associa-tion for computational linguistics (volume 1: longpapers), pages 2514–2523, melbourne, australia.
association for computational linguistics..meishan zhang, yue zhang, and duy-tin vo.
2015.neural networks for open domain targeted sentiment.
in proceedings of the 2015 conference on empiri-cal methods in natural language processing, pages612–621, lisbon, portugal.
association for compu-tational linguistics..meishan zhang, yue zhang, and duy-tin vo.
2016.gated neural networks for targeted sentiment anal-in proceedings of the thirtieth aaai con-ysis.
ference on artiﬁcial intelligence, february 12-17,2016, phoenix, arizona, usa, pages 3087–3093.
aaai press..he zhao, longtao huang, rong zhang, quan lu, andhui xue.
2020. spanmlt: a span-based multi-tasklearning framework for pair-wise aspect and opinionterms extraction.
in proceedings of the 58th annual.
2427a supplemental material.
a.1 experimental environment.
we use the triangular learning rate warmup.
allexperiments are conducted in the nvidia ge-forcertx-3090 graphical card with 24g graphicalmemory..the averages running time for experiments oneach dataset is less than 15 minutes.
the numberof parameters is as follows:.
• bart-base model: 12 layers, 768 hidden di-mensions and 16 heads with the total number ofparameters, 139m;.
• bert-base model: 12 layers, 768 hidden di-mensions and 12 heads with the total number ofparameters, 110m..a.2 decoding algorithm for different.
datasets.
in this part, we introduce the decoding algorithmwe used to convert the predicted target sequence yinto the target span set l. these algorithm can befound in algorithm 2, 3, 4..algorithm 2 decoding algorithm for the aoe sub-taskinput: number of tokens in the input sentencen, target sequence y = [y1, ..., ym] and yi ∈[1, n + |c|], lt is a given length for differenttasks..1, oe.
1, ..., os.
i , oe.
i )}.
output: target span set l = {(os1: l = {}, e = [], i = 32: while i <= m doyi = y [i]3:e.append(yi)i+ = 15:6: end while7: l.add(e)8: return l.4:.
algorithm 3 decoding algorithm for the aescsubtaskinput: number of tokens in the input sentencen, target sequence y = [y1, ..., ym] and yi ∈[1, n + |c|]output: target.
=.
l.seti , si)}.
i , ae.
{(as.
1, ae.
span1, s1), ..., (as1: l = {}, e = [], i = 12: while i <= m doyi = y [i]3:if yi > n then.
4:.
5:.
6:.
7:.
8:.
l.add((e, cyi−n))e = [].
else.
e.append(yi).
9:.
end ifi+ = 110:11: end while12: return l.algorithm 4 decoding algorithm forae/oe/pair subtasksinput: number of tokens in the input sentencen, target sequence y = [y1, ..., ym] and yi ∈[1, n + |c|], lt is a given length for differenttasks..the.
output: target span set l = {x1, ..., xi}(xii ) for.
i ) and (as.
is (asi ), (osae/oe/pair, respectively).
i , ae.
i , ae.
i , os.
i , oe.
i , oe.
1: l = {}, e = [], i = 12: while i <= m doyi = y [i]3:if len(e) == lt thenl.add((e, cyi−n))e = [].
5:.
6:.
4:.
7:.
8:.
end ife.append(yi)i+ = 19:10: end while11: return l.a.3 detailed experimental setup.
experiments on each dataset.
as the different subtasks are conducted on differ-ent datasets, speciﬁcally, we conduct the followingexperiments on each dataset:.
• on the d17 dataset, we conduct the aesc andthe oe in multi-task learning method.
to that end,we feed the pre-deﬁned task tags “<aesc>” and“<oe>” to the decoder ﬁrst.
for example, for theinput “the drinks are always (cid:58)(cid:58)(cid:58)(cid:58)well (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)made and wineselection is (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)priced” from d17 dataset, we.
fairly (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)(cid:58).
deﬁne the aesc sequence and the oe target se-quence as “<aesc>, 1, 1, pos, 7, 8, pos, </s>”and “<oe>, 4, 5, 10, 11, </s>”..• on the d19 dataset, we conduct the aoe.
asthe aoe subtask requires to detect the opinionterms given aspect terms in advance, the aspectterms need to be fed to our decoder ﬁrst.
forthe aforementioned example sentence from d19dataset, we deﬁne the aoe target sequence as “ 1,1, 4, 5, </s>” and the “ 7, 8, 10, 11, </s>”..2428• on the d20a and d20b datasets, we conduct thetriplet extraction.
for the aforementioned examplesentence from d20a and d20b dataset, we deﬁne thetriplet target sequence as “1, 1, 4, 5, pos, 7, 8, 10,11, pos, </s>”.
speciﬁc subtask metrics.
• on the d17 dataset, we get the aesc and oeresults directly.
following previous work, we onlycalculate the metrics for aesc and alsc fromthose true positive ae predictions.
speciﬁcally, thef1.
• on the d19 dataset, we get the aoe results di-rectly.
the metrics for aoe are standard precision,recall and the f1 score..• on the d20a and d20b datasets, we get thetriplet results directly.
we preserve the <at,ot>for pair metric and <at, sp> for aesc metric.
the metrics for them are standard precision, recalland the f1 score..2429