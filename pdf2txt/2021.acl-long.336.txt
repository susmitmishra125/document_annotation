pairre: knowledge graph embeddings via paired relation vectors.
linlin chao, jianshan he, taifeng wang, wei chuantgroup{chulin.cll,yebai.hjs}@antgroup.com{taifeng.wang,wei.chu}@alibaba-inc.com.
abstract.
distance based knowledge graph embeddingmethods show promising results on link pre-diction task, on which two topics have beenwidely studied: one is the ability to handlecomplex relations, such as n-to-1, 1-to-n andn-to-n, the other is to encode various rela-tion patterns, such as symmetry/antisymmetry.
however, the existing methods fail to solvethese two problems at the same time, whichleads to unsatisfactory results.
to mitigate thisproblem, we propose pairre, a model withpaired vectors for each relation representation.
the paired vectors enable an adaptive adjust-ment of the margin in loss function to ﬁt forcomplex relations.
besides, pairre is capableof encoding three important relation patterns,symmetry/antisymmetry, inverse and composi-tion.
given simple constraints on relation rep-resentations, pairre can encode subrelationfurther.
experiments on link prediction bench-marks demonstrate the proposed key capabili-ties of pairre.
moreover, we set a new state-of-the-art on two knowledge graph datasets ofthe challenging open graph benchmark..1.introduction.
knowledge graphs store huge amounts of struc-tured data in the form of triples, with projects suchas wordnet (miller, 1995), freebase (bollackeret al., 2008), yago (suchanek et al., 2007) anddbpedia (lehmann et al., 2015).
they have gainedwidespread attraction from their successful use intasks such as question answering (bordes et al.,2014), semantic parsing (berant et al., 2013), andnamed entity disambiguation (zheng et al., 2012)and so on..since most knowledge graphs suffer from incom-pleteness, predicting missing links between entitieshas been a fundamental problem.
this problemis named as link prediction or knowledge graph.
completion.
knowledge graph embedding meth-ods, which embed all entities and relations into alow dimensional space, have been proposed for thisproblem..distance based embedding methods from transe(bordes et al., 2013) to the recent state-of-the-artrotate (sun et al., 2019) have shown substan-tial improvements on knowledge graph comple-tion task.
two major problems have been widelystudied.
the ﬁrst one refers to handling of 1-to-n, n-to-1, and n-to-n complex relations (bordeset al., 2013; lin et al., 2015).
in case of the 1-to-n relations, given triples like (stevenspielberg,directorof , ?
), distance based models shouldmake all the corresponding entities about ﬁlm namelike jaws and jurassicp ark have closer dis-tance to entity stevenspielberg after transforma-tion via relation directorof .
the difﬁculty isthat all these entities should have different repre-sentations.
same issue happens in cases of n-to-nand n-to-1 relations.
the latter is learning andinferring relation patterns according to observedtriples, as the success of knowledge graph com-pletion heavily relies on this ability (bordes et al.,2013; sun et al., 2019).
there are various types ofrelation patterns: symmetry (e.g., issimilart o),antisymmetry (e.g., f atherof ),inverse (e.g.,p eoplebornhere and p laceof birth), compo-sition (e.g., my mother’s father is my grandpa) andso on..previous methods solve these two problemsseparately.
transh (wang et al., 2014), transr(lin et al., 2015), transd (ji et al., 2015) all fo-cus on ways to solve complex relations.
how-ever,these methods can only encode symme-try/antisymmetry relations.
the recent state-of-the-art rotate shows promising results to encodesymmetry/antisymmetry, inverse and compositionrelations.
however, complex relations remain chal-lenging to predict..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4360–4369august1–6,2021.©2021associationforcomputationallinguistics4360here we present pairre, an embedding methodthat is capable of encoding complex relations andmultiple relation patterns simultaneously.
the pro-posed model uses two vectors for relation repre-sentation.
these vectors project the correspondinghead and tail entities to euclidean space, wherethe distance between the projected vectors is mini-mized.
this provides three important beneﬁts:.
• the paired relation representations enable anadaptive adjustment of the margin in loss func-tion to ﬁt for different complex relations;.
• semantic connection among relation vectorscan be well captured, which enables the modelto encode three important relation patterns,symmetry/antisymmetry, inverse and compo-sition;.
• adding simple constraints on relation repre-sentations, pairre can encode subrelation fur-ther..besides, pairre is a highly efﬁcient model, whichcontributes to large scale datasets..we evaluate pairre on six standard knowledgegraph benchmarks.
the experiment results showpairre can achieve either state-of-the-art or highlycompetitive performance.
further analysis alsoproves that pairre can better handle complex rela-tions and encode symmetry/antisymmetry, inverse,composition and subrelation relations..2 background and notation.
given a knowledge graph that is represented asa list of fact triples, knowledge graph embeddingmethods deﬁne scoring function to measure theplausibility of these triples.
we denote a tripleby (h, r, t), where h represents head entity, r rep-resents relation and t represents tail entity.
thecolumn vectors of entities and relations are repre-sented by bold lower case letters, which belongto set e and r respectively.
we denote the set ofall triples that are true in a world as t .
fr(h, t)represents the scoring function..we take the deﬁnition of complex relations from(wang et al., 2014).
for each relation r, we com-pute average number of tails per head (tphr) andaverage number of heads per tail (hptr).
if tphr <1.5 and hptr < 1.5, r is treated as 1-to-1; if tphr >1.5 and hptr > 1.5, r is treated as a n-to-n; if tphr> 1.5 and hptr < 1.5, r is treated as 1-to-n..we focus on four important relation patterns,which includes: (1) symmetry/antisymmetry.
arelation r is symmetric if ∀e1, e2 ∈ e, (e1, r, e2) ∈t ⇐⇒ (e2, r, e1) ∈ t and is antisymmetric if(e1, r, e2) ∈ t ⇒ (e2, r, e1) /∈ t ; (2) inverse.
if∀e1, e2 ∈ e, (e1, r1, e2) ∈ t ⇐⇒ (e2, r2, e1) ∈t , then r1 and r2 are inverse relations; (3) com-position.
if ∀e1, e2, e3 ∈ e, (e1, r1, e2) ∈ t ∧(e2, r2, e3) ∈ t ⇒ (e1, r3, e3) ∈ t , then r3can be seen as the composition of r1 and r2; (4)subrelation (qu and tang, 2019).
if ∀e1, e2 ∈e, (e1, r1, e2) ∈ t ⇒ (e1, r2, e2) ∈ t , then r2can be seen as a subrelation of r1..3 related work.
distance based models.
distance based modelsmeasure plausibility of fact triples as distance be-tween entities.
transe interprets relation as a trans-lation vector r so that entities can be connected,i.e., h + r ≈ t. transe is efﬁcient, though cannotmodel symmetry relations and have difﬁculty inmodeling complex relations.
several models areproposed for improving transe to deal with com-plex relations, including transh, transr, transd,transparse (ji et al., 2016) and so on.
all thesemethods project the entities to relation speciﬁc hy-perplanes or spaces ﬁrst, then translate projectedentities with relation vectors.
by projecting entitiesto different spaces or hyperplanes, the ability tohandle complex relations is improved.
however,with the added projection parameters, these mod-els are unable to encode inverse and compositionrelations..the recent state-of-the-art, rotate, which canencode symmetry/antisymmetry, inverse and com-position relation patterns, utilizes rotation basedtranslational method in a complex space.
althoughexpressiveness for different relation patterns, com-plex relations remain challenging.
gc-ote (tanget al., 2020) proposes to improve complex relationmodeling ability of rotate by introducing graphcontext to entity embedding.
however, the calcula-tion of graph contexts for head and tail entities istime consuming, which is inefﬁcient for large scaleknowledge graphs, e.g.
ogbl-wikikg (hu et al.,2020)..another related work is se (bordes et al., 2011),which utilizes two separate relation matrices toproject head and tail entities.
as pointed out by(sun et al., 2019), this model is not able to encodesymmetry/antisymmetry, inverse and composition.
4361method.
score function.
−||h + r − t||.
transetransr −||mrh + r − mrt||rotatepairre −||h ◦ rh − t ◦ rt ||.
−||h ◦ r − t||.
performance ofcomplex relationslowhighlowhigh.
relation patternssym asym inv comp sub(cid:51)(cid:55)(cid:51)(cid:51).
(cid:51)(cid:51)(cid:51)(cid:51).
(cid:51)(cid:55)(cid:51)(cid:51).
(cid:55)(cid:51)(cid:51)(cid:51).
(cid:55)(cid:55)(cid:55)(cid:51)*.
table 1: comparison between pairre and some distance based embedding methods.
sym, asym, inv, compand sub are abbreviations for symmetry, antisymmetry, inverse and subrelation respectively.
(cid:51)* means the modelcan have the speciﬁc capability with some constraints..relations..table 1 shows comparison between our methodand some representative distance based methods.
as the table shows, our model is the most expres-sive one, with the ability to handle complex rela-tions and encode four key relation patterns..semantic matching models.
semantic match-ing models exploit similarity-based scoring func-tions, which can be divided into bilinear modelsand neural network based models.
as the modelshave been developed, such as rescal (nickelet al., 2011), distmult (yang et al., 2014), hole(nickel et al., 2016), complex (trouillon et al.,2016) and quate (zhang et al., 2019), the key rela-tion encoding abilities are enriched.
however, allthese models have the ﬂaw in encoding composi-tion relations (sun et al., 2019)..rescal, complex and simple (kazemi andpoole, 2018) are all proved to be fully expressivewhen embedding dimensions fulﬁll some require-ments (wang et al., 2018; trouillon et al., 2016;kazemi and poole, 2018).
the fully expressive-ness means these models can express all the groundtruth which exists in the data, including complexrelations.
however, these requirements are hardlyfulﬁlled in practical use.
it is proved by (wanget al., 2018) that, to achieve complete expressive-ness, the embedding dimension should be greaterthan n /32, where n is the number of entities indataset..neural networks based methods, e.g., convolu-tion neural networks (dettmers et al., 2018), graphconvolutional networks (schlichtkrull et al., 2018)show promising performances.
however, they aredifﬁcult to analyze as they work as a black box..encoding subrelation.
existing methods en-code subrelation by utilizing ﬁrst order logic rules.
one way is to augment knowledge graphs withgrounding of rules, including subrelation rules(guo et al., 2018; qu and tang, 2019).
theother way is adding constraints on entity and rela-tion representations, e.g., complex-nne-aer and.
simple+.
the second way enriches the models’ ex-pressiveness with relatively low cost.
in this paper,we show that pairre can encode subrelation withconstraints on relation representations while keep-ing the ability to encode symmetry/antisymmetry,inverse and composition relations..4 methodology.
to overcome the problem of modeling 1-to-n/n-to-1/n-to-n complex relations and enrich the ca-pabilities for different relation patterns, we pro-pose a model with paired vectors for each relation.
given a training triple (h, r, t), our model learnsvector embeddings of entities and relation in realspace.
specially, pairre takes relation embeddingas paired vectors, which is represented as [rh , rt ].
rh and rt project head entity h and tail entity tto euclidean space respectively.
the projectionoperation is the hadamard product1 between thesetwo vectors.
pairre then computes distance of thetwo projected vectors as plausibility of the triple.
we want that h ◦ rh ≈ t ◦ rt when (h, r, t)holds, while h ◦ rh should be far away from t ◦ rtotherwise.
in this paper, we take the l1-norm tomeasure the distance..in order to remove scaling freedoms, we alsoadd constraint on embeddings similar to previousdistance based models (bordes et al., 2013; wanget al., 2014; lin et al., 2015).
and the constraintis only added on entity embeddings.
we want re-lation embeddings to capture semantic connectionamong relation vectors (e.g., p eoplebornhereand p laceof birth) and complex characteristic(e.g., 1-n) easily and sufﬁciently.
for entity em-bedding, the l2-norm is set to be 1..the scoring function is deﬁned as follows:.
fr(h, t) = −||h ◦ rh − t ◦ rt ||,.
(1).
where h, rh , rt , t ∈ rd and ||h||2 = ||t||2 = 1.the model parameters are, all the entities’ embed-.
1hadamard product means entry-wise product..4362(a) transe.
(b) rotate.
(c) pairre.
figure 1: illustration of transe, rotate and pairre when the entities stay in a plane.
for pairre, all entities areon the unit circle.
the relation vectors project entities to different locations..dings, {ej}e{rj}rj=1..j=1 and all the relations’ embeddings,.
proof.
if (e1, r1, e2) ∈ t and (e2, r1, e1) ∈ t , wehave.
illustration of the proposed pairre is shown infigure 1. compared to transe/rotate, pairre en-ables an entity to have distributed representationswhen involved in different relations.
we also ﬁndthe paired relation vectors enable an adaptive ad-justment of the margin in loss function, which alle-viates the modeling problem for complex relations.
let’s take a 1-to-n relation as an example.
weset the embedding dimension to one and remove theconstraint on entity embeddings for better illustra-tion.
given triples (h, r, ?
), where the correct tailentities belong to set s = {t1, t2, ..., tn }, pairrepredicts tail entities by letting.
||h ◦ rh − ti ◦ rt || < γ,.
where γ is a ﬁxed margin for distance based em-bedding models and ti ∈ s. the value of ti shouldstay in the following range:.
.
.
ti ∈.
((h ◦ rh − γ)/rt , (h ◦ rh + γ)/rt ), if rt > 0,((h ◦ rh + γ)/rt , (h ◦ rh − γ)/rt ), if rt < 0,(−∞, +∞), otherwise..the above analysis shows pairre can adjust thevalue of rt to ﬁt the entities in s. the larger thesize of s, the smaller the absolute value rt .
whilemodels like transe or rotate have a ﬁxed marginfor all complex relation types.
when the size of sis large enough, these models will be difﬁcult toﬁt the data.
for n-to-1 relations, pairre can alsoadjust the value of rh adaptively to ﬁt the data..meanwhile, not adding a relation speciﬁc trans-lational vector enables the model to encode severalkey relation patterns.
we show these capabilitiesbelow..proposition 1. pairre can encode symme-try/antisymmetry relation pattern..e1 ◦ rh.
1 = e2 ◦ rt.
1 ∧ e2 ◦ rh.
if (e1, r1, e2) ∈ t and (e2, r1, e1) /∈ t , we have.
e1 ◦ rh.
1 = e2 ◦ rt.
1 ∧ e2 ◦ rh.
1 = e1 ◦ rt122= rt1.
⇒ rh1.
1 (cid:54)= e1 ◦ rt122(cid:54)= rt1.
⇒ rh1.
(2).
(3).
proposition 2. pairre can encode inverse relationpattern..proof.
if (e1, r1, e2) ∈ t and (e2, r2, e1) ∈ t , wehave.
e1 ◦ rh.
1 = e2 ◦ rt.
1 ∧ e2 ◦ rh1 ◦ rh⇒ rh.
2 = e1 ◦ rt21 ◦ rt2 = rt2.
(4).
proposition 3. pairre can encode compositionrelation pattern..proof.
if (e1, r1, e2) ∈ t , (e2, r2, e3) ∈ t and(e1, r3, e3) ∈ t , we have.
e1 ◦ rh.
1 = e2 ◦ rt.
1 ∧ e2 ◦ rhe1 ◦ rh3 = rh.
2 = e3 ◦ rt2 ∧3 = e3 ◦ rt32 ◦ rt1 ◦ rh3.
2 ◦ rh.
(5).
⇒ rt.
1 ◦ rt.
moreover, with some constraint, pairre canalso encode subrelations.
for a subrelation pair,∀h, t ∈ e : (h, r1, t) → (h, r2, t), it suggeststriple (h, r2, t) should be always more plausiblethan triple (h, r1, t).
in order to encode this pat-tern, pairre should have the capability to enforcefr2(h, r2, t) ≥ fr1(h, r1, t)..4363proposition 4. pairre can encode subrelation re-lation pattern using inequality constraint..proof.
assume a subrelation pair r1 and r2 that∀h, t ∈ e: (h, r1, t)→(h, r2, t).
we impose thefollowing constraints:.
datasetogbl-wikikg2ogbl-biokgfb15kfb15k-237db100ksports.
|r|5355113k2374704.
|e|2,500k94k15k15k100k1039.train16,109k4,763k483k272k598k1312.valid test598k429k163k163k59k50k20k18k50k50k307-.
=.
= αi, |αi| ≤ 1,.
(6).
table 2: number of entities, relations, and observedtriples in each split for the six benchmarks..rh2,irh1,i.
rt2,irt1,i.
where α ∈ rd.
then we can get.
fr2(h, t) − fr1(h, t)1 − t ◦ rt= ||h ◦ rh1 − t ◦ rt= ||h ◦ rh≥ 0..1 || − ||h ◦ rh1 || − ||α ◦ (h ◦ rh.
2 − t ◦ rt.
2 ||1 − t ◦ rt.
1 )||.
(7)when the constraints are satisﬁed, pairre forcestriple (h, r2, t) to be more plausible than triple(h, r1, t)..optimization.
to optimize the model, we uti-lize the self-adversarial negative sampling loss(sun et al., 2019) as objective for training:.
l = − log σ(γ − fr(h, t)).
−.
p(h.i, r, t.i) log σ(fr(h.i, t.i) − γ),.
(cid:48).
(cid:48).
(cid:48).
(cid:48).
(8).
n(cid:88).
i=1.
where γ is a ﬁxed margin and σ is the sigmoidfunction.
(h(cid:48)i) is the ith negative triple andi, r, t(cid:48)p(h(cid:48)i) represents the weight of this negativesample.
p(h(cid:48)i) is deﬁned as follows:.
i, r, t(cid:48).
i, r, t(cid:48).
(cid:48).
(cid:48).
p((h.i, r, t.i)|(h, r, t)) =.
exp fr(h(cid:48)i, t(cid:48)i)j, t(cid:48)j exp fr(h(cid:48)j).
..(cid:80).
(9).
5 experimental results.
5.1 experimental setup.
we evaluate the proposed method on link predictiontasks.
at ﬁrst, we validate the ability to deal withcomplex relations and symmetry/antisymmetry, in-verse and composition relations on four bench-marks.
then we validate our model on two sub-relation speciﬁc benchmarks.
statistics of thesebenchmarks are shown in table 2..ogbl-wikikg22 (hu et al., 2020) is extractedfrom wikidata knowledge base (vrandeˇci´c andkr¨otzsch, 2014).
one of the main challengesfor this dataset is complex relations.
ogbl-biokg.
(hu et al., 2020) contains data from a large num-ber of biomedical data repositories.
one of themain challenges for this dataset is symmetry rela-tions.
fb15k (bordes et al., 2013) contains triplesfrom freebase.
the main relation patterns are in-verse and symmetry/antisymmetry.
fb15k-237(toutanova and chen, 2015) is a subset of fb15k,with inverse relations removed.
the main rela-tion patterns are antisymmetry and composition.
db100k (ding et al., 2018) is a subset of dbpedia.
the main relation patterns are composition, inverseand subrelation.
sports (wang et al., 2015) is asubset of nell (mitchell et al., 2018).
the mainrelation patterns are antisymmetry and subrelation.
evaluation protocol.
following the state-of-the-art methods, we measure the quality of theranking of each test triple among all possible headentity and tail entity substitutions: (h(cid:48), r , t) and(h, r, t(cid:48), ∀t(cid:48) ∈ e. three evaluation metrics,including mean rank(mr), mean reciprocal rank(mrr) and hit ratio with cut-off values n = 1, 3,10, are utilized.
mr measures the average rankof all correct entities.
mrr is the average inverserank for correct entities with higher value repre-senting better performance.
hit@n measures thepercentage of correct entities in the top n predic-tions.
the rankings of triples are computed afterremoving all the other observed triples that appearin either training, validation or test set.
for experi-ments on ogbl-wikikg2 and ogbl-biokg, we followthe evaluation protocol of these two benchmarks(hu et al., 2020)..), ∀h(cid:48).
implementation.
we utilize the ofﬁcial imple-mentations of benchmarks ogbl-wikikg2 and ogbl-biokg (hu et al., 2020) for the corresponding exper-iments3.
only the hypeparameter γ and embeddingdimension are tuned.
the other settings are keptthe same with baselines.
for the rest experiments,we implement our models based on the implemen-tation of rotate (sun et al., 2019).
all hypeparam-.
2ogbl-wikikg2 ﬁxes a bug in test/validation negative sam-.
ples from original ogbl-wikikg..3our.
code.
is.
available.
at:.
https://github.com/alipay/knowledgegraphembeddingsviapairedrelationvectors pairre.
4364-modeltransedistmultcomplexrotatepairretransedistmultcomplexrotatepairre.
ogbl-wikikg2.
ogbl-biokg.
#dim1001005050100500†500†250†250†200.test mrr0.2622 ± 0.00450.3447 ± 0.00820.3804 ± 0.00220.2530 ± 0.00340.4849 ± 0.00290.4256 ± 0.00300.3729 ± 0.00450.4027 ± 0.00270.4332 ± 0.00250.5208 ± 0.0027.valid mrr0.2465 ± 0.00200.3150 ± 0.00880.3534 ± 0.00520.2250 ± 0.00350.4941 ± 0.00350.4272 ± 0.00300.3506 ± 0.00420.3759 ± 0.00160.4353 ± 0.00280.5423 ± 0.0020.
#dim-----20002000100010002000.test mrr-----0.7452 ± 0.00040.8043 ± 0.00030.8095 ± 0.00070.7989 ± 0.00040.8164 ± 0.0005.valid mrr-----0.7456 ± 0.00030.8055 ± 0.00030.8105 ± 0.00010.7997 ± 0.00020.8172 ± 0.0005.table 3: link prediction results on ogbl-wikikg2 and ogbl-biokg.
best results are in bold.
all the results exceptpairre are from (hu et al., 2020).
† requires a gpu with 48gb memory.
pairre runs on a gpu with 16gbmemory..-modeltranse†distmult(cid:51)holeconvecomplexsimplerotateseekotegc-otepairre.
mr-42-51--40---37.7.mrr0.4630.7980.5240.6570.6920.7270.7970.825--0.811.fb15khit@100.7490.8930.7390.8310.8400.8380.8840.886--0.896.hit@30.578-0.7590.7230.7590.7730.8300.841--0.845.hit@10.297-0.5990.5580.5990.6600.7460.792--0.765.mr357254-244339-177---160.mrr0.2940.241-0.3250.247-0.338-0.3510.3610.351.fb15k-237hit@100.4650.419-0.5010.428-0.533-0.5370.5500.544.hit@3-0.263-0.3560.275-0.375-0.3880.3960.387.hit@1-0.155-0.2370.158-0.241-0.2580.2670.256.
±0.4979 ±0.00077 ±0.00071 ±0.0011 ±0.0012 ±0.9949 ±0.00066 ±0.00093 ±0.00079 ±0.00097.
table 4: link prediction results on fb15k and fb15k-237.
results of [†] are taken from (nickel et al., 2016);results of [(cid:51)] are taken from (kadlec et al., 2017).
other results are taken from the corresponding papers.
gc-oteadds graph context to ote (tang et al., 2020)..subrelation(h, coachesteam, t) → (h, personbelongstoorganization, t)(h, athleteledsportsteam, t) → (h, atheleteplaysforteam, t).
table 5: the added subrelation rules for sports dataset..modelsimplesimple+pairrepairre+rule.
mrr0.2300.4040.468 ± 0.0030.475 ± 0.003.hit@10.1840.3490.416 ± 0.0050.432 ± 0.004.modeltransedistmultholecomplexseekcomplex-nnecomplex-nne-aerpairre.
mrr0.1110.2330.2600.2420.3380.2980.3060.412.hit@100.2700.4480.4110.4400.4670.4260.4180.600.hit@30.1640.3010.3090.3120.3700.3300.3340.472.hit@10.0160.1150.1820.1260.2680.2290.2440.309.
±0.0015 ±0.0006 ±0.0015 ±0.0027.
pairre+rule.
0.419.
0.599.
0.475.
0.321.
±0.0010 ±0.0008 ±0.0008 ±0.0016.
table 6: link prediction results on sports dataset.
other results are taken from (fatemi et al., 2019)..table 7: link prediction results on db100k.
all theresults are taken from the corresponding papers..eters except γ and embedding dimension are keptthe same with rotate..5.2 main results.
comparisons for ogbl-wikikg2 and ogbl-biokg areshown in table 3. on these two large scale datasets,pairre achieves state-of-the-art performances.
forogbl-wikikg2 dataset, pairre performs best onboth limited embedding dimension and increasedembedding dimension.
with the same number ofparameters to complex (dimension 100), pairre.
improves test mrr close to 10%.
with increaseddimension, all models are able to achieve highermrr on validation and test sets.
due to the lim-itation of hardware, we only increase embeddingdimension to 200 for pairre.
pairre also outper-forms all baselines and improves test mrr 8.7%.
based on performances of baselines, the perfor-mance of pairre may be improved further ifembedding dimension is increased to 500. un-der the same experiment setting and the same num-ber of parameters, pairre also outperforms allbaselines on ogbl-biokg dataset.
it improves test.
4365mrr by 0.69%, which proves the superior abilityto encode symmetry relations..changed to:.
comparisons for fb15k and fb15k-237 datasetsare shown in table 4. since our model shares thesame hyper-parameter settings and implementationwith rotate, comparing with this state-of-the-artmodel is fair to show the advantage and disadvan-tage of the proposed model.
besides, the compar-isons also include several leading methods, suchas transe (bordes et al., 2013), distmult (yanget al., 2014), hole (nickel et al., 2016), conve(dettmers et al., 2018), complex (trouillon et al.,2016), simple (kazemi and poole, 2018), seek(xu et al., 2020) and ote (tang et al., 2020).
com-pared with rotate, pairre shows clear improve-ments on fb15k and fb15k-237 for all evaluationmetrics.
for mrr metric, the improvements are1.4% and 1.3% respectively.
compared with theother leading methods, pairre also shows highlycompetitive performances.
all these comparisonsprove the effectiveness of pairre to encode inverseand composition relations..5.3 further experiments on subrelation.
we further compare our method with two ofthe leading methods complex-nne-aer andsimple+, which focus on encoding subrelation.
these two methods add subrelation rules to seman-tic matching models.
we utilize these rules as con-straints on relation representations for pairre.
twoways are validated.
we ﬁrst test the performance ofweight tying for subrelation rules on sports dataset.
the rules (r1−→r2) are added as follows:.
rh2 = rh2 = rtrt.
1 ◦ cosine(θ),1 ◦ cosine(θ),.
(10).
where θ ∈ rd.
the added rules are shown intable 5. the experiments results in table 6 showeffectiveness of the proposed method..weight tying on relation representation is a wayto incorporate hard rules.
the soft rules can alsobe incorporated into pairre by approximate en-tailment constraints on relation representations.
inthis section, we add the same rules from complex-nne-aer, which includes subrelation and inverseλ−→ r2 the approximaterules.
we denote by r1entailment between relations r1 and r2, with con-ﬁdence level λ. the objective for training is then.
lrule = l + µ.
(cid:88).
λ1t (rh.
1 ◦ rt.
2 − rt.
1 ◦ rh.
2 )2.
(cid:88).
τsubrelationλ1t (rh.
+ µ.τinverse.
1 ◦ rh.
2 − rt.
1 ◦ rt.
2 )2,.
(11)where l is calculated from equation 8, µ isloss weight for added constraints, τsubrelation andτinverse are the sets of subrelation rules and inverserules respectively.
following (ding et al., 2018),we take the corresponding two relations from sub-relation rules as equivalence.
because τsubrelationcontains both rule r1→r2 and rule r2→r1..we validate our method on db100k dataset.
theresults are shown in table 7. we can see pairreoutperforms the recent state-of-the-art seek andcomplex based models with large margins on allevaluation metrics.
with added constraints, theperformance of pairre is improved further.
theimprovements for the added rules are 0.7%, 1.2%for mrr and hit@1 metrics respectively..5.4 model analysis.
analysis on complex relations.
we analyze the performances of pairre for com-plex relations.
the results of pairre on differentrelation categories on fb15k and ogbl-wikikg2 aresummarized into table 8. we can see pairre per-forms quite well on n-to-n and n-to-1 relations.
it has a signiﬁcant lead over baselines.
we alsonotice that performance of 1-to-n relations on ogbl-wikikg2 dataset is not as strong as the other relationcategories.
one of the reasons is that only 2.2% oftest triples belong to the 1-to-n relation category.
in order to further test the performance of pairedrelation vectors, we change the relation vector inrotate to paired vectors.
in the modiﬁed ro-tate model, both head and tail entities are ro-tated with different angles based on the paired.
figure 2: performance comparison between rotateand rotate+pairrelation on ogbl-wikikg2 dataset..4366-modelkge2e kl(he et al., 2015)transecomplexrotatepairre.
fb15k(hits@10)1-to-n n-to-1 n-to-n 1-to-10.8130.8220.8960.8400.899.
0.8020.7660.8220.7820.872.
0.7150.8950.9020.9080.940.
-0.0740.3940.1640.262.
1-to-10.9250.8870.9390.9230.785.ogbl-wikikg2(hits@10).
1-to-n n-to-1 n-to-n-0.4000.4830.4310.594.
-0.2200.5040.2610.587.
-0.0630.2780.1440.270.table 8: experimental results on fb15k and ogbl-wikikg2 by relation category.
results on fb15k are taken fromrotate (sun et al., 2019).
the embedding dimensions for models on ogbl-wikikg2 are same to the experiments intable 3, which is 100 for real space models and 50 for complex value based models..(a) r1.
(b) rh1.
2.
2.
− rt1.
(c) r2.
(d) rh2.
2.
2.
− rt2.
(e) r3.
(f) rh.
2 ◦ rh.
3 − rt.
2 ◦ rt3.
(g) r4.
(h) r5.
(i) r6.
(j) rh.
4 ◦ rh.
5 ◦ rt.
6 − rt.
4 ◦ rt.
5 ◦ rh.
6.relation /broadcast/tv station/owner..figure 3: histograms of relation embeddings for different relation patterns.
isr4capital relationship/capital.
base/areas/schema/administrative area/capital..r2relation /broadcast/tv station owner/tv stations.
/location/administrative division/capital/location/administrative division-relation.
relation /location/hud county place/place..r1 is relation spouse..relation.
r5.
r6.
r3.
is.
is.
is.
is.
relation vectors.
this model can also be seenas complex value based pairre.
we name thismodel as rotate+pairrelation.
the experimentresults are shown in figure 2. with the sameembedding dimension (50 in the experiments), ro-tate+pairrelation improves performance of rotatewith 20.8%, 27.5%, 14.4% and 39.1% on 1-to-1,1-to-n, n-to-1 and n-to-n relation categories re-spectively.
these signiﬁcant improvements provethe superior ability of paired relation vectors tohandle complex relations..analysis on relation patterns.
to further verify the learned relation patterns, we vi-sualize some examples.
histograms of the learnedrelation embeddings are shown in figure 3 ..symmetry/antisymmetry.
figure 3a shows asymmetry relation spouse from db100k.
the em-bedding dimension is 500. for pairre, symmetryrelation pattern can be encoded when embeddingr satisﬁes rh 2 = rt 2.
figure 3b shows most ofthe paired elements in rh and rt have the sameabsolute value.
figure 3c shows a antisymmetry re-lation tv station owner, where most of the paired.
4367inverse..3c and figure.
elements do not have the same absolute value asshown in figure 3d.
figure.
3e showan example of inverse relations from fb15k.
3f shows theseas the histogram in figuretwo inverse relations tv station owner (r2) andtv station owner tv stations (r3) close to sat-3 ◦ rtisfy rh2 ..2 = rt.
3 ◦ rh.
composition.
figures 3g, 3h, 3i show an ex-ample of composition relation pattern from fb15k,where the third relation r6 can be seen as the com-position of the ﬁrst relation r4 and the second rela-tion r5.
as figure 3j shows these three relations5 ◦ rtclose to satisfy rh.
5 ◦ rh6 ..4 ◦ rh.
6 − rt.
4 ◦ rt.
6 conclusion.
to better handle complex relations and tackle morerelation patterns, we proposed pairre, which rep-resents each relation with paired vectors.
with aslight increase in complexity, pairre can solve theaforementioned two problems efﬁciently.
beyondthe symmetry/antisymmetry, inverse and composi-tion relations, pairre can further encode subrela-tion with simple constraint on relation representa-tions.
on large scale benchmark ogbl-wikikg2 anogbl-biokg, pairre outperforms all the state-of-the-art baselines.
experiments on other well designedbenchmarks also demonstrate the effectiveness ofthe focused key abilities..references.
jonathan berant, andrew chou, roy frostig, and percyliang.
2013. semantic parsing on freebase fromquestion-answer pairs.
in proceedings of the 2013conference on empirical methods in natural lan-guage processing, pages 1533–1544, seattle, wash-ington, usa.
association for computational lin-guistics..kurt bollacker, colin evans, praveen paritosh, timsturge, and jamie taylor.
2008. freebase: a collab-oratively created graph database for structuring hu-man knowledge.
in proceedings of the 2008 acmsigmod international conference on managementof data, pages 1247–1250.
acm..antoine bordes, nicolas usunier, alberto garcia-duran,jason weston, and oksana yakhnenko.
2013. translating embeddings for modeling multi-relational data.
in advances in neural informationprocessing systems, pages 2787–2795..antoine bordes, jason weston, and nicolas usunier.
2014. open question answering with weakly super-vised embedding models.
in joint european confer-ence on machine learning and knowledge discoveryin databases, pages 165–180.
springer..tim dettmers, pasquale minervini, pontus stenetorp,convolutional 2din thirty-second.
and sebastian riedel.
2018.knowledge graph embeddings.
aaai conference on artiﬁcial intelligence..boyang ding, quan wang, bin wang, and li guo.
improving knowledge graph embedding us-2018.theing simple constraints.
56th annual meeting of the association for com-putational linguistics (volume 1: long papers),pages 110–121, melbourne, australia.
associationfor computational linguistics..in proceedings of.
bahare fatemi, siamak ravanbakhsh, and david poole.
2019. improved knowledge graph embedding usingbackground taxonomic information.
in proceedingsof the aaai conference on artiﬁcial intelligence,volume 33, pages 3526–3533..shu guo, quan wang, lihong wang, bin wang, andli guo.
2018. knowledge graph embedding withiterative guidance from soft rules.
in thirty-secondaaai conference on artiﬁcial intelligence..shizhu he, kang liu, guoliang ji, and jun zhao.
2015. learning to represent knowledge graphs within proceedings of the 24thgaussian embedding.
acm international on conference on informationand knowledge management, pages 623–632..weihua hu, matthias fey, marinka zitnik, yuxiaodong, hongyu ren, bowen liu, michele catasta,and jure leskovec.
2020. open graph benchmark:arxivdatasets for machine learning on graphs.
preprint arxiv:2005.00687..guoliang ji, shizhu he, liheng xu, kang liu, andjun zhao.
2015. knowledge graph embedding viain proceedings of thedynamic mapping matrix.
53rd annual meeting of the association for compu-tational linguistics and the 7th international jointconference on natural language processing (vol-ume 1: long papers), pages 687–696..guoliang ji, kang liu, shizhu he, and jun zhao.
2016.knowledge graph completion with adaptive sparsein aaai, volume 16, pages 985–transfer matrix.
991..rudolf kadlec, ondrej bajgar, and jan kleindienst.
2017. knowledge base completion: baselines strikeback.
in proceedings of the 2nd workshop on rep-resentation learning for nlp, pages 69–74, vancou-ver, canada.
association for computational linguis-tics..antoine bordes, jason weston, ronan collobert, andyoshua bengio.
2011. learning structured embed-dings of knowledge bases.
in conference on artiﬁ-cial intelligence, conf..seyed mehran kazemi and david poole.
2018. simpleembedding for link prediction in knowledge graphs.
in advances in neural information processing sys-tems, pages 4284–4295..4368th´eo trouillon, johannes welbl, sebastian riedel, ´ericgaussier, and guillaume bouchard.
2016. com-in in-plex embeddings for simple link prediction.
ternational conference on machine learning, pages2071–2080..denny vrandeˇci´c and markus kr¨otzsch.
2014. wiki-data: a free collaborative knowledgebase.
commu-nications of the acm, 57(10):78–85..quan wang, bin wang, and li guo.
2015. knowl-edge base completion using embeddings and rules.
in twenty-fourth international joint conference onartiﬁcial intelligence..yanjie wang, rainer gemulla, and hui li.
2018. onmulti-relational link prediction with bilinear models..zhen wang, jianwen zhang, jianlin feng, and zhengchen.
2014. knowledge graph embedding by trans-lating on hyperplanes.
in twenty-eighth aaai con-ference on artiﬁcial intelligence..wentao xu, shun zheng, liang he, bin shao, jian yin,and tie-yan liu.
2020. seek: segmented embed-in proceedings of theding of knowledge graphs.
58th annual meeting of the association for compu-tational linguistics, pages 3888–3897, online.
as-sociation for computational linguistics..bishan yang, wen-tau yih, xiaodong he, jianfenggao, and li deng.
2014. embedding entities andrelations for learning and inference in knowledgebases.
arxiv preprint arxiv:1412.6575..shuai zhang, yi tay, lina yao, and qi liu.
2019.arxiv.
quaternion knowledge graph embedding.
preprint arxiv:1904.10281..zhicheng zheng, xiance si, fangtao li, edward ychang, and xiaoyan zhu.
2012. entity disambigua-tion with freebase.
in proceedings of the the 2012ieee/wic/acm international joint conferences onweb intelligence and intelligent agent technology-volume 01, pages 82–89..jens lehmann, robert isele, max jakob, anja jentzsch,dimitris kontokostas, pablo n mendes, sebastianhellmann, mohamed morsey, patrick van kleef,s¨oren auer, et al.
2015. dbpedia–a large-scale, mul-tilingual knowledge base extracted from wikipedia.
semantic web, 6(2):167–195..yankai lin, zhiyuan liu, maosong sun, yang liu,and xuan zhu.
2015. learning entity and relationembeddings for knowledge graph completion.
intwenty-ninth aaai conference on artiﬁcial intelli-gence..george a miller.
1995. wordnet: a lexical database forenglish.
communications of the acm, 38(11):39–41..tom mitchell, william cohen, estevam hruschka,partha talukdar, bishan yang, justin betteridge, an-drew carlson, bhanava dalvi, matt gardner, bryankisiel, et al.
2018. never-ending learning.
commu-nications of the acm, 61(5):103–115..maximilian nickel, lorenzo rosasco, and tomasopoggio.
2016. holographic embeddings of knowl-edge graphs.
in thirtieth aaai conference on artiﬁ-cial intelligence..maximilian nickel, volker tresp, and hans-peterkriegel.
2011. a three-way model for collectivein icml, vol-learning on multi-relational data.
ume 11, pages 809–816..meng qu and jian tang.
2019. probabilistic logic neu-ral networks for reasoning.
in advances in neuralinformation processing systems, pages 7710–7720..michael schlichtkrull, thomas n kipf, peter bloem,rianne van den berg, ivan titov, and max welling.
2018. modeling relational data with graph convolu-tional networks.
in european semantic web confer-ence, pages 593–607.
springer..fabian m suchanek, gjergji kasneci, and gerhardweikum.
2007. yago: a core of semantic knowledge.
in proceedings of the 16th international conferenceon world wide web, pages 697–706.
acm..zhiqing sun, zhi-hong deng, jian-yun nie, and jiantang.
2019. rotate: knowledge graph embeddingby relational rotation in complex space.
in interna-tional conference on learning representations..yun tang, jing huang, guangtao wang, xiaodong he,and bowen zhou.
2020. orthogonal relation trans-forms with graph context modeling for knowledgein proceedings of the 58th an-graph embedding.
nual meeting of the association for computationallinguistics, pages 2713–2722, online.
associationfor computational linguistics..kristina toutanova and danqi chen.
2015. observedversus latent features for knowledge base and textin proceedings of the 3rd workshop oninference.
continuous vector space models and their compo-sitionality, pages 57–66..4369