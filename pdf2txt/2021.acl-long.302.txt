w-rst: towards a weighted rst-style discourse framework.
patrick huber∗, wen xiao∗, giuseppe careninidepartment of computer scienceuniversity of british columbiavancouver, bc, canada, v6t 1z4{huberpat, xiaowen3, carenini}@cs.ubc.ca.
abstract.
aiming for a better integration of data-drivenand linguistically-inspired approaches, we ex-plore whether rst nuclearity, assigning a bi-nary assessment of importance between textsegments, can be replaced by automaticallygenerated, real-valued scores, in what we calla weighted-rst framework.
in particular, weﬁnd that weighted discourse trees from aux-iliary tasks can beneﬁt key nlp downstreamapplications compared to nuclearity-centeredapproaches.
we further show that real-valuedimportance distributions partially and interest-ingly align with the assessment and uncer-tainty of human annotators..1.introduction.
ideally, research in natural language processing(nlp) should balance and integrate ﬁndings frommachine learning approaches with insights and the-ories from linguistics.
with the enormous successof data-driven approaches over the last decades,this balance has arguably and excessively shifted,with linguistic theories playing a less and less crit-ical role.
even more importantly, there are onlylittle attempts made to improve such theories inlight of recent empirical results..in the context of discourse, two main theorieshave emerged in the past: the rhetorical structuretheory (rst) (carlson et al., 2002) and pdtb(prasad et al., 2008).
in this paper, we focus onrst, exploring whether the underlying theory canbe reﬁned in a data-driven manner..in general, rst postulates a complete discoursetree for a given document.
to obtain this formalrepresentation as a projective consituency tree, agiven document is ﬁrst separated into so called el-ementary discourse units (or short edus), repre-senting clause-like sentence fragments of the input.
∗equal contribution..document.
afterwards, the discourse tree is built byhierarchically aggregating edus into larger con-stituents annotated with an importance indicator(in rst called nuclearity) and a relation holdingbetween siblings in the aggregation.
the nuclear-ity attribute in rst thereby assigns each sub-treeeither a nucleus-attribute, indicating central impor-tance of the sub-tree in the context of the document,or a satellite-attribute, categorizing the sub-tree asof peripheral importance.
the relation attribute fur-ther characterizes the connection between sub-trees(e.g.
elaboration, cause, contradiction)..one central requirement of the rst discoursetheory, as for all linguistic theories, is that a trainedhuman should be able to specify and interpret thediscourse representations.
while this is a clearadvantage when trying to generate explainableoutcomes, it also introduces problematic, human-centered simpliﬁcations; the most radical of whichis arguably the nuclearity attribute, indicating theimportance among siblings..intuitively, such a coarse (binary) importanceassessment does not allow to represent nuanced dif-ferences regarding sub-tree importance, which canpotentially be critical for downstream tasks.
forinstance, the importance of two nuclei siblings israther intuitive to interpret.
however, having sib-lings annotated as “nucleus-satellite” or “satellite-nucleus” leaves the question on how much moreimportant the nucleus sub-tree is compared to thesatellite, as shown in figure 1. in general, it isunclear (and unlikely) that the actual importancedistributions between siblings with the same nucle-arity attribution are consistent..based on this observation, we investigate thepotential of replacing the binary nuclearity assess-ment postulated by rst with automatically gen-erated, real-valued importance scores in a new,weighted-rst framework.
in contrast with pre-vious work that has assumed rst and developed.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3908–3918august1–6,2021.©2021associationforcomputationallinguistics3908attribute, assigned to every internal node of the dis-course tree, encoding relative importance betweenthe nodes’ sub-trees, with the nucleus expressingprimary importance and a satellite signifying sup-plementary sub-trees.
(3) a relation attribute forevery internal node describing the relationship be-tween the sub-trees of a node (e.g., contrast, evi-dence, contradiction)..arguably, the weakest aspect of an rst repre-sentation is the nuclearity assessment, which makesa too coarse differentiation between primary andsecondary importance of sub-trees.
however, de-spite its binary assignment of importance and eventhough the nuclearity attribute is only one of threecomponents of an rst tree, it has major implica-tions for many downstream tasks, as already shownearly on by marcu (1999), using the nuclearityattribute as the key signal in extractive summariza-tion.
further work in sentiment analysis (bhatiaet al., 2015) also showed the importance of nu-clearity for the task by ﬁrst converting the con-stituency tree into a dependency tree (more alignedwith the nuclearity attribute) and then using thattree to predict sentiment more accurately.
bothof these results indicate that nuclearity, even inthe coarse rst version, already contains valuableinformation.
hence, we believe that this coarse-grained classiﬁcation is reasonable when manuallyannotating discourse, but see it as a major pointof improvement, if a more ﬁne-grained assessmentcould be correctly assigned.
we therefore explorethe potential of assigning a weighted nuclearityattribute in this paper..while plenty of studies have highlighted theimportant role of discourse for real-world down-stream tasks, including summarization, (geraniet al., 2014; xu et al., 2020; xiao et al., 2020), sen-timent analysis (bhatia et al., 2015; hogenboomet al., 2015; nejat et al., 2017) and text classiﬁ-cation (ji and smith, 2017), more critical to ourapproach is very recent work exploring such con-nection in the opposite direction.
in huber andcarenini (2020b), we exploit sentiment related in-formation to generate “silver-standard” nuclearityannotated discourse trees, showing their potentialon the domain-transfer discourse parsing task.
cru-cially for our purposes, this approach internallygenerates real-valued importance-weights for trees..for the task of extractive summarization, we fol-low our intuition given in xiao et al.
(2020) andxiao et al.
(2021), exploiting the connection be-.
figure 1: document wsj 0639 from the rst-dt cor-pus with inconsistent importance differences betweenn-s attributions.
(the top-level satellite is clearly morecentral to the overall context than the lower-level satel-lite.
however, both are similarly assigned the satelliteattribution by at least one annotator).
top relation: an-notator 1: n-s, annotator 2: n-n..computational models of discourse by simply ap-plying machine learning methods to rst annotatedtreebanks (ji and eisenstein, 2014; feng and hirst,2014; joty et al., 2015; li et al., 2016; wang et al.,2017; yu et al., 2018), we rely on very recent empir-ical studies showing that weighted “silver-standard”discourse trees can be inferred from auxiliary taskssuch as sentiment analysis (huber and carenini,2020b) and summarization (xiao et al., 2021)..in our evaluation, we assess both, computationalbeneﬁts and linguistic insights.
in particular, weﬁnd that automatically generated, weighted dis-course trees can beneﬁt key nlp downstream tasks.
we further show that real-valued importance scores(at least partially) align with human annotationsand can interestingly also capture uncertainty inhuman annotators, implying some alignment of theimportance distributions with linguistic ambiguity..2 related work.
first introduced by mann and thompson (1988),the rhetorical structure theory (rst) has beenone of the primary guiding theories for discourseanalysis (carlson et al., 2002; subba and di eu-genio, 2009; zeldes, 2017; gessler et al., 2019;liu and zeldes, 2019), discourse parsing (ji andeisenstein, 2014; feng and hirst, 2014; joty et al.,2015; li et al., 2016; wang et al., 2017; yu et al.,2018), and text planning (torrance, 2015; gatt andkrahmer, 2018; guz and carenini, 2020).
the rstframework thereby comprehensively describes theorganization of a document, guided by the author’scommunicative goals, encompassing three compo-nents: (1) a projective constituency tree structure,often referred to as the tree span.
(2) a nuclearity.
3909figure 2: three phases of our approach to generate weighted rst-style discourse trees.
left and center steps aredescribed in section 3, right component is described in section 4.
† = as in huber and carenini (2020b), ‡ = as inmarcu (1999), ∗ = sentiment prediction component is a linear combination, mapping the aggregated embeddingto the sentiment output.
the linear combination has been previously learned on the training portion of the dataset..tween summarization and discourse.
in particular,in xiao et al.
(2021), we demonstrate that the self-attention matrix learned during the training of atransformer-based summarizer captures valid as-pects of constituency and dependency discoursetrees..to summarize, building on our previous work oncreating discourse trees through distant supervision,we take a ﬁrst step towards generating weighteddiscourse trees from the sentiment analysis andsummarization tasks..3 w-rst treebank generation.
given the intuition from above, we combine infor-mation from machine learning approaches withinsights from linguistics, replacing the human-centered nuclearity assignment with real-valuedweights obtained from the sentiment analysis andsummarization tasks1.
an overview of the processto generate weighted rst-style discourse trees isshown in figure 2, containing the training phase(left) and the w-rst discourse inference phase(center) described here.
the w-rst discourse eval-uation (right), is covered in section 4..3.1 weighted trees from sentiment.
to generate weighted discourse trees from senti-ment, we slightly modify the publicly availablecode2 presented in huber and carenini (2020b) byremoving the nuclearity discretization component.
an overview of our method is shown in fig-ure 2 (top), while a detailed view is presented inthe left and center parts of figure 3. first (on theleft), we train the multiple instance learning (mil).
1please note that both tasks use binarized discourse trees,.
as commonly used in computational models of rst..2code available at https://github.com/nlpat/.
mega-dt.
model proposed by angelidis and lapata (2018)on a corpus with document-level sentiment gold-labels, internally annotating each input-unit (in ourcase edus) with a sentiment- and attention-score.
after the mil model is trained (center), a tuple(si, ai) containing a sentiment score si and an at-tention ai is extracted for each edu i. based onthese tuples representing leaf nodes, the cky algo-rithm (jurafsky and martin, 2014) is applied to ﬁndthe tree structure to best align with the overall doc-ument sentiment, through a bottom-up aggregationapproach deﬁned as3:.
sp =.
sl ∗ al + sr ∗ aral + ar.
ap =.
al + ar2.with nodes l and r as the left and right child-nodes of p respectively.
the attention scores(al, ar) are here interpreted as the importanceweights for the respective sub-trees (wl = al/(al +ar) and wr = ar/(al + ar)), resulting in a com-plete, normalized and weighted discourse structureas required for w-rst.
we call the discourse tree-bank generated with this approach w-rst-sent..3.2 weighted trees from summarization.
in order to derive weighted discourse trees from asummarization model we follow xiao et al.
(2021)4,generating weighted discourse trees from the self-attention matrices of a transformer-based summa-rization model.
an overview of our method isshown in figure 2 (bottom), while a detailed viewis presented in the left and center parts of figure 4.we start by training a transformer-based extrac-tive summarization model (left), containing three.
3equations taken from huber and carenini (2020b)4codeat.
https://github.com/.
available.
wendy-xiao/summ_guided_disco_parser.
3910figure 3: three phases of our approach.
left/center: detailed view into the generation of weighted rst-stylediscourse trees using the sentiment analysis downstream task.
right: sentiment discourse application evaluation.
figure 4: three phases of our approach.
left/center: detailed view into the generation of weighted rst-stylediscourse trees using the summarization downstream task.
right: summarization discourse application evaluation.
components: (1) a pre-trained bert edu en-coder generating edu embeddings, (2) a standardtransformer architecture as proposed in vaswaniet al.
(2017) and (3) a ﬁnal classiﬁer, mapping theoutputs of the transformer to a probability score foreach edu, indicating whether the edu should bepart of the extractive summary..with the trained transformer model, we thenextract the self-attention matrix a and build a dis-course tree in bottom-up fashion (as shown in thecenter of figure 4).
speciﬁcally, the self-attentionmatrix a reﬂects the relationships between unitsin the document, where entry aij measures howmuch the i-th edu relies on the j-th edu.
giventhis information, we generate an unlabeled con-stituency tree using the cky algorithm (jurafskyand martin, 2014), optimizing the overall tree score,as previously done in xiao et al.
(2021)..in terms of weight-assignment, given a sub-treespanning edus i to j, split into child-constituentsat edu k, then max(ai:k,(k+1):j), representing themaximal attention value that any edu in the leftconstituent is paying to an edu in the right child-constituent, reﬂects how much the left sub-tree re-lies on the right sub-tree, while max(a(k+1):j,i:k)deﬁnes how much the right sub-tree depends on theleft.
we deﬁne the importance-weights of the left(wl) and right (wr) sub-trees as:.
wl = max(a(k+1):j,i:k)/(wl + wr)wr = max(ai:k,(k+1):j)/(wl + wr).
in this way, the importance scores of the two sub-trees represent a real-valued distribution.
in com-bination with the unlabeled structure computation,we generate a weighted discourse tree for each doc-ument.
we call the discourse treebank generatedwith the summarization downstream informationw-rst-summ..4 w-rst discourse evaluation.
to assess the potential of w-rst, we consider twoevaluation scenarios (figure 2, right): (1) applyweighted discourse trees to the tasks of sentimentanalysis and summarization and (2) analyze theweight alignment with human annotations..4.1 weight-based discourse applications.
in this evaluation scenario, we address the questionof whether w-rst trees can support downstreamtasks better than traditional rst trees with nucle-arity.
speciﬁcally, we leverage the discourse treeslearned from sentiment for the sentiment analysistask itself and, similarly, rely on the discourse treeslearned from summarization to beneﬁt the summa-rization task..39114.1.1 sentiment analysisin order to predict the sentiment of a documentin w-rst-sent based on its weighted discoursetree, we need to introduce an additional sourceof information to be aggregated according to suchtree.
here, we choose word embeddings, as com-monly used as an initial transformation in manymodels tackling the sentiment prediction task (kim,2014; tai et al., 2015; yang et al., 2016; adhikariet al., 2019; huber and carenini, 2020a).
toavoid introducing additional confounding factorsthrough sophisticated tree aggregation approaches(e.g.
treelstms (tai et al., 2015)), we selecta simple method, aiming to directly compare theinferred tree-structures and allowing us to better as-sess the performance differences originating fromthe weight/nuclearity attribution (see right step infigure 3).
more speciﬁcally, we start by comput-ing the average word-embedding for each leaf nodeleaf i (here containing a single edu) in the dis-course tree..leaf i =.
emb(wordj.
i )/|leaf i|.
j<|leaf i|(cid:88).
j=0.
with |leaf i| as the number of words in leaf i,emb(·) being the embedding lookup and wordjirepresenting word j within leaf i. subsequently,we aggregate constituents, starting from the leafnodes (with leaf i as embedding constituent ci), ac-cording to the weights of the discourse tree.
forany two sibling constituents cl and cr of the parentsub-tree cp in the binary tree, we compute.
cp = cl ∗ wl + cr ∗ wr.
with wl and wr as the real-valued weight-distribution extracted from the inferred discoursetree and cp, cl and cr as dense encodings.
we aggre-gate the complete document in bottom-up fashion,eventually reaching a root node embedding con-taining a tree-weighted average of the leaf-nodes.
given the root-node embedding representing a com-plete document, a simple multilayer perceptron(mlp) trained on the original training portion ofthe mil model is used to predict the sentiment ofthe document..4.1.2 summarizationin the evaluation step of the summarization model(right of figure 4), we use the weighted discoursetree of a document in w-rst-summ to predict itsextractive summary by applying an adaptation of.
the unsupervised summarization method by marcu(1999)..we choose this straightforward algorithm overmore elaborate and hyper-parameter heavy ap-proaches to avoid confounding factors, since ouraim is to evaluate solely the potential of theweighted discourse trees compared to standardrst-style annotations.
in the original algorithm,a summary is computed based on the nuclearityattribute by recursively computing the importancescores for all units as:.
sn(u, n ) =.
.
.
dn ,s(u, c(n )) s.t.
u ∈ c(n ).
u ∈ p rom(n ).
otherwise.
where c(n ) represents the child of n , andp rom(n ) is the promotion set of node n , which isdeﬁned in bottom-up fashion as follows: (1) p romof a leaf node is the leaf node itself.
(2) p rom ofan internal node is the union of the promotion setsof its nucleus children.
furthermore, dn representsthe level of a node n , computed as the distancefrom the level of the lowest leaf-node.
this way,units in the promotion set originating from nodesthat are higher up in the discourse tree are ampli-ﬁed in their importance compared to those fromlower levels..as for the w-rst-summ discourse trees withreal-valued importance-weights, we adapt marcu’salgorithm by replacing the promotion set with real-valued importance scores as shown here:.
sw(u, n ) =.
.
.
d + wn ,sw(u, c(n )) + wn ,.
n is leaf.
u ∈ c(n ).
otherwise.
once sn or sw are computed, the top-k unitsof the highest promotion set or with the highestimportance scores respectively are selected into theﬁnal summary..4.1.3 nuclearity-attributed baselines.
to test whether the w-rst trees are effectivelypredicting the downstream tasks, we need to gen-erate traditional rst trees with nuclearity to com-pare against.
however, moving from weighted dis-course trees to coarse nuclearity requires the intro-duction of a threshold.
more speciﬁcally, while“nucleus-satellite” and “satellite-nucleus” assign-ments can be naturally generated depending onthe distinct weights, in order to assign the third“nucleus-nucleus” class, frequently appearing in.
3912ing any positional bias in the data (e.g.
the leadbias), which would confound the results..4.2 weight alignment with human.
annotation.
as for our second w-rst discourse evaluationtask, we investigate if the real-valued importance-weights align with human annotations.
to be ableto explore this scenario, we generate weightedtree annotations for an existing discourse treebank(rst-dt (carlson et al., 2002)).
in this eval-(1) the nucleus in auation task we verify if:gold-annotation generally receives more weightthan a satellite (i.e.
if importance-weights gener-ally favour nuclei over satellites) and, similarly, ifnucleus-nucleus relations receive more balancedweights.
(2) in accordance with figure 1, we fur-ther explore how well the weights capture the ex-tend to which a relation is dominated by the nu-cleus.
here, our intuition is that for inconsistenthuman nuclearity annotations the spread shouldgenerally be lower than for consistent annotations,assuming that human misalignment in the discourseannotation indicates ambivalence on the impor-tance of sub-trees..to test for these two properties, we use discoursedocuments individually annotated by two humanannotators and analyze each sub-tree within thedoubly-annotated documents with consistent inter-annotator structure assessment for their nuclear-ity assignment.
for each of the 6 possible inter-annotator nuclearity assessments, consisting of 3consistent annotation classes (namely n-n/n-n, n-s/n-s and s-n/s-n) and 3 inconsistent annotationclasses (namely n-n/n-s, n-n/s-n and n-s/s-n)5, we explore the respective weight distributionof the document annotated with the two w-rsttasks – sentiment analysis and summarization (seefigure 5).
we compute an average spread sc foreach of the 6 inter-annotator nuclearity assessmentsclasses c as:.
sc = (.
wjl − wj.
r)/|c|.
j<|c|(cid:88).
j=0.
l and wj.
with wjchild node of sub-tree j in class c, respectively..r as the weights of the left and right.
5we don’t take the order of annotators into consideration,.
mapping n-n/n-s and n-s/n-n both onto n-n/n-s..figure 5: three phases of our approach.
left: genera-tion of w-rst-sent/summ discourse trees.
right: lin-guistic evaluation.
rst-style treebanks, we need to specify how closetwo weights have to be for such conﬁguration toapply.
formally, we set a threshold t as follows:.
if:else:else:.
|wl − wr| < t → nucleus-nucleusif: wl > wr → nucleus-satelliteif: wl ≤ wr → satellite-nucleus.
this way, rst-style treebanks with nuclearityattributions can be generated from w-rst-sent andw-rst-summ and used for the sentiment analy-sis and summarization downstream tasks.
for thenuclearity-attributed baseline of the sentiment task,we use a similar approach as for the w-rst eval-uation procedure, but assign two distinct weightswn and ws to the nucleus and satellite child re-spectively.
since it is not clear how much moreimportant a nucleus node is compared to a satelliteusing the traditional rst notation, we deﬁne thetwo weights based on the threshold t as:.
wn = 1 − (1 − 2t)/4.
ws = (1 − 2t)/4.
the intuition behind this formulation is thatfor a high threshold t (e.g.
0.8), the nuclearityneeds to be very prominent (the difference be-tween the normalized weights needs to exceed0.8), making the nucleus clearly more importantthan the satellite, while for a small threshold (e.g.
0.1), even relatively balanced weights (for exam-ple wl = 0.56, wr = 0.44) will be assigned as“nucleus-satellite”, resulting in the potential dif-ference in importance of the siblings to be lesseminent..for the nuclearity-attributed baseline for summa-rization, we directly apply the original algorithm bymarcu (1999) as described in section 4.1.2. how-ever, when using the promotion set to determinewhich edus are added to the summarization, po-tential ties can occur.
since the discourse tree doesnot provide any information on how to prioritizethose, we randomly select units from the candi-dates, whenever there is a tie.
this avoids exploit-.
39135 experiments.
5.1 experimental setup.
sentiment analysis: we follow our previousapproach in huber and carenini (2020b) for themodel training and w-rst discourse inferencesteps (left and center in figure 3) using the adaptedmilnet model from angelidis and lapata (2018)trained with a batch-size of 200 and 100 neuronsin a single layer bi-directional gru with 20%dropout for 25 epochs.
next, discourse trees aregenerated using the best-performing heuristic ckymethod with the stochastic exploration-exploitationtrade-off from huber and carenini (2020b) (beamsize 10, linear decreasing τ ).
as word-embeddingsin the w-rst discourse evaluation (right in figure3), we use glove embeddings (pennington et al.,2014), which previous work (tai et al., 2015;huber and carenini, 2020a) indicates to be suitablefor aggregation in discourse processing.
for train-ing and evaluation of the sentiment analysis task,we use the 5-class yelp’13 review dataset (tanget al., 2015).
to compare our approach againstthe traditional rst approach with nuclearity, weexplore the impact of 11 distinct thresholds for thebaseline described in §4.1.3, ranging from 0 to 1in 0.1 intervals.
summarization: to be consistent with rst, oursummarizer extracts edus instead of sentencesfrom a given document.
the model is trained onthe edu-segmented cnndm dataset containingedu-level oracle labels published by xu et al.
(2020).
we further use a pre-trained bert-base(“uncased”) model to generate the embeddings ofedus.
the transformer used is the standard modelwith 6 layers and 8 heads in each layer (d = 512).
we train the extractive summarizer on the trainingset of the cnndm corpus (nallapati et al., 2016)and pick the best attention head using the rst-dtdataset (carlson et al., 2002) as the developmentset.
we test the trees by running the summarizationalgorithm in marcu (1999) on the test set of thecnndm dataset, and select the top-6 edus basedon the importance score to form a summary innatural order.
regarding the baseline model usingthresholds, we apply the same 11 thresholds as forthe sentiment analysis task..nuclearity.
0000..
..1100..
..2200..
..3300..
..4400..
..5500..
..6600..
..7700..
..8800..
..9900..
..0011..
..1.
0.8.
0.6.
1.
0.8.
0.6.oitarsuelcun.oitarsuelcun.56.
55.
54.
53.
23.
22.
21.
20.ycarucca.eguorgva.
0000..
..1100..
..2200..
..3300..
..4400..
..5500..
..6600..
..7700..
..8800..
..9900..
..0011..
..threshold.
figure 6: top: sentiment analysis accuracy of the w-rst model compared to the standard rst frameworkwith different thresholds.
bottom: average rougescore (rouge-1, -2 and -l) of the w-rst summa-rization model compared to different thresholds.
fullnumerical results are shown in appendix a..n-n n-s99694-.
n-n 273n-ss-n.--.
s-n4175172.table 1: statistics on consistently and inconsistentlyannotated samples of the 1, 354 structure-aligned sub-trees generated by two distinct human annotators..lished by carlson et al.
(2002), 53 of the 385 doc-uments annotated with full rst-style discoursetrees are doubly tagged by a second linguist.
weuse the 53 documents containing 1, 354 consistentstructure annotations between the two analysts toevaluate the linguistic alignment of our generatedw-rst documents with human discourse interpre-tations.
out of the 1, 354 structure-aligned sub-trees, in 1, 139 cases both annotators agreed on thenuclearity attribute, while 215 times a nuclearitymismatch appeared, as shown in detail in table 1..weight alignment with human annotation:as discussed in §4.2, this evaluation requires twoparallel human generated discourse trees for everydocument.
luckily, in the rst-dt corpus pub-.
5.2 results and analysis.
the results of the experiments on the discourseapplications for sentiment analysis and summa-rization are shown in figure 6. the results for.
3914sent.
n-n.n-s.s-n.n-s.s-n.n-n-0.228(106).
-.
-.
-.
-.
n-s-0.238(33)-0.038(325).
-.
-.
n-s0.604(42)0.713(418).
s-n-0.240(19)-0.044(22)-0.278(115).
s-n0.506(25)0.518(36)0.616(134).
summ n-n0.572(136).
n-n.table 2: confusion matrices based on human annota-tion showing the absolute weight-spread using the sen-timent (top) and summarization (bottom) tasks on 620and 791 sub-trees aligned with the human structureprediction, respectively.
cell upper value: absoluteweight spread for the respective combination of human-annotated nuclearities.
lower value (in brackets): sup-port for this conﬁguration..sentiment analysis (top) and summarization (bot-tom) thereby show a similar trend: with an in-creasing threshold and therefore a larger number ofn-n relations (shown as grey bars in the figure),the standard rst baseline (blue line) consistentlyimproves for the respective performance measureof both tasks.
however, reaching the best perfor-mance at a threshold of 0.8 for sentiment analysisand 0.6 for summarization, the performance startsto deteriorate.
this general trend seems reason-able, given that n-n relations represent a ratherfrequent nuclearity connection, however classify-ing every connection as n-n leads to a severe lossof information.
furthermore, the performance sug-gests that while the n-n class is important in bothcases, the optimal threshold varies depending onthe task and potentially also the corpus used, mak-ing further task-speciﬁc ﬁne-tuning steps manda-tory.
the weighted discourse trees following ourw-rst approach, on the other hand, do not requirethe deﬁnition of a threshold, resulting in a single,promising performance (red line) for both tasksin figure 6. for comparison, we apply the gener-ated trees of a standard rst-style discourse parser(here the two-stage parser by wang et al.
(2017))trained on the rst-dt dataset (carlson et al., 2002)on both downstream tasks.
the fully-supervisedparser reaches an accuracy of 44.77% for sentimentanalysis and an average rouge score of 26.28 forsummarization.
while the average rouge score.
n-n.n-s.s-n.∅-0.36 ∅-0.43 ∅-0.45.
∅+1.00 ∅+0.96.
∅-0.72.
summ.
n-n.n-s.s-n.∅-0.13 ∅+0.13 ∅-0.66.
∅+1.00 ∅-0.56.
∅+0.22.
-.
-.
sent.
n-n.n-s.s-n.n-n.n-s.s-n.-.
-.
-.
-.
table 3: confusion matrices based on human anno-tation showing the weight-spread relative to the task-average for sentiment (top) and summarization (bot-tom), aligned with the human structure prediction, re-spectively.
cell value: relative weight spread as thedivergence from the average spread across all cells intable 2. color: positive/negative divergence, ∅ = av-erage value of absolute scores..of the fully-supervised parser is above the perfor-mance of our w-rst results for the summarizationtask, the accuracy on the sentiment analysis taskis well below our approach.
we believe that theseresults are a direct indication of the problematicdomain adaptation of fully supervised discourseparsers, where the application on a similar domain(wall street journal articles vs. cnn-daily mailarticles) leads to superior performances comparedto our distantly supervised method, however, withlarger domain shifts (wall street journal articles vs.yelp customer reviews), the performance drops sig-niﬁcantly, allowing our distantly supervised modelto outperform the supervised discourse trees forthe downstream task.
arguably, this indicates thatalthough our weighted approach is still not com-petitive with fully-supervised models in the samedomain, it is the most promising solution availablefor cross-domain discourse parsing..with respect to exploring the weight alignmentwith human annotations, we show a set of confu-sion matrices based on human annotation for eachw-rst discourse generation task on the absoluteand relative weight-spread in tables 2 and 3 re-spectively.
the results for the sentiment analysistask are shown on the top of both tables, while theperformance for the summarization task is shownat the bottom.
for instance, the top right cell ofthe upper confusion matrix in table 2 shows thatfor 19 sub-trees in the doubly annotated subset ofrst-dt one of the annotators labelled the sub-tree with a nucleus-nucleus nuclearity attribution,while the second annotator identiﬁed it as satellite-.
3915nucleus.
the average weight spread (see §4.2) forthose 19 sub-trees is −0.24.
regarding table 3, wesubtract the average spread across table 2 deﬁnedas ∅ = (cid:80)ci∈c (ci)/|c| (with c = {c1, c2, ...c6}containing the cell values in the upper trianglematrix) from each cell value ci and normalize bymax = maxci∈c(|ci−∅|), with ∅ = −0.177 andmax = 0.1396 across the top table.
accordingly,we transform the −0.24 in the top right cell into(−0.24 − avg)/max = −0.45..moving to the analysis of the results, we ﬁndthe following trends in this experiment: (1) as pre-sented in table 2, the sentiment analysis task tendsto strongly over-predict s-n (i.e., wl << wr), lead-ing to negative spreads in all cells.
in contrast,the summarization task is heavily skewed towardsn-s assignments (i.e., wl >> wr), leading to ex-clusively positive spreads.
we believe both trendsare consistent with the intrinsic properties of thetasks, given that the general structure of reviewstends to become more important towards the endof a review (leading to increased s-n assignments),while for summarization, the lead bias potentiallyproduces the overall strong nucleus-satellite trend.
(2) to investigate the relative weight spreads fordifferent human annotations (i.e., between cells)beyond the trends shown in table 2, we normalizevalues within a table by subtracting the averageand scaling between [−1, 1].
as a result, table 3shows the relative weight spread for different hu-man annotations.
apart from the general trendsdescribed in table 2, the consistently annotatedsamples of the two linguists (along the diagonalof the confusion matrices) align reasonably.
themost positive weight spread is consistently foundin the agreed-upon nucleus-satellite case, while thenucleus-nucleus annotation has, as expected, thelowest divergence (i.e., closest to zero) along the di-agonal in table 3.
(3) regarding the inconsistentlyannotated samples (shown in the triangle matrixabove the diagonal) it becomes clear that in the sen-timent analysis model the values for the n-n/n-sand n-n/s-n annotated samples (top row in ta-ble 3) are relatively close to the average value.
thisindicates that, similar to the nucleus-nucleus case,the weights are also ambivalent, with the n-n/n-s value (top center) slightly larger than the valuefor n-n/s-n (top right).
the n-s/s-n case forthe sentiment analysis model is less aligned withour intuition, showing a strongly negative weight-spread (i.e.
wl << wr) where we would have.
expected a more ambivalent result with wl ≈ wr(however, aligned with the overall trend shown intable 2).
for summarization, we see a very similartrend with the values for n-n/n-s and n-n/s-nannotated samples.
again, both values are closeto the average, with the n-n/n-s cell showing amore positive spread than n-n/s-n. however forsummarization, the consistent satellite-nucleus an-notation (bottom right cell) seems misaligned withthe rest of the table, following instead the generaltrend for summarization described in table 2. allin all, the results suggest that the values in mostcells are well aligned with what we would expectregarding the relative spread.
interestingly, humanuncertainty appears to be reasonably captured in theweights, which seem to contain more ﬁne grainedinformation about the relative importance of siblingsub-trees..6 conclusion and future work.
we propose w-rst as a new discourse framework,where the binary nuclearity assessment postulatedby rst is replaced with more expressive weights,that can be automatically generated from auxiliarytasks.
a series of experiments indicate that w-rstis beneﬁcial to the two key nlp downstream tasksof sentiment analysis and summarization.
further,we show that w-rst trees interestingly align withthe uncertainty of human annotations..for the future, we plan to develop a neural dis-course parser that learns to predict importanceweights instead of nuclearity attributions whentrained on large w-rst treebanks.
more longerterm, we want to explore other aspects of rstthat can be reﬁned in light of empirical results,plan to integrate our results into state-of-the-artsentiment analysis and summarization approaches(e.g.
xu et al.
(2020)) and generate parallel w-rststructures in a multi-task manner to improve thegenerality of the discourse trees..acknowledgments.
we thank the anonymous reviewers for their in-sightful comments.
this research was supported bythe language & speech innovation lab of cloudbu, huawei technologies co., ltd and the nat-ural sciences and engineering research councilof canada (nserc).
nous remercions le conseilde recherches en sciences naturelles et en g´enie ducanada (crsng) de son soutien..3916references.
ashutosh adhikari, achyudh ram, raphael tang, andjimmy lin.
2019. rethinking complex neural net-work architectures for document classiﬁcation.
inproceedings of the 2019 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long and short papers), pages 4046–4051..stefanos angelidis and mirella lapata.
2018. multi-ple instance learning networks for ﬁne-grained sen-timent analysis.
transactions of the association forcomputational linguistics, 6:17–31..parminder bhatia, yangfeng ji, and jacob eisenstein.
2015. better document-level sentiment analysisfrom rst discourse parsing.
in proceedings of the2015 conference on empirical methods in naturallanguage processing, pages 2212–2218..lynn carlson, mary ellen okurowski, and danielmarcu.
2002. rst discourse treebank.
linguisticdata consortium, university of pennsylvania..vanessa wei feng and graeme hirst.
2014. a linear-time bottom-up discourse parser with constraintsand post-editing.
in proceedings of the 52nd annualmeeting of the association for computational lin-guistics (volume 1: long papers), pages 511–521..albert gatt and emiel krahmer.
2018. survey of thestate of the art in natural language generation: coretasks, applications and evaluation.
journal of artiﬁ-cial intelligence research, 61:65–170..shima gerani, yashar mehdad, giuseppe carenini,raymond t ng, and bita nejat.
2014. abstractivesummarization of product reviews using discoursestructure.
in proceedings of the 2014 conference onempirical methods in natural language processing(emnlp), pages 1602–1613..luke gessler, yang janet liu, and amir zeldes.
2019.a discourse signal annotation system for rst trees.
inproceedings of the workshop on discourse relationparsing and treebanking 2019, pages 56–61..grigorii guz and giuseppe carenini.
2020. towardstext structuring trainable ondomain-independentin proceedings of thelarge discourse treebanks.
2020 conference on empirical methods in naturallanguage processing: findings, pages 3141–3152..alexander hogenboom, flavius frasincar, franciskade jong, and uzay kaymak.
2015. using rhetori-cal structure in sentiment analysis.
commun.
acm,58(7):69–77..patrick huber and giuseppe carenini.
2020b.
megarst discourse treebanks with structure and nuclear-ity from scalable distant sentiment supervision.
inproceedings of the 2020 conference on empiricalmethods in natural language processing (emnlp),pages 7442–7457..yangfeng ji and jacob eisenstein.
2014. representa-tion learning for text-level discourse parsing.
in pro-ceedings of the 52nd annual meeting of the associa-tion for computational linguistics (volume 1: longpapers), volume 1, pages 13–24..yangfeng ji and noah a smith.
2017. neural dis-course structure for text categorization.
in proceed-ings of the 55th annual meeting of the associationfor computational linguistics (volume 1: long pa-pers), pages 996–1005..shaﬁq joty, giuseppe carenini, and raymond t ng.
2015. codra: a novel discriminative frameworkfor rhetorical analysis.
computational linguistics,41(3)..dan jurafsky and james h martin.
2014. speech andlanguage processing, volume 3. pearson london..yoon kim.
2014. convolutional neural networks forsentence classiﬁcation.
in proceedings of the 2014conference on empirical methods in natural lan-guage processing (emnlp), pages 1746–1751..qi li, tianshi li, and baobao chang.
2016. discourseparsing with attention-based hierarchical neural net-in proceedings of the 2016 conference onworks.
empirical methods in natural language processing,pages 362–371..yang liu and amir zeldes.
2019. discourse relationsand signaling information: anchoring discourse sig-nals in rst-dt.
proceedings of the society for compu-tation in linguistics, 2(1):314–317..william c mann and sandra a thompson.
1988.rhetorical structure theory: toward a functional the-ory of text organization.
text, 8(3):243–281..daniel marcu.
1999. discourse trees are good indica-tors of importance in text.
advances in automatictext summarization, 293:123–136..ramesh nallapati, bowen zhou, cicero dos santos,c¸ a˘glar gu`i‡lc¸ehre, and bing xiang.
2016. abstrac-tive text summarization using sequence-to-sequencein proceedings of the 20thrnns and beyond.
signll conference on computational natural lan-guage learning, pages 280–290.
association forcomputational linguistics..annotations.
patrick huber and giuseppe carenini.
2020a.
fromto sentiment predictionsentimentthrough discourse augmentation.
in proceedings ofthe 28th international conference on computationallinguistics, pages 185–197..bita nejat, giuseppe carenini, and raymond ng.
2017.exploring joint neural model for sentence level dis-course parsing and sentiment analysis.
in proceed-ings of the 18th annual sigdial meeting on dis-course and dialogue, pages 289–298..3917jeffrey pennington, richard socher, and christopher d.manning.
2014. glove: global vectors for word rep-resentation.
in empirical methods in natural lan-guage processing (emnlp), pages 1532–1543..rashmi prasad, nikhil dinesh, alan lee, eleni milt-sakaki, livio robaldo, aravind joshi, and bonniewebber.
2008. the penn discourse treebank 2.0.lrec..rajen subba and barbara di eugenio.
2009. an effec-tive discourse parser that uses rich linguistic infor-mation.
in proceedings of human language tech-nologies: the 2009 annual conference of the northamerican chapter of the association for computa-tional linguistics, pages 566–574.
association forcomputational linguistics..kai sheng tai, richard socher, and christopher dmanning.
2015. improved semantic representationsfrom tree-structured long short-term memory net-in proceedings of the 53rd annual meet-works.
ing of the association for computational linguisticsand the 7th international joint conference on natu-ral language processing (volume 1: long papers),pages 1556–1566..duyu tang, bing qin, and ting liu.
2015. docu-ment modeling with gated recurrent neural networkin proceedings of thefor sentiment classiﬁcation.
2015 conference on empirical methods in naturallanguage processing, pages 1422–1432..mark torrance.
2015. understanding planning in textproduction.
handbook of writing research, pages1682–1690..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in proceedings of the 31st internationalconference on neural information processing sys-tems, pages 6000–6010..yizhong wang, sujian li, and houfeng wang.
2017.a two-stage parsing method for text-level discourseanalysis.
in proceedings of the 55th annual meet-ing of the association for computational linguistics(volume 2: short papers), pages 184–188..wen xiao, patrick huber, and giuseppe carenini.
2020.do we really need that many parameters in trans-former for extractive summarization?
discourse canhelp!
in proceedings of the first workshop on com-putational approaches to discourse, pages 124–134..wen xiao, patrick huber, and giuseppe carenini.
2021.predicting discourse trees from transformer-basedin proceedings of the 2021neural summarizers.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, pages 4139–4152, online.
association for computational linguistics..jiacheng xu, zhe gan, yu cheng, and jingjing liu.
2020. discourse-aware neural extractive text sum-marization.
in proceedings of the 58th annual meet-ing of the association for computational linguis-tics, pages 5021–5031.
association for computa-tional linguistics..zichao yang, diyi yang, chris dyer, xiaodong he,alex smola, and eduard hovy.
2016. hierarchi-cal attention networks for document classiﬁcation.
in proceedings of the 2016 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,pages 1480–1489..nan yu, meishan zhang, and guohong fu.
2018.transition-based neural rst parsing with implicit syn-in proceedings of the 27th inter-tax features.
national conference on computational linguistics,pages 559–570..amir zeldes.
2017. the gum corpus: creating mul-tilayer resources in the classroom.
language re-sources and evaluation, 51(3):581–612..a numeric results.
the numeric results of our w-rst approach for thesentiment analysis and summarization downstreamtasks presented in figure 6 are shown in table 4below, along with the threshold-based approach, aswell as the supervised parser..approach.
sentimentaccuracy.
summarizationr-2.
r-1.
r-l.t = 0.0t = 0.1t = 0.2t = 0.3t = 0.4t = 0.5t = 0.6t = 0.7t = 0.8t = 0.9t = 1.0.nuclearity with threshold.
28.2228.4128.6428.9629.3629.5529.7829.5729.1828.1126.94.
53.7653.9354.1354.3354.4454.7954.9955.0755.3254.9054.15.
8.588.698.859.089.349.509.659.459.088.297.60our weighted rst framework9.58supervised training on rst-dt12.77.
44.77.
34.20.
29.70.
54.76.weighted.
supervised.
26.4526.6126.8327.1427.5127.6827.9027.7427.3226.3525.27.
27.85.
32.09.table 4: results of the w-rst approach compared tothreshold-based nuclearity assignments and supervisedtraining on rst-dt..3918