lower perplexity is not always human-like.
tatsuki kuribayashi1,2, yohei oseki3,4, takumi ito1,2,ryo yoshida3, masayuki asahara5, kentaro inui1,41tohoku university 2langsmith inc. 3university of tokyo 4riken 5ninjal{kuribayashi, takumi.ito.c4, inui}@tohoku.ac.jp ,{oseki, yoshiryo0617}@g.ecc.u-tokyo.ac.jp , masayu-a@ninjal.ac.jp.
abstract.
in computational psycholinguistics, variouslanguage models have been evaluated againsthuman reading behavior (e.g., eye movement)to build human-like computational models.
however, most previous efforts have focusedalmost exclusively on english, despite the re-cent trend towards linguistic universal withinthe general community.
in order to ﬁll the gap,this paper investigates whether the establishedresults in computational psycholinguistics canbe generalized across languages.
speciﬁcally,we re-examine an established generalization—the lower perplexity a language model has,the more human-like the language model is—in japanese with typologically different struc-tures from english.
our experiments demon-strate that this established generalization ex-hibits a surprising lack of universality; namely,lower perplexity is not always human-like.
moreover, this discrepancy between englishand japanese is further explored from theperspective of (non-)uniform information den-sity.
overall, our results suggest that a cross-lingual evaluation will be necessary to con-struct human-like computational models..1.introduction.
it is well known that the probability of a wordin context (i.e., surprisal) impacts its processingdifﬁculty in incremental human language compre-hension (hale, 2001; demberg and keller, 2008;levy, 2008; smith and levy, 2013).
buildingon this basis, researchers have compared a vari-ety of language models (lms) in terms of how welltheir surprisal correlates with human reading be-havior (roark et al., 2009; frank and bod, 2011;fossum and levy, 2012; hale et al., 2018; good-kind and bicknell, 2018; aurnhammer and frank,2019; merkx and frank, 2020; wilcox et al., 2020).
such investigations could provide insights into thedevelopment of a general computational model of.
human language processing.
for example, recentstudies reported that lms with better performancefor next-word prediction could also better predictthe human reading behavior (i.e.
more human-like) (fossum and levy, 2012; goodkind and bick-nell, 2018; wilcox et al., 2020)..in this paper, we re-examine whether the re-cent ﬁndings on human-like computational mod-els can be generalized across languages.
despitethe community’s ongoing search for a language-independent model (bender, 2011), existing stud-ies have focused almost exclusively on the englishlanguage.
having said that, broad-coverage cross-linguistic evaluation of the existing reports is pro-hibitively difﬁcult.
in fact, data on human readingbehavior (e.g., eye movement) is available only inlimited languages.
as an initial foray, this studyfocuses on the japanese language as a representa-tive of languages that have typologically differentcharacteristics from the english language.
if the ob-servation is different between english and japanese,the current ﬁndings on english data might lack auniversality across languages..we speciﬁcally revisit the recent report—thelower perplexity a lm has, the more human-like thelm is—in the english and japanese languages (fos-sum and levy, 2012; goodkind and bicknell, 2018;wilcox et al., 2020).
in addition to the importanceof cross-linguistic evaluation, the report itself isworth investigating.
recent studies in the machinelearning ﬁeld have reported that more parameters,training data, and computation cost can result inbetter ppl (kaplan et al., 2020; brown et al., 2020).
our investigation has implications for whether ahuman-like model might exist beyond such im-provements..more concretely, over three dozens of lms weretrained for each language, with variants in their ar-chitecture, training data size, and the number of pa-rameter updates.
then, the surprisals computed by.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5203–5217august1–6,2021.©2021associationforcomputationallinguistics5203figure 1: gaze duration from human subjects and surprisal from language models for the japanese sentence“yononakaniwa samazamana hitoga irutoiu kotoga yoku wakatta.” (i understood well that there are all kinds ofpeople in the world.).
each lm were compared to human eye movementdata (figure 1).
the analysis of the relationship be-tween ppl and the psychometric predictive powerrevealed substantively different trends between thejapanese and english lms.
in japanese, a lowerppl of a lm does not indicate better performancefor modeling reading behavior.
by contrast, in en-glish, there was a clear relationship between thetwo metrics as reported in the prior studies..this opens a remaining and important question:why are english and japanese different in this as-pect?
we discuss the differing results betweenenglish and japanese from the perspective of theuniform information density hypothesis (genzeland charniak, 2002; levy, 2005; jaeger and levy,2007).
we ﬁnd that the processing difﬁculty (i.e.,gaze duration) of segments is less uniformly dis-tributed within a japanese sentence.
given this,the discrepancy of the results between english andjapanese might stem from a mismatch betweenthe information uniformity of the target languageand the lm’s training objective.
we demonstratethat tuning japanese lms to this training objec-tive collapses the human-like nonuniformity of theprocessing difﬁculty observed in japanese subjects.
our code is made publicly available.1.
2 related work.
2.1 human sentence processing and lms.
what factor determines the incremental difﬁculty ofhuman language processing?
at present, surprisaltheory (hale, 2001; levy, 2008) has been widelyadopted in the ﬁeld of computational psycholin-guistics.
this theory suggests that the processingdifﬁculty of a segment is determined by how pre-dictable the segment is in its preceding context(− log p(segment|preceding context))..1https://github.com/kuribayashi4/.
surprisal_reading_time_en_ja.
existing studies have compared various com-putational models by checking the effectivenessof their surprisals in modeling human reading be-havior (hale, 2001; roark et al., 2009; frank andbod, 2011; fossum and levy, 2012; hale et al.,2018; goodkind and bicknell, 2018; merkx andfrank, 2020; wilcox et al., 2020).
data such aseye movement (kennedy et al., 2003) and brainactivity (frank et al., 2015; brennan et al., 2016)are used as measures of human reading behavior.
for example, using eye movement data, frank andbod (2011) compared the surprisals from phrase-structure grammars (psgs) with those from a non-hierarchical, sequential model, tentatively conclud-ing that human sentence processing was insensitiveto hierarchical structures since non-hierarchicalmodels displayed better psychological predictivepower than psgs.
recently, researchers reportedthat surprisals from lms with low ppl correlatewell with human reading behaviors (fossum andlevy, 2012; goodkind and bicknell, 2018; aurn-hammer and frank, 2019; wilcox et al., 2020)..the work most closely related to this studyis wilcox et al.
(2020).
they examined the relation-ship between ppl, psychometric predictive power,and syntactic knowledge in lms using a varietyof models, including modern neural lms (radrofet al., 2018).
they found a tight relationship be-tween ppl and psychometric predictive powerin the english corpora.
this study investigateswhether this relationship can be generalized acrosslanguages..2.2 reading behavior in japanese.
in comparison to english speakers, japanese speak-ers display different patterns in sentence process-ing.
for example, an anti-locality effect (the moremodiﬁers a word has in its preceding context,the easier the word is to process) has typicallybeen observed in head-ﬁnal languages, including.
5204yononakaniwa(in the world)samazamana(all kinds of)hitoga(people)irutoiu(there are)kotoga(that)yoku(well)wakatta(understood)gaze duration and surprisaljapanese (konieczny, 2000).
such differences be-tween the languages are assumed to be more orless due to their different sentence structures.
re-cently, eye movement data for naturally occurringjapanese texts have recently become available (asa-hara et al., 2016) and was extensively annotatedwith various linguistic properties (asahara andkato, 2017; asahara, 2017, 2018)..3 methods.
this section describes the settings of lms, eyemovement data, and evaluation metrics..3.1 language models.
a variety of sentence-level, left-to-right sequentiallms was used..training data of english lms: we used thewikitext-103 dataset to train the english lms.
based on the reports that subword-level englishlms exhibits superior psychometric predictivepower (wilcox et al., 2020), input texts weredivided into subwords by a byte-pair encoding(bpe) (sennrich et al., 2016).2 the training dataconsist of approximately 4m sentences (114m sub-words units)..training data of japanese lms: we used newsarticles and the japanese part of wikipedia to trainthe japanese lms.
input texts were ﬁrst segmentedinto morphemes by mecab (kudo, 2006), and thenfurther divided into subwords by bpe.2 the train-ing data consist of approximately 5m sentences(146m subwords units)..architectures: the following four variants oflms were used: transformer-large (trans-lg) (vaswani et al., 2017), transformer-small(trans-sm), lstm (lstm) (hochreiter andschmidhuber, 1997), and n-gram lms (n-gram).3 the parameter size was almost the samefor trans-sm and lstm.
with respect to the n-gram models, 3-gram, 4-gram, and 5-gram lmswere used.
appendix a shows the hyperparametersof the neural lms..2implemented in sentencepiece (kudo and richardson,2018).
we set character coverage to 0.9995，and vocabularysize to 32,000 in english.
in japanese, the vocabulary size is100,000, reﬂecting its rich morphemes..3the neural lms were trained with the fairseq toolkit (ottet al., 2019).
n-gram lms were trained using kenlmhttps://github.com/kpu/kenlm..training data size: for each neural lm architec-ture (trans-lg, trans-sm, and lstm), threevariants were trained using different training datasizes: lg (full training data), md (1/10 trainingdata), and sm (1/100 training data).
the n-gramlms were trained on lg datasets..number of updates: the parameters of eachneural lm were saved at four different points dur-ing training: 100, 1k, 10k, and 100k parameterupdates..to summarize, 39 lm training settings wereattained for each language (3 architectures × 3 datasize × 4 parameter updates = 36 neural lms, plus3 n-gram lms).
in addition, our experimentsuse three lms trained using different random seedsfor each neural lm training conﬁgure; hence, 111lms (36 neural lms × 3 seeds, plus 3 n-gramlms) were tested for each language..3.2 eye movement data.
english: the dundee corpus (kennedy et al.,2003), which contains gaze duration annotation foreach word, was used.
following smith and levy(2013), the ﬁrst-pass gaze duration was analyzed.
then, following goodkind and bicknell (2018), thedata points that met any of the following criteriawere excluded:.
• data points with zero gaze duration or that.
beyond three standard deviations.
• segments with punctuation or numeric charac-.
ters.
• segments whose next segment has punctuation.
or numeric characters.
• ﬁrst or last segment in a line.
in total, the analysis included 107,580 data pointsin the corpus..japanese: the bccwj-eyetrack (asaharaet al., 2016), which contains gaze duration annota-tion for each phrasal unit, was used.
note that thephrasal unit (i.e., bunsetsu) consists of at least onecontent morpheme and its postpositional functionmorphemes.
henceforth, an english word and ajapanese phrasal unit are referred to as a “segment.”the same exclusion criteria as the dundee corpuswas applied to the bccwj-eyetrack data.4 in.
4strictly speaking, the exclusion criteria was slightly dif-ferent between japanese and english data.
in the japanesedata, we included the segments whose next segment had punc-tuation or a numeric character, as there is no spillover effectin japanese (see section 3.3).
5205corpus.
#articles.
#sents..#segments.
#data points(used).
#subjectsper article.
avg.
gdper segment.
avg.
#subwordsper segment.
dundee corpusbccwj-eyetrack.
2020.
2,478218.
51,5011,643.
107,5806,009.
1012.
197.6361.6.
1.33.4.table 1: statistics of the corpora used for evaluating the psychometric predictive power of lms.
“#articles” and“#sents.” are the number of articles and sentences in each corpus.
“#segments” denotes the number of segmentsannotated with human reading time in each corpus.
“#data points” is the number of reading time annotations usedin our experiments.
each segment has the reading time annotations from multiple subjects (#subjects per article).
“avg.
gd per segment” is the averaged gaze duration per segment.
“avg.
#subwords per segment” denotes theaveraged number of subwords consisting of each segment..total, the analysis included 6,009 data points in thecorpus.
note that the bccwj-eyetrack data wasdeliberately designed to address language-speciﬁcissues in japanese such as the lack of segmentationspaces in japanese texts (asahara et al., 2016)..statistics: table 1 shows the statistics of thedundee corpus and bccwj-eyetrack data.
thebccwj-eyetrack has more than 10 times asmaller number of data points than the dundeecorpus.
notably, the segment annotated with eyemovement information differs between english andjapanese.
on average, a japanese segment consistsof 3.4 subwords, while an english segment consistsof 1.3 subwords.
smith and levy (2013) theoret-ically proved that the more fragments a word isdivided into when computing its surprisal, the bet-ter the calculated surprisal approximates the humancognitive effort if the human language processingis highly incremental.
thus, we tentatively con-sider that this difference did not make a negativeimpact on the results using the japanese data..3.3 evaluation metrics.
perplexity (ppl): ppl, the inverse geometricmean of next-word probabilities p(wi|w<i) in atext that consists of n signals (w1, w2, · · · , wn ), isa typical evaluation metric for unidirectional lms(eq.
1):.
also called a linguistically accurate model (frankand bod, 2011)..a.segment.
negative.
predictivea.power: thepsychometriclogarith-surprisal measure,in contextmic probability of(− log p(segment|preceding context)),aiswidely used information-theoretic complexityintuitively, a model is considered tometric.
have high psychometric predictive power (i.e.,psychological accuracy)the surprisals ofsegments computed by the model have trendssimilar to the human subject’s cognitive load(e.g., measured by gaze duration).
following theexisting studies (goodkind and bicknell, 2018;merkx and frank, 2020; wilcox et al., 2020), thepsychometric predictive power of a model wasmeasured by comparing surprisal from the modeland gaze duration from human subjects..if.
while lms process a text subword-by-subword,gaze duration is annotated in a larger segment.
fol-lowing the study using subwords (wilcox et al.,2020), the surprisal of each segment was calcu-lated using the joint probability of its constituentsubwords.
formally, given a text consisting ofn subwords w1:n = (w1, w2, · · · , wn ), surprisali(·) of a segment sk = (wl, wl+1, · · · , wm), where1 ≤ l ≤ m ≤ n , was calculated as follows:.
ppl =.
p(wi|w<i)− 1.n ..(1).
n(cid:89).
i=0.
low ppl indicates that the model can accuratelypredict the upcoming signal based on its precedingcontext.
the training objective of lms works tominimize the ppl computed by the model.
in theexperiments, the ppl of a lm is evaluated with thetexts in the eye movement data, which do not over-lap with the training data.
a model with low ppl is.
i(sk) = − log p(wl, · · · , wm|w<l).
= −.
log p(wk|w1, · · · , wk−1) ..(2).
m(cid:88).
k=l.
the effect of surprisals for modeling human read-ing behavior was calculated using a linear mixed-effects regression (bates et al., 2015).
speciﬁcally,the gaze duration (gd) was modeled using the fol-lowing formula:.
5206figure 2: relationship between ppl (x-axis) and psychometric predictive power, i.e., ∆loglik (y-axis) in theenglish and japanese languages.
each point corresponds to each lm.
a low score on the x-axis indicates the highlinguistic accuracy of the model.
the ppl was calculated on the eye movement data, and the lms with ppl morethan 106 was excluded from the ﬁgure.
a high score on the y-axis indicates that the model has a high psychometricpredictive power.
note that the x-axis is on a log scale..gd ∼ surprisal + surprisal prev 1.
+ surprisal prev 2 + freq ∗ length+ freq prev 1 ∗ length prev 1+ screenn + linen + segmentn+ (1|article) + (1|subj) ..(3).
the regression model includes baseline factors(e.g., frequency of a segment) that are of no in-terest in the comparison of lms.
a collection offactors used in the existing studies (asahara et al.,2016; wilcox et al., 2020) were initially examinedand the factors that were not signiﬁcant (p > 0.05)for gaze duration modeling both in the dundeecorpus and bccwj-eyetrack were excluded.
thefrequency of a segment (freq) was calculated us-ing the entire training data for lms.
appendix bshows the details of each factor in eq.
3..(surprisal prev 1.in english experiments,.
surprisals of pre-ceding wordsandsurprisal prev 2) were included in order tohandle the spillover effect (the processing costof a certain segment is affected by its precedingsegments) (rayner and well, 1996; smith andlevy, 2013).
thesurprisals of preceding words were not includedbecause our preliminary experiment showed thatthese factors were not signiﬁcantly effective formodeling gaze duration in the bccwj-eyetrack.5.
in japanese experiments,.
5the reason is probably that a japanese phrasal unit (i.e.,.
bunsetsu) could be a larger unit than an english word..all the regression models used in our experimentswere converged..to isolate the effect of surprisal for gaze du-ration modeling, a baseline regression modelwas trained without surprisal information (exclud-ing the surprisal, surprisal prev 1, andsurprisal prev 2 terms from eq.
3).
follow-ing goodkind and bicknell (2018), the differenceof log-likelihood between the model using surprisalvalues (eq.
3) and the baseline model was calcu-lated.
henceforth, this metric is called ∆loglik.
when surprisal from a lm is not effective for gazeduration modeling, the ∆loglik score becomeszero.
a high ∆loglik means that the surprisal val-ues obtained by the lm are effective for modelinggaze duration (i.e., the lm has a high psychometricpredictive power)..4 experiments.
the relationship between ppl and psychometricpredictive power is investigated.
furthermore, therelationship is analyzed with respect to the trainingconﬁgures of lms (e.g., the number of parameterupdates).
then, we discuss the results from the per-spective of the uniformity of information density..4.1 psychometric predictive power and ppl.
figure 2 shows the relationship between ppl andpsychometric predictive power (i.e., ∆loglik) oflms in each of the languages.
each point cor-responds to each lm, and a score on the y-axisindicates the psychometric predictive power of a.
5207trans-smlstmtrans-lgmodel100000number of updates100001000100data sizelgmdsm+n-gram400psychometricpredictive powerbccwj-eyetrack(japanese)dundee corpus (english)figure 3: separate effect of model architecture, training data size, and the number of parameter updates for lms’psychometric predictive power in each language.
each point corresponds to each lm.
the box shows the quartilesof the data.
the whiskers show 1.5 times interquartile range..lm (higher is better).
the x-axis is ppl on a logscale (lower is better)..dundee corpus: first, the results of the datafrom the dundee corpus show a clear relationshipbetween ppl and psychometric predictive power;namely, lower ppl corresponds to more psycho-metric predictive power, as reported by prior stud-ies (goodkind and bicknell, 2018; wilcox et al.,2020).
spearman’s rank correlation coefﬁcient be-tween the two metrics was −0.69..bccwj-eyetrack: by contrast, in bccwj-eyetrack, there was no clear, consistent trend be-tween the ppl and psychometric predictive power.
while lms with ppl over 400 show the correlationbetween ppl and psychometric predictive power(−0.68 with spearman’s ρ), there is a positive cor-relation (0.53 with spearman’s ρ) for lms withppl below 400. the positive correlation meansthat the more accurately the lms can predict theupcoming word, the worse the psychometric predic-tive power of the lms is.
these results demonstratethe non-universality of the recent report across lan-guages; lower perplexity is not always human-like.
the lstm lm trained using the md dataset with1k updates achieved the best psychometric predic-tive power.
notably, surprisal was effective forgaze duration modeling in all the japanese lms.
∆loglik scores were signiﬁcantly higher than zero.
with the chi-square test (p <0.05)..4.2 model architectures, data sizes, number.
of parameter updates.
which factor (e.g., model architecture, training datasize, and the number of parameter updates) charac-terizes the psychometric predictive power of lms?
is the collection of effective factors consistent be-tween the two languages?
this study takes a morein-depth look at the separate effects of (i) modelarchitecture, (ii) training data size, and (iii) thenumber of parameter updates for the psychometricpredictive power..figure 3 summarizes the effect of each factor,where the y-axis denotes the psychometric pre-dictive power.
the most noticeable trend is thatjapanese lms with a relatively fewer number of pa-rameter updates (1k) have better psychometric pre-dictive power than the other japanese lms (bottomright part of figure 3), while this trend does not ex-ist in the english lms (top right part).
this impliesthat the training objective of the lms, maximizing1i=1 log p (wi|w<i), had a negative impact onnthe psychometric predictive power of lms, at leastin japanese.
we discuss this point in section 4.3..(cid:80)n.to quantitatively test the differences in figure 3,a linear regression model was trained to estimatepsychometric predictive power with the factors ofthe model architecture, the training data size, and.
5208bccewj-eyetrack(japanese)dundeecorpus(english)psychometricpredictive powerpsychometricpredictive powerthe parameter update number in each language.
the training data size and the parameter updatenumber are represented as logarithmically trans-formed numerical factors.
the following trendswere found: (i) no signiﬁcant difference by modelarchitecture; (ii) the training data size positively af-fects the performance in english alone; and (iii) thenumber of parameter updates positively affects theperformance only in english.
there was no factorthat boosted the psychometric predictive power oflms in both english and japanese languages..4.3 discussion: uniform information density.
the key question is: why do japanese and englishshow different trends between ppl and psychomet-ric predictive power?
one possible interpretationconnecting our results to the uniform informationdensity is discussed in this section..in computational psycholinguistics, it is com-monly assumed that language is designed to enableefﬁcient communication.
this principle has beentypically investigated under the uniform informa-tion density (uid) hypothesis (genzel and char-niak, 2002; levy, 2005; jaeger and levy, 2007).
this hypothesis suggests that speakers seek to keepthe amount of information constant across the sig-nals (e.g., segments)..assuming this hypothesis holds for all languages,the reasonable expectation would be for human sub-jects to show a near-uniform gaze duration acrosssegments regardless of their native language.
how-ever, this study found that the coefﬁcient of varia-tion6 in gaze duration over the whole corpus was2.5 times higher in japanese compared to english(0.84 vs. 0.34).
speciﬁcally, in japanese, the gazeduration tended to speed up towards the end of sen-tences, whereas the duration was near-uniform inenglish (figure 4).7 these observations imply thatthe japanese language might have a less uniform in-formation density than english.
this phenomenonwas also investigated through the lens of word or-der, where sov languages such as japanese arereported to show less uniformity of informationdensity (maurits et al., 2010)..6coefﬁcient of variation is σ.µ , where σ and µ are the stan-dard deviation and the mean of the ﬁrst-pass gaze durations inthe eye movement data..7at least in our experimental setup, token position withinthe sentence was not signiﬁcantly effective for gaze durationmodeling in english sentences, whereas it was signiﬁcant injapanese sentences.
we checked the coefﬁcient of the factorof position in sentence segmentn using the linear regressionmodel of gd ∼ sengmentn..figure 4: uniformity of gaze duration with respectto segment position in a sentence.
this plot is com-puted by the generalized additive model of gd ∼segmentn.
here, segmentn is denoted as the posi-tion of a segment in a sentence..(cid:80)n.based on this observation, the discrepancy be-tween english and japanese low-ppl lms’ psy-cholinguistic predictive power could stem from amismatch between the lm’s training objective andthe information uniformity of the target language.
the objective function, 1i=1 log p (wi|w<i),ndeﬁnes that the “ideal” is to maximize all nextword probabilities to 1.0 (a uniform goal).8 that is,lms are, in theory, trained to approach a model sat-isfying the uid assumption (bloem, 2016), whereall surprisals from the lm are equally, sufﬁcientlysmall across the segments.
therefore, the objectivefunction might lead to a worse approximation ofhuman-like surprisal in languages that are furtherfrom the uid assumption, such as japanese, whileit might be more compatible with english, whichhas a more uniform processing difﬁculty acrosssegments.
this explanation would be consistentwith the observation that more tuning to the lmtraining objective (i.e., a lower ppl) had a negativeimpact on the psycholinguistic performance of thejapanese lms (section 4.2).
note the tendencyof lms to assign unreasonably high probabilitiesto segments has also attracted attention from theviewpoint of memorization capability of lms (car-lini et al., 2020).
in addition, the connection of theuid hypothesis to the modern nlp techniques hasbeen recently explored (meister et al., 2020; weiet al., 2021).
we further investigate our hypothesisin section 5..5 probing nonuniform information.
density of japanese lms.
this study hypothesized that tuning to the lm ob-jective (i.e., uniform goal) obscures the nonuniformtrend observed in the reading behavior of japanesesubjects.
we investigated whether the nonunifor-.
8ppl, (cid:81)n.i=1 p (wi|w<i)− 1.objective are maximized..n , is minimized when the lm.
5209020406080−15−5515tokenn_in_sents(tokenn_in_sent,3.7)051020−100−50050tokenns(tokenn,2.62)change of gaze duration (ms)position in sentenceposition in sentencechange of gaze duration (ms)dundee corpus (english)bccwj-eyetrack(japanese)figure 5: relationship between the lm’s psychometric predictive power and the effect of the syntactic categoryon the surprisal computed by each lm (left part), and that between ppl and the effect of the syntactic category(right part).
each point corresponds to each lm.
the ppl was calculated on the eye movement data, and the lmswith ppl more than 106 was excluded from the right part of the ﬁgure..mity of the processing difﬁculty observed in humanreading time is mirrored by lm surprisals..settings:in a preliminary experiment, we ob-served that the syntactic category (similar to part-of-speech) was the most dominant linguistic factorfor explaining the difference in human gaze dura-tion in japanese sentences (see appendix d).
basedon this observation, we analyze the nonuniformityof surprisals in japanese lms with respect to thesyntactic categories..the segments in bccwj-eyetrack were classi-ﬁed into one of the following syntactic categories:(a) nominal (nouns), (b) verbal (verbs), (c)modifier (adjectives and adverbs), and (d)other entries, as follows:.
kaban-okanojo-gashe-nombag-acc buy-pastnominal modifier nominal verbal.
akaired.
kat-ta.
as asahara and kato (2017) reported, verbaland modifier segments have a shorter gaze dura-tion than the other segments in japanese sentences.
an analysis was conducted on how strongly thejapanese lm’s surprisals on segments are inﬂu-enced by their syntactic category.
this inﬂuencecan be evaluated by examining how effectively syn-tactic category factors can model lm surprisals..in this experiment, surprisal was regarded as“simulated gaze duration” from an “lm subject,”and the importance of syntactic category infor-mation for modeling the simulated gaze duration(simulated gd) was evaluated.
to inspect the.
effect of the syntactic category information formodeling the simulated gaze duration, the follow-ing regression model9 was used, including a factordeﬁning which syntactic category the segment fallsinto (syn category):.
simulated gd ∼ syn category + sentn.
+ tokenn + freq ∗ length ..(4).
from this regression model, a log-likelihoodscore for the simulated gaze duration was ob-to evaluate the separate effect oftained.
syn category, ∆loglik between eq.
4 and abaseline model was calculated.
the baseline modelwas simulated gd ∼ sentn + tokenn +freq ∗ length.
the ∆loglik is denoted as“effect of syntactic category.” a lower score meansthat the lm lacked the property of varying process-ing difﬁculty with respect to the syntactic category..results: the results are shown in figure 5. first,the higher psychometric predictive power the lmsexhibit, the greater the effect of syntactic categoryon surprisals (left part in figure 5).
this meansthat, depending on the syntactic category of thesegment they processed, lms with high psycho-metric predictive power computed surprisals witha more nonuniform trend.
the right part of fig-ure 5 shows that, as ppl decreases below a certainvalue (ppl ∼ 400), the japanese lms compute.
9sentn and tokenn denote the sentence position andthe segment position in a sentence (see appendix b).
note thatthe tokenn and syntactic category exhibit low correlation(0.02 with pearson’s r)..5210trans-smlstmtrans-lgmodel100000number of updates100001000100data sizelgmdsm+n-gram400effectof syntactic categorysurprisals that obscure the nonuniform trends withrespect to the syntactic category of segments.10this trend supports our hypothesis that tuning tolm objectives obscures the human-like nonuni-formity of the processing difﬁculty.
even thoughlms that are not fully tuned to the lm objective(ppl ∼ 400) acquire human-like trends with re-spect to syntactic category, these biases tend to belost by further lowering their ppl..notably, we also observed that not all the typesof linguistic nonuniformity were obscured in sur-prisals computed by the lms with low ppl.
forexample, appendix e shows that lms with lowerppl compute surprisals that better correlates witha particular syntactic factor although that factor isa less dominant trend in human reading behaviorthan the syntactic category (appendix d)..investigation has re-examined the recent report—the lower ppl a lm has, the more human-like thelm is—using japanese eye movement data.
ourexperiments have demonstrated a surprising lackof universality of this report; lower perplexity isnot always human-like.
this discrepancy of theresults between the languages reinforces the needfor the cross-lingual evaluation of the psychomet-ric predictive power of lms.
the discussion con-siders potential factors that make the observationdifferent across languages from the viewpoint ofthe uniform information density hypothesis.
webelieve that this is an important ﬁrst step for seek-ing a language-agnostic model of human sentenceprocessing.
hopefully, this study encourages re-searchers to further investigate the universality ofhuman language processing across languages..6 limitations and future works.
acknowledgements.
to test the universality of the recent ﬁndings incomputational psycholinguistics across languages,the initial focus is on english and japanese as a pairof languages with different linguistic properties.
although the discrepancy of the results in the twolanguages is discussed from the viewpoint of theuid hypothesis, the two languages are also differ-ent in various ways, such as writing systems, agglu-tinative property, case marking, sentence structure,and pro-drop nature.
to identify the difference thatrelates to the human-like behaviors of lms, experi-ments that include additional languages should beconducted in the future..in addition, the corpus size of the bccwj-eyetrack data is smaller than the dundee cor-pus.
while the reading time data in the bccwj-eyetrack was collected from various human sub-jects, the number of the independent segments waslimited (1,643 segments, 218 sentences).
thus,whether the trends reported in this study generalizeto more diverse japanese texts should be exploredin future work.
it is hoped that this study moti-vates the creation of a large-scale corpus of humanreading behaviors in diverse languages..we would like to thank the members at the tohokunlp lab for their valuable advice, particularlyana brassard for proofreading.
this work wassupported by grant-in-aid for jsps fellows grantnumber jp20j22697, jsps kakenhi grant num-ber 19h04990, and jst crest grant number jp-mjcr20d2.
this work was also supported by thenational institute for japanese language and lin-guistics (ninjal) collaborative research project“computational psycholinguistics of language pro-cessing with large corpora.”.
ethical considerations.
language models with low perplexity are typicallytrained with a high computational cost.
our workdemonstrates that further up-scaling the modelsmight not be a reasonable direction of searchingfor human-like language models.
this could po-tentially contribute to reducing energy and carboncosts, which are needed to train large-scale lan-guage models..references.
7 conclusion.
this study has investigated whether the recent re-ports on the psychometric predictive power of lmscan be generalized across languages.
our initial.
10the correlation between ppl and the effect of syntacticcategory in the lms with ppl less than 400 was 0.45 and 0.34with pearson’s r and spearman’s ρ, respectively..masayuki asahara.
2017. between reading time andin proceedings of paclic,.
information structure.
pages 15–24..masayuki asahara.
2018. between reading time andclause boundaries in japanese - wrap-up effect ina head-ﬁnal language.
in proceedings of paclic,pages 19–27..5211masayuki asahara and sachi kato.
2017. betweenreading time and syntactic / semantic categories.
in proceedings of ijcnlp, pages 404–412..masayuki asahara, hajime ono,.
and edson tmiyamoto.
2016.reading-time annotationsfor “balanced corpus of contemporary writtenjapanese”.
in proceedings of coling, pages 684–694..c aurnhammer and s l frank.
2019. comparinggated and simple recurrent neural network archi-tectures as models of human sentence processing.
in proceedings of cogsci, pages 112–118..douglas bates, martin m¨achler, ben bolker, and stevewalker.
2015. fitting linear mixed-effects modelsusing lme4.
journal of statistical software, articles,67(1):1–48..emily m bender.
2011. on achieving and evaluatinglanguage-independence in nlp.
linguistic issuesin language technology, 6(3):1–26..jelke bloem.
2016. testing the processing hypoth-esis of word order variation using a probabilisticin proceedings of the workshoplanguage model.
on computational linguistics for linguistic com-plexity (cl4lc), pages 174–185, osaka, japan.
thecoling 2016 organizing committee..jonathan r brennan, edward p stabler, sarah evan wagenen, wen-ming luh, and john t hale.
2016. abstract linguistic structure correlates withtemporal activity during naturalistic comprehension.
brain and language, 157:81–94..tom b brown, benjamin mann, nick ryder, melaniesubbiah, jared kaplan, prafulla dhariwal, arvindneelakantan, pranav shyam, girish sastry, amandaaskell, sandhini agarwal, ariel herbert-voss,gretchen krueger, tom henighan, rewon child,aditya ramesh, daniel m ziegler, jeffrey wu,clemens winter, christopher hesse, mark chen,eric sigler, mateusz litwin, scott gray, benjaminchess, jack clark, christopher berner, sam mc-candlish, alec radford, ilya sutskever, and darioamodei.
2020. language models are few-shotlearners.
in proceedings of neurips..nicholas carlini, florian tram`er, eric wallace,matthew jagielski, ariel herbert-voss, katherinelee, adam roberts, tom b. brown, dawn song,´ulfar erlingsson, alina oprea, and colin raffel.
2020. extracting training data from large languagemodels.
corr, abs/2012.07805..vera demberg and frank keller.
2008. data from eye-tracking corpora as evidence for theories of syntac-journal of cognition,tic processing complexity.
109(2):193–210..victoria fossum and roger levy.
2012. sequential vs.hierarchical syntactic models of human incremen-tal sentence processing.
in proceedings of cmcl,pages 61–69, montr´eal, canada..stefan l frank and rens bod.
2011. insensitivity ofthe human sentence-processing system to hierar-chical structure.
psychological science, 22(6):829–834..stefan l. frank, leun j. otten, giulia galli, andgabriella vigliocco.
2015. the erp response to theamount of information conveyed by words in sen-tences.
brain and language, 140:1–11..dmitriy genzel and eugene charniak.
2002. entropyrate constancy in text.
in proceedings of the 40th an-nual meeting of the association for computationallinguistics, pages 199–206, philadelphia, pennsyl-vania, usa.
association for computational linguis-tics..adam goodkind and klinton bicknell.
2018. predic-tive power of word surprisal for reading times is ain pro-linear function of language model quality.
ceedings of cmcl2018, pages 10–18..john hale.
2001. a probabilistic earley parser as apsycholinguistic model.
in proceedings of naacl,pages 159–166..john hale, chris dyer, adhiguna kuncoro, andjonathan r. brennan.
2018. finding syntax in hu-in pro-man encephalography with beam search.
ceedings of acl, pages 2727–2736..sepp hochreiter and j¨urgen schmidhuber.
1997. longshort-term memory.
journal of neural computa-tion, 9(8):1735–1780..t jaeger and roger levy.
2007. speakers optimize in-formation density through syntactic reduction.
inadvances in neural information processing systems,volume 19, pages 849–856.
mit press..jared kaplan, sam mccandlish, tom henighan,tom b brown, benjamin chess, rewon child, scottgray, alec radford, jeffrey wu, and dario amodei.
2020. scaling laws for neural language models.
arxiv preprint arxiv:2001.08361..alan kennedy, robin hill, and jo¨el pynte.
2003. thedundee corpus.
in proceedings of the 12th europeanconference on eye movement..lars konieczny.
2000. locality and parsing com-journal of psycholinguistic research,.
plexity.
29(6):627–645..taku kudo.
2006. mecab: yet another part-of-speechand morphological analyzer.
http://mecab.
source-forge.
jp..taku kudo and john richardson.
2018. sentencepiece:a simple and language independent subword tok-enizer and detokenizer for neural text processing.
in proceedings of emnlp, pages 66–71..roger levy.
2005. probabilistic models of word orderand syntactic discontinuity.
stanford university..5212ethan gotlieb wilcox, jon gauthier, jennifer hu, pengqian, and roger levy.
2020. on the predictivepower of neural language models for human real-time comprehension behavior.
in proceedings ofcogsci, pages 1707–1713..roger levy.
2008. expectation-based syntactic com-journal of cognition, 106(3):1126–.
prehension.
1177..luke maurits, dan navarro, and amy perfors.
2010.why are some word orders more common than oth-ers?
a uniform information density account.
in ad-vances in neural information processing systems,volume 23. curran associates, inc..clara meister, ryan cotterell, and tim vieira.
2020.if beam search is the answer, what was the question?
in proceedings of the 2020 conference on empiricalmethods in natural language processing (emnlp),pages 2173–2185, online.
association for computa-tional linguistics..danny merkx and stefan l. frank.
2020. human sen-tence processing: recurrence or attention?
in proc-ceding of cmcl 2021..myle ott, sergey edunov, alexei baevski, angelafan, sam gross, nathan ng, david grangier, andmichael auli.
2019.fairseq: a fast, extensiblein proceedings oftoolkit for sequence modeling.
the 2019 conference of the north american chap-ter of the association for computational linguistics(demonstrations), pages 48–53, minneapolis, min-nesota.
association for computational linguistics..alec radrof, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2018. languagemodels are unsupervised multitask learners.
tech-nical report, openai..keith rayner and arnold d well.
1996. effects of con-textual constraint on eye movements in reading: afurther examination.
psychonomic bulletin & re-view, 3(4):504–509..brian roark, asaf bachrach, carlos cardenas, andchristophe pallier.
2009. deriving lexical and syn-tactic expectation-based measures for psycholinguis-tic modeling via incremental top-down parsing.
inproceedings of emnlp, pages 324–333, singapore..rico sennrich, barry haddow, and alexandra birch.
2016. neural machine translation of rare wordswith subword units.
in proceedings of acl, pages1715–1725..nathaniel j. smith and roger levy.
2013. the effectof word predictability on reading time is logarithmic.
journal of cognition, 128(3):302–319..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allin proceedings of nips, pages 5998–you need.
6008..jason wei, clara meister, and ryan cotterell.
2021. acognitive regularizer for language modeling.
arxivpreprint arxiv:2105.07144..5213figure 6: relationship between ppl (x-axis) and psy-chometric predictive power (y-axis).
each point cor-responds to each lm.
low score on x-axis indicatesthe high linguistic accuracy of the model.
high scoreon y-axis indicates that the model has a high psycho-metric predictive power.
note that x-axis is on a logscale.
the shape, color, and size of each point is sameas figure 2..figure 7: relationship between ppl (x-axis) and theeffect of the anti-locality (y-axis).
each point corre-sponds to each lm.
low score on x-axis indicates thehigh linguistic accuracy of the model.
high score on y-axis indicates that the surprisals computed by the cor-responding model are highly biased towards the anti-locality effect.
note that x-axis is on a log scale.
theshape, color, and size of each point is same as figure 2..a hyperparameters of lms.
table 2 shows the hyperparameters of trans-sm,trans-lg, and lstm, respectively.
note that thenumber of parameter updates varies as describedin section 3..b factors used in regression models.
descriptions for the factors used in our experimentsare shown in table 3. the frequency of a segment(freq) was estimated using the full training datafor the lms..c results of modeling logarithmic gazeduration in bccwj-eyetrack.
existing studies (asahara et al., 2016) performedexperiments using the logarithmic gaze duration be-cause the logarithmic gaze duration more matchesthe normal distribution than the raw gaze duration.
given this, we additionally conducted experimentsin section 4, changing the target variable from theraw gaze duration to its logarithmic gaze duration.
the result with this setting is shown in figure 6.there was no substantial difference with the resultsshown in section 4..d preliminary experiments in section 5.which linguistic factor is helpful for explaining thedifference in gaze duration?
we conducted experi-ments using linguistic annotation in the bccwj-eyetrack.
following the existing studies, we.
checked the separate effect of syntactic category,semantic category (asahara and kato, 2017), and aparticular aspect of hierarchical syntactic structure(i.e., the anti-locality effect) (asahara et al., 2016).
speciﬁcally, we used the factors, syn category,sem category, and n dependents, shown intable 3. for each factor, we inspect the separateeffect of each factor for modeling gaze duration.
as eq.
4, we ﬁrst modeled the gaze duration usingeach factor (factor x):.
gd ∼ factor x + sentn.
+ segmentn + freq ∗ length ..(5).
then, we calculated the ∆loglik between x anda baseline model.
the baseline model was gd ∼sentn + segmentn + freq ∗ length..the ∆loglik for each collection of factors areshown in 5. we found that syntactic category is themost inﬂuential factor for modeling gaze duration,at least in this experiment..e anti-locality effect in lms.
similar to section 5, we analyzed how stronglythe surprisals from each japanese lm are biasedtowards a particular linguistic property.
in thissection, we investigated the anti-locality effect inthe surprisals from lms.
the anti-locality is thatthe more dependents a segment has in its preceding.
5214context, the cognitive effort of the head segmentis reduced (i.e., modiﬁers alleviate the processingcost of their head)..analogous to the section 5, we regarded sur-prisal as “simulated gaze duration” from an “lmsubject,” and evaluated the importance of thenumber of the dependents in its preceding con-text (n dependents) for modeling the simulatedgaze duration (simulated gd).
to inspect theeffect of the n dependents for modeling thesimulated gaze duration, we used the followingregression model:.
simulated gd ∼ n dependents + sentn.
+ tokenn + freq ∗ length ..(6).
from this regression model, we obtained a log-likelihood score for the simulated gaze duration.
to evaluate the separate effect of n dependents,we calculated the ∆loglik between eq.
6 anda baseline model.
the baseline model wassimulated gd ∼ sentn + segmentn +freq ∗ length.
the ∆loglik is denoted as“effect of the anti-locality.”.
the results are shown in figure 7. there is aclear trend that the lms with lower ppl exhibitsurprisals that are more consistent with the anti-locality effect (spearman’s ρ = −0.77 betweenppl and the strength of the anti-locality effect).
this suggests that the surprisals from lms with lowppl are biased towards the hierarchical structureof sentences rather than the syntactic category..5215architectureadaptive softmax cut offshare-decoder-input-output-embedembed dimffn embed dimlayersheadsdropoutattention dropout.
transformer lm gpt2 small50,000, 140,000true1,0244,09624160.10.1.fairseq model.
optimizer.
learning rate scheduler.
training.
algorithmlearning ratesbetasweight decayclip norm.
typewarmup updateswarmup init lrarning rate.
batch sizesample-break-mode.
(a) trans-lg..architectureadaptive softmax cut offshare-decoder-input-output-embedembed dimffn embed dimlayersheadsdropoutattention dropout.
transformer lm gpt50,000, 140,000true3842,048860.10.1.fairseq model.
optimizer.
learning rate scheduler.
training.
fairseq model.
optimizer.
learning rate scheduler.
training.
algorithmlearning ratesbetasweight decayclip norm.
typewarmup updateswarmup init lrarning rate.
batch sizesample-break-mode.
(b) trans-sm..algorithmlearning ratesbetasweight decayclip norm.
typewarmup updateswarmup init lrarning rate.
batch sizesample-break-mode.
(c) lstm..table 2: hyperparameters for the lms..architectureadaptive softmax cut offshare-decoder-input-output-embedembed dimhiden sizelayersdropout.
lstm lm50,000, 140,000true4001,02420.1.adamw5e-4(0.9, 0.98)0.010.0.inverse sqrt4,0001e-7.
61,440 tokensnone.
adamw5e-4(0.9, 0.98)0.010.0.inverse sqrt4,0001e-7.
61,440 tokensnone.
adamw1e-3(0.9, 0.98)0.010.0.inverse sqrt4,0001e-7.
20,480 tokensnone.
5216factor name.
type description.
surprisalgdarticlescreennlinensegmentnsentntokennlengthfreq.
subj.
numnumfactorintintintintintintnum.
factor.
surprisal caluzulted by lmsreading time (ﬁrst pass time)article idscreen display orderthe serial number of line the segment is displayedthe serial number of segment in a screenthe serial number of sentence the segment belongs tothe position of segment in sentencenumber of charactersgeometric mean of the frequencies of subword constituents in asegmentparticipant id.
syn category factor.
sem category factor.
n dependents int.
syntactic category the segment falls into (nominal, verbal,modifier, or other)semantic category the segment falls into (relation, subject,action, product, or nature)number of dependents before the segment.
table 3: factor names and their description..syntactic category.
number of segments avg.
gaze duration.
nominalverbalmodifierother.
4,3221,0905889.
388.4291.0297.1239.3.table 4: the statistics of the syntactic category labels in bccwj-eyetrack..linguistic property ∆loglik.
syntactic categorysemantic categorynumber of dependents.
58.3717.0813.84.table 5: the separate effect of each linguistic annotation for modeling gaze duration..5217