probabilistic, structure-aware algorithms for improved variety,accuracy, and coverage of amr alignments.
austin blodgett nathan schneidergeorgetown university{ajb341, nathan.schneider}@georgetown.edu.
abstract.
we present algorithms for aligning compo-nents of abstract meaning representation(amr) graphs to spans in english sentences.
we leverage unsupervised learning in combi-nation with heuristics, taking the best of bothworlds from previous amr aligners.
our un-supervised models, however, are more sensi-tive to graph substructures, without requiring aseparate syntactic parse.
our approach coversa wider variety of amr substructures than pre-viously considered, achieves higher coverageof nodes and edges, and does so with higheraccuracy.
we will release our leamr datasetsand aligner for use in research on amr pars-ing, generation, and evaluation..1.introduction.
research with the abstract meaning represen-tation (amr; banarescu et al., 2013), a broad-coverage semantic annotation framework in whichsentences are paired with directed acyclic graphs,must contend with the lack of gold-standard align-ments between words and semantic units in theenglish data.
a variety of rule-based and statisticalalgorithms have sought to fill this void, with im-provements in alignment accuracy often translatinginto improvements in amr parsing accuracy (pour-damghani et al., 2014; naseem et al., 2019; liuet al., 2018).
yet current alignment algorithms stillsuffer from limited coverage and less-than-idealaccuracy, constraining the design and accuracy ofparsing algorithms.
where parsers use latent align-ments (e.g., lyu and titov, 2018; cai and lam,2020), explicit alignments can still facilitate evalu-ation and error analysis.
moreover, amr-to-textgeneration research and applications using amrstand to benefit from accurate, human-interpretablealignments..we present linguistically enriched amr(leamr) alignment, which achieves full graph cov-.
erage via four distinct types of aligned structures:subgraphs, relations, reentrancies, and duplicatesubgraphs arising from ellipsis.
this formulationlends itself to unsupervised learning of alignmentmodels.
advantages of our algorithm and releasedalignments include: (1) much improved coverageover previous datasets, (2) increased variety of thesubstructures aligned, including alignments for allrelations, and alignments for diagnosing reentran-cies, (3) alignments are made between spans andconnected substructures of an amr, (4) broaderidentification of spans including named entities andverbal and prepositional multiword expressions..contributions are as follows:• a novel all-inclusive formulation of amralignment in terms of mappings betweenspans and connected subgraphs, includingspans aligned to multiple subgraphs; map-pings between spans and inter-subgraphedges; and characterization of reentrancies.
together these alignments fully cover thenodes and edges of the amr graph (§3).
• an algorithm combining rules and em toalign english sentences to amrs without su-pervision (§5), achieving higher coverage andquality than existing amr aligners (§7).
• a corpus with automatic alignments forldc2020 and little prince data as well asa few hundred manually annotated sentencesfor tuning and evaluation (§4)..we release this dataset of alignments for over60,000 sentences along with our aligner code tofacilitate more accurate models and greater inter-pretability in future amr research..2 related work.
the main difficulty presented by amr alignmentis that it is a many-to-many mapping problem, withgold alignments often mapping multiple tokens to.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3310–3321august1–6,2021.©2021associationforcomputationallinguistics3310multiple nodes while preserving amr structure.
previous systems use various strategies for aligning.
they also have differing approaches to what typesof substructures of amr are aligned—whetherthey are nodes, subgraphs, or relations—and whatthey are aligned to—whether individual tokens, to-ken spans, or syntactic parses.
two main alignmentstrategies remain dominant, though they may becombined or extended in various ways: rule-basedstrategies as in flanigan et al.
(2014), flaniganet al.
(2016), liu et al.
(2018), and szubert et al.
(2018), and statistical strategies using expectation-maximization as in pourdamghani et al.
(2014).
jamr.
the jamr system (flanigan et al., 2014,2016) aligns token spans to subgraphs using itera-tive application of an ordered list of 14 rules whichinclude exact and fuzzy matching.
jamr align-ments form a connected subgraph of the amr bythe nature of the rules being applied.
a disadvan-tage of jamr is that it lacks a method for resolvingambiguities, such as repeated tokens, or of learningnovel alignment patterns.
isi.
the isi system (pourdamghani et al., 2014)produces alignments between tokens and nodes andbetween tokens and relations via an expectation-maximization (em) algorithm in the style of ibmmodel 2 (brown et al., 1988).
first, the amr islinearized; then em is applied using a symmetrizedscoring function of the form p(a ∣ t) + p(t ∣ a),where a is any node or edge in the linearized amrand t is any token in the sentence.
graph connect-edness is not enforced for the elements aligning toa given token.
compared to jamr, isi producesmore novel alignment patterns, but also struggleswith rare strings such as dates and names, where arule-based approach is more appropriate.
extensions and combinations.
tamr (tunedabstract meaning representation; liu et al., 2018)uses the jamr alignment rules, along with twoothers, to produce a set of candidate alignmentsfor the sentence.
then, the alignments are “tuned”with a parser oracle to select the candidates thatcorrespond to the oracle parse that is most similarto the gold amr..some amr parsers (naseem et al., 2019; fer-nandez astudillo et al., 2020) use alignments whichare a union of alignments produced by the jamrand isi systems.
the unioned alignments achievegreater coverage, improving parser performance.
syntax-based.
several alignment systems at-tempt to incorporate syntax into amr alignments..jamrisitamr∗.
nodes91.178.794.9.edges✗9.8✗.
reentrancies✗✗✗.
table 1: coverage and types of previous alignment sys-tems.
scores are evaluated on 200 gold test sentences.
∗tamr is evaluated on a subset of 91 sentences..chen and palmer (2017) perform unsupervised emalignment between amr nodes and tokens, takingadvantage of a universal dependencies (ud) syn-tactic parse as well as named entity and semanticrole features.
szubert et al.
(2018) and chu andkurohashi (2016) both produce hierachical (nested)alignments between amr and a syntactic parse.
szubert et al.
use a rule-based algorithm to alignamr subgraphs with ud subtrees.
chu and kuro-hashi use a supervised algorithm to align amrsubgraphs with constituency parse subtrees.
word embeddings.
additionally, anchiêta andpardo (2020) use an alignment method designed towork well in low-resource settings using pretrainedword embeddings for tokens and nodes.
graph distance.
wang and xue (2017) use anhmm-based aligner to align tokens and nodes.
they include in their aligner a calculation of graphdistance as a locality constraint on predicted align-ments.
this is similar to our use of projectiondistance as described in §5.
drawbacks of current alignments.
align-ment methods vary in terms of components of theamr that are candidates for alignment.
most sys-tems either align nodes (e.g., isi) or connectedsubgraphs (e.g., jamr), with incomplete cover-age.
most current systems do not align relationsto tokens or spans, and those that do (such as isi)do so with low coverage and performance.
noneof the current systems align reentrancies, althoughszubert et al.
(2020) developed a rule-based set ofheuristics for identifying reentrancy types.
table 1summarizes the coverage and variety of prominentalignment systems..3 an all-inclusive formulation of amr.
alignment.
aligning amrs to english sentences is a vexingproblem not only because the english training datalacks gold alignments, but also because amrs—unlike many semantic representations—are not de-signed with a derivational process of form–functionsubunits in mind.
rather, each amr graph repre-sents the full-sentence meaning, and amr anno-.
3311(w / want-01.
:arg0 (p / person.
:arg0-of (s / study-01):arg1-of (i / include-91:arg2 (p2 / person.
:arg0-of (s2 / study-01)).
:arg3 (m / most))).
:arg1 (v / visit-01.
:arg0 p:arg1 (c / city :name (n / name:op1 "new" :op2 "york")).
:time (g / graduate-01.
:arg0 p))).
subgraph alignmentsmost → m,of → i,the → ∅,.
students → (p :arg0-of s),.
want → w,to → ∅,visit → v,new york → (c :name(n :op1 "new" :op2 "york")),.
relation alignmentsof → s :arg1-of i,.
i :arg2 p2,i :arg3 m;want → w :arg0 p,w :arg1 v;visit → v :arg0 p,v :arg1 c;graduate → g :arg0 p;when → v :time g.when → ∅,they → ∅,graduate → g.duplicate subgraphsstudents → (p2 :arg0-of s2).
reentrancy alignmentswant → w :arg0 p (primary),v :arg0 p (control);.
they → g :arg0 p (coref).
figure 1: amr and alignments for the sentence “most of the students want to visit new york when they graduate.”alignments are differentiated by colors: blue (subgraphs), green (duplicate subgraphs), and orange (relations).
relations that also participate in reentrancy alignments are bolded..tation conventions can be opaque with respect tothe words or surface structure of the sentence, e.g.,by unifying coreferent mentions and making ex-plicit certain elided or pragmatically inferable con-cepts and relations.
previous efforts toward generaltools for amr alignment have considered mappingtokens, spans, or syntactic units to nodes, edges,or subgraphs (§2).
other approaches to amralignment have targeted specific compositional for-malisms (groschwitz et al., 2018; beschke, 2019;blodgett and schneider, 2019)..we advocate here for a definition of alignmentthat is principled—achieving full coverage of thegraph structure—while being framework-neutraland easy-to-understand, by aligning graph sub-structures to shallow token spans on the form side,rather than using syntactic parses.
we do use struc-tural considerations to constrain alignments on themeaning side, but by using spans on the form side,we ensure the definition of the alignment searchspace is not at the mercy of error-prone parsers..definitions.
given a tokenized sentence w andits corresponding amr graph g, a complete align-ment assumes a segmentation of w into spans s,each containing one or more contiguous tokens;and puts each of the nodes and edges of g in cor-respondence with some span in s. a span may bealigned to one or more parts of the amr, or else isnull-aligned.
individual alignments for a sentenceare grouped into four layers: subgraph alignments,duplicate subgraph alignments, relation alignments,and reentrancy alignments.
these are given for anexample in figure 1..all alignments are between a single span and asubstructure of the amr.
a span may be aligned.
in multiple layers which are designed to capturedifferent information.
within the subgraph layer,alignments are mutually exclusive with respect toboth spans and amr components.
the same holdstrue within the relation layer.
every node will bealigned exactly once between the subgraph and du-plicate subgraph layers.
every edge will be alignedexactly once between the subgraph and relation lay-ers, and may additionally have a secondary align-ment in the reentrancy layer..3.1 subgraph layer.
alignments in this layer generally reflect the lexicalsemantic content of words in terms of connected,1directed acyclic subgraphs of the correspondingamr.
alignments are mutually exclusive (disjoint)on both the form and meaning sides..3.2 duplicate subgraph layer.
a span may be aligned to multiple subgraphs ifone is a duplicate of the others, with a matchingconcept.
this is often necessary when dealing withellipsis constructions, where there is more semanticcontent in the amr than is pronounced in the sen-tence and thus several identical parts of the amrmust be aligned to the same span.
in this case, asingle subgraph is chosen as the primary alignment(whichever is first based on depth-first order) andis aligned in the subgraph alignment layer, and anyothers are represented in the duplicates alignment.
1nodes aligned to a span must form a connected subgraphwith two exceptions: (1) duplicate alignments are allowedand are separated into subgraph and duplicate layers; (2) aspan may be aligned to two terminal nodes that have the sameparent.
for example, never aligns to :polarity - :timeever, two nodes and two edges which share the same parent..3312layer.
for example, verb phrase ellipsis, as in iswim and so do you, would involve duplication ofthe predicate swim, with distinct arg0s.
similarly,in figure 1, most of the students involves a subset-superset structure where the subset and supersetcorrespond to separate nodes.
because student isrepresented in amr like person who studies, thereare two 2-node subgraphs aligned to student, onewith the variables p and s, and the duplicate withp2 and s2.
the difficulty that duplicate subgraphspose for parsing and generation makes it conve-nient to put these alignments in a separate layer..3.3 relation layer.
this layer includes alignments between a spanand a single relation—such as when → :time—and alignments mapping a span to its argumentstructure—such as give → :arg0 :arg1 :arg2.
all edges in an amr that are not contained ina subgraph fit into one of these two categories..english function words such as prepositions andsubordinators typically function as connectives be-tween two semantically related words or phrases,and can often be identified with the semantics ofamr relations.
but many of these function wordsare highly ambiguous.
relation alignments maketheir contribution explicit.
for example, when infigure 1 aligns to a :time relation..for spans that are aligned to a subgraph, incom-ing or outgoing edges attached to that subgraphmay also be aligned to the span in the relation layer.
these can include core or non-core roles as longas they are evoked by the token span.
for example,figure 1 contains visit → :arg0 :arg1..3.4 reentrancy layer.
a reentrant node is one with multiple incomingedges.
in figure 1, for example, p appears threetimes: once as the arg0 of w (the wanter), once asthe arg0 of v (the visitor), and once as the arg0 ofg (the graduate).
the p node is labeled with theconcept person—in the penman notation usedby annotators, each variable’s concept is only desig-nated on one occurrence of the variable, the choiceof occurrence being, in principle, arbitrary.
thesethree arg0 relations are aligned to their respectivepredicates in the relation layer.
but there are manydifferent causes of reentrancy, and amr parsersstand to benefit from additional information aboutthe nature of each reentrant edge, such as the factthat the pronoun they is associated with one of thearg0 relations..the reentrancy layer “explains” the cause ofeach reentrancy as follows: for the incoming edgesof a reentrant node, one of these edges is designatedas primary—this is usually the first mention ofthe entity in a local surface syntactic attachment,e.g.
the argument of a control predicate like wantdoubles as an argument of an embedded clausepredicate.
the remaining incoming edges to a reen-trant node are aligned to a reentrancy trigger andlabeled with one of 8 reentrancy types: coref, rep-etition, coordination, control, adjunct control, un-marked adjunct control, comparative control, andpragmatic.
these are illustrated in table 2. thesetypes, adapted from szubert et al.’s (2020) classifi-cation, correspond to different linguistic phenom-ena leading to amr reentrancies—anaphoric andnon-anaphoric coreference, coordination, control,etc.
the trigger is the word that most directly sig-nals the reentrancy phenomenon in question.
forthe example in figure 1, the control verb want isaligned to the embedded predicate–argument re-lation and typed as control, while the pronounthey serves as the trigger for the third instance of pin when they graduate..3.5 validation.
to validate the annotation scheme we elicited twogold-standard annotations for 40 of the test sen-tences described in §4 and measured interannotatoragreement.2 interannotator exact-match f1 scoreswere 94.54 for subgraphs, 90.73 for relations, 76.92for reentrancies, and 66.67 for duplicate subgraphs(details in appendix a)..4 released data.
we release a dataset3 of the four alignment lay-ers reflecting correpondences between english textand various linguistic phenomena in gold amrgraphs—subgraphs, relations (including argumentstructures), reentrancies (including coreference,control, etc.
), and duplicate subgraphs..automatic alignments cover the ≈60,000 sen-tences of the ldc2020t02 dataset (knight et al.,2020) and ≈1,500 sentences of the little prince..we manually created gold alignments for eval-uating our automatic aligner, split into a develop-ment set (150 sentences) and a test set (200 sen-.
2both annotators are ph.d. students with backgrounds inlinguistics.
one annotator aligned all development and testsentences; the other aligned a subset of 40 test sentences..3.https://github.com/ablodge/leamr.
3313coref.
repetition.
coordination.
control.
type triggered by.
a pronoun (including possessive or reflexive)(anaphora)a repeated name or non-pronominal phrase(non-anaphoric coreference)coordination of two or more phrases sharingan argumentcontrol verbs, control nouns, or controladjectivescontrol within an adjunct phrase.
control within an adjunct phrase with only abare verb and no subordinating conjunctiona comparative constructionreentrancies that must be resolved usingcontext.
examplei love my house.
the u.s. promotes american goods.
they cheered and celebrated.
i was afraid to speak up.
i left to buy some milk; mary cookedwhile listening to musicmary did her homework listening tomusicbe as objective as possiblejohn met up with a friend.
adjunct control.
unmarked adjunct control.
comparative controlpragmatic.
table 2: reentrancy types with examples.
for each reentrant node, one of its incoming edges is labeled primaryand the others are labeled with one of the above reentrancy types.
in the examples, the word aligned to an edgelabeled with the specified type is underlined, and the word aligned to the parent of that edge is bolded..(h / have-degree-91.
:arg1 (h2 / house :location (l / left)):arg2 (b / big):arg3 (m / more):arg4 (h3 / house :location (r / right))).
figure 2: amr for the sentence “the house1 on theleft is bigger than the house2 on the right.”.
tences).4 the test sentences were annotated fromscratch; the development sentences were first au-tomatically aligned and then hand-corrected.
westress that no preprocessing apart from tokeniza-tion is required to prepare the test sentences andamrs for human annotation.
we also release ourannotation guidelines as a part of our data release..5 leamr aligner.
we formulate statistical models for the alignmentlayers described above—subgraphs, duplicatesubgraphs, relations, and reentrancies—and usethe expectation-maximization (em) algorithm toestimate probability distributions without supervi-sion, with a decoding procedure that constrainsaligned units to obey structural requirements.
inline with flanigan et al.
(2014, 2016), we use rule-based preprocessing to align some substructuresusing string-matching, morphological features, etc.
before delving into the models and algorithm,.
we motivate two important characteristics:structure-preserving.
constraints on legal can-didates during alignment ensure that at any point.
4our test set consists of sentences from the test set ofszubert et al.
(2018) but with amrs updated to the latestrelease version.
this test set contains a mix of english sen-tences drawn from the ldc data and the little prince—somesampled randomly, others hand-selected—as well as severalsentences constructed to illustrate particular phenomena..only connected substructures may be aligned to aspan.
thus, while our aligner is probabilistic likethe isi aligner, it has the advantage of preservingthe amr graph structure.
projection distance.
the scores calculated foran alignment take into account a distance metricdesigned to encourage locality—tokens that areclose together in a sentence are aligned to subtruc-tures that are close together in the amr graph.
we define the projection distance dist(n1, n2) be-tween two neighboring nodes n1 and n2 to be thesigned distance in the corresponding sentence be-tween the span aligned to n1 and the span alignedto n2.
this motivates the model to prefer align-ments whose spans are close together when align-ing nodes which are close together—particularlyuseful when a word occurs twice with identicalsubgraphs.
thus, our aligner relies on more infor-mation from the amr graph structure than otheraligners (note that the isi system linearizes thegraph).
further details are given in §5.2..5.1 overview.
algorithm 1 illustrates our base algorithm in pseu-docode.
the likelihood for a sentence can be ex-pressed as a sum of per-span alignment scores: wewrite the score of a full set of a sentence’s subgraphalignments a as.
score(a ∣ g,w) =.
score(⟨gi,si⟩ ∣ g,w).
(1).
n∏i=1.
where s are n aligned spans in the sentence w, andg are sets of subgraphs of the amr graph g alignedto each span.
for relations model and the reentran-cies model, each gi consists of relations rather than.
3314subgraphs.
henceforth we assume all alignmentscores are conditioned on the sentence and graphand omit w and g for brevity.
the score(⋅) compo-nent of eq.
(1) is calculated differently for each ofthe three models detailed below..alignment pipeline.
alignment proceeds in thefollowing phases, with each phase depending onthe output of the previous phase:1. preprocessing: using external tools we extractlemmas, parts of speech, and coreference.
2. span segmentation: tokens are grouped intospans using a rule-based procedure (appendix b).
3. align subgraphs & duplicate subgraphs: wegreedily identify subgraph and duplicate subgraphalignments in the same alignment phase (§5.2).
4. align relations: relations not belonging to asubgraph are greedily aligned in this phase, usingpos criteria to identify legal candidates (§5.3).
5. align reentrancies: reentrancies are aligned inthis phase, using pos and coreference in criteriafor identifying legal candidates (§5.4)..the three main alignment phases use differentmodels with different parameters; they also havetheir own preprocessing rules used to identify somealignments heuristically (appendices c to e).5 intraining, parameters for each phase are iterativelylearned and used to align the entire training set byrunning em to convergence before moving on tothe next phase.
at test time, the pipeline can be runsentence-by-sentence..decoding.
the three main alignment phases alluse essentially the same greedy, substructure-awaresearch procedure.
this searches over node–spancandidate pairs based on the scoring function mod-eling the compatibility between a subgraph (or re-lation) g and span s, which we denote score(⟨g,s⟩).
for each unaligned node (or edge), we identify a setof legal candidate alignments using phase-specificcriteria.
the incremental score improvement ofadding each candidate—either extending a sub-graph/set of relations already aligned to the span, oradding a completely new alignment—is calculatedas as ∆score = score(⟨g0 ∪ {n},s⟩) − score(⟨g0,s⟩),where g0 is the current aligned subgraph, s is thespan, and n is an amr component being consid-ered.
of the candidates for all unaligned nodes, thenode–span pair giving the best score improvementis then greedily selected to add to the alignment..579% of nodes and 89% of edges are aligned by rules.
webelieve this is why in practice, em performs well withoutrandom restarts..this is repeated until all nodes have been aligned(even if the last ones decrease the score).
the pro-cedure is detailed in algorithm 1 for subgraphs; therelations phase and the reentrancies phase use dif-ferent candidates (respectively: unaligned edges;reentrant edges), different criteria for legal candi-dates, and different scoring functions..5.2 aligning subgraphs.
the score assigned to an alignment between a spanand subgraph is calculated as score(⟨g,s⟩) =.
palign(g ∣ s;θ1) ⋅ ∏di∈d.
1.pdist(di;θ2).
∣d∣ ⋅ ib(g,s).
(2).
where g is a subgraph, s is a span, di is the projec-tion distance of g with its ith neighboring node, andθ1 and θ2 are model parameters which are updatedafter each iteration.
the subgraph g is representedin the model as a bag of concept labels and (parentconcept, relation, child concept) triples..the distributions palign and pdist are inspired byibm model 2 (brown et al., 1988), and can bethought of as graph-theoretic extensions of transla-tion (align) and alignment (dist) probabilities.
ibstands for inductive bias, explained below.
legal candidates.
for each unaligned node n,the model calculates a score for spans of three possi-ble categories: 1) unaligned spans; 2) spans alignedto a neighboring node (in this case, the aligner con-siders adding n to an existing subgraph if the re-sulting subgraph would be connected); 3) spansaligned to a node with the same concept as n (thisallows the aligner to identify duplicate subgraphs—candidates in this category receive a score penaltybecause duplicates are quite rare, so they are gener-ally the option of last resort)..limiting the candidate spans in this way en-sures only connected, plausible substructures of theamr are aligned.
to form a multinode subgraphalignment t1 → n1 :rel n2, the aligner could firstalign n1 to an unaligned span t1, then add n2, whichis a legal candidate because t1 is aligned to a neigh-boring node of n2 (ensuring a connected subgraph).
distance.
we model the probability of the pro-jection distance pdist(d;θ2) using a skellam dis-tribution, which is the difference of two poissondistributed random variables d = n1 −n2 and can bepositive or negative valued.
parameters are updatedbased on alignments in the previous iteration.
foreach aligned neighbor ni of a subgraph g, we cal-culate pdist(dist(g,ni);θ2) and take the geometricmean of probabilities as pdist..3315alignments ← dict()unaligned_nodes ← get_unaligned_nodes(amr, alignments)while ∣unaligned_nodes∣ > 0 do.
algorithm 1 procedure for greedily aligning all nodes to spans using a scoring function that decomposesover (span, subgraph) pairs.
(scores are expressed in real space but the implementation is in log space.)
1: function alignsubgraphs(spans, amr)2:3:4:5:6:7:8:9:.
candidate_spans ← get_legal_alignments(n, alignments)for span, i_subgraph ∈ candidate_spans do.
∆scores ← []candidate_s_g_pairs ← []for n ∈ unaligned_nodes do.
▷either there is an edge between n and the indicated subgraph.
▷map from span to an ordered list of aligned subgraphs.
already aligned to span, or i_subgraph would be a new subgraph consisting of n.▷∅ if this would be a new subgraph.
current_aligned_nodes ← alignments[span][i_subgraph]new_aligned_nodes ← current_aligned_nodes ∪ {n}∆score ← get_score(span, new_aligned_nodes, alignments).
− get_score(span, current_aligned_nodes, alignments).
▷change from adding n into a subgraph.
aligned to span; get_score queries score(⟨g, s⟩) and multiplies λdup if i_subgraph > 1.
∆scores.add(∆score)candidate_s_g_pairs.add((span, new_aligned_nodes, i_subgraph)).
span∗, subgraph∗, i_subgraph∗ ← candidate_s_g_pairs[argmax(∆scores)] ▷update having the best impact on score.
(equivalently, maximizing sum of scores across individual aligned spans).
alignments[span∗][i_subgraph∗] ← subgraph∗unaligned_nodes ← get_unaligned_nodes(amr, alignments).
return alignments.
10:11:12:13:.
14:15:16:.
17:18:19:.
null alignment.
the aligner models the possibil-ity of a span being unaligned using a fixed heuristic:.
palign(∅ ∣ s) = max{rank(s).
− 12 ,0.01}.
(3).
where rank assigns 1 to the most frequent word,2 to the 2nd most frequent, etc.
thus, the modelexpects that very common words are more likelyto be null-aligned and rare words should almostalways be aligned.6factorized backoff.
so that the aligner general-izes to unseen subgraph–span pairs, where palign(g ∣s) = 0, we use a backoff factorization into compo-nents of the subgraph.
in particular, the factorsare empirical probabilities of (i) an amr conceptgiven a span string in the sentence, and (ii) a rela-tion and child node concept given the parent nodeconcept and span string.
these cooccurrence prob-abilities pˆ are estimated directly from the trainingsentence/amr pairs (irrespective of latent align-ments).
the product is scaled by a factor λ .
e.g.,for a subgraph n1 :rel1 n2 :rel2 n3, where cnis the concept of node n, we have.
pfactorized(g ∣ s) = λ ⋅ pˆ (cn1 ∣ s)⋅ pˆ (:rel1, cn2 ∣ cn1,s)(4).
⋅ pˆ (:rel2, cn3 ∣ cn1,s).
inductive bias.
lastly, to encourage good initial-ization, the score function includes an inductive.
6we allow several exceptions.
for punctuation, words inparentheses, and spans that are coreferent to another span, theprobability is 0.5. for repeated spans, the probability is 0.1..bias which does not depend on em-trained param-eters.
this inductive bias is based on the empiricalprobability of a node occurring in the same amrwith a span in the training data.
we calculate in-ductive bias as an average of exponentiated pmis1n ∑i exp(pmi(ni,s)), where n is the number ofnodes in g, ni is the ith node contained in the sub-graph, and pmi is the pmi of ni and s.aligning duplicate subgraphs.
on rare occa-sion a span should be aligned to multiple subgraphs(§3.2).
to encourage the model to align a differentspan where possible, there is a constant penaltyλdup for each additional subgraph aligned to a spanbeyond the first.
thus the score for a span and itssubgraphs is computed as:.
score(⟨g,s⟩) = λ ∣g∣−1.
dup ∏g∈g.
score(⟨g,s⟩).
(5).
5.3 aligning relations.
for a given relation alignment between a span and acollection of edges, we calculate a score as follows:.
score(⟨a,s⟩) = palign(a ∣ s;θ3) ⋅ ∏di∈d1.
pdist(di;θ4).
1∣d1∣.
pdist(d j;θ5).
1∣d2∣.
(6).
⋅ ∏d j∈d2.
where a is the argument structure (the collectionof aligned edges), s is a span, d1 is the projectiondistances of each edge and its parent, and d2 is.
3316exact alignr.p.partial alignr.f1subgraph alignments (n = 1707).
f1.
p.f1.
spans coverage.
our systemjamrisitamr (91 sentences).
93.9187.2171.5685.68.
94.0283.0668.2483.38.
93.9785.0969.8684.51.
95.6990.2978.0388.62.
95.8185.9974.5486.24.
95.7588.0976.2487.41.relation alignments (n = 1263).
our systemisi.
85.6759.28.
85.378.51.
85.5214.89.
88.7466.32.
88.449.52.
88.5916.65.ours (labeled)ours (unlabeled).
55.7562.72.
54.6161.43.our system.
66.67.
58.82.reentrancy alignments (n = 293).
--.
55.1762.07.
--duplicate subgraph alignments (n = 17)-.
65.62.
62.50.
61.76.
70.00.
--.
--.
96.0592.3886.5993.64.
95.4183.09.
100.091.178.794.9.
100.09.8.
100.0100.0.
100.0.table 3: main results on the test set.
n represents the denominator of exact alignment recall.
there are 2860 goldspans in total, 41% of which are null-aligned and 0.6% of which are aligned to multiple subgraphs.
95% of thespans consist of a single token, and 49% of spans are aligned to a single subgraph consisting of a single node..the projection distances of each edge and its child.
the collection of edges a is given a normalizedlabel which represents the relations contained inthe alignment (distinguishing incoming versus out-going relations, and normalizing inverse edges)..legal candidates.
there are two kinds of candi-date spans for relation alignment.
first, previouslyunaligned spans7 (with no relation or subgraphalignments), e.g.
prepositions and subordinatingconjunctions such as in → :location or when →:time.
second, any spans aligned to the relation’sparent or child in the subgraph layer: this facilitatesalignment of argument structures such as give →:arg0 :arg1 :arg2.
additionally, we constraincertain types of edges to only align with the parentand others to only align with the child..distance.
for relations there are potentially twodistances of interest—the projected distance of therelation from its parent and the projected distanceof the relation from its child.
we model theseseparately as parent distance and child distancewith distinct parameters.
to see why this is use-ful, consider the sentence “should we meet at therestaurant or at the office?”, where each at tokenshould be aligned to a :location edge.
in english,prepositions like at precede an object and follow agovernor.
thus parent distance tends to be to theleft (negative valued) while child distance tends tobe to the right (positive valued)..7we constrain these to particular parts of speech: prepo-sitions (in), infinitival to (to), possessives (pos), and pos-sessive pronouns (prp$).
additionally, only spans that arebetween the spans aligned to the parent and any descendentof child nodes of the relation (and are not between the child’saligned span and any of its descendants’ spans) are allowed.
this works well in practice for english..5.4 aligning reentrancies.
the probability of a reentrancy alignment is sim-ilar to eq.
(6), but with an extra variable for thereentrancy type: score(⟨r,s,type⟩) =.
palign(r,type ∣ s;θ6) ⋅ pdist(d1;θ7) ⋅ pdist(d2;θ8) (7).
where r is the role label of the reentrant edge..legal candidates.
there are 8 reentrancy types(§3.4).
for each type, a rule-based test determinesif a span and edge are permitted to be aligned.
the8 tests use part of speech, the structure of the amr,and subgraph and relation alignments.
a span maybe aligned (rarely) to multiple reentrancies, butthese alignments are scored separately..6 experimental setup.
sentences are preprocessed with the stanza library(qi et al., 2020) to obtain lemmas, part-of-speechtags, and named entities.
we identify token spansusing a combination of named entities and a fixedlist of multiword expressions (details are givenin appendix b).
coreference information, whichis used to identify legal candidates in the reen-trancy alignment phase, is obtained using neural-coref.8 lemmas are used in each alignment phaseto normalize representation of spans, while partsof speech and coreference are used to restrict legalcandidates in the relation and reentrancy alignmentphases.
we tune hyperparameters, including penal-ties for duplicate alignments and our factorizedbackoff probability, on the development set..8.https://github.com/huggingface/neuralcoref.
3317exact alignr.p.f1.
ablations.
relation alignments breakdown.
reentrancy alignments breakdown.
our system: all (1163).
.
.
single relations (121).
.
.
argument structures (1042).
isi: all (1163).
.
.
single relations (121).
.
.
argument structures (1042).
our system: all (293).
.
.
primary (128).
.
.
coref (41).
.
.
control (36).
.
.
coordination (29).
.
.
pragmatic (25).
.
.
adjunct control (15).
.
.
repetition (13).
.
.
comparative control (5).
.
.
unmarked adjunct control (1).
85.6753.4989.67.
59.2882.8939.56.
62.3779.3757.1473.0857.1420.93100.0060.000.00.0.
85.3756.5688.73.
8.5152.073.45.
61.0978.1258.5452.7858.5436.006.6746.150.00.0.
85.5254.9889.20.
14.8963.966.35.
61.7278.7457.8361.2957.8326.4712.5052.170.00.0.table 4: detailed results for relation alignments andreentrancy alignments..7 results.
table 3 describes our main results on the 200-sentence test set (§4), reporting exact-match andpartial-match alignment scores as well as span iden-tification f1 and coverage.9 the partial alignmentevaluation metric is designed to be more forgivingof arbitrary or slight differences between alignmentsystems.
we argue that this metric is more com-parable across alignment systems.
it assigns par-tial credit equal to the product of jaccard indices∣t1∩t2∣∣n1∩n2∣∣t1∪t2∣ for nodes (or edges) and tokens re-∣n1∪n2∣ ⋅spectively.
this partial credit is calculated for eachgold alignment and the closest matching predictedalignment with nodes (or edges) n1 and n2 andtokens t1 and t2.
coverage is the percentage ofrelevant amr components that are aligned..our aligner shows improvements over previousaligners in terms of coverage and accuracy evenwhen using a partial credit metric for evaluation.
we demonstrate greater coverage, including cover-age of phenomena not aligned by previous systems.
table 4 shows detailed results for relation sub-types and reentrancy subtypes.
here, we see roomfor improvement.
in particular, isi outperformsour system at aligning single relations.
our reen-trancy aligner lacks a baseline to compare to, butthe breakdown of results by type suggest thereare several categories of reentrancies where scorescould be improved.
qualitative analysis.
a number of errors fromour subgraph aligner resulted from unseen mul-.
9a previous draft of this work reported lower scores onrelations before a constraint was added to improve the legalcandidates for relation alignment..subgraphssubgraphs (−distance)subgraphs (−inductive bias)relationsrelations (−distance)relations (gold subgraphs).
exact alignr94.0292.8593.4485.3784.7790.59.p93.9192.6993.8885.6785.1491.21.f193.9792.7793.6685.5284.9590.90.table 5: results when the aligner is trained withoutprojection distance probabilities (−distance) and with-out the subgraph inductive bias (−inductive bias), aswell as a relation aligner with access to gold (instead oftrained) subgraphs..tiword expressions in our test data that our spanpreprocessing failed to recognize and our alignerfailed to align.
for example, the expression “on theone hand” appears in test and should be aligned tocontrast-01.
the jamr aligner suffers withouta locality bias; we notice several cases where itmisaligns words that are repeated in the sentence.
the isi aligner generally does not align very fre-quent nodes such as person, thing, country, orname, resulting in generally lower coverage.
italso frequently aligns disconnected nodes with thesame concept to one token instead of separate to-kens.
while our relation aligner yields significantlyhigher coverage, we do observe that the model isovereager to align relations to extremely frequentprepositions (such as to and of ), resulting in lowerprecision of single relations in particular.
ablations.
table 5 shows that projection dis-tance is valuable, adding 1.20 points (exact alignf1) for subgraph alignment and 0.57 points for rela-tion alignment.
despite showing anecdotal benefitsin early experiments, the inductive bias does not aidthe model in a statistically significant way.
usinggold subgraphs for relation alignment produces animprovement of over 5 points, indicating the scopeof error propagation for the relation aligner..8 conclusions.
we demonstrate structure-aware amr aligners thatcombine the best parts of rule-based and statisticalmethods for amr alignment.
we improve on pre-vious systems in terms of accuracy and particularlyin terms of alignment coverage and variety of amrcomponents to be aligned..acknowledgments.
we thank reviewers for their thoughtful feedback,jakob prange for assisting with annotation, andmembers of the nert lab for their support..3318references.
rafael anchiêta and thiago pardo.
2020. semanti-cally inspired amr alignment for the portuguesein proc.
of emnlp, pages 1595–1600,language.
online..laura banarescu, claire bonial, shu cai, madalinageorgescu, kira griffitt, ulf hermjakob, kevinknight, philipp koehn, martha palmer, and nathanschneider.
2013. abstract meaning representationfor sembanking.
in proc.
of the 7th linguistic an-notation workshop and interoperability with dis-course, pages 178–186, sofia, bulgaria..sebastian beschke.
2019. exploring graph-algebraicccg combinators for syntactic-semantic amr pars-ing.
in proc.
of ranlp, pages 112–121, varna, bul-garia..austin blodgett and nathan schneider.
2019. an im-proved approach for semantic graph compositionwith ccg.
in proc.
of the 13th international con-ference on computational semantics - long papers,pages 55–70, gothenburg, sweden..p. brown, j. cocke, s. della pietra, v. della pietra,f. jelinek, r. mercer, and p. roossin.
1988. a sta-tistical approach to language translation.
in proc.
ofcoling, pages 71–76, budapest, hungary..deng cai and wai lam.
2020. amr parsing via graph-sequence iterative inference.
in proc.
of acl, pages1290–1301, online..wei-te chen and martha palmer.
2017. unsuper-in proc..vised amr-dependency parse alignment.
of eacl, pages 558–567, valencia, spain..chenhui chu and sadao kurohashi.
2016..super-vised syntax-based alignment between english sen-tences and abstract meaning representation graphs.
arxiv:1606.02126 [cs]..ramón fernandez astudillo, miguel ballesteros,tahira naseem, austin blodgett, and radu flo-rian.
2020. transition-based parsing with stack-in findings of the association fortransformers.
computational linguistics: emnlp 2020, pages1001–1007, online..jeffrey flanigan, chris dyer, noah a. smith, andjaime carbonell.
2016. cmu at semeval-2016task 8: graph-based amr parsing with infiniteramp loss.
in proc.
of semeval, pages 1202–1206,san diego, california..jeffrey flanigan, sam thomson, jaime carbonell,chris dyer, and noah a. smith.
2014. a discrim-inative graph-based parser for the abstract meaningrepresentation.
in proc.
of acl, pages 1426–1436,baltimore, maryland, usa..jonas groschwitz, matthias lindemann, meaghanfowlie, mark johnson, and alexander koller.
2018..amr dependency parsing with a typed semantic al-in proc.
of acl, pages 1831–1841, mel-gebra.
bourne, australia..kevin knight, bianca badarau, laura baranescu,claire bonial, kira griffitt, ulf hermjakob, danielmarcu, tim o’gorman, martha palmer, nathanschneider, and madalina bardocz.
2020.ab-stract meaning representation (amr) annotationrelease 3.0. technical report ldc2020t02, lin-guistic data consortium, philadelphia, pa..yijia liu, wanxiang che, bo zheng, bing qin,and ting liu.
2018. an amr aligner tuned bytransition-based parser.
in proc.
of emnlp, pages2422–2430, brussels, belgium..chunchuan lyu and ivan titov.
2018. amr parsing asgraph prediction with latent alignment.
in proc.
ofacl, pages 397–407, melbourne, australia..tahira naseem, abhishek shah, hui wan, radu flo-rian, salim roukos, and miguel ballesteros.
2019.rewarding smatch:transition-based amr parsingwith reinforcement learning.
in proc.
of acl, pages4586–4592, florence, italy..nima pourdamghani, yang gao, ulf hermjakob, andkevin knight.
2014. aligning english strings within proc.
abstract meaning representation graphs.
of emnlp, pages 425–429, doha, qatar..peng qi, yuhao zhang, yuhui zhang, jason bolton,and christopher d. manning.
2020.stanza: apython natural language processing toolkit for manyin proceedings of the 58th an-human languages.
nual meeting of the association for computationallinguistics: system demonstrations..nathan schneider, jena d. hwang, vivek srikumar,jakob prange, austin blodgett, sarah r. moeller,aviram stern, adi bitan, and omri abend.
2018.comprehensive supersense disambiguation of en-glish prepositions and possessives.
in proc.
of acl,pages 185–196, melbourne, australia..nathan schneider and noah a. smith.
2015. a corpusand model integrating multiword expressions and su-in proc.
of naacl-hlt, pages 1537–persenses.
1547, denver, colorado..ida szubert, marco damonte, shay b. cohen, andmark steedman.
2020. the role of reentrancies inabstract meaning representation parsing.
in proc.
of findings of emnlp, pages 2198–2207, online..ida szubert, adam lopez, and nathan schneider.
2018.a structured syntax-semantics interface for english-in proc.
of naacl-hlt, pagesamr alignment.
1169–1180, new orleans, louisiana..chuan wang and nianwen xue.
2017. getting thein proc.
of emnlp,.
most out of amr parsing.
pages 1257–1268, copenhagen, denmark..3319a interannotator agreement.
table 6 illustrates interannotator agreement foreach of the four alignment layers..
etc.).
b identifying spans.
as a preprocessing step, sentences have their to-kens grouped into spans based on three criteria,outlined in detail below:1. named entity spans identified by stanza.
2. spans matching multiword expressions from afixed list of ≈1600.
(a) 143 prepositional mwes from streusle(schneider and smith, 2015; schneider et al., 2018).
(b) 348 verbal mwes from streusle(c) 1095 mwes taken from gold amrs in ldctrain data (any concept which is a hyphenated com-pound of multiple words, e.g., alma-mater or white-collar) and are not present in the above lists..(d) ≈12 hand-added mwes.
3. any sequence of tokens which is an exact matchto a name in the gold amr (e.g., “united kingdom”and (n/name :op1 "united" :op2 "kingdom"))is also treated as a span..• parsing dates and times• numbers written out (e.g., one, two, thousand,.
• currencies (e.g., $, c, etc.)
• decades (e.g., twenties, nineties)• and (matching and, additionally, as well, etc.)
• multi-sentence (matching punctuation)• :polarity - (matching not, none, never,.
etc.).
etc.).
etc.).
• cause-01 (matching thus, since, because,.
• amr-unknown (matching ?, who, when, etc.)
• person (matching people)• rate-entity-91 (matching daily, weekly,.
• "united" "states" (matching us, u.s.,.
american, etc.).
• include-91 (matching out of, include, etc.)
• instead-of-91 (matching instead, etc.)
• have-03 (matching have, ’s, etc.)
• mean-01 (matching : and ,)• how (matching :manner thing or :degree.
so).
• as.
.
.
as (matching equal).
c rule-based subgraph alignment.
c.2 graph rules.
preprocessing.
c.1 token matching.
we use three phases of rule-based alignment whichattempt to align particular spans to particular amrsubgraphs:1. exact token matching: if there is a unique fullstring correspondence between a span and a nameor number in the amr, they are aligned.
2. exact lemma matching: if there is a uniquecorrespondence between an amr concept and thelemma of a span (which in the case of a multiwordspan is the sequence of lemmas of the tokens joinedby hyphens), they are aligned.
3. prefix token matching: a span with a prefixmatch of length 6, 5, or 4 is aligned if it uniquelycorresponds to an amr named entity.
4. prefix lemma matching: a span with a prefixmatch of length 6, 5, or 4 of its lemma is aligned ifit uniquely corresponds to an concept.
5. english rules: several hand-written rules formatching english strings to specific subgraphs areused to match constructions such as dates, currency,and some frequent amr concepts with many dif-ferent ways of being expressed, such as and and-..we also perform preprocessing to expand a sub-graph alignment to include some neighboringnodes.
these fall into two main categories:1. some amr concepts are primarily notationalrather than linguistic and should be alignedtogether with a neighboring node.
for ex-ample named entities (e.g., (country :name(n/name :op1 :united" :op2 "kingdom"))) arealigned as a unit rather than one node at atime.
likewise, date entities, and subgraphsmatching (x/x-quantity :unit x :quant x) or(x/x-entity :value x) are also aligned as a unit.
2. neighboring nodes which are associated withmorphological information of the aligned span(e.g., biggest → (have-degree-91 :arg1 big:arg2 most)) are added to the alignment usinga series of rules for identifying comparatives, su-perlatives, polarity, and suffixes such as -er or -able,etc..d rule-based relation alignment.
preprocessing.
many of the relations are forced to be aligned ina particular way as a matter of convention.
weuse a similar approach to that of (groschwitz et al.,.
3320iaa.
subgraphs (366).
exact alignr94.54.p94.54.f194.54.partial alignr95.56.p95.56.f195.56.relations (260).
91.09.
90.38.
90.73.
93.38.
92.66.
93.02.reentrancies (65).
76.92.
76.92.
76.92.
90.00.
90.00.
90.00.duplicates (5).
75.00.
60.00.
66.67.
79.17.
63.33.
70.37.spansf194.97.
93.75.
90.77.
66.67.table 6: interannotator agreement for subgraph, relation, reentrancy, and duplicate subgraph layers of align-ment scored on a sample of 40 sentences of the gold test data..2018).
1. :argx edges are automatically aligned to thesame span as the parent (:argx-of edges are auto-matically aligned to the child).
2. :opx edges are automatically aligned with theparent.
3. :sntx edges are automatically aligned with theparent.
4. :domain edges are automatically aligned withthe parent.
(we don’t align these edges to copula.
instead, a concept with a :domain edge is thoughtof as a predicate which takes one argument.)
5. :name, :polarity, and :li edges are automati-cally aligned with the child..d.1 token matching.
some relations take the form :prep-x or :conj-xwhere x is a preposition or conjunction in the sen-tence.
we use exact match to align these relationsas a preprocessing step.
the relations :poss and:part may be automatically aligned to ’s or of ifthe correspondence is unique within a sentence..e rule-based reentrancy alignment.
preprocessing.
primary edges are identified as a preprocessingstep before aligning reentrancies with the followingrules: any relation which is aligned to the samespan as its token (any incoming edge which is apart of a span’s argument structure) is automaticallymade the primary edge.
otherwise, for each edgepointing to a node, we identify the spans alignedto the parent and child nodes in the subgraph layer.
whichever edge has the shortest distance betweenthe span aligned to the parent and the span alignedto the child is identified as the primary edge.
in theevent of a tie, the edge whose parent is aligned tothe leftmost span is identified as the primary edge.
primary reentrancy edges are always aligned to thesame span the edge is aligned to in the relationlayer of alignments..3321