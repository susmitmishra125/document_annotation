raddle: an evaluation benchmark and analysis platform forrobust task-oriented dialog systems.
baolin peng1, chunyuan li1,zhu zhang12† , chenguang zhu1, jinchao li1, jianfeng gao11microsoft research, redmond, wa2iowa state university / ames, ia{bapeng,chunyl,chezhu,jincli,jfgao}@microsoft.comzhuzhang@iastate.edu.
abstract.
for task-oriented dialog systems to be maxi-mally useful, it must be able to process con-versations in a way that is (1) generalizablewith a small number of training examples fornew task domains, and (2) robust to user inputin various styles, modalities, or domains.
inpursuit of these goals, we introduce the rad-dle1 benchmark 2, a collection of corpora andtools for evaluating the performance of modelsacross a diverse set of domains.
by includingtasks with limited training data, raddle isdesigned to favor and encourage models witha strong generalization ability.
raddle alsoincludes a diagnostic checklist that facilitatesdetailed robustness analysis in aspects suchas language variations, speech errors, unseenentities, and out-of-domain utterances.
weevaluate recent state-of-the-art systems basedon pre-training and ﬁne-tuning, and ﬁnd thatgrounded pre-training on heterogeneous dia-log corpora performs better than training a sep-arate model per domain.
adversarial trainingis also proposed to improve model robustnessagainst noisy inputs.
overall, existing modelsare less than satisfactory in robustness evalu-ation, which suggests opportunities for futureimprovement..1.introduction.
dialogs constitute a crucial communication chan-nel in completing a broad range of tasks, such asweather query, ﬂight and restaurant booking, moviebooking, it help desk, etc.
comparing to chit-chat systems that are usually modeled with single-turn context-response pairs, task-oriented dialogsystems involve retrieving information from knowl-edge bases and reasoning over multiple dialog turns.
this makes it especially important for a system to.
† work was done when zhu zhang was visiting msr1robust task-oriented dialog systems evaluation2benchmark link: http://aka.ms/raddle.
be able to produce response that are grounded ontasks goals and user intents.
in a bid to supporthuman-computer interactions, task-oriented dialogsystems have been built to allow users to conversewith a computer system using natural language,such as siri, google assistant, amazon alexa, mi-crosoft xiaoice (zhou et al., 2020).
traditionally,a task-oriented dialog system uses a modularizedpipeline with four modules that execute sequen-tially (gao et al., 2019).
a natural language un-derstanding (nlu) module identiﬁes user intentsand extracts associated information such as slotsand corresponding values from user input.
a dia-log state tracker (dst) infers the belief state (oruser goal) from dialog history.
the belief state isoften used to query a task-speciﬁc database (db)to obtain the db state, such as the number of enti-ties that match the user goal.
the dialog state anddb state are then passed to a dialog policy (pol)module to select the next system action.
a naturallanguage generation (nlg) module converts theaction to a natural language response..the human ability to converse is general, ﬂex-ible, and robust.
in contrast, most popular toolsfor dialog system development adopting the abovemodular systems are designed for speciﬁc tasksif we as-and struggle with out-of-scope data.
pire to develop models beyond extensively hand-crafted rules and annotated data for each singledomain/task, it is critical to develop a more uniﬁed,efﬁcient and robust model that can more quicklylearn to execute a range of tasks in different do-mains..to fuel research in this direction, we presentthe raddle benchmark.
it includes a collectionof task-oriented dialog tasks in diverse domains(e.g.
end-to-end modeling, dialog state tracking).
the benchmark also has a companion online plat-form for model evaluation, comparison, and robust-ness analysis.
importantly, raddle exhibits two.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4418–4429august1–6,2021.©2021associationforcomputationallinguistics4418unique advantages that pave the way for buildingmore pragmatic dialog systems: (i) limited datasetting is the major focus of raddle, to evalu-ate the generalization ability of models.
it aimsat simulating the real-world application scenarioswhere only very limited amount of labelled datais available for new domains.
given this focus,raddle is therefore a favorable benchmark toevaluate recent models in the pre-training and ﬁne-tuning paradigm, which learn to represent linguisticknowledge in a way that facilitates sample-efﬁcientlearning and effective knowledge transfer.
(ii) ro-bustness analysis is introduced to study model per-formance in various challenging scenarios, wheremodels are evaluated with anomalous user inputsuch as language variations, speech errors, unseenentities and out-of-domain utterances.
failing tohandle these inputs often produce inappropriateresponses leading to frustrating user experience.
these scenarios are common for deployed systemsin the real world, but are largely ignored in existingdialog benchmarks.
to the best of our knowledge,raddle presents the ﬁrst work to ﬁll this gap..to better understand the challenges posed byraddle, we conduct experiments with simplebaselines and state-of-the-art task-oriented dialogmodels.
we ﬁnd that grounded pre-trained mod-els with a uniﬁed multi-task learning objectiveoutperform models separately trained on each do-main.
moreover, even the best performing model(soloist (peng et al., 2020a)) in our evaluationachieves a fairly low score in robustness analysis.
this suggests that our baseline models can han-dle common inputs with strong regularities, butstruggle with anomalous inputs that require deeperreasoning..in summary, our key contributions are: (i) anovel dialog benchmark with an emphasis on lim-ited data and multiple domains/tasks, which for-mally creates a scenario to evaluate the groundingand generalization ability of pre-trained models.
(ii) a crowd-sourced diagnostic evaluation datasetto cover a broad range of real-world sophisticationto study model robustness.
(iii) an online evalu-ation platform and leaderboard to track researchprogress, with human evaluation services to begranted to top-ranked submissions on a bi-monthlybasis.
(iv) baseline results for major existing ap-proaches to task-oriented dialogs are reported.
anadversarially robust model is proposed to improvethe generalization ability in noisy environments..starter codes, pre-trained models, and scripts to re-produce the results will be provided together withthe benchmark..2 related work.
2.1 dialog benchmarks.
to drive the progress of building dialog systems us-ing data-driven approaches, a number of conversa-tional corpora have been released.
they are roughlygrouped into two categories: (i) corpora with struc-tured semantic labels (wen et al., 2017; shah et al.,2018).
these datasets are often speciﬁcally anno-tated, and used to study an individual module in thedialog pipeline.
for example, dialoglue (mehriet al., 2020) is a recently proposed benchmark witha focus on nlu and dst tasks.
(ii) corpora withan implicit user goal (lowe et al., 2015).
thesedatasets are often without semantic labels but canbe used in end-to-end (e2e) dialog modeling (liet al., 2016; zhu, 2020; wu et al., 2019; zhu et al.,2019a; lee et al., 2019; zhu et al., 2020)..multiwoz (budzianowski et al., 2018) is themost related work to raddle.
it is a large-scalemulti-turn conversational corpus across several do-mains.
it can be used to develop individual dialogmodules as separate tasks for existing modular-based methods, or serves as a benchmark for e2edialog modeling methods.
raddle inherits theadvantages of multiwoz in its ﬂexibility for sepa-rate/joint task modeling and its comprehensivenessin multi-domain data coverage, but differs signiﬁ-cantly in two aspects: an emphasis on limited datasettings and an unique robustness checklist.
bothare essential qualities in building task bots at scale.
further, raddle provides an online plat-form for model evaluation and fair comparisonbased on privately-held test data,inspired byglue (wang et al., 2018).
to the best of ourknowledge, raddle is the ﬁrst online platformfor dst and e2e tasks in the dialog commu-nity.
this can reduce the inconsistency causedby different researchers/teams using varying pro-cessing/evaluation scripts to dilute where the gaincomes from..2.2 evaluation of pre-trained models.
pre-trained language models (plms) have sub-stantially advanced the state of the art across avariety of language understanding and generationtasks (peters et al., 2018; devlin et al., 2019; yanget al., 2019; liu et al., 2019; radford et al., 2019;.
4419standard.
language variations / speech errors.
unseen.
ood.
domain attraction train hotel restaurant attraction train hotel restaurant reminder attraction.
#train#test.
task.
metrics.
50100.
50200.
50200.
50200.
-100.
-200.
-200.
-200.
50400.
50800.dialog state tracking / end-to-end modeling.
dst / ic dst / ood.
joint goal accuracy / combined score.
jga / acc..jga / f1.
table 1: dataset descriptions and statistics.
dst is short for dialog state tracking, e2e denotes end-to-endmodeling, and ic stands for intent classiﬁcation.
joint goal accuracy (jga) is used for dst and combined scoreis used for e2e..keskar et al., 2019; dong et al., 2019; peng et al.,2020b,c; li et al., 2020a).
plms are often trainedto predict words based on their context on massivetext data, and the learned models can be ﬁne-tunedto quickly adapt to various downstream tasks, ex-hibiting strong generalization capacity even withjust a few in-domain training examples.
buildingtask bots at scale requires the model to deal with thelimited data problem for each domain, which canbe used as a testbed to evaluate the generalizationability of plms.
to this end, we limit the numberof task-speciﬁc training examples in raddle toevaluate the sample-efﬁciency of models..meanwhile, task-oriented dialogs pose a uniqueset of challenges for plms (gao et al., 2020): adialog is intrinsically goal-driven, multi-turn andoften informal/noisy.
indeed, dialog-speciﬁc plmsare proposed (wu et al., 2020a; peng et al., 2020a).
however, the robustness of plms to linguistic per-turbations often occurring in dialog settings (seesection 4 for details) is largely unexplored.
notethat our notion of robustness emphasizes naturallanguage variations, which is different from adver-sarial examples/training that aim to fool a trainedmodel (nie et al., 2019).
from this perspective,raddle provides an unique benchmark for assess-ing plms with a robustness orientation..3 tasks.
raddle is centered on ﬁve english dialog scenar-ios in daily life, which cover a broad range of datacollection schemes, task types and complexities.
as our ﬁrst goal of raddle is to spur developmentof generalizable dialog systems, we design thebenchmark such that a good performance requires amodel to leverage substantial knowledge (e.g., pre-trained parameters) learned from its previous lifecycle, while still maintaining some task-speciﬁccomponents (coope et al., 2020; henderson et al.,2020; peng et al., 2020a; wu et al., 2020b).
speciﬁ-.
cally, we deliberately keep a small number of train-ing examples for each scenario.
this is consis-tent with the common practice that only limitedlabelled data is provided when deploying a dialogsystem to new domains.
table 1 shows the datastatistics.
four domains in the standard-setting aresampled from multiwoz 2.0 (budzianowski et al.,2018).
reminder is intentionally only utilizedfor unseen entity tracking.
because it is a human-machine corpus with a relatively smaller actionspace meaning that the impact of policy learning onmodels is largely alleviated.
therefore, the perfor-mance of models on this corpus will mostly reﬂectits capability of unseen entity tracking.
note thatthe number of training examples is limited to 50, anaccepted scale that users can provide.
though it ispossible to train a single model for each task fromscratch without outside sources of knowledge, weexpect that our focus on data-scarce settings willrender this approach uncompetitive..furthermore, a typical task-oriented dialog sys-tem uses a modularized pipeline that has four mod-ules and executes sequentially.
recent researchhas shown promising results on parameterizing themodularized pipeline using a single neural auto-regressive model, and training it in an end-to-endmanner (peng et al., 2020a; ham et al., 2020;hosseini-asl et al., 2020).
in fact, a single auto-regressive model can signiﬁcantly ease the work-ﬂow of training and deploying dialog systems fornew tasks, compared to existing modularized toolsand methods.
therefore, we design the benchmarkto allow evaluations on end-to-end dialog model-ing, in addition to the modularized evaluation ondialog state tracking.
to reveal the gap between thecomplexity of dialogs in lab environments and thatin real scenarios, we construct a suite of tasks tostudy the robustness of models.
we describe thesetasks below and in table 1..on the evaluation front, we concentrate on.
4420simulation-based methodologies, in order to facil-itate automation.
though we only offer humanevaluations (gao et al., 2019) to top-ranked submis-sions at this point, we emphasize realistic scenariosin pursuit of system robustness (see section 4)..task 1: dialog state tracking a robust nluand dst is the ﬁrst step towards building a reliabledialog system.
the dialog state is a summary ofthe entire conversation till the current turn.
in atask-oriented system, it is represented in the formof slot-value pairs, where slot indicates the cat-egory/attribute of the user goal expressed in theutterance, and value is the corresponding informa-tion.
for the evaluation metric, we report joint goalaccuracy, which indicates the proportion of dialogturns where all the user’s search goal constraintsare correctly identiﬁed (mrksic et al., 2017).
tospecially study the nlu performance, we considerintent classiﬁcation, which aims to automaticallyextract meaning from a natural language utterancein order to understand user’s goal (hemphill et al.,1990; zhu et al., 2019b)..task 2: end-to-end modeling the end-to-end(e2e) dialog models consider dialog history as in-put, and produce the natural language response.
it jointly implements the dialog management (in-cluding dst and pol) and response generation(i.e., nlg) components.
following budzianowskiet al.
(2018), inform, success, and bleu scoresare reported.
the ﬁrst two metrics evaluate dialogtask completion: inform measures if the systemprovides a correct entity (inform rate), meanwhilesuccess measures the exact matching of answer-ing all the requested information (success rate),and if the answered information matches users’goal.
bleu evaluates how ﬂuent the generated re-sponses are compared to human-written responses.
a combined score (combined) is also reported us-ing combined = (inform + success) × 0.5 +bleu as an overall quality measure, as suggestedin (budzianowski et al., 2018)..4 robustness diagnostic checklist.
method results in a dataset where most user utter-ances are straight-forward, stick to the goal andtend to leave out the variation/errors commonlyfound in real-world conversational data.
to thisend, we collect a suite of language variations toreveal the dialog sophistication in the real world,and measure the robustness of dialog models..4.1 checklist tasks.
language variationsit is well-known thathumans communicate using language with fairlylarge variations such as different ways of expres-sions or personalized styles (sacks et al., 1978),while template-based crowd-sourcing fails in cov-ering the linguistic variations (schegloff et al.,1977; moore and arar, 2019).
speciﬁcally, weconsider four types of variations in raddle: (i)paraphrase widely exists among different users,who may present restatements of the meaning of atext or message using other words.
(ii) verbositydescribes a quality that users may express theirintents using more words than needed.
(iii) simpli-ﬁcation is a quality that users express their intentsusing fewer words to be concise.
(iv) typos of-ten result from mistakes made in the typing.
infigure 1(b)-(e), we provide examples to illustratethese language variations..speech errorsit is desirable that dialog sys-tems can leverage automatic speech recognition(asr) techniques to serve the speech modality, asin amazon alexa.
however, almost all dialog sys-tems have typically assumed that the user inputis written text, and hoped that the system wouldseamlessly integrate with speech inputs.
recently,it has been empirically shown in gopalakrishnanet al.
(2020) that dialog systems trained on writtendata is very sensitive to various types of syntheticand actual asr hypotheses in the dialog history.
to bring attention to this gap, raddle promotesspeech robustness as an evaluation criterion.
forexample in figure 1(f), “what’s available” can betranscribed as “once available” due to asr deﬁ-ciency, and a robust dialog system is expected tostill correctly perceive user intents..existing benchmarks assume a world of a “per-fect” user who always provides precise, concise,and semantically unambiguous utterances.
thesegoal-oriented dialog datasets are largely collectedby crowd-sourcing, where a crowd-sourced workerenacts the part of a real user by following a set oftemplate instructions provided for the task.
this.
unseen entitiesmost existing dst methodsare not designed to handle slot values that are notknown to the tracker.
the assumption that a pre-deﬁned ontology exists for the dialog and one canenumerate all possible values for each slot is oftennot valid in real-world scenarios.
even if such listsor dictionaries exist, they can be very large in size.
4421(a) standard dialog session.
(b) paraphrase.
(c) verbosity.
(d) simpliﬁcation.
(e) typos.
(f) speech errors.
(g) unseen entities.
(h) out-of-domain utterance.
figure 1: illustration of different language perturbations in the robustness diagnostic checklist.
the standard dialogexample is shown in (a).
based on it, (b)-(e) are four types of language variations,, (f) shows speech error(e) shows unseen entitiesin each case, some representativeexamples are highlighted in red text.., and (h) shows out-of-domain utterance.
..and highly dynamic (xu and hu, 2018).
there-fore, unseen entities are common in dialogs, i.e.,entities that are not observed during training, butappear in the testing stage.
in figure 1(g), the en-tity bellevue downtown is in the knowledgebase but never appears in model training, a robustdst should be able to recognize it as a city/place,via generalizing from other similar entities learnedduring training..out-of-domain utterancesmost deployedtask-oriented dialog systems are built for a closedset of target domains.
thus, they are fragile when.
dealing with out-of-domain (ood) utterances (leeand shalyminov, 2019).
failure to detect ood ut-terances often prevents the model from respondingwith an appropriate fallback action, hence leadingto frustrating user experience.
therefore, it is im-portant to endow task bots with the ability to detectood utterances for special handling (larson et al.,2019).
for example, in figure 1(h), the user sug-gests an excursion to a task bot trained in collegeconsulting, which is out of the bot’s scope.
thebot is expected to raise a ﬂag to label the utteranceas an outlier, and guides the user to focus on the.
4422user: i want to tour a college in the center of town.
what's available?system: i have several different options available .
did you want one with free entrance ?user: entrance fee is not an issue.,system: christ's college is free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, that's it.
thanks.system: thank you , goodbye .user: iwant to tour college in the center of town once availablesystem: i have several different options available .
did you want one with free entrance ?user: entrance phi is not an issue.system: christ's college is free to enter.user: can ihave the postcard and address for that college?,system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: iknow that's it uh thankssystem: thank you , goodbye .user: i want to tour a parkin the bellevue downtown .
what's available?system: i have several different options available .
did you want one with free entrance ?user: entrance fee is not an issue.,system: downtown park is a nice one and it is free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at 10201 ne 4th st, postcode 98004. is there any other information you need?user: no, that's it.
thanks.system: thank you , goodbye .user:  i want to tour a college in the center of town .
what's available?system: i have several different options available .
did you want one with free entrance ?user: today is a sunny day we should go outside for a walk.system: sorry i do not understand.
can you paraphrase?
by the way, christ's college is a good place and free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at 10201 ne 4th st, postcode 98004. is there any other information you need?user: no, that's it.
thanks.system : thank you , goodbye .paraphraseverboseuser: i want to take a tour in a college which lies in the center of town.
any recommendation?system: i have several different options available .
did you want one with free entrance ?user: i don't have a problem paying the entrance fee.system: christ's college is free to enter.user: will you please give me postcode and address of that college?
system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, perfect.
i appreciate that.system: thank you , goodbye .user: i want to tour a college.
what do you have available?
i know some college in the center area is awesome.system: i have several different options available .
did you want one with free entrance ?user: i do not have any preference on the fee but does paying the fee give me something extra?system: christ's college is free to enter.user: okay, sounds good!
i would like to visit that college to enjoy this afternoon, do you have its address and postcode?system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thanks.system: thank you , goodbye .user: any college available in the center of town?system: i have several different options available .
did you want one with free entrance ?user: do not care about feesystem: christ's college is free to enter.user: give me address and postcode.system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thanks.system: thank you , goodbye .user: want to tour a college in center.
whatsavailablesystem: i have several different options available .
did you want one with free entrance ?user: i don't have a problem paying the entrance fee.system: christ's college is free to enter.user: plztell me addrand postcode of that college.system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thatsall.
thxsystem: thank you , goodbye .paraphraseverboseuser: i want to take a tour in a college which lies in the center of town.
any recommendation?system: i have several different options available .
did you want one with free entrance ?user: i don't have a problem paying the entrance fee.system: christ's college is free to enter.user: will you please give me postcode and address of that college?
system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, perfect.
i appreciate that.system: thank you , goodbye .user: i want to tour a college.
what do you have available?
i know some college in the center area is awesome.system: i have several different options available .
did you want one with free entrance ?user: i do not have any preference on the fee but does paying the fee give me something extra?system: christ's college is free to enter.user: okay, sounds good!
i would like to visit that college to enjoy this afternoon, do you have its address and postcode?system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thanks.system: thank you , goodbye .user: any college available in the center of town?system: i have several different options available .
did you want one with free entrance ?user: do not care about feesystem: christ's college is free to enter.user: give me address and postcode.system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thanks.system: thank you , goodbye .user: want to tour a college in center.
whatsavailablesystem: i have several different options available .
did you want one with free entrance ?user: i don't have a problem paying the entrance fee.system: christ's college is free to enter.user: plztell me addrand postcode of that college.system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thatsall.
thxsystem: thank you , goodbye .paraphraseverboseuser: i want to take a tour in a college which lies in the center of town.
any recommendation?system: i have several different options available .
did you want one with free entrance ?user: i don't have a problem paying the entrance fee.system: christ's college is free to enter.user: will you please give me postcode and address of that college?
system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, perfect.
i appreciate that.system: thank you , goodbye .user: i want to tour a college.
what do you have available?
i know some college in the center area is awesome.system: i have several different options available .
did you want one with free entrance ?user: i do not have any preference on the fee but does paying the fee give me something extra?system: christ's college is free to enter.user: okay, sounds good!
i would like to visit that college to enjoy this afternoon, do you have its address and postcode?system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thanks.system: thank you , goodbye .user: any college available in the center of town?system: i have several different options available .
did you want one with free entrance ?user: do not care about feesystem: christ's college is free to enter.user: give me address and postcode.system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thanks.system: thank you , goodbye .user: want to tour a college in center.
whatsavailablesystem: i have several different options available .
did you want one with free entrance ?user: i don't have a problem paying the entrance fee.system: christ's college is free to enter.user: plztell me addrand postcode of that college.system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thatsall.
thxsystem: thank you , goodbye .paraphraseverboseuser: i want to take a tour in a college which lies in the center of town.
any recommendation?system: i have several different options available .
did you want one with free entrance ?user: i don't have a problem paying the entrance fee.system: christ's college is free to enter.user: will you please give me postcode and address of that college?
system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, perfect.
i appreciate that.system: thank you , goodbye .user: i want to tour a college.
what do you have available?
i know some college in the center area is awesome.system: i have several different options available .
did you want one with free entrance ?user: i do not have any preference on the fee but does paying the fee give me something extra?system: christ's college is free to enter.user: okay, sounds good!
i would like to visit that college to enjoy this afternoon, do you have its address and postcode?system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thanks.system: thank you , goodbye .user: any college available in the center of town?system: i have several different options available .
did you want one with free entrance ?user: do not care about feesystem: christ's college is free to enter.user: give me address and postcode.system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thanks.system: thank you , goodbye .user: want to tour a college in center.
whatsavailablesystem: i have several different options available .
did you want one with free entrance ?user: i don't have a problem paying the entrance fee.system: christ's college is free to enter.user: plztell me addrand postcode of that college.system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, thatsall.
thxsystem: thank you , goodbye .user: i want to tour a college in the center of town.
what's available?system: i have several different options available .
did you want one with free entrance ?user: entrance fee is not an issue.,system: christ's college is free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, that's it.
thanks.system: thank you , goodbye .user: iwant to tour college in the center of town once availablesystem: i have several different options available .
did you want one with free entrance ?user: entrance phi is not an issue.system: christ's college is free to enter.user: can ihave the postcard and address for that college?,system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: iknow that's it uh thankssystem: thank you , goodbye .user: i want to tour a parkin the bellevue downtown .
what's available?system: i have several different options available .
did you want one with free entrance ?user: entrance fee is not an issue.,system: downtown park is a nice one and it is free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at 10201 ne 4th st, postcode 98004. is there any other information you need?user: no, that's it.
thanks.system: thank you , goodbye .user:  i want to tour a college in the center of town .
what's available?system: i have several different options available .
did you want one with free entrance ?user: today is a sunny day we should go outside for a walk.system: sorry i do not understand.
can you paraphrase?
by the way, christ's college is a good place and free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at 10201 ne 4th st, postcode 98004. is there any other information you need?user: no, that's it.
thanks.system : thank you , goodbye .user: i want to tour a college in the center of town.
what's available?system: i have several different options available .
did you want one with free entrance ?user: entrance fee is not an issue.,system: christ's college is free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: no, that's it.
thanks.system: thank you , goodbye .user: iwant to tour college in the center of town once availablesystem: i have several different options available .
did you want one with free entrance ?user: entrance phi is not an issue.system: christ's college is free to enter.user: can ihave the postcard and address for that college?,system: yes, it's located at saint andrew'sstreet, postcode cb23bu.
is there any other information you need?user: iknow that's it uh thankssystem: thank you , goodbye .user: i want to tour a parkin the bellevue downtown .
what's available?system: i have several different options available .
did you want one with free entrance ?user: entrance fee is not an issue.,system: downtown park is a nice one and it is free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at 10201 ne 4th st, postcode 98004. is there any other information you need?user: no, that's it.
thanks.system: thank you , goodbye .user:  i want to tour a college in the center of town .
what's available?system: i have several different options available .
did you want one with free entrance ?user: today is a sunny day we should go outside for a walk.system: sorry i do not understand.
can you paraphrase?
by the way, christ's college is a good place and free to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at 10201 ne 4th st, postcode 98004. is there any other information you need?user: no, that's it.
thanks.system : thank you , goodbye .user: i want to tour a college in the center of town.
what's available?,system : i have several different options available .
did you want one with free entrance ?user : today is a sunny day we should go outside for a walk.system: sorry i do not understand.
can you paraphrase?
by the way, christ’s college is a good place and fee to enter.user: can ihave the postcode and address for that college?,system: yes, it's located at 10201 ne 4th st, postcode 98004. is there any other information you need?user: no, that's it.
thanks.system: thank you , goodbye .
current domain..5 methods.
4.2 collection protocols.
the standard setting is sampled from multiwoz2.0 (budzianowski et al., 2018) but re-purposed ina few-shot learning setting..the language variations corpus is created byworkers on amazon mechanical turks based onthe standard corpus.
to maximize the quality, werequire workers in us locale and have a minimalprevious approval rate of 90%.
assignments areconstructed at the turn level.
given a user utteranceand associated dialog history, workers are requiredto answer four questions, what are the paraphrase,typos, verbose, and simpliﬁed versions of the userutterance.
moreover, in each assignment, the work-ers are instructed to exactly mention the slot valuesin the answers if the given user utterance has them.
we pay turks 0.5$ per assignment and each assign-ment can be ﬁnished in one to two minutes..for the speech recognition errors setting, weemploy the audio-level error simulation (gopalakr-ishnan et al., 2020), which generates audio signalsfrom texts, adds noise into the audio, and thendecodes the audio with an asr model to obtainhypotheses.
in particular, we employ microsoftcognition text-to-speech service to synthesize au-dio signals.
after injecting background noise intothe audio signals, we use the speech recognition ser-vice to obtain a corpus of word error rate (wer)of 30%..for the reminder domain that is applied forunseen entity evaluation, we ﬁrstly simulate severaldialogs as seed scenarios using an agenda-basedsimulator and then randomly replace the slots in thedialogs with new values.
similar to constructingthe language variations corpus, we then hire work-ers to rewrite the corpus as diverse and realistic aspossible.
finally, the out-of-domain corpus is de-veloped following lee and shalyminov (2019).
werandomly choose 50% utterances in dstc (hen-derson et al., 2014) for the attraction domainas the training set.
for the test set, besides utter-ance from dstc, we also introduce utterance froma diverse set of domains like stanford (ericand manning, 2017), reddit, twitter (sor-doni et al., 2015) to evaluate the capability of han-dling different out-of-domain utterances.
a boardof data researchers reviews all the collected data toensure no ethical concerns in it..5.1 competitive baselines.
for baselines, we consider three representativemethods, holding state-of-the-art positions on exist-ing benchmarks such as multiwoz (budzianowskiet al., 2018)..damd (zhang et al., 2020) is a state-of-the-art modular system, where each dialog module isimplemented using a neural network, and the wholesystem is trained in an end-to-end manner..gpt-2 represents a single multi-task learningmodel with impressive results on general languageunderstanding and generation tasks.
gpt-2 isan auto-regressive language model that leverages12-24 layers of masked, multi-head self-attentiontransformers.
gpt-2 is pre-trained on extremelymassive text data openwebtext (radford et al.,2019).
it has demonstrated superior performanceon characterizing human language data distribu-tion and knowledge transfer.
given text prompts,gpt-2 can often generate ﬂuent sentences.
its an-cestral work gpt (with a smaller model size andless training data) has shown impressive results onlanguage understanding tasks.
in this paper, weconsider gpt-2ft as the approach of directly ﬁne-tuning the pre-trained gpt-2 on a speciﬁc domain.
hence, gpt-2ft can be viewed as soloist with-out grounded pre-training, and serve as a strongbaseline for both dst and e2e task..soloist represents recent model variants (hamet al., 2020; hosseini-asl et al., 2020) to param-eterize dialog system as a single auto-regressivemodel.
soloist subsumes different dialog mod-ules (e.g.
state tracker, dialog policy, responsegenerator) into a single transformer model.
it hasthe similar capability with gpt-2 in understand-ing and generating natural language sentences butis pre-trained on large heterogeneous dialog cor-pora to gain additional capability of grounding textresponse in user goals and real-world knowledgefor task completion (peng et al., 2020a; gao et al.,2020).
for detailed description, please see sectiona in appendix..5.2 adversarially robust soloist.
it is known that adversarial training can improvea model’s adversarial robustness, which refers toa model’s invariance to small (often impercepti-ble) perturbations of its inputs (i.e., clean exam-.
4423standard.
para..simp..typos.
verbo..speech err.
unseen.
ood.
modeldamdgpt-2ftsoloistsoloistadv.
avg.
avg.c jga ↑14.1840.5253.1755.47.
-47.4659.0961.03.
46.5358.3060.14.c ↑48.9967.3676.1379.06.jga ↑6.7531.3640.2742.11.c ↑44.1362.7264.8971.13.jga ↑5.7828.8237.1838.28.c ↑42.9359.4463.6169.89.jga ↑5.3322.3122.7323.30.c ↑42.5854.1557.7763.17.jga ↑7.0830.4038.2140.02.c ↑42.5654.1665.7169.36.jga ↑9.131.4136.8139.02.c ↑45.9465.9570.4872.33.jga ↑ ic ↑ jga ↑ f1 ↑.
-28.2869.0569.56.
-51.2996.9898.79.
-47.3756.2855.03.
-83.8696.1889.94.table 2: overall results of baselines across all raddle tasks.
c indicates the combined metric, ic denotes intentclassiﬁcation accuracy.
avg.
is averaged over all the tasks while avg.c is averaged over all the roubust checklisttasks.
para., simp., verbo.
are short for paraphrase, simplification, and verbosity.
note that it isnot straightforward to directly apply damd to unseen and ood tasks since it requires extra annotations.
assuch, we omit results of damd on these two tasks..ples) (madry et al., 2017; miyato et al., 2018; liuet al., 2020; li et al., 2020b).
adversarial exam-ples are produced by adding perturbations on cleanexamples to fool the predictions of a trained modelthe most.
though fundamentally different, onemay view adversarial examples as resembling thevariations in natural language to some extent.
in-spired by this idea, we propose an adversariallyrobust soloist model, denoted as soloistadv.
speciﬁcally, for a dialog turn x drawn from thetraining dataset d, and a neural model soloistparameterized by θ, the standard training min-imizes the empirical risk: minθ ex∼dlθ(x),where lθ(x) is the soloist learning objectivedeﬁned in appendix section a. the key idea ofadversarial training is to modify the objectiveby applying small perturbation δ to input wordembeddings that maximize the adversarial loss:minθ ex∼d maxδ lθ(x+δ), where the inner max-imization can be solved by running a number ofprojected gradient descent steps (goodfellow et al.,2014; bubeck, 2014).
soloistadv is trained ina hybrid manner that combines standard trainingand adversarial training.
it augments the trainingdataset with adversarial examples that add pertur-bations in the word embedding space of originaldialog turns, which improve the model’s robust-ness against noisy inputs that arguably covers lan-guage variations.
in our experiments, soloistadvemploys adversarial training in both task-speciﬁcpre-training and ﬁne-tuning stages..5.3 submission details.
training we leverage the pre-trained check-points from the corresponding work, and ﬁne-tunethem on raddle.
for soloistadv, we apply100k steps of adversarial training to the pre-trainedcheckpoints.
each domain is trained separately.
wetrain our models with adam with initial learningrate 5e-5 and batch size 1 for 20 epochs.
we en-courage subsequent submissions systems to devote.
the same computation efforts in ﬁne-tuning stage,e.g., up to one hour gpu time, for each model toensure fair comparisons..evaluation the raddle benchmark followsthe same evaluation model as glue (wang et al.,2018) or kaggle3.
to evaluate a system on thebenchmark, one must run the system on the pro-vided test data for the tasks, then upload the resultsto the website http://aka.ms/raddle for scoring.
the benchmark site shows per-task scores and amacro-average of those scores to determine a sys-tem’s position on the leaderboard.
the websitealso provides ﬁne- and coarse-grained results onthe robustness diagnostic datasets.
we will providehuman evaluation services for top-ranked submis-sions on a quarterly basis.
the human evaluationprotocol follows peng et al.
(2020a) and li et al.
(2020c)..6 benchmark results.
6.1 overall results.
we ﬁrst present the results of baseline methodsacross all tasks on the raddle benchmark in ta-ble 2. as shown, gpt-2ft ﬁne-tuned with domain-speciﬁc dialog corpora outperforms the strongmodular-based method damd.
this highlights theefﬁcacy of pre-trained language models.
soloistimproves upon gpt-2ft over 10 points in termsof average score, and consistently performs betterthan gpt-2ft across all the tasks.
these strongresults indicate that large-scale task-speciﬁc pre-training on dialog corpora is crucial for effectiveand robust task adaptation.
however, the perfor-mance of soloist drops on robust checklist tasks.
beneﬁting from adversarial training, soloistadvoutperforms soloist about 2 points..3https://www.kaggle.com/.
44246.2 robustness diagnostic checklist results.
table 2 shows the overall performance of dst ande2e modeling under different variation settings..language variationsit is noticeable that all themodels incur signiﬁcant performance drops undereach type of variation.
among all variation types,typos has the most substantial impact on bothjga and combined score resulting in 10 to 20points of drop in performance.
this is expected asmisspelled keywords pose signiﬁcant challengesfor state tracking.
the inﬂuence of other threetypes of variations are also prominent.
the resultsreveal that existing sota dialog models trainedon limited task-speciﬁc examples are not robustenough to handle various types of user utterances.
adversarial training improves robustness to lan-guage variations, boosting performance across allthe language variations tasks..speech errors we observe a clear degradationin all metrics for all models.
this shows that dur-ing inference, models trained on textual data aresensitive and not robust to actual asr hypothesesintroduced in dialog history..unseen entities withouttask-speciﬁc pre-training, gpt-2ft only achieves less than 30% ofjga and 51.20 of dialog act accuracy even on asimple domain with most of the common entityvalues.
soloist performs signiﬁcantly betterthan gpt-2ft by achieving 69.05% jga and96.98 dialog act accuracy but remains imperfect.
soloistadv performs similar to soloist, whichis expected as adversarialtraining does notprovides additional knowledge.
these resultsimply that task-speciﬁc pre-training can improvethe generalization capability of models but is stillfar from enough for production environments..out-of-domain utterancesit is non-trivial forconventional modular-based dialog systems to han-dle ood detection.
it often requires an additionalcomponent to classify whether a user utterance asin-domain or not.
as such, we omit the resultof damd in our experiments.
gpt-2ft achieves83.96 f1 score while soloist has 96.18 f1 score,which shows that task-speciﬁc pre-training can im-prove robustness of models to ood utterances.
itis interesting to observe that adversarial traininghurts model’s performance on ood detection.
weconjecture that adversarial training enable modelsto tolerate disturbances on the inputs and thus yield.
(a) dstc8.
(b) dstc9.
figure 2: corpus and human evaluation for differentmodels in two recent multi-domain dialog challenges:(a) dstc8 and (b) dstc9.
the regions indicate thegap between human and corpus evaluations for differ-ent types of models.
we observe that (i) in dstc8,team 5 is the winner, and the only submission adopt-ing pre-trained gpt-2 models; the performance dis-crepancy between the corpus and human evaluation issigniﬁcantly smaller than other teams using modular-based methods without pre-training.
(ii) a general trendshifting from modular based systems to pre-trained end-to-end systems.
(iii) a substantial drop in performancewhich indicates that pre-trained methods remain sensi-tive to noisy inputs..more false positive predictions on this task..finally, it is worth pointing out some importanttrends in the dialog research community, basedon the dstc challenge (kim et al., 2019; gu-nasekara et al., 2020) in the last 2 years (figure 2).
in dstc8 (kim et al., 2019), the winning sub-mission by team 5 is the only one that uses pre-trained models (gpt-2).
when moving from cor-pus evaluation to human evaluation, it exhibits theleast performance drop relative to other submis-sions, which is strong evidence to demonstrate ro-bustness of pre-trained models.
by the time ofdstc9 (gunasekara et al., 2020), the communityhave witnessed a general trend shift from modu-lar systems to pre-trained end-to-end architectures.
however, the signiﬁcant performance gap betweencorpus evaluation and human evaluation indicatesthat pre-trained methods remain sensitive to noisyinputs.
such observations underscore the impor-tance of robustness-oriented design and evaluation,for which raddle ﬁlls a major void..7 conclusion.
we introduce raddle, a platform and collectionof resources for evaluating and analyzing task-oriented dialog systems.
we conﬁrm (1) the util-ity of grounded pre-training and transfer learningmethods in dialog systems: pre-training improves.
442512345team id0.50.60.70.80.9success ratedstc-8corpus e.human e.non-pre-trained modelspre-trained models12345team id0.50.60.70.80.9success ratedstc-812345team id0.50.60.70.80.9success ratedstc-9generalization in a limited data setting, and (2)adversarial training improves robustness, but stillleaves room for improvement.
when evaluatingthese models on our diagnostic dataset, we ﬁnd thatthey fail (often spectacularly) on many robustnesstest cases, suggesting possible avenues for futurework.
in summary, the question of how to designuniﬁed, efﬁcient, robust models remains largely un-explored, and we believe that raddle can providefertile soil for addressing this challenge..acknowledgement.
we gratefully acknowledge the entire project phillyteam inside microsoft, who provided the comput-ing platform for our research.
we also thank theanonymous reviewers whose suggestions helpedclarify this work..ethical considerations.
the collection of our raddle dataset is consistentwith the terms of use of any sources and the origi-nal authors’ intellectual property and privacy rights.
the dataset is collected with amazon mechanicalturks, and each hit requires up to two minutesto complete.
the requested inputs are general lan-guage variations, and no privacy-related informa-tion is collected during data collection.
each hitwas paid 0.5 usd, with the hourly pay being 15%higher than the minimum wage requirements in ourarea.
a board of data researchers has reviewed allthe collected data to ensure no ethical concerns e.g.,toxic language and hate speech..references.
s´ebastien bubeck.
2014..algorithms and complexity.
arxiv:1405.4980..convex optimization:arxiv preprint.
paweł budzianowski, tsung-hsien wen, bo-hsiangtseng, i˜nigo casanueva, stefan ultes, osman ra-madan, and milica gasic.
2018. multiwoz-a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling.
in proceedings of the2018 conference on empirical methods in naturallanguage processing, pages 5016–5026..sam coope, tyler farghly, daniela gerz, ivan vulic,and matthew henderson.
2020. span-convert: few-shot span extraction for dialog with pretrained con-in proceedings of theversational representations.
58th annual meeting of the association for com-putational linguistics, acl 2020, online, july 5-10, 2020, pages 107–121.
association for compu-tational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 1 (long and short papers), pages4171–4186..li dong, nan yang, wenhui wang, furu wei, xi-aodong liu, yu wang, jianfeng gao, ming zhou,and hsiao-wuen hon.
2019. uniﬁed languagemodel pre-training for natural language understand-ing and generation.
in advances in neural informa-tion processing systems, pages 13042–13054..mihail eric and christopher d manning.
2017. key-value retrieval networks for task-oriented dialogue.
arxiv preprint arxiv:1705.05414..jianfeng gao, michel galley, and lihong li.
2019.neural approaches to conversational ai.
founda-tions and trends r(cid:13) in information retrieval, 13(2-3):127–298..jianfeng gao, baolin peng, chunyuan li, jinchaoli, shahin shayandeh, lars liden, and heung-robust conversational aiyeung shum.
2020.arxiv preprintwith grounded text generation.
arxiv:2009.03457..ian j goodfellow, jonathon shlens, and christianszegedy.
2014. explaining and harnessing adversar-ial examples.
arxiv preprint arxiv:1412.6572..karthik gopalakrishnan, behnam hedayatnia, long-shaokan wang, yang liu, and dilek hakkani-tur.
2020. are neural open-domain dialog sys-tems robust to speech recognition errors in the di-alog history?
an empirical study.
arxiv preprintarxiv:2008.07683..chulaka gunasekara, seokhwan kim, luis fernandod’haro, abhinav rastogi, yun-nung chen, mihaileric, behnam hedayatnia, karthik gopalakrishnan,yang liu, chao-wei huang, et al.
2020. overviewof the ninth dialog system technology challenge:dstc9.
arxiv preprint arxiv:2011.06486..donghoon ham, jeong-gwan lee, youngsoo jang,and kee-eung kim.
2020.end-to-end neuralpipeline for goal-oriented dialogue systems usingin proceedings of the 58th annual meet-gpt-2.
ing of the association for computational linguistics,pages 583–592..charles t. hemphill, john j. godfrey, and george r.doddington.
1990. the atis spoken language sys-tems pilot corpus.
in speech and natural language:proceedings of a workshop held at hidden valley,pennsylvania, june 24-27,1990..matthew henderson, i˜nigo casanueva, nikola mrk-sic, pei-hao su, tsung-hsien wen, and ivan vulic..44262020. convert: efﬁcient and accurate conversa-in pro-tional representations from transformers.
ceedings of the 2020 conference on empirical meth-ods in natural language processing: findings,emnlp 2020, online event, 16-20 november 2020,pages 2161–2174.
association for computationallinguistics..matthew henderson, blaise thomson, and jason dwilliams.
2014. the second dialog state trackingchallenge.
in proceedings of the 15th annual meet-ing of the special interest group on discourse anddialogue (sigdial), pages 263–272..ehsan hosseini-asl, bryan mccann, chien-sheng wu,semih yavuz, and richard socher.
2020. a simplelanguage model for task-oriented dialogue.
arxivpreprint arxiv:2005.00796..nitish shirish keskar, bryan mccann, lav r varshney,caiming xiong, and richard socher.
2019. ctrl: aconditional transformer language model for control-lable generation.
arxiv preprint arxiv:1909.05858..seokhwan kim, michel galley, chulaka gunasekara,sungjin lee, adam atkinson, baolin peng, hannesschulz, jianfeng gao, jinchao li, mahmoud adada,et al.
2019. the eighth dialog system technologychallenge.
arxiv preprint arxiv:1911.06394..stefan larson, anish mahendran, joseph j. peper,christopher clarke, andrew lee, parker hill,jonathan k. kummerfeld, kevin leach, michael a.laurenzano, lingjia tang, and jason mars.
2019.an evaluation dataset for intent classiﬁcation andtheout-of-scope prediction.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 1311–1316, hong kong,china.
association for computational linguistics..in proceedings of.
sungjin lee and igor shalyminov.
2019. contextualout-of-domain utterance handling with counterfeitin icassp 2019-2019 ieeedata augmentation.
international conference on acoustics, speech andsignal processing (icassp), pages 7205–7209.
ieee..sungjin lee, qi zhu, ryuichi takanobu, zheng zhang,yaoqin zhang, xiang li, jinchao li, baolin peng,xiujun li, minlie huang, et al.
2019. convlab:multi-domain end-to-end dialog system platform.
in proceedings of the 57th annual meeting of theassociation for computational linguistics: systemdemonstrations, pages 64–69..chunyuan li, xiang gao, yuan li, baolin peng, xiu-jun li, yizhe zhang, and jianfeng gao.
2020a.
opti-mus: organizing sentences via pre-trained modelingof a latent space.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing (emnlp), pages 4678–4699, online.
as-sociation for computational linguistics..chunyuan li, xiujun li, lei zhang, baolin peng,mingyuan zhou, and jianfeng gao.
2020b.
self-supervised pre-training with hard examples im-arxiv preprintproves visualarxiv:2012.13493..representations..jinchao li, baolin peng, sungjin lee, jianfeng gao,ryuichi takanobu, qi zhu, minlie huang, hannesschulz, adam atkinson, and mahmoud adada.
2020c.
results of the multi-domain task-completiondialog challenge.
in proceedings of the 34th aaaiconference on artiﬁcial intelligence, eighth dialogsystem technology challenge workshop..jiwei li, michel galley, chris brockett, jianfeng gao,and bill dolan.
2016. a diversity-promoting objec-tive function for neural conversation models.
in pro-ceedings of the 2016 conference of the north amer-ican chapter of the association for computationallinguistics: human language technologies, pages110–119..xiaodong liu, hao cheng, pengcheng he, weizhuchen, yu wang, hoifung poon, and jianfeng gao.
2020. adversarial training for large neural languagemodels.
arxiv preprint arxiv:2004.08994..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
arxiv preprint arxiv:1907.11692..ryan lowe, nissan pow, iulian serban, and joellepineau.
2015. the ubuntu dialogue corpus: a largedataset for research in unstructured multi-turn dia-logue systems.
arxiv preprint arxiv:1506.08909..aleksander madry, aleksandar makelov, ludwigschmidt, dimitris tsipras, and adrian vladu.
2017.towards deep learning models resistant to adversar-ial attacks.
arxiv preprint arxiv:1706.06083..shikib mehri, mihail eric, and dilek hakkani-tur.
2020. dialoglue: a natural language understand-ing benchmark for task-oriented dialogue.
arxivpreprint arxiv:2009.13570..takeru miyato, shin-ichi maeda, masanori koyama,and shin ishii.
2018. virtual adversarial training:a regularization method for supervised and semi-supervised learning.
t-pami..robert j moore and raphael arar.
2019. conversa-tional ux design: a practitioner’s guide to the nat-ural conversation framework.
acm..nikola mrksic, diarmuid ´o s´eaghdha, tsung-hsienwen, blaise thomson, and steve j young.
2017.neural belief tracker: data-driven dialogue statetracking.
in acl (1)..yixin nie, adina williams, emily dinan, mo-jason weston, and douwe kiela.
hit bansal,2019. adversarial nli: a new benchmark forarxiv preprintnaturalarxiv:1910.14599..language understanding..4427baolin peng, chunyuan li,.
jinchao li, shahinshayandeh, lars liden, and jianfeng gao.
2020a.
soloist: few-shottask-oriented dialog with asingle pre-trained auto-regressive model.
corr,abs/2005.05298..baolin peng, chenguang zhu, chunyuan li, xiujunli, jinchao li, michael zeng, and jianfeng gao.
2020b.
few-shot natural language generation forin findings of the associa-task-oriented dialog.
tion for computational linguistics: emnlp 2020,pages 172–182, online.
association for computa-tional linguistics..baolin peng, chenguang zhu, michael zeng, and jian-feng gao.
2020c.
data augmentation for spoken lan-guage understanding via pretrained models.
arxivpreprint arxiv:2004.13952..matthew e peters, mark neumann, mohit iyyer, mattgardner, christopher clark, kenton lee, and lukezettlemoyer.
2018. deep contextualized word repre-sentations.
arxiv preprint arxiv:1802.05365..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners..harvey sacks, emanuel a schegloff, and gail jeffer-son.
1978. a simplest systematics for the organiza-tion of turn taking for conversation.
in studies in theorganization of conversational interaction.
elsevier..emanuel a schegloff, gail jefferson, and harveysacks.
1977. the preference for self-correction inlan-the organization of repair in conversation.
guage..pararth shah, dilek hakkani-t¨ur, gokhan t¨ur, ab-hinav rastogi, ankur bapna, neha nayak, andlarry heck.
2018. building a conversational agentovernight with dialogue self-play.
arxiv preprintarxiv:1801.04871..alessandro sordoni, michel galley, michael auli,chris brockett, yangfeng ji, margaret mitchell,jian-yun nie, jianfeng gao, and bill dolan.
2015.a neural network approach to context-sensitive gen-eration of conversational responses.
arxiv preprintarxiv:1506.06714..alex wang, amanpreet singh, julian michael, felixhill, omer levy, and samuel r bowman.
2018.glue: a multi-task benchmark and analysis platformfor natural language understanding.
arxiv preprintarxiv:1804.07461..tsung-hsien wen, david vandyke, nikola mrkˇsi´c,milica gasic, lina m rojas barahona, pei-hao su,stefan ultes, and steve young.
2017. a network-based end-to-end trainable task-oriented dialoguein proceedings of the 15th conference ofsystem.
the european chapter of the association for compu-tational linguistics: volume 1, long papers, pages438–449..chien-sheng wu, steven hoi, richard socher, andcaiming xiong.
2020a.
tod-bert: pre-trained nat-ural language understanding for task-oriented dia-logues.
arxiv preprint arxiv:2004.06871..chien-sheng wu, steven ch hoi, richard socher, andcaiming xiong.
2020b.
tod-bert: pre-trained nat-ural language understanding for task-oriented dia-in proceedings of the 2020 conference onlogue.
empirical methods in natural language processing(emnlp), pages 917–929..qingyang wu, yichi zhang, yu li, and zhou yu.
2019. alternating recurrent dialog model with large-scale pre-trained language models.
arxiv preprintarxiv:1910.03756..puyang xu and qi hu.
2018. an end-to-end approachfor handling unknown slot values in dialogue statetracking.
in proceedings of the 56th annual meet-ing of the association for computational linguistics(volume 1: long papers), pages 1448–1457, mel-bourne, australia.
association for computationallinguistics..zhilin yang, zihang dai, yiming yang, jaime car-bonell, ruslan salakhutdinov, and quoc v le.
2019.xlnet: generalized autoregressive pretraining forlanguage understanding.
neurips..yichi zhang, zhijian ou, and zhou yu.
2020. task-oriented dialog systems that consider multiple ap-propriate responses under the same context.
in pro-ceedings of the aaai conference on artiﬁcial intel-ligence, volume 34, pages 9604–9611..li zhou, jianfeng gao, di li, and heung-yeung shum.
2020. the design and implementation of xiaoice, anempathetic social chatbot.
computational linguis-tics, 46(1):53–93..chenguang zhu.
2020. boosting naturalness of lan-guage in task-oriented dialogues via adversarialtraining.
arxiv preprint arxiv:2004.14565..chenguang zhu, michael zeng, and xuedong huang.
2019a.
multi-task learning for natural language gen-eration in task-oriented dialogue.
in proceedings ofthe 2019 conference on empirical methods in nat-ural language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 1261–1266..chenguang zhu, michael zeng, and xuedong huang.
sim: a slot-independent neural modelarxiv preprint.
2019b.
for dialogue state tracking.
arxiv:1909.11833..qi zhu, zheng zhang, yan fang, xiang li, ryuichitakanobu, jinchao li, baolin peng, jianfeng gao,xiaoyan zhu, and minlie huang.
2020. convlab-2: an open-source toolkit for building, evaluating,in proceedingsand diagnosing dialogue systems.
of the 58th annual meeting of the association forcomputational linguistics: system demonstrations,pages 142–149, online.
association for computa-tional linguistics..4428down the mismatched items (y = 0 for negativesamples x(cid:48)).
since the the special token [eos] at-tends all tokens in the sequence, the output featureon [eos] is the fused representation of all items.
we apply a binary classiﬁer on top of the feature.
lc = y log(pθ(x)) + (1−y) log(1 − pθ(x(cid:48)))..(5).
please refer (peng et al., 2020a) for more details..a background on soloist.
we review the soloist (peng et al., 2020a) forcompleteness.
each dialog turn is represented as:.
x = (s, b, c, r),.
(1).
where s is the entire dialog history up to the cur-rent dialog turn, b is the dialog belief state acquiredfrom human annotation, c is the db state automat-ically retrieved from a database using b, and r isthe delexicalized dialog response, from which thesystem response in natural language can be easilyobtained with some automatic post-processing.
insum, each item in x is by itself a sequence of to-kens, the entire dialog turn can be viewed as a longsequence..soloist is a neural model parameterized by θto characterize the sequence generation probabilitypθ(x).
it is pre-trained using publicly availableheterogeneous dialog corpora with labels of beliefstates and db states.
the pre-trained model can beﬁne-tuned to any new task to generate responsesgrounded in task-speciﬁc user goals and a database.
the pre-training and ﬁne-tuning share the samemulti-task objective for learning θ:.
lθ = lb + lr + lc ,.
(2).
where each task is described as follows:.
task 1: belief prediction for a belief state se-quence of length tb, we deﬁne the objective ofpredicting the belief state as:.
lb = log p(b|s) =.
log pθ(bt|b<t, s),.
(3).
tb(cid:88).
t=1.
where b<t indicates all tokens before t..task 2: grounded response generation alength tr, r =delexicalized response of[r1, · · · , rtr ], is generated by our model token-by-token from left to right, grounded in dialog historyc, belief state b and db state s. the correspondingtraining objective is deﬁned as.
lr = log p(r|c, b, s).
(4).
=.
log pθ(rt|r<t, c, b, s)..tr(cid:88).
t=1.
task 3: contrastive objective a contrastiveobjective is employed to promote the matcheditems (y = 1 for positive samples x) while driving.
4429