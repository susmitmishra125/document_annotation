end-to-end lexically constrained machine translationfor morphologically rich languages.
josef jon and joão paulo aires and dušan variš and ondˇrej bojarcharles universitysurname@mail.ufal.mff.cuni.cz.
abstract.
lexically constrained machine translation al-lows the user to manipulate the output sen-tence by enforcing the presence or absenceof certain words and phrases.
although cur-rent approaches can enforce terms to appearin the translation, they often struggle to makethe constraint word form agree with the restof the generated output.
our manual analy-sis shows that 46% of the errors in the outputof a baseline constrained model for englishto czech translation are related to agreement.
we investigate mechanisms to allow neural ma-chine translation to infer the correct word in-ﬂection given lemmatized constraints.
in par-ticular, we focus on methods based on trainingthe model with constraints provided as part ofthe input sequence.
our experiments on theenglish-czech language pair show that this ap-proach improves the translation of constrainedterms in both automatic and manual evaluationby reducing errors in agreement.
our approachthus eliminates inﬂection errors, without intro-ducing new errors or decreasing the overallquality of the translation..1.introduction.
in neural machine translation (nmt), lexical con-straining (song et al., 2019; hokamp and liu,2017; post and vilar, 2018) involves changing thetranslation process in a way that desired terms ap-pear in the model’s output.
translation constraintsare useful in domain adaptation, interactive ma-chine translation or named entities translation.
cur-rent approaches focus either on manipulating beamsearch decoding (hokamp and liu, 2017; post andvilar, 2018; hu et al., 2019) or training an nmtmodel using constraints alongside the input (dinuet al., 2019; song et al., 2019; chen et al., 2020).
in inﬂected languages, constraints from bothsource and target sides may appear in numeroussurface forms, which may result in errors during.
figure 1: comparison between constrained translationsfrom english to czech..translation.
by enforcing the presence of a certainexact term on the target side, existing approachesfail to deal with word inﬂections.
as we show, theypreserve the surface form of the word provided asconstraint regardless of the context.
morphologi-cally rich languages have multiple forms of eachword, e.g.
inﬂections to nouns.
for satisfactoryresults in these languages, the constraint process-ing method needs to be capable of detecting anysurface form on the source side and generating thecorrect surface form on the target side..to illustrate the problem, figure 1 shows a sen-tence translation from english to czech with out-puts from three methods.
the ﬁrst one is a no-constraint translation where “hawkish” is translatedas “jestˇrábím” (literally “hawkish”, no ﬁgurativemeaning; followed by a further mis-translation of“lot”).
the second is a constrained model requestedto use the word form “radikální” (“radical”) in theoutput.
the constraint was satisﬁed but the adjec-tive should have taken the comparative degree tomatch the rest of the translation.
the third output isthe result of a model that processes the input alongwith the canonical form constraint (“radikální”)and modiﬁes the constraint inﬂection in the ﬁnaltranslation (“radikálnˇejší”) to correctly express thecomparative form (although the translation of “lot”is worse than in previous case)..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4019–4033august1–6,2021.©2021associationforcomputationallinguistics4019likud party has merged with an even more hawkish lotunder avigdor lieberman.input(en)no constrainttranslation(cs)strana likud se spojila s ještě jestřábím losempod avigdorem liebermanem.surface formmodel output(cs)strana likud se spojila s ještě radikální partoupod vedením avigdora liebermanalemmatizedmodel output(cs)strana likud se spojila s ještě radikálnější partiípod vedením avigdora liebermana.radikálníradikálníwe evaluate different methods of lexically con-strained machine translation on the czech language.
we propose an approach to deal with word inﬂec-tion in lexically constrained translation.
by traininga model that receives lemmatized target constraintsas the input alongside the source sentence, we im-prove the generation of constraints in forms match-ing the output context.
we run experiments on bothsynthetic and real-world test scenarios..2 related work.
in mt, there are scenarios where words that shouldor should not appear in the output are known up-front.
common use cases include integration ofdomain-speciﬁc terminology and translation ofnamed entities or rare words using a dictionary.
such functionality was previously implemented inphrase-based systems (okuma et al., 2008), likemoses (koehn et al., 2007).
in nmt, this taskis not yet deﬁnitely solved, since the translationprocess is hard to interpret and inﬂuence..2.1 output post-processing.
in order to enforce the presence of speciﬁc terms,some approaches post-process the output.
prior tosubword handling (sennrich et al., 2016; kudo andrichardson, 2018), unknown words were correctedby replacing them with word translation pairs froma bilingual dictionary (luong et al., 2015).
cregoet al.
(2016) use placeholders to translate numbersand named entities.
placeholders have also beenfound useful for translation of text with formalmark-up and its interaction with content (hanne-man and dinu, 2020)..2.2 constrained decoding.
an alternative way of adding constraints to the ﬁ-nal translation is by manipulating the beam searchdecoding process.
anderson et al.
(2017) use aﬁnite state machine (fsm) that recognizes targetsentence with constraint patterns.
each state ofthe fsm has its own beam and only hypothesesin beams that are in accepting states can be ﬁn-ished.
hasler et al.
(2018) improve upon this workby utilizing encoder-decoder attention weights toguide the placement of a constraint.
chatterjee et al.
(2017) also use attention weights and beam searchlook-ahead to choose constraint positions..hokamp and liu (2017) present grid beamsearch, which extends the usual beam search (ochand ney, 2004) with a mechanism to ensure the.
coverage of all constrains.
post and vilar (2018)propose a similar but more efﬁcient algorithm.
bydynamically reallocating the beam capacity, an arbi-trary number of constraints can be processed withina constant width of the beam..one shortcoming of the above methods is theslower inference compared to unmodiﬁed beamsearch models.
this issue is in large part solvedby effective vectorized beam allocation (hu et al.,2019).
another drawback of constrained decodingis a less ﬂuent output, especially in morphologi-cally rich languages, since we force the output tocontain a phrase that may not be in agreement withthe rest of the output..2.3 learned constraining.
one way of integrating constraints into nmt is toprovide them alongside the input sentence and trainthe model to be biased towards utilizing them.
thisgives the user less direct control over the outputtranslation and requires specially trained models.
on the other hand, these approaches are simple toimplement, do not incur inference slowdown, andmake the translation more robust in case of wronglychosen constraints.
nmt models are often able toproduce very ﬂuent output (popel et al., 2020a),making them capable to cope with inﬂections prop-erly.
thus, using this capability may yield betterresults than constrained decoding with heuristicsfor inﬂections in inﬂected languages..dinu et al.
(2019) use input factors to annotatesource sentences with desired translations and trainthe model to copy these translations into the outputsequence.
chen et al.
(2020) append constraintsto the end of the source sentence.
their goal is totrain the model to place constraints in the outputtranslation without the need of a bilingual dictio-nary or a speciﬁed word alignment.
song et al.
(2019) also propose a data augmentation approachthat uses constraints along the source as input dur-ing the model training.
concurrently to our work,bergmanis and pinnis (2021) modify dinu et al.
(2019) approach by providing lemmatized wordfactors associated to random tokens in the sourcesentence.
with the lemmatized factors, they forcethe model to learn the correct inﬂection of the wordin the translation..the main difference between our work and mostof the existing approaches is the use of lemma-tized constraints to allow the model to correctlyinﬂect them to agree with the output context.
the.
4020concurrent work by bergmanis and pinnis (2021)presents a very similar idea.
they also use lem-matized forms of the constraints and let the modelitself to generate correct surface form.
while theirchoice of languages (english to latvian) and theirexperimental setup was slightly different, the over-all conclusions of their work agree with ours.
themain difference is the approach to integration of theconstraints.
bergmanis and pinnis (2021) use fac-tors to directly annotate to the source tokens withlemmas of their desired translations.
we experi-mented with this approach (see b.5), but in most ofthe experiments, we opted for a simpler integrationmethod, by concatenating desired target lemmas tothe source sentence.
this simpliﬁes preparation ofthe training data by removing the need for sourceto target word alignment and as we show, hurts theperformance only by a very slight margin..3 proposed methods.
building upon the described techniques, we fo-cus on allowing the model to choose the correctword form.
our approaches are based on learnedconstraining, where the constraints are lemmatizedduring both training and test time..3.1 learned constraining.
in our approach, we append the target constraintsas a sufﬁx of the input sentences, same as chenet al.
(2020).
we use <sep> token to separateconstraints from the input sentence, and <c> tokento separate constraints from each other.
inspiredby chen et al.
(2020), we shift the positional em-beddings by 1024 for the constraint tokens.
how-ever, while chen et al.
(2020) start each constrainton the same position, we shift the start of theconstraint string and continue monotonically fromthere.
we do not use any other techniques describedin their work.
the following example illustratesan input to our baseline constrained model, pass-ing two constraints (“plánováno” and “obcích”)along with the source text.
in this case, both con-straints are in correct target surface forms, whichare obtained from the reference translation.
with-out knowledge of the reference, it is necessary tosolve the problem of agreement of the constraintwith the rest of the translation, which is the maingoal of our work..source: price increase is planned mainly in largermunicipalities.
<sep> plánováno <c> obcích.
reference: zvýšení cen je plánováno pˇredevšímve vˇetších obcích..we also experimented with the factored translationapproach introduced by dinu et al.
(2019) asa second constraintinappendix b, we present the description of themethod and a comparison with appending theconstraints as a sufﬁx..integration method..3.2 preparing synthetic constraints.
to our current knowledge, there is no english-czech dataset with provided constraints.
thus, wegenerate constraints from the existing parallel data.
we consider two approaches to generate constraintsfor the training and test data..training the simplest method of obtainingtarget-side constraints is sampling random tokensubsequences from the reference sentence.
in ourexperiments, every token in the sentence can be-come a start of a constraint with probability of 0.3.an open constraint ﬁnishes on each subsequenttoken with probability of 0.85 and multiple con-straints for a single sentence are permitted (withoutoverlapping).
we did not optimize these probabil-ities, further gains may be obtained by a searchfor better values.
the constraint order is randomlypermuted, since during the test time, order of con-straints in the target is not known beforehand.
thesecond approach makes use of either a bilingualdictionary or a terminology database.
if a transla-tion pair from the dictionary is found in the sourceand target sentences, its target side can serve as theconstraint.
by this method, we also obtain align-ment of the source and target expressions, whichis useful for the factored translation approach (seeappendix b.5)..test time given an input sentence and no refer-ence translation, we can synthesize constraints bysearching for source expressions in a dictionaryor a terminology database.
dictionaries generallymap one expression to many target ones and weor the model have to decide which of them to use.
terminology databases are usually unambiguousand the target translation serves as the constraint.
we experiment with terminology in section 4.3..4021lemmatization our methods use lemmatized1constraints.
for the random target subsequencemethod, we lemmatize the selected words.
forthe dictionary search method, we lemmatize boththe dictionary and training data and we searchfor matching expression pairs using the lemmas.
during the actual training, we use the original,non-lemmatized sentence with lemmatized con-straints.
this scenario is more similar to real-lifeuse cases, since target word form which shouldbe produced is not known beforehand.
with con-straint lemmatization, the above example would be:.
input: price increase is planned mainly in largermunicipalities.
<sep> obec <c> plánovat.
4 experiments.
in this section, methods presented above are com-pared on various tasks and datasets.
first, weuse an oracle test set, which is created with pre-vious knowledge of the reference.
we use it toassess the ability of the models to integrate the con-straints themselves without additional noise causedby problems of the real world.
in the subsequentexperiments, we present a more realistic scenario –we use ofﬁcial terminology for eu-related expres-sions to translate parts of europarl corpus.
finally,we evaluate the approaches on translation of gen-eral, open-domain rare words using dictionary..4.1 data.
we train english-czech nmt models for our exper-iments.
czech has a high degree of inﬂection withseven cases and three genders for nouns and adjec-tives.
we train our models on czeng 2.0 (kocmiet al., 2020) using all authentic parallel sentences(61m), as well as back-translated czech mono-lingual sentences (51m).
newstest-2019 (barraultet al., 2019) is used as a validation set and newstest-2020 (barrault et al., 2020) as a test set.
we breakthe text into subwords using sentencepiece (kudoand richardson, 2018) and lemmatize using ud-pipe (straka and straková, 2017).
bleu scoresare computed using sacrebleu (post, 2018).2.for experiments mentioning dictionaries, we ex-tracted pairs of terms from english and czech wik-.
tionary3 and a large commercial dictionary.
in ap-pendix b.2 we show that using wiktionary alsoimproves performance upon baseline, but the com-mercial dictionary offers better coverage of theexpressions and thus provides better overall results.
for this reason, all the experimets shown furtherare based on the commercial dictionary data..we use the czech government database for euterminology4 to evaluate integration of domain-speciﬁc terminology through constraints.
we se-lect all czech terms and their translation to en-glish, which corresponds to 14203 expressionsper language.
then, we search the europarl5 cor-pus (koehn, 2005) for sentence pairs containingenglish terms in the source side and lemmas ofthe czech translation in a lemmatized version ofthe target side, ignoring trivial terms.
keeping atmost the ﬁrst ten sentence pairs containing speciﬁcsource term, the ﬁnal dataset consists of 6585 ex-amples, covering 1433 terms.
we remove thesesentences from the training data, since europarl ispart of the czeng corpus..4.1.1 model.
we use mariannmt (junczys-dowmunt et al.,2018) to train transformer-base models with stan-dard parameters (vaswani et al., 2017).
inspired bypopel et al.
(2020b), we alternate between authenticand backtranslated data every 25 million trainingsentences, while using exponential smoothing ofthe parameters.
four nvidia v100 gpus wereused for the training and one training run (400-500k steps) takes approximately 40 hours with thisconﬁguration.
a large portion of the computationtime can be saved by ﬁnetuning an existing nmtmodel on the proposed dataset.
by ﬁnetuning thebaseline model we reached the same performanceafter 30-50k steps.
however, all the results pro-vided in this paper are obtained by training fromscratch.
since we integrate constraints in the targetlanguage into the source sequence, we share sourceand target vocabularies (and embeddings), consist-ing of 32000 subwords, to allow easier copying ofthe subwords from source to target sequence..4.2 oracle constraints.
to assess the ability of a model to produce theprovided constraints in the output, we use newstest-.
1in appendix b, we show that simple stemming heuristicperforms at least as well as proper lemmatization in automatedmetrics described further..2sacrebleu signature: bleu+case.mixed+lang.en-cs+numrefs.1+smooth.exp+test.wmt20+tok.13a+version.1.4.14.
3www.wiktionary.org4sap.vlada.cz/dul/zavaznet.nsf/ca?.
openview.
5www.statmt.org/europarl/.
4022train const..train form test form bleu cvg.
baselinerandomrandomrandomrandomdictdictdictdictdict, skip halfdict, skip halfdict, skip halfdict, skip half.
--surfacesurfacelemmasurfacesurfacesurfacelemmasurfacesurfacesurfacelemma.
--surfacelemmalemmasurfacesurfacelemmalemma-surfacelemmalemma.
bleul cvgl78.1478.4794.5594.2693.6168.6993.2391.5589.0278.0693.0090.7985.30.
38.237.139.936.839.720.442.239.640.538.242.340.039.3.
68.8469.5994.0061.3182.3757.3493.4664.1178.6168.8891.3768.075.36.
32.031.234.527.133.316.537.730.634.231.736.931.433.1.table 1: results on newstest-2020 with oracle constraints.
the ﬁrst column shows the methods used for obtainingconstraints for training.
‘random’ means sampling random subsequences of target tokens, ‘dict’ stands for termsmatched by dictionary.
in the ‘skip half’ variant, a half of the training examples is presented with no constraint.
for test sets, only constraints from the dictionary are used, still chosen so that the reference sentence containsthe requested words.
the second and third column indicate if the appended constraints are lemmatized or not, attraining and test time, respectively..2020 test set with oracle constraints.
these con-straints are obtained via dictionary search on thetest set as described above, i.e., the constraints areterms from a english-czech dictionary, where bothsource and target sides are present in the sentencepair.
note that we know the reference beforehand,thus, this evaluation may not reﬂect improvementin translation in a real world setting.
we only useit to measure the ability of constraint integration.
we trained two sets of constrained models.
theﬁrst one, baseline constrained models, use originaltarget side forms of the constraint expressions.
thesecond set consists of models trained using lemma-tized forms of the constraints.
our goal with thelemmatized models was to harness the languagemodeling capacity of the model to generate a sur-face form of lemmatized constraint that agrees withthe rest of the translation..table 1 presents the results.
we used two formsof the test set constraints – original reference formsand lemmatized constraints (column test form).
the lemmatized constraints are closer to real worldscenario, where we do not know the output form ofthe constraint expression beforehand..as a sanity check, we compute standard bleuand bleu calculated on lemmatized hypothesisagainst lemmatized reference (bleul).
more im-portantly, we assess target constraint coverage (cvgand cvgl) on original and lemmatized test set by.
comparing the constraints in the output with thereference.
note that in theory, cvg value should al-ways be lower or equal to cvgl, since surface formcoverage is equal to lemma coverage minus propor-tion of incorrectly generated surface forms.
this isnot always the case, since the lemmatizer takes thesentence context into consideration and lemmatizedversions of stand-alone terms in the terminologydatabase may not match lemmatized versions ofthe same terms inside a reference sentence.
thiscauses a slight underestimation of cvgl..the cvg and cvgl columns document that bothmethods of constraint synthesis for training (ran-dom target subsequences and dictionary terms) leadto models capable of producing more than 93% ofthe constraints when constraints are not lemma-tized.
surface coverage of surface form trainedmodels drops to 61–68% when using lemmatizedform of the test set constraints, but lemma coverageis only slightly lower – this is expected, as thesemodels are trained to reproduce exact form of thegiven constraints..the results of models trained on lemmatizedconstraints with lemmatized test constraints showthat the surface form coverage increases com-pared to surface form trained models with lem-matized test constraints (rows lemma/lemma vs.surface/lemma).
while the coverage is lower thanwhen using surface form test set for the surface.
4023train.
test.
bleu.
cvg.
train c..test c. bleu cvg cvgl.
baseline.
all.
skip half.
no constraintsno constraintstermsdictterms + dictno constraintstermsdictterms + dict.
37.919.137.343.344.038.238.443.543.1.
75.0261.4091.7384.1493.7575.3290.5283.4991.22.
-.
sf.
lemma.
--canon.
ref sflemma-canon.
ref sflemma.
38.238.836.640.635.138.638.939.138.9.
69.9070.2744.096.9730.8869.8777.181.4477.22.
84.3785.096.5695.0896.7484.0595.4494.1595.55.table 2: performance of models trained using surfaceforms of dictionary constraints on the same europarltest set split.
train column documents whether allof the training sentences were accompanied by con-straints, or we left 50% of them without constraints(skip half ).
term constraints come from a terminologydatabase, dict constraints are expressions from a gen-eral dictionary.
note that for applying dict constraintsat test time, we used test reference for dictionary targetterm disambiguation, which makes this combined ap-proach not feasible in realistic conditions.
all test setconstraints are used in reference surface forms..table 3: results on whole europarl test set.
none ofthe bleu scores for constrained models (except refsf) is signiﬁcantly better than the best unconstrainedscore..4.3 terminology integration.
since the studied methods proved to work wellwith oracle surface form of constraints, we movedto a realistic use-case with the europarl test setdescribed in section 4.1. we split the test set intotwo parts:.
form model, we show in section 5 that this ismainly an artifact of reference-based evaluationand that the model inﬂects the constraints correctly..the model trained with constraints based on dic-tionary reaches the best performance on the oracleconstraint test set, for which the constraints are gen-erated in the same way.
however, when constraintsare not supplied, bleu and coverage drops sharply(the row dict/surface/-).
this may be caused by thefact that sentences containing expressions presentin the dictionary are almost always accompaniedby the constraint during the training.
therefore, themodel is not presented with many examples wherethe translation appears without the correspondingconstraint and generates constraint expression withmuch lower probability when this happens duringthe test time.
we experimented with skipping halfof the sentences during the constraint generation,leaving them without any constraints (“skip half”in the table).
as shown in table 1, this largelyreduces the problem – without any test time con-straints, the model reaches baseline results (the rowdict, skip half/surface/-).
however, when the con-straints are supplied, the coverage is slightly lowerthan for a model trained with constraints for all thesentences (e.g.
91.4% instead of 93.5% for surfaceform models).
fine-tuning the ratio or choosingthe sentences to leave without the constraints dy-namically during the training might help to solvethis problem..• same contains examples where the form ofthe constraint in the reference is the same asin the terminology database (and as providedto the baseline constrained model),.
• diff contains examples where the form of theconstraint in the target sentence is differentfrom the database form..the target lemmas of the constraint should matchin both cases..this split allows us to better assess the trans-lation in inﬂected languages, since the problemswe focus on are more pronounced in the diff testset.
table 2 shows that the model trained withdictionary constraints underperforms in terms ofbleu when only the constraints from terminol-ogy database are supplied (bleu of 19.1).
thisis caused by the issue described earlier – duringthe training, the model does not encounter thewords which are present in the dictionary enoughtimes without the constraint.
when the dictio-nary constraints are used alongside the terminologydatabase constraints (rows denoted by “terms +dict”), the bleu score increases.
this approachrequires either prior knowledge of the reference,or a mechanism for the target dictionary term dis-ambiguation.
to mitigate this issue, we skip halfof the sentences when generating the constraints,i.e., half of the training corpus is seen without anyconstraints.
this alleviates the problem to a largeextent, see the “skip half” results..4024train c..test c. bleu cvg cvgl.
train c..test c. bleu cvg cvgl.
-.
sf.
lemma.
--canon.
ref sflemma-canon.
ref sflemma.
38.338.835.040.834.338.738.939.239.0.
67.167.1415.2096.3215.3866.6172.3179.1672.62.
84.1284.6896.2093.9296.4183.4294.7692.7894.88.table 4: results on diff europarl test set split, wherewe only consider cases where the constraint is providedin different form than in the reference, i.e.
referencecontains different form than the canonical one presentin the terminology database.
none of the bleu scoresfor constrained models (except ref sf) is signiﬁcantlybetter than the best unconstrained score..we present the results on the whole test set in ta-ble 3. the ﬁrst and second columns show wordform of the constraints during the training andtest time, respectively.
canon.
constraint is in itscanonical, original form from the the terminologydatabase.
ref sf rows show results with constraintsin the same form as in the reference translation (thisrequires prior knowledge of the reference)..first, let us focus on results of models trainedwith surface form constraints.
three trends in theresults hint that generating the correct constraintform is challenging for the model, if the correctform is different from the one supplied in the in-put.
first, the difference between surface formand lemma coverage (44% vs 96.6%) shows themodel generates the correct constraint words, butin a form not matching the reference.
second, thedifference is more pronounced in the diff split (ta-ble 4), while in the same split (table 5), surfaceform coverage is almost the same as the lemmacoverage.
this is because in the same split, targetconstraints are already in the canonical form, sameas in the terminology database, so there is no needfor further inﬂection.
third, using constraints inthe same surface form as in the reference (ref sf)improves the observed coverage compared to usingthe canonical form from the terminology database(e.g., 97% vs 44% on the whole test set, see ta-ble 3).
this “oracle” setting, using the referenceto determine the correct surface form, shows theupper limits of the constraint integration approach,if the inﬂection issue is solved optimally..as stated earlier, we trained the models again us-ing lemmatized versions of the constraints.
whenwe supply lemmatized constraints to these mod-.
-.
sf.
lemma.
--canon.
lemma-canon.
lemma.
37.938.839.936.638.438.838.8.
75.0275.9497.6959.5675.8985.8185.58.
84.7285.5097.0397.3885.1596.5596.55.table 5: results on same europarl test set split.
in thissubset, the constraints from terminology database arealready in the same form as in reference, i.e.
canon.
is the same as ref sf.
bleu score that is signiﬁcantlybetter than the best bleu without constraints is in bold(bootstrap resampling, p ≤ 0.05)..els during the test time, the coverage rises from44% (surface form trained model with canonicalconstraint forms) to 77%, but this is still far fromthe oracle 97%.
this suggests that a large roomfor improvement exists, but as we show in sec-tion 5, most of these discrepancies are caused byreference-based evaluation and are not real errors.
in majority (92%) of the cases marked as not cov-ered when using lemmatized model, the form ofthe constraint is different from the reference, butcorrect given the context, as the model translatesthe sentences differently (but correctly)..4.4 comparison with constrained decoding.
our work is based on training the nmt model toinclude provided constraints in the output transla-tion.
another popular way of constraint integrationis modifying the decoding process.
we hypothesizethat this approach will not be useful in our scenario,since the constraints are enforced in their surfaceforms, which is the issue we are trying to solve.
to verify this, we evaluated lexically constraineddecoding by hu et al.
(2019) as implemented infairseq (ott et al., 2019) on the europarl test setsdescribed in section 4.3..split.
con.
bleu cvg bleul cvgl.
pos ρ.samesamediffdiffwholewhole.
noyesnoyesnoyes.
36.435.736.430.636.432.3.
69.397.163.126.065.250.7.
42.841.543.139.343.040.0.
79.797.381.394.780.895.6.
0.950.830.950.800.950.81.table 6: lexically constrained decoding.
the results in table 6 show that while the con-strained decoding indeed produces the target con-straints in the output, they stay in the same formas in the terminology database.
this is shown bythe low surface form constraint coverage (column.
4025constraint srcno constraintreference termrandom term.
bleu % as ref % correct21.623.122.6.
64.691.783.3.
35.491.754.2.table 7: translation of sentences containing rare words.
for source expressions with multiple possible transla-tions according to the dictionary, we compare choosinga translation variant randomly (random term) againstchoosing the same translation variant as in the refer-ence.
all constraints are lemmatized.
column % as refshows the percentage of examples with the constrainttranslated with the same term as in the reference.
col-umn % correct shows human evaluation of rare wordtranslation..cvg) for the diff and whole dataset splits, whilefor the same split, where the constraints are in thesame form in the translation as in the terminologydatabase, the coverage is high.
on lemma level(cvgl), coverage on all splits remains high, againshowing that the system produces exactly the sur-face form provided, instead of correct target sen-tence form.
note that the results are not directlycomparable with the results in previous subsec-tion, since here we use only a part of the trainingdata (ﬁrst 25m sentence pairs from parallel part ofczeng) for the preliminary experiments..we also observed that the pearson correlation ofconstraint placement in respect to reference transla-tion (see appendix a.1 for details) is lower (0.81)when using constrained decoding than when usingthe training approach as in the main experiments(0.94)..4.5 semi-parametric rare words translation.
we deﬁne rare words as terms from a dictionarythat occur in the source side of the training corpusat most 50 times.
we create a subset of our generaldictionary by only using expression pairs with rarewords on source side.
we search wmt 2007-2020english-czech news test sets (barrault et al., 2020)for sentence pairs containing term pairs from thisrare word dictionary, resulting in 48 examples.
adictionary generally provides 1-to-many mappingsof source terms to a target language, so the cor-rect target expression needs to be disambiguated.
table 7 presents results with no constraints, withconstraints where the lemmatized target constraintis chosen based on the lemmatized reference, andwith constraints where the target expression is cho-sen randomly from all the possible translations.
weused a model trained on lemmatized random targettoken subsequences for the translation.
on aver-.
age, each rare word in the test set has 3.3 possibledictionary translations.
aside from bleu score,we show the percentage of rare words translatedcorrectly, meaning that either they are the sameexpression as in the reference, or that they are syn-onymous expressions that are correct in the givencontext.
this is different from the terminology usecase, since we do not strictly enforce single possi-ble translation.
the results show that even with therandom choice of the dictionary constraint trans-lation, our model improves the translation of rarewords..5 manual analysis.
in this section, we analyse examples marked aserrors by automatic evaluation.
in appendix a.1,we analyse the position of constraints in translationoutputs, showing that they are placed correctly.
inappendix a.2, we look closely at the constrainedtranslation of an out-of-domain document..5.1 error analysis.
we manually analysed outputs marked as not hav-ing the desired constraint in the reference surfaceform by the automatic coverage evaluation intro-duced in the previous section.
table 9 presents theresults.
we compare three models.
first, the base-line without any constraints (column b).
second,the best model trained with non-lemmatized con-straints (sf), and, ﬁnally, the best model trained onlemmatized constraints (column l).
the baselinemodel outputs have constraint surface form cover-age of 69.9% on the whole europarl test set, whichresults in 1982 out of 6585 examples being markedas different from the reference by the automaticevaluation.
the sf model reached 44% coverage(4346 differences).
the lemmatized model agreedwith the reference in 77.1% (1508 differences).
foreach model, we randomly sample 100 supposedlyerroneous translations to be analysed..the ﬁrst row of table 9 shows the number of ex-amples with constraints incorrectly inﬂected in thecontext of the generated output.
rows 2 and 3 showcases where the constraint form agrees with rest ofthe translation: correct in correct context (ccc)indicates that the target sentence is a valid trans-lation, whereas correct in incorrect context (cic)indicates that the constraint was inﬂected correctlygiven its context but as a whole, the translation iswrong.
thus, ccc cases are not in fact errors, butwere wrongly classiﬁed as such by the automatic.
4026sourcethey are seeking to weakenthe commission’s proposal tobeneﬁt the industry..canon ref.
návrh.
návrhu.
translationsnaží se oslabit návrh komise ve prospˇech pr˚umyslu.
snaží se oslabit návrh komise na prospˇech pr˚umyslu.
snaží se oslabit návrhu komise ve prospˇech pr˚umyslu..errorccccicinﬂection.
table 8: example of three error types given canonical and reference target form constraints..error type.
incorrect inﬂectioncorrect in correct contextcorrect in incorrect contextdifferent correct word choicedifferent incorrect word choiceinvalid translation.
b.
26502805.sf.
46443205.l.0922411.table 9: analysis of 100 outputs marked as errors bythe automatic evaluation, which means that either theydo not contain the constraint or they contain it in a dif-ferent surface form compared to the reference.
we anal-ysed three models – baseline (b), a model trained withsurface form constraints using canonical forms of theconstraints at test time (sf), and a model trained withlemmatized constraints using lemmatized terminologyentries at test time (l)..evaluation, based on a direct comparison with thereference.
the cases where the model ignores theconstraint and generates a different word are in thecategories different correct/incorrect word choice(fourth and ﬁfth rows), based on whether the gen-erated word is a plausible translation of the sourceconstraint.
examples where the translation gener-ally goes wrong and the issue does not ﬁt into theprevious categories are under invalid translation..our analysis shows that for the lemmatizedmodel (l), the vast majority of the examples clas-siﬁed as errors are actually correctly translated andcontain the requested constraint in the correct sur-face form.
the presumed error is an artifact ofthe reference-based evaluation.
only 8% of theseexamples are real errors, compared to 66% for thesurface form model..in table 8, we show three examples of errorsfound by the automatic evaluation.
given thecanonical and reference source form of a constraint(návrh and návrhu, respectively, meaning “pro-posal”), some errors may arise in the translation.
in the ﬁrst row, although different from the ref-erence source form, the constraint is correctly in-ﬂected given the context generated and in a correcttranslation, which conﬁgures a “correct in correctcontext” error (ccc).
similarly, in the second row,the same constraint with the same source form iscorrectly inﬂected given the context but in a wrongtranslation, which describes a “correct in incorrect.
context” (cic) error.
finally, the third translationhas a wrong inﬂection given the context generated(inﬂection error)..6 conclusion.
we described the problem of word inﬂection in lexi-cally constrained machine translation.
our solutioncapitalizes on the ability of nmt models to gen-erate correct word forms in the output translation.
we train a transformer model using lemmatizedconstraints supplied alongside the input sentences,and correct surface forms of the constraints in thereference.
this training leads to a model producingthe constraints in the output with high coverage,correct placement, and in a correct surface form..we compare several methods of obtaining con-instraints and integrating them into the input.
the realistic use case of terminology integration,we evaluated our methods and show that withoutlemmatizing the training constraints, the chosenapproach of integrating constraints into nmt doesnot work well for czech.
we effectively solvethe issue of inﬂection errors by lemmatizing con-straints, taking advantage of the transformer’s lan-guage modelling capacity with no additional infer-ence costs.
this has been proven by both automaticand manual evaluation.
we show our method is alsoeffective in translating general domain rare wordsusing a bilingual dictionary and we plan futurework in solving the problem of choosing correcttranslation term from number of variants..acknowledgements.
our work is supported by the bergamot project (eu-ropean union’s horizon 2020 research and innova-tion programme under grant agreement no 825303)aiming for fast and private user-side browser trans-lation, ga ˇcr neurem3 grant (neural repre-sentations in multi-modal and multi-lingual mod-elling, 19-26934x (riv: gx19-26934x)) and bysvv 260 453 grant.
we also want to thank michalnovák for his useful feedback and discussions..4027references.
peter anderson, basura fernando, mark johnson, andstephen gould.
2017. guided open vocabulary im-age captioning with constrained beam search.
inproceedings of the 2017 conference on empiricalmethods in natural language processing, pages936–945, copenhagen, denmark.
association forcomputational linguistics..loïc barrault, magdalena biesialska, ondˇrej bojar,marta r. costa-jussà, christian federmann, yvettegraham, roman grundkiewicz, barry haddow,matthias huck, eric joanis, tom kocmi, philippkoehn, chi-kiu lo, nikola ljubeši´c, christofmonz, makoto morishita, masaaki nagata, toshi-aki nakazawa, santanu pal, matt post, and marcoszampieri.
2020. findings of the 2020 conference onin proceedings ofmachine translation (wmt20).
the fifth conference on machine translation, pages1–55, online.
association for computational lin-guistics..loïc barrault, ondˇrej bojar, marta r. costa-jussà,christian federmann, mark fishel, yvette gra-ham, barry haddow, matthias huck, philipp koehn,shervin malmasi, christof monz, mathias müller,santanu pal, matt post, and marcos zampieri.
2019.findings of the 2019 conference on machine transla-tion (wmt19).
in proceedings of the fourth con-ference on machine translation (volume 2: sharedtask papers, day 1), pages 1–61, florence, italy.
as-sociation for computational linguistics..toms bergmanis and m¯arcis pinnis.
2021. facilitat-ing terminology translation with target lemma anno-tations.
in proceedings of the 16th conference of theeuropean chapter of the association for computa-tional linguistics: main volume, pages 3105–3111,online.
association for computational linguistics..rajen chatterjee, matteo negri, marco turchi, mar-cello federico, lucia specia, and frédéric blain.
2017. guiding neural machine translation decodingwith external knowledge.
in proceedings of the sec-ond conference on machine translation, pages 157–168, copenhagen, denmark.
association for com-putational linguistics..guanhua chen, yun chen, yong wang, and victor o.k.
li.
2020. lexical-constraint-aware neural machinetranslation via data augmentation.
in proceedings ofthe twenty-ninth international joint conference onartiﬁcial intelligence, ijcai-20, pages 3587–3593.
international joint conferences on artiﬁcial intelli-gence organization.
main track..josep crego, jungi kim, guillaume klein, anabel re-bollo, kathy yang, jean senellart, egor akhanov,patrice brunelle, aurelien coquard, yongchaodeng, satoshi enoue, chiyo geiss, joshua johan-son, ardas khalsa, raoum khiari, byeongil ko,catherine kobus, jean lorieux, leidiana martins,dang-chuan nguyen, alexandra priori, thomasriccardi, natalia segal, christophe servan, cyril ti-quet, bo wang, jin yang, dakun zhang, jing zhou,.
and peter zoldan.
2016. systran’s pure neural ma-chine translation systems..georgiana dinu, prashant mathur, marcello federico,and yaser al-onaizan.
2019. training neural ma-chine translation to apply terminology constraints.
in proceedings of the 57th annual meeting of theassociation for computational linguistics, pages3063–3068, florence, italy.
association for compu-tational linguistics..greg hanneman and georgiana dinu.
2020. howshould markup tags be translated?
in proceedings ofthe fifth conference on machine translation, pages1160–1173, online.
association for computationallinguistics..eva hasler, adrià de gispert, gonzalo iglesias, andbill byrne.
2018. neural machine translation decod-ing with terminology constraints.
in proceedings ofthe 2018 conference of the north american chap-ter of the association for computational linguistics:human language technologies, volume 2 (short pa-pers), pages 506–512, new orleans, louisiana.
as-sociation for computational linguistics..chris hokamp and qun liu.
2017. lexically con-strained decoding for sequence generation using gridin proceedings of the 55th annualbeam search.
meeting of the association for computational lin-guistics (volume 1: long papers), pages 1535–1546,vancouver, canada.
association for computationallinguistics..j. edward hu, huda khayrallah, ryan culkin, patrickxia, tongfei chen, matt post, and benjaminvan durme.
2019.improved lexically constraineddecoding for translation and monolingual rewriting.
in proceedings of the 2019 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long and short papers), pages 839–850,minneapolis, minnesota.
association for computa-tional linguistics..marcin junczys-dowmunt, roman grundkiewicz,tomasz dwojak, hieu hoang, kenneth heaﬁeld,tom neckermann, frank seide, ulrich germann,alham fikri aji, nikolay bogoychev, andré f. t.martins, and alexandra birch.
2018. marian: fastneural machine translation in c++.
in proceedingsof acl 2018, system demonstrations, pages 116–121, melbourne, australia.
association for compu-tational linguistics..tom kocmi, martin popel, and ondrej bojar.
2020.announcing czeng 2.0 parallel corpus with over 2gigawords.
arxiv preprint arxiv:2007.03006..philipp koehn.
2005. europarl: a parallel corpus forstatistical machine translation.
in mt summit, vol-ume 5, pages 79–86.
citeseer..philipp koehn, hieu hoang, alexandra birch, chriscallison-burch, marcello federico, nicola bertoldi,.
4028matt post and david vilar.
2018. fast lexically con-strained decoding with dynamic beam allocation forin proceedings of theneural machine translation.
2018 conference of the north american chapter ofthe association for computational linguistics: hu-man language technologies, volume 1 (long pa-pers), pages 1314–1324, new orleans, louisiana.
association for computational linguistics..rico sennrich, barry haddow, and alexandra birch.
2016. neural machine translation of rare wordswith subword units.
in proceedings of the 54th an-nual meeting of the association for computationallinguistics (volume 1: long papers), pages 1715–1725, berlin, germany.
association for computa-tional linguistics..kai song, yue zhang, heng yu, weihua luo, kunwang, and min zhang.
2019. code-switching forenhancing nmt with pre-speciﬁed translation.
inproceedings of the 2019 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long and short papers), pages 449–459,minneapolis, minnesota.
association for computa-tional linguistics..milan straka and jana straková.
2017. tokenizing,pos tagging, lemmatizing and parsing ud 2.0 withudpipe.
in proceedings of the conll 2017 sharedtask: multilingual parsing from raw text to univer-sal dependencies, pages 88–99, vancouver, canada.
association for computational linguistics..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, undeﬁne-dukasz kaiser, and illia polosukhin.
2017. attentionis all you need.
in proceedings of the 31st interna-tional conference on neural information processingsystems, nips’17, page 6000–6010, red hook, ny,usa.
curran associates inc..vilém zouhar, tereza vojtˇechová, and ondˇrej bojar.
2020. wmt20 document-level markable error ex-ploration.
in proceedings of the fifth conference onmachine translation, pages 371–380, online.
asso-ciation for computational linguistics..brooke cowan, wade shen, christine moran,richard zens, chris dyer, ondˇrej bojar, alexandraconstantin, and evan herbst.
2007. moses: opensource toolkit for statistical machine translation.
inproceedings of the 45th annual meeting of the as-sociation for computational linguistics companionvolume proceedings of the demo and poster ses-sions, pages 177–180, prague, czech republic.
as-sociation for computational linguistics..taku kudo and john richardson.
2018. sentencepiece:a simple and language independent subword tok-enizer and detokenizer for neural text processing.
inproceedings of the 2018 conference on empiricalmethods in natural language processing: systemdemonstrations, pages 66–71, brussels, belgium.
association for computational linguistics..thang luong, ilya sutskever, quoc le, oriol vinyals,and wojciech zaremba.
2015. addressing the rareword problem in neural machine translation.
in pro-ceedings of the 53rd annual meeting of the associ-ation for computational linguistics and the 7th in-ternational joint conference on natural languageprocessing (volume 1: long papers), pages 11–19,beijing, china.
association for computational lin-guistics..franz josef och and hermann ney.
2004. the align-ment template approach to statistical machine trans-lation.
computational linguistics, 30(4):417–449..hideo okuma, hirofumi yamamoto, and eiichirointroducing a translation dictionaryieice - trans.
inf.
syst.,.
sumita.
2008.into phrase-based smt.
e91-d(7):2051–2057..myle ott, sergey edunov, alexei baevski, angelafan, sam gross, nathan ng, david grangier, andfairseq: a fast, extensiblemichael auli.
2019.in proceedings oftoolkit for sequence modeling.
the 2019 conference of the north american chap-ter of the association for computational linguistics(demonstrations), pages 48–53, minneapolis, min-nesota.
association for computational linguistics..martin popel, marketa tomkova,.
jakub tomek,łukasz kaiser, jakob uszkoreit, ondˇrej bojar, andzdenˇek žabokrtský.
2020a.
transforming machinetranslation: a deep learning system reaches newstranslation quality comparable to human profession-als.
nature communications, 11(4381):1–15..martin popel, marketa tomkova,.
jakub tomek,łukasz kaiser, jakob uszkoreit, ondˇrej bojar, andzdenˇek žabokrtský.
2020b.
transforming machinetranslation: a deep learning system reaches newstranslation quality comparable to human profession-als.
nature communications, 11(4381):1–15..matt post.
2018. a call for clarity in reporting bleuscores.
in proceedings of the third conference onmachine translation: research papers, pages 186–191, brussels, belgium.
association for computa-tional linguistics..4029a further analysis.
a.1 constraint placement.
increased bleu and constraint coverage show thatthe evaluated methods are able to generate correctconstraint string in the output.
however, these met-rics do not tell much about placement of constraints.
if all the constraints are appended at the end of theoutput, we would get perfect coverage and, in somecases, possible increase in bleu score – but thisis not a desired behavior of the system..to evaluate the correctness of constraint place-ment, we record starting indices of each satisﬁedconstraint in both mt output and reference, and wecompute pearson’s correlation between these twovariables.
as a sanity check of the correlation mea-sure, we also modify the output of the constrainedsystem and move the constraints it correctly pro-duced to random positions.
both bleu and thepearson correlation drop considerably, see the linemarked with “*” in table 10..the second row shows the case of supplying con-straints as a sufﬁx for the baseline model, whichwas not trained to utilize them.
coverage of theconstraints has increased – but, as expected, themodel only generates some of the constraints at theend of the translation.
lower correlation with thereference placement shows that the placement is in-correct.
in the fourth row, we randomly change po-sitions of the constraints as described above.
again,the correlation decreases.
these experiments indi-cate that the evaluated systems can generate con-straints at correct positions in the output..a.2 lease agreement case study.
our method proved to work well on the europarlterminology test set.
since europarl is included inthe training data (only the actual test sentences areﬁltered out), we used an out-of-domain test docu-ment to assess the results using unknown terminol-ogy.
for this purpose, we used a sublease agree-ment translated from czech into english, which isincluded in wmt20 markables test suite6 (zouharet al., 2020).
there are minor translation errors inthe reference of the test set version used at wmt20,which we ﬁxed.7 the difﬁculty of translating thisagreement accurately lies in the translation of someof the legal terms, e.g.
tenant, lessee, lease or sub-.
modelbaselinebaselinesufﬁxsufﬁx *.
constr.
bleu cvg70.70-76.93sufﬁx95.05sufﬁx95.05sufﬁx.
30.927.635.316.8.pos ρ0.93620.84070.93820.3486.table 10: correlation between start character indicesof the satisﬁed constraints in system’s output and refer-ence.
the table shows that the evaluated methods placeconstraints at the correct positions in the output.
whenwe move the constraints (marked with an asterisk), thecorrelation between the positions drops..lease.
these terms are often used interchangeablyin common language.
in this case, tenant (nájemníkin czech) is a person who has an apartment in alease from the owner and lessee (podnájemník) isa person that is using the apartment based on theagreement with the tenant..we manually created a database of 11 legal termsand their translations used in the document.
notethat we know that the sublease agreement is be-tween two women, so we used feminine forms ofthe translations for lessee and tenant.
table 11 com-pares translations produced by our systems againstexisting approaches on one problematic sentence.
we used following term pairs as our constraints forthis sentence:.
source.
target.
term of the leaselesseetenantapartment in questionsublease agreement.
doba podnájmupodnájemkynˇenájemkynˇepˇredmˇetný bytsmlouva o podnájmubytu.
our three systems are: (1) the model based onsufﬁxed surface form constraints, (2) the samemodel using lemmatized constraints, and (3) thetwo-factored model using surface form factors asdescribed in appendix b.5.
they are comparedwith the outputs of cubbitt8, the state-of-the-artenglish-czech system by popel et al.
(2020b), andtwo commercial translation engines (google trans-late9 and lingea translator10).
constraint termstypeset in green are translated correctly accordingto the terminology, orange terms are very similar.
6https://github.com/elitr/.
wmt20-elitr-testsuite/.
7we will provide the link to the ﬁxed test set in the camera-.
ready version..8https://lindat.mff.cuni.cz/services/.
translation/.
9https://translate.google.com/10https://translator.lingea.com/.
4030model.
source.
translationin art.
iii of the sublease agreement1, entitled “ term of the lease2 ,” the tenant3, and the lessee4agreed that the apartment in question5 would be rented to the lessee6 for a ﬁxed period from 13thmay 2016 to 31st december 2018..google translate.
v ˇcl.
iii smlouvy o podnájmu1 s názvem „doba nájmu“2 se nájemce3 a nájemce4 dohodli, žepˇredmˇetný byt5 bude nájemci6 pronajat na dobu urˇcitou od 13. kvˇetna 2016 do 31. prosince 2018..lingea translator.
v ˇcl.
iii podnájemní smlouvy1, nadepsané „lh ˚uta nájmu2 ,„ se nájemce3 a nájemce4 dohodli, žedotˇcený byt5 bude nájemci6 pronajat na dobu urˇcitou od 13. kvˇetna 2016 do 31. prosince 2018..cubbitt.
v umˇení.
iii podnájemní smlouvy1 nazvané „ podmínky pronájmu2 “ se nájemce3 a nájemce4dohodli, že pˇredmˇetný byt5 bude nájemci6 pronajímán na dobu urˇcitou od 13. kvˇetna 2016 do 31.prosince 2018.sufﬁx surface form v ˇcl.
iii podnájemní smlouva o podnájmu1, nadepsaném „ lh ˚uta nájmu2“, se nájemkynˇe3 apodnájemkynˇe4 dohodly, že pˇredmˇetný byt5 bude nájemci6 pronajat na dobu urˇcitou od 13. kvˇetna2016 do 31. prosince 2018..sufﬁx lemmatized.
v ˇclánku iii smlouvy o podnájmu1, nazvaném „doba podnájmu2 ,“ se nájemkynˇe3 apodnájemkynˇe dohodli4, že pˇredmˇetný byt5 bude nájemci6 pronajat na dobu urˇcitou od 13. kvˇetna2016 do 31. prosince 2018..factored sf.
ref.
iii.
v ˇcl.
apodnájemkynˇe4souhlasily s tím, že pˇredmˇetný byt5 bude pronajat podnájemkyni6 na dobuurˇcitou od 13. kvˇetna 2016 do 31. prosince 2018..smlouvy o podnájmu bytu1,.
nadepsaný „podnájmu2.
,“ nájemkynˇe3.
iii smlouvy o podnájmu1 bytu, nazvaném „doba podnájmu2“, se nájemkynˇe3 av ˇcl.
podnájemkynˇe4 dohodly, že pˇredmˇetný byt5 bude podnájemkyni6 pˇrenechán k užívání na dobuurˇcitou od 13.
5.
2016 do 31.
12.
2018..table 11: translations of one of the difﬁcult sentences from wmt20 elitr test set..in meaning to the terminology database transla-tion, and red ones are clear translation errors.
wenote that especially the word podnájemkynˇe (lesseein feminine form) poses some difﬁculties for themodel to produce, since it does not appear in thetraining data.
its masculine forms, podnájemce orpodnájemník appear 182 times in different inﬂec-tions..another difﬁculty is added by the fact that theword lessee appears two times in the sentence.
allof the systems produce the correct constrainedtranslation at most for the ﬁrst occurrence, withexception of factored model, which is supplied ex-plicit alignment between source and target part ofthe constraints.
we hypothesize that other mod-els consider the constraint as covered after it isgenerated for the ﬁrst time..overall, the constrained models provide more ac-curate translations compared to the unconstrainedsota models, effectively integrating the con-straints even in a difﬁcult out-of-domain example..b other related experiments.
we present experiments that inﬂuenced our archi-tectural choices in the paper, but are not discussedin the main text.
note that the results are not di-.
rectly comparable, since a slightly different prepro-cessing was used..b.1 constraints as preﬁx or sufﬁx.
in table 12, we compare passing the constraintsas a preﬁx of the source sentence, as a sufﬁx andas a sufﬁx with all positional embeddings of theconstraint part starting with 1024. using preﬁxresulted in the best coverage, but, as visible in col-umn pos ρ, correlation of constraint positions islower than for other models.
upon manual in-spection, we saw that the constraints were in somecases generated also as a preﬁx of the target sen-tence.
for the main experiments, we decided touse sufﬁx integration with positional embeddingshifting, since it provided slightly better coveragethan the basic sufﬁx variant..b.2 wiktionary vs. proprietary dictionary.
dictionary is necessary for one of the training meth-ods we explore.
for our main results, we used aproprietary dictionary, which provides better cover-age of the possible term pairs, but harms the repro-ducibility of this part of our experiments.
thus, wealso evaluated our method using wiktionary11 to.
11https://www.wiktionary.org/.
4031train const..integration bleu cvg.
baselinerandomrandomrandom, shift.
-preﬁxsufﬁxsufﬁx+shift.
30.934.734.934.9.
70.5196.1593.0293.12.bleul cvgl77.4695.5192.9993.25.
37.039.440.040.1.pos ρ.
0.93220.84680.93360.9349.table 12: comparison of integrating the constraints as a preﬁx, sufﬁx and sufﬁx with positional embedding shifting.
note the results are not directly comparable to main paper results, as the train and test set preprocessing is different..wordsfactor.
price0.increase0.is0.plannedsrc.
plánováno mainly.
larger municipalities.
tgt.
0.
0.src.
in0.obcíchtgt.
.
0.table 13: example of the constrained translation process using factors..train c..test c. bleu cvg cvgl.
training dict.
test dict.
bleu cvg.
-.
sf.
lemma.
mixed.
--canon.
ref sflemma-canon.
ref sflemma-canon.
ref sflemma.
38.238.836.640.635.138.638.939.138.937.737.53938.
69.9070.2744.096.9730.8869.8777.181.4477.2269.3769.6891.6576.57.
84.3785.096.5695.0896.7484.0595.4494.1595.5583.5195.0894.7295.25.table 14: performance of the model mixing half ofthe training examples with surface form constraints andhalf of them lemmatized on the whole europarl test set.
compared with the models, where either lemmatizationwas never applied on constraints during training (sf),or it was applied on all data examples (lemma)..obtain constraints in the same way as described inthe main experiments section (see section 4).
wepresent the results in table 15..looking up term pairs from the commercial dic-tionary in the test set, we found 7201 term pairsthat were used as a constraint.
on the other hand,we found only 2529 term pairs using wiktionary.
we see that both models are able to incorporate con-straints from the dictionary used during the trainingwith similar success – about 94% of the constraintsare covered.
however, large dictionary providesbetter bleu scores, since more constraint pairs arefound overall in the test set..b.3 mixed lemma and surface form training.
as we noticed in section 4, lemmatized mod-els have lower surface form coverage than non-lemmatized models when supplied with constraintsin the reference surface form.
as we show inour manual analysis, this is mostly an issue of.
--wikiwikilargelarge.
wikilargewikilargewikilarge.
29.229.230.129.624.634.3.
79.569.293.781.891.794.3.table 15: comparison between using large, commer-cial dictionary (large) as opposed to wiktionary (wiki)to obtain both training and test constrains.
the resultsare computed on the oracle newstest-2020 test set, see4.2 for details..automated evaluation based on comparison withreference, as the constraints are produced in cor-rect form given the context of the output sentenceproduced by the model.
nevertheless, we experi-mented with a way to improve results of this auto-matic evaluation..we trained another batch of models with 50% ofthe constraints lemmatized and 50% left in the sur-face forms.
table 14 shows that this type of train-ing improves integration of reference surface formconstraints over the training where all constraintsare lemmatized, while performance on lemmatizedconstraints does not decrease by a large margin..b.4 stemmingin table 17, we compare stemming12 and lemmati-zation as the contraint preprocessing methods.
themodels in the table are trained with sufﬁx con-straints.
the results are very similar, with stem-ming obtaining better results in terms of surfaceform coverage whereas lemmatization is better inlemma coverage.
since in section 5 we haveshown that the difference between surface andlemma coverage for lemmatized model is caused.
12https://research.variancia.com/czech_.
stemmer/.
4032train const..integration const.
form bleu cvg.
baselinerandomdictdict.
-sufﬁxsufﬁxfactors.
-surfacesurfacesurface.
30.935.337.737.5.
70.7095.0593.4695.72.bleul cvgel77.7394.6793.2395.11.
37.140.442.242.0.table 16: comparison of constraint integration methods on the oracle test set.
all the models were trained onnon-lemmatized, surface form constraints.
train prep.
test prep..bleu cvg.
pos ρ.baselinelemmalemmastemmingstemming.
no constraintsno constraintslemmano constraintsstemming.
3231.833.331.333.2.
68.8469.7682.1569.5184.10.bleul cvgl78.1479.0193.4278.4892.86.
38.237.939.637.439.5.
0.94040.93670.93410.93380.9235.table 17: comparison of stemming and lematization as a preprocessing for training and test constraints..model.
for example, function esub produces anembedding of an input subword and function efproduces an embedding of its label.
final embed-ding of the word planned in the above example iscomputed by the following formula:.
e(plannedsrc) = esub(planned) + ef (src).
table 16 shows the comparison with the otherintegration methods on the oracle test set, similarto section 4.2. we see factors provide the bestcoverage of the constraints.
the factored approachmakes use of alignment between source and target.
this additional information probably helps withgenerating the correct constraints, but also com-plicates the preprocessing.
since the differencesare only minor and the goal of our paper is not toreach state-of-the-art results in constrained trans-lation, we opted for the sufﬁx-based approachesfor simplicity.
nevertheless, we note that factoredapproach is promising and we plan further researchin this direction..by the automatic reference-based evaluation andnot by real errors in the translation, we opted forlemmatization in the paper..b.5 constraint integration using factors.
we also present preliminary experiments with thefactored model for constraining inspired by dinuet al.
(2019).
we use a two-factor model, wherethe ﬁrst factor comprises of the input sequenceof words.
for each source constraint in the inputsequence, the translation tokens are inserted im-mediately after.
in the second factor, one of thefollowing three label values is assigned to a corre-sponding input token:.
• 0: ordinary source token without constraint.
• src: source side of a constraint.
• tgt: translation of the constraint.
for instance, consider the example in table 13.each word in the ﬁrst factor has an associated la-bel in the second factor according to its role inthe translation.
the words plánováno and obcíchare czech constraints that must appear in the trans-lation of the english sentence.
as a part of thetarget constraint, both words are labeled with thevalue tgt in the second factor.
the words plannedand municipalities are english words representingthe source part of the constraints, thus receivingthe value src.
words that are not constrained arelabeled by 0 in the second factor..the values of the second factor are copied overall subwords of the constraint sequence.
embed-dings of the values in both factors have the samedimensionality demb and they are summed to ob-tain a complete embedding, which is used by the.
4033