mpc-bert: a pre-trained language model for multi-partyconversation understanding.
jia-chen gu1∗, chongyang tao2, zhen-hua ling1, can xu2, xiubo geng2, daxin jiang2†1national engineering laboratory for speech and language information processing,university of science and technology of china, hefei, china2microsoft, beijing, chinagujc@mail.ustc.edu.cn, zhling@ustc.edu.cn,{chotao,caxu,xigeng,djiang}@microsoft.com.
abstract.
speaker.
addressee.
and.
these.
response.
existing methods.
recently, various neural models for multi-party conversation (mpc) have achievedimpressive improvements on a variety oftasks such as addressee recognition, speakerprediction.
identiﬁcationhowever,oninterlocutors andmpc usually representutterancestheignoreandindividuallyinherent complicated structure in mpc whichmay provide crucial interlocutor and utterancesemantics and would enhance the conversationunderstanding process.
to this end, we presentmpc-bert, a pre-trained model for mpcunderstanding that considers learning whosays what to whom in a uniﬁed model withtasks.
self-supervisedseveralthese tasks can be generallyparticularly,interlocutor structurecategorized into (1)utterancemodelingincludingsearchingidenticalrecognition,and pointer consistency distinction,and(2) utterance semantics modeling includingmasked shared utterance restoration andshared node detection.
we evaluate mpc-bert on three downstream tasks includingaddressee recognition, speaker identiﬁcationand response selection.
experimental resultsshow that mpc-bert outperforms previousmethods by large margins and achieves newstate-of-the-art performance on allthreedownstream tasks at two benchmarks..reply-tospeaker.
elaborated.
1.introduction.
building a conversational agent with intelligencehas drawn signiﬁcant attention from both academiaand industry.
most of existing methods havestudied understanding conversations between twoparticipants, aiming to return an appropriate re-sponse either in a generation-based (shang et al.,.
∗work done during the internship at microsoft.
†corresponding author..utterancehow can i setup if i want add newserver at xchat?
from places, network servers, workgroup, his computer, and then iclicked on the shared folder.
it did not allow you to see the ﬁles?
it prompts for authentication and idon’t know what to put.
i tried guestwith no password.
put proper authentication in, then?
i think you had kde on suse?.
i.1.
i.2.
i.3.
i.2.
i.4i.3.
-.
i.1.
i.2.
i.3.
i.2i.2.
table 1: an mpc example in ubuntu irc channel.
here, “i.” is the abbreviation of “interlocutor”..2015; serban et al., 2016, 2017; zhang et al.,2018b, 2020) or retrieval-based manner (loweet al., 2015; wu et al., 2017; zhou et al., 2018; taoet al., 2019a,b; gu et al., 2019a,b, 2020).
recently,researchers have paid more attention to a morepractical and challenging scenario involving morethan two participants, which is well known as multi-party conversation (mpc) (ouchi and tsuboi,2016; zhang et al., 2018a; le et al., 2019; hu et al.,2019).
table 1 shows an mpc example in theubuntu internet relay chat (irc) channel, whichis composed of a sequence of (speaker, utterance,addressee) triples.
in addition to returning anappropriate response, predicting who will be thenext speaker (meng et al., 2018) and who is theaddressee of an utterance (ouchi and tsuboi, 2016;zhang et al., 2018a; le et al., 2019) are unique andimportant issues in mpc..an instance of mpc always contains compli-cated interactions between interlocutors, betweenutterances and between an interlocutor and anutterance.
therefore, it is challenging to modelthe conversation ﬂow and fully understand thedialogue content.
existing studies on mpc learnthe representations of interlocutors and utteranceswith neural networks, and their representation.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3682–3692august1–6,2021.©2021associationforcomputationallinguistics3682spaces are either separate (ouchi and tsuboi, 2016)or interactive (zhang et al., 2018a).
however,the semantics contained in the interlocutor andutterance representations may not be effectivelycaptured as they are from two different represen-tation spaces.
recently, to take advantage ofthe breakthrough in pre-training language mod-els (plms) for natural language understanding,some studies proposed to integrate the speaker(gu et al., 2020) or topic (wang et al., 2020)information into plms.
despite of the performanceimprovement on response selection, these modelsstill overlook the inherent relationships betweenutterances and interlocutors, such as “address-to”.
furthermore, most existing studies design modelsfor each individual task in mpc (e.g., addresseerecognition, speaker identiﬁcation and responseprediction) separately.
intuitively, these tasks arecomplementary among each other.
making useof these tasks simultaneously may produce bettercontextualized representations of interlocutors andutterances, and would enhance the conversationunderstanding, but is neglected in previous studies..on account of above issues, we propose mpc-bert which jointly learns who says what to whomin mpc by designing self-supervised tasks forplms, so as to improve the ability of plms onmpc understanding.
speciﬁcally, the ﬁve designedtasks includes reply-to utterance recognition, iden-tical speaker searching, pointer consistency dis-tinction, masked shared utterance restoration andshared node detection.
the ﬁrst three tasks aredesigned to model the interlocutor structure inmpc in a semantics-to-structure manner.
in theoutput of mpc-bert, an interlocutor is describedthrough the encoded representations of the ut-terances it says.
thus, the representations ofutterance semantics are utilized to construct theconversation structure in these three tasks.
on theother hand, the last two tasks are designed to modelthe utterance semantics in a structure-to-semanticsmanner.
intuitively, the conversation structureinﬂuences the information ﬂow in mpc.
thus, thestructure information can also be used to strengthenthe representations of utterance semantics in return.
in general, these ﬁve self-supervised tasks areemployed to jointly train the mpc-bert in amulti-task learning framework, which helps themodel to learn the complementary informationamong interlocutors and utterances, and that be-tween structure and semantics.
by this means,.
mpc-bert can produce better interlocutor andutterance representations which can be effectivelygeneralized to multiple downstream tasks of mpc.
to measure the effectiveness of these self-supervised tasks and to test the generalizationability of mpc-bert, we evaluate it on threedownstream tasks including addressee recognition,speaker identiﬁcation and response selection,which are three core research issues of mpc.
twobenchmarks based on ubuntu irc channel areemployed for evaluation.
one was released by huet al.
(2019).
the other was released by ouchiand tsuboi (2016) and has three experimentalsettings according to session lengths.
experimentalresults show that mpc-bert outperforms thecurrent state-of-the-art models by margins of3.51%, 2.86%, 3.28% and 5.36% on the test setsof these two benchmarks respectively in termsof the session accuracy of addressee recognition,by margins of 7.66%, 2.60%, 3.38% and 4.24%respectively in terms of the utterance precision ofspeaker identiﬁcation, and by margins of 3.82%,2.71%, 2.55% and 3.22% respectively in terms ofthe response recall of response selection..in summary, our contributions in this paperare three-fold: (1) mpc-bert, a plm for mpcunderstanding, is proposed by designing ﬁve self-supervised tasks based on the interactions amongutterances and interlocutors.
(2) three downstreamtasks are employed to comprehensively evaluate theeffectiveness of our designed self-supervised tasksand the generalization ability of mpc-bert.
(3)our proposed mpc-bert achieves new state-of-the-art performance on all three downstream tasksat two benchmarks..2 related work.
existing methods on building dialogue systemscan be generally categorized into studying two-party conversations and multi-party conversations(mpc).
in this paper, we study mpc.
in addition topredicting utterances, identifying the speaker andrecognizing the addressee of an utterance are alsoimportant tasks for mpc.
ouchi and tsuboi (2016)ﬁrst proposed the task of addressee and responseselection and created an mpc corpus for studyingthis task.
zhang et al.
(2018a) proposed si-rnn,which updated speaker embeddings role-sensitivelyfor addressee and response selection.
meng et al.
(2018) proposed a task of speaker classiﬁcation asa surrogate task for speaker modeling.
le et al..3683(2019) proposed a who-to-whom (w2w) modelto recognize the addressees of all utterances.
huet al.
(2019) proposed a graph-structured network(gsn) to model the graphical information ﬂow forresponse generation.
wang et al.
(2020) proposedto track the dynamic topic for response selection.
generally speaking, previous studies on mpccannot unify the representations of interlocutorsand utterances effectively.
also, they are limited toeach individual task, ignoring the complementaryinformation among different tasks.
to the bestof our knowledge,this paper makes the ﬁrstattempt to design various self-supervised tasks forbuilding plms aiming at mpc understanding, andto evaluate the performance of plms on threedownstream tasks as comprehensively as possible..3 mpc-bert and self-supervised tasks.
an mpc instance is composed of a sequence of(speaker, utterance, addressee) triples, denotedas {(sn, un, an)}nn=1, where n is the number ofturns in the conversation.
our goal is to builda pre-trained language model for universal mpcunderstanding.
given a conversation, this modelis expected to produce embedding vectors for allutterances which contain not only the semanticinformation of each utterance, but also the speakerand addressee structure of the whole conversation.
thus, it can be effectively adapted to variousdownstream tasks by ﬁne-tuning model parameters..3.1 model overview.
in this paper, bert (devlin et al., 2019) is chosenas the backbone of our plm for mpc.
thus, wename it mpc-bert.
it is worth noting that ourproposed self-supervised tasks for training mpc-bert can also be applied to other types of plms.
we ﬁrst give an overview of the input represen-tations and the overall architectures of mpc-bert.
when constructing the input representations, inorder to consider the speaker information of eachutterance, speaker embeddings (gu et al., 2020)are introduced as shown in figure 1. consideringthat the set of interlocutors are inconsistent in dif-ferent conversations, a position-based interlocutorembedding table is initialized randomly at ﬁrst andupdated during pre-training, which means eachinterlocutor in a conversation is assigned withan embedding vector according to the order itappears in the conversation.
then, the speakerembeddings for each utterance can be derived by.
looking up this embedding table.
the speakerembeddings are combined with standard token,position and segmentation embeddings and arethen encoded by bert.
the output embeddingsof bert corresponding to different input tokensare utilized by different self-supervised tasks forfurther calculation..3.2 tasks of interlocutor structure modeling.
three tasks follow the semantics-to-the ﬁrststructure manner.
in mpc-bert, each interlocutoris described through the encoded representationsof the utterances it says.
thus, the representationsof utterance semantics are utilized to constructthe conversation structure.
figure 1 shows theinput representations and the model architecturesof these three tasks.
a [cls] token is inserted atthe start of each utterance, denoting its utterance-level representation.
then, all utterances in aconversation are concatenated and a [sep] tokenis inserted at the end of the whole sequence.
it isnotable that these three tasks share the same formof input data.
thus, the input only needs to beencoded once by bert while the output can befed into three tasks, which is computation-efﬁcient.
as shown in figure 1, a task-dependent non-lineartransformation layer is placed on top of bertin order to adapt the output of bert to differenttasks.
we will describe the details of these tasks asfollows..3.2.1 reply-to utterance recognition.
to enable the model to recognize the addressee ofeach utterance, a self-supervised task named reply-to utterance recognition (rur) is proposed to learnwhich preceding utterance the current utterancereplies to.
after encoded by bert, we extractthe contextualized representations for each [cls]token representing individual utterances.
next,a non-linear transformation followed by a layernormalization are performed to derive the utterancerepresentations for this speciﬁc task {ururi=1,∈ rd and d = 768. then, for awhere ururspeciﬁc utterance ui, its matching scores with allits preceding utterances are calculated as.
i }n.i.mij = softmax(urur(cid:62).
i.
· arur · urur.
),.
j.
(1).
where arur ∈ rd×d is a linear transformation, mijdenotes the matching degree of uj being the reply-to utterance of ui, and 1 ≤ j < i. we construct aset s by sampling a certain number of utterances.
3684figure 1: input representations and model architectures of the three self-supervised tasks for interlocutor structuremodeling, including (a) reply-to utterance recognition, (b) identical speaker searching and (c) pointer consistencydistinction..in a conversation and this recognition operationis performed for each utterance in s. meanwhile,a dynamic sampling strategy is adopted so thatmodels can see more samples.
finally, the pre-training objective of this self-supervised task is tominimize the cross-entropy loss as.
lrur = −.
yij log(mij),.
(2).
(cid:88).
i−1(cid:88).
i∈s.
j=1.
where yij = 1 if uj is the reply-to utterance of uiand yij = 0 otherwise..identical speaker searching.
3.2.2having knowledge of who is the speaker of anutterance is also important for mpc.
the taskof identical speaker searching (iss) is designedby masking the speaker embedding of a speciﬁcutterance in the input representation, and aims topredict its speaker given the conversation.
sincethe set of interlocutors vary across conversations,the task of predicting the speaker of an utteranceis reformulated as searching for the utterancessharing the identical speaker..first, for a speciﬁc utterance, its speaker embed-ding is masked with a special [mask] interlocutorembedding to avoid information leakage.
giventhe utterance representations for this speciﬁc taski ∈ rd, the matching scores of{uissui with all its preceding utterances are calculatedsimilarly with eq.
(1).
here, mij denotes the.
i=1 where uiss.
i }n.matching degree of uj sharing the same speakerwith ui.
for each instance in the dynamic samplingset s, there must be an utterance in previous turnssharing the same speaker.
otherwise, it is removedout of the set.
finally, the pre-training objectiveof this task is to minimize the cross-entropy losssimilarly with eq.
(2).
here, yij = 1 if uj sharesthe same speaker with ui and yij = 0 otherwise..3.2.3 pointer consistency distinctionwe design a task named pointer consistency dis-tinction (pcd) to jointly model speakers andaddressees in mpc.
in this task, a pair of utterancesrepresenting the “reply-to” relationship is deﬁnedas a speaker-to-addressee pointer.
here, weassume that the representations of two pointersdirecting from the same speaker to the sameaddressee should be consistent.
as illustrated infigure 2 (a), speaker sm speaks ui and uj whichreply to ui(cid:48) and uj(cid:48) from speaker sn respectively.
thus, the utterance tuples (ui, ui(cid:48)) and (uj, uj(cid:48))both represent the pointer of sm-to-sn and theirpointer representations should be consistent...i }n.given the utterance representations for thisspeciﬁc task {upcdi=1 where upcdi ∈ rd, we ﬁrstcapture the pointer information contained in eachutterance tuple.
the element-wise difference andmultiplication between an utterance tuple (ui, ui(cid:48))are computed and are concatenated as.
pii(cid:48) = [upcd.
i − upcdi(cid:48).
; upcd.
i (cid:12) upcdi(cid:48).
],.
(3).
3685ui’uiun[sep]inputtokenembeddingssegmentembeddingspositionembeddingsspeakerembeddings........................pre-trained language model (bert)e[cls]eu_i’e[cls]eu_ie[cls]eu_ne[sep]output......[cls][cls][cls](a) reply-to utterance recognitionnon-linear transformation+ layer normalizationui'ruruirurunrur......mij..................uj’uj...[cls][cls].....................e[cls]eu_j’e[cls]eu_j......uj'rurujrur......(b) identical speaker searchingnon-linear transformation+ layer normalizationui'issuiissuniss.........uj'issujiss......(c) pointer consistency distinctionnon-linear transformation+ layer normalizationui'pcduipcdunpcd.........uj'pcdujpcd......pointer pointer similarityclassifier...¯pii(cid:48) = relu(pii(cid:48) · wpcd + bpcd),.
(4).
lmsur = −.
log pui,t,.
(8).
1li.
li(cid:88).
t=1.
(a) pointer consistency dis-tinction.
(b) shared node detection.
figure 2: illustrations of the self-supervised tasks of(a) pointer consistency distinction and (b) shared nodedetection.
rectangles denote utterances, circles denoteinterlocutors, a solid line denotes an utterance replyingto an utterance, and a dashed line denotes an utterancefrom an interlocutor..where pii(cid:48) ∈ r2d.
then, we compress pii(cid:48) andobtain the pointer representation ¯pii(cid:48) as.
where wpcd ∈ r2d×d and bpcd ∈ rd are param-eters.
identically, a consistent pointer representa-tions ¯pjj(cid:48) and an inconsistent one ¯pkk(cid:48) sampledfrom this conversation are obtained.
the similari-ties between every two pointers are calculated as.
mij = sigmoid(¯p(cid:62).
ii(cid:48) · apcd · ¯pjj(cid:48)),.
(5).
where mij denotes the matching degree of pointer¯pii(cid:48) being consistent with pointer ¯pjj(cid:48).
mik canbe derived accordingly.
finally, the pre-trainingobjective of this task is to minimize the hinge losswhich enforces mij to be larger than mik by at leasta margin ∆ as.
lpcd = max{0, ∆ − mij + mik}..(6).
3.3 tasks of utterance semantics modeling.
intuitively, the conversation structure might inﬂu-ence the information ﬂow, so that it can be used tostrengthen the representations of utterance seman-tics.
thus, two self-supervised tasks following thestructure-to-semantics manner are designed..3.3.1 masked shared utterance restorationthere are usually several utterances replying-toa shared utterance in mpc.
intuitively, a sharedutterance is semantically relevant to more utter-ances in the context than non-shared ones.
basedon this characteristic, we design a task namedmasked shared utterance restoration (msur).
weﬁrst randomly sample an utterance from all sharedutterances in a conversation and all tokens in thissampled utterance are masked with a [mask].
token.
then the model is enforced to restore themasked utterance given the rest conversation..formally, assuming ui as the masked shared ut-terance and li as the number of tokens in ui.
giventhe token representations for this task {umsurwhere umsureach masked token can be calculated as.
}lit=1∈ rd, the probability distribution of.
i,t.
i,t.
pui,t = softmax(umsur.
i,t.
· wmsur + bmsur),.
(7).
where wmsur ∈ rd×v is the token embeddingtable, v denotes the vocabulary size, and bmsur ∈rv is a bias vector.
finally, the pre-trainingobjective of this self-supervised task is to minimizethe negative log-likelihood loss as.
where pui,t is the element in pui,t corresponding tothe original token..3.3.2 shared node detection.
a full mpc instance can be divided into severalsub-conversations and we assume that the repre-sentations of sub-conversations under the sameparent node tend to be similar.
as illustrated infigure 2 (b), two sub-conversations {u3, u5, u7,u8} and {u4, u6, u9} share the same parent nodeu2.
thus, they should be semantically relevant.
under this assumption, we design a self-supervisedtask named shared node detection (snd), whichutilizes the conversation structure to strengthen thecapability of models on measuring the semanticrelevance of two sub-conversations..we ﬁrst construct the pre-training samples forthis task.
empirically, only the sub-conversationsunder the top shared node in a conversation arecollected in order to ﬁlter out the sub-conversationswith few utterances.
given a full mpc, the twosub-conversations with the most utterances forma positive pair.
for each positive pair, we replaceone of its elements with another sub-conversationrandomly sampled from the training corpus to forma negative pair..formally, given two sub-conversations ci andcj, utterances in each sub-conversation are ﬁrstconcatenated respectively to form two segments.
then, the two segments are concatenated with a[sep] token and a [cls] token is inserted at thebeginning of the whole sequence.
this sequenceare encoded by bert to derive the contextualized.
3686ui ui...uj ujsnsm......: speaker: utterance: utterance-to-utterance: speaker-to-utteranceu1u2u3u5u8u4u6u7u9l = lrur + liss + lpcd + lmsur+ lsnd + lmlm + lnsp..(10).
4.3 response selection.
representation for the [cls] token.
a non-lineartransformation with sigmoid activation is furtherapplied to this representation for calculating thematching score mij, i.e., the probability of ci andcj sharing the same parent node.
finally, the pre-training objective of this task is to minimize thecross-entropy loss as.
lsnd = −[yijlog(mij) + (1 − yij)log(1 − mij)],(9)where yij = 1 if ci and cj share the same parentnode and yij = 0 otherwise..3.4 multi-task learning.
in addition, we also adopt the tasks of maskedlanguage model (mlm) and next sentence predic-tion (nsp) in original bert pre-training (devlinet al., 2019), which have been proven effectivefor incorporating domain knowledge (gu et al.,2020; gururangan et al., 2020).
finally, mpc-bert is trained by performing multi-task learningthat minimizes the sum of all loss functions as.
4 downstream tasks.
4.1 addressee recognition.
given a multi-party conversation where part of theaddressees are unknown, ouchi and tsuboi (2016)and zhang et al.
(2018a) recognized an addresseeof the last utterance.
le et al.
(2019) recognizedaddressees of all utterances in a conversation.
inthis paper, we follow the more challenging settingin le et al.
(2019)..n=1\{an}n.formally, models are asked to predict {ˆan}n.n=1given {(sn, un, an)}nn=1, where ˆan isselected from the interlocutor set in this conver-sation and \ denotes exclusion.
when applyingmpc-bert, this task is reformulated as ﬁndinga preceding utterance from the same addressee.
its rur matching scores with all preceding ut-terances are calculated following eq.
(1).
then, theutterance with the highest score is selected and thespeaker of the selected utterance is considered asthe recognized addressee.
finally, the ﬁne-tuningobjective of this task is to minimize the cross-entropy loss as.
lar = −.
yij log(mij),.
(11).
n(cid:88).
i−1(cid:88).
i=2.
j=1.
where mij is deﬁned in eq.
(1), yij = 1 if thespeaker of uj is the addressee of ui and yij = 0otherwise..4.2 speaker identiﬁcation.
this task aims to identify the speaker of the lastutterance in a conversation.
formally, models areasked to predict ˆsn given {(sn, un, an)}nn=1\sn ,where ˆsn is selected from the interlocutor set inthis conversation.
when applying mpc-bert, thistask is reformulated as identifying the utterancessharing the same speaker.
for the last utteranceun , its speaker embedding is masked and its issmatching scores mn j with all preceding utterancesare calculated following section 3.2.2. the ﬁne-tuning objective of this task is to minimize thecross-entropy loss as.
lsi = −.
yn j log(mn j),.
(12).
n −1(cid:88).
j=1.
where yn j = 1 if uj shares the same speaker withun and yn j = 0 otherwise..this task asks models to select ˆun from a set ofresponse candidates given the conversation context{(sn, un, an)}nn=1\un .
the key is to measure thesimilarity between two segments of context andresponse.
we concatenate each response candidatewith the context and extract the contextualizedrepresentation e[cls] for the ﬁrst [cls] tokenusing mpc-bert.
then, e[cls] is fed into a non-linear transformation with sigmoid activation toobtain the matching score between the context andthe response.
finally, the ﬁne-tuning objectiveof this task is to minimize the cross-entropy lossaccording to the true/false labels of responses inthe training set as.
lrs = −[ylog(mcr)+(1−y)log(1−mcr)], (13).
where y = 1 if the response r is a proper one forthe context c; otherwise y = 0..5 experiments.
5.1 datasets.
we evaluated our proposed methods on two ubuntuirc benchmarks.
one was released by hu et al.
in which both speaker and addressee(2019),labels was provided for each utterance.
the otherbenchmark was released by ouchi and tsuboi.
3687datasetshu et al.
(2019).
ouchi and tsuboi (2016).
train.
testvalid5,000311,725 5,000len-5 461,120 28,570 32,668len-10 495,226 30,974 35,638len-15 489,812 30,815 35,385.table 2: statistics of the two benchmarks evaluated inthis paper..(2016).
here, we adopted the version sharedin le et al.
(2019) for fair comparison.
theconversation sessions were separated into threecategories according to the session length (len-5, len-10 and len-15) following the splittingstrategy of previous studies (ouchi and tsuboi,2016; zhang et al., 2018a; le et al., 2019).
table 2presents the statistics of the two benchmarksevaluated in our experiments..5.2 baseline models.
non-pre-training-based models ouchiandtsuboi(2016) proposed a dynamic modeldrnn which updated speaker embeddings withthe conversation ﬂow.
zhang et al.
(2018a)improved drnn to si-rnn which updatedspeaker embeddings role-sensitively.
le et al.
(2019) proposed w2w which jointly modeledin a uniforminterlocutorsframework, and predicted all addressees..and utterances.
pre-training-based models bert (devlin et al.,2019) was pre-trained to learn general languagerepresentations with mlm and nsp tasks.
sa-bert (gu et al., 2020) added speaker embeddingsand further pre-trained bert on a domain-speciﬁccorpus to incorporate domain knowledge.
were-implemented sa-bert with the pre-trainingcorpus used in this paper to ensure fair comparison..5.3.implementation details.
the version of bert-base-uncased was adoptedfor all our experiments.
for pre-training, gelu(hendrycks and gimpel, 2016) was employed asthe activation for all non-linear transformations.
the adam method (kingma and ba, 2015) wasemployed for optimization.
the learning rate wasinitialized as 0.00005 and the warmup proportionwas set to 0.1. we pre-trained bert for 10epochs.
the training set of the dateset used inhu et al.
(2019) was employed for pre-training.
the maximum utterance number was set to 7. themaximum sequence length was set to 230. themaximum sampling numbers for each example.
were set to 4 for rur, 2 for iss and 2 for pcd.
∆ in eq.
(6) was set to 0.4, achieving the bestperformance out of {0.2, 0.4, 0.6, 0.8} on thevalidation set.
the pre-training was performedusing a geforce rtx 2080 ti gpu and the batchsize was set to 4..for ﬁne-tuning, some conﬁgurations were dif-ferent according to the characteristics of thesedatasets.
for hu et al.
(2019), the maximumutterance number was set to 7 and the maximumsequence length was set to 230. for the threeexperimental settings in ouchi and tsuboi (2016),the maximum utterance numbers were set to 5, 10and 15, and the maximum sequence lengths wereset to 120, 220 and 320. all parameters in plmswere updated.
the learning rate was initialized as0.00002 and the warmup proportion was set to 0.1.for hu et al.
(2019), the ﬁne-tuning process wasperformed for 10 epochs for addressee recognition,10 epochs for speaker identiﬁcation, and 5 epochsfor response selection.
for ouchi and tsuboi(2016), the ﬁne-tuning epochs were set to 5, 5 and3 respectively.
the ﬁne-tuning was also performedusing a geforce rtx 2080 ti gpu.
the batchsizes were set to 16 for hu et al.
(2019), and 40, 20,and 12 for the three experimental settings in ouchiand tsuboi (2016) respectively.
the validation setwas used to select the best model for testing..all codes were implemented in the tensorflowframework (abadi et al., 2016) and are publishedto help replicate our results.
1.
5.4 metrics and results.
addressee recognition we followed the metricsof previous work (le et al., 2019) by employingprecision@1 (p@1) to evaluate each utterance withground truth.
also, a session is marked as positiveif the addressees of all its utterances are correctlyrecognized, which is calculated as accuracy (acc.).
table 3 presents the results of addressee recog-nition.
it shows that mpc-bert outperformsthe best performing model, i.e., sa-bert, bymargins of 3.51%, 2.86%, 3.28% and 5.36%on these test sets respectively in terms of acc.,verifying the effectiveness of the proposed ﬁve self-supervised tasks as a whole.
to further illustratethe effectiveness of each task, ablation tests wereperformed as shown in the last ﬁve rows of table 3.we can observe that all self-supervised tasks areuseful as removing any of them causes performance.
1https://github.com/jasonforjoy/mpc-bert.
3688preceding (le et al., 2019)subsequent (le et al., 2019)drnn (ouchi and tsuboi, 2016)sirnn (zhang et al., 2018a)w2w (le et al., 2019)bert (devlin et al., 2019)sa-bert (gu et al., 2020)mpc-bertmpc-bert w/o.
rurmpc-bert w/o.
issmpc-bert w/o.
pcdmpc-bert w/o.
msurmpc-bert w/o.
snd.
hu et al.
(2019).
p@1-----96.1697.1298.3197.7598.2098.2098.0898.25.acc.
-----83.5088.9192.4289.9891.9691.9091.3292.18.ouchi and tsuboi (2016)len-15len-10len-5p@1 acc.
p@1 acc.
p@1 acc.
63.50 40.46 56.84 21.06 54.97 13.0861.03 40.25 54.57 20.26 53.07 12.7972.75 58.18 65.58 34.47 62.60 22.5875.98 62.06 70.88 40.66 68.13 28.0577.55 63.81 73.52 44.14 73.42 34.2385.95 75.99 83.41 58.22 81.09 44.9486.81 77.45 84.46 60.30 82.84 47.2388.73 80.31 86.23 63.58 85.55 52.5987.51 78.42 85.63 62.26 84.78 50.8388.67 80.25 86.14 63.40 85.02 51.1288.51 80.06 85.92 62.84 85.21 51.1788.70 80.26 86.21 63.46 85.28 51.2388.68 80.25 86.14 63.41 85.29 51.39.table 3: evaluation results of addressee recognition on the test sets.
results except ours are cited from le et al.
(2019).
numbers in bold denote that the improvement over the best performing baseline is statistically signiﬁcant(t-test with p-value < 0.05)..bert (devlin et al., 2019)sa-bert (gu et al., 2020)mpc-bertmpc-bert w/o.
rurmpc-bert w/o.
issmpc-bert w/o.
pcdmpc-bert w/o.
msurmpc-bert w/o.
snd.
hu et al.
(2019) ouchi and tsuboi (2016)len-5 len-10 len-1551.5853.1762.2454.2857.6264.9658.5261.0067.5657.3360.1266.8856.7360.0366.7758.0060.6267.1258.0360.7667.2158.1260.4467.04.
71.8175.8883.5482.4877.9583.3983.5183.47.table 4: evaluation results of speaker identiﬁcation on the test sets in terms of p@1. numbers in bold denote thatthe improvement over the best performing baseline is statistically signiﬁcant (t-test with p-value < 0.05)..drop.
among the ﬁve tasks, rur plays the mostimportant role, and the tasks focusing on modelinginterlocutor structure contribute more than thosefor utterance semantics..speaker identiﬁcation similarly, p@1 was em-ployed as the evaluation metric of speaker iden-tiﬁcation for the last utterance of a conversationand the results are shown in table 4. it shows thatmpc-bert outperforms sa-bert by margins of7.66%, 2.60%, 3.38% and 4.24% respectively interms of p@1. besides, from the ablation resultswe ﬁnd that all tasks are useful for improvingthe performance of speaker identiﬁcation andiss and rur contribute the most.
in particular,removing pcd, msur and snd only leads toslight performance drop.
the reason might be.
that the information conveyed by these tasks isredundant..response selection the rn@k metrics adoptedby previous studies (ouchi and tsuboi, 2016;zhang et al., 2018a) were used here.
each modelwas tasked with selecting k best-matched responsesfrom n available candidates, and we calculated therecall as rn@k. two settings were followed inwhich k was set to 1 and n was set to 2 or 10..table 5 presents the results of response selec-tion.
it shows that mpc-bert outperforms sa-bert by margins of 3.82%, 2.71%, 2.55% and3.22% respectively in terms of r10@1. ablationtests show that snd is the most useful task forresponse selection and the two tasks focusing onthe utterance semantics contribute more than those.
3689drnn (ouchi and tsuboi, 2016)sirnn (zhang et al., 2018a)bert (devlin et al., 2019)sa-bert (gu et al., 2020)mpc-bertmpc-bert w/o.
rurmpc-bert w/o.
issmpc-bert w/o.
pcdmpc-bert w/o.
msurmpc-bert w/o.
snd.
hu et al.
(2019).
ouchi and tsuboi (2016)len-10.
len-5.
len-15.
r2@1 r10@1 r2@1 r10@1 r2@1 r10@1 r2@1 r10@136.9340.8358.9260.4263.6463.2463.5163.4663.2063.34.
--92.4892.9894.9094.4894.5894.6694.3693.92.
78.6480.9187.1988.3489.7089.0789.5889.4589.2589.27.
76.0778.1485.5286.5387.6387.2087.5487.5087.1187.30.
33.6236.4553.9555.2457.9557.5657.7757.5157.5857.54.
78.1680.3486.9387.9889.1488.9688.9888.7588.5988.77.
--73.4275.1678.9878.1678.8278.7078.2276.96.
36.1439.2057.4159.2761.8261.4761.7661.6261.0561.54.table 5: evaluation results of response selection on the test sets.
results except ours are cited from ouchi andtsuboi (2016) and zhang et al.
(2018a).
numbers in bold denote that the improvement over the best performingbaseline is statistically signiﬁcant (t-test with p-value < 0.05)..(a) addressee recognition.
(b) speaker identiﬁcation.
(c) response selection.
figure 3: performance of models under different session lengths on the test sets of ouchi and tsuboi (2016) onthe tasks of (a) addressee recognition, (b) speaker identiﬁcation and (c) response selection..focusing on the interlocutor structures..5.5 discussions.
figure 3 illustrates how the performance of bert,sa-bert and mpc-bert changed with respectto different session lengths on the test sets ofit can be seen thatouchi and tsuboi (2016).
the performance of addressee recognition andspeaker identiﬁcation dropped as the session lengthincreased.
the reason might be that longer ses-sions always contain more interlocutors whichincrease the difﬁculties of predicting interlocutors.
meanwhile, the performance of response selectionwas signiﬁcantly improved as the session lengthincreased.
it can be attributed to that longersessions enrich the representations of contextswith more details which beneﬁt response selection.
furthermore, as the session length increased, theperformance of mpc-bert dropped more slightlythan that of sa-bert on addressee recognition and.
speaker identiﬁcation, and the r10@1 gap betweenmpc-bert and sa-bert on response selectionenlarged from 2.71% to 3.22%.
these results implythe superiority of mpc-bert over sa-bert onmodeling long mpcs with complicated structures..6 conclusion.
in this paper, we present mpc-bert, a pre-trainedlanguage model with ﬁve self-supervised tasks formpc understanding.
these tasks jointly learn whosays what to whom in mpcs.
experimental resultson three downstream tasks show that mpc-bertoutperforms previous methods by large marginsand achieves new state-of-the-art performance ontwo benchmarks..acknowledgments.
we thank anonymous reviewers for their valuablecomments..369051015length50607080session accuracybertsa-bertmpc-bert51015length556065utterance preisionbertsa-bertmpc-bert51015length545658606264response recallbertsa-bertmpc-bertreferences.
mart´ın abadi, paul barham, jianmin chen, zhifengchen, andy davis, jeffrey dean, matthieu devin,sanjay ghemawat, geoffrey irving, michael isard,manjunath kudlur, josh levenberg, rajat monga,sherry moore, derek gordon murray, benoitsteiner, paul a. tucker, vijay vasudevan, petewarden, martin wicke, yuan yu, and xiaoqiangzheng.
2016. tensorﬂow: a system for large-scalein 12th usenix symposiummachine learning.
on operating systems design and implementation,osdi 2016, savannah, ga, usa, november 2-4,2016., pages 265–283..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, naacl-hlt 2019, minneapolis, mn,usa, june 2-7, 2019, volume 1 (long and shortpapers), pages 4171–4186..jia-chen gu, tianda li, quan liu, zhen-hualing, zhiming su, si wei, and xiaodan zhu.
2020. speaker-aware bert for multi-turn responsein cikmselection in retrieval-based chatbots.
’20: the 29th acm international conference oninformation and knowledge management, virtualevent, ireland, october 19-23, 2020, pages 2041–2044..jia-chen gu, zhen-hua ling, and quan liu.
2019a.
in-teractive matching network for multi-turn responseselection in retrieval-based chatbots.
in proceedingsofthe 28th acm international conference oninformation and knowledge management, cikm2019, beijing, china, november 3-7, 2019, pages2321–2324..jia-chen gu, zhen-hua ling, xiaodan zhu, and quanliu.
2019b.
dually interactive matching network forpersonalized response selection in retrieval-basedchatbots.
in proceedings of the 2019 conference onempirical methods in natural language processingand the 9th international joint conference onnatural language processing, emnlp-ijcnlp2019, hong kong, china, november 3-7, 2019,pages 1845–1854.
association for computationallinguistics..suchin gururangan, ana marasovic,.
swabhaswayamdipta, kyle lo, iz beltagy, doug downey,and noah a. smith.
2020. don’t stop pretraining:inadapt language models to domains and tasks.
proceedings ofthethe 58th annual meeting ofassociation for computational linguistics, acl2020, online, july 5-10, 2020, pages 8342–8360..dan hendrycks and kevin gimpel.
2016. bridgingnonlinearities and stochastic regularizers with gaus-sian error linear units.
corr, abs/1606.08415..wenpeng hu, zhangming chan, bing liu, dongyanzhao, jinwen ma, and rui yan.
2019. gsn: agraph-structured network for multi-party dialogues.
in proceedings of the twenty-eighth internationaljoint conference on artiﬁcial intelligence, ijcai2019, macao, china, august 10-16, 2019, pages5010–5016..diederik p. kingma and jimmy ba.
2015. adam: ain 3rd inter-method for stochastic optimization.
national conference on learning representations,iclr 2015, san diego, ca, usa, may 7-9, 2015,conference track proceedings..ran le, wenpeng hu, mingyue shang, zhenjun you,lidong bing, dongyan zhao, and rui yan.
2019.who is speaking to whom?
learning to identifyutterance addressee in multi-party conversations.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on naturallanguage processing, emnlp-ijcnlp 2019, hongkong, china, november 3-7, 2019, pages 1909–1919..ryan lowe, nissan pow, iulian serban, and joellepineau.
2015.the ubuntu dialogue corpus: alarge dataset for research in unstructured multi-turndialogue systems.
in proceedings of the sigdial2015 conference, the 16th annual meeting of thespecial interest group on discourse and dialogue,2-4 september 2015, prague, czech republic, pages285–294..zhao meng, lili mou, and zhi jin.
2018. towardsneural speaker modeling in multi-party conversation:in proceedings ofthe task, dataset, and models.
the eleventh international conference on languageresources and evaluation, lrec 2018, miyazaki,japan, may 7-12, 2018. european language re-sources association (elra)..hiroki ouchi and yuta tsuboi.
2016. addressee andresponse selection for multi-party conversation.
inproceedings of the 2016 conference on empiricalmethods in natural language processing, emnlp2016, austin, texas, usa, november 1-4, 2016,pages 2133–2143..iulian vlad serban, alessandro sordoni, yoshuabengio, aaron c. courville, and joelle pineau.
2016. building end-to-end dialogue systems usingingenerative hierarchical neural network models.
proceedings ofthe thirtieth aaai conferenceon artiﬁcial intelligence, february 12-17, 2016,phoenix, arizona, usa, pages 3776–3784..iulian vlad serban, alessandro sordoni, ryan lowe,laurent charlin, joelle pineau, aaron c. courville,and yoshua bengio.
2017. a hierarchical latentvariable encoder-decoder modelfor generatingdialogues.
in proceedings of the thirty-first aaaiconference on artiﬁcial intelligence, february 4-9,2017, san francisco, california, usa, pages 3295–3301. aaai press..3691lifeng shang, zhengdong lu, and hang li.
2015.neural responding machine for short-text conversa-tion.
in proceedings of the 53rd annual meeting ofthe association for computational linguistics andthe 7th international joint conference on naturallanguage processing of the asian federation ofnatural language processing, acl 2015, july 26-31, 2015, beijing, china, volume 1: long papers,pages 1577–1586..yizhe zhang, siqi sun, michel galley, yen-chunchen, chris brockett, xiang gao, jianfeng gao,jingjing liu, and bill dolan.
2020. dialogpt: large-scale generative pre-training for conversa-in proceedings oftional response generation.
the 58th annual meeting of the association forcomputational linguistics: system demonstrations,acl 2020, online, july 5-10, 2020, pages 270–278.
association for computational linguistics..chongyang tao, wei wu, can xu, wenpeng hu,dongyan zhao, and rui yan.
2019a.
multi-representation fusion network for multi-turn re-sponse selection in retrieval-based chatbots.
inproceedings ofthe twelfth acm internationalconference on web search and data mining, wsdm2019, melbourne, vic, australia, february 11-15,2019, pages 267–275.
acm..xiangyang zhou, lu li, daxiang dong, yi liu,ying chen, wayne xin zhao, dianhai yu, andhua wu.
2018. multi-turn response selection forchatbots with deep attention matching network.
inproceedings oftheassociation for computational linguistics, acl2018, melbourne, australia, july 15-20, 2018,volume 1: long papers, pages 1118–1127..the 56th annual meeting of.
chongyang tao, wei wu, can xu, wenpeng hu,dongyan zhao, and rui yan.
2019b.
one timeof interaction may not be enough: go deep withan interaction-over-interaction network for responsein proceedings of the 57thselection in dialogues.
conference of the association for computationallinguistics, acl 2019, florence, italy, july 28-august 2, 2019, volume 1: long papers, pages 1–11..weishi wang, steven c. h. hoi, and shaﬁq r.response selection for multi-partyjoty.
2020.conversations with dynamic topic tracking.
inproceedings of the 2020 conference on empiricalmethods in natural language processing, emnlp2020, online, november 16-20, 2020, pages 6581–6591..yu wu, wei wu, chen xing, ming zhou, andzhoujun li.
2017. sequential matching network:a new architecture for multi-turn response selectionin proceedings ofin retrieval-based chatbots.
the 55th annual meeting of the association forcomputational linguistics, acl 2017, vancouver,canada, july 30 - august 4, volume 1: long papers,pages 496–505..in proceedings of.
rui zhang, honglak lee, lazaros polymenakos, anddragomir r. radev.
2018a.
addressee and responseselection in multi-party conversations with speakerthe thirty-interaction rnns.
second aaai conference on artiﬁcial intelligence,(aaai-18),the 30th innovative applications ofartiﬁcial intelligence (iaai-18), and the 8th aaaisymposium on educational advances in artiﬁcialintelligence (eaai-18), new orleans, louisiana,usa, february 2-7, 2018, pages 5690–5697..yizhe zhang, michel galley, jianfeng gao, zhe gan,xiujun li, chris brockett, and bill dolan.
2018b.
generating informative and diverse conversationalresponses via adversarial information maximization.
in advances in neural information processing sys-tems 31: annual conference on neural informationprocessing systems 2018, neurips 2018, december3-8, 2018, montr´eal, canada, pages 1815–1825..3692