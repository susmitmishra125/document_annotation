uniﬁed dual-view cognitive model for interpretable claim veriﬁcation.
lianwei wu, yuan rao, yuqian lan, ling sun, zhaoyin qixi’an key lab.
of social intelligence and complexity data processing,school of software engineering, xi’an jiaotong university, chinashaanxi joint key laboratory for artifact intelligence(sub-lab of xi’an jiaotong university), chinaresearch institute of xi’an jiaotong university, shenzhen, china{stayhungry,yuqian lan xjtu,sunling,daqige123}@stu.xjtu.edu.cnraoyuan@mail.xjtu.edu.cn.
abstract.
recent studies constructing direct interactions be-tween the claim and each single user responseto capture evidence have shown remarkable suc-cess in interpretable claim verification.
owingto different single responses convey different cog-nition of individual users, the captured evidencebelongs to the perspective of individual cognition.
however, individuals’ cognition of social thingsis not always able to truly reflect the objective.
there may be one-sided or biased semantics intheir opinions on a claim.
the captured evidencecorrespondingly contains some unobjective andbiased information.
in this paper, we propose adual-view model based on the views of collectiveand individual cognition (cicd) for interpretableclaim verification.
for collective cognition, wenot only capture the word-level semantics basedon individual users, but also focus on sentence-level semantics (i.e., the overall responses) amongall users to generate global evidence.
for indi-vidual cognition, we select the top-k articles withhigh degree of difference and interact with theclaim to explore the local key evidence fragments.
to weaken the bias of individual cognition-viewevidence, we devise an inconsistent loss to sup-press the divergence between global and local ev-idence for strengthening the consistent shared ev-idence between the both.
experiments on threebenchmark datasets confirm the effectiveness ofcicd..1.introduction.
the problem of claim credibility has seriously affectedthe media ecosystem.
research (allen et al., 2020) illus-trates that the prevalence of ‘fake news’ has decreasedtrust in public institutions, and undermined democracy.
meanwhile, ‘massive infodemic’ during covid-19has taken a great toll on health-care systems and lives(fleming, 2020).
therefore, how to verify the claimsspread in networks has become a crucial issue..current approaches on claim verification could bedivided into two categories: 1) the first category re-.
claim: in such a hot and rainy season, we should pay attention to the prevention of dengue fever.
not only mosquitoes can transmit it, but it is said that the disease could also be transmitted through the air.
.
such a hot and rainy season, weitoes can transmit it, but it is s.rainynd mit itsansm.
ot atra.
y s.this year is really.
r1: this year is really hard, let's get over this summer soon!
r2: i think it's true.
my husband had dengue fever before, and i also got infected soon.
maybe he infected me.
r3: no, not all types of mosquitoes transmit dengue fever.
r4: false, please don't continue to spread.
it has been refuted that dengue fever will spread in the air.
.
figure 1: users’ individual cognition of a false claim..lies on traditional machine learning and deep learningmethods to capture semantics (yang et al., 2019), sen-timents (ajao et al., 2019), writing styles (przybyla,2020), and stances (kumar and carley, 2019) fromclaim content, and meta-data features, such as userprofiles (shu et al., 2019; wu et al., 2020b) for verifi-cation.
such approaches could improve verificationperformance, but they are hard to make reasonableexplanations for the verified results, i.e., where falseclaims go wrong; 2) to tackle this issue, many re-searchers further focus on interpretable claim verifica-tion (the second category) by establishing interactivemodels between claims and each individual relevantarticle (or comment) to explore coherent (ma et al.,2019; wu et al., 2021), similar (nie et al., 2019; wuet al., 2020a), or conflicting (zhou et al., 2020) se-mantics as evidence for verifying the false parts ofclaims..in interpretable claim verification, the majority ofmodels construct interactions between claims andeach single user response (i.e., a comment or a rele-vant article) to capture evidence, which could effec-tively learn some of errant aspects of false claims.
due to different single responses reflect the cognitionof different individual users, the evidence capturedby these models is usually confined to individualcognition.
however, individuals’ cognition of socialthings is not always able to truly reflect the objec-tive (greenwald et al., 1998; boogert et al., 2018).
owing to individuals are affected by factors suchas emotional tendency (ji et al., 2019), traditionalbeliefs (willard and norenzayan, 2017), and selec-tively capturing information (hoffman, 2018), there.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages59–68august1–6,2021.©2021associationforcomputationallinguistics59are considerable differences in cognition of differentindividuals, and they are prone to cognitive bias, likeprimacy effect (troyer, 2011) and halo effect (gold-stein and naglieri, 2011), there may be one-sided orbiased semantics in their expressed opinions.
thus,the captured evidence also correspondingly containssome unobjective and biased evidence fragments, de-teriorating task performance.
for instance, as shownin figure 1, facing a claim to be verified, differentindividual users (here, users are the normal users onsocial media, not journalists or professionals) havedifferent reactions.
r2 (i.e., response 2 or relevantarticle 2) and r3 released by users contain unreliableand biased information perceived by their individu-als, which may lead to some misleading informationbeing captured as evidence by existing interactivemodels.
therefore, how to explore users’ collectivecognition on claims is a major challenge for inter-pretable claim verification..to address the deficiencies, we propose a unifieddual-view model based on collective and individualcognition (cicd) for interpretable claim verification,which focuses on discovering global evidence andlocal key evidence, respectively, and then strength-ens the consistent shared evidence between the both.
specifically, to explore users’ collective cognition tocapture global evidence, we design collective cog-nition view-based encoder-decoder module (ced).
ced develops claim-guided encoder that not onlylearns word-level semantics based on individual user,but also captures sentence-level semantics (i.e., theoverall opinions) among all users.
here, a relevantarticle (a response) released by an individual useris usually a sentence sequence, so all sentence-levelsemantics convey the overall opinions of all users.
then, ced develops hierarchical attention decoderto generate global evidence by adjusting weights ofword-level and sentence-level semantics.
to furtheracquire the local key evidence based on individual cog-nition, we develop individual cognition view-basedselected interaction module (isi) to screen represen-tative top-k articles with high difference and interactwith the claim to gain local key evidence fragments.
to weaken the bias of individual cognition view andstrengthen the consistent shared evidence betweenglobal and local evidence, we project inconsistent lossto suppress the divergence.
experimental results notonly reveal the effectiveness of cicd but also provideits interpretability.
our contributions are summarized:.
• a novel framework integrating interdisciplinaryknowledge on interpretable claim verification is.
explored, which discovers global and local ev-idence from the perspectives of collective andindividual cognition to interpret verified results..• proposed ced captures word-level (individual)and sentence-level (holistic) opinions, and reason-ably adjusts the proportion between them, whichgenerates global evidence of the view of all users..• experiments on three competitive datasets demon-strate that cicd achieves better performance thanother strong baselines..2 related work.
automatic verification approaches rely on neural net-works to extract content-based features, like seman-tics (popat et al., 2018; wu et al., 2019), sentiments(nguyen et al., 2020), writing styles (przybyla, 2020),etc., and metadata-based features, like user profiles-based (kumar and carley, 2019), comment-based(bovet and makse, 2019), etc., for verification.
thesemethods could improve the accuracy of claim veri-fication, but they are lack of interpretability for theverified results.
to tackle this, interpretable claimverification has received great attention.
its basicprinciple is to obtain queried, corrected, and rumor-refuted semantics from the articles (or comments)related to claims to interpret the credibility of claims.
at present, the methods for this task generally focuson direct interactions between claims and relevantarticles to identify their matching degree (nie et al.,2019), consistency (ma et al., 2019), implication (liuet al., 2019), conflict (wu et al., 2020c), etc., to learnpractical evidence.
for instances, han (ma et al.,2019) and ehian (wu et al., 2020c) learned implica-tion relationships between claims and relevant articlesto capture semantic conflicts as evidence, which re-flected a certain interpretability.
however, since allrelevant articles are involved, the captured conflictsmay be affected by some low-quality articles withnoisy semantics, easily resulting in the invalidationof the evidence.
in our model, we design isi moduleto screen all relevant articles to capture the valuablerepresentative articles with differential semantics, soas to learn local key evidence fragments.
in addition,some methods, such as gear (zhou et al., 2019)and kgat (liu et al., 2020), relied on graph-basednetworks to conduct semantic aggregation and rea-soning on relevant articles, so as to capture globalevidence.
nevertheless, these models treat an entirearticle (at the sentence level) as a node and ignore theimportance of word-level semantics in each article..60to overcome these defects, our model constructs ahierarchical attention decoder to fuse sentence-leveland word-level semantics for finely-grained generat-ing global evidence..3 the proposed approach.
in this section, we introduce the details of cicd asillustrated in figure 2..inputs and outputs for cognitive input repre-sentations, the inputs of ced are a claim sequenceand the concatenation of its all relevant articles withthe number of n, while the inputs of isi are a claimsequence and each relevant article.
given any a se-quence of length l words x={x1, x2, ..., xl}, whereeach word xi ∈rd is a d-dimensional vector obtainedby pre-trained bert model (devlin et al., 2019).
par-ticularly, the length of each sequence in relevant arti-cles is l and that of the claim sequence is p. thus, weobtain the representations of the i-th relevant articlei ∈rl×d, xc ∈rp×d, respectively.
and the claim as xrfor the outputs of the model, the outputs of ced arethe generated global evidence sequence of length owords g = {g1, g2, ..., go}, where gt is the represen-tation of the t-th generated word and o is the lengthof g. the outputs of isi are the integrated vector oftop-k local key evidence fragments i=[i1; i2, ; ...; ik],where ; is the concatenation operation..3.1 collective cognition view-based.
encoder-decoder (ced).
to explore users’ collective cognition on claims,we ﬁrst rely on claim-guided encoder to captureword-level and sentence-level semantics from allrelevant articles, and then adjust the proportionbetween the both by hierarchical attention decoderto generate global evidence..3.1.1 claim-guided encoderthe claim-guided encoder module involves a se-quence encoding layer and a matching layer..sequence encoding layer we rely on bil-stms to encode all relevant articles and the claimfor their contextual representations.
we utilizethe produced hidden states hr = {hr}(where lall means the total length of all articles) andhc ={hcp} to denote the contextual repre-sentations of relevant articles and the claim, respec-i or hctively, where hi (i.e., hri ) is defined as follows:−→hi;.
2, ..., hrlall.
2, ..., hc.
1, hr.
1, hc.
←−hi].
hi = [←−hi ∈ rdh are the i-th hidden.
(1).
−→hi ∈ rdh and.
where.
state of the forward and backward lstms for theword xi respectively.
; is concatenation operation.
attention-based matching layer is engaged toaggregate the relevant information from the claim foreach word within the context of relevant articles.
thei , hc) is as follows:aggregation operation ai=attn(hr.
ai =.
αi,jhcj.kc(cid:2).
j=1.
p(cid:2).
k=1.
αi,j =exp(si,j)/.
exp(si,k).
si,j = (hr.
i )(cid:2).
w1hcj.
(2).
(3).
(4).
where ai is the aggregated vector for the i-th wordof the articles.
αi,j is the normalized attention scorebetween hr.
i and hcj..here, the purpose of adopting claim to guide the en-coding of relevant articles includes two perspectives:1) strengthening the focus of consistent semanticsassociated with the claim in relevant articles, i.e., ex-ploring how relevant articles evaluate the claim; and2) making the encoding semantics purer.
we observethat there are some advertisements or useless informa-tion in relevant articles.
this way is able to effectivelyfilter the noise irrelevant to the claim from relevantarticles, and consolidates the generation of relevantsemantics in the decoder module..furthermore, we output the hidden state correspond-ing to the last word encoded by each relevant article toform consistent sentence-level representations, wherehsi represents sentence-level representations of the i-threlevant article.
particularly, we apply word-level rep-resentations hr={hr2, ..., hr} (which can also belallrepresented in the form of different relevant articles,i.e., hr={hr1,2, ..., hrn,l}, where lall=n×l) andsentence-level representations hrs={hsn }as memory bank for decoder generation..2, ..., hs.
1,1, hr.
1, hs.
1, hr.
3.1.2 hierarchical attention decoderto capture the collective cognition-view evidencefrom relevant articles, we devise hierarchical atten-tion decoder to consider the consistent semanticswith different granularity of relevant articles to gen-erate global evidence.
specifically, we employ uni-directional lstm as the decoder, and at each decod-ing time-step, we calculate in parallel both sentence-level attention weight β and word-level α by:w3hdt.αi,j = (hr.
βi = (hs.
w2hdt.i,j)(cid:2).
i )(cid:2).
(5).
γi,j =.
αi,jβi(cid:3).
i,j αi,jβi.
(6).
61(cid:54)(cid:82)(cid:73)(cid:87)(cid:80)(cid:68)(cid:91)(cid:44)(cid:81)(cid:70)(cid:82)(cid:81)(cid:86)(cid:76)(cid:86)(cid:87)(cid:72)(cid:81)(cid:70)(cid:92)(cid:3)(cid:79)(cid:82)(cid:86)(cid:86).
(cid:39)(cid:88)(cid:68)(cid:79)(cid:16)(cid:57)(cid:76)(cid:72)(cid:90)(cid:3)(cid:38)(cid:79)(cid:68)(cid:86)(cid:86)(cid:76)(cid:73)(cid:76)(cid:70)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81).
(cid:38)(cid:79)(cid:68)(cid:76)(cid:80)(cid:16)(cid:74)(cid:88)(cid:76)(cid:71)(cid:72)(cid:71)(cid:3)(cid:40)(cid:81)(cid:70)(cid:82)(cid:71)(cid:72)(cid:85).
(cid:38)(cid:82)(cid:16)(cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:68)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81).
(cid:38)(cid:82)(cid:16)(cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:68)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81).
(cid:38)(cid:82)(cid:16)(cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:68)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:47)(cid:68)(cid:92)(cid:72)(cid:85).
(cid:485).
(cid:137)(cid:2869).
(cid:137)(cid:3047).
(cid:485).
(cid:137)(cid:3042).
(cid:55)(cid:75)(cid:72)(cid:3)(cid:74)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:87)(cid:72)(cid:71)(cid:3)(cid:86)(cid:72)(cid:84)(cid:88)(cid:72)(cid:81)(cid:70)(cid:72).
(cid:1860)(cid:4632)(cid:3031)(cid:2869).
(cid:1860)(cid:4632)(cid:3031)(cid:3047).
(cid:43)(cid:76)(cid:72)(cid:85)(cid:68)(cid:85)(cid:70)(cid:75)(cid:76)(cid:70)(cid:68)(cid:79)(cid:3)(cid:36)(cid:87)(cid:87)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:39)(cid:72)(cid:70)(cid:82)(cid:71)(cid:72)(cid:85)(cid:43)(cid:76)(cid:72)(cid:85)(cid:68)(cid:85)(cid:70)(cid:75)(cid:76)(cid:70)(cid:68)(cid:79)(cid:3)(cid:36)(cid:87)(cid:87)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81).
(cid:54)(cid:72)(cid:81)(cid:87)(cid:72)(cid:81)(cid:70)(cid:72)(cid:16)(cid:79)(cid:72)(cid:89)(cid:72)(cid:79)(cid:3)(cid:68)(cid:87)(cid:87)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81).
(cid:485).
(cid:1855)(cid:2869).
(cid:485).
(cid:1855)(cid:3047).
(cid:2011).
(cid:3046) (cid:485)(cid:1860)(cid:3015).
(cid:3046)(cid:1860)(cid:2870).
(cid:3046)(cid:1860)(cid:2869).
(cid:2010).
(cid:2009).
(cid:58)(cid:82)(cid:85)(cid:71)(cid:16)(cid:79)(cid:72)(cid:89)(cid:72)(cid:79)(cid:3)(cid:68)(cid:87)(cid:87)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81).
(cid:3045)(cid:1860)(cid:2869)(cid:481)(cid:3039).
(cid:3045)(cid:1860)(cid:2869)(cid:481)(cid:2869).
(cid:3045)(cid:1860)(cid:3039)(cid:3276)(cid:3287)(cid:3287).
(cid:3031)(cid:1860)(cid:2869).
(cid:485).
(cid:3031)(cid:1860)(cid:3047).
(cid:3).
(cid:71)(cid:72)(cid:86)(cid:68)(cid:69)(cid:16)(cid:90)(cid:72)(cid:76)(cid:89)(cid:3)(cid:81)(cid:82)(cid:76)(cid:87)(cid:76)(cid:81)(cid:74)(cid:82)(cid:70)(cid:3)(cid:72)(cid:89)(cid:76)(cid:87)(cid:70)(cid:72)(cid:79)(cid:79)(cid:82)(cid:38).
(cid:12).
(cid:39)(cid:40)(cid:38).
(cid:11)(cid:3)(cid:85)(cid:72)(cid:71)(cid:82)(cid:70)(cid:72)(cid:39)(cid:16)(cid:85)(cid:72)(cid:71)(cid:82)(cid:70)(cid:81)(cid:40).
(cid:54)(cid:72)(cid:81)(cid:87)(cid:72)(cid:81)(cid:70)(cid:72)(cid:16)(cid:79)(cid:72)(cid:89)(cid:72)(cid:79).
(cid:58)(cid:82)(cid:85)(cid:71)(cid:16)(cid:79)(cid:72)(cid:89)(cid:72)(cid:79).
(cid:3046)(cid:1860)(cid:2869).
(cid:171).
(cid:3046)(cid:1860)(cid:3015).
(cid:36)(cid:87)(cid:87)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81)(cid:16)(cid:69)(cid:68)(cid:86)(cid:72)(cid:71)(cid:3)(cid:80)(cid:68)(cid:87)(cid:70)(cid:75)(cid:76)(cid:81)(cid:74).
(cid:171).
(cid:3045)(cid:1860)(cid:2869).
(cid:3045)(cid:1860)(cid:2919).
(cid:3045)(cid:1860)(cid:3039)(cid:3276)(cid:3287)(cid:3287).
(cid:171).
(cid:171).
(cid:171).
(cid:171).
(cid:171).
(cid:38)(cid:82)(cid:74)(cid:81)(cid:76)(cid:87)(cid:76)(cid:89)(cid:72)(cid:3)(cid:44)(cid:81)(cid:83)(cid:88)(cid:87)(cid:3)(cid:53)(cid:72)(cid:83)(cid:85)(cid:72)(cid:86)(cid:72)(cid:81)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86).
(cid:55)(cid:75)(cid:72)(cid:3)(cid:70)(cid:82)(cid:81)(cid:70)(cid:17)(cid:3)(cid:82)(cid:73)(cid:3)(cid:68)(cid:79)(cid:79)(cid:3)(cid:85)(cid:72)(cid:79)(cid:72)(cid:89)(cid:68)(cid:81)(cid:87)(cid:3)(cid:68)(cid:85)(cid:87)(cid:76)(cid:70)(cid:79)(cid:72)(cid:86).
(cid:1860)(cid:3030)(cid:3046).
(cid:3030)(cid:1860)(cid:3043).
(cid:171).
(cid:171).
(cid:3030)(cid:1860)(cid:2869).
(cid:171)(cid:38)(cid:79)(cid:68)(cid:76)(cid:80).
(cid:1769).
(cid:1769).
(cid:54)(cid:82)(cid:73)(cid:87)(cid:80)(cid:68)(cid:91).
(cid:1769).
(cid:257).
(cid:55).
(cid:1769).
(cid:54)(cid:82)(cid:73)(cid:87)(cid:80)(cid:68)(cid:91)(cid:55).
(cid:1866)(cid:857)(cid:882)(cid:484)(cid:884)(cid:887) (cid:882)(cid:484)(cid:886).
(cid:1870)(cid:3019)(cid:882)(cid:484)(cid:886).
(cid:882)(cid:484)(cid:885)(cid:884).
(cid:882)(cid:484)(cid:884).
(cid:882)(cid:484)(cid:883).
(cid:1827)(cid:4670)(cid:1865)(cid:481)(cid:1866)(cid:4671).
(cid:3).
(cid:69)(cid:68)(cid:86)(cid:72)(cid:71)(cid:54)(cid:72)(cid:79)(cid:72)(cid:70)(cid:87)(cid:72)(cid:71)(cid:3)(cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:68)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:11)(cid:44)(cid:54)(cid:44)(cid:12).
(cid:44)(cid:81)(cid:71)(cid:76)(cid:89)(cid:76)(cid:71)(cid:88)(cid:68)(cid:79)(cid:3)(cid:70)(cid:82)(cid:74)(cid:81)(cid:76)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90).
(cid:16).
(cid:257)(cid:1870)(cid:2869).
(cid:1870)(cid:2869)(cid:1865)(cid:857).
(cid:1870)(cid:3019).
(cid:1769).
(cid:171).
(cid:171).
(cid:171).
(cid:171).
(cid:3045)(cid:3046)(cid:1860)(cid:3036).
(cid:3045)(cid:3046)(cid:1860)(cid:3037)(cid:54)(cid:72)(cid:79)(cid:72)(cid:70)(cid:87)(cid:72)(cid:71)(cid:3)(cid:48)(cid:72)(cid:70)(cid:75)(cid:68)(cid:81)(cid:76)(cid:86)(cid:80).
(cid:54)(cid:72)(cid:79)(cid:72)(cid:70)(cid:87)(cid:72)(cid:71)(cid:3)(cid:48)(cid:72)(cid:70)(cid:75)(cid:68)(cid:81)(cid:76)(cid:86)(cid:80).
(cid:3045)(cid:3046)(cid:1860)(cid:2869).
(cid:3045)(cid:3046)(cid:171)(cid:1860)(cid:2919).
(cid:171).
(cid:3045)(cid:1860)(cid:2869)(cid:481)(cid:2869).
(cid:3045)(cid:1860)(cid:2869)(cid:481)(cid:3039).
(cid:171).
(cid:3045)(cid:1860)(cid:3015)(cid:481)(cid:2869).
(cid:3045)(cid:3046)(cid:1860)(cid:3015).
(cid:3045)(cid:1860)(cid:3015)(cid:481)(cid:3039).
(cid:54)(cid:72)(cid:81)(cid:87)(cid:72)(cid:81)(cid:70)(cid:72)(cid:16)(cid:79)(cid:72)(cid:89)(cid:72)(cid:79)(cid:3)(cid:53)(cid:72)(cid:83)(cid:85)(cid:72)(cid:86)(cid:72)(cid:81)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86).
(cid:171)(cid:36)(cid:85)(cid:87)(cid:76)(cid:70)(cid:79)(cid:72)(cid:3)(cid:20).
(cid:171)(cid:36)(cid:85)(cid:87)(cid:76)(cid:70)(cid:79)(cid:72)(cid:3)(cid:49).
(cid:36)(cid:79)(cid:79)(cid:3)(cid:70)(cid:82)(cid:81)(cid:86)(cid:88)(cid:80)(cid:72)(cid:85)(cid:86).
(cid:38)(cid:82)(cid:81)(cid:86)(cid:88)(cid:80)(cid:72)(cid:85)(cid:3)(cid:20).
(cid:38)(cid:82)(cid:81)(cid:86)(cid:88)(cid:80)(cid:72)(cid:85)(cid:3)(cid:49).
figure 2: the general architecture of cicd.
the model consists of: 1) ced for generating global evidence; 2) isifor exploring local key evidence fragments; and 3) dual-view classiﬁcation module leveraging inconsistency lossto promote the learning of shared available evidence between global and local evidence..where hdt is the hidden state of the decoder at thet-th time-step, w2 and w3 are trainable parameters.
the word-level attention ascertains how to distributethe attention over words in each sentence (each ar-ticle), which could learn salient evidence segmentsin each article, while the sentence-level attention de-termines how much each article should contributeto the generation at current time-step, which couldcapture potential global semantics in all articles..then the context vector ct is derived as a combi-nation of all word-level representations reweightedby combined attention γ:(cid:2).
ct =.
γi,jhri.i,j.
and the attentional vector is calculated as:t = tanh(w4[hdˆhd.
t ; ct]).
finally, the predicted probability distribution.
over the vocabulary v at the current step is:pv = softmax(wv ˆhd.
(9)where w4, wv , and bv are trainable parameters.
we adopt g = {g1, g2, ..., go} to denote the gen-.
t + bv ).
erated sequence rich in global evidence..(7).
(8).
3.2 individual cognition view-based.
selected interaction (isi).
to capture evidence fragments from individual cogni-tion view, we design isi module with the followinglayers: 1) sentence-level representation for captur-ing high-level representations of relevant articles; 2)selected mechanism for screening the representativetop-k relevant articles with degree of difference; and3) co-interaction layer for making the claim and theselected articles interact with each other to explorelocal key evidence fragments..3.2.1 sentence-level representation.
we exploit bilstm to encode each relevant articleand capture the output of the last hidden state as thesentence-level representation, where the encodingprocess is similar to sequence encoding layer insection 3.2.1, where the sentence-level representa-tion of the i-th article is hrsi ..3.2.2 selected mechanism.
to capture representative top-k articles, we de-velop selected mechanism to calculate the differ-ence between each articles and other articles inan automated manner.
to do this, selected mech-anism learns and optimizes an inter-sentential at-tention matrix a ∈ rn×n .
the entry (m, n) of aholds the difference between article m and articlen (1≤m, n≤n and m(cid:6)=n) and is computed as:um=ϕ(wmhrs.
m +bm) un=ϕ(wnhrs.
n +bn) (10).
a[m, n] =.
(cid:3)n.exp(um (cid:7) un)i=1 exp(ui (cid:7) un).
(11).
where ϕ is a activation function, wm and wn areweight matrix, bm and bn are biases, and (cid:7) denotesdot product operator.
the larger the entry a[m, n] is,the higher the similar between article m and article nis.
thus, the smaller a[m, n] corresponds to article mand n contain more differential semantics, and finallywe screen top-k relevant articles with high differencefor further downstream interaction..3.2.3 co-interaction layer.
this co-interaction layer aims to explore local key ev-idence fragments.
specifically, the layer enables theclaim to focus on the i-th article to discover the specificevidence fragment, while the i-th article pays close at-tention to the claim to explore the possible false part of.
62the claim.
finally, we combine the two interactions toconstitute the individual key local evidence fragments..h.h.i = hrsrini + softmax(hrscin = hcs + softmax(hcin]rinii = [hi.; h.i ((hcs((hrs.
cs)(cid:2)))hcsi )(cid:2)))hrsi.
(12).
(13).
(14).
i.where hrinis the evidence fragment of the i-th arti-cle, hcin is the false part of the claim, and hcs is theoutputs of the last time step of hc..for all top-k articles, we integrate all local evi-.
dence fragments by concatenation operation..i = [i1; i2; ...; ik].
(15).
3.3 dual-view classiﬁcation.
lossin = dkl(g||i) =.
to alleviate the bias of individual cognition-viewevidence fragments and strengthen the consistentshared evidence between global and local evidence,we introduce an inconsistency loss to penalize thedisagreement between the both evidence.
we de-fine the inconsistency loss function as the kulllback-leibler (kl) divergence between g and i.
(cid:2)gk(cid:2)ik.k=1(cid:2)k is the k-th element of the concatenationwhere g(cid:2)k is the k-th element of i.of the words in g, and ifurthermore, we fuse the two types of penalizedevidence, and adopt softmax function to emit the prob-ability distribution for training, where a loss forcesthe model to minimize the cross-entropy error for atraining sample with ground-truth label y:(cid:2).
(cid:2)klogg.(16).
k(cid:2).
loss = −.
ylogp.
p = softmax(wp[g; i] + bp).
(17).
(18).
where wp and bp are the learnable parameters..to ensure the effective synergy of the two cog-nition views, we put together all loss mentionedabove for joint training..responses of different individual users to claims) col-lected from various web sources respectively.
feverconsists of 185,445 claims accompanied by manualannotation wikipedia articles.
for labels, each claimin snopes is labeled as true and false, while poli-tifact divides claims into six kinds of credibility la-bels: true, mostly true, half true, mostly false, false,and pants on fire.
to distinguish the veracity morepractically, like ma et al.
(2019), we merge mostlytrue, half true and mostly false into mixed, and treatfalse and pants on fire as false.
then, the labels ofpolitifact are classified as true, mixed, and false.
on fever, each claim is partitioned as supported,refuted, or nei (not enough information).
forevaluation metrics, on snopes and politifact, weexploit micro-/macro-averaged f1(micf1/macf1),class-specific precision (prec.
), recall (rec.)
and f1-score (f1) as evaluation metrics.
we hold out 10% ofthe claims for tuning the hyper parameters, and con-duct 5-fold cross-validation on the rest of the claims.
on fever, we leverage accuracy (acc.
), and f1-score (f1) as evaluation metrics, and follow thorneet al.
(2018) to partition the annotated claims intotraining, development (dev.
), and testing (test.)
sets..4.2 settings.
for parameter configurations, we adjust them accord-ing to the performance of development sets, we setthe word embedding size d to 768. the dimensional-ity of lstm hidden states dh is 120. the length l ofeach relevant article is 100 and that of the claim p isassigned as 20. due to no parameters depend on thenumber of articles n, instead of intercepting a fixednumber, we set n to vary with claims.
initial learningrate is set to 2e-3.
the loss weight coefficient α istrained to 0.2. the dropout rate is 0.4, and we set themini-batch size of the three datasets as 32, 32, and64, respectively.
additionally, an adam (kingma andba, 2015) optimizer with β1 as 0.9 and β2 as 0.999is used to optimize all trainable parameters..l = loss + αlossin.
(19).
4.3 experiments on snopes and politifact.
where α is the hyper-parameter..4 experiments.
4.1 datasets and evaluation metrics.
for evaluation, we utilize three publicly availabledatasets, i.e., snopes, politifact (both released by(popat et al., 2018)), and fever (thorne et al.,2018).
the first two datasets contain 4,341 and 3,568news claims, associating with 29,242 and 29,556relevant articles (these articles can be regarded as.
4.3.1 performance comparison.
we compare cicd and several competitive baselines:1) declare (popat et al., 2018) models joint inter-actions between claims and articles and aggregatesword-level credibility signals from external articles forevidence-aware assessment; 2) bert (devlin et al.,2019), we employ pre-trained bert classifier to ver-ify claims; 3) han (ma et al., 2019), a hierarchicalattention network, constructs the interactions betweenclaims and relevant articles for capturing sentence-.
63methods.
declareberthanhan-baehiancicd (ours).
micf1 macf10.6950.7620.7060.7810.7590.8070.7380.7710.7840.8310.7950.846.prec.
0.5590.5870.6370.5560.6140.629.snopes.
truerec.
0.5560.6010.6650.7650.7900.796.f10.5530.5940.6510.6440.6910.703.prec.
0.8390.8520.8740.8990.8930.897.falserec.
0.8370.8540.8600.7740.8960.904.f10.8370.8530.8670.8320.8940.900.micf1 macf10.4430.4750.4620.4930.4870.5230.4710.5200.5090.5540.5250.572.false mixed.
politifacttruef10.4470.4780.4950.4750.5130.529.f10.5760.5960.6270.6290.6510.665.f10.3070.3200.3400.3080.3620.373.table 1: comparison of our model with baselines on snopes and politifact..level evidence by considering their topical coherenceand semantic inference strength; 4) han-ba (maet al., 2019) is a variant of han, where the gatedattention is replaced to biaffine attention for acquiringevidence; and 5) ehian (wu et al., 2020c) is anevidence-aware hierarchical interactive attention net-work, which focuses on the direct interaction betweenclaim and relevant articles to explore key evidencefragments.
as shown in table 1, we observe that:.
• bert achieves at least 6.5% improvement onmicf1 than declare, which illustrates pre-trainedmodel can learn rich semantic context features toimprove performance, which is also the reason thatwe adopt bert to train word embeddings.
hanconsistently outperforms bert, which indicateshan capturing the coherence between relevantarticles could help improve the task performance..• in interpretable methods, cicd outperforms de-clare, which is because our model not only focuseson word-level semantics like declare, but alsograsps the holistic sentence-level features.
more-over, owing to han and han-ba drive all relevantarticles to participate in the interaction, promptingthem to gain a small boost in precision on snopes,but this way may introduce noise from nonsignifi-cant articles.
cicd effectively avoids this problemby selecting vital articles for interaction, whichobtains significant improvements in other metricscompared with han and han-ba.
furthermore,cicd consistently outperforms ehian on snopesand politifact.
the superiority is clear: cicd notonly values individual cognition view to capturekey evidence fragments, but also generates collec-tive cognition-view evidence for claim verification..4.3.2 ablation studyin order to evaluate the impact of each component ofcicd, we ablate cicd into the following simplifiedmodels: 1) -matching u represents the attention-based matching layer of ced is removed; 2) -ced.
snopes.
politifact.
methods.
-matching u 0.802-ced 0.7910.8100.8220.8030.831cicd 0.846.
-selected i-interaction i-isi-inconsistency loss.
micf1 macf1 micf1 macf10.4860.4760.4900.4970.4830.5080.525.
0.7530.7480.7630.7700.7510.7820.795.
0.5290.5260.5410.5570.5300.5560.572.table 2: ablation analysis of cicd..means ced is deleted from our model; 3) -selected irefers to the selected mechanism is removed from isi;4) -interaction i represents the co-interaction unit ofisi is replaced by concatenation operation; 5) -isicorresponds to isi is separated; and 6) -inconsistencyloss means the inconsistency loss is removed.
asshown in table 2, we observe that:.
• the removal of each module (-ced or -isi) weak-ens the performance of cicd, presenting from4.2% to 5.5% degradation in micf1, and the strip-ping of different layers (like -selected i and -interaction i) of each module also reduces the modelperformance, reducing at least 2.4% performancein micf1, which describes the effectiveness of eachcomponent and the organic integrity of cicd..• -ced reflects the lowest performance in all simpli-fied models, decreasing 5.5% and 4.6% in micf1on the two datasets, respectively, which elaboratesthe effectiveness of our cicd capturing the collec-tive cognition-view global evidence.
meanwhile,-isi underperforms cicd, showing 4.3% and 4.2%degradation in micf1 on the two datasets respec-tively, which conveys the necessity of the explo-ration of local key evidence fragments from indi-vidual cognition view..• when compared with -inconsistency loss, cicdsignificantly improves the performance on the twodatasets with the help of inconsistency loss unit,which verifies the effectiveness of our model rely-.
64ing on inconsistency loss to discover shared valu-able semantics between global and local evidence..4.3.3 evaluation of co-interaction networksto obtain a more detailed understanding of the su-periority of our co-interaction networks (coi), wecompare coi with the following prevalent interactionnetworks: 1) mlp (multilayer perceptron) acts asan interaction strategy to automatically abstract theintegrated representation of claims and articles; 2)self-att (self-attention networks) (vaswani et al.,2017) adopts the claim as query, and relevant arti-cles to serve as values and keys for interaction; 3)biaf-att (biaffine attention) (ma et al., 2019) mea-sures the degree of semantic matching for interaction;and 4) symm-intr (symmetric interaction attention)(tao et al., 2019) is exploited to model the interac-tion between claims and articles.
specifically, weinvestigate the performance and time cost of thesemethods on snopes and politifact based on linuxcentos with nvidia titan xp gpu, as shownin figure 3. we observe that:.
from the overall performance of all methods, ourmethod achieves the optimal performance, outper-forming other methods by more than 5.1% and 5.6%performance in micf1, respectively.
from the indi-cator of time cost, our method saves a great deal oftime.
compared with self-att and symm-intr, ourmethod saves from 500 to 1,000 seconds in time coston the two datasets, respectively.
the reason is thatthe structures of multiple mappings of self-attentionnetworks and the repeat stacks of symmetric atten-tion delay the efficiency.
although the time cost ofour method is higher than that of mlp and biaf-att,the performance of both methods is unsatisfactory,which is lower than our method al least 2.6% and3.7% in micf1 on both datasets.
on the whole, theseadequately manifest the superiority of our method..4.3.4 evaluation of hierarchical attention.
decoder.
to verify the effectiveness of the internal structureof hierarchical attention decoder (had) in ced,we ablate had with the following models: -word.,-sentence., and -merge.
respectively denote had re-moving word-level attention α, sentence-level atten-tion β, and merged semantics γ. decoder.
representsthe vanilla decoder.
experimental results are shownin table 3, we observe that: first, the removal of anymodule of had could weaken the performance ofthe model, which confirms the effectiveness of eachmodule.
second, in addition to the basic decoder,.
methods.
-word.
-sentence.
-merge.
decoder.
cicd.
snopes.
politifact.
micf1 macf1 micf1 macf10.5170.8270.5020.8150.5200.8330.4890.8040.5250.846.
0.5580.5450.5620.5350.572.
0.7840.7700.7870.7580.795.table 3: evaluation of hierarchical attention decoder..methods.
nsmnhangearkgatcicd (ours).
dev..test..acc.
0.6970.7200.7380.7450.763.f10.4310.4880.4920.5010.525.acc.
0.6210.6690.7080.7160.731.f10.3980.4460.4740.4850.497.table 4: results of different baselines on fever..our model achieves the most prominent boost withthe support of sentence-level attention, which provesthe effectiveness of had fusing sentence-level se-mantics to capture global semantics of had..to further investigate the contribution of sentence-level semantics to the global evidence, we take figure1 as an example to visualize the global evidence gen-erated by our model with and without sentence-levelattention, respectively.
as shown in figure 4, weobserve that the model with sentence-level attentionfocuses more on the sentences with maximum weight,that is, r4, such as the words ‘do not spread’ and ‘re-futed it spreads in the air’, while the model withoutsentence-level attention does not identify which rele-vant articles are more valuable, so that they concen-trate more on r2 and r3, like ‘get infected husband’and ‘not all types of mosquitoes’.
these fully provethe effectiveness of sentence-level semantics for thegeneration of global evidence..4.4 experiments on fever.
to examine the extensibility of our model, wealso compare cicd and the following state-of-the-art baselines on fever dataset: 1) nsmn: thepipeline-based system, neural semantic matchingnetwork (nie et al., 2019), conducts document re-trieval, sentence selection, and claim verificationjointly for fact extraction and verification; 2) han: ithas introduced in section 4.3.1; 3) gear: a graph-.
do  not  spread  this  news,  we  prevent  the transmission of dengue fever through mosquito.
it is refuted that it spreads in the air.
(a) our model with sentence-level attention .
i  get  infected  after  my  husband,  it  maybe  true that  dengue  fever  could  be  transmitted  through mosquitoes and air, but not all types of mosquitoes.
(b) our model without sentence-level attention(cid:3).
figure 4: the sequences generated by our model withand without sentence-level attention, respectively..65(cid:12).
(cid:8).
(cid:11)(cid:3)(cid:20)(cid:41)(cid:70)(cid:76)(cid:80).
(cid:19)(cid:17)(cid:27)(cid:25).
(cid:19)(cid:17)(cid:27)(cid:19).
(cid:19)(cid:17)(cid:26)(cid:23).
(cid:19)(cid:17)(cid:25)(cid:27).
(cid:19)(cid:17)(cid:25)(cid:21).
(cid:12).
(cid:8).
(cid:11)(cid:3)(cid:20)(cid:41)(cid:70)(cid:76)(cid:80).
(cid:19)(cid:17)(cid:24)(cid:27).
(cid:19)(cid:17)(cid:24)(cid:22).
(cid:19)(cid:17)(cid:23)(cid:27).
(cid:19)(cid:17)(cid:23)(cid:22).
(cid:19)(cid:17)(cid:22)(cid:27).
(cid:24)(cid:19)(cid:19).
(cid:48)(cid:47)(cid:51).
(cid:20)(cid:19)(cid:19)(cid:19)(cid:54)(cid:72)(cid:79)(cid:73)(cid:16)(cid:36)(cid:87)(cid:87).
(cid:20)(cid:24)(cid:19)(cid:19).
(cid:21)(cid:19)(cid:19)(cid:19).
(cid:21)(cid:24)(cid:19)(cid:19).
(cid:22)(cid:19)(cid:19)(cid:19).
(cid:37)(cid:76)(cid:68)(cid:73)(cid:16)(cid:36)(cid:87)(cid:87).
(cid:54)(cid:92)(cid:80)(cid:80)(cid:16)(cid:44)(cid:81)(cid:87)(cid:85).
(cid:38)(cid:82)(cid:44).
(cid:22)(cid:24)(cid:19)(cid:19)(cid:23)(cid:19)(cid:19)(cid:19)(cid:55)(cid:76)(cid:80)(cid:72)(cid:3)(cid:70)(cid:82)(cid:86)(cid:87)(cid:3)(cid:11)(cid:54)(cid:72)(cid:70)(cid:82)(cid:81)(cid:71)(cid:12).
(cid:24)(cid:19)(cid:19).
(cid:48)(cid:47)(cid:51).
(cid:20)(cid:19)(cid:19)(cid:19)(cid:54)(cid:72)(cid:79)(cid:73)(cid:16)(cid:36)(cid:87)(cid:87).
(cid:20)(cid:24)(cid:19)(cid:19).
(cid:21)(cid:19)(cid:19)(cid:19).
(cid:21)(cid:24)(cid:19)(cid:19).
(cid:22)(cid:19)(cid:19)(cid:19).
(cid:37)(cid:76)(cid:68)(cid:73)(cid:16)(cid:36)(cid:87)(cid:87).
(cid:54)(cid:92)(cid:80)(cid:80)(cid:16)(cid:44)(cid:81)(cid:87)(cid:85).
(cid:38)(cid:82)(cid:44).
(cid:22)(cid:24)(cid:19)(cid:19)(cid:23)(cid:19)(cid:19)(cid:19)(cid:55)(cid:76)(cid:80)(cid:72)(cid:3)(cid:70)(cid:82)(cid:86)(cid:87)(cid:3)(cid:11)(cid:54)(cid:72)(cid:70)(cid:82)(cid:81)(cid:71)(cid:12).
(a) on snopes.
(b) on politifact.
figure 3: the performance comparison between co-interaction networks (coi) and some prevalent interaction networks..r3 .
r3 .
r5 .
claimed 120 million americans died of coronavirus is a serious error, biden's mistake, the screenshot is one-sided.
.
(a) generated sequence from ced .
claim: 120 million people had died of the covid-19 coronavirus disease.
r1: that's what this video screenshot shows "people don't have a job, people don't know where to go, they don't know what to do," biden said thursday.
"now we have over 120 million dead from covid."
r2: is this a prophecy?
coronavirus is terrible.
more than one-third of the country died from it.
r3: he just falsely claimed 120 million americans died from the coronavirus.
"that's a serious error.
that's not a permissible type of error," trump said.
trump took to twitter to criticize biden's mistake, which he called, "mortifying stupid."
r4: joe biden short circuiting again.
you better get programmed better next speech.
r5: the screenshot of the video is one-sided, it is only a segment of the video.
however, he corrected himself immediately to say the number was actually 120,000. .
(b) the interpretation via visualization of cicd .
claim: 120 million people had died of the covid-19 coronavirus disease.
r1: that's what this video screenshot shows "people don't have a job, people don't know where to go, they don't know what to do," biden said thursday.
"now we have over 120 million dead from covid."
r2: is this a prophecy?
coronavirus is terrible.
more than one-third of the country died from it.
r3: he just falsely claimed 120 million americans died from the coronavirus.
"that's a serious error.
that's not a permissible type of error," trump said.
trump took to twitter to criticize biden's mistake, which he called, "mortifying stupid."
r4: joe biden short circuiting again.
you better get programmed better next speech.
r5: the screenshot of the video is one-sided, it is only a segment of the video.
however, he corrected himself immediately to say the number was actually 120,000. .
(c) the visualization of captured words by attention weights in isi .
figure 5: the interpretability and transparency of different modules of cicd via a false sample on snopes..based evidence aggregating and reasoning model(zhou et al., 2019) enables information to transferon a fully-connected evidence graph and then utilizesdifferent aggregators to collect multi-evidence infor-mation; 4) kgat: kernel graph attention network(liu et al., 2020) conducts more fine-grained fact ver-ification with kernel-based attentions, where usingbert (base) encoder with esim retrieved sentences.
as shown in table 4, we observe that: cicd out-performs the two pipelines (nsmn and han) byfrom 4.3% to 11.0% boost in accuracy, respectively.
this is because these two baselines lack the integra-tion and reasoning process between relevant articleswhen capturing evidence.
cicd boosts the perfor-mance in comparison with gear and kgat, show-ing at least 1.8% and 1.5% improvement in accuracyon development and testing sets, respectively.
the rea-son may be that although the two graph-based modelsaggregate and reason information from relevant arti-cles to collect multi-evidence, they treat each relevantarticle equally, leading to individual-cognitive rele-vant articles with some biased semantics interferingwith their reasoning process.
it is more feasible forour model to discover global evidence and local keyevidence fragments comprehensively from the per-spectives of collective and individual cognition..5 (a) is the sequence generated by ced module, andthe highlighted words in figure 5(b) and 5 (c) arerespectively the words captured by cicd to interpretthe results and the words obtained by isi module toobtain the evidence fragments.
we could learn:.
• isi ignores some articles with pale and feeblesemantics (r2 and r4), and selects the articleswith more valuable semantics (r1, r3, and r5)and captures multiple local evidence fragments,such as ‘this video screenshot shows’ (e1), ‘se-rious error’ (e2), and ‘screenshot of the video isone-sided’ (e3).
particularly, fragment e1 is mis-leading, which reflects the deviation of individualcognition..• the sequence generated by ced effectively gainsavailable evidence ‘120 million americans a seri-ous error’ and ‘the screenshot is one-sided’ throughbalancing the possible evidence semantics in rele-vant articles from a global perspective..• by constraining global and local evidence, cicddisciplines the misleading evidence fragment e1captured by isi, and finally highlights the sharedsalient evidence between the both as the final in-terpretability of the verification results..4.5 case study: cognition-view explanation.
5 conclusion.
analysis.
to interpret the results of our model more transpar-ently and intuitively, we visualize the outputs of eachmodule of cicd as shown in figure 5, where figure.
in this paper, we proposed a unified dual-view modelbased on the perspectives of collective and individ-ual cognition for interpretable claim verification,which constructed collective cognition view-based.
66encoder-decoder module to generate global evidenceand designed individual cognition view-based se-lected interaction module to explore local key ev-idence segments.
besides, we introduced incon-sistent loss to penalize the disagreement betweenglobal and local evidence for promoting the captureof consistent shared evidence.
experiments on threedifferent widely used datasets demonstrated the ef-fectiveness and interpretability of our model.
in thefuture, we plan to expand the work as follows: 1)developing questioning mechanism to filter the sus-picious evidence; and 2) integrating social cognition,psychology, and other interdisciplinary knowledgeto improve the interpretability of claim verification..acknowledgments.
the research work was supported by nationalkey research and development program inchina (2019yfb2102300); the world-classuniversities (disciplines) and the characteris-tic development guidance funds for the cen-tral universities of china (py3a022); min-istry of education fund projects (18jzd022 and2017b00030); shenzhen science and technologyproject (jcyj20180306170836595); basic scien-tiﬁc research operating expenses of central uni-versities (zdyf2017006); xi’an navinfo corp.&engineering center of xi’an intelligence spatial-temporal data analysis project (c2020103); beilindistrict of xi’an science & technology project(gx1803).
we would like to thank the anonymousreviewers for their valuable and constructive com-ments..references.
oluwaseun ajao, deepayan bhowmik, and shahrzadzargari.
2019. sentiment aware fake news detec-in icassp 2019-tion on online social networks.
2019 ieee international conference on acoustics,speech and signal processing (icassp), pages2507–2511.
ieee..jennifer allen, baird howland, markus mobius, davidrothschild, and duncan j watts.
2020. evaluatingthe fake news problem at the scale of the informationecosystem.
science advances, 6(14):eaay3539..n. boogert,.
j. madden,.
j. morand-ferron, anda. thornton.
2018. measuring and understandingindividual differences in cognition.
philosophicaltransactions of the royal society b: biological sci-ences, 373..alexandre bovet and hern´an a makse.
2019..inﬂu-ence of fake news in twitter during the 2016 us pres-.
idential election.
nature communications, 10(1):1–14..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 1 (long and short papers), pages4171–4186..nic fleming.
2020. coronavirus misinformation, andhow scientists can help to ﬁght it.
nature, 583:155–156..sam goldstein and jack a. naglieri, editors.
2011.halo effect, pages 725–725.
springer us, boston,ma..a. greenwald, d. mcghee, and j. l. schwartz.
1998.measuring individual differences in implicit cogni-tion: the implicit association test.
journal of person-ality and social psychology, 74 6:1464–80..paul hoffman.
2018. an individual differences ap-proach to semantic cognition: divergent effects ofage on representation, retrieval and selection.
scien-tiﬁc reports, 8..j. ji, e. holmes, c. macleod, and f. murphy.
2019.spontaneous cognition in dysphoria: reduced posi-tive bias in imagining the future.
psychological re-search, 83:817 – 831..diederik p kingma and jimmy ba.
2015. adam:in iclr.
a method for stochastic optimization.
(poster)..sumeet kumar and kathleen m carley.
2019. treelstms with convolution units to predict stance andrumor veracity in social media conversations.
inproceedings of the 57th annual meeting of the asso-ciation for computational linguistics, pages 5047–5058..shuaipeng liu, shuo liu, and lei ren.
2019. trustor suspect?
an empirical ensemble framework forfake news classiﬁcation.
in proceedings of the 12thacm international conference on web search anddata mining, pages 11–15..zhenghao liu, chenyan xiong, maosong sun, andzhiyuan liu.
2020. fine-grained fact veriﬁcationwith kernel graph attention network.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics, pages 7342–7351..jing ma, wei gao, shaﬁq joty, and kam-fai wong.
2019. sentence-level evidence embedding for claimveriﬁcation with hierarchical attention networks.
inacl, pages 2561–2571..van-hoang nguyen, kazunari sugiyama, preslavnakov, and min-yen kan. 2020. fang: leveragingsocial context for fake news detection using graph.
67lianwei wu, yuan rao, hao liang, ambreen nazir,et al.
2020a.
dtca: decision tree-based co-attentionnetworks for explainable claim veriﬁcation.
in pro-ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 1024–1035..lianwei wu, yuan rao, ambreen nazir, and haolinjin.
2020b.
discovering differential features: adver-sarial learning for information credibility evaluation.
information sciences, 516:453–473..lianwei wu, yuan rao, ling sun, and wangbo he.
2021. evidence inference networks for interpretableclaim veriﬁcation.
in proceedings of the aaai con-ference on artiﬁcial intelligence, pages 1165–1174..lianwei wu, yuan rao, xiong yang, wanzhen wang,and ambreen nazir.
2020c.
evidence-aware hierar-chical interactive attention networks for explainableclaim veriﬁcation.
in proceedings of ijcai..shuo yang, kai shu, suhang wang, renjie gu, fanwu, and huan liu.
2019. unsupervised fake newsdetection on social media: a generative approach.
in proceedings of the aaai conference on artiﬁcialintelligence, volume 33, pages 5644–5651..jie zhou, xu han, cheng yang, zhiyuan liu, lifengwang, changcheng li, and maosong sun.
2019.gear: graph-based evidence aggregating and rea-soning for fact veriﬁcation.
in proceedings of the57th annual meeting of the association for compu-tational linguistics, pages 892–901..xinyi zhou, jindi wu, and reza zafarani.
2020. safe:similarity-aware multi-modal fake news detection.
in paciﬁc-asia conference on knowledge discoveryand data mining, pages 354–367.
springer..representation.
in proceedings of the 29th acminternational conference on information & knowl-edge management, pages 1165–1174..yixin nie, haonan chen, and mohit bansal.
2019.combining fact extraction and veriﬁcation with neu-ral semantic matching networks.
in proceedings ofthe aaai conference on artiﬁcial intelligence, vol-ume 33, pages 6859–6866..kashyap popat, subhabrata mukherjee, andrew yates,and gerhard weikum.
2018. declare: debunkingfake news and false claims using evidence-awaredeep learning.
in proceedings of the 2018 confer-ence on empirical methods in natural languageprocessing, pages 22–32..piotr przybyla.
2020. capturing the style of fake news.
in proceedings of the aaai conference on artiﬁcialintelligence, volume 34, pages 490–497..kai shu, xinyi zhou, suhang wang, reza zafarani,and huan liu.
2019. the role of user proﬁles forfake news detection.
in proceedings of the 2019ieee/acm international conference on advancesin social networks analysis and mining, pages 436–439..chongyang tao, wei wu, can xu, wenpeng hu,dongyan zhao, and rui yan.
2019. one time ofinteraction may not be enough: go deep with aninteraction-over-interaction network for response se-lection in dialogues.
in proceedings of the 57th an-nual meeting of the association for computationallinguistics, pages 1–11..james.
andreas vlachos,.
and arpit mittal..christosthorne,christodoulopoulos,2018.fever: a large-scale dataset for fact extraction andveriﬁcation.
in proceedings of the 2018 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long papers), pages809–819..angela k. troyer.
2011. primacy effect, pages 2017–.
2018. new york, ny..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in advances in neural information pro-cessing systems, pages 5998–6008..aiyana k. willard and a. norenzayan.
2017. spiritualbut not religious: cognition, schizotypy, and conver-sion in alternative beliefs.
cognition, 165:137–146..lianwei wu, yuan rao, haolin jin, ambreen nazir,and ling sun.
2019. different absorption from thesame sharing: sifted multi-task learning for fakenews detection.
in proceedings of the 2019 con-ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 4636–4645..68