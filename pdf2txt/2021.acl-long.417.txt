alignment rationale for natural language inference.
zhongtao jiang1,2, yuanzhe zhang1,2, zhao yang1,2, jun zhao1,2 and kang liu1,21national laboratory of pattern recognition, institute of automation, cas, beijing, china2school of artiﬁcial intelligence, university of chinese academy of sciences, beijing, china{zhongtao.jiang, yzzhang, zhao.yang, jzhao, kliu}@nlpr.ia.ac.cn.
abstract.
deep learning models have achieved great suc-cess on the task of natural language infer-ence (nli), though only a few attempts tryto explain their behaviors.
existing explana-tion methods usually pick prominent featuressuch as words or phrases from the input text.
however, for nli, alignments among words orphrases are more enlightening clues to explainthe model.
to this end, this paper presentsarec, a post-hoc approach to generate align-ment rationale explanations for co-attentionbased models in nli.
the explanation is basedon feature selection, which keeps few but suf-ﬁcient alignments while maintaining the sameprediction of the target model.
experimentalresults show that our method is more faith-ful and readable compared with many exist-ing approaches.
we further study and re-evaluate three typical models through our ex-planation beyond accuracy, and propose a sim-ple method that greatly improves the model ro-bustness.1.
1.introduction.
natural language inference (nli) is a fundamentaltask in natural language processing (nlp) whichis to determine if a hypothesis entails a premise.
recently, with the introduction of large-scale an-notated datasets (bowman et al., 2015; williamset al., 2018), deep learning models are adopted tosolve the task in a supervised manner (conneauet al., 2017; chen et al., 2017; devlin et al., 2019)and achieve great success, while inner mechanismsof these methods are still opaque due to high com-putational complexities..towards interpretability, explaining the modelbehavior has gained increasing attention.
lots ofapproaches are based on feature attribution which.
1our code is available at https://github.com/.
changmenseng/arec.
figure 1: different post-hoc explanations.
for attribu-tion explanations, features with deeper colors are con-sidered more important..assigns saliency scores for input features (bah-danau et al., 2015; lundberg and lee, 2017; thorneet al., 2019; kim et al., 2020), and feature selectionor rationale that keeps a subset of features sufﬁ-cient for the prediction (lei et al., 2016; bastingset al., 2019; de cao et al., 2020; deyoung et al.,2020).
figure 1 (a) and (b) present a text attributionexplanation by lime (ribeiro et al., 2016) and atext rationale explanation from li et al.
(2016) ofan nli sentence pair.
both explanations provideinsights of which input words are responsible forthe prediction.
however, nli is a cross-sentencetask requiring a system to reason over alignments2(maccartney and manning, 2009).
intuitively, it ismore sensible to explain nli systems in the way of.
2in machine translation, alignments refer to bilingual textpairs with identical meanings.
but for nli, the semantics oftwo sentences may be different, it is more suitable to deﬁnealignments as any text pairs related lexically or logically, etc..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5372–5387august1–6,2021.©2021associationforcomputationallinguistics5372 (c) alignment attribution (gradient) (a) text attribution (lime) p:  passengers  in  a  rusty  yellow  car  driving  down  the  street  .
h:  people  walk  through  a  store  .
passengersinarustyyellowcardrivingdownthestreet.
(b) text rationale (erasure) p:  passengers  in  a  rusty  yellow  car  driving  down  the  street  .
h:  people  walk  through  a  store  .
peoplewalkthroughastore.peoplewalkthroughastore.
(d) alignment rationale (arec)alignments instead of isolated words/phrases.
forthe example in figure 1, the contradicted phrasepair street – store is one of the key align-ments responsible for the correct prediction..to explain nli models over alignments, the liter-ature usually looks at co-attention weights (parikhet al., 2016; pang et al., 2016; chen et al., 2017),which is a dominant way to implicitly align wordpairs (wang et al., 2017; gong et al., 2018; de-vlin et al., 2019).
however, attention is arguednot as explainable as expected (jain and wallace,2019; serrano and smith, 2019; bastings and filip-pova, 2020).
moreover, co-attention assigns scoresamong words thus forbids us to observe phrase-level alignments, which is a ﬂaw that generallyexists for attribution explanations as shown in fig-ure 1 (c).
other works build hard alignments re-sorting sparse attention (yu et al., 2019; bastingset al., 2019; swanson et al., 2020).
but their self-explanatory architectures pay for the interpretabil-ity at a cost of performance dropping on accuracy(molnar, 2020).
meanwhile, these techniques areunable to analyze well-trained models..to resolve above problems,.
this paper pro-poses arec, a post-hoc local approach to generatealignment rationale explanation for co-attentionbased models.
analogous with lei et al.
(2016),our alignment rationale is a set that contains textpairs from the nli sentence pair with two require-ments.
first, the explanation is supposed to befaithful to the predictive model, where selectedtext pairs must alone sufﬁce for the original pre-diction.
second, the explanation should be human-friendly or readable (miller, 2019), which meansthe pairs are few to promote compact rationales,and extracted continuously to make phrase-levelrationales as far as possible (lei et al., 2016; bast-ings et al., 2019).
figure 1 (d) presents an exampleof arec explanation.
it shows that the modelreaches the right prediction reasonably: it identi-ﬁes people – passengers, walk through–car driving and store – street to makeup the alignment rationale.
arec is ﬂexible toapply on any co-attention architectures, allowingus for deep investigations of well-trained models..with the proposed arec, we study three typicalco-attention based models decomposable atten-tion (da) (parikh et al., 2016), enhanced lstm(esim) (chen et al., 2017) and bert (devlin et al.,2019) on four benchmarks including snli (bow-man et al., 2015), esnli (camburu et al., 2018),.
bnli (glockner et al., 2018) and hans (mccoyet al., 2019).
experimental results show that ourmethod could generate more faithful and readableexplanations.
moreover, we employ our proposedarec to analyze these models deeply from the as-pect of alignments.
based on our explanations, wefurther present a simple improvement strategy thatgreatly increases robustness of different modelswithout modifying their architectures or retraining.
this proves that our method could factually reﬂecthow models work..our contributions are summarized as follows:1) we come up with arec, a post-hoc localexplanation method to extract the alignment ratio-nale for co-attention based models.
we comparearec with other explanation methods, illustratingits advantages on faithfulness and readability..2) we diagnose three typical co-attention basedmodels using arec by re-evaluating them in amore ﬁne-grained alignment level beyond accu-racy.
experimental results could reveal potentialimprovement solutions.
to the best of our knowl-edge, we are the ﬁrst to study existing models withalignment exhaustively..2 related works.
natural language inference.
natural language inference has been studied foryears.
despite lots of works construct representa-tions for the input two sentences individually (bow-man et al., 2015; mueller and thyagarajan, 2016;conneau et al., 2017), the task actually requires asystem to recognize alignments (maccartney andmanning, 2009).
in early days, alignment detec-tion is sometimes formed as an independent task(chambers et al., 2007; maccartney et al., 2008),or a component of a pipeline system (maccartneyet al., 2006).
currently deep learning methods seekto model alignments implicitly through co-attentionmechanism (parikh et al., 2016; pang et al., 2016;chen et al., 2017; wang et al., 2017; gong et al.,2018; joshi et al., 2019; devlin et al., 2019).
thetechnique is ﬁrst proposed in machine translation(bahdanau et al., 2015), and soon dominates inmany applications including nli.
however whymodels with co-attention layers are effective is stillcalled for answers..explaining models in nlp.
explaining model behaviors has attracted muchinterests.
existing studies include opening the com-.
5373ponent of models (murdoch et al., 2018), assigningword importance scores (ribeiro et al., 2016; liet al., 2016; kim et al., 2020), extracting predic-tive related input pieces, referred as sufﬁcient inputsubset (carter et al., 2019) or rationale (lei et al.,2016; bastings et al., 2019), building hierarchi-cal explanations (chen et al., 2020; zhang et al.,2020), and generating natural language explana-tions (camburu et al., 2018; kumar and talukdar,2020).
however, they usually explain the model onthe granularity of words/phrases.
such ways aresufﬁcient for text classiﬁcation but not suitable fornli, since atom features in the task are alignments.
co-attention itself is often viewed as an expla-nation.
indeed, co-attention is a key proxy tomodel alignments, where perturbing its weightshas a signiﬁcant impact (vashishth et al., 2019).
yet recently, attention is argued to be not explain-able as expected (jain and wallace, 2019; serranoand smith, 2019; grimsley et al., 2020; bastingsand filippova, 2020).
secondly, co-attention alongwith feature attribution explanations just assignsscores among words, which is infeasible to ob-serve phrase-level alignments.
furthermore, formodels with multiple attentions (vaswani et al.,2017), it’s hard to acquire a global understandingof alignments.
other approaches include yu et al.
(2019), who adopts generator-encoder architecture(lei et al., 2016) to generate corresponded ratio-nales.
but their approach is unable to extract moreﬁne-grained alignments (e.g., one-to-one continu-ous alignments).
bastings et al.
(2019); swansonet al.
(2020) design sparse attention for hard align-ments.
however, these methods trade performancefor interpretability, and are immutable to analyzewell-trained models..3 method.
in this section, we describe our arec in details.
as mentioned before, arec is a post-hoc approachfor explaining co-attention based models.
thus weﬁrst introduce the co-attention layer, then depictthe propose arec..3.1 background: co-attention in nli.
models.
in our notation, we have an instance including apremise p = [p1, · · · , p|p|] ∈ rd×|p| and a hy-pothesis h = [h1, · · · , h|h|] ∈ rd×|h|, where|p|/|h| is the length of the premise/hypothesis, andpi/hj ∈ rd denotes corresponding word embed-.
ding (ﬁxed or contextual).
co-attention layer ac-cepts p and h as input and outputs alignmentenhanced word representations ¯p ∈ rd×|p| and¯h ∈ rd×|h|.
at the ﬁrst step, we compute a simi-larity matrix s ∈ r|p|×|h|.
si,j = φ(pi, hj).
(1).
where φ is a similarity function, ordinarily a vectordot product (chen et al., 2017).
then s is normal-ized to compute soft alignment scores for everyword in a sentence w.r.t all the words in its partner.
api,: = softmax(si,:)ah:,j = softmax(s:,j).
(2).
here ap and ah are so-called co-attention ma-trices, each element inside indicates the matchingdegree of the corresponding word pair.
next, weobtain soft alignments features for every word inthe premise/hypothesis by averaging word embed-dings in the hypothesis/premise weighted by thesoft alignment scores.
¯p = h · apt¯h = p · ah.
(3).
now ¯p/ ¯h is a richer representation of p/h en-hanced by h/p and fed to following modules,such as a classiﬁer which outputs probabilities ofcandidate categories, i.e., entailment, contradictionand neutral in nli task..3.2 problem formation.
the proposed arec relies on feature selection,keeping few but sufﬁcient alignments while main-taining the original prediction.
thus to restrictthe model to only consider some speciﬁc align-ments, we intuitively mask co-attention matricesap and ah following serrano and smith (2019);pruthi et al.
(2020).
let z ∈ {0, 1}|p|×|h| be a bi-nary mask indicating the presence or absence ofevery word pair alignment, and m be a model withco-attention layers.
then the masking process issimply hadamard product between mask z andco-attention matrices ap and ah.
an alignmentrationale is obtained by an optimistic problem.
˜z = arg minz.λ0l0 + λ1l1 + λ2l2.
(4).
the loss contains three terms (l0, l1 and l2) tosatisfy faithfulness and readability as mentionedin section 1. λ0, λ1 and λ2 are hyper-parameters.
5374standing for loss weights.
every rectangular regionin ˜z represents a text alignment in the alignmentrationale..we now describe loss terms.
the ﬁrst term l0 isabout ﬁdelity, asking that the model prediction ismaintained after masking (molnar, 2020).
fidelityensures faithfulness, making the derived explana-tion depict the true proﬁle of how the model works.
we choose the euclidean distance between logits asthis loss term, i.e.,.
l0 := (cid:107)ml(p, h) − mz.
l (p, h)(cid:107)2(5)l (p, h) ∈ r3 are origi-where ml(p, h) and mznal output logits and output logits when applyingthe mask z respectively.
compared to commonlyused kl divergence (de cao et al., 2020) or labelequality (feng et al., 2018), the euclidean distancebetween logits is a stricter constraint that narrowsdown the solution space and would lead to morefaithful explanations3..secondly, an explanation ought to be readable(molnar, 2020).
that requirement contains com-pactness and contiguity under the context of align-ment explanation.
compactness draws intuitionfrom the philosophy that a good explanation shouldbe short or selective (miller, 2019), which encour-ages fewer alignments to be selected.
compactnessloss is simply the l1 norm of the mask z.l1 := |z|1 =.
zi,j.
(6).
(cid:88).
i,j.
where zi,j is an element in z. contiguity encour-ages continuous phrase-level alignments4 (zenkelet al., 2020), which is helpful for human under-standings.
concretely, contiguity prefers z withrectangular clusters.
thus, we have.
l2 :=.
z = 3.
.
(7).
.
.
.
(cid:88).
1.i,j.
(cid:88).
z∈wzi,j.
where 1(·) is the indicator function and wzi,j ={zi,j, zi,j+1, zi+1,j, zi+1,j+1} is a 2 × 2 window atthe position.
the loss is based on the observationthat if there are three 1s in the window, there mustbe a non-rectangle region nearby, as marked by redboxes in figure 2..3if we use label equality (feng et al., 2018), which theprediction is only maintained in terms of the label, there aremany explanations satisfying the constraint.
using a strictﬁdelity constraint ensures uniqueness or less variety, makingthe explanation more faithful..4following lei et al.
(2016) and bastings et al.
(2019), aphrase could be any continuous span in a sentence, which maynot be a syntactical phrase..figure 2: the contiguity loss l2 could encourage thealgorithm to extract phrase alignments, i.e., penalises zwith non-rectangular clusters, as marked by red boxes..3.3 optimization.
searching the exponential huge (2|p||h|) solutionspace of z straightforwardly is impracticable.
touse the gradient-based method, we relax binary zto be a stochastic matrix z, and optimize loss ex-pectation over it.
speciﬁcally, we assume that everyelement zi,j in z is an independent random vari-able satisfying hardconcrete distribution (louizoset al., 2018a).
hardconcrete variables are allowedto be exactly discrete 0 and 1, while having con-tinuous and differential probability densities onthe open interval (0, 1).
additionally, hardcon-crete distribution accommodates reparameteriza-tion, permitting us to obtain a hardconcrete sam-ple z by transforming a parameter-less unit uniformsample u, i.e., z = g(u; α), where g is differential.
details are shown in appendix a..under this setting, we turn to optimize the ex-.
pectation of the objective.
for l0, we have.
l0 = eu [(cid:107)ml(p, h) − mg(u ;α).
(p, h)(cid:107)2].
l.(cid:39).
1n.n(cid:88).
i=1.
(cid:107)ml(p, h) − mg(ui;α).
(p, h)(cid:107)2.l.(8)here, u is a random matrix ﬁlled with i.i.d unituniform variables, α ∈ r|p|×|h|is the parameter of+z. the second line is a monte-carlo approxima-tion of the expectation, where n is the sample size,and ui is the i-th sample of u ..5375inmostpacificcountrythereareveryfewwomeninparliament.womenarepoorlyrepresentedinparliament.womenarepoorlyrepresentedinparliament.inmostpacificcountrythereareveryfewwomeninparliament.addcontiguityloss (l2)for l1 and l2, we have.
l1 =.
e(zi,j) ≤.
p(zi,j (cid:54)= 0; αi,j).
(cid:88).
i,j.
.
.
e.1.
.
.
.
.
.
.
(cid:88).
(cid:100)z(cid:101) = 3.z∈wzi,j.
(9).
(cid:88).
i,j.
(cid:88).
i,j.
l2 =.
(cid:88).
(cid:88).
=.
p(z = 0; α).
i,j.
z∈wzi,j.
(cid:89).
p(z(cid:48) > 0; α(cid:48)).
z(cid:48)∈wz.
i,j \{z}.
where (cid:100)z(cid:101) is the up round of z and p(·; α) isthe probability over the parameter α. now, allthe losses are differential over α, making gradientdescent feasible.
derivation details are presentedin appendix b..after training, we obtain the alignment rationale.
as follows.
two lstms before and after the co-attention layer(hochreiter and schmidhuber, 1997) to boost theperformance.
differently, bert concatenates theinput sentence pair with a template “[cls] p[sep] h [sep]” and uses global self-attention(vaswani et al., 2017).
all the models are trainedon snli training set and tested across datasets..implementationwe mask attention matrices for da and esim as de-scribed in section 3.2 since they are directly formedby co-attention.
for bert, we use a single maskto mask co-attention corresponded sub-matrices6of all the attention matrices identically, no matterof their layers or attention heads..we consider that faithfulness has a higher pri-ority than readability.
correspondingly, we adjustweights in the loss dynamically, based on ﬁdelityof current mask.
to this end, weights are set as.
λ0 = 1, λ1 = λ2 = 0.15 × spac.
(11).
˜zi,j = arg maxv∈{0,1}.
p(zi,j = v; αi,j).
(10).
where spac is the accuracy of current sampledmasks.
4 experiments.
our experiments include two parts.
first, we quan-titatively compare the proposed arec with severaltypical explanation methods (section 4.1) to provethe effectiveness of our method.
second, by meansof arec, we study and re-evaluate different mod-els from the aspect of alignment beyond accuracy,revealing potential improvements (section 4.2)..datasets.
we use four datasets snli (bowman et al., 2015),esnli (camburu et al., 2018), bnli (glockneret al., 2018) and hans as our testbeds.
snli is atraditional nli benchmark, while esnli extendsit by annotating text rationales.
bnli and hansare stress testing sets to test lexical inference andoverlap heuristics respectively..models.
we choose three typical co-attention based nlimodels da5 (parikh et al., 2016), esim (chenet al., 2017) and bert (base version) (devlinet al., 2019) for our discussion.
da applies theco-attention directly on word embeddings.
esimfurther incorporates order information by putting.
1n.n(cid:88).
i=1.
spac =.
1[my(p, h) = mg(ui;α).
y.
(p, h)].
(12)here, mzy is the model predicted label under maskz. thus terms related to readability are controlledby the explanation faithfulness.
this simple dy-namic weight strategy is similar to the approachin platt and barr (1988) and highly improves theexplanation quality and the algorithm stability..4.1 explanation evaluation.
in this section, we aim to evaluate the faithfulnessand readability of different explanations..4.1.1 baselineswe select feature attribution baselines includingco-attention itself, perturbation-based approachesleaveoneout (li et al., 2016), lime (ribeiroet al., 2016), backselect (carter et al., 2019),gradient-based approaches gradient (simonyanet al., 2014) and integratgrad (sundararajanet al., 2017) and a feature selection method diff-mask (de cao et al., 2020).
the original diff-mask is applied on text level, we derive an align-ment variant for comparison in appendix c..5following glockner et al.
(2018), in our implementation,we discard the optional intra-sentence attention and achievesimlar and comparable accuracy performance..6for a bert attention map a ∈ r(|p|+|h|+3)×(|p|+|h|+3),a2:|p|+1,|p|+3:|p|+|h|+2 and a|p|+3:|p|+|h|+2,2:|p|+1 are co-attention corresponded sub-matrices..53764.1.2 metrics.
inspired by deyoung et al.
(2020), we use areaover reservation curve (aorc) to evaluate faith-fulness7 as follows.
k(cid:88).
k=0.
aorc =.
(cid:107)ml(p, h) − mz(k).
l.(p, h)(cid:107)2.
(13)where z(k) is the mask that reserves top k% co-attention weights from an attribution explanation.
though arec belongs to feature selection expla-nations, its parameter α also provides importancescores.
we also report ﬁdelity deﬁned in equation(5) as a measure of faithfulness..for readability evaluation, we report compact-ness and contiguity deﬁned in equation (6) andequation (7) respectively.
we also conduct hu-man evaluations on random sampled 300 examplesfrom snli testing test to directly measure read-ability.
we let 2 annotators to rate how easy theexplanation is to read and understand the model’sdecision-making process along alignments from 1to 5 points and report the average scores8..we admit that metrics including ﬁdelity, com-pactness and contiguity are that arec optimizes.
actually it’s hard to unitedly evaluate different ex-planations since their contexts and techniques areusually completely different.
if we only follow def-initions of those metrics, we consider they are rea-sonable.
note that these metrics are not compatiblefor feature attribution explanations.
for fair com-parison, we follow carter et al.
(2019) to inducealignment rationales by thresholding9 for feature at-tribution baselines.
that is, we sequentially remainco-attention weights according to attribution scoresuntil the ﬁdelity loss is lower than the pre-deﬁnedthreshold..4.1.3 results.
automatic evaluation and readability human eval-uation results are shown in table 1 and table 2respectively.
we obtain the following ﬁndings:.
7we don’t use area over perturbation curve (aopc)(deyoung et al., 2020) because our method is to reserve fea-tures (i.e., alignments) that keep the prediction, it is ﬁtter toutilize reservation curve..8both annotators are well-educated postgraduates major incomputer science.
we conduct human evaluation on randomlysampled 300 examples in snli testing set..9the threshold is set to l0 + 0.1 of arec to obtain align-ment rationales with similar ﬁdelity for fair comparison.
wedon’t use ﬁx size constraint to construct rationales as donein jain et al.
(2020) because we think the size of a rationaledepends on the instance..1) arec is quite faithful with the lowest aorcand ﬁdelity value in most cases.
perturbation-basedmethods are equally matched with moderate perfor-mances, while gradient-based ones have the leastfaithfulness.
surprisingly, co-attention is a verystrong baseline to indicate important alignments fornli, surpassing most other baselines on aorc, ex-tremely for esim.
this result is of accordance withvashishth et al.
(2019) that attention is more faith-ful in cross-sentence tasks compared with single-sentence tasks..2) arec is quite readable which achieves thelowest compactness value and contiguity value inmost cases for automatic evaluation.
arec is alsothe most readable explanation according to humanevaluation.
as a contrast, feature attribution meth-ods are unable to induce readable alignment ratio-nales.
they reserve too much co-attention weights,usually half of which, to ensure similar ﬁdelitywith arec rather than satisfying compactness andcontiguity.
appendix e shows some examples forintuitive feelings of different explanations’ read-abilities..3) compared to rationale explanation diff-mask, arec is far more promising that outper-forms it with huge gaps on ﬁdelity while maintainsequivalent or better compactness and contiguity.
inour knowledge, diffmask is to globally learn toexplain local instances: the explainer is trained on atraining set which may contain artifacts and biases(gururangan et al., 2018; tsuchiya, 2018; poliaket al., 2018).
therefore this architecture leveragesdata information.
it is susceptible to over-ﬁttingand generate data-relevant biased explanations asa result, leading to poor ﬁdelity when facing held-out data (bnli and hans) as shown in table 1.moreover, we believe that a faithful explanationis a proﬁle of a model.
correspondingly, an ex-planation method should only access knowledgefrom the model instead of from the data.
that is anappealing theoretical advantage of our method..4.2 beyond accuracy: behavior testing of.
nli models with arec.
diverse evaluations are pursued to understand mod-els profoundly (ribeiro et al., 2020).
beyondaccuracy, in this section, we analyze da, esimand bert resorting to our proposed arec byre-evaluating them from the more ﬁned-grainedaspect of alignment.
for a model, we ﬁrst gen-erate its alignment rationales using arec, then.
5377models.
explanations.
snli.
bnli.
hans.
faithfulness.
readability.
faithfulness.
readability.
faithfulness.
readability.
aorc.
fide.
comp.
cont.
aorc.
fide.
comp.
cont.
aorc.
fide.
comp.
cont.
da.
esim.
bert.
co-attentionleaveoneoutbackselectlimegradientintegratgraddiffmaskarec (ours).
co-attentionleaveoneoutbackselectlimegradientintegratgraddiffmaskarec (ours).
co-attentionleaveoneoutbackselectlimegradientintegratgraddiffmaskarec (ours).
0.601.121.150.991.421.830.540.47.
0.241.010.900.942.842.990.510.40.
0.521.000.920.821.771.450.620.43.
0.45∗0.43∗0.43∗0.43∗0.42∗0.35∗1.280.36.
0.29∗0.25∗0.25∗0.27∗0.20∗0.21∗1.210.23.
0.45∗0.44∗0.45∗0.44∗0.39∗0.42∗1.000.36.
42.4657.7857.0552.8065.6563.872.776.23.
8.7242.8841.0852.4673.3780.323.944.86.
27.9145.5041.3239.6975.5859.8214.406.05.
131.3070.9167.0890.81135.0949.760.211.40.
4.4317.8015.7372.29109.1933.210.260.70.
58.2050.0542.0857.69127.9256.577.412.18.
0.461.231.341.221.732.310.620.42.
0.551.051.081.523.513.800.710.60.
0.650.640.690.624.631.211.610.47.
0.39∗0.34∗0.34∗0.34∗0.35∗0.25∗1.300.32.
0.15∗0.16∗0.16∗0.16∗0.10∗0.15∗2.620.15.
0.34∗0.36∗0.37∗0.36∗0.16∗0.32∗2.670.28.
30.9364.6765.1963.0174.8081.606.866.83.
15.4653.1552.3276.5283.6089.689.7711.02.
26.8139.8240.0844.0190.3554.3019.438.30.
59.8565.0255.8871.95155.5044.761.361.12.
6.55523.3816.1257.8578.8313.912.000.62.
46.4066.3560.9096.0574.6470.3720.172.65.
0.480.951.070.811.762.370.710.60.
0.511.050.981.295.154.450.790.73.
0.610.930.980.993.592.520.700.53.
0.56∗0.58∗0.58∗0.57∗0.55∗0.38∗0.970.50.
0.42∗0.43∗0.43∗0.42∗0.22∗0.38∗1.890.36.
0.50∗0.48∗0.48∗0.46∗0.26∗0.31∗0.950.44.
22.8866.3071.6148.3265.6970.986.466.07.
14.4056.3750.8873.6891.0591.388.3412.43.
29.6043.5140.9450.4790.9374.2618.958.56.
41.90125.06137.85124.71194.5080.431.390.23.
1.3630.7627.52179.10111.1455.631.060.41.
57.6858.1955.8092.14132.3090.1510.260.79.table 1: evaluation results of explanations across datasets.
fide, comp and cont denote ﬁdelity, compactnessand contiguity respectively.
we report comp in % and cont in ‰ for convenience.
numbers marked by * areﬁdelity of attribution induced rationales and are at the same level with arec’s ﬁdelity for fair comparison..explanations.
models.
da.
esim bert.
co-attentionleaveoneoutbackselectlimegradientintegratgraddiffmaskarec (ours).
2.702.422.602.401.682.143.984.07.
3.752.672.712.131.421.693.924.03.
2.192.472.742.421.312.283.083.98.table 2: human evaluation results of readability..we evaluate its alignment plausibility (jacovi andgoldberg, 2020): how well do its alignment ratio-nales agree with human judgments (deyoung et al.,2020).
since it is established in section 4.1 that ourmethod is faithful, thus alignment plausibility re-ﬂects a model’s power of alignment detection, i.e.,whether it makes a prediction with right alignments.
figure 3 illustrates the evaluation process..firstly, let’s have a look at table 3 that shows theaccuracy performances of various models acrossdatasets.
both da, esim and bert achieve highand tied accuracy performances on snli.
however,they are distinguished on lexical reasoning, wherebert surpasses others signiﬁcantly on bnli.
ad-ditionally, neither of them is robust against overlapheuristic, as their performances are extremely poor.
on non-entailment instances.
we seek to uncoverthe behind reasons (section 4.2.2) and try to makeimprovements (section 4.2.3) using our arec..4.2.1 metricswe deﬁne different metrics to measure alignmentplausibility (or equally speaking, alignment ratio-nale agreements with humans) in various datasets.
for esnli, since it’s annotated in the text level,we simply collect corresponding words to convertan alignment rationale to a text rationale for com-parison.
we adopt iou-f1 and token-f1 fromdeyoung et al.
(2020), and only use a subset ofesnli whose instances are labeled contradictionfor our evaluation10..in bnli, each sentence pair differs by a singleword or phrase.
naturally this pair forms up anannotation, which should be counted in a goldenalignment rationale.
further, we reasonably pre-sume this pair is the most essential alignment inits corresponding alignment rationale.
thus, threemetrics are deﬁned: 1) max-f1: we remain thealignment with max score from the alignment ra-tionale outputted by arec according to leaveo-neout.
max-f1 is the f1 measure comparingremaining ones and annotations.
2) exact-inc: the.
10in esnli, every contradiction instance selects words inboth the premise and the hypothesis to make up text rationale,ﬁtting with arec explanations..5378testsets.
metrics.
da.
esim bert.
snli.
esnlic.
bnli.
hanse.
hansn.
accuracyiou-f1token-f1.
accuracymax-f1exact-incsoft-inc.accuracyhumanaccuracyhuman.
85.0427.6254.45.
48.8235.0466.5871.86.
96.9441.672.479.33.
87.7820.4444.57.
67.0949.9083.1189.01.
99.3591.331.5124.00.
90.2730.2460.52.
95.4064.0589.5093.11.
99.5694.0016.5927.33.table 3: re-evaluation results of different mod-including rationale plausibility besides accu-elsracy.
esnlic is the contradiction labeled subset ofesnli.
hansc and hansn are entailment and non-entailment labeled subsets of hans respectively..combining the two factors makes bert an effec-tive approach for nli..2) our explanation method is helpful to detectartifacts or biases leveraged by the model.
for ex-ample, though obtaining high accuracy on hanse,da’s low alignment plausibility suggests it usu-ally makes a right prediction with wrong align-ments (see appendix d for examples).
further,all the models are brittle on catching reasonablealignments when facing non-entailment instancesin hans.
as we will discuss next, they tend doshallow literal lexical matching, which we conjec-ture the reason why they also fail on accuracy..in summary, the ability to capture correct align-ments is closely related to accuracy performancein nli.
this conclusion is often discussed qual-itatively in previous works.
but we are the ﬁrstto illustrate and prove this point exhaustively viaquantitative evaluation..4.2.3.improving robustness against overlapheuristics.
with our arec, we ﬁnd that both three modelstend to align overlapped words between the sen-tence pair no matter their syntactical or semanticroles, causing wrong predictions in hans.
figure4 presents an example, where the model mistakenlymatches identical words.
however, presidentin the premise and doctor in the hypothesis aresubjects of the same predicate advised, theyshould be aligned, and so do doctor in thepremise and president in the hypothesis..to remedy this, we turn to semantic role label-ing (srl), the task to recognize arguments for apredicate and assign semantic role labels to them,.
figure 3: an illustration of evaluating instance-wise ac-curacy and alignment plausibility for a bnli instance.
both evaluations compare model outputs and humanoutputs.
alignment in the orange box is remained forcomputing max-f1.
human thinking outputs includeannotated labels and rationales which could be anno-tated text rationales (esnli), annotated essential align-ments (bnli) and any other forms.
if there are no anno-tated rationales, we apply human evaluations (hans)to directly judge the agreements..metric is the proportion that the alignment ratio-nale includes the annotated alignment.
3) soft-inc:it is a loosed version of exact-inc, which is theaverage recall comparing alignment rationales andannotations.
details are shown in figure 3..we carry out human evaluations on hans be-cause it is not annotated in any form of rationales.
we ask 2 human annotators if (yes/no) the decisionprocess observed by arec is agreed with them andreport averaged agreed ratio11 (see appendix d fordetails)..4.2.2 results.
table 3 shows alignment plausibility results, wherewe obtain the following ﬁndings:.
1) across datasets, alignment plausibilities areconsistent with the accuracy performances in dif-ferent degrees.
especially on bnli, where bertsurpasses other competitors on all metrics substan-tially, quantitatively revealing that the alignmentdetection ability is important and distinguishes nlimodels.
we also discover that modeling order in-formation explicitly is also useful for nli, whereesim achieves a better accuracy even with a pooreralignment plausibility on snli compared to da..11the human evaluation is conducted on randomly selected.
300 examples, 10 examples per heuristic..5379this is water close to the woman.this is water far away from the woman.nlimodelcontradictioncontradictionarechumanthinkingaccuracy:equal label => 1thisiswaterfarawayfromthewoman.thisiswaterclosetothewoman.
alignment plausibility: max-f1: (2*1*1/3)/(1+1/3)=0.5 exact-inc: not included => 0 soft-inc: 2/6=0.33thisiswaterclosetothewoman.thisiswaterfarawayfromthewoman.
hans.
methods.
daesimbert.
dasrl guidesimsrl guidbertsrl guid.
bert‡.
srl mtl.
entailment.
non-entailment.
lex.
sub.
cons.
lex.
97.1899.6898.82.
93.6693.9496.24.
96.0298.76100.00.
96.6496.7699.36.
97.6299.6099.86.
96.3699.4299.74.
2.660.1843.02.
88.2499.1096.26.sub.
1.760.122.94.
25.8832.2829.44.cons.
3.004.223.82.
3.285.300.24.avg.
49.7150.4358.08.
67.3471.1370.21.
91.00.
98.00.
95.00.
71.00.
13.00.
25.00.
66.00.table 4: accuracy performances of different models across different datasets.
lex, sub and cons are differentoverlap heuristics in hans (mccoy et al., 2019).
bert‡srl mtl is reported from cengiz and yuret (2020) thatutilizes nli and srl multi-task learning and just for reference since they use different resources..improvements on non-entailment instances, espe-cially for lexical heuristic.
nevertheless, it doesn’tboost model performances for constituent heuristic.
we speculate that is because constituent heuristicinstances are accompanied with restrictions such asprepositions, which is unable to handle only withalignments.
overall, the results show that guidingalignments is a potential promising way to incor-porate useful information.
additionally, this alsoproves that our method is faithful towards modelsfrom another point of view..5 conclusions.
in this work, we propose arec, a new post-hocmethod to generate alignment rationale for co-attention based nli models.
experimental resultsshow that our explanation is faithful and readable.
we study typical models using our method andshed lights on potential improvements.
we be-lieve our method and ﬁndings are illuminating fornli.
for future works, we plan to explore model-agnostic alignment explanations, and analyze mod-els in other nlp tasks..acknowledgements.
this work was supported by the national keyresearch and development program of china(no.2020aaa0105200),the national naturalscience foundation of china (no.
61922085,61831022, 61906196).
this work is also sup-ported by beijing academy of artiﬁcial intel-ligence (baai2019qn0301), the key researchprogram of the chinese academy of sciences(grant no.
zdbs-ssw-jsc006) and independentresearch project of national laboratory of patternrecognition..figure 4: an illustration of using srl to guide align-ments.
a nli model fails on highly overlapped non-entailed examples (yellow path) because it mistakenlyaligns overlapped words.
to relief this problem, we usesrl to guide alignments by masking co-attention witha srl mask (green path)..to guide alignments for nli models.
in particu-lar, we employ an off-the-shelf bert-based srlmodel (shi and lin, 2019) to extract predicates andtheir corresponding arguments from the premiseand the hypothesis in advance.
then we limit themodel to only align identical predicates and phraseswith identical semantic roles by applying a corre-sponding co-attention mask (srl mask), as pre-sented in figure 4. in this way the semantic roleinformation is injected into the model.
note thatthere is no need to modify the model architectureor design new training protocol, contrary to cengizand yuret (2020) who jointly train nli and srl ina multi-task learning (mtl) manner..we report model accuracy performances whenalignments are guided by srl masks (subscriptedwith srl guid) in table 4. the results show thatwithout obvious performance drops on entailmentinstances, applying srl masks gains signiﬁcant.
5380thepresidentadvisedthedoctor.thedoctoradvisedthepresident.thedoctoradvisedthepresident.the president advised the doctor.the doctor advised the president.the president advised the doctor.
argument_0    predicate  argument_1the doctor advised the president.
argument_0  predicate    argument_1thepresidentadvisedthedoctor.srlmodelcomposesrl masknli modelnon-entailmententailmentarecreferences.
dzmitry bahdanau, kyunghyun cho, and yoshua ben-gio.
2015. neural machine translation by jointlyin 3rd inter-learning to align and translate.
national conference on learning representations,iclr 2015, san diego, ca, usa, may 7-9, 2015,conference track proceedings..jasmijn bastings, wilker aziz, and ivan titov.
2019.interpretable neural predictions with differentiablebinary variables.
in proceedings of the 57th annualmeeting of the association for computational lin-guistics, pages 2963–2977, florence, italy.
associa-tion for computational linguistics..jasmijn bastings and katja filippova.
2020. the ele-phant in the interpretability room: why use atten-tion as explanation when we have saliency methods?
in proceedings of the third blackboxnlp workshopon analyzing and interpreting neural networks fornlp, pages 149–155, online.
association for com-putational linguistics..samuel r. bowman, gabor angeli, christopher potts,and christopher d. manning.
2015. a large anno-tated corpus for learning natural language inference.
in proceedings of the 2015 conference on empiri-cal methods in natural language processing, pages632–642, lisbon, portugal.
association for compu-tational linguistics..oana-maria camburu, tim rockt¨aschel, thomaslukasiewicz, and phil blunsom.
2018. e-snli: nat-ural language inference with natural language expla-nations.
in advances in neural information process-ing systems 31: annual conference on neural infor-mation processing systems 2018, neurips 2018, de-cember 3-8, 2018, montr´eal, canada, pages 9560–9572..brandon carter, jonas mueller, siddhartha jain, anddavid k. gifford.
2019. what made you do this?
understanding black-box decisions with sufﬁcient in-put subsets.
in the 22nd international conferenceon artiﬁcial intelligence and statistics, aistats2019, 16-18 april 2019, naha, okinawa, japan, vol-ume 89 of proceedings of machine learning re-search, pages 567–576.
pmlr..cemil cengiz and deniz yuret.
2020..joint trainingwith semantic role labeling for better generalizationin natural language inference.
in proceedings of the5th workshop on representation learning for nlp,pages 78–88, online.
association for computationallinguistics..nathanael chambers, daniel cer, trond grenager,david hall, chloe kiddon, bill maccartney, marie-catherine de marneffe, daniel ramage, eric yeh,and christopher d. manning.
2007. learning align-ments and leveraging natural logic.
in proceedingsof the acl-pascal workshop on textual entail-ment and paraphrasing, pages 165–170, prague.
as-sociation for computational linguistics..hanjie chen, guangtao zheng, and yangfeng ji.
2020.generating hierarchical explanations on text classi-in pro-ﬁcation via feature interaction detection.
ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5578–5593, online.
association for computational lin-guistics..qian chen, xiaodan zhu, zhen-hua ling, si wei, huijiang, and diana inkpen.
2017. enhanced lstmin proceedings offor natural language inference.
the 55th annual meeting of the association for com-putational linguistics (volume 1: long papers),pages 1657–1668, vancouver, canada.
associationfor computational linguistics..alexis conneau, douwe kiela, holger schwenk, lo¨ıcbarrault, and antoine bordes.
2017. supervisedlearning of universal sentence representations fromnatural language inference data.
in proceedings ofthe 2017 conference on empirical methods in nat-ural language processing, pages 670–680, copen-hagen, denmark.
association for computationallinguistics..nicola de cao, michael sejr schlichtkrull, wilkeraziz, and ivan titov.
2020. how do decisionsemerge across layers in neural models?
interpreta-tion with differentiable masking.
in proceedings ofthe 2020 conference on empirical methods in nat-ural language processing (emnlp), pages 3243–3255, online.
association for computational lin-guistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..jay deyoung, sarthak jain, nazneen fatema rajani,eric lehman, caiming xiong, richard socher, andbyron c. wallace.
2020. eraser: a benchmark toevaluate rationalized nlp models.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics, pages 4443–4458, on-line.
association for computational linguistics..shi feng, eric wallace, alvin grissom ii, mohit iyyer,pedro rodriguez, and jordan boyd-graber.
2018.pathologies of neural models make interpretationsdifﬁcult.
in proceedings of the 2018 conference onempirical methods in natural language processing,pages 3719–3728, brussels, belgium.
associationfor computational linguistics..max glockner, vered shwartz, and yoav goldberg.
2018. breaking nli systems with sentences that re-in proceedings ofquire simple lexical inferences.
the 56th annual meeting of the association for com-putational linguistics (volume 2: short papers),.
5381pages 650–655, melbourne, australia.
associationfor computational linguistics..yichen gong, heng luo, and jian zhang.
2018. nat-ural language inference over interaction space.
in6th international conference on learning represen-tations, iclr 2018, vancouver, bc, canada, april30 - may 3, 2018, conference track proceedings.
openreview.net..christopher grimsley, elijah mayﬁeld, and juliar.s.
bursten.
2020. why attention is not expla-nation: surgical intervention and causal reasoningin proceedings of the 12thabout neural models.
language resources and evaluation conference,pages 1780–1790, marseille, france.
european lan-guage resources association..suchin gururangan, swabha swayamdipta, omerlevy, roy schwartz, samuel bowman, and noah a.smith.
2018. annotation artifacts in natural lan-in proceedings of the 2018guage inference data.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 2 (short papers),pages 107–112, new orleans, louisiana.
associa-tion for computational linguistics..sepp hochreiter and j¨urgen schmidhuber.
1997. longshort-term memory.
neural computation, 9:1735–80..alon jacovi and yoav goldberg.
2020. towards faith-fully interpretable nlp systems: how should we de-ﬁne and evaluate faithfulness?
in proceedings of the58th annual meeting of the association for compu-tational linguistics, pages 4198–4205, online.
as-sociation for computational linguistics..sarthak jain and byron c. wallace.
2019. attention isin proceedings of the 2019 con-not explanation.
ference of the north american chapter of the asso-ciation for computational linguistics: human lan-guage technologies, volume 1 (long and short pa-pers), pages 3543–3556, minneapolis, minnesota.
association for computational linguistics..sarthak jain, sarah wiegreffe, yuval pinter, and by-ron c. wallace.
2020. learning to faithfully rational-ize by construction.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 4459–4473, online.
associationfor computational linguistics..mandar joshi, eunsol choi, omer levy, daniel weld,and luke zettlemoyer.
2019. pair2vec: composi-tional word-pair embeddings for cross-sentence in-in proceedings of the 2019 conferenceference.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 3597–3608, minneapolis, minnesota.
associ-ation for computational linguistics..siwon kim, jihun yi, eunji kim, and sungroh yoon.
2020. interpretation of nlp models through inputin proceedings of the 2020 con-marginalization.
ference on empirical methods in natural languageprocessing (emnlp), pages 3154–3167, online.
as-sociation for computational linguistics..sawan kumar and partha talukdar.
2020. nile : natu-ral language inference with faithful natural languagein proceedings of the 58th annualexplanations.
meeting of the association for computational lin-guistics, pages 8730–8742, online.
association forcomputational linguistics..tao lei, regina barzilay, and tommi jaakkola.
2016.rationalizing neural predictions.
in proceedings ofthe 2016 conference on empirical methods in nat-ural language processing, pages 107–117, austin,texas.
association for computational linguistics..jiwei li, will monroe, and dan jurafsky.
2016. un-derstanding neural networks through representationerasure.
corr, abs/1612.08220..christos louizos, max welling, and diederik p.kingma.
2018a.
learning sparse neural networksthrough l 0 regularization.
in 6th international con-ference on learning representations, iclr 2018,vancouver, bc, canada, april 30 - may 3, 2018,conference track proceedings.
openreview.net..christos louizos, max welling, and diederik p.kingma.
2018b.
learning sparse neural networksthrough l 0 regularization.
in 6th international con-ference on learning representations, iclr 2018,vancouver, bc, canada, april 30 - may 3, 2018,conference track proceedings.
openreview.net..scott m. lundberg and su-in lee.
2017. a uniﬁedin ad-approach to interpreting model predictions.
vances in neural information processing systems30: annual conference on neural information pro-cessing systems 2017, december 4-9, 2017, longbeach, ca, usa, pages 4765–4774..bill maccartney, michel galley, and christopher d.manning.
2008. a phrase-based alignment modelin proceedings offor natural language inference.
the 2008 conference on empirical methods in natu-ral language processing, pages 802–811, honolulu,hawaii.
association for computational linguistics..bill maccartney, trond grenager, marie-catherinede marneffe, daniel cer, and christopher d. man-ning.
2006. learning to recognize features of validin proceedings of the humantextual entailments.
language technology conference of the naacl,main conference, pages 41–48, new york city,usa.
association for computational linguistics..bill maccartney and christopher d manning.
2009..natural language inference.
citeseer..chris j. maddison, andriy mnih, and yee whye teh.
2017. the concrete distribution: a continuous re-laxation of discrete random variables.
in 5th inter-national conference on learning representations,.
5382iclr 2017, toulon, france, april 24-26, 2017, con-ference track proceedings.
openreview.net..tom mccoy, ellie pavlick, and tal linzen.
2019.right for the wrong reasons: diagnosing syntacticheuristics in natural language inference.
in proceed-ings of the 57th annual meeting of the associationfor computational linguistics, pages 3428–3448,florence, italy.
association for computational lin-guistics..tim miller.
2019. explanation in artiﬁcial intelligence:insights from the social sciences.
artiﬁcial intelli-gence, 267:1 – 38..christoph molnar.
2020. interpretable machine learn-.
ing.
lulu.
com..jonas mueller and aditya thyagarajan.
2016. siameserecurrent architectures for learning sentence simi-in proceedings of the thirtieth aaai con-larity.
ference on artiﬁcial intelligence, february 12-17,2016, phoenix, arizona, usa, pages 2786–2792.
aaai press..w. james murdoch, peter j. liu, and bin yu.
2018.beyond word importance: contextual decomposi-tion to extract interactions from lstms.
in 6th inter-national conference on learning representations,iclr 2018, vancouver, bc, canada, april 30 - may3, 2018, conference track proceedings.
openre-view.net..liang pang, yanyan lan, jiafeng guo, jun xu, shengx-ian wan, and xueqi cheng.
2016. text matching asimage recognition.
in proceedings of the thirtiethaaai conference on artiﬁcial intelligence, febru-ary 12-17, 2016, phoenix, arizona, usa, pages2793–2799.
aaai press..ankur parikh, oscar t¨ackstr¨om, dipanjan das, andjakob uszkoreit.
2016. a decomposable attentionin proceed-model for natural language inference.
ings of the 2016 conference on empirical methodsin natural language processing, pages 2249–2255,austin, texas.
association for computational lin-guistics..john platt and alan barr.
1988. constrained differen-tial optimization.
in neural information processingsystems.
american institute of physics..adam poliak, jason naradowsky, aparajita haldar,rachel rudinger, and benjamin van durme.
2018.hypothesis only baselines in natural language in-in proceedings of the seventh joint con-ference.
ference on lexical and computational semantics,pages 180–191, new orleans, louisiana.
associa-tion for computational linguistics..marco t´ulio ribeiro, sameer singh, and carlosguestrin.
2016.
”why should i trust you?”: explain-in proceed-ing the predictions of any classiﬁer.
ings of the 22nd acm sigkdd international con-ference on knowledge discovery and data mining,san francisco, ca, usa, august 13-17, 2016, pages1135–1144.
acm..marco tulio ribeiro, tongshuang wu, carlos guestrin,and sameer singh.
2020. beyond accuracy: be-havioral testing of nlp models with checklist.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4902–4912, online.
association for computational lin-guistics..soﬁa serrano and noah a. smith.
2019. is attentionin proceedings of the 57th annualinterpretable?
meeting of the association for computational lin-guistics, pages 2931–2951, florence, italy.
associa-tion for computational linguistics..peng shi and jimmy lin.
2019. simple bert mod-els for relation extraction and semantic role labeling.
corr, abs/1904.05255..karen simonyan, andrea vedaldi, and andrew zisser-man.
2014. deep inside convolutional networks: vi-sualising image classiﬁcation models and saliencymaps..mukund sundararajan, ankur taly, and qiqi yan.
2017.in pro-axiomatic attribution for deep networks.
ceedings of the 34th international conference onmachine learning, icml 2017, sydney, nsw, aus-tralia, 6-11 august 2017, volume 70 of proceedingsof machine learning research, pages 3319–3328.
pmlr..kyle swanson, lili yu, and tao lei.
2020. rational-izing text matching: learning sparse alignments viain proceedings of the 58th an-optimal transport.
nual meeting of the association for computationallinguistics, pages 5609–5626, online.
associationfor computational linguistics..james.
andreas vlachos,.
and arpit mittal..christosthorne,christodoulopoulos,2019.generating token-level explanations for naturalin proceedings of the 2019language inference.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 1 (long and shortpapers), pages 963–969, minneapolis, minnesota.
association for computational linguistics..danish pruthi, mansi gupta, bhuwan dhingra, gra-ham neubig, and zachary c. lipton.
2020. learn-ing to deceive with attention-based explanations.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4782–4793, online.
association for computational lin-guistics..masatoshi tsuchiya.
2018..performance impactcaused by hidden bias of training data for recog-in proceedings of thenizing textual entailment.
eleventh international conference on language re-sources and evaluation (lrec 2018), miyazaki,japan.
european language resources association(elra)..5383shikhar vashishth, shyam upadhyay, gaurav singhatten-and manaal faruqui.
2019.tomar,corr,tion interpretability across nlp tasks.
abs/1909.11218..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in advances in neural information pro-cessing systems 30: annual conference on neuralinformation processing systems 2017, december 4-9, 2017, long beach, ca, usa, pages 5998–6008..zhiguo wang, wael hamza, and radu florian.
2017.bilateral multi-perspective matching for natural lan-guage sentences.
in proceedings of the twenty-sixthinternational joint conference on artiﬁcial intelli-gence, ijcai 2017, melbourne, australia, august19-25, 2017, pages 4144–4150.
ijcai.org..adina williams, nikita nangia, and samuel bowman.
2018. a broad-coverage challenge corpus for sen-tence understanding through inference.
in proceed-ings of the 2018 conference of the north americanchapter of the association for computational lin-guistics: human language technologies, volume1 (long papers), pages 1112–1122, new orleans,louisiana.
association for computational linguis-tics..xiang yu, ngoc thang vu, and jonas kuhn.
2019.learning the dyck language with attention-basedseq2seq models.
in proceedings of the 2019 aclworkshop blackboxnlp: analyzing and interpretingneural networks for nlp, pages 138–146, florence,italy.
association for computational linguistics..thomas zenkel, joern wuebker, and john denero.
2020. end-to-end neural word alignment outper-forms giza++.
in proceedings of the 58th annualmeeting of the association for computational lin-guistics, pages 1605–1617, online.
association forcomputational linguistics..die zhang, huilin zhou, xiaoyi bao, da huo, ruizhaochen, xu cheng, hao zhang, mengyue wu, andquanshi zhang.
2020. interpreting hierarchical lin-guistic interactions in dnns..a the hardconcrete distribution.
the hardconcrete distribution (louizos et al.,2018b) is derived from the binary concrete dis-tribution (maddison et al., 2017) using stretch andrectify, assigning probability densities on the closeunit interval [0, 1].
the concrete distribution is acontinuous relaxation of categorical distributionand submissive for reparameterization (gumbel-softmax trick) (maddison et al., 2017).
we onlyintroduce the special binary case here for concise-ness..figure 5: stretch and rectify process of binary concretedistribution.
the binary concrete pdf is stretchedfrom (0,1) to (-0.1, 1,1).
red and blue regions areprobability masses that the binary hardconcrete vari-able equals 0 and 1 separately..a binary concrete variable ˆz could be sampledby ﬁrst sampling u ∼ u(0, 1), and conducting thefollowing transformations.
l = log u − log(1 − u )ˆz = σ(log α + l)/τ ).
(14).
where σ is sigmoid function, α and τ are parame-ters of ˆz, where the latter one is called temperaturecontroling the sharpness.
in practice, log α is usu-ally the logit outputted by a classiﬁer, e.g., a neuralnetwork.
the probability density function (pdf)and the cumulative distribution function (cdf) ofz is.
p ˆz(z) =.
τ αz−τ −1(1 − z)−τ −1(αz−τ + (1 − z)−τ )2q ˆz(z) = σ((log z − log(1 − z))τ − log α).
(15)however, we are about to generate binary masksas our rationales, implying word alignment appear-ances.
that is, we require z remains some discreteproperties, allowing us to sample the exact 0 and1. for this purpose, louizos et al.
(2018b) intro-duces stretch and rectify strategy.
as illustrated infigure 5, the binary concrete pdf is ﬁrst stretchedto support (γ, ζ), where γ < 0 and ζ > 1, via ascaling transformation, then we rectify densities onthe close unit interval.
z = min(1, max(0, γ + (ζ − γ) ˆz)).
(16).
where γ, ζ and τ are hyperparameters and we set-0.1, 1.1 and 0.2 respectively.
transformations in.
5384-0.1011.1z0123456p(z)binary concrete pdfstretched binary concrete pdfequation (14) and equation (16) compose g inequation (8).
now, we have.
note that we optimize l1’s upper bound instead ofitself.
for l2, we have.
p(z = 0) = p.0 < ˆz ≤.
(cid:18).
(cid:19).
γγ − ζ.
(cid:18) γ.
(cid:19).
= q ˆz(cid:18).
γ − ζ(cid:18).
(cid:19).
γζ.
= σ.τ log.
−.
− log α.
(17).
(cid:19).
and.
p(z = 1) = p.(cid:18) 1 − γζ − γ.
(cid:19).
≤ ˆz < 1.
(cid:19).
(cid:18) 1 − γζ − γ.
= 1 − q ˆz(cid:18).
= σ.log α − τ log.
(18).
(cid:19)(cid:19).
(cid:18) 1 − γζ − γ.b loss derivation.
(cid:88).
e.l2 =.
1.
.
.
1.
.
.
p.i,j.
(cid:88).
i,j(cid:88).
=.
=.
(cid:100)z(cid:101) = 3.
.
.
.
.
.
.
(cid:100)z(cid:101) = 3.
.
.
(cid:88).
z∈wi,j.
(cid:88).
z∈wi,j.
(cid:88).
p(z = 0).
i,j.
z∈wzi,j.
(cid:19).
γζ.
(cid:89).
(1 − p(z(cid:48) = 0)).
z(cid:48)∈wzi,j \{z}(cid:18).
σ.τ log.
−.
− log α.
(cid:18).
(cid:19).
γζ.
(cid:88).
(cid:88).
=.
i,j.
α∈wαi,j.
(cid:89).
(cid:18).
σ.log α(cid:48) − τ log.
−.
(cid:18).
(cid:19)(cid:19).
α(cid:48)∈wα.
i,j \{α}.
(20)optimizing l1 and l2 is directly since we don’tneed to sample.
now the loss functions are dif-ferential about α, allowing us to process gradientdescent.
in the implementation, we actually opti-mize over log α because it’s a free variable..c alignment diffmask baseline.
diffmask utilizes a neural network to obtainlog α on input representations, and optimizes theneural network on a training set.
in the originalimplementation (de cao et al., 2020), the neuralnetwork is feed with word vectors from differentlayers.
to make it be on alignment level, log α iscomputed on alignment features.
where ffn is a feed forward neural networkwith one hidden layer and ; means concatenation.
word representations pi and hj are the input in-contextualized word vectors.
the subsequent stepsare similar to arec, except that diffmask istrained on a traning set, leveraging data knowledge..d alignment plausibility human.
according to the above basis, for l1, we have.
log αi,j = ffn([pi; hj; pi − hj; pi (cid:12) hj]) (21).
l1 =.
e(zi,j).
p(zi,j = 1) +.
zpzi,j (z)dz.
(cid:90) 1.
(cid:90) 1.
0.
0.
(cid:88).
i,j.
(cid:88).
i,j.
(cid:88).
i,j(cid:88).
i,j.
(cid:88).
i,j.
=.
≤.
=.
=.
p(zi,j = 1) +.
fzi,j (z)dz.
(19).
evaluation.
(1 − p(zi,j = 0)).
(cid:18).
σ.log αi,j − τ log.
−.
(cid:18).
(cid:19)(cid:19).
γζ.the principle of manual evaluation is that the deci-sion process observed by arec is agreed with hu-mans when it includes complete alignment informa-tion for the correct prediction.
thus, an alignmentrationale could not agree with humans even instruct.
5385figure 6: an example labeled entailment in hans,where the alignment rationale is extracted from da.
the alignment rationale is not agreed with humanswhile allowing humans to reach the correct prediction..humans to arrive the correct prediction.
this is dif-ferent from human accuracy (jain et al., 2020).
figure 6 presents an example.
from the alignmentrationale, a human is able to predict entailmentwith identical nouns professor – professorand lawyer – lawyer.
however, as a human,we also need to identify the predicate pair saw –saw for complete semantics.
thus, we consideralignment rationales like in figure 6 are not agreedwith human justiﬁcations..e visualization.
we plot a few examples of arec explanations infigure 7. we also present examples of differentalignment explanations in figure 8. it’s clear thatour proposed arec explanation is the most read-able one..(a) da.
(b) esim.
(c) bert.
figure 7: arec explanation examples..5386theprofessorinfrontofthebankerssawthelawyer.theprofessorsawthelawyer.boysittinglookingthroughaglasswindowatatrainstation.aboyissittingatatrainstation.ayoungboyingreenispracticingkicking.theyoungboyiswearingblackboysittinglookingthroughaglasswindowatatrainstation.aboyissittingatatrainstation.ayoungboyingreenispracticingkicking.theyoungboyiswearingblackboysittinglookingthroughaglasswindowatatrainstation.aboyissittingatatrainstation.ayoungboyingreenispracticingkicking.theyoungboyiswearingblack(a) co-attention.
(b) leaveoneout.
(c) backselect.
(d) lime.
(e) gradient.
(f) integratgrad.
(g) diffmask.
(h) arec (ours).
figure 8: visualization of different alignment explanations.
all the explanations are generated from bert.
forattribution explanations (a) - (f), we plot attribution maps (left) and induced rationales (right).
for rationale expla-nations (g) and (h), we plot parameters α (left) and rationales (right)..5387passengersinarustyyellowcardrivingdownthestreet.peoplewalkthroughastore.peoplewalkthroughastore.passengersinarustyyellowcardrivingdownthestreet.peoplewalkthroughastore.peoplewalkthroughastore.passengersinarustyyellowcardrivingdownthestreet.peoplewalkthroughastore.peoplewalkthroughastore.passengersinarustyyellowcardrivingdownthestreet.peoplewalkthroughastore.peoplewalkthroughastore.passengersinarustyyellowcardrivingdownthestreet.peoplewalkthroughastore.peoplewalkthroughastore.passengersinarustyyellowcardrivingdownthestreet.peoplewalkthroughastore.peoplewalkthroughastore.passengersinarustyyellowcardrivingdownthestreet.peoplewalkthroughastore.peoplewalkthroughastore.passengersinarustyyellowcardrivingdownthestreet.peoplewalkthroughastore.peoplewalkthroughastore.