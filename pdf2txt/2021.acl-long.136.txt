discovering dialog structure graph for coherent dialog generation.
jun xu1.
∗, haifeng wang2, zheng-yu niu2, hua wu2, wanxiang che1.
∗, zeyang lei21research center for social computing and information retrieval,harbin institute of technology, harbin, china2baidu inc., beijing, china.
†.
jxu, car}.
{.
@ir.hit.edu.cn,.
leizeyang, wanghaifeng, niuzhengyu, wu hua@baidu.com{}.
abstract.
learning discrete dialog structure graph fromhuman-human dialogs yields basic insightsinto the structure of conversation, and also pro-vides background knowledge to facilitate dia-log generation.
however, this problem is lessstudied in open-domain dialogue.
in this pa-per, we conduct unsupervised discovery ofdiscrete dialog structure from chitchat cor-pora, and then leverage it to facilitate coher-ent dialog generation in downstream systems.
to this end, we present an unsupervised model,discrete variational auto-encoder with graphneural network (dvae-gnn), to discoverdiscrete hierarchical latent dialog states (at thelevel of both session and utterance) and theirtransitions from corpus as a dialog structuregraph.
then we leverage it as backgroundknowledge to facilitate dialog management ina rl based dialog system.
experimental re-sults on two benchmark corpora conﬁrm thatdvae-gnn can discover meaningful dialogstructure graph, and the use of dialog structureas background knowledge can signiﬁcantly im-prove multi-turn coherence..1.introduction.
with the aim of building a machine to conversewith humans naturally, some work investigate neu-ral generative models (shang et al., 2015; serbanet al., 2017).
while these models can generate lo-cally relevant dialogs, they struggle to organize in-dividual utterances into globally coherent ﬂow (yuet al., 2016; xu et al., 2020b).
the possible reasonis that it is difﬁcult to control the overall dialogﬂow without background knowledge about dialogstructure.1 however, due to the complexity of open-domain conversation, it is laborious and costly toannotate dialog structure manually.
therefore, it is.
∗equal contribution.
† corresponding author: wanxiang che.
1dialog structure means dialog states and their transitions..of great importance to discover open-domain dia-log structure from corpus in an unsupervised wayfor coherent dialog generation..some studies tried to discover dialog structurefrom task-oriented dialogs (shi et al., 2019).
how-ever, the number of their dialog states is limited toonly dozens or hundreds, which cannot cover ﬁne-grained semantics in open-domain dialogs.
fur-thermore, the dialog structures they discoveredgenerally only contain utterance-level semantics(non-hierarchical), without session-level semantics(chatting topics) that are essential in open-domaindialogs (wu et al., 2019; kang et al., 2019; xuet al., 2020c).2 thus, in order to provide a full pic-ture of open-domain dialog structure, it is desirableto discover a two-layer directed graph that containssession-level semantics in the upper-layer vertices,utterance-level semantics in the lower-layer ver-tices, and edges among these vertices..in this paper, we propose a novel discrete vari-ational auto-encoder with graph neural network(dvae-gnn) to discover a two-layer dialog struc-ture from chitchat corpus.
intuitively, since dis-crete dialog states are easier to capture transitionsfor dialog coherence, we use discrete variables torepresent dialog states (or vertices in the graph)rather than dense continuous ones in most vae-based dialog models (serban et al., 2017; zhaoet al., 2017).
speciﬁcally, we employ an rnn en-coder with softmax function as vertex recognitionmodule in dvae, and an rnn decoder as recon-struction module in dvae, as shown in figure3. furthermore, we integrate gnn into dvae tomodel complex relations among discrete variablesfor more effective discovery.
the parameters ofdvae-gnn can be optimized by minimizing a re-construction loss, without the requirement of anyannotated datasets..2a session refers to a dialog fragment about one topic..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1726–1739august1–6,2021.©2021associationforcomputationallinguistics1726figure 1: the procedure of dialog structure discovery.
figure (d) shows the discovered dialog structure graph..ture graph discovery.
experimental results on twobenchmark corpora demonstrate that we can dis-cover meaningful dialog structure, the use of gnnis crucial to dialog structure discovery, and thegraph can improve dialog coherence signiﬁcantly..2 related work.
2.1 dialog structure learning for.
task-oriented dialogs.
there are previous work on discovering human-readable dialog structure for task-oriented dialogsvia hidden markov models (chotimongkol, 2008;ritter et al., 2010; zhai and williams, 2014) orvariational auto-encoder (shi et al., 2019).
how-ever, the number of their dialog states is limitedto only dozens or hundreds, which cannot coverﬁne-grained semantics in chitchat.
moreover, ourmethod can discover a hierarchical dialog structure,which is different from the non-hierarchical dialogstructures in most previous work..2.2 knowledge aware conversation.
generation.
there are growing interests in leveraging knowl-edge bases for generation of more informative re-sponses (moghe et al., 2018; dinan et al., 2019;liu et al., 2019; xu et al., 2020c,a).
in this work,we employ a dialog-modeling oriented graph builtfrom dialog corpora, instead of a external knowl-edge base, in order to facilitate multi-turn dialogmodeling..2.3 latent variable models for chitchat.
recently, latent variables are utilized to improvediversity (serban et al., 2017; zhao et al., 2017; guet al., 2019; gao et al., 2019; ghandeharioun et al.,2019), control responding styles (zhao et al., 2018;li et al., 2020) and incorporate knowledge (kimet al., 2020) in dialogs.
our work differs from.
4ai.baidu.com/tech/nlp basic/dependency parsing.
figure 2: response generation grounded on a dialogstructure graph..as shown in figure 1, with well-trained dvae-gnn, we build the dialog structure graph bythree steps.
first, we map all dialog sessionsto utterance-level and session-level vertices, asshown in figure 1 (b); second, we calculate co-occurrence statistics of mapped vertices for all dia-log sessions, as shown in figure 1 (c).3 finally, webuild edges among vertices based on all collectedco-occurrence statistics to form the dialog structuregraph, as shown in figure 1 (d)..to prove the effectiveness of the discoveredstructure, we propose a hierarchical reinforcementlearning (rl) based graph grounded conversationalsystem (gcs) to leverage it for conversation gener-ation.
as shown in figure 2, given a dialog context,gcs ﬁrst maps it to a utterance-level vertex, andthen learns to walk over graph edges, and ﬁnally se-lects a contextual appropriate utterance-level vertexto guide response generation at each turn..our contribution includes: (1) we identify thetask of unsupervised dialog structure graph discov-ery in open-domain dialogs.
(2) we propose a novelmodel, dvae-gnn, for hierarchical dialog struc-.
3co-occurrence means that two utterance-level vertices are.
mapped by two adjacent utterances in a session..172713346725121334672512session-level semantic vertexutterance-level semantic vertex(b) map each dialog session to vertices (c) collect co-occurrence statistics of mapped vertices for all dialog sessions(d) build edges between vertices to form dialog structure graph(a) a set of dialog sessions1334672512找到房子了么have you found a place to live?13472512session-level semantic vertexutterance-level semantic vertex3speak1:嗯，我提前订好了酒店。[yes, i have booked a hotel in advance.
]speak1: 假期准备去爬黄山[i’m going to climb huangshan mountain on holiday.]speak2:哇！准备在山上找房子过夜么？[wow!
are you going to find a house on the mountain for the night?
]contextresponse有时间找我玩visitmewhenyou are free好久没见你haven't seen you for a long time明天去长沙go to changsha tomorrow预定了酒店have booked a hotel roomone co-occurrence of two verticesedge6找到房子了么have you found a place to live?预定了酒店have booked a hotel roomphrase associated with utterance-level vertex放假来找我玩啊[let’s take vacations together.
]我明天准备去长沙上班[i’ll go to changsha tomorrow]好啊，好久没见面了[yep, long time no see]……你租房子了么[oh, have you rent a room yet?
]……放假来找我玩啊[let’s take vacations together.
]好啊，好久没见面了[yep, long time no see]我明天准备去长沙上班[i’ll go to changsha tomorrow]你租房子了么[oh, have you rent a room yet?
]1334672512……1334672512session-level semantic vertexutterance-level semantic vertex……(b) map each dialog session to vertices (c) collect co-occurrence statistics of mapped vertices for all dialog sessions(d) build edges between vertices to form dialog structure graph(a) a set of dialog sessions1334672512找到房子了么have you found a place to live?13472512session-level semantic vertexutterance-level semantic vertex3speak1:嗯，我提前订好了酒店。[yes, i have booked a hotel in advance.
]speak1: 假期准备去爬黄山[i’m going to climb huangshan mountain on holiday.]speak2:哇！准备在山上找房子过夜么？[wow!
are you going to find a house on the mountain for the night?
]contextresponse有时间找我玩visitmewhenyou are free好久没见你haven't seen you for a long time明天去长沙go to changsha tomorrow预定了酒店have booked a hotel roomone co-occurrence of two verticesedge6找到房子了么have you found a place to live?预定了酒店have booked a hotel roomphrase associated with utterance-level vertexfigure 3: overview of our algorithm “dvae-gnn” for discovering a dialog structure graph from dialog dataset.
ffn denotes feed-forword neural networks and emb refers to embedding layers.
algorithm 1 phrase extractioninput: an utterance uoutput: a set of phrases e extracted from u1: obtain a dependency parse tree t for u ;42: get all the head words hed that are connected to root.
node, and all the leaf nodes in t (denoted as l);.
3: for each leaf node in |l| do4:.
extract a phrase consisting of words along the treefrom hed to current leaf node, denoted as ei;if ei is a verb phrase, then append it into e;.
5:6: end for7: return e.theirs in that: (1) we focus on open-domain dia-log structure discovery.
(2) we use discrete latentvariables to model dialog states instead of densecontinuous ones in most previous work..3 our approach.
3.1 problem deﬁnition.
|.
,.
d.|}.
{v.d|.
given a corpus d that containsdialog sessions|, where each dialog session xx1, x2, ..., x{consists of a sequence of c utterances, and x =[x1, ..., xc].
the objective is to discover a two-layerfrom all dialog=dialog structure graphge}sessions in d, whereis theis the vertex set andvconsists of two types, vsedge set.
speciﬁcally,mm ) for session-level vertices (topics)m(1≤≤and vun ) for utterance-level vertices.
n (1contains three types: edges between two session-elevel vertices (denoted as sess-sess edges), edgesbetween two utterance-level vertices (denoted asutter-utter edges), and edges between an utterance-level vertex and its parent session-level vertices(denoted as sess-utter edges)..≤.
≤.
v.n.e.figure 3 shows the proposed dvae-gnn frame-work.
it contains two procedures, vertex recogni-tion that maps utterances and sessions to vertices.
(as the role of recognition module in vae (kingmaand welling, 2014)), and utterance reconstructionthat regenerates all utterances in sessions (as therole of decoding module in vae)..3.2 graph initialization.
vertex initialization.
theoretically, we can coldstart the representation learning of vertices in dia-log structure graph.
in practice, to accelerate thelearning procedure, we warm start each utterance-level vertex representation with the combinationof two parts: one discrete latent variable andone distinct phrase.
the associated phrase witheach utterance-level vertex provides prior seman-tic knowledge for utterance-level vertex represen-tation, which is beneﬁcial for reducing the learn-ing difﬁculty.
speciﬁcally, we ﬁrst extract distinctphrases from all dialog utterances with algorithm 1.then we choose the top-n most frequent extractedphrases (the same number as utterance-level ver-tices), and then randomly match utterance-levelvertices and the phrases in pairs during initializa-tion.
notice that the association relations are notchanged afterwards..formally, we use λs and λx to represent thehidden representation matrix of discrete session-level and utterance-level vertices respectively.
thecalculation can be shown as follows:.
λs[m] = w svsmλx[n] = [e(phn); w uvun],.
(1).
(2).
where λs[m] denotes the representation vector ofm-th session-level vertex, λx[n] denotes the rep-resentation vector of n-th utterance-level vertex,vsm and vun are one-hot vectors of discrete vertices,e(phn) denotes the representation vector of the.
1728放假过来找我玩啊[let‘sgatheronholiday]好啊，好久没见面了[yep, long time no see]我明天准备去长沙上班[i’ll go to changsha tomorrow]你租房子了么[oh, have you rent a room yet?
]embeddingspaceofutterance-levelsemanticverticesembeddingspaceofsession-levelsemanticvertices……放假过来找我玩啊[let‘sgatheronholiday]好啊，好久没见面了[yep, long time no see]我明天准备去长沙上班[i’ll go to changsha tomorrow]你租房子了么[oh, have you rent a room yet?
]rnnencoderffnrnndecoder11234embdvae:vertex recognitionprocedurevectorsofsession-levelsemanticverticesvectorsofutterance-levelsemanticverticesvectorsofutterancephrases1334672512dvae:utterancereconstructionproceduregnnassociated phrase phn with vun, w u and w s areparameters, and “;” denotes concatenation opera-tion.
speciﬁcally, for phrase representation, weﬁrst feed word sequence in the phrase to an rnnencoder and obtain their hidden vectors.
then wecompute the average pooling value of these hiddenvectors as e(phn).
edge initialization we build an initial utter-utteredge between two utterance-level vertices whentheir associated phrases can be extracted sequen-tially from two adjacent utterances in the samedialog session..3.3 vertex recognition.
utterance-level vertex recognition.
for each ut-terance xi in a dialog session, we map it to anutterance-level vertex.
speciﬁcally, we ﬁrst encodethe utterance xi with an rnn encoder to obtain itsrepresentation vector e(xi).
then, we calculate theposterior distribution of the mapped utterance-levelvertex, zi, by a feed-forward neural network (ffn):.
zi ∼.
q(z.xi) = softmax(λxe(xi)).
|.
(3).
finally, we obtain the mapped utterance-levelvertex, zi, by sampling from the posterior distri-bution with gumbel-softmax (jang et al., 2017).
here, we can obtain an utterance-level vertex se-quence after mapping each utterance in one dialogsession, where the sequence is utilized for session-level vertex recognition.
session-level vertex recognition.
we assumethat each session-level vertex corresponds to agroup of similar utterance-level vertex sequencesthat are mapped by different dialog sessions.
andthese similar sequences might have overlappedutterance-level vertices.
to leverage this lo-cally overlapping vertex information for encour-aging mapping similar utterance-level vertex se-quences to similar session-level vertices, we em-ploy graph neural network to model complex rela-tions among vertices for session-level vertex recog-nition.
speciﬁcally, we utilize a three-layer graphconvolution network (gcn) over utter-utter edgesto calculate structure-aware utterance-level seman-tics.
the calculation is deﬁned by:.
hjvun.= σj(.
1.hj−vun(cid:48).
),.
(4).
(cid:88)vun(cid:48) ∈n.
(vun).
where hjdenotes the j-th layer structure-awarevunrepresentation for the n-th utterance-level vertex.
, h3vuzi.
, ..., h3vuzc.
vun. σj is the sigmoid activation function for(vun) is the set of utterance-the j-th layer, andnlevel neighbors of vun in the graph.
here, wecan obtain a structure-aware semantic sequence], where h3[h3represents the ﬁ-vuvuziz1nal structure-aware representation of i-th mappedutterance-level vertex, vuzi.
then, we feed the structure-aware semantic se-quence to an rnn encoder, denoted as the vertex-sequence encoder, to obtain the structure-awaresession representation e(z1,...,c).
we calculate theposterior distribution of the mapped session-levelvertex, g, as follows:.
g.q(g.z1,...,c) = softmax(λse(z1,...,c)).
|.
∼.
(5).
then, we obtain the mapped session-level vertex,g, by sampling from the session-level posteriordistribution with gumbel-softmax..3.4 utterance reconstruction.
we reconstruct all utterances in the dialog sessionby feeding these mapped vertices into an rnndecoder (denoted as the reconstruction decoder).
speciﬁcally, to regenerate utterance xi, we concate-nate the representation vector of mapped utterance-level vertex λx[zi] and the representation vectorof the mapped session-level vertex λs[g], as theinitial hidden state of the reconstruction decoder..finally, we optimize the dvae-gnn model bymaximizing the variational lower-bound (elbo)(kingma and welling, 2014).
please refer to ap-pendix d for more details..3.5 graph construction.
after training dvae-gnn, we construct the dialogstructure graph with well-trained dvae-gnn bythree steps, as shown in figure 1. speciﬁcally, weﬁrst map all dialog sessions in corpus to verticesby equation 3 and 5..then, we collect co-occurrence statistics of thesemapped vertices.
speciﬁcally, we count the totalmapped times for each session-level vertex, de-noted as #(vsi ), and those for each utterance-levelvertex, denoted as #(vuj ).
furthermore, we collectthe co-occurrence frequency of a session-level ver-tex and an utterance-level vertex that are mappedby a dialog session and an utterance in it respec-i , vutively, denoted as #(vsj ).
moreover, we collectthe co-occurrence frequency of two utterance-levelvertices that are sequentially mapped by two ad-jacent utterances in a dialog session, denoted as#(vu.
j , vuk )..1729j to vuk )/#(vu.
finally, we build edges between vertices basedon these co-occurrence statistics.
we ﬁrst build a di-rected utter-utter edge from vuk if the bi-gramtransition probability #(vuj , vuj ) is above athreshold αuu.
then, we build a bidirectional sess-utter edge between vuj and vsk if the probability#(vsj ) is above a threshold αsu.
more-j )/#(vuover, we build a directed sess-sess edge from vsii ) is above a threshold αss,to vsi , vswhere the ﬁrst item #(vso) is the number ofutterance-level vertices that are connected to bothsession-level vertices.
here, sess-sess edges aredependent on sess-utter edges..o, if #(vs.o)/#(vs.i , vu.
i , vs.3.6 graph grounded dialog generation.
to prove the effectiveness of the discovered struc-ture for coherent dialog generation, we utilize agraph grounded conversation system (gcs) follow-ing (xu et al., 2020a).
different from single-layerpolicy in xu et al.
(xu et al., 2020a), we present ahierarchical policy for two-level vertex selection.
the gcs contains three modules: (1) a dialogcontext understanding module that maps given di-alog context (the previous two utterances) to anutterance-level vertex (called as hit utterance-levelvertex) in the graph with well-trained dvae-gnn,(2) a hierarchical policy that learns to walk overone-hop graph edges (for dialog coherence) to se-lect an utterance-level vertex to serve as responsecontent, and (3) a response generator that gener-ate an appropriate response based on the selectedutterance-level vertex.
speciﬁcally, a session-levelsub-policy ﬁrst selects a session-level vertex ascurrent dialog topic.
then, an utterance-level sub-policy selects an utterance-level vertex from currentdialog topic’s child utterance-level vertices..a.session-level sub-policy let.
gsl denote the setof session-level candidate actions at time step l. itconsists of all parent session-level vertices of thehit utterance-level vertex.
given current rl statesl at the time step l, the session-level sub-policyµg selects an appropriate session-level vertex fromgsl as the current dialog topic.
speciﬁcally, µg is.
aformalized as follows:.
µg(sl, vscgj.)
=.
t λs[cg.
exp(esln gk=1 exp(esll.j ])t λs[cg.
k]).
,.
(cid:80).
where esl is the aforementioned rl state represen-tation, cggj the j-th session-level vertex insl, andgn gis the number of session-level vertices insl.
luutterance-level sub-policy letsl denote theaset of utterance-level candidate actions at time step.
a.a.l. it consists of utterance-level vertices that are con-nected to the vertex of current dialog topic.
givencurrent state sl at the time step l, the utterance-level sub-policy µu selects an optimal utterance-sl.
speciﬁcally, µu is deﬁnedulevel vertex fromaas follows:.
µu(sl, vucuj.)
=.
exp(esln uk=1 exp(esll.t λx[cu.
j ])t λx[cu.
k]).
..(cid:80).
a.here, esl is the aforementioned rl state rep-resentation, cuj is the j-th utterance-level vertexsl, and n uuis the number of utterance-levelinlucandidate vertices insl.
with the distribution cal-culated by the above equation, we utilize gumbel-softmax to sample an utterance-level vertex fromusl, to provide response content for response gen-aerator, which is a seq2seq model with attentionmechanism..a.to train rl, we use a set of rewards includingutterance relevance, utter-topic closeness, and rep-etition penalty.
for the session-level sub-policy, itsreward rg is the average rewards from the utterance-level sub-policy during current dialog topic.
thereward for the utterance-level sub-policy, ru, is aweighted sum of the below-mentioned factors.
thedefault values of weights are set as [60, 0.5, -0.5].
5.i) utterance relevance we choose the classi-cal multi-turn response selection model, dam in(zhou et al., 2018), to calculate utterance relevance.
we expect the generated response is coherent todialog context..ii) utter-topic closeness the selected utterance-j should be closely related to currenti , vuj ) in sec-.
level vertex vutopic vsj )/#(vution 3.5 as the utter-topic closeness score..i .
and we use the #(vs.iii) repetition penalty this factor is 1 whenthe selected utterance-level vertex shares more than60% words with one of contextual utterance, other-wise 0. we expect that the selected utterance-levelvertices are not only coherent, but also diverse..further implementation details can be found in.
the appendix c..4 experiments for dialog structure.
graph discovery.
4.1 datasets and baselines.
we evaluate the quality of dialog structure graphdiscovered by our method and baselines on two.
5we optimize these weights by grid search..1730datasets methods.
automatic evaluation.
weibo.
douban dvrnn.
dvrnnphrase graphdvae-gnndvae-gnn w/o gnndvae-gnn w/o phrase.
phrase graphdvae-gnndvae-gnn w/o gnndvae-gnn w/o phrase.
nll.
bleu-1/2..29.187-20.96923.36424.28272.744-35.97537.41549.606.
0.427/0.322-/-0.588/0.4550.560/0.4290.468/0.3550.124/0.093-/-0.525/0.4120.504/0.3940.254/0.206.
s-u appr.
(multi-turncoherence)--0.850.530.43--0.600.380.28.human evaluationu-u appr.
(single-turncoherence)0.160.630.790.780.270.140.340.700.540.19.sess.v.-qual.
(multi-turncoherence)--1.441.060.95--0.930.480.27.table 1: evaluation results for dialog structure graphs extracted from weibo corpus or douban corpus.
as dvrnnlearns only utterance-level states, its results in terms of s-u appr.
and sess.v.-qual.
are not available..benchmark datasets: (1) weibo (li and yan, 2018):this is a chinese multi-turn tweet-style corpora.
af-ter data cleaning, we obtain 3.1 million sessionsfor training, 10k sessions for validation and 10ksessions for testing.
(2) douban (wu et al., 2017):we use the original multi-turn dialog corpus, andobtain 2.3 million sessions for training, 10k ses-sions for validation and 10k sessions for testing.
for the weibo or douban corpus, each dialog ses-sion has 4 sentences on average, and each sentencecontains about 7 or 14 words respectively.
thediscovered dialog structure graph on weibo corpuscontains 1,641,238 utterance-level vertices, 6000session-level vertices and 11,561,007 edges.
andthe discovered dialog structure graph on doubancorpus contains 1,768,720 utterance-level vertices,5500 session-level vertices and 6,117,159 edges.
the number of utterance-level vertices is equal tothe number of extracted phrase number in corpusand session-level vertices is determined by gridsearch based on the nll metric in section 4.2..in this work, we select dvrnn (shi et al., 2019)as a baseline, since there is few previous study onunsupervised open-domain dialog structure discov-ery.
dvrnn is the sota unsupervised methodin discovering dialog structure in task-oriented di-alogs, which outperforms other hidden markovbased methods by a large margin (shi et al., 2019).
we rerun the original source codes.6 notice that,to suite the setting of open-domain dialog and alsoconsider the limit of our 16g gpu memory (we setbatch size as 32 to ensure training efﬁciency), we.
6github.com/wyshi/unsupervised-structure-learning.
set the number of dialog states as 50 (originally itis 10).7 we also evaluate the quality of the initial-ized graph (denoted as phrase graph) that consistsof only phrases (as vertices) and initial edges (be-tween phrases) in section 3.2. for more details,please refer to appendix a.1..4.2 evaluation metrics.
we evaluate discovered dialog structure graph withboth automatic evaluation and human evaluation.
for automatic evaluation, we use two metrics toevaluate the performance of reconstruction: (1)nll is the negative log likelihood of dialog ut-terances; (2) bleu-1/2 measures how much thatreconstructed sentences contains 1/2-gram overlapswith input sentences (papineni et al., 2002).
thetwo metrics indicate how well the learned dialogstructure graph can capture important semantic in-formation in dialog dataset..for multi-turn dialog coherence..further, we manually evaluate the quality ofedges and vertices in the graph.
for edges, (1)s-u appr.
itmeasures the appropriateness of sess-utter edges,where these edges provide crucial prior informationto ensure multi-turn dialog coherence (see resultsin section 5.4).
“1” if an utterance-level vertexis relevant to its session-level vertex (topic), oth-erwise “0”.
(2) u-u appr.
for single-turn dialogcoherence: it measures the quality of utter-utteredges between two utterance-level vertices, wherethese edges provide crucial prior information to.
7we ever tried to modify their codes to support the learn-ing of a large number of dialog states (up to 30k).
but itsperformance is even worse than original code with 50 states..1731ensure single-turn dialog coherence.
it is “1” if anutter-utter edge is suitable for responding, other-wise “0”.
notice that we don’t evaluate the qualityof sess-sess edges because sess-sess edges aredependent on the statistics of sess-utter edges..meanwhile, for vertices, we evaluate session-level vertex quality (sess.v.-qual.).
ideally, asession-level vertex (topic) should be mapped bydialog sessions that share high similarity.
in otherwords, we can measure the quality of a session-level vertex by evaluating the similarity of seman-tics between two sessions that are mapped to it.
it is“2” if the two sessions mapped to the same session-level vertex are about the same or highly similartopic, ”0” if the two sessions contains differenttopic, otherwise “1”.
speciﬁcally, during evalu-ation, we provide typical words of each topic bycalculating tf-idf on utterances that are mappedto it.
high “sess.v.-qual.” is beneﬁcial to conducttopic management for coherent multi-turn dialogs.
note that we don’t evaluate utterance-level vertexquality since it is too ﬁne-grained for annotators todetermine whether two utterances that are mappedto a utterance-level vertex are “highly-similar”..for human evaluation, we sample 300 cases andinvite three annotators from a crowd-sourcing plat-form to evaluate each case.8 notice that all systemidentiﬁers are masked during human evaluation..4.3 experiment results.
as shown in table 1, dvae-gnn signiﬁcantly out-performs dvrnn, in terms of all the metrics (signtest, p-value < 0.01) on the two datasets.
it demon-strates that dvae-gnn can better discover mean-ingful dialog structure graph.
speciﬁcally, dvae-gnn obtains the best results in terms of nll andbleu-1/2, which shows that dvae-gnn can bet-ter capture important semantic information in com-parison with dvrnn.
meanwhile, dvae-gnnalso surpasses all baselines in terms of “u-u appr.”and “s-u appr.”.
it indicates that our discovereddialog structure graph has higher-quality edges andcan better facilitate coherent dialog generation..furthermore, we conduct ablation study.
specif-ically, to evaluate the contribution of gnn, weremove gnn from dvae-gnn, denoted as dvae-gnn w/o gnn.
we see that its performance dropsharply in terms of “s-u appr.” and “sess.v.-qual.”.
it demonstrates that gnn can better incor-porate the structure information (complex relations.
8test.baidu.com.
among vertices) into session-level vertex represen-tation learning.
moreover, to evaluate the contribu-tion of phrases to utterance-level vertex representa-tion, we remove phrases, denoted as dvae-gnnw/o phrase.
we see that its scores in terms of all themetrics drops sharply, especially the three humanevaluation metrics.
the reason is that it’s difﬁcultto learn high-quality utterance-level vertex repre-sentation from a large amount of ﬁne-grained se-mantic content in open-domain dialogs without anyprior information.
the kappa value is above 0.4,showing moderate agreement among annotators..two sample parts of the discovered dialog struc-.
ture graph can be found in appendix b..5 experiments for graph grounded.
dialog generation.
to conﬁrm the beneﬁts of discovered dialog struc-ture graph for coherent conversation generation,we conduct experiments on the graph discoveredfrom weibo corpus.
all the systems (includingbaselines) are trained on weibo corpus..5.1 models.
we carefully select the following six baselines.
mmpms it is the multi-mapping based neuralopen-domain conversational model with posteriormapping selection mechanism (chen et al., 2019),which is a sota model on the weibo corpus.
memgm itis the memory-augmented open-domain dialog model (tian et al., 2019), whichlearns to cluster u-r pairs for response generation.
hred it is the hierarchical recurrent encoder-decoder model (serban et al., 2016).
cvae it is the conditional variational auto-encoder based neural open-domain conversationalmodel (zhao et al., 2017).
vhcr-ei this variational hierarchical rnnmodel can learn hierarchical latent variables fromopen-domain dialogs (ghandeharioun et al., 2019).
it is a sota dialog model with hierarchical vae.
dvrnn-rl it discovers dialog structure graph fortask-oriented dialog modeling (shi et al., 2019).
gcs it is our proposed dialog structure graphgrounded dialog system with hierarchical rl.
gcs w/ utterg it is a simpliﬁed version ofgcs that just uses the utterance-level graph andutterance-level sub-policy.
gcs w/ phrase graph it is a simpliﬁed version ofgcs that just uses the phrase graph and utterance-level sub-policy..1732methods.
coherence.
mmpmsmemgmhredcvaevhcr-eidvrnn-rlgcsgcs w/ utterggcs w/ phrase graph.
multi.t.-coh.∗0.660.530.540.580.680.601.030.930.72.single.t.-coh.∗0.450.370.430.390.430.390.590.560.41.overall qualityinformativenessinfo.∗ dist-1/2# enga.∗ length#0.500.340.190.430.530.390.580.550.54.
0.08/0.320.09/0.330.08/0.260.11/0.380.12/0.360.06/0.220.19/0.550.16/0.470.16/0.45.
0.240.200.200.220.280.220.480.340.24.
5.824.085.047.747.307.868.008.008.00.table 2: evaluation results for baselines and our system trained on weibo corpus.
automatic evaluation metrics..∗.
or # denote human or.
we use the same user simulator for rl trainingof dvrnn-rl, gcs and gcs w/ utterg.
here,we use the original mmpms as user simulator be-cause it achieves the best result on the weibo cor-pus.
the user simulator is pre-trained on dialogcorpus and not updated during policy training.
weuse the original source codes for all the baselinesand the simulator.
further details about baselinesand gcs can be found in appendix a.2..we conduct model-human dialogs for evalua-tion.
given a model, we ﬁrst randomly select anutterance (the ﬁrst utterance in a session) from testset for the model side to start the conversationswith a human turker.
then the human is asked toconverse with the selected model till 8 turns arereached.
finally, we obtain 50 model-human di-alogs for multi-turn evaluation.
then we randomlysample 200 u-r pairs from the above dialogs forsingle-turn evaluation..5.2 evaluation metrics.
since the proposed system does not aim at predict-ing the highest-probability response at each turn,but rather the long-term success of a dialog (e.g.,coherence), we do not employ bleu (papineniet al., 2002) or perplexity for evaluation.
we usethree multi-turn evaluation metrics and three single-turn metrics.
for human evaluation, we invite threeannotators to conduct evaluation on each case, andwe ask them to provide 1/0 (yes or no) scores formost of the metrics.
moreover, for multi-turn co-herence, we ﬁrst ask the annotators to manuallysegment a dialog by topics and then conduct evalu-ation on each session.
a session refers to a dialogfragment about one topic.
notice that system iden-tiﬁers are masked during human evaluation..multi-turn metrics.
we use the following met-rics: (1) multi-turn coherence (multi.t.-coh.)
it measures the coherence within a session.
com-mon incoherence errors in a session include am-phora errors across utterances and information in-consistency.
“0” means that there are more thantwo incoherence errors in a session.
“1” meansthat there are only one error.
“2” means that thereare no errors.
finally, we compute the averagescore of all the sessions.
(2) dialog engagement(enga.)
this metric measures how interesting adialogs is.
it is “1” if a dialog is interesting andthe human is willing to continue the conversation,otherwise “0”.
(3) length of high-quality dialog(length) a high-quality dialog ends if the modeltends to produce dull responses or two consecutiveutterances are highly overlapping (li et al., 2016b).
single-turn metrics.
we use the following met-rics: (1) single-turn coherence (single.t.-coh.)
“0” if a response is inappropriate as an reply, oth-erwise “1”; (2) informativeness (info.)
“0” if aresponse is a “safe” response, e.g.
“i don’t know”,or it is highly overlapped with context, otherwise“1”; (3) distinct (dist.-i) it is an automatic metricfor response diversity (li et al., 2016a)..5.3 experiment results.
as shown in table 2, gcs signiﬁcantly outper-forms all the baselines in terms of all the metrics ex-cept “length-of-dialog” (sign test, p-value < 0.01).
it indicates that gcs can generate more coherent,informative and engaging dialogs.
speciﬁcally,our system’s two sub-policies strategy on the dia-log structure graph enables more coherent dialogﬂow control than hierarchical latent variable basedvhcr-ei model that performs the best among.
1733ablation study.
in order to evaluate the contri-bution of session-level vertices, we run gcs withan utterance-level dialog structure graph, denotedas “gcs w/ utterg”.
results in table 2 show thatits performance in terms of “multi.t.-coh.” and“enga.” drops sharply.
it demonstrates the contri-bution of our hierarchical dialog structure graphfor enhancing dialog coherence and dialog engage-ment.
the possible reason for the inferior perfor-mance of “gcs w/ utterg” is that the removalof session-level vertices harms the capability ofselecting coherent utterance-level vertex sequence..6 conclusion.
in this paper, we conduct unsupervised discoveryof discrete dialog structure from chitchat corpora.
further, we try to formalize the structure as a two-layer directed graph.
to discover the dialog struc-ture, we present an unsupervised model, dvae-gnn, which integrates gnn into dvae to modelcomplex relations among dialog states for moreeffective dialog structure discovery.
experimen-tal results demonstrate that dvae-gnn can dis-cover meaningful dialog structure, and the use ofdialog structure as background knowledge can sig-niﬁcantly improve multi-turn dialog coherence..acknowledgments.
we are grateful for the support from ying yu.
this work is supported by the national keyresearch and development project of china(no.2018aaa0101900) and the national naturalscience foundation of china (nsfc) via grant61976072..figure 4: a sample dialog between our dialog sys-tem gcs and a human, where“bot” is our system and“user” is the human.
this dialog contains three dialogtopics.
we translate the original chinese texts into en-glish language..baselines, as indicated by “multi.t.-coh.”.
more-over, our high-quality edges between utterance-level vertices (measured by the metric “u-u appr.”in table 1) help gcs to achieve higher single-turncoherence score than dvrnn-rl, as indicatedby “single.t.-coh.”.
in addition, gcs, vhcr-ei,mmpms and cvae can obtain better performancein terms of “info.”, indicating that latent variablecan effectively improve response informativeness.
the kappa value is above 0.4, showing moderateagreement among annotators..5.4 case study of conversation generation.
references.
figure 4 shows a sample dialog between our sys-tem “gcs” and a human.
we see that our systemcan generate a coherent, engaging and informativemulti-turn dialog.
for an in-depth analysis, wemanually segment the whole dialog into two ses-sions.
it can be seen that the ﬁrst session is about“meeting appointment”, and it contains a reason-able dialog logic, i will have a holidayi will→arrivelook forward to await for you at homebig meal.
and the second session is about “jokingbetween friends”, and it also contains a reasonablelogic, you are beautifuli amsorry..ﬂattering me.
→.
→.
→.
→.
chaotao chen, jinhua peng, fan wang, jun xu, andhua wu.
2019. generating multiple diverse re-sponses with multi-mapping and posterior mappingin proceedings of the twenty-eighthselection.
international joint conference on artiﬁcial intelli-gence, ijcai 2019, macao, china, august 10-16,2019, pages 4918–4924.
ijcai.org..ananlada chotimongkol.
2008. learning the structureof task-oriented conversations from the corpus of in-in ph.d. thesis, carnegie mellondomain dialogs.
university..emily dinan, stephen roller, kurt shuster, angelafan, michael auli, and jason weston.
2019. wizardof wikipedia: knowledge-powered conversational.
1734start国庆节快到了，我快放假了。[nationaldayiscoming,i‘mgoingtohaveaholiday.]user放假了，我们可以出去玩了，放风筝[inholiday,wecangooutandhavefun,suchasflyingkites.]bot我星期五就到了。[i’llcomebackonfriday.]user那我在家等你回来[allright,i'llwaitforyouathome]bot好的呀，哈哈哈。那就等着你的大餐[great!lookingforwardtoyourbigmeal.]user哈哈，我想去南京旅游，一起吧[well,iwanttotraveltonanjing,let’sgotogether.]bot不要我了！[ifeellikeyou'reabandoningme.]user要你，咱们一起去[no,youcancomewithus.]bot看你秀恩爱好嘛。[isitappropriatetotravelwithalovey-doveycouple?]user秀恩爱，分的快，这句话我不同意[idon’tthinkitisreasonablethatshowingsweetmakesalovey-doveycouplebrokeupfast.]bot那你好棒棒哦[youareveynice.]user一般啦，并不是很棒[justso-so.]bot好的吧，我觉得你很好看[allright,youarebeautifulinmyeyes!]user哈哈，你好好笑哦，敷衍我！[ha-ha,youaresofunny.you'rejustflatteringme.]bot对不起哈哈哈[yeah,i’msorry.]user没关系，我很大度，原谅你了[that’sdoesn’tmatter,you'reforgiven]bot怎么有这么好的事[youaresogenerous.howcouldsuchagoodthinghappen.]
in 7th international conference on learn-agents.
ing representations, iclr 2019, new orleans, la,usa, may 6-9, 2019. openreview.net..jun gao, wei bi, xiaojiang liu, junhui li, guodongzhou, and shuming shi.
2019. a discrete cvae forresponse generation on short-text conversation.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 1898–1908, hong kong, china.
association for computa-tional linguistics..asma ghandeharioun, judy hanwen shen, natasha`agatajaques, craig ferguson, noah jones,lapedriza, and rosalind w. picard.
2019. approxi-mating interactive human evaluation with self-playin advances infor open-domain dialog systems.
neural information processing systems 32: annualconference on neural information processing sys-tems 2019, neurips 2019, december 8-14, 2019,vancouver, bc, canada, pages 13658–13669..xiaodong gu, kyunghyun cho, jung-woo ha, andsunghun kim.
2019. dialogwae: multimodal re-sponse generation with conditional wasserstein auto-encoder.
in 7th international conference on learn-ing representations, iclr 2019, new orleans, la,usa, may 6-9, 2019. openreview.net..eric jang, shixiang gu, and ben poole.
2017. categor-ical reparameterization with gumbel-softmax.
in 5thinternational conference on learning representa-tions, iclr 2017, toulon, france, april 24-26, 2017,conference track proceedings.
openreview.net..dongyeop kang, anusha balakrishnan, pararth shah,paul crook, y-lan boureau, and jason weston.
2019. recommendation as a communication game:self-supervised bot-play for goal-oriented dialogue.
in proceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 1951–1961, hong kong, china.
association for computa-tional linguistics..byeongchang kim, jaewoo ahn, and gunhee kim.
2020. sequential latent knowledge selection forknowledge-grounded dialogue.
in 8th internationaliclrconference on learning representations,2020, addis ababa, ethiopia, april 26-30, 2020.openreview.net..diederik p. kingma and max welling.
2014. auto-in 2nd internationalencoding variational bayes.
conference on learning representations,iclr2014, banff, ab, canada, april 14-16, 2014, con-ference track proceedings..of a latent space.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing (emnlp), pages 4678–4699, online.
as-sociation for computational linguistics..jiwei li, michel galley, chris brockett, jianfeng gao,and bill dolan.
2016a.
a diversity-promoting ob-jective function for neural conversation models.
inproceedings of the 2016 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,pages 110–119, san diego, california.
associationfor computational linguistics..jiwei li, will monroe, alan ritter, dan jurafsky,michel galley, and jianfeng gao.
2016b.
deep rein-forcement learning for dialogue generation.
in pro-ceedings of the 2016 conference on empirical meth-ods in natural language processing, pages 1192–1202, austin, texas.
association for computationallinguistics..juntao li and rui yan.
2018. overview of the nlpcc2018 shared task: multi-turn human-computer con-in ccf international conference onversations.
natural language processing and chinese comput-ing, pages 446–451.
springer..zhibin liu, zheng-yu niu, hua wu, and haifengwang.
2019. knowledge aware conversation gen-eration with explainable reasoning over augmentedgraphs.
in proceedings of the 2019 conference onempirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages1782–1792, hong kong, china.
association forcomputational linguistics..nikita moghe, siddhartha arora, suman banerjee, andmitesh m. khapra.
2018. towards exploiting back-ground knowledge for building conversation sys-in proceedings of the 2018 conference ontems.
empirical methods in natural language processing,pages 2322–2332, brussels, belgium.
associationfor computational linguistics..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2002. bleu: a method for automatic eval-in proceedings ofuation of machine translation.
the 40th annual meeting of the association for com-putational linguistics, pages 311–318, philadelphia,pennsylvania, usa.
association for computationallinguistics..alan ritter, colin cherry, and bill dolan.
2010. unsu-pervised modeling of twitter conversations.
in hu-man language technologies: the 2010 annual con-ference of the north american chapter of the associ-ation for computational linguistics, pages 172–180,los angeles, california.
association for computa-tional linguistics..chunyuan li, xiang gao, yuan li, baolin peng, xiu-jun li, yizhe zhang, and jianfeng gao.
2020. opti-mus: organizing sentences via pre-trained modeling.
stephen robertson and hugo zaragoza.
2009. theprobabilistic relevance framework: bm25 and be-yond.
now publishers inc..1735iulian vlad serban, alessandro sordoni, yoshua ben-gio, aaron c. courville, and joelle pineau.
2016.building end-to-end dialogue systems using gener-in pro-ative hierarchical neural network models.
ceedings of the thirtieth aaai conference on arti-ﬁcial intelligence, february 12-17, 2016, phoenix,arizona, usa, pages 3776–3784.
aaai press..iulian vlad serban, alessandro sordoni, ryan lowe,laurent charlin, joelle pineau, aaron c. courville,and yoshua bengio.
2017. a hierarchical latentvariable encoder-decoder model for generating di-in proceedings of the thirty-first aaaialogues.
conference on artiﬁcial intelligence, february 4-9,2017, san francisco, california, usa, pages 3295–3301. aaai press..lifeng shang, zhengdong lu, and hang li.
2015. neu-ral responding machine for short-text conversation.
in proceedings of the 53rd annual meeting of theassociation for computational linguistics and the7th international joint conference on natural lan-guage processing (volume 1: long papers), pages1577–1586, beijing, china.
association for compu-tational linguistics..weiyan shi, tiancheng zhao, and zhou yu.
2019. un-in proceed-supervised dialog structure learning.
ings of the 2019 conference of the north americanchapter of the association for computational lin-guistics: human language technologies, volume 1(long and short papers), pages 1797–1807, min-neapolis, minnesota.
association for computationallinguistics..richard s sutton and andrew g barto.
2018. rein-forcement learning: an introduction.
mit press..zhiliang tian, wei bi, xiaopeng li, and nevin l.zhang.
2019. learning to abstract for memory-inaugmented conversational response generation.
proceedings ofthethe 57th annual meeting ofassociation for computational linguistics, pages3816–3825, florence, italy.
association for compu-tational linguistics..wenquan wu, zhen guo, xiangyang zhou, hua wu,xiyuan zhang, rongzhong lian, and haifeng wang.
2019. proactive human-machine conversation within proceedings of theexplicit conversation goal.
57th annual meeting of the association for com-putational linguistics, pages 3794–3804, florence,italy.
association for computational linguistics..yu wu, wei wu, chen xing, ming zhou, and zhou-jun li.
2017.sequential matching network: anew architecture for multi-turn response selectionin proceedings of thein retrieval-based chatbots.
55th annual meeting of the association for compu-tational linguistics (volume 1: long papers), pages496–505, vancouver, canada.
association for com-putational linguistics..jun xu, zeyang lei, haifeng wang, zheng-yu niu,hua wu, and wanxiang che.
2020a.
enhancing di-alog coherence with event graph grounded content.
planning.
in proceedings of the twenty-ninth inter-national joint conference on artiﬁcial intelligence,ijcai 2020, pages 3941–3947.
ijcai.org..jun xu, haifeng wang, zheng-yu niu, hua wu, wanx-iang che, and ting liu.
2020b.
conversationalgraph grounded policy learning for open-domainconversation generation.
in proceedings of the 58thannual meeting of the association for computa-tional linguistics, pages 1835–1845, online.
asso-ciation for computational linguistics..jun xu, haifeng wang, zhengyu niu, hua wu, andwanxiang che.
2020c.
knowledge graph groundedgoal planning for open-domain conversation gener-in proceedings of the aaai conference onation.
artiﬁcial intelligence, volume 34, pages 9338–9345..zhou yu, ziyu xu, alan w black, and alexander rud-nicky.
2016. strategy and policy learning for non-in proceed-task-oriented conversational systems.
ings of the 17th annual meeting of the special inter-est group on discourse and dialogue, pages 404–412, los angeles.
association for computationallinguistics..ke zhai and jason d. williams.
2014. discovering la-tent structure in task-oriented dialogues.
in proceed-ings of the 52nd annual meeting of the associationfor computational linguistics (volume 1: long pa-pers), pages 36–46, baltimore, maryland.
associa-tion for computational linguistics..tiancheng zhao, kyusong lee, and maxine eskenazi.
2018. unsupervised discrete sentence representa-tion learning for interpretable neural dialog genera-tion.
in proceedings of the 56th annual meeting ofthe association for computational linguistics (vol-ume 1: long papers), pages 1098–1107, melbourne,australia.
association for computational linguis-tics..tiancheng zhao, ran zhao, and maxine eskenazi.
2017. learning discourse-level diversity for neuraldialog models using conditional variational autoen-in proceedings of the 55th annual meet-coders.
ing of the association for computational linguistics(volume 1: long papers), pages 654–664, vancou-ver, canada.
association for computational linguis-tics..xiangyang zhou, lu li, daxiang dong, yi liu, yingchen, wayne xin zhao, dianhai yu, and hua wu.
2018. multi-turn response selection for chatbotswith deep attention matching network.
in proceed-ings of the 56th annual meeting of the associationfor computational linguistics (volume 1: long pa-pers), pages 1118–1127, melbourne, australia.
as-sociation for computational linguistics..1736a implementation details.
a.1.
implementation details aboutdvae-gnn.
for all models, we share the same vocabulary (max-imum size is 50000) and initialized word embed-ding (dimension is 200) with the pre-trained ten-cent ai lab embedding.9 meanwhile, we ran-domly initialized the embedding space of session-level vertices and latent vectors for utterance-levelvertices (dimensions are 200).
the hidden sizes ofall rnn encoders and rnn decoders are set as 512.the three threshold variables about co-occurrencestatistics αuu, αsu and αss are all set as 0.05..we use the paddlepaddle framework for the de-.
velopment of our systems.10.
notice that it is costly to calculate equation 3 insection 3.3 since the total number of utterance-level vertices, n , is very large (more than onemillion).
in practice, for each utterance, we ﬁrstretrieve the top-50 most related utterance-level ver-tices according to okapi bm25 (robertson andzaragoza, 2009) similarity between the utteranceand associated phrases of all candidate vertices.
and then calculate equation 3 only with these re-trieved vertices.
thus, only a part of vectors inλx will be dynamically updated for each trainingsample when training dvae-gnn..a.2 experiment settings about gcs.
source codes about baselines.
• hred:github.com/julianser/.
hed-dlg-truncated.
• mmpms:github.com/paddlepaddle/.
research/tree/master/nlp/.
ijcai2019-mmpms.
• cvae:github.com/snakeztc/.
neuraldialog-cvae.
• vhcr-ei:github.com/natashamjaques/.
neural_chat.
• memgm:github.com/tianzhiliang/.
memoryaugdialog.
• dvrnn:github.com/wyshi/.
unsupervised-structure-learning.
9ai.tencent.com/ailab/nlp/embedding.html10paddlepaddle.org.cn/.
hyper-parameter setting for training in ourexperiments, all the models share the same vocabu-lary (maximum size is 50000 for both weibo corpusand douban corpus), initialized word embedding(dimension is 200) with the tencent ai lab em-bedding.
moreover, bidirectional one-layer gru-rnn (hidden size is 512) is utilized for all thernn encoders and rnn decoders.
in addition,dropout rate is 0.3, batch size is 32 and optimizeris adam(lr=2le-3) for all models.
during rl train-ing, the discounting weight for rewards is set as0.95. the mmpms model for the user simulatoremploys 10 responding mechanisms.
we utilizedependency parse for phrase extraction.11 we pre-train the response generator in the weibo corpus.
rewards and training procedure for thegraph grounded conversational system.
weuse the paddlepaddle framework for the develop-ment of our systems.12 we hot-start the responsegenerator by pre-training it before the training ofpolicy module.
meanwhile, to make the rl basedtraining process more stable, we employ the a2cmethod (sutton and barto, 2018) for model op-timization rather than the original policy gradientas done in previous work (li et al., 2016b).
more-over, during rl training, the parameters of thepolicy module are updated, and the parameters ofresponse generator and the representation of seman-tic vertices stay intact..b case study of dialog structure graph.
discovery.
figure 5 shows a part of the uniﬁed dialog struc-ture graph that is discovered from the weibo cor-pus.
each yellow-colored circle in this ﬁgurerepresents a session-level vertex with expert in-terpreted meanings based on the information oftop words (from phrases of utterance-level verticesbelonging to this session-level vertex) ranked bytf/idf.
each green-colored rectangle representsan utterance-level vertex.
the directed-arrows be-tween utterance-level vertices represent dialog tran-sitions between states, and the utterance-level ver-tices within blue dotted-lines are about the samesession-level vertex (topic)..we observe reasonable dialog structures in fig-ure 5. it captures the major interaction logic indialogs about the topic “go traveling”, traveling islet’sreally good.
you decide where to travel.
→.
→.
11ai.baidu.com/tech/nlp basic/dependency parsing12paddlepaddle.org.cn/.
1737figure 5: a part of the uniﬁed dialog structure graph that is extracted from weibo corpus.
here, we interpretsession-level semantics based on their child utterance-level vertices.
we translate the original chinese textsinto english language..figure 6: a part of the uniﬁed dialog structure graph that is extracted from weibo corpus.
here, we interpretsession-level semantics based on their child utterance-level vertices.
we translate the original chinese textsinto english language..1738出去旅游gotraveling找个男朋友wanta boyfriend好久没出去旅游haven't been traveling for a long time出去旅旅游真好travel is really good应该带上一个西安人should travel with a xi’an people想回到以前的西安want to go back to historical xi'an等我一起去看兵马俑wait for me to see the terra cotta warriors好想和你们约起来really want to make an appointment with you约起来出去旅游make an appointment to travel你定地点you decide where to travel可以去黄山let’s go to huangshan现在黄山人少huangshan isn’t crowded now大声告诉我你的目标tell me your goal loudly找个会照相的男朋友find a boyfriend who can take goodpictures会让人羡慕beenslightlyenviable拍出好看的照片take beautiful pictures真心觉得好看itreally looks good单身的女孩要先坚强single girls need to be strong first需要一个男朋友need a boyfriend你好烦you are so boring这样找不到对象willneverhaveaboyfriend找男朋友干嘛what's a boyfriend for可以陪我过节日can accompany me to celebrate the festival看周杰伦演唱会watchjaychou’sconcert周杰伦在西安jaychou可以现场买buyonsite已经没票了hasnoticket求拼宿seeksharehouse准备看他演唱会plantowatchtheconcert门票在淘宝上买buyticketontaobao.com多少人要去看howmanypeoplewillwatch看周杰伦演唱会watchjaychou’sconcert小苦逼想看演唱会iwanttogototheconcert看周杰伦演唱会watchjaychou’sconcert星座constellation小苦逼想看演唱会iwanttogototheconcert看周杰伦演唱会watchjaychou’sconcert多少人要去看howmanypeoplewillwatch准备看他演唱会plantowatchtheconcert求拼宿seeksharehouse周杰伦在西安jaychouisinxi’an门票在淘宝上买buy ticketontaobao已经没票了tickets are sold out可以现场买buyonsite喜欢周董的人很多manypeoplelikejaychou听不清歌词cannothearthelyricsclearly摩羯男害羞capricornmenareshy喜欢射手座likeasagittarius射手座挺爱胡思乱想asagittariusiscranky有大男子主义hasmalechauvinism完全正确absolutelyright射手座简直八面玲珑asagittariusisallthingstoallmen处女男贴心virgomenareintimate生日是摩羯座thebirthdayiscapricorn处女男怎么样howaboutvirgomen→.
go to huangshancomments about huangshan.
furthermore, it also captures the major logic in di-alogs about the topic “want a boyfriend”, need aboyfriendhe can accompany me to cel-ebrate the festival.
moreover, it captures a dialogtopic transition between the topic “go trveling” andanother topic “want a boyfriend”..why?.
→.
→.
figure 6 shows another part of the uniﬁed dialogstructure graph that discovered from the weibocorpus..we optimize the proposed dvae-gnn model bymaximizing the variational lower-bound:.
e.|.
q(z.x)[log p(x.z)].
kl(q(z.
|.
−.
x)|.
p(z)),(cid:107).
where p(z) is the prior uniform distribution of z.speciﬁcally, we approximate the ﬁrst item inthe above equation by sampling z from q(zx)|and calculate the the negative log-likelihood recon-struction loss.
for the second item, we calculate itby:.
c gcs with rl.
c.kl[q(zj|.
xj)(cid:107).
p(zj)] + kl[q(g.z1,...,c)|.
p(g)],(cid:107).
(cid:88)j=1where we can calculate each sub-item straightlysince z1,...,c and g follow discrete distribution.
be-low, we provide the derivation of the second item..in the following, we will elaborate the details ofgcs..c.1 dialog context understanding.
given a dialog context (the last two utterances), weﬁrst map it to the graph by recognizing the mostrelated utterance-level vertex with the well-traineddvae-gnn.
here, the recognized utterance-levelvertex is denoted as the hit utterance-level vertex.
for policy learning, we build current rl state slat time step l by collecting dialog context (the lasttwo utterances), previously selected session-levelvertex sequence, and previously selected utterance-level vertex sequence.
here, we ﬁrst utilize threeindependent rnn encoders to encode them respec-tively, and then concatenate these three obtainedrepresentation vectors, to obtain the representationof the rl state, esl..c.2 response generator.
the response generator is a pre-trained seq2seqmodel with attention mechanism, whose parame-ters are not updated during rl training.
speciﬁ-cally, we take the last user utterance, and the asso-ciated phrase of the selected utterance-level vertexas input of the generator..d training objective for dvae-gnn.
the proposed dvae-gnn model consists of twoprocedures.
in the recognition procedure, for adialog session x that consists of a sequence of cutterances, x = [x1, ..., xc], in recognition proce-dure, we ﬁrst recognize an utterance-level vertex zifor each utterance xi, and then recognize a session-level vertex g based on all recognized utterance-level vertices, [z1, ..., zc].
in reconstruction proce-dure, we regenerate all the utterances in x withthe predicted vertices z = [z1, ..., zc, g].
here,.
1739141300130113021303130413051306130713081309131013111312131313141315131613171318131913201321132213231324132513261327132813291330133113321333133413351336133713381339134013411342134313441345134613471348134913501351135213531354135513561357135813591360136113621363136413651366136713681369137013711372137313741375137613771378137913801381138213831384138513861387138813891390139113921393139413951396139713981399acl-ijcnlp2021submission***.conﬁdentialreviewcopy.donotdistribute.kl[q(z|x)kp(z)]=xz[logq(z|x)−logp(z)]q(z|x)=xz1,...,c,g{cxj=1[logq(zj|xj)−logp(zj)]+[logq(g|z1,...,c)−logp(g)]}cyi=1q(zi|xi)q(g|z1,...,c)=cxj=1xz1,...,c,g[logq(zj|xj)−logp(zj)]q(zj|xj)cyi=1,i6=jq(zi|xi)q(g|z1,...,c)+xz1,...,c,g[logq(g|z1,...,c)−logp(g)]q(g|z1,...,c)cyi=1q(zi|xi)=cxj=1xzj[logq(zj|xj)−logp(zj)]xz[1,...,c]−j,gq(zj|xj)cyi=1,i6=jq(zi|xi)q(g|z1,...,c)+xg[logq(g|z1,...,c)−logp(g)]q(g|z1,...,c)xz1,...,ccyi=1q(zi|xi)=cxj=1kl[q(zj|xj)kp(zj)]xz[1,...,c]−j,gcyi=1,i6=jq(zi|xi)q(g|z1,...,c)+kl[q(g|z1,...,c)kp(g)]xz1,...,ccyi=1q(zi|xi)=cxj=1kl[q(zj|xj)kp(zj)]+kl[q(g|z1,...,c)kp(g)]