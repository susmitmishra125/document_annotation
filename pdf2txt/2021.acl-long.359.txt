how knowledge graph and attention help?
a quantitative analysis into bag-level relation extraction.
zikun hu1 , yixin cao2 , lifu huang3 , tat-seng chua11national university of singapore2s-lab, nanyang technological university3computer science department, virginia techzikunhu@nus.edu.sg, yixin.cao@ntu.edu.sglifuh@vt.edu, chuats@comp.nus.edu.sg.
abstract.
assumed to express this relation and will form asentence bag as its annotations..knowledge graph (kg) and attention mecha-nism have been demonstrated effective in in-troducing and selecting useful information forweakly supervised methods.
however, onlyqualitative analysis and ablation study are pro-vided as evidence.
in this paper, we contributea dataset and propose a paradigm to quantita-tively evaluate the effect of attention and kgon bag-level relation extraction (re).
we ﬁndthat (1) higher attention accuracy may lead toworse performance as it may harm the model’sability to extract entity mention features; (2)the performance of attention is largely inﬂu-enced by various noise distribution patterns,which is closely related to real-world datasets;(3) kg-enhanced attention indeed improvesre performance, while not through enhancedattention but by incorporating entity prior; and(4) attention mechanism may exacerbate theissue of insufﬁcient training data.
based onthese ﬁndings, we show that a straightfor-ward variant of re model can achieve sig-niﬁcant improvements (6% auc on average)on two real-world datasets as compared withthree state-of-the-art baselines.
our codes anddatasets are available at https://github.com/zig-kwin-hu/how-kg-att-help..1.introduction.
relation extraction (re) is crucial for knowledgegraph (kg) construction and population.
mostrecent efforts rely on neural networks to learn efﬁ-cient features from large-scale annotated data, thuscorrectly extract the relationship between entities.
to save the manual annotation cost and alleviate theissue of data scarcity, distant supervision relationextraction (dsre) (mintz et al., 2009) is proposedand becomes increasingly popular as it can auto-matically generate large-scale labeled data.
dsreis based on a simple yet effective principle: if thereis a relation between two entities in kg, then allsentences containing mentions of both entities are.
figure 1: examples of disturbing bags in nyt-fb60k..although effective, distant supervision may in-troduce noise to a sentence bag when the assump-tion fails — some sentences are not describing thetarget relation (zeng et al., 2015) (a.k.a.
noisy anno-tation).
to alleviate the negative impacts of noise,recent studies (lin et al., 2016; ji et al., 2017; duet al., 2018; li et al., 2020) leveraged attention toselect informative instances from a bag.
further-more, researchers introduced kg embeddings toenhance the attention mechanism (hu et al., 2019;han et al., 2018a).
the basic idea is to utilizeentity embeddings as the query to compute atten-tion scores, so that the sentences with high atten-tion weights are more likely to be valid annota-tions (zhang et al., 2019).
previous studies haveshown performance gain on dsre with attentionmodule and kg embeddings, however, it’s still notclear how these mechanisms work, and, are thereany limitations to apply them?.
in this paper, we aim to provide a thorough andquantitative analysis about the impact of both atten-tion mechanism and kg on dsre.
by analyzingseveral public benchmarks including nyt-fb60k(han et al., 2018a), we observe lots of disturb-ing bags — all of the bag’s sentences are valid ornoisy annotations, which shall lead to the failureof attention.
as shown in figure-1, all of anno-tations in the ﬁrst disturbing bag are valid, whilethe learned attentions assign the second annotation.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4662–4671august1–6,2021.©2021associationforcomputationallinguistics4662with a very low weight, which suggests an inefﬁ-cient utilization of annotations and exacerbates thedata sparsity issue.
or, in the second bag, all sen-tences are noisy, can attention and kg still improvethe performance?
if so, how do they work and towhat extent can they tolerate these disturbing bags?
answering these questions is crucial since this typeof noise is common in practice.
the unveiling oftheir working mechanism shall shed light on futureresearch direction, not limited to dsre..to achieve this, we propose a paradigm based onnewly curated dsre benchmark, bagrel-wiki73kextracted from fewrel (han et al., 2018b) andwikidata 1, for quantitative analysis of attentionand kg.
with extensive experiments, we concludethe following innovative and inspiring ﬁndings:.
(1) the accuracy of attention is inversely pro-portional to the total noise ratio and disturbing bagratio of training data; (2) attention effectively se-lects valid annotations by comparing their contextswith the semantics of relations, thus tends to relymore on the context to make predictions.
how-ever, it somehow lowers the model’s robustness tonoisy sentences that do not express the relation; (3)kg-enhanced attention indeed improves re per-formance, surprisingly not via enhanced attentionaccuracy, but by incorporating entity features toreduce the demand of contexts when facing noise;(4) attention could hurt the performance especiallywhen there is no sufﬁcient training data..based on the above observations, we propose anew straightforward yet effective model based onpre-trained bert (devlin et al., 2018) for re withconcatenated kg embedding, namely bre+ce.
instead of in-bag attention, it breaks the bag and en-sembles the results of all sentences belonging to thebag.
for each sentence, we directly incorporate en-tity embeddings into bert, rather than to enhanceattentions, to improve the robustness of extractingboth context and mention features.
bre+ce sig-niﬁcantly outperforms existing state-of-the-arts ontwo publicly available datasets, nyt-fb60k (hanet al., 2018a) and gids-fb8k (jat et al., 2018), by6% auc on average.
we summarize our contribu-tions as follows:.
• to the best of our knowledge, our proposedframework is the ﬁrst work to quantitativelyanalyze the working mechanism of knowl-edge graph and attention for bag-level re..1dumps.wikimedia.org/wikidatawiki/entities/20201109/.
• we have conducted extensive experiments toinspire and support us with the above ﬁndings..• we demonstrate that a straightforward methodbased on the ﬁndings can achieve improve-ments on public datasets..2 related work.
to address the issue of insufﬁcient annotations,mintz et al.
(2009) proposed distant supervisionto generate training data automatically, which alsointroduces much noise.
from then, dsre becomesa standard solution that relies on multi-instancelearning from a bag of sentences instead of a sin-gle sentence (riedel et al., 2010; hoffmann et al.,2011).
attention mechanism (lin et al., 2016) ac-celerates this trend via strong ability in handlingnoisy instances within a bag (liu et al., 2017; duet al., 2018).
aside from intra-bag attention, yeand ling (2019) also designed inter-bag attentionsimultaneously handling bags with the same re-lation.
to deal with only-one-instance bags, liet al.
(2020) utilized a new selective gate (seg)framework to independently assign weights to eachsentence.
external kg is also incorporated to en-hance the attention module (han et al., 2018a; huet al., 2019).
however, due to the lack of sentence-level ground truth, it is difﬁcult to quantitativelyevaluate the performance of the attention module.
previous researchers tend to provide examples ascase study.2 therefore, we aim to ﬁll in this re-search gap by constructing a dataset and providinga framework for thorough analysis..3 preliminary.
knowledge graph (kg) is a directed graph g ={e, r, t }, where e denotes the set of entities, rdenotes the set of relation types in g, and t ={(h, r, t)} ⊆ e × r × e denotes the set of triples.
kg embedding models, e.g., rotate (sun et al.,2019), can preserve the structure information in thelearned vectors eh, et and er.
we adopt transe(bordes et al., 2013) in experiments..bag-level relation extraction (re) takes a bagof sentences b = {s1, s2, .
.
.
, sm} as input.
eachsentence si in the bag contains the same entity pair(h, t), where h, t ∈ e. the goal is to predict arelation y ∈ r between (h, t)..attention-based bag-level re uses attentionto assign a weight to each sentence within a bag..2shahbazi et al.
(2020) claim to annotate each positive bagin nyt-fb60k, but haven’t published their code and dataset..4663given a bag b from the dataset d, an encoderis ﬁrst used to encode all sentences from b intovectors {s(cid:48)m} separately.
then, an at-tention module computes an attention weight αifor each sentence and outputs the weighted sum of{s(cid:48).
i} as s to denote b:.
2, .
.
.
, s(cid:48).
1, s(cid:48).
ωi = vy · s(cid:48).
i.αi =.
exp(ωi)m(cid:80)j=1.
exp(ωj).
m(cid:88).
αis(cid:48).
i.s =.
i=1where vy is the label embedding of relation y inthe classiﬁcation layer, we denote this attentionmodule as att in the rest of paper..kg-enhanced attention aims to improve vy with.
entities eh and et (han et al., 2018a):.
rht = eh − et.
ωi = rht · tanh(wss(cid:48).
i + bs).
where rht is regarded as latent relation embedding.
we mark this way of computing ωi as ka.
ws andbs are learnable parameters..given a bag representation s, the classiﬁcationlayer further predicts a conﬁdence of each relation:.
o = wbs + bb.
p (y|b) = softmax(o).
where o is a logit vector.
wb and bb are learnableparameters.
during training, the loss is computedby:.
4 benchmark.
to quantitatively evaluate the effect of attention andkg on bag-level re, we ﬁrst deﬁne two metrics tomeasure the noise pattern (section 4.1).
then, weconstruct a kg and a bag-level re dataset (section4.2).
finally, we introduce a general evaluationframework to assess attention, kg and the entirere model (section 4.3)..4.1 metrics describing noise pattern.
to analyze how attention module functions on dif-ferent noise patterns, we ﬁrst design 2 metrics todescribe the noise pattern: noise ratio (nr) anddisturbing bag ratio (dr)..noise ratio (nr)represents the proportion ofnoisy sentences in the dataset.
given a bag bi andits relation label yi, a sentence sij ∈ bi is noisy ifits context does not express yi.
suppose isn(sij, yi)is an indicator function to tell whether sij is noise.
then nr is deﬁned as:.
nr =.
(11).
isn(sij, yi).
n(cid:80)i=1.
|bi|(cid:80)j=1n(cid:80)i=1.
|bi|.
where |bi| is the size of bi, n is the total numberof bags..disturbing bag ratio (dr) means the propor-tion of disturbing bags in the dataset.
a bag isdisturbing if all sentences in it are valid or all sen-tences are noisy.
formally, we use function isd(bi)to indicate whether a bag is disturbing or not:.
(1).
(2).
(3).
(4).
(5).
(6).
(7).
l = −.
log(p (yi|bi)).
(8).
isd(bi) =.
isn(sij, yi) +.
(1 − isn(sij, yi)).
|bi|(cid:89).
j=1.
|bi|(cid:89).
j=1.
n(cid:88).
i=0.
(12).
(13).
where n is the number of training bags in d. sincethe classiﬁcation layer is linear, we can rewrite thebag’s logit vector o using a weighted sum of eachsentence’s logit vector o:.
then we deﬁne dr as follows:.
n(cid:80)i=1.
isd(bi).
n.dr =.
i + bb.
oi = wbs(cid:48)m(cid:88).
o =.
αioi.
i=1.
(9).
(10).
from equation 10, we can see that the model’soutput on the whole bag depends on three aspects:(1) the model’s output on valid sentences withinthe bag; (2) the model’s output on noisy sentenceswithin the bag; (3) the attention weight assigned tovalid sentences and noisy ones..4.2 dataset construction.
based on fewrel and wikidata, we construct abag-level re dataset containing multiple trainingsets with different noise patterns, a test set and adevelopment set.
for each sentence in the bags,there is a ground truth attention label indicatingwhether it is a valid sentence or noise.
we alsoconstruct a kg containing all entities in the redataset by retrieving one-hop triples from wikidata..4664figure 2: left: process of synthesizing the valid sentence with correct context and the noisy sentence with wrongcontext.
right: visualization of different train sets of different noise patterns, the four sets from left to right arenamed as train 2.and train 1.
3 ,0,train 1.
2 ,0,train 1.
2 , 1.
2.
2 ,1..synthesize sentence fewrel is a sentence-levelre dataset, including 80 relations.
for each rela-tion, there are 700 valid sentences.
each sentencehas a unique entity pair.
every sentence along withits entities and relation label form a tuple (s, h, t, y).
we thus synthesize valid and noisy sentences forthe same entity pair for data augmentation..trainfewrel,.
the ﬁrst step is to divide sentences of eachtestfewrel andrelation into 3 sets:devfewrel, where each set has 500, 100 and 100sentences.
then, for each tuple (s, h, t, y) in theset, we aim to augment it to a bag b, where all ofits sentences contain (h, t).
besides, the sentencesin b are either the original s, or a synthesizedvalid sentence, or a synthesized noisy sentence.
wesynthesize sentences in the form of (s(cid:48), h, t, y, z),where z denotes the attention label (1 for valid, 0for noisy).
in speciﬁc, to synthesize a sentence,we randomly replace the source pair of entity men-tions with other target entity pairs while keepingthe context unchanged.
thus, if the contexts ex-press the same relation type with the entity pair, wecan automatically assign an attention label..we illustrate the synthesizing process in figure 2.
(s2, h2, t2, crosses) is a sentence from trainfewrel.
to generate a valid sentence, we randomly selectanother sentence (s1, h1, t1, crosses) which is la-beled with the same relation as s2 from trainfewrel.
then we replace its entity mentions h1 and t1 as h2and t2.
the output is (s4, h2, t2, crosses, 1).
sinceits context correctly describe crosses, we regards4 as valid.
for the noisy sentence, we randomlyselect a sentence (s3, h3, t3, isa) under another re-lation.
with similar process for s4, we get a synthe-size sentence (s5, h2, t2, crosses, 0).
because thecontext of s5 does not express target relation, welabel it as a noise..training sets with different noise patternsas deﬁned in section 4.1, we use nr and dr tomeasure the noise pattern of bag-level re dataset.
by controlling the number of synthesized noisysentences in each bag and the total ratio of noiseamong all sentences, we can construct several train-ing sets with different patterns.
in the followingsections, we denote a training set of which the nris x and dr is y as trainx,y.
higher x and y indi-cate noisy sentences and disturbing bags accountfor larger proportion.
for example, in figure 2, as-suming there are 4 sentences in trainfewrel, for eachsentence, we synthesize two noisy sentences thatform the bag together with the original sentence.
thus each bag contains 3 sentences: 1 valid and 2noisy, and its nr is 2/3 and dr is 0. for the other3 sets, the number of synthesized noisy sentencesequals the sum of original valid sentences and syn-thesized valid sentences.
thus they all have a nrof 1/2.
since we deﬁne bags containing no validsentences or no noisy sentences as disturbing bags,the third set and fourth set have 2 and 4 disturbingbags, with a dr of 1/2 and 1, respectively..test set and development set we also con-struct a test and a development set.
similar asthe second set in figure 2, each bag in the test/devsets contains two sentences, the nr of both sets is1/2 while the dr is 0.
i.e., in every bag of test/devsets, there is one valid sentence and one noisy sen-tence.
instead of multiple test sets of different noisepatterns, we only have one test set so that the eval-uation of different models is consistent.
to avoidinformation leak, when construct trainx,y, test anddevelopment sets, the context of synthesized sen-tences only come from trainfewrel, testfewrel anddevelopmentfewrel, respectively..the ﬁnal bagrel contains 9 train sets, 1 test and.
4665validthis road begins at the end of thetoll bridge over the wabash river.guillemard bridge is a railway bridge across sungai kelantan.oru kai osai was a tamilsoap opera that aired on zee tamil.this road begins at the end of the guillemard bridge over the sungai kelantan.guillemard bridge was a sungai kelantan soap opera that aired on zee tamil.relation: crosses (s1, s2)entity: toll bridge (h1), wabash river (t1)entity: guillemard bridge (h2), sungai kelantan (t2)synthesized validtrain 2/3,0nr=2/3 dr=0s1relation: isa (s3)entity: oru kai osai (h3), tamil (t3)s2s3s4synthesized noises5train 1/2,0nr=1/2 dr=0train 1/2,1/2nr=1/2 dr=0train 1/2,1nr=1/2 dr=11 development set, as listed in table 1. the nr ofthe training sets has three options: 1/3, 1/2 or 2/3,and similarly, dr can be 0, 1/2 or 1. the nr ofboth test and development sets are 1/2, while theirdr are 0. all data sets contain 80 relations.
fortraining sets whose nr are 1/3, 1/2 and 2/3, everybag in these sets contains 3, 2 and 3 sentences,respectively..train 1train 1train 2.dataset3 ,(0, 12 ,(0, 13 ,(0, 12 ,02 ,0.dev 1test 1.
2 ,1)2 ,1)2 ,1).
# noisy sentence40k40k80k8k8k.
# sentence120k80k120k16k16k.
# bag40k40k40k8k8k.
table 1: statistics of 11 sets of bagrel-wiki73k,where trainc,(x,y,z) denotes three sets oftrainc,x,trainc,y, and trainc,z..kg construction to evaluate the impact of kgon attention mechanism, we also construct a kgbased on wikidata.
denoting the set of entitiesappearing in fewrel as e, we link each entity in eto wikidata by its freebase id, and then extract alltriples t = (h, r, t) in wikidata where h, t ∈ e.to evaluate the effect of structural information fromkg, we also construct a random kg whose tripleset is ˆt .
speciﬁcally, for each triple (h, r, t) in t ,we corrupt it into (h, ˆr, t) by replacing r with arandom relation ˆr (cid:54)= r. thus the prior knowledgewithin the kg is destroyed.
kg-73k and kg73k-random have the same scale: 72,954 entities, 552relations and 407,821 triples..finally, we obtain bagrel-wiki73k, including.
the bag-level re sets and kg-73k..4.3 evaluation framework.
we ﬁrst deﬁne several measurements to evaluate theeffect of the attention mechanism and kg: atten-tion accuracy (aacc), area under precision-recall curve (auc), auc on valid sentences(aucv) and auc on noisy sentences (aucn)..aacc measures the attention module’s ability toassign higher weights to valid sentences than noisysentences.
given a non-disturbing bag (a bagcontaining both valid and noisy sentences) bi ={(sj, hi, ti, yi, zj)} and the predicted probabilitydistribution pi, the aacc of this bag is calculated.
by the following formula:.
m(cid:80)j=1.
m(cid:80)k=1.
aacci =.
i(zj)i(1 − zk)i(pij > pik).
m(cid:80)j=1.
m(cid:80)j=1.
i(zj).
i(1 − zj).
(14)where m = |bi| is the size of bi, i(·) is an indicatorfunction which returns 1 or 0 if the input is true.
or false.
by.
i(zj).
i(1 − zj), we count how.
m(cid:80)j=1.
m(cid:80)j=1.
many valid-noisy sentence pairs contained in bi.
i(zj)i(1 − zk)i(pij > pik), we countwith.
m(cid:80)j=1.
m(cid:80)k=1.
how many pairs show higher weight on the validsentence.
then the aacc of the whole data set isn(cid:80)computed as aacc = (aacci)/n where n isi=1.
the number of bags in the data set..aacc is designed speciﬁcally for non-disturbingbags.
on disturbing bags, with all sentences noisyor valid, it is meaningless to evaluate attentionmodule’s performance.
so in test/dev sets of ourbagrel-wiki73k, all bags are non-disturbing bags.
then without distraction, the evaluation results canbetter present how the attention module works..auc is a standard metric to evaluate dsremodel’s performance on bag-level test set.
as men-tioned in section 3, attention-based model’s per-formance on non-disturbing bags relies on threeaspects: (1)aacc, (2) model’s performance onvalid sentences and (3) model’s performance onnoisy sentences.
so we use aucv and aucn tomeasure the second and the third aspects, respec-tively.
the difference between auc and aucvis that auc is computed on the original test setd = {bi}, while aucv is auc computed on thevalid-only test set dv = {bvi }.
compared withbi, bvi has the same label but removes all noisysentences within it.
thus there is no noisy contextfeature in dv, then models can utilize both entitymentions and contexts to achieve a high aucv.
on the opposite, aucn is auc computed on thenoise-only test set dn = {bnre-moves all valid sentences in bi.
since all contextfeatures in dn are noisy, to achieve a high aucn,models have to ignore context and rely more onmention features to make predictions..i }, where bni.auc, aucv and aucn range from 0 to 1, anda higher value of the 3 metrics indicates that amodel makes better prediction on the whole bag,valid sentences and noisy sentences, respectively..46665 method.
6.1 experimental setup.
for fair comparison, all of baselines share thesame encoding structure as bre.
the attention-based models include bre+att,bre+ka andbre+seg, where seg (li et al., 2020) is anadvanced attention mechanism which achievesthe state-of-the-art performance on nyt-fb60k.
brieﬂy, seg uses sigmoid instead of softmax tocompute attention weights of each instance in abag.
the models without attention are bre andbre+ce.
to check the effect of noise pattern, wetrain model on different train sets.
as a reminder,trainx,y is a train set whose nr and dr is x and y,respectively..6.2 noise pattern v.s.
attention accuracy.
we train bre+att on 9 different training sets withdifferent noise patterns.
as shown in figure 3, wecan see that: (1) higher noise ratio (nr) makes themodel harder to highlight valid sentences, leadingto a lower attention accuracy (aacc); (2) higherdisturbing bag ratio (dr) results in lower aacc, in-dicating that disturbing bags challenge the attentionmodule.
based on these results, we claim that thenoise pattern within the training set largely affectsthe attention module’s effectiveness..to evaluate the effects of attention and kg, wedesign two straightforward bag-level re modelswithout the attention module, bre and bre+ce.
by comparing their performance with bre+att(bre with attention module) and bre+ka (brewith kg-enhanced attention module), we can havea better understanding of the roles of att andknowledge-enhanced att..bre uses bert (devlin et al., 2018) as the en-coder.
speciﬁcally, we follow the way describedin (peng et al., 2020; soares et al., 2019): entitymentions in sentences are highlighted with specialmarkers before and after mentions.
then the con-catenation of head and tail entity representationsare used as the representation s(cid:48).
since bre doesnot have attention mechanism, it breaks the bagsand compute loss on each sentence:.
l = −.
log(p (yi|sij)).
(15).
n(cid:88).
|bi|(cid:88).
i=1.
j=1.
p (yi|sij) = softmax(wbs(cid:48).
ij + bb).
(16).
bre can be viewed as a special case of bre+att.
its attention module assigns all sentences in all bagswith the same attention weight 1. during inference,given a bag, bre uses the mean of each sentence’sprediction as the whole bag’s prediction:.
p (yi|bi) = (.
p (yi|sij))/|bi|.
(17).
|bi|(cid:88).
j=1.
bre+ce concatenates an additional feature vec-tor rht with bert output, where rht is deﬁnedbased on entity embeddings of h and t. the con-catenated vector is used as the representation of thesentence and fed into the classiﬁcation layer..6 experiment.
we apply our proposed framework on bagrel-wiki73k and two real-world datasets to explorethe following questions:.
• how noise pattern affects the attention module?.
figure 3: attention accuracy (aacc) on the test setof bagrel-wiki73k.
the results are collected withbre+att trained on train sets of various noise pat-terns.
the x axis denote train sets of different disturb-ing bag ratio (dr).
the different colors indicate vari-ous noise ratio (nr)..• whether attention mechanism promotes re.
6.3 attention v.s.
re performance.
model’s performance?.
• how kg affects the attention mechanism?.
• whether attention aggravates data sparsity?.
to quantitatively analyze the effect of attentionmechanism, we compare the performance of breand bre+att in table 2, keeping other variablesof the model unchanged.
particularly, a higher.
4667modelbre-train 12 ,0bre+att-train 1bre+att-train 1bre+att-train 1.
2 ,02 , 122 ,1.auc aacc aucv aucn.910.878.897.896.
.850.434.711.759.na.881.751.713.
.932.941.932.925.table 2: test results of models trained on different trainset.
in the model column, x-y means model x trainedon train set y. among 3 train sets, train 12 ,1 has the mostdisturbing bags, while train 1.
2 ,0 has no such bag..aucv indicates the stronger ability of the modelitself — in an ideal setting without any noise, and ahigher aucn indicates higher robustness of modelto noise.
surprisingly, when using the same train-ing set train 12 ,0, the auc of the attention-enhancedmodel is lower than the auc of the model with-out attention (0.878 v.s.
in addition,bre+att has lowest auc using train 12 ,0, whichhas no disturbing bags.
the highest aacc (0.881)also suggests that the attention module does effec-tively select valid sentences.
why the most effec-tive attention module leads to the worst perfor-mance?
the reason is that bre+att-train 12 ,0 hasa much lower aucn, which indicates that it is lessrobust to noisy sentences..0.910)..is it true that an effective attention moduleshall hurt model’s robustness to noise?
this isactually against our intuition.
to answer it, wedraw figure 4 by assigning ﬁxed attention weightsto sentences during training.
speciﬁcally, each bag2 ,0 has a valid sentence and a noisy sen-in train 1tence, and we assign ﬁxed attention weight α to thevalid and 1 − α to the noisy one, instead of com-puting α with attention module.
then we test theresulting model’s aucn and aucv performance.
we can see that when the valid sentences receivehigher attention weights, the aucv curve risesslightly, indicating the model’s performance indeedgets enhanced.
meanwhile, the aucn curve goesdown sharply.
this demonstrates the effective atten-tion weakens the model’s robustness to noise.
thereason is that the model with a high-performanceattention module prefers to utilize context informa-tion instead of entity mention features.
thus, itusually fails if most contexts are noisy.
thus we2 ,0 has thecan explain the results in table 2. train 1highest aacc, indicating that it assigns very lowweights to noisy sentences.
thus the gain fromaucv can not make up the loss from aucn, re-sulting a worse auc..in conclusion, attention module can effectivelyselect valid sentences during training and test.
but.
figure 4: aucv and aucn results of bre+att-train 1.
2 ,0 trained with ﬁxed attention weights..it has an underlying drawback that it might hurt themodel’s ability to predict based on entity mentionfeatures, which are important in re tasks (li et al.,2020) (peng et al., 2020), leading to worse overallperformance..6.4 kg v.s.
attention.
modelbre+att-train 12 ,0bre+karand-train 1bre+ka-train 1bre+ka-train 1bre+ka-train 1.
2 ,02 , 122 ,1.
2 ,0.bre+ce-train 1bre+ce-train 1bre+ce-train 1.
2 ,02 , 122 ,1.auc aacc aucv aucn.878.915.932.924.913.
.881.762.857.720.617.
.941.936.936.928.916.
.434.659.560.723.761.
.915.919.918.nanana.
.935.939.941.
.856.849.845.table 3: results of models trained on different trainset.
in the model column, x-y means model x trainedon train set y. bre+karand uses entity embeddingslearned on kg-73k-random for the attention module..to measure kg’s effect on the combined withattention mechanism, we compare the results ofka with att, while keeping other parts of themodel unchanged.
as shown in table 3. when2 ,0, the kg-enhanced model (ka-trained on train 12 ,0) has lower aacc than the model withouttrain 12 ,0) (0.857 v.s.
0.881), while thekg (att-train 1auc is higher (0.932 v.s.
0.878).
this is be-cause the ka version has a higher aucn (0.560)and comparable aucv and aacc.
thus, the kg-enhanced model achieves better performance onnoisy bags, leading to a better re performance..in addition, comparing table 2 and table 3, kashows lower aacc and higher aucn than att onall three train sets.
this also demonstrates that kgdoes not promote model’s performance by improv-ing attention module’s accuracy, but by enhancingthe encoder and classiﬁcation layer’s robustness.
4668to noisy sentences.
this makes sense because theinformation from kg focuses on entities instead ofcontexts.
by incorporating kg, the model reliesmore on entity mention features instead of noisycontexts feature, thus becomes better at classifyingnoisy sentences..moreover, comparing bre+karand’s perfor-mance with bre+ka on train 12 ,0, we can observethat after incorporating entity embeddings learnedfrom a random kg, bre+karand has a much lowerattention accuracy.
this indicates that misleadingknowledge would hurt attention mechanism..6.5 attention v.s.
data sparsity.
2.
2 , 1.attention module assigns low weights to part oftraining sentences.
when training data is insufﬁ-cient, not making full use of all training examplescould aggravate the data sparsity issue.
thus wecompare performance of models trained on subsets.
from figure 5, we can see that alongof train 1with the decreasing size of training data, the perfor-mance gap between bre+att and bre+ce be-comes larger.
this is because the latter one fully uti-lizes every example by assigning the same weight 1to all sentences.
we also check each model’s atten-tion weights.
bre+seg assigns all sentences withweights > 0.9, so its performance drop is similarto the model without attention.
thus, we claim thattraditional attention mechanism could exacerbatethe model’s ability to insufﬁcient data.
this moti-vates us a better attention mechanism for few-shotsettings.
we leave it in the future..figure 5: auc test results of models trained on 4 sub-set.
the 4 subsetssets of bagrel-wiki73k’s train 1set.
contain 2%, 10%, 20% and 100% bags of train 1.
2 , 1.
2.
2 , 1.
2.
6.6 stability of attention v.s.
noise pattern.
from results in table 2 and table 3, we can seethat the performance of bre+ce is stable when.
the ratio of disturbing bags changes.
in compar-ison, bre+att and bre+ka show varying re-sults across different train sets.
on train 12 ,1 whichhas the most disturbing bags, bre+ce outper-forms bre+att and bre+ka, demonstratingthat bre+ce could be a competitive method forbag-level dsre..6.7 results on real-world datasets.
nyt-fb60k gids-fb8k.
modeljointerelesegbre+attbre+kabrebre+ce.
.408.497.451.457.480.625.630.
.912.905.913.917.917.910.917.table 4: auc on nyt-fb60k and gids-fb8k..figure 6: precision/recall curves on nyt-fb60kbased on previous observations, we ﬁnd thatbre and bre+ce could avoid latent drawbacksof attention mechanism and have a stable perfor-mance on datasets with different noise patterns,thus they are competitive methods compared withprior baselines.
to examine whether they work onthe real-world bag-level dsre datasets, we com-pare our method to 3 previous baselines on nyt-fb60k (han et al., 2018a) and gids-fb8k (jatet al., 2018).
we select jointe (han et al., 2018a),rele (hu et al., 2019) and seg (li et al., 2020) asbaselines, because they achieve state-of-the-art per-formance on bag-level re.
to collect auc results,we carefully re-run published codes of them usingsuggested hyperparameters from the original pa-pers.
we also draw precision-recall curves follow-ing prior works.
as shown in table 4 and figure 6,our method bre+ce largely outperforms exist-ing methods on nyt-fb60k and has comparableperformance on gids-fb8k.
such result demon-strates that we avoid attention mechanism’s latent.
4669drawback of hurting model’s robustness.
further-more, the model’s improvement on nyt-fb60kis promising (around 13% auc).
this is due totwo reasons: (1) nyt-fb60k is a noisy datasetcontaining prevalent disturbing bags, which is sim-ilar to our synthesized datasets.
(2)nyt-fb60kis highly imbalanced and most relation types onlyhave limited training data, while all relation typesin our balanced datasets have the same number oftraining examples; thus bre+ce and bre achievemuch higher improvement on nyt-fb60k com-pared with synthesized datasets.
in conclusion, thehigh performance not only validates our claim thatattention module may not perform well on noisyand insufﬁcient training data, but also veriﬁes thatour thorough analysis on attention and kg havepractical signiﬁcance..6.8 effect of kg.
modelbre+attbre+kabrebre+ce.
bagrel nyt.457.878.480.932.625.910.630.915.gids.917.917.910.917.table 5: auc test results of models on bagrel-in thewiki73k, nyt-fb60k and gids-fb8k.
2 ,0.bagrel column, all models are trained on train 1.from results in table 5, we provide a straightcomparison between models with kg (bre+ka,bre+ce) and models without kg (bre+att,bre).
apparently, both methods of utilizing kg(combined with attention and concatenated as ad-ditional features) outperforms methods not usingkg.
this demonstrates the prior knowledge fromkg is beneﬁcial for relation extraction task.
ex-cept our naive bre+ce, we expect that a carefullydesigned mechanism incorporating kg can lead tohigher improvement.
we leave it in the future..7 conclusion.
in conclusion, we construct a set of datasets andpropose a framework to quantitatively evaluate howattention module and kg work in the bag-level re.
based on the ﬁndings, we demonstrate the effec-tiveness of a straightforward solution on this task.
experiment results well support our claims thatthe accuracy of attention mechanism depends onthe noise pattern of the training set.
in addition,although effectively selecting valid sentences, at-tention mechanism could harm model’s robustnessto noisy sentences and aggravate the data sparsity.
issue.
as for kg’s effects on attention, we observethat it promotes model’s performance by enhanc-ing its robustness with external entity information,instead of improving attention accuracy..in the future, we are interested in developing amore general evaluation framework for other tasks,such as question answering, and improving the at-tention mechanism to be robust to noise and insufﬁ-cient data, and an effective approach to incorporatethe kg knowledge to guide the model training..acknowledgement.
this research/project is supported by next re-search centre.
this research was also conductedin collaboration with sensetime.
this work is par-tially supported by a*star through the industryalignment fund - industry collaboration projectsgrant, by ntu (ntu–ace2020-01) and ministryof education (rg96/20), and by the national re-search foundation, prime minister’s ofﬁce, singa-pore under its energy programme (ep award no.
nrf2017ewt-ep003-023) administrated by theenergy market authority of singapore..references.
antoine bordes, nicolas usunier, alberto garcia-duran,jason weston, and oksana yakhnenko.
2013. translating embeddings for modeling multi-in neural information processingrelational data.
systems (nips), pages 1–9..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training of deepbidirectional transformers for language understand-ing.
arxiv preprint arxiv:1810.04805..jinhua du, jingguang han, andy way, and dadongwan.
2018. multi-level structured self-attentionsfor distantly supervised relation extraction.
arxivpreprint arxiv:1809.00699..xu han, zhiyuan liu, and maosong sun.
2018a.
neu-ral knowledge acquisition via mutual attention be-tween knowledge graph and text.
in proceedings ofthe aaai conference on artiﬁcial intelligence, vol-ume 32..xu han, hao zhu, pengfei yu, ziyun wang, yuan yao,zhiyuan liu, and maosong sun.
2018b.
fewrel:a large-scale supervised few-shot relation classiﬁca-tion dataset with state-of-the-art evaluation.
in pro-ceedings of the 2018 conference on empirical meth-ods in natural language processing, pages 4803–4809, brussels, belgium.
association for computa-tional linguistics..4670on machine learning and knowledge discovery indatabases, pages 148–163.
springer..hamed shahbazi, xiaoli z fern, reza ghaeini, andprasad tadepalli.
2020. relation extraction with ex-planation.
arxiv preprint arxiv:2005.14271..livio baldini soares, nicholas fitzgerald, jeffreyling, and tom kwiatkowski.
2019. matching theblanks: distributional similarity for relation learn-ing.
arxiv preprint arxiv:1906.03158..zhiqing sun, zhi-hong deng, jian-yun nie, and jiantang.
2019. rotate: knowledge graph embed-ding by relational rotation in complex space.
arxivpreprint arxiv:1902.10197..zhi-xiu ye and zhen-hua ling.
2019. distant supervi-sion relation extraction with intra-bag and inter-bagattentions.
arxiv preprint arxiv:1904.00143..daojian zeng, kang liu, yubo chen, and jun zhao.
2015. distant supervision for relation extraction viain pro-piecewise convolutional neural networks.
ceedings of the 2015 conference on empirical meth-ods in natural language processing, pages 1753–1762..ningyu zhang, shumin deng, zhanlin sun, guanyingwang, xi chen, wei zhang, and huajun chen.
2019.long-tail relation extraction via knowledge graphembeddings and graph convolution networks.
arxivpreprint arxiv:1903.01306..raphael hoffmann, congle zhang, xiao ling, lukezettlemoyer, and daniel s weld.
2011. knowledge-based weak supervision for information extractionof overlapping relations.
in proceedings of the 49thannual meeting of the association for computationallinguistics: human language technologies, pages541–550..linmei hu, luhao zhang, chuan shi, liqiang nie,weili guan, and cheng yang.
2019.improvingdistantly-supervised relation extraction with joint la-in proceedings of the 2019 con-bel embedding.
ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 3812–3820..sharmistha jat, siddhesh khandelwal, and parthatalukdar.
2018. improving distantly supervised rela-tion extraction using word and entity based attention.
arxiv preprint arxiv:1804.06987..guoliang ji, kang liu, shizhu he, and jun zhao.
2017. distant supervision for relation extractionwith sentence-level attention and entity descriptions.
in proceedings of the aaai conference on artiﬁcialintelligence, volume 31..yang li, guodong long, tao shen, tianyi zhou, linayao, huan huo, and jing jiang.
2020. self-attentionenhanced selective gate with entity-aware embed-ding for distantly supervised relation extraction.
inproceedings of the aaai conference on artiﬁcial in-telligence, volume 34, pages 8269–8276..yankai lin, shiqi shen, zhiyuan liu, huanbo luan,and maosong sun.
2016. neural relation extractionwith selective attention over instances.
in proceed-ings of the 54th annual meeting of the associationfor computational linguistics (volume 1: long pa-pers), pages 2124–2133..tianyu liu, kexiang wang, baobao chang, and zhi-fang sui.
2017. a soft-label method for noise-tolerant distantly supervised relation extraction.
inproceedings of the 2017 conference on empiricalmethods in natural language processing, pages1790–1795..mike mintz, steven bills, rion snow, and dan juraf-sky.
2009. distant supervision for relation extrac-in proceedings of thetion without labeled data.
joint conference of the 47th annual meeting of theacl and the 4th international joint conference onnatural language processing of the afnlp, pages1003–1011..hao peng, tianyu gao, xu han, yankai lin, pengli, zhiyuan liu, maosong sun, and jie zhou.
2020.learning from context or names?
an empiricalstudy on neural relation extraction.
arxiv preprintarxiv:2010.01923..sebastian riedel, limin yao, and andrew mccallum.
2010. modeling relations and their mentions with-in joint european conferenceout labeled text..4671