towards emotional support dialog systems.
siyang liu1,2‚àó, chujie zheng1‚àó, orianna demasi3, sahand sabour1, yu li3,zhou yu4, yong jiang2, minlie huang1‚Ä†1the coai group, dcst, institute for artiÔ¨Åcial intelligence, state key lab of intelligent technology and systems,1beijing national research center for information science and technology, tsinghua university, beijing 100084, china2tsinghua-berkeley shenzhen institute, tsinghua shenzhen international graduate school,2tsinghua university, shenzhen, china.
3university of california, davis.
4columbia university.
siyang-l18@mails.tsinghua.edu.cn, chujiezhengchn@gmail.com, aihuang@tsinghua.edu.cn.
abstract.
emotional support is a crucial ability for manyconversation scenarios, including social inter-actions, mental health support, and customerservice chats.
following reasonable proce-dures and using various support skills can helpto effectively provide support.
however, dueto the lack of a well-designed task and corporaof effective emotional support conversations,research on building emotional support into di-alog systems remains untouched.
in this pa-per, we deÔ¨Åne the emotional support conver-sation (esc) task and propose an esc frame-work, which is grounded on the helping skillstheory (hill, 2009).
we construct an emotionsupport conversation dataset (esconv) withrich annotation (especially support strategy) ina help-seeker and supporter mode.
to ensure acorpus of high-quality conversations that pro-vide examples of effective emotional support,we take extensive effort to design training tu-torials for supporters and several mechanismsfor quality control during data collection.
fi-nally, we evaluate state-of-the-art dialog mod-els with respect to the ability to provide emo-tional support.
our results show the impor-tance of support strategies in providing effec-tive emotional support and the utility of es-conv in training more emotional support sys-tems 1..1.introduction.
emotional support (es) aims at reducing indi-viduals‚Äô emotional distress and helping them un-derstand and work through the challenges thatthey face (burleson, 2003; langford et al., 1997;heaney and israel, 2008).
it is a critical capacityto train into dialog systems that interact with users.
‚àóequal contribution.
‚Ä† corresponding author.
1our data and codes are available athttps://github.com/thu-coai/emotional-support-conversation..figure 1: an example chat showing effective emotionalsupport (adapted from esconv) being provided to thehelp-seeker(left) by the supporter(right).
the supportstrategies (skills) used by the supporter are marked inthe parentheses before the utterances.
the red boldtexts in the dashed boxes highlight the three stages ofour proposed esc framework (figure 3)..on daily basis (van der zwaan et al., 2012; zhouet al., 2020), particularly for settings that includesocial interactions (accompanying and cheering upthe user), mental health support (comforting a frus-trated help-seeker and helping identify the prob-lem), customer service chats (appeasing an angrycustomer and providing solutions), etc.
recentresearch has also shown that people prefer dialogsystems that can provide more supportive responses(rains et al., 2020)..research has shown that providing emotionalsupport is not intuitive (burleson, 2003), so proce-dures and conversational skills have been suggested(hill, 2009) to help provide better support throughconversation.
such skills can be seen in the exam-ple conversation that we collected and is shownin figure 1. to identify the causes of the help-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3469‚Äì3483august1‚Äì6,2021.¬©2021associationforcomputationallinguistics3469üòøifeelsofrustrated.ishouldfirstunderstandhis/hersituation...letmeexplorehis/herexperiencesüòØ(question)may i ask why you are feeling frustrated?üòømy school was closed without any prior warning due to thepandemic.ishouldcomforthim/herwhengradually learning abouthis/hersituation(providing suggestions)have you thought about talking to yourparents or a close friend about this?ü§î(self-disclosure)iunderstandyou.i wouldalso have been really frustrated ifthat happened to me.üòîüòøyeah!
i don't even know what is going to happen with our final.mere comforting cannot solve the problem...letmehelphim/hertakesomeactionandgetout of the difficulty(reflectionoffeelings)that is really upsetting and stressful.
seeker‚Äôs distress, the supporter Ô¨Årst explores thehelp-seeker‚Äôs problems.
without exploration, thesupport is unlikely to understand the help-seeker‚Äôsexperiences and feelings, and thus it may be offen-sive or even harmful if the supporter would giveirrelevant advice, like ‚Äòyou could go for a walk torelax‚Äô.
while learning about the help-seeker‚Äôs sit-uation, the supporter may express understandingand empathy to relieve the help-seeker‚Äôs frustra-tion by using various skills (e.g., self-disclosure,reÔ¨Çection of feelings, etc.).
after understandingthe help-seeker‚Äôs problem, the supporter may of-fer suggestions to help the help-seeker cope withthe problem.
if the supporter only comforts thehelp-seeker without any inspiration for action tochange, the supporter may not effectively help thehelp-seeker‚Äôs emotions improve.
finally, duringthe data collection of this example conversation, thehelp-seeker reported that their emotion intensity de-creased from 5 to 2 (emotion intensity is labeledin our corpus, we give detailed annotations of thisconversation example in appendix a), which indi-cates the effectiveness of the es provided by thesupporter..despite the importance and complexity of es,research on data-driven es dialog systems is lim-ited due to a lack of both task design and relevantcorpora of conversations that demonstrate diversees skills in use.
first, existing research systemsthat relate to emotional chatting (zhou et al., 2018)or empathetic responding (rashkin et al., 2019)return messages that are examples of emotion orempathy and are thus limited in functionality, asthey are not capable of many other skills that areoften used to provide effective es (hill, 2009).
fig-ure 2 illustrates the relationship between the threetasks and we provide further discussion in section2.1. second, people are not naturally good at beingsupportive, so guidelines have been developed totrain humans how to be more supportive.
withouttrained individuals, existing online conversationdatasets(sharma et al., 2020a; rashkin et al., 2019;zhong et al., 2020; sun et al., 2021) do not natu-rally exhibit examples or elements of supportiveconversations.
as a result, data-driven models thatleverage such corpora (radford et al., 2019; zhanget al., 2020; roller et al., 2020) are limited in theirability to explicitly learn how to utilize supportskills and thus provide effective es..in this paper, we deÔ¨Åne the task of emotionalsupport conversation (esc), aiming to provide.
figure 2: emotional support conversations (our work)can include elements of emotional chatting (zhou et al.,2018) and empathetic responding(rashkin et al., 2019)..support through social interactions (like the inter-actions between peers, friends, or families) ratherthan professional counseling, and propose an escframework, which is grounded on the helpingskills theory (hill, 2009) and tailored to be appro-priate for a dialog system setting (figure 3).
wecarefully design the esc framework for a dialogsystem setting by adapting relevant components ofhill‚Äôs helping skills model of conversational sup-port.
the esc framework proposes three stages(exploration, comforting and action), where eachstage contains several support strategies (or skills).
to facilitate the research of emotional support con-versation, we then construct an emotional supportconversation dataset, esconv, and take multipleefforts to ensure rich annotation and that all con-versations are quality examples for this particu-larly complex dialog task.
esconv is collectedwith crowdworkers chatting in help-seeker and sup-porter roles.
we design tutorials based on the escframework and train all the supporters and devisemultiple manual and automatic mechanisms to en-sure effectiveness of emotional support in conver-sations.
finally, we evaluate the state-of-the-artmodels and observe signiÔ¨Åcant improvement in theemotional support provided when various supportstrategies are utilized.
further analysis of the in-teractive evaluation results shows the joint modelcan mimic human supporters‚Äô behaviors in strat-egy utilization.
we believe our work will facilitateresearch on more data-driven approaches to builddialog systems capable of providing effective emo-tional support..2 related work.
2.1 emotional & empathetic conversation.
figure 2 intuitively shows the relationships amongesc, emotional conversation, and empathetic con-versation.
emotion has been shown to be impor-.
3470emotionalsupportconversationreduce users' emotional distress and help them work through the challengesempatheticrespondingunderstandusers'feelingsandreply accordinglyemotionalchattingaccuratelyexpressemotionsinresponsestant for building more engaging dialog systems(zhou et al., 2018; li et al., 2017; zhou and wang,2018; huber et al., 2018; huang et al., 2020).
asa notable work of emotional conversation, zhouet al.
(2018) propose emotional chatting machine(ecm) to generate emotional responses given apre-speciÔ¨Åed emotion.
this task is required to ac-curately express (designated or not) emotions ingenerated responses.
while es may include ex-pressing emotions, such as happiness or sadness, ithas a broader aim of reducing the user‚Äôs emotionaldistress through the utilization of proper supportskills, which is fundamentally different from emo-tional chatting.
emotional chatting is merely abasic quality of dialog systems, while es is a morehigh-level and complex ability that dialog systemsare expected to be equipped with.
another relatedtask is empathetic responding (rashkin et al., 2019;lin et al., 2019; majumder et al., 2020; zandie andmahoor, 2020; sharma et al., 2020a; zhong et al.,2020; zheng et al., 2021), which aims at under-standing users‚Äô feelings and then replying accord-ingly.
for instance, rashkin et al.
(2019) arguedthat dialog models can generate more empatheticresponses by recognizing the interlocutor‚Äôs feelings.
effective es naturally requires expressing empa-thy according to the help-seeker‚Äôs experiences andfeelings, as shown in our proposed emotional sup-port framework (section 3.2, figure 3).
hence,empathetic responding is only one of the necessarycomponents of emotional support.
in addition toempathetic responding, an emotional support con-versation needs to explore the users‚Äô problems andhelp them cope with difÔ¨Åculty..2.2 related datasets for emotional support.
various works have considered conversations ofemotional support in a social context, such as onsocial media or online forums (medeiros and bosse,2018; sharma et al., 2020b; hosseini and caragea,2021).
medeiros and bosse (2018) collected stress-related posts and response pairs from twitter andclassiÔ¨Åed replies into supportive categories.
in(sharma et al., 2020b), the post-response pairs fromtalklife and mental health subreddits are annotatedwith the communication mechanisms of text-basedempathy expression (only the data of the redditpart is publicly available).
hosseini and caragea(2021) also collected such post-response pairs fromonline support groups, which have been annotatedas needing or expressing support.
the dialoguesin these corpora are either single-turn interactions.
(post-response pair) or very short conversations,which limits the potential for effective es, as es of-ten requires many turns of interaction (hill, 2009)..2.3 emotional support dialog systemssome traditional dialog systems have appliedhuman-crafted rules to provide emotional supportresponses (van der zwaan et al., 2012; van derzwaan et al., 2012).
a recent system has consid-ered a rule-based algorithm that determines thesupportive act used in the response and then se-lects proper replies from the pre-deÔ¨Åned list ofcandidates (medeiros and bosse, 2018).
anotherconversational system designed to provide supportfor coping with covid-19 was implemented byidentifying topics that users mentioned and thenresponding with a reÔ¨Çection from a template or amessage from a pre-deÔ¨Åned lexicon (welch et al.,2020).
few studies have focused on generating sup-portive responses, and those that have have beenlimited in scope.
for example, shen et al.
(2020)explored how to generate supportive responses viareÔ¨Çecting on user input..3 emotional support conversation.
3.1 task deÔ¨Ånitionwhen a user is in a bad emotional state, perhapsdue to a particular problem, they may seek help toimprove their emotional state.
in this setting, theuser can be tagged with a negative emotion labele, a emotion intensity level l (e.g., ranging from 1to 5), and an underlying challenge that the user isgoing through.
the supporter (or the system) needsto comfort the user in a conversation with supportskills to lower their intensity level.
note that theuser‚Äôs state is unknown to the supporter prior tothe conversation.
during the conversation, the sup-porter needs to identify the problem that the useris facing, comfort the user, and then provide somesuggestions or information to help the user takeaction to cope with their problem.
an emotionalsupport conversation is effective if the intensitylevel of the user is lowered at the end of the con-versation, or more concretely, if the supporter caneffectively identify the problem, comfort the user,and provide solutions or suggestions..the esc task has several sub-problems: (1) sup-port strategy selection and strategy-constrained re-sponse generation.
as shown in our later experi-ments (section 6.4), the timing of applying strate-gies is relevant to the effectiveness of es.
it is thusimportant that a generated response conforms to a.
3471figure 3: overview of our proposed esc framework.
it contains three stages and suggested support strategies.
the procedure of emotional support generally follows the order: 1(cid:13)exploration ‚Üí 2(cid:13)comforting ‚Üí 3(cid:13)action (asindicated by the black arrows), but it can also be adapted to the individual conversation as needed (indicated bythe dashed gray arrows).
the column of ‚Äúlexical features‚Äù displays top 5 unigrams or bigrams associated withmessages that use each strategy in our dataset.
each feature is ranked by the rounded z-scored log odds ratios(monroe et al., 2008) in the parentheses..speciÔ¨Åed strategy.
(2) emotion state modeling.
itis important to model and track the user‚Äôs emotionstate dynamically, both for dynamic strategy selec-tion and for measuring the effectiveness of esc.
(3)evaluation of support effectiveness.
in addition tothe traditional dimension of evaluating a conversa-tion‚Äôs relevance, coherence, and user engagement,esc raises a new dimension of evaluating the ef-fectiveness of es..3.2 esc framework.
we present an esc framework, which character-izes the procedure of emotional support into threestages, each with several suggested support strate-gies.
we ground the esc framework on hill‚Äôshelping skills theory (hill, 2009) and adapt itmore appropriate for a dialog system setting, aim-ing to provide support through social interactions(like the interactions between peers, friends, or fam-ilies) rather than merely professional counseling.
an overview of the conversational stages and strate-gies in the esc framework is shown in figure 3.stages hill (2009) proposes three stages of sup-porting people: exploration (exploring to help thehelp-seeker identify the problems), insight (help-ing the help-seeker move to new depths of self-understanding), and action (helping the help-seekermake decisions on actions to cope with the prob-lems).
however, we note that insight usually re-quires re-interpreting users‚Äô behaviors and feel-ings, which is both difÔ¨Åcult and risky for the sup-porters without sufÔ¨Åcient support experience.
wethus adapt insight to comforting (deÔ¨Åned as provid-.
ing support through empathy and understanding).
while it is suggested that emotional support conver-sations target these three ordered stages, in practiceconversations cannot follow a Ô¨Åxed or linear orderand must adapt appropriately.
as suggested in (hill,2009), the three stages can be Ô¨Çexibly adjusted tomeet the help-seeker‚Äôs needs.
strategies hill (2009) also provides several rec-ommended conversational skills for each stage.
some of the described skills are not appropriate2in a dialog system setting without professional su-pervision and experience.
to adapt these skillsappropriate to the dialog system setting, we extractseven methods from these skills (along with an‚Äúothers‚Äù one), which we called strategies in ourtask and hereafter.
we provide a detailed deÔ¨Ånitionof each strategy in appendix b..4 data collection.
to facilitate the research of emotional support skillsin dialog systems, we introduce an emotional sup-port conversation dataset, esconv, which is col-lected in a help-seeker and supporter mode withcrowdworkers.
as high-quality conversation ex-amples are needed for this complex task, we tooktremendous effort to try to ensure the effective-ness of es in conversations.
our efforts includedthe following major aspects: (1) because providingconversational support is a skill that must be trained.
2for instance, one skill named challenging refers to point-ing out the discrepancies or irrational beliefs that the help-seeker is unaware of or unwilling to change.
such skillsusually require professional experience, which is too difÔ¨Åcultfor an average person..3472strategiesstagesexampleslexical featuresquestioncan you talk more about your feelings at that time?do you (15.0), are you (13.8), how (13.7), what (12.3), do (11.5)restatement or paraphrasingit sounds that you feel like everyone is ignoring you.
is it correct?is that (8.2), so you (8.2), it sounds (7.1), correct (7.1), so (6.6)reflection offeelingsi understand how anxious you are.can tell (7.4), understand how (5.8), are feeling (5.1), tell (5.1), understand (4.9)self-disclosurei feel the same way!
i also don't know what to say to strangers.my (15.3), was (10.5), me (10.2), had (9.7), myself (7.8)affirmation and reassuranceyou've done your best and i believe you will get it!its (5.7), thats(5.6), will (5.4), through this (5.1), you will (4.7)providing suggestionsdeep breaths can help people calm down.
could you try to take a few deep breaths?maybe (7.3), if (6.5), have you (6.4), talk to (5.8), suggest (5.8)informationapparently, lots of research has found that getting enough sleep before an exam can help students perform better.there are (4.4), will (3.8), available (3.7), seen (3.3), possible (3.3)othersi am glad to help you!welcome (9.6), hope (9.6), glad (7.3), thank (7.0), hope you (6.9)‚ë¢actionhelptheseekersolvetheproblems‚ë°comfortingcomforttheseekerthroughexpressingempathyandunderstanding‚ë†explorationexploretoidentifytheproblemsfor supporters to be effective (burleson, 2003), wedesign a tutorial with the esc framework and traincrowdworkers to be supporters.
only those whopass the examination are admitted to the task.
(2)we require help-seekers to complete a pre-chat sur-vey on their problems and emotions and to providefeedback during and after the conversations.
(3) wedevise and use multiple manual or automatic mech-anisms to Ô¨Ålter out the low-quality conversationsafter collecting raw dialog data..4.1 supporter-speciÔ¨Åc taskstraining and examinationto teach crowd-workers how to provide effective emotional support,we designed a tutorial with the esc framework.
inspired by 7cups (7cups.com) (baumel, 2015),we developed eleven sub-tasks (3 + 8) to help work-ers to learn the deÔ¨Ånitions of the three stages andthe eight support strategies.
each sub-task includesan example conversation excerpt and a correspond-ing quiz question.
as noted in section 3.2, we alsoinformed participants that following a Ô¨Åxed ordermay not be possible and that they may need to beÔ¨Çexible with adjusting the stage transitions.
strategy annotation to encourage supportersto use the esc support strategies during the con-versation and to structure the resulting dataset, weask the supporter to Ô¨Årst select a proper strategythat they would like to use according to the dialogcontext.
they are then able to write an utterancereÔ¨Çecting their selected strategy.
we encouragesupporters to send multiple messages if they wouldlike to use multiple strategies to provide support.
post-chat survey after each conversation, thesupporter is asked to rate the extent that the seekergoes into detail about their problems on Ô¨Åve-pointlikert scales..4.2 seeker-speciÔ¨Åc taskspre-chat survey before each conversation, thehelp-seeker was asked to complete the followingsurvey: (1) problem & emotion category: the help-seeker should select one problem from 5 optionsand one emotion from 7 options (the options werebased on conversations collected in pilot data col-lection trials).
(2) emotion intensity: a score from1 to 5 (the larger number indicates a more intenseemotion).
(3) situation: open text describing thecauses of the emotional problem.
(4) experienceorigin: whether the described situation was the cur-rent experience of the help-seeker or based on priorlife circumstances.
we found that 75.2% of conver-.
roles.
aspects.
supporter(‚â• 3)*.
understanding the help-seeker‚Äôs experi-ences and feelings (rated by the help-seeker).
relevance of the utterances to the con-versation topic (rated by the help-seeker).
average length of utterances.
improvement in the help-seeker‚Äôs emo-tion intensity (rated by the help-seeker)**.
criteria.
>= 3.
>= 4.
>= 8.
>= 1.seeker.
describing details about the own emo-tional problems (rated by the supporter).
notrequired.
average length of utterances.
>= 6.table 1: criteria of high-quality conversations.
* de-notes that supporters must meet at least two of the threecriteria.
in **, the improvement of the help-seeker‚Äôsemotion intensity was calculated by subtracting the in-tensity after from that before the conversation..sations originated from the help-seekers‚Äô currentexperiences.
feedback during the conversation,the help-seeker was asked to give feedback after every twonew utterances they received from the supporter.
their feedback scored the helpfulness of the sup-porter messages on a 5-star scale.
we divided eachconversation into three phases and calculated theaverage feedback score for each phase.
the scoresin the three phases are 4.03, 4.30, and 4.44 re-spectively, indicating that the supporters were sufÔ¨Å-ciently trained to effectively help the help-seekersfeel better.
post-chat survey after each conversation, thehelp-seeker is asked to rate their emotion and theperformance of the supporter on the following Ô¨Åve-point likert scales: (1) their emotion intensity af-ter the emotional support conversation (a decreasefrom the intensity before the conversation reÔ¨Çectsemotion improvement), (2) the supporter‚Äôs empa-thy and understanding of the help-seeker‚Äôs expe-riences and feelings, and (3) the relevance of thesupporter‚Äôs responses to the conversation topic..4.3 quality controlwe use multiple methods to ensure that the corpuscontains high-quality examples of effective emo-tional support conversations.
preliminary filtering mechanisms when re-cruiting participants for the supporter role, weinitially received 5,449 applicants, but only 425(7.8%) passed the training tutorial.
from the 2,472conversations that we initially collected, we Ô¨Ålteredout those that were not Ô¨Ånished by the help-seekersor that had fewer than 16 utterances.
this Ô¨Åltering.
3473left 1,342 conversations (54.3%) for consideration.
auto-approval program for qualiÔ¨Åed conver-sations we carefully designed the auto-approvalprogram, which is the most important part of dataquality control.
this program uses criteria basedon the post-chat survey responses from both rolesand the length of utterances, which are summarizedin table 1. these criteria are based on initial hu-man reviewing results.
we show how to choosethese auto-approval criteria in appendix d. thecomputed average emotion intensity before conver-sations is 4.04 and 2.14 after.
such improvementdemonstrates the effectiveness of the emotionalsupport provided by the supporters.
in a smallnumber of conversations, the help-seeker did notÔ¨Ånish the post-chat surveys, so we added anothercriterion for these conversations requiring that thelast two feedback scores from the help-seekers areboth greater than 4. thus, among all the conver-sations without post-chat surveys, only those whomet both (2) and (3) were qualiÔ¨Åed.
using thesequality criteria, 1,053 (78.5% of 1,342) of collectedconversations were qualiÔ¨Åed.
annotation correction to further ensure dataquality, we reviewed and revised incorrect anno-tations of support strategy and seeker‚Äôs emotionintensity.
(1) for strategy annotation correction,we asked new qualiÔ¨Åed supporters to review andrevise annotations on previously collected conver-sations as necessary, which led to 2,545 utterances(17.1%) being reviewed.
we manually reviewedannotations where more than 75% of reviewers dis-agreed and revised 139 of them.
(2) accordingto the auto-approval criteria (table 7), a conversa-tion can be qualiÔ¨Åed when the score of the seeker‚Äôsemotion improvement is less than one, but the otherthree criteria are satisÔ¨Åed.
upon review, we foundthis to most often result from seekers mistakingnegative emotion intensity as the positiveness oftheir emotion.
we manually re-checked and revisedthe emotion intensity of these conversations by us-ing other helpful information, such as the responsesto the post-chat survey open question and the seek-ers‚Äô feedback scores during the chat.
of 130 suchconversations, 92% were revised and included inthe corpus..5 data characteristics.
5.1 statisticsthe overall statistics of the 1,053 esconv exam-ples are shown in table 2. relatively long conversa-tions (avg.
29.8 utterances) indicate that providing.
category.
total supporter seeker.
# dialoguesavg.
minutes per chat# workers# utterancesavg.
length of dialoguesavg.
length of utterances.
1,05322.685431,41029.817.8.
--42514,85514.120.2.
--53216,55515.715.7.table 2: statistics of esconv..categories.
num proportion.
1,053.
100.0%.
m ongoing depression.
job crisisbreakup with partnerproblems with friendsacademic pressure.
elborps‚Äôrekees.noitomes‚Äôrekees.overall.
anxietydepressionsadnessangerfeardisgustshame.
overall.
k 1 (very bad)ca2 (bad)bd3 (average)eef4 (good)s‚Äôr5 (excellent)ekees.overall.
questionrestatement or paraphrasingreÔ¨Çection of feelingsself-disclosureafÔ¨Årmation and reassuranceproviding suggestionsinformationothers.
ygetartstroppus.306233216159139.
28127625096883230.
1,053.
711839601,8553,144.
6,213.
3,1098831,1561,3962,3882,3239042,696.
29.1%22.1%20.5%15.1%13.2%.
26.7%26.2%23.7%9.1%8.4%3.0%2.8%.
100.0%.
1.1%2.9%15.5%29.9%50.6%.
100.0%.
20.9%5.9%7.8%9.4%16.1%15.6%6.1%18.1%.
overall.
14,855.
100.0%.
table 3: statistics of all the annotations, including thehelp-seekers‚Äô problems, emotions, feedback, and thesupport strategies..effective es usually requires many turns of interac-tion and considerably more turns than typical forprevious emotional chatting (zhou et al., 2018) orempathetic dialog (rashkin et al., 2019) datasets.
we also present the statistics of other annotationsin table 3. perhaps due to the current outbreakof covid-19, ongoing depression and job crisisare the most commonly stated problems for thehelp-seekers and depression and anxiety are themost commonly noted emotions.
from the help-seekers‚Äô feedback, we found that they are usuallyhighly satisÔ¨Åed with the emotional support, whichfurther indicates that the training tutorial basedon the esc framework indeed helps supporterslearn to provide effective es.
we release all theseannotations to facilitate further research..3474as the tutorial of esc framework trains, supportersusually ask questions and explore the help-seekers‚Äôsituations before comforting the help-seekers..6 experiments.
our experiments focus on two key questions: (1)how much can esconv with strategy annotationimprove state-of-the-art generative dialog models?
(2) can these models learn to provide effectiveemotional support from esconv?.
6.1 backbone modelswe used two state-of-the-art pre-trained models asthe backbones of the compared variant models:blenderbot blenderbot (roller et al., 2020) isan open-domain conversational agent trained withmultiple communication skills, including empa-thetic responding.
as such, blenderbot should becapable of providing es for users to some extent.
we used the small version3 of blenderbot in exper-iments, because the larger versions have the limi-tation of maximum context length 128, which wefound harms the model performance and responsecoherence.
dialogpt we additionally evaluated dialogpt(zhang et al., 2020), which is a gpt-2-based modelpre-trained on large-scale dialog corpora.
we usedthe small version4..6.2 variant modelstaking each of the above pre-trained models as thebackbone, we built the following variant models:vanilla directly Ô¨Åne-tuning the backbone modelon esconv with no access to strategy annota-tions.
formally, suppose the Ô¨Çattened dialog his-tory is x and the response to be generated is y, wemaximize the conditional probability: p(y|x) =(cid:81)|y|i=1.
p (yi|x, y‚â§i)..variants with strategy to incorporate the strat-egy annotation into the backbone model, we used aspecial token to represent each strategy.
for eachutterance y from the supporters, we appended thecorresponding strategy token before this utterance:Àúy = [st] ‚äï y, where [st] denotes the special to-ken of the used strategy.
then, taking the Ô¨Çat-tened dialog history x as input, the model gen-erates the response conditioned on the Ô¨Årst pre-dicted (or designated) strategy token: p(Àúy|x) =p([st]|x) (cid:81)|y|p (yi|x, [st], y<i).
i=1.
3https://huggingface.co/facebook/.
blenderbotbot_small-90m.
4https://huggingface.co/microsoft/.
dialogpt-small.
figure 4: the distribution of strategies at different con-versation progress..5.2 strategy analysis.
lexical features we extracted lexical featuresof each strategy by calculating the log odds ratio,informative dirichlet prior (monroe et al., 2008)of all the unigrams and bigrams for each strategycontrasting to all other strategies.
we list the top 5phrases for each strategy in figure 3. those strate-gies are all signiÔ¨Åcantly (z-score > 3) associatedwith certain phrases (e.g., question with ‚Äúare you‚Äù,self-disclosure with ‚Äúme‚Äù).
strategy distribution we computed the distri-bution of strategies at different phases of the con-versation.
for a conversation with l utterances intotal, the k-th (1 ‚â§ k ‚â§ l) utterance is from thesupporter and adopts the strategy st, we say that itlocates at the conversation progress k/l.
speciÔ¨Å-cally, we split the conversation progress into six in-i=0[i/5, (i + 1)/5) (cid:83){1}.
then,tervals: [0, 1] = (cid:83)4for all the conversations in esconv, we countedthe proportions of different strategies in the six in-tervals.
we split the conversation progress intoi=0[i/5, (i + 1)/5) (cid:83){1}six intervals: [0, 1] = (cid:83)4and drew the distributions on the six intervals atsix points i/5(i = 0, .
.
.
, 5) respectively and con-nected them, Ô¨Ånally obtaining figure 4..the supporters generally follow the stage ordersuggested by the esc framework (figure 3), butthere is also Ô¨Çexible adjustment of stages and adop-tion of strategies.
for instance, at the early phaseof conversation, the supporters usually adopt ex-ploratory strategies such as question.
after know-ing help-seekers‚Äô situations, the supporters tendto provide their opinions (such as providing sug-gestions).
throughout the entire conversation, thecomforting strategies (such as afÔ¨Årmation and re-assurance) are used and label a relatively constantproportion of messages.
strategy transition we present the top-5 mostfrequent strategy transitions with 3 / 4 hops in ap-pendix (table 6).
these transitions indicate that,.
3475backbones variants.
ppl.
b-2.
r-l.extrema.
vanilla.
15.51.
5.13.
15.26.dialogpt.
joint.
5.00.
15.09.oracle.
15.19.
5.52.
15.82.vanilla.
16.23.
5.45.
15.43.blenderbot.
joint.
5.35.
15.46.oracle.
16.03.
6.31.
17.90.
-.
-.
49.80.
49.97.
50.18.
50.49.
50.27.
51.65.table 4: results of automatic evaluation.
the resultsin bold are signiÔ¨Åcantly better than all the competitors(student‚Äôs t-test, p-value < 0.05)..we studied three variants that use strategy an-notation in the later experiments.
(1) oracle: re-sponses are generated conditioned on the gold ref-erence strategy tokens.
(2) joint: responses aregenerated conditioned on predicted (sampled) strat-egy tokens.
(3) random: responses are generatedconditioned on randomly selected strategies.
im-plementation details are in appendix c..6.3 automatic evaluationto investigate the impact of utilizing support strate-gies on the model performance with either blender-bot or dialogpt as the backbone, we comparedthe performance of the vanilla, joint, and oraclevariants described above.
the automatic metricswe adopted include perplexity (ppl), bleu-2 (b-2) (papineni et al., 2002), rouge-l (r-l) (lin,2004), and the bow embedding-based (liu et al.,2016) extrema matching score.
the metrics ex-cept ppl were calculated with an nlg evaluationtoolkit5 (sharma et al., 2017) with responses tok-enized by nltk6 (loper and bird, 2002)..there are three major Ô¨Åndings from the experi-ments (table 4).
(1) the oracle models are signiÔ¨Å-cantly superior to the vanilla models on all the met-rics, indicating the great utility of support strategies.
(2) the joint models obtain sightly lower scoresthan the vanilla models, as, if the predicted strategyis different from the ground truth, the generated re-sponse will be much different from the referenceresponse.
however, learning to predict strategiesis important when there are no ground truth labelsprovided, and we will further investigate the per-formance of the joint model in human interactiveevaluation (section 6.4).
(3) the blenderbot vari-ants consistently perform better than the dialogptones, indicating that blenderbot is more suitablefor the esc task.
thus, in the subsequent humanevaluation, we will focus evaluation on the blender-.
5https://github.com/maluuba/nlg-eval6https://www.nltk.org/.
joint vs..w/o ft.vanillawin lose win lose win lose.
random.
71‚Ä°fluencyidentiÔ¨Åcation 65‚Ä°75‚Ä°comforting72‚Ä°suggestion.
overall.
73‚Ä°.
24252021.
20.
52‚Ä†5054‚Ä°47.
51‚Ä†.
35343439.
34.
53‚Ä†54‚Ä†4748‚Ä†.
56‚Ä°.
35373927.
36.table 5: results of the human interactive evaluation.
ties are not shown.
all the models use blenderbot asthe backbone.
‚Äòw/o ft‚Äô denotes the blenderbot modelwithout Ô¨Åne-tuning on esconv.
the joint model out-performs all the competitors on all the metrics (signtest, ‚Ä†/‚Ä° denote p-value < 0.1/0.05 respectively)..bot variants..6.4 human interactive evaluation.
we recruited participants from amazon mechani-cal turk to chat with the models.
the online testswere conducted on the same platform as our datacollection, but with the role of supporter taken bya model.
each participant chatted with two differ-ent models that were randomly ordered to avoidexposure bias.
participants were asked to comparethe two models based on the following questions:(1) fluency: which bot‚Äôs responses were more Ô¨Çu-ent and understandable?
(2) identiÔ¨Åcation: whichbot explored your situation more in depth and wasmore helpful in identifying your problems?
(3)comforting: which bot was more skillful in com-forting you?
(4) suggestion: which bot gave youmore helpful suggestions for your problems?
(5)overall: generally, which bot‚Äôs emotional supportdo you prefer?
the metrics in (2), (3), and (4) cor-respond to the three stages in the esc framework.
we compare three pairs of models: (a) joint vs.blenderbot (without Ô¨Åne-tuning on esconv), (b)joint vs. vanilla, and (c) joint vs. random (usingrandomly selected strategies).
to better simulatethe real strategy occurrence, the random modelrandomly selects a strategy following the strategydistribution in esconv (table 3)..each pair of models was compared by 100 con-versations with human participants (table 5).
theresults of comparison (a) show that blenderbot‚Äôscapability of providing es is signiÔ¨Åcantly improvedon all the metrics after being Ô¨Åne-tuned on esconv.
from comparison (b), we found that utilizing strate-gies can better comfort the users.
the results ofcomparison (c) also demonstrate that the propertiming of strategies is critical to help users identifytheir problems and to provide effective suggestions.
in general, through being Ô¨Åne-tuned with the su-.
3476figure 5: the joint model‚Äôs generation distribution.
the meanings of all the graphics and abbreviations areconsistent with figure 4..acknowledgments.
potential utility of esconv in terms of improvingdialog systems‚Äô ability to provide effective es.
ourwork can facilitate future research of es dialogsystems, as well as improve models for other con-versation scenarios where emotional support playsan important role.
strategy selection and realiza-tion, user state modeling, and task evaluation areimportant directions for further research..this work was supported by the nsfc projects61936010 and regular(key project with no.
project with no.
61876096).
this work wasalso supported by the guoqiang institute of ts-inghua university, with grant no.
2019gqg1 and2020gqg0005..ethical considerations.
there are many types and levels of support that hu-mans can seek to provide, e.g., professional versuspeer support, and some of these levels may be inap-propriate, unrealistic, and too risky for systems todeliver.
however, as dialog systems become morecommon in daily use, opportunities will arise whenat least some basic level of supportive statementsmay be required.
in developing the esc frame-work, we have carefully considered which elementsof conversational support may be relevant for a di-alog system and omitted elements that are clearoversteps.
considerable additional work is neededto determine what are appropriate levels of supportfor systems to provide or that can be expected fromsystems, but our work provides a cautious, yet con-crete, step towards developing systems capable ofreasonably modest levels of support.
the corpuswe construct can also provide examples to enablefuture work that probes the ethical extent to whichsystems can or should provide support.
in additionto these broader ethical considerations, we havesought to ethically conduct this study, includingby transparently communicating with crowdwork-ers about data use and study intent, compensatingworkers at a reasonable hourly wage, and obtain-ing study approval from the institutional reviewboard..references.
amit baumel.
2015. online emotional support deliv-ered by trained volunteers: users‚Äô satisfaction andtheir perception of the service compared to psy-chotherapy.
journal of mental health, 24(5):313‚Äì320..pervision of strategy prediction on esconv, thepre-trained models become preferred by the users,which proves the high-quality and utility of es-conv..6.5 further analysis of human interactive.
evaluation.
in this section, we explore what the dialog mod-els learned from esconv.
firstly, we analyzedthe strategy distribution based on the 300 dialogsbetween users and the joint model in human inter-active experiments.
we can see in figure 5 (thecalculation was consistent with figure 4), the strate-gies that the joint model adopted have a very simi-lar distribution compared with the truth distributionin esconv (figure 4).
it provides important evi-dence that models mimic strategy selection andutilization as human supporters do to achieve moreeffective es.
secondly, we present a case studyin figure 7. we see in cases that the joint modelprovides more supportive responses and uses moreskills in conversation, while blenderbot withoutÔ¨Åne-tuning seems not to understand the user‚Äôs dis-tress very well and prefers to talk more about itself.
this may imply that having more supportive re-sponses and a diverse set of support strategies arecrucial to effective emotional support..7 conclusion.
in this work, we deÔ¨Åne the task of emotional sup-port conversation and present an esc framework.
the esc framework is adapted from the helpingskills theory into a dialog system setting, whichcharacterizes three stages with corresponding sup-port strategies useful at each stage.
we then con-struct an emotional support conversation dataset,esconv.
we carefully design the process of datacollection and devise multiple mechanisms to en-sure the effectiveness of es in conversations.
fi-nally, we evaluate the es ability with state-of-the-art dialog models.
experimental results show the.
3477brant r burleson.
2003..emotional support skill.
handbook of communication and so-cial interaction skills, page 551..jacob cohen.
1960. a coefÔ¨Åcient of agreement fornominal scales.
educational and psychological mea-surement, 20(1):37‚Äì46..catherine a heaney and barbara a israel.
2008. so-cial networks and social support.
health behaviorand health education: theory, research, and prac-tice, 4:189‚Äì210..clara e hill.
2009. helping skills: facilitating, explo-ration, insight, and action.
american psychologicalassociation..ari holtzman, jan buys, li du, maxwell forbes, andyejin choi.
2019. the curious case of neural text de-in international conference on learn-generation.
ing representations..mahshid hosseini and cornelia caragea.
2021. it takestwo to empathize: one to seek and one to provide.
proceedings of the 35th american association forartiÔ¨Åcial intelligence (aaai 2021)..minlie huang, xiaoyan zhu, and jianfeng gao.
2020.challenges in building intelligent open-domain dia-log systems.
acm transactions on information sys-tems (tois), 38(3):1‚Äì32..bernd huber, daniel mcduff, chris brockett, michelgalley, and bill dolan.
2018. emotional dialoguegeneration using image-grounded language models.
in proceedings of the 2018 chi conference on hu-man factors in computing systems, pages 1‚Äì12..diederik p kingma and jimmy ba.
2014. adam: amethod for stochastic optimization.
arxiv preprintarxiv:1412.6980..catherine penny hinson langford, juanita bowsher,joseph p maloney, and patricia p lillis.
1997. so-cial support: a conceptual analysis.
journal of ad-vanced nursing, 25(1):95‚Äì100..yanran li, hui su, xiaoyu shen, wenjie li, ziqiangcao, and shuzi niu.
2017. dailydialog: a manu-ally labelled multi-turn dialogue dataset.
in proceed-ings of the eighth international joint conference onnatural language processing (volume 1: long pa-pers), pages 986‚Äì995, taipei, taiwan.
asian federa-tion of natural language processing..chin-yew lin.
2004. rouge: a package for auto-matic evaluation of summaries.
in text summariza-tion branches out, pages 74‚Äì81, barcelona, spain.
association for computational linguistics..zhaojiang lin, andrea madotto, jamin shin, peng xu,and pascale fung.
2019. moel: mixture of empa-in proceedings of the 2019 con-thetic listeners.
ference on empirical methods in natural language.
processing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 121‚Äì132, hong kong, china.
as-sociation for computational linguistics..chia-wei liu, ryan lowe, iulian serban, mike nose-worthy, laurent charlin, and joelle pineau.
2016.how not to evaluate your dialogue system: anempirical study of unsupervised evaluation metricsfor dialogue response generation.
in proceedings ofthe 2016 conference on empirical methods in natu-ral language processing, pages 2122‚Äì2132, austin,texas.
association for computational linguistics..edward loper and steven bird.
2002. nltk: the natural.
language toolkit.
arxiv preprint cs/0205028..navonil majumder, pengfei hong, shanshan peng,jiankun lu, deepanway ghosal, alexander gel-bukh, rada mihalcea, and soujanya poria.
2020.mime: mimicking emotions for empathetic re-sponse generation.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing (emnlp), pages 8968‚Äì8979, online.
as-sociation for computational linguistics..lenin medeiros and tibor bosse.
2018. using crowd-sourcing for the development of online emotionalin international conference onsupport agents.
practical applications of agents and multi-agentsystems, pages 196‚Äì209.
springer..burt l monroe, michael p colaresi, and kevin mquinn.
2008. fightin‚Äôwords: lexical feature selec-tion and evaluation for identifying the content of po-litical conÔ¨Çict.
political analysis, 16(4):372‚Äì403..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2002. bleu: a method for automatic eval-in proceedings ofuation of machine translation.
the 40th annual meeting of the association for com-putational linguistics, pages 311‚Äì318, philadelphia,pennsylvania, usa.
association for computationallinguistics..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners.
openaiblog, 1(8):9..stephen a rains, corey a pavlich, bethany lutovsky,sup-eric tsetsi, and anjali ashtaputre.
2020.port seeker expectations, support message quality,and supportive interaction processes and outcomes:the case of the comforting computer program revis-ited.
journal of social and personal relationships,37(2):647‚Äì666..hannah rashkin, eric michael smith, margaret li, andy-lan boureau.
2019. towards empathetic open-domain conversation models: a new benchmark andin proceedings of the 57th annual meet-dataset.
ing of the association for computational linguis-tics, pages 5370‚Äì5381, florence, italy.
associationfor computational linguistics..3478stephen roller, emily dinan, naman goyal, da ju,mary williamson, yinhan liu, jing xu, myle ott,kurt shuster, eric m smith, et al.
2020. recipesfor building an open-domain chatbot.
arxiv preprintarxiv:2004.13637..ashish sharma, adam miner, david atkins, and timalthoff.
2020a.
a computational approach to un-derstanding empathy expressed in text-based men-tal health support.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing (emnlp), pages 5263‚Äì5276, online.
as-sociation for computational linguistics..ashish sharma, adam s miner, david c atkins,and tim althoff.
2020b.
a computational ap-proach to understanding empathy expressed inarxiv preprinttext-based mental health support.
arxiv:2009.08441..shikhar sharma, layla el asri, hannes schulz, andjeremie zumer.
2017.relevance of unsuper-vised metrics in task-oriented dialogue for evalu-ating natural language generation.
arxiv preprintarxiv:1706.09799..siqi shen, charles welch, rada mihalcea, andver√≥nica p√©rez-rosas.
2020. counseling-style re-Ô¨Çection generation using generative pretrained trans-in proceedingsformers with augmented context.
of the 21th annual meeting of the special interestgroup on discourse and dialogue, pages 10‚Äì20, 1stvirtual meeting.
association for computational lin-guistics..hao sun, zhenru lin, chujie zheng, siyang liu, andminlie huang.
2021. psyqa: a chinese dataset forgenerating long counseling text for mental healthsupport.
in findings of the association for compu-tational linguistics: acl 2021..janneke m van der zwaan, virginia dignum, andcatholijn m jonker.
2012. a conversation modelenabling intelligent agents to give emotional sup-port.
in modern advances in intelligent systems andtools, pages 47‚Äì52.
springer..jm van der zwaan, v dignum, and cm jonker.
2012.a bdi dialogue agent for social support: speciÔ¨Åca-tion and evaluation method.
in aamas 2012: pro-ceedings of the 11th international conference on au-tonomous agents and multiagent systems, workshopon emotional and empathic agents, valencia, spain,4-8 june 2012; authors version.
international foun-dation for autonomous agents and multiagent sys-tems (ifaamas)..charles welch, allison lahnala, veronica perez-rosas,siqi shen, sarah seraj, larry an, kenneth resni-cow, james pennebaker, and rada mihalcea.
2020.expressive interviewing: a conversational systemfor coping with covid-19.
in proceedings of the1st workshop on nlp for covid-19 (part 2) atemnlp 2020, online.
association for computa-tional linguistics..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, remi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander rush.
2020. trans-formers: state-of-the-art natural language process-ing.
in proceedings of the 2020 conference on em-pirical methods in natural language processing:system demonstrations, pages 38‚Äì45, online.
asso-ciation for computational linguistics..rohola zandie and mohammad h mahoor.
2020.emptransfo: a multi-head transformer architec-ture for creating empathetic dialog systems.
arxivpreprint arxiv:2003.02958..yizhe zhang, siqi sun, michel galley, yen-chun chen,chris brockett, xiang gao, jianfeng gao, jingjingliu, and bill dolan.
2020. dialogpt : large-scale generative pre-training for conversational re-in proceedings of the 58th an-sponse generation.
nual meeting of the association for computationallinguistics: system demonstrations, pages 270‚Äì278, online.
association for computational linguis-tics..chujie zheng, yong liu, wei chen, yongcai leng, andminlie huang.
2021. comae: a multi-factor hier-archical framework for empathetic response genera-in findings of the association for computa-tion.
tional linguistics: acl 2021..peixiang zhong, chen zhang, hao wang, yong liu,and chunyan miao.
2020. towards persona-basedin proceed-empathetic conversational models.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages6556‚Äì6566, online.
association for computationallinguistics..hao zhou, minlie huang, tianyang zhang, xiaoyanzhu, and bing liu.
2018. emotional chatting ma-chine: emotional conversation generation with in-ternal and external memory.
in proceedings of theaaai conference on artiÔ¨Åcial intelligence..li zhou, jianfeng gao, di li, and heung-yeung shum.
2020. the design and implementation of xiaoice, anempathetic social chatbot.
computational linguis-tics, 46(1):53‚Äì93..xianda zhou and william yang wang.
2018. mo-jitalk: generating emotional responses at scale.
inproceedings of the 56th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 1128‚Äì1137, melbourne, aus-tralia.
association for computational linguistics..3479a data example from esconv.
here we detail the conversation that figure 1demonstrates to show the annotations that ourdataset contains.
the detailed example can be seenin figure 6. each pre-chat survey of conversationis labeled its problem category, emotion category,emotion intensity, and a brief of the situation ofthe seeker.
in the context of each conversation, thestrategies used by supporters are labeled and theseeker‚Äôs feedback score per two utterances of thesupporter‚Äôs responses are also given in our dataset.
note that not all conversations have the label ofemotion intensity after the conversation.
it is be-cause some seekers don‚Äôt Ô¨Ånish the post-chat sur-vey but we still include such conversations intoour dataset due to their high quality that meets ourcriteria..figure 6: data example from esconv.
blue text: thehelp-seeker‚Äôs pre-chat survey.
red text: strategies usedby the supporter.
orange text: the question that thesystems ask help-seeker to evaluate the helpfulness pertwo utterances from the supporter.
thus the stars de-note the seeker‚Äôs feedback score..b deÔ¨Ånitions of strategies.
question asking for information related to theproblem to help the help-seeker articulate the is-sues that they face.
open-ended questions are best,.
strategy transition.
proportion.
3-hop.
4-hop.
qu ‚Üí ar ‚Üí ququ ‚Üí rp ‚Üí ququ ‚Üí rp ‚Üí arar ‚Üí qu ‚Üí arot ‚Üí qu ‚Üí rp.
qu ‚Üí ar ‚Üí qu ‚Üí arar ‚Üí qu ‚Üí ar ‚Üí quot ‚Üí qu ‚Üí rp ‚Üí qups ‚Üí ot ‚Üí ps ‚Üí otqu ‚Üí rp ‚Üí ar ‚Üí qu.
19.65 ‚Ä∞14.55 ‚Ä∞12.37 ‚Ä∞11.96 ‚Ä∞11.64 ‚Ä∞.
7.00 ‚Ä∞5.13 ‚Ä∞4.20 ‚Ä∞3.85 ‚Ä∞3.85 ‚Ä∞.
table 6: proportions of top-5 strategy transitions insupporter utterances.
abbreviations are consistent withfigure 4..and closed questions can be used to get speciÔ¨Åcinformation.
restatement or paraphrasing a simple, moreconcise rephrasing of the help-seeker‚Äôs statementsthat could help them see their situation moreclearly.
reÔ¨Çection of feelings articulate and describethe help-seeker‚Äôs feelings.
self-disclosure divulge similar experiences thatyou have had or emotions that you share with thehelp-seeker to express your empathy.
afÔ¨Årmation and reassurance afÔ¨Årm the help-seeker‚Äôs strengths, motivation, and capabilities andprovide reassurance and encouragement.
providing suggestions providesuggestionsabout how to change, but be careful to not overstepand tell them what to do.
information provide useful information to thehelp-seeker, for example with data, facts, opinions,resources, or by answering questions.
others exchange pleasantries and use other sup-port strategies that do not fall into the above cate-gories..c implementation details.
the implementation of all models was based ontransformer library7 (wolf et al., 2020).
we splitesconv into the sets of training / validation / testwith the proportions of 6:2:2. since the conversa-tions in esconv usually have long turns, we cuteach dialog into conversation pieces with 5 utter-ances, which contain one supporter‚Äôs response andthe preceding 4 utterances.
during training, wetrained all the models with adam (kingma and ba,2014) optimizer with learning rate 5e‚àí5.
all themodels were trained for 5 epochs, and the check-.
7https://github.com/huggingface/.
transformers.
3480pre-chat survey problem: academic pressure emotion: anxiety  emotion intensity: 5 situation: my school was closed due to the pandemic.
conversation seeker: i feel so frustrated.
supporter (questions): may i ask why you are feeling frustrated?
seeker: my school was closed without any prior warning due to the pandemic.
supporter (affirmation and reassurance): that is really upsetting and stressful.
i commend you for having to deal with that!
supporter (self-disclosure): i know i would have been really frustrated if that happened to me.
system: do those messages help you feel better?
‚≠ê‚≠ê‚≠ê‚≠ê seeker: yeah!
i don't even know what is going to happen with our finals now.
supporter (restatement or paraphrasing): i can see how that would make you frustrated.
supporter (providing suggestions): have you thought about talking to your parents or a close friend about this?
system: do those messages help you feel better?
‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‚Ä¶ seeker: i really appreciate your assistance today.
i feel better and will take some action this week.
thank you!
supporter (others): you're very welcome!
feel free to chat if you need anything else!
post-chat survey emotion intensity: 2  e interface of data collection platform.
to facilitate readers to have an intuitive under-standing of our data collection process, we presentan interface diagram of some important steps inthe data collection process in figure 8, whichcontains the surfaces of support strategy training,supporter‚Äôs chatting, help-seeker‚Äôs pre-chat survey,help-seeker‚Äôs chatting, and post-survey..points with the lowest perplexity scores on the val-idation set were selected for evaluation.
duringinference, we masked other tokens and sampled astrategy token at the Ô¨Årst position of the response.
for the random variant models, we sampled strate-gies randomly following the strategy distributionin esconv, which is reported in table 3. the re-sponse were decoded by top-k and top-p samplingwith p = 0.9 (holtzman et al., 2019), k = 30, tem-perature œÑ = 0.7, and the repetition penalty 1.03..d auto-approval criteria.
to establish each criterion of the auto-approval pro-gram as shown in the main paper (section 3.4),we searched the most suitable thresholds for eachÔ¨Åltering rule.
we recruited three well-trained hu-man annotators, who have also received the sametraining procedures as the supporter applicants did.
we then randomly sampled 100 conversations fromour dataset and asked the three annotators to judgewhether the conversations are qualiÔ¨Åed for provid-ing effective emotional support.
next, we utilizedthe post-survey results and the lengths of speakerutterances to choose suitable thresholds for Ô¨Ålteringrules.
we then treated each auto-Ô¨Åltering rule asa rule annotator and computed the cohen‚Äôs kappa(cohen, 1960) score between the rule annotator andeach human annotator..the agreement scores in table 7 are cohen‚Äôskappa consistency among the agreement scoresbetween each rule annotator and the three humanannotators.
we selected the thresholds that lead tothe second-highest agreement score with humanannotators and used these thresholds in the Ô¨Ålter-ing rules.
we didn‚Äôt use the set of thresholds thathas the highest agreement score because the rulebased on these thresholds is stricter so that manyconversations would be Ô¨Åltered out.
however, thesecond-highest score is only slightly lower thanthe highest so the rule based on the thresholds ofsecond-highest score can remain more qualiÔ¨Åedconversations with little accepted cost.
as a re-sult, a qualiÔ¨Åed conversation requires that the sup-porter must meet at least three of all the four cri-teria, and the help-seeker must satisfy both of thetwo corresponding criteria.
the Ô¨Ånal ‚Äôrule‚Äô annota-tor combines the two conditions, and the averagedagreement score between the Ô¨Ånal rule annotatorand the three human annotators is 0.576, indicatingsigniÔ¨Åcant agreement..3481auto-approval rule.
consistency.
improvement avg.
length empathy relevance detail avg.
length.
supporter.
seeker.
human1 human2 human3 average.
1211111111111.
8888888888897.
3342333333333.
4444354444444.
--------324--.
6666667566666.
0.5450.5050.5390.5390.5460.5750.5390.5200.5050.5270.4570.5100.515.
0.6590.5660.6020.6180.6300.6400.6020.5510.6530.6400.5990.6210.633.
0.5250.4860.5190.5700.5260.5550.4730.5010.5310.5080.4820.4900.495.
0.5760.5190.5530.5760.5670.5900.5380.5240.5630.5580.5130.5400.548.table 7: the agreement score between each ‚Äúrule‚Äù annotator and three human annotators.
the aspects are consis-tent with table 1. the Ô¨Årst rule means: 1) the supporter improves the help-seeker‚Äôs emotional state as least onescore (emotional improvement is calculated as the help-seeker‚Äôs emotion intensity before the conversation minusthe emotion intensity after the conversation).
2) the average length of the supporter‚Äôs utterances is no less thaneight.
3) the empathy score of the supporter‚Äôs performance is no less than three.
4) the topic relevance score ofthe supporter‚Äôs performance is no less than four.
5) the score that measures how well the help-seeker goes intodetail about their problems is not required to be used in the rule (denoted as ‚Äò-‚Äô).
(6) the average length of thehelp-seeker‚Äôs utterances is no less than six..figure 7: case study.
blue text: the help-seeker‚Äôs pre-chat survey.
red text: strategies predicted by the model.
green background : utterances that corresponding to the used strategies.
yellow background : utteranceswhere the model talks about itself and is not user-centered..3482 problem: problems with friends emotion: sadness  emotion intensity: 5 situation: my friend is drinking too much.
joint blenderbot w/o fine-tuning seeker: hi there.
i feel sadness because my friend has a drinking problem.
supporter (question): i am sorry to hear that.
what do you think is going on?
seeker: i think he just got used to drink every day and i can't pursue  him to stop at least for a week.
supporter (question): i can see how that would be difficult for you.
does your friend drink at home or does it happen at work or home?
seeker: well he is working from home.
so he is drinking almost 24/7.
i feel so exhausted as well.
supporter (reflection of feelings): i understand that you feel like you are exhausted, but i think you can get through this!
seeker: i just need a way to make him stop drinking.
maybe i should stop any communication with him for a while?
supporter (affirmation and reassurance): i think it's a great idea!
i would do it if i were you!
seeker: probably that's what i will do.
i just can't take this anymore.
if he wants he can buy drinks himself as i am tired walking to shop every day and all neighbors thinking that i am an alcoholic.
supporter (self-disclosure): i completely understand where you are coming from.
i was in the same situation as you.
seeker: it was so nice to chat with you, i feel better now.
supporter (affirmation and reassurance): you're welcome!
i'm glad i could help!
seeker: hi there.
my friend has a drinking problem and i don't know what to do.
supporter: i know it can be difficult, but if you can do it, i'm sure you can find a way.
i hope he gets better soon.
seeker: i feel such a sadness inside me.
i am trying to help him but he won't listen.
supporter: i understand completely.
it is tough, but i am sure you will get through it.
seeker: every day he is drinking beer and he is not listening to me.
supporter: i can imagine.
i feel like that's the only way i can keep up with him.
i have tried so hard.
i think i just have to try harder than him to get through this.
seeker: few more months and i think i will give up on him  supporter: that is exactly how i feel... i am trying to find the right person for me and i can't do it!
seeker: i thought you are here to help me?
supporter: it's hard, but we all have to stick together.
there are so many people out there.
you just have time.
seeker: maybe i should ignore my friend for a while?
maybe i will feel better?
supporter: i try to just hang out with friends.
i have been trying to meet new people in the city but they just don't show up.
i just want to be alone and be alone.
seeker: thank you for your help.
supporter: you're welcome.
i think that's what i'll do too.
i'm trying to get used to the city life.
i feel like i've been stuck in this city for so long.
(a).
(c).
(b).
(d).
figure 8: (a) support strategy training.
(b) pre-chat survey.
(c) the help-seeker‚Äôs chatting interface.
(d) thesupporter‚Äôs chatting interface.
(e) post-chat survey..(e).
3483