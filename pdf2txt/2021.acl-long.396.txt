reasoning over entity-action-location graph for procedural textunderstanding.
hao huang1∗, xiubo geng2†, pei jian3, guodong long1, daxin jiang2†1australian ai institute, school of cs, feit, university of technology sydney2stca nlp group, microsoft3school of computing science, simon fraser university{hao.huang-4,guodong.long}@{student.uts,uts}.edu.au{xigeng,djiang}@microsoft.com, jpei@cs.sfu.ca.
abstract.
procedural text understanding aims at track-ing the states (e.g., create, move, destroy)and locations of the entities mentioned in agiven paragraph.
to effectively track the statesand locations,it is essential to capture therich semantic relations between entities, ac-tions, and locations in the paragraph.
al-though recent works have achieved substan-tial progress, most of them focus on leverag-ing the inherent constraints or incorporatingexternal knowledge for state prediction.
therich semantic relations in the given paragraphare largely overlooked.
in this paper, we pro-pose a novel approach (real) to proceduraltext understanding, where we build a generalframework to systematically model the entity-entity, entity-action, and entity-location rela-tions using a graph neural network.
we fur-ther develop algorithms for graph construc-tion, representation learning, and state and lo-cation tracking.
we evaluate the proposed ap-proach on two benchmark datasets, propara,and recipes.
the experimental results showthat our method outperforms strong baselinesby a large margin, i.e., 5.0% on propara and3.2% on recipes, illustrating the utility of se-mantic relations and the effectiveness of thegraph-based reasoning model..1.introduction.
procedural text often consists of a sequence of sen-tences describing processes, such as a phenomenonin nature (e.g., how sedimentary rock forms) (dalviet al., 2018) or instructions to complete a task(e.g., the recipe of mac and cheese) (bosselutet al., 2018).
given a paragraph and its partic-ipant entities, the task of procedural text under-standing is to track the states (e.g., create, move,destroy) and locations (a span in the text) of the.
∗work is done during internship at microsoft.
† corresponding author..entities.
compared with traditional machine read-ing task, which mainly focuses on the static rela-tions among entities, procedural text understandingis more challenging since it involves discoveringcomplex temporal-spatial relations among variousentities from the process dynamics..to effectively track the states and locations ofentities, it is crucial to systematically model richrelations among various concepts in the paragraph,including entities, actions, and locations.
threetypes of relations are of particular interest..first, mentions of the same entity in differentsentences are related.
the inherent relation amongthese mentions may provide clues for a model togenerate consistent predictions about the entity.
forexample, the entity electrical pulses are mentionedin two sentences “the retina’s rods and cones con-vert it to electrical pulses.
the optic nerve carrieselectrical pulses through the optic canal.”.
con-necting its two mentions in two sentences helpsto infer its location in the ﬁrst sentence using thesecond sentence’s information..second, detecting connections between an en-tity and the corresponding actions helps to makestate predictions more accurate.
take the sentence“as the encased bones decay, minerals seep in re-placing the organic material.” as an example.
theentity bone is related to decay which indicates thestate destroy, while it is not connected to seep indi-cating the state move.
given the relation betweenbone and decay, it is easier for the model to predictthe state of bone as destroy, instead of being misledby the action seep..last, when the state or location of one entitychanges, it may impact all associated entities.
forexample, in sentence “trashbags are thrown intotrashcans.”, trashbags are associated with trash-cans.
then, in the following sentence “the trash-can is emptied by a large trash truck.”, althoughtrashbags are not explicitly mentioned, their loca-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5100–5109august1–6,2021.©2021associationforcomputationallinguistics5100tions are changed by the association with trashcan.
recent works on procedural text understandinghave achieved remarkable progress (tandon et al.,2018; bosselut et al., 2018; gupta and durrett,2019b; du et al., 2019; das et al., 2019; gupta anddurrett, 2019a).
however, the existing methods donot systematically model the relations among enti-ties, actions, and locations.
instead, most methodseither leverage inherent constraints on entity statesor exploit external knowledge to make predictions.
for example, gupta and durrett (2019b) propose astructural neural network to track each entity’s hid-den state and summarize the global state transitionswith a crf model.
tandon et al.
(2018) inject com-monsense knowledge into a neural model with softand hard constraints.
although das et al.
(2019)model the relation between entities and locations,there is no general framework to model the rela-tions, and some important relations, such as entity-action and entity-entity relations, are ignored..a general framework to systematically modelthe rich types of relations among entities, actions,and locations is essential to procedural text under-standing.
to the best of our knowledge, we arethe ﬁrst to explore comprehensive relation model-ing, representation, and reasoning systematically.
speciﬁcally, we ﬁrst construct an entity-action-location graph from a given paragraph, wherethree types of concepts (i.e., entities, locations,and actions) are identiﬁed and extracted as nodes.
we then detect critical connections among thoseconcepts and represent them as edges.
finally,we adopt a graph attention network to conductreasoning over the entity-action-location graph(real), which provides expressive representationsfor downstream state and location predictions..we evaluate the proposed approach on twobenchmark datasets for procedural text under-standing, propara (dalvi et al., 2018) andrecipes (bosselut et al., 2018).
our approach out-performs the state-of-the-art strong baselines by alarge marge, i.e., 5.0% on propara and 3.2% onrecipes.
the ablation study and analysis showthat the graph-based reasoning approach generatesbetter representations for entities, locations, andactions.
thus, it is highly valuable for both stateand location tracking of entities..2 related work.
real is closely related to two lines of works, i.e.,procedural text understanding and graph reasoning.
in language understanding..procedural text understanding.
comparedwith early-stage models (henaff et al., 2017; seoet al., 2017), recent progress in the procedural textunderstanding task is mainly made on ensuringthe prediction’s consistency or injecting externalknowledge.
various approaches (dalvi et al., 2018;gupta and durrett, 2019b; amini et al., 2020) havebeen proposed to predict consistent state sequence.
for example, ncet (gupta and durrett, 2019b)tracks the entity in a continuous space and lever-ages a conditional random ﬁeld (crf) to keep aconsistent prediction sequence.
other models in-ject knowledge from external data sources to com-plement missing knowledge.
prostruct (tandonet al., 2018) introduces commonsense constraints toreﬁne the probability space, while koala (zhanget al., 2020) leverages bert encoder pre-trained onrelated corpus from wiki, and injects the concept-net (speer et al., 2017) knowledge.
besides, a fewmodels (das et al., 2019; dalvi et al., 2019) are pro-posed to build graphs on the procedural text.
forinstance, kg-mrc (das et al., 2019) constructsdynamic knowledge graphs between entities and lo-cations.
however, these methods can not systemat-ically capture the relations among entities, actions,and locations, and entity-action and entity-entityrelations are ignored..graph reasoning in language understanding.
graph-based reasoning methods (zeng et al., 2020;zhong et al., 2020; zheng and kordjamshidi, 2020)are widely used in natural language understand-ing tasks to enhance performance.
for example,zeng et al.
(2020) constructs a double graph designfor the document-level relation extraction (re)task, zhong et al.
(2020) constructs the retrievedevidence sentences as a graph for fact-checkingtask.
compared with these works, the entity-action-location graph in our approach copes better withprocedural text understanding task since it pre-cisely deﬁnes concepts we are concerned within thetask and captures the rich and expressive relationsamong them..3 model.
task deﬁnition.
the procedural text understand-ing task is deﬁned as follows.
given a paragraphp consists of t sentences (s1, s2, ..., st ), describ-ing the process (e.g., photosynthesis, erosion) ofa set of n pre-speciﬁed entities {e1, e2, ..., en },.
5101t and location yl.
we need to predict the state yst foreach entity at each step t corresponding to sentence1. candidate states are pre-deﬁned (e.g., ysstt ∈{not exist (o), exist (e), move (m), create (c), de-stroy (d)} in the propara dataset), and location yltis usually a text span in the paragraph.
gold an-notations for state and location at each step t aredenoted as (cid:101)ys.
t , respectively..t and (cid:101)ys.
figure 1: an overview of real..figure 1 shows the overview of our approach,which consists of three main components: graphconstruction, graph-based representation learning,and prediction module.
the graph constructionmodule extracts nodes and edges from the inputprocedural paragraph and constructs a graph.
thegraph reasoning module initializes nodes represen-tations using contextual word representations andreasons over the built graph.
finally, the predictionmodule leverages the graph-based representationsto predict the state and location..3.1 graph construction.
figure 2 shows an example of the graph constructedfor a paragraph which describes how fossil forms.
a semantic graph is denoted as g = (n, e), wheren = {ni}ki=1 denotes all the nodes, and e ={ei}l.i=1 denotes all the edges..nodes extraction.
we ﬁrst extract text spans asnodes from the given paragraph.
the text spansin the extracted nodes should cover all essentialconcepts in the paragraph.
three types of conceptsplay an important role in the entity tracking task,i.e., actions, entity mentions, and location mentions.
therefore, we extract nodes for them and get allthe nodes n = {na, ne, nl} where na represents.
1we will use step and sentence interchangeably..action nodes, ne represents entity mention nodes,and nl represents location mention nodes..we ﬁrst tag all the verbs by an off-the-shelf part-of-speech (pos) tagger2 and construct a set of ac-tion nodes na with each node associated with asingle verb or a phrase consisting of two consecu-tive verbs.
for the entity mentions, we extract theexplicit (exact matching or matching after lemma-tization) or implicit (pronouns) mentions of all theentities.
coreference resolution is used to ﬁnd pro-noun mentions in data pre-processing.
besides,we utilize the pos tagger to extract location men-tions.
each tagged noun or consecutive phrase ofadjective + noun is identiﬁed as a location mention..edges generation.
capturing the semantic rela-tions between various nodes is critical for under-standing the process dynamics in the proceduraltext.
to this end, we ﬁrst derive verb-centric se-mantic structures via semantic role labeling (srl)3(shi and lin, 2019) for each sentence and then es-tablish intra- and inter-semantic structure edges..given a verb-centric structure consisting of acentral verb and corresponding arguments, we cre-ate two types of edges.
(1) if an entity mentionne ∈ ne or location mention nl ∈ nl is a sub-string of an argument for verb na ∈ na, then weconnect ne/nl to na.
for example, for the sentence“as the encased bones decay, minerals seep in re-placing ...”, the verb decay has an argument theencased bones where bones is an entity mention,then we will connect the action node decay andentity mention node bones.
(2) two mentions intwo arguments of the same verb are connected too.
for example, for the sentence “the trashbags arethrown into a large outdoor trashcan”, the verbthrown has two arguments, the trashbags and intoa large outdoor trashcan, then we connect the twomention nodes trashbags and trashcans..we also create edges between mentions of thesame entity in different semantic structures.
for ex-ample, in figure 2, the entity bones are mentionedin two sentences, which correspond to two entitymention nodes.
we connect these two nodes topropagate information from one to the other duringgraph-based reasoning..3.2 graph-based representation learning.
nodes representation.
we ﬁrst feed the en-tire paragraph to the bert (devlin et al., 2019).
2https://github.com/ﬂairnlp/ﬂair3https://github.com/allenai/allennlp..5102graphreasoningstatetrackinglocationpredictionprocedural textbert encoder…textencoderh1h2h3h4h’1h5⍺12⍺13⍺14⍺15⍺11prediction modelrepresentationlearninggraphconstructionnodesextractionedgesgenerationbi lstm……figure 2: an example of entity-action-location graph, constructed for paragraph “...soft tissues quickly decomposeleaving the hard bones or shells behind.
as the encased bones decay, minerals seep in replacing the organicmaterial... ”.
model, which is then sent into a bidirectionallstm (hochreiter and schmidhuber, 1997) (bil-stm) to obtain the contextual embedding for eachtoken.
each node in our graph is associated witha text span in the paragraph.
therefore, the ini-tial node representation is derived by mean pool-ing over all token embeddings in its correspondingtext span.
the contextual representation of nodeni ∈ n is denoted as hi (i = 1, .
.
.
, k) withhi ∈ rd..graph reasoning.
we leverage a graph atten-tion network (gat) (velickovic et al., 2018) forreasoning over the built graph.
the network per-forms masked attention over neighbor nodes (i.e.,connected with an edge) instead of all the nodesin the graph.
we apply a two-layer gat, whichmeans each node can aggregate information fromtheir two-hop neighbor nodes (nodes that can bereached within two edges)..in each gat layer, we ﬁrst extract a set of neigh-bor nodes ni for each node ni.
the attention coefﬁ-cients between node ni and its neighbour nj can becomputed through a shared attention mechanism,eij = at [whi(cid:107)whj],(1)where a ∈ r2d and w ∈ rd×d are learnable pa-rameters, and (cid:107) is the concatenation operation.
weapply a leakyrelu activate function and normal-ize the attention coefﬁcients,.
αij = softmax.
(leakyrelu (eij)) ..(2).
j.then, we aggregate the information from the neigh-bor nodes with multi-head attention to enhance thestability and efﬁciency.
the aggregated feature forni with a k-head attention can be represented as.
h(cid:48).
i =.
.
σ.
.
k(cid:13)(cid:13)(cid:13)(cid:13)k=1.
(cid:88).
nj ∈ni.
.
ijwkhjαk.
.
(3).
in the ﬁrst layer, and.
h(cid:48)(cid:48).
i = σ.
.
.
1k.k(cid:88).
(cid:88).
k=1.
nj ∈ni.
.
ijw(cid:48)kh(cid:48)α(cid:48)kj.
 (4).
in the second layer, where (cid:107) is the concatena-tion operation, σ is the sigmoid activate function,wk ∈ rd×d is learnable matrix for kth head in ﬁrstlayer, and w(cid:48)k ∈ rkd×d is learnable matrix forkth head in second layer.
αkij are calculatedwith the corresponding wk and w(cid:48)k, respectively..ij and α(cid:48)k.3.3 prediction model.
inspired by ncet (gupta and durrett, 2019b), wetrack the state and location separately, by a statetracking and a location prediction module.
eachmodule takes the representations of concernednodes as input and outputs the prediction (i.e., stateor location of an entity) at each time step..figure 3: overview of state tracking model, which pre-dicts states of the entity in every sentence st given en-tity e and paragraph p ..state tracking.
given a paragraph p and an en-tity e, the state tracking module tracks the stateof the entity for each sentence.
we ﬁrst generatethe representations of all sentences for the entity.
considering that actions are good state-changingsignals, we concatenate the embeddings of entity.
5103decaymineralseepreplaceorganic materialbones2: soft tissues quickly decompose leaving the hard bones or shells behind.softtissuedecomposeleavings3: as the encased bones decay, minerals seep in replacing the organic material.bone…s1snaction nodeentity/loc mention nodeintra-structure edgeinter-structure edgeverb-centric structuresentence structure…linearbilstmlinearlinearcrf layerbilstmbilstmstate 1state 2state t………𝑋!
"𝑋#"𝑋$"mention node and action node in the sentence asrepresentation at step t. that is,.
xe.
t =.
(cid:26) [het (cid:107)hvt ],0,.if st contains neotherwise.
where xet denotes the representation of entity e insentence st , het denotes the representation of theentity mention node ne in sentence st, hvt denotesthe representation of the action node na connectedwith ne in sentence st. if entity e is not mentionedin sentence st, we use zero vector as representationof st for e. note if there are multiple mentionnodes for the entity e in sentence st, we take themean pooling over all mention nodes as het .
andwe take similar approach for multiple actions..we utilize a bilstm layer on the sequence ofsentence embeddings.
and a conditional randomﬁeld (crf) (durrett and klein, 2015) is applied onthe top of the bilstm to make the ﬁnal prediction.
the loss function for the state tracking module isdeﬁned as.
lstate = −.
(cid:88).
t(cid:88).
1t.(e,p )∈d.
t=1.
logp (cid:0).
t |p, e; θg, θst(cid:1) ,(cid:101)ys.
(6)where d is the training collection containing entity-t |p, e; θg, θst(cid:1) represents theparagraph pairs, p (cid:0)(cid:101)yspredicted probability of gold state (cid:101)yst in sentencest given the entity e and paragraph p , θg are pa-rameters for graph reasoning and the text encoder,and θst are parameters in state tracking module..figure 4: overview of location prediction model,which predicts locations of the entity in every sentencest given entity e and paragraph p ..location prediction.
for the location predictionmodule, we ﬁrst collect all the location mentionnodes as location candidates set c. we add an iso-lated location node to represent the special location.
candidate ‘?’, which means the location cannot befound in the paragraph.
the representation of thisnode is randomly initialized and learnable duringthe training process..(5).
given an entity e and location candidate l ∈ c,.
we represent the sentence st as.
t = [hexl.
t (cid:107)hlt],.
(7).
t and hl.
where het denotes the representation of theentity mention node and location mention node insentence st. if the entity or location candidate isnot mentioned in sentence st, we use a zero vectorreplacing he.
t or hlt..we use a bilstm followed by a linear layer forthe location predictor.
the model outputs a scorefor each candidate at each step t. then, we applya softmax layer over all the location candidates’scores at the same step, resulting in a normalizedprobabilistic distribution.
the location loss is de-ﬁned as.
lloc = −.
(cid:88).
t(cid:88).
1t.logp.
(cid:16).
t|p, e; θg, θloc(cid:17)(cid:101)yl.
,.
(e,p )∈d.
t=1.
(8)t|p, e; θg, θloc(cid:1) represents the predictedwhere p (cid:0)(cid:101)ylprobability of gold location (cid:101)ylt for entity e in sen-tence st, and θloc are parameters for location pre-diction module..3.4 learning and inference.
we create a single graph for each paragraph, whichstays unchanged once created.
then the graph rea-soning module and state/location prediction mod-ule are jointly trained in an end-to-end manner.
theoverall loss is deﬁned as.
ltotal = lstate + λloclloc,.
(9).
where λloc is the hyper-parameter to balance thestate tracking and the location prediction loss..we perform inference in pipeline mode.
speciﬁ-cally, for each entity, we ﬁrst apply the state track-ing module to infer its state at each time step.
thenwe only predict its location at steps when its stateis changed (i.e., the predicted state is create ormove4).
and the locations of an entity with un-changed states can be inferred according to its lo-cations in previous steps.
such pipeline fashion.
4the location of an entity will be none if its state is destroy.
therefore, we do not need to predict its location when an entityis destroyed..5104…linearbilstmlinearlinearbilstmbilstm……location 1location 2…softmaxlocationn…softmaxsoftmax𝑋!
"𝑋#"𝑋$"can increase consistency between states and loca-tions of an entity than inferring location and statesimultaneously..4 experiments.
this section describes the evaluation results ofreal on two datasets (propara (dalvi et al., 2018)and recipes (bosselut et al., 2018)).
we also pro-vide ablation study and case analysis to illustratethe effectiveness of graph-based reasoning..4.1 datasets and evaluation metrics.
statistics.
propara.
recipes.
#sentences#para#train/#dev/#testavg.
#entities per paraavg.
#sentences per para.
3.3k488391/43/544.176.7.
7.6k866693/86/878.578.8.table 1: statistics of propara and recipes dataset..propara contains procedural texts about scien-tiﬁc processes, e.g., photosynthesis, fossil formu-lation.
it contains about 1.9k instances (one entity-paragraph pair as an instance) written and anno-tated by human crowd workers.
we follow theofﬁcial split (dalvi et al., 2018) for train/dev/testset.
the recipes dataset consists of paragraphs de-scribing cooking procedures and their ingredientsas entities.
we only use the human-labeled data inour experiment, with 80%/10%/10% of the data fortrain/dev/test, respectively.
detail statistics for thetwo datasets can be found in table 1..we follow previous work’s setting (dalvi et al.,2018) and evaluate the proposed approach on twotypes of tasks on the propara dataset, document-level task and sentence-level task.
document-leveltask focuses on ﬁguring out input entities, outputentities, entity conversions, and entity movementsby answering corresponding questions.
more de-tails can be found in the ofﬁcial script5.
followingthe ofﬁcial script, we evaluate models with aver-aged precision, recall, and f1 scores.
in sentence-level task, we need to answer three categories ofquestions: (cat-1) is entity e created (destroyed,moved) in the process?
(cat-2) when is e created(destroyed, moved)?
(cat-3) where is e created(destroyed, moved from/to)?
for this task, we take.
5https://github.com/allenai/aristo-leaderboard/tree/master.
/propara.
macro-average and micro-average of the score forthree sets of questions as evaluation metrics6..for the recipes dataset, we take the same settingas (zhang et al., 2020), where the goal is to predictthe ingredients’ location changes during the pro-cess.
we take precision, recall, and f1 scores toevaluate models7..4.2.implementation details.
we use bert base (devlin et al., 2019) as encoderand reason with 3-heads gat.
batch size is set to16, and embedding size is set to 256. the learningrate r, location loss coefﬁcient λloc and dropoutrate d are derived by grid searching with in 9 tri-als in r ∈ {2.5 × 10−5, 3 × 10−5, 3.5 × 10−5},λloc ∈ {0.2, 0.3, 0.4}, and d ∈ {0.3, 0.4, 0.5}.
the implementation is based on python and trainedon a tesla p40 gpu with adam optimizer for ap-proximately one hour (with approximately 112mparameters).
we choose the best model with high-est prediction accuracy on development set..4.3 main results.
table 2 compares real with previous work on thepropara data for both document-level and sentence-level tasks.
our proposed approach consistentlyoutperforms all previous models, which do notutilize external knowledge on all metrics.
in par-ticular, compared to dynapro, it increases thedocument-level f1 score by 5.3%, and sentence-level macro averaged accuracy from 55.4% to58.2%.
without any external data, our approachachieves comparable results to koala, whichextensively leverages rich external knowledge inconceptnet and wikipedia pages, demonstratingthe effectiveness of exploiting the entity-action-location graph.
we also compare real with there-implemented ncet8 on the recipes dataset.
asshown in 3, real also surpass the strong baselineby 3.2%.
all these results verify the effectivenessof the proposed graph-based reasoning approach..4.4 ablations.
we conduct an ablation study to testify the effec-tiveness of multiple components in our approach.
table 4 and table 3 list the results on propara and.
6https://github.com/allenai/propara/tree/master/propara/.
evaluation.
7https://github.com/ytyz1307zzh/recipes8the re-implemented ncet achieves comparable accu-racy with the previous state-of-the-art algorithm, dynapro,i.e., 65.2% f1 score for ncet v.s.
65.5% for dynapro..5105models.
document-level taskf1.
precsion recall.
sentence-level taskcat-1 cat-2 cat-3 macro-avg micro-avg.
entnet (henaff et al., 2017)qrn (seo et al., 2017)prolocal (dalvi et al., 2018)proglobal (dalvi et al., 2018)prostruct (tandon et al., 2018)xpad (dalvi et al., 2019)kg-mrc (das et al., 2019)ncet (gupta and durrett, 2019b)dynapro (amini et al., 2020)koala (zhang et al., 2020)real (our approach).
54.760.981.748.874.370.569.367.175.277.781.9.
30.731.136.861.743.045.349.358.558.064.461.9.
39.441.450.751.954.555.257.662.565.570.470.5.
51.652.462.763.0--62.973.772.478.578.4.
18.815.530.536.4--40.047.149.353.353.7.
7.810.910.435.9--38.241.044.541.342.4.
26.126.334.545.1--47.053.955.457.758.2.
26.026.534.045.4--46.654.055.557.557.9.table 2: experiment results on propara document-level task and sentence-level task.
koala uses rich externaldata from wikipedia and conceptnet.
our approach achieves comparable performance to koala without anyexternal knowledge..models.
precsion recall.
f1.
segments models.
precision recall.
f1.
ncet re-implementation.
real.
-location-state-graph.
56.5.
55.254.954.957.2.
46.4.
52.951.752.047.9.
50.9.
54.153.353.452.1.table 3: comparison on recipes dataset..models.
precsion.
recall.
f1.
real.
-location-state-graph.
81.981.0 (-0.9)73.7 (-8.2)72.0 (-9.9).
61.957.7 (-4.2)61.2 (-0.7)61.2 (-0.7).
70.567.4 (-3.1)66.9 (-3.6)66.1 (-4.4).
table 4: ablation study on propara dataset..recipes, respectively.
as shown in table 4, re-moving the graph-based representation learning forlocation/state prediction decreases the f1 score by3.1%/3.6%, the gap becomes 4.4% without anygraph-based reasoning.
we can get similar obser-vations on the recipes dataset, indicating that ex-ploiting the paragraph’s rich relations is critical forboth state tracking and location prediction..4.5 analyses of different relations.
to further illustrate the effectiveness of differenttypes of relations, we conduct below analyses andpresent three cases with predictions of real withand without graph reasoning in figure 5..first, to verify the effectiveness of action-entityrelations in multi-verb sentences, we comparereal of with and without graph reasoning on sen-.
muli-verb.
implicit.
w/o graphw/ graph.
w/o graphw/ graph.
73.082.5.
74.983.7.
58.261.0.
57.960.3.
64.870.1.
65.370.1.table 5: analyses of impact of entity-action and entity-entity relations on propara..tences containing multiple (i.e., more than 2) verbsin table 5. we ﬁgure out that graph-based reason-ing increases the performance by 5.7%, indicatingthat accurately connecting entities and correspond-ing actions improves the prediction accuracy.
forcase 1 shown in figure 5, the relation between theentity bone the action decay helps the model to cor-rectly predict the state of bone as destroy since theaction decay indicates destroy.
however, withoutsuch accurate connection between bone and decay,the prediction model is very likely to be misled byother actions such as seep or replace..second, we illustrate the impact of entity-entityrelations by comparing our approach and baselinewhere the entity is not explicitly mentioned9.
asshown in table 5, real increase the accuracy by4.8%, which indicates the effectiveness of our ap-proach by modeling cross-entity relations.
thesecond case in figure 5 illustrates the effectivenessof using entity-entity relations.
the entity bags isnot explicitly mentioned in the sentence “trashcangets emptied into trash truck”, and thus the base-line model cannot correctly predict its state and.
9we only compare performance for those entity-sentence.
pairs with gold state as move, create and destroy..5106figure 5: examples of model predictions of our approach w/ (black) and w/o (red) graph reasoning.
correspondingsub-graph is plot on the right of the paragraph.
dotted rectangles in the sub-graph highlight key connections forcorrect prediction in graph-based reasoning..location.
however, connecting it to the entity trash-can which is derived in the ﬁrst sentence, helps themodel infer its state and location correctly..third, as discussed in section 1, mention-mention connections might improve accuracy whenthere are multiple mentions for the same entity.
thethird case in figure 5 shows how real utilizes re-lations between different mentions for the sameentity.
in the ﬁrst sentence, the location of en-tity small image is not mentioned, which results inwrong location prediction when no graph reasoningis used.
in contrast, the built graph connects thismention with preposition it in the second sentencewhere its location is revealed as retina.
therefore,our model correctly predicts small image’s locationby graph-based representation learning..4.6 error analyses.
we randomly sample 100 wrongly predicted exam-ples and summarize them into the following types.
first, the ambiguity between similar entitiesmakes it difﬁcult to derive accurate representationsfor them.
for instance, ﬁxed nitrogen and gas-based nitrogen are two different entities related tonitrogen in the paragraph “nitrogen exists naturallyin the atmosphere.
bacteria in soil ﬁx the nitrogen.
nitrogen is now usable by living things.”.
it is dif-ﬁcult for a model to distinguish which entity themention nitrogen refers to..second, commonsense knowledge is required.
for example, it is difﬁcult to infer the location of.
the entity bone in the sentence “an animal dies.
it is buried in a watery environment.” without theknowledge “bone is part of animal”.
therefore, in-jecting appropriate external knowledge while avoid-ing noise may improve the model..third, similar actions indicate different states indifferent contexts.
for instance, in sentence “thetree eventually dies.”, the state of tree is labeledas destroy, while in sentence “most fossils formedwhen animals or plants die in wet environment.”,the state of animals and plants are all annotated asexist, which may confuse the model..5 conclusion and future work.
in this work, we propose a novel approach realfor procedural text understanding.
unlike all pre-vious works, we systematically exploit the richsemantic relations between entities, location, andactions.
we design an entity-action-location graphto systematically model various types of conceptsand their relations and develop the algorithms forgraph construction, representation, and reasoning.
we comprehensively conduct a quantitative andqualitative comparison of the proposed approachwith strong baselines on two popular benchmarkdatasets for procedural text understanding anddemonstrate the effectiveness of our approach.
inthe future, we will investigate approaches to fur-ther advance the procedural text understanding task,such as incorporating entity disambiguation and ex-ternal knowledge in our approach..5107text paragraph (extract)statelocationas the encased bones decay, minerals seep in replacing the organic material cell by cell in a process called petrification.e→ d-text paragraph (extract)statelocation1.bagsget carried out to the trashcan.
mtrashcan2.
trashcan gets emptied into trash truck.e→mtrashcan→ trash trucktext paragraph (extract)statelocation1.the cornea and lens refract light into a small image.
ccornea and lens → retina2.shine iton the retina.eretinacase 3 entity: small imagecase 1 entity: bonecase 2 entity: bagssmall imagerefractcornea andlensitretinashinecase 3 sub-graphmineralsdecaybonesmaterialseepcase 1 sub-graphtrashcanget carriedbagtrashcantrash truckget emptiedcase 2 sub-graphreplacereferences.
aida amini, antoine bosselut, bhavana dalvi mishra,yejin choi, and hannaneh hajishirzi.
2020. pro-cedural reading comprehension with attribute-awarecontext ﬂow.
in conference on automated knowl-edge base construction, akbc 2020, virtual, june22-24, 2020..antoine bosselut, omer levy, ari holtzman, corin en-nis, dieter fox, and yejin choi.
2018. simulatinginaction dynamics with neural process networks.
6th international conference on learning represen-tations, iclr 2018, vancouver, bc, canada, april30 - may 3, 2018, conference track proceedings.
openreview.net..bhavana dalvi, lifu huang, niket tandon, wen-tauyih, and peter clark.
2018. tracking state changesin procedural text: a challenge dataset and modelsfor process paragraph comprehension.
in proceed-ings of the 2018 conference of the north americanchapter of the association for computational lin-guistics: human language technologies, naacl-hlt 2018, new orleans, louisiana, usa, june 1-6, 2018, volume 1 (long papers), pages 1595–1604.
association for computational linguistics..bhavana dalvi, niket tandon, antoine bosselut, wen-tau yih, and peter clark.
2019. everything hap-pens for a reason: discovering the purpose of ac-in proceedings of thetions in procedural text.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing,emnlp-ijcnlp 2019, hong kong, china, novem-ber 3-7, 2019, pages 4495–4504.
association forcomputational linguistics..rajarshi das, tsendsuren munkhdalai, xingdi yuan,adam trischler, and andrew mccallum.
2019.building dynamic knowledge graphs from text us-in 7th inter-ing machine reading comprehension.
national conference on learning representations,iclr 2019, new orleans, la, usa, may 6-9, 2019.openreview.net..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, naacl-hlt 2019, minneapolis, mn,usa, june 2-7, 2019, volume 1 (long and short pa-pers), pages 4171–4186.
association for computa-tional linguistics..xinya du, bhavana dalvi mishra, niket tandon, an-toine bosselut, wen-tau yih, peter clark, and clairecardie.
2019. be consistent!
improving procedu-ral text comprehension using label consistency.
inproceedings of the 2019 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,.
naacl-hlt 2019, minneapolis, mn, usa, june 2-7, 2019, volume 1 (long and short papers), pages2347–2356.
association for computational linguis-tics..greg durrett and dan klein.
2015. neural crf pars-ing.
in proceedings of the 53rd annual meeting ofthe association for computational linguistics andthe 7th international joint conference on naturallanguage processing of the asian federation of nat-ural language processing, acl 2015, july 26-31,2015, beijing, china, volume 1: long papers, pages302–312.
the association for computer linguis-tics..aditya gupta and greg durrett.
2019a.
effective useof transformer networks for entity tracking.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing, emnlp-ijcnlp 2019, hongkong, china, november 3-7, 2019, pages 759–769.
association for computational linguistics..aditya gupta and greg durrett.
2019b.
tracking dis-crete and continuous entity state for process under-standing.
in proceedings of the third workshop onstructured prediction for nlp@naacl-hlt 2019,minneapolis, minnesota, jun 7, 2019, pages 7–12.
association for computational linguistics..mikael henaff, jason weston, arthur szlam, antoinebordes, and yann lecun.
2017. tracking the worldin 5th inter-state with recurrent entity networks.
national conference on learning representations,iclr 2017, toulon, france, april 24-26, 2017, con-ference track proceedings.
openreview.net..sepp hochreiter and j¨urgen schmidhuber.
1997. longshort-term memory.
neural comput., 9(8):1735–1780..min joon seo, sewon min, ali farhadi, and han-naneh hajishirzi.
2017. query-reduction networksin 5th international con-for question answering.
ference on learning representations, iclr 2017,toulon, france, april 24-26, 2017, conferencetrack proceedings.
openreview.net..peng shi and jimmy lin.
2019. simple bert mod-els for relation extraction and semantic role labeling.
corr, abs/1904.05255..robyn speer, joshua chin, and catherine havasi.
2017.conceptnet 5.5: an open multilingual graph of gen-eral knowledge.
in proceedings of the thirty-firstaaai conference on artiﬁcial intelligence, febru-ary 4-9, 2017, san francisco, california, usa,pages 4444–4451.
aaai press..niket tandon, bhavana dalvi, joel grus, wen-tau yih,antoine bosselut, and peter clark.
2018. reasoningabout actions and state changes by injecting com-in proceedings of the 2018monsense knowledge.
conference on empirical methods in natural lan-guage processing, brussels, belgium, october 31.
5108- november 4, 2018, pages 57–66.
association forcomputational linguistics..petar velickovic, guillem cucurull, arantxa casanova,adriana romero, pietro li`o, and yoshua bengio.
in 6th inter-2018. graph attention networks.
national conference on learning representations,iclr 2018, vancouver, bc, canada, april 30 - may3, 2018, conference track proceedings.
openre-view.net..shuang zeng, runxin xu, baobao chang, and lei li.
2020. double graph based reasoning for document-level relation extraction.
in proceedings of the 2020conference on empirical methods in natural lan-guage processing, emnlp 2020, online, novem-ber 16-20, 2020, pages 1630–1640.
association forcomputational linguistics..zhihan zhang, xiubo geng, tao qin, yunfang wu, anddaxin jiang.
2020. knowledge-aware proceduraltext understanding with multi-stage training.
corr,abs/2009.13199..chen zheng and parisa kordjamshidi.
2020. srlgrn:semantic role labeling graph reasoning network.
inproceedings of the 2020 conference on empiricalmethods in natural language processing, emnlp2020, online, november 16-20, 2020, pages 8881–8891. association for computational linguistics..wanjun zhong, jingjing xu, duyu tang, zenan xu,nan duan, ming zhou, jiahai wang, and jian yin.
2020. reasoning over semantic-level graph for factchecking.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,acl 2020, online, july 5-10, 2020, pages 6170–6180. association for computational linguistics..5109