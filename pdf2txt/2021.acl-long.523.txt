polyjuice: generating counterfactualsfor explaining, evaluating, and improving models.
tongshuang wu11university of washingtonwtshuang@cs.uw.edu.
marco tulio ribeiro22microsoft researchmarcotcr@microsoft.com.
jeﬀrey heer1.
daniel s. weld1,3.
3allen institute for artiﬁcial intelligence.
{jheer,weld}@cs.uw.edu.
abstract.
while counterfactual examples are useful foranalysis and training of nlp models, cur-rent generation methods either rely on man-ual labor to create very few counterfactuals,or only instantiate limited types of perturba-tions such as paraphrases or word substitutions.
we present polyjuice, a general-purpose coun-terfactual generator that allows for controlover perturbation types and locations, trainedby ﬁnetuning gpt-2 on multiple datasets ofpaired sentences.
we show that polyjuice pro-duces diverse sets of realistic counterfactuals,which in turn are useful in various distinctapplications:improving training and evalua-tion on three diﬀerent tasks (with around 70%less annotation eﬀort than manual generation),augmenting state-of-the-art explanation tech-niques, and supporting systematic counterfac-tual error analysis by revealing behaviors eas-ily missed by human experts..1.introduction.
counterfactual reasoning — mentally simulatingwhat would have happened if conditions were dif-ferent — is a common tool for making causality as-sessments (kahneman and tversky, 1981), whichin turn are crucial for model evaluation, error anal-ysis, and explanation (miller, 2019).
for example,in figure 1, “it is great for kids” is perturbed intomultiple variations, each providing unique insightsby simulating what would have happened if thesentence was diﬀerent..applications of counterfactual reasoning to nlpgenerally specify the relationship x (cid:41) ˆx, and thencreate ˆx according to the relationship.
as a re-sult, prior work has tailored counterfactual gen-erators for diﬀerent applications, only collectingsubsets of ˆx that are useful for the speciﬁc task.
for example, to support model training and eval-uation, human annotators create counterfactuals.
figure 1: overview: (a) given a sentiment analysis in-stance x, polyjuice1generates (b) various counterfactu-als ˆx, which are then (c) selected for downstream use.
e.g., in (d) we select counterfactual explanations thatcomplement a black box explanation:though “great”and “kids” are deemed important, perturbing them maynot aﬀect the prediction f (x) = f ( ˆx) = positive, reveal-ing model failures not covered by feature attributions..that change the groundtruth labels by manuallyrewriting instances (gardner et al., 2020; qin et al.,2019) or deﬁning perturbation functions (ribeiroet al., 2020).
manual rewrites are costly (e.g., 4–5minutes per counterfactual (kaushik et al., 2020))and susceptible to systematic omissions (e.g., hu-man annotators may cover great (cid:41) not great, butmiss kids (cid:41) no one in figure 1b).
meanwhile, au-tomated generators for model analysis and expla-nation usually focus on other relationships, e.g.,generating ˆx that have diﬀerent model predictionsthan x (ross et al., 2020; zhang et al., 2019a).
asa result, they neglect prediction-preserving counter-factuals that are equally important for understand-ing or shaping model behaviors, like kids (cid:41) no oneand great (cid:41) scary linked to figure 1d..however, counterfactual generation does nothave to be task-speciﬁc.
the same set of counter-factuals in figure 1 can support a variety of applica-.
1we open source polyjuice at https://github.com/.
tongshuangwu/polyjuice..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6707–6723august1–6,2021.©2021associationforcomputationallinguistics6707it is great for kids.it is great for kids→adults.
it is great→scary for kids.deletelexicalnegationit is great for kids.polyjuice generates  ̂xioriginal  xselect for use casesbacf(̂xi)— ++ ++f(x)+it is great for kids trainingevaluationexplanationderror analysisit is not great for kids.
it is great for kids→no one.
tions.
moreover, for cases like model explanationand analysis, a general-purpose pool of counterfac-tuals may be preferable, as the relationship of inter-est can be more exploratory and user-oriented (wuet al., 2019).
in this work, we formalize the taskof counterfactual generation, disentangling genera-tion from the application of counterfactuals.
givenan input x (figure 1a), our generator produces a setof counterfactuals ˆx = { ˆx1, ˆx2, ...} with application-agnostic relationships x (cid:41) ˆxi (figure 1b).
after-wards, we use application-speciﬁc selection meth-ods to ﬁnd subsets of ˆx that are most eﬀective for agiven use case (figure 1c)..we frame the generation step as conditional textgeneration, and ﬁnetune gpt-2 (radford et al.,2019) into a generator called polyjuice using(x, ˆx) pairs.
to allow for targeted counterfactu-als, we also design control codes like negationor delete (figure 1b), and adopt ﬁll-in-the-blankstructures (donahue et al., 2020) to specify wherethe perturbation occurs and how.
intrinsic evalua-tion shows that polyjuice generates ˆx that are ﬂuent,diverse, and close to x, and that the control mecha-nisms retrieve perturbations that would likely notbe sampled from oﬀ-the-shelf language models..with simple selection heuristics, we show thata single polyjuice model can signiﬁcantly aid hu-mans in diverse downstream applications.2 forcounterfactual training and evaluation (§3), hu-mans label polyjuice counterfactuals rather thancreating them from scratch.
they produce train-ing data that signiﬁcantly improve model general-ization, as well as contrast sets that help identifymodel vulnerabilities (gardner et al., 2020), witharound 70% less annotation eﬀort.
in another ap-plication, polyjuice produces counterfactual expla-nations (§4), providing signiﬁcant insight on topof state-of-the-art explanation techniques.
finally,polyjuice supports counterfactual error analysis(§5).
it allows users to explore related counterfac-tuals (e.g., the model responds diﬀerently to diﬀer-ent negation forms in figure 1b), and to aggregateindividual counterfactuals into patterns in order togain systematic understanding of model behavior..2 general-purpose counterfactuals.
2.1 deﬁnition and desiderata.
given an instance x, a generator g produces a setof counterfactuals ˆx = { ˆx1, ˆx2, ...} with various re-2we demonstrate polyjuice in semi-automatic settings, but.
as discussed in §2.2, it can also work automatically..figure 2: (a) polyjuice prompt format, which concate-nates the original x, the control code, and the ˆx (“it isnot great for children” converted to an inﬁlling struc-ture).
at generation time, polyjuice accepts promptsthat just include x (line 1), or optionally with the codeand the [blank]s (lines 2–3), and ﬁlls in the blankssequentially with spans separated by [answer]s (line4).
(b) polyjuice allows blanking at diﬀerent granular-ities (even the entire sentence), such that lines 3–4 in(a) can be replaced by lines 6–7 or 8–9..lationships x (cid:41) ˆxi.
for example, great (cid:41) not great,kids (cid:41) no one in figure 1b are both instances of thenegation relationship.
each (x, ˆx) pair shares mul-tiple relationships — these two are also instancesof the label ﬂipping relationship if the task is sen-timent analysis (but might not be for other tasks).
as illustrated in §1, knowing which relationshipsapply aids selection for downstream applications..we expect g to produce counterfactuals ˆx thatare (1) close to x, preferably only involving theminimal changes necessary to establish a certain ef-fect (pearl, 2018), allowing users to make causalityassessments.
the generated ˆx should also be (2) ﬂu-ent, i.e., grammatically correct (morris et al., 2020)and semantically meaningful (e.g.,“colorless greenideas sleep furiously” is not meaningful (chom-sky, 2002)).
fluency operationalizes “probable”counterfactuals in the context of nlp; as kahne-man and tversky (1981) stated, humans stronglyfavor counterfactuals that are close to the origi-nal instance, but also prefer those that could haveeasily happened without assuming rare events orstrange coincidences.
further, as a general-purposegenerator, g should produce counterfactuals with ameasure of (3) control over relationships x (cid:41) ˆx,such that the counterfactuals can vary with theobject-of-attention in each application (the “focusrule” (kahneman and tversky, 1981)).
finally, weexpect g to output a (4) diverse set of ˆx in terms ofrelationships, covering a large variety of “what-ifs”for diﬀerent applications (pearl, 2018)..6708it is great for kids.
<|perturb|> [negation] it is [blank] great for [blank].
[sep] not [answer] children [answer]<|endoftext|>it [blank] great [blank].
[sep]  is not [answer] for children [answer][blank] [sep]it is not great for children.
[answer]̂xcodebax̂x̂x1 2 3 4 56 7 8 9control code deﬁnitions and polyjuice-generated examples.
negation.
quantifier.
shuffle.
lexical.
a dog is not embraced by the woman.
a dog is (cid:41) three dogs are embraced by the woman..to move (or swap) key phrases or entities around the sentence.
a dog (cid:41) woman is embraced by the woman (cid:41) dog..training datasets.
(kaushik et al., 2020).
(gardner et al., 2020).
(zhang et al., 2019b).
to change just one word or noun chunk without altering the pos tags.
a dog is embraced (cid:41) attacked by the woman..(sakaguchi et al., 2020).
resemantic.
to replace short phrases without altering the remaining dependency tree.
a dog is embraced by the woman (cid:41) wrapped in a blanket..(wieting and gimpel, 2018).
insert.
delete.
to add short phrases without altering the remaining dependency tree.
a dog is embraced by the little woman..to remove short phrases without altering the remaining dependency tree.
a dog is embraced by the woman..(mccoy et al., 2019).
(mccoy et al., 2019).
restructure.
to alter the dependency tree structure, e.g., changing from passive to active.
a dog is embraced by (cid:41) hugging the woman..(wieting and gimpel, 2018).
table 1: we design a list of control codes to guide generation.
we show polyjuice-generated counterfactualexamples, and the representative training datasets for each corresponding pattern.
details are in appendix a..2.2 conditional counterfactual generation.
we frame counterfactual generation as a condi-tional text generation task using language mod-els (lms), and train polyjuice by ﬁnetuning gpt-2 (radford et al., 2019) using the following promptdesign (alternative lms could also have been used)..prompt format design.
to ensure that ˆx is closeto x rather than arbitrary text, we condition the gen-eration on x, followed by a special token (line 1in figure 2a).
in line 2, we have control codes(keskar et al., 2019) such as negation.
we designthem to specify types of perturbation from amonglexical, syntactic, or semantic aspects (see table1), inspired by prior work that categorizes manu-ally created counterfactuals (kaushik et al., 2020;gardner et al., 2020).
as an additional layer ofcontrol over x (cid:41) ˆx, we allow users to specify wherechanges happen by having the lm inﬁll [blank]tokens (donahue et al., 2020), rather than generat-ing arbitrary counterfactuals (lines 3–4)..finetuning gpt-2 — a causal lm for predictingnext tokens — additionally allows us to exercisecontrol at various levels of granularity.
at gener-ation time, if the user provides only the originalexample, polyjuice will generate the control code,the blank locations, and the inﬁlling (lines 2–4).
alternatively, the user can specify the control code,or the control code and the blanks, to exercise dif-ferent degrees of control depending on the applica-tion.
as later shown in §4 and §5, such control isimportant for diﬀerent use cases..training data.
to train a conditional model, wecombine six existing sentence-pair datasets, eachcontaining a subset of the desired phenomena intable 1. further, we ﬁnd naturally occurring sen-tence pairs (ﬁltered by edit distance to guaran-tee closeness) in non-paired datasets includingcommongen (lin et al., 2020), natural ques-tions (kwiatkowski et al., 2019), and squad (ra-jpurkar et al., 2016), such that the resulting datasetcontains diverse counterfactuals.3.
we translate these sentence pairs into the formatgiven in figure 2a.
for each (x, ˆx), we compute itsprimary control code using part-of-speech tags anddependency trees.
for example, negation occurswhen we observe changes to negation modiﬁers orspeciﬁc words like “supposedly”, and shuffle oc-curs when we have overlap between tokens deletedand added.
when multiple changes occur, we la-bel it with the control code which most signiﬁ-cantly changes the semantics of the correspond-ing subphrase as computed by sbert (reimersand gurevych, 2019).
for example, in figure 2a,negation (great (cid:41) not great) is more signiﬁcantthan lexical (kids (cid:41) children).
to balance the dis-tribution (table 7 in appendix a), for each dataset,we extract control codes from all the (x, ˆx),4 andrandomly sample up to 10,000 instances per codes.
in order to allow for ﬂexible blanking at gener-ation time, we generate multiple training promptsper pair, covering diﬀerent dependency tree struc-.
3we exclude data related to our applications, e.g., paws-.
qqp (zhang et al., 2019b)..4we use sentences in a pair interchangeably as x and ˆx to.
learn the control codes both ways..6709model.
polyjuicegpt-2t5roberta.
diversity.
closeness.
self-bleu ↓.
levenshtein ↓.
syntactic ↓.
0.340.180.120.47.
0.250.709,520.14.
2.136.353.501.32.table 2: intrinsic evaluations: polyjuice counterfactu-als are closer to the original instance than non-ﬁntunedgpt-2 and t5, and more diverse than roberta.
com-putational details are in appendix a.2..tures related to the perturbed spans (figure 2b),including (1) just the changed tokens, (2) the asso-ciated parsing structures, (3) the merged changes,and (4) the entire sentence.
we eventually obtain657, 144 prompts from 186, 451 pairs..fluency ﬁltering.
while the original gpt-2 pro-duces ﬂuent text, some combinations of controlcodes and blanks cause polyjuice to generate non-sensical results.
following morris et al.
(2020), wescore both x and ˆx with gpt-2, and ﬁlter ˆx whenthe log-probability (on the full sentence or the per-turbed chunks) decreases by more than 10 pointsrelative to x. fully automated uses of polyjuice(e.g., adversarial attacks) may beneﬁt from stricterconstraints, at the cost of diversity (as surprisingchanges may be ﬁltered even if they are ﬂuent)..intrinsic evaluation.
2.3we evaluate polyjuice on closeness and diversityby comparing its perturbations on 300 randomlyselected sentences with baselines that use more orless context from x: (1) non-ﬁnetuned gpt-2, (2)token-inﬁlling roberta (liu et al., 2019) and (3)span-inﬁlling t5 (raﬀel et al., 2020)..as shown in table 2, polyjuice generates coun-terfactuals that are close to the original instance,measured by syntactic tree (zhang and shasha,1989) and levenshtein edit distance (levenshtein,1966).
in contrast, non-ﬁnetuned gpt-2 generatesarbitrary text instead of perturbations when giventhe starting tokens of a sentence, as it only lever-ages context in a single direction.
as for inﬁllingmodels, polyjuice counterfactuals are more diverse(measured by self-bleu (zhu et al., 2018)) thanroberta ones, which is restricted to word sub-stitution.
meanwhile, t5 displays higher diversitybut less closeness, probably due to the fact that itdoes not consider the original masked tokens whengenerating ˆx.
for example, in figure 1 “it is greatfor kids,” t5 replaces “for kids” with “idea”, “to.
meet you,” whereas polyjuice generates “for kidsyet adults can enjoy,” “for any audience.”.
we evaluate controllability by comparingpolyjuice with t5 as well as with gpt-2 ﬁnetunedon prompts without codes.
we verify that the codesimprove the success rate of generating counterfac-tuals with the desired perturbation types set out intable 1 by as much as 42% for perturbations suchas negation and insert.
for example, given“it is [blank] great for kids,” baselines generate“also,” “fun and,” rather than “not” (negation)..we further verify the ﬂuency for polyjuice coun-terfactuals in three tasks/datasets: (1) sentimentanalysis, sst-2 (socher et al., 2013), (2) nat-ural language inference (nli), snli (bowmanet al., 2015), and (3) duplicate question detection(qqp) (wang et al., 2019).
we randomly select100 sentences per dataset, generate 3 ˆx per x, andask crowd workers to rate whether they are “likelywritten by native speakers.” the workers ratedmost counterfactuals as ﬂuent: 78% in sst-2, 76%in qqp, and 86% in snli.
in subsequent sections,we show these rates are suitable for applicationswhere people “team up” with polyjuice..3 counterfactual evaluation & training.
we ask crowdworkers to label polyjuice-generatedcounterfactuals for sentiment, nli, and qqp, forthe purposes of evaluation and training.5 in eachlabeling round, the worker is presented with anoriginal x and its label, and asked to annotate thegroundtruth for three ˆx, rejecting non-ﬂuent ones(details and interface in appendix b.1)..we use a simple heuristic to select which coun-terfactuals are presented for labeling, aimed at in-creasing diversity.
representing each ˆx by its to-ken changes, control code, and dependency treestructure, we greedily select the ones that are leastsimilar to those already selected for labeling.
thisavoids redundancy in the labeling set, e.g., commonperturbation patterns such as black (cid:41) white..3.1 evaluation with contrast setswe verify whether polyjuice counterfactuals can beused to create contrast sets (gardner et al., 2020),i.e., evaluation sets where each instance has anearby counterfactual with a diﬀerent groundtruth,to better evaluate model decision boundaries.
we.
5we collect asymmetric counterfactuals (garg et al., 2019)by sampling more duplicate and entailment examples in qqpand nli to perturb, due to the diﬃculty of ﬂipping other labels..6710task.
dev.
orig.
set contrast set ↓ consistency ↓.
sentiment 94.386.591.7.nliqqp.
93.891.687.5.
84.9 (-8.9)72.3 (-19.3)75.3 (-12.2).
76.156.461.1.table 3: polyjuice ˆx as contrasts sets, with model accu-racy on the development set, the original set of x, thecontrast sets, and consistency (cases where the modelpredicts both x and ˆx correctly).
the performancedrops are similar to that of expert-created sets (gardneret al., 2020), on which the accuracy of all classiﬁcationmodels decreases by 9.8 on average, with a consistencyof ≈64.1.
this indicates polyjuice can be used to createsuch sets without expert annotators and at less cost..construct these sets by simply ﬁltering out counter-factuals that are labeled the same as their originalinstances (40%–63% depending on the task)..for each task, we test multiple classifers open-sourced by huggingface (wolf et al., 2020), and re-port the best performing model for each6 in table 3(results for other models are analogous).
polyjuicecontrast sets display performance gaps consistentwith those of gardner et al.
(2020), where the setsare constructed manually by nlp researchers, eventhough we use non-expert annotators who only la-bel examples rather than creating them..3.2 training with counterfactuals.
following kaushik et al.
(2020), we augment train-ing sets with counterfactual examples.
in all experi-ments, we ﬁnetune roberta-base on datasets of noriginal examples and m counterfactuals, which aregenerated by polyjuice (m-polyjuice) or craftedfrom scratch by humans (m-cad from kaushik et al.
(2020), only available for nli).
to distinguish thebeneﬁt of counterfactuals from that of just addingmore data, we further add a baseline that uses n + moriginal examples (m-baseline).
in addition toin-domain test set accuracy, we measure models’generalization on out-of-domain datasets, as wellas contrast sets and challenge sets.
we also evaluatemodel capabilities with checklist (ribeiro et al.,2020) for sentiment and qqp.
reported modelperformances are averaged across multiple datasamples and random seeds (appendix b.2)..for sentiment, we select random polyjuice coun-terfactuals regardless of their labels, as long as anoriginal x has at least one ˆx that ﬂips the label.
fornli and qqp, we observed in a pilot study that.
6huggingface.co/{roberta-large-mnli,.
textattack/roberta-base-sst-2,ji-xin/roberta_base-qqp-two_stage}.
randomly chosen counterfactuals may not be moreeﬀective than the same amount of additional data.
we suspect that polyjuice lacks domain knowledgeand context for identifying critical perturbations,and therefore brings beneﬁts redundant with pre-training (longpre et al., 2020).
thus, we use theslicing functions of chen et al.
(2019) to ﬁnd pat-terns of interest (e.g., prepositions in nli), andperturb those patterns by placing [blank]s on thematched spans.
for example, “his surfboard isbeneath him” becomes “his surfboard is [blank]him”, and polyjuice generates counterfactuals suchas “his surfboard is beneath (cid:41) next to him.”.
results.
tables 4–6 indicate that polyjuice aug-mentation is eﬀective in all tasks: m-polyjuicemaintains in-domain accuracy while consistentlyimproving or maintaining generalization accuracyin various out-of-domain and challenge sets.
onnli, polyjuice counterfactuals are as eﬀective ormore eﬀective than counterfactuals created fromscratch (m-cad).
notably, we obtain the largestgains on challenge and contrast sets (e.g., breakand dnc in table 5) or when the out-of-domaindataset is suﬃciently diﬀerent from the trainingdomain (e.g., senti140 and semeval in table 4).
polyjuice also improves results on checklist teststhat previously had high error rates: it signiﬁcantlylowers the error rates on 11 out of 27 qqp tests,7making 2/27 tests worse.
for sentiment, it im-proves the model on 5 out of 15 tests, hurting 1.here, we only report a low m/n ratio (<10% fornli and qqp) to show that a small amount ofaugmentation is already beneﬁcial.
the results aresimilar for other combinations we explored (seeappendix b.2), except when the ratio of counter-factual to original data was too high (e.g.,, m = nmay decrease vocabulary diversity or induce addi-tional data bias, echoing (khashabi et al., 2020))..3.3 discussionwe show that polyjuice counterfactuals are usefulfor evaluation, and more eﬀective than additional(non-counterfactual) data for training in a varietyof tasks.
in contrast to prior work where humansgenerate counterfactuals from scratch, we only askthem to label automatically generated ones, whilestill achieving similar or better results..we believe our approach is more eﬀective thanmanual creation (although both are beneﬁcial): in.
7the absolute error rate drops for at least 5 points, with a.relative diﬀerence of more than 10%..6711model.
sst-2.
senti140.
semeval.
amzbook yelp.
imdb.
imdb-cont..imdb-cad.
m-baselinem-polyjuice.
92.9 ± 0.292.7 ± 0.2.
88.9 ± 0.390.7 ± 0.4.
84.8 ± 0.586.4 ± 0.1.
85.1 ± 0.485.6 ± 0.8.
90.0 ± 0.390.1 ± 0.0.
90.8 ± 0.590.6 ± 0.3.
92.2 ± 0.694.0 ± 0.3.
86.5 ± 0.289.7 ± 0.5.table 4: sentiment model performance, with n=4, 000 and m=2, 000. bolded cells highlight signiﬁcant improve-ments.
m-polyjuice maintains the in-domain and out-of-domain accuracies on reviews (sst-2, amzbook, yelp,imdb movie review (ni et al., 2019; asghar, 2016; maas et al., 2011)), improving it on twitter data (senti140and semeval 2017 (go et al., 2009; nakov et al., 2013)) and contrast sets (gardner et al., 2020; kaushik et al.,2020), likely because their distributions are less similar to the original sst-2 training data..model.
snli.
mnli-m mnli-mm snli-cad break.
dnc.
stress.
m-baselinem-cadm-polyjuice.
85.7 ± 0.485.8 ± 0.685.3 ± 0.3.
86.1 ± 0.286.6 ± 0.186.0 ± 0.1.
86.6 ± 0.285.6 ± 0.386.4 ± 0.0.
72.8 ± 0.373.8 ± 0.273.6 ± 0.2.
86.4 ± 1.589.4 ± 2.989.1 ± 1.2.
54.5 ± 0.655.8 ± 0.957.7 ± 0.3.
65.1 ± 0.665.5 ± 0.565.1 ± 0.2.diagnostic.
56.0 ± 0.856.4 ± 0.457.5 ± 0.5.table 5: nli models, with n=20, 000 and m=1, 574.m-polyjuice improves accuracy on contrast andchallenge sets (kim et al., 2019; naik et al., 2018; glockner et al., 2018; wang et al., 2019); it exhibits comparable(or better) gains than m-cad (manual counterfactuals) with less implementation and annotation eﬀort..model.
qqp.
paws-qqp.
m-baselinem-polyjuice.
84.5 ± 0.684.7 ± 1.0.
37.0 ± 0.538.7 ± 0.4.table 6: polyjuice with n=20, 000 and m=1, 911 im-proves accuracy on paws-qqp (zhang et al., 2019b)..terms of implementation eﬀort, the process of justlabeling counterfactuals is the same as labelingoriginal examples, such that no additional annota-tor training or separate pipelines are required; incontrast, kaushik et al.
(2020) set up two separatecrowdsourcing tasks for creating and labeling thecounterfactuals.
further, annotator eﬀort is muchlower, as evaluating examples is easier than creat-ing them — kaushik et al.
(2020) report an aver-age of ≈2 minutes per nli counterfactual prior toquality validation, while our median time was 10seconds per counterfactual.
even after our qualityvalidation (removing noisy annotators, disregard-ing non-ﬂuent counterfactuals), our rate for nli is≈36 seconds per counterfactual (used in table 5).
in terms of the utility per counterfactual, man-ual creation and polyjuice may be complementary.
manual annotation may be unreliable or incompletefor certain forms of counterfactuals (ribeiro et al.,2018), whereas polyjuice can miss more complexor context-dependent changes, and could beneﬁtfrom target perturbations that compensate for itslack of domain knowledge (targeted guidance isalso helpful for human annotators (huang et al.,2020)).
thus, it may be important to mix both ap-proaches (khashabi et al., 2020).
polyjuice’s ﬂex-ibility opens up possibilities for hybrids betweenhuman creation and human veriﬁcation of targeted,machine-generated counterfactuals..figure 3: (a) an instance in qqp where the model pre-diction f (x) is duplicate (=) at 98.2% conﬁdence, withshap importance weights for tokens in q2.
counter-factual explanations complement shap with concreteexamples and surprising behaviors, e.g., (b) shows thatfriend (cid:41) woman surprisingly ﬂips the prediction to non-duplicate ((cid:44)), despite the low weight on “friend.”.
4 counterfactual explanations.
a popular way of explaining nlp models is toattribute importance weights to the input tokens,either using attention scores (wiegreﬀe and pin-ter, 2019) or by summarizing the model behav-ior on perturbed instances (e.g., lime (ribeiroet al., 2016) and shap (lundberg and lee, 2017)).
though ubiquitous, token scores may not alwaysreﬂect their real importance (pruthi et al., 2020).
popular packages like lime or shap estimatescores by masking words, and therefore may notreﬂect model behavior on natural counterfactualcases.
for example, the token “friend” in figure 3ais not considered important even though a naturalsubstitution in figure 3b ﬂips the prediction.
theopposite happens to “in depression,” where a sig-niﬁcant change makes no diﬀerence to the model’sprediction (figure 3c).
even perfect importance.
6712bq1:  q2: predict  : = duplicate (98.2% conﬁdent)f(x)how can i help a friend experiencing  serious depression?
how do i help a friend who is in depression?q2: how do i help a ●woman who is in depression?
q2: how do i help a friend who is ●suicidal?
q2: how do i ●ﬁnd a friend who is in depression?, perturbed q2̂xf(̂x)≠ = =0.00.10.2weightindepression?ihelpcdascores may be too abstract for users to gain realunderstanding (miller, 2019), e.g., users may notgrasp the signiﬁcance of a low importance score forthe token “help” without concrete examples suchas the one in figure 3d..since presenting a large number of concretecounterfactuals would be overwhelming, we pro-pose a hybrid approach, displaying feature attribu-tions as a high-level summary, together with a ju-dicious selection of polyjuice counterfactuals thatmake behaviors concrete and highlight potentiallimitations.
following miller (2019)’s observationthat people look for explanations revealing unex-pected behavior, we select surprising counterfac-tuals.8 that is, we estimate the expected changein prediction with feature attributions, and selectcounterfactuals that violate these expectations, i.e.,examples where the real change in prediction islarge even though importance scores are low (fig-ure 3b), and examples where the change is smallbut importance scores are high (figure 3c).
ofcourse, users can also view additional counterfac-tuals that perturb tokens of particular interest, atechnique that we explore in the next section..user evaluation.
we study the scenario wherean expert has access to a model and local explana-tions, and evaluate the additional beneﬁt of show-ing counterfactuals, i.e., whether they bring newinsights.
we evaluate three ways of generatingcounterfactuals: (1) polyjuice-random, a baselinewhere we show random polyjuice counterfactuals,(2) expert-surprise, where two graduate students(non-participants) were given access to the modeland instructed to create counterfactuals that are sur-prising given the associated shap scores, and (3)polyjuice-surprise, which uses the selection proce-dure described in the previous paragraph..we recruited 13 participants (graduate studentswith experience in model explanation), and hadthem analyze the aforementioned qqp model.
ineach round, users were shown an example, themodel prediction, and a shap explanation, as infigure 3a.
users were instructed to create up to 10counterfactuals in order to better understand modelbehavior around the example, for which model pre-dictions were given (users created 6 on average).
finally, users simulated what the model would doon six counterfactuals (hase and bansal, 2020),two from each condition (in random order).
coun-terfactuals where users make mistakes are prefer-.
8details in appendix c.1..figure 4: simulation error rates per condition (higherthe better).
polyjuice-surprise has the highest errorrate, indicating these counterfactuals would add themost information to users if displayed..able, as displaying these would add informationthat users do not already have..as shown in figure 4, humans simulated modelbehavior on polyjuice-surprise counterfactualsonly slightly better than random guessing (45% ±6%), i.e., these examples display model behaviorthat is surprising to users even after seeing ex-planations and creating their own counterfactuals.
expert-surprise also had a high error rate, but ata much higher cost: generating these for just 20original instances took 1.5–2 hours of expert labor.
while high error rates could be achieved withunrelated or nonsensical examples, all counterfac-tuals under evaluation were close to the originalexamples, when measured by syntactic tree edit(≈1.0) or levenshtein distance (≈0.2), polyjuice-surprise being the closest on both.
an independentrater labeled 95% of polyjuice-surprise counter-factuals as “likely written by a native speaker,” incontrast to 85% for expert-surprise, indicating thatexperts sometimes resorted to ungrammatical ornonsensical sentences to ﬁnd surprising behaviors.
qualitatively, the study participants tended tocreate counterfactuals by perturbing the token withthe highest weights (84% of their ˆx perturbed to-kens in the top 15% quantile of weights), not gain-ing a real understanding of how the other tokensimpact predictions.
participants also made a sig-niﬁcant number of mistakes even for tokens theyhad inspected, e.g., a participant perturbed the ex-ample in figure 3a by replacing help (cid:41) play with,yielding a non-duplicate model prediction.
whenfaced with help (cid:41) ﬁnd in figure 3d, they incorrectlyassumed the behavior would be the same..these results indicate that polyjuice counter-factuals complement feature attribution explana-tions by displaying information that users oftenmiss, even after they have manually explored themodel behavior beyond explanations.
moreover,polyjuice counterfactuals for this application weremore surprising and ﬂuent than expert-surprise,despite being computed automatically..67130%10%20%30%40%50%error ratepolyjuice-randomexpert-surprisepolyjuice-surpriseconditionsfigure 6: perturbing the subject of x in figure 5athrough [blank], resulting in erroneous predictionsfor diﬀerent quantiﬁers (all should be neutral)..its prediction from neutral to contradiction withroughly the same frequency (≈43%) whether thenegation word is “not” or “n’t”, but ﬂips much morefrequently with a diﬀerent negation pattern wherea determiner is replaced with “no” (92.8%).
whilethese behaviors may be correct in some instances,they often are not (e.g., figure 5a), and thus wouldwarrant further exploration, and potential mitiga-tion strategies (e.g., counterfactual training, §3).
tangentially, the impact of det (cid:41) no might leadthe analyst to explore the impact of perturbing thesubject of hypotheses, which we do in figure 6 byplacing a [blank] on the subject rather than usinga control code.
this leads to the discovery of unsta-ble and erroneous behaviors regarding quantiﬁers,which we analyze in more detail in appendix d.1..discussion.
polyjuice is a powerful tool for in-teractive analysis.
generating multiple counter-factuals per instance leads to insights that mightbe missed by manual analysis, and the steeringprovided by control codes and [blank]s allowfor analyses that would be non-trivial to do man-ually (wu et al., 2019) or with masked languagemodels (e.g., figure 5b places negations in variousparts of sentences, and figure 6 replaces spans withother spans of varying lengths).
besides error anal-ysis, an analogous interactive use of polyjuice maybe suitable for test creation (ribeiro et al., 2020)and forms of data augmentation that are more con-trolled than what we presented in §3..6 related work.
some prior work in training and evaluation re-lies on humans to generate counterfactuals fromscratch (gardner et al., 2020; teney et al., 2020;kaushik et al., 2020).
our experiments in §3 indi-cate that asking humans to label polyjuice counter-factuals yields similar or better results at a lowercost, which motivates an exploration of a mixtureof manual and semi-automated generation.
sim-ilarly, prior work on analysis relies on experts to.
figure 5: (a) an nli case with a neutral prediction(underlined f ( ˆx) are correct).
polyjuice generates coun-terfactual hypotheses conditioned on the negationcontrol code.
(b) generalizing perturbations into pat-terns (wu et al., 2020).
the change det (cid:41) no ﬂips92.8% of predictions from neutral (cid:41) contradiction..5.interactive analysis.
while our use of polyjuice has so far relied on au-tomatic selection of counterfactuals, we show inthis section how an analyst can beneﬁt from mul-tiple counterfactuals per x, make use of controlledgeneration for more advanced analysis, and extractgeneral patterns from individual observations.
ouruse case is counterfactual error analysis (wu et al.,2019) of roberta ﬁnetuned on nli (used in §3.1),although the techniques are generally applicable..there is a known correlation between the la-bel contradiction and hypotheses with negation innli datasets (gururangan et al., 2018), which maycause models to fail on non-contradiction nega-tions.
we explore this in figure 5a by generatingcounterfactual hypotheses for a random neutral in-stance, conditioning only on the original x and thenegation control code.
while the ﬁrst two coun-terfactuals display this failure mode, there is a sur-prising inconsistency in model behavior between“not” and “n’t”.
we note that manual analysis maynot explore these three negation forms, and thusnot surface this puzzling behavior..to verify if the pattern is widespread, we gen-erate counterfactuals with the negation controlcode for a random set of instances correctly pre-dicted as neutral (n = 895).
to generalize individ-ual changes into patterns, we extract frequent coun-terfactual templates with tempura (wu et al., 2020)(details in appendix d.2), shown in figure 5b.
thetop templates (in bold) show that the model ﬂips.
6714, perturbed h through [negation]̂xp: a woman is holding a baby by a window.
h: this woman is looking out the window.h: ●no woman is looking out the window.
h: this woman isn’t looking out the window.
h: this woman is not looking out the window.f(̂x)contradiction contradiction neutralxf(x)aux → aux not * → * not * → * n’t * → * part det → no…is not looking… …aren’t playing… the→no girls like… a→no man in…coverage (%n→c)412 (42.3%) 434 (43.5%) 180 (92.8%)neutral → xf(̂x)templateab, perturbed h with [blank]̂xh: ●two women are looking out the window.
h: ●ten women are looking out the window.
h: ●more than one person…window.f(̂x)neutral contradiction entailment[blank] looking out the window.
, perturbed h with [blank]̂xh: ●two women are looking out the window.
h: ●ten women are looking out the window.
h: ●more than one person…window.f(̂x)neutral contradiction entailment[blank] looking out the window.
create individual counterfactuals or perturbationfunctions (wu et al., 2019; ribeiro et al., 2020).
in §5, we show that polyjuice enhances currentpractice by generating multiple counterfactuals thatmight have been overlooked, and by providing ab-stractions that allow for new kinds of analyses..prior work on automatically generating counter-factuals typically has a narrower scope in termsof the relationships x (cid:41) ˆx.
for example, adver-sarial generators aim to maintain semantics whilechanging model predictions (ribeiro et al., 2018;iyyer et al., 2018; li et al., 2021), whereas concur-rent work to our own (madaan et al., 2021; rosset al., 2020) automatically generates ˆx that changepredictions for explanation or analysis, with no con-straints on semantics.
however, as shown in §3–§5,a mix of label-preserving and label-ﬂipping coun-terfactuals generated by polyjuice is quite usefulfor training, evaluation, explanation, and analy-sis.
further, general-purpose counterfactuals maylead to serendipitous discoveries (§5), especially aspolyjuice is not ﬁne-tuned to the target domain (andthus less liable to merely replicate what is alreadythere).
finally, by allowing control through controlcodes and [blank]s, polyjuice supports human-generator collaboration, where a person speciﬁesdesired changes (e.g., perturb the sentence subject).
such collaboration is hard to imagine using auto-matic generators with no control, or with coarsercontrol through predeﬁned style attributes or la-bels (madaan et al., 2020; malmi et al., 2020).
toour knowledge, prior work on controlled genera-tion (keskar et al., 2019; dathathri et al., 2020)does not address counterfactual generation..7 conclusion and future work.
we propose polyjuice, a general-purpose generatorthat produces ﬂuent and diverse counterfactuals,allowing for control over the kinds and locationsof perturbations.
with simple, task-speciﬁc selec-tion heuristics, polyjuice supports various down-stream tasks on diﬀerent domains, including coun-terfactual data augmentation, contrast set genera-tion, counterfactual explanation, and error analysis.
while polyjuice is broadly applicable, it is notbias-free: control codes are pre-deﬁned and cer-tainly not exhaustive, and the model is ﬁne-tunedon a collection of paired datasets where certainperturbations are more or less likely (e.g., we ob-serve that words with negative sentiment tend tobe slightly more likely than positive ones in some.
contexts).
collecting naturally occurring counter-factuals is an important area of future research, asis the development of generators that allow for con-trol even without a-priori control codes..besides improving the generators, further workis needed to improve the value of counterfactu-als.
for example, while polyjuice shows consistentgains across tasks in data augmentation, the im-provements on some datasets are not as signiﬁcant.
this aligns with observations in prior work thateven manual counterfactuals can be marginally ben-eﬁcial (kaushik et al., 2020; huang et al., 2020),possibly because the original data is already diverseenough, or the perturbed signal in counterfactuals istoo subtle to aﬀect the model (e.g., when only a sin-gle word is changed in a long sentence.)
we hopeto perform more thorough experiments on tuningthe amount and the distribution of counterfactualaugmentation, as well as other ways of incorporat-ing counterfactuals, such as having explicit termsin the loss function for contrasting counterfactu-als with original data (teney et al., 2020), or otherforms of contrastive learning..although our applications all involved people,the human-polyjuice collaboration in labeling andexplanations could beneﬁt from richer interactionmechanisms.
we believe polyjuice motivates fu-ture research on more expressive forms of counter-factual training, where users generate counterfactu-als together with polyjuice, and label counterfac-tual patterns rather than individual instances.
simi-larly, interactive explanations and analysis are excit-ing directions, especially as we develop new waysof selecting, presenting, and aggregating counter-factuals for various analysis objectives.
havingnoted these opportunities, we believe polyjuice isalready a powerful tool for counterfactual reason-ing, in particular for tasks where people are directlyinvolved.
polyjuice is opensource, and available athttps://github.com/tongshuangwu/polyjuice..acknowledgements.
the work was supported by onr grant n00014-18-1-2193, nsf rapid grant 2040196, nsfaward iis-1901386, the university of washing-ton wrf/cable professorship, and the allen in-stitute for artiﬁcial intelligence (ai2).
we thankjim chen, dianqi li, scott lundberg, hao peng,sameer singh, jiao sun, victor zhong, and sitongzhou for their helpful comments, as well as ouruser study participants for their valuable input..6715ethical considerations.
our work includes labeling counterfactuals oncrowdsourcing platforms, as well as conductinguser studies with graduate students.
as detailed inappendix b.1 and c.2, we compensated the mturkworkers $2.5 for ≈15 minutes of labeling, and thegraduate students $20 for the user study (one hour),above the u.s. federal minimum wage.
the studiesare with irb approval..we only ﬁnetune gpt-2 rather than training itfrom scratch, such that our compute costs are rel-atively low (around 8 hours for ﬁnetuning, ap-pendix a).
all of our ﬁnetuning experiments in-volved ﬁnetuning roberta on smaller datasets..more critically, with most of our demonstratedapplications using a human-generator hybrid mech-anism, we stress that the interaction between thetwo deserves careful consideration.
it has longbeen reported that algorithms interacting with hu-mans can negatively impact the human.9 in ourcase, the concern might be that users can developan over-reliance on polyjuice (bansal et al., 2021)and hastily accept its generations.
not only canthis decrease users’ creativity (green et al., 2014),but it may bias their analysis process: as discussedin §7, polyjuice generation is not exhaustive, andmay favor some perturbation patterns over othersin unpredictable ways.
in the short term, we planto highlight these limitations as part of the modeldocumentation, while future research should iden-tify interaction mechanisms, so as to ensure thatpolyjuice or other counterfactual generators sup-port humans, rather than hindering their perfor-mance..references.
nabiha asghar.
2016. yelp dataset challenge: reviewrating prediction.
arxiv preprint arxiv:1605.05362..gagan bansal, tongshuang wu, joyce zhou, ray-mond fok, besmira nushi, ece kamar, marco tulioribeiro, and daniel weld.
2021. does the wholeexceed its parts?
the eﬀect of ai explanations oncomplementary team performance.
in proceedingsof the 2021 chi conference on human factors incomputing systems, chi ’21, new york, ny, usa.
association for computing machinery..samuel r. bowman, gabor angeli, christopher potts,and christopher d. manning.
2015. a large anno-tated corpus for learning natural language inference..in proceedings of the 2015 conference on empiri-cal methods in natural language processing, pages632–642, lisbon, portugal.
association for compu-tational linguistics..vincent s. chen, sen wu, alexander j. ratner, jenweng, and christopher ré.
2019. slice-based learn-ing: a programming model for residual learning inin advances in neural infor-critical data slices.
mation processing systems 32: annual conferenceon neural information processing systems 2019,neurips 2019, december 8-14, 2019, vancouver,bc, canada, pages 9392–9402..noam chomsky.
2002. syntactic structures.
walter de.
gruyter..sumanth dathathri, andrea madotto, janice lan, janehung, eric frank, piero molino, jason yosinski, androsanne liu.
2020. plug and play language models:a simple approach to controlled text generation.
in8th international conference on learning represen-tations, iclr 2020, addis ababa, ethiopia, april26-30, 2020. openreview.net..chris donahue, mina lee, and percy liang.
2020. en-abling language models to ﬁll in the blanks.
in pro-ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 2492–2501, online.
association for computational lin-guistics..matt gardner, yoav artzi, victoria basmov, jonathanberant, ben bogin, sihao chen, pradeep dasigi,dheeru dua, yanai elazar, ananth gottumukkala,nitish gupta, hannaneh hajishirzi, gabriel ilharco,daniel khashabi, kevin lin, jiangming liu, nel-son f. liu, phoebe mulcaire, qiang ning, sameersingh, noah a. smith, sanjay subramanian, reuttsarfaty, eric wallace, ally zhang, and ben zhou.
2020. evaluating models’ local decision boundariesin findings of the associationvia contrast sets.
for computational linguistics: emnlp 2020, pages1307–1323, online.
association for computationallinguistics..sahaj garg, vincent perot, nicole limtiaco, ankurtaly, ed h chi, and alex beutel.
2019. counterfac-tual fairness in text classiﬁcation through robustness.
in proceedings of the 2019 aaai/acm conferenceon ai, ethics, and society, pages 219–226..max glockner, vered shwartz, and yoav goldberg.
2018. breaking nli systems with sentences that re-in proceedings ofquire simple lexical inferences.
the 56th annual meeting of the association for com-putational linguistics (volume 2: short papers),pages 650–655, melbourne, australia.
associationfor computational linguistics..9https://www.nytimes.com/.
interactive/2017/04/02/technology/uber-drivers-psychological-tricks.html?_r=0.
alec go, richa bhayani, and lei huang.
2009. twit-ter sentiment classiﬁcation using distant supervision.
cs224n project report, stanford, 1(12):2009..6716spence green, sida i. wang, jason chuang, jeﬀreyheer, sebastian schuster, and christopher d. man-ning.
2014. human eﬀort and machine learnabil-ity in computer aided translation.
in proceedings ofthe 2014 conference on empirical methods in nat-ural language processing (emnlp), pages 1225–1236, doha, qatar.
association for computationallinguistics..suchin gururangan, swabha swayamdipta, omerlevy, roy schwartz, samuel bowman, and noah a.smith.
2018. annotation artifacts in natural lan-in proceedings of the 2018guage inference data.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 2 (short papers),pages 107–112, new orleans, louisiana.
associa-tion for computational linguistics..peter hase and mohit bansal.
2020. evaluating ex-plainable ai: which algorithmic explanations helpusers predict model behavior?
in proceedings of the58th annual meeting of the association for compu-tational linguistics, pages 5540–5552, online.
as-sociation for computational linguistics..william huang, haokun liu, and samuel r. bowman.
2020. counterfactually-augmented snli trainingdata does not yield better generalization than unaug-mented data.
in proceedings of the first workshopon insights from negative results in nlp, pages 82–87, online.
association for computational linguis-tics..mohit iyyer, john wieting, kevin gimpel, and lukezettlemoyer.
2018. adversarial example generationwith syntactically controlled paraphrase networks.
in proceedings of the 2018 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long papers), pages 1875–1885, neworleans, louisiana.
association for computationallinguistics..daniel kahneman and amos tversky.
1981. the simu-lation heuristic.
technical report, stanford univ cadept of psychology..divyansh kaushik,.
eduard h. hovy,.
andzachary chase lipton.
2020. learning the diﬀer-ence that makes a diﬀerence with counterfactually-augmented data.
in 8th international conference onlearning representations, iclr 2020, addis ababa,ethiopia, april 26-30, 2020. openreview.net..nitish shirish keskar, bryan mccann, lav varsh-ney, caiming xiong, and richard socher.
2019.ctrl - a conditional transformer languagemodel for controllable generation.
arxiv preprintarxiv:1909.05858..daniel khashabi, tushar khot, and ashish sabharwal.
2020. more bang for your buck: natural perturba-tion for robust question answering.
in proceedingsof the 2020 conference on empirical methods in.
natural language processing (emnlp), pages 163–170, online.
association for computational linguis-tics..najoung kim, roma patel, adam poliak, patrick xia,alex wang, tom mccoy, ian tenney, alexis ross,tal linzen, benjamin van durme, samuel r. bow-man, and ellie pavlick.
2019. probing what diﬀerentnlp tasks teach machines about function word com-prehension.
in proceedings of the eighth joint con-ference on lexical and computational semantics(*sem 2019), pages 235–249, minneapolis, min-nesota.
association for computational linguistics..tom kwiatkowski, jennimaria palomaki, olivia red-ﬁeld, michael collins, ankur parikh, chris al-berti, danielle epstein, illia polosukhin, jacob de-vlin, kenton lee, kristina toutanova, llion jones,matthew kelcey, ming-wei chang, andrew m. dai,jakob uszkoreit, quoc le, and slav petrov.
2019.natural questions: a benchmark for question an-swering research.
transactions of the associationfor computational linguistics, 7:452–466..vi levenshtein.
1966. binary codes capable of cor-recting deletions, insertions and reversals.
sovietphysics doklady, 10:707..dianqi li, yizhe zhang, hao peng, liqun chen, chrisbrockett, ming-ting sun, and bill dolan.
2021.contextualized perturbation for textual adversarialin proceedings of the 2021 conference ofattack.
the north american chapter of the association forcomputational linguistics: human language tech-nologies, pages 5053–5069, online.
association forcomputational linguistics..bill yuchen lin, wangchunshu zhou, ming shen, peizhou, chandra bhagavatula, yejin choi, and xiangren.
2020. commongen: a constrained text gen-eration challenge for generative commonsense rea-soning.
in findings of the association for computa-tional linguistics: emnlp 2020, pages 1823–1840,online.
association for computational linguistics..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
arxiv preprint arxiv:1907.11692..shayne longpre, yu wang, and chris dubois.
2020.how eﬀective is task-agnostic data augmentation forpretrained transformers?
in findings of the associ-ation for computational linguistics: emnlp 2020,pages 4401–4411, online.
association for computa-tional linguistics..scott m. lundberg and su-in lee.
2017. a uniﬁedin ad-approach to interpreting model predictions.
vances in neural information processing systems30: annual conference on neural information pro-cessing systems 2017, december 4-9, 2017, longbeach, ca, usa, pages 4765–4774..6717andrew l. maas, raymond e. daly, peter t. pham,dan huang, andrew y. ng, and christopher potts.
2011. learning word vectors for sentiment analy-sis.
in proceedings of the 49th annual meeting ofthe association for computational linguistics: hu-man language technologies, pages 142–150, port-land, oregon, usa.
association for computationallinguistics..aman madaan, amrith setlur, tanmay parekh, barn-abas poczos, graham neubig, yiming yang, ruslansalakhutdinov, alan w black, and shrimai prabhu-moye.
2020. politeness transfer: a tag and generateapproach.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,pages 1869–1881, online.
association for computa-tional linguistics..nishtha madaan, inkit padhi, naveen panwar, and dip-tikalyan saha.
2021. generate your counterfactu-als: towards controlled counterfactual generationfor text.
proceedings of the aaai conference onartiﬁcial intelligence..eric malmi, aliaksei severyn, and sascha rothe.
2020.unsupervised text style transfer with padded maskedlanguage models.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing (emnlp), pages 8671–8680, online.
as-sociation for computational linguistics..tom mccoy, ellie pavlick, and tal linzen.
2019.right for the wrong reasons: diagnosing syntacticheuristics in natural language inference.
in proceed-ings of the 57th annual meeting of the associationfor computational linguistics, pages 3428–3448,florence, italy.
association for computational lin-guistics..tim miller.
2019. explanation in artiﬁcial intelligence:insights from the social sciences.
artiﬁcial intelli-gence, 267:1 – 38..john morris, eli liﬂand, jin yong yoo, jake grigsby,di jin, and yanjun qi.
2020. textattack: a frame-work for adversarial attacks, data augmentation, andadversarial training in nlp.
in proceedings of the2020 conference on empirical methods in natu-ral language processing: system demonstrations,pages 119–126, online.
association for computa-tional linguistics..aakanksha naik, abhilasha ravichander, normansadeh, carolyn rose, and graham neubig.
2018.stress test evaluation for natural language inference.
in proceedings of the 27th international conferenceon computational linguistics, pages 2340–2353,santa fe, new mexico, usa.
association for com-putational linguistics..preslav nakov, sara rosenthal, zornitsa kozareva,veselin stoyanov, alan ritter, and theresa wilson.
2013. semeval-2013 task 2: sentiment analysis intwitter.
in second joint conference on lexical andcomputational semantics (*sem), volume 2: pro-ceedings of the seventh international workshop on.
semantic evaluation (semeval 2013), pages 312–320, atlanta, georgia, usa.
association for com-putational linguistics..jianmo ni, jiacheng li, and julian mcauley.
2019.justifying recommendations using distantly-labeledin proceedingsreviews and ﬁne-grained aspects.
of the 2019 conference on empirical methods innatural language processing and the 9th interna-tional joint conference on natural language pro-cessing (emnlp-ijcnlp), pages 188–197, hongkong, china.
association for computational lin-guistics..judea pearl.
2018. causal and counterfactual inference..the handbook of rationality, pages 1–41..danish pruthi, mansi gupta, bhuwan dhingra, gra-ham neubig, and zachary c. lipton.
2020. learn-ing to deceive with attention-based explanations.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4782–4793, online.
association for computational lin-guistics..lianhui qin, antoine bosselut, ari holtzman, chandrabhagavatula, elizabeth clark, and yejin choi.
2019.counterfactual story reasoning and generation.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 5043–5053, hong kong, china.
association for computa-tional linguistics..alec radford, jeﬀrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners.
openaiblog, 1(8):9..colin raﬀel, noam shazeer, adam roberts, kather-ine lee, sharan narang, michael matena, yanqizhou, wei li, and peter j. liu.
2020. exploringthe limits of transfer learning with a uniﬁed text-to-text transformer.
journal of machine learning re-search, 21(140):1–67..pranav rajpurkar, jian zhang, konstantin lopyrev, andpercy liang.
2016. squad: 100,000+ questions formachine comprehension of text.
in proceedings ofthe 2016 conference on empirical methods in natu-ral language processing, pages 2383–2392, austin,texas.
association for computational linguistics..nils reimers and iryna gurevych.
2019. sentence-bert: sentence embeddings using siamese bert-networks.
in proceedings of the 2019 conference onempirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages3982–3992, hong kong, china.
association forcomputational linguistics..marco túlio ribeiro, sameer singh, and carlosguestrin.
2016.
"why should i trust you?
": explain-.
6718in proceed-ing the predictions of any classiﬁer.
ings of the 22nd acm sigkdd international con-ference on knowledge discovery and data mining,san francisco, ca, usa, august 13-17, 2016, pages1135–1144.
acm..marco tulio ribeiro, sameer singh, and carlosguestrin.
2018. semantically equivalent adversar-ial rules for debugging nlp models.
in proceedingsof the 56th annual meeting of the association forcomputational linguistics (volume 1: long papers),pages 856–865, melbourne, australia.
associationfor computational linguistics..marco tulio ribeiro, tongshuang wu, carlos guestrin,and sameer singh.
2020. beyond accuracy: be-havioral testing of nlp models with checklist.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4902–4912, online.
association for computational lin-guistics..alexis ross, ana marasovi´c, and matthew e. peters.
explaining nlp models via minimal con-.
2020.trastive editing (mice)..keisuke sakaguchi, ronan le bras, chandra bhaga-vatula, and yejin choi.
2020. winogrande: an ad-versarial winograd schema challenge at scale.
pro-ceedings of the aaai conference on artiﬁcial intel-ligence, 34(05):8732–8740..richard socher, alex perelygin, jean wu, jasonchuang, christopher d. manning, andrew ng, andchristopher potts.
2013. recursive deep modelsfor semantic compositionality over a sentiment tree-in proceedings of the 2013 conference onbank.
empirical methods in natural language processing,pages 1631–1642, seattle, washington, usa.
asso-ciation for computational linguistics..damien teney, ehsan abbasnedjad, and anton van denhengel.
2020. learning what makes a diﬀerencefrom counterfactual examples and gradient supervi-sion.
in computer vision – eccv 2020, pages 580–599, cham.
springer international publishing..vijay v vazirani.
2013. approximation algorithms..springer science & business media..alex wang, amanpreet singh, julian michael, felixhill, omer levy, and samuel r. bowman.
2019.glue: a multi-task benchmark and analysis plat-in 7thform for natural language understanding.
international conference on learning representa-tions, iclr 2019, new orleans, la, usa, may 6-9,2019. openreview.net..sarah wiegreﬀe and yuval pinter.
2019. attention isnot not explanation.
in proceedings of the 2019 con-ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 11–20, hong kong, china.
associ-ation for computational linguistics..john wieting and kevin gimpel.
2018. paranmt-50m: pushing the limits of paraphrastic sentence em-beddings with millions of machine translations.
inproceedings of the 56th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 451–462, melbourne, australia.
association for computational linguistics..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, remi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander rush.
2020. trans-formers: state-of-the-art natural language process-ing.
in proceedings of the 2020 conference on em-pirical methods in natural language processing:system demonstrations, pages 38–45, online.
asso-ciation for computational linguistics..tongshuang wu, marco tulio ribeiro, jeﬀrey heer,and daniel weld.
2019. errudite: scalable, repro-in proceed-ducible, and testable error analysis.
ings of the 57th annual meeting of the associationfor computational linguistics, pages 747–763, flo-rence, italy.
association for computational linguis-tics..tongshuang wu, kanit wongsuphasawat, donghaoren, kayur patel, and chris dubois.
2020. tem-pura: query analysis with structural templates.
inchi ’20: chi conference on human factors incomputing systems, honolulu, hi, usa, april 25-30, 2020, pages 1–12.
acm..huangzhao zhang, hao zhou, ning miao, and lei li.
2019a.
generating ﬂuent adversarial examples forin proceedings of the 57th an-natural languages.
nual meeting of the association for computationallinguistics, pages 5564–5569, florence, italy.
asso-ciation for computational linguistics..kaizhong zhang and dennis shasha.
1989. simplefast algorithms for the editing distance between treesand related problems.
siam journal on computing,18(6):1245–1262..yuan zhang, jason baldridge, and luheng he.
2019b.
paws: paraphrase adversaries from word scram-in proceedings of the 2019 conference ofbling.
the north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 1 (long and short papers), pages1298–1308, minneapolis, minnesota.
associationfor computational linguistics..yaoming zhu, sidi lu, lei zheng, jiaxian guo,weinan zhang, jun wang, and yong yu.
2018. texy-gen: a benchmarking platform for text generationmodels.
in the 41st international acm sigir con-ference on research & development in informationretrieval, sigir 2018, ann arbor, mi, usa, july 08-12, 2018, pages 1097–1100.
acm..6719dataset.
negation quantifier lexical resemantic insert delete restructure shuffle global.
cadcontrasthansparanmtpawswinograndecrawledtotal.
3,274336502,797813,01109,549.
29243608251,8159403,462.
8,1431,607010,00010,00010,0005,00044,750.
2,6031,291010000100006,927030,821.
9605893,9266,4423,6301205,00020,667.
9525863,9266,2053,4031245,00020,167.
2202754945,1364,551453011,129.
361491,6021,41710,0006510813,377.
3,466877210,00010,00031845,00032,529.table 7: the datasets used for ﬁnetuning polyjuice, and the control code distributions..a gpt-2 as counterfactual generator.
a.1 training data and parameterswe combine several datasets to ﬁnetune polyjuice.
contrast set.
authors of 10 existing nlpdataset each manually perturbed 100–1,000 in-stances to change the gold label, so to inspect amodel’s local decision boundary (gardner et al.,2020).
the perturbation patterns vary based onthe tasks and the annotators, allowing us to learndiverse strategies.
to make sure we can use thecontrast set to evaluate the sentiment model, weexcluded the imdb movie review from the training.
counterfactually-augmented data (cad).
kaushik et al.
(2020) crowdsourced counterfactualsfor imdb movie review (1.7k), which we split intopaired sentences to match the text length of otherdatasets.
cad’s perturbation patterns also varybased on the task, but can especially contributeto negation.
as nli is in our demonstratingapplications, we did not use their 6.6k snlicounterfactuals.10.
winogrande is a large-scale dataset of 44k in-stances for testing common sense problems (sak-aguchi et al., 2020).
it contains sentences that diﬀeronly by one trigger word (e.g., one noun), makingit most suitable for learning lexical exchanges..paranmt-50m contains 50 million english-english sentential paraphrase pairs, covering vari-ous domains and styles of text, as well as diﬀerentsentence structures (wieting and gimpel, 2018)..paws (zhang et al., 2019b) contains pairswith high text overlaps, created through controlledword swapping, best demonstrating shuffle andrestructure.
we used its 49k wikipedia parts..hans (mccoy et al., 2019), a challenge set fornli, contains 10k pairs of premises and hypothesescreated based on 10 heavily fallible syntactic tem-plates, and therefore compensates rarer structuralchanges that may be missed by paws..10similarly, though qqp is suitable for training polyjuice,.
we omitted it so qqp can be used in our evaluation..crawled we additionally crawl naturally occur-ring sentence pairs from non-paired datasets boostsome speciﬁc patterns and increase lexical diversity.
this include (1) commongen (lin et al., 2020),sentences with common sense concepts; (2) naturalquestions (kwiatkowski et al., 2019), collectionsof queries issued to google engines (and thereforeinvolve various paraphrases of similar user intents),and (3) squad (rajpurkar et al., 2016), whoseparagraphs involve wikipedia knowledge.
we es-timate close pairs using edit distance, and broadlyaccept those with less than 60% editing.
to excludetricky cases (e.g.,“how do i not be” can be incor-rectly regarded as negation for “how do i recoverit”), we only augment the most determined patterns:lexical, insert, delete, and shuffle..to balance the distribution (table 7), for eachdataset, we extract control codes from all the (x, ˆx),and randomly sample up to 10,000 instances percodes.
still, quantifier and negation have lesstraining data compared to other codes.
fortunately,these codes tend to be limited to more speciﬁcpatterns (“more than”, “not”, “never”) when com-pared to “broad” codes like lexical, and thuseven a small sample is enough to learn them.
weﬁnetuned an oﬀ-the-shelf gpt-2 model from wolfet al.
(2020) for 10 epochs with an initial learningrate 5e-5, a batch size of 8, and a sequence lengthof 120 (but any lm can potentially be used).
weselect the best epoch based on the evaluation losson a holdout set of size 5,000. the training tookaround 8 hours on two titan rtxs..a.2.
intrinsic evaluation details.
a.2.1 closeness and diversity.
similar to madaan et al.
(2021), we compare thediversity and closeness of polyjuice with alterna-tive generators, i.e., roberta and t5, representingmasked language models that prioritize word andspan substitution, and original gpt-2, representingthe standard generative model not conditioned on x.for a given x and its counterfactuals ˆx, we approx-.
6720imate diversity using self-bleu (zhu et al., 2018)within ˆx.
meanwhile, closeness is the average dis-tance between x and every ˆx ∈ ˆx, both with thenormalized word level levenshtein edit distance((levenshtein, 1966), used in mice (ross et al.,2020)), and syntactic tree edit distance ((zhang andshasha, 1989) in gyc (madaan et al., 2021))..we run the three generators on 300 sentencesin total.
in gpt-2, we take the ﬁrst two wordsof an x as the input context (prompt), limit thelength of the generation to be similar to x, andcollect 10 counterfactuals.
as for roberta andt5, we repeatedly perturb x for three times, eachtime randomly placing up to three [mask] tokens,and ask the generator to generate 5 counterfactu-als through beam search, following ribeiro et al.
(2020).
polyjuice uses the same blank (mask)placement as in roberta and t5, but we addi-tionally enumerate through all control codes.
foreach x, we randomly sample 5 counterfactuals toform ˆx per generator..as shown in table 2, polyjuice achieves a bal-ance between diversity and closeness.
ideally, wewould also like to compare polyjuice with concur-rent work (madaan et al., 2021; ross et al., 2020),but these are yet to be open-sourced and requireextensive implementation or ﬁnetuning..a.2.2 controllabilityto evaluate controllability, we compare polyjuicewith t5, and gpt-2 ﬁnetuned on prompts withoutcodes (called polyjuice -a), such that both base-lines consider suﬃcient context.
for each con-trol code, we compare the control success rate ofpolyjuice and polyjuice-a on 300 prompts.
foreach prompt, we generate counterfactuals throughbeam search (beam = 5), and recompute the codeson the top three generated ˆx.
we deem the controlsuccessful if at least one of the three recomputedcodes matches the desired control code (though inpolyjuice-a, we only measure whether the code nat-urally occurs in the uncontrolled generation.)
thesuccess rate increases by 26% ± 13% across all con-trol codes, ranging from quantifier (increasing6%, from 50% to 56%) to negation (42%, from5% to 47%).
non-ﬁnetuned t5 also achieves lesscontrol (success rate decreases by 33% on average.)
common failure cases include (1) the con-trol codes conﬂict with the blanks, e.g.,“a dog isembraced by a [blank]” would not respond tonegation.
(2) x does not have a corresponding pat-tern, e.g., shuffle is not applicable to “the movie.
figure 7: a sample labeling task: the crowdworkersannotate three counterfactuals based on their validityand class label, with respect to the original instance..is good.” (3) certain salient patterns dominate thegeneration probability, e.g., the model tends to per-turb the quantiﬁer “two” in “two dogs are running,”regardless of the code..b additional train & eval details, §3.
b.1 mturk labeling details.
procedure the study started with an introductionthat explained the context and tasks.
to familiar-ize crowdworkers with the task, we asked them tocomplete 1-2 training rounds, and explained theexpected labels.
each annotator then completed 22tasks, labeling 3 counterfactuals of a single exam-ple in each round, as in figure 7. the 22 roundsconsisted of 20 actual labeling tasks and 2 extra“gold rounds” with known correct labels.
the goldcases later served to ﬁlter low-quality crowdwork-ers.
the median annotation time was around 15minutes, and participants received $2.5..participants.
we recruited participants frommturk, limiting the pool to subjects from withinthe us with a prior task approval rating of at least97% and a minimum of 1,000 approved tasks..data quality.
we applied two ﬁltering strate-gies: (1) high-quality worker.
we only kept datafrom participants whose median labeling time perround was more than 18 seconds and correctly la-beled at least 4 gold counterfactuals (out of 6), orwho correctly labeled all gold ones.
(2) majorityvote labeling.
we collected two annotations percounterfactual, and only kept those that at least oneannotator deemed valid, and both annotators agreedon a particular class label.
one of the authors la-.
6721prediction change df(t, x) is the weighted aver-age of | fp(x) − fp( ˆx)| for all the ˆx that aﬀect t(depression (cid:41) trouble, depression (cid:41) a mood), wherefp(x) is the prediction probability of f on x. theweight corresponds to the number of words modi-ﬁed in ˆx: if e( ˆx) denotes the set of edited words inx, then w( ˆx) = 1/|e( ˆx)|.
intuitively, the more wordschanged in ˆx, the less impact each word has; in fig-ure 3d, we regard “depression” to be responsiblefor half of the impact in in depression (cid:41) suicidal.
we group ˆx based on their aﬀected words gt ={ ˆx | t ∈ e( ˆx)}.
df(t, x) then becomes:.
.
df(t, x) =.
1|gt| + 1.
.
s(t) +.
(cid:88).
ˆx∈gt.
w(t) · | fp(x) − fp( ˆx)|.
.
the additional shap weight s(t) acts as a smooth-ing factor to penalize outliers.
then the gap be-tween the expectation and reality is:.
∆ df(t, x) = df(t, x) − h[df(t, x)].
(1) t withwe ﬁrst ﬁnd the abnormal tokens:small shap weight, but ˆx that change t experi-tl =ence large prediction change on average:∆ df(t, x), and (2) t with large shaparg maxt∈xweight, but ˆx with t changed usually have intactprediction: tu = arg maxt∈x −∆ df(t, x)..then, we use the most extreme cases within thegroups of gtl and gtu as the concrete counterfac-tual explanations, based on their prediction change| fp(x) − fp( ˆx)|, and the aggregated shap weightsof all the changed tokens:.
ˆxl = arg max.
| fp(x) − fp( ˆx)| −.
.
.
ˆx∈gtl.
.
.
s(u).
(cid:88).
u∈r( ˆx).
c.2 user study details.
figure 9 shows the sample interface.
participantsstarted by just seeing the reference example and themodel query box on the left hand side.
when theychose to start the task or after they had exhaustedtheir ten query chances, the query box was disabled,the tasks on the right were displayed, and the par-ticipants completed the tasks.
we compensatedparticipants $20 for the one hour study..d additional err.
analysis details §5.
d.1 additional case study: quantiﬁers.
as a follow-up to figure 6, we slice the data to ﬁndentailment instances that have numbers in the hy-pothesis sentence, and perturb their quantifiers..figure 8: the accuracy trend on two sentiment datasets,as the total training datasize (m+n) varies.
the blue lineshows an augmentation of m = 2k counterfactuals, andthe blue one represents the corresponding m-baseline.
though the counterfactuals remains useful on datasetslike semeval across all m+n, it appears too many coun-terfactuals may be harmful (amzbook)..beled a subset of 100 ˆx on 100 x in sentiment, andreached high agreement with the majority-votedresults (κ = 0.77, raw labeling agreement 88%)..b.2 training details & m/n ratios, for §3.2for each (m, n), we created three samples of train-ing data.
each sample was further averaged overfour random seeds.
for each run, we heuristicallypicked the initial learning rates 1e-5, 2e-5, 2e-5 forsentiment, nli and qqp, and trained 20 epochswith a dropout rate of 0.1 and a batch size of 16.we selected the epoch that had the highest accuracyon the corresponding validation set, which takes1/5 of the training data size, with the same ratio ofm/n counterfactual and original examples..we further explore ratios of added counterfac-tuals.
take sentiment as an example: while thecounterfactual remains eﬀective on most datasets,it hurts the model performance on amzbook whenthe counterfactual takes a large proportion (fig-ure 8, yelp followed a similar but more mild trend).
we suspect that ﬂipping out too much original dataaﬀects the data diversity, and in turn decreases themodel performance.
similarly, huang et al.
(2020)asserted that augmenting n = 1.7k nli data withm = 6.6k counterfactuals did not improve modelgeneralization accuracy..c additional explanation details §4.
c.1 selection methodsbecause shap weights reﬂect the average eﬀect ofmasking a token t, we also focus on word featuresthat are abnormal on average..more concretely, we deﬁne the expected change-in-prediction for perturbing a token t to be theshap importance on it, h[df(t, x)] = s(t).
infigure 3, s(t=depression) = 0.276. the actual.
67224,0004,5005,0005,5006,000total training size8590accuracysemeval4,0004,5005,0005,5006,000total training size8085accuracyamzbookdatasetm-polyjuicem-baselinemodelfigure 9: a sample explanation task for §4.
ing contexts determined by the dependency treestructure (tokens that share the same parents asthe perturbed span).
for example, “is not read-ing” can result in templates t as ﬁne-grained asis reading (cid:41) is not reading, or as sparse as +part.
meanwhile, “are not playing” also translates to+part or +not, but not is reading (cid:41) is not reading.
as such, the ˆx and templates form a many-to-manyrelationship: each ˆx generates multiple templates,and each template covers a diﬀerent group of ˆx..select representative templates.
to ﬁnd rep-resentative changes, we prefer (1) templates thatcover a large number of ˆx.
meanwhile, to avoidoverﬁtting to one instance (e.g., extracting a tem-plate red (cid:41) adj only because “red” is repeatedlyperturbed in one x), we prefer (2) templates thatperturb various unique x. we also prefer (3) ﬁner-grained templates, to avoid being unnecessarilyabstract (e.g., to avoid abstracting “not” when it isthe only part changed.).
with these intuitions, we form the template se-lection as a weighted set coverage problem.
wesee the union of counterfactuals for each x, ˆx, asthe entire set of elements.
then, each templatet ∈ t = t1, ..., tm represents a subset of ˆx that con-tains a number of counterfactuals |t|.
we deﬁnethe weight as w(t) = g(t)/|t|x, where |t|x quantiﬁesthe unique original x covered by t, and g(t) rep-resents the sparsity of t (heuristically decreasingfrom text to pos).
this way, templates that aretoo abstract or too focused on a certain x are pe-nalized by having a high weight.
we use a classicgreedy algorithm (vazirani, 2013) to select a subsetof t ∗ ⊂ t , such that the aggregated coverage ismaximized, and the weight is minimized..figure 10: the nli model cannot perform the actualcounting when the exact number is missing from p..the extracted templates show that the model doesnot perform actual counting.
when changing onenumber to another (num (cid:41) num), the model only ﬂipsthe label in 64.7% cases, while we would expectall cases to be like in figure 10a.
an inspection ofinstances indicates the model gets confused whenthe premise does not contain the same number ex-plicitly.
indeed, when we ﬁlter for such instances(e.g.
figure 10b), the label ﬂip rate of num (cid:41) numis lowered to 30.2%..further, the model only reacts to some quantiﬁerphrase modiﬁers.
+at least (“at least two womenare at a bar”) will always still result in entailment,prediction, +only and +exactly ﬂip the predictedlabel to neutral 90% of the time (“exactly twowomen are at a bar”), but the model only changesthe prediction 52.6% of the time when we add+more than (“more than two women are at a bar”)..d.2 representative perturbation templates.
similar to wu et al.
(2020), the process of ﬁndingrepresentative perturbation patterns takes two steps:extract template.
for each ˆx, we compareit with its x, and translate the perturbed spansinto templates using diﬀerent combinations oftexts, lemmas, sparse and ﬁne-grained part-of-speech tags.
we optionally include surround-.
6723p: two women having drinks at the bar.
h: two→three woman are at a bar.
→ : entailment → contradictionxf(̂x)abp: a boy and a girl gaze in a clothing store window.
h: two→three kids are looking in a store window.
→ : entailment → entailmentxf(̂x)