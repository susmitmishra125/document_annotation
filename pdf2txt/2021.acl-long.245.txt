from machine translation to code-switching:generating high-quality code-switched text.
ishan tarunesh∗, syamantak kumar∗, preethi jyothisamsung korea, google india, iit bombay{ishantarunesh, syamantak.kumar}@gmail.com, pjyothi@cse.iitb.ac.in.
abstract.
generating code-switched text is a problemof growing interest, especially given thescarcity of corpora containing large volumesof real code-switched text.
in this work, weadapt a state-of-the-art neural machine trans-lation model to generate hindi-english code-switched sentences starting from monolingualhindi sentences.
we outline a carefully de-signed curriculum of pretraining steps, includ-ing the use of synthetic code-switched text, thatenable the model to generate high-quality code-switched text.
using text generated from ourmodel as data augmentation, we show signif-icant reductions in perplexity on a languagemodeling task, compared to using text fromother generative models of cs text.
we alsoshow improvements using our text for a down-stream code-switched natural language infer-ence task.
our generated text is further sub-jected to a rigorous evaluation using a humanevaluation study and a range of objective met-rics, where we show performance compara-ble (and sometimes even superior) to code-switched text obtained via crowd workers whoare native hindi speakers..1.introduction.
code-switching (cs) refers to the linguistic phe-nomenon of using more than one language withina single sentence or conversation.
cs appears natu-rally in conversational speech among multilingualspeakers.
the main challenge with building mod-els for conversational cs text is that we do nothave access to large amounts of cs text that is con-versational in style.
one might consider using so-cial media text that contains cs and is more read-ily available.
however, the latter is quite differentfrom conversational cs text in its vocabulary (e.g.,due to the frequent use of abbreviated slang terms,∗ work done while first two authors were students at iit.
bombay..hashtags and mentions), in its sentence structure(e.g., due to character limits in tweets) and in itsword forms (e.g., due to transliteration being com-monly employed in social media posts).
this mo-tivates the need for a generative model of realisticcs text that can be sampled to subsequently trainmodels for cs text..in this work, we tackle the problem of gen-erating high-quality cs text using only limitedamounts of real cs text during training.
we alsoassume access to large amounts of monolingualtext in the component languages and parallel textin both languages, which is a reasonable assump-tion to make for many of the world’s languages.
we focus on hindi-english cs text where the ma-trix (dominant) language is hindi and the embed-ded language is english.1 rather than train a gen-erative model, we treat this problem as a transla-tion task where the source and target languagesare monolingual hindi text and hindi-english cstext, respectively.
we also use the monolingualhindi text to construct synthetic cs sentences us-ing simple techniques.
we show that synthetic cstext, albeit being naive in its construction, plays animportant role in improving our model’s ability tocapture cs patterns..we draw inspiration from the large body ofrecent work on unsupervised machine transla-tion (lample et al., 2018a,b) to design our model,which will henceforth be referred to as translationfor code-switching, or tcs.
tcs, once trained,will convert a monolingual hindi sentence intoa hindi-english cs sentence.
tcs makes ef-fective use of parallel text when it is availableand uses backtranslation-based objective functionswith monolingual text..1given the non-trivial effort involved in collecting anno-tations from professional annotators and crowd workers, wefocused on a single language pair (hindi-english) and leaveexplorations on more language pairs for future work..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3154–3169august1–6,2021.©2021associationforcomputationallinguistics3154below, we summarize our main contributions:.
1. we propose a state-of-the-art.
translationmodel that generates hindi-english cs textstarting from monolingual hindi text.
thismodel requires very small amounts of real cstext, uses both supervised and unsupervisedtraining objectives and considerably benefitsfrom a carefully designed training curriculum,that includes pretraining with syntheticallyconstructed cs sentences..2. we introduce a new hindi-english cs textcorpus in this work.2 each cs sentence is ac-companied by its monolingual hindi transla-tion.
we also designed a crowdsourcing taskto collect cs variants of monolingual hindisentences.
the crowdsourced cs sentenceswere manually verified and form a part of ournew dataset..3. we use sentences generated from our modelto train language models for hindi-englishcs text and show significant improvementsin perplexity compared to other approaches..4. we present a rigorous evaluation of the qual-ity of our generated text using multiple ob-jective metrics and a human evaluation study,and they clearly show that the sentences gen-erated by our model are superior in qualityand successfully capture naturally occurringcs patterns..2 related work.
early approaches of language modeling for code-switched text included class-based n-gram mod-els (yeh et al.
), factored language models that ex-ploited a large number of syntactic and semanticfeatures (adel et al., 2015), and recurrent neurallanguage models (adel et al., 2013) for cs text.
all these approaches relied on access to real cstext to train the language models.
towards alle-viating this dependence on real cs text, there hasbeen prior work on learning code-switched lan-guage models from bilingual data (li and fung,2014b,a; garg et al., 2018b) and a more recentdirection that explores the possibility of generat-ing synthetic cs sentences.
(pratapa et al., 2018)presents a technique to generate synthetic cs textthat grammatically adheres to a linguistic theory.
2the new dataset and relevant code is available at:.
https://www.cse.iitb.ac.in/~pjyothi/tcs..of code-switching known as the equivalence con-straint (ec) theory (poplack, 1979; sankoff, 1998).
lee and li (2020) proposed a bilingual attentionlanguage model for cs text trained solely using aparallel corpus..another recent line of work has explored neu-ral generative models for cs text.
garg et al.
(2018a) use a sequence generative adversarial net-work (seqgan (yu et al., 2017)) trained on realcs text to generate sentences that are used to aidlanguage model training.
another gan-basedmethod proposed by chang et al.
(2019) aims topredict the probability of switching at each to-ken.
winata et al.
(2018) and winata et al.
(2019)use a sequence-to-sequence model enabled with acopy mechanism (pointer network (vinyals et al.,2015)) to generate cs data by leveraging parallelmonolingual translations from a limited source ofcs data.
samanta et al.
(2019) proposed a hier-archical variational autoencoder-based model tai-lored for code-switching that takes into accountboth syntactic information and language switchingsignals via the use of language tags.
(we presenta comparison of tcs with both samanta et al.
(2019) and garg et al.
(2018a) in section 5.2.1.).
in a departure from using generative modelsfor cs text, we view this problem as one of se-quence transduction where we train a model to con-vert a monolingual sentence into its cs counter-part.
chang et al.
(2019); gao et al.
(2019) usegan-based models to modify monolingual sen-tences into cs sentences, while we treat this prob-lem of cs generation as a translation task and drawinspiration from the growing body of recent workon neural unsupervised machine translation mod-els (lample et al., 2018a,b) to build an effectivemodel of cs text..the idea of using translation models for code-switching has been explored in early work (vuet al., 2012; li and fung, 2013; dhar et al., 2018).
concurrent with our work, there have been effortstowards building translation models from englishto cs text (solorio et al., 2021) and cs text to en-glish (gupta et al., 2021).
while these works focuson translating from the embedded language (en-glish) to the cs text or vice-versa, our approachstarts with sentences in the matrix language (hindi)which is the more dominant language in the cstext.
also, ours is the first work, to our knowledge,to repurpose an unsupervised neural machine trans-lation model to translate monolingual sentences.
3155into cs text.
powerful pretrained models likembart (liu et al., 2020) have been used for code-mixed translation tasks in concurrent work (gau-tam et al., 2021).
we will further explore the useof synthetic text with such models as part of futurework..3 our approach.
figure 1 shows the overall architecture of ourmodel.
this is largely motivated by prior work onunsupervised neural machine translation (lampleet al., 2018a,b).
the model comprises of three lay-ers of stacked transformer (vaswani et al., 2017)encoder and decoder layers,two of which areshared and the remaining layer is private to eachlanguage.
monolingual hindi (i.e.
the source lan-guage) has its own private encoder and decoderlayers (denoted by encp0 and decp0, respectively)while english and hindi-english cs text jointlymake use of the remaining private encoder and de-coder layers (denoted by encp1 and decp1, respec-tively).
in our model, the target language is eitherenglish or cs text.
ideally, we would like encp1and decp1 to be trained only using cs text.
how-ever, due to the paucity of cs text, we also use textin the embedded language (i.e.
english) to trainthese layers.
next, we outline the three main train-ing steps of tcs..(i) denoising autoencoding (dae).
we usemonolingual text in each language to estimate lan-guage models.
in lample et al.
(2018b), this isachieved via denoising autoencoding where an au-toencoder is used to reconstruct a sentence given anoisy version as its input whose structure is alteredby dropping and swapping words arbitrarily (lam-ple et al., 2018a).
the loss incurred in this step isdenoted by ldae and is composed of two termsbased on the reconstruction of the source and tar-get language sentences, respectively..(ii) backtranslation (bt): once the layers areinitialized, one can use non-parallel text in bothlanguages to generate a pseudo-parallel corpus ofbacktranslated pairs (sennrich et al., 2015).
thatis, a corpus of parallel text is constructed by trans-lating sentences in the source language via thepipeline, encp0, encsh, decsh and decp1, andtranslating target sentences back to the source lan-guage via encp1, encsh, decsh and decp0.
thebacktranslation loss lbt is composed of cross-entropy losses from using these pseudo-parallel.
figure 1: model architecture.
each loss term along withall the network components it modifies are shown.
duringunsupervised training with non-parallel text, ldae and lbtare optimized while for supervised training with parallel text,ldae and lce are optimized..sentences in both directions..(iii) cross-entropy loss (ce): both the previ-ous steps used unsupervised training objectivesand make use of non-parallel text.
with access toparallel text, one can use the standard supervisedcross-entropy loss (denoted by lce) to train thetranslation models (i.e.
going from encp0 to decp1and encp1 to decp0 via the common shared layers)..3.1 synthetic cs text.
apart from the use of parallel text and monolin-gual text employed in training tcs, we also con-struct large volumes of synthetic cs text using twosimple techniques.
this synthetic cs text is non-parallel and is used to optimize both ldae andlbt .
the role of the synthetic cs text is to exposetcs to various cs patterns (even if noisy), therebyencouraging the model to code-switch.
the finalstep of finetuning using all-cs enables model tomimic switching patterns of real cs texts.
the first technique (named lex) is a simpleheuristic-based technique that constructs a cs sen-tence by traversing a hindi sentence and randomlyreplacing a word by its english translation usinga bilingual lexicon (conneau et al., 2017).
theprobability of replacing a word is chosen to matchthe switching distribution in real cs text.
thesecond technique (named emt) is more linguisti-cally aware.
following the methodology proposedby bhat et al.
(2016) that is based on the embedded.
3156encp0<latexit sha1_base64="qe5fc3z9zymvnrv25zesnbk6vwm=">aaab+3icbvdlssnafl3xweur1qwbwsk4kkkvdfkuwwuf+4a2hml00g6dsclmrcwhv+lghsju/rf3/o2tmiw2hhg4nhmvc+7xy86utu0va2v1bx1js7jv3d7z3duvhdr7kkokov0s8ugofkwozyhtaqy5hcssyufz2vdn17nff6bsssi81/oyugjpqhywgrwrvfp9jlcesphehctz0tizm6/wsjt2abrmnji0oethq32oxhfjba014vipowph2k2x1ixwmlvhiaixjjm8oundqyyoctmie4zojdjgqstnczuq1n8bkrzkzyvvjvokathlxf+8yakdszdlyzxoam4rpgosjnse8ilqmelknj8bgolkjisiuywx0aauqinbwtx5mfratees2bo7b7svyjoqcathcaooxeabbqedxsdwce/waq9wzj1bb9b7z+ikve4cwh9yh99n+jss</latexit>encsh<latexit sha1_base64="2clzrthuus4gm27vrwba0tggjja=">aaab+nicbvdlssnafj3uv62vvjdubovgqirv0gvrbjcv7apaecbtstt0zhjmjkqj+rq3lhrx65e482+cxcy09cda4zx7mxnpedoqton8wzwv1bx1jepmbwt7z3fpru/3vjritlo4ypecbegrrgxpaqozgcssib4w0g9mv7nfvyds0ujc6xlmpi4mgoyui20k366ponjtydnrgtm/vdpmtxto0ykal4lbkgyo0fhtz9e4wgknqmoglbq6tqy9felnmsnzbzqoeim8qxmynfqgtpsxftezegyumqwjaz7qsfb/b6sikzxngznmg6pflxf/84ajdi+8lio40cscvnwujgzqcoy9wdgvbgs2nwrhsu1wikdiiqxnwzvtgrt48jlptzruabn1e9zox5z1vmehoainwaxnoa1uqad0aqyp4am8gffr0xq23qz3n9gkve4cgd+wpr4bbyiufg==</latexit>decsh<latexit sha1_base64="5yqchazeq2t4ytt0kwqxffwwfba=">aaab+nicbvdlssnafl3xwesr1awbwsk4kkkvdfnuhcsk9gftcjpppb06k4szivjip8wnc0xc+ixu/bsnbrbaemdgcm693dmnsdht2ng+rzxvtfwnzdjwextnd2/frhy0vzxkqlsk5rhsblhrzila0kxz2k0kxslgtbomr3o/80clynf0rycj9qqerixkbgsj+xall7aeszhdudl1mzwa+nbvqtkzogxifqqkbzq+/dufxcqvnnkey6v6rpnol8nsm8lptnxpfu0wgemh7rkayugvl82it9gjuqyojkv5kuyz9fdghovsexgyytyowvry8t+vl+rw0stylksarmr+kew50jhke0adjinrfgiijpkzriimsmrem7bkpgr38cvlpf2vuwe1+t15txfv1fgcizigu3dhahpwc01oayfheizxeloerbfr3fqyj65yxc4h/ih1+qp2cpr0</latexit>lce:encp0encshdecshdecp1;encp1encshdecshdecp0<latexit sha1_base64="jhovl8mvhoxmqnntczyc3i/on/u=">aaacphicnvhlsgmxfm2m7/qqunqtlyqrmqocohtriy66anfqoa1djr21wcyd5i5yhvky/8kdf2m6fts2ky8edufce3iffiyfrsf5toyz2bn5hcwlwvlk6tp6cwpzquej4tdgkyxu02capaihgqilngmflpalppovv0p98rwuflf4j4myogf7dkvpciag8orv7ybhnzozvjmvvapkbyq3tm9ornnfbwkl5eakpwec0v0f5hqmm7hngir3ppscgtvcuk/7p18n84olp+zkqsebowilmoqav/xodyoebbail0zrluve2emzqselziv2oifm/iu9q8vakawgo2m+5izugazle5eyl0sas78ruhzopqh8kznsvi9rq3ka1kqwd9pjrrgncgb+/kneiilgdhgx2hukomqbaywryxqlvm8u42juwjblcmdhngqph2x3qhxypy5dxi7wsui2ys45ic45irfkltrig3brx7qxalbd3rer9p3d+e61rvhnfvkt9tmxzpptyg==</latexit>lbt:encp1encshdecshdecp0;encp0encshdecshdecp1<latexit sha1_base64="ogvgjyh7eufegnvsw5xkarpkpta=">aaacphicnvhjsgnbeo0z97hfpxppdyqnmkocohdxqq85jghmiildt6dignswumvemmyx+rfe/bs7y0bncrkg4ffe1eta/fgkjy7zadkzs3pzc4tlhewv1bx14sbmo44sxahoixmpps80sbfchqvkamykwoblapgvv0o98qpkiyh8weemnya9h6inoendecx3dscwz5lmk5mxxj5kbyq3tm9ornnfbelnyi0ue+44pfs/zdvmz2lpmvtusek5nbafcv/nf75u5hvlttnjg04cdwrkzbrvr/jr7ky8csbelpnwldejszmyhyjlyartrepm+at7hpabiqtad9j8yrndm0yx9ijlxog0z39xpczqehd4jnpyqr7xhuq0rzvg77stijboemz8+ue9rfkm6pbitcsucjqdaxhxwvrkez8pxthctwcw4i6ppaked8vuufmwdly6ubyty5fsk11yqfxyqi7ihamsouhwjnvrva2avw9x7hu7/p1qw6oalfin7kcv7tltca==</latexit>encp1<latexit sha1_base64="ga5koi/fkjtrlss2eaq6epqabjy=">aaab+3icbvdlssnafl3xweur1qwbwsk4kkkvdfkuwwuf+4a2hml00g6dsclmrcwhv+lghsju/rf3/o2tmiw2hhg4nhmvc+7xy86utu0va2v1bx1js7jv3d7z3duvhdr7kkokov0s8ugofkwozyhtaqy5hcssyufz2vdn17nff6bsssi81/oyugjpqhywgrwrvfp9jlcesphehctz0thzmq/wsjt2abrmnji0oethq32oxhfjba014vipowph2k2x1ixwmlvhiaixjjm8oundqyyoctmie4zojdjgqstnczuq1n8bkrzkzyvvjvokathlxf+8yakdszdlyzxoam4rpgosjnse8ilqmelknj8bgolkjisiuywx0aauqinbwtx5mfratees2bo7b7svyjoqcathcaooxeabbqedxsdwce/waq9wzj1bb9b7z+ikve4cwh9yh99pfzst</latexit>decp0<latexit sha1_base64="ubcar71z26araqjr/yum5mkw+cw=">aaab+3icbvdlssnafl2pr1pfss7ddbbbvumqomuillxwsa9oq5hmp+3qmstmtmqs8ituxcji1h9x5984abpq1gmdh3pu5z45qcyz0o7zbzxw1jc2t8rblz3dvf0d+7dauveicw2tieeyf2bfoqtpwzpnas+wfiua024wvcn97iovikxhg57f1bn4hliri1gbybera4h1rir0lplmt2pfyxy75tsdodaqcqtsgwit3/4adcoscbpqwrfsfdejtzdiqrnhnksmekvjtkz4tpughlhq5axz7bk6ncoqjsjpxqjrxp29kwkh1ewezjjpqpa9xpzp6yd6dowlliwttuoyodrkoniryotaqyyp0xxmccasmayitlderju6kqyed/nlq6ttqlvn9cb9ra15xdrrhmm4gtnw4rkacactaaobj3igv3izmuvferc+fqmlq9g5gj+wpn8awh+uog==</latexit>decp1<latexit sha1_base64="39okxs3psyaezlatbnzdatmahlm=">aaab+3icbvdlssnafl2pr1pfss7ddbbbvumqomuillxwsa9oq5hmp+3qmstmtmqs8ituxcji1h9x5984abpq1gmdh3pu5z45qcyz0o7zbzxw1jc2t8rblz3dvf0d+7dauveicw2tieeyf2bfoqtpwzpnas+wfiua024wvcn97iovikxhg57f1bn4hliri1gbybera4h1rir0lplmt2pfzxy75tsdodaqcqtsgwit3/4adcoscbpqwrfsfdejtzdiqrnhnksmekvjtkz4tpughlhq5axz7bk6ncoqjsjpxqjrxp29kwkh1ewezjjpqpa9xpzp6yd6dowlliwttuoyodrkoniryotaqyyp0xxmccasmayitlderju6kqyed/nlq6ttqlvn9cb9ra15xdrrhmm4gtnw4rkacactaaobj3igv3izmuvferc+fqmlq9g5gj+wpn8awgsuow==</latexit>hihien/csen/csldae:encp0encshdecshdecp0;encp1encshdecshdecp1<latexit sha1_base64="7brf3mozryimvtts4mdcqncuzpi=">aaacpxicnvhlsgmxfm2mr1pfvzdugkv0vwzuuhrttyilbsttfdoyznlbnjtzilkjlmh+zk9w59+yjgw1uvjc4hdovsf34cdsahscd8uem19yxcosf1dw19y3sptblr0likotrzjstz7tieuitrqo4slwwajfwqm/uproj8+gtijcbo5j6azseiq+4awn5zveowhdiwcyvc28thzxnxuqxja9oxnnjrwk1ye3wuw5s5qefje1+jv5lms9kt2nxry46+v+z9fnvflzqth50n/anyiymca9v3rr9ckebbail0zrtuve2e2zqselzmvooifmfmqg0dywzahobppvoan7hunrfqtmc5hm7peklavajwpfze461bpahpxlayfyp+2miowtbdn//le/krqjojkz7qkfhoxyamavml1spmskctshlzolulmj/watw4p7vdmsh5erl9n1fmgo2suhxcunpepuyd1pem7twjdw3xqw9+07u2g3plnta1qztx6e7x0aivvtrg==</latexit>matrix theory (emt) for code-switching, we applyclause substitution methods to monolingual text toconstruct synthetic cs text.
from inspecting en-glish parse trees, we found that replacing embed-ded sentence clauses or subordinate clauses withtheir hindi translations would likely produce cstext that appears somewhat natural..4 description of datasets.
4.1 a new hindi-english cs dataset.
we introduce a new hindi-english cs dataset,that we will refer to as all-cs.
it is partitionedinto two subsets, movie-cs and treebank-cs,based on their respective sources.
movie-cs con-sists of conversational hindi-english cs text ex-tracted from 30 contemporary bollywood scriptsthat were publicly available.3 the hindi wordsin these sentences were all romanized with po-tentially multiple non-canonical forms existingfor the same hindi token.
we employed a pro-fessional annotation company to convert the ro-manized hindi words into their respective back-transliterated forms rendered in devanagari script.
we also asked the annotators to provide mono-lingual hindi translations for all these sentences.
using these monolingual hindi sentences as astarting point, we additionally crowdsourced forcs sentences via amazon’s mechanical turk(mturk) (amazon, 2005).
table 1 shows twohindi sentences from movie-cs and treebank-cs,along with the different variants of cs sentences.
turkers were asked to convert a monolingualhindi sentence into a natural-sounding cs variantthat was semantically identical.
each turker hadto work on five hindi sentences.
we developeda web interface using which turkers could easilycopy parts of the hindi sentence they wanted toretain and splice in english segments.
more de-tails about this interface, the crowdsourcing taskand worker statistics are available in appendix a.all-cs comprises a second subset of cs sen-tences, treebank-cs, that was crowdsourcing us-ing mturk.
we extracted 5292 monolingual hindisentences (with sentence lengths less than or equalto 15 words) from the publicly available hindidependency treebank that contains dependencyparses.4 these annotations parse each hindi sen-tence into chunks, where a chunk is defined as.
3https://www.filmcompanion.in/category/fc-pro/scripts/.
https://moifightclub.com/category/scripts/.
4http://ltrc.iiit.ac.in/treebank_h2014/.
movie-cs(eng)(gold)mturkmturkmturk.
पर हँसी िच(cid:465)कत्सा ने मेरा जीवन बदल (cid:465)दया वास्तव में(but laughter medicine really changed my life)but laughter therapy ने मेर(cid:547) life बदल द(cid:547) actuallyपर laughter therapy ने मेरा जीवन बदल (cid:465)दया वास्तव मेंbut laughter therapy ने really में मेर(cid:547) life change कर द(cid:547)पर हँसी therapy ने मेरा life बदल (cid:465)दया वास्तव में.
treebank-cs(eng)mturkmturk.
मेले से आमदनी 7.20 करोड़ रुपये आंक(cid:551) गई(income from the fair was estimated at rs 7.20 crore)fair से income 7.20 करोड़ रुपये evaluate क(cid:551) गईमेले से income 7.20 करोड़ रुपये आंक(cid:551) गई.
table 1: two all-cs examples.
english translations in blue..figure 2: distribution across overall sentence lengths anddistribution across lengths of continuous english spans inmovie-cs and treebank-cs..a minimal, non recursive phrase.
turkers wereasked to convert at least one hindi chunk intoenglish.
this was done in an attempt to elicitlonger spans of english segments within each sen-tence.
figure 2 shows the sentence length distribu-tions for movie-cs and treebank-cs, along withhistograms accumulating english segments of dif-ferent lengths in both subsets.
we clearly see alarger fraction of english segments with lengthswithin the range [2-6] in treebank-cs comparedto movie-cs..table 2 provides detailed statistics of the newcs dataset.
we also report two metrics proposedby guzmán et al.
(2017) to measure the amount ofcode-switching present in this new corpus.
mono-lingual index (m-index) is a value between 0 and 1.quantity/metric.
movie-cs.
treebank-cs.
all-cs.
|train||test||valid|# tokens# hindi sentences# nesfraction of nesm-indexi-index.
155091500500196300929043420.02210.55420.2852.
5914100050087979529248100.05470.63110.3434.
21423250010002842791458291520.03220.57740.3023.table 2: key statistics of cs datasets..3157that quantifies the amount of mixing between lan-guages (0 denotes a purely monolingual corpus and1 denotes equal mixing from both languages) andi-index measures the fraction of switching pointsin the corpus.
we observe treebank-cs exhibitshigher m-index and i-index values compared tomovie-cs indicating more code-switching over-all.
all-cs also contains a non-trivial number ofnamed entities (nes) which are replaced by an netag in all our language modeling experiments..4.2 other datasets.
parallel hindi-english text.
as described insection 5, tcs uses parallel text for supervisedtraining.
for this purpose, we use the iit bombayenglish-hindi corpus (kunchukuttan et al., 2017)containing parallel hindi-english text.
we alsoconstruct a larger parallel corpus using text fromthe opensubtitles (opsub) corpus (lison andtiedemann, 2016) thatis more conversationaland hence more similar in style to movie-cs.
wechose ~1 million english sentences (opsub-en),where each sentence contained an embeddedclause or a subordinate clause to supporttheconstruction of emt lines.
we used the googletranslate api to obtain hinditranslations forall these sentences (opsub-hi).
henceforth, weuse opsub to refer to this parallel corpus ofopsub-en paired with opsub-hi.
we extracted318k sentences from the iitb corpus after thresh-olding on length (5-15) and considering overlapin vocabulary with opsub.
(one could avoid theuse of an external service like google translateand use existing parallel text (zhang et al., 2020))in conjunction with a word aligner to constructemt lines.
opsub, being more conversational instyle, turns out to be a better pretraining corpus.
adetailed comparison of these choices is describedin appendix h.).
synthetic cs datasets.
as mentioned in sec-tion 3.1, we use two simple techniques lex andemt to generate synthetic cs text, which in turnis used to train tcs in an unsupervised trainingfor each hindi monolingual sentencephase.
in opsub, we generate two lex and two emtsynthetic cs sentences giving us opsub-lex andopsub-emt, respectively.
we also generate fivelex and five emt lines for each monolingualsentence in all-cs.
in order to generate emtlines, we first translate the monolingual hindi.
sentences in all-cs to english using googletranslate and then follow the emt generationscheme.
this results in two datasets, all-cs-lexand all-cs-emt, which appear in later evalua-(appendix b contains more details abouttions.
emt applied to opus and all-cs.).
from existing approaches..datasets(i)vacs (samanta et al., 2019) is a hierarchi-cal variational autoencoder-based model designedto generate cs text.
we train two vacs mod-els, one on all-cs (vacsv1) and the other onopsub-emt followed by all-cs (vacsv2).
(ii)garg et al.
(2018a) use seqgan (yu et al., 2017)– a gan-based sequence generation model – togenerate cs sentences by providing an rnnlmas the generator.
as with vacs, we train twoseqgan5 models, one on all-cs (seqganv1)and one on opsub-emt followed by all-cssamples are drawn from both(seqganv2).
seqgan and vacs by first drawing a randomsample from the standard normal distributionin the learned latent space and then decodingvia an rnn-based generator for seqgan and avae-based decoder for vacs.
we sample ~2mlines for each dataset to match the size of the othersynthetic datasets..5 experiments and results.
first, we investigate various training curricula totrain tcs and identify the best training strategy byevaluating bleu scores on the test set of all-cs(§5.1).
next, we compare the output from tcswith synthetic cs text generated by other meth-ods (§5.2).
we approach this via language model-ing (§5.2.1), human evaluations (§5.2.2) and twodownstream tasks—natural language inferenceand sentiment analysis—involving real cs text(§5.2.3).
apart from these tasks, we also presentfour different objective evaluation metrics to eval-uate synthetic cs text: bertscore, accuracy ofa bert-based classifier and two diversity scores(§5.3)..5.1 improving quality of tcs outputs.
table 3 shows the importance of various trainingcurricula in training tcs; these models are eval-uated using bleu (papineni et al., 2002) scorescomputed with the ground-truth cs sentences for.
5https://github.com/suragnair/seqgan.
3158curriculum.
o all-csa iitb + opsuba | all-csb.c1 c | all-csc2 c | all-cs.
d1 d | all-csd2 d | all-cs.
c a | opsub-hi + opsub-lexd a | opsub-hi + opsub-emt.
training.
bleu(hi (cid:0) cs).
s.ss.uu.us.us.19.18.
1.5127.84.
15.2317.73.
32.7139.53.
35.5243.15.table 3: bleu score on (hi (cid:0) cs) for different curriculameasured on all-cs (test).
the first column gives names toeach training curriculum.
a | x represents starting with modeldenoted by a and further training using dataset(s) x.
“s” and“u” refer to supervised and unsupervised training phases, re-spectively..the test set of all-cs.
we start with supervised pre-training of tcs using the two parallel datasets wehave in hand – iitb and opsub (system a).
ais then further finetuned with real cs text in all-cs.
the improvements in bleu scores movingfrom system o (trained only on all-cs) to systemb illustrate the benefits of pretraining tcs usinghindi-english parallel text..systems c and d in table 3 use our syntheticcs datasets opsub-lex and opsub-emt, respec-tively.
these systems are further finetuned on all-cs using both unsupervised and supervised train-ing objectives to give c1, c2, d1 and d2, respec-tively.
comparing these four systems with systemb shows the importance of using synthetic cs forpretraining.
further, comparing c1 against d1 and.
figure 3: variation of bleu score with amount of all-csparallel training data..c2 against d2, we observe that opsub-emt is in-deed a better choice for pretraining compared toopsub-lex.
also, supervised finetuning with all-cs is clearly superior to unsupervised finetuning.
henceforth, systems d1 and d2 will be referred toas tcs (u) and tcs (s), respectively..while having access to parallel cs data is an ad-vantage, we argue that the benefits of having par-allel data only marginally increase after a thresh-old.
figure 3 shows how bleu scores vary whenchanging the amount of parallel cs text used totrain d2.
we observe that bleu increases substan-tially when we increase cs data from 1000 lines to5000 lines, after which there is a trend of diminish-ing returns.
we also find that d1 (that uses thedata in all-cs as non-parallel text) is as good asthe model trained using 4000 lines of parallel text..5.2 comparing tcs with other synthetic cs.
5.2.1 language modeling.
we use text generated by our model to train alanguage model (lm) and evaluate perplexitieson the test set of all-cs to show how closelysentences from tcs mimic real cs text.
we usea state-of-the-art rnnlm model awd-lstm-lm merity et al.
(2018) as a blackbox lm andonly experiment with different training datasets.
the model uses three lstm layers of 1200 hid-den units with weight tying and 300-dimensionalword embeddings.
in initial runs, we trained ourlanguage model on the large parallel/syntheticcs datasets and finetuned on the all-cs data.
however, this training strategy was prone to over-fitting on all-cs data.
to counter this problemof forgetting during the pretrain-finetuning steps,we adopted the mix-review strategy proposedby he et al.
(2021).
the training sentences fromall-cs remain constant through the epochs andthe amount of pretraining data is exponentiallydecayed with each epoch.
this greatly alleviatesthe forgetting problem in our model, and leadsto better overall perplexities.
additional detailsabout these lms are provided in appendix e..table 4 shows test perplexities using differenttraining curricula and data generated using twoprior approaches, vacs and seqgan.
sentencesgenerated using tcs yield the largest reductions intest perplexities, compared to all other approaches..3159pretraining corpus.
| train |.
test pplopsub.
test pplall-cs.
opsub + opsub-lexopsub + opsub-emt.
opsub + vacsv1opsub + vacsv2opsub + seqganv1opsub + seqganv2.
opsub + tcs (u)opsub + tcs (s).
4.00m4.03m.
4.05m4.05m4.03m4.03m.
3.99m3.96m.
56.8355.56.
64.7762.4157.3256.50.
57.4556.28.
332.66276.56.
335.79321.12336.62317.81.
271.19254.37.table 4: test perplexities on all-cs using different pretrain-ing datasets..5.2.2 human evaluation.
we evaluated the quality of sentences generated bytcs using a human evaluation study.
we sampled150 sentences each, using both tcs (u) and tcs(s), starting from monolingual hindi sentences inthe evaluation sets of all-cs.
the sentences werechosen such that they were consistent with thelength distribution of all-cs.
for the sake of com-parison, corresponding to the above-mentioned150 monolingual hindi samples, we also chose150 cs sentences each from all-cs-lex and all-cs-emt.
along with the ground-truth cs sen-tences from all-cs, this resulted in a total of 750sentences.6 these sentences were given to threelinguistic experts in hindi and they were askedto provide scores ranging between 1 and 5 (1 forworst, 5 for best) under three heads: “syntacticcorrectness”, “semantic correctness” and “natu-ralness”.
table 5 shows that the sentences gener-ated using tcs (s) and tcs (u) are far superiorto the emt and lex sentences on all three crite-ria.
tcs (s) is quite close in overall quality to thereal sentences and tcs (u) fares worse, but onlyby a small margin..table 6 shows some illustrative examples ofcode-switching using tcs (u) on test samples.
we also show some examples of code-switching.
6we only chose cs sentences from tcs that did not ex-.
actly match the ground-truth cs text..method.
syntactic.
semantic naturalness.
realtcs (s)tcs (u)emtlex.
4.47±0.734.21±0.924.06±1.063.57±1.092.91±1.11.
4.47±0.764.14±0.994.01±1.123.48±1.142.87±1.19.
4.27±1.063.77±1.333.58±1.462.80±1.441.89±1.14.
table 5: mean and standard deviation of scores (between 1and 5) from 3 annotators for 150 samples from 5 datasets..generated using moviecs.
मैं खुश हूँ तुमने नो(cid:465)टस (cid:465)कया(i am glad you noticed)i am happy तुमने notice (cid:465)कया.
नह(cid:547)ं मैं तुमसे बहुत प्यार करता हू(no i really love you but just like a friend)नह(cid:547)ं i love you very much सच में but िसफर् एक friend क(cid:551) तरह.
ँ सच में ले(cid:465)कन िसफर् एक दोस्त क(cid:551) तरह.
generated using treebankcs.
बैठक अगले हफ़्ते होने क(cid:551) संभावना है(meeting will likely be next week)meeting next week होने क(cid:551) possibility है.
उन्होंने कहा (cid:465)क इनका नाम लेना उिचत नह(cid:547)ं होगा ले(cid:465)कन यह स्प(cid:436) है(he said that it would not be appropriate to name thembut it is clear)उन्होंने कहा (cid:465)क इनका नाम लेना fair नह(cid:547)ं होगा but it is clear.
generated using opsub.
आपको अपने भीतर उन भावनाओं को संसािधत करने केसमय देना होगा(you have to give yourself time to process those feelingswithin you)आपको अपने भीतर उन emotions को process करने केtime देना होगा.
िलए खुद को.
िलए खुद को.
क्यों(cid:465)क मुझे पता है (cid:465)क मुख्य पकवान क्या होगा(because i know what the main dish will be)because i know main dish क्या होगा.
table 6: examples generated by tcs (u) on validation andtest data.
for each example the first line is the monolingualsentence, followed by its english translation and finally thetranslation from tcs (u).
more examples are in appendix f..within monolingual sentences from opsub.
weobserve that the model is able to introduce longcontiguous spans of english words (e.g.
“meetingnext week”, “but it is clear”, etc.).
the model alsodisplays the ability to meaningfully switch multi-ple times within the same sentence (e.g., “i loveyou very much”, “but”, “friend”).
there are alsointeresting cases of english segments that appearto be ungrammatical but make sense in the cs con-text (e.g., “because i know main dish”, etc.)..
5.2.3 gluecos benchmark.
gluecos (khanuja et al., 2020) is an evaluationbenchmark spanning six natural language tasks forcode-switched english-hindi and english-spanishdata.
the authors observe that m-bert (pireset al., 2019) consistently outperforms cross-lingualembedding techniques.
furthermore, pretrainingm-bert on small amounts of code-switched textimproves its performance in most cases.
for ourevaluation, we select two tasks that require seman-tic understanding: natural language inference(nli) and sentiment analysis (sa)..we sample 100k monolingual sentences from.
3160pretraining data nli (accuracy).
baselineopsub-hiopsub-lexopsub-emttcs (s)all-cs.
57.88±1.2258.47±0.3658.67±0.9458.96±0.7059.57±0.5759.74±0.96.
sentimentanalysis (f1).
57.97±0.0658.13±0.2558.40±0.3358.79±0.3759.39±0.8158.77±0.44.
table 7: gluecos evaluation: mean and standard devia-tion of scores after evaluating on 5 seeds.
baseline denotesthe m-bert model without any mlm pretraining..opsub-hi and select corresponding lex, emtand tcs (s) sentences.
m-bert is then trainedusing the masked language modelling (mlm)objective on text from all 4 systems (includingopsub-hi) for 2 epochs.
we also train m-berton 21k sentences from all-cs (real cs).
finally,these pretrained models are fine-tuned on the se-lected gluecos tasks.
(more details are in ap-pendix g.).
table 7 lists the accuracies and f1 scores us-ing different pretraining schemes for both nli andsentiment analysis, respectively.
plain monolin-gual pretraining by itself leads to performance im-provements on both tasks, presumably due to do-main similarity between gluecos (movie scripts,social media etc.)
and opsub.
as mentionedin khanuja et al.
(2020), pretraining on cs text fur-ther improves performance for both nli and sa.
among the synthetic methods, tcs (s) has consis-tently better scores than lex and emt.
for sa,tcs (s) even outperforms pretraining on real cstext from all-cs..each token in the reference sentence, using con-textual bert embeddings (devlin et al., 2018) ofthe tokens.
we use this as an additional objec-tive metric to evaluate the quality of the sentencesgenerated using tcs.
we use the real monolin-gual sentence as the reference and the generatedcs sentence as the candidate, excluding sentencesfrom tcs (s) and tcs (u) that exactly match thereal sentence.
since our data is hindi-english cstext, we use multilingual bert (m-bert) (pireset al., 2019) for high-quality multilingual represen-tations..table 8 outlines our main results on the testset of all-cs.
tcs sometimes generates purelymonolingual sentences.
this might unfairly tiltthe scores in favour of tcs since the referencesentences are also monolingual.
to discount forsuch biases, we remove sentences generated bytcs (u) and tcs (s) that are purely monolingual(row label “mono” in bertscore).
sentenceshaving <unk> tokens (labeled “unk”) are alsofiltered out since these tokens are only generatedby tcs for out-of-vocabulary words.
“unk &mono” refers to applying both these filters..emt lines consistently show the worst perfor-mance, which is primarily due to the somewhatpoor quality of translations involved in generat-ing these lines (refer to appendix b).
with remov-ing both monolingual and <unk> tokens, we ob-serve that tcs (u) and tcs (s) yield the highestbertscores, even outperforming the bertscoreon real data obtained from the turkers..5.3 other objective evaluation metrics.
bertscore.
bertscore (zhang* et al., 2020)is a recently-proposed evaluation metric for textgeneration.
similarity scores are computed be-tween each token in the candidate sentence and.
bert-based classifier.
in this evaluation, weuse m-bert (pires et al., 2019) to build a classi-fier that distinguishes real cs sentences from syn-thetically generated ones (fake).
when subject toexamples from high-quality generators, the classi-fier should find it hard to tell apart real from fake.
evaluation metric.
tcs (s).
tcs (u).
bertscore.
bert-based classifier.
diversity.
all (3500)mono (3434)unk (1983)unk & mono (1857).
|sentences|accuracy(fake).
gzip (d)self-bleu.
real.
0.8120.8120.8090.808.
476742.76.
22.1361.3.lex.
0.7960.7820.8040.785.
1239396.52.
24.1229.7.emt.
0.6270.6230.6360.633.
1248497.83.
33.1724.6.
0.7640.7550.8270.813.
1247580.31.
21.3763.6.
0.7880.7720.8460.821.
1247588.62.
17.5964.2.table 8: (a) bertscores on test split of all-cs.
each row corresponds to a different data filter.
the numbers in parenthesisdenote the number of sentences in the data after filtering.
(b) accuracies from the classifier for samples generated by variousmethods as being fake.
the |sentences| refer to size of dataset for each system.
tcs models have the lowest accuracy amongsynthetic methods.
(c) diversity scores for different techniques using gzip and self-bleu based diversity measures..3161samples.
we add a fully connected layer over them-bert base architecture that takes the [cls] to-ken as its input to predict the probability of the sen-tence being real or fake.
fake sentences are drawnfrom the union of tcs (u), tcs (s), all-cs-lexand all-cs-emt.
in order to alleviate the class im-balance problem, we oversample the real sentencesby a factor of 5 and shuffle the data.
the modelconverges after training for 5 epochs.
we see in ta-ble 8 that the classification accuracy of whether asample is fake or not is lowest for the outputs fromtcs among the different generation techniques..measuring diversity.
we are interested in find-ing out how diverse the predictions from tcs are.
we propose a simple measure of diversity in the csvariants that is based on how effectively sentencescan be compressed using the gzip utility.7 we con-sidered using byte pair encoding (bpe) (gage,1994) as a measure of data compression.
how-ever, bpe operates at the level of individual words.
two word sequences “w1 w2 w3” and “w3 w2w1” would be identically compressed by a bpe to-kenizer.
we would ideally like to account for suchdiversity and not discard this information.
gzipuses lempel-ziv coding (ziv and lempel, 1977)that considers substrings of characters during com-pression, thus allowing for diversity in word order-ing to be captured..our diversity measure d is simply the follow-ing: for a given set of cs sentences, run gzip oneach sentence individually and sum the resultingfile sizes (s1).
next, paste all the cs sentences intoa single file and run gzip on it to get a file of sizes2.
then, d = s1 − s2.
smaller d scores indicatelarger diversity.
if the variants of a sentence aredissimilar to one another and hence very diverse,then s2 would be large thus leading to smaller val-ues of d. table 8 shows the diversity scores fordifferent techniques.
both tcs (s) and tcs (u)have a higher diversity score compared to lexand emt.
tcs (u) exceeds even the responses re-ceived via mturk (real) in diversity.
we note herethat diversity, by itself, is not necessarily a desir-able trait.
our goal is to generate sentences that arediverse while being natural and semantically mean-ingful.
the latter properties for text from tcs (s)and tcs (u) have already been verified in our hu-man evaluation study..zhu et al.
(2018) propose self-bleu score as ametric to evaluate the diversity of generated data..7http://www.gzip.org/.
however, using self-bleu is slightly problematicin our setting as systems like lex that switchwords at random positions would result in lowself-bleu (indicating high diversity).
this is in-deed the case, as shown in table 8 - lex, emtgive lower self-bleu scores as compared to tcs.
however, note that the scores of the tcs modelsare comparable to that of real cs data..6 conclusions.
in this work, we present a neural translation modelfor cs text that transduces monolingual hindi sen-tences into realistic hindi-english cs text.
textgenerated by our model is evaluated using a num-ber of different objective metrics, along with lm,nli and sentiment analysis tasks, and a detailedhuman evaluation study.
the role of synthetic datain training such models merits a more detailed in-vestigation which we leave for future work..7 acknowledgements.
we thank all the anonymous reviewers for theirconstructive feedback which helped improve thepresentation of this work.
we also thank all thevolunteers who helped with the collection of cstext that is released as part of our dataset, all-cs..references.
heike adel, ngoc thang vu, katrin kirchhoff, do-minic telaar, and tanja schultz.
2015. syntacticand semantic features for code-switching factoredlanguage models.
ieee/acm transactions on audio,speech, and language processing, 23(3):431–440..heike adel, ngoc thang vu, franziska kraus, timschlippe, haizhou li, and tanja schultz.
2013. re-current neural network language modeling for codeswitching conversational speech.
in 2013 ieee in-ternational conference on acoustics, speech andsignal processing, pages 8411–8415.
ieee..amazon.
2005. amazon mechanical turk website.
vis-.
ited on 2020-01-02..gayatri bhat, monojit choudhury, and kalika bali.
2016. grammatical constraints on intra-sententialcode-switching:from theories to working models.
arxiv:1612.04538..ching-ting chang, shun-po chuang, and hung-yilee.
2019. code-switching sentence generationby generative adversarial networks and its appli-cation to data augmentation.
in proc.
interspeech2019, pages 554–558..3162alexis conneau, guillaume lample, marc’aurelioranzato, ludovic denoyer, and hervé jégou.
2017.arxivword translation without parallel data.
preprint arxiv:1710.04087..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training ofdeep bidirectional transformers for language under-standing.
corr, abs/1810.04805..mrinal dhar, vaibhav kumar, and manish shrivas-tava.
2018. enabling code-mixed translation: paral-lel corpus creation and mt augmentation approach.
in proceedings of the first workshop on linguisticresources for natural language processing, pages131–140, santa fe, new mexico, usa.
associationfor computational linguistics..philip gage.
1994. a new algorithm for data compres-.
sion.
c users j., 12(2):23–38..yingying gao, junlan feng, ying liu, leijing hou,xin pan, and yong ma.
2019. code-switching sen-tence generation by bert and generative adversarialnetworks.
in interspeech, pages 3525–3529..saurabh garg, tanmay parekh, and preethi jyothi.
2018a.
code-switched language models using dualrnns and same-source pretraining.
in proceedingsof the 2018 conference on empirical methods in nat-ural language processing, pages 3078–3083, brus-sels, belgium.
association for computational lin-guistics..saurabh garg, tanmay parekh, and preethi jyothi.
2018b.
dual language models for code switchedproceedings of interspeech,speech recognition.
pages 2598–2602..devansh gautam, prashant kodali, kshitij gupta, an-mol goel, manish shrivastava, and ponnurangamkumaraguru.
2021. comet: towards code-mixedtranslation using parallel monolingual sentences.
inproceedings of the fifth workshop on computa-tional approaches to linguistic code-switching,pages 47–55..abhirut gupta, aditya vavre, and sunita sarawagi.
2021. training data augmentation for code-mixedtranslation.
in proceedings of the 2021 conferenceof the north american chapter of the association forcomputational linguistics: human language tech-nologies, pages 5760–5766..gualberto a. guzmán, joseph ricard, jacqueline seri-gos, barbara e. bullock, and almeida jacquelinetoribio.
2017. metrics for modeling code-switchingacross corpora.
in interspeech..kotaro hara, abigail adams, kristy milland, saiphsavage, chris callison-burch,and jeffrey p.bigham.
2018. a data-driven analysis of workers’earnings on amazon mechanical turk, page 1–14.
association for computing machinery, new york,ny, usa..tianxing he, jun liu, kyunghyun cho, myle ott, bingliu, james glass, and fuchun peng.
2021. analyz-ing the forgetting problem in pretrain-finetuning ofopen-domain dialogue response models.
in proceed-ings of the 16th conference of the european chap-ter of the association for computational linguistics:main volume, pages 1121–1133, online.
associa-tion for computational linguistics..masoud jalili sabet, philipp dufter, françois yvon,and hinrich schütze.
2020. simalign: high qual-ity word alignments without parallel training data us-ing static and contextualized embeddings.
in find-ings of the association for computational linguis-tics: emnlp 2020, pages 1627–1643, online.
asso-ciation for computational linguistics..simran khanuja, sandipan dandapat, anirudh srini-vasan, sunayana sitaram, and monojit choudhury.
2020. gluecos: an evaluation benchmark forcode-switched nlp.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 3575–3585, online.
associationfor computational linguistics..anoop kunchukuttan, pratik mehta, and pushpak bhat-tacharyya.
2017. the iit bombay english-hindi par-allel corpus.
corr, abs/1710.02855..guillaume lample, alexis conneau, ludovic denoyer,and marc’aurelio ranzato.
2018a.
unsupervisedmachine translation using monolingual corpora only.
in international conference on learning represen-tations..guillaume lample, myle ott, alexis conneau, lu-dovic denoyer, and marc’aurelio ranzato.
2018b.
phrase-based & neural unsupervised machine trans-in proceedings of the 2018 conference onlation.
empirical methods in natural language processing,pages 5039–5049, brussels, belgium.
associationfor computational linguistics..grandee lee and haizhou li.
2020. modeling code-switch languages using bilingual parallel corpus.
inproceedings of the 58th annual meeting of the as-sociation for computational linguistics, pages 860–870, online.
association for computational linguis-tics..ying li and pascale fung.
2013. improved mixed lan-guage speech recognition using asymmetric acousticmodel and language model with code-switch inver-in 2013 ieee international con-sion constraints.
ference on acoustics, speech and signal processing,pages 7368–7372.
ieee..ying li and pascale fung.
2014a..code switchlanguage modeling with functional head constraint.
2014 ieee international conference on acoustics,speech and signal processing (icassp), pages4913–4917..ying li and pascale fung.
2014b.
language modelingwith functional head constraint for code switching.
3163speech recognition.
in proceedings of the 2014 con-ference on empirical methods in natural languageprocessing (emnlp), pages 907–916, doha, qatar.
association for computational linguistics..pierre lison and jörg tiedemann.
2016. opensub-titles2016: extracting large parallel corpora frommovie and tv subtitles.
in lrec..yinhan liu, jiatao gu, naman goyal, xian li, sergeyedunov, marjan ghazvininejad, mike lewis, andluke zettlemoyer.
2020. multilingual denoising pre-training for neural machine translation.
transac-tions of the association for computational linguis-tics, 8:726–742..stephen merity, nitish shirish keskar, and richardsocher.
2018. regularizing and optimizing lstmin international conference onlanguage models.
learning representations..tomas mikolov, ilya sutskever, kai chen, greg cor-rado, and jeffrey dean.
2013. distributed represen-tations of words and phrases and their composition-ality.
corr, abs/1310.4546..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2002. bleu: a method for automatic eval-uation of machine translation.
in proceedings of the40th annual meeting on association for computa-tional linguistics, acl ’02, page 311–318, usa.
association for computational linguistics..telmo pires, eva schlinger, and dan garrette.
2019.in pro-how multilingual is multilingual bert?
ceedings of the 57th annual meeting of the asso-ciation for computational linguistics, pages 4996–5001, florence, italy.
association for computationallinguistics..shana poplack.
1979.
“sometimes i’ll start a sentencein spanish y termino en español”: toward a typologyof code-switching..adithya pratapa, gayatri bhat, monojit choudhury,sunayana sitaram, sandipan dandapat, and kalikabali.
2018. language modeling for code-mixing:the role of linguistic theory based synthetic data.
inproceedings of acl 2018. acl..mohd sanad zaki rizvi, anirudh srinivasan, t. ganu,m. choudhury, and sunayana sitaram.
2021. gcm:a toolkit for generating synthetic code-mixed text.
in eacl..bidisha samanta, sharmila reddy, hussain jagirdar,niloy ganguly, and soumen chakrabarti.
2019.a deep generative model for code switched text.
in proceedings of the twenty-eighth internationaljoint conference on artificial intelligence, ijcai-19, pages 5175–5181.
international joint confer-ences on artificial intelligence organization..david sankoff.
1998. a formal production-based ex-planation of the facts of code-switching.
bilingual-ism: language and cognition, 1(1):39–50..rico sennrich, barry haddow, and alexandra birch.
2015. improving neural machine translation modelswith monolingual data.
corr, abs/1511.06709..thamar solorio, shuguang chen, alan w. black,mona diab, sunayana sitaram, victor soto, andemre yilmaz, editors.
2021. proceedings of thefifth workshop on computational approaches tolinguistic code-switching.
association for compu-tational linguistics, online..jörg tiedemann.
2012. parallel data, tools and inter-in proceedings of the eighth in-faces in opus.
ternational conference on language resources andevaluation (lrec’12), pages 2214–2218, istanbul,turkey.
european language resources association(elra)..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
corr, abs/1706.03762..oriol vinyals, meire fortunato, and navdeep jaitly.
2015. pointer networks.
in advances in neural in-formation processing systems, pages 2692–2700..ngoc thang vu, dau-cheng lyu, jochen weiner, do-minic telaar, tim schlippe, fabian blaicher, eng-siong chng, tanja schultz, and haizhou li.
2012.a first speech recognition system for mandarin-english code-switch conversational speech.
in2012 ieee international conference on acoustics,speech and signal processing (icassp), pages4889–4892.
ieee..genta indra winata, andrea madotto, chien-shengwu, and pascale fung.
2018. learn to code-switch:data augmentation using copy mechanism on lan-guage modeling.
corr, abs/1810.10254..genta indra winata, andrea madotto, chien-shengwu, and pascale fung.
2019. code-switched lan-guage models using neural based synthetic data fromparallel sentences.
in conll..ching feng yeh, chao yu huang, liang che sun,and lin shan lee.
an integrated framework fortranscribing mandarin-english code-mixed lectureswith improved acoustic and language modeling.
in2010 7th international symposium on chinese spo-ken language processing, pages 214–219.
ieee..lantao yu, weinan zhang, jun wang, and yong yu.
2017. seqgan: sequence generative adversarial netsin thirty-first aaai confer-with policy gradient.
ence on artificial intelligence..biao zhang, philip williams, ivan titov, and rico sen-nrich.
2020. improving massively multilingual neu-ral machine translation and zero-shot translation.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 1628–1639, online.
association for computational lin-guistics..3164tianyi zhang*, varsha kishore*, felix wu*, kilian q.weinberger, and yoav artzi.
2020. bertscore: eval-in internationaluating text generation with bert.
conference on learning representations..yaoming zhu, sidi lu, lei zheng, jiaxian guo,weinan zhang, jun wang, and yong yu.
2018.texygen: a benchmarking platform for text gener-in the 41st international acm si-ation models.
gir conference on research development in in-formation retrieval, sigir ’18, page 1097–1100,new york, ny, usa.
association for computingmachinery..j. ziv and a. lempel.
1977. a universal algorithm forsequential data compression.
ieee transactions oninformation theory, 23(3):337–343..3165a mturk task details.
figure 4: a snapshot of the web interface used to collectmovie-cs and treebank-cs data via amazon mechanicalturk..figure 4 depicts the portal used to collect data us-ing amazon’s mechanical turk platform.
the col-lection was done in two rounds, first for movie-cs and then for treebank-cs.
with treebank-cs,the sentences were first divided into chunks andthe turkers were provided with a sentence groupedinto chunks as shown in figure 4. they were re-quired to switch at least one chunk in the sentenceentirely to english so as to ensure a longer span ofenglish words in the resulting cs sentence.
a sug-gestion box converted transliterated hindi wordsinto devanagari and also provided english sugges-tions to aid the workers in completing their task.
with movie-cs, since there were no chunk labelsassociated with the sentences, they were tokenizedinto words..on mturk, we selected workers with hit ap-proval rate of 90% and location restricted to coun-tries with significant hindi speakers - australia,bahrain, canada, india, kuwait, malaysia, mauri-tius, myanmar, nepal, netherlands, new zealand,oman, pakistan, qatar, saudi arabia, singapore,south africa, sri lanka, thailand, united arabemirates, united kingdom, united states of amer-ica.
it was clearly specified in the guidelines thatthe task must be attempted by native hindi speak-ers.
each response was manually checked beforeapproving.
turkers were paid $0.15 for workingon 5 sentences (roughly takes 3-4 minutes).
thisamounts to $2.25-$3/hr which is in the ballpark of.
a median hourly wage on mturk of ~$2/hr (haraet al., 2018)..b emt lines generation.
following the methodology described in (bhatet al., 2016), we apply clause substitution method-ology to produce emt sentences.
to createopsub-emt, we start with the gold englishsentence that contains either embedded sentenceclauses (s) or subordinate clauses (sbar) andswap one or more of them with their hindi trans-lations to produce an emt synthetic cs sentence.
due to the lack of gold english translations avail-able for all-cs sentences, we used the googletranslate api to first acquire their english transla-tion.
many of the sentences in all-cs are shorterin length and do not contain the abovementionedclauses.
so, we also considered inverted declar-ative sentence clauses (sinv), inverted questionclauses (sq) and direct question clauses (sbarq)in addition to s and sbar.
in case none of theclause level tags were present, we considered thefollowing phrase level tags as switching candi-dates: noun phrase (np), verb phrase (vp), ad-jective phrase (adjp) and adverb phase (advp).
owing to the shorter length and lack of clause-level tags, we switch only one tag per sentence forall-cs-emt.
the choice of which clause to switchwas made empirically by observing what switchescaused the resulting sentence to resemble a natu-rally occurring cs sentence.
one can also use thetoolkit provided by rizvi et al.
(2021) for generat-ing emt lines..c implementation details: tcs.
as an initialisation step, we learn the token embed-dings (mikolov et al., 2013) on the same corpususing skipgram.
the embedding dimension wasset to be 256 and the encoder-decoder layers sharethese lookup tables.
adam optimiser with a learn-ing rate of 0.0001 was used to train the model.
val-idation bleu scores on (hi → eng/cs) transla-tions and (en → hi → en) reconstructions wereused as metrics to save the best model for tcs (s)and tcs (u), respectively..d human evaluation.
the 150 samples evaluated in table 5 were takenentirely from test/validation splits.
we undertookan alternate human evaluation experiment involv-ing 100 real cs sentences and its corresponding.
3166e language model training.
generated using movie-cs.
cs sentences using lex, emt, tcs (u) and tcs(s).
out of these 100 sentences, 40 of them cameentirely from the test and validation splits and theremaining 60 are training sentences which we fil-tered to make sure that sentences generated by tcs(s) and tcs (u) never exactly matched the real cssentence.
the table below (table 9) reports theevaluations on the complete set of 100 sentencesfrom 5 datasets.
we observe that the trend remainsexactly the same as in table 5, with tcs (s) beingvery close to real cs sentences in its evaluation andtcs (u) trailing behind tcs (s)..method.
syntactic.
semantic naturalness.
realtcs (s)tcs (u)emtlex.
4.36±0.764.29±0.843.96±1.063.47±1.253.10±2.16.
4.39±0.804.30±0.893.93±1.133.53±1.233.05±1.35.
4.20±1.004.02±1.163.52±1.452.66±1.492.01±1.32.
table 9: mean and standard deviation of scores (between 1and 5) from 3 annotators for 100 samples from 5 datasets..the awd-lstm language model was trained for100 epochs with a batch size of 80 and a sequencelength of 70 in each batch.
the learning rate wasset at 30. the model uses nt-asgd, a variant ofthe averaged stochastic gradient method, to updatethe weights.
the mix-review decay parameter wasset to 0.9. this implies that the fraction of pretrain-ing batches being considered at the end of n epochsis 0.9n, starting from all batches initially.
two de-cay coefficients {0.8, 0.9} were tested and 0.9 waschosen based on validation perplexities..f code-switching examples.
the sentences in table 10 have been generated onthe test and validation splits of all-cs as well asthe opsub dataset.
overall, they depict how themodel is able to retain context over long sentences(e.g.
“and social sectors”) and perform meaningfulswitching over large spans of words (e.g.
“old con-versation writer media”, “regularly security prac-tices”).
we also note that at times, the model useswords which are different from the natural englishtranslations of the sentence, which are appropriatewithin the context of a cs sentence (e.g.
the use of“manage” instead of “manageable”)..g details of gluecos experiments.
for masked language modeling (mlm), we selectthe default parameters for the learning rate (5e-5),.
batch masking probability (0.15), sequence length(512).
the models are trained for 2 epochs with abatch size of 4 and gradient accumulation step of10. for task specific fine tuning we rely on the offi-cial training scripts provided by gluecos repos-itory.
8 we train the models for 5 seed (0,1,2,3and 4) and report mean and standard deviations ofaccuracy and f1 for nli and sentiment analysisrespectively.
h additional dataset and experiments.
dataset the additional corpus on which exper-iments were performed is opus-100 (zhanget al., 2020) which was sampled from the originalopus corpus (tiedemann, 2012).
the primarydifference between opsub and opus-100 is thatopsub does not have manual hindi translations.
8https://github.com/microsoft/gluecos.
सारे पुराने बातचीत लेखक मी(cid:465)डया और राजनीित में जमा हो गए हैं(all the old conversation writers have gathered in mediaand politics)सारे old conversation writer media और politics में जमा हो गए हैं.
क्या बात है तुमने आखर(cid:547) बार कब पाट(cid:569) क(cid:551) थी(what is the last time you had a party)क्या बात है तुमने last time party कब क(cid:551) थी.
तू अपने कमरे में जा यार आप दोनों कृ पया शांत हो जाओ(you go to your room man please relax both of you)तू अपने room में जा यार आप दोनों please calm down.
generated using treebankcs.
यह पॉिलसी पित प(cid:420)ी के संयु(cid:416) नाम से थी(this policy was in the joint name of husband and wife)यह policy husband wife के joint नाम से थी.
स्कू लों में तो िनयिमत रूप से सुरक्षा अभ्यास कराए जाने लगे हैं(regular safety exercises are being conducted in schools)schools में तो regularly security practice (cid:465)कये जाने लगे हैं.
इसमें बुिनयाद(cid:547) कृ (cid:466)ष और सामा(cid:468)जक क्षेऽों में सावर्जिनक िनवेशभी शािमल है(it also includes public investment in basic agriculturaland social sectors)इसमें बुिनयाद(cid:547) farming and social areas में public investmentभी शािमल है.
generated using opsub.
ंजी (cid:466)वकास उपायों पर बल देना है.
इस सम्मेलन का चौथा (cid:466)वषय मानव पू(the fourth theme of this conference is to emphasizehuman capital development measures.)
इस सम्मेलन का fourth subject human पूउपायों पर बल देना है.
ंजी development.
देश का आंत(cid:464)रक कजर् ूबन्ध (cid:465)कए जाने योग्य सीमा में है(the country’s internal debt is within manageable limits)देश का internal loan manage (cid:465)कए जाने योग्य सीमा में है.
table 10: more examples of code-switching generated bytcs (u)..3167of its sentences and requires the use of an externalapi such as google translate for translation.
however, opus-100 has manually annotatedsentences as part of the corpus.
the sourceof opus-100 ranges from movie subtitles tognome documentation to the bible.
we extract340k sentences from opus-100 corpus afterthresholding on length (5-15).
we offer thiscomparison of systems trained on opsub andopus-100 to show how our models fare whenusing two datasets that are very different in theircomposition..lex lines generation.
generation of lex linesis straightforward and requires only a bilinguallexicon.
for each monolingual hindi sentencewe generate ~5 sentences on opus-100 resultingin opus-100-lex (to roughly match the size ofopsub-lex)..emt lines generation.
for generation of emtlines we have two strategies depending on theavailability of tools (parsers, translation service,aligners, etc).
the first strategy requires atranslation service (either in-house or publiclyavailable).
we substitute the embedded clausefrom parse trees of english sentences with theirhindi translations.
this strategy does not require aparallel hindi corpus and has been previously usedfor generating opsub-emt and all-cs-emt(described in detail in appendix b)..the second strategy,is used to generatethatopus-100-emt, requires a parallel corpus, aconstituent parser in english and a word alignerbetween parallel sentences.
opus-100 sentencesare aligned using simalign (jalili sabet et al.,2020) and embedded clauses from parse trees ofenglish sentences are replaced by hindi clausesusing word aligners.
here again, for each mono-lingual hindi sentenece we generate ~5 emtsentences (strategy-2) on opus-100 resulting inopus-100-emt..curriculum training experiments.
table 11provides a walkthrough of systems using varioustraining curricula that are evaluated for two differ-ent choices of datasets - opsub vs opus-100 dif-fering in the generation of emt lines.
the modelsare evaluated using bleu (papineni et al., 2002)scores computed on the test set of all-cs.
the vo-.
x=opsub x=opus-100.
curriculumo all-cs (s)a iitb + x (s)b a | all-cs (s)c a | x-hi + x-lex (u)c1 c | all-cs (u)c2 c | all-cs (s)d a | x-hi + x-emt (u)d1 d | all-cs (u)d2 d | all-cs (s).
19.18.
1.5127.84.
15.2332.7139.53.
17.7335.5243.15.
19.14.
0.2925.63.
14.1731.4837.51.
15.0333.9140.32.table 11: bleu score on (hi (cid:0) cs) for different curriculameasured on all-cs (test).
x | y represents starting withmodel x and further training using dataset y. values fromtable 3 are replicated here for ease of comparison..cabulary is generated by combining train sets of alldatasets to be used in the curricula.
it is 126,576when x = opsub and 164,350 when x = opus-100 (opsub shows a higher overlap in vocabu-lary with all-cs compared to opus-100).
themarginal difference in system o for opsub andopus-100 is attributed to differences in the sizeof the vocabulary.
opsub being conversational innature, is a better pretraining corpus compared toopus-100 as seen from system a, the sources ofthe latter being gnome documentations and thebible, apart from movie subtitles..the results for c1, c2, d1, d2 are consistentlybetter when x = opsub versus when x = opus-100. we choose to highlight four models fromtable 11 which together demonstrate multipleuse-cases of tcs in table 12.tcs (lex)refers to (c2, x=opsub), tcs (u) refers to (d1,x=opsub), tcs (s) refers to (d2, x=opsub) andtcs (simalign) refers to (d2, x=opus-100)..language modelling experiments.
table 13shows results from lm experiments (using thesame setup as in section 5.2.1).
the values fortcs (s) and tcs (u) have been reproduced here.
tcs model.
use-case.
tcs (lex).
easy generation of sentences,only requires a bilingual lexicon.
tcs (u) and tcs (s).
requires parser and translation servicedoes not require parallel data.
tcs (simalign).
requires parser along with parallel dataalignment can be generatedusing simalign.
table 12: use cases for different tcs models..3168pretraining corpus.
| train |.
test pplopsub.
test pplall-cs.
opsub + tcs (lex)opsub + tcs (u)opsub + tcs (simalign)opsub + tcs (s).
4.03m3.99m4.03m3.96m.
57.2457.4560.0156.28.
268.54271.19314.28254.37.table 13: test perplexities on opsub and all-cs using dif-ferent pretraining datasets..for ease of comparison.
(note that tcs (simalign)does not perform as well as the other models sincethe sentences for training the language model aregenerated on opsub for all the models here, buttcs (simalign) has been trained on opus-100.).
evaluation metrics.
table 14 shows the resultsof the three objective evaluation metrics on the ad-ditional tcs models.
in comparison with the re-sults in table 8, we observe that tcs (lex) andtcs (simalign) perform comparably to tcs (s)and tcs (u) on all metrics..evaluation metric.
tcs (lex) tcs (simalign).
bertscore.
all (3500)mono (3434)unk (1983)unk & mono (1857).
bert-basedclassifier.
|sentences|accuracy(fake).
diversity.
gzip (d)self-bleu.
0.7730.7690.8320.817.
1247584.17.
19.6256.3.
0.7680.7530.8290.822.
1247582.98.
19.8359.8.table 14: evaluation metrics for the additional tcs models.
please see table 8 for a comparison with other models..3169