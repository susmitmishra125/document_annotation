ontoed: low-resource event detection with ontology embedding.
shumin deng1,2∗, ningyu zhang1,2∗, luoqiu li1,2, hui chen3, huaixiao tou3,mosha chen3, fei huang3, huajun chen1,2†1zhejiang university & azft joint lab for knowledge engine2hangzhou innovation center, zhejiang university3alibaba group, china{231sm, zhangningyu, 3160102409}@zju.edu.cn, {weidu.ch, huaixiao.thx}@alibaba-inc.com,{chenmosha.cms, f.huang}@alibaba-inc.com, huajunsir@zju.edu.cn.
abstract.
event detection (ed) aims to identify eventtrigger words from a given text and classify itinto an event type.
most of current methodsto ed rely heavily on training instances, andalmost ignore the correlation of event types.
hence, they tend to suffer from data scarcityand fail to handle new unseen event types.
toaddress these problems, we formulate ed as aprocess of event ontology population: linkingevent instances to pre-deﬁned event types inevent ontology, and propose a novel ed frame-work entitled ontoed with ontology embed-ding.
we enrich event ontology with linkagesamong event types, and further induce moreevent-event correlations.
based on the eventontology, ontoed can leverage and propagatecorrelation knowledge, particularly from data-rich to data-poor event types.
furthermore,ontoed can be applied to new unseen eventtypes, by establishing linkages to existing ones.
experiments indicate that ontoed is more pre-dominant and robust than previous approachesto ed, especially in data-scarce scenarios..1.introduction.
event detection (ed) (chen et al., 2015) is the taskto extract structure information of events from un-structured texts.
for example, in the event mention“jack is married to the iraqi microbiologist knownas dr. germ.”, an ed model should identify theevent type as ‘marry’ where the word ‘married’triggers the event.
the extracted events with canon-ical structure facilitate various social applications,such as biomedical science (li et al., 2019; wanget al., 2020c), ﬁnancial analysis (deng et al., 2019;liang et al., 2020), fake news detection (wanget al., 2018; nikiforos et al., 2020) and so on..as a non-trivial task, ed suffers from the low-resource issues.
on the one hand, the maldistribu-.
∗ equal contribution.
† corresponding author..figure 1: low-resource event detection w.r.t.
eventcorrelation in fewevent (deng et al., 2020) dataset..tion of samples is quite serious in ed benchmarkdatasets, e.g., fewevent (deng et al., 2020) andmaven (wang et al., 2020b), where a large por-tion of event types contain relatively few traininginstances.
as shown in figure 1, the sample sizeof two event types attack and riot differs greatly(4816 & 30).
in low-resource scenarios, superviseded models (chen et al., 2015; nguyen et al., 2016;liu et al., 2018) are prone to overﬁtting since theyrequire sufﬁcient training instances for all eventtypes.
on the other hand, real-world applicationstend to be open and evolve promptly, and accord-ingly there can be numerous new unseen eventtypes.
handling new event types may even entailstarting over, without being able to re-use annota-tions from previous ones (huang et al., 2018)..regarding low-resource ed, huang et al.
(2018)take a fresh look at ed, by mapping each eventmention to a speciﬁc type in a target event ontology,which can train from few seen event types and thentransfer knowledge to new unseen ones.
however,the event ontology here merely considers the intra-structure for each event mention and event type..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2828–2839august1–6,2021.©2021associationforcomputationallinguistics2828sentence(321)acquit(27)pardon(10)justiceattack(4816)riot(30)conflictinjure(547)marry(26229)lifedivorce(65)causecausebeforebeforebeforesubsupercosupercosupernew event typedemonstratebe-bornnew event typein this paper, we enrich the event ontology withmore inter-structures of event types, such as tem-poral, causal and hierarchical event-event relations(ning et al., 2018; wang et al., 2020a).
for exam-ple, as seen in figure 1, attack cause−−−−→ sentence,sentence before−−−−→ acquit, attack cosuper−−−−−→ riot.
our key intention is to fully utilize the event ontol-ogy and leverage correlation knowledge from data-rich event types (i.e., attack) to data-poor ones (i.e.,sentence, acquit and riot).
besides, new eventtypes (i.e., be-born) can be learned with correla-tion (i.e., cosuper) of existing ones (i.e., injure).
as the ﬁrst attempt to construct such event ontol-ogy, we propose a novel ed framework with ontol-ogy embedding called ontoed.
first, we establishthe initial event ontology with event instances andtypes.
we capture semantic features and relationsof event instances with bert (devlin et al., 2019)and utilize prototypes (snell et al., 2017) to repre-sent event types, where a prototype is the averageof its instance embeddings.
second, we extend theevent ontology with event-event relations based onextracted relations among event instances, and thenlearn ontology embedding by aggregating neigh-bor prototypes for each prototype w.r.t.
correlationsamong event types.
in this way, semantically simi-lar event types in vector space will be closer, thus,improving the discrimination of dissimilar eventtypes.
third, we design an event correlation infer-ence mechanism to induce new event correlationsbased on symbolic rules, e.g., (sentence, before,acquit) ∧ (acquit, before, pardon) → (sentence,before, pardon).
thus, we can induce new event-event relations to further enrich the event ontology.
to the best of our knowledge, it is the ﬁrst workto explicitly model correlations among event typeswith event ontology in low-resource ed..our contributions can be summarized as follows:.
• we study the low-resource event detectionproblem and propose a novel ontology-basedmodel, ontoed, that encodes intra and interstructures of events..• we provide a novel ed framework based onontology embedding with event correlations,which interoperates symbolic rules with popu-lar deep neural networks..• we build a new dataset ontoevent for ed.
extensive experimental results demonstratethat our model can achieve better performanceon the overall, few-shot, and zero-shot setting..2 related work.
traditional approaches to ed are mostly based onneural networks (chen et al., 2015; nguyen et al.,2016; liu et al., 2018; wang et al., 2019; yan et al.,2019; cui et al., 2020; shen et al., 2020; lou et al.,2021), and ignore correlation knowledge of eventtypes, especially in low-resource scenarios.
mostprevious low-resource ed methods (peng et al.,2016) have been based on supervised learning.
however, supervised-based methods are too de-pendent on data, and fail to be applied to new typeswithout additional annotation efforts.
another pop-ular methods for low-resource ed are based onmeta learning.
deng et al.
(2020); lai et al.
(2020);shen et al.
(2021) reformulate ed as a few-shotlearning problem to extend ed with limited la-beled samples to new event types, and propose toresolve few-shot ed with meta learning.
besides,knowledge enhancement and transfer learning areapplied to tackle low-resource ed problems.
tonget al.
(2020) leverage open-domain trigger knowl-edge to address long-tail issues in ed.
liu et al.
(2020); du and cardie (2020) propose to handlefew-shot and zero-shot ed tasks by casting it as amachine reading comprehension problem.
huanget al.
(2018) propose to tackle zero-shot ed prob-lem by mapping each event mention to a speciﬁctype in a target event ontology.
note that huanget al.
(2018) establish the event ontology merelywith intra-structure of events, while we extend itwith inter-structure of event correlations.
thoughthese methods are suitable for low-resource scenar-ios, they mostly ignore implicit correlation amongevent types and lack reasoning ability..in order to utilize correlation knowledge amongevent types, li et al.
(2020) propose a new eventgraph schema, where two event types are connectedthrough multiple paths involving entities.
how-ever, it requires various annotations of entities andentity-entity relations, which is complicated anddemanding.
different from li et al.
(2020), wepropose to revisit the ed task as an ontology learn-ing process, inspired by relation extraction (re)tasks based on ontology and logic-based learning.
lima et al.
(2018, 2019) present a logic-based rela-tional learning approach to re that uses inductivelogic programming for generating information ex-traction (ie) models in the form of symbolic rules,demonstrating that ontology-based ie approachesare advantageous in capturing correlation amongclasses, and succeed in symbolic reasoning..28293 methodology.
3.1 problem formulation.
we revisit the event detection task as an iterativeprocess of event ontology population.
given anevent ontology o with an event type set e ={ei|i ∈ [1, ne]}, and corpus t = {xi|i ∈ [1, k]}that contains k instances, the goal of event on-tology population is to establish proper linkagesbetween event types and instances.
speciﬁcally,each instance xi in t is denoted as a token se-quence xi = {xji |j ∈ [1, l]} with maximum ltokens, where the event trigger xti are annotated.
we expect to predict the index t (1 ≤ t ≤ l) andthe event label ei for each instance respectively..besides, we utilize a multi-faceted event-eventrelation set r = rh (cid:116) rt (cid:116) rc for event on-tology population and learning.
thereinto, rh ={subsuper, supersub, cosuper1} denotes aset of relation labels deﬁned in the subevent rela-tion extraction task (wang et al., 2020a; yao et al.,2020).
rt = {before, after, equal2} de-notes a set of temporal relations (han et al., 2020).
rc = {cause, causedby} denotes a set ofcausal relations (ning et al., 2018)..3.2 model overview.
in this paper, we propose a general frameworkcalled ontoed with three modules: (1) event de-tection (ontology population), (2) event ontologylearning, and (3) event correlation inference.
fig-ure 2 shows the key idea of the three modules..figure 2: overview of our proposed ontoed..event detection aims at identifying the eventtrigger xti and type ei for each input tokens xi,and then identify relations among event instances.
the average instance embedding of each type iscalculated as the primitive event prototype..event ontology learning aims to obtain eventontology embedding with the correlation of eventprototypes, based on the relations among eventtypes derived from instances..1(ei, cosuper, ej): ei and ej has the same super type.
2(ei, equal, ej): ei and ej happens simultaneously..event correlation inference seeks to infer newevent correlations based on existing event-eventrelations, so as to obtain a solid event ontology..the detailed architecture of ontoed with run-.
ning examples is illustrated in figure 3..3.3 event detection (ontology population).
the input of ed is an initial event ontology withevent types e and coarse corpus t ..i , · · · , xl.
instance encoder.
given a token sequencexi = {x1i } with trigger xti, we use a pre-trained bert (devlin et al., 2019) to get a contex-i for xttual representation x ti, and use the tokenembedding of [cls] as the contextual represen-tation xi for xi.
note that the instance encoderis pluggable, and can be replaced as other modelsfollowed by (deng et al., 2020; cui et al., 2020)..class encoder.
we then represent event typesas prototypes (snell et al., 2017), as it is proven tobe robust for low-resource ed (deng et al., 2020).
initially, event types have no correlation withothers, thus we require to compute the prototype pkfor ek ∈ e by averaging its instance embeddings:.
pk =.
1nk.
(cid:88)nki=1.
xi.
(1).
where nk is the instance number of ek.
afterward,event prototypes will be induced from the moduleof event correlation inference, as shown in figure 3.event detector.
given embeddings of a tokensequence, we treat each token as an event triggercandidate and then compute probability of the cor-responding event type for event trigger candidatexti, denoted by:.
p (y = ek) =.
exp(−(cid:107)x tj=1 exp(−(cid:107)x t.(cid:80)ne.
i − pk(cid:107)).
i − pj(cid:107)).
(2).
where (cid:107) · (cid:107) denotes euclidean distance, and ne =|e| denotes the number of event types..as general, we adopt cross entropy as the loss.
function for event detection, denoted by:.
led = −.
y log p (y = ek).
(3).
(cid:88)nek=1.
where y is the ground-truth label for xti..instance relation extractor.
for each eventinstance pair (xi, xj), we adopt a comprehensiveway to model embedding interactions (zhou et al.,2020), denoted by x pij = [xi, xj, xi (cid:12)xj, xi −xj], where [·, ·] denotes a vector concatenation,and (cid:12) is the element-wise hadamard product..28303(cid:17)(cid:3)event correlation inference2(cid:17)(cid:3)event ontology learning event types and event-event relations 1(cid:17)(cid:3)event detection (ontology population)instances of eventtypes and relations new event correlations for low-resource events figure 3: detailed example for the process of ontoed.
note that we ignore instance nodes in no.2 and no.3 eventontology for space limit.
step 1: event detection (ontology population) connect event types with instances,given the initial event ontology with coarse corpus.
step 2: event ontology learning establish correlationsamong event types, given the event ontology enriched with instances.
step 3: event correlation inferenceinduce more event correlations based on existing event-event relations, e.g., (e1, cause, e2) → (e1, before, e2),and (e1, before, e2) ∧ (e2, before, e3) → (e1, before, e3)..we then calculate the probability p (y = rk)of relation rk ∈ r between (xi, xj) by softmax.
generally, we adopt cross entropy as the loss func-tion for instance relation extraction, denoted by:.
lre = −.
(cid:88)nrk=1where y is the ground-truth for (xi, xj), and nr =|r| denotes the number of event-event relations..y log p (y = rk).
(4).
overall, the loss function for event detection.
(ontology population) is calculated by:.
lop = γled + (1 − γ)lre.
(5).
where γ is a hyperparameter..3.4 event ontology learning.
ontology completion.
we complete event ontol-ogy o with both intra and inter structure of events.
we normatively link event instances t to eventtypes e, and establish correlations among eventtypes based on linkages among event instances..instance-to-class linking.
given a sentence si(formalized as a token sequence xi) with a triggerxti of an event instance, we link these informationto its corresponding event type ei with normativetriples: (si, triggeris, xti) and (si, instanceof, ei).
class-to-class linking.
given an event instancepair (xi, xj) with a relation r, we upgrade the.
instance correlation to corresponding event types,denoted by (ei, r, ej).
besides, we link each eventsubtype to its corresponding supertype3 with asubsuper relation (supersub in reverse), andwe link each event subtype pair having the samesupertype with a cosuper relation..ontology embedding.
we represent the eventontology considering both instances and correla-tions for each event type.
speciﬁcally, given a triple(cid:96) = (eh, r, et) ∈ o, we propagate the prototypeph of head event type eh to prototype pt of tailevent type et with a relation transformation matrixmr ∈ rd×d.
we select a matrix to embed r as itshows great robustness to model relations in low-resource senarios (zhang et al., 2019).
we thenaggregate propagation from all head event types by.
p ∗.
t =.
(cid:88).
p i.hmri.
(6).
(ei.
h,ri,et)∈o(cid:96)where o(cid:96) is all one-hop neighbor triples of et in o.the prototype pt of et in (cid:96) after propagationt with weight.
is a weighted average of pt and p ∗λ ∈ [0, 1], denoted by:.
pt = λpt + (1 − λ)p ∗t.(7).
3the supertypes and its corresponding subtypes in this.
paper are pre-deﬁned and will be introduced in appendix..28311(cid:17)(cid:3)event ontology population2.
event ontology learninginitial event ontology with coarse event corpus0killing(2030 instances)death(1226 instances)legal_rulings(241 instances)1killing(2030 instances)death(1226 instances)legal_rulings(241 instances)causebeforeevent ontology enriched with event instances3.
event correlation inferencerefined event ontology w.r.t event correlationsmore enriched event ontology with correlation inference(     , cause,     )e2e1(     , before,     )e3e22killing(2030 instances)death(1226 instances)legal_rulings(241 instances)causebeforee1e2e3subobjectproperty(cause, before)inverseobjectproperty(subsuper, supersub)inverseobjectproperty(before, after)inverseobjectproperty(cause, causedby)transitiveobjectproperty(subsuper)transitiveobjectproperty(supersub)transitiveobjectproperty(cosuper)transitiveobjectproperty(before)transitiveobjectproperty(after)transitiveobjectproperty(equal)3killing(2030 instances)death(1226 instances)legal_rulings(241 instances)causebeforebeforebeforee1e2e3super e1(conﬂict)super e3(justice)subsupersubsupersubsupers1s2s3causext1triggeristriggeristriggerisxt2xt3sislsnsmsjskinstanceofinstanceofinstanceofcausebeforebeforee1e2e3killingdeathlegal_rulingssuper e2(life)killeddeathconvicted……………………event instances [s1]: former nopd police ofﬁcer david warren shot and killed henry glover.
[s2]: five current and former ofﬁcers of the nopd were charged with glover's death.
[s3] david was convicted and sentenced to 25 years and 9 months in prison for shooting and killing glover.event corpus(killed, trigger, killing)(convicted, trigger, legal_rulings)(death, trigger, death)causebefore(     , before,     )e1e3(     , before,     )e2e1object property axioms.
rule form.
according to linear map assumption.
relation constraint.
subop(r1, r2)inverseop(r1, r2)transitiveop(r).
(ei, r2, ej) ← (ei, r1, ej)(ei, r1, ej) ← (ej, r2, ei).
pimr2 = pj, pimr1 = pjpimr1 = pj, pjmr2 = pi.
(ei, r, ek) ← (ei, r, ej), (ej, r, ek) pimr = pk, pimr = pj, pjmr = pk.
mr1 = mr2mr1mr2 = imrmr = mr.table 1: three types of object property expression axioms.
op is the short for objectproperty.
i is an identity matrix..we calculate the possibility that r is the relationbetween eh and et with a truth value for (eh, r, et):φ(eh, r, et) = sim(phmr, pt) = σ(p (cid:62)h mrpt),where σ is sigmoid function, and the similarity be-tween phmr and pt is evaluated via dot product.
overall, the loss fuction for event ontology learn-.
ing is deﬁned by:.
matrices either from a single matrix or a product oftwo matrices.
as relation constraints are derivedfrom ideal linear map assumption (the 3rd columnin table 1), m †r are usually unequal butsimilar during training.
thus, the normalized truthvalue fp of g can be calculated based on relationconstraints (the 4th column in table 1):.
r and m ‡.
lol = −.
y log φ(eh, r, et).
(8).
(cid:48).
f.p = (cid:107)m †.
r − m ‡.
r (cid:107)f , fp =.
(cid:88).
(eh,r,et)∈o.
p − f (cid:48)f maxpp − f minf max.
p.and y denotes the ground-truth label for (eh, r, et)..3.5 event correlation inference.
given the event ontology with correlations amongevent types, we infer new event correlations basedon existing ones.
to be speciﬁc, we utilize thegrounding g to infer new event correlation triples,which can be generalized as the following form:.
(ei.
h, ri , ei.
t ) ← (e1.
h, r1, e1.
t ), · · · , (en.
h, rn, en.
t ) (9).
h, rk, ek.
where the right side event triples (ekt ) ∈o with k ∈ [1, n] have already existed in o andh, ri , ei(eit ) /∈ o is new inferred triples to be added.
to compute the truth value of the groundingg, we select three object properties (op) of rela-tions deﬁned in owl24 web ontology language:subop, inverseop, and transitiveop, and thenlearn matrics of relations from linear map assump-tion (zhang et al., 2019), presented in table 1.wang et al.
(2020a); ning et al.
(2018) have de-ﬁned some conjunctive constraints of relations be-tween the event pair, we translate them into objectproperty axioms, shown in table 2..object property axioms.
instances of relation / relation pair.
subop(r1, r2).
(cause, before).
inverseop(r1, r2).
(subsuper, supersub),(before, after), (cause, causedby).
transitiveop(r).
subsuper, supersub, cosuper,before, after, equal.
table 2: groundings of three object properties in o..assuming that m †.
r and m ‡r denotes the relationset on left and right of eq (9) respectively, they are.
4https://www.w3.org/tr/owl2-proﬁles/.
where (cid:107) · (cid:107)f denotes frobenius norm, and sub-script p respectively denotes one of the three objectproperties.
f maxis a the maximum andpminimum frobenius norm score.
fp ∈ [0, 1] is thetruth value for the grounding g and the higher fpmeans the more conﬁdent that g is valid..and f min.
p.the loss function for new event correlation in-.
ference is deﬁned by:(cid:88).
ler = − ψs.
log f i.p − ψv.
(cid:88).
log f jp.j∈g(v ).
− ψt.
log f kp.i∈g(s)(cid:88).
k∈g(t ).
(10)g(·) denotes all groundings w.r.t.
subop (s),inverseop (v ), and transitiveop (t ).
ψs, ψv ,and ψt are hyperparameters for the loss of threeobject properties respectively..as a whole, the ﬁnal loss function for ontoed.
is denoted by:.
l = αlop + βlol + ler.
(11).
where α and β are hyperparameters for the lossof event ontology population (eq (5)) and eventontology learning (eq (8)) respectively..4 experiments.
the experiments seek to: (1) demonstrate that on-toed with ontology embedding can beneﬁt bothstandard and low-resource ed, and (2) assess theeffectiveness of different modules in ontoed andprovide error analysis.
to this end, we verify the ef-fectiveness of ontoed in three types of evaluation:(1) overall evaluation, (2) few-shot evaluation,and (3) zero-shot evaluation..28324.1 datasets.
as none of present datasets for ed is annotatedwith relations among events, we propose a new eddataset namely ontoevent with event correla-tions.
it contains 13 supertypes with 100 subtypes,derived from 4,115 documents with 60,546 eventinstances.
the details of ontoevent are intro-duced in appendix.
we show the main statistics ofontoevent and compare them with some exist-ing widely-used ed datasets in table 3..dataset.
#ins.
#supert #subt #e-e rel.
ace 2005tac kbp 2017feweventmavenontoevent.
#doc.
599167-4,4804,115.
4,0904,83970,852111,61160,546.
88192113.
3318100168100.nonenonenonenone3,804.table 3: statistics of ontoevent compared with ex-isting widely-used ed datasets.
(doc: document, ins:instance, supert: supertype, subt: subtype, e-e rel:event-event relation.).
ontoevent is established based on two newlyproposed datasets for ed: maven (wang et al.,2020b) and fewevent (deng et al., 2020).
they areconstructed from wikipedia documents or basedon existing event datasets, such as ace-20055 andtac-kbp-20176.
in terms of event-event rela-tion annotation in ontoevent, we jointly usetwo models: tcr (ning et al., 2018) is appliedto extract temporal and causal relations, and jcl(wang et al., 2020a) is used for extract hierarchi-cal relations.
the source code of ontoed andontoevent dataset can be obtained from the link:https://github.com/231sm/reasoning in ee..4.2 baselines.
for overall evaluation, we adopt cnn-basedmodel dmcnn (chen et al., 2015), rnn-basedmodel jrnn (nguyen et al., 2016), and gcn-based model jmee (liu et al., 2018).
besides,we adopt bert-based model ad-dmbert (wanget al., 2019) with adversarial imitation learning.
wealso adopt graph-based models oneie (lin et al.,2020) and pathlm (li et al., 2020) which generategraphs from event instances for ed.
for few-shot evaluation and zero-shot evaluation,we adopt some metric-based models for few-shoted, such as matchnet (lai et al., 2020), protonet(snell et al., 2017) and dmbpn (deng et al., 2020).
we also adopt knowledge-enhanced model ekd.
5http://projects.ldc.upenn.edu/ace/6https://tac.nist.gov/2017/kbp/event/index.html.
(tong et al., 2020) and bert-based models qaee(du and cardie, 2020) as well as rcee (liu et al.,2020) based on machine reading comprehension.
besides, we adopt zsee (huang et al., 2018) espe-cially for zero-shot ed..4.3 experiment settings.
with regard to settings of the training process, sgd(ketkar, 2014) optimizer is used, with 30,000 itera-tions of training and 2,000 iterations of testing.
thedimension of token embedding is 50, and the maxi-mum length of a token sequence is 128. in ontoed,a dropout rate of 0.2 is used to avoid over-ﬁtting,and the learning rate is 1 × 10−3.
the hyperparam-eters of γ, λ, α, and β are set to 0.5, 0.5, 1.5 and1 respectively.
ψs, ψv , and ψt are set to 0.5, 0.5and 1 respectively.
we evaluate performance of edwith precision (p), recall (r) and f1 score (f)..4.4 overall evaluation.
setting.
we follow the evaluation protocol of stan-dard ed models, e.g., dmcnn (chen et al., 2015).
event instances are split into training, validating,and testing subset with ratio of 0.8, 0.1 and 0.1respectively.
note that there are no new event typesin testing set which are not seen in training set..as seen from table 4, ontoed achieves largergains compared to conventional baselines, e.g.,dmcnn, jrnn and jmee.
moreover, ontoedstill generally excel bert-based ad-dmbert.
this implies the effectiveness of ed frameworkwith ontology embedding, which can leverage andpropagate correlations among event types, so thatreduce the dependence on data to some extent.
especially, ontoed also outperform graph-basedmodels, i.e., oneie and pathlm.
the possible rea-son is that although they both convert sentencesinto instance graphs, and pathlm even connectsevent types with multiple entities, the event correla-tions are still implicit and hard to capture.
ontoedcan explicitly utilize event correlations and directlypropagate information among event types..4.5 few-shot evaluation.
setting.
we follow the evaluation protocol andmetrics of data-scarce ed models, i.e., rcee (liuet al., 2020), which train models with partial data.
we randomly sample nearly 80% event types fortraining, 10% for validating, and 10% for testing.
differently from overall evaluation, the event typesin testing set are not exsiting in training set..2833model.
trigger identiﬁcationr.f.p.event classiﬁcationr.f.p.dmcnn (chen et al., 2015)jrnn (nguyen et al., 2016)jmee (liu et al., 2018)ad-dmbert (wang et al., 2019)oneie (lin et al., 2020)pathlm (li et al., 2020)ontoed.
64.65 ± 0.8965.94 ± 0.8870.92 ± 0.9074.94 ± 0.9574.33 ± 0.9375.82 ± 0.8577.67 ± 0.99.
64.17 ± 0.9466.67 ± 0.9557.58 ± 0.9672.19 ± 0.9171.46 ± 1.0272.15 ± 0.9475.92 ± 0.92.
64.15 ± 0.9166.30 ± 0.9361.87 ± 0.9473.33 ± 0.9773.68 ± 0.9774.91 ± 0.9277.29 ± 0.98.
62.51 ± 1.1063.73 ± 0.9852.02 ± 1.1467.35 ± 1.0171.94 ± 1.0373.51 ± 0.9975.46 ± 1.06.
62.35 ± 1.1263.54 ± 1.1353.80 ± 1.1573.46 ± 1.1268.52 ± 1.0568.74 ± 1.0370.38 ± 1.12.
63.72 ± 0.9966.95 ± 1.0368.07 ± 1.0271.89 ± 1.0371.77 ± 1.0172.83 ± 1.0174.92 ± 1.07.table 4: evaluation of event detection with overall instances.
p (%), r(%) and f (%) stand for precision, recall,and f1-score respectively..model.
1%.
5%.
10%.
15%.
20%.
matchnet (lai et al., 2020)protonet (snell et al., 2017)dmbpn (deng et al., 2020)ekd (tong et al., 2020)qaee (du and cardie, 2020)rcee (liu et al., 2020)ontoed.
7.09 ± 2.108.18 ± 2.5111.25 ± 2.1335.82 ± 2.0241.17 ± 1.8542.58 ± 1.9444.98 ± 1.98.
14.22 ± 2.1815.25 ± 2.2720.03 ± 1.9944.51 ± 1.8348.69 ± 1.8450.06 ± 1.8152.19 ± 1.74.
20.59 ± 2.1121.74 ± 2.0227.69 ± 1.9549.64 ± 1.7754.03 ± 1.8156.51 ± 1.7158.53 ± 1.75.
26.34 ± 2.0727.75 ± 2.0133.13 ± 1.9152.79 ± 1.2658.97 ± 1.8160.79 ± 1.1362.47 ± 1.52.
30.93 ± 1.9832.21 ± 1.6638.06 ± 1.5455.95 ± 1.3462.04 ± 1.6763.98 ± 1.0865.51 ± 1.17.table 5: f1 score (%) of event classiﬁcation on extremely sparse intances for few-shot evaluation..creases, the possible reason may lie in data noiseand redundancy.
in low-resource scenarios, moredata are not always better.
particularly for somemerely data-driven ed models, such as dmbpn,may obtain a worse effect instead if added data aredirty or duplicated.
but for ontoed, as it utilizescorrelation knowledge in the event ontology andhas less dependence on event instances, making itmore robust to noisy and redundant data.
further-more, ontoed also outperforms than bert-basedmodel with regarding each event instance as a ques-tion, i.e., qaee and rcee.
this implies that eventontology learning with event type knowledge mayresolve low-resource ed more advantageously thantraining merely with event instances..4.6 zero-shot evaluation.
setting.
we follow the evaluation protocol andmetrics of zero-shot ed models, i.e., zsee (huanget al., 2018), and comply with the same datasetsegmentation policy as few-shot evaluation, thusthere are also new unseen event types for testing.
differently, ed data are completely banned fortraining, meaning that we train models only withevent types other than instances..table 6 demonstrates the results regarding zero-shot ed.
we can see that ontoed achieves bestprecision and f1 score as well as comparable recallresults in comparison to baselines.
this illustratesthe effectiveness of ontoed handling new unseenevent types without introducing outsourcing data..figure 4: results on different ratios of ed training data..as seen from table 5, we demonstrate f1 scoreresults in extremely low-resource scenarios (train-ing with less than 20% data, with the similar settingto liu et al.
(2020)).
obviously, ontoed behavestremendous advantages in low-resource ed.
for ex-ample, ontoed obtains 44.98% f1 with 1% data,in comparison to 7.09% in matchnet and 8.18% inprotonet.
we also illustrate accuracy results withdifferent ratios of training data followed by liuet al.
(2020), show in figure 4. as seen, ontoeddemonstrates superior performance with less datadependence than baselines.
especially comparingwith dmbpn and ekd, which require 60% train-ing data to closely achieve the best results, whileontoed only uses 20%.
besides, we ﬁnd that theperformance on dmbpn increases ﬁrst and thenslightly decreases as the ratio of training data in-.
283400.10.20.30.40.50.60.70.80.9ratio of training data for ed10203040506070accuracy (%) for edontoedrceeqaeeekddmbpnmodel.
p.r.f.ekd (tong et al., 2020)qaee (du and cardie, 2020)rcee (liu et al., 2020)zsee (huang et al., 2018)ontoed.
32.5836.6937.4540.9242.13.
31.7737.3336.8344.1844.04.
32.1737.0137.1443.0243.06.table 6: comparisons of performance on zero-shot ed..traditional models, such as ekd and rcee, re-quire to adopt other datasets, e.g., wordnet (milleret al., 1990) (where words are grouped and in-terlinked with semantic relations) and framenet(baker, 2014) (where frames are treated as metaevent types) to increase the persuasiveness of re-sults.
in contrast, ontoed naturally models thestructure of event types with an event ontology,thus even for a new unseen event type without in-stance data, we can also obtain its representationthrough the event-event correlation.
moreover, on-toed is also beneﬁcial to resolve zero-shot edthan zsee.
this may due to ontoed modelingwith both intra and inter structures of events whilezsee merely considering the intra-structure..5 further analysis.
5.1 ablation study.
to assess the effect of event ontology learning andcorrelation inference, we remove the two modulesin ontoed, and evaluate f1 score shown in fig-ure 5. from the results, we observe that ontoedoutperforms the two baselines in all evaluation set-tings, indicating that event ontology learning andcorrelation inference facilitate ed, as they utilizeknowledge among event types and has less depen-dence on instance data.
furthermore, in terms ofperformance degradation compared to ontoed, f1score of ontoed merely without event correlationinference (e.g., 10.9%↓) drops more seriously thanthat without event ontology learning (e.g., 6.6%↓),and the phenomenon is more obvious in few-shotand zero-shot evaluation (e.g., 10.9%↓ v.s.
15.9%↓and 28.1%↓).
this illustrates that event correlationinference is more necessary in ontoed, as it estab-lishes more correlations among event types, therebyknowledge can be propagated more adequately, es-pecially from data-rich to data-poor events..5.2 error analysis.
we further conduct error analysis and provide somerepresentative examples.
(1) one typical error re-lates to similar event-event structures in the eventontology.
as ontoed considers event correlations,.
figure 5: effect of different modules in ontoed..event types with similar neighbor triples can be in-distinguishable.
for example, robbery and kidnap-ping have the same supertype crime, and they bothhave the neighbor triples of (∗, cause, arrest).
(2) the second error relates to wrong instance re-lations.
as the instance relation extraction directlyinﬂuence the establishment of event correlations,wrong instance relations will cause error propaga-tion.
(3) the third error relates to the same eventmention for different event types.
for example, ‘ofthe 126 people aboard, 47 died and 74 sustainedserious injuries.’ both mentions die and injure..6 conclusion and future work.
this paper proposes a novel event detection frame-work with ontology embedding called ontoed.
werevisit the ed task by linking each event instance toa speciﬁc type in a target event ontology.
to facili-tate the linkage, we enrich the event ontology withevent-event relations, such as temporal, causal andhierarchical correlation, and induce more event cor-relations based on existing ones.
the key insight isthat event ontology can help to reduce model depen-dence on instance data, especially in low-resourcescenarios.
as data-rich event types can propagatecorrelation knowledge to data-poor ones, and newevent types can establish linkages to the event ontol-ogy.
we demonstrate the effectiveness of ontoedin three settings: overall, few-shot as well as zero-shot, and experiments show that ontoed excelsprevious methods with great robustness..in the future, we intend to extend our work inseveral aspects.
first, we would improve the eventontology and consider more event correlations.
sec-ond, we would explore if low-resource ed can alsoboost to identify event correlation.
third, we woulddevelop more neuro-symbolic methods for ed..28352veraoo evaouationfez-6hot evaouationzero-6hot evaouationdliierent settlngs ior evdoudtlon010203040506070)1 sfore (%) ior (donto(donto(d w/o &orreodtlon inierenfeonto(d w/o &orreodtlon inierenfe  & ontooogy /edrnlng10.9%6.6%15.9%28.1%8.1%13.9%acknowledgments.
we want to express gratitude to the anonymousreviewers for their hard work and kind comments.
this work is funded by national key r&d pro-gram of china (funding no.2018yfb1402800)and nsfc91846204..broader impact statement.
a broad goal of event detection is to extract struc-tured knowledge from unstructured texts to facil-itate knowledge acquisition.
for example, it isvaluable in the medical domain and provides socialbeneﬁts to analyze dispensatory details as well aselectronic health records.
furthermore, a solid edsystem can also be applied to many society issues,such as anti-terrorist and public opinion analysis.
in this paper, we present a new datasetontoevent for ed with event-event correlations.
the event data are all collected from existingdatasets (i.e., ace 2005) or open source databases(e.g., wikipedia), and the annotation are generatedfrom existing models with citations.
in experi-ments, we detailedly describe how to evaluate thenewly-proposed ontoevent and provide speciﬁcanalysis.
the code and dataset are both available.
our approach to ed can leverage only a fewevent corpus to establish the linkage between eventtypes and event instances w.r.t.
event correlations.
in addition, this work is also a brand-new attemptto combine information extraction and symbolicreasoning, based on ontology embedding.
our in-tention is to develop an ontology-based ed systemfor the nlp community, and wish our innovationcan become a small step in this direction..references.
collin f baker.
2014. framenet: a knowledge basefor natural language processing.
in proceedings offrame semantics in nlp: a workshop in honor ofchuck fillmore (1929-2014), pages 1–5..yubo chen, liheng xu, kang liu, daojian zeng, andjun zhao.
2015. event extraction via dynamic multi-pooling convolutional neural networks.
in acl (1),pages 167–176.
the association for computer lin-guistics..shiyao cui, bowen yu, tingwen liu, zhenyu zhang,xuebin wang, and jinqiao shi.
2020.edge-enhanced graph convolution networks for event de-in emnlp (find-tection with syntactic relation.
ings), pages 2329–2339.
association for computa-tional linguistics..shumin deng, ningyu zhang, jiaojian kang, yichizhang, wei zhang, and huajun chen.
2020. meta-learning with dynamic-memory-based prototypicalin wsdm,network for few-shot event detection.
pages 151–159.
acm..shumin deng, ningyu zhang, wen zhang, jiaoyanchen,jeff z. pan, and huajun chen.
2019.knowledge-driven stock trend prediction and ex-planation via temporal convolutional network.
inwww (companion volume), pages 678–685.
acm..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in naacl-hlt (1), pages 4171–4186.
as-sociation for computational linguistics..xinya du and claire cardie.
2020. event extractionby answering (almost) natural questions.
in emnlp(1), pages 671–683.
association for computationallinguistics..rujun han, yichao zhou, and nanyun peng.
2020. do-main knowledge empowered structured neural netfor end-to-end event temporal relation extraction.
in emnlp (1), pages 5717–5729.
association forcomputational linguistics..lifu huang, heng ji, kyunghyun cho, ido dagan, se-bastian riedel, and clare r. voss.
2018. zero-shotin acl (1),transfer learning for event extraction.
pages 2160–2170.
association for computationallinguistics..nikhil ketkar.
2014. stochastic gradient descent.
op-.
timization..viet dac lai, thien huu nguyen, and franck der-noncourt.
2020. extensively matching for few-shotlearning event detection.
in nuse@acl, pages 38–45. association for computational linguistics..diya li, lifu huang, heng ji, and jiawei han.
2019.biomedical event extraction based on knowledge-driven tree-lstm.
in naacl-hlt (1), pages 1421–1430. association for computational linguistics..manling li, qi zeng, ying lin, kyunghyun cho, hengji, jonathan may, nathanael chambers, and clare r.voss.
2020. connecting the dots: event graphschema induction with path language modeling.
inemnlp (1), pages 684–695.
association for com-putational linguistics..xin liang, dawei cheng, fangzhou yang, yifeng luo,weining qian, and aoying zhou.
2020. f-hmtc:detecting ﬁnancial events for investment decisionsbased on neural hierarchical multi-label text classiﬁ-cation.
in ijcai, pages 4490–4496.
ijcai.org..rinaldo lima, bernard espinasse, and fred freitas.
2018. ontoilper: an ontology- and inductive logicprogramming-based system to extract entities and re-lations from text.
knowl.
inf.
syst., 56(1):223–255..2836rinaldo lima, bernard espinasse, and fred freitas.
2019. a logic-based relational learning approach torelation extraction: the ontoilper system.
eng.
appl.
artif.
intell., 78:142–157..ying lin, heng ji, fei huang, and lingfei wu.
2020.a joint neural model for information extraction withglobal features.
in acl, pages 7999–8009.
associa-tion for computational linguistics..jian liu, yubo chen, kang liu, wei bi, and xiaojiangliu.
2020. event extraction as machine reading com-prehension.
in emnlp (1), pages 1641–1651.
asso-ciation for computational linguistics..xiao liu, zhunchen luo, and heyan huang.
2018.jointly multiple events extraction via attention-in emnlp,based graph information aggregation.
pages 1247–1256.
association for computationallinguistics..dongfang lou, zhilin liao, shumin deng, ningyuzhang, and huajun chen.
2021. mlbinet: a cross-sentence collective event detection network.
in acl.
association for computational linguistics..george a miller, richard beckwith, christiane fell-baum, derek gross, and katherine j miller.
1990.introduction to wordnet: an on-line lexical database.
internationallexicography, 3(4):235–244..journal of.
thien huu nguyen, kyunghyun cho, and ralph grish-man.
2016. joint event extraction via recurrent neu-ral networks.
in hlt-naacl, pages 300–309.
theassociation for computational linguistics..maria nefeli nikiforos, spiridon vergis, andreanastylidou, nikolaos augoustis, katia lida kermani-dis, and manolis maragoudakis.
2020. fake newsdetection regarding the hong kong events fromtweets.
in aiai workshops, volume 585 of ifip ad-vances in information and communication technol-ogy, pages 177–186.
springer..qiang ning, zhili feng, hao wu, and dan roth.
2018.joint reasoning for temporal and causal relations.
inacl (1), pages 2278–2288.
association for compu-tational linguistics..haoruo peng, yangqiu song, and dan roth.
2016.event detection and co-reference with minimal su-pervision.
in emnlp, pages 392–402.
the associa-tion for computational linguistics..shirong shen, guilin qi, zhen li, sheng bi, andlusheng wang.
2020. hierarchical chinese legalevent extraction via pedal attention mechanism.
incoling, pages 100–113.
international committeeon computational linguistics..shirong shen, tongtong wu, guilin qi, yuan-fang li,gholamreza haffari, and sheng bi.
2021. adap-tive knowledge-enhanced bayesian meta-learningin findings of acl.
for few-shot event detection.
association for computational linguistics..jake snell, kevin swersky, and richard s. zemel.
2017. prototypical networks for few-shot learning.
in nips, pages 4077–4087..meihan tong, bin xu, shuai wang, yixin cao, leihou, juanzi li, and jun xie.
2020. improving eventindetection via open-domain trigger knowledge.
acl, pages 5887–5897.
association for computa-tional linguistics..haoyu wang, muhao chen, hongming zhang, andjoint constrained learning fordan roth.
2020a.
in emnlp (1),event-event relation extraction.
pages 696–706.
association for computational lin-guistics..xiaozhi wang, xu han, zhiyuan liu, maosong sun,and peng li.
2019. adversarial training for weaklyin naacl-hlt (1),supervised event detection.
pages 998–1008.
association for computationallinguistics..xiaozhi wang, ziqi wang, xu han, wangyi jiang,rong han, zhiyuan liu, juanzi li, peng li, yankailin, and jie zhou.
2020b.
maven: a massive gen-eral domain event detection dataset.
in emnlp (1),pages 1652–1671.
association for computationallinguistics..xing david wang, leon weber, and ulf leser.
2020c.
biomedical event extraction as multi-turn questionanswering.
in louhi@emnlp, pages 88–96.
as-sociation for computational linguistics..yaqing wang, fenglong ma, zhiwei jin, ye yuan,guangxu xun, kishlay jha, lu su, and jing gao.
2018. eann: event adversarial neural networks forin kdd, pagesmulti-modal fake news detection.
849–857.
acm..haoran yan, xiaolong jin, xiangbin meng, jiafengguo, and xueqi cheng.
2019. event detection withmulti-order graph convolution and aggregated atten-tion.
in emnlp/ijcnlp (1), pages 5765–5769.
as-sociation for computational linguistics..wenlin yao, zeyu dai, maitreyi ramaswamy, bonanmin, and ruihong huang.
2020. weakly supervisedin emnlp (1),subevent knowledge acquisition.
pages 5345–5356.
association for computationallinguistics..wen zhang, bibek paudel, liang wang, jiaoyan chen,hai zhu, wei zhang, abraham bernstein, and hua-jun chen.
2019.iteratively learning embeddingsand rules for knowledge graph reasoning.
in www,pages 2366–2377.
acm..ben zhou, qiang ning, daniel khashabi, and danroth.
2020. temporal common sense acquisitionin acl, pages 7579–with minimal supervision.
7589. association for computational linguistics..2837a hierarchical event type schema.
b hierarchical event type schema.
(part 1).
(part 2).
supertype.
subtype.
#instance.
supertype.
subtype.
#instance.
movement.
natural-disaster.
personnel.
proecess.
arrivingbody-movementdepartingmotion-directionalplacingtransport-artifacttransport-persontraveling.
catastrophedamagingdestroying.
change-of-leadershipelectemploymentend-positionnominatestart-position.
confronting-problemprocess-endprocess-startresolve-problem.
earnings-and-lossesexchangegettinggivingreceivingrentingsupplytransaction.
1542140488869815241446937.
397412271445.
93357715688745506.
22517303275157.
11047910676953622161850.table 8: hierarchical event types in ontoevent..conﬂict.
transaction.
collaborationdeclare-bankruptcyend-orgmerge-orgstart-org.
causationcause-change-of-position-on-a-scalecause-change-of-strengthcause-to-amalgamatecause-to-be-includedcause-to-make-progressinﬂuence.
business.
cause-effect.
commerce.
carry-goodscommerce-buycommerce-paycommerce-sellmanufacturing.
attackbearing-armsbesiegingconqueringdefendingescapinghostile-encounterkillingmilitary-operationprotestquarrelingreleasingrescuingrevengesendingterrorismuse-firearmviolence.
broadcastcome-togethercommunicationcontactcorrespondencetelling.
kidnappingrobberytheft.
acquitappealarrestcommitting-crimeconvictcriminal-investigationexecuteextraditionfinejustifyinglegal-rulingspardonprisonrelease-parolesentencesue.
awardbe-bornbodily-harmbreathingcuredeathdivorceeducation-teachingmarryname-conferralrecovering.
contact.
crime.
justice.
life.
2729511541162.
338711381180374850448812.
6264114153411.
3550115312175492395636202030125718521514316264512309538419.
638400582237197195.
1097024.
2712537926526027770148434241106995321196.
711281255788122665132205760337.table 7: hierarchical event types in ontoevent..2838c overview of temporal & causal.
event-event correlations.
e-e relation.
head event type.
tail event type.
personnel.start-positionpersonnel.nominatecommerce.commerce-sellcommerce.manufacturinglife.marrylife.be-bornjustice.arrestjustice.suejustice.criminal-investigationtransaction.transactionproecess.confronting-problemjustice.justifyingjustice.convictjustice.convictjustice.convictjustice.convictjustice.sentencejustice.acquit.
personnel.end-positionpersonnel.electcommerce.commerce-buycommerce.carry-goodslife.divorcelife.name-conferraljustice.prisonjustice.criminal-investigationjustice.legal-rulingstransaction.earnings-and-lossesproecess.resolve-problemjustice.committing-crimejustice.executejustice.finejustice.extraditionjustice.sentencejustice.release-parolejustice.pardon.
movement.arrivingmovement.arrivingmovement.arrivingbusiness.end-orglife.deathlife.cureproecess.process-endjustice.appealconﬂict.escapingconﬂict.bearing-arms.
commerce.commerce-paybusiness.declare-bankruptcybusiness.merge-orgtransaction.gettingtransaction.givingtransaction.rentingmovement.travelingnatural-disaster.damagingmovement.body-movementlife.curejustice.extraditionconﬂict.revengeconﬂict.protestconﬂict.protestconﬂict.protestconﬂict.protestconﬂict.protestconﬂict.protestconﬂict.protestconﬂict.protest.
cause-effect.causationnatural-disaster.catastropheconﬂict.attackconﬂict.killing.
justice.arrestjustice.arrestjustice.arrestjustice.arrestjustice.arrest.
movement.transport-artifactmovement.departingmovement.transport-personbusiness.start-orglife.be-bornlife.bodily-harmproecess.process-startjustice.sueconﬂict.besiegingconﬂict.use-firearm.
commerce.commerce-buybusiness.end-orgbusiness.collaborationtransaction.receivingtransaction.supplytransaction.exchangemovement.transport-personnatural-disaster.destroyingmovement.travelinglife.recoveringjustice.legal-rulingsconﬂict.hostile-encounterconﬂict.quarrelingconﬂict.use-firearmconﬂict.violenceconﬂict.attackconﬂict.killingconﬂict.besiegingconﬂict.conqueringconﬂict.defending.
cause-effect.inﬂuencenatural-disaster.damaginglife.bodily-harmlife.death.
crime.kidnappingcrime.robberycrime.theftconﬂict.attackconﬂict.killing.
before.
after.
equal.
cause.
causedby.
table 9: overview of temporal & causal event-eventcorrelations in ontoevent..2839