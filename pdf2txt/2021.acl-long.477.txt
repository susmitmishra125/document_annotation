xmoco: cross momentum contrastive learningfor open-domain question answering.
nan yang, furu wei, binxing jiao, daxin jiang, linjun yangmicrosoft corporation{nanya,fuwei,binxjia,djiang,linjya}@microsoft.com.
abstract.
dense passage retrieval has been shown to bean effective approach for information retrievaltasks such as open domain question answering.
under this paradigm, a dual-encoder modelis learned to encode questions and passagesseparately into vector representations, and allthe passage vectors are then pre-computed andindexed, which can be efﬁciently retrievedby vector space search during inference time.
in this paper, we propose a new contrastivelearning method called cross momentum con-trastive learning (xmoco), for learning a dual-encoder model for query-passage matching.
our method efﬁciently maintains a large poolof negative samples like the original moco,and by jointly optimizing question-to-passageand passage-to-question matching, enables us-ing separate encoders for questions and pas-sages.
we evaluate our method on variousopen domain qa datasets, and the experimen-tal results show the effectiveness of the pro-posed approach..1.introduction.
retrieving relevant passages given certain queryfrom a large collection of documents is a crucialcomponent in many information retrieval systemssuch as web search and open domain questionanswering (qa).
current qa systems often em-ploy a two-stage pipeline: a retriever is ﬁrstly usedto ﬁnd relevant passages, and then a ﬁne-grainedreader tries to locate the answer in the retrievedpassages.
as recent advancement in machine read-ing comprehension (mrc) has demonstrated ex-cellent results of ﬁnding answers given the correctpassages (wang et al., 2017), the performance ofopen-domain qa systems now relies heavily on therelevance of the selected passages of the retriever.
traditionally the retrievers usually utilize sparsekeywords matching such as tf-idf or bm25.
(robertson and zaragoza, 2009), which can be efﬁ-ciently implemented with an inverted index.
withthe popularization of neural network in nlp, thedense passage retrieval approach has gained trac-tion (karpukhin et al., 2020).
in this approach, adual-encoder model is learned to encode questionsand passages into a dense, low-dimensional vectorspace, where the relevance between questions andpassages can be calculated by the inner productof their respective vectors.
as the vectors of allpassages can be pre-computed and indexed, densepassage retrieval can also be done efﬁciently withvector space search methods during inference time(shrivastava and li, 2014)..dense retrieval models are usually trained withcontrastive objectives between positive and nega-tive question-passage pairs.
as the positive pairsare often given by the training data, one challengein contrastive learning is how to select negativeexamples to avoid mismatch between training andinference.
during inference time, the model needsto ﬁnd the correct passages from a very large set ofpre-computed candidate vectors, but during train-ing, both positive and negative examples need tobe encoded from scratch, thus severely limiting thenumber of negative examples due to computationalcost.
one promising way to reduce the discrepancyis momentum constrastive learning (moco) pro-posed by he et al.
(2020).
in this method, a pairof fast/slow encoders are used to encode questionsand passages, respectively.
the slow encoder isupdated as a slow moving average of the fast en-coder, which reduces the inconsistency of encodedpassage vectors between subsequent training steps,enabling the encoded passages to be stored in alarge queue and reused in later steps as negativeexamples.
unfortunately, directly applying mocoin question-passage matching is problematic.
un-like the image matching tasks in original mocopaper, the questions and passages are distinct from.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6120–6129august1–6,2021.©2021associationforcomputationallinguistics6120each other and not interchangeable.
furthermore,the passages are only encoded by the slow encoder,but the slow encoder is only updated with momen-tum from the fast encoder, not directly affectedby the gradients.
as the fast encoder only seesthe questions, the training becomes insensitive tothe passage representations and fails to learn prop-erly.
to solve this problem, we propose a new con-trastive learning method called cross momentumcontrastive learning (xmoco).
xmoco employstwo sets of fast/slow encoders and jointly optimizesthe question-passage and passage-question match-ing tasks.
it can be applied to scenarios where thequestions and passages require different encoders,while retaining the advantage of efﬁciently main-taining a large number of negative examples.
wetest our method on several open-domain qa tasks,and the experimental results show the effectivenessof the proposed approach..to summarize, the main contributions of this.
work are as follows:.
• we proposes a new momentum contrastivelearning method, cross momentum contrast(xmoco), which can learn question-passagematching where questions and passages re-quire different encoders..• we demonstrate the effectiveness of xmocoin learning a dense passage retrieval modelfor various open domain question answeringdatasets..2 related work.
there are mainly two threads of research work re-lated to this paper..2.1 passage retrieval for qa.
retrieving relevance passages is usually the ﬁrststep in the most qa pipelines.
traditional pas-sage retriever utilizes the keyword-matching basedmethods such as tf-idf and bm25 (chen et al.,2017).
keyword-based approach enjoys its sim-plicity, but often suffers from term mismatch be-tween questions and passages.
such term mismatchproblem can be reduced by either query expansion(carpineto and romano, 2012) or appending gen-erated questions to the passages (nogueira et al.,2019).
dense passage retrieval usually involveslearning a dual-encoder to map both questionsand passages into dense vectors, where their inner-product denotes their relevance (lee et al., 2019)..the challenge in training a dense retriever often liesin how to select negative question-passage pairs.
as a small number of randomly generated negativepairs are considered too easy to differentiate, previ-ous work has mainly focused on how to generate“hard” negatives.
karpukhin et al.
(2020) selectsone negative pair from the top results retrieved bybm25 as hard examples, in addition to one ran-domly sampled pair.
xiong et al.
(2020) uses aniterative approach to gradually produce harder neg-atives by periodically retrieving top passages foreach question using the trained model.
in addi-tion to ﬁnding hard negatives, ding et al.
(2020)also address the problem of false negatives by ﬁl-tering them out using a more accurate, fused inputmodel.
different from the above works, our ap-proach aims to address this problem by enlargingthe pool of negative samples using momentum con-trastive learning, and can be adapted to incorporateharder, cleaner negative samples by other methods..2.2 momentum contrastive learning.
momentum contrastive learning (moco) is orig-inally proposed by he et al.
(2020).
he et al.
(2020) learns image representations by trainingthe model to ﬁnd the heuristically altered imagesamong a large set of other images.
it is later im-proved by constructing better positive pairs (chenet al., 2020).
different from the image counter-part, many nlp tasks has readily available positivepairs such question-passage pairs.
here the mainbeneﬁt of momentum contrastive learning is to ef-ﬁciently maintain a large set of negative samples,thus making the learning process more consistentwith the inference.
one example of applying mo-mentum contrastive learning in nlp is chi et al.
(2020).
in their work, momentum contrastive learn-ing is employed to optimize the infonce lowerbound between parallel sentence pairs from differ-ent languages.
different from the above works, thequestions and passages in our work are not inter-changeable and require different encoders, whichrenders the original moco not directly applicable..3 background.
3.1 task description.
in this paper, we deal with the task of retrievingrelevant passages given certain natural languagequestions.
given a question q and a collection ofn passages {q1, q2, .
.
.
, qn }, a passage retrieveraims to return a list of passages {qi1, qi2, .
.
.
, qim }.
6121ranked by their relevance to q. while the numberof retrieved passages m is usually in the magni-tude of hundreds or thousands, the number of totalpassages n is typically very large, possibly in mil-lions or billions.
such practical concern placesconstraints in model choices of the passage retriev-ers..3.2 dual-encoder framework for dense.
passage retrieval.
the de-facto “go-to” choice for dense passage re-trieval is the dual-encoder approach.
in this frame-work, a pair of encoders eq and ep, usually im-plemented as neural networks, are used to mapthe question q and the passage p into their low-dimensional vectors separately.
the relevance orsimilarity score between q and p is calculated asthe inner product of the two vectors:.
s(q, p) = eq(q) · ep(p).
the advantage of this approach is that the vectors ofall passages can be pre-computed and stored.
dur-ing inference, we only need to compute the vectorfor the question, and the maximum inner productsearch (mips) (shrivastava and li, 2014) can beused to efﬁciently retrieve most relevant passagesfrom a large collection of candidates.
it is possibleto train a more accurate matching model if the q andp are fused into one input sequence, or if a moresophisticated similarity model is used instead ofthe simple inner-product, but those changes wouldno longer permit efﬁcient retrieval, thus can onlybe used in a later “re-ranking” stage..the training data d for passage retrieval con-sists of a collection of positive question-passagepairs {(p1, q1), (p2, q2), .
.
.
, (pn, qn)}, and an ad-ditional m passages {pn+1, .
.
.
, pn+m} withouttheir corresponding questions.
the encoders aretrained to optimize the negative log-likelihood ofall positive pairs:.
l(d, eq, ep) = −.
log.
n(cid:88).
i=1.
exp s(qi, pi)j=1 exp s(qi, pj).
(cid:80)n+m.
as the number of negative pairs (n + m − 1) isvery large, it is infeasible to optimize the loss di-rectly.
instead, only a subset of the negative sam-ples will be selected to compute the denominator inthe above equation.
the selection of the negativesamples is critical to the performance of trainedmodel.
previous works such as xiong et al.
(2020).
and ding et al.
(2020) mainly focus on selecting afew “hard” examples, which hve higher similarityscores with the question and thus contribute moreto the sum in the denominator.
in this work, we willexplore how to use a large set of negative samplesto better approximate the sum in the denominator..4 method.
4.1 momentum contrast for passage retrieval.
we brieﬂy review momentum contrast and explainwhy directly applying momentum contrast for pas-sage retrieval is problematic..momentum contrast method employs a pair ofencoders eq and ep.
for each training step, thetraining pair of qi and pi is encoded as eq(qi) andep(pi) respectively, which is identical to othertraining method.
the key difference is that mo-mentum contrast maintains a queue q of passagevectors {ep(pi−k)}k encoded in previous trainingsteps.
the passage vectors in the queue serve asnegative candidates for the current question qi.
theprocess is computationally efﬁcient since the vec-tors for negative samples are not re-computed, butit also brings the problem of staleness: the vectorsin the queue are computed by the previous, notup-to-date models.
to reduce the inconsistency,momentum contrast uses momentum update on theencoder ep, making ep a slow moving-averagecopy of the question encoder eq.
the gradientfrom the loss function is only directly applied tothe question encoder eq, not the passage encoderep.
after each training step, the newly encodedepi is pushed into the queue and the oldest vector isdiscarded, keeping the queue size constant duringtraining.
such formulation poses no problem forthe original moco paper (he et al., 2020), becausetheir “questions” and “passages” are both imagesand are interchangeable.
unfortunately, in our pas-sage retrieval problem, the questions and passagesare distinct, and it is desirable to use different en-coders eq and ep.
even in scenarios where theparameters of the two encoders can be shared, thepassages are only encoded by the passage encoderep, but the gradient from the loss is not applied onthe passage encoder.
it makes the training processinsensitive to the input passages, thus unable tolearn reasonable representations..4.2.xmoco: cross momentum contrast.
to solve the problems mentioned above, we pro-pose a new momentum contrastive learning method,.
6122(a) moco.
(b) xmoco.
figure 1: illustration of moco and xmoco.
compared with moco, xmoco utilizes two pairs of fast/slow en-coders, employs two separate queues for questions and passages, and jointly optimizes both question-to-passageand passage-to-question matching tasks..q.q.p.p.and eslow.
called cross momentum contrast (xmoco).
xmocoemploys two pairs of encoders: ef astand eslowfor questions; ef astfor passages.
inaddition, two separate queues qq and qp storeprevious encoded vectors for questions and pas-sages, respectively.
in one training step, given apositive pair q and p, the question encoders map qinto ef ast(q) and eslow(q), while the passage en-coders map p into ef ast(p) and eslow(p).
the twovectors encoded by slow encoders are then pushedinto their respective queues qq and qp.
we jointlyoptimize the question-to-passage and passage-to-question tasks by pitting q against all vectors in qqand p against all vectors in qp:.
p.p.q.q.lqp = − log.
exp (ef ast.
q.
(q) · eslow.
(p)).
p.(cid:80).
p(cid:48)∈qp.
exp ef astq.
(q) · eslow.
(p(cid:48)).
p.lpq = − log.
exp (ef ast.
p.(p) · eslow.
(q)).
q.
(cid:80).
q(cid:48)∈qq.
exp ef astp.(p) · eslow.
(q(cid:48)).
q.l = λlqp + (1 − λ)lpq.
where λ is a weight parameter and simply set to 0.5in all experiments in this paper.
like the originalmoco, the gradient update from the loss is onlyapplied to the fast encoders ef ast, whilethe slow encoders esloware updatedwith momentum from the fast encoders:.
and ef astp.and eslow.
p.q.q.eslow.
p ← αef ast.
p + (1 − α)eslow.
p.eslow.
q ← αef ast.
q + (1 − α)eslow.
q.where α controls the update speed of the slow en-coders and is typically set to a small positive value.
when training is ﬁnished, both slow encoders arediscarded, and only the fast encoders are used ininference.
hence, the number of parameters forxmoco is comparable to other dual-encoder meth-ods when employing similar-sized encoders..q.in this framework, the two fast encoders ef astand ef astare not tightly coupled in the gradient up-pdate, but instead inﬂuence other through the slowencoders.
ef astupdates eslowthrough momen-tum updates, which in turn inﬂuences ef astby gra-dient updates from optimizing the loss lqp.
ef astcan also inﬂuence ef astthrough similar path.
seepfig.
1 for illustration..p.p.q.q.
4.3 adaption for batch training.
batch training is the standard training protocol fordeep learning models due to efﬁciency and perfor-mance reasons.
for xmoco, we also expect ourmodel to be trained in batches.
under the batchtraining setting, a batch of positive examples areprocessed together in one training step.
the onlyadaption we need here is to push all vectors com-puted by slow encoders in one batch into the queuestogether.
it effectively mimics the behavior of the“in-batch negative” strategy employed by previousworks such as karpukhin et al.
(2020), where thepassages in one batch will serve as negatives exam-ples for their questions..6123fastencoderslowencoderloss(p,q)gradientupdatemomentumupdatequestion qpassage pq fastencodergradientupdatemomentumupdatequestion qq slowencoderpfastencoderpassageppslowencoderloss(q,p)loss(p,q)4.4 encoders.
we use pre-trained uncased bert-base (devlinet al., 2019) models as our encoders followingkarpukhin et al.
(2020).
the question and passageencoders utilize two sets of different parametersbut are initialized from the same bert-base model.
for both question and passage, we use the vectorsof the sequence start tokens in the last layer as theirrepresentations.
better pre-trained models such asliu et al.
(2019) can lead to better retrieval per-formance, but we choose the uncased bert-basemodel for easier comparison with previous work..4.5.incorporating hard negative examples.
previous work has shown selecting hard examplescan be helpful for training passage retrieval models.
our method can easily incorporate hard negativeexamples by simply adding an additional loss underthe multitask framework:.
lhard.
= − log.
exp (ef astp(cid:48)∈p − (cid:83){p} exp ef ast.
(q) · ef ast.
(p))p(q) · ef ast.
p.q.q.
(cid:80).
(p(cid:48)).
where p is a set of hard negative examples.
theloss only involves the two fast encoders, not theslow encoders.
we only add hard negatives forthe question-to-passage matching tasks, not thepassage-to-question matching tasks.
in addition,we also encode these negative passages using theslow passage encoder eslowand enqueue them topserve as negative passages in calculating loss lqp.
in this work, we only implement a simplemethod of generating hard examples followingkarpukhin et al.
(2020): for each positive pair,we add one hard negative example by randomlysampling from top retrieval results using a bm25retriever.
more elaborate methods of ﬁnding hardexamples such as xiong et al.
(2020) and dinget al.
(2020) can also be included, but we leave itto future work..4.6 removing false negative examples.
false negative examples are passages that canmatch the given question but are falsely labeledas negative examples.
in xmoco formulation, falsenegatives can arise if a previous encoded passagep in the queue can answer current question q. itcan happen if the some questions share the samepassage as answer, or if the same question-passagepair is sampled another time when its previous en-coded vector is still in the queue because the queue.
size can be quite large.
this is especially importantfor datasets with small number of positive pairs.
toﬁx the problem, we keep track of the passage idsin the queue and mask out those passages identicalto the current passage when calculating the loss..labeling issues can also be the source of falsenegative examples as pointed out in ding et al.
(2020).
in their work, an additional model withfused input is trained to reduce the false negatives.
we plan to incorporate such model-based approachin the future..5 experiment.
5.1 wikipedia data as passage retrieval.
candidates.
as many question answering datasets only providepositive pairs of questions and passages, we needto create a large collection of passages for passageretrieval tasks.
following lee et al.
(2019), weextract the passage candidate set from the englishwikipedia dump from dec. 20, 2018. followingthe pre-processing steps in karpukhin et al.
(2020),we ﬁrst extract clean texts using pre-processingcode from drqa (chen et al., 2017), and thensplit each article into non-overlapping chunks of100 tokens as the passages for our retrieval task.
after pre-processing, we get 20,914,125 passagesin total..5.2 question answering datasets.
we use the ﬁve qa datasets from karpukhin et al.
(2020) and follow their training/dev/test splits.
here is a brief description of the datasets..natural questions (nq) (kwiatkowski et al.,2019) is a question answer dataset where the ques-tions were real google search queries and answerswere text spans of wikipedia articles manually se-lected by annotators..triviaqa (joshi et al., 2017) is a set of triviaquestions with their answers.
we use the unﬁlteredversion of triviaqa..webquestions (wq) (berant et al., 2013) is acollection of questions from google suggest apiwith answers from freebase..curatedtrec (trec) (baudiˇs and ˇsediv´y,2015) composes of questions from both trec qatracks and web sources..squad v1.1 (rajpurkar et al., 2016) is originalused as a benchmark for reading comprehension..we follow the same procedure in karpukhin et al.
(2020) to create positive passages for all datasets..6124for triviaqa, wq and trec, we use the highest-ranked passage from bm25 which contains theanswer as positive passage, because these threedatasets do not provide answer passages.
we dis-card questions if answer cannot be found at the top100 bm25 retrieval results.
for nq and squad,we replace the gold passage with the matching pas-sage in our passage candidate set and discard un-matched questions due to differences in processing.
table 1 shows the number of questions in the origi-nal training/dev/test sets and the number of ques-tions in training sets after discarding unmatchedquestions.
note that our numbers are slightly dif-ferent from karpukhin et al.
(2020) due to smalldifferences in the candidate set or the ﬁltering pro-cess..5.3 settings.
following karpukhin et al.
(2020), we test ourmodel on two settings: a “single” setting whereeach dataset is trained separately, and a “multi” set-ting where the training data is combined from nq,triviaqa, wq and trec (excluding squad)..we compare our model against two baselines.
the ﬁrst baseline is the classic bm25 baseline.
the second baseline is the deep passage retrieval(dpr) model from karpukhin et al.
(2020).
wealso implement the setting where the candidatesare re-ranked using a linear combination of bm25and the model similarity score from either dpr orour xmoco model..the evaluation metric for passage retrieval istop-k retrieval accuracy.
here the top-k accuracymeans the percentage of questions which have atleast one passage containing the answer in the top kretrieved passages.
in our experiments, we evaluatethe results on both top-20 and top-100 retrievalaccuracy..5.4.implementation details.
for training, we used batch size of 128 for our mod-els.
for the two small datasets trec and wq, wetrained the model for 100 epochs; for other datasets,we trained the model for 40 epochs.
we used thedev set results to select the ﬁnal checkpoint for test-ing.
the dropout is 0.1 for all encoders.
the queuesize of negative examples in our model is 16, 384.the momentum co-efﬁcient α in the momentumupdate is set to 0.001. we used adam optimizerwith a learning rate of 3e − 5, linear schedulingwith 5% warm-up.
we didn’t do hyperparametersearch.
we follow their speciﬁcation in karpukhin.
et al.
(2020) when re-implementing dpr baselines.
training was done on 16 32gb nvidia gpus, andtook less than 12 hours to train each model..for inference, we use faiss (johnson et al.,2017) for indexing and retrieving passage vectors.
for bm25, we use lucene implementation withb = 0.4 (length normalization) and k1 = 0.9(term frequency scaling) following karpukhin et al.
(2020)..5.5 main results.
we compare our xmoco model with both bm25and dpr baselines over the ﬁve qa datasets.
asshown in table 2, our model out-performs bothbm25 and dpr baselins in most settings whenevaluating on top-20 and top-100 accuracy, exceptsquad where xmoco does slightly worse thanbm25.
the lower performance on squad thanbm25 is consistent with previous observation inkarpukhin et al.
(2020).
all the baseline numbersare our re-implementations and are comparablebut slightly different from the numbers reported inkarpukhin et al.
(2020) due to the difference in thepre-processing and random variations in training.
the results empirically demonstrate that using alarge number of negative samples in xmoco indeedleads to a better retrieval model.
the improvementof top-20 accuracy is larger than that of top-100accuracy, since top-100 accuracy is already reason-ably high for the dpr baselines.
linearly addingbm25 and model scores does not bring consistentimprovement, as xmoco’s performance is signiﬁ-cantly better than bm25 except for squad dataset.
furthermore, combining training data only bringsimprovement on smaller datasets and hurts resultson larger datasets due to domain differences..5.6 ablation study.
we perform all ablation experiments on nq datasetexcept for the end-to-end qa result evaluation..5.6.1 size of the queue of negative samples.
one main assumption of xmoco is that using alarger size of negative samples will lead to a bettermodel for passage retrieval.
here we empiricallystudy the assumption by varying the size of thequeues of negative samples.
the queue size cannotbe reduced to zero because we need at least onenegative sample to compute the contrastive loss.
instead, we use the two times the batch size as theminimal queue size, when the strategy essentiallyreverses to “in-batch negatives” used in previous.
6125dataset.
train (original) train (processed).
dev.
test.
natural questionstriviaqawebquestionscuratedtrecsquad.
79,16878,7853,4171,35378,713.
3,61058,792 8,75760,404 8,837 11,3132,03236169413370,083 8,886 10,570.
2,4701,126.table 1: number of questions in the datasets.
numbers in the training sets are slightly different from the numbersreported in () due to difference in pre-processing..training retriever.
nq triviaqa wq trec squad nq triviaqa wq trec squad.
top-20.
top-100.
none.
bm25.
59.0.single.
multi.
78.6dpr82.3xmocodpr+bm2576.0xmoco+bm25 79.2.dpr79.482.5xmocodpr+bm2578.3xmoco+bm25 80.3.
66.9.
79.080.279.780.1.
78.580.179.680.0.
54.2.
72.276.572.376.6.
74.878.274.976.1.
70.9.
80.180.785.285.8.
89.289.488.788.3.
68.9.
64.365.172.373.0.
52.855.967.268.3.
73.9.
85.386.083.785.2.
85.786.384.085.2.
76.6.
85.185.984.385.2.
84.885.783.584.0.
71.1.
81.283.180.183.0.
82.984.882.182.5.
84.5.
88.989.492.493.1.
93.794.192.193.2.
80.3.
77.177.581.581.2.
68.170.178.779.2.table 2: evaluation results on the ﬁve open domain test sets.
evaluation metric is top-k accuracy which means thepercentage of any passage in the top k retrieval results contain the answer.
“single” denotes the experiments wherethe training is performed on its own training data for each dataset, while “multi” denotes the experiments wherethe training is performed on the combined training sets from nq, triviaqa, wq and trec.
all dpr results arefrom our re-implementation, which are slightly different, but comparable to the numbers reported in the originalpaper..setting.
top-20 top-100.
xmoco+tied encoders.
82.375.4.
86.081.2.table 3: ablation of tied encoders on naturalquestionsdataset.
tying the parameters in the question and pas-sage encoders decreases the performance of xmoco..5.6.2 effect of using two set of encoders.
xmoco formulation expands on the original mo-mentum contrastive learning framework moco byenabling two different set of encoders for questionsand passages respectively.
for open-domain qa,it is unclear whether it is beneﬁcial to use two dif-ferent encoders for questions and passages becauseboth questions and passages are texts.
to empir-ically answer this question, we perform anotherablation experiment where the parameters in thequestion and passage encoders are tied.
as canbe seen in table 3, the model with tied encodersgives reasonable results, but still under-performsthe model with two different encoders.
further-more, the ﬂexibility of xmoco is necessary fortasks such as text-to-image matching where “ques-.
figure 2: the effect of queue size of xmoco.
the re-sults are top-20 accuracy on naturalquestions dataset..works.
as shown in fig.
2, the model performanceincreases as the queue size increases initially, buttapers off past 16k.
this is different from previouswork chi et al.
(2020), where they observe per-formance gains with queue size up to 130k.
onepossible explanation is that the number of trainingpairs is relatively small, thus limiting the effective-ness of the larger queue sizes.
as for computationalefﬁciency, the size of the queue has little impact onboth training speed and memory cost, because bothare dominated by the computation of the encoders..612673747576777879808182832565121k2k4k8k16k32k64ktraining retriever nq triviaqa wq trec squad.
none.
bm25.
single.
multi.
dprxmoco.
dprxmoco.
32.1.
42.142.4.
41.942.4.
50.1.
56.457.1.
56.457.1.
30.4.
35.635.4.
41.241.1.
25.3.
26.126.3.
47.348.1.
39.2.
29.730.1.
24.026.1.table 4: end-to-end qa results..tions” and “passages” are drastically different..6 discussion.
5.6.3 end-to-end qa results.
for some open domain qa tasks, after the relevantpassages are fetched by the retriever, a “reader” isthen applied to the retrieval results to extract ﬁne-grained answer spans.
while improving retrievalaccuracy is an important goal, it is interesting tosee how the improvement would translate into theend-to-end qa results.
following karpukhin et al.
(2020), we implement a simple bert based readerto predict the answer spans.
give a question qand n retrieved passages {p1, .
.
.
, pn }, the readerﬁrst concatenates the question q to each passagepi and predicts the probability of span (p si asthe answer as:.
i , p e.p(i, s, e|q, p1, .
.
.
, pn ) = pr(i|q, p1, .
.
.
, pn ).
× pstart(s|q, pi)× pend(e|q, pi).
where pr is the probability of selecting the ith pas-sage, and pstart, pend are the probabilities of thesth and eth tokens being the answer start and endposition respectively.
pstart and pend is computedby the standard formula in the original bert pa-per (devlin et al., 2019), and the pr is computedby applying softmax over a linear transformationover the vectors of the start tokens of all passages.
we follow the training strategy of karpukhin et al.
(2020), and sample one positive passages and 23negative passages from the top-100 retrieval resultsduring training.
please refer to their paper for thedetails..the results are shown in table 4. while theresults from xmoco are generally better in mostcases, the improvements are marginal comparedto the results of dpr models.
the reason mightbe that the improvement of xmoco over dpr ontop-100 accuracy is not very large, and it mightrequire better reader to ﬁnd out the answer spans..how to select/create negative examples is an es-sential aspect of passage retrieval model training.
xmoco improves passage retrieval model by efﬁ-ciently maintaining a large set of negative exam-ples, while previous works mainly focus on ﬁndinga few hard examples.
it is desirable to design amethod to take the best from both worlds.
as de-scribed in section 4.5, we can combine the twoapproaches under a simple multitask framework.
but this multitask framework also has its draw-backs.
firstly, it loses the computational efﬁciencyof xmoco, especially if the method of generatingthe hard examples is expensive.
secondly, the largeset of negative examples in xmoco and the set ofhard examples are two separate sets, while ideally,we want to maintain a large set of hard negativeexamples.
to this end, one possible direction is toemploy curriculum learning (bengio et al., 2009).
assuming the corresponding passages for similarquestions can serve as hard examples for each other,we can schedule the order of training examples sothat similar questions are trained in adjacent steps,resulting more hard examples to be kept in thequeue.
we plan to explore this possibility in futurework..7 conclusion.
in this paper, we propose cross momentum con-trastive learning (xmoco), for passage retrievaltask in open domain qa.
xmoco jointly opti-mizes question-to-passage and passage-to-questionmatching, enabling using separate encoders forquestions and passages, while efﬁciently maintainsa large pool of negative samples like the originalmoco.
we verify the effectiveness of the proposedmethod on various open domain qa datasets.
forfuture work, we plan to investigate how to betterintegrate hard negative examples into xmoco..6127referencespetr baudiˇs and jan ˇsediv´y.
2015. modeling of thequestion answering task in the yodaqa system.
inproceedings of the 6th international conference onexperimental ir meets multilinguality, multimodal-ity, and interaction - volume 9283, clef’15, page222–228, berlin, heidelberg.
springer-verlag..yoshua bengio, j´erˆome louradour, ronan collobert,and jason weston.
2009. curriculum learning.
inproceedings of the 26th annual international con-ference on machine learning, icml ’09, page41–48, new york, ny, usa.
association for com-puting machinery..jonathan berant, andrew chou, roy frostig, and percyliang.
2013. semantic parsing on freebase fromquestion-answer pairs.
in proceedings of the 2013conference on empirical methods in natural lan-guage processing, pages 1533–1544, seattle, wash-ington, usa.
association for computational lin-guistics..claudio carpineto and giovanni romano.
2012. a sur-vey of automatic query expansion in information re-trieval.
acm comput.
surv., 44(1)..danqi chen, adam fisch, jason weston, and antoinebordes.
2017. reading wikipedia to answer open-in proceedings of the 55th an-domain questions.
nual meeting of the association for computationallinguistics (volume 1: long papers), pages 1870–1879, vancouver, canada.
association for computa-tional linguistics..xinlei chen, haoqi fan, ross girshick, and kaiminghe.
2020. improved baselines with momentum con-trastive learning..zewen chi, li dong, furu wei, nan yang, sakshamsinghal, wenhui wang, xia song, xian-ling mao,heyan huang, and ming zhou.
2020. infoxlm: aninformation-theoretic framework for cross-linguallanguage model pre-training..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..jeff johnson, matthijs douze, and herv´e j´egou.
2017..billion-scale similarity search with gpus..mandar joshi, eunsol choi, daniel s. weld, and lukezettlemoyer.
2017. triviaqa: a large scale distantlysupervised challenge dataset for reading comprehen-sion..vladimir karpukhin, barlas oguz, sewon min, patricklewis, ledell wu, sergey edunov, danqi chen, andwen-tau yih.
2020. dense passage retrieval foropen-domain question answering.
in proceedings ofthe 2020 conference on empirical methods in nat-ural language processing (emnlp), pages 6769–6781, online.
association for computational lin-guistics..tom kwiatkowski, jennimaria palomaki, olivia red-ﬁeld, michael collins, ankur parikh, chris al-berti, danielle epstein, illia polosukhin, jacob de-vlin, kenton lee, kristina toutanova, llion jones,matthew kelcey, ming-wei chang, andrew m. dai,jakob uszkoreit, quoc le, and slav petrov.
2019.natural questions: a benchmark for question an-swering research.
transactions of the associationfor computational linguistics, 7:453–466..kenton lee, ming-wei chang, and kristina toutanova.
2019. latent retrieval for weakly supervised opendomain question answering.
in proceedings of the57th annual meeting of the association for com-putational linguistics, pages 6086–6096, florence,italy.
association for computational linguistics..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach..rodrigo nogueira, wei yang,.
andkyunghyun cho.
2019. document expansion byquery prediction.
corr, abs/1904.08375..jimmy lin,.
pranav rajpurkar, jian zhang, konstantin lopyrev, andpercy liang.
2016. squad: 100,000+ questions formachine comprehension of text.
in proceedings ofthe 2016 conference on empirical methods in natu-ral language processing, pages 2383–2392, austin,texas.
association for computational linguistics..stephen robertson and hugo zaragoza.
2009. theprobabilistic relevance framework: bm25 and be-yond.
found.
trends inf.
retr., 3(4):333–389..yingqi qu yuchen ding, jing liu, kai liu, ruiyangren, xin zhao, daxiang dong, hua wu, andhaifeng wang.
2020. rocketqa: an optimized train-ing approach to dense passage retrieval for open-domain question answering..anshumali shrivastava and ping li.
2014. asymmetriclsh (alsh) for sublinear time maximum inner productin advances in neural informationsearch (mips).
processing systems, volume 27, pages 2321–2329.
curran associates, inc..k. he, h. fan, y. wu, s. xie, and r. girshick.
2020.momentum contrast for unsupervised visual rep-in 2020 ieee/cvf confer-resentation learning.
ence on computer vision and pattern recognition(cvpr), pages 9726–9735..wenhui wang, nan yang, furu wei, baobao chang,and ming zhou.
2017. gated self-matching net-works for reading comprehension and question an-in proceedings of the 55th annual meet-swering.
ing of the association for computational linguistics.
6128(volume 1: long papers), pages 189–198, vancou-ver, canada.
association for computational linguis-tics..lee xiong, chenyan xiong, ye li, kwok-fung tang,jialin liu, paul bennett, junaid ahmed, and arnoldoverwijk.
2020. approximate nearest neighbor neg-ative contrastive learning for dense text retrieval..6129