space efﬁcient context encoding for non-task-orienteddialogue generation with graph attention transformerfabian galetzka1,2,∗, jewgeni rose1,3,∗,†, david schlangen2 and jens lehmann3,41volkswagen innovation center, wolfsburg, germany2computational linguistics, university of potsdam, germany3university of bonn, germany4fraunhofer iais, dresden, germany{jewgeni.rose,fabian.galetzka}@volkswagen.dejens.lehmann@iais.fraunhofer.de.
david.schlangen@uni-potsdam.de.
abstract.
to improve the coherence and knowledge re-trieval capabilities of non-task-oriented dia-logue systems, recent transformer-based mod-els aim to integrate ﬁxed background context.
this often comes in the form of knowledgegraphs, and the integration is done by cre-ating pseudo utterances through paraphrasingknowledge triples, added into the accumulateddialogue context.
however, the context lengthis ﬁxed in these architectures, which restrictshow much background or dialogue context canbe kept.
in this work, we propose a more con-cise encoding for background context struc-tured in the form of knowledge graphs, by ex-pressing the graph connections through restric-tions on the attention weights.
the results ofour human evaluation show that this encod-ing reduces space requirements without nega-tive effects on the precision of reproduction ofknowledge and perceived consistency.
further,models trained with our proposed context en-coding generate dialogues that are judged tobe more comprehensive and interesting..1.introduction.
building on the idea of attention-based seq2seqmodels (vaswani et al., 2017), recent languagemodels such as bert (devlin et al., 2019) andgpt-2 (radford et al., 2019) enable neural conver-sational models to generate responses that appearhuman-like and engaging (yu et al., 2019).
a closerlook, however, reveals that the lack of long-termmemory to represent consistent (world) knowledgeand personality over multiple speaker turns canlead to incoherent content being generated (li et al.,2016; serban et al., 2017).
initiated by the con-versational intelligence challenge (burtsev et al.,2018; dinan et al., 2020), the research focus there-fore shifted towards knowledge-grounded dialogue.
∗the ﬁrst two authors contributed equally to this paper.
† corresponding author.
generation, resulting in ﬁrst promising approachesusing transformer-based architectures (dinan et al.,2019; ghazvininejad et al., 2018; galetzka et al.,2020)..the basic idea of these approaches is to providethe required background knowledge together withthe current dialogue context when decoding thenext system utterance.
as the underlying languagemodel’s input sequence length is limited – for in-stance, to 1024 tokens in the case of gtp-2 – thepresentation of the background knowledge to themodel highly impacts the amount of context infor-mation that can be fed into a transformer network.
in these earlier attempts, the knowledge was para-phrased into pseudo-utterances, on a par with theutterances from the dialogue history.
in this paper,we show that a structured knowledge representa-tion offers advantages over unstructured text: factsand complex relationships between different enti-ties can be encoded concisely without performancedrop in key indicators, such as knowledge correct-ness, consistency, and interestingness.
chaudhuriet al.
(2019) showed the general feasibility of in-tegrating knowledge graphs into domain-speciﬁcdialogues.
with this work, we integrate arbitraryknowledge graphs into open-domain knowledge-grounded dialogues, preserving the informationencoded in their structure..space efﬁcient context encoding for our pro-posed encoding, we generate dialogue-speciﬁc lo-cal knowledge graphs (subgraphs of a backgroundknowledge graph) that capture the information rel-evant to the dialogue (similar to (chaudhuri et al.,2021)).
we transform these subgraphs into a con-cise representation that ﬁts the input sequence en-coding for the underlying language model (gpt-2):labels of the distinct nodes and edges (entities andcorresponding relations) are concatenated with thedialogue history.
to preserve the graph structure,.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages7028–7041august1–6,2021.©2021associationforcomputationallinguistics7028we ﬁt the attention mask to force the self-attentionlayers for each node to attend to only connectednodes in the original graph (if there is a connection,attention weight is set to 1, otherwise to 0).
thisresembles the message-passing approach of graphneural networks (gilmer et al., 2017)..naive concatenation of graph triples has a spacecomplexity of o(n · k), with n being the numberof triples and k the number of word tokens perverbalized triple.
paraphrasing these triples intopseudo-utterances results in even larger space com-plexity.
our proposed encoding has a space com-plexity of o(l), with l being the number of distinctnode and edge labels (entities and relations).
thisreduces the required context space compared totriple concatenation or paraphrasing if entities arerepeated in the triples (and hence l < n · k), whichcan be assumed to be the case in knowledge graphs(see discussion below).
the space savings growwith the size and average degree (connectedness)of the graph.
empirical results with two differentknowledge-grounded dialogue datasets conﬁrm ourtheoretical considerations and show that we canreduce the required space by a factor of up to 3.6.these results imply that we can feed more contextinformation into the model, which should result inhigher accuracy.
we discuss these results in detailin section 4.3..contributions we propose an approach to in-tegrate a concise encoding of knowledge graphsinto a transformer-based decoder architecture forknowledge-grounded dialogue generation.
trans-formers for natural language generation can beviewed as graph neural networks which use self-attention (veliˇckovi´c et al., 2018) for neighborhoodaggregation on fully-connected word graphs (xuet al., 2019).
we utilize this relationship and restrictthe self-attention weights to match the underlyinggraph structure.
our comprehensive human evalu-ation with models trained with the publicly avail-able datasets komodis (galetzka et al., 2020) andopendialkg (moon et al., 2019), both provid-ing dialogues enriched with structured knowledge,shows that we can reduce the space requirement forcontext without negative effects on the precisionof reproduction of knowledge and perceived con-sistency.
moreover, our models generate dialoguesthat are judged to be more detailed and interesting.
for reproducibility, we publish all necessary sourcecode and data (https://github.com/fabiangal/space-efficient-context-encoding-acl21)..2 knowledge-augmented neural.
conversational models.
neural conversational models can be categorizedinto retrieval-based approaches (lowe et al., 2015;wu et al., 2017) that choose a next utterance froma set of suitable candidates, and generative ap-proaches (serban et al., 2016; wolf et al., 2019;chaudhuri et al., 2019; roller et al., 2021) whichdecode the next utterance token by token out of aﬁxed vocabulary.
the architectures are based onrecurrent neural networks such as lstm (hochre-iter and schmidhuber, 1997) or gru (cho et al.,2014) cells or self-attention layers (vaswani et al.,2017) in sequence-to-sequence structures.
to inte-grate knowledge in addition to the dialogue historythese models can be augmented by additional re-current cells to encode the knowledge into a ﬁxed-sized vector representation (young et al., 2018;parthasarathi and pineau, 2020; ghazvininejadet al., 2018).
this can be traced back to ﬁrst end-to-end approaches reading documents for question-answering (miller et al., 2016) or more generalsequential data (sukhbaatar et al., 2015).
he et al.
(2017) embedded knowledge graphs (stored astriples) with lstm cells and message-passing, andthen used a decoder lstm to generate a suitableanswer.
long et al.
(2017) used a cnn architectureto encode external knowledge instead..the recent success of unsupervised pre-trainedlanguage generation models such as gpt-2 yieldeda variety of conversational models using self-attention based on the idea of ﬁne-tuning themodels with speciﬁc knowledge-grounded dia-logue datasets (which we will discuss in sec-tion 3).
these models concatenate the additionalcontext information as plain text to the input se-quence (zhang et al., 2018; dinan et al., 2019;galetzka et al., 2020).
to differentiate contextfrom dialogue, additional tokens are learned duringﬁne-tuning and added to the word tokens.
for big-ger knowledge graphs, the limitation of the inputsequence length of these models makes an informa-tion retrieval system necessary to estimate a smallsubset of relevant information that can be fed intothe model..3 knowledge-grounded dialogue.
datasets.
the increasing availability of conversational con-tent on social media platforms such as twitteror reddit led to the construction of many dia-.
7029figure 1: illustration of the underlying subgraph data model for the external knowledge of a komodis dialoguefor different graphs depths: nodes (green) with their fact-based attributes (blue) and opinions (orange).
subgraphsfor depth 1 and depth 2 are incomplete..logue datasets, with open-subtitles (vinyals andle, 2015) and twitter-corpus (sordoni et al., 2015)being some popular examples (see also (ritter et al.,2010; duplessis et al., 2016))..some recently published datasets emphasizeknowledgeable dialogues by integrating externalinformation sources.
the objective is to create mod-els that generate consistent dialogues with a highknowledge retrieval accuracy (utilizing informa-tion from user proﬁles or knowledge graphs).
di-nan et al.
(2019) released the wizard of wikipediadataset with over 22k open-domain dialogues.
ineach dialogue, one participant is playing the “wiz-ard”, i.e.
an expert who is presented with poten-tially interesting and relevant wikipedia article ex-cerpts, while the chat partner is the curious appren-tice.
the textual knowledge passages that wereshown to the wizard are part of the dataset.
thepersona-chat dataset (zhang et al., 2018) con-tains over 10k dialogues that are conditioned onproﬁle information (personas), which ranges fromhobbies or favorite food to family background.
theinformation is shown to the participants as a setof sentences and they are tasked to integrate theminto the dialogues.
in addition, the dataset containsrevised personas, which are rephrased, generalized,or specialized versions of the original personas..3.1 dialogue datasets with knowledge.
graphs.
we use two publicly available human/human multi-turn dialogue datasets that use structured back-ground knowledge..komodis (galetzka et al., 2020) is a closed-domain dataset with dialogues between human par-ticipants that were tasked to chit-chat about onegiven movie and use provided information about it.
this information includes facts about the ﬁlm, suchas release year or shot location (“movie was shot incanada.” or “the release year is 1995.”), free textcontaining plot or trivia related to the ﬁlm crew andcast, and opinions towards the facts and entities(“i agree with the age restriction.” or “i don’t likebruce willis.”).
the dataset contains over 7,500conversations with an average of 13.8 utterancesper dialogue..opendialkg (moon et al., 2019) is an open-domain dataset containing 15k dialogues, whichwere collected in a wizard-of-oz setup, by connect-ing two human participants that were tasked to havean engaging dialogue about a given topic.
each di-alogue is paired with its corresponding “kg paths”from freebase (bollacker et al., 2007) (connectingentities and relations mentioned in the dialogue)..3.2 subgraph generation.
for our experiments with different encoding strate-gies, we restructure the context information pro-vided by both datasets into dialogue-speciﬁc sub-graphs.
figure 1 illustrates an example of an (in-complete) subgraph that belongs to a dialoguefrom komodis.
the inner subgraph containingthe two green entity nodes ’pulp fiction’ and’bruce willis’, and corresponding attribute nodes(blue), marked as depth 0, represents the informa-tion on which one particular dialogue was based..7030typeactoropinionage certificateshot locationyeartriviaactorgenrepulp fictiontriviatypebruce willismovie1994i like“worked on the film only for 18 days.”actor16united statestypesamuel l.jacksonactoryeartypeopiniongenregoodfellascrimemoviefavourite1990depth 0depth 1depth 2actoractorfigure 2: shortened illustration of the input sequence with encoded context sequence, dialogue history and nextutterance with three layers of embeddings: word, segment and positional embeddings.
the layers are summed upto yield the by-token embeddings..4 graph attention transformer.
4.1 model overview.
for all experiments, we use the gpt-2 model pro-posed by radford et al.
(2019), which is com-monly used in transformer-based dialogue gen-eration for english.
the authors published four dif-ferent sized variations.
we use the model with 117million parameters, 12 self-attention layers, and768-dimensional word embeddings.
the model has12 heads per attention layer and 3072 nodes in allfeed-forward layers.
our architecture is visualizedin figure 3. a knowledge estimator creates a sub-graph from the available knowledge graphs for bothdatasets based on the dialogue history and convertsit using our encoding.
then, the dialogue historyand encoded context sequences are concatenatedand fed into the gpt-2 model.
for training, we op-timize model weights from gpt-2 by minimizingthe negative log-likelihood for next-token predic-tion.
training details are listed in appendix b..4.2 concise graph encoding.
figure 2 shows the general encoding strategythat we propose.
similar to our previous ap-proach (galetzka et al., 2020) and wolf et al.
(2019), we use three layers of input embeddingsfor words, segments and positions.
but insteadof concatenating paraphrased triples (e.g.
(cid:104)‘pulpfiction’, ‘is a’, ‘movie’(cid:105), (cid:104)‘pulp fiction’, ‘releaseyear’, ‘1994’(cid:105)), we convert the graph into uniqueentity-relation pairs (e.g.
(cid:104)‘pulp fiction’, ‘movie’(cid:105),(cid:104)‘1994’, ‘release year’(cid:105) in the leftmost part of theﬁgure) and concatenate them with the dialogue his-tory (middle part in ﬁgure).
in previous work, thesegments layer distinguished context and differentspeakers.
we experiment with two different encod-ing strategies, utilizing the segments layer in otherways.
figure 4 illustrates both encoding strategies.
in the series encoding (upper half of the ﬁgure),relation and entity tokens are sequenced in a se-.
figure 3: model architecture: a knowledge estima-tor creates a subgraph based on the previous conversa-tion.
processed subgraph and input sequence are con-catenated and fed into the gpt-2 decoder.
we experi-ment with different ways of encoding and adding in theknowledge..to test the limits of the capacity for represent-ing knowledge, we also experiment with expandedsubgraphs—depths 1 and depths 2 in the ﬁgure—by including information from external knowledgesources (imdb for komodis, and freebase foropendialkg).
for instance, pulp fiction alsohas samuel l. jackson as an actor (depth 1) whoalso stars in goodfellas (depth 2).
this way, thesubgraph depth directly reﬂects the hop distancefrom the entities in the core subgraph..for subgraphs of depth 2, we restrict some at-tributes and entities to prevent the subgraphs toexplode in size, thus unlikely to ﬁt in gpt-2.
forexample, we don’t add trivia information that isn’talready in the dialogues or limit additional actorsper movie to three.
in contrast to opendialkg,the dialogues in komodis are about one main en-tity (here, the movie) each.
to better compare theexperiments across datasets, we create two versionsof depth 1 for komodis, where depth 1b includesa second movie that is related to the ﬁrst movie(e.g.
by an actor).
this version is then used tocreate the subgraph of depth 2..7031bosmoviemovieyeargenreeoswordssegmentspositionsgraph encodingdialogue historynext utterancebospulpfiction1994crimedoyoulikemovies?yes,ilovepulpfictioneosknowledgeestimatorgpt-2sub-graphdialoghistorygeneratedanswerupdateknowledge graphwhere.
i.j.
· kl−1hl−1.
wij = softmaxj(mj + ql−1hl−1.
),(2)with learnable weights k, q, and v .
equation 1is similar to message-passing algorithms (duve-naud et al., 2015; li et al., 2016; gilmer et al.,2017), where a new hidden state for a graph nodeis computed by an arbitrary function of all previoushidden states of connected nodes.
our attentionmasks mj are added as shown in equation 2 so thatentity and relation tokens can only attend to tokensfrom their neighboring nodes.
this attention mask-ing was originally used for mask out future tokens(setting mi,j for all j > i to the masking value)..figure 5 illustrates the concept with an attentionmask of the graph example from figure 1. here, thenode ‘bruce willis’ (blue) is not connected with therelease year ‘1994’.
thus, the attention weights aremasked out with zeros.
but, it is connected withthe trivia information ‘worked on the movie foronly 18 days’ and these attentions are not masked(ones)..although entities and relations from the knowl-edge graph are position invariant within s, theword order still matters.
therefore, we keep thepositional encoding of the model but shufﬂe theknowledge graph nodes and relations for each train-ing sample to facilitate order invariance of thegraph encoding..4.3 context length requirement.
figure 6 shows the growth of the number of re-quired context tokens when the graph size is in-creased (and hence, more knowledge is providedto the model), for different encoding types.
thebaselines are paraphrased-based encodings, wherebase-triples are the concatenated triples (“pulp fic-tion release year 1994”) and base-paraphrased theverbalized paraphrase (“the movie pulp fictionwas released in 1994”).
for opendialkg, noparaphrased version is available.
for both datasets,the average number of tokens increases with thegraph depth and the average number of nodes andrelations for all encodings, as expected.
however,it grows much slower in the case of our proposedencodings..the increase of required tokens for opendi-alkg is steeper than for komodis, due to thedifferent structure of the dialogue context andthe underlying knowledge graphs.
the contextgraph for opendialkg is initially rather small.
figure 4: illustration of the difference between seriesand parallel encoding with data from the example graphin figure 1..ries and added to the words layer.
two new tokens((cid:104)entity(cid:105) and (cid:104)relation(cid:105)) differentiate between re-lations and entities in the segments layer.
in theparallel encoding, entity tokens are added to thewords layer and according relations to the segmentslayer—thus in parallel.
padding tokens are used toalign the length between the two layers..figure 5: simpliﬁed and shortened illustration of theattention mask for the example graph from figure 1.the node ‘bruce willis’ (highlighted in blue) is con-nected (ones) with the movie ‘pulp fiction’ and thetrivia ‘worked on the ...’.
other nodes (‘i like’, ‘1994’)are masked out (zeros), since they only belong to themovie..this encoding via a segments layer reduces thespace requirements compared to paraphrasing, asrepeating tokens occur only once, but on its ownloses information encoded in the graph structure(node-edge connections).
to preserve this struc-ture information, we create and add a per-graphattention mask to all hidden layers.
given an inputsequence s, the hidden state hli of the i’th token atlayer l in the gpt-2 model can be computed by:.
i = (cid:88)hl.
wij(v l−1hl−1.
),.
j.
(1).
j∈s.
7032bosentityentityrel.entityrel.rel.wordssegmentsbospulpfictionmovie1994releaseyearwordssegmentsbospulpfiction1994<pad>series encodingparallel encodingbosmovie<pad>releaseyearnodesattention maskpulp fiction (1)bruce willis (2)i like (3)1994 (4)“worked on the ...” (n).................................(1)(2)(3)(4)(n).........1111111001101001001011001figure 6: average number of context tokens in the input sequence for different encodings and knowledge graphdepths (komodis from left: d0, d1a, d1b, d2; opendialkg from left: d0, d1, d2).
data extracted from thewhole train subset..and increases very fast with more hops.
further,the komodis context graph contains informationabout plot and trivia, which are normally longerstrings that belong to one entity, thus the beneﬁt ofseries-encoding (series-enc) and parallel-encoding(parallel-enc) regarding this information is rathersmall compared to the baselines.
concluding, thesequence length reduction correlates with the av-erage number of edges per node.
the series-encis between 14% and 30% longer than the parallel-enc, due to representing relation labels within thesegments instead of word embeddings (as shownin figure 4)..5 automated evaluation, and its limits.
we trained 25 models with both datasets withseries-encoding, parallel-encoding, base-triplesand base-paraphrased (only komodis) and withgraph depths d0, d1 and d2.
as we were also in-terested to investigate the effect of different de-coding strategies, we used beam-search and top-k-sampling when generating the dialogues.
thesewere created by four colleagues (who were not in-volved in the creation of the models and did notknow what the innovation was) interacting with themodels.
in sum, we created 500 dialogues..at training time, we use perplexity on the valida-tion subset as the stopping criterion.
table 3 liststhe results for all models estimated on the test set.
base-triples (baselines) models reach the lowestperplexity and an increasing graph depth increasesperplexity, which is reasonable since the format ofthe baseline encodings resembles the pre-training.
data of the gpt-2 model the most.
this corre-lation is stronger for opendialkg models.
inour experiments, perplexity does not correlate withnaturalness (estimated by the human evaluators),indicating that this metric is insufﬁcient to evaluatethe overall dialogue quality, in particular acrossmodels trained on different datasets..in information retrieval, precision/recall and f1score are typically chosen as automated metricsto evaluate the retrieval capabilities of a system.
in our case, we are interested in the ability of re-producing entities and relations from the knowl-edge graph.
commonly used word-overlap met-rics, such as rouge-n/rouge-l (lin, 2004),or bleu (papineni et al., 2001), aren’t capable ofmeasuring these.
evaluating precision and recallrequires precise co-reference resolution, parse treeannotation and question labelling (e.g.
entities, rela-tions, intent).
assume following background factsand generated utterance:.
• (cid:104)‘pulp fiction’, ‘has genre’, ‘crime’(cid:105).
• (cid:104)‘comedy’, ‘bot opinion’, ‘i like’(cid:105).
• “it is a crime movie, but i am more interested.
in comedy ﬁlms.”.
without knowing the intent (asking for the genreof ’pulp fiction’ vs. asking for the preferred genre)of the previous utterance, we cannot determine ifthe occurrences of crime and comedy are true orfalse positives concerning the underlying knowl-edge graph.
moreover, in a conversation knowl-edge is not only used when answering a question.
7033dialogue.
model.
human.
model.
human.
model.
“have you seen ghost, the musical with brad pitt?” genre: drama.
“no, but is the genre really a musical?”.
context.
inference.
neutral.
“yes, it’s a crime and drama movie.”.
genre: drama.
entailment.
“nice.
what is the age certiﬁcate?”.
“the age restriction is 12. i think that’s agood age to watch it .”.
age certiﬁcate: 12age certiﬁcate: agree.
entailmententailment.
human.
“and do you know the budget?”.
model.
“yes, it was $24,000,000.
i think that’s a lotof money for a movie that came out in 1990.”.
budget: 22$ millionyear: 1990.contradictionentailment.
table 1: example of a dialogue from the series-enc-d1 model trained on komodis.
relevant utterance-contextpairs are shown together with annotations from our human evaluators.
line one is labeled with “neutral”, asa “drama” might be a “musical”, the utterance in line three entails with the context regarding the genre and istherefore labeled with “entailment”.
line seven is labeled with “contradiction” as the value of the budget is wrong,but also as “entailment”, as the proactive use of the release year is correct..but also proactively (“did you know that brucewillis worked on the movie only for 18 days?”).
however, the resources that we use offer no suchannotations and to the best of our knowledge, nopublished dataset does.
without it, automated met-rics don’t work well.
to tackle these challenges,we put our effort into a comprehensive human eval-uation and annotation, which is described in thenext section..6 human evaluation.
6.1 method.
participants the evaluation study was managedby researchers not involved in setting up the modelsand experiments.
they recruited 20 participantsnot familiar with our research and the goals of thestudy.
demographic data is given in appendix a.participants were paid for their effort..materials to keep the number of assessed dia-logues manageable, we limited the number of ex-periments and did not test all possible variationsof the factors described in section 5. we preparedthree series of experiments, aimed at evaluating theinﬂuence of decoding algorithms, encoding strate-gies and graph depths.
early samples indicatedthat beam-search generates more precise dialoguesregarding context.
we, therefore, decided to evalu-ate the decoding algorithm series beforehand.
asshown in section 6.2 our hypothesis proved to becorrect, so that the other two series of experimentswere done with beam-search only..procedure all participants were instructed be-fore and supervised during the study by a super-visor to ensure their understanding of the metrics.
they were given a participant-speciﬁc question-naire with the human/chatbot dialogues and hadto perform three tasks.
first, mark utterances thateither entail (correct use) or contradict (wrong use)the dialogue context.
based on these annotationswe measure the model’s knowledge retrieval abilityas the ratio between entailing utterances and thesum of entailing and contradicting utterances (pre-cision).
second, rate the dialogues with the follow-ing statements for agreement on a 7-point likertscale: (1) person b sounds natural.
(2) person bsounds consistent.
(3) person b sounds interesting.
person b is always a model, person a a human.
last, choose between two dialogues, by answering:“to which person b would you prefer to talk?”.
additionally, the participants could brieﬂy reasontheir decision.
an example questionnaire can befound in appendix a..6.2 results and discussion.
decoding table 2 shows the results for beam-search and top-k-sampling decoding.
knowledgeprecision is better with beam-search for all mod-els, while dialogues generated with top-k-samplingare considered more natural, less self-contradicting,and less repetitive.
n-gram ﬁltering reduces repeti-tion through beam-search, but could not be avoidedcompletely.
decoding with top-k-sampling in-cludes more often wrong entity nouns when es-.
7034experiment.
knowledge precision.
naturalness.
base-triples.
series-enc-d1 base-triples.
series-enc-d1.
komodis beam-searchkomodis top-k-sampling.
opendialkg beam-searchopendialkg top-k-sampling.
0.690.52.
0.730.54.
0.740.56.
0.700.45.
5.0 (1.5)5.9 (1.2).
4.0 (1.6)5.3 (1.4).
4.8 (1.6)5.9 (1.3).
3.4 (1.5)5.4 (1.3).
table 2: human evaluation results for beam-search and top-k-sampling, with respect to the correct reproductionof dialogue context.
precision as the ratio between entailing utterances and the sum of entailing and contradictingutterances.
naturalness on a 7-point likert scale.
higher is better.
standard deviation in brackets..experiment.
ppl.
winratio (%).
precision.
knowledge.
opinions.
natural.
interesting.
agreementsconsistent.
komodis.
opendialkg.
base-paraphrasedbase-triples.
series-enc-d1series-enc-d2parallel-enc-d1parallel-enc-d2.
base-triples.
series-enc-d1series-enc-d2parallel-enc-d1parallel-enc-d2.
10.39.73.
10.0110.2810.0710.36.
8.40.
9.9310.539.8810.44.
12.543.8.
66.762.556.360.0.
65.0.
66.751.338.532.5.
0.740.69.
0.740.730.700.72.
0.73.
0.620.460.700.62.
0.500.71.
0.360.430.330.57.
—.
————.
4.7 (1.7)5.0 (1.5).
4.8 (1.7)4.8 (1.7)4.5 (1.7)4.8 (1.5).
4.1 (1.7)4.0 (2.0).
4.5 (1.9)4.2 (1.6)4.5 (1.2)4.6 (1.5).
3.9 (1.9)3.7 (1.7)3.4 (1.6)3.4 (1.9).
4.1 (1.9)4.0 (2.0)3.2 (1.8)3.6 (1.9).
4.2 (1.2)4.6 (1.1).
4.9 (1.1)4.4 (1.2)4.5 (1.1)4.5 (1.2).
3.5 (1.9)3.8 (1.6)3.0 (1.3)3.3 (1.6).
4.0 (1.6).
3.9 (1.6).
3.6 (1.6).
table 3: perplexity on the test set (lower is better) and human evaluation results for models trained on both datasets.
metrics explained in section 6.1. agreements are on a 7-point likert scale (higher is better).
standard deviationin brackets.
“base-*” are the baseline models; “series/parallel-enc-*” denotes the way the knowledge is encodedand “-*d1/d2” is the depth of the graphs..timating the best next tokens, which are then se-lected by the algorithm.
in this work, we emphasizethe model’s ability to integrate additional dialoguecontext correctly.
here, models with beam-searchperform signiﬁcantly better.
thus, our further eval-uation focuses on beam-search..graph encoding the results with series and par-allel graph encodings are shown in table 3 and com-pared against the baselines.
within each dataset,all models perform similar regarding knowledgeprecision.
due to the high standard deviation onthe agreements, the difference between the mod-els is statistically insigniﬁcant.
our graph encod-ing approach reduces the required input sequencelength by a factor of up to 3.6 and still achieves thesame quality of knowledge reproduction, consis-tency, and naturalness as the baselines.
further, thedirect dialogue comparison (win ratio) indicatesmore comprehensive and interesting utterances forkomodis.
dialogue preference correlates high-est with interestingness and non-existence of con-.
tradicting statements.
the most common reasonsfrom participants in no speciﬁc order are “longerand more comprehensive utterances”, “more inter-esting”, “asks counter questions” and “more pleas-ant”.
the opendialkg models perform worsein general but show similar results between the dif-ferent encodings.
both datasets have similar sizesbut opendialkg is not limited to the movie do-main, which makes it harder to train compared tokomodis..series vs. parallel encoding a quick summary:the segments layer encodes the typing of the wordtokens (from the words layer).
the intuition be-hind it is that the model learns the meaning of thewords instead of the word distribution alone.
forthe series encoding, we encode the types generi-cally as either entity or relation.
for the parallelencoding, we use the actual typing from the under-lying knowledge graph, such as movie, actor, orrelease year (section 4.2).
we had two objectives.
first, reducing the required context space even fur-.
7035ther (which we achieved, see figure 6).
second,analyzing if this improves the accuracy.
the re-sults show, that parallel encoding performs slightlyworse compared to series encoding.
we assumethat this is the case due to the lack of training data,which is, in particular, evident for opendialkgthat has much more entity and relation types thankomodis, i.e.
fewer samples per type..graph depth results for training with differentcontext lengths with komodis are shown in ta-ble 4. all metrics (one outlier for opinion precisionwith d = 1) correlate with increasing graph depth.
results for d = 2, however, are statistically notsigniﬁcantly higher than for d = 1. a bigger sub-graph leads to more difﬁcult training data, as themodel has more options to choose from.
the sameresults couldn’t be reproduced for opendialkg.
this dataset was created for graph generation basedon dialogues.
however, the dialogue structure isdifferent due to the recommendation task of thedata collection.
most entities in these dialogues(e.g.
persons, books, movies) are exchangeable(“can you recommend me a crime book similarto x?”, “can you recommend me a crime moviesimilar to y?”) and therefore not mandatory for acorrect and consistent dialogue.
adding more ofthese entities did not help to determine a correctnext entity, as all entities of the same type could beused correctly by the model..effectiveness of graph attention maskinggraph masking encodes the relationships betweenthe entities.
we hypothesize that dropping theserelationships will lead to an information gap, par-ticularly for bigger subgraphs due to more entitiesthat are not represented (well) in the training data.
table 5 shows the results from an early evalua-tion phase for komodis and opendialkg withgraph depth 1 and 2 without graph masking.
thedialogues are signiﬁcantly worse, in particular interms of reproducing entities correctly for graphdepth 2 – which validates our hypothesis.
as ourresources were limited, we had to reduce the num-ber of models for a thorough human evaluationand thus decided to not pursue this approach anylonger..7 conclusion.
metric.
d0.
d1.
d2.
knowledge precisionopinion precisionnaturalnesswin-ratio (%).
0.560.424.528.6.
0.700.334.556.3.
0.7210.574.8160.01.table 4: inﬂuence of graph depth on various metricsfrom the human evaluation for the parallel-enc modeltrained on komodis.
1statistically not signiﬁcant com-pared to d1..experiment.
knowledge.
opinions naturalness.
komodis d2komodis d1.
opendialkg d2opendialkg d1.
0.440.61.
0.370.54.
0.250.46.
——.
4.44.1.
3.83.9.table 5: results from a pre-evaluation for models with-out graph attention masking.
there are no opinions inthe case of opendialkg.
knowledge and opinionsas precision (ratio between entailing utterances and thesum of entailing and contradicting utterances).
natural-ness on a 7-point likert scale.
higher is better.
stan-dard deviation in brackets..for consistent non-goal-driven dialogue generation.
in our encoding, we reduce the context length byavoiding repetition by concatenating the wholetriples with the dialogue history.
by manipulat-ing self-attention layers to reﬂect connections be-tween nodes in the graphs, we preserve the graphstructure.
the evaluation results prove that ourencoding reduces space requirements without neg-ative effects on the precision of reproduction ofknowledge and perceived consistency.
for repro-ducibility, we publish the source code and data..acknowledgements.
we thank our colleagues from the digital assis-tant for mobility team at the volkswagen groupinnovation europe for their support in preparingthe human evaluation..references.
kurt bollacker, robert cook, and patrick tufts.
2007.freebase: a shared database of structured generalhuman knowledge.
proceedings of the national con-ference on artiﬁcial intelligence, 22(2):1962..we proposed a new and concise encoding forknowledge triples from a knowledge graph, whichcan be integrated into a transformer architecture.
mikhail burtsev, varvara logacheva, valentin malykh,iulian vlad serban, ryan lowe, shrimai prabhu-moye, alan w black, alexander rudnicky, and.
7036yoshua bengio.
2018. the ﬁrst conversational in-telligence challenge.
in the nips’17 competition:building intelligent systems, pages 25–46.
springer..debanjan chaudhuri, md rashad al hasan rony, si-mon jordan, and jens lehmann.
2019. using a kg-copy network for non-goal oriented dialogues.
lecture notes in computer science (including sub-series lecture notes in artiﬁcial intelligence andlecture notes in bioinformatics), 11778 lncs:93–109..debanjan chaudhuri, md rashad al hasan rony, andjens lehmann.
2021. grounding dialogue systemsvia knowledge graph aware decoding with pre-trained transformers.
pages 1–16..kyunghyun cho, bart van merri¨enboer, caglar gul-cehre, dzmitry bahdanau, fethi bougares, holgerschwenk, and yoshua bengio.
2014.learningphrase representations using rnn encoder-decoderfor statistical machine translation.
emnlp 2014- 2014 conference on empirical methods in natu-ral language processing, proceedings of the con-ference, pages 1724–1734..jacob devlin, ming wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in naacl hlt 2019 - 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies - proceedings of the conference, volume 1,pages 4171–4186..emily dinan, varvara logacheva, valentin ma-lykh, alexander miller, kurt shuster, jack ur-banek, douwe kiela, arthur szlam, iulian serban,ryan lowe, shrimai prabhumoye, alan w. black,alexander rudnicky, jason williams, joelle pineau,mikhail burtsev, jason weston, and others.
2020.the second conversationalintelligence challengein the neurips’18 competition, pages(convai2).
187–208.
springer..emily dinan, stephen roller, kurt shuster, an-gela fan, michael auli, and jason weston.
2019.of wikipedia: knowledge-powered conversationalagents.
7th international conference on learningrepresentations, iclr 2019, pages 1–18..fabian galetzka, chukwuemeka uchenna eneh, anddavid schlangen.
2020. a corpus of controlledopinionated and knowledgeable movie discussionsfor training neural conversation models.
proceed-ings of the 12th language resources and evalua-tion conference, (may):565–573..marjan ghazvininejad, chris brockett, ming weichang, bill dolan, jianfeng gao, wen tau yih, andmichel galley.
2018. a knowledge-grounded neuralconversation model.
32nd aaai conference on arti-ﬁcial intelligence, aaai 2018, pages 5110–5117..justin gilmer, samuel s. schoenholz, patrick f. riley,oriol vinyals, and george e. dahl.
2017. neuralmessage passing for quantum chemistry.
34th in-ternational conference on machine learning, icml2017, 3:2053–2070..he he, anusha balakrishnan, mihail eric, and percyliang.
2017. learning symmetric collaborative dia-logue agents with dynamic knowledge graph embed-dings.
acl 2017 - 55th annual meeting of the asso-ciation for computational linguistics, proceedingsof the conference (long papers), 1:1766–1776..sepp hochreiter and j¨urgen schmidhuber.
1997.long short-term memory.
neural computation,9(8):1735–1780..yujia li, richard zemel, marc brockschmidt, anddaniel tarlow.
2016. gated graph sequence neuralnetworks.
4th international conference on learn-ing representations, iclr 2016 - conference trackproceedings, (1):1–20..c y lin.
2004. rouge: a package for automatic eval-uation of summaries.
proceedings of the workshopon text summarization branches out (was 2004)..yinong long, jianan wang, zhen xu, zongshengwang, baoxun wang, and zhuoran wang.
2017.a knowledge enhanced generative conversationalservice agent.
dstc6 conference, pages 1–5..ryan lowe, nissan pow, iulian v. serban, and joellepineau.
2015. the ubuntu dialogue corpus: alarge dataset for research in unstructured multi-turndialogue systems.
sigdial 2015 - 16th annualmeeting of the special interest group on discourseand dialogue, proceedings of the conference, pages285–294..guillaume dubuisson duplessis, vincent letard,anne laure ligozat, and sophie rosset.
2016.purely corpus-based automatic conversation author-ing.
proceedings of the 10th international confer-ence on language resources and evaluation, lrec2016, pages 2728–2735..alexander h. miller, adam fisch,.
jesse dodge,amir hossein karimi, antoine bordes, and jasonweston.
2016. key-value memory networks for di-rectly reading documents.
emnlp 2016 - confer-ence on empirical methods in natural languageprocessing, proceedings, pages 1400–1409..david duvenaud, dougal maclaurin, jorge aguilera-iparraguirre, rafael g´omez-bombarelli, timothyhirzel, al´an aspuru-guzik, and ryan p. adams.
2015. convolutional networks on graphs for learn-advances in neuraling molecular ﬁngerprints.
information processing systems, 2015-janua:2224–2232..seungwhan moon, pararth shah, anuj kumar, and ra-jen subba.
2019. opendialkg: explainable conver-sational reasoning with attention-based walks overknowledge graphs.
in proceedings of the 57th an-nual meeting of the association for computationallinguistics, pages 845–854, florence, italy.
associ-ation for computational linguistics..7037kaiser, and illia polosukhin.
2017. attention is allyou need.
advances in neural information process-ing systems, 2017-decem(nips):5999–6009..petar veliˇckovi´c, arantxa casanova, pietro li`o,guillem cucurull, adriana romero, and yoshuabengio.
2018. graph attention networks.
6th inter-national conference on learning representations,iclr 2018 - conference track proceedings, pages1–12..oriol vinyals and quoc le.
2015. a neural conversa-.
tional model.
37..thomas wolf, victor sanh, julien chaumond, andclement delangue.
2019. transfertransfo: a trans-fer learning approach for neural network basedconversational agents.
(ii)..yu wu, wei wu, chen xing, zhoujun li, and mingsequential matching network: azhou.
2017.new architecture for multi-turn response selection inretrieval-based chatbots.
acl 2017 - 55th annualmeeting of the association for computational lin-guistics, proceedings of the conference (long pa-pers), 1:496–505..peng xu, chaitanya k. joshi, and xavier bresson.
2019. multi-graph transformer for free-handsketch recognition..tom young, erik cambria, iti chaturvedi, hao zhou,subham biswas, and minlie huang.
2018. aug-menting end-to-end dialogue systems with common-sense knowledge.
32nd aaai conference on artiﬁ-cial intelligence, aaai 2018, pages 4970–4977..dian yu, michelle cohn, yi mang yang, chun yenchen, weiming wen, jiaping zhang, mingyangzhou, kevin jesse, austin chau, antara bhowmick,shreenath iyer, giritheja sreenivasulu, sam david-son, ashwin bhandare, and zhou yu.
2019. gun-rock: a social bot for complex and engaging longconversations.
in proceedings of the 2019 confer-ence on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp): system demonstrations, pages 79–84,stroudsburg, pa, usa.
association for computa-tional linguistics..saizheng zhang, emily dinan, jack urbanek, arthurszlam, douwe kiela, and jason weston.
2018. per-sonalizing dialogue agents: i have a dog, do youhave pets too?
acl 2018 - 56th annual meeting ofthe association for computational linguistics, pro-ceedings of the conference (long papers), 1:2204–2213..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2001. bleu: a method for automatic eval-uation of machine translation.
in acl, volume 371,pages 311–318, morristown, nj, usa.
associationfor computational linguistics..prasanna parthasarathi and joelle pineau.
2020. ex-tending neural generative conversational model us-ing external knowledge sources.
proceedings ofthe 2018 conference on empirical methods in natu-ral language processing, emnlp 2018, pages 690–695..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners.
openaiblog, 1(8):9..alan ritter, colin cherry, and bill dolan.
2010.unsupervised modeling of twitter conversations.
naacl hlt 2010 - human language technologies:the 2010 annual conference of the north ameri-can chapter of the association for computationallinguistics, proceedings of the main conference,(june):172–180..stephen roller, emily dinan, naman goyal, da ju,mary williamson, yinhan liu, jing xu, myle ott,eric michael smith, y-lan boureau, and jason we-ston.
2021. recipes for building an open-domainchatbot.
in proceedings of the 16th conference ofthe european chapter of the association for compu-tational linguistics: main volume, pages 300–325,online.
association for computational linguistics..iulian v. serban, alessandro sordoni, yoshua bengio,aaron courville, and joelle pineau.
2016. buildingend-to-end dialogue systems using generative hier-archical neural network models.
30th aaai con-ference on artiﬁcial intelligence, aaai 2016, pages3776–3783..iulian vlad serban, alessandro sordoni, laurent char-lin, joelle pineau, aaron courville, and yoshuabengio.
2017.a hierarchical latent variableencoder-decoder model for generating dialogues.
aaai2017, pages 3295–3301..alessandro sordoni, michel galley, michael auli,chris brockett, yangfeng ji, margaret mitchell,jian yun nie, jianfeng gao, and bill dolan.
2015. aneural network approach to context-sensitive genera-tion of conversational responses.
naacl hlt 2015- 2015 conference of the north american chapterof the association for computational linguistics:human language technologies, proceedings of theconference, pages 196–205..sainbayar sukhbaatar, arthur szlam, jason weston,and rob fergus.
2015. end-to-end memory net-works.
advances in neural information processingsystems, 2015-janua:2440–2448..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, łukasz.
7038with the next sentence classiﬁer loss.
each mini-batch consists of 32 sequences of up to 256 tokens(padded to maximum length).
if dialogue historyexceeds maximum sequence length, the ﬁrst ut-terances are cut off.
for each sample, only thetokens from the last utterance are considered forthe language modeling loss.
encoded nodes andedges are shufﬂed randomly for each sample, notfor each dialogue.
we used a cluster of 4 geforcertx 2080 titan to train our models with batch dis-tribution and gradient accumulation to handle themini-batch size.
based on graph depth an epochtook up to 4 hours.
we trained the models for 7 to10 epochs.
our graph encoding approaches tooklonger to converge, compared to the baselines..c dialogue examples.
we show three additional typical dialogue exam-ples for both models in tables 6, 7 and 8. theycontain entailing and contradicting statements re-garding the context.
the inconsistent opinion intable 8 (correct in line 4, but incorrect in line 6)was observed more often.
for both datasets, wesometimes observe slight misspellings of entities(see table 8, line 6, ‘charlie chaplin’ and ‘charleschaplin’).
we left the decision, whether this is acontradiction (a wrong entity) or not (a misspelling)to the participants.
another issue that occurred mul-tiple times, is the wrong use of repeated entities(see figure 7 with ‘julia roberts’ in line 6).
mod-els trained with opendialkg also sometimes useentities that are not in the knowledge graph (seetable 7, line 4 ‘the player’)..a human evaluation.
demographic data 45% of the 20 participantsare women.
75% of the participants stated thatthey already have experience with various forms ofchatbots.
due to data privacy reasons, age infor-mation is classiﬁed into three different categories.
65% of the participants are 18–35 years old, 20%36–50 years, and three participants are older than50 years..questionnaire the questionnaire contains a sur-vey guide and a set of dialogue pairs to evaluate.
an example dialogue pair is shown in figure 7. la-bels were added by the authors.
the survey guideconsists of four pages with examples and explana-tions for the participants.
the following excerptsare from the guide..general instructions: following, you are pre-sented with two dialogues between person a andperson b with according background information.
the dialogues are completely independent of eachother.
you must read both dialogues carefully.
please take time for this task..instructions for evaluating the knowledge andopinion precision: please remember that the evalu-ation is for person b only!
please add ‘entailment’to the ﬁelds, when the utterance entails a speciﬁcfact or opinion.
please add ‘contradiction’ if anutterance contradicts a speciﬁc fact or opinion.
please leave all other ﬁelds empty..instructions for rating the dialogues on the 7-point likert scale: please rate the three statementsfor each dialogue on a scale from 1 to 7, where 1means that you strongly disagree with it and 7 thatyou strongly agree with it.
please rate all state-ments independently from the given facts and opin-ions.
for instance, if a dialogue contains wrongfacts, it still can sound very natural..instructions for deciding between two dialogues:please rate intuitively with which person b youwould prefer to talk.
please reason your decisionbrieﬂy..all instructions are provided with examples..b training details.
for ﬁne-tuning gpt-2, we reused most training pa-rameters from the generative pre-training (radfordet al., 2019).
the learning rate linearly decreasesto zero with an initial value of lr = 6.25e−6 withmax-norm gradient clipping.
the language mod-eling loss is multiplied by 2 before summed up.
7039.
eriannoitseuq.eht.morf.riap.eugolaid.eno.fo.elpmaxe.:7.erugi.f.7040dialoguesarfarosh is of genre action.smita jaykar has trivia: often plays the role of the mother in bollywood movies.sonali bendre is an actor in sarfarosh.sarfarosh was released in 1999.action is not a good genre.sonali bendre is very good.i like sarfarosh very much.with which person b would you prefer to talk?why?person b sounds naturalperson b sounds consistentperson b sounds interesting1ahey, how are you?
i watched sarfaroshyesterday.contradiction2it would be more interesting to talk to the second person.534bi'mgood thanks... yourself?.
idon't know that movie actually... what's it about?
ai am good!
it's an action movie with sonalibendre.entailmententailmentboh okay cool... sounds like it might be a good one to watch with your kids.
awhy do you think so?
entailmententailmentcontradictionbidon't really care for action movies... so maybe that's why ididn't care for this one.
awhat do you like?entailmentbijust don't think it's a good genre to be a part of... idon't like action movies either.
bill raymond is an actor in twelve monkeys.twelve monkeys is of genre sci-fi.twelve monkeys was released in 1995.twelve monkeys is of genre mystery.age restriction: i agree.i like bill raymond very much.
'twelve monkeys' is good.2ahey, how are you?646bi'mgood.
ijust watched a movie called "twelve monkeys".
have you seen it?
ayes, but i didn't like it.entailmentbreally?
ithought it was pretty good.
abill raymond is such a good actor!entailmentcontradictionbidon't really like bill raymond, but he did a good job in this movie.
ado you know the release year?entailmentbibelieve it was 1995. do you know what the budget was for this movie by any chance?
dialogue.
context.
inference.
human “i am a fan of fc bayern munich!”.
model.
“they are a good team.
they are in the allianz arena right now building: allianz arenaand they are playing in the bundesliga, do you like them?”.
team: fc bayern munich.
neutralentailment.
human “yes i do, what is the allianz arena?”.
model.
“it is a building of the fc bayern munich and was built bymark van bommel.”.
building: allianz arenaplayer: mark van bommel.
entailmentcontradiction.
human “did they participate in the uefa champions league?”.
model.
“yes, they did.
it is the team that won the 2012-13champions league.”.
champions league 2012-13champion: fc bayern munich.
entailment.
table 6: example of a dialogue from the series-enc-d1 model trained on opendialkg.
relevant utterance-context pairs are shown with gathered labels from our human evaluation..dialogue.
context.
inference.
human “do you recommend pretty woman?”.
model.
“pretty woman is starring hank azaria.
do you like him?”.
human “yes, who else plays in the movie?”.
has actor: hank azaria.
entailment.
model.
“julia roberts is also in pretty woman.
she is married todaniel moder, who also starred in the player and a few others.” j. roberts spouse: daniel moder.
has actor: julia roberts.
entailmententailment.
human “do they have children?”.
model.
“yes, they have a daughter named julia roberts.”.
j. roberts has child: henry.
contradiction.
table 7: example of a dialogue from the series-enc-d1 model trained on opendialkg.
relevant utterance-context pairs are shown with gathered labels from our human evaluation..dialogue.
human “hey, what’s up?”.
model.
“not much.
i just watched a movie calledcity lights, have you seen it?”.
human “no, what genre is it?”.
context.
inference.
model.
“it is a drama and family movie.
i really likedrama movies, but this one didn’t do it for me.”.
genre: dramacity lights: don’t like.
entailmententailment.
human “so you wouldn’t recommend it?”.
“i think charlie chaplin is a bad director, but he did a goodjob with this movie.”.
model.
director: charles chaplincharles chaplin: don’t likecity lights: don’t like.
entailmententailmentcontradiction.
human “what else do you know about him?”.
model.
“i don’t know much about him, but he cofoundedthe distribution company united artists in 1919.”.
charles chaplin has trivia:co-founded the ... in 1919..entailment.
table 8: example of a dialogue from the series-enc-d1 model trained on komodis.
relevant utterance-contextpairs are shown with gathered labels from our human evaluation..7041