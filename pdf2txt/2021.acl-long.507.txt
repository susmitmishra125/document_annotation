ccmatrix:mining billions of high-quality parallel sentences on the web.
holger schwenk and guillaume wenzek and sergey edunovedouard grave and armand joulin and angela fanfacebook ai{schwenk,guw,edunov,egrave,ajoulin,angelafan}@fb.com.
abstract.
we show that margin-based bitext mining ina multilingual sentence space can be success-fully scaled to operate on monolingual cor-pora of billions of sentences.
we use 32 com-mon crawl snapshots (wenzek et al., 2019), to-talling 71 billion unique sentences.
using oneuniﬁed approach for 90 languages, we wereable to mine 10.8 billion parallel sentences,out of which only 2.9 billions are aligned withenglish.
we illustrate the capability of ourscalable mining system to create high qual-ity training sets from one language to anyother by training hundreds of different ma-chine translation models and evaluating themon the many-to-many ted benchmark.
fur-ther, we evaluate on competitive translationbenchmarks such as wmt and wat.
usingonly mined bitext, we set a new state of the artfor a single system on the wmt’19 test set forenglish-german/russian/chinese.
in particu-lar, our english/german and english/russiansystems outperform the best single ones byover 4 bleu points and are on par with bestwmt’19 systems, which train on the wmttraining data and augment it with backtrans-lation.
we also achieve excellent results fordistant languages pairs like russian/japanese,outperforming the best submission at the 2020wat workshop.
all of the mined bitext willbe freely available..1.introduction.
parallel data, i.e.
sentences in two languages whichare mutual translations, are a crucial resource formany multilingual natural language processingtasks.
traditionally, high quality parallel texts areobtained from the publications of international or-ganizations like the the united nations (ziemskiet al., 2016) or the european parliament (koehn,2005).
these are professional human translations,but they are in a more formal language and tendto be limited to political topics.
another direction.
is to rely on volunteers to provide translations forpublic texts, such as the ted corpus (qi et al.,2018), news commentary (tiedemann, 2012) oropensubtitles (lison and tiedemann, 2016), butthis approach lacks scalability..there is also a large body of works which aimsin mining bitexts by comparing huge collectionsof monolingual data.
our aim is to mine at mas-sive scale, both in number of possible languagesand in quantity of mined parallel sentences.
mostexisting large scale bitext mining techniques use ahierarchical approach.
first, a subset of texts thatmay contain parallel sentences are selected at thedocument level.
subsequently, sentences withinthese aligned documents are compared to identifyparallel ones.
this local mining is potentially fastsince only a few thousand sentences need to becompared for each document pair.
however, sen-tences not present in these pre-selected documentscannot be aligned, which vastly limits the quan-tity of mineable bitext.
a ﬁrst system to globallycompare all sentences in monolingual collectionsfor many language pairs was presented in schwenket al.
(2019), but was limited to only wikipedia..in this paper, we show that this type of globalmining scales to extremely huge corpora: 71 bil-lion sentences, about 120x larger than the work ofschwenk et al.
(2019).
our contributions are:.
• development of a new highly efﬁcient and par-allelized processing pipeline to confront thesubstantial computational challenge;.
• unprecedented size: 10.8 billion mined paral-.
lel sentences in 90 different languages;.
• all these resources are freely available;.
• we demonstrate the quality of our mined dataon a variety of machine translation bench-marks, such as ted, wmt, and wat, achiev-ing highly competitive results..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6490–6500august1–6,2021.©2021associationforcomputationallinguistics64902 related work.
much previous work has explored the automaticcreation of parallel data from monolingual re-sources.
in this section, we detail various ap-proaches and illustrate the differences of our al-gorithmic approach and the scale of our mining..mining methodology at the start, various ap-proaches used alignment on information beyondtext itself, such as with document metadata (resnik,1999; resnik and smith, 2003).
later, workaligned based on text with techniques such asjaccard similarity (etchegoyhen and azpeitia,2016; azpeitia et al., 2017, 2018), crosslingualdocument retrieval (utiyama and isahara, 2003;language mod-munteanu and marcu, 2005),els (buck and koehn, 2016), translation (abdul-rauf and schwenk, 2009; bouamor and sajjad,2018), or bag-of-words (buck and koehn, 2016).
in contrast, we use massively multilingual sentenceembeddings trained on almost 100 languages, andthen conduct margin-based mining in the multilin-gual embedding space (schwenk, 2018; artetxeand schwenk, 2018a,b; kvapil´ıkov´a et al., 2020).
previous work such as espa˜na-bonet et al.
(2017);hassan et al.
(2018); guo et al.
(2018); yang et al.
(2019) used bilingual embeddings, which is notscalable for mining many different languages..compared to work such as schwenk (2018), wedrastically increase the scale of our mining andproduce two orders of magnitude more data — thisis possible by the increased efﬁciency and scala-bility of our improved mining methods.
a fewmining approaches were applied to large quanti-ties of language pairs.
for example, the paracrawlproject1 mined data for all european languages.
bitextor (espl`a-gomis and forcada, 2010) was ap-plied to many languages, but took an approach thatrequired identifying parallel documents ﬁrst andthen extracting aligned sentences.
this is similar tothe ccaligned project (el-kishky et al., 2020).
incontrast to these, we mine much larger quantities ofparallel data due to the global margin-based miningapproach that we take..data used to mine many previous methods fordata mining focused on wikipedia.
otero andl´opez (2010) and patry and langlais (2011), forinstance, aligned entire parallel documents.
forexample, adafre and de rijke (2006) and moham-madi and ghasemaghaee (2010) used machinetranslation systems to compare dutch and per-.
sian wikipedias to english, to identify aligned sen-tences.
various other worked used similarities inmentioned entities to align text, such as gottschalkand demidova (2017) and tsai and roth (2016).
work such as smith et al.
(2010); tuﬁs et al.
(2013);aghaebrahimian (2018) used wikipedia to mineparallel sentences, but focused on fewer languages,often high resource.
in contrast, our system minesnot in wikipedia but in commoncrawl, a muchlarger source of data — and is applied to a muchlarger quantity of languages..work has extended mining beyond wikipedia.
for example, paracrawl1 has been heavily used(e.g.
in wmt), which is based on several noisymultilingual crawls (koehn et al., 2018, 2019).
el-kishky et al.
(2019) focused on mining documentsin common crawl rather than sentences.
our workcontinues this line of scalable mining on the web,but pushes to large-scale mining to produce billionsof aligned sentences..3 distance-based mining approach.
we leverage massively multilingual sentence em-beddings and a margin-based criterion to mine par-allel sentences.
the core idea is to learn a multilin-gual sentence embedding, or an embedding spacein which semantically similar sentences are close,independent of the language they are written in.
this means that distance in the embedding spacecan be used to determine if two sentences are mu-tual translations or not.
we use the open sourcelaser (artetxe and schwenk, 2018b) embed-dings as they cover over 90 different languages.2another recent multilingual sentence embedding islabse (feng et al., 2020)..3.1 margin criterion.
given two sentence embeddings, how can we de-cide if they are mutual translations?
using an abso-lute threshold on the cosine distance was shown toachieve competitive results (schwenk, 2018), butis globally inconsistent (guo et al., 2018).
there-fore, we use margin-based mining (artetxe andschwenk, 2018a).
the margin m(x, y) betweentwo sentence embeddings x and y is deﬁned as theratio between the cosine distance between x andy, and the average cosine similarity of its nearest.
1http://www.paracrawl.eu/2https://github.com/facebookresearch/.
laser.
6491figure 1: parallelized processing ﬂow to create an faiss index for each language..neighbors in both directions:.
m(x, y) =.
cos(x, y).
(cid:88).
cos(x, z)2k.
(cid:88).
+z∈nnk(y).
cos(y, z)2k.
z∈nnk(x).
where nnk(x) denotes the k unique nearest neigh-bors of x in the other language, and analogouslyfor nnk(y).
we set k to 16..artetxe and schwenk (2018a) describe the max-strategy as one of the best performing ones: themargin is calculated in both directions for all sen-tences in languages l1 and l2.
then, the unionof forward and backward candidates is built, can-didates are sorted, and pairs with source or targetsentences which were already used are omitted.
fi-nally, a threshold is applied to the margin scoreto decide if two sentences are mutual translations.
this strategy was motivated by evaluation on thebucc corpus (zweigenbaum et al., 2018), wherethe reference alignments are known to be strictly1:1. our aim is to mine at the billion-scale, andat this size, the probability of ﬁnding multiple per-fect translations increases.
therefore, we take theunion of the best forward and backward alignments,excluding duplicate bitexts..3.2 scaling to billions of sentences.
in this work, we mine billions of parallel sentencesfrom the web by using the data released in com-mon crawl.3 we preprocess the raw text followingthe pipeline used to create the ccnet dataset (wen-zek et al., 2019).
we use 32 crawls spanning theperiod from december 2017 to february 2020..our ccnet corpus is about 120 times largerthan wikipedia: 71 billion compared to 595 mil-lion unique sentences (schwenk et al., 2019).
thelargest corpora are english (14.3 billion), then ger-man, french, and spanish (more than 5.2 billion.
3https://commoncrawl.org/.
sentences).
for 17 different languages, ccnet con-tains over one billion unique sentences (see ta-ble 1).
this requires a carefully designed miningapproach in order to tackle the substantially com-putational complexity and successfully scale.
wedeveloped a multi-step mining procedure that isstructured into three distinct tasks:.
1. text extraction and processing including sen-tence splitting and language identiﬁcation;.
2. creation of a faiss index for each language;.
3. mining parallel data for each language pairusing the sentence embeddings and indices..each step is parallelized as much as possible bysplitting the data into several blocks..text extraction.
the ﬁrst task, text extractionand processing, consists of three steps: 1) ex-tract text from the json data of ccnet and splitthe paragraphs into sentences; 2) mark duplicatesentences; and 3) perform language identiﬁcation(lid) and exclude sentences not in the expectedlanguage.
each of these three steps processesblocks in parallel.
at the ﬁnal step, we merge allthe block-wise deduplicated sentences and createone set of globally unique sentences for each lan-guage.
we used a python library4 to detect sentenceboundaries.
if speciﬁc rules for a language are notavailable, we fall-back to a linguistically similarlanguages, e.g.
using spanish rules for gallican,and default to english otherwise.
most of the asianlanguages are handled by regular expressions.
weexclude sentences with more than 500 characters.
a major challenge of web data is noise.
this partic-ularly manifests in text that has the wrong languagelabel.
as noise in this stage will affect our miningprocess, we perform strict ﬁltering using two lidsystems on each sentence, fasttext (grave et al.,.
4https://pypi.org/project/.
sentence-splitter/.
6492text1textntextfaissembed1embednembedfaissindex1indexntrained indexdedup.
textembeddingsindex………index for all sentencesfaiss index trainingsamplefigure 2: parallelized processing ﬂow to mine parallel sentences.
left: forward distances; right: backwarddistances.
middle: both distances are combined according to equation 3.1 and the extracted bitext..2018) and langid (lui and baldwin, 2011), anddiscard the data if the two disagree or have lowconﬁdence.
this processing yields a corpus of niunique sentences for each language li.
these textsare the basis for index creation and mining (seecolumn size in table 1)..index creation.
we follow schwenk et al.
(2019)and use the highly optimized faiss library (john-son et al., 2017)5 to create compact indices ofthe sentence embedding.
laser’s sentence rep-resentations are 1024-dimensional, which meansthat the embeddings of all sentences would require71 · 109 × 1024 × 4 ≈ 290 tb to store.
to practi-cally handle this scale, we use an aggressive vectorcompression based on a 64-bit product-quantizer(j´egou et al., 2011), and 64k cells to partition thesearch space.
this corresponds to the index typeopq64,ivf65536,pq64 in faiss..exhaustive search in huge indices is tractableonly if performed on gpu.
faiss supports shard-ing of a single index on multiple gpus - this ismost efﬁcient if the gpus are in the same machineand communicate very quickly.
our index type, us-ing eight gpus with 32gb of memory each, allowsus to handle an index size of 3.2 billion sentences.
seven languages exceed this threshold, so we pro-ceed to create multiple indices (english, german,french, spanish, russian, chinese, and japanese).
the processing pipeline to train and create theindices is summarized in figure 1. we train anindex on 40 million sampled sentences of the wholecorpus.
once the index is trained, the data in eachblock is independently added to this common index,which can be performed in parallel.
the individualindices are subsequently merged into one index perlanguage.
the largest indices have a size of around210gb, making 90 indices total almost 4tb..5https://github.com/facebookresearch/.
faiss/wiki/faiss-indexes.
mining.
after indices for all languages are cre-ated, we begin the mining process for each lan-guage pair.
to illustrate the process, we describeit concretely with the example of two high re-source languages, italian and portuguese, whichhave 2.5 billion sentences each.
this requires2.5 109×2.5 109 = 6.25 1018 distance calculations.
performing this on a single node with 8 gpuswould require more than 6 months.
instead, wetackle this computational challenge by decouplingthe distance calculations of the forward and back-ward direction and the margin calculation, and pro-cessing these in parallel.
this processing pipelineis illustrated in figure 2..for all language pairs, we compute both forwardand backward distances, even for languages withmultiple indices, such as english, french and ger-man.
all available alignments for one pair aremerged, excluding duplicate sentence pairs..in the current ccmatrix corpus, we have mineddata for a diverse set of 90 languages, covering avariety of different language families and scripts(full list in the appendix).
as the mining process iscomputationally intensive, we focus on many com-monly spoken languages to support existing trans-lation systems, as well as mine several mid to lowresource languages to provide parallel data for di-rections with limited to no public training data.
weorganized all languages into twelve groups whichmostly correspond to well established linguistic lan-guage families, but we have also performed somegeographic groupings, in particular for small lan-guage families or isolated languages.
in addition,we have identiﬁed major languages in each groupand use them as “bridge languages”.
we mine forall bitexts among these 27 bridge languages.
themotivation for this bridge language approach is toconnect the languages of the various groups, butsill avoid mining the full matrix.
additional detailsare given in the appendix..6493text1frembed1frindexdeembed1detext1deindexfrmargin based miningtextnfrembednfrembedmdetextmde………………idxndnd1idx1idx1d1dmidxm3.3 choosing the margin threshold.
the margin threshold used to mine parallel sen-tences impacts the quality of mined bitexts.
ahigher threshold leads to better aligned sentences,and thus higher quality bitexts, but also to smallerdatasets.
thus, there is a trade-off between size andquality.
exploratory experiments based on train-ing different nmt models showed that a thresholdaround 1.06 gave good results.
we display a repre-sentative example on hungarian-danish in fig.
3..figure 3: bleu scores on hu-da ted dev set forvarious margin threshold values..4 quantity of mined data.
4.1 total quantity.
we mine a total of 10.8 billion parallel sentencesout of which only 2913 million are aligned withenglish, considering a margin threshold of 1.06 forall language pairs.
table 1 gives a summary forthe 54 largest languages.
the full list of supportedlanguages is given in the appendix.
in contrastto other works, such as the european paracrawlproject,1 we do not limit to alignments with en-glish, but provide alignments for 1197 languagepairs..this yielded unprecedented amounts of bitextsof non-english language pairs, for example 286mfor spanish-french, 24m for arabic-french andspanish-chinese, and a total of 326m bitexts withnorwegian (which is not present in europarl).
fur-ther, a variety of different asian languages weremined, producing 7.2m pairs for japanese-korean,7.8m for indonesian-malay, and 1.3m for bengali-hindi.
to the best of our knowledge, this makesccmatrix the largest collection of high-qualitymined parallel texts, with coverage over a widevariety of languages.
providing multiple alignedbitexts for many languages also opens the possibil-ity of improved training of massively multilingual.
nmt systems (fan et al., 2020), as this substan-tially increases the amount of bitexts for low re-source languages.
as an example, nepali has lessthan 1m bitexts with english, but 17m bitexts withmultiple languages (see last column of table 1)..4.2 analysis of mined bitexts.
table 1 gives the amount of mined bitexts for var-ious language pairs.
the general tendency is ofcourse that mining in large monolingual corporaleads to larger extracted bitexts.
this is howevernot systematically true.
let us consider for exampledanish, a germanic language.
when aligned withnorwegian, also a germanic language, we obtain17.7m bitexts.
the pair danish-italian, however,has only 14.7m bitexts although italian has almostsix times more sentences than norwegian.
one onehand, a possible explanation could be that laseralignments are more reliable for languages whichin the same language fam-are very similar, i.e.
ily.
on the other hand, it may also be that peoplewhich live in nearby countries have similar inter-ests which increases the chance to ﬁnd translationson the web.
additional analysis and examples areprovided in the appendix..5 evaluation on translation benchmarks.
to assess our mined bitext, we train nmt systemsonly on our mined data and evaluate on severalpublic benchmarks.
we do not use any of the train-ing data provided with these corpora, so do not useany available human translated data, and have noguarantee our bitext covers the same domain as thetest sets.
nevertheless, we show on the many tomany ted corpus that our mined data produceshigh quality translation systems, even through dis-tant language pairs not aligned through english andlow resource languages.
finally, we demonstratethat models trained on ccmatrix can surpass stateof the art systems in wmt’19 and wat’20..5.1 ted evaluation.
we examine the quality of our mined bitext across adiverse set of languages, focusing on performanceof bitext pairs not aligned through english.
follow-ing gottschalk and demidova (2017), we evaluateon the test sets of the ted corpus (qi et al., 2018),which contains parallel ted talk transcripts in 58languages.
this corpus is tokenized, so we deto-kenize using moses, with the exception of pairs.
64941.0501.0551.0601.0651.070margin threshold10.210.410.610.811.011.211.4bleu scorehu-dada-hu3.
0.
1.
1.
7.
1.
-.
6.
1.
5.
0.
-.
2.
4.
0.
2.
2.
1.
5.
0.
7.
862.
1.
761.
3.
803.
3.
823.
8.
12.
9.
853.
5.
81.
9.
366.
4.
623.
2.
785.
4.
671.
5.
7702-.
8.
58.
3.
349.
1.
034.
5.
3801-.
6.
91.
9.
043.
0.
225.
1.
301.
9.
046.
9.
077.
0.
804.
4.
392.
9.
922.
1.
461.
7.
104.
3.
102.
3.
843.
6.
073.
1.
662.
7.
561.
0.
74.
6.
411.
4.
224.
9.
023.
0.
642.
1.
481.
3.
16.
5.
01.
0.
71.
6.
02.
3.
91.
7.
86.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
5.
0.
7.
7.
8.
2.
3.
9.
2.
6.
-.
6.
5.
-.
4.
9.
1.
6.
9.
7.
-.
8.
1.
9.
93.
9.
12.
8.
01.
8.
02.
0.
6.
-.
-.
5.
3.
2.
6.
7.
31.
1.
41.
0.
5.
1.
4.
2.
4.
2.
2.
0.
9.
4.
3.
1.
8.
5.
4.
7.
3.
5.
2.
-.
-.
6.
6.
6.
9.
1.
6.
4.
6.
3.
3.
0.
4.
3.
1.
3.
6.
3.
2.
0.
2.
3.
2.
7.
0.
5.
0.
3.
1.
1.
1.
-.
5.
0.
3.
2.
3.
7.
-.
0.
1.
7.
0.
8.
0.
4.
0.
1.
9.
2.
8.
-.
1.
1.
6.
4.
7.
0.
-.
6.
0.
7.
0.
6.
0.
9.
0.
5.
1.
5.
0.
5.
0.
5.
0.
3.
0.
8.
1.
4.
0.
8.
1.
8.
1.
4.
1.
3.
0.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
4.
19.
7.
521.
1.
0.
1.
0.
5.
0.
5.
0.
5.
0.
6.
0.
4.
0.
4.
0.
8.
6.
1.
05.
5.
82.
9.
41.
6.
393.
7.
1.
1.
0.
2.
0.
2.
0.
-.
3.
2.
1.
0.
3.
0.
-.
-.
8.
7.
1.
0.
2.
0.
3.
0.
3.
0.
2.
0.
2.
1.
-.
3.
0.
4.
0.
1.
0.
0.
0.
2.
0.
3.
0.
-.
5.
0.
8.
0.
1.
0.
0.
0.
3.
0.
-.
4.
0.
4.
0.
1.
0.
0.
0.
-.
0.
0.
1.
0.
0.
0.
-.
-.
2.
0.
5.
0.
-.
3.
1.
-.
5.
1.
9.
0.
8.
0.
7.
0.
4.
3.
0.
2.
9.
1.
7.
1.
1.
4.
7.
2.
9.
1.
2.
2.
5.
0.
3.
3.
9.
1.
9.
1.
8.
1.
2.
3.
7.
1.
9.
0.
9.
1.
7.
3.
0.
2.
9.
1.
6.
1.
5.
4.
2.
2.
2.
1.
7.
1.
8.
1.
1.
1.
0.
1.
9.
0.
5.
5.
6.
3.
8.
2.
8.
2.
4.
2.
4.
1.
-.
-.
-.
-.
0.
1.
9.
0.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
8.
1.
5.
1.
3.
3.
3.
2.
7.
1.
9.
0.
8.
2.
9.
1.
9.
0.
6.
0.
5.
2.
1.
1.
-.
-.
-.
-.
-.
-.
-.
-.
7.
5.
7.
3.
8.
2.
8.
1.
2.
1.
6.
2.
6.
1.
9.
0.
-.
2.
3.
4.
6.
8.
1.
1.
0.
9.
1.
0.
2.
-.
4.
2.
5.
3.
8.
1.
7.
1.
8.
1.
9.
0.
3.
3.
4.
1.
1.
3.
2.
3.
5.
2.
2.
1.
-.
-.
-.
8.
1.
2.
5.
2.
1.
1.
0.
2.
1.
4.
1.
-.
6.
1.
6.
2.
1.
1.
9.
0.
9.
0.
6.
0.
0.
3.
8.
0.
8.
2.
0.
3.
1.
2.
6.
0.
-.
-.
1.
5.
1.
3.
3.
2.
6.
2.
-.
-.
-.
-.
4.
2.
8.
5.
-.
-.
2.
1.
6.
3.
0.
0.
6.
0.
7.
0.
-.
0.
1.
4.
1.
6.
0.
5.
0.
5.
0.
3.
0.
5.
1.
8.
0.
4.
1.
4.
1.
9.
0.
8.
0.
-.
-.
4.
3.
8.
1.
0.
1.
6.
1.
3.
2.
6.
1.
6.
5.
9.
4.
-.
2.
2.
4.
7.
-.
4.
7.
3.
2.
3.
3.
-.
5.
4.
8.
9.
7.
2.
-.
-.
9.
2.
2.
1.
1.
7.
5.
5.
2.
2.
8.
1.
9.
1.
1.
1.
6.
2.
5.
1.
0.
2.
1.
2.
6.
1.
0.
1.
8.
1.
0.
2.
0.
4.
5.
4.
1.
4.
-.
1.
7.
3.
4.
0.
6.
2.
5.
-.
2.
3.
2.
9.
-.
5.
9.
3.
3.
8.
8.
-.
-.
-.
-.
3.
3.
8.
3.
8.
8.
5.
9.
2.
3.
4.
2.
4.
2.
8.
1.
3.
6.
0.
2.
6.
5.
7.
5.
9.
3.
6.
1.
8.
1.
5.
1.
-.
6.
7.
7.
3.
8.
3.
5.
2.
8.
8.
6.
6.
-.
5.
4.
-.
7.
7.
6.
4.
6.
6.
3.
6.
3.
7.
2.
7.
7.
2.
5.
5.
0.
31.
-.
9.
81.
1.
6.
4.
91.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
7.
2.
5.
5.
8.
1.
2.
7.
0.
5.
7.
3.
3.
3.
1.
2.
9.
3.
7.
2.
0.
4.
3.
4.
2.
3.
2.
2.
0.
2.
6.
2.
0.
2.
4.
5.
4.
41.
-.
3.
71.
0.
11.
6.
6.
7.
4.
1.
4.
4.
2.
8.
01.
3.
3.
3.
5.
2.
6.
4.
7.
6.
2.
8.
3.
5.
7.
1.
0.
2.
3.
2.
3.
6.
1.
0.
4.
8.
5.
1.
3.
5.
2.
9.
2.
5.
1.
2.
3.
4.
1.
0.
2.
5.
2.
6.
1.
2.
1.
9.
0.
-.
-.
7.
5.
-.
2.
3.
3.
11.
2.
5.
5.
5.
4.
3.
-.
5.
4.
0.
11.
3.
81.
1.
11.
9.
02.
9.
5.
9.
1.
0.
2.
3.
2.
8.
3.
9.
0.
2.
1.
6.
01.
1.
1.
6.
6.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
9.
0.
1.
1.
9.
0.
8.
0.
-.
5.
2.
5.
1.
4.
2.
5.
2.
6.
1.
4.
1.
-.
-.
2.
1.
9.
1.
4.
2.
-.
2.
4.
6.
9.
-.
5.
5.
4.
3.
8.
4.
0.
1.
2.
9.
3.
9.
-.
8.
5.
5.
5.
4.
4.
1.
0.
9.
4.
3.
5.
0.
2.
0.
6.
1.
5.
1.
5.
3.
3.
9.
1.
1.
4.
1.
4.
9.
3.
4.
4.
3.
5.
-.
8.
2.
7.
1.
5.
5.
4.
3.
-.
-.
4.
7.
6.
4.
5.
6.
-.
3.
8.
0.
8.
2.
6.
2.
0.
1.
7.
5.
7.
9.
2.
2.
9.
0.
7.
2.
6.
9.
3.
0.
3.
4.
5.
6.
5.
4.
5.
3.
6.
-.
2.
4.
4.
2.
0.
8.
8.
4.
04.
..42.
..67.
..64.
..-.
-.
-.
-.
6.
11.
..411.
2.
6.
18.
..0.
01.
..181.
-.
-.
5.
31.
6.
21.
..411.
..801.
2.
9.
46.
..4.
0.
3.
8.
3.
11.
3.
3.
6.
21.
4.
21.
8.
01.
4.
7.
3.
4.
6.
2.
6.
7.
5.
5.
8.
7.
-.
20.
..56.
..98.
..52.
....001.
..301.
47.
..06.
..63.
..32.
..-.
36.
..06.
..-.
71.
..62.
..23.
..-.
-.
96.
..24.
..26.
..-.
17.
..76.
..05.
..20.
..65.
..76.
..42.
..07.
..85.
..35.
..43.
..02.
..-.
74.
..-.
93.
..12.
..48.
..05.
..-.
-.
95.
..19.
....011.
-.
..061.
..332.
69.
..20.
..59.
..19.
..-.
..401.
..821.
67.
..16.
..64.
..72.
..02.
..01.
..91.
..32.
..-.
52.
..57.
..-.
33.
..52.
..92.
..11.
..68.
..67.
..-.
72.
..74.
..43.
..90.
..18.
..04.
..81.
..85.
..16.
..54.
..64.
..-.
6.
0.
6.
1.
5.
2.
4.
0.
4.
1.
4.
1.
2.
0.
7.
0.
9.
11.
1.
01.
8.
41.
..101.
..562.
6.
62811.
1.
3.
2.
4.
4.
6.
0.
8.
11.
4.
11.
6.
0.
9.
3.
1.
01.
3.
0.
9.
6.
1.
8.
1.
1.
3.
1.
6.
1.
-.
3.
8.
2.
91.
0.
22.
2.
32.
4.
53.
4.
42.
3.
42.
2.
42.
4.
1.
0.
2.
81.
..21.
..52.
..7.
32.
6.
42.
8.
73.
7.
83.
..143.
..363.
..411.
..811.
..254.
..444.
41.
..71.
..02.
....621.
..321.
..361.
..661.
..522.
..722.
..955.
..384.
..634.
..044.
29.
....433.
..243.
4.
68211.
1.
5.
33821.
3.
4.
2.
8.
6.
0.
4.
7.
01.
7.
0.
7.
1.
0.
71.
5.
07.
1.
6.
3.
6.
7.
0.
9.
2.
1.
51.
1.
01.
6.
42.
2.
52.
4.
22.
8.
7.
7.
61.
0.
61.
7.
94.
5.
02.
0.
74.
3.
2.
6.
8.
0.
1.
8.
5.
7.
7.
59.
..45.
..67.
..1.
31.
3.
32.
4.
32.
4.
63.
..002.
..063.
..521.
..022.
..791.
..394.
..202.
14.
..46.
..97.
..58.
..95.
....021.
..562.
..081.
..472.
..052.
..183.
..954.
041.
..644.
..147.
92.
..98.
....881.
35.
..67.
....923.
..365.
..602.
..644.
77.
....712.
..655.
..041.
..735.
471.
..741.
..617.
641.
..231.
731.
923.
211.
904.
..312.
..342.
..142.
22.
....611.
..241.
-.
68.
..87.
..-.
..461.
..851.
..441.
-.
83.
....062.
..712.
-.
07.
..07.
..15.
..50.
..78.
..16.
..94.
..69.
..76.
..60.
..99.
..99.
..24.
..-.
..701.
-.
88.
....931.
..031.
..681.
..172.
..031.
..933.
..921.
90.
..04.
..32.
....331.
..473.
..323.
..082.
..591.
..813.
73.
..10.
..14.
..54.
....663.
-.
77.
..25.
..-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
02.
..69.
....301.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
20.
..20.
..70.
..91.
..-.
30.
..20.
..30.
..-.
-.
..111.
-.
51.
..90.
....001.
..652.
..401.
76.
....041.
40.
....501.
30.
..-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
-.
85.
....175.
..685.
81.
....792.
..681.
..696.
-.
891.
821.
99.
..841.
841.
04.
....721.
..411.
03.
....442.
..456.
-.
..223.
..271.
-.
682.
-.
-.
-.
-.
95.
..54.
..75.
..-.
98.
..55.
..49.
..-.
-.
..811.
..752.
..103.
..121.
..412.
..072.
-.
76.
..57.
..05.
..52.
..08.
....622.
16.
..98.
....552.
..501.
36.
..29.
....711.
..852.
..021.
..113.
..392.
..721.
..112.
..183.
..702.
..663.
..684.
..602.
..083.
02.
..-.
-.
-.
-.
-.
-.
71.
..1.
32.
9.
34.
0.
77.
71.
..8.
32.
3.
32.
-.
-.
0.
41.
-.
4.
1.
7.
71.
8.
32.
8.
74.
3.
1.
3.
2.
6.
61.
8.
86.
701.
7.
1.
3.
0.
3.
1.
4.
3.
7.
8.
-.
-.
742.
-.
3.
25.
3.
82.
-.
7.
8.
6.
3.
1.
1.
-.
51.
354.
6275.
33341.
43.
..02.
..53.
..73.
..53.
..22.
..83.
..73.
..14.
..03.
..55.
..84.
..59.
..17.
..48.
....041.
67.
..85.
..47.
....611.
62.
..76.
..99.
..66.
....901.
14.
..42.
..74.
..35.
..14.
..-.
84.
..15.
..88.
..49.
..28.
..58.
..64.
..88.
....221.
..401.
..051.
..101.
..061.
..412.
..451.
..301.
..043.
..142.
39.
..47.
..57.
..2.
21.
0.
4.
7.
2.
4.
4.
7.
4.
4.
21.
4.
8.
2.
8.
2.
21.
-.
-.
-.
-.
9.
04.
4.
91.
1.
05.
4.
17.
8.
9.
5.
41.
8.
21.
6.
81.
1.
4.
5.
2.
0.
4.
9.
4.
-.
-.
-.
-.
-.
1.
5.
0.
8.
4.
21.
-.
4.
3.
9.
3.
-.
2.
7.
9293.
2941.
3002.
3634.esemanteiv.esen.i.hc.esenapaj.naerok.-.
-.
-.
-.
-.
-.
-.
-.
-.
latot.lt.l.m.sm.gmdi.at.ru.is.en.r.m.ih.nb.ws.af.eh.ra.rt.qs.ue.vl.tl.uh.ﬁ.te.le.ku.rs.ls.ks.ur.lp.rh.sc.gb.eb.or.tp.ti.lg.rf.se.ac.vs.on.ln.si.ne.ed.ad.fahz.iv.ok.ezis.emanosi.
23.
2171.
634.
3371.
261.
8625.
4865.
34.
1442.
8452.
665.
52.
172.
689.
18.
8951.
5524.
593.
681.
561.
184.
875.
29.
774.
975.
951.
58.
23.
48.
687.
362.
877.
7512.
9.
631.
0.
32.
91.
23.
53.
451.
1.
54.
95.
24.snaakirf.a.namreg.hsinad.hsilgne.cidnalsi.hctud.naigewron.hsi.dews.nalatac.hsi.naps.hcnerf.naicilag.nailati.eseugutrop.nainamor.naisuraleb.nairaglub.naitaorc.naissur.kavol.s.hsilop.hcezc.nainevol.s.naibres.nainiarku.nainotse.hsi.nnf.i.keerg.naivtal.euqsab.nainabla.hsikrut.ci.bara.werbeh.israf.aj.ok.iv.hz.fa.ad.ed.ne.si.l.n.on.vs.ac.se.rf.lg.ti.tp.or.eb.gb.sc.rh.l.p.ur.ks.ls.rs.ku.le.te.ﬁ.tl.vl.ue.qs.rt.ra.eh.af.nainauhti.l.nairagnuh.uh.4101.naisenodni.ilagneb.ihtara.m.ilapen.alahni.s.i.dnh.i.li.mat.udru.ysagala.m.mayala.m.golagat.yala.m.nb.i.h.r.m.en.is.ru.at.gm.s.m.l.m.d.i.lt.ili.haws.ws..
sliated.rof.txet.ees...601.
..fodlohserhtnigrama.rof.)snoilli.mn.i.srebmun.lla(.
riap.egaugnal.hcae.rof.secnetnes.lellarap.detcartxe.fo.rebmun.:xirtamcc.:1.elbat.6495ﬁ.lt.it.
el.
fr.
et.
vi.
fa.
es.
pl.
sv.
pt.
ru.
de.
en.
- 16.8.ja ko.
tr uk.
cs da.
nl no.
ar bg.
he hu.
- 22.3 30.9 26.1 27.7 41.4 28.6 20.0.
- 22.0 23.7 22.9 33.4 26.0 19.0 8.3 15.4 27.5 14.3 16.4 21.8 21.2 13.3.
- 10.4 15.2 24.4 12.3 17.4 21.4 19.9- 7.4 22.0 10.7 11.3 18.2 18.8- 20.5 11.5 14.4 15.8 18.5.
- 24.7 39.8 30.0 19.8 9.3 15.5 31.3 17.5 18.3 24.2 26.9- 41.0 31.0 18.1 9.4 14.3 31.9 17.7 17.8 24.6 27.7.zhid- 16.6 14.4 19.3 18.4 20.0 33.3 24.6 12.6 8.7 10.0 25.5 14.8 12.7 19.2 21.4 13.0 4.0 12.1 19.1 24.6 12.4 23.8 15.5 22.6 9.5 13.4 21.2 16.7- 14.8 28.7 17.5 18.0 22.1 27.8 14.4 4.8 17.4 26.3 30.0 17.0 26.8 20.6 27.9 9.8 19.0 25.0 18.0- 26.8 18.1 25.9 19.3 24.6 10.0 17.2 22.3 17.5- 29.6 28.6 48.9 31.5 19.3 9.4 16.6 33.0 18.7 17.9 26.4 29.3 14.7 5.5 17.5 31.3 36.7 16.5 31.8 19.3 36.2 12.5 19.1 23.4 17.9- 4.8 16.8 28.8 25.4 17.3 29.9 19.3 28.6 12.7 17.4 24.3 19.0- 31.8 16.3 30.0 20.2 27.2 12.1 17.2 24.5 18.7- 4.9 17.3- 43.1 22.5 13.5 19.8 42.8 26.9 22.0 35.0 37.3 16.3 6.4 21.3 35.3 46.6 20.6 43.1 23.3 39.6 17.5 23.2 30.7 24.7- 19.9 9.9 15.9 34.6 18.2 18.3 26.0 32.0 15.5 5.0 16.6 27.9 29.2 17.6 34.1 21.0 28.5 12.5 18.0 26.1 20.5-- 14.3 21.2 15.4 12.4 21.6 17.3 21.6 8.4 15.3 17.9 17.5- 3.7 8.6 16.5 16.2 10.0 19.7 14.0 17.1 9.1 10.9 18.4 15.2- 4.0 12.7 19.8 18.2 13.5 19.2 14.0 19.7 9.3 12.3 18.3 13.6- 17.8 18.0 26.6 29.7 15.0 4.9 17.8 27.9 30.0 17.6 33.2 21.4 28.7 12.6 19.1 26.4 17.1- 4.5 0.0 21.9 24.5 14.3 27.4 17.2 25.1 10.3 14.9 22.1 14.7- 14.6 20.9 19.1 14.8 23.2 16.2 21.2 10.5 13.9 20.1 17.3-- 23.6 13.5 5.2 12.6 24.1 26.0 14.6 26.3 16.6 22.8 11.4 15.2 24.7 18.2- 13.8 5.1 16.8 26.8 31.7 15.9 33.0 19.2 29.4 13.4 11.5 25.6 19.3- 9.1 9.5 6.6 10.5 8.5 8.6 4.5 5.5 13.1 13.9- 12.1- 8.6 14.6 9.7 12.4 6.9 7.5 16.9 16.6- 20.8 21.9 15.3 23.0 19.3 23.9 9.8 16.7 20.7 16.0- 21.0 17.6 30.0 18.9 27.5 11.2 16.5 23.6 17.3-- 12.4 31.7 18.6 34.6 13.7 19.3 19.6- 21.4 16.8 19.4 8.8 15.0 19.9 15.6- 21.5 29.3 13.3 18.9 25.5 17.2- 20.6 6.8 20.9 20.5 17.3- 12.7 17.7 26.8 18.0- 6.6 20.8 16.7- 20.8 15.7- 16.2-.
arbg 7.2cs8.6 24.9da 8.6 30.5 18.5de 10.2 27.3 22.4 33.5el 11.0 28.3 20.7 30.6 24.6en 16.8 38.5 26.9 43.5 33.9 36.3es 13.6 27.0 21.3 32.1 26.8 28.0 44.3et6.9 22.9 18.2 22.0 20.7 20.2 26.9 23.3fa8.3- 13.0 18.1 16.3 17.4 30.9 20.1 12.8ﬁ6.5 18.4 16.1 21.0 17.6 17.1 25.4 20.8 16.1 4.9fr 11.9 26.2 21.4 32.1 26.6 28.0 42.9 33.6 19.4 9.7 15.6he 11.3 25.5 18.4 27.1 23.1 23.1 39.3 27.3 16.5 8.3 12.3 28.2hu 9.3 21.5 17.0 22.6 20.4 20.5 29.1 23.0 18.1 7.7 13.8 23.6 13.0idit 11.8 28.8 19.0 30.3 26.0 27.6 41.1 33.9 18.2 10.1 15.8 34.2jako 5.3 12.8ltnl 10.3 26.3no 13.5 29.5 24.2 37.1 25.4 29.9 51.2 31.1 11.6 6.3 15.3 32.2 18.7 16.5 27.9 33.3 15.0 4.8 15.7 20.9pl7.6 20.2 18.1 19.9 19.0 18.2 25.3 21.9 12.9 6.6 12.5 23.4 12.0 13.9 19.0 18.4 12.1 4.0 13.9 19.7 14.5pt 12.5 26.9 22.2 34.0 27.8 29.4 47.9 36.5 18.3 10.2 15.5 35.8 19.3 19.0 28.3 33.3 14.1 5.0 18.1 29.5 29.0 18.2ru 8.4 21.3 17.1 19.1 19.1 20.0 26.9 23.2 16.0 8.1 11.4 23.8 12.6 14.2 18.7 19.8 14.1 3.6 15.7 19.5 19.4 15.2 22.4sv 12.7 28.2 21.5 36.0 28.4 27.0 44.7 30.8 20.8 9.1 16.2 32.4 18.3 17.8 25.6 30.0 14.1 5.0 19.8 27.8 34.9 16.5 30.6 20.2tr8.9 16.6 14.3 19.5 19.0 18.6 29.2 22.1 13.7 8.4 11.1 22.4 12.2 14.0 19.5 20.9 12.8 4.6 12.1 18.5 19.1 12.0 21.4 11.7 19.4uk 8.4 22.4 17.6 23.9 20.2 20.9 30.3 24.0 14.9 7.2 11.5 25.1 12.2 14.2 19.9 15.2 11.3 3.8 16.1 19.8 20.9 16.0 23.4 23.8 19.8 4.8vizh 6.0 14.3 10.8 13.4 13.4 14.4 21.6 17.3 9.9 6.0 7.9 16.7 8.3 10.4 15.8.
- 10.0 9.2- 15.4 13.88.2 21.7 17.5 22.2 20.8 19.4 29.8 23.1 14.4 5.9 12.9 24.8 0.0 14.7 17.7 21.2.
8.5 19.9 13.0 20.1 18.5 18.7 29.0 21.4 12.7 7.8 11.5 23.6 11.8 12.1 21.8 20.6 12.6 4.3 11.8 17.3 15.9 12.6 20.4 15.4 20.5 9.2 13.4.
8.6 20.6 16.9 25.7 21.6 21.7 35.3 26.3 15.5 8.7 11.7 27.0 14.5 14.9.
- 39.3 30.8 19.3 9.0 15.7 31.0 16.3 17.4 25.3 27.2 14.1 4.6 17.0.
- 13.2 3.8 8.2 14.3 15.1 9.7 15.6 12.5 14.8 6.9 9.5 18.8.
- 9.3 15.5 12.2- 13.6 11.2 12.4 19.6 15.0.
- 4.5- 11.5 4.6- 5.9 7.8 15.3 6.9.
-- 20.0 21.5.
4.3 9.6 6.5 9.8.
- 14.6 22.6.
- 17.7 25.6.
- 32.1 27.3.
---.
---.
table 2: bleu scores on the ted test set.
nmt systems were trained on bitexts mined in ccmatrix only..involving chinese, japanese and korean as it cre-ates artifacts..we consider 29 different languages, resulting in778 nmt systems to train.
we apply the same pre-processing and training procedure for all languagepairs.
we train a sentencepiece model (kudo andrichardson, 2018) with a vocabulary of size 50k.
the bitext were not ﬁltered to remove sentenceswhich may appear in the ted dev or test sets.
also,we did not try to optimize the architecture of thenmt models to to size of the bitexts for each lan-guage pair.
instead, for all the pairs, we use thesame architecture, a transformer model with sixlayers for both the encoder and decoder.
we usea dimension of 512 and 4096 for the feed-forward.
we train each model for 50 epochs with an initiallearning rate of 0.001. we keep the model with thebest bleu on the ted validation set..in table 2, we report tokenized bleu on the testsets.
when translating into chinese, we scored withsacrebleu -tok zh, and kytea6 was usedto tokenize japanese, respectively.
the averagebleu over all pairs is 18.8 and 33.0 for pairs withenglish.
there are 86 pairs out of 778 with bleuabove 30, compared to 10 out of 1620 languagepairs for wikimatrix.
the best wikimatrix pairreached 37.3 bleu (for brazilian portuguese toenglish), while here 25 pairs are over 37.3, the bestpair reaching 51.2 bleu (norwegian to english)..6http://www.phontron.com/kytea/.
these results show the quality of the mined bitextsand suggest that our mining strategy is robust to thenoise and domain differences existing in large cor-pora like common crawl.
however, since we didnot optimize the nmt systems for each languagepair, these bleu score should not be consideredas the best possible ones based on the ccmatrixbitexts.
in particular, we anticipate that better re-sults can be obtained when using models with moreparameters for the high-resource language pairs..further, our mined data provides a starting pointfor those interested in training translation systemsdirectly between languages that currently havein particularno available bitext training data.
ccmatrix bitexts have been used to train a mas-sively multilingual nmt systems for 100×100 lan-guages (fan et al., 2020)..5.2 wmt’19 evaluation.
next, we focus on arguably the most competitivetranslation benchmark, the wmt news translationtask, to compare our mined data to the best exist-ing systems.
we only consider the high resourcedirections, as they constitute the largest challenge— existing systems perform strongly, and previouswork incorporating mined data from paracrawl (ottet al., 2018) only found marginal gains..we follow ng et al.
(2019) and trained systemson en-de, en-ru, en-zh, and de-fr.
we used thetransformer big architecture with ffn size 8192,.
6496system.
de-en.
en-de.
en-ru.
ru-en.
zh-en.
en-zh.
de-fr.
fr-de.
nt’18 wmt bitextnt’18 ccmatrix.
nt’19 wmt bitextnt’19 ccmatrix.
nt’20 wmt bitextnt’20 ccmatrix.
46.249.9.
41.043.3.
40.339.2.
45.950.3.
40.444.5.
31.935.1.
33.535.7.
31.435.5.
24.025.5.
33.436.9.
38.141.8.
35.537.1.
25.830.2.
-34.8.
-35.0.
39.240.8.
-35.6.
-38.8.
--.
-37.9.
-33.8.
--.
-33.5.
-33.8.nt’19 best.
42.8.
44.9.
36.3.
40.2.
39.9.
44.6.
37.3.
35.0.singlesystems.
ensembles+ bt+ reranking.
table 3: bleu scores on the newstest’18, newstest’19 and newstest’20 test sets.
newstest’18 wmt bi-text, newstest’19 wmt bitext and newstest’20 wmt bitext are the results for single models trained on parallelwmt’19 data, en-de and en-ru using the setup from ng et al.
(2019), and en-zh results from sun et al.
(2019).
newstest’19 best are the best bleu scores from ensembles trained on parallel and back-translated wmt’19 data,according to http://matrix.statmt.org/..language pair.
src.
tgt.
en-deen-ruen-zhde-fr.
3.9% 2.2%4.2% 2.5%3.0% 0.7%3.6% 3.1%.
table 4: 8-gram test data overlap.
percentage of 8-gram bpe tokens from newstest 2019 that are alsofound in ccmatrix training data..embedding size 2048, with 9 encoder/decoder lay-ers, with layerdrop (fan et al., 2019).
we trainedfor 400k updates on 8 gpus.
given the largeamounts of mined bitext (see table 1), we trainonly on data with a margin threshold at least 1.07,and perform some additional ﬁltering, resulting in146m for en-de, 78m for en-ru, 82m for de-fr and31m for en-zh.
for each direction, we learn jointsource-target bpe (sennrich et al., 2016) and shareinput/output embeddings.
we tune training param-eters on wmt’12-13 when available and on thewmt’19 dev set for de-fr..in table 3 we demonstrate that the performanceof a single model trained on mined data is betterthan the performance of the best published singlemodels trained on wmt bitext, this can be seen asa clear indicator of the quality of the mined data..because ccmatrix data is mined from the web,we want to make sure there is no signiﬁcant leak-age of the test sets that might be available onlineinto the training data.
while there are no exactmatches of test and train samples, partial overlap.
is still possible.
following radford et al.
(2019)and shoeybi et al.
(2019) in table 4 we report thepercentage of 8-gram bpe tokens from the testdata that are also found in ccmatrix training data.
finally, in table 3 we also report performance onnewstest’20 tests sets that were not available at thetime of mining the data..we further investigate the impact of training ona combination of human translated and mined data.
we examine en-de and include the wmt’19 train-ing data.
we found that this system outperformsthe system trained on ccmatrix data only on av-erage by only 0.6 bleu, achieving bleu score50.9 on newstest2018 and 45.1 on newstest2019..5.3 wat’20 evaluation.
finally, we examine the quality of our mined dataon low resource, distant language pairs.
we fo-cus on russian-japanese, a language direction inthe 2020 workshop on asian translation (wat)(nakazawa et al., 2020).the organizers provide atiny amount of parallel data from the global voicesdomain for training (12k sentences), and a develop-ment (486 sentences) and test set (600 sentences)from the news commentary domain, respectively.7we trained an nmt system on ccmatrixjapanese-russian mined data only, without usingother resources or texts aligned with english.
weapplied a threshold of 1.06 on the margin whichyielded 9.5 million parallel sentences.
we ﬁlteredthe mined bitexts to exclude all sentences which.
7https://github.com/aizhanti/jarunc.
6497system.
ccmatrix devccmatrix test.
ja-ru.
ru-ja.
13.6814.77.
20.3819.60.wat’20 test best.
14.36.
18.48.table 5: bleu scores on wat’20..appear in the wat dev or test set..we use the same nmt architecture as in sec-tion 5.1. we report tokenized bleu in table 5.when translating from russian into japanese, to-kenization was performed with kytea and thenscored with multi-bleu.perl..we outperform the best performing systemat wat’20,8 in particular when translating intojapanese.
on one hand, the participants in watwere constrained to only use the provided re-sources.
but on the other hand, russian/englishand japanese/english were included and partici-pants were encouraged to train multilingual models,and use techniques like monolingual pre-trainingor back-translation.
therefore, our results are notdirectly comparable, but remain a positive indicatorof the quality of our mined bitexts..6 conclusion.
we show that margin-based mining in a joint multi-lingual sentence embedding space can be scaled tomonolingual texts of more than 71 billion uniquesentences in 90 languages, including several lowresource languages.
this procedure yields 10.8billion parallel sentences, out of which only 2.9billions are aligned with english.
we performed anextensive evaluation of the quality of the mined bi-texts by training nmt systems for many languagepairs.
training only on mined data, we outper-form the best single nmt systems at wmt’19for translations between german, russian, andchinese with english, as well as between ger-man and french.
we also achieve state-of-the-artbleu scores for translation between russian andjapanese at wat’20..all mined data is freely available.9 we hope thiswill enable widespread research on multilingualnmt, particularly on languages where training datais not currently available..8see results at http://lotus.kuee.kyoto-u.ac..jp/wat/evaluation/index.html.
9https://github.com/facebookresearch/.
laser/tree/master/tasks/ccmatrix.
references.
sadaf abdul-rauf and holger schwenk.
2009. on theuse of comparable corpora to improve smt perfor-mance.
in eacl, pages 16–23..sisay fissaha adafre and maarten de rijke.
2006.finding similar sentences across multiple languagesin proceedings of the workshop onin wikipedia.
new text wikis and blogs and other dynamic textsources..ahmad aghaebrahimian.
2018. deep neural networksat the service of multilingual parallel sentence ex-traction.
in coling..mikel artetxe and holger schwenk.
2018a.
margin-based parallel corpus mining with multilingual sen-tence embeddings.
https://arxiv.org/abs/1811.01136..mikel artetxe and holger schwenk.
2018b.
mas-sively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond.
in https://arxiv.org/abs/1812.10464..andoni azpeitia, thierry etchegoyhen, and evamart´ınez garcia.
2017. weighted set-theoreticin bucc,alignment of comparable sentences.
pages 41–45..andoni azpeitia, thierry etchegoyhen, and evamart´ınez garcia.
2018. extracting parallel sen-tences from comparable corpora with stacc vari-ants.
in bucc..and hassan2018.houda bouamorh2@bucc18:parallel sentence extractionfrom comparable corpora using multilingualsentence embeddings.
in bucc..sajjad..christian buck and philipp koehn.
2016. findings ofthe wmt 2016 bilingual document alignment sharedtask.
in proceedings of the first conference on ma-chine translation, pages 554–563, berlin, germany.
association for computational linguistics..ahmed el-kishky, vishrav chaudhary, francisco guz-man, and philipp koehn.
2019. a massive collectionof cross-lingual web-document pairs.
arxiv preprintarxiv:1911.06154..ahmed el-kishky, vishrav chaudhary, francisco guz-man, and philipp koehn.
2020. a massive collectionin proceed-of cross-lingual web-document pairs.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages5960–5969..cristina espa˜na-bonet,.
´ad´am csaba varga, albertobarr´on-cede˜no, and josef van genabith.
2017. anempirical analysis of nmt-derived interlingualembeddings and their use in parallel sentence iden-tiﬁcation.
ieee journal of selected topics in signalprocessing, pages 1340–1348..6498miquel espl`a-gomis and mikel l. forcada.
2010.combining content-based and url-based heuristics toharvest aligned bitexts from multilingual sites withbitextor.
the prague bulletin of mathematical lin-guistics, 9:77–86..thierry etchegoyhen and andoni azpeitia.
2016. set-theoretic alignment for comparable corpora.
inacl, pages 2009–2018..angela fan, shruti bhosale, holger schwenk, zhiyima, ahmed el-kishky, siddharth goyal, man-deep baines, onur celebi, guillaume wenzek,vishrav chaudhary, naman goyal, tom birch, vi-taliy liptchinsky, sergey edunov, edouard grave,be-michael auli, and armand joulin.
2020.yond english-centric multilingual machine transla-tion.
jmlr..angela fan, edouard grave, and armand joulin.
2019.reducing transformer depth on demand with struc-tured dropout..fangxiaoyu feng, yinfei yang, daniel cer, naveenarivazhagan, and wei wang.
2020.language-agnostic bert sentence embedding.
arxiv preprintarxiv:2007.01852..simon gottschalk and elena demidova.
2017. mul-intiwiki:wikipedia.
acm transactions on the web (tweb),11(1):6..text passage alignment.
interlingual.
edouard grave, piotr bojanowski, prakhar gupta, ar-mand joulin, and tomas mikolov.
2018. learningword vectors for 157 languages.
https://arxiv.
org/abs/1802.06893..mandy guo, qinlan shen, yinfei yang, hemingge, daniel cer, gustavo hernandez abrego, keithstevens, noah constant, yun-hsuan sung, brianstrope, and ray kurzweil.
2018. effective paral-lel corpus mining using bilingual sentence embed-dings.
arxiv:1807.11906..hany hassan, anthony aue, chang chen, vishalchowdhary,jonathan clark, christian feder-mann, xuedong huang, marcin junczys-dowmunt,william lewis, mu li, shujie liu, tie-yan liu,renqian luo, arul menezes, tao qin, frank seide,xu tan, fei tian, lijun wu, shuangzhi wu,yingce xia, dongdong zhang, zhirui zhang, andming zhou.
2018. achieving human parity onautomatic chinese to english news translation.
arxiv:1803.05567..jeff johnson, matthijs douze, and herv´e j´egou.
2017.billion-scale similarity search with gpus.
arxivpreprint arxiv:1702.08734..h. j´egou, m. douze, and c. schmid.
2011. prod-uct quantization for nearest neighbor search.
ieeetrans.
pami, 33(1):117–128..philipp koehn.
2005. europarl: a parallel corpus for.
statistical machine translation.
in mt summit..philipp koehn, francisco guzm´an, vishrav chaud-hary, and juan m. pino.
2019. findings of thewmt 2019 shared task on parallel corpus ﬁlteringfor low-resource conditions.
in proceedings of thefourth conference on machine translation, volume2: shared task papers, florence, italy.
associationfor computational linguistics..philipp koehn, huda khayrallah, kenneth heaﬁeld,and mikel l. forcada.
2018. findings of the wmt2018 shared task on parallel corpus ﬁltering.
in pro-ceedings of the third conference on machine trans-lation: shared task papers, pages 726–739, bel-gium, brussels.
association for computational lin-guistics..taku kudo and john richardson.
2018. sentencepiece:a simple and language independent subword tok-enizer and detokenizer for neural text processing.
inemnlp, pages 66–71..ivana kvapil´ıkov´a, mikel artetxe, gorka labaka amdeneko agirre, and ondˇrej bojar.
2020. unsuper-vised multilingual sentence embeddings for parallelcorpus mining.
in acl..p. lison and j. tiedemann.
2016. opensubtitles2016:extracting large parallel corpora from movie and tvsubtitles.
in lrec..marco lui and timothy baldwin.
2011. cross-domainfeature selection for language identiﬁcation.
in ijc-nlp, pages 553–561..mehdi zadeh mohammadi and nasser ghasemaghaee.
2010. building bilingual parallel corpora based onin 2010 second international confer-wikipedia.
ence on computer engineering and applications,pages 264–268..dragos stefan munteanu and daniel marcu.
2005. im-proving machine translation performance by ex-ploiting non-parallel corpora.
computational lin-guistics, 31(4):477–504..toshiaki nakazawa, hideki nakayama, chenchending, raj dabre, shohei higashiyama, hideyamino, isao goto, win pa pa, anoop kunchukut-tan, shantipriya parida, ondˇrej bojar, and sadaokurohashi.
2020. overview of the 7th workshop onasian translation.
in proceedings of the 7th work-shop on asian translation, pages 1–44..nathan ng, kyra yee, alexei baevski, myle ott,michael auli, and sergey edunov.
2019. facebookfair’s wmt19 news translation task submission.
inproceedings of the fourth conference on machinetranslation (volume 2: shared task papers, day1), pages 314–319, florence, italy.
association forcomputational linguistics..pablo gamallo otero and isaac gonz´alez l´opez.
2010.wikipedia as multilingual source of comparable cor-pora.
in proceedings of the 3rd workshop on build-ing and using comparable corpora, lrec, pages21–25..6499machine translation systems for wmt19.
in proceed-ings of the fourth conference on machine transla-tion (volume 2: shared task papers, day 1), pages374–381, florence, italy.
association for computa-tional linguistics..j. tiedemann.
2012. parallel data, tools and interfaces.
in opus.
in lrec..chen-tse tsai and dan roth.
2016. cross-lingualwikiﬁcation using multilingual embeddings.
in pro-ceedings of the 2016 conference of the north amer-ican chapter of the association for computationallinguistics: human language technologies, pages589–598..dan tuﬁs, radu ion, s, tefan daniel, dumitrescu, anddan s, tef˘anescu.
2013. wikipedia as an smt trainingcorpus.
in ranlp, pages 702–709..masao utiyama and hitoshi isahara.
2003. reliablemeasures for aligning japanese-english news arti-cles and sentences.
in acl..guillaume wenzek, marie-anne lachaux, alexis con-neau, vishrav chaudhary, francisco guzm´an, ar-mand joulin, and edouard grave.
2019.cc-net: extracting high quality monolingual datasetsfrom web crawl data.
https://arxiv.org/abs/1911.00359..yinfei yang, gustavo hern´andez ´abrego, steve yuan,mandy guo, qinlan shen, daniel cer, yun-hsuansung, brian strope, and ray kurzweil.
2019.improving multilingual sentence embedding usingbi-directional dual encoder with additive marginsoftmax.
in https://arxiv.org/abs/1902.
08564..michał ziemski, marcin junczys-dowmunt, and brunopouliquen.
2016. the united nations parallel cor-pus v1.0.
in lrec..pierre zweigenbaum, serge sharoff, and reinhardrapp.
2018. overview of the third bucc sharedtask: spotting parallel sentences in comparablein proceedings of the 11th workshop oncorpora.
building and using comparable corpora..myle ott, sergey edunov, david grangier, andmichael auli.
2018. scaling neural machine trans-lation.
arxiv:1806.00187..alexandre patry and philippe langlais.
2011. identify-ing parallel documents from a large bilingual collec-tion of texts: application to parallel article extrac-tion in wikipedia.
in proceedings of the 4th work-shop on building and using comparable corpora:comparable corpora and the web, pages 87–95.
as-sociation for computational linguistics..ye qi, devendra sachan, matthieu felix, sarguna pad-manabhan, and graham neubig.
2018. when andwhy are pre-trained word embeddings useful for neu-ral machine translation?
in proceedings of the 2018conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 2 (short papers),pages 529–535, new orleans, louisiana.
associa-tion for computational linguistics..a. radford,.
jeffrey wu, r. child, david luan,lan-unsupervised multitaskin https://openai.com/blog/.
dario amodei, and ilya sutskever.
2019.areguage modelslearners.
better-language-models/..philip resnik.
1999. mining the web for bilingual.
text.
in acl..philip resnik and noah a. smith.
2003. the webas a parallel corpus.
computational linguistics,29(3):349–380..holger schwenk.
2018. filtering and mining parallelin acl, pages.
data in a joint multilingual space.
228–234..holger schwenk, vishrav chaudhary, shuo sun,hongyu gong, and francisco guzm´an.
2019. wiki-matrix: mining 135m parallel sentences in 1620 lan-in http://arxiv.
guage pairs from wikipedia.
org/abs/1907.05791..rico sennrich, barry haddow, and alexandra birch.
2016. neural machine translation of rare words withsubword units.
in proceedings of the 54th annualmeeting of the association for computational lin-guistics, pages 1715–1725..mohammad shoeybi, mostofa patwary, raul puri,patrick legresley, jared casper, and bryan catan-zaro.
2019. megatron-lm: training multi-billion pa-rameter language models using model parallelism.
corr, abs/1909.08053..jason r. smith, chris quirk, and kristina toutanova.
2010. extracting parallel sentences from compa-rable corpora using document level alignment.
innaacl, pages 403–411..meng sun, bojian jiang, hao xiong, zhongjun he,hua wu, and haifeng wang.
2019. baidu neural.
6500