knowledgeable or educated guess?
revisiting language models asknowledge basesboxi cao1,3, hongyu lin1∗, xianpei han1,2∗, le sun1,2lingyong yan1,3, meng liao4, tong xue4, jin xu41chinese information processing laboratory 2state key laboratory of computer scienceinstitute of software, chinese academy of sciences, beijing, china3university of chinese academy of sciences, beijing, china4data quality team, wechat, tencent inc., china{boxi2020,hongyu,xianpei,sunle,lingyong2014}@iscas.ac.cn{maricoliao,xavierxue,jinxxu}@tencent.com.
abstract.
previous literatures show that pre-trainedmasked language models (mlms) such asbert can achieve competitive factual knowl-edge extraction performance on some datasets,indicating that mlms can potentially be a reli-able knowledge source.
in this paper, we con-duct a rigorous study to explore the underly-ing predicting mechanisms of mlms over dif-ferent extraction paradigms.
by investigatingthe behaviors of mlms, we ﬁnd that previousdecent performance mainly owes to the biasedprompts which overﬁt dataset artifacts.
fur-thermore, incorporating illustrative cases andexternal contexts improve knowledge predic-tion mainly due to entity type guidance andgolden answer leakage.
our ﬁndings shedlight on the underlying predicting mechanismsof mlms, and strongly question the previousconclusion that current mlms can potentiallyserve as reliable factual knowledge bases1..1.introduction.
recently, pre-trained language models (peters et al.,2018; devlin et al., 2019; brown et al., 2020) haveachieved promising performance on many nlptasks.
apart from utilizing the universal representa-tions from pre-trained models in downstream tasks,some literatures have shown the potential of pre-trained masked language models (e.g., bert (de-vlin et al., 2019) and roberta (liu et al., 2019b))to be factual knowledge bases (petroni et al., 2019;bouraoui et al., 2020; jiang et al., 2020b; shin et al.,2020; jiang et al., 2020a; wang et al., 2020; kass-ner and sch¨utze, 2020a; kassner et al., 2020).
forexample, to extract the birthplace of steve jobs, wecan query mlms like bert with “steve jobs wasborn in [mask]”, where steve jobs is the subject.
∗corresponding authors1we openly release the source code and data at https:.
//github.com/c-box/lanka.
figure 1: this paper explores three different kinds offactual knowledge extraction paradigms from mlms,and reveal the underlying predicting mechanisms be-hind them..of the fact, “was born in” is a prompt string for therelation “place-of-birth” and [mask] is aplaceholder for the object to predict.
then mlmsare expected to predict the correct answer “califor-nia” at the [mask] position based on its internalknowledge.
to help mlms better extract knowl-edge, the query may also be enriched with externalinformation like illustrative cases (e.g., (obama,hawaii)) (brown et al., 2020) or external context(e.g., jobs lives in california) (petroni et al., 2020).
some literatures have shown that such paradigmscan achieve decent performance on some bench-marks like lama (petroni et al., 2019)..despite some reported success, currently thereis no rigorous study looking deeply into the un-derlying mechanisms behind these achievements.
besides, it is also unclear whether such achieve-ments depend on certain conditions (e.g., datasets,domains, relations).
the absence of such kind ofstudies undermines our trust in the predictions ofmlms.
we could neither determine whether thepredictions are reliable nor explain why mlmsmake a speciﬁc prediction, and therefore signiﬁ-cantly limits mlms’ further applications and im-provements..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1860–1874august1–6,2021.©2021associationforcomputationallinguistics1860promptbias“wasbornin”withoutxpredicts <?>typeguidance<?>willhavethesametypeasbanswerleakagecontexthelpsifitleaks<?>mechanism prompt-basedxwasbornin<?>.case-basedawasborninb.xwasbornin<?>.context-basedxlivesiny.xwasbornin<?>.paradigm to this end, this paper conducts a thorough studyon whether mlms could be reliable factual knowl-edge bases.
throughout our investigations, weanalyze the behaviors of mlms, ﬁgure out thecritical factors for mlms to achieve decent per-formance, and demonstrate how different kinds ofexternal information inﬂuence mlms’ predictions.
speciﬁcally, we investigate factual knowledge ex-traction from mlms2 over three representative fac-tual knowledge extraction paradigms, as shown infigure 1:.
• prompt-based retrieval (petroni et al., 2019;jiang et al., 2020b; shin et al., 2020), whichqueries mlm for object answer only given thesubject and the corresponding relation promptas input, e.g., “jobs was born in [mask].”.
• case-based analogy (brown et al., 2020;madotto et al., 2020; gao et al., 2020), whichenhances the prompt-based retrieval with sev-eral illustrative cases, e.g., “obama was bornin hawaii.
[sep] jobs was born in [mask].”.
• context-based inference (petroni et al.,2020; bian et al., 2021), which augmentsthe prompt-based retrieval with external rele-vant contexts, e.g., “jobs lives in california.
[sep] jobs was born in [mask].”.
surprisingly, the main conclusions of this pa-per somewhat diverge from previous ﬁndings inpublished literatures, which are summarized in fig-ure 1. for prompt-based paradigm (§ 3), we ﬁndthat the prediction distribution of mlms is signiﬁ-cantly prompt-biased.
speciﬁcally, we ﬁnd thatprompt-based retrieval generates similar predic-tions on totally different datasets.
and predictionsare spuriously correlated with the applied prompts,rather than the facts we want to extract.
therefore,previous decent performance mainly stems fromthe prompt over-ﬁtting the dataset answer distri-bution, rather than mlms’ knowledge extractionability.
our ﬁndings strongly question the conclu-sions of previous literatures, and demonstrate thatcurrent mlms can not serve as reliable knowledgebases when using prompt-based retrieval paradigm..2this paper shows the experimental results on bert-largebecause previous work has shown that it can achieve thebest performance on factual knowledge extraction among allmlms.
in the appendix, we also report the experimentalresults on roberta-large, which also reach the main conclu-sions reported in the paper..for case-based paradigm (§ 4), we ﬁnd that theillustrative cases mainly provide a “type guidance”for mlms.
to show this, we propose a novel al-gorithm to induce the object type of each relationbased on wikidata3 taxonomy.
according to theinduced types, we ﬁnd that the performance gainbrought by illustrative cases mainly owes to theimprovement on recognizing object type.
by con-trast, it cannot help mlms select the correct answerfrom the entities with the same type: the rank ofanswer within its entity type is changed randomlyafter introducing illustrative cases.
that is to say,under the case-based paradigm, although mlmscan effectively analogize between entities with thesame type, they still cannot well identify the exacttarget object based on their internal knowledge andthe provided illustrative cases..for context-based paradigm (§ 5), we ﬁnd thatcontext can help the factual knowledge extractionmainly because it explicitly or implicitly leaks thecorrect answer.
speciﬁcally, the knowledge ex-traction performance improvement mainly happenswhen the introduced context contains the answer.
furthermore, when we mask the answer in the con-text, the performance still signiﬁcantly improves aslong as mlms can correctly reconstruct the maskedanswer in the remaining context.
in other words, inthese instances, the context itself servers as a dele-gator of the masked answer, and therefore mlmscan still obtain sufﬁcient implicit answer evidenceeven the answer doesn’t explicitly appear..all the above ﬁndings demonstrate that currentmlms are not reliable in factual knowledge extrac-tion.
furthermore, this paper sheds some light onthe underlying predicting mechanisms of mlms,which can potentially beneﬁt many future studies..2 related work.
the great success of pre-trained language models(plms) raises the question of whether plms can bedirectly used as reliable knowledge bases.
petroniet al.
(2019) propose the lama benchmark, whichprobes knowledge in plms using prompt-basedretrieval.
jiang et al.
(2020a) build a multilingualknowledge probing benchmark based on lama.
there are many studies focus on probing speciﬁcknowledge in plms, such as linguistic knowl-edge (lin et al., 2019; tenney et al., 2019; liuet al., 2019a; htut et al., 2019; hewitt and man-ning, 2019; goldberg, 2019; warstadt et al., 2019),.
3www.wikidata.org.
1861semantic knowledge (tenney et al., 2019; wal-lace et al., 2019; ettinger, 2020) and world knowl-edge (davison et al., 2019; bouraoui et al., 2020;forbes et al., 2019; zhou et al., 2019; roberts et al.,2020; lin et al., 2020; tamborrino et al., 2020).
re-cently, some studies doubt the reliability of plmsas knowledge base by discovering the the spuriouscorrelation to surface forms (mccoy et al., 2019;poerner et al., 2020; shwartz et al., 2020), and theirsensitivity to “negation” and “mispriming” (kass-ner and sch¨utze, 2020b)..currently, there are three main paradigms forknowledge extraction from plms: prompt-basedretrieval (schick and sch¨utze, 2021; li and liang,2021), case-based analogy (schick and sch¨utze,2020a,b), and context-based inference.
for prompt-based retrieval, current studies focus on seekingbetter prompts by either mining from corpus (jianget al., 2020b) or learning using labeled data (shinet al., 2020).
for case-based analogy, current stud-ies mostly focus on whether good cases will leadto good few-shot abilities, and many tasks aretried (brown et al., 2020; madotto et al., 2020;gao et al., 2020).
for context-based inference, cur-rent studies focus on enhancing the prediction byseeking more informative contexts, e.g., for knowl-edge extraction (petroni et al., 2020) and com-monsenseqa (bian et al., 2021).
however, thereis no previous work which focuses on systemati-cally study the underlying predicting mechanismsof mlms on these paradigms..3 prompt-based retrieval.
factualthe prompt-based retrieval extractsknowledge by querying mlms with (subject,prompt, [mask]).
for example, to extract the“place-of-birth” of steve jobs, we couldquery bert with “steve jobs was born in[mask].” and the predicted “california” wouldbe regarded as the answer.
we consider three kindsof prompts: the manually prompts tman createdby petroni et al.
(2019), the mining-based promptstmine by jiang et al.
(2020b) and the automaticallysearched prompts tauto from shin et al.
(2020)..3.1 overall conclusion.
conclusion 1. prompt-based retrieval is prompt-biased.
as a result, previous decent performanceactually measures how well the applied promptsﬁt the dataset answer distribution, rather than thefactual knowledge extraction ability from mlms..(a) the true answer distributions are very different betweenlama and wiki-uni..(b) however, the prediction distribution made by mlms onthem are still very similar..figure 2: an illustration example of the vastly differentanswer distributions but similar prediction distributionson lama and wiki-uni on “place-of-birth”relation..speciﬁcally, we conduct studies and ﬁnd that1) prompt-based retrieval will generate similar re-sponses given quite different datasets.
to show this,we construct a new dataset from wikidata – wiki-uni, which have a totally different answer distribu-tion from the widely-used lama4 dataset (petroniet al., 2019).
however, we ﬁnd that the predic-tion distributions on wiki-uni and lama arehighly correlated, and this spurious correlationholds across different prompts.
such results re-veal that there is just a weak correlation betweenthe predictions of mlms and the factual answerdistribution of the dataset.
2) the prediction dis-tribution is dominated by the prompt, i.e., the pre-diction distribution using only (prompt, [mask])is highly correlated to the prediction distributionusing (subject, prompt, [mask]).
this indicatesthat it is the applied prompts, rather than the ac-tual facts, determine the predictions of mlms.
3)the performance of the prompt can be predictedby the divergence between the prompt-only distri-bution and the answer distribution of the dataset.
all these ﬁndings reveal that previous decent per-formance in this ﬁeld actually measures the degreeof prompt-dataset ﬁtness, rather than the universalfactual knowledge extraction ability..3.2 different answers, similar predictions.
finding 1. prompt-based retrieval will generatesimilar responses to quite different datasets..a reliable knowledge extractor should generate.
4since we focus on factual knowledge, we use the t-.
rex (elsahar et al., 2018) subset of the lama benchmark..1862londonparisrometokyobostonchicagomontrealberlinmilanmoscowlamawiki-uni0.10.2londonparisrometokyobostonchicagomontrealberlinmilanmoscowlamawiki-uni0.20.4figure 3: correlations of the prediction distributions onlama and wiki-uni.
even these two datasets havetotally different answer distributions, mlms still makehighly correlated predictions..lama.
answer.
distribution datasets top1 top3 top5 precision22.041.6831.0927.12.
48.037.7857.9352.18.
--30.3616.47.
39.375.0349.2144.19.prediction.
wiki-uni.
wiki-uni.
lama.
table 1: average percentage of instances being cov-ered by top-k answers or predictions.
for answer dis-tribution, top-5 objects in lama cover 6.2 times ofinstances than that in wiki-uni, however, for predic-tion distribution, they are almost the same.
as a result,the precision is signiﬁcantly dropped in wiki-uni..different responses to different knowledge queries.
to verify whether mlms meet this standard, wemanually construct a new dataset – wiki-uni,which has a comparable size but totally differentanswer distribution to lama, and then comparethe prediction distributions on them.
for a faircomparison, we follow the construction criteria oflama: we use the same 41 relations, ﬁlter outthe queries whose objects are not in the mlms’vocabulary.
compared with lama, the major dif-ference is that wiki-uni has a uniform answerdistribution, i.e., for each relation, we keep thesame number of instances for each object.
pleaserefer to appendix for more construction details.
figure 2a shows the answer distributions of lamaand wiki-uni on relation “place-of-birth”.
we can see that the answers in lama are highlyconcentrated on the head object entities, while theanswers in wiki-uni follow a uniform distribu-tion..given lama and wiki-uni, we investigatethe predicting behaviors of mlms.
surprisingly,the prediction distributions on these two totallydifferent datasets are highly correlated.
figure 2bshows an example.
we can see that the predictiondistribution on wiki-uni is very similar to that onlama.
and these two distributions are both closeto the answer distribution of lama but far awayfrom the answer distribution of wiki-uni..to investigate whether this spurious correlation.
figure 4: correlations between the prompt-only dis-tribution and prediction distribution on wiki-uni.
mlms make correlated predictions w. or w/o.
subjects..is a common phenomenon, we analyze the pearsoncorrelation coefﬁcient between prediction distribu-tions on lama and wiki-uni across differentrelations and three kinds of prompts.
the boxplotin figure 3 shows the very signiﬁcant correlationbetween the prediction distributions on lama andwiki-uni: on all three kinds of prompts, the cor-relation coefﬁcients exceed 0.8 in more than halfof relations.
these results demonstrate that prompt-based retrieval will lead to very similar predictiondistributions even when test sets have vastly differ-ent answer distributions..furthermore, we ﬁnd that the prediction distri-bution obviously doesn’t correspond to the answerdistribution of wiki-uni.
from table 1, we cansee that on average, the top-5 answers of each rela-tion in wiki-uni cover only 7.78% instances.
bycontrast, the top-5 predictions of each relation inwiki-uni cover more than 52% instances, whichis close to the answer distribution and predictiondistribution on lama.
as a result, the perfor-mance on wiki-uni (mean p@1: 16.47) is sig-niﬁcantly worse than that on lama (mean p@1:30.36).
in conclusion, the facts of a dataset cannotexplain the predictions of mlms, and therefore pre-vious evaluations of the mlms’ ability on factualknowledge extraction are unreliable..3.3 prompts dominates predictions.
finding 2. the prediction distribution is severelyprompt-biased..to investigate the underlying factors of the pre-dicting behavior of mlms, we compare the prompt-only prediction distribution using only (prompt,[mask]) and the full prediction distribution using(subject, prompt, [mask]).
to obtain the prompt-only distribution, we mask the subject and then use([mask], prompt, [mask]) to query mlms (e.g.,[mask] was born in [mask]).
because there is nosubject information in the input, mlms can onlydepend on applied prompt’s information to make.
18630.20.40.60.81.0tmantminetauto0.00.20.40.60.81.0tmantminetautothe prediction at the second [mask].
therefore,we regard the probability distribution at the second[mask] symbol as the prompt-only distribution.
after that, we analyze the correlations betweenthe prompt-only distribution and the prediction dis-tribution on wiki-uni dataset.
figure 4 showsthe boxplot.
on all three kinds of prompts, correla-tion coefﬁcients between the prompt-only distribu-tion and the prediction distribution on wiki-uniexceed 0.6 in more than half of relations.
thisdemonstrates that in these relations, the prompt-only distribution dominates the prediction distribu-tion.
combining with the ﬁndings in section 3.2,we can summarize that the prompt-based retrievalis mainly based on guided guessing, i.e., the predic-tions are generated by sampling from the prompt-biased distribution guided by the moderate impactof subjects..note that among a minor part of relations, thecorrelations between the prompt-only distributionand the prediction distribution are relatively low.
we ﬁnd that the main reason is the type selectionalpreference provided by the subject entities, andsection 4 will further discuss the impact of thistype-guidance mechanism for mlms..3.4 better prompts are over-fitting.
“better” prompts are the promptsfinding 3.ﬁtting the answer distribution better, rather thanthe prompts with better retrieval ability..some previous literatures attempt to ﬁnd bet-ter prompts for factual knowledge extraction frommlms.
however, as we mentioned above, theprompt itself will lead to a biased prediction dis-tribution.
this raises our concern that whether thefound better prompts are really with better knowl-edge extraction ability, or the better performancejust come from the over-ﬁtting between the prompt-only distribution and the answer distribution of thetest set..to answer this question, we evaluate the kldivergence between the prompt-only distributionand the answer distribution of lama on differentkinds of prompts.
the results are shown in ta-ble 2. we ﬁnd that the kl divergence is a strongindicator of the performance of a prompt, i.e., thesmaller the kl divergence between the prompt-only distribution and the answer distribution ofthe test set is, the better performance the promptachieve.
furthermore, table 3 shows several com-parisons between different kinds of prompts and.
prompt precision kl divergencetmantminetauto.
30.3639.4940.36.
12.2710.4010.27.table 2: the smaller kl divergence between theprompt-only distribution and golden answer distribu-tion of lama, the better performance of the prompt..relation.
citizenship.
work location.
instance of.
promptx is y citizenx returned to yx used to work in yx was born in yx is a yx is a small y.source prec.
kl.
tman24.670.00tmine6.3243.58tman19.0711.01tmine2.2140.25tman22.9830.15tmine13.9852.60.table 3: examples of prompts that can achieve signiﬁ-cant improvements on lama.
we can see that the bet-ter performance actually stems from over-ﬁtting:thebetter prompts are not prompts with a stronger seman-tic association to the relation..their performance on lama.
we can easily ob-serve that the better-performed prompts are actuallyover-ﬁtting the dataset, rather than better capturingthe underlying semantic of the relation.
as a re-sult, previous prompt searching studies are actuallyoptimized on the spurious prompt-dataset compati-bility, rather than the universal factual knowledgeextraction ability..4 case-based analogy.
the case-based analogy enhances the prompt-basedparadigm with several illustrative cases.
for exam-ple, if we want to know the “place-of-birth”of steve jobs, we would ﬁrst sample cases such as(obama, place-of-birth, hawaii), and com-bine them with the original query.
in this way, wewill use “obama was born in hawaii.
[sep] stevejobs was born in [mask].” to query mlms..4.1 overall conclusion.
conclusion 2. illustrative cases guide mlms tobetter recognizing object type, rather than betterpredicting facts..to show this, we ﬁrst design an effective algo-rithm to induce the type of an entity set based onwikidata taxonomy, which can identify the objecttype of a relation.
according to the induced types,we ﬁnd that the beneﬁts of illustrative cases mainlystem from the promotion of object type recognition.
in other words, case-based analogy guides mlmswith better type prediction ability but contributes.
1864figure 5: illustration of our type induction algorithm.
the numbers on the right of each type indicate howmany entities does the type cover.
the type of an en-tity set is the ﬁnest grained type in the type graph thatcan cover a sufﬁcient number of the instances in theentity set, which is city in the example..little to the entity prediction ability.
in the follow-ing, we ﬁrst illustrate our type inducing algorithm,and then explain how we reach the conclusion..4.2 entity set type induction.
to induce the object type of a relation, we ﬁrstcollect all its objects in lama and form an entityset.
then we induce the type of an entity set bydesigning a simple but effective algorithm.
themain intuition behind our algorithm is that a rep-resentative type should be the ﬁnest grained typethat can cover a sufﬁcient number of the instancesin the entity set.
figure 5 shows an example of ouralgorithm.
given a set of entities in wikidata, weﬁrst construct an entity type graph (etg) by recur-sively introducing all ancestor entity types accord-ing to the instance-of and subclass-ofrelations.
for the example in figure 5, chicagois in the entity set and is an instance-of bigcity.
big city is a subclass-of city.
as aresult, chicago, big city and city will all be intro-duced into etg.
then we apply topological sorting(cook, 1985) to etg to obtain a fine-to-coarse en-tity type sequence.
finally, based on the sequence,we select the ﬁrst type which covers more than 80%of entities in the entity set (e.g., city in figure 5).
table 4 illustrates several induced types, and pleaserefer to the appendix for details..4.3 cases help type recognition.
finding 4. illustrative cases help mlms to betterrecognize the type of objects, and therefore improvefactual knowledge extraction..for case-based analogy, the ﬁrst thing we wantto know is whether illustrative cases can improvethe knowledge extraction performance.
to this end,for each (subject, relation) query in lama, we.
figure 6: percentages on the change of overall rank(among all candidates) and the in-type rank (amongcandidates with the same type) of golden answer.
wecan see that the illustrative cases mainly raise the over-all rank but cannot raise the in-type rank, which meansthe performance improvements mainly come from bet-ter type recognition..randomly sample 10 illustrative cases.
to avoidanswer leakage, we ensure the objects of thesecases don’t contain the golden answer of the query.
then we use (cases, subject, prompt, [mask]) asthe analogous query to mlms..results show that case-based analogy can signif-icantly improve performance.
after introducing il-lustrative cases, the mean precision increases from30.36% to 36.23%.
besides, we ﬁnd that 11.81%instances can beneﬁt from the introduced cases andonly 5.94% instances are undermined.
this showsthat case-based analogy really helps the mlms tomake better predictions..by analyzing the predicting behaviors, we ob-serve that the main beneﬁt of introducing illus-trative cases comes from the better type recogni-tion.
to verify this observation, we investigatehow the types of predictions changed after intro-ducing the illustrative cases.
table 4 shows the re-sults on relations whose precision improvement ismore than 10% after introducing illustrative cases.
from the table, it is very obvious that illustrativecases enhance the factual knowledge extraction byimproving type prediction: 1) for queries whosepredictions are correctly reversed (from wrong toright), the vast majority of them stems from therevised type prediction; 2) even for queries whosepredictions are mistakenly reversed (from right towrong), the type of the majority of predictions stillremains correct.
in conclusion, introducing illustra-tive cases can signiﬁcantly improve the knowledgeextraction ability by recognizing the object typemore accurately.
that is, adding illustrative caseswill provide more guidance for object type..1865londonchicagocapital1milanbigcity2city3area3area1.0city1.0entitysetentitytypesequenceentitytypegraphbigcity0.6capital0.325%30%35%40%45%in-typerankoverallrankraisedunchangeddroppedrelation.
induced object type.
country of citizenship sovereign stateposition heldreligionwork locationinstrumentcountryemployercontinent.
religious servantreligioncitymusical instrumentsovereign statebusinesscontinent.
precision∆43.3736.8833.2026.1017.0714.3012.0110.87.typeprec.
∆84.1680.2634.8870.5555.7529.0499.2251.18.wrong → rightw/ type change100.0091.15100.0085.0489.0888.48100.0096.86.right → wrongw/o type change-90.00-100.0075.0087.93-88.24.table 4: detailed analysis on relations where the mean precision increased more than 10%.
precision ∆ and typeprec.
∆ represents the precision changes on the answer and the type of the answer respectively.
“w/ type change”and “w/o type change” represents the type of prediction changed/unchanged before/after introducing illustrativecases.
“-” indicate there is no queries whose predictions are mistakenly reversed..4.4 cases do not help entity prediction.
illustrative cases are of limited helpfinding 5.for selecting the answer from entities of the sametype..to show this, we introduce a new metric referredas in-type rank, which is the rank of the correct an-swer within the entities of the same type for a query.
by comparing the in-type rank in prompt-basedand case-based paradigm, we can evaluate whetherthe illustrative cases can actually help better entityprediction apart from better type recognition..figure 6 shows the percentages on the changeof overall rank (among all candidates) and thein-type rank (among candidates with the sametype) of golden answer.
unfortunately, we ﬁndthat illustrative cases are of limited help for en-the change of in-type rank istity prediction:nearly random.
the percentages of queries withraised/unchanged/dropped in-type rank are nearlythe same: 33.05% vs 35.47% vs 31.47%.
fur-thermore, we ﬁnd that the mrr with the type onlychanged from 0.491 to 0.494, which shows littleimprovement after introducing illustrative cases.
these results show that the raises of overall rank ofgolden answer are not because of the better predic-tion inside the same type.
in conclusion, illustrativecases cannot well guide the entity prediction, andthey mainly beneﬁt the factual knowledge extrac-tion by providing guidance for object type recogni-tion..5 context-based inference.
answerin contextpresent(45.30%)absent(54.70 %).
prompt-based context-based.
∆.
34.83.
25.37.
64.13.
+29.30.
23.26.
-2.11.table 5: comparison between prompt-based andcontext-based paradigms grouped by whether the an-swer presents or absents in the context.
we can see thatonly contexts containing the answer can signiﬁcantlyimprove the performance..query “jobs was from california.
[sep] steve jobswas born in [mask].” to query mlms.
specif-ically, we use the same context retrieval methodas petroni et al.
(2020): for each instance, giventhe subject and relation as query, we use the ﬁrstparagraph of drqa’s (chen et al., 2017) retrieveddocument as external contexts..5.1 overall conclusion.
conclusion 3. additional context helps mlms topredict the answer because they contain the answer,explicitly or implicitly..several studies (petroni et al., 2020; bian et al.,2021) show that external context can help knowl-edge extraction from mlms.
to investigate theunderlying mechanism, we evaluate which kindsof information in contexts contribute to the factprediction, and ﬁnd that the improvement mainlycomes from the answer leakage in context.
further-more, we ﬁnd the answers can not only be leakedexplicitly, but can also be leaked implicitly if thecontext provides sufﬁcient information..the context-based inference augments the prompt-based paradigm with external contexts.
for exam-ple, if we want to know the “place-of-birth”of steve jobs, we can use the external context “jobswas from california.”, and form a context-enriched.
5.2 explicit answer leakage helps.
finding 6. explicit answer leakage signiﬁcantlyimproves the prediction performance..to show this, we split lama into two parts ac-.
1866prompt-based context-based masked context-based.
30.36.
41.44.
35.66.table 6: overall performance when introducing differ-ent kinds of contexts.
“masked context-based” indi-cates that we mask the golden answer in contexts, andthere is still a signiﬁcant performance improvement..answerreconstructablereconstructable(60.23%)not-reconstructable(39.77 %).
prompt-based context-based.
∆.
39.58.
28.84.
60.82.
+21.24.
35.83.
+6.99.
table 7: comparison between prompt-based andcontext-based paradigms grouped by whetherthemasked answer in the context can be reconstructedfrom the remaining context.
we can see that contextscan reconstruct the masked answer is more likely to im-prove the performance..cording to whether the additional context containsthe answer.
table 5 shows the results on these twoparts respectively.
we can see that the improve-ments on these two parts diverge signiﬁcantly.
forcontext containing the answer, context-based infer-ence signiﬁcantly improves the factual knowledgeextraction performance.
however, there is even alittle performance drop for those instances whosecontext does not contain the answer.
this indicatesthat the improvement of factual knowledge extrac-tion is mainly due to the explicit existence of theanswer in the context..5.3.implicit answer leakage helps.
implicit answer leakage can alsofinding 7.signiﬁcantly improve the prediction performance.
as we mentioned above, explicit answer leak-age signiﬁcantly helps the answer prediction.
theanswer-leaked context may explicitly provide theanswer or implicitly guide the prediction by provid-ing answer-speciﬁc information.
to understandingthe underlying mechanism, we mask the answer inthe context and verify whether it can still achievethe performance gain..table 6 shows the results.
we ﬁnd that the per-formance gain is still very signiﬁcant after mask-ing the answer.
this indicates that the contextspreviously containing the answer are still very ef-fective even the answer doesn’t explicitly present.
to further investigate the reason behind, we splitthe masked version of answer-leaked instances intotwo groups by whether mlms can or cannot cor-rectly reconstruct the masked answer from the re-.
maining context.
the results are shown in table 7.we can see that the performance gain signiﬁcantlydiverges in these two groups: the improvementsmainly come from the instances whose answer incontext can be reconstructed – we refer to this asimplicit answer leakage.
that is to say, for theseinstances, the context serves as a sufﬁcient delega-tor of its answer, and therefore mlms can obtainsufﬁcient answer evidence even the answer doesnot explicitly appear.
however, for contexts thatcannot reconstruct the masked answer, the improve-ments are relatively minor.
in conclusion, the realefﬁcacy of context-based inference comes from thesufﬁcient answer evidence provided by the context,either explicitly or implicitly..6 conclusions and discussions.
in this paper, we thoroughly study the underly-ing mechanisms of mlms on three representativefactual knowledge extraction paradigms.
we ﬁndthat the prompt-based retrieval is severely prompt-biased, illustrative cases enhance mlms mainly viatype guidance, and external contexts help knowl-edge prediction mostly because they contain thecorrect answer, explicitly or implicitly.
theseﬁndings strongly question previous conclusionsthat current mlms could serve as reliable factualknowledge bases..the ﬁndings of this paper can beneﬁt the commu-nity in many directions.
by explaining the underly-ing predicting mechanisms of mlms, we providereliable explanations for many previous knowledge-intensive techniques.
for example, our method canexplain why and how incorporating external con-texts will help knowledge extraction and common-senseqa (talmor et al., 2019).
our ﬁndings alsoreveal why plm probing datasets may not be re-liable and how the evaluation can be promoted bydesigning de-biased evaluation datasets..this paper also sheds light on future researchdirections.
for instance, knowing the main bene-ﬁt of illustrative cases comes from type-guidance,we can enhance many type-centric prediction taskssuch as ner (lample et al., 2016) and factoidqa (iyyer et al., 2014).
moreover, based on themechanism of incorporating external contexts, wecan better evaluate, seek, and denoise external con-texts for different tasks using mlms.
for exam-ple, we can assess and select appropriate facts forcommonsenseqa based on whether they can re-construct the candidate answers..1867this paper focuses on masked language mod-els, which have been shown very effective and arewidely used.
we also want to investigate anotherrepresentative category of language models – thegenerative pre-trained models (e.g., gpt2/3 (rad-ford et al., 2019; brown et al., 2020)), which havebeen shown to have quite different mechanisms andwe leave it for future work due to page limitation..acknowledgments.
we sincerely thank all anonymous reviewers fortheir insightful comments and valuable suggestions.
this work is supported by the national key re-search and development program of china (no.
2020aaa0106400), the national natural sciencefoundation of china under grants no.
u1936207,and in part by the youth innovation promotion as-sociation cas(2018141)..references.
ning bian, xianpei han, bo chen, and le sun.
2021. benchmarking knowledge-enhanced com-monsense question answering via knowledge-to-text transformation.
arxiv:2101.00760 [cs]..zied bouraoui, jos´e camacho-collados, and stevenschockaert.
2020.inducing relational knowledgefrom bert.
in the thirty-fourth aaai conferenceon artiﬁcial intelligence, aaai 2020, the thirty-second innovative applications of artiﬁcial intelli-gence conference, iaai 2020, the tenth aaai sym-posium on educational advances in artiﬁcial intel-ligence, eaai 2020, new york, ny, usa, february7-12, 2020, pages 7456–7463.
aaai press..tom b. brown, benjamin mann, nick ryder, melaniesubbiah, jared kaplan, prafulla dhariwal, arvindneelakantan, pranav shyam, girish sastry, amandaaskell, sandhini agarwal, ariel herbert-voss,gretchen krueger, tom henighan, rewon child,aditya ramesh, daniel m. ziegler, jeffrey wu,clemens winter, christopher hesse, mark chen,eric sigler, mateusz litwin, scott gray, benjaminchess, jack clark, christopher berner, sam mc-candlish, alec radford, ilya sutskever, and darioamodei.
2020. language models are few-shot learn-ers.
in advances in neural information processingsystems 33: annual conference on neural informa-tion processing systems 2020, neurips 2020, de-cember 6-12, 2020, virtual..danqi chen, adam fisch, jason weston, and antoinebordes.
2017. reading wikipedia to answer open-in proceedings of the 55th an-domain questions.
nual meeting of the association for computationallinguistics (volume 1: long papers), pages 1870–1879, vancouver, canada.
association for computa-tional linguistics..stephen a. cook.
1985. a taxonomy of problems withinformation and control,.
fast parallel algorithms.
64(1):2–22..joe davison, joshua feldman, and alexander rush.
2019. commonsense knowledge mining from pre-in proceedings of the 2019 con-trained models.
ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 1173–1178, hong kong, china.
as-sociation for computational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..hady elsahar, pavlos vougiouklis, arslen remaci,jonathon hare, frederiquechristophe gravier,laforest, and elena simperl.
2018. t-rex: a largescale alignment of natural language with knowledgebase triples.
in proceedings of the eleventh interna-tional conference on language resources and eval-uation (lrec 2018), miyazaki, japan.
europeanlanguage resources association (elra)..allyson ettinger.
2020. what bert is not: lessonsfrom a new suite of psycholinguistic diagnostics forlanguage models.
transactions of the associationfor computational linguistics, 8:34–48..maxwell forbes, ari holtzman, and yejin choi.
2019.do neural language representations learn physi-cal commonsense?
arxiv:1908.02899 [cs]..tianyu gao, adam fisch, and danqi chen.
2020. mak-ing pre-trained language models better few-shotlearners.
arxiv:2012.15723 [cs]..yoav goldberg.
2019. assessing bert’s syntactic.
abilities.
arxiv:1901.05287 [cs]..john hewitt and christopher d. manning.
2019. astructural probe for ﬁnding syntax in word repre-sentations.
in proceedings of the 2019 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4129–4138, minneapolis, minnesota.
associ-ation for computational linguistics..phu mon htut, jason phang, shikha bordia, anddo attentionsamuel r. bowman.
2019.heads in bert track syntactic dependencies?
arxiv:1911.12246 [cs]..mohit iyyer, jordan boyd-graber, leonardo claudino,richard socher, and hal daum´e iii.
2014. a neuralnetwork for factoid question answering over para-in proceedings of the 2014 conference ongraphs..1868empirical methods in natural language processing(emnlp), pages 633–644..zhengbao jiang, antonios anastasopoulos, jun araki,haibo ding, and graham neubig.
2020a.
x-factr: multilingual factual knowledge retrievalfrom pretrained language models.
in proceedings ofthe 2020 conference on empirical methods in nat-ural language processing (emnlp), pages 5943–5959, online.
association for computational lin-guistics..zhengbao jiang, frank f. xu, jun araki, and grahamneubig.
2020b.
how can we know what languagemodels know?
transactions of the association forcomputational linguistics, 8:423–438..nora kassner, benno krojer, and hinrich sch¨utze.
2020. are pretrained language models symbolicin proceedings ofreasoners over knowledge?
the 24th conference on computational natural lan-guage learning, pages 552–564, online.
associa-tion for computational linguistics..nora kassner and hinrich sch¨utze.
2020a.
bert-knn: adding a knn search component to pretrainedlanguage models for better qa.
in findings of theassociation for computational linguistics: emnlp2020, pages 3424–3430, online.
association forcomputational linguistics..nora kassner and hinrich sch¨utze.
2020b.
negatedand misprimed probes for pretrained language mod-els: birds can talk, but cannot ﬂy.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics, pages 7811–7818, on-line.
association for computational linguistics..guillaume lample, miguel ballesteros, sandeep sub-ramanian, kazuya kawakami, and chris dyer.
2016.neural architectures for named entity recognition.
in naacl hlt 2016, the 2016 conference of thenorth american chapter of the association for com-putational linguistics: human language technolo-gies, san diego california, usa, june 12-17, 2016,pages 260–270.
the association for computationallinguistics..xiang lisa li and percy liang.
2021. preﬁx-tuning:optimizing continuous prompts for generation.
arxiv:2101.00190 [cs]..bill yuchen lin, seyeon lee, rahul khanna, and xi-ang ren.
2020. birds have four legs?!
numersense:probing numerical commonsense knowledge ofin proceedings ofpre-trained language models.
the 2020 conference on empirical methods in nat-ural language processing (emnlp), pages 6862–6868, online.
association for computational lin-guistics..yongjie lin, yi chern tan, and robert frank.
2019.open sesame: getting inside bert’s linguisticknowledge.
in proceedings of the 2019 acl work-shop blackboxnlp: analyzing and interpreting neu-ral networks for nlp, pages 241–253, florence,italy.
association for computational linguistics..nelson f. liu, matt gardner, yonatan belinkov,matthew e. peters, and noah a. smith.
2019a.
lin-guistic knowledge and transferability of contextualrepresentations.
in proceedings of the 2019 confer-ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1 (long and short pa-pers), pages 1073–1094, minneapolis, minnesota.
association for computational linguistics..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019b.
roberta: a robustly optimized bert pretrain-ing approach.
arxiv:1907.11692 [cs]..andrea madotto, zihan liu, zhaojiang lin, andpascale fung.
2020. language models as few-shot learner for task-oriented dialogue systems.
arxiv:2008.06239 [cs]..tom mccoy, ellie pavlick, and tal linzen.
2019.right for the wrong reasons: diagnosing syntacticheuristics in natural language inference.
in proceed-ings of the 57th annual meeting of the associationfor computational linguistics, pages 3428–3448,florence, italy.
association for computational lin-guistics..matthew peters, mark neumann, mohit iyyer, mattgardner, christopher clark, kenton lee, and lukezettlemoyer.
2018. deep contextualized word rep-in proceedings of the 2018 confer-resentations.
ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1 (long papers), pages2227–2237, new orleans, louisiana.
associationfor computational linguistics..fabio petroni, patrick s. h. lewis, aleksandra piktus,tim rockt¨aschel, yuxiang wu, alexander h. miller,and sebastian riedel.
2020. how context affects lan-in conferenceguage models’ factual predictions.
on automated knowledge base construction, akbc2020, virtual, june 22-24, 2020..fabio petroni, tim rockt¨aschel, sebastian riedel,patrick lewis, anton bakhtin, yuxiang wu, andalexander miller.
2019. language models as knowl-in proceedings of the 2019 confer-edge bases?
ence on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 2463–2473, hong kong, china.
as-sociation for computational linguistics..nina poerner, ulli waltinger, and hinrich sch¨utze.
2020. e-bert: efﬁcient-yet-effective entity em-in findings of the associa-beddings for bert.
tion for computational linguistics: emnlp 2020,pages 803–818, online.
association for computa-tional linguistics..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. language.
1869learn from context?
probing for sentence structurein contextualized word representations.
in 7th inter-national conference on learning representations,iclr 2019, new orleans, la, usa, may 6-9, 2019.openreview.net..denny vrandeˇci´c and markus kr¨otzsch.
2014. wiki-data: a free collaborative knowledgebase.
commun.
acm, 57(10):78–85..eric wallace, yizhong wang, sujian li, sameer singh,and matt gardner.
2019. do nlp models knownumbers?
probing numeracy in embeddings.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 5307–5315, hong kong, china.
association for computa-tional linguistics..chenguang wang, xiao liu, and dawn song.
2020.language models are open knowledge graphs.
arxiv:2010.11967 [cs]..alex warstadt, yu cao, ioana grosu, wei peng, ha-gen blix, yining nie, anna alsop, shikha bordia,haokun liu, alicia parrish, sheng-fu wang, jasonphang, anhad mohananey, phu mon htut, palomajeretic, and samuel r. bowman.
2019.investi-gating bert’s knowledge of language: five anal-in proceedings of theysis methods with npis.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 2877–2887, hong kong,china.
association for computational linguistics..xuhui zhou, yue zhang, leyang cui, and dandanhuang.
2019. evaluating commonsense in pre-trained language models.
arxiv:1911.11931 [cs]..models are unsupervised multitask learners.
openaiblog, 1(8):9..adam roberts, colin raffel, and noam shazeer.
2020.how much knowledge can you pack into the param-in proceedings of theeters of a language model?
2020 conference on empirical methods in naturallanguage processing (emnlp), pages 5418–5426,online.
association for computational linguistics..timo schick and hinrich sch¨utze.
2020a.
few-shottext generation with pattern-exploiting training.
arxiv:2012.11926 [cs]..timo schick and hinrich sch¨utze.
2020b..it’s notjust size that matters: small language models arealso few-shot learners.
arxiv:2009.07118 [cs]..timo schick and hinrich sch¨utze.
2021. exploitingcloze-questions for few-shot text classiﬁcation andin proceedings of thenatural language inference.
16th conference of the european chapter of the as-sociation for computational linguistics: main vol-ume, eacl 2021, online, april 19 - 23, 2021, pages255–269.
association for computational linguis-tics..taylor shin, yasaman razeghi, robert l. logan iv,eric wallace, and sameer singh.
2020. autoprompt:eliciting knowledge from language models within proceed-automatically generated prompts.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages4222–4235, online.
association for computationallinguistics..vered shwartz, rachel rudinger, and oyvind tafjord.
2020.
“you are grounded!”: latent name artifacts inpre-trained language models.
in proceedings of the2020 conference on empirical methods in naturallanguage processing (emnlp), pages 6850–6861,online.
association for computational linguistics..alon talmor, jonathan herzig, nicholas lourie, andjonathan berant.
2019. commonsenseqa: a ques-tion answering challenge targeting commonsenseknowledge.
in proceedings of the 2019 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, naacl-hlt 2019, minneapolis, mn,usa, june 2-7, 2019, volume 1 (long and short pa-pers), pages 4149–4158.
association for computa-tional linguistics..alexandre tamborrino, nicola pellican`o, baptiste pan-nier, pascal voitot, and louise naudin.
2020. pre-training is (almost) all you need: an applicationin proceedings of theto commonsense reasoning.
58th annual meeting of the association for compu-tational linguistics, pages 3878–3887, online.
as-sociation for computational linguistics..ian tenney, patrick xia, berlin chen, alex wang,adam poliak, r. thomas mccoy, najoung kim,benjamin van durme, samuel r. bowman, dipan-jan das, and ellie pavlick.
2019. what do you.
1870a wiki-uni construction details.
to construct wiki-uni, we ﬁrst collect all thetriples which belong to the same 41 relations withlama from wikidata (vrandeˇci´c and kr¨otzsch,2014), then we randomly sample 50k triples witha single-token object for each relation.
similar tolama, we ﬁlter out the instances whose objectis not in mlms’ vocabulary.
for each relation,we group the instances based on different objects,and indicate fo as the frequency of each object.
we denote the median of fo with fm.
for groupswhere fo > fm, we randomly sample fm instances,and delete the groups where fo < fm.
therefore,we acquire a dataset named wiki-uni with a uni-form answer distribution.
there are 70k facts inwiki-uni and 34k facts in lama.
since bertand roberta have a different vocabulary, so thedatasets for their evaluation are slightly different..b results on roberta-large.
our conclusions are similar on bert-large androberta-large, therefore, we report the results ofbert-large in the article and results of roberta-large here..b.1 promp-based retrieval.
figure 7 shows the very signiﬁcant correlation be-tween the prediction distributions on lama andwiki-uni for roberta-large: on all three kindsof prompts, the pearson correlation coefﬁcient be-tween these two prediction distributions exceeds0.9 in most relations.
table 8 shows the percentageof instances that the topk object entities cover forroberta-large..distribution.
answer.
prediction.
datasetslamawiki-unilamawiki-uni.
top1 top3 top550.0842.0223.938.615.531.8465.4556.8537.4863.5855.5136.53.prec.
--23.6513.59.table 8: the percentage of instances that the topk ob-ject entities cover for roberta-large.
the statisticsis different from table 1 because we ﬁlter lama withroberta’s vocabulary when evaluate roberta-large..performance for roberta-large.
table 14 showshow the entity types of predictions changed after in-troducing the illustrative cases for roberta-largemodel, the conclusion is similar with bert-large.
figure 8 shows the percentage on the change ofoverall rank and in-type rank for roberta-largemodel..and another ﬁnding is that bert-large has abetter type prediction ability than roberta-large,even without illustrative cases.
we calculate theoverall type precision over prompt-based paradigm(the percentage of predictions that the type is cor-rect).
and the type precision for bert-large is 68%and for roberta-large is only 51%, which partlyexplains why performance of roberta-large issigniﬁcantly worse than bert-large on lamadataset..enhanced withcasesnoyes.
prec.
better worse.
23.6529.78.
-14.09.
-7.96.table 9: performance of the case-based analogyparadigm for roberta-large.
figure 7: the correlations of the prediction distributionon lama and wiki-uni for roberta-large..b.2 case-based analogy.
table 9 shows the performance improvement afterintroducing illustrative cases for roberta-largemodel, we can see that the illustrative cases couldalso signiﬁcantly increase the knowledge extraction.
figure 8: percentages on the change of overall rank(among all candidates) and the in-type rank (amongcandidates with the same type) of golden answer ofroberta-large model..18710.20.40.60.81.0tmantminetauto10%25%40%55%in-typerankoverallrankraisedunchangeddroppeda few relations (e.g., part of, applies tojurisdiction, subclass of).
speciﬁcally,the “surface form” indicate that the object entityname (e.g., apple) is a substring of the subject en-tity name (e.g., apple watch).
such phenomenonis also mentioned in poerner et al.
(2020)..b.3 context-based inference.
table 10 shows the comparison of contexts groupby whether the contexts contain the answer forroberta-large.
we can see that for contexts con-taining the answer, context-based inference sig-niﬁcantly improves the factual extraction perfor-mance.
meanwhile, there is a performance drop forthose instances whose context does not contain theanswer.
table 11 shows the overall performanceimprovements when introducing different exter-nal contexts for roberta-large.
table 12 showsthe comparison of the masked contexts based onwhether they can/cannot reconstruct the maskedanswer for roberta-large.
the improvementsmainly comes from the instances whose answer incontexts can be reconstructed..answerin contextpresent(46.04%)absent(53.96 %).
prompt-based context-based.
∆.
27.95.
18.95.
52.05.
+24.10.
14.72.
-4.23.table 10: comparison of contexts grouped by whetherthe answer presents or absents for roberta-large..without contexts full contexts masked contexts31.44.
23.65.
24.44.table 11: the overall performance when introducingdifferent contexts for roberta-large..answerreconstructablereconstructable(61.23%)not-reconstructable(38.77 %).
prompt-based context-based.
∆.
30.50.
22.19.
42.37.
+11.87.
22.15.
-0.04.table 12: comparison of the masked contexts based onwhether they can/cannot reconstruct the masked answerfor roberta-large..c full version of the type prediction.
results.
table 13 shows the detailed analysis of all rela-tions using case-based analogy paradigm for bert-large and table 14 is the results on roberta-large.
because of the page limit, another ﬁnd-ing we didn’t mention in the article is that,apart from “type guidance”, the illustrative casescould also provide a “surface form guidance” in.
1872relation.
named aftercountry of citizenshipposition heldreligionwork locationinstrumentcountryemployercontinentlanguages spoken, written or signedapplies to jurisdictioncountry of originsubclass ofpart oflanguage of work or namelocation of formationhas partgenreowned byinstance ofoccupationplace of deathtwinned administrative bodydiplomatic relationnative languagemanufacturerﬁeld of workdeveloperlocationcapitalposition played on team / specialityheadquarters locationofﬁcial languageoriginal language of ﬁlm or tv showplace of birthcapital ofshares border withrecord labeloriginal networklocated in the administrative territorial entitymember of.
induced object type.
physical objectsovereign statereligious servantreligioncitymusical instrumentsovereign statebusinesscontinentindo-european languagesstatesovereign stateobjectobjectindo-european languagescityabstract objectseriesorganizationconcrete objectprofessioncitycitysovereign stateindo-european languagesbusinessknowledgeenterprisecommunitycitypositioncitynostratic languagesnostratic languagescitypolitical territorial entitycommunityrecord labeltelevision stationcommunityorganization.
precision∆68.0643.3736.8833.2026.1017.0714.3012.0110.879.918.718.367.687.516.055.025.024.622.622.061.351.260.910.800.20-1.02-1.15-1.52-1.57-2.00-4.10-4.24-5.28-5.84-6.25-6.84-7.37-7.93-10.56-12.94-14.67.typeprec.
∆98.9184.1680.2634.8870.5555.7529.0499.2251.18-0.93-6.1333.2227.2837.6610.9566.3427.2617.6111.504.34-0.5316.370.801.110.620.310.001.524.590.1411.030.62-1.14-16.714.340.422.72-22.380.4511.6916.45.wrong → rightw/ type change99.77100.0091.15100.0085.0489.0888.48100.0096.8610.567.2371.6466.1854.2777.2380.7725.3395.459.5735.800.0068.6315.3810.0038.6433.3326.094.173.034.55-0.005.4519.1514.29-2.22-11.3610.5394.74.right → wrongw/o type change--90.00-100.0075.0087.93-88.2481.5463.6498.2887.1097.8777.08100.00100.00-100.0096.77100.00100.0075.00100.0092.8661.2990.3296.97100.0097.22100.00100.0090.5743.30100.00100.0097.350.0086.1399.2598.08.table 13: a detailed analysis of all relations using case-based analogy paradigm for bert-large, which is corre-sponding to table 4 in the article.
“-” indicates the number of queries whose predictions are reversed correctly ormistakenly is less than 3..1873relation.
religionposition heldcountry of citizenshipmember ofcontinentinstrumentcountry of origincountrypart ofplace of deathinstance oflocation of formationsubclass ofcapitalnamed afterlanguage of work or namehas partwork locationlanguages spoken, written or signedemployerposition played on team / specialitynative languagegenrerecord labelplace of birthtwinned administrative bodyheadquarters locationdiplomatic relationowned byﬁeld of workoccupationofﬁcial languagelocated in the administrative territorial entityoriginal language of ﬁlm or tv showshares border withlocationdeveloperoriginal networkapplies to jurisdictioncapital ofmanufacturer.
induced object type.
religionreligious servantsovereign stateorganizationcontinentmusical instrumentsovereign statesovereign stateobjectcityconcrete objectcityobjectcityphysical objectindo-european languagesabstract objectcityindo-european languagesbusinesspositionindo-european languagesseriesrecord labelcitycitycitysovereign stateorganizationknowledgeprofessionnostratic languagescommunitynostratic languagescommunitycommunityenterprisetelevision stationstatepolitical territorial entitybusiness.
precision∆56.9241.8637.1631.0329.5128.2628.1826.6424.5722.8814.9714.1212.0710.6210.259.108.798.095.093.973.261.091.050.00-0.13-0.45-1.00-1.16-1.45-2.10-2.43-3.11-3.35-5.29-9.82-11.49-12.25-16.46-18.38-39.44-49.63.typeprec.
∆66.3647.4274.1177.8387.806.0494.9269.8490.2295.3520.5399.8826.2536.3185.0526.7267.9912.4317.7510.3156.511.630.23-7.5541.021.040.001.0543.780.690.003.8845.81-21.300.1627.156.80-15.842.117.226.79.wrong → rightw/ type change100.0099.03100.00100.00100.0094.0499.6195.2296.9898.9534.30100.0063.3192.19100.0089.1277.6596.9554.2019.0571.4328.2175.00-66.670.000.0025.0064.6210.530.0018.3775.9315.380.0041.4337.5014.2935.71-44.44.right → wrongw/o type change----100.000.00100.0096.55100.00100.0097.50-90.0085.71100.0072.17-6.4586.90100.0075.0093.1066.67-100.00100.00100.00100.0094.5996.77100.0097.4097.5034.2998.86100.0079.4172.4998.00100.0093.82.table 14: a detailed analysis of all relations using case-based analogy paradigm for roberta-large, which iscorresponding to table 4 in the article.
“-” indicates the number of queries whose predictions are reversed correctlyor mistakenly is less than 3..1874