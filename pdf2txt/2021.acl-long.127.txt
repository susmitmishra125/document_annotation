stance detection in covid-19 tweets.
kyle glandt♣ sarthak khanal♣ yingjie li♦ doina caragea♣ cornelia caragea♦.
♣computer science, kansas state university♦computer science, university of illinois at chicago{kglandt,sarthakk,dcaragea}@ksu.edu{yli300,cornelia}@uic.edu.
abstract.
the prevalence of the covid-19 pandemicin day-to-day life has yielded large amountsof stance detection data on social media sites,as users turn to social media to share theirviews regarding various issues related to thepandemic, e.g.
stay at home mandates andwearing face masks when out in public.
weset out to make use of this data by collect-ing the stance expressed by twitter users, withrespect to topics revolving around the pan-demic.
we annotate a new stance detectiondataset, called covid-19-stance.
using thisnewly annotated dataset, we train several es-tablished stance detection models to ascertaina baseline performance for this speciﬁc task.
to further improve the performance, we em-ploy self-training and domain adaptation ap-proaches to take advantage of large amountsof unlabeled data and existing stance detec-tion datasets.
the dataset, code, and other re-sources are available on github.1.
1.introduction.
we live in unprecedented times caused by a globalcovid-19 pandemic, which has forced majorchanges in our daily lives.
given the developmentsconcerning covid-19, communities and govern-ments need to take appropriate action to mitigatethe effects of the novel coronavirus, which is at theroot of the pandemic.
for example, states in theunited states that have imposed strict social dis-tancing mandates were able to slow the growth ofthe virus within their communities (courtemancheet al., 2020).
for such measures to work, how-ever, it is important that the public fully adhere tothese guidelines and mandates.
“pandemic fatigue,”or when people become tired of pandemic man-dates and begin to ease in adherence, can lead to.
1https://github.com/kglandt/.
stance-detection-in-covid-19-tweets.
resurgences of the novel coronavirus (feuer andrattner, 2020).
to reduce the spread of covid-19,it is essential to understand the public’s opinion onthe various initiatives, such as stay at home orders,wearing a face mask in public, school closures, etc.
understanding how the public feels about thesemandates could help health ofﬁcials better estimatethe expected efﬁcacy of their mandates, as well asdetect pandemic fatigue before it leads to a seriousresurgence of the virus..in the era of web 2.0, and especially during apandemic in which people often resort to onlinecommunications, social media platforms providean astounding amount of data relating to the stanceand views held by various populations with respectto a variety of current and important topics.
how-ever, the total amount of data that is being gener-ated each second makes it impossible for humansalone to fully make use of them.
fortunately, recentdevelopments in deep learning have yielded state-of-the-art performance in text classiﬁcation.thismakes deep learning an ideal solution for extract-ing and making sense of the large amounts of datacurrently in circulation on social media sites..in particular, given the current events, it is evi-dent that automated approaches for detecting thestance of the population towards targets, such ashealth mandates related to covid-19, using twit-ter posts, or tweets, can help gauge the level ofcooperation with the mandates.
stance detection isa natural language processing (nlp) task in whichthe goal is for a machine to learn how to automati-cally determine from text alone an author’s stance,or perspective/view, towards a controversial topic,or target.
research in the area of stance detec-tion has yielded accurate results, especially in theunited states politics (mohammad et al., 2017;ghosh et al., 2019; xu et al., 2020).
however, re-search on stance detection for targets relevant tocovid-19 health mandates lags behind, due to the.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1596–1611august1–6,2021.©2021associationforcomputationallinguistics1596tweetidc what you say, you’re selﬁsh if you refuse to wear amask.
this shouldn’t be political.
#maskupthat video, my god.
i’m as progressive as the next personand i dearly hope trump will lose, but i can’t rememberthe last time i watched such a cynical, fear-mongeringpiece of propaganda.
keeping schools closed will bedevastating for our most vulnerable children.
i believe in science.
i wear a mask for your protec-tion.
#joebidenforpresident2020”@realdonaldtrump also death rate down big time!
america is ready for business!”.
targetwearing a face mask.
stance opinionexplicit.
in favor.
sentimentnegative.
keeping schools closed.
against.
explicit.
negative.
anthony s. fauci, m.d..in favor.
implicit.
positive.
stay at home orders.
against.
implicit.
positive.
table 1: examples of tweet/target pairs from the covid-19-stance dataset, manually annotated with respect touser’s stance towards the target, the way stance opinion was expressed, and the overall sentiment of the tweet..recency of the pandemic and a lack of benchmarkdatasets.
we set out to address this problem byconstructing a covid-19 stance detection dataset(called covid-19-stance), which includes tweetsthat express views towards four targets, speciﬁ-cally “anthony s. fauci, m.d.”, “keeping schoolsclosed”, “stay at home orders”, and “wearing aface mask.” this is a challenging task, which isrelated but different from sentiment analysis.
atweet may express support for a target, while us-ing a negative language, and expressing a negativesentiment overall.
furthermore, the opinion ex-pressed in a tweet may not be explicitly towards thetarget of interest, while the stance can be implic-itly inferred.
some examples of tweet/target pairslabeled with respect to stance, target of opinionand sentiment are shown in table 1 to illustrate theabove mentioned challenges..to address the stance detection task, carefully de-signed approaches are needed to extract languagepatterns informative with respect to stance.
weprovide a comprehensive set of baseline results forthe newly constructed covid-19-stance dataset,including results with established supervised base-lines for stance detection tasks, and also baselinesthat employ approaches for handling small amountsof labeled data, including self-training and domainadaptation approaches.
in summary, the contribu-tions of this work are as follows:.
• we construct a covid-19-stance dataset thatconsists of 6,133 tweets covering user’s stancetowards four targets relevant to covid-19health mandates.
the tweets are manuallyannotated for stance according to three cate-gories: in-favor, against, and neither..• we establish baseline results using state-of-the-art supervised stance detection models, in-cluding transformer-based models..• we also establish baselines for self-trainingand domain adaptation approaches that use un-labeled data from the current task, or labeleddata from a related task, to complement forlimited labeled data for the current task..2 related work.
we discuss related work in terms of existingdatasets and approaches for stance detection..2.1 stance detection datasets.
recent work on stance detection in social me-dia data has been facilitated by mohammad et al.
(2016, 2017), who constructed a manually anno-tated stance detection dataset, shared publicly assemeval2016 task 6. the dataset was based ontweets about united states politics, collected dur-ing the lead up to the united states 2016 presiden-tial election.
given a set of politics-relevant tar-gets (e.g., politicians, feminism, climate change),the initial selection of tweets to be included in thedataset was done using “query hashtags”, which aretwitter hashtags within a manually curated short-list that had been observed to correlate stances andtargets on twitter.
subsequently, tweet/target pairswere annotated by crowdflower2 workers, whowere provided with a generic, but detailed ques-tionnaire regarding the stance of a tweet’s authortoward a target, as well as the sentiment of thetweet (mohammad et al., 2016, 2017)..several other datasets for stance detection havebecome available in the last few years, includinga large dataset (containing approximately 50,000tweets) focused on the stance towards ﬁnancialtransactions that involve mergers and acquisition(conforti et al., 2020), a dataset for identifyingthe stance in twitter replies and quotes (villa-cox.
2http://www.crowdflower.com/.
1597et al., 2020), datasets in languages different fromenglish (hercig et al., 2017; vychegzhanin andkotelnikov, 2019; evrard et al., 2020), and multi-lingual datasets (zotova et al., 2020; vamvas andsennrich, 2020; lai et al., 2020)..furthermore, the global prevalence and impactof the covid-19 pandemic has led to the quick de-velopment, concurrently with our work, of severalcovid-19 stance-related twitter datasets (mutluet al., 2020; miao et al., 2020; hossain et al., 2020).
mutlu et al.
(2020) published a dataset of approxi-mately 14,000 tweets (called covid-cq), whichwere manually annotated with respect to the au-thor’s stance regarding the use of hydroxychloro-quine in the treatment of covid-19 patients.
miaoet al.
(2020) constructed a dataset focused on au-thor’s stance towards lockdown regulations in newyork city.
the authors used keywords related to“lockdown” and “new york city” and extractedapproximately 31,000 relevant tweets from a largecovid-19 tweet dataset published by chen et al.
(2020).
they manually annotated 1629 tweet withrespect to stance, while the remaining tweets wereused as unlabeled..our dataset construction procedure is similar tothe one followed by miao et al.
(2020), but we labeldata for four targets using global english tweets, asopposed to miao et al.
(2020) who label data forjust one target (“lockdown”) in one location (“newyork city”)..2.2 stance detection approaches.
in terms of approaches used for stance detection,strong baseline results based on support vector ma-chines (svm) with manually engineered featureswere provided for the semeval2016 task 6 by mo-hammad et al.
(2016, 2017).
deep learning ap-proaches used in semeval2016 task 6 includedrecurrent neural networks (rnns) (zarrella andmarsh, 2016) and convolutional neural networks(cnns) (vijayaraghavan et al., 2016; wei et al.,2016).
such approaches used the tweets as in-put, but did not use any target-speciﬁc informa-tion, and did not outperform the svm baselines.
later approaches were provided with both targetand tweet representations as input, and employedrnns and/or cnns, together with the attentionmechanism (augenstein et al., 2016; du et al.,2017; zhou and cristea, 2017; sun et al., 2018;siddiqua et al., 2019) to improve the performanceof the svm baselines..given the dominance of transformers (vaswaniet al., 2017), especially bidirectional encoder rep-resentations from transformers (bert) (devlinet al., 2019), in nlp tasks, some recent works(slovikovskaya and attardi, 2020; li and caragea,2021; ghosh et al., 2019) have focused on investi-gating the use of bert models for stance detection.
for example, ghosh et al.
(2019) explored the re-producibility of approaches for stance detectionand compared them to bert.
they found bertto be the best model overall for stance detection onthe semeval2016 task 6. li and caragea (2021)also explored bert based models with data aug-mentation and found bert to be a powerful modelfor stance detection.
thus, we have selected bertas a strong baseline for our paper..several works have shown that auxiliary infor-mation, such as sentiment and emotion informa-tion, or the subjective/objective nature of a text(provided as additional inputs or presented in theform of auxiliary tasks in a multi-task framework),can help improve the performance obtained fromthe tweet/target information alone (mohammadet al., 2017; sun et al., 2019; li and caragea, 2019;hosseinia et al., 2020; xu et al., 2020).
other ap-proaches to improve the performance, especiallywhen the amount of labeled data for the task ofinterest is small, include weak supervision (weiet al., 2019) and knowledge distillation (miao et al.,2020); transfer learning through distant supervision(zarrella and marsh, 2016) or pre-trained models(ebner et al., 2019; hosseinia et al., 2020); anddomain adaptation from a source task to the targettask (xu et al., 2018, 2020)..in particular, the dual-view adaptation network(dan) (xu et al., 2020) learns to predict the stanceof a tweet by combining the subjective and objec-tive views/representations of the tweet, while alsolearning to adapt them across domains.
we usean adaptation of the dan model as a strong base-line in this work.
most relevant to our work oncovid-19-stance, miao et al.
(2020) compareda supervised in-domain bert model trained andtested on “lockdown” tweets, with cross-domainmodels, and knowledge distillation variants.
theresults showed signiﬁcantly improved performancefor the knowledge distillation variants, and empha-sized the importance of having a small amount ofdata for the task of interest (as a better alterna-tive to zero-shot learning).
similar to miao et al.
(2020), we also use bert together with knowledgedistillation/self-training as a strong baseline..1598targetanthony s. fauci, m.d..keeping schools closed.
stay at home orders.
wearing a face mask.
in-favoristandwithfauci, fauciisahero, faucihero,firetrumpnotfauci, savefauci, istandwith-drfauci, thankyoudrfauci, standwithfauci,listentofauci,drfauciisanationalhero,imwithfauci, trustfauci, letfaucileadschoolsmustshutdown,closetheschools,saveourschools, notmychild, schoolsmust-shutdown, closetheschoolssaferathome, lockdownnow, stayathome-savelives, staysafestayhome.
maskssavelives, wearamasksavealife,maskmoaners, wearamaskplease, covery-ourface, maskson, wearadamnmask.
againstfirefauci, faucithefraud, faucifraud, fire-faucinow, fraudfauci.
righttolearn, openschools, schoolreopen-ing, reopeningschools.
reopenamericanow,reopenamerica,endtheshutdown, endthelockdown, ope-namericanow, notolockdownmasksoff, saynotomasks, nomasks, no-mask, masksdontwork, masksoff, masksof-famerica, nomaskonme.
table 2: in favor and against query hashtags for each target.
3 covid-19-stance dataset.
the recency of the covid-19 pandemic meansthere was no established stance detection datasetfor this broader topic, when we began our re-search.
therefore, we set out to construct our owndataset, called covid-19-stance, by followingthe methodology introduced by mohammad et al.
(2016, 2017), which is generic and applicable forany controversial topic discussed on twitter..data collection.
we began crawling twitter, us-ing the twitter streaming api, on february 27th,2020. we collected tweets that contained gen-eral keywords pertaining to the novel coronavirus(e.g.
“coronavirus”, “covid-19”, “corona virus”,“#covid19”, etc.).
as new hashtags emerged, we it-eratively added additional, more speciﬁc keywordsto the search (e.g., “#lockdown”, “stay at home”,“#socialdistancing”, “#washhands”, etc.).
we con-tinued crawling until august 20th, 2020. the fulllist of keywords that was used over this time pe-riod is provided in appendix a. we only storedoriginal tweets (not a retweet or quoted tweet) thatcontained no hyperlinks, and ended up collecting agrant total of 30,331,993 tweets..target selection.
after being able to analyzethe initial tweets, and following the developmentsof the covid-19 events, we began to identify con-troversial topics that arose as the virus continuedits spread in the united states (us).
four topicsthat we found to be among the most prevalent inour collection of tweets, and are understood by alarge number of people in the us, were “stay athome orders”, “wearing a face mask”, “keepingschools closed”, and “anthony s. fauci, m.d.”..data selection.
similar to mohammad et al.
(2016), we identiﬁed query hashtags to encompass.
targetanthony s. fauci, m.d.
keeping schools closedstay at home orderswearing a face maskall.
#in-favor2,4175,3458,43727,60043,799.
#against6,6415,6655,32312,06429,693.table 3: the number of tweets selected using “in-favor”and “against” hashtags for each target..the four main targets/topics selected, and began tocollect and organize the tweets according to topicand likely labels.
for example, if “#firefauci” iscontained within a tweet, it is likely that the au-thor of that tweet is posting information indicatingthey do not support the current director of the na-tional institute of allergy and infectious diseases(niaid), anthony s. fauci, m.d.
for each of thefour selected targets, we identiﬁed two types ofquery hashtags, speciﬁcally, “in-favor” hashtagsand “against” hashtags (stance-neutral hashtagswere very rare).
the exact query hashtags iden-tiﬁed for each target are shown in table 2. usingthe “in-favor” and “against” query hashtags, weselected a “noisy stance set” of tweets for each tar-get, as shown in table 3. out of the total numberof tweets corresponding to a target, we further se-lected a relatively balanced (in terms of in-favorand against noisy labels) dataset to be manuallylabeled, and another relatively balanced dataset oftweets to be used as unlabeled in the self-trainingapproach.
the exact number of tweets to-label andto be used unlabeled are shown in table 4..data annotation.
although query hashtags aregreat for selecting likely relevant tweets, they arenoisy and not reliable enough to accurately identifythe stance towards a target for a tweet (see table 5for some examples illustrating this point).
there-.
1599targetanthony s. fauci, m.d.
keeping schools closedstay at home orderswearing a face maskall.
# to-label2,0851,4791,7171,9217,122.
# unlabeled2,4432,70315,4889,00629,640.table 4: the number of tweets selected to be labeled(#to-label) and the number of tweets to be used as unla-beled in self-training (#unlabeled) for each target..fore we used amazon mechanical turk (amt) toenlist the help of gig workers to analyze and la-bel our collection of 7,122 tweets selected to belabeled (the exact number of tweets for each targetis shown in table 4).
we removed the hashtagsthat appeared at the end of a tweet to exclude ob-vious cues, without making the tweet syntacticallyambiguous.
this increases the chance that our col-lection contains tweets that do not explicitly men-tion the target, and potentially some tweets withneutral stance towards the target.
each tweet waslabeled by three annotators.
at one time, each an-notator was shown a page with a tweet and a target,and asked to answer a questionnaire designed anddetailed by mohammad et al.
(2017).
the ques-tionnaire, shown in appendix b, contains detailedquestions and multi-choice answers that allow us toannotate each tweet with respect to three criteria:.
1. the stance of the tweet’s author/user towardsthe given target: in favor, against or neither;.
2. the way the opinion is expressed, which cap-tures whether the text of the tweet reveals thestance explicitly, implicitly, or neither;.
3. the sentiment of the tweet, which essentiallycaptures the language used in the tweet: posi-tive, negative, both, sarcasm, or neither..our ﬁnal covid-19-stance dataset containsonly tweets for which at least two out of the threeannotators agreed on the stance category.
thecohen’s kappa scores that we obtained for inter-annotator agreement for the ﬁnal dataset were 0.82for stance, 0.83 for target of opinion, and 0.60 forsentiment.
according to (cohen, 1960), the scoresfor stance and target of represent almost perfectagreement, while the score for sentiment showssubstantial agreement.
table 1 shows several ex-amples of annotated tweets in our dataset..dataset statistics.
the number of tweets foreach target and the stance distribution for each tar-get are shown in table 6. the number of tweets for.
figure 1: the number of tweets by target over themarch to august 2020 months..each target over the months when data was crawledis graphically displayed in figure 1, which showsthat a large number of the tweets in our datasetwere posted in july 2020. the distribution of thetype of opinion is shown in tables 7 and 8, for eachtarget and each stance, respectively.
similarly, thedistribution of the sentiment (or tweet language) isshown in tables 9 and 10, for each target and eachstance, respectively.
as can be seen from thesetables, our dataset contains a good mix of in-favor,against and neutral categories, and also a good mixof tweets with implicit and explicit opinion towardsthe target.
however, the sentiment is generally neg-ative or in the other category (which includes bothpositive and negative, sarcastic language and nei-ther).
together, these characteristics make our taskboth realistic and challenging.
while we only usethe stance label in this work, the other labels will beexplored in future works, as auxiliary informationpotentially useful for stance detection..benchmark subsets.
to enable progress oncovid-19 stance detection, and facilitate com-parisons between models developed for this task,we randomly split our covid-19-stance dataset(using stratiﬁed sampling) into training (train),development (val) and test (test) subsets, re-spectively.
we used the training subset to train ourmodels, the development to select hyperparametersand the test to evaluate the ﬁnal performance ofthe models.
statistics for the dataset in terms ofnumber of tweets in the train, test and valsubsets, respectively, are shown in table 11..4 baseline models.
having described our covid-19-stance dataset,we now brieﬂy review several models that we useto establish baseline results on this dataset..1600tweet125 days.
@deanobeidallah #icantbreathe #blacklivesmatter #wednesdaymotivation #pride#wearamask #stayhome #votebymail #imridenwithbiden #joe2020 #joebiden #lockhimup #there-sistance #strongertogether #equalityforall #makeitcount #enough #loveislove #neveragain#lovewinsi will not #wearamask because the #government says i have to wear one.
you #wearadamnmask ifyou want to.
i will not subjugate myself to their unconstitutional rules.
#idonotcomply #idonotconsent“i will not be chipped.
i will not be tracked” the devil coronavirus covid 19,all governments willcontrol billions of people, 198 countries!!
#illegal #puppets #nofacemask #coronavirus #covid19#pandemic #wearamask #wearadamnmask #nofacemask.
query tagwearamask.
wearadamnmask.
wearadamnmask.
table 5: examples of tweets where the query tags are not reliable silver labels for the wearing a face mask target..targetanthony s. fauci, m.d.
keeping schools closedstay at home orderswearing a face maskall.
# total18641190137217076133.distribution of stances (%)in-favor against neither40.8827.3157.0020.2736.12.
26.3951.6813.8540.6032.45.
32.7321.0129.1539.1331.44.table 6: the distribution of stances in the dataset..opinion towards target (%).
targetanthony s. fauci, m.d.
keeping schools closedstay at home orderswearing a face maskall.
explicit44.7469.6623.1874.1752.94.implicit neither6.923.9526.463.229.69.
48.3426.3950.3622.6137.37.table 7: the distribution of opinion for each target..stancefavoragainstneither.
opinion towards target (%).
explicit81.6179.254.29.implicit neither0.750.2625.91.
17.6420.4969.80.table 8: the distribution of opinion for each stance..targetanthony s. fauci, m.d.
keeping schools closedstay at home orderswearing a face maskall.
sentiment of tweet (%)positive negative other20.8213.8734.4012.8920.30.
9.3314.6219.1713.2413.65.
69.8571.5146.4373.8766.05.table 9: the distribution of sentiment for each target..4.1 supervised baseline models.
to get a baseline understanding of how establishedstance detection networks perform on our dataset,we used the following models:.
• bilstm: bi-directional long short termmemory networks (schuster and paliwal,1997) take tweets as input, and are trainedto predict the stance towards a target, withoutexplicitly using the target information..• kim-cnn: convolutional neural networksfor text, proposed by kim (2014), are alsoprovided with tweets as input, and trained topredict the stance towards a target, withoutexplicitly using the target information..• tan: target-speciﬁc attention networks (duet al., 2017) represent an attention-based bil-stm model that identiﬁes features speciﬁc tothe target of interest, by explicitly incorporat-ing the target information..• atgru: the bi-directional gated recurrentunit network with token-level attentionmechanism (zhou and cristea, 2017) is anattention-based bi-gru model that also uses.
the target information explicitly, and identiﬁesspeciﬁc target features using the attention..• gcae: the gated convolutional networkwith aspect embedding (xue and li, 2018)in addition tois based on a cnn model.
tweets, it also has information about the tar-get, and uses a gating mechanism to blocktarget-unrelated information..• bert: bidirectional encoder representa-tions from transformers (devlin et al., 2019)represent language models that are pre-trainedon a large unlabeled corpus to encode sen-tences and their tokens into dense vector rep-resentations.
we used the pre-trained covid-twitter-bert model3 (m¨uller et al., 2020)..4.2 self-training baseline.
given that a large amount of unlabeled data isavailable for each target included in our covid-19-stance dataset, we explored the use of a self-training approach that can make use of unlabeleddata, as described below:.
3https://huggingface.com/.
digitalepidemiologylab/covid-twitter-bert.
1601stancefavoragainstneither.
sentiment of tweet (%)positive negative other15.486.5936.57.
62.1687.9750.47.
22.365.4512.96.table 10: the distribution of sentiment for each stance..placed the bilstm networks with pre-trainedcovid-twitter-bert models, and trainedthe network to predict the stance using bothlabeled data from the prior task and from thecurrent task.
the prior data was the wholesemeval2016 task 6 data..targetanthony s. fauci, m.d.
keeping schools closedstay at home orderswearing a face mask.
# train14647909721307.
# val200200200200.
# test200200200200.
5 experimental setup.
5.1.implementation details.
table 11: the number of tweets for the training (train),validation (val) and test (test) subsets per target..• bert-ns: self-training with noisy student(xie et al., 2020) is a semi-supervised learn-ing approach that employs self-training andknowledge distillation (hinton et al., 2015) toimprove the performance of a teacher modelusing unlabeled data.
more speciﬁcally, ateacher is originally trained from the availablelabeled data, and is used to predict pseudo-labels for the unlabeled data.
subsequently,a noisy student model is trained using the la-beled and pseudo-labeled data.
by replacingthe teacher with the student, the process canbe iterated several times.
in our work, we per-formed just one iteration.
both the teacherand the student models were covid-twitter-bert, with a softmax layer at the top..4.3 domain adaptation baseline.
to understand the beneﬁts of using a prior stancedetection dataset, in addition to the dataset we con-structed, we experimented with a domain adapta-tion model, as described below:.
• bert-dan: dual-view attention networks(xu et al., 2020) capture explicitly subjectiveand objective information contained in tweets,and also enable the use of labeled data for aprior, related task to train a model for a cur-rent task of interest.
the original dan modelproposed by xu et al.
(2020) makes use ofbilstm networks and domain adversarialnetworks to learn the subjective and objec-tive representations and make them domaininvariant.
at the same time, dan learns topredict the stance using labeled data from theprior task (under the assumption that no la-beled data is available for the task of interest).
compared to the original dan model, we re-.
data pre-processing before the tweets in ourdataset were used for training, they were pre-processed and transformed to embedded tensors.
for every tweet in the dataset, we removed anyemojis, urls, and reserved words.
we then usedthe pre-trained covid-twitter-bert to tokenizeand embed each tweet, truncating the sequencelength to 128 as needed.
hyperparameters.
the validation set was usedto determine generally good hyperparameters forthe models.
for each non-bert supervised model,adam optimizer was used with a learning rate of1e−5, weight decay of 4e−5, and gradient clippingwith a max norm of 4.0. each model was trainedfor 120 epochs, with a mini-batch size of 16 ineach iteration.
a dropout of 0.5 was used for eachnetwork.
other speciﬁc hyper-parameters for eachnetwork are shown below:.
• rnn networks: bilstm, atgru, andtan each had a hidden lstm dimension of512 with a dropout of 0.2..• cnn networks: gcae and kim-cnn bothused ﬁlters of width 2, 3, 4, and 5. for eachﬁlter width, there were 25 feature maps.
fol-lowing the convolutional layers was a linearclassiﬁer with a hidden dimension of 128..• bert: this model was initialized with thepre-trained covid-twitter-bert model.
itwas optimized with adamw with a learningrate of 1e−5 over the course of 10 epochs,with 15 warmup steps..• bert-ns: the implementation of the studentmodel is exactly the same as that of the su-pervised bert.
the teacher and the studentmodels are set up in the same manner, exceptthat the teacher has no dropout..• bert-dan: the formation functions are thesame as those of the supervised bert model,.
1602bilstm kim-cnn tan0.5880.6330.6380.5580.6850.6390.5640.6120.6310.5470.6040.630.target: anthony s. fauci, m.d.
atgru gcae0.6350.6400.6130.612target: keeping schools closed.
0.6520.6610.6340.640.bilstm kim-cnn tan0.5980.6250.6270.5450.5490.5700.5320.5090.5450.5340.4950.548.bilstm kim-cnn tan0.6950.7030.7350.5230.5520.6790.5570.5440.6400.5360.5350.645.bilstm kim-cnn tan0.5600.6920.5780.5510.6930.5690.5540.6930.5800.5460.6890.567.
0.5880.5280.4880.490.atgru gcae0.5900.5480.5280.527target: stay at home ordersatgru gcae0.6820.5090.5380.521target: wearing a face maskatgru gcae0.6100.6050.6030.599.
0.7380.7170.6320.645.
0.6400.6620.6460.633.bert0.8170.8160.8300.818.bert0.7720.7650.7610.755.bert0.8430.8160.7880.800.bert0.8100.8030.8180.803.accprref1.
accprref1.
accprref1.
accprref1.
avg..avg..avg..avg..bert-ns0.8200.8210.8230.821.bert-ns0.7800.7730.7430.753.bert-ns0.8320.8130.7680.784.bert-ns0.8400.8300.8370.833.bert-dan0.8300.8330.8390.832.bert-dan0.7580.7480.7020.717.bert-dan0.8330.7990.7790.787.bert-dan0.8400.8350.8190.825.table 12: performance of the baseline models for stance detection on the four targets in the covid-19-stancedataset.
the performance is reported in terms of accuracy (acc), precision (pr), recall (re) and f1 score (f1).
each baseline was trained and evaluated three times.
the results reported are averaged over three runs..except that there is no softmax layer on top.
the discriminators and classiﬁers were all twolayer neural nets with a hidden dimension of1024. a dropout of 0.15 was used throughoutthe network.
optimization was performed byadamw with a learning rate of 3e−6 for ﬁrst7 epochs, and 3e−7 for the ﬁnal 3 epochs.
thefollowing weights were assigned to this net-work’s loss functions: 0.1 for the domain dis-criminators, 0.05 for the objective and subjec-tive classiﬁers, and 0.4 for the source stanceclassiﬁer.
a mini-batch size of 4 was used dueto gpu memory limitations..5.2 evaluation metrics.
to evaluate the performance of the baseline modelson our dataset, we used the following standard met-rics: accuracy, (macro average) precision, recall,and f1 score4.
we report the performance on thetest set at the epoch in which the model recordedthe highest f1 score on the validation data.
weperformed 3 independent runs for each model toaccount for variability, and report average resultsover the three runs..4precision, recall and f1 scores for each stance category.
are also reported in appendix c.6 results and discussion.
the results of the experiments are shown in table12 for the four targets in the covid-19-stancedataset, respectively.
between the two supervisedbaselines that do not explicitly use the target infor-mation, bi-lstm and kim-cnn, the bi-lstmgives better results overall, in all metrics, except forthe “wearing a face mask” target.
when compar-ing kim-cnn with gcae (a cnn-based modelsthat explicitly uses the target), kim-cnn givesbetter accuracy and f1 scores for two targets (“an-thony s. fauci, m.d.” and “stay at home orders”),while the gcae model gives better results for theother two targets (“keeping schools closed” and“wearing a face mask”).
similarly, when com-paring the two recurrent models with attention,tan and atgru, tan performs better on twotargets, “keeping schools closed” and “stay athome orders”, while atgru performs better on“anthony s. fauci, m.d.” and “wearing a facemask”.
surprisingly, these two models, which ex-plicitly use the target information, perform worsethan the bilstm model overall.
finally, we cansee that among the supervised baselines, the bertmodel performs signiﬁcantly better than all theother models, a result that is in agreement withprior works (ghosh et al., 2019; miao et al., 2020)..1603no..tweet.
1 @brad dickson my son teaches in japan.
they wear masksbecause they are a polite society.
school closed asap in feb. didremote learning.
but as of early june, back to in school learningdue to so few cases.
masks work..2 hell no to your mask mandate3.
4.
5.
6.
7.if, 6 months later, you’re still wearing a mask.....you might aswell wear one the rest of your life.
people tweeting from their smart phones about how masks are aform of government control is hilarious to me.
thank goodness trump wasn’t there to greet the astronauts aftersplashdown.
i’m sure he would have shown up with no mask!
#splashdown #spacexsome of ya’ll couldn’t dissect a frog in high school but youknow more than health professionals about the coronavirus!?!?
:man facepalming dark skin tone: #covid19small local grocery store did not have sign requiring mask perstate mandate and was pretty busy.
only about half of customerswearing masks.
the dairy section looked almost empty.
love itand they will continue to get my business..8 @simondolan @saltyseadog7 by not wearing a mask you aregiving the children of the covid generation a chance to go toschool, play sports, and have real childhoods.
label ns prediction dan predictionfavor.
favor.
favor.
againstagainst.
againstfavor.
againstfavor.
favor.
against.
against.
favor.
favor.
against.
favor.
none.
favor.
against.
favor.
against.
against.
favor.
against.
table 13: error analysis: a comparison of the ns model’s predictions with the dan model’s predictions..when comparing bert with bert-ns withbert-dan (models that use unlabeled data andsemeval2016 task 6 data, respectively), we seethat bert performs better than the models thatuse additional information on the “stay at homeorders” target and comparable to the bert-ns onthe “keeping schools closed” target - speciﬁcally,the targets with smaller labeled datasets.
on theother hand, bert-dan performs the best on the“anthony s. fauci, m.d.” target, and comparableto bert-ns on the “wearing a face mask” target,i.e., the targets with larger labeled datasets.
thisresult suggests that a larger amount of labeled datais useful for the domain adaptation approach.
how-ever, when only a small amount of labeled data isavailable, bert is better than the noisy studentwhich may not start with a very good teacher..error analysis.
to better understand how two ofour best models would perform in the wild, wehave included some of their predictions on exam-ples from the wearing a face mask test set, alongwith the gold-standard label in table 13. as we cansee, both models perform well on examples wherethe stance is presented explicitly, such as in tweets1 and 2. however, the models generally strugglewith sarcasm and humor as seen in tweets 3, 5, and6. they also both demonstrate a strong bias to-wards certain phrases such as “form of governmentcontrol” which is a common phrase in againsttweets for wearing a face mask.
interestingly,the noisy student model seems to be more likely.
to incorrectly predict a favor stance when thesentiment of the tweet is positive compared to thedan model, as seen in tweets 7 and 8..7 conclusions and future work.
in this work, we have constructed a covid-19-stance dataset that can be used to further the re-search on stance detection, especially in the contextof covid-19 pandemic.
in addition to the dataset,we have established baselines using several super-vised models used in prior works on stance detec-tion, and also two models that can make use ofunlabeled data and data from a prior stance de-tection task, respectively.
our results show thepre-trained covid-twitter-bert model consti-tutes a strong baseline.
when a larger amount oflabeled data is available for a target, the bert-nsand bert-dan can help further improve the per-formance.
as part of future work, we plan to studythe beneﬁts of the opinion and sentiment data thatwe annotated towards the stance detection.
we alsoplan to study the usefulness of multi-task learning,where we train models for all our targets concur-rently.
other transfer learning approaches that canleverage existing datasets will also be explored..acknowledgements.
we thank the national science foundation andamazon web services for support from grantsiis-1741345, iis-1802284, iis-1912887, and iis-1903963 which supported the research and the com-putation in this study..1604ethics and impact statement.
our dataset does not provide any personally identi-ﬁable information as only the tweet ids and humanannotated stance labels will be shared.
thus, ourdataset complies with twitter’s information privacypolicy.
the research enabled by this dataset hasthe potential to help ofﬁcials and health organiza-tions understand the public’s opinion on variousinitiatives, estimate the efﬁcacy of their mandatesand prevent serious resurgence of the novel coron-avirus..references.
isabelle augenstein, tim rockt¨aschel, andreas vla-chos, and kalina bontcheva.
2016. stance detectionwith bidirectional conditional encoding.
in proceed-ings of the 2016 conference on empirical methodsin natural language processing, pages 876–885,austin, texas.
association for computational lin-guistics..emily chen, kristina lerman, and emilio ferrara.
2020. tracking social media discourse about thecovid-19 pandemic: development of a public coro-navirus twitter data set.
jmir public health andsurveillance, 6(2):e19273..jacob cohen.
1960. a coefﬁcient of agreement foreducational and psychological.
nominal scales.
measurement, 20(1):37–46..costanza conforti, jakob berndt, mohammad taherpilehvar, chryssi giannitsarou, flavio toxvaerd,and nigel collier.
2020. will-they-won’t-they: avery large dataset for stance detection on twitter.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 1715–1724, online.
association for computational lin-guistics..charles courtemanche, joseph garuccio, anh le,pinkston j, and aaron yelowitz.
2020. strong so-cial distancing measures in the united states reducedthe covid-19 growth rate: study evaluates the im-pact of social distancing measures on the growth rateof conﬁrmed covid-19 cases across the united states.
health affairs, 39:10.1377/hlthaff..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..jiachen du, ruifeng xu, yulan he, and lin gui.
2017.stance classiﬁcation with target-speciﬁc neural at-in proceedings of the twenty-sixth inter-tention.
national joint conference on artiﬁcial intelligence,ijcai-17, pages 3988–3994..seth ebner, felicity wang, and benjamin van durme.
2019. bag-of-words transfer: non-contextual tech-in proceedings ofniques for multi-task learning.
the 2nd workshop on deep learning approaches forlow-resource nlp (deeplo 2019), pages 40–46,hong kong, china.
association for computationallinguistics..marc evrard, r´emi uro, nicolas herv´e, and b´eatricemazoyer.
2020. french tweet corpus for automaticin proceedings of the 12th lan-stance detection.
guage resources and evaluation conference, pages6317–6322..will feuer and nate rattner.
2020.
“pandemic fatigue”leads to resurgence of coronavirus in europe wherecases hit fresh records in france and spain.
cnbc..shalmoli ghosh, prajwal singhania, siddharth singh,koustav rudra, and saptarshi ghosh.
2019. stancedetection in web and social media: a comparativestudy.
experimental ir meets multilinguality, mul-timodality, and interaction, 11696:75–87..tom´as hercig, peter krejzl, barbora hourov´a, josefsteinberger, and ladislav lenc.
2017. detectingstance in czech news commentaries.
in itat, pages176–180..geoffrey hinton, oriol vinyals, and jeff dean.
2015.distilling the knowledge in a neural network.
arxivpreprint arxiv:1503.02531..tamanna hossain, robert l logan iv, arjuna ugarte,yoshitomo matsubara, sean young, and sameersingh.
2020. covidlies: detecting covid-19 misin-formation on social media.
in proceedings of the 1stworkshop on nlp for covid-19 (part 2) at emnlp2020..marjan hosseinia, eduard dragut, and arjun mukher-jee.
2020. stance prediction for contemporary is-in proceedings ofsues: data and experiments.
the eighth international workshop on natural lan-guage processing for social media, pages 32–40,online.
association for computational linguistics..yoon kim.
2014..convolutional neural networksin proceedings of thefor sentence classiﬁcation.
2014 conference on empirical methods in naturallanguage processing (emnlp), pages 1746–1751,doha, qatar.
association for computational lin-guistics..mirko lai, alessandra teresa cignarella, deliairaz´u hern´andez far´ıas, cristina bosco, vivianapatti, and paolo rosso.
2020. multilingual stancedetection in social media political debates.
com-puter speech & language, 63:101075..1605yingjie li and cornelia caragea.
2019. multi-taskstance detection with sentiment and stance lexicons.
in proceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 6299–6305, hong kong, china.
association for computa-tional linguistics..yingjie li and cornelia caragea.
2021. target-awaredata augmentation for stance detection.
in proceed-ings of the 2021 conference of the north ameri-can chapter of the association for computationallinguistics: human language technologies, pages1850–1860, online.
association for computationallinguistics..lin miao, mark last, and marina litvak.
2020. twitterdata augmentation for monitoring public opinion onin proceedingscovid-19 intervention measures.
of the 1st workshop on nlp for covid-19 (part 2)at emnlp 2020, online.
association for computa-tional linguistics..saif m mohammad, svetlana kiritchenko, parinazsobhani, xiaodan zhu, and colin cherry.
2016.semeval-2016 task 6: detecting stance in tweets.
in proceedings of the 10th international workshopon semantic evaluation (semeval-2016), pages 31–41, san diego, california.
association for computa-tional linguistics..saif m. mohammad, parinaz sobhani, and svetlanakiritchenko.
2017. stance and sentiment in tweets.
acm trans.
internet technol., 17(3)..ece c mutlu, toktam oghaz, jasser jasser, ege tutun-culer, amirarsalan rajabi, aida tayebi, ozlem oz-men, and ivan garibay.
2020. a stance data set onpolarized conversations on twitter about the efﬁcacyof hydroxychloroquine as a treatment for covid-19.
data in brief, 33:106401..martin m¨uller, marcel salath´e, and per e kummervold.
2020. covid-twitter-bert: a natural language pro-cessing model to analyse covid-19 content on twit-ter..mike schuster and kuldip paliwal.
1997. bidirectionalrecurrent neural networks.
signal processing, ieeetransactions on, 45:2673 – 2681..umme aymun siddiqua, abu nowshed chy, andmasaki aono.
2019. tweet stance detection usingan attention based neural ensemble model.
in pro-ceedings of the 2019 conference of the north amer-ican chapter of the association for computationallinguistics: human language technologies, vol-ume 1 (long and short papers), pages 1868–1873,minneapolis, minnesota.
association for computa-tional linguistics..valeriya slovikovskaya and giuseppe attardi.
2020.transfer learning from transformers to fake news.
in pro-challenge stance detection (fnc-1) task.
ceedings of the 12th language resources and eval-uation conference, pages 1211–1218, marseille,france.
european language resources association..qingying sun, zhongqing wang, shoushan li, qiaom-ing zhu, and guodong zhou.
2019. stance detectionvia sentiment information and neural network model.
frontiers of computer science, 13(1):127–138..qingying sun, zhongqing wang, qiaoming zhu, andguodong zhou.
2018. stance detection with hierar-chical attention network.
in proceedings of the 27thinternational conference on computational linguis-tics, pages 2399–2409, santa fe, new mexico, usa.
association for computational linguistics..jannis vamvas and rico sennrich.
2020. x-stance:a multilingual multi-target dataset for stance detec-tion..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, undeﬁne-dukasz kaiser, and illia polosukhin.
2017. attentionis all you need.
in proceedings of the 31st interna-tional conference on neural information processingsystems, nips’17, page 6000–6010, red hook, ny,usa.
curran associates inc..prashanth vijayaraghavan,.
ivan sysoev, soroushvosoughi, and deb roy.
2016. deepstance atsemeval-2016 task 6: detecting stance in tweetsusing character and word-level cnns.
in proceed-ings of the 10th international workshop on seman-tic evaluation (semeval-2016), pages 413–419, sandiego, california.
association for computationallinguistics..ramon villa-cox, sumeet kumar, matthew babcock,and kathleen m carley.
2020. stance in repliesand quotes (srq): a new dataset for learningarxiv preprintstance in twitter conversations.
arxiv:2006.00691..sergey v vychegzhanin and evgeny v kotelnikov.
2019.stance detection based on ensembles ofclassiﬁers.
programming and computer software,45(5):228–240..penghui wei, wenji mao, and guandan chen.
2019. atopic-aware reinforced model for weakly supervisedstance detection.
in proceedings of the aaai con-ference on artiﬁcial intelligence, volume 33, pages7249–7256..wan wei, xiao zhang, xuqin liu, wei chen, andtengjiao wang.
2016. pkudblab at semeval-2016task 6 : a speciﬁc convolutional neural network sys-tem for effective stance detection.
in proceedings ofthe 10th international workshop on semantic eval-uation (semeval-2016), pages 384–388, san diego,california.
association for computational linguis-tics..1606qizhe xie, minh-thang luong, eduard hovy, andquoc v le.
2020. self-training with noisy studentimproves imagenet classiﬁcation.
in proceedings ofthe ieee/cvf conference on computer vision andpattern recognition, pages 10687–10698..chang xu, c´ecile paris, surya nepal, and ross sparks.
2018. cross-target stance classiﬁcation with self-attention networks.
in proceedings of the 56th an-nual meeting of the association for computationallinguistics (volume 2: short papers), pages 778–783, melbourne, australia.
association for compu-tational linguistics..chang xu, cecile paris, surya nepal, ross sparks,chong long, and yafang wang.
2020. dan: dual-view representation learning for adapting stance clas-siﬁers to new domains.
in proceedings of the 24theuropean conference on artiﬁcial intelligence, vol-ume 24, pages 2260–2267.
european conference onartiﬁcial intelligence..wei xue and tao li.
2018. aspect based sentimentanalysis with gated convolutional networks.
in pro-ceedings of the 56th annual meeting of the associa-tion for computational linguistics (volume 1: longpapers), pages 2514–2523, melbourne, australia.
association for computational linguistics..guido zarrella and amy marsh.
2016. mitre atsemeval-2016 task 6: transfer learning for stancedetection.
in proceedings of the 10th internationalworkshop on semantic evaluation (semeval-2016),pages 458–463, san diego, california.
associationfor computational linguistics..yiwei zhou and a. i. cristea.
2017. connecting tar-gets to tweets: semantic attention-based model fortarget-speciﬁc stance detection.
in athman bouguet-taya, yunjun gao, andrey klimenko, lu chen, xi-angliang zhang, fedor dzerzhinskiy, weijia jia,stanislav v. klimenko, and qing li, editors, pro-ceedings of the 18th international conference onweb information systems engineering, wise 2017,puschino, russia, october 7-11, 2017, number10569 in lecture notes in computer science, pages18–32.
springer, cham..elena zotova, rodrigo agerri, manuel nu˜nez, andgerman rigau.
2020. multilingual stance detec-tion in tweets: the catalonia independence cor-pus.
in proceedings of the 12th language resourcesand evaluation conference, pages 1368–1375, mar-seille, france.
european language resources asso-ciation..1607a keywords used for twitter crawler.
#covid-19,.
stayhome,.
coronavirus,.
trumppandemic,.
#coronavirus,#coronavid19,corona virus,#coronavirususa, #coronavirusaustralia, #covid19,#coron-covid-19,apocalypse, #quarantinelife, #socialdistancing,socialdistancing,stayathome,lockdown,stayhomesavelives, quarantine,socialdistancing, conﬁnement, flattenthecurve,stayhomestaysafe, stayhome, quarantinelife,5g, trumpvirus, staysafe, coronavirustruth,washyourhands, chinesevirus, trumpliedpeo-pledied, stayhome, lockdown, trumpliesabout-coronavirus, chinavirus, covidiots, covid-iot, quarantinelife, staysafestayhome, hoax,trumpviruscoverup, panicbuying, hydroxychloro-quine, thelockdown, lockdowneffect, toiletpaper,staythefhome,stayathomeandstaysafe,selfisolation, quarantineandchill,stayath-socialdistanacing,ome,chinaliedpeopledied, quaratinelife,lock-downextension, trumpdemic, trumpliedpeo-pledied, workfromhome, trumpliespeopledie,trumpliesamericansdie,quarentinelife,lockdown21, workingfromhome, trumpown-severydeath, trumpplague, lockdownextended,coronaviruslockdown, trumpgenocide, so-cialdistancingnow, ccpvirus, socialdistance,chinesevirus19, shelterinplace, stayathome-savelives, physicaldistancing, resist, isolation,chinacoronavirus, toiletpapercrisis, lockdownuk,chloroquine, wfh, chinaliedandpeopledied,lockdownnow, selﬁsolating, lockdownextention,closetheschools, pencedemic, supportlock-toiletpaperpanic, schoolclosure,downstaysafe,toiletpaperapocalypse,selfquarantine, masks,handwashing, wearamask, safehands, handsani-tizer, lockdown, mask, isolation, ﬂattenthecurve,panickbuying,panicbuyers,washyourhands,social distancing, chinamustexplain, masks4all,washyourhandschallenge,bloodontrump-shands, isolationlife, hoax, toiletpaperpanic,toiletpapergate, homeschooling, panicshopping,hydroxychloroquine,5gkills,lockdown-trumpvirus, stayhomesavelifes,houseparty,familiesfirst,pencepandemic,homeofﬁce,stayhomecanada,selﬁsolation,ﬂatteningthecurve, quaratineandchill, herdim-munity, alonetogether, hydroxycloroquine,remotework, masks, flatten-workfromhome,thecuve,socialdistancing,hydroxychloriquine, day8oﬂockdown, wfh, stay-.
covididiot,.
facemasks,.
trumpburialpits,.
home, herdimmunity, coronaviruslockdownuk,shutit-trumpvirus2020,down, 5gcoronavirus, homeofﬁce, resistance,chineseviruscorona, chinesevirus, panicbuyin-facemask,guk, kungflu, nyclockdown,trumpandemic, coronahoax, homeofﬁce, chi-nesecoronavirus, pandumbic, coronalockdown,openamericanow, togetherathome, testing,wherearethetests,feverdetectioncamera,vaccines, plandemic, scamdemic, firefauci,studentlivesmatter, stayathome, endthelock-down, reopenamerica, lockdown2020, cance-schoolreopening,lapexamspromotestudents,healthoverexams, promotestudentssavefuture,testingtestingtesting, schools, lockdownuknow,saferathome, contacttracing, freethemall,trumpcoronavirustestfailure, trumpliedamer-icansdied, handwashing, chinaliedpeopledie,stayathomeorder, openamerica, vaccine,remoteworking, californialockdown, testtraceiso-late, endtheshutdown, wholiedpeopledied,curfew, curfew, reopenamerica, testing,testvirusnow, socialdistance, plandemic,stayhomestaysafe, trumppan-fakepandemic,demicfailure,backtowork,backtowork,chinavirus,reopenamericanow, makechi-napay, testandtrace,#masksoff, masksoff,saynotomasks,#saynotomasks, constitu-tionovercoronavirus, #constitutionovercoron-avirus, endthelockdownuk, #endthelockdownuk,#studentban, #studentban, schoolsmustopen-infall, schoolreopening, reopeningschools,#schoolreopening,#schoolsmustopeninfall,#reopeningschools,#hydroxychloroquine,hydroxychloroquine.
b questionnaire used for amazon.
mechanical turk workers.
q1: from reading the tweet, which of the op-tions below is most likely to be true about thetweeter’s stance or outlook towards stance toprevent the spread of covid-19:.
1. we can infer from the tweet that the tweeter.
supports the target.
this could be because of any of reasons shownbelow:.
• the tweet is explicitly in support for the.
target..• the tweet.
is in support of some-thing/someone aligned with the target,.
1608from which we can infer that the tweetersupports the target..• the tweet is against something/someoneother than the target, from which we caninfer that the tweeter supports the target.
• the tweet is not in support of or againstanything, but it has some information,from which we can infer that the tweetersupports the target..• we cannot infer the tweeter’s stance to-ward the target, but the tweet is echo-ing somebody else’s favorable stance to-wards the target (this could be a newsstory, quote, retweet, etc)..q2: from reading the tweet, which of the op-tions below is most likely to be true about thefocus of opinion/sentiment in the tweet:.
1. the.
tweet.
explicitly.
expresses.
opin-.
ion/sentiment about the target..2. the tweet expresses opinion/sentiment aboutsomething/someone other than the target..3. the tweet is not expressing opinion/sentiment.
about anything..q3: what kind of language is the speaker us-.
ing?.
1. the speaker is using positive language, forexample, expressions of support, admiration,positive attitude, forgiveness, fostering, suc-cess, positive emotional state (happiness, opti-mism, pride, etc.)..
2. the speaker is using negative language,for example, expressions of criticism, judg-ment, negative attitude, questioning valid-ity/competence, failure, negative emotionalstate (anger, frustration, sadness, anxiety,etc.)..
3. the speaker is using expressions of sarcasm,.
ridicule, or mockery..4. the speaker is using positive language in part.
and negative language in part..5. the speaker is neither using positive language.
nor using negative language..c comprehensive results by class.
the average results for stance detection over allthree classes, as well as detailed results per classare shown for the four targets in tables 14, 15, 16,and 17, respectively..2. we can infer from the tweet that the tweeter.
is against the target.
this could be because of any of the following:.
• the tweet is explicitly against the target.
• the tweet is against someone/somethingaligned with the target entity, from whichwe can infer that the tweeter is againstthe target.
• the tweet.
some-one/something other than the target, fromwhich we can infer that the tweeter isagainst the target..in support of.
is.
• the tweet is not in support of or againstanything, but it has some information,from which we can infer that the tweeteris against the target..• we cannot infer the tweeter’s stance to-ward the target, but the tweet is echoingsomebody else’s negative stance towardsthe target entity (this could be a newsstory, quote, retweet, etc)..3. we can infer from the tweet that the tweeter.
has a neutral stance towards the target..• the tweet must provide some informa-tion that suggests that the tweeter is neu-tral towards the target - the tweet beingneither favorable nor against the targetis not sufﬁcient reason for choosing thisoption.
one reason for choosing this op-tion is that the tweeter supports the targetentity to some extent, but is also againstit to some extent..4. there is no clue in the tweet to reveal thestance of the tweeter towards the target (sup-port/against/neutral)..1609target: anthony s. fauci, m.d..bilstm kim-cnn tan atgru gcae bert bert-ns bert-dan0.6380.6390.6310.6300.6580.6460.6510.6570.6710.6610.6020.5770.577.
0.8170.8160.8300.8180.8590.8410.8500.8600.7390.7950.7280.9100.809.
0.5880.5580.5640.5470.5880.5850.5840.6230.7150.6550.4620.3910.402.
0.6350.6400.6130.6120.6650.5690.6100.6260.7750.6870.6280.4940.540.
0.8300.8330.8390.8320.8840.7900.8320.8300.8030.8160.7850.9230.848.
0.8200.8210.8230.8210.8600.8050.8310.8150.8110.8130.7880.8530.818.
0.6520.6610.6340.6400.7070.5540.6210.6320.7790.6980.6430.5710.601.
0.6330.6850.6120.6040.7220.5740.6240.6160.7670.6830.7160.4940.506.accprref1prref1prref1prref1.
average.
against.
favor.
none.
table 14: performance of the baseline models for stance detection on the target “anthony s. fauci, m.d.”.
averageperformance over three classes, as well as performance per class is reported in terms of accuracy (acc), precision(pr), recall (re) and f1 score (f1).
each baseline was trained and evaluated three times.
the results reported areaveraged over three runs..target: keeping schools closed.
bilstm kim-cnn tan atgru gcae bert bert-ns bert-dan0.6270.5700.5450.5480.3720.2380.2870.6740.5940.6290.6650.8030.727.
0.7800.7730.7430.7530.6600.6510.6520.8690.7090.7790.7910.8710.829.
0.7720.7650.7610.7550.5960.7300.6470.8620.7580.8060.8360.7960.813.
0.5980.5450.5320.5340.3810.3170.3420.5860.5270.5540.6670.7510.706.
0.7580.7480.7020.7170.6060.5480.5730.8680.6670.7510.7710.8930.827.
0.5900.5480.5280.5270.3700.3100.3210.6160.5450.5720.6570.7280.690.
0.5880.5280.4880.4900.3640.1900.2490.5960.4480.5100.6240.8250.710.
0.6250.5490.5090.4950.3770.1030.1600.6280.5390.5800.6420.8830.744.accprref1prref1prref1prref1.
average.
against.
favor.
none.
table 15: performance of the baseline models for stance detection on the target “keeping schools closed”.
av-erage performance over three classes, as well as performance per class is reported in terms of accuracy (acc),precision (pr), recall (re) and f1 score (f1).
each baseline was trained and evaluated three times.
the resultsreported are averaged over three runs..1610target: stay at home orders.
bilstm kim-cnn tan atgru gcae bert bert-ns bert-dan0.7350.6790.6400.6450.7000.6440.6690.7850.8550.8180.5540.4200.447.
0.6950.5230.5570.5360.6030.6090.5980.7550.8520.8000.2100.2100.210.
0.6820.5090.5380.5210.6130.5980.6040.7210.8430.7750.1940.1730.183.
0.8330.7990.7790.7870.7810.8390.8090.8810.8810.8810.7350.6170.671.
0.8430.8160.7880.8000.8300.8390.8340.8680.8960.8820.7510.6300.684.
0.8320.8130.7680.7840.7840.8330.8060.8690.8900.8780.7860.5800.667.
0.7380.7170.6320.6450.6460.7010.6710.7910.8490.8170.7140.3460.446.
0.7030.5520.5440.5350.6140.6150.6140.7360.8810.8020.3060.1360.188.accprref1prref1prref1prref1.
average.
against.
favor.
none.
table 16: performance of the baseline models for stance detection on the target “stay at home orders”.
averageperformance over three classes, as well as performance per class is reported in terms of accuracy (acc), precision(pr), recall (re) and f1 score (f1).
each baseline was trained and evaluated three times.
the results reported areaveraged over three runs..target: wearing a face mask.
bilstm kim-cnn tan atgru gcae bert bert-ns bert-dan0.5780.5690.5800.5670.6130.5900.6000.4360.5850.4960.6580.5640.606.
0.8400.8300.8370.8330.8590.8630.8610.7660.8210.7920.8640.8270.845.
0.6100.6050.6030.5990.5890.7010.6400.5300.5610.5440.6960.5470.613.
0.8100.8030.8180.8030.8540.8030.8210.6940.8620.7650.8610.7900.822.
0.5600.5510.5540.5460.5580.6280.5900.4410.5200.4770.6550.5140.572.
0.6400.6620.6460.6330.6150.7650.6750.6090.6670.6190.7600.5060.605.
0.8400.8350.8190.8250.8200.9360.8740.8060.7070.7530.8800.8150.846.
0.6920.6930.6930.6890.6540.7350.6910.6580.6990.6740.7660.6460.701.accprref1prref1prref1prref1.
average.
against.
favor.
none.
table 17: performance of the baseline models for stance detection on the target “wearing a face mask”.
averageperformance over three classes, as well as performance per class is reported in terms of accuracy (acc), precision(pr), recall (re) and f1 score (f1).
each baseline was trained and evaluated three times.
the results reported areaveraged over three runs..1611