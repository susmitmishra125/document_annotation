learning from miscellaneous other-class wordsfor few-shot named entity recognitionmeihan tong1, shuai wang2, bin xu1∗, yixin cao3, minghui liu1, lei hou1, juanzi li11knowledge engineering laboratory, tsinghua university, beijing, china2slp group, ai technology department, joyy inc, china3s-lab nanyang technological university, singaporetongmeihan@gmail.com, wangshuai1@yy.comxubin@tsinghua.edu.cn, caoyixin2011@gmail.comliu-mh16@mails.tsinghua.edu.cn,greener2009@gmail.comlijuanzi@tsinghua.edu.cn.
abstract.
few-shot named entity recognition (ner)exploits only a handful of annotations to iden-tify and classify named entity mentions.
pro-totypical network shows superior performanceon few-shot ner.
however, existing prototyp-ical methods fail to differentiate rich seman-tics in other-class words, which will aggravateoverﬁtting under few shot scenario.
to addressthe issue, we propose a novel model, miningundeﬁned classes from other-class (muco),that can automatically induce different unde-ﬁned classes from the other class to improvefew-shot ner.
with these extra-labeled unde-ﬁned classes, our method will improve the dis-criminative ability of ner classiﬁer and en-hance the understanding of predeﬁned classeswith stand-by semantic knowledge.
experi-mental results demonstrate that our model out-performs ﬁve state-of-the-art models in both 1-shot and 5-shots settings on four ner bench-marks.
we will release the code upon accep-tance.
the source code is released on https://github.com/shuaiwa16/otherclassner.git..1.introduction.
named entity recognition (ner) seeks to locateand classify named entities from sentences intopredeﬁned classes (yadav and bethard, 2019).
hu-mans can immediately recognize new entity typesgiven just one or a few examples(lake et al., 2015).
although neural ner networks have achieved su-perior performance when provided large-scale oftraining examples (li et al., 2019), it remains anon-trivial task to learn from limited new samples,also known as few-shot ner (fritzler et al., 2019).
traditional ner models, such as lstm+crf(lample et al., 2016), fail in few-shot settings.
they calculate the transition probability matrixbased on statistics, which requires a large num-ber of data for optimization.
recently, prototypical.
∗corresponding author..figure 1: (a): examples for undeﬁned classes.
(b): dif-ferent ways to handle o class (single prototype vs. mul-tiple prototypes)..network (snell et al., 2017) shows potential on few-shot ner.
the basic idea is to learn prototypes foreach predeﬁned entity class and an other class, thenclassify examples based on which prototypes theyare closest to (fritzler et al., 2019).
most existingstudies focus on the predeﬁned classes and lever-age the label semantic to reveal their dependencyfor enhancement (hou et al., 2020).
however, theyignore the massive semantics hidden in the wordsof other class (o-class for short)..in this paper, we propose to learn from o-classwords, rather than using predeﬁned entity classesonly, to improve few-shot ner.
in fact, o-classcontains rich semantics and can provide stand-byknowledge for named entity identiﬁcation and dis-ambiguation.
as shown in figure 1(a), if we candetect an undeﬁned class consisting of referencesto named entities (such as pronouns), then due totheir interchangeability (katz and fodor, 1963), wewill obtain prior knowledge for named entity iden-tiﬁcation.
for example, newton can be replacedwith he or professor in s2 and s3.
if we can detectadditional classes, including he and professor, wewill have more evidence about where newton mayappear.
in addition, if we can detect an undeﬁnedclass that composed of action (o1), we may cap-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6236–6247august1–6,2021.©2021associationforcomputationallinguistics6236previous methodsour methodpersonlocationo3o2o1predefined classesundefined classess1: emeneya was born in local hospital and died in pariso3o1o1s3: the professor from the city studies mathematicso3o2o1o1s2: newton is a polymath.
he was born in lincolnshire.o2(a)(b)oopersonlocationture underlined relations between different namedentities, which is important evidence when distin-guishing the named entity type (ghosh et al., 2016;zheng et al., 2017)..nevertheless, it is challenging to detect relatedundeﬁned classes from o class words due to tworeasons: 1) miscellaneous semantics.
o-class con-tains miscellaneous types of words.
based on ourobservations, although there are massive related yetundeﬁned classes, the noise maybe even more, suchas function and stop words.
these noisy classeshave little or negative impacts on the identiﬁcationof target entities.
therefore, how to distinguishnoise from task-related classes is a key point.
2)lack of golden label.
we neither have the la-beled examples nor the metadata of each undeﬁnedclass.
the zero-shot methods (pushp and srivas-tava, 2017) fail in this case, since they need meta-data (such as class name and class description) asknown information.
unsupervised clustering meth-ods also cannot meet quality requirements as shownin our experiment..to handle the issues, we propose the miningundeﬁned classes from other-class (muco)model to leverage the rich semantics to improvefew-shot ner.
instead of a single prototype, welearn multiple prototypes to represent miscella-neous semantics of o-class.
figure 1(b) showsthe difference between our method and previousmethods.
to distinguish task-related undeﬁnedclasses without annotations, we leverage weaklysupervised signals from predeﬁned classes and pro-pose a zero-shot classiﬁcation method called zero-shot miner.
the main idea is inspired by trans-fer learning in prototypical network.
prototypicalnetwork can be quickly adapted to new class bwhen pre-training on related base class a. the un-derlined reason is that if two classes (a and b)are task-related, when we make examples in aclass to cluster in the space, the examples in bclass also tend to cluster in the space, even with-out explicit supervision on class b (koch et al.,2015).
based on this phenomenon, we ﬁrst per-form prototype learning on predeﬁned classes tocluster words in predeﬁned classes, and then regardwords in o-class that also tend to cluster as theundeﬁned classes.
speciﬁcally, we train a binaryclassiﬁcation to judge whether clustering occursbetween any two of the words.
after that, we labelthe found undeﬁned classes back into sentences tojointly recognize predeﬁned and undeﬁned classes.
for knowledge transfer.
our contributions can besummarized as follows:.
• we propose a novel approach muco to lever-age rich semantics in o class to improve few-shot ner.
to the best of our knowledge, thisis the ﬁrst work exploring o-class in this task..• we propose a novel zero-shot classiﬁcationmethod for undeﬁned class detection.
in theabsence of labeled examples and metadata,our proposed zero-shot method creatively usethe weakly supervised signal of the predeﬁnedclasses to ﬁnd undeﬁned classes..• we conduct extensive experiments on fourbenchmarks as compared with ﬁve state-of-the-art baselines.
the results under both 1-shot and 5-shots settings demonstrate the ef-fectiveness of muco.
further studies showthat our method can also be convenientlyadapted to other domains..2 related work.
few-shot ner aims to recognize new categorieswith just a handful of examples (feng et al., 2018;cao et al., 2019).
four groups of methods areadopted to handle the low-resource issue: knowl-edge enhanced, cross-lingual enhanced, cross-domain enhanced, and active learning.
knowledge-enhanced methods exploit ontology, knowledgebases or heuristics labeling (fries et al., 2017; tsaiand salakhutdinov, 2017; ma et al., 2016) as sideinformation to improve ner performance in lim-ited data settings, which suffer from knowledgelow-coverage issue.
cross-lingual (feng et al.,2018; rahimi et al., 2019) and cross-domain en-hanced methods (wang et al., 2018; zhou et al.,2019) respectively use labeled data from a coun-terpart language or a different domain as externalsupervised signals to avoid overﬁtting.
when thelanguage or domain discrepancy is large, these twomethods will inevitably face the problem of per-formance degradation (huang et al., 2017).
ac-tive learning methods (wei et al., 2019) explicitlyexpand corpus by selecting the most informativeexamples for manual annotation, which need extrahuman-laboring.
different from previous methods,we focus on mining the rich semantics in the oclass to improve few-shot ner..62372.1 prototypical network.
prototypical network (snell et al., 2017), initiallyproposed for image classiﬁcation, has been success-fully applied to sentence-level classiﬁcation tasks,such as text classiﬁcation (sun et al., 2019) andrelation extraction (gao et al., 2019).
however,there is a dilemma to adapt prototypical networkfor token-level classiﬁcation tasks such as ner.
prototypical network assumes that each class hasuniform semantic and vectors belong to the sameclass should cluster in the space.
however, in ner,data in o class contain multiple semantics and thusviolate the uniform semantic hypothesis in proto-typical network.
to handle the issue, deng et al.
(2020) ﬁrst trains a binary classiﬁer to distinguish oclass from other predeﬁned classes, and then adopttraditional prototypical network methods, whichsuffers from pipeline error propagation.
fritzleret al.
(2019) does not calculate the prototype of oclass from data, but directly sets a hyper-parameterbo as the fake distance similarity and optimize boduring training, which still regards o class as awhole.
on the contrary, we are the ﬁrst to divide oclass into multiple undeﬁned classes and explicitlylearn multiple spatially-dispersed prototypes for oclass..3 methodology.
figure 2 illustrated the architecture of the proposedmuco model.
muco is composed of two mainmodules: undeﬁned classes detection detectsmultiple undeﬁned classes hidden in o class to fullyexploit the rich semantics in o class.
joint classi-ﬁcation jointly classiﬁes the undeﬁned classes andpredeﬁned classes, so as to leverage the stand-by se-mantic knowledge in undeﬁned classes to enhancethe understanding of predeﬁned classes..3.1 notation.
in few-shot ner, we are given training exam-ples d = dc ∪ do, where dc = {xi, yi|ni=1}is the training examples of predeﬁned classesc = {c1, c2, .
.
.
, ck} and do = {xi|mi=1} is thetraining examples of o class.
for each exam-ple (x, y), x is composed by s and wj, wheres =< w1, w2, .
.
.
, wn > stands for the sentenceand wj is the queried named entity, y is the classlabel of the queried named entity wj.
we denotethe prototype of class y as py and prototypes forall classes c ∪ o as p = {py|y ∈ c ∪ o}.
for-mally, our goal is ﬁrst to detect multiple undeﬁned.
classes o = {o1, o2, .
.
.
, or} to label the examplesin do, and then maximize the prediction probabil-ity p (y|x) on dc and do..3.2 undeﬁned classes detection.
in few-shot ner, most of the words in the sen-tence belong to o class.
different from predeﬁnedclasses, o class means none-of-the-above, and con-tains multiple undeﬁned entity types.
previousmethods ignore the ﬁne-grained semantic informa-tion in o class and simply regard o as a normalclass.
we argue to further decouple o class intomultiple undeﬁned classes to fully exploit the richsemantics hidden in o class..in the section, we aim to detect undeﬁned classesfrom o class.
it is a non-trivial task since we lackmetadata and golden labels to help us distinguishundeﬁned classes.
what is worse, the examplesfrom o class is numerous and the search spaceis large.
to handle the issue, we propose a zero-shot classiﬁcation method called zero-shot minerto leverage the weak supervision from predeﬁnedclasses for undeﬁned classes detection.
our methodinspires by transfer learning, we argue that if anundeﬁned class is task-related, when we push theexamples in predeﬁned classes to cluster in thespace, the examples in the undeﬁned class shouldalso have the signs of gathering, even without ex-plicit supervision (koch et al., 2015).
for instance,in figure 2, if we guide emeneya and newton (thegreen points 1, 3) to cluster in the space, professorand he (the grey points 9, 12) will also tend tocluster in the space..based on this argument, undeﬁned classes detec-tion could be achieved by ﬁnding multiple groupsof examples in o class that have a tendency tocluster during the training of the prototypical net-work on predeﬁned classes.
as shown in figure2, there are three steps in our zero-shot classiﬁca-tion method.
in step 1, we train the prototypicalnetwork on predeﬁned classes to obtain the learnedmapping function.
through the learned mappingfunction the examples belonging to the same classwill cluster in the space.
in step 2, we train a bi-nary group classiﬁer on predeﬁned classes baseon the position features from the learned mappingfunction and unlearned mapping function to judgewhether any two points tend to cluster during thestep 1 training.
in step 3, we use the learned bi-nary group classiﬁer in step 2 to infer examples ino class to distinguish undeﬁned classes from each.
6238figure 2: the architecture of the proposed muco model.
we ﬁrst detect undeﬁned classes from o class, andthen jointly classify the predeﬁned classes and the found undeﬁned classes for knowledge transfer.
speciﬁcally,in undeﬁned classes detection, we propose a zero-shot classiﬁcation method, which includes three steps.
in step1, we learn a mapping function through prototypical network training on predeﬁned classes.
in step 2, we learna binary group classiﬁer to judge whether any two points in predeﬁned classes tend to cluster during the step 1training.
in step 3, we use the binary group classiﬁer to infer pairs of examples in o class to distinguish multipleundeﬁned classes..other.
the following articles will illustrate the threesteps sequentially..where fθ(x) and py are ﬁrst normalized by l2 nor-malization..3.2.1 step 1: mapping function learningin prototypical network, mapping function fθ(x)aims to map the example x to a hidden representa-tion.
bert is adopted as the mapping function inour model, which is a pre-trained language repre-sentation model that employs multi-head attentionas the basic unit, and have superior representationability (geng et al., 2019)..we train the mapping function by correctly dis-tinguishing the predeﬁned classes.
first, we extractthe feature of the queried word.
formally, giventhe training example (x, y) ∈ dc, where x is com-posed of sentence s =< w1, w2, .
.
.
, wn > andthe queried word wj, we extract the j-th represen-tation of the sequence output of the last layer ofbert as the hidden representation..h = fθ(x).
(1).
then, following (qi et al., 2018), we randomlyinitialize the prototype py of class y at the begin-ning of training, and then we shorten the distancebetween examples in class y to prototype py dur-ing training.
compared to traditional prototypicallearning (snell et al., 2017), we do not need towaste part of the examples for prototype calcula-tion..d(x, py) = −fθ(x)t py.
(2).
the ﬁnal optimization goal for training the map-.
ping function is.
l(θ1) = −log.
(cid:80).
exp(−d(x, py)).
pc∈pc.
exp(−d(x, pc)).
(3).
where pc = {pc|c ∈ c} stands for the prototypesof all the predeﬁned classes..3.2.2 step 2: binary group classiﬁer.
training.
recall that to detect multiple undeﬁned classes,we need to ﬁnd multiple example groups, and theexamples in each group should have a tendency tocluster..to handle the issue, we learn a binary group clas-siﬁer on predeﬁned classes.
the main idea is thatif we can determine whether any two examples be-long to the same group, we can distinguish groupsfrom each other.
formally, given a pair of examples(xi, yi) and (xj, yj) in dc, their original positionhi, hj from unlearned mapping function fθ(x), andafter-training position ˜hi, ˜hj from learned mappingfunction ˜fθ(x), the probability of xi and xj belong-ing to the same class is deﬁned as follows:.
bij = w ([hi; hj; ˜hi; ˜hj; |hi − hj|;.
|˜hi − ˜hj|; |hi − ˜hi|; |hj − ˜hj|]) + b.
(4).
6239lincolnshireheborn…original positionsafter- training positions3128751110691311129>γ41undefined classes detections1:emeneya1 was born in local hospital and died in pairs2  s2:newton3 is a polymath.
he was born in lincolnshire4 s3:the professor from the city studies mathematicsexamples from pre-defined classes (dc)joint classificationexamples from o class (do)unlearned mapping functiondc & dopo1po2ppersonploclearned mapping functionunlearned mapping function42emeneyabinary group classifier 2581313local hospicalcityo3o3professoro2heo2ppersonploc⑥ ⑦⑦ ⑩⑤ ⑧0.90.80.80.10.3⑤ ⑥⑤ ⑨① ②① ③01newtonpersonpersonpairslincolnshirelocationlocations1:emeneya was born5 in local6 hospital7 and died8 in paris.
s2:newton is a polymath.
he12 was born13 in  lincolnshire s3:the professor9 from the city10 studies11 mathematicss2:newton is a polymath.
he was born in lincolnshire② ④1② ③0newtonpersonlocationo2o16107borno1diedo1step 1step 2step 3by comparing the distance variation between orig-inal positions h and the after-training positions ˜h,we can tell whether aggregation occurs betweenany of the two points..the optimization goal of the binary group classi-.
formally, given the examples (x, y) ∈ dc ∪do, the corresponding prototype py and prototypesset p = pc ∪ po from both predeﬁned classes cand undeﬁned classes o, the optimization object isdeﬁned as:.
ﬁer is.
l(θ2) =.
(−yij ∗ log(bij).
1n 2.n(cid:88).
n(cid:88).
i.j.
+ (1 − yij) ∗ log(1 − bij))(5)where n is the numbers of the examples in pre-deﬁned classes, and yij is the label.
if xi and xjare from the same predeﬁned class (yi=yj), yij is1, otherwise 0..3.2.3 step 3: binary group classiﬁer.
inference.
after training, we feed each pair of examples xuand xv in do to the binary group classiﬁer to obtainthe group dividing results.
the output buv indicatesthe conﬁdence that xu and xv belong to the samegroup.
we set a threshold to divide the group.
ifbuv is larger than the threshold γ, xu and xv shallbelong to the same group (undeﬁned class).
if con-secutive words belong to the same group, we willtreat these words as one multi-word entity.
notedthat some of the examples in o class may not be-long to any group.
we assume that these examplescome from the task-irrelevant classes, and no fur-ther classiﬁcation is made for these examples..soft labeling after the process of group divid-ing, we obtain labels of multiple undeﬁned classeso = {o1, o2, .
.
.
, or}.
we further adopt the soft la-beling mechanism.
for each undeﬁned class oi, wecalculate the mean of the examples as the class cen-ter, then we apply softmax on the cosine similaritybetween examples and its class center as the softlabels.
through soft labeling, we can consider howlikely examples belong to the undeﬁned classes..3.3.joint classiﬁcation.
in the section, we take into consideration of boththe predeﬁned classes c and the found undeﬁnedclasses o for joint classiﬁcation.
first, we la-bel the examples in undeﬁned classes back intothe sentences, as shown in joint classiﬁcationof figure 2. then, we optimize the examplesto make them closer to the corresponding proto-type for better discrimination.
comparing to theequation 3, we add the prototypes from o classpo = {po1, po2, .
.
.
, por } as candidate prototypes..l(θ3) = −log.
exp(−d(x, py))p∈{pc∪po} exp(−d(x, p)).
(cid:80).
(6).
scale factor when calculating d(x, py), the fθ(x)and py have been normalized and the value is lim-ited to [-1, 1].
when softmax activation is applied,the output is unable to approach the one-hot en-coding and therefore imposes a lower bound onthe cross-entropy loss (qi et al., 2018).
for in-stance, even we give the golden prediction: giving1 for correct category and -1 for the wrong ones,the probability of output p(y|x) = e1/[e1 + (|c ∪t | − 1)e−1] is still unable to reach 1. the problembecomes more severe as we increase the numberof named entity categories by introducing morecategories for o class.
to alleviate the issue, wemodify eq.
6 by adding a trainable scalar s sharedacross all classes to scale the inner product (wanget al., 2017)..l(θ3) = −log.
exp(−sd(x, py))p∈{pc∪pt} exp(−sd(x, p)).
(cid:80).
(7).
3.4.implementation details.
following traditional prototypical network (snellet al., 2017), we pre-train the model on several baseclasses, whose types are disjoint to few-shot classesand have abundant labeled corpus.
the underlinedidea is to leverage existing fully annotated classesto improve the performance of the model on newclasses with only a few annotations.
all predeﬁnedclasses (both base classes and few-shot classes) areused when searching for undeﬁned classes, so thatthe annotations of undeﬁned classes can be sharedbetween pre-training and ﬁne-tuning, which willimprove the transfer performance of our model..4 experiment.
4.1 datasets.
we conduct experiments on multiple datasets toreduce the dataset bias, including three englishbenchmarks conll2003 (sang and de meulder,2003), re3d (science and laborator, 2017) and.
6240ontonote5.0 (pradhan et al., 2013) and one chi-nese benchmark cluener2020 (xu et al., 2020).
conll2003 contains 20,679 labeled sentences, dis-tributed in 4 classes in the news domains.
thedata in re3d comes from defense and security do-main, with 10 classes and 962 labeled sentences.
ontonotes5.0 has 17 classes with 159,615 labeledsentences in mixed domains - news, bn, bc, weband tele.
cluener2020 has 10 ﬁned grained en-tity types with 12,091 annotated sentences.
for allof the datasets, we adopt bio (beginning, inside,and outside) labeling, which introduces an extra oclass for non-entity words..4.2 data split.
we divided the classes of each benchmark intotwo parts: base classes and few-shot classes.
the few-shot classes for conll / re3d / ontonote/ cluener are person / person, nationality,weapon / person, language, money, percent, norp/ game, government, name, scene.
the rest arethe base classes.
the division is based on the av-erage word similarity among classes (mean sim-ilarity is reported in appendix a).
at each time,the class with the largest semantic difference fromother classes is selected and added to the few-shotclasses until the number of few-shot classes reaches1/3 of the base classes.
in this way, we can preventthe few-shot classes and base classes from beingtoo similar, leading to information leakage.
wedo not follow previous methods (hou et al., 2020)to adopt different datasets as base and few-shotclasses, because there are overlapped classes insuch data split, such as person, which will reducethe difﬁculty of few-shot setting.
for base classes,all examples are used to train the base classiﬁer.
for few-shot classes, only k examples are used fortraining, and the rest are used for testing.
alterna-tively, we adopt the n-way k-shot setting for few-shot classes, where n is the number of few-shotclasses and k is the number of examples sampledfrom each few-shot class.
k is set to 1 and 5 respec-tively in our experiment.
noted that we can notguarantee the number of the examples is exactlyequal to k when sampling, because there will bemultiple class labels in one sentence.
following(fritzler et al., 2019), we ensure there are at leastk labels for each few-shot class..4.3 evaluation metrics.
few-shot classes.
for fair comparison with base-lines, as long as the found undeﬁned class is clas-siﬁed as o class, it can be considered correct.
wereport the average on ten runs as the ﬁnal results..4.4 hyperparameters.
for feature extraction, we adopt bert-base as ourbackbone 1, which has 12-head attention layers and768 hidden embedding dimension.
for learningrate, we adopt greedy search in the range of 1e-6to 2e-4.
we set learning rage to 2e-5 when pre-training on base classes and 5e-6 when ﬁne-tuningon few-shot classes.
the threshold γ is set to 0.68to ensure that the found undeﬁned classes are sufﬁ-ciently relevant to the predeﬁned classes.
the batchsize is 128 and the maximum sequence length 128.we set the scale factor in eq.
7 to 10 at the be-ginning.
our code is implemented by tensorﬂowand all models can be ﬁt into a single v100 gpuwith 32g memory.
the training procedure lasts forabout a few hours.
the best result appears aroundthe 100 epochs of the training process..4.5 baselines.
we divide the baselines into two categories: 1)supervised-only methods.
bert uses pre-trainedbert model to sequentially label words in sen-tence (devlin et al., 2018).
prototypical network(pn) learns a metric space for each class (snellet al., 2017).
both of the methods are only trainedon the few-shot classes.
2) few-shot methods.
l-tapnet+cdt (ltc) uses semantic associationsbetween base and few-shot classes to improve theprototype quality, which is only trained on baseclasses (hou et al., 2020).
we use the originalpublished code 2. warm prototypical network(wpn) (fritzler et al., 2019) is the transfer learningversion of pn, which is ﬁrst pre-trained on baseclasses and then ﬁne-tuned on few-shot classes.
maml ﬁrst learns fast-adapted parameters onbase classes and then ﬁne-tune the parameters onfew-shot classes (finn et al., 2017)..4.6 overall performance.
table 1 and 2 present the overall performance ofthe proposed approach on four ner benchmarks -conll2003, re3d, ontonote5.0 and cluener2020.
muco (ours) consistently outperforms state-of-the-art models, showing the effectiveness of ex-.
following (hou et al., 2020), we measure the pre-cision, recall, and macro-averaged f1 scores on all.
1https://github.com/google-research/bert2https://github.com/atmahou/fewshottagging.
6241table 1: overall performance on conll2003, re3d, ontonote5.0 and cluener2020 dataset in 1-shot setting(%)..methods.
bertpnltcwpnmamlmuco (ours).
conll2003r50.4650.7270.3686.5885.6983.98.f54.2852.1073.3181.4079.8082.69.p61.0055.7878.1977.8775.9581.70.
1-shot named entity recognitionre3dr22.5623.0919.3338.9034.7740.37.ontonote5.0r32.0930.5643.2554.3955.8455.82.p54.9255.7760.8358.2956.6360.43.f26.1326.7523.3440.2737.8341.57.f39.9238.6750.0456.2056.1557.89.cluener2020r18.6819.78-70.9669.5373.60.f21.7722.81-73.5073.0875.80.p26.9527.64-76.6377.7178.29.table 2: overall performance on conll2003, re3d, ontonote5.0 and cluener2020 dataset in 5-shot setting(%)..methods.
bertpnltcwpnmamlmuco (ours).
conll2003r68.2871.4682.4195.0096.0495.35.f70.5472.7083.9794.6895.3795.78.p73.9474.3685.8994.3994.7696.23.
5-shots named entity recognition.
re3dr25.0525.3732.0038.6339.4941.70.f28.0927.7735.8339.6840.5242.37.ontonote5.0r56.6458.6146.0867.6669.3169.00.f59.0460.1252.3566.3467.5771.06.p61.8161.8462.0665.2865.9973.27.cluener2020r68.1468.56-79.7182.8382.67.p71.571.60-80.5277.0678.88.f69.6169.92-80.0479.7880.64.p31.4932.0729.8443.1243.9543.23.p32.4331.2640.9840.9341.7843.04.ploiting the rich semantics in o class and the supe-riority of the proposed muco model..few-shot methods.
compared with supervised-only methods (bert(transferbert,and pn),wpn, maml, l-tapnet+cdt and muco(ours))achieve better performance.
by ﬁrst training onbase classes, these methods will learn a prior,which prevents from overﬁtting densely labeledwords.
among few-shot methods, our modelachieves the best performance.
previous meth-ods regard o class as a single class.
on the con-trary, we induce different undeﬁned classes fromo class, and add more task-related classes forjoint training, which directly handles the dilemmaof scarcity of data in few-shot learning and pro-vides stand-by semantics to identify and disam-biguate named entity, thereby improving the perfor-mance of few-shot ner.
no matter english corpus(the ﬁrst three) or chinese corpus (the last one),our methods consistently improves the f score,showing the language-independent superiority ofour method.
task-agnostic superiority also showsin section 4.10. our undeﬁned classes detectionmethod is completely data-driven.
the found unde-ﬁned classes will be automatically adjusted to beuseful and task-related based on current languageor task predeﬁned classes..to further evaluate our core module undeﬁnedclasses detection in section 3.2, we introduce aword-similarity (ws) baseline.
ws detects un-deﬁned classes by performing kmeans (kanungoet al., 2002) in o words based on word similarity..to be fair, ws, like our method, uses soft-labelenhancement (section 3.2.2).
we report the ﬁnalfew-shot ner performance on ontonote for com-parison..figure 3: few-shot ner performance under differentundeﬁned classes detection algorithm.
as shown in figure 3, our method achieves bet-ter performance, which shows the superior of ourundeﬁned classes detection module.
word similar-ity baseline only uses semantics of words and lacksweak supervision from predeﬁned classes, so thatnoisy classes (such as punctuation) cannot be dis-tinguished from task-related ones, which inevitablyreduces the quality of undeﬁned classes..4.7 quality of found undeﬁned classes.
in the section, we evaluate the quality of the foundundeﬁned classes from quantitative and qualitativeperspective.
all the following experiments are con-ducted on ontonote5.0..for quantitative analysis, we invite three com-puter engineers to manually label 100 sentencesfor human evaluation.
the metrics are intra-classcorrelation (ic) and inter-class distinction (id).
the ic statistics how many labels actually belong.
62425560657075precision(%)recall(%)f score(%)71.066973.2761.0357.9467.98word similarity baselineoursto the declared class.
the id counts how manylabels belong to only one of the undeﬁned classes,not to multiple classes.
we obtain golden labels byapplying the majority vote rule.
table 3 reports theaverage results on undeﬁned classes..table 3: human evaluation.
metricsaverage score(%).
ic49.15.id50.85.considering the zero-shot setting, the accuracyof 49.15% and 50.85% is high enough, which in-dicates that the found undeﬁned classes basicallyhave semantic consistency within the classes andsemantic difference between classes..for qualitative analysis, we illustrate a case studyin table 4. the words in o1, o2 and o3 are mainlythe general entity versions of person, location andnumerous respectively.
according to the grammat-ical rules, general entities and named entities canbe substituted for each other, lincoln can also becalled president, so identifying general entities canprovide additional location knowledge and enhancenamed entity identiﬁcation.
the words in o4 ando5 are mainly action, which may imply relationsbetween different named entities and provide im-portant evidence for named entity disambiguation(tong et al., 2020).
the errors mainly come fromthree aspects: 1) the surrounding words are incor-rectly included, such as from in businessmen fromin o1; 2) some strange words reduce intra-classconsistency, such as was at the tail in o3; 3) thereis semantic overlap between classes, such as o4and o5.
future work will explore how to improvethe quality of the undeﬁned classes..4.8 different number of undeﬁned classes.
since our model needs to manually set the num-ber of undeﬁned classes, we observe the perfor-mance of the model under different number set-tings.
we set the number of undeﬁned classes to1/2/5/10/25/50 by adjusting the threshold γ..figure 4: different numbers of undeﬁned classes.
figure 4 illustrates the f score of muco (ours)on various numbers of undeﬁned classes.
it will.
impair the performance when the number is toolarge or too small.
when the number is toolarge, the found classes will have overlapping prob-lems, resulting in severe performance degradation (-11.51%).
when the number is too small, the modelis unable to ﬁnd enough task-related classes, lim-iting the ability to capture the ﬁne-grained seman-tics in o class.
empirical experiments found thatwhen the number of undeﬁned classes is approxi-mately equal to the number of few-shot classes, ourmethod achieves the best performance (the num-ber is 5 in figure 4).
we argue that the numberof predeﬁned classes is proportional to the amountof information hidden in weak supervision.
there-fore, with more predeﬁned classes, we can also ﬁndmore high-quality undeﬁned classes..4.9 cross-domain ability.
in this section, we answer whether our modelcould achieve superior performance facing the dis-crepancy of different domains.
to simulate a do-main adaption scenario, we choose the benchmarkconll2003 (sang and de meulder, 2003) as thesource domain and anem (ohta et al., 2012) as thetarget domain.
the entity types in anem, such aspathological-formation, are all medical academicterms and can ensure the discrepancy to commonclasses in conll2003..table 5: domain adaption ability..methodpnwpnmuco (ours).
p7.3433.0634.17.r17.1431.9532.84.f7.4326.9028.31.as illustrated in table 5, our method achieves thebest adaptation performance on the target domain.
all the predeﬁned classes, both in source domainsand target domains, are used when detection unde-ﬁned classes.
the annotations of undeﬁned classescan be shared between pre-training and ﬁne-tuning,which will improve the transfer performance of ourmodel..4.10 task-agnostic ability.
in this section, we answer whether our assump-tion of o class is task-agnostic and effective forfew-shot token-level classiﬁcation tasks other thanner.
we conduct experiments on two tasks ofwidespread concern: slot tagging (hou et al.,2020) and event argument extraction (ahn, 2006).
slot tagging aims to discover user intent from task-.
6243f score(%)556065707512510255059.365.7270.0671.0668.3467.57table 4: case study of the found undeﬁned classes.
annotated wordsgentleman; journalist; president; ambassador; i; he; they; businessmen from; and those huwei people who;the harbour; this land, which; over the river; with the great outdoors; outsides; to nature; the skyline;some; a major; the small number; supplied; not only one of the; empty; large; increase of; was at the tail;believe; comfort; attacked or threatened; arrest; geared; talks; not dealing; discussions; agreement;stop; have; do; discussion; take; seek; sat down; negotiated; think; failed; replace;.
o1o2o3o4o5.
oriented dialogue system.
we adopt snips dataset(coucke et al., 2018) for slot tagging, and thesplit of train/test is we,mu,pl,bo,se/re,cr.
eventargument extraction aims to extract the main el-ements of event from sentences.
we adopt theace2005 dataset 3 with 33 classes and 6 domains.
the train/test is bc,bn,cts,nw/un,wl..table 6: task-agnostic effectiveness of silent major-ity(ours).
methods.
pnwpnsilent majority (ours).
methods.
pnwpnsilent majority (ours).
p61.2973.6075.92.p51.0278.3979.61.str58.2473.2973.71eaer53.1470.5972.02.f59.0270.5672.04.f51.8573.1375.20.as illustrated in table 6, the proposed modelachieves superior performance on both tasks, whichdemonstrates the generalization ability of ourmethod.
no matter what task the predeﬁned classbelongs to, our method is always able to mine thetask-related classes from the o class to help elim-inate the ambiguity of the predeﬁned class.
thereason is that our detection method is entirely data-driven, and does not rely on manually writing un-deﬁned class descriptions.
the found category willautomatically change according to the task typeof the entered predeﬁned classes.
therefore, themigration cost between tasks of our method is mea-ger..5 conclusion.
in this paper, we propose mining undeﬁnedclasses from other-class (muco) to utilize therich semantics in o class to improve few-shot ner.
speciﬁcally, we ﬁrst leverage weakly supervisedsignals from predeﬁned classes to detect undeﬁnedclasses from o classes.
then, we perform joint clas-siﬁcation to exploit the stand-by semantic knowl-.
3http://projects.ldc.upenn.edu/ace/.
edge in undeﬁned classes to enhance the under-standing of few-shot classes.
experiments showthat our method outperforms ﬁve state-of-the-artbaselines on four benchmarks..acknowledgements.
this work is supported by the national keyresearch and development program of china(2018yfb1005100 and 2018yfb1005101) andnsfc key project (u1736204).
this work is sup-ported by national engineering laboratory forcyberlearning and intelligent technology, bei-jing key lab of networked multimedia and theinstitute for guo qiang, tsinghua university(2019gqb0003).
this research was conductedin collaboration with sensetime.
this work is par-tially supported by a*star through the industryalignment fund - industry collaboration projectsgrant, by ntu (ntu–ace2020-01) and ministryof education (rg96/20)..references.
david ahn.
2006. the stages of event extraction.
inproceedings of the workshop on annotating andreasoning about time and events, pages 1–8..yixin cao, zikun hu, tat-seng chua, zhiyuan liu, andheng ji.
2019. low-resource name tagging learnedwith weakly labeled data.
in emnlp..alice coucke, alaa saade, adrien ball, th´eodorebluche, alexandre caulier, david leroy, cl´ementdoumouro, thibault gisselbrecht, francesco calta-girone, thibaut lavril, et al.
2018. snips voice plat-form: an embedded spoken language understandingsystem for private-by-design voice interfaces.
arxivpreprint arxiv:1805.10190..shumin deng, ningyu zhang, jiaojian kang, yichizhang, wei zhang, and huajun chen.
2020. meta-learning with dynamic-memory-based prototypicalin proceed-network for few-shot event detection.
ings of the 13th international conference on websearch and data mining, pages 151–159..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training of deepbidirectional transformers for language understand-ing.
arxiv preprint arxiv:1810.04805..6244xiaocheng feng, xiachong feng, bing qin, zhangyinfeng, and ting liu.
2018. improving low resourcenamed entity recognition using cross-lingual knowl-edge transfer.
in ijcai, pages 4071–4077..chelsea finn, pieter abbeel, and sergey levine.
2017.model-agnostic meta-learning for fast adaptation ofdeep networks.
in international conference on ma-chine learning, pages 1126–1135.
pmlr..jason fries, sen wu, alex ratner, and christopher r´e.
2017. swellshark: a generative model for biomed-ical named entity recognition without labeled data.
arxiv preprint arxiv:1704.06360..alexander fritzler, varvara logacheva, and maksimkretov.
2019. few-shot classiﬁcation in named en-in proceedings of the 34thtity recognition task.
acm/sigapp symposium on applied computing,pages 993–1000..tianyu gao, xu han, zhiyuan liu, and maosong sun.
2019. hybrid attention-based prototypical networksin pro-for noisy few-shot relation classiﬁcation.
ceedings of the aaai conference on artiﬁcial intel-ligence, volume 33, pages 6407–6414..ruiying geng, binhua li, yongbin li, yuxiao ye,ping jian, and jian sun.
2019. few-shot text clas-siﬁcation with induction network.
arxiv preprintarxiv:1902.10482..souvick ghosh, promita maitra, and dipankar das.
2016. feature based approach to named entity recog-nition and linking for tweets..yutai hou, wanxiang che, yongkui lai, zhihan zhou,yijia liu, han liu, and ting liu.
2020.few-shot slot tagging with collapsed dependency trans-fer and label-enhanced task-adaptive projection net-work.
arxiv preprint arxiv:2006.05702..guillaume lample, miguel ballesteros, sandeep sub-ramanian, kazuya kawakami, and chris dyer.
2016.neural architectures for named entity recognition.
in proceedings of the 2016 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,pages 260–270, san diego, california.
associationfor computational linguistics..xiaoya li, xiaofei sun, yuxian meng,.
junjunliang, fei wu, and jiwei li.
2019. dice lossarxiv preprintfor data-imbalanced nlp tasks.
arxiv:1911.02855..yukun ma, erik cambria, and sa gao.
2016. labelembedding for zero-shot ﬁne-grained named entitytyping.
in proceedings of coling 2016, the 26thinternational conference on computational linguis-tics: technical papers, pages 171–180..tomoko ohta, sampo pyysalo, jun’ichi tsujii, andsophia ananiadou.
2012. open-domain anatomi-cal entity mention detection.
in proceedings of theworkshop on detecting structure in scholarly dis-course, pages 27–36..sameer pradhan, alessandro moschitti, nianwen xue,hwee tou ng, anders bj¨orkelund, olga uryupina,yuchen zhang, and zhi zhong.
2013. towards ro-in pro-bust linguistic analysis using ontonotes.
ceedings of the seventeenth conference on computa-tional natural language learning, pages 143–152..pushpankar kumar pushp and muktabh mayanktest anywhere:srivastava.
2017.zero-shot learning for text classiﬁcation.
corr,abs/1712.05972..train once,.
hang qi, matthew brown, and david g lowe.
2018.low-shot learning with imprinted weights.
in pro-ceedings of the ieee conference on computer visionand pattern recognition, pages 5822–5830..lifu huang, heng ji, kyunghyun cho, and clare rvoss.
2017. zero-shot transfer learning for event ex-traction.
arxiv preprint arxiv:1707.01066..afshin rahimi, yuan li, and trevor cohn.
2019. mas-sively multilingual transfer for ner.
arxiv preprintarxiv:1902.00193..tapas kanungo, david m mount, nathan s netanyahu,christine d piatko, ruth silverman, and angela ywu.
2002. an efﬁcient k-means clustering algo-rithm: analysis and implementation.
ieee transac-tions on pattern analysis and machine intelligence,24(7):881–892..jerrold j katz and jerry a fodor.
1963. the structureof a semantic theory.
language, 39(2):170–210..gregory koch, richard zemel, and ruslan salakhutdi-nov. 2015. siamese neural networks for one-shot im-age recognition.
in icml deep learning workshop,volume 2. lille..brenden m lake, ruslan salakhutdinov, and joshua btenenbaum.
2015. human-level concept learningthrough probabilistic program induction.
science,350(6266):1332–1338..erik f sang and fien de meulder.
2003..intro-duction to the conll-2003 shared task: language-arxivindependent named entity recognition.
preprint cs/0306050..defence science and technology laborator.
2017. re-lationship and entity extraction evaluation dataset..jake snell, kevin swersky, and richard zemel.
2017.prototypical networks for few-shot learning.
in ad-vances in neural information processing systems,pages 4077–4087..shengli sun, qingfeng sun, kevin zhou, and tengchaolv.
2019. hierarchical attention prototypical net-in proceed-works for few-shot text classiﬁcation.
ings of the 2019 conference on empirical methodsin natural language processing and the 9th inter-national joint conference on natural language pro-cessing (emnlp-ijcnlp), pages 476–485..6245meihan tong, bin xu, shuai wang, lei hou, andimproving low-resource chinesejuaizi li.
2020.event detection with multi-task learning.
in interna-tional conference on knowledge science, engineer-ing and management, pages 421–433.
springer..and base classes from being too similar, causinginformation leakage.
the embedding of words areextracted from bert, and the mean similarity isreported in table 7..yao-hung hubert tsai and ruslan salakhutdinov.
2017. improving one-shot learning through fusingside information.
arxiv preprint arxiv:1710.08347..feng wang, xiang xiang, jian cheng, and alan lod-don yuille.
2017. normface: l2 hypersphere em-bedding for face veriﬁcation.
in proceedings of the25th acm international conference on multimedia,pages 1041–1049..zhenghui wang, yanru qu, liheng chen, jian shen,weinan zhang, shaodian zhang, yimei gao, gengu, ken chen, and yong yu.
2018.label-aware double transfer learning for cross-specialtymedical named entity recognition.
arxiv preprintarxiv:1804.09021..qiang wei, yukun chen, mandana salimi, joshua cdenny, qiaozhu mei, thomas a lasko, qingxiachen, stephen wu, amy franklin, trevor cohen,et al.
2019. cost-aware active learning for named en-tity recognition in clinical text.
journal of the amer-ican medical informatics association, 26(11):1314–1322..liang xu, qianqian dong, yixuan liao, cong yu,yin tian, weitang liu, lu li, caiquan liu, xuan-wei zhang, et al.
2020. cluener2020: fine-grainednamed entity recognition dataset and benchmark forchinese.
arxiv, pages arxiv–2001..vikas yadav and steven bethard.
2019. a survey on re-cent advances in named entity recognition from deeplearning models.
arxiv preprint arxiv:1910.11470..suncong zheng, feng wang, hongyun bao, yuexinghao, peng zhou, and bo xu.
2017.joint extrac-tion of entities and relations based on a novel taggingscheme.
arxiv preprint arxiv:1706.05075..joey tianyi zhou, hao zhang, di jin, hongyuan zhu,meng fang, rick siow mong goh, and kennethkwok.
2019. dual adversarial neural transfer forlow-resource named entity recognition.
in proceed-ings of the 57th annual meeting of the associationfor computational linguistics, pages 3461–3471..a data split.
we divided the classes of each benchmark into twoparts: base classes and few-shot classes.
the divi-sion is based on the average word similarity amongclasses.
at each time, the class with the largestsemantic difference from other classes is selectedand added to the few-shot classes until the numberof few-shot classes reaches 1/3 of the base classes.
in this way, we can prevent the few-shot classes.
6246militaryplatform4.34organisation5.74.table 7: mean word similarity between predeﬁned classes.
per0.64.nationality3.3quantity4.37.misc1.36.person3.87money4.38.loc1.68.conll2003.
re3d.
org1.75.weapon4.05documentreference location5.03.temporal4.28.
5.2.ontonotes5.0.
money2.2.percent3.88.person0.31cardinal product quantity4.58time6.01date7.27.
5.165.41ordinal work of art6.246.23eventfac8.117.53.language norp4.14org5.74gpe6.7.
4.49law5.99loc7.18.cluener2020.
name7.28address7.61.government7.38movie7.62.game7.43company7.65.scene7.45organization7.72.position7.6book7.91.
6247