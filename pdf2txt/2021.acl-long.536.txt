improving factual consistency of abstractive summarization viaquestion answering.
feng nan1 cicero nogueira dos santos1 henghui zhu1.
patrick ng1.
kathleen mckeown1,2 ramesh nallapati1 dejiao zhang1zhiguo wang1 andrew o. arnold 1 bing xiang1amazon web services1, columbia university2{nanfen, cicnog, henghui, patricng, mckeownkrnallapa, dejiaoz, zhiguow, anarnld, bxiang}@amazon.com.
abstract.
that.
a commonly observed problem with the state-of-the art abstractive summarization models isthat the generated summaries can be factuallyinconsistent with the input documents.
thesummarization mayfactautomaticproduce plausible-sounding yetinaccuratesummaries is a major concern that limits itswide application.
in this paper we presentan approach to address factual consistency insummarization.
we ﬁrst propose an efﬁcientautomatic evaluation metric to measure factualconsistency; next, we propose a novel learningalgorithm that maximizes the proposed metricduring model training.
through extensiveexperiments, we conﬁrm that our method iseffective in improving factual consistencyand even overall quality of the summaries, asjudged by both automatic metrics and humanevaluation..1.introduction.
recent advances in neural text generation haveled to signiﬁcant improvement in the quality ofabstractive summarization (radford et al., 2019;gehrmann et al., 2019; lewis et al., 2019).
despitethis progress, there are still many limitations facingneural text summarization (kryscinski et al., 2019),the most serious of which is the tendency togenerate summaries that are not factually consistentwith the input document; a factually consistentsummary only contains statements that can beinferred from the source document.
recent studiesshow that about 30% of the summaries generatedby neural network sequence-to-sequence (seq2seq)models suffer from fact fabrication (cao et al.,2018)..the standard training approach for seq2seqlearning has been maximizing the log likelihoodof the target given the input sequences (mle).
ithas empirically performed well as a surrogate loss.
input:.
mle:.
...“klitschko doesn’t have the legs, the power that he used to,”said lewis.
“he has a chink in his armour after getting beatby tyson fury.
anthony joshua is now taking that challenge,going after the man.” ....anthony joshua has a “chink in his armour” ahead of his worldheavyweight title bout with wladimir klitschko, says formerchampion lennox lewis..conseq: wladimir klitschko has a “chink in his armour” and is nomatch for british champion anthony joshua, says former worldheavyweight champion lennox lewis..table 1: example summaries from the bart-largeﬁnetuned models on test set.
standard mle traininggenerates a factually inconsistent summary whereasour proposed conseq is consistent..for evaluation metrics such as bleu and rouge.
this empirical success can be ascribed to the factthat both bleu and rouge are directly linkedto the n-gram overlap between the output and thetarget sequences, which can be efﬁciently learnedvia mle.
in contrast, metrics to capture factualconsistency are much more elusive as they musttake into account the relations among tokens in thecontext of an entire sequence.
the widely usedrouge score is inadequate to quantify factualconsistency (kryscinski et al., 2019).
in fact,the lack of an effective (automatic) metric forfactual consistency has been the major hurdlein improving abstractive summarization modeltraining beyond mle.
table 1 shows an example ofa factually inconsistent summary generated by ﬁne-tuning the bart-large model (lewis et al., 2019),which is a transformer based seq2seq model pre-trained on a large corpus with denoising objectives.
standard mle training produces summaries withfactual errors that, in addition to hallucinating facts,sometimes even contradict the input article..to make abstractive summarization modelsproduce more factually consistent summaries,we need two critical components: an automaticevaluation metric for factual consistency andan effective training algorithm that maximizes.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6881–6894august1–6,2021.©2021associationforcomputationallinguistics6881figure 2: qagen model:generates a question (q) followed by an answer (a)..for an input text (p), it.
candidate answers using an answer extraction(ae) model; secondly, a question generation (qg)model takes in the summary, concatenating witheach candidate answer to generate a correspondingquestion; thirdly, a question answering (qa) modelis used to answer each generated question in thecontext of the summary and the input document,separately; ﬁnally, the answers from the qa modelbased on the summary and the input document arecompared to calculate f1 score in terms of theirword level overlap as the qags score.
intuitively,for the same question, if the answer obtainedfrom the input document matches that from thesummary, it is an indication that the summaryis factually consistent with the input document.
we show the qags pipeline in the top part offigure 1. qags has the advantage of beinginterpretable and is shown to correlate well withhuman evaluation.
however, using qags directlyas a part of the training process presents severalchallenges.
first, qags requires three separatemodels for ae, qg and qa.
in addition to thesummarization model being trained, these modelsconsume a signiﬁcant amount of machine memory.
second, performing these three steps separatelytakes a signiﬁcant amount of time.
for goodcoverage in qags, multiple answers are extractedfor a given summary and multiple questions aregenerated for each answer.
this means the qamodel needs to perform inference on an explodingnumber of inputs even for one summary.
indeed,qags evaluation on a training set would take 584days on a single gpu.2.
2.2 quals (ours).
in order to enable the use of a qa driven metricto maximize factual correctness during the trainingof summarization models, we propose quals(question answering with language model scorefor summarization), which is illustrated in thebottom part of figure 1. quals is an efﬁcient.
figure 1: comparison between qags (top) andquals (bottom) protocols.
quals uses only oneqagen model instead of the ae, qg and qa modelsused in qags..factualness.
our main contributions lie in bothareas.
first, we propose an efﬁcient automaticevaluation metric for factual consistency that isa simpliﬁcation of the recently published qagsprotocol (wang et al., 2020).
evaluating qags iscomputationally expensive and ill-suited for beingpart of the model training process.
our proposedprotocol achieves a 55x speedup while correlatingclosely with qags1.
second, we propose a newcontrastive learning method that uses factualnessas a training objective.
we demonstrate throughexperiments that our method improves the factualconsistency of summarization models measured byboth automatic metrics such as qags as well ashuman evaluation..2 an efﬁcient metric for factual.
consistency.
to improve factual consistency ofin ordersummarization models, we must have a metric toquantify it.
in addition, the metric needs to becomputationally efﬁcient so that we can incorporateit as part of the model training process.
we ﬁrstdescribe the qags protocol and then present ourquals protocol..2.1 background on qags.
given a summary and an input document, qags(wang et al., 2020) scores the summary usinga 4-steps pipeline: ﬁrstly, it extracts the namedentities and noun phrases in the summary as.
1see sec.
a.2 in the appendix for details..2see sec.
a.2 in the appendix for details..6882metric that employs a single neural language model(qagen), as proposed in (shakeri et al., 2020),to generate both the questions and answers fromthe summary.
in particular, given a summary,qagen outputs a question-answer (q-a) pair jointly,separated by a special token <a> as shown infigure 2. let llsumm(q, a) be the average loglikelihood of generating the q-a pair from the givensummary:.
llsumm(q, a) =.
log pqagen(qi|summ, q<i).
1nq + na.
.
.
nq(cid:88).
i=1.
log pqagen(ai|summ, q, a<i).
,.
(cid:33).
+.
na(cid:88).
i=1.
where nq and na are the number of tokens forthe question and answer, respectively.
note thatwe consider the log likelihood scores over boththe question and answer tokens to account forfactual consistency of both.
to obtain goodcoverage and diverse q-a pairs, we use diversebeam search (vijayakumar et al., 2016) to generate60 q-a pairs for a given summary with 60 diversebeam groups and a diverse beam strength of0.5. we then ﬁlter out low-quality q-a pairs bykeeping only those with answers found in the inputsummary.
when multiple q-a pairs share the sameanswer, we only select the pair with the highestllsumm(q, a).
then given the input document,we simply evaluate the average log likelihood ofthe qagen model producing the same q-a pairs,denoted as lldoc(q, a).
formally, given a summaryand input document, quals score is computed asfollows:.
qu als(doc, summ) =.
(lldoc(qi, ai).
1m.m(cid:88).
i=1.
−llsumm(qi, ai)) ,.
where m is the number of q-a pairs selected on thesummary.
there are two justiﬁcations for takingthe difference between the log likelihood scores.
1. lldoc(q, a) alone only indicates the likelihoodof the q-a pair given the document; subtractingllsumm(q, a) baselines it with the likelihood ofgenerating the q-a pair given the summary.
e.g.
alow lldoc(q, a) does not necessarily imply factualinconsistency - it can be caused by the fact thatthe q-a pair itself is generated with low likelihoodfrom the summary in the ﬁrst place.
2. documentsmay vary in style, vocabulary and topic, whichlead to variations in log likelihood scores unrelated.
to factual consistency; lldoc(q, a) − llsumm(q, a)can help normalize these domain-related shiftssince both the document and summary share thesame basic style, vocabulary and topic..3.improving factual consistencythrough contrastive learning.
although quals can be computed moreefﬁciently, using it in the training process isnot straightforward because one would need tobackpropagate through generated sumaries and q-a pairs.
we present our conseq (contrastiveseq2seq learning) algorithm that can effectivelymaximize such metrics in training..to ﬁx notation, x = x1, .
.
.
, xm denotes asequence of input tokens; y = y1, .
.
.
, yn denotesa sequence of target output tokens; ˆy = ˆy1, .
.
.
, ˆyˆndenotes a sequence of generated tokens from aseq2seq model via sampling, i.e.
ˆy ∼ pθ(·|x),where θ is the parameter of the model.
let r(ˆy, x)be the evaluation (in our case the quals) metricthat we aim to maximize..3.1 conseq.
first, we train an initial seq2seq model withparameters θ0 using the original labeled training set{x(i), y(i)} via mle.
second, we collect groundtruth labeled training target sequences y(i) as wellas the sampled sequence ˆy(i) to form a set ofcandidate sequences s = {y(i), ˆy(i)}.
third,we construct s + and s − from s based on theevaluation scores r and minimize the followingloss function from the initial parameters θ0:.
lcontrast = −ex,s∈s+ log pθ(s|x)(cid:125).
(cid:124).
(cid:123)(cid:122)contrast.
l+.
(1).
−ex,s∈s− log (1 − pθ(s|x))(cid:125)(cid:123)(cid:122)(cid:124)contrast.
l−.
..intuitively, s + consists of highly rewardedsequences (factually consistent summaries) andminimizing l+contrast forces the model to generatehigh score sequences; likewise, s − consists ofpoorly rewarded sequences (factually inconsistentsummaries) and minimizing l−contrast forces themodel to move away from low score sequences.
we present the full method in algorithm 1..with.
reinforce: thecomparisontypical approach to directly optimize a non-differentiable evaluation score during training.
6883algorithm 1: conseq.
input: initial seq2seq (summarization).
model weights θ0 via mle, inputand target sequences {x(i), y(i)},evaluation metric r..initialize k = 0;while not converged do.
sample candidate sequences {ˆy(i)} forinput sequences {x(i)} and θk;construct s + and s − as described insec.
3;.
minimize the contrastive loss in eq.
1 toobtain θk+1;k = k + 1;.
end.
is the reinforce algorithm (williams, 1992).
reinforce samples a sequence ˆy at eachiteration and updates the model with the gradient.
(r(ˆy, x) − r(b, x)) (cid:53)θ log pθ(ˆy|x),.
(2).
where b is a baseline sequence, conditionallyindependent of ˆy given θ, x. to see the connectionwith conseq, suppose the reward r is eitherif r(ˆy, x) = 1 and r(b, x) = 0, the0 or 1.sampled sequence ˆy is strongly rewarded comparedto baseline and eq.
2 reduces to (cid:53)θ log pθ(ˆy|x).
on the other hand, if r(ˆy, x) = 0 and r(b, x) = 1,the sampled sequence is strongly discouraged andeq.
2 reduces to − (cid:53)θ log pθ(ˆy|x), which pushesthe model away from generating ˆy.
this pull-and-push effect is analogous to the l+contrast andl−contrast terms in the loss eq.
1 in conseq.
note that the gradient updates of reinforceare entirely based on the sampled sequences.
incontrast, conseq takes advantage of the groundtruth targets in addition to the sampled ones, whichhelp avoid the instability of reinforce.
indeed,we implemented the reinforce algorithm withthe bart-large model ﬁne-tuned under mleobjective as initialization; we found that after afew hundred updates the summaries sampled fromthe model become unintelligible and our rewardfunction fails to compute the scores (no meaningfulq-a pairs can be generated based on the summaries)..3.2 conseq + quals for imposing factual.
consistency.
we use quals to select high quality positive andnegative examples for conseq with the goal of.
training seq2seq summarization models that aremore factual.
in order to create s + and s − we ﬁrstevaluate quals for all the ground truth summariesof the training set and select p% of those with thehighest quals scores to form ˆs +.3 to generatethe negative samples, we use the topk sampling(k = 50) during decoding to generate 6 summariesfor each input document in the training set; wethen select the one with the lowest quals scoreout of the 6 summaries for each input document;next, we rank the selected summaries and choosep% of those with the lowest quals scores toform ˆs −.
note that the summaries in ˆs + andˆs − may correspond to different input documents.
the last step is to take the intersection of theexamples between ˆs + and ˆs − to form s + and s −,respectively.
for example, we select a summarys from ˆs + to be included in s + if and only ifthere exists a summary s(cid:48) in ˆs − such that s and s(cid:48)correspond to the same input document.
as a resultof the above process, the contrastive loss in eq.
1 can thus push the model from the inconsistentsummary towards the consistent one for the sameinput document.
next, we describe two variants ofthe conseq algorithm..weighted loss: we can weight the losses in eq.
1 using quals scores and minimize the followingloss, assuming normalization of 0 ≤ r ≤ 1:.
lcontrast = −ex,s∈s+r(s, x) log pθ(s|x)− ex,s∈s− (1 − r(s, x)) log (1 − pθ(s|x)) ,.
where r(s, x) is the quals score for summary sand input document x..online learning: we refer to algorithm 1 asthe ofﬂine training setting in the sense that ineach iteration, s + and s − are constructed bypooling together all available input documents andtheir candidate summaries to train the model.
itis also possible to perform training in an onlinefashion.
speciﬁcally, we can take in a batchof input sequences in each iteration, constructs + and s − based only on the examples in thebatch, and take a gradient step with respect toeq.
1. compared to the ofﬂine setting, the modelparameters are updated much more frequently and.
3we found it necessary to select the top p% of the groundtruth summaries to form ˆs + because not all ground truthsummaries are factually consistent to the input documents,due to the imperfect data collection process.
this is especiallytrue for the xsum dataset as we discuss in the next section..6884the candidate sequences are always generated fromthe latest model parameters.
on the other hand,the construction of s + and s − are restricted to theexamples within the batch, resulting in potentiallyless representative samples compared to the ofﬂinesetting..4 experiments.
4.1 experimental setup.
datasets: we perform oursummarizationexperiments on two widely used news datasets:xsum (narayan et al., 2018) and cnn/dailymail(nallapati et al., 2016).
the xsum dataset consistsof short, one-sentence summaries of the bbc newsarticles.
the dataset is constructed by taking theﬁrst sentence of an article as the summary andthe rest of the article as input document.
as aresult, the summaries are highly abstractive.
atthe same time, there are many examples wherea summary contains information (e.g.
the ﬁrstname of a person) that is not mentioned in theinput document.
this introduces an undesirablebias in the training data to encourage the modelto hallucinate.
the cnndm dataset containsmulti-sentence (4 sentences on average) summariesof news articles from the cnn and dailymail.
the summaries are curated by human annotatorsin terms of highlights of the article.
comparedto xsum, the summaries in cnndm are muchmore extractive - each summary sentence usuallycorresponds to an existing sentence in the inputdocument..evaluation metrics: we use the rouge (lin,2004) to measure general summarizaiton quality.
forfactual consistency, we use the qagsprotocol (see appendix for more details) as wellas the factcc model (kry´sci´nski et al., 2019)downloaded directly from the ofﬁcial website.4in contrast to qags, factcc is a bert-basedclassiﬁcation model that makes a binary predictionif the given claim sentence is factually consistentor not with the given input document..implementation details: we use the fairseq(ott et al., 2019) implementation of bart-large(lewis et al., 2019) for the summarization model asit is shown to achieve the state-of-the-art rougescores for this task.
we ﬁne-tune the bart-largemodel with the standard learning rate of 3 × 10−5.
4https://github.com/salesforce/factcc.
figure 3: correlation between quals and qags onxsum (left) and cnndm (right).
the average qagstend to increase with the increase in quals..on xsum and cnndm respectively to establishthe mle baselines.
we then initialize conseqwith the mle baseline models.
in conseq weuse a learning rate of 3 × 10−6.
for evaluation,we generate summaries using beam search withbeam sizes of 4 and 6 for cnndm and xsum,respectively.
the generated summaries are limitedto 55-140 and 10-60 tokens in lengths for cnndmand xsum, respectively.
our qagen model inquals is also a bart-large model ﬁne-tuned onthe squad (rajpurkar et al., 2016) and newsqa(trischler et al., 2017) datasets.
to construct thes + and s −, we found that selecting the p = 30%and 50% leads to the best result on the validationset of xsum and cnndm, respectively, amongthe choices of p = 25, 30, 50, 75, 90..4.2 quals approximates qags.
we ﬁrst verify that our proposed quals metriccorrelates well with qags.
we evaluate bothquals and qags on the same set of summariesgenerated by the mle baseline model on thetest set of documents in xsum and cnndm,respectively.
the examples are grouped into binsbased on the percentiles of the quals scores.
we then plot the average qags score of theexamples within each bin.
as shown in figure3 (a more ﬁne-grained plot is shown in figure 4 ofthe appendix), quals correlates very well withqags in both datasets.
since our method onlyrelies on ranking quals scores in contrastivelearning, monotonicity of quals with respect toqags is sufﬁcient..4.3 results.
we compare our proposed method quals-abstractiveconseq to thesummarization model (bart-large mle).
in anablation study, we check the effect of changing the.
state-of-the-art.
6885quals metric as well as the effect of changing theconseq algorithm.
we summarize the results intable 2 and table 3. we observe that our proposedmethod quals-conseq (q-c) achieves morethan 4 points improvement in qags over the mlebaseline in xsum and about 2 points improvementin cnndm, where we also achieve a slightlybetter rouge over mle.
improving rouge isnot the goal of our paper; what we show is thatwe can signiﬁcantly improve factual consistencyof summaries without degrading rouge, as iscommon practice (kedzie and mckeown, 2019).
next, we describe the various ablation settings..1) in r-c (rouge-conseq), we simply usethe sum of rouge-1,2,l scores to evaluate thegenerated summaries against the ground truthsummaries as the metric in constructing s + ands −.
in both table 2 and 3 it results in poorer qagsthan the mle baseline.
this conﬁrms the necessityof having an effective metric for factual consistency.
note that r-c even results in poorer rougescores.
we believe this is caused by the fact thatrouge is already highly optimized by the mlemodel and it is used as initialization for r-c; the“hard” examples where the mle model couldn’tproduce good rouge scores may be inherentlyproblematic (e.g.
hallucination in the ground truthsummary); focusing on these examples by r-ccan therefore make the model weaker on otherexamples..2) in q-f1-c (quals-f1-conseq), we makea modiﬁcation to quals.
instead of measuring thefactual consistency in terms of the log likelihoodscores, we measure the f1 between generatedanswers from the summary and the input documentin the qagen model.
in particular, given asummary as input, the qagen model generatesa q-a pair q, a. we then use the correspondingdocument as input to the qagen model and forcethe decoder to generate the question tokens q andallow the qagen to generate the answer tokens a(cid:48).
we then compute the f1 overlap score between aand a(cid:48).
this would be closer to the qags settingwhere explicit answers are generated and compared.
we observe that in table 3, q-f1-c achieves aslightly higher qags than q-c. but overall q-f1-c performs worse than q-c. we believe this is dueto the fact the log likelihood scores are softer thanf1 and can potentially account for answers that aresemantically similar..quals qags factcc rouge 1 rouge 2 rouge l.mle.
-1.0393.
29.77.r-c.-1.0907.
28.47.q-f1-c -0.9866.
32.76.q-c-w -0.9856.
31.39.q-c-o -0.9747.
32.26.q-p.q-c.-0.9739.
31.92.
-0.9061.
34.36.
23.64.
23.76.
22.75.
21.68.
23.68.
22.68.
22.42.mle.
0.0169.
82.84.r-c.-0.0701.
79.28.q-f1-c 0.0779.
84.97.q-c-w 0.0720.
83.54.q-c-o 0.0292.
83.08.q-p.q-c.0.0437.
83.84.
0.0857.
84.75.
68.33.
63.50.
70.54.
70.03.
68.16.
69.40.
72.83.
45.18.
44.59.
44.54.
44.42.
45.22.
45.02.
44.67.
44.24.
41.17.
44.23.
44.04.
44.70.
44.62.
44.40.
22.19.
21.88.
21.63.
21.17.
22.19.
22.00.
21.66.
21.35.
18.41.
21.24.
20.88.
21.58.
21.65.
21.37.
36.97.
36.58.
36.37.
35.94.
37.00.
36.83.
36.47.
41.18.
37.94.
40.96.
40.74.
41.53.
41.47.
41.17.table 2: test set results on xsum.
quals-conseq(q-c) achieves over 4 points higher qags than thebart-large mle baseline..quals qags factcc rouge 1 rouge 2 rouge l.table 3: test set results on cnndm.
quals-conseq(q-c) achieves about 2 points higher qags than thebart-large mle baseline..3) in q-c-w (quals-conseq-weighted), weuse the weighted version of conseq as describedin sec.
3. since the quals score is a differencebetween log likelihood scores, it can have negativevalues.
we evaluate the quals on the trainingexamples to obtain an interval of its values andlinearly normalize the quals as weights in the lossfunction.
we observe that it improves the factualconsistency over the mle baseline but not as muchas q-c..4) in q-c-o (quals-conseq-online), we usethe online version of conseq as described in sec.
3. we sample about 6 examples in a mini-batchand select 2 of them for s + and s − per gpu witha total of 40 gpus.
we observe that it tends toachieve higher rouge scores but lower factualconsistency scores compared to q-c..contrast in eq..5) in q-p (quals-positive), we only usethe positive summaries (s +) and the positiveloss l+1 for training.
weobserve that it achieves lower factual consistencyscores compared to q-c and this shows that thenegative loss in conseq is useful to boost factualconsistency..factcc results: as3for cnndm, q-c achieves over 4 pointsimprovements in factcc score over the mle.
in table.
shown.
6886baseline.
however, in table 2 for xsum, q-c hasabout 1 point lower factcc score than the mlebaseline.
we investigated this issue and found thatthe ground truth summaries of the xsum test sethave a factcc score of just 21.0, which meansthat only 21% of the ground truth summaries inxsum are judged as factual according to factcc.
this suggests that the factcc model is not wellsuited for making predictions on highly abstractivesummaries.
this is not surprising as the authors offactcc mentioned in sec.
3.1 (kry´sci´nski et al.,2019) that factcc is built on the premise that “..thelevel of abstraction of generated summaries is lowand models mostly paraphrase single sentencesand short spans from the source”.
unfortunatelyfor xsum, this premise does not hold..comparison with other methods: there are2 other methods in the literature (cao et al.,2018; zhu et al., 2020) for improving factualconsistency of summarization models.
both rely oninformation extraction (openie) to extract relationsand incorporate the relation representations intoseq2seq models.
the authors in (zhu et al., 2020)proposed a fact-aware summarizer (fasum)and a fact corrector model.
in table 4 oftheir paper,the fasum achieves signiﬁcantlylower rouge scores (30.28/10.03/23.76 and40.53/17.84/37.4 for rouge-1/2/l on xsumand cnndm respectively).
this indicates asigniﬁcant gap in the summary quality.
eventheir best result, which is using fact correctoron unilm (dong et al., 2019), achieves lowerrouge scores than bart-large mle.
althoughthe authors in (zhu et al., 2020) used factcc asan evaluation metric, they did not use the ofﬁcialmethod to train factcc; they used the ground truthsummaries rather than sampled sentences from theinput documents as positive examples.
as a result,we are not able to compare the factcc numbersreported in (zhu et al., 2020).
nevertheless, wecan observe that there is little or no improvementsfor fact corrector on unilm according to factcc.
we believe that this is because the recent largetransformer-based, pre-trained seq2seq modelssuch as unilm and bart have signiﬁcantlyimproved the summarization quality and it is muchmore challenging to improve even the factualconsistency of these state-of-the-art models.
incomparison, our results reported in table 2 andtable 3 represent signiﬁcant improvements.
theauthors in (cao et al., 2018) only experimented on.
metrics.
factual.
informative.
grammatical.
better worse.
equal.
better worse.
equal.
better worse.
equal.
xsumcnndm.
1818.
97.
7375.
2242.
922.
6936.
45.
26.
9489.table 4: human evaluation results on summariesgenerated by quals-conseq in comparison to thebart-large mle baseline for 100 randomly selectedexamples from the test sets of xsum and cnndm..the gigaword corpus (rush et al., 2015) and did notrelease their code so we were unable to compare totheir method.
however, given the recent progressin transformer-based seq2seq models, it is likelythat our bart-large mle baseline outperformstheir rnn-based models.
again, we believe thatit is much easier to improve factual consistency ofa weak seq2seq model than that of a strong model(such as unilm or bart-large) as shown in (zhuet al., 2020)..use.
evaluation: we.
humanamazonsagemaker ground truth5 to conduct humanevaluation.
we sample 100 examples from thetest set of xsum and cnndm, respectively.
in each task, we present an input document,together with the generated summaries from thebart-large mle and quals-conseq models.
we ask the annotators to select which of the twosummaries they prefer along 3 dimensions: factualconsistency,informativeness and grammaticalcorrectness.
for each of these dimensions theycan also choose “equal” if they feel that bothsummaries are of similar quality.
our annotatorsconsist of 10 data associates who are native englishspeakers whose background includes training inlinguistic annotation.
each task is performed by 3different annotators and we take the majority vote.
we provide the detailed setup and instructions inthe appendix..the result of human evaluation is reported intable 4, showing the percentage of examples alongthese three dimensions.
in both datasets, weobserve that quals-conseq clearly improvesthe factual consistency of the generated summariescompared to the bart-large mle baseline.
wenotice that the improvement in informativeness iseven greater..fleiss’s kappa (fleiss et al., 1971) showsfairconsistency,informativeness and grammatical correctness.
agreement.
factual.
for.
5https://aws.amazon.com/sagemaker/.
groundtruth/.
6887input 1:.
mle:.
keates made over 150 league appearances for wrexham andcaptained the club to an fa trophy win in 2013.
... his ﬁrstgame in charge as permanent manager will be ...wrexham have appointed dean keates as their new manageron a two-year contract..conseq: wrexham have appointed former captain dean keates as their.
new manager..input 2:.
mle:.
passwords were found on public websites such as pastebin,... it found 705 emails andwhere hackers often dump data.
passwords originating from government agencies.
...more than 700,000 government emails and passwords havebeen leaked online ....conseq: more than 705 emails and passwords belonging to us.
government agencies have been found on the open web ....input 3:.
mle:.
the girlfriend of a british student killed in the alps planetragedy ... revealed she did not blame the co-pilot who crashedthe jet.
paul bramley, 28, died when andreas lubitz locked thegermanwings ﬂight’s captain out of the cockpit before ﬂyingthe plane into a mountainside...paul bramley, 28, died when andreas lubitz locked him out ofcockpit.
....conseq: paul bramley, 28, died when andreas lubitz locked captain.
out of cockpit.
....table 5: qualitative analysis.
example 1: “two-yearcontract” was never mentioned in the input document.
example 2: “700,000” was wrong in mle output;“more than” was inaccurate.
example 3: andreaslubitz locked the captain out of cockpit, not paulbramley..(0.136/0.270/0.043 for xsum andchoices0.237/0.202/0.206 for cnndm).
we note,however, that most disagreements occur whenone annotator rates two summaries as equal andanother rates one of the two as either better orworse.
to measure this, we computed fleiss’skappa again, counting equal and either betteror worse as equivalent (and better and worseisas not equivalent).
here, our agreementalmost perfect (0.837/0.839/0.975 for xsum and0.945/0.816/0.967 for cnndm).
we thus see thatannotators rarely directly contradict each otheron rating one summary above or below another,but often have a hard time deciding when the twosummaries are equal..4.4 qualitative analysis.
types of.
we analyzed the human evaluation results andimprovements/errorsfound severalproduced by quals-conseq.
our model is ableto rectify factual errors found in mle such as 1)entity hallucination and errors (example 1 and2 in table 5) and 2) relations and co-reference(see table 1 and example 3 in table 5).
quals-conseq also made mistakes in cases where itwas not sensitive to certain modiﬁer phrases (extra“more than” in example 2 in table 5).
moreexamples of generated summaries and q-a pairsare in the appendix..illustration of quals: we take an exampleto illustrate how quals captures the factualinconsistency of summaries.
the bart-large mlemodel generate a summary: the airasia ﬂight 4u9525 crash was the latest in a series of tragediesthat have hit the aviation industry.
the inputdocument described the airasia crash but did notmention the ﬂight number.
in fact, “4u 9525” is thegermanwings ﬂight that crashed in the french alps.
the model hallucinated the ﬂight number becauseit appeared in several training examples that coverthe germanwings crash.
given the above summary,our qagen model generates the following q-apairs: q1: what was the name of the ﬂight thatcrashed?
a1: 4u 9525. q2: which airlinesﬂight crashed?
a2: airasia.
in figure 5 in theappendix we show the negative log likelihood persubword token on these q-a pairs conditioned onthe summary (blue) and input document (orange).
the answer to the ﬁrst question is very likelyaccording to the summary while extremely unlikelyaccording to the input document, indicating factualinconsistency.
on the other hand, “airasia” isfactually consistent and the second q-a pair is likelyaccording to the input document.
the qualsscore for the two q-a pairs are −2.615 and −0.054,respectively..5 related work.
several authors have pointed out the problem offactual inconsistency in abstractive summarizationmodels (kryscinski et al., 2019; cao et al., 2018;durmus et al., 2020).
besides qags (wang et al.,2020) and factcc (kry´sci´nski et al., 2019), anotherpossible approach to quantify factual consistencyis to rely on open information extraction (openie)and dependency parsing tools to identify and matchthe relations in an input document and its summary(cao et al., 2018; zhu et al., 2020).
however, theunderlying openie tools are often not accurateenough to be used for this purpose..our proposed conseq algorithm is related tothe unlikelihood training (welleck et al., 2019; liet al., 2019) as both have positive and negative lossterms.
the key difference is that in unlikelihoodtraining, the negative loss serves as a regularizationterm, weighted by a hyperparameter α, in additionto the regular mle training.
in contrast, ourconseq is motivated from the reinforcealgorithm and treats the positive and negativeterms equally.
furthermore, while the unlikelihood.
6888training uses allthe ground truth sequencesequally in the regular mle (positive) loss term,we construct the positive and negative sets byincorporating the reward function (e.g.
quals)as discussed in sec.
3..in another related work, factual consistencymetrics at the entity level have been proposed(nan et al., 2021).
the authors also investigatedseveral techniques such as data cleaning, multi-task learning and entity-augmented decoding toimprove entity level factual consistency scores ofabstractive summarization models.
in contrast, thequals metric that we propose is more general,not limited to entities.
another recent worktackles the hallucination problem in abstractive textsummarization via post processing on the generatedsummary (chen et al., 2021).
speciﬁcally, entitiesof the generated summaries are swapped withother named entities of the same type found inthe original document to form a set of candidatesummaries.
the ﬁnal summary is determined bya ranking model trained to prefer the factuallyconsistent summaries..6 conclusion.
in this paper we proposed to improve the factualconsistency of abstractive summarization models.
we ﬁrst proposed an efﬁcient evaluation protocolcalled quals to measure factual consistency.
wethen proposed a contrastive learning algorithmfor seq2seq models called conseq to maximizequals during training.
we demonstrated thatour proposed method signiﬁcantly improves thefactual consistency of the current state-of-the-art summarization model measured by automaticmetrics as well as side-by-side human evaluation.
in addition to improving factual consistencyof summarization models, we believe that theconseq algorithm can have a wider impact ontraining seq2seq models in general to incorporatenon-differentiable evaluation metrics into modeltraining..references.
ziqiang cao, furu wei, wenjie li, and sujian li.
2018. faithful to the original: fact aware neuralabstractive summarization..sihao chen, fan zhang, kazoo sone, and danroth.
2021.improving faithfulness in abstractivesummarization with contrast candidate generationand selection..li dong, nan yang, wenhui wang, furu wei,xiaodong liu, yu wang, jianfeng gao, mingzhou, and hsiao-wuen hon.
2019.uniﬁedlanguage model pre-training for natural languagein advances inunderstanding and generation.
neural information processing systems 32: annualinformation processingconference on neuralsystems 2019, neurips 2019, 8-14 december 2019,vancouver, bc, canada, pages 13042–13054..esin durmus, he he, and mona diab.
2020. feqa:frameworkabstractivein association for computational.
evaluationin.
a questionforsummarization.
linguistics (acl)..faithfulness.
assessment.
answering.
j.l.
fleiss et al.
1971. measuring nominal scalepsychological.
agreement among many raters.
bulletin, 76(5):378–382..sebastian gehrmann, zachary ziegler, and alexanderrush.
2019. generating abstractive summariesin proceedingswith ﬁnetuned language models.
of the 12th international conference on naturallanguage generation, pages 516–522, tokyo,japan.
association for computational linguistics..chris kedzie and kathleen mckeown.
2019. a goodsample is hard to ﬁnd: noise injection sampling andself-training for neural language generation models.
in proceedings of the 12th international conferenceon natural language generation, pages 584–593, tokyo, japan.
association for computationallinguistics..wojciech kry´sci´nski, bryan mccann, caiming xiong,and richard socher.
2019. evaluating the factualconsistency of abstractive text summarization..wojciech kryscinski, nitish shirish keskar, bryanmccann, caiming xiong, and richard socher.
2019.neural text summarization: a critical evaluation.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on naturallanguage processing (emnlp-ijcnlp), pages540–551, hong kong, china.
association forcomputational linguistics..zhenzhong lan, mingda chen, sebastian goodman,kevin gimpel, piyush sharma, and radu soricut.
2019. albert: a lite bert for self-supervised learningin internationalofconference on learning representations..language representations..mike lewis, yinhan liu, naman goyal, marjanghazvininejad, abdelrahman mohamed, omerlevy, veselin stoyanov, and luke zettlemoyer.
bart: denoising sequence-to-sequence2019.generation,pre-trainingforarxiv preprinttranslation, and comprehension.
arxiv:1910.13461..language.
natural.
margaret li, stephen roller,.
ilia kulikov, seanwelleck, y-lan boureau, kyunghyun cho, and.
6889siamak shakeri, cicero nogueira dos santos, henghuizhu, patrick ng, feng nan, zhiguo wang, rameshnallapati, and bing xiang.
2020.end-to-endsynthetic data generation for domain adaptation ofquestion answering systems.
in proceedings of the2020 conference on empirical methods in naturallanguage processing (emnlp), pages 5445–5460,online.
association for computational linguistics..adam trischler, tong wang, xingdi yuan, justinharris, alessandro sordoni, philip bachman, andnewsqa: a machinekaheer suleman.
2017.thein proceedings ofcomprehension dataset.
2nd workshop on representation learning for nlp,pages 191–200..ashwin k. vijayakumar, michael cogswell,ramprasaath r. selvaraju, qing sun, stefan lee,david j. crandall, and dhruv batra.
2016. diversebeam search: decoding diverse solutions fromneural sequence models.
corr, abs/1610.02424..alex wang, kyunghyun cho, and mike lewis.
2020.asking and answering questions to evaluate thein proceedingsfactual consistency of summaries.
ofthe associationthe 58th annual meeting offor computational linguistics, pages 5008–5020,online.
association for computational linguistics..sean welleck, ilia kulikov, stephen roller, emilydinan, kyunghyun cho,and jason weston.
2019. neural text generation with unlikelihoodin international conference on learningtraining.
representations..ronald j williams.
1992..simple statisticalgradient-following algorithmsfor connectionistreinforcement learning.
machine learning, 8(3-4):229–256..chenguang zhu, william hinthorn, ruochen xu,qingkai zeng, michael zeng, xuedong huang, andmeng jiang.
2020. boosting factual correctnessof abstractive summarization with knowledge graph.
arxiv preprint arxiv:2003.08612..jason weston.
2019. don’t say that!
makinginconsistent dialogue unlikely with unlikelihoodtraining.
corr, abs/1911.03860..chin-yew lin.
2004. rouge: a package for automaticin text summarization.
evaluation of summaries.
branches out, pages 74–81..and bing xiang..ramesh nallapati, bowen zhou, cicero dos santos,ça˘glar guì‡lçehre,2016.abstractive text summarization using sequence-to-sequence rnns and beyond.
in proceedings ofthe 20th signll conference on computationalnatural language learning,pages 280–290,berlin, germany.
association for computationallinguistics..feng nan, ramesh nallapati, zhiguo wang, ciceronogueira dos santos, henghui zhu, dejiaozhang, kathleen mckeown,and bing xiang.
2021. entity-level factual consistency of abstractivethetext16th conference of the european chapter of theassociation for computational linguistics: mainvolume, pages 2727–2733, online.
association forcomputational linguistics..in proceedings of.
summarization..shashi narayan, shay b. cohen, and mirella lapata.
2018. don’t give me the details, just the summary!
fortopic-aware convolutional neural networksin proceedings ofextreme summarization.
the 2018 conference on empirical methods innatural language processing, pages 1797–1807,brussels, belgium.
association for computationallinguistics..myle ott, sergey edunov, alexei baevski, angelafan, sam gross, nathan ng, david grangier, andfairseq: a fast, extensiblemichael auli.
2019.in proceedings oftoolkit for sequence modeling.
naacl-hlt 2019: demonstrations..alec radford, jeff wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners..pranav rajpurkar, robin jia,.
and percy liang.
2018. know what you don’t know: unanswerablethequestions for squad.
the association for56th annual meeting ofcomputational linguisticsshort(volume 2:papers), pages 784–789..in proceedings of.
pranav rajpurkar, jian zhang, konstantin lopyrev, andpercy liang.
2016.squad: 100,000+ questionsfor machine comprehension of text.
arxiv preprintarxiv:1606.05250..alexander m. rush, sumit chopra,.
a neural attention model.
and jasonweston.
2015.forabstractive sentence summarization.
in proceedingsthe 2015 conference on empirical methodsofin natural language processing, pages 379–389,lisbon, portugal.
association for computationallinguistics..6890a appendices.
a.1 our implementation of qags.
for answer extraction, we follow the originalauthors to use spacy to extract named entities andnoun phrases.
we ﬁlter out the stop words suchas “who”, “it” as we ﬁnd them uninformative inquestion generation and keep 10 answer candidates.
we then use the bart-large model trained onnewsqa (trischler et al., 2017) dataset forquestion generation.
for each answer candidate weuse beam size of 10 and select the top 3 questionsper answer.
so we would have 30 questions persummary.
for the question answering model, weuse the albert-xxlarge (lan et al., 2019) modeltrained on squad2.0 (rajpurkar et al., 2018) as itachieves even better accuracy than bert-large..a.2 speed estimate for quals and qags.
evaluating the qags using the albert-xxlargeas the qa model on the test set (11490 examples)of cnndm would take about 93.6 hours on asingle nvidia v100 tensor core gpu.
qualsonly takes about 1.7 hours on the same gpu,offering more than 55x speedup.
if we wereto use qags during training (287112 examplesin the training set), we would need to evaluateit for each training example 6 times (6 sampledcandidate summaries).
it would take a staggering14033 hours, or 584 days on a single gpu.
onthe other hand, we are able to compute qualson a machine with 4 gpus for the training set in66 hours.
we believe the efﬁciency of qualsis critical in enabling the optimization of factualconsistency..a.3 additional experimental details of.
conseq.
we experimented with other ways of constructings + and s −.
we tried using ˆs + and ˆs −directly in conseq (without taking intersection ofexamples) and found that the overall quality of thesummaries are worse than taking the intersection.
after taking the intersection, the sizes |s +| =|s −| = 6492, 48809, respectively for xsum andcnndm.
note the original training sets have203540 and 287112 examples for xsum andcnndm, respectively.
furthermore, we foundthat using the positive and negative summariescorresponding to the same document in a minibatchleads to better results.
we also found in our.
figure 4: correlation between quals and qags onxsum (left) and cnndm (right).
the average qagstend to increase with the increase in quals.
thestandard deviation of the qags for each bin is about0.187 for xsum and 0.127 for cnndm..experiments that the best results are obtained withonly one outer iteration of algorithm 1..a.4 quals approximates qags.
as shown in figure 3 in the main paper, qualscorrelates very well with qags in both datasetswith 10 percentile bins.
we also show thecorrelation plot with 100 bins in figure 4, withthe same monotonicity trend..a.5.
illustration of quals:.
we take an example to illustrate how qualscaptures the factual inconsistency of summaries.
below is a generated summary from the bart-large mle model on a test example:.
the airasia ﬂight 4u 9525 crash wasthe latest in a series of tragedies thathave hit the aviation industry..the input document described the airasia crashbut did not mention the ﬂight number.
in fact, “4u9525” is the germanwings ﬂight that crashed in thefrench alps.
the model hallucinated the ﬂightnumber because it appeared in several trainingexamples that cover the germanwings crash.
giventhe above summary, our qagen model generatesthe following q-a pairs: q1: what was the nameof the ﬂight that crashed?
a1: 4u 9525. q2:which airlines ﬂight crashed?
a2: airasia.
infigure 5 we show the negative log likelihood persubword token on these q-a pairs conditioned onthe summary (blue) and input document (orange).
the answer to the ﬁrst question is very likelyaccording to the summary while extremely unlikelyaccording to the input document, indicating factualinconsistency.
on the other hand, “airasia” isfactually consistent and the second q-a pair is.
6891figure 6: human evaluation interface using amazonsagemaker ground truth..figure 5: negative log likelihood per subword token ontwo q-a pairs from the qagen model according to thesummary(blue) and input document (orange).
highermeans unlikely.
the ﬁrst q-a pair (top ﬁgure) has amuch higher average negative log likelihood accordingto the input document than according to the summary..as likely according to the summary as the inputdocument.
the quals score for the two q-a pairsare −2.615 and −0.054, respectively..a.6 more qualitative examples.
we provide additional qualitative examples in table6 for summaries generated by mle and conseq.
in table 7, we show additional examples of thequestions and answers generated by qagen modelbased on the summaries..a.7 human evaluation.
we show the interface of our human evaluation inthe figure 6. the full instruction for the annotatorsare shown in figure 7.figure 7: human evaluation instruction screenshots..6892input 1:.
mle:.
conseq:.
input 2:.
mle:conseq:.
input 3:.
mle:conseq:.
input 4:.
mle:.
conseq:.
input 5:.
mle:.
conseq:.
input 6:.
mle:.
conseq:.
input 7:.
mle:conseq:.
...eventually she decided to train for the 10,000m and her win at parliament hill, 17 seconds inside the gb qualiﬁcation time, camein only her second track event at the distance...."i haven’t been racing on the british scene recently, so that’s why it’s come as quitea shock."...
"we’ll start to plan the build-up, the training and the races i’ll compete in before rio."
british 10,000m runner sophie andrews says she has been "blown away" by the reaction to her shock victory at the londonanniversary games.
british 10,000m runner sophie andrews says she is still in shock after winning at parliament hill in london to qualify for the rioolympics..... the plymouth university marine biology student said she only realised the cosmetic prosthetic was missing the followingmorning.
she thinks she could have left it in a nightclub and forgot to pick it up....a university student who lost her hand in a nightclub has said she is “devastated” to have lost it.
a student who lost her prosthetic hand in a nightclub has said it is “worth everything” to her..the snp topped the vote in the leith walk by-election, while scottish labour won the second seat from the greens.
... the snp’sjohn lewis ritchie topped the leith walk poll with 2,290 votes.
he was elected at stage one in the stv process with a swing inﬁrst-preference votes of 7.6% from labour.
...the snp has won the leith walk by-election and the scottish greens have won the midlothian west seat.
the snp has won the leith walk by-election in edinburgh with a swing of 7.6% from labour..conrad clitheroe, left, and gary cooper, right, were thrown in jail after being arrested for writing down aircraft registrationnumbers in dubai.
three british men who have spent two months in prisons in dubai and abu dhabi after they were seen planespotting are to be freed.
conrad clitheroe, 54 and gary cooper, 45, from stockport, along with their ex-pat friend neil munrowere stopped by police for writing down aircraft registration numbers at fujairah airport.
they were taken to a police station anddespite being told they would not be detained, were put into prison.
...conrad clitheroe, gary cooper and neil munro were stopped at fujairah airport.
they were taken to a police station and toldthey would not be detained.
but despite being told they would be detained, they were put into prison.
families were concerned fortheir welfare as mr clitheroe has a heart condition.
today they were told they would be able to go home after the court accepted adefense argument they were pursuing their passion for plane spotting.
conrad clitheroe, gary cooper and neil munro were stopped by police in dubai.
they were taken to a police station and despitebeing told they would not be detained, were put into prison.
families of the three men conﬁrmed they would ﬁnally be able toreturn home and charges of espionage would not be brought against them.
mr clitheroe, who suffers from a heart condition, willbe able to celebrate his ﬁrst wedding anniversary with his wife valerie on may 9....now police investigating the case have come across cctv that shows the man following three other potential victims earlier onthe same night.
... it includes one woman who was forced to ﬂee from the man by bus after walking to her car in leeds city centre,ending up miles away from where she was going, just to get to safety.
another potential victim followed may have been aware shewas being stalked as he also walked up behind her in the city centre as she walked past a row of bars.
while a third woman can beseen on the footage seen by police turning around to ﬁnd herself just an inch away from the rapist, before darting into a shop andstaying in there until he left on the city’s burley road.
... he told the daily mirror: ’his ﬁrst target was a woman in her 20s whohad parked her car.
he is seen walking behind her, six inches from her back pocket.
’she was so concerned she got a bus that tookher miles from where she was going.
woman, 18, was attacked at a bus stop in beeston, leeds, on march 6. she was hit over the head 20 times with a rock and left fordead.
police have now found cctv showing the man following three other women.
one woman was forced to ﬂee by bus to get tosafety from the rapist.
another woman in her 20s was just an inch away from the rapist.
the man is wanted for attempted murderand rape after the ’appalling’ attack.
the 18-year-old was hit over the head 20 times with a rock and dragged into a garden to be brutally raped by the man and left fordead.
police investigating the case have come across cctv that shows the man following three other potential victims earlier onthe same night.
one woman was forced to ﬂee from the man by bus after walking to her car, ending up miles away from where shewas going.
another woman can be seen turning around to ﬁnd herself just an inch away from the rapist, before darting into a shop.....a new metro line extension opened this week in the czech capital, transporting travellers closer to the airport than ever before‚but the point where passengers transfer from trains to buses doesn’t have a moving staircase.
...new metro line extension opened this week but there is no moving staircase.
that means porters are left to carry heavy bags upand down 32 stairs.
one of the porters said he wanted to ’stay ﬁt and help the elderly’ ofﬁcials are now considering adding anescalator while the train project is completed.
a new metro line extension opened this week in the czech capital.
but the point where passengers transfer from trains to busesdoesn’t have a moving staircase.
that means porters are left to carry heavy bags up and down 32 stairs.
ofﬁcials are nowconsidering adding an escalator while it remains unclear when the train project will be completed..at least two have been treated for symptoms of poisoning after being walked near a cricket pitch in fordham heath ... the dogswhich were treated, both suffered "severe sickness" after being walked in a ﬁeld near eight ash green cricket club in spring lane...a number of dogs have been taken ill after being walked in a ﬁeld near a cricket club.
two dogs have suffered "severe sickness" after being walked in a ﬁeld near a cricket club..table 6: mle summaries in example 1 contains hallucination.
mle summary in example 2 was misleading byomitting “prosthetic”.
mle summary in example 3 contradicted the input document, which says scottish greenslost.
mle summary in example 4 misses a “not”.
mle summary in example 5 confuses the victims; the womanin her 20s ﬂed by bus according to the input document.
the conseq summary in example 6 is more informativeas it mentions the metro line is located in the czech capital.
example 7: input document mentioned “at least twodogs” but conseq omitted “at least”..6893summary1:q&a:q&a:q&a:q&a:q&a:q&a:.
summary2:.
summary3:.
q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:.
q&a:q&a:q&a:.
q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:.
q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:.
summary4:.
summary5:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:q&a:.
a security alert at the alliance party ofﬁces in belfast city centre is being considered a hoax, its chairman has said.
what is the security alert considered?
a hoaxin what city is the security alert located?
belfastwho said that the security alert was a hoax?
chairmanwhat is the security alert considered?
a hoaxwhat party is the security alert at?
alliance partywhat is considered a hoax?
security alert at the alliance party ofﬁces in belfast city centre.
the uk’s international reputation has been knocked, with a global energy watchdog warning the uk faces a loss of status as aleader in clean energy.
what is the name of the global energy watchdog?
global energy watchdogwhat has been knocked?
the uk’s international reputationwhich country’s reputation has been knocked?
the ukwhat does the global energy watchdog say the uk faces?
loss of status as a leader in clean energywho warned that the uk could lose its clean energy leadership status?
a global energy watchdogin what ﬁeld is the uk losing its status as a leader?
clean energywhat did global energy watchdog say?
the uk faces a loss of status as a leader in clean energy.
in what ﬁeld is the uk losing its status as a leader?
clean energy.
how much of a reputation has the uk lost in the world?
the uk’s international reputation has been knocked,in what ﬁeld is the uk losing its status as a leader?
clean energyis the uk’s international reputation good or bad?
has been knockedwhat kind of reputation has been knocked?
internationalwhat kind of reputation has been knocked by the global energy watchdog?
international reputationwhat does the global energy watchdog say the uk faces?
loss of status as a leader in clean energy..former italy and south africa coach nick mallett says southern hemisphere sides need to put themselves in the same category astheir world cup rivals.
what does nick mallett say?
southern hemisphere sides need to put themselves in the same category as their world cup rivalswhat team does nick mallett coach?
italy and south africawhich coach says that southern hemisphere teams need to put themselves in the same category as their world cup rivals?
nickmallettwhat did mallett say?
southern hemisphere sides need to put themselves in the same category as their world cup rivals.
what type of competition does nick mallett coach?
southern hemisphere sidesalong with south africa, what country does nick mallett coach?
italywhose name does nick mallett use as a coach?
italy and south africa coachwho says that southern hemisphere teams need to put themselves in the same category as their world cup rivals?
nick malletnick mallett is the coach of what team?
italy and south africaname the coach of italy and south africa?
nick mallettwhat does nick mallett say?
southern hemisphere sides need to put themselves in the same category as their world cup rivals.
to whom did nick mallett compare the world cup rivals?
southern hemisphere sideswhere does nick mallett work?
italy and south africa coachwhich coach says that southern hemisphere teams need to put themselves in the same category as their world cup rivals?
nickmallet.
new bury boss lee clark has conﬁrmed the appointment of former sunderland striker rob wilson as ﬁrst-team manager on atwo-year contract.
who is the sunderland striker?
rob wilsonwhat team did rob wilson play for?
sunderlandhow long is the contract that rob wilson has?
two-yearwho appointed rob wilson?
lee clarkwhat team did rob wilson play for?
sunderland strikerwhen did lee clark conﬁrm the appointment of rob wilson?
two-year contracton what kind of contract did rob wilson sign?
ﬁrst-team managerwho is the new manager of the bury football team?
rob wilsonwhat job has lee clark done?
bury bossrob wilson is a former sunderland striker for what team?
bury.
an image thought to be by street artist banksy appeared on a shop wall on sunday during the queen’s jubilee.
when did banksy’s image appear on a shop wall?
sundaywhat type of building has been built over a tree?
buildingwhich artist was thought to be banksy?
street artistwhat was the name of the artist who was on the wall?
banksywhere did banksy’s image appear?
on a shop wallwhich artist was thought to be banksy?
street artist banksya banksy image appeared on a shop wall during what event?
queen’s jubileeon what day did banksy’s image appear on a shop wall?
sundaywhen the image appeared?
sunday during the queen’s jubileewhat event did banksy appear on a shop wall during?
queen’s jubilee.
on what day did banksy’s image appear on a shop wall?
sundaybanksy’s image was thought to be by who?
street artistwho painted an image on sunday?
banksywhat was the name of the artist who was on the wall?
street artist banksywhat event did banksy appear on a shop wall during?
queen’s jubileewhen did this happen?
sunday during the queen’s jubilee.
table 7: additional examples of the question and answers generated by the qagen model based on the summaries..6894