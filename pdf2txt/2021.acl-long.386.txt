early detection of sexual predators in chats.
matthias vogt ulf leser alan akbikhumboldt universit¨at zu berlinmatthias.vogt@campus.tu-berlin.deleser@informatik.hu-berlin.dealan.akbik@hu-berlin.de.
abstract.
an important risk that children face todayis online grooming, where a so-called sexualpredator establishes an emotional connectionwith a minor online with the objective of sex-ual abuse.
prior work has sought to automati-cally identify grooming chats, but only after anincidence has already happened in the contextof legal prosecution.
in this work, we insteadinvestigate this problem from the point of viewof prevention.
we deﬁne and study the taskof early sexual predator detection (espd) inchats, where the goal is to analyze a runningchat from its beginning and predict groomingattempts as early and as accurately as possible.
we survey existing datasets and their limita-tions regarding espd, and create a new datasetcalled panc for more realistic evaluations.
we present strong baselines built on bert thatalso reach state-of-the-art results for conven-tional spd.
finally, we consider coping withlimited computational resources, as real-lifeapplications require espd on mobile devices...
.
...
.
..figure 1: visualization of chat messages and earlysexual predator detection (espd).
on each new mes-sage, the analysis is updated to reﬂect the level of risk.
finally, an alert is triggered as the risk-threshold ispassed.
our goal is to detect such risk as early as pos-sible.
note that real chats are much longer and can benon-contiguous conversations that span over weeks ormonths.
original source [3].
1.introduction.
online grooming denotes the process where a so-called sexual predator establishes an emotional con-nection with a minor online to systematically so-licit and exploit them for sexual purposes (wachset al., 2012).
online grooming is a major con-cern of public safety that, sadly, is rapidly growing.
for instance, in england and wales in the year tomid-2020, police recorded 5,083 offenses of sex-ual communication with a child [1], an averageof 14 offenses per day.
in germany, there were2,632 recorded cases in 2020 where a child wassexually abused through internet communicationtechnologies [2], an increase of 50 % to the previ-ous year.
as such crimes often go unreported orundetected, police-recorded incidents certainly do.
not fully reﬂect the real scale of the issue (bowlesand keller, 2019; mcguire and dowling, 2013)..the problem of detecting whether or not a childis being groomed by a predator is called sex-ual predator detection (spd).
most previous ap-proaches to spd have cast this as the problemof identifying predatory authors in a corpus ofsegments of chats (villatoro-tello et al., 2012;cardei and rebedea, 2017).
other approaches in-terpreted it as a binary classiﬁcation problem oversegments of a chat (ebrahimi et al., 2016), or theentire chat (bours and kulsrud, 2019).
approacheswere evaluated mostly using data from the panshared task on sexual predator detection (inchesand crestani, 2012).
however, most prior work has.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4985–4999august1–6,2021.©2021associationforcomputationallinguistics4985viewed spd from the point of view of forensics:they focused on identifying completed groomingchats in preparation for legal prosecution..we believe that it is also important to study ap-proaches that may prevent online grooming – asearly as possible, i.e., during an ongoing chat.
ide-ally, the grooming process should be disrupted be-fore it succeeds to protect children from harm.
thistask is non-trivial as the content of grooming chatschanges over time: chats often start with the ex-change of personal information and building oftrust, a phase in which they are difﬁcult to detect.
in a second stage, predators further develop trustwith their victims in a cycle of entrapment.
theytry to desensitize their victims to sexual topics, iso-late them from others, and arrange meetings (olsonet al., 2007, p. 236).
even in this second stage, itis difﬁcult to distinguish between grooming andconsensual conversations between minors or adults.
for this, a model needs to be able to detect dis-criminative features like a user talking about agedifference, checking on the victim’s relationshipwith their parents, isolating them from their supportnetwork, reframing sexual actions as appropriateand more (see olson et al.
(2007), pp.
234ff)..an example of arranging a meeting is shownin figure 1. here, an alert is triggered only late inthe grooming process, when an in-person meetingis already explicitly being discussed.
ideally, suchchats should be detected far sooner.
however, thereal-world consequences of a triggered espd alertcan be considerable and may involve police actions.
this means that false alerts should be avoided asmuch as possible.
at the same time, false negativesmust be avoided by all means as these could leadto a sexual assault.
it is therefore as important asethically difﬁcult to ﬁnd the best balance betweenthe earliness of an alert and the certainty that analert is justiﬁed..1.1 contributions.
we introduce the task of early sexual predator de-tection (espd) in chats.
we cast espd as an earlyrisk detection problem in which chats are analyzedfrom the start and message by message, with thegoal of raising warnings for chats early and accu-rately.
speciﬁcally, we make the following contri-butions:.
• we introduce the problem of espd and for-.
mally deﬁne it..limitations, and build a new combined datasetcalled panc as a best-effort for evaluatingespd..• we propose a task setup to evaluate espd,focusing on the trade-off between earlinessand accuracy..• we present strong baselines for espd using atwo-tier approach.
our method (1) analyzessliding windows of messages from an ongoingchat using bert and (2) continuously classi-ﬁes the sequence of the window classiﬁcations.
we evaluate three different bert languagemodels, two of which work on mobile..• we compare our models to previous researchin conventional (i.e.
“non-early”) spd settingsand ﬁnd that two of them outperform the cur-rent state of the art..• we provide an extensive discussion of the lim-itations of our models and the available data.
we see our work as an important step to en-courage more research into espd.
to this end, wemake our experimental setup, our baseline models,scripts for corpus processing, and the visualizationtool for inspecting analyzed chats (used to gener-ate figure 1) publicly available1.
we emphasizethat we do not consider our models to be ready foruse in real scenarios, which we discuss in depth inour ethics statement (see below)..2 analysis of available datasets.
due to privacy and legal reasons, grooming chatsare extremely difﬁcult to obtain.
we introduce the(few) known corpora of this kind and discuss theirlimitations, motivating the assembly of the pancdataset we discuss in section 3..2.1 original data sources.
the main source of grooming chats used inspd literature is the perverted justice founda-tion (pj) [10].
this organization used trainedvolunteers (decoys) posing as children in publicchat rooms to help authorities convict sexual preda-tors.
they provide their chats with convicted preda-tors for download but ceased their decoy opera-tions in 2019. nearly all prior work evaluates ondatasets derived from pj (mcghee et al., 2011;gupta et al., 2012; bogdanova et al., 2014; meyer,2015; ebrahimi et al., 2016; cardei and rebedea,2017; pastor ´lopez-monroy et al., 2018)..1early-sexual-predator-detection..• we survey available datasets, analyze their.
gitlab.io.
4986to our knowledge, the only work using realgrooming chats is cheong et al.
(2015) who usedchats extracted from moviestarplanet, a massivelymultiplayer online game for children.
unfortu-nately, this corpus is not publicly available..2.2 corpora used for spd.
pan12.
2.2.1the pan lab at the 2012 clef conference in-troduced a shared task on sexual predator identiﬁ-cation [7].
the organizers created a large datasetwhich we call pan12 using data from pj.
as non-grooming chats, they sampled from logs of ircchannels and of the chatting site omegle [11].
these chats also include cybersex between con-senting adults among non-predatory conversations,which makes distinguishing grooming chats espe-cially difﬁcult.
they divided chats into segmentswhenever a conversation was interrupted for morethan 25 minutes and ﬁltered all segments with morethan 150 messages.
this results in a total of 222ksegments, of which 2.58 % are grooming chats,through which the organizers try to mimic the dis-tribution of grooming in actual online conversa-tions.
they are partitioned into train and test splitsof a 30:70 ratio..pan12 has several limitations.
all groomingchats stem from decoy operations and are not withactual victims, and the non-grooming chats are notwith decoys.
real.
most problematic for espd isthe separation into relatively short, unordered seg-ments, thus completely blurring the true timelineof a chat.
this makes the data unsuitable for espdsince we aim to detect predators as early as possiblein potentially long-running chats..2.2.2 vt panvillatoro-tello et al.
(2012) found that ﬁltering thepan12 segments to only focus on the most impor-tant samples can lead to better model performance.
they created a new dataset (vtpan) by remov-ing from pan12 segments that have only one par-ticipant, less than 6 interactions per user, or longsequences of special characters (often depictingascii art).
many short segments which stem frompredatory chats actually contain no predatory lan-guage, so a beneﬁt of vtpan is that many of thesesegments are ﬁltered.
the dataset is only 10% ofthe size of pan12, and is also used in recent workon spd (escalante et al., 2016, 2017; pastor ´lopez-monroy et al., 2018).
regarding espd, this datasetsuffers from the same limitation as pan12..2.2.3 chatcoder2.
the chatcoder2 (c c 2) corpus was created bymcghee et al.
in 2011 and was later also used byother researchers (basave et al., 2014).
it contains497 complete predator chats from pj and was builtmainly for studying the semantic segmentation ofgrooming chats.
accordingly, messages in 155chats are also labeled as belonging to one of threephases: (1) exchange of personal information, (2)grooming, and (3) approach of the victim..2.3 limitations.
in summary, we ﬁnd that existing datasets sufferfrom limitations that make them difﬁcult to use fortraining and evaluating espd.
the commonly useddatasets pan12 and vtpan only contain short, dis-jointed, and unordered chat segments.
for espd,however, one needs to detect grooming in a contin-uous message stream, which is ordered and theoret-ically unbounded in length.
classifying segmentsonly, we have no information about how early inthe complete chat grooming is detected.
moreover,evaluating earliness within single segments wouldnot be interesting as it is not interpretable and be-cause they are so short.
while c c 2 does have fullchat logs, it does not contain any negative samples.
our analysis thus motivates the assembly of thenew panc dataset as explained in the next section..3 early sexual predator detection.
in this section, we propose an evaluation setupfor espd.
we give a formal deﬁnition of the taskfollowed by suitable evaluation metrics.
finally,we discuss how we use and combine existing spddatasets to create panc for the evaluation of espd..3.1 task deﬁnition.
we interpret espd as an early risk detection prob-lem (losada et al., 2020).
this means that we needto consider the earliness and the accuracy of warn-ings, continuously analyzing a chat after each newmessage.
formally:deﬁnition 1 (message).
a message is a string witha time and an author.
deﬁnition 2 (chat).
a chat c = (m1, m2, .
.
. )
is a sequence of messages mi where the time ofmessages is monotonically increasing.
a ﬁnite chatc = (m1, .
.
.
, mn), where we say bis of the form bchas a length of n. we call grooming chats positiveand other chats negative.
this is the class of a chat..4987predator segments.
non-predator segments.
pan12 dataset.
only use non-predator segments.
pan12 non-predator segments.
chatcoder2 predator segments.
cut into segments .
+ some ﬁltering.
panc dataset.
full-length predator chats.
chatcoder2 dataset.
figure 2: creating panc from pan12 and c c 2..the length of real chats is potentially unboundedand keeps increasing, so regarding real chats asinﬁnite is handy.
we analyze chats after each newmessage, thus considering only ﬁnite preﬁxes forclassiﬁcation.
deﬁnition 3 (preﬁx).
let c = (m1, .
.
.
, ml, .
.
. )
be a chat.
we call c(l) := (m1, .
.
.
, ml) the preﬁxof c with length l.finally, we deﬁne espd as follows.
deﬁnition 4 (espd).
let xtest be a dataset of ﬁ-nite chats.
for c = (m1, .
.
.
, mn) ∈ xtest andl = 1, .
.
.
, n increasing over time, an espd systemdecides for each l whether a warning for c shouldbe raised or not by classifying c(l).
it stops as soonas a warning is raised, classifying c as grooming.
if no warning is raised for all l = 1, .
.
.
, n, it clas-siﬁes c as non-grooming.
finally, espd is theproblem of classifying all c ∈ xtest as early andaccurately as possible..note that this deﬁnition deliberately states thatan espd system never classiﬁes a chat as non-grooming as long as there are messages left (orthe chat did not end, in a real-life setting), as it can-not know the future after the current preﬁx c(l)..3.2 evaluation metrics for espd.
in espd, there are two desiderata between which atrade-off exists: (a) raising alerts as early as possi-ble, and (b) raising alerts as accurately as possible.
raising warnings early is good for (a), but hampers(b) as less data is available.
waiting longer withwarning hurts (a), but most likely improves (b), aslater decisions are based on more messages..3.2.1 accuracy of warnings.
accuracy metrics are most prominent in relatedwork on detecting sexual predators (pastor ´lopez-monroy et al., 2018; escalante et al., 2017), i.e.
“non-early” spd.
we report the established metricsof precision, recall, and f1 for the grooming class..3.2.2 earliness of warningswe call the number of messages that have beenexchanged before a warning is raised the warninglatency.
we use latency-weighted f1 (sadequeet al., 2018) as a measure that accounts for bothwarning accuracy and warning latency.
to calculateit, we ﬁrst deﬁne a penalty for each warning latencyl ≥ 1 given by.
penalty(l) := −1 +.
21 + exp(−p · (l − 1)).
where p determines how quickly the penalty shouldincrease as latency increases.
a warning after theﬁrst message receives 0 penalty and for increasingwarning latency, the penalty approaches 1..now assume an espd system to produce a listlatencies of warning latencies for all chats c ∈xtest where (1) c is positive, and (2) the systemraises a warning for c. we deﬁne the overall speedof correct warnings as.
speed := 1−median{penalty(l) | l ∈ latencies}..this metric is more interpretable than just us-ing the mean or median warning latency, as itdepends on the problem and the dataset at handhow good a median warning latency actuallyis.
finally, the latency-weighted f1 is given byflatency := f1 · speed.
we generally consider anespd system a better than an espd system bwhen it reaches, for a given dataset, a higherflatency; comparisons focusing more on speed ormore on accuracy or searching for pareto-optimalsolutions are also possible.
note that we, followinglosada et al.
(2019), compute the speed of warn-ings only for grooming chats classiﬁed as such.
allother cases (false positives, false negatives, truenegatives) are accounted for through the f1 value..3.3 the panc dataset.
evaluating an espd system needs a corpus of chats,where each entire chat is annotated as groomingor not.
note that we do not require this annotation.
4988number of positive negative % positive full-lengthsegments segments segments segments.
pos.
chats messages,.
pos.
segment lengthwords.
neg.
segment lengthwordsmessages,.
length of full-length positive chats.
messages,.
words.
pa n c train 19,35113,159pa n c test32,510pa n c.1,7531,4263,179.
17,59811,73329,331.
9.06 %10.84 %9.78 %.
298199497.
64 (±43), 289 (±218)65 (±43), 292 (±222)64 (±43), 291 (±220).
36 (±25), 173 (±1,385)36 (±26), 184 (±1,529)36 (±25), 177 (±1,444).
1,959 (±3,032), 8,730 (±12,223)2,248 (±3,141), 10,231 (±13,177)2,075 (±3,079), 9,331 (±12,635).
table 1: panc overview.
segment/chat lengths are given through mean and standard deviation.
on the message level, as what constitutes the ﬁrstgrooming message in a chat is highly subjective.
furthermore, espd based on supervised learningrequires an annotated training corpus.
existingdatasets cannot be directly used for this purpose,because they either consist only of unordered seg-ments (vtpan, pan12), which hinders measuringspeed, or only contain positive chats (c c 2), whichmakes measuring f1 impossible.
furthermore, theexisting corpora all use pj grooming chats andpartly overlap..to address these issues, we assembled panc, anevaluation dataset for espd, by carefully combin-ing selected parts from pan12 and from c c 2. theprocess is illustrated in figure 2: the ﬁnal corpusconsists of (1) all positive full length chats fromc c 2 and (2) the negative segments of pan12.
werandomly split the corpus on this level at propor-tions 60:40 into train/test splits.
through (1), wecan evaluate earliness.
we cannot measure accu-racy as deﬁned above due to the lack of full-lengthnegative chats.
instead, in the experiments, wewill compute accuracy based on segments as anestimate of (2), for which we split the full-lengthgrooming chats into segments.
we ﬁlter all seg-ments shorter than 6 messages, similar to vtpan,and those longer than 150 messages (some of thelatter were actually not ﬁltered in pan12, contraryto its original speciﬁcation).
finally, we removedsegments that are not between exactly two authorsto make them comparable to c c 2 chats.
statisticson the resulting corpus are given in table 1..discussion.
we consider panc to be the ﬁrst cor-pus suitable for realistic espd evaluations.
yet itstill has limitations: first, the negative chats arenot full-length chats but only segments.
while thisdoes not impact our earliness evaluation, it pre-vents the computation of true espd accuracy.
ourproposed workaround is to replace chat accuracywith segment accuracy, although we do not knowhow well the latter approximates the former as wetherein classify short segments which can stemfrom anywhere in a chat.
an alternative wouldbe to use a difference source for the negative chats;.
however, we decided on those from pan12 as theyalso include “hard negative” cases (i.e.
sexual con-versations between consenting adults), which webelieve gives more realism to our evaluation.
an-other limitation is that panc only contains chatsbetween exactly two authors, so our systems arenot applicable in group chats.
however, groomingis very rare in group chats as predators depend ontheir actions staying unnoticed..4 baseline approach: two-tier espd.
we present a straightforward espd approach todemonstrate the validity of our task setup and toestablish baselines for future works.
it consists oftwo tiers of classiﬁcation: (1) a local tier (tier 1)that moves a sliding window over the messagesof a chat and classiﬁes them, and (2) a global tier(tier 2) that decides after each window predictionwhether to raise a warning or not based on the se-quence of recent window predictions.
the purposeof this architecture is to balance earliness and ac-curacy and especially to prevent single suspiciouswindows from triggering warnings..4.1 tier 1: classifying sliding windows.
for tier 1, we use a standard approach in whichwe add a linear classiﬁer to a pre-trained trans-former model and ﬁne-tune the entire architecture.
it takes as input all messages in a given windowand outputs a binary prediction.
we evaluated dif-ferent bert models: b ertlarge, b ertbase (devlinet al., 2018), and mobile b ert (sun et al., 2020).
model parameters can be found in appendix a.mobile b ert is a version of b ertlarge with smallermodel size and faster inference, optimized for useon mobile devices.
hyperparameters.
next to the choice of languagemodel, the main hyperparameter of tier 1 is thewindow size.
it controls the number of messagesthat are input into the classiﬁer..4.2 tier 2: classifying chat preﬁxes.
we use a simple approach for the problem of de-tecting a chat as grooming based on tier-1 clas-.
4989approachsbert-largesbert-basesmobilebert.
f10.88 (± 0.05)0.89 (± 0.02)0.80 (± 0.04).
precision0.88 (± 0.03)0.82 (± 0.04)0.69 (± 0.07).
recall0.89 (± 0.11)0.96 (± 0.01)0.95 (± 0.01).
speed0.75 (± 0.17)0.91 (± 0.02)0.72 (± 0.02).
flatency0.67 (± 0.18)0.81 (± 0.03)0.58 (± 0.02).
table 2: warning accuracy scores of our espd systems on panc (as mean and standard deviation).
siﬁcation results over a series of windows.
afterevery window classiﬁcation, we consider the countof positively classiﬁed windows within the last 10windows.
if this value exceeds a pre-deﬁned thresh-old called skepticism s ∈ {1, .
.
.
, 10}, the chat isclassiﬁed as grooming.
hyperparameters.
the only hyperparameter oftier-2 is thus skepticism which controls the earli-ness/accuracy tradeoff..5 evaluation.
we evaluate our baseline approach in our espdtask setup using the proposed metrics for warningearliness, accuracy, and flatency.
we compare threedifferent espd systems: sbert-large, sbert-base, andsmobilebert, which use the respective transformermodels as described above as the tier-1 classiﬁer.
we use a window size of 50 and a skepticism of5; an evaluation of the impact of the skepticismparameter can also be found below.
we ﬁne-tuneeach of our bert models on panc and vtpan.
as the results of ﬁne-tuning bert models oftenvary heavily based on the random seed used (dodgeet al., 2020), we repeat this process three times.
inthe evaluation, we always report the mean of theresulting measures together with standard devia-tion.
we ﬁne-tune b ertbase and mobile b ert usingthe tensorflow lite model maker [8] library andb ertlarge using flair [9] (akbik et al., 2019)..5.1 experimental results.
an overview of evaluation results for our threemodel variants is given in table 2. to compute theflatency of warnings, we measured their f1 scorefor segments, while speed is based on full positivechats (see section 3).
evaluating earliness in isolation.
figure 3 showsviolin plots of the distribution of warning latenciesfor the three systems for all predator chats frompanctest, based on the means over three runs.
thesystems sbert-large and smobilebert have similarperformance while sbert-base outperforms both.
itsmedian warning latency is roughly 30 messageslower compared to the other systems.
moreover,sbert-base exhibits much less variance in warning.
●.
●.
●●.
●●●.
●.
●●●.
●.
●.
segassem. f.o rebmunn. .
i ycne.t.a.l .
i.gnnraw.500.
450.
400.
350.
300.
250.
200.
150.
100.
50.
0.
●.
●.
●.
●●.
●●●.
●.
●.
●.
●.
bert−largemedian: 54std.
dev.
: 74.bert−basemedian: 18std.
dev.
: 25.mobilebertmedian: 44std.
dev.
: 46.figure 3: warning latency distributions of our systemsfor the full-length predator chats in panctest..latency than the other two models.
an explanationof the somewhat surprising scores of sbert-largeis that one of the three runs of this model led tosigniﬁcantly worse results than the other runs.
as aconsequence, the standard deviation of this modelis also much higher than for the other two models.
interpreting and penalizing warning latency.
to calculate flatency, we need to set the parame-ter p which controls the penalty that is assigned toa given warning latency.
however, when inspect-ing the full-length predator chats, we noticed thatthe number of messages before a chat gets suspi-cious varies heavily, and there is no “typical” valuefor this, which makes setting p difﬁcult.
we be-lieve that it would be better to not set p globallybut on a chat by chat basis, which could be donein future work.
conventionally (sadeque et al.,2018; losada et al., 2019), p is set such that thepenalty is 0.5 at the median length of chats.
butfor our full-length predator chats, this would be1,055 messages which we think is way too late toraise a warning.
ultimately, we decided to set pwith help from the message labels from c c 2. weset p such that the penalty is 0.5 when about 20grooming messages are exchanged.
in median forthe labeled c c 2 chats, this is 90 messages, so weset p = ln(3)/(90 − 1) ≈ 0.0123. however, thestandard deviation for this is about 200 messages..4990best baseline approach.
as table 2 shows, over-all results differ whether one considers only f1 orflatency: considering f1, sbert-large and sbert-basehave similar performance and both outperformsmobilebert.
however, when considering speed,b ertbase signiﬁcantly outperforms the other mod-els.
one of the b ertlarge runs only scored a speedof 0.55 , which is why the mean speed is unexpect-edly low and the standard deviation is high.
inflatency, sbert-base outperforms sbert-large by 0.14which again outperforms smobilebert by 0.09 .
impact of skepticism.
the skepticism hyperpa-rameter s controls the propensity of the tier-2 clas-siﬁer to raise warnings and can thus be seen as thecentral knob to tune the earliness/accuracy trade-offfor our approach.
we would expect that being moreskeptical leads to a lower recall, higher precision,and higher latency of warnings.
to conﬁrm this, weevaluate each of our espd systems on panc foreach skepticism s = 1, .
.
.
, 10 and note precision,recall, and speed of warnings depending on skepti-cism.
here, the speed of warnings is calculated asexplained in section 3.2.2..in figure 4, we plot the concrete accuracy andspeed metrics of our espd systems, depending onthe skepticism of the tier-2 classiﬁers.
for allof our systems, we indeed ﬁnd that as skepticismincreases, precision increases as well, while recalland speed are decreasing.
moreover, the flatency ofour detectors does not signiﬁcantly change as longas s is in a medium range of {3, 4, 5, 6, 7}, exceptfor sbert-large, but here the standard deviation offlatency is so high that no clear correlation exists..5.2 comparison to conventional spd.
to get a better understanding of the accuracy ofour proposed baseline approach, we also employit in a conventional spd setting.
this allows us tocompare against the state-of-the-art approaches byescalante et al.
(2017) and pastor ´lopez-monroyet al.
(2018).
evaluation setup.
for this comparison, we repli-cate their evaluation setting in which they clas-sify segments on vtpan by considering increas-ing fractions of each segment as measured by thenumber of characters.
they evaluate their spd ac-curacy after 10%, 20%, .
.
.
, 100% of all charactersof a segment where only whole words are included.
as classiﬁcation is not message-by-message, weonly use our tier-1 classiﬁers in this setting.
notethat evaluating accuracy as a function of fraction.
figure 4:impact of master classiﬁers skepticisms for our espd systems sbert-large, sbert-base, andsmobilebert.
dots and lines are the mean across differ-ent runs and the shaded area is the standard deviation.
of a segment also may be interpreted as earliness,though in a very different sense than proposed forespd in this paper, because segments are muchshorter than chats and may be from anywherewithin a chat..new state of the art on spd.
figure 5 summarizesthe results of this comparison.
notably, even themobile b ert model is competitive with previousworks in spite of being much less resource hun-gry.
both other models outperform previous worksfor all settings.
the difference in performance isespecially large for small segment preﬁxes and de-.
499100.10.20.30.40.50.60.70.80.91 1 2 3 4 5 6 7 8 910skepticismevaluation metrics  –  bert-largeprecisionrecallf1speedf_latency00.10.20.30.40.50.60.70.80.91 1 2 3 4 5 6 7 8 910skepticismevaluation metrics  –  bert-baseprecisionrecallf1speedf_latency00.10.20.30.40.50.60.70.80.91 1 2 3 4 5 6 7 8 910skepticismevaluation metrics  –  mobilebertprecisionrecallf1speedf_latencycreases with increasing availability of information.
for 10 % of information, b ertlarge outperforms thesota by as much as 8 % in f1.
a complete list ofthe f1 values is given in appendix b.discussion.
we believe that improvements primar-ily stem from our usage of bert, which previouslyhad not been applied to spd.
the implementationsof previous approaches are not openly available, sowe cannot directly compare example inputs.
butprior work uses document representations wherewords are considered irrespective of their context.
thus, we believe that these approaches are mostlyable to detect grooming attempts that use speciﬁcwords, for instance those with a sexual connotation.
a bert-style transformer model on the other handmay be able to better distinguish whether the over-all context in which words are used is a groomingcontext and identify attempts that use more indirectlanguage such as innuendo..6 discussion.
we discuss several issues that must be consideredbefore planning to apply an algorithm like the onespresented in this work in practice..6.1 language in (non-)grooming chatsa critical question is how representative panc isof real grooming chats.
chiang and grant (2019,p. 693) and schneevogt et al.
(2018), suggest thatthe pj chats created by adult decoy volunteers in-stead of actual child victims (see section 2.1) maynot truly represent real grooming chats.
speciﬁ-cally, they found that they are missing themes offorceful persuasion or extortion of victims, whichis present in real grooming chats.
furthermore,youth language changes very fast over the years;as our corpus is from 2012, it is questionable howwell it would represent current chats.
for instance,it does not contain any emojis.
another issue isthe lack of deep relationships in our non-groomingchats.
among those, the only chats with personalor intimate conversations are from omegle.
this isa platform that invites cybersex, for example, butusers do not have a strong personal relationshipas they randomly meet (only) online.
an exampleof how the lack of such chats might lead to falsepositives is shown in appendix c..figure 5: our bert models vs. sota on vtpanclassifying 10%, 20%,.
.
.
of characters of segments.
plotted lines represent the mean results of three runsand the shaded regions represent standard deviation..to measuring accuracy at the segment level, andwe cannot provide concrete estimates on warningaccuracy for such chats.
however, we consider ourresults on negative segments to be promising..6.3 segment versus window classiﬁcationour tier-1 classiﬁers are trained on segments ofa chat, created by a speciﬁc partitioning of the se-quence of messages.
however, during espd we ap-ply them to windows of the last 50 messages, whichmay exhibit different properties than the predeﬁnedsegments.
for instance, as segments are separatedby lengthy breaks in the conversation, they oftenbegin with greetings – which is not the case forour windows.
such differences may confuse ourmodels and lead to sequences of wrong windowclassiﬁcations, an effect we counteract through thetier-2 classiﬁer..6.4 use of additional informationwhile we consider only chat messages as infor-mation to detect grooming attempts, real-worldapplications might also have additional data avail-able.
for instance, in social media, users are oftenrequired to state their age when they create theirproﬁle.
such data could be very helpful for espd.
however, we caution that proﬁle information maynot be reliable as it is typically not veriﬁed andtherefore easy to fake – and it is common for preda-tors to use fake information..7 related work.
6.2 lack of complete negative chatsdue to the lack of publicly available datasets, wecould not test our models on complete negativechats.
this has implications: we had to resort.
online grooming is a real and pressing problemfaced by any chat system open to children.
accord-ingly, social media sites and games often use au-tomated grooming detection systems (bowles and.
49920.60.70.80.910.10.20.30.40.50.60.70.80.91percentage of charactersf1bert-largebert-basemobilebertpastor ĺopez-monroy et al.
(2018)escalante et al.
(2017)keller, 2019).
for example, youtube applies nlpto detect predatory messages in video commentsand livestream chats followed by human veriﬁca-tion (iicsa and canegallo, 2019, p. 63, ll.
10–25).
microsoft uses a similar approach for xbox liveand skype chat [6] and also licenses their softwareto other service providers free of charge (patel,2020).
their obvious advantage over academic re-search is the access to much larger datasets.
how-ever, these solutions are server-based and cannotbe applied for end-to-end encrypted chats.
manyparents also resort to using parental control apps,some of which send children’s chats to externalservers for analysis, which is a privacy concern.
because of these reasons, there is a need for espdsystems even on mobile devices..in academia, espd so far has seen comparablylittle research despite its high societal importance,probably due to the difﬁculties of obtaining appro-priate datasets.
villatoro-tello et al.
(2012) wasthe winning team of the ﬁrst problem of the pan12competition, which was the identiﬁcation of thepredatory authors of the pan12 segments.
they ap-proached the problem by ﬁrst predicting segmentsas grooming or not and then distinguishing victimfrom predator.
this two-step method was reﬁnedby cardei and rebedea (2017) who additionallyused behavioral features, such as the number ofquestions asked, achieving an f0.5 of 0.934 for seg-ment classiﬁcation on a subset of pan12test.
boursand kulsrud (2019) studied the same problem andincluded an analysis of early segment classiﬁcation,i.e., an attempt to ﬁnd predators early within a seg-ment.
they explored their method also by applyingit to 10 full-length pj chats, which could be seenas the ﬁrst instance of espd we are aware of..early text classiﬁcation.
to our knowledge, es-calante et al.
(2016) was the ﬁrst work to approachspd from an early text classiﬁcation perspective,but restricted their analysis to the segment level.
their results were improved in escalante et al.
(2017) using proﬁle-based representations, wheredocuments are represented as normalized sumsof vector representations of words.
the best re-sults so far for early segment classiﬁcation wereachieved by pastor ´lopez-monroy et al.
(2018) us-ing a multi-resolution representation (mulr) fordocuments to cope equally well with longer andshorter segments.
we compared to the results ofthe latter two works in section 5.2 and found thatour approach outperforms both.
note that we are.
not aware of any previous work employing trans-formers for spd.
early time series classiﬁcation.
an interestingperspective on our tier 2 is that it actually solves anearly time series classiﬁcation (etsc) problem, forwhich there exist several mature approaches, e.g.
teaser (sch¨afer and leser, 2020) or ects (xinget al., 2012).
however, there exists a key differencethat prevents us from using such methods directly:an espd system never classiﬁes a chat as non-grooming as long as there are still messages left(or expected), while an etsc system at some stagemight decide that it is safe to stop controlling thechat (loyola et al., 2018).
this opens the doorto malicious attacks by using long and harmlessopenings in grooming attempts.
we neverthelessbelieve exploring ways to adapt etsc to espd tobe an interesting avenue for future research..8 conclusion.
we deﬁned the problem of early sexual predatordetection (espd) in online chats and proposed anevaluation setup for this task.
to this end, we as-sembled the panc dataset, which, albeit havingclear limitations, in our mind is the currently besteffort possible with the data available.
we alsoshowed that a baseline built on current bert-basedlanguage models achieves strong results on thisdataset, and beats previous methods in related set-tings.
notably, results are only modestly impactedfor models that can run on mobile devices.
we dis-cussed open issues in our data and evaluation setupthat must be studied carefully in future work beforeespd systems could go live (and expand on thisdiscussion in appendix d).
we hope that makingour task setup accessible to the research commu-nity will encourage more research into the highlyimportant topic of early sexual predator detection..acknowledgmentswe would like to thank dr. hugo jair escalanteand dr. esa´u villatoro-tello for providing us withvtpan and allowing us to publish the means torecreate it, as well as professor april edwards forproviding us with c c 2. we thank the institute ofsexology and sexual medicine at charit´e – uni-versit¨atsmedizin berlin for introducing us to theproblem of online grooming and the need for au-tomatic solutions, and fruitful discussions.
finally,we thank the tensorflow lite support team andspeciﬁcally chen cen for creating a workaroundthat enables our bert models to work on mobile..4993ethics statement.
early sexual predator detection is a highly sensitivetopic which calls for a proper discussion of poten-tial implications of such research, the datasets be-ing used, and the readiness of espd models.
thereare potentially high stakes for any subject whosechats are analyzed by espd systems.
any applica-tion of espd in running chat systems would incurinteraction with vulnerable populations (minors)which must be ﬁrmly protected.
false-negative, aswell as false-positive predictions, may have severeimplications for the falsely alleged chat partner orthe erroneously unprotected child, respectively.
on-line grooming is forbidden by law in many coun-tries, as are the establishment of sexual relation-ships of any kind to children.
in many countries,including germany, already obtaining logs of chatcontent with sexual content involving children isforbidden, which makes acquisition or usage ofreal data impossible outside criminal investigations.
at the same time, online grooming does happennow, and in many instances, making research intoways to prevent or at least diminish it important.
datasets.
for this study, we did not create anynew data or perform any experiments with humanbeings.
according to european regulations, suchresearch does not require an ethics vote from aninstitutional review board.
instead, we performedspeciﬁc ﬁltering and combination of data from thetwo datasets pan12 and chatcoder2 (c c 2), whichare available on request to their authors, and havebeen extensively used in the literature..the creators of pan12 anonymized the data byremoving usernames and email addresses to avoidthe identiﬁcation of users.
this makes pan12 com-patible with european regulations that permit theexchange of carefully anonymized data.
the c c 2chats stem from pj and are with offenders whowere prosecuted in court and adult decoys posingas children.
thus, they contain no conversationswith minors or victims, which makes c c 2 compat-ible with the above-mentioned regulations againstpossession and usage of any real chat logs involv-ing sexual content with children.
readiness of espd models.
real-world applica-tions already use automatic systems to support de-tection of grooming in chats (patel, 2020; bowlesand keller, 2019), yet no details about their mea-sured performance and internal functioning areknown to us.
however, we do not consider the mod-els and methods presented in this paper as ready for.
production systems.
we already discussed someof their technical limitations in section 6. on topof these, we believe that any espd system must becarefully adapted to any concrete chat system andcontinuously retrained and monitored to be able topick up speciﬁc styles of communication and howthey change over time.
additionally, any systemapplying espd must take an ethically highly difﬁ-cult decision regarding the trade-off between thetwo immanent desiderata for espd systems: theearliness of warnings and their accuracy.
perfectlyachieving both, i.e., performing only correct classi-ﬁcations after the very ﬁrst message, is impossible.
in this research paper, we studied the impact of ourskepticism factor which controls this trade-off.
theconcrete setting of this (or a similar) parameter ina real application must depend on an independentand careful assessment of consequences of falsepositive and false negative alarms.
this decisionmust take the respective circumstances into accountand requires an application-speciﬁc ethical assess-ment of its own, including options of monitoring byhuman professionals as discussed in appendix d..references.
alan akbik, tanja bergmann, duncan blythe, kashifrasul, stefan schweter, and roland vollgraf.
2019.flair: an easy-to-use framework for state-of-the-art nlp.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics (demonstrations), pages54–59, minneapolis, minnesota.
association forcomputational linguistics..amparo cano basave, miriam fern´andez, and harithalani.
2014. detecting child grooming behaviourpatterns on social media.
in sociinfo 2014: the 6thinternational conference on social informatics..dasha bogdanova, paolo rosso, and thamar solorio.
2014. exploring high-level features for detecting cy-berpedophilia.
computer speech and language..patrick bours and halvor kulsrud.
2019. detectionof cyber grooming in online conversation.
2019ieee international workshop on information foren-sics and security, wifs 2019, pages 9–12..nellie bowles and michael h. keller.
2019. videogames and online chats are ’hunting grounds‘for sexual predators.
the new york times,nytimes.com/interactive/2019/12/07/us/video-games-child-sex-abuse.html.
(accessed on 2020/07/15)..claudia cardei and traian rebedea.
2017. detectingsexual predators in chats using behavioral features.
4994and imbalanced learning.
natural language engi-neering, 23(4):589–616..yun gyung cheong, alaina k. jensen, elin rut gud-nadottir, byung chull bae, and julian togelius.
2015. detecting predatory behavior in game chats.
ieee transactions on computational intelligenceand ai in games, 7(3):220–232..emily chiang and tim grant.
2019. deceptive identityperformance: offender moves and multiple identi-ties in online child abuse conversations.
applied lin-guistics, 40(4):675–698..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training ofdeep bidirectional transformers for language un-derstanding.
arxiv preprint arxiv:1810.04805..jesse dodge, gabriel ilharco, roy schwartz, alifarhadi, hannaneh hajishirzi, and noah smith.
2020. fine-tuning pretrained language models:weight initializations, data orders, and early stop-ping.
arxiv preprint arxiv:2002.06305..mohammadreza ebrahimi, ching y. suen, and olgaormandjieva.
2016. detecting predatory conversa-tions in social media by deep convolutional neuralnetworks.
digital investigation..hugo jair escalante, manuel montes y gomez, luisvillasenor, and marcelo luis errecalde.
2016. earlytext classiﬁcation: a na¨ıve solution.
proceedings ofnaacl-hlt 2016, 7th workshop on computationalapproaches to subjectivity, sentiment and social me-dia analysis, pages 91–99..hugo jair escalante, esa´u villatoro-tello, sara e.garza, a. pastor l´opez-monroy, manuel montes-yg´omez, and luis villase˜nor-pineda.
2017. earlydetection of deception and aggressiveness usingproﬁle-based representations.
expert systems withapplications, 89:99–111..aditi gupta, ponnurangam kumaraguru, and ashishsureka.
2012. characterizing pedophile conversa-tions on the internet using online grooming.
arxivpreprint arxiv:1208.4324..iicsa and kristie canegallo.
2019..iicsa inquiry -.
internet hearing.
iicsa.org.uk/key-documents/11479/view/open-session-transcript-16-may-2019.pdf.
availableplqrdhiqfcnwfqrxe4piak4pntewn16imr..video transcripts are alsoyoutube.com/playlist?list=.
at.
giacomo inches and fabio crestani.
2012. overviewof the international sexual predator identiﬁcationcompetition at pan-2012.
in clef (online work-ing notes/labs/workshop), volume 30..diederik p. kingma and jimmy lei ba.
2015. adam:3rd inter-a method for stochastic optimization.
national conference on learning representations,iclr 2015 - conference track proceedings, pages1–15..david e. losada, fabio crestani, and javier parapar.
2019. overview of erisk 2019 early risk predic-tion on the internet.
in lecture notes in computerscience (including subseries lecture notes in artiﬁ-cial intelligence and lecture notes in bioinformat-ics)..david e. losada, fabio crestani, and javier parapar.
2020. overview of erisk 2020: early risk pre-diction on the internet (extended overview).
lec-ture notes in computer science (including subserieslecture notes in artiﬁcial intelligence and lecturenotes in bioinformatics), 12260 lncs:272–287..juan mart´ın loyola, marcelo luis errecalde, hugo jairescalante, and manuel montes y gomez.
2018.learning when to classify for early text classiﬁca-tion.
communications in computer and informationscience, 790:24–34..india mcghee, jennifer bayzick, april kontostathis,lynne edwards, alexandra mcbride, and emmajakubowski.
2011. learning to identify internet sex-international journal of electronicual predation.
commerce..mike mcguire and samantha dowling.
2013. cy-ber crime: a review ofukhome ofﬁce, home ofﬁce research report 75.gov.uk/government/publications/cyber-crime-a-review-of-the-evidence..the evidence..maxime meyer.
2015. machine learning to detect on-line grooming.
master’s thesis, uppsala universitet..loreen n. olson, joy l. daggs, barbara l. ellevold,and teddy k.k.
rogers.
2007.entrapping theinnocent: toward a theory of child sexual preda-tors’ luring communication.
communication the-ory, 17(3):231–251..a. pastor ´lopez-monroy, fabio a. gon´zalez, manuelmontes-y- ´gomez, hugo jair escalante, and thamarsolorio.
2018. early text classiﬁcation using multi-resolution concept representations.
in naacl hlt2018 - 2018 conference of the north americanchapter of the association for computational lin-guistics: human language technologies - proceed-ings of the conference..priti patel.
2020. new ai technique to block online.
child grooming launched.
gov.uk/government/news/new-ai-technique-to-block-online-child-grooming-launched.
(accessed on 2020/07/19)..farig sadeque, dongfang xu, and steven bethard.
2018. measuring the latency of depression detectionin social media.
wsdm 2018 - proceedings of the11th acm international conference on web searchand data mining, 2018-febua:495–503..patrick sch¨afer and ulf leser.
2020. teaser: earlyand accurate time series classiﬁcation.
data miningand knowledge discovery..4995daniela schneevogt, emily chiang, and timothygrant.
2018. do perverted justice chat logs containexamples of overt persuasion and sexual extortion?
a research note responding to chiang and grant(2017, 2018).
language and law = linguagem edireito, 5(1):97–102..[6] microsoft shares new technique to address onlinegrooming of children for sexual purposes - mi-crosoft on the issuesblogs.microsoft.com/on-the-issues/2020/01/09/artemis-online-grooming-detection/.
zhiqing sun, hongkun yu, xiaodan song, renjieliu, yiming yang, and denny zhou.
2020. mo-bilebert: task-agnostic compression of bert byarxiv preprintprogressive knowledge transfer.
arxiv:2004.02984..esa´u villatoro-tello, antonio.
ju´arez-gonz´alez,hugo jair escalante, manuel montes-y g´omez,and luis villase˜nor-pineda.
2012. a two-stepapproach for effective detection of misbehavingusers in chats - notebook for pan at clef 2012.clef (notebook papers/labs/workshop)..sebastian wachs, karsten d wolf, and ching-chingpan.
2012. cybergrooming:risk factors, copingstrategies and associations with cyberbullying.
psi-cothema, 24(4):628–33..zhengzheng xing, jian pei, and philip s. yu.
2012.early classiﬁcation on time series.
knowledge andinformation systems..links.
[7] pan is a series of scientiﬁc events and shared tasks.
on digital text forensics and stylometry.
pan.webis.de.
[8] text classiﬁcation with tensorflow lite model.
makertensorflow.org/lite/tutorials/model_maker_text_classification.
[9] ﬂairnlp/ﬂair: a very simple framework for state-of-the-art natural language processing (nlp)github.com/flairnlp/flair.
[10] perverted justice foundation homepage.
perverted-justice.com.
[11] omegle: talk to strangers!.
omegle.com.
[12] pan12 deception detection: sexual predator.
identiﬁcation — zenodozenodo.org/record/3713280.
[1] instagram most recorded platform used in childgrooming crimes during lockdown — nspccnspcc.org.uk/about-us/news-opinion/2020/instagram-grooming-crimes-children-lockdown/.
[13] chatcoder data page.
chatcoder.com/data.html.
[14] cybertipline.
missingkids.org/gethelpnow/cybertipline.
[15] facebook encryption plans will hit ﬁght against.
child abuse, warns pateltheguardian.com/society/2021/apr/19/priti-patel-says-tech-companies-have-moral-duty-to-safeguard-children.
all accessed june 1, 2021..[2] bka – pks tabellen – thematische gliederung –pks 2020 bund – falltabellen; t05 grundtabelle- straftaten mit tatmittel ,,internet” – fallentwick-lung (v1.0); see “einwirken auf kinder § 176abs.
4 nr.
3 und 4 stgb”bka.de/de/aktuelleinformationen/statistikenlagebilder/polizeilichekriminalstatistik/pks2020/pkstabellen/bundfalltabellen/bundfalltabellen.html.
[3] full log of the chat gjk1352 from pj..perverted-justice.com/?archive=gjk1352.
[4] full log of the chat bloodlineofhate from.
pj.
perverted-justice.com/?archive=bloodlineofhate.
[5] full log of the chat ich bin der eggman 67.from pj.
perverted-justice.com/?archive=ich_bin_der_eggman_67.
4996appendix.
a models and training.
the parameters for our bert models can be foundin table 3. the hyperparameters we used for ﬁne-tuning our bert models are listed in table 4. weﬁne-tuned the models on a high-end compute serverwhich has an nvidia tesla v100 gpu with 32gbof ram, an intel xeon 6254 processor, and 756gbof ram..b speciﬁc evaluation results for.
comparison with sota.
table 5 gives the speciﬁc f1 scores for the evalua-tion in section 5.2..c examples of grooming chats withoutpredatory language that are classiﬁedas predatory.
next to cybersex chats, an important possibilityfor false-positive warnings in practice are chatsbetween lovers.
such chats are most likely veryrare among the negative pan12 segments, whichwe use for panc.
in figure 6, we can see twoexcerpts from positive chats for which sbert-largeraises warnings.
in our opinion, out of context, theexcerpts could just as well occur in a regular chatbetween lovers, so they should not be classiﬁed asgrooming by themselves.
this is an example of afeature that is discriminative in our datasets but notin reality..d further discussion: scenarios forapplications of espd systems.
we see two main operational modes in which espdsystems as presented in this paper could be de-ployed.
chats may either be analyzed centrally,i.e.
at the messenger’s server, or decentrally, i.e.
at the chat clients.
these modes lead to very dif-ferent situations regarding the earliness/accuracytrade-off.
server-side systems.
in most systems, chats arestored on a server of the chat provider.
this enablesa hybrid setup that combines automatic predictionswith manual veriﬁcation by experts: espd sys-tems would be used to ﬂag suspicious chats at scalewhich are then referred to trained professionals.
only if professionals agree, proper actions wouldbe taken, like stopping the chat, notifying certainpersons, referring to appropriate institutions like.
the cybertipline [14], or informing the police.
such a hybrid approach reduces the danger of falsealarms.
for example, youtube handles live-streamchats with such an approach, as stated in iicsaand canegallo (2019, p. 63, ll.
10–25)..however, even in a hybrid setup, we encounterethical questions regarding the trade-off betweenearliness and accuracy of warnings.
if the espdsystem prioritizes earliness and thus raises manywarnings, it might result in a ﬂood of warningsthat can quickly overwhelm moderators.
moreover,mass moderation of user chats could raise privacyconcerns.
on the other hand, if the system priori-tizes accuracy, this may lead to a failure to preventsexual assaults of minors.
finding the speciﬁc bal-ance for a given application requires careful ethicalconsiderations whose reasoning should be madetransparent to the users, and in case of minors es-pecially to the parents.
to use a messaging appli-cation, users should have to give informed consentto the system-speciﬁc regulations, the modes ofcontrol and moderation, and the potential risks ofthe implemented strategies..client-side systems.
as many messaging (andchatting) systems are moving toward end-to-endencryption [15], the previously described mode ofcentralized application of espd becomes increas-ingly infeasible, as neither moderators nor softwareare able to decrypt the chats once they left the de-vice of the chatting persons.
in this case, espdsystems can only be deployed on the chat client,which is in most cases a smartphone.
they couldbe installed separately from the client, or be alreadyintegrated into the client.
the latter could result inwarnings being created both at the side of the childand at the side of the potential predator; both casesmust be analyzed carefully.
note that during instal-lation, the software is not able to control whether itis being installed on the smartphone of an adult orof a minor..on the child side, systems could be conﬁguredto (1) send alerts to the parents of the minor, (2)directly alerting the minor, or (3) both.
option (2)is beneﬁcial for the privacy of the minor, but placesa higher responsibility on them to adequately dealwith warnings.
a grooming alert would have tobe communicated very carefully to not be trauma-tizing.
in all of the above cases, children couldalso mistakenly assume that the espd system isa bullet-proof “safety net” that allows them to beless careful when chatting online.
a missing alert.
4997model.
version max-seq.
l h a params.
mobile model size (quantized).
inference latency (mobile).
uncasedbertlargeuncasedbertbasemobile bert uncased.
512512512.
24 1024 1612 768 12424 128.
✗336 m110 m ✓25 m ✓.
1,300 mb.
419 mb (106 mb)95 mb (25 mb).
20 ms.2,700 ms (5,410 ms)800 ms (1,907 ms).
table 3: overview of the bert models we used for our tier-1 classiﬁers.
the models have l layers, hidden sizeh and a attention heads.
inference latency shows the average desktop/mobile inference latency.
for b ertbaseand mobile b ert, we ran the converted tensorflow lite models on desktop/mobile, which is still experimentaland not well optimized yet.
the mobile inference latencies are for the quantized versions of the models which weran on a sony xperia xz1 compact which has an octa-core cpu (4x2.45 ghz kryo & 4x1.9 ghz kryo)..hyperparameter.
value.
optimizerloss functionepochsmini batch sizeinitial learning rate.
adam (kingma and ba, 2015)crossentropy3163 · 10.
−5 for bertlarge, else 5 · 10.
−3.
table 4: overview of training hyperparameters.
overall, client-side systems thus face challengesin how and to whom to raise warnings.
warningsshould on the one hand be disruptive enough to betaken seriously by the user while at the other handclearly communicating that a warning is only anestimation and therefore does not establish guilt.
users might also be given the option to disablealerts for certain contacts whom they trust to re-duce the number of false alerts.
for systems thatraise warnings to a minor’s parents, it would beimportant to include clear messaging to the parentthat espd systems are not perfect and may bothraise false warnings as well as miss actual groom-ing attempts.
the parent should be clearly advisedthat an espd system offers only partial protectionand that it is still important to teach their childrenhow to identify a dangerous chat themselves..e supplementary material.
our evaluation setup, dataset preprocessing code,trained models, and chat visualization soft-ware can be found at early-sexual-predator-detection.gitlab.io.
we are not allowed to dis-tribute the pan12 and c c 2 datasets which are avail-able on request to the respective dataset’s originalauthors (see [12, 13])..could be interpreted as that a chat is safe, no matterwhat is being communicated, which would actu-ally reduce the safety of the child.
options (1) and(3) create greater safety for the minor, but at therisk that parents are sometimes falsely warned insituations where no online grooming takes place,which could quickly result in psychologically deli-cate situations.
parents are not trained profession-als, as moderators are, which increases the chancesof misunderstanding warnings.
one can imaginethat uninformed and very cautious parents call thepolice in any case of a warning without any fur-ther checks, which in case of false alarms wouldlead to wrong allegations, psychological stress, andsocietal stigma on part of the accused..we should further consider that a predator coulduse an espd system and monitor its assessment ofthe ongoing chat to anticipate warnings.
this couldsignal the predator to change wording and languageto circumvent detection.
one could even imaginesystems where the predator can check if sendinga speciﬁc message would trigger a warning (byrunning a second, parallel yet faked chat).
whilemessages by the victim could also trigger warnings,the predator could still use the method to makedetection much less likely, and possibly to learnhow to use language to elude the system.
in anycase, to avoid predators ﬁnding ways to circumventdetection, the speciﬁc espd system used by theapplication should not be made available separately.
users should also not be able to see the current“risk level” of a chat or to control the sensitivity ofwarnings..4998approach.
10% of characters.
20% of characters.
30% of characters.
40% of characters.
50% of characters.
bertlargebertbasemobile bertpastor ´lopez-monroy et al.
(2018)escalante et al.
(2017).
0.7916 (± 0.0574 )0.7457 (± 0.0551 )0.6285 (± 0.0854 )0.71150.6710.
0.8908 (± 0.0261 )0.8558 (± 0.0275 )0.7923 (± 0.0389 )0.84000.7697.
0.9230 (± 0.0168 )0.8969 (± 0.0162 )0.8492 (± 0.0283 )0.88560.8169.
0.9408 (± 0.0135 )0.9284 (± 0.0082 )0.8860 (± 0.0187 )0.91660.8500.
0.9515 (± 0.0098 )0.9421 (± 0.0056 )0.9064 (± 0.0148 )0.94110.8603.approach.
60% of characters.
70% of characters.
80% of characters.
90% of characters.
100% of characters.
bertlargebertbasemobile bertpastor ´lopez-monroy et al.
(2018)escalante et al.
(2017).
0.9596 (± 0.0085 )0.9507 (± 0.0057 )0.9167 (± 0.0120 )0.94920.8721.
0.9660 (± 0.0035 )0.9598 (± 0.0049 )0.9311 (± 0.0092 )0.95310.8814.
0.9696 (± 0.0044 )0.9657 (± 0.0026 )0.9379 (± 0.0097 )0.96500.8916.
0.9754 (± 0.0034 )0.9716 (± 0.0033 )0.9448 (± 0.0091 )0.97160.9025.
0.9796 (± 0.0027 )0.9794 (± 0.0014 )0.9527 (± 0.0091 )0.97430.9121.table 5: speciﬁc f1 scores as mean and standard deviation for the evaluation in section 5.2.
(a) chat excerpt.
original source [4].
(b) chat excerpt.
original source [5].
figure 6: excerpts from full-length grooming chats with predictions by sbert-large (for the messages in the respec-tive excerpt only)..4999