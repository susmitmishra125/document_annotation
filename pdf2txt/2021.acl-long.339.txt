neural stylistic response generation with disentangled latent variables.
qingfu zhu(cid:93), weinan zhang(cid:93)∗, ting liu(cid:93), william yang wang(cid:91)(cid:93)harbin institute of technology, harbin, china(cid:91)university of california, santa barbara, usa{qfzhu, wnzhang, tliu}@ir.hit.edu.cnwilliam@cs.ucsb.edu.
abstract.
generating open-domain conversationalre-sponses in the desired style usually suffersfrom the lack of parallel data in the style.
meanwhile, using monolingual stylistic datato increase style intensity often leads to theexpense of decreasing content relevance.
inthis paper, we propose to disentangle thecontent and style in latent space by dilutingsentence-level information in style representa-tions.
combining the desired style representa-tion and a response content representation willthen obtain a stylistic response.
our approachachieves a higher bert-based style intensityscore and comparable bleu scores, comparedwith baselines.
human evaluation results showthat our approach signiﬁcantly improves styleintensity and maintains content relevance..figure 1: an example of responses generated by s2s,s2s+lm (niu and bansal, 2018), style fusion (gaoet al., 2019b), and our approach, targeting the holmesstyle, which is quite formal and polite..1.introduction.
linguistic style is an essential aspect of natural lan-guage interaction and provides particular ways ofusing language to engage with the audiences (kab-bara and cheung, 2016).
in human-bot conversa-tions, it is crucial to generate stylistic responsesfor increasing user engagement to conversationalsystems (gan et al., 2017).
currently, most ofthe existing parallel datasets are not stylisticallyconsistent.
samples in these datasets are usuallycontributed by a variety of users, resulting in anaveraging effect across style characteristics (zhanget al., 2018a).
meanwhile, constructing a paral-lel stylistic dataset for training the open-domainconversational agents is both labor-intensive andtime-consuming..recent studies show the effect of stylizingresponses using a monolingual dataset in thedesired style and a conventional conversationaldataset (niu and bansal, 2018; gao et al., 2019b).
however, increasing style intensity often leads to.
∗corresponding author..the expense of decreasing content relevance be-tween dialogue history and response.
as an ex-ample in figure 1 shows, niu and bansal (2018)independently train a response generation modeland a stylistic language model and subsequently in-terpolates them in the inference phase.
lacking theinteraction between the stylistic language modeland response generation encoder, it usually yieldsa trade-off between style intensity and content rele-vance.
gao et al.
(2019a,b) fuse a structured latentspace where the direction denotes the diversity, andthe distance denotes style intensity and content rel-evance.
the main issue is that style intensity andcontent relevance are contradictory in measurementbut are coupling to the same “distance” metric ofthe latent space.
to sum up, the key issue of theabove studies is the improper entanglement of styleand content..to address the issue, we propose to disentanglethe style and content of a response.
the disentan-glement is conducted on the structured latent space,where each sentence (dialogue history, response,.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4391–4401august1–6,2021.©2021associationforcomputationallinguistics4391dialogue history:a:hello,thisis<name>apartmentoffice,whatcanidoforyou?b:iwanttorentanapartment.a:doyouwantthewholeleaseorasharedlease?contentrelevancestyle intensitys2s:i just want to rent a room.stylefusion:i hope i can share.ours:i should prefer having a partner to being alone.
s2s+lm:my friend had a considerable share in clearing the matter up.
and stylistic sentence) is projected into a vector rep-resentation.
we further split the representation intotwo components: style and content representations.
the former is a corpus-level feature since sentenceswithin a dataset have the same style.
in contrast, thecontent representation is a sentence-level featuredecided by a sentence itself.
we thus disentan-gle the content and style by diluting sentence-levelinformation in the style representation.
this en-courages the encoding of content information intothe content representation.
otherwise, the contentinformation will be corrupted in the style represen-tation, making it hard to reconstruct the originalcontent in the subsequent decoding process.
weconduct experiments on dailydialogue conversa-tional dataset (li et al., 2017) and holmes mono-lingual stylistic dataset (gao et al., 2019b).
exper-imental results show that our proposed approachimproves style intensity and maintains content rel-evance.
our contributions are listed below:.
• we propose a uniﬁed framework to simulta-neously improve style intensity and maintaincontent relevance for neural stylistic responsegeneration..• we introduce a scheme of learning latent vari-ables by a diluting strategy to disentangle thestyle and content..• experimental results show that our approachachieves higher performance in style intensitywithout decreasing content relevance, com-pared with previous approaches..2 method.
2.1 task deﬁnition.
the task of stylistic response generation is deﬁnedas follows: given a monolingual stylistic datasets = {s1, ..., sn }1 and a conversational datasetc = {(x1, y1), ..., (xm , ym )}, where si, xi,and yi denote a stylistic sentence, dialogue his-tory, and a response respectively, the goal is tolearn a generation model p ( ˆy |x), where ˆy isa generated response expected to be in the styleof s (called the desired style in the following sec-tions).
we will ﬁrst brieﬂy review the concept ofstructured latent space and then introduce our dis-entanglement approach..1throughout the paper, we use bold letters to denote vec-.
tors, i.e., v = {v1, v2, ..., vn }..figure 2: an example of a dialogue in the structuredlatent space.
the center point corresponds to the di-alogue history representation zs2s(xi).
the k-th re-sponse representation zae(y ki ) (denoted by a blackpoint) is optimized to be distributed around zs2s(xi).
the red point zae(sj) and the purple point z( ˆyi) arerepresentations of a monolingual stylistic sentence anda stylistic response, respectively..2.2 background: structured latent space.
overview the structured latent space is con-structed by two main mechanisms: (i) sharing adecoder between a sequence-to-sequence (s2s)model and an auto-encoder (ae), and (ii) fusionand smoothness objectives.
as an example in fig-ure 2 shows, a response representation zae(yi)is regularized by the two mechanisms to be dis-tributed around its dialogue history representationzs2s(xi).
the notations zae(·) and zs2s(·) de-note the representations computed by ae encoderand s2s encoder, respectively.
such a latent spacemakes it possible to predict a response ˆy by sam-pling nearby the dialogue history representation.
based on that, gao et al.
(2019b) further alignstylistic sentence representations into the latentspace, which improves the style intensity of gener-ated responses.
in summary, the construction of thestructred latent space is a process of aligning thethree spaces (zs2s(xi), zae(yi), and zae(sj))by two mechanisms (sharing the decoder, and fu-sion and smoothness objectives)..fusion objectivecross-aligns sentences of dif-ferent spaces.
since xi and yi are paired, we alignthem by minimizing their pair-wise dissimilarity:.
dconv =.
(cid:88).
de(zs2s(xi), zae(yi))√.
,.
(1).
i∈batch.
n.l.where de denotes the euclidean distance, n is thebatch size, and l is the dimensionality of the latentspace.
in contrast, the pair-wise dissimilarity can-.
4392^12zs2s(xi)zae(yi)zae(yi)z(yi)zae(sj)structured latent spacexi : we are going hiking this weekend.
do you want to join us?yi : yes, of course.yi : i don’t like hiking.yi : i would like to join.sj : thanks for your help.
i would like to book.12^not be applied to stylistic sentences since they arenot paired with conversational data.
to this end,the fusion objective instead optimizes the nearestneighbor distance between the two datasets:.
dstyle =.
dcrossnn ({zs2s(xi)}, {zae(sj)}).
+.
dcrossnn ({zae(sj)}, {zs2s(xi)}),.
(2).
1212.where dcrossnn ({ai}, {bj}) denotes the batch averagedistance between ai and its nearest neighbor in theset {bj}.
to further encourage the representationsspread-out the latent space, a inner-distance loss isintroduced:.
dspread-out = min{dinnernn (zs2s(xi)),dinnernn (zae(yi)),dinnernn (zae(sj))},.
(3).
where dinnernn ({ai}) denotes the batch average dis-tance between ai and its nearest neighbor in the set{ai}.
the ﬁnal fusion objective is deﬁned as:.
lfuse = dconv + dstyle − dspread-out..(4).
smoothness objectiveaims to make the struc-tured latent space a continuous space, where eachpoint can decode a natural sentence.
given threediscrete points zs2s(xi), zae(yi), and zae(sj),the objective encourages points in the area betweenzs2s(xi) and zae(yi) to generate yi:.
zconv = u zs2s(xi) + (1 − u )zae(yi) + (cid:15),lsmooth,conv = − log p (yi|zconv),.
(5).
where (cid:15) ∼ n (0, σ2i), and u ∼ u (0, 1).
mean-while, as a point moves from zae(yi) to zae(sj),the corresponding generation is expected to gradu-ally move from yi to sj:.
zstyle = u zae(yi) + (1 − u )zae(sj) + (cid:15)lsmooth,style = −u log p (yi|zstyle)− (1 − u ) log p (sj|zstyle)..(6).
the smoothness objective lsmooth is the sum oflsmooth,conv and lsmooth,style, and is added to theﬁnal loss function along with the fusion objectiveand response generation loss of s2s..2.3 our method.
we conjecture this is due to the coupling of the styleand the content in sentence representations.
to thisend, we propose to disentangle the two aspects inthe structured latent space..in our proposed approach, a sentence represen-tation z ∈ rl in the latent space consists of twocomponents: content representation zc ∈ rlc andstyle representation zs ∈ rls, where l is the di-mensionality of latent space and lc + ls = l. zsencodes all the style information of a sentence.
itis a corpus-level feature because zs for differentsentences in the same corpus should be similar.
in contrast, zc can be seen as a sentence-levelfeature which only decided by the content of itscorresponding sentence..(cid:80).
j∈batch zs.
figure 3 shows an example of our approach,where zc and zs can be seen as two “contain-ers”.
colored squares represent the content andstyle information.
we encourage the disentan-glement of the two types of information by di-luting sentence-level content information in zs.
as an example in figure 3 (a) shows, the contentand style information may be mixed in both zcand zs.
during the decoding process of a sen-tence, i.e., yi, we replace its style representationzsae(yi) with its batch average style representation¯zsae(yi) = 1ae(yj).
in this way, itsnsentence-level content information will be dilutedsince it greatly varies from other sentences’ contentinformation, which introduces extra noise.
in con-trast, its corpus-level style information, which issimilar to that of other sentences within the batch,will remain unaffected.
as the training processes,the content information will be encouraged to beencoded into zc where it can remain unchanged,as an example in figure 3 (b) shows.
otherwise,the content information will be corrupted in zs,making it hard to recover the content of yi.
as aresult, the encoding process will be punished bythe response generation loss of s2s and the recon-struction loss of ae, as shown in figure 3 (a)..based on that, we update the response genera-tion process by replacing its style representationzs with the corresponding batch average style rep-resentation ¯zs:.
ls2s = − log p (yi|[zc.
s2s(xi) : ¯zs.
s2s(xi)]),.
(7).
despite aligning monolingual stylistic sentencesinto the structured latent space helps stylize gener-ated responses, their style intensity is still limited..where the bracket [:] denotes concatenation.
thedecoding process in the smoothness objective isupdated similarly.
note that when we move from.
4393figure 3: an example of disentangling content and style.
the purple block is the content information of theﬁrst sentence.
the yellow block is the content information of the second sentence.
style information in both twosentences is denoted by red blocks as it is a corpus-level feature shared among samples within the corpus.
(a): anegative example whose content and style information is mixed in zc and zs.
its content information is corruptedafter averaging zs within the batch and fails to recover the input content.
(b): a positive example.
contentinformation in zc and style information in zs will not be affected after averaging zs..yi to sj, and from xi to yi, we only interpolatetheir content representations zc in the latent space:.
zczc.
conv = u zcstyle = u zc.
s2s(xi) + (1 − u )zcae(yi) + (1 − u )zc.
ae(yi) + (cid:15),ae(sj) + (cid:15)..(8).
the batch average style representation ¯zs remainsconsistent with the target, i.e., being ¯zsae(sj)when the target is sj.
the updated smoothnessobjective is as follows:.
lsmooth,conv = − log p (yi|[zclsmooth,style = −u log p (yi|[zc− (1 − u ) log p (sj|[zc.
conv : ¯zs.
style : ¯zs.
ae(yi)]),ae(yi)])ae(sj)]).
(9).
style : ¯zs.
the ﬁnal training loss is the sum of the responsegeneration loss, fusion objective, and smoothnessobjective:.
l =ls2s + lfuse + lsmooth..(10).
here, we do not employ pre-training models, i.e.,dialogpt (zhang et al., 2020b) and openaigpt2 (radford et al., 2019).
this is because thedisentanglement is usually conducted on a sentencerepresentation.
while most of the pre-training mod-els depend on the attention mechanism, and thereis no static global sentence representation duringthe decoding process..inference.
2.4to generate a stylistic response ˆyi given dialoguehistory xi during the inference process, we ﬁrst.
obtain zcs2s(xi) by s2s encoder and subsequentlysample zc( ˆyi) from the hypersphere of zcs2s(xi)with a mannually tuned radius r. after that, we gen-erate ˆyi by concatenating zc( ˆyi) and ¯zsae(sj),which is the batch average style representation ofrandomly sampled stylistic sentences..considering the discrepancy between trainingand inference that content and style representationsin different corpora have never been concatenatedfor generation, we propose a soft combination ap-proach to introduce the desired style by interpolat-ing zsae(sj):s2s(xi) + α ∗ ¯zs.
s2s(xi) and ¯zssoft = zszs.
ae(sj),.
(11).
where α is the weight of the desired style.
afterthat, ˆyi is generated by the decoder whose hiddenstate is set to [zc( ˆyi) : zs.
soft].
to further balance style intensity and contentrelevance, we also employ the re-ranking strategyfollowing gao et al.
(2019b).
it samples ny candi-date responses and re-ranks them by:.
sr = γ ∗ ps2s( ˆyi|xi) + (1 − γ) ∗ pstyle( ˆyi), (12).
where ps2s( ˆyi|xi) is the generation probabil-ity under a s2s model measuring the relevance.
pstyle( ˆyi) is the probability that ˆyi has the desiredstyle.
it is a interpolation between the probabilitiesof a neural-based classiﬁer and a n-gram classiﬁer:.
pstyle( ˆyi) =η ∗ pneural( ˆyi) + (1 − η).
∗.
n(cid:88).
n=1.
wn ∗ pn-gram( ˆyi),.
(13).
4394content information of sentence #1 (s1)content information of sentence #2 (s2)style informationcontent representation zcstyle representation zss1: could you please tell me how i can go job-hunting in the web?encodings1: could you please tell me how i can go job-hunting in the web?encodingaverage style representationaverage style representationdecodingdecodings1: could you please tell mehow i can put my bags?s1: could you please tell me how i can go job-hunting in the web?
(cid:1)(cid:2)(cid:1)(cid:3)(cid:2)(cid:1)(cid:4)(cid:2)s2: sorry, sir, where shall i put my bags?s2: sorry, sir, where shall i put my bags?s2: sorry, sir, where shall i put my bags?s2:sorry,how i can put my bags?
training dialoguesvalidation dialoguestest dialoguesaverage tokens per dialogueaverage tokens per utterance.
11,1181,0001,000114.714.6.model.
time (s).
# of parameters.
s2sstyle fusionours.
4.554.604.60.
63m75m75m.
table 1: statistics of the dailydialog dataset..table 2: the average running time (in seconds perbatch) and the number of parameters..where wn is a weight which is set to the accuracyof the corresponding classiﬁer..3 experiments.
3.1 data.
conversational dataset we employ dailydia-log2 (li et al., 2017) as our conversational datasetc. it is a human-written multi-turn dataset cover-ing various topics of daily life.
table 1 shows somestatistics of its training, validation, and test set.
wesplit dialogue of k utterances into k-1 samples.
each sample consists of at most three continuousutterances.
the last utterance of a sample is re-garded as the response.
the previous utterancesof the response are concatenated as its dialoguehistory.
here, reddit dataset is not employed asgao et al.
(2019b) because the post-reply formatdata collected from social networks is noisy anddifferent from real conversations (li et al., 2017)..monolingual stylistic dataset following gaoet al.
(2019b), we use holmes3 as the stylisticdataset s. it is collected from the sherlock holmesnovel series and consists of roughly 38k sentences.
we do not use the arxiv dataset as it contains toomany special tokens, i.e., equations, and incom-plete sentences, such as “is concerned” and “ex-actly identical restrictions”..3.2 baselines.
we compare the proposed approach with the fol-lowing baselines:.
• style fusion, a multi-task learning basedmodel whose latent space fuses dialogue his-tory, responses, and stylistic sentences with aspeciﬁc structure (gao et al., 2019b)..note that we do not consider the label-fine-tuning model and polite reinforcement learningmodel (niu and bansal, 2018), because they requiresome training samples in the conversational datasetto have the desired style (gao et al., 2019b)..3.3 experiment settings.
we implement the proposed approach based on thereleased code of style fusion model4.
the vocab-ulary table consists of the most frequent 20,000words.
s2s encoder, ae encoder, and the shareddecoder are two-layer lstms.
the number of theirhidden units is 1000, which is also the size of thestructured latent space.
the dimension of zc andzs is 950 and 50, respectively.
the maximumlength is set to 90 for the dialogue history and 30for the response..during the training process, we use the adamoptimizer, whose learning rate is 0.0003. σ2 forsampling (cid:15) in equation 8 is 0.12. table 2 showsthe average running time on a single titan x(pascal) gpu.
during the inference process, theweights γ and η for re-ranking are set to 0.5. theweight (accuracy) of n-gram classiﬁer is 0.93, 0.87,0.77, and 0.65 for n from 1 to 4. the number ofcandidate responses, ny, is set to 10. the radius ris set to 3..• s2s, the sequence-to-sequence response gen-.
eration model (shang et al., 2015)..4 results.
4.1 evaluation metrics.
• s2s+lm, a s2s trained on c and a stylisticlanguage model trained on s (niu and bansal,2018).
during the inference process, it gener-ates a stylistic response by interpolating out-puts of the two models..2http://yanran.li/dailydialog3https://github.com/golsun/stylefusion.
automatic evaluation considering that it is un-fair to evaluate a response by the classiﬁers that areused for selecting the response (song et al., 2020),we ﬁne-tune a bert (devlin et al., 2019) to mea-sure style intensity.
concretely, positive samplesare the stylistic sentences.
negative samples are.
4https://github.com/golsun/stylefusion.
4395model.
si(%) dist-1 dist-2 bleu-3 bleu-4 mean.
s2s (shang et al., 2015)s2s+lm (niu and bansal, 2018)style fusion (gao et al., 2019b).
ours (α=0.25)ours (α=0.50)ours (α=0.75).
6.3232.7910.58.
11.9120.6734.85.
0.0350.0150.043.
0.0410.0400.038.
0.2270.0860.280.
0.2750.2750.285.
0.700.550.82.
0.790.640.47.
0.200.080.22.
0.230.170.10.
0.100.130.14.
0.160.190.16.table 3: automatic evaluation results of si, dist-1, dist-2, and bleu.
the last column is the harmonic mean ofsi and bleu-4 measuring the overall performance of style intensity and content relevance..content relevance.
style intensity.
win.
40.2165.0043.32.lose.
39.7920.0042.67.win.
lose.
49.3753.3048.77.
36.8432.5036.68.vs. s2svs. s2s+lmvs. style fusion.
table 4: pair-wise human evaluation results of contentrelevance and style intensity..figure 4: the trade-off between style intensity mea-sured by si and content relevance measured by bleu-4. the x-axis corresponds to α. the harmonic meanachieves the maximum around α=0.5..better (ties are also permitted)..4.2 results.
randomly selected from dailydialog’s responses,which are of the same amount of sentences as thepositive samples.
given the ﬁne-tuned bert clas-siﬁer (whose accuracy achieves 0.96 on the vali-dation set), we report the average probability ofresponses being positive as a measurement of thestyle intensity.
for brevity, we denote this metricas si.
the content relevance is evaluated by bleu.
since it may correlate weakly with human judg-ments of quality in a single reference setting (liuet al., 2016), we employ the expanded responses inmulti-reference dailydialog test set (gupta et al.,2019) as references to alleviate the problem.
mean-while, we evaluate the diversity by dist-k (li et al.,2016), which is the number of distinct k-grams nor-malized by the total number of words of responses..human evaluation we randomly sample 200messages from the test set of c to conduct the hu-man evaluation from two aspects: style intensityand content relevance.
each aspect is indepen-dently evaluated by ﬁve amazon mechanical turk(amt)5 workers whose approval rate is greaterthan 95%, and the number of approved is greaterthan 500. given dialogue history and two responsesgenerated by a baseline and our approach, the work-ers are asked to give a preference of which one is.
5https://www.mturk.com.
figure 4 shows the trade-off between style intensityand content relevance in our approach.
there isan improvement in si and a decrease in bleuassociated with the increase of α in equation 11.to assess the overall performance, we also computetheir harmonic mean, whose maximum lies aroundα = 0.5. we thus conduct the human evaluationand analysis in this parameter setting..we report the human evaluation results in ta-ble 4. our approach is clearly preferred in styleintensity because the percentage of win is signiﬁ-cantly higher than that of lose (p <0.001, t-test).
in terms of content relevance, the ratios of winin “vs.
s2s” and “vs.
style fusion” are similarto those of lose.
this suggests that our approachcan signiﬁcantly improve the style intensity with-out decreasing the content relevance.
in contrast,s2s+lm loses in most of the cases in the contentrelevance.
following zhou et al.
(2018) and keet al.
(2018), we evaluate the agreement of anno-tators via inter-rater consistency.
the percentageof samples that at least three annotators have thesame preference (3/5 agreement) is 81.80%.
andthe percentage for 4/5 agreement is 32.15%..table 3 shows the results of the automatic eval-uation.
our approach has the highest mean score,which indicates that it achieves the best overall per-formance.
s2s+lm has a high si score, but itsbleu scores are not as good as others, i.e., s2s..439600.10.20.30.400.250.50.75sibleu-4meansi bleu-3.
bleu-4 mean.
[z c : z s].
z s.full model-disentangle-lfuse-lsmooth.
11.717.526.466.02.
0.670.680.590.63.
0.170.170.150.17.
0.140.110.090.09.table 5: results of the ablation study..style fusionours.
0.830.88.
0.72 (-13.02%)0.86 (-1.71%).
table 6: style classiﬁcation accuracy of the full latentvariable ([zc : zs]) and zs..can achieve a good content relevance performancebut fails to stylize a response.
by removing thedisentanglement component, our approach degener-ates into style fusion.
in this case, the si score de-creases signiﬁcantly while bleu scores are nearlyunchanged, which demonstrates the disentangle-ment could improve the style intensity and maintainthe relevance at the same time.
the decreases in siafter removing the fusion objective and smoothnessobjective are more signiﬁcant than that after remov-ing the disentanglement.
this is because the twoobjectives are bottom components for constructingthe structured latent space, where our approach andstyle fusion are built upon..4.4 analysis.
in this section, we analyze whether style informa-tion is disentangled into zs.
to achieve this goal,we train style classiﬁers taking as input a latentvariable and use the validation accuracy as an indi-cator.
taking our approach as an instance, we ﬁrstfreeze the parameters of our well-trained model.
then we independently learn two style classiﬁerswhose inputs are the full latent variable ([zc : zs])and zs respectively.
note that zc and zs in stylefusion are a simple partition of its latent variable.
there are not any disentanglement approaches ap-plied to obtain the two representations.
as shownin table 6, style fusion achieves 0.83 validationaccuracy training on its full latent variable.
and theaccuracy decreases by 13.02% when the classiﬁca-tion is only based on zs.
in contrast, the decreaseof our approach is only 1.71%, indicating that mostof the style information is disentangled into zs..we show a visualization of the disentanglementof the latent variable by mds (borg and groe-nen, 2005) in figure 5. each ﬁgure consists ofzs (black) and three continuous sub-sequences ex-tracted from the head (yellow), middle (red), andtail (blue) of zc.
the sub-sequences are of thesame length with zs.
for both stylistic and con-versational samples, all the sub-sequences and zsare mixed in style fusion.
in contrast, there is aclear separation between zs and the sub-sequences.
figure 5: mds visualization of zs (black) and threecontinuous sub-sequences extracted from the head (yel-low), middle (red), and tail (blue) of zc..this is in line with our human evaluation resultsand niu and bansal (2018)’s observation that bias-ing a decoder with a stylistic language model mayharm the content relevance.
in contrast, our ap-proach (α = 0.25) signiﬁcantly outperforms s2sand is comparable to style fusion.
by increasingα to 0.5, the bleu score drops slightly but is com-parable to baselines (evidenced by the human eval-uation results).
meanwhile, there is a signiﬁcantimprovement (up to 95.37%) in si comparing withstyle fusion.
this veriﬁes the effectiveness of ourdisentanglement approach in improving the styleintensity and maintaining the content relevance.
besides, the dist-k results in table 3 also indicatethat the diversity of our approach is comparable tothe best-performed style fusion..4.3 ablation study.
we conduct ablation studies to investigate the con-tributions of the fusion objective, smoothness ob-jective, and our disentanglement approach.
to fo-cus on their effects on the generation process, inthis section, we sample a single response withoutusing the re-ranking strategy (equation 12)..table 5 shows the results of the ablation study.
there is a signiﬁcant decline in si and a slightchange in bleu-3 and bleu-4 after removingeach component.
this indicates that a multi-tasklearning architecture without the three components.
4397style fusionoursstylisticsamplesconversational samplesdialoguehistory.
– yes , after my graduation,.
i worked in a trade companyin macao for one year..– what section did you work in?
– the export business section..s2s.
– have you received any other.
s2s+lm.
– did you ever ﬁnd a job that you.
honors?.
did not?.
style fusionours.
– what was your major in?
– i ’m glad that you have been.
doing great..dialoguehistory.
– i will always have you comein for a discussion if there isa major problem..– will i be able to read the resultson the website and understandthem?.
– yes, if you go there, you cansee what each test is about..s2s.
– ok, i will ask the manager.
to take care of that..s2s+lm.
– i’m not sure i’ll have you to.
do that,.
style fusionours.
– what are my parents for me?
– i am looking forward to gettingthe information about that..table 7: an example of responses generated by base-lines and our approach..in our approach.
this is because most of thestyle information is disentangled into zs in ourapproach, making its distribution different fromsub-sequences of zc..4.5 case study.
table 7 shows some examples of generated re-sponses.
there is no signiﬁcant holmes style inresponses of s2s.
similarly, the style intensity ofresponses in style fusion is also limited.
the se-mantics of s2s+lm’s response in the ﬁrst exampleis not very clear, making it less relevant to the di-alogue history than other responses.
we believethis is also due to the lack of interaction betweenthe response generation encoder and the stylisticlanguage model.
in contrast, our approach not onlyachieves a good content relevance performance butalso has a signiﬁcant holmes style, which is quitepolite and formal..and subsequently combine the content with the de-sired style.
the disentanglement can be achievedby adversarial learning (shen et al., 2017; huet al., 2017; fu et al., 2018; yang et al., 2018; lo-geswaran et al., 2018), reinforcement learning (jainet al., 2019), back-translation (prabhumoye et al.,2018; nogueira dos santos et al., 2018), multi-tasklearning (john et al., 2019), and removing stylisticphrases (li et al., 2018; xu et al., 2018; zhanget al., 2018b).
the other way transfers the stylewithout disentangled representations, for exampleusing generator-evaluator architecture (gong et al.,2019), cycle reconstruction (dai et al., 2019), pa-rameter sharing (wang et al., 2020), and data aug-mentation (zhang et al., 2020a)..the main difference between our task and textstyle transfer lies in two aspects.
first, all the con-tent to be generated is available in the input in textstyle transfer, while our task needs to create new(response) content.
and the key is content rele-vance to the dialogue history, rather than contentpreservation of the input.
second, the data for textstyle transfer is isomorphic.
data in different stylesare in the same free-text format.
however, our con-versational data are context-response pairs whilethe stylistic data are free-texts, which is heteroge-neous and requires more sophisticated structures,i.e., the structured latent space (gao et al., 2019b)..5.2 stylistic response generation without.
parallel stylistic data.
niu and bansal(2018) propose three weak-supervised models based on reinforcement learn-ing, conditional text generation, and languagemodel.
gao et al.
(2019b) fuses the latent spacesof a response generation model and a stylistic auto-encoder to improve the style intensity of sampledresponses.
yang et al.
(2020) inject the style infor-mation by introducing a word-level kl loss anda sentence-level style classiﬁer to the ﬁne-turningprocess of dialogpt (zhang et al., 2020b).
dis-tinct from previous work, we explicitly disentanglethe style and content in the latent space and employa uniﬁed architecture to jointly optimize the styleintensity and content relevance..5 related work.
6 conclusion.
5.1 text style transfer without parallel data.
the task of text style transfer aims at transferringthe style of a sentence while preserving its mean-ing.
one way is to disentangle the content and style,.
we propose a uniform framework to simultaneouslyimprove the style intensity and maintain the contentrelevance for neural stylistic response generation.
in contrast to existing approaches, our approach.
4398disentangles the style and the content in the latentspace by a diluting strategy.
experiments showthat our approach improves the style intensity ofgenerated responses and maintains the content rel-evance at the same time, which demonstrates theeffectiveness of this approach..acknowledgments.
the authors would like to thank all the anonymousreviewers for their insightful comments.
the au-thors from hit are supported by the national nat-ural science foundation of china (no.
62076081,no.
61772153, and no.
61936010) and scienceand technology innovation 2030 major projectof china (no.
2020aaa0108605).
the authorfrom ucsb is not supported by any of the projectsabove..ethical statement.
this paper honors the acl code of ethics.
stylis-tic response generation intends to improve the en-gagement of a dialogue system in human-bot con-versations.
it responds to users with the desiredstyle, i.e., being polite, humorous, or romantic,rather than imitating any speciﬁc person.
mean-while, style is a linguistic aspect of natural lan-guage interaction.
there is not any identity charac-teristic being used as a variable..references.
ingwer borg and patrick jf groenen.
2005. modernmultidimensional scaling: theory and applications.
springer science & business media..ning dai, jianze liang, xipeng qiu, and xuanjinghuang.
2019.style transformer: unpaired textstyle transfer without disentangled latent represen-in proceedings of the 57th annual meet-tation.
ing of the association for computational linguistics,pages 5997–6007..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..zhenxin fu, xiaoye tan, nanyun peng, dongyan zhao,and rui yan.
2018. style transfer in text: explo-ration and evaluation.
in thirty-second aaai con-ference on artiﬁcial intelligence..chuang gan, zhe gan, xiaodong he, jianfeng gao,and li deng.
2017. stylenet: generating attractivevisual captions with styles.
in proceedings of cvpr,pages 955–964.
ieee..xiang gao, sungjin lee, yizhe zhang, chris brockett,michel galley, jianfeng gao, and bill dolan.
2019a.
jointly optimizing diversity and relevance in neuralin proceedings of the 2019response generation.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 1 (long and shortpapers), pages 1229–1238, minneapolis, minnesota.
association for computational linguistics..xiang gao, yizhe zhang, sungjin lee, michel gal-ley, chris brockett, jianfeng gao, and bill dolan.
2019b.
structuring latent spaces for stylized re-sponse generation.
in proceedings of the 2019 con-ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 1814–1823, hong kong, china.
as-sociation for computational linguistics..hongyu gong, suma bhat, lingfei wu, jinjun xiong,and wen-mei hwu.
2019. reinforcement learningbased text style transfer without parallel training cor-pus.
in proceedings of the 2019 conference of thenorth american chapter of the association for com-putational linguistics: human language technolo-gies, volume 1, pages 3168–3180..prakhar gupta, shikib mehri, tiancheng zhao, amypavel, maxine eskenazi, and jeffrey bigham.
2019.investigating evaluation of open-domain dialoguesystems with human generated multiple references.
in proceedings of the 20th annual sigdial meetingon discourse and dialogue, pages 379–391, stock-holm, sweden.
association for computational lin-guistics..zhiting hu, zichao yang, xiaodan liang, ruslansalakhutdinov, and eric p xing.
2017. towardin proceedingscontrolled generation of text.
of the 34th international conference on machinelearning-volume 70, pages 1587–1596.
jmlr.
org..parag jain, abhijit mishra, amar prakash azad, andkarthik sankaranarayanan.
2019. unsupervisedin proceedings ofcontrollable text formalization.
the aaai conference on artiﬁcial intelligence, vol-ume 33, pages 6554–6561..vineet john, lili mou, hareesh bahuleyan, and olgavechtomova.
2019. disentangled representationlearning for non-parallel text style transfer.
in pro-ceedings of the 57th annual meeting of the associa-tion for computational linguistics, pages 424–434..jad kabbara and jackie chi kit cheung.
2016. stylis-tic transfer in natural language generation systemsin proceedingsusing recurrent neural networks.
of the workshop on uphill battles in languageprocessing: scaling early achievements to robustmethods, pages 43–47..4399pei ke, jian guan, minlie huang, and xiaoyan zhu.
2018. generating informative responses with con-in proceedings of thetrolled sentence function.
56th annual meeting of the association for compu-tational linguistics (volume 1), pages 1499–1508..jiwei li, michel galley, chris brockett, jianfeng gao,and bill dolan.
2016. a diversity-promoting objec-tive function for neural conversation models.
in pro-ceedings of the 2016 conference of the north amer-ican chapter of the association for computationallinguistics: human language technologies, pages110–119..juncen li, robin jia, he he, and percy liang.
2018.delete, retrieve, generate: a simple approach to sen-timent and style transfer.
in proceedings of the 2018conference of the north american chapter of theassociation for computational linguistics,volume 1,pages 1865–1874..yanran li, hui su, xiaoyu shen, wenjie li, ziqiangcao, and shuzi niu.
2017. dailydialog: a manuallylabelled multi-turn dialogue dataset.
in proceedingsof the eighth international joint conference on nat-ural language processing (volume 1: long papers),pages 986–995..chia-wei liu, ryan lowe, iulian serban, mike nose-worthy, laurent charlin, and joelle pineau.
2016.how not to evaluate your dialogue system: anempirical study of unsupervised evaluation metricsfor dialogue response generation.
in proceedings ofthe 2016 conference on empirical methods in natu-ral language processing, pages 2122–2132, austin,texas.
association for computational linguistics..lajanugen logeswaran, honglak lee, and samy ben-gio.
2018. content preserving text generation within advances in neural informa-attribute controls.
tion processing systems, pages 5103–5113..tong niu and mohit bansal.
2018. polite dialogue gen-eration without parallel data.
transactions of the as-sociation for computational linguistics, 6:373–389..shrimai prabhumoye, yulia tsvetkov, ruslan salakhut-style transferdinov, and alan w black.
2018.in proceedings of thethrough back-translation.
56th annual meeting of the association for compu-tational linguistics (volume 1), pages 866–876..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners..cicero nogueira dos santos, igor melnyk, and inkitpadhi.
2018. fighting offensive language on so-cial media with unsupervised text style transfer.
inproceedings of the 56th annual meeting of the as-sociation for computational linguistics (volume 2),pages 189–194, melbourne, australia..lifeng shang, zhengdong lu, and hang li.
2015. neu-ral responding machine for short-text conversation.
in proceedings of the 53rd annual meeting of the.
association for computational linguistics and the7th international joint conference on natural lan-guage processing (volume 1), pages 1577–1586..tianxiao shen, tao lei, regina barzilay, and tommijaakkola.
2017. style transfer from non-parallel textby cross-alignment.
in advances in neural informa-tion processing systems, pages 6830–6841..haoyu song, wei-nan zhang, jingwen hu, and tingliu.
2020. generating persona consistent dialoguesby exploiting natural language inference.
proceed-ings of the aaai conference on artiﬁcial intelli-gence, 34(05):8878–8885..yunli wang, yu wu, lili mou, zhoujun li, and wen-han chao.
2020.formality style transfer withshared latent space.
in proceedings of the 28th inter-national conference on computational linguistics,pages 2236–2249..jingjing xu, xu sun, qi zeng, xiaodong zhang, xu-ancheng ren, houfeng wang, and wenjie li.
2018.unpaired sentiment-to-sentiment translation: a cy-in proceed-cled reinforcement learning approach.
ings of the 56th annual meeting of the associationfor computational linguistics, volume 1, pages 979–988..ze yang, wei wu, can xu, xinnian liang, jiaqibai, liran wang, wei wang, and zhoujun li.
2020.styledgpt: stylized response generation with pre-trained language models.
in findings of the associ-ation for computational linguistics: emnlp 2020,pages 1548–1559, online.
association for computa-tional linguistics..zichao yang, zhiting hu, chris dyer, eric p xing, andtaylor berg-kirkpatrick.
2018. unsupervised textstyle transfer using language models as discrimina-tors.
in advances in neural information processingsystems, pages 7287–7298..ye zhang, nan ding, and radu soricut.
2018a.
shaped: shared-private encoder-decoder for textin proceedings of the 2018 con-style adaptation.
ference of the north american chapter of the asso-ciation for computational linguistics: human lan-guage technologies, volume 1, pages 1528–1538..yi zhang, tao ge, and xu sun.
2020a.
parallel datain pro-augmentation for formality style transfer.
ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 3221–3228, online.
association for computational lin-guistics..yi zhang, jingjing xu, pengcheng yang, and xu sun.
2018b.
learning sentiment memories for sentimentmodiﬁcation without parallel data.
in proceedingsof the 2018 conference on empirical methods innatural language processing, pages 1103–1108..yizhe zhang, siqi sun, michel galley, yen-chun chen,chris brockett, xiang gao, jianfeng gao, jingjing.
4400liu, and bill dolan.
2020b.
dialogpt : large-scale generative pre-training for conversational re-in proceedings of the 58th an-sponse generation.
nual meeting of the association for computationallinguistics: system demonstrations, pages 270–278, online.
association for computational linguis-tics..hao zhou, tom young, minlie huang, haizhou zhao,jingfang xu, and xiaoyan zhu.
2018.com-monsense knowledge aware conversation generationin the 27th internationalwith graph attention.
joint conference on artiﬁcial intelligence and the23rd european conference on artiﬁcial intelligence,pages 4623–4629..4401