align voting behavior with public statements forlegislator representation learningxinyi mou1, zhongyu wei1,2∗, lei chen1, shangyi ning1,yancheng he3, changjian jiang4∗, xuanjing huang51school of data science, fudan university, china2research institute of intelligent and complex systems, fudan university, china3platform and content group, tencent, china4school of international relations & public affairs, fudan university, china5school of computer science, fudan university, china{xymou20,zywei,chenl18,syning18}@fudan.edu.cncollinhe@tencent.com, {changjian,xjhuang}@fudan.edu.cn.
abstract.
ideology of legislators is typically estimatedby ideal point models from historical recordsof votes.
it represents legislators and legis-lation as points in a latent space and showspromising results for modeling voting behav-ior.
however, it fails to capture more speciﬁcattitudes of legislators toward emerging issuesand is unable to model newly-elected legisla-tors without voting histories.
in order to miti-gate these two problems, we explore to incor-porate both voting behavior and public state-ments on twitter to jointly model legislators.
in addition, we propose a novel task, namelyhashtag usage prediction to model the ideol-ogy of legislators on twitter.
in practice, weconstruct a heterogeneous graph for the leg-islative context and use relational graph neuralnetworks to learn the representation of legisla-tors with the guidance of historical records oftheir voting and hashtag usage.
experiment re-sults indicate that our model yields signiﬁcantimprovements for the task of roll call vote pre-diction.
further analysis further demonstratesthat legislator representation we learned cap-tures nuances in statements..1.introduction.
modeling the behavior of legislators is one of themost important topics of quantitative political sci-ence.
existing researches largely rely on roll calldata, i.e.
historical voting records, to estimatethe political preference of legislators.
the mostwidely used approach for roll call data analysis isideal point model (clinton et al., 2004) that rep-resents legislators and legislation as points in aone-dimension latent space.
researchers enhanceideal point model by incorporating textual infor-mation of legislation (gerrish and blei, 2011; gu.
∗corresponding author..figure 1: an illustration of correspondence of vote be-havior and public statements on twitter.
supporters ofthe abortion-banning legislation frequently mention thetag life while opponents focus on choice..et al., 2014; kraft et al., 2016) and report positiveresults for roll call vote prediction..although roll call data is the major resource forlegislator behavior modeling, it has two limitations.
firstly, it fails to uncover detailed opinions of legis-lators towards legislative issues.
therefore, wehave no clue about the motivation behind theirvoting.
secondly, it is unable to model the be-havior of newly-elected legislators because theirhistorical voting records are not available (i.e., cold-start problem).
meanwhile, researchers explore touse public statements to characterize the ideologyof legislators with the guidance of framing the-ory (entman, 1993; chong and druckman, 2007;baumer et al., 2015; vafa et al., 2020).
vafa et al.
(2020) propose a text-based ideal point model toanalyze tweets of legislators independent of rollcall data.
experiment results show some correla-tions between distributions of ideal points learned.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1236–1246august1–6,2021.©2021associationforcomputationallinguistics1236from legislative data and public statements.
how-ever, they treat the two resources separately and failto uncover deep relationships of behavior betweenthese two landscapes..figure 1 shows a legislative issue related to pro-hibit partial-birth abortion.
it includes the titleand description of the legislation, roll call voterecords and public statements on twitter of leg-islators.
based on the voting records, we knowthe stance of legislators.
with the discussion ontwitter, we can further understand their opinionstowards the topic.
supporters concentrate on pro-tecting the life while opponents emphasize rightsof choice.
this motivates that bridging public state-ments on twitter with roll call data can provide afull image of behavior patterns of legislators..a closer look at the example (figure 1) revealsthat most tweets utilize hashtags to express ideasin short.
moreover, people with opposite stanceschoose different groups of hashtags, i.e., support-ers use #life and #theyfeelpain while opponentsuse #choice and #whatwomenwant.
further anal-ysis on a large tweets dataset, where each tweet isprocessed by a python library textblob1, showsthat most hashtags are polarized with one senti-ment (figure 2a).
based on this observation andprevious studies that reveal polarization of hash-tags (conover et al., 2011a; garimella and weber,2017), we explore to utilize hashtags as a label todescribe the preferences of legislators on public dis-cussion and propose a novel task of hashtag usageprediction to characterize their ideology..in this paper, we collect public statements of leg-islators on twitter as an extension of roll call datafor legislator representation learning.
our intuitionis to combine roll call votes as hard labels and hash-tags as soft labels to jointly model legislators.
inpractice, we build a heterogeneous graph to bridgethe voting behavior and public statements of legisla-tors.
it consists of three kinds of nodes, legislators,legislation and hashtags in tweets.
subsequently,we employ a heterogeneous relational graph con-volutional network (rgcn) (schlichtkrull et al.,2018) to simultaneously update the representationof different nodes.
two tasks are used for training,including roll call vote prediction and hashtag us-age prediction to model the behavior of legislatorson voting and on public statements respectively.
the major contributions of this paper are three-fold:.
(a).
(c).
(b).
(d).
figure 2: statistics of twitter dataset.
(a) sentimentdistribution of hashtags in legislators’ tweets.
(b) num-(c) life span of hashtags.
ber of tweets each year.
(d)distribution of length of hashtags.
- to the best of our knowledge, this is the ﬁrststudy incorporating both voting behavior andpublic statements to jointly depict legislators.
the proposed framework enables us to under-stand the preferences of legislators combiningtheir behavior in legislative process and on pub-lic platforms..- we propose to learn the representation of legis-lation and legislators using heterogeneous graphwhich can densify relations among legislators,thus mitigate the cold-start problem..- we propose a novel task of hashtag usage predic-tion to characterize the preferences of legislatorson public discussion and construct a dataset asthe benchmark.
our dataset and code is availableon github 2..2 dataset and tasks.
the voteview website (lewis et al., 2021) providesa benchmark for the task of roll call vote prediction.
it contains roll call votes history and keeps updat-ing.
meanwhile, a dataset constructed by yanget al.
(2020) enables the public to take advantageof detailed description and sponsor information oflegislation from 1993 to 2018. we extend thesecorpora with tweets published by legislators..2.1 twitter dataset.
since twitter became popular among legislatorsin the last decade, we reserve 1,198,758 roll call.
2https://github.com/xymou/align-voting-behavior-with-.
1https://github.com/sloria/textblob.
public-statements..1237figure 3: proposed framework..records after 2009, involving 906 legislators and3,210 pieces of legislation.
for dataset construc-tion, we ﬁrst extract twitter accounts of legisla-tors from their homepages on the website of u.s.congress 3. for those who have not provided twit-ter account, we manually search their names ontwitter, and identify their accounts by checkingthe veriﬁcation information and biography.
in thisway, 735 accounts of legislators are included inour extended dataset.
we crawl all tweets (beforejuly 20th, 2020) for each legislator remained viatwitterscraper 4. in addition to this, we also collecttheir following list..we show some statistics of the dataset in figure2. figure 2b presents the distribution of the amountof tweets posted by year.
it shows that legislatorspay increasing attention to twitter from year 2009to 2017. legislators post 3,071 tweets on averageand 57.82% of legislators post more than 2,000times.
in terms of hashtag, a third of tweets containat least one hashtag with 82,381 unique hashtags intotal.
figure 2c indicates that most hashtags fadeaway within three months.
figure 2d shows thedistribution of the length of hashtags, illustrating ahashtag usually consists of a few words.
in order toreduce noise, we keep hashtags with length greaterthan 2 and frequency higher than 50. after that,2,057 hashtags are reserved for graph construction.
to explore hashtag usage behavior, we construct0-1 labels indicating whether a legislator has posteda speciﬁc hashtag or not.
considering some hash-tags are not popular, we further remove thoseposted by less than 100 legislators, for hashtag.
3www.congress.gov4https://github.com/bisguzar/twitter-scraper.
usage prediction.
in this way, 194,040 labels arecreated..2.2 task formulation.
we introduce notations in this paper..- m = {m1, m2, ...} is the list of legislators,where each mi(i = 1, 2, ...) contains basic back-ground information of legislators: member id,state and party, accompanied with following liston twitter..- l = {l1, l2, ...} is the list of legislation, whereeach li(i = 1, 2, ..) contains its title and descrip-tion, as well as sponsor information and votingresults..- t = {t1, t2, ...} is the list of hashtags that havebeen mentioned by legislators on twitter.
eachof these hashtags contains information of relatedtweets and authors..note that each element (legislator, legislationor hashtag) is accompanied with the time whenit appears in the context.
we utilize these timemarkers to build our experimental environment toavoid future information leakage..we use two tasks, i.e., roll call vote predic-tion and hashtag usage prediction to characterizethe behavior of legislators in different landscapes,namely, congress and twitter.
(1) roll call voteprediction.
this task aims to predict vote resultsof legislators towards legislation with stances ofyea or nay.
(2) hashtag usage prediction.
thistask aims to predict whether a legislator will post agiven hashtag or not..12383 proposed framework.
the overall framework we proposed is shown infigure 3. we construct a heterogeneous graph withthree kinds of nodes (legislation, legislator andhashtag) to cover the two landscapes of congressand twitter.
on top of this graph, rgcn is appliedto optimize the representation.
this is achieved bya joint training of the two tasks of roll call vote pre-diction and hashtag usage prediction.
in addition,we utilize an unsupervised following proximity lossto further optimize the representation..3.1 heterogeneous graph construction.
the heterogeneous graph consists of three kindsof nodes and six types of relations with two cate-gories (relations between homogeneous nodes andrelations between heterogeneous nodes).
we willintroduce the structure of the graph in this subsec-tion..initialization of nodes.
3.1.1legislator nodes we follow yang et al.
(2020) tomap each legislator to a continuous low-dimensionvector, utilizing information of member id, stateand party.
the legislator representation is xm =eid ⊕ ep arty ⊕ estatelegislation nodes for legislation, we pay atten-tion to title and description and represent eachlegislation by sentence embedding generated bybert (devlin et al., 2019).
thus, the legis-lation representation is xl = bert (title +description)hashtag nodes to represent a hashtag, we ran-domly choose k tweets with the tag and use bertto get sentence embedding of each tweet text.
af-ter that, we take the average of these vectors,xt = avg(bert (tweeti)) i = 1, 2, ...k.3.1.2 relations between homogeneous nodesr1: co-sponsorship of legislators each legisla-tion is initialized by a sponsor and several co-sponsors.
previous study (yang et al., 2020)has proved the effectiveness of modeling co-sponsorship in legislator representation learning.
obviously, more legislation two legislators havecollaborated on means they are more alike ideolog-ically.
we follow this setup and regard the numberof legislation two legislators have co-sponsored asweight of this relation to measure strength of therelationship between congressmen.
in this way, alegislator network can be constructed and we ob-tain an adjacency matrix a, with each element aij.
representing the number of legislation mi and mjhave co-sponsored.
r2: similarity of legislation both topic modelsand embedding paradigms have been incorporatedto model legislation in previous studies.
however,the semantic relations among legislation have notbeen explicitly considered.
we explore to betterlearn legislation representation by incorporatingthese semantic relationships.
to achieve this goal,we construct a network of legislation, and use se-mantic similarity to link two legislation.
specif-ically, an adjacency matrix b is computed, witheach element bij denoting the number of commonwords in texts of legislation li and lj.
r3: co-occurrence of hashtags if two hashtagsare mentioned together frequently, it’s likely thatthey bear similar ideas, such as #dreamact and#protectdreamers.
therefore, we build a hashtagnetwork, to help hashtag nodes learn from oneswith similar ideology.
an adjacency matrix c isconstructed, with each element cij indicating thenumber of co-occurrence of hashtag ti and tj..3.1.3 relations between heterogeneous.
nodes.
r4: relation between legislator and legislationin the legislative process, each legislation isinitialized by multiple legislators.
karimi et al.
(2019) have indicated that features of the bipartitenetwork of legislators and bills are informative.
therefore, we use such sponsorship relation toconnect nodes of legislator and legislation.
anadjacency matrix d is constructed, with eachelement dij meaning whether legislator mi hassponsored legislation lj..(cid:26) 1 if mi has sponsored lj.
dij =.
0 otherwise.
r5: relation between legislator and hashtaglegislators choose hashtags to use when theypublish tweets.
therefore, we deﬁne an adjacencymatrix f to measure preferences of legislators tohashtags.
each element fij is computed as thetimes legislator mi has mentioned hashtag tj.
r6: relation between legislation and hashtaglegislation might discuss similar topics with hash-tags used in tweets.
we therefore align legislationwith hashtags by computing the semantic similaritybased on their textual information.
to achieve this,an adjacency matrix g is constructed, with eachelement gij representing the number of common.
1239words in the text of legislation li and tweets withhashtag tj..3.3 model training.
3.2 relational graph convolutional network.
after initializing representation of legislator, leg-islation and hashtag, we feed them into re-lational graph convolutional network(rgcn)(schlichtkrull et al., 2018) to update their repre-sentation based on the context.
graph convolu-tional networks (gcns) (kipf and welling, 2017)provide an efﬁcient way to perform message prop-agation and aggregation.
in the propagation phase,nodes send signals to their neighbors while in theaggregation phase, each node sums up messagesfrom its neighbors and updates its representation.
when there are only one type of relations, the layer-wise rule of gcns is:.
h (l+1) = σ.
(cid:16) ˆah (l)w (l)(cid:17).
(1).
where h (l) is hidden representation of lth layer,ˆa represents the adjusted adjacency matrix andw (l) is weight matrix shared by all edges in layerl, σ(·)represents the activation function.
for eachnode i with neighbors ni, the update rule can bedescribed as:.
h(l+1)i.
= σ.w (l)h(l)j.
.
(2).
.
.
(cid:88).
j∈ni.
1ci.
where ci represents the normalization item, whichis often set to |ni| when each neighbor has equalimportance..rgcns generalize gcns to deal with relationsof different types.
rgcns utilize different weightmatrixes and normalization factors for differentrelation types.
thus, the hidden representation foreach node i in layer (l + 1) can be computed as:.
.
.
(cid:88).
(cid:88).
r∈r.
j∈n ri.
1ci,r.
h(l+1)i.
= σ.w (l).
r h(l).
j + w (l).
0 h(l).
i.
.
(3)where r is the set of relation types, and n ri is theset of neighbors of node i connected by relationtype r. since each neighbor has different degrees ofimportance in our graph, we compute the normal-ization factor ci,r according to weights of relationswe have obtained, instead of using ci,r = |n ri |.
we apply 2-layer rgcns to capture 2nd order rela-tions between nodes empirically.
after convolution,we get representations of legislator, legislation andhashtag, denoted as rm, rl and rt..we utilize two tasks, namely roll call vote pre-diction and hashtag usage prediction to train ourmodel.
in addition, we introduce a following prox-imity loss to further measure relationships of legis-lators based on their social networks..3.3.1 roll call vote prediction.
given representation of legislators and legislation,the roll call vote prediction comes out to be a clas-siﬁcation task.
we conduct element-wise productand element-wise difference of embeddings of tar-get legislator and legislation, and concatenate themto encode the relation.
then, we feed the relationrepresentation into a feed-forward neural network(ffnn) with softmax to predict the result.
crossentropy loss is used:.
lvote = −.
ym,l,k log(fk(m, l)).
(4).
(cid:88).
m,l,k.
where ym,l,k is the kth one-hot class label of leg-islator m’s vote on legislation l and fk indicatesthe kth component of the output of activation layerσ(·)..similar to roll call vote prediction, hashtag usageprediction is modeled as a relation prediction task.
the representation of an edge is produced by em-beddings of target legislator and hashtag.
we thenfeed this representation to another ffnn with soft-max.
cross entropy loss is used:.
lhashtag = −.
ym,t,k log(gk(m, t)).
(5).
(cid:88).
m,t,k.
where ym,t,k is the kth one-hot post label of leg-islator m’s for hashtag t and gk indicates the kthcomponent of the output of activation layer σ(·)...
3.3.3 following proximity lossprevious studies (barber´a, 2015; peng et al., 2016)have proved the effectiveness of using the follow-ing relationships on twitter for political preferenceestimation, and show that users prefer to followthose with similar political positions.
in order toincorporate this factor into consideration, we in-troduce a proximity loss (hamilton et al., 2017;nguyen et al., 2020) computed from a follow-ing network of legislators.
it enables neighboringnodes to be represented more similarly and alien-ates representations of un-associated nodes.
the.
.
3.3.2 hashtag usage prediction.
1240proximity loss is formulated as follows:.
lprox = −.
(cid:88).
(cid:16).
(cid:16).
(cid:16).
log.
σ.e(cid:62)memp.
(cid:17)(cid:17).
m∈g(cid:48).
+q · emn∼pn(m) log.
(cid:16).
(cid:16).
σ.
−e(cid:62).
memn.
(cid:17)(cid:17)(cid:17).
(6)where g(cid:48) is the subgraph of legislators formedby following relationships, and em is the represen-tation of a legislator m. mp is a neighbor of m thatcan be derived using ﬁxed-length random walk,while mn is a negative sample that can be obtainedthrough negative sampling mn ∼ pn(m) (hamil-ton et al., 2017).
q controls the number of negativesamples..we form the ﬁnal loss by linearly combin-ing these three factors: ltotal = λ1lvote +λ2lhashtag + λ3lprox, where λ1, λ2 and λ3 arehyperparameters controlling the weight of differentlosses..4 experiments.
4.1 experiment setup.
dataset splits our experiment is based on datafrom the 112th to 115th congress, including bothbills and resolutions from house and senate.
weuse two conﬁgurations to form the experimentaldataset.
(1) random: we set up an in-session ex-periment environment following kornilova et al.
(2018); davoodi et al.
(2020), where records ofeach two-year session is considered as an indepen-dent experiment set.
this results in 4 experimentsets.
for each set, 20% legislation is selected fortesting, 20% is for validation and the rest is fortraining.
(2) time-based: we set up a time-basedenvironment following yang et al.
(2020).
we forman experiment set with two consecutive sessionsand use the former one for training and validationand the latter one for testing respectively.
this re-sults in 3 experiment sets.
in this setting, somelegislators might appear in the testing session only.
therefore, we report results of two settings.
formem train, we only include legislators appearingin training set for testing.
for mem all, we includeall legislators in test set..implementation details the dimensions of ini-tial legislative representations are 64, 768 and 768for legislator, legislation and hashtag respectively.
we randomly choose 50 tweets to encode each hash-tag.
when modeling relations, we set a threshold asthe mean value for each type of relations, and only.
reserve those with weights greater than the thresh-old, to eliminate noise.
we use 2-layer rgcns andthe sizes of hidden layers are 128 and 64. a batchnormalization layer is added after initializing rep-resentation.
the batch size is 128 and learning rateis 1 × 10−4.
dropout and early stopping strategiesare adopted to prevent the model from over-ﬁtting.
for hyperparameters of three losses, we simply setλ1 = λ2 = 10λ3 to control three losses within thesame order of magnitude.
for graph construction,the entity set covers all entities involved in andbefore that year while the relation set only coversinformation before that year to avoid future infor-mation leakage..models for comparison we compare our modelwith some state-of-the-art approaches..- majority is a baseline which assumes all legisla-.
tors vote yea..- ideal-point-wf (gerrish and blei, 2011): a regres-sion model that takes the word frequency of leg-islation text as features.
the training paradigmfollows the traditional ideal point model.
thus,it can only predict on legislators present in thetraining data..- ideal-point-tﬁdf : similar to ideal-point-wf, ituses tfidf of legislation text as features instead..- ideal-vector (kraft et al., 2016): it learns multi-dimensional ideal vectors for legislators based onbill texts..- cnn (kornilova et al., 2018): it uses cnn to.
encode legislation..- cnn+meta (kornilova et al., 2018): on the ba-sis of cnn, it adds percentage of sponsors ofdifferent parties as bill’s authorship information..- lstm+gcn (yang et al., 2020): it uses lstmto encode legislation and applies a gcn to updaterepresentations of legislators..- vote: the single task of roll call vote in our frame-.
work..- ours: our framework..4.2 overall performance.
we report the average accuracy of all experimentsets following kornilova et al.
(2018); yang et al.
(2020).
besides, macro f1 score is also providedfor more information.
table 1 shows the overallperformance for roll call vote prediction..1241methods.
majorityideal-point-wfideal-point-tﬁdfideal-vectorcnncnn+metalstm+gcnvoteours.
random.
time-based.
acc.
maf.
77.4885.3786.4687.3587.2888.0288.4190.2291.84.
43.6278.4880.0280.1580.3481.5982.2684.9286.73.mem trainacc.
maf43.2176.1653.3065.7254.1566.4179.7185.5478.9085.6680.4486.4080.9187.0184.7289.9085.9190.52.mem allacc.
maf43.6277.40----75.4981.9575.6881.9777.6784.3080.7385.8284.3589.7685.4590.61.table 1: overall performance of different models for roll call vote prediction.
random stands for in-session setup.
mem train reports performance on legislators appear in training set while mem all reports results on all legislatorsin test set..roll call vote prediction we have several ﬁnd-ings for results of roll call vote prediction..- our model yields the best results.
by utilizinghashtag usage information, our framework canfurther improve the performance on the basis ofthe single task vote..- neural networks based approaches perform bet-ter than ideal-point based models.
cnn+metaand lstm+gcn achieve better results than otherbaselines.
this proves that introducing back-ground information is helpful to capture generalpreferences..- all models perform worse in time-based settingcompared to random setting.
the performancedrop of ideal-point based models that incorporatetextual information is the largest.
this indicatesthat ideal-point based models have difﬁculty fortransfer learning from one session to another..- comparing the setting of mem train and memall, we ﬁnd that most methods have difﬁcultymodeling new-elected legislators.
models incor-porating background knowledge perform morestable, among which our model is the most robustone..hashtag usage prediction for hashtag usageprediction, we evaluate our model in time-basedsetting.
for comparison, we employ a simpleffnn to process initial embeddings of legisla-tors and hashtags for label prediction.
experimentresults show that our model achieves better per-formance than ffnn in terms of both accuracy(80.44% vs 80.03%) and macro f1 (61.34% vs.53.93%).
this indicates that it’s difﬁcult to pre-dict preferences on hashtags of legislators based ontextual information only.
incorporating legislativeinformation, our model achieves improvements, es-pecially for macro f1.
this also demonstrates thatlearning the voting behavior of legislators also ben-eﬁts predicting what they will say..4.3.inﬂuence of noise in hashtag set.
although most hashtags are polarized, there arestill general ones like #america and #trump .
theusage of these hashtags is not able to stand for thestance.
therefore, the set of hashtags in our datasetcontains noise.
we conduct an additional experi-ment to explore the inﬂuence of noise brought byhashtags on the task of roll call prediction.
we seta threshold to ﬁlter noise.
different thresholds in-dicate different degrees of polarization, where 0.5means using all hashtag labels in our dataset (thesetting of our model in table 1), and 0.8 representsthe ratio of major sentiment in tweets of the hash-tag must exceed 0.8. figure 4a presents the results.
the performance increases when the threshold in-creases from 0.5 to 0.7, indicating hashtags withoutﬁrm attitudes would hurt the performance.
afterthat, the performance drops because of the reduc-tion of data.
however, due to the chance of hashtaghijacking strategy where a hashtag is deliberatelytaken up and used by “the other side”(hadgu et al.,2013), noise in hashtags can not be completelyeliminated in this way..1242(a).
(c).
(b).
(d).
figure 4: further analysis on the experiment results.
(a) inﬂuence of hashtags used on the performance.
(b)cold start simulation.
(c) visualization of legislator rep-resentation without hashtag prediction.
(d) legislatorrepresentation of our model..5 further analysis.
we perform additional analysis to further evaluatethe effectiveness of our model..5.1 cold start simulation.
since our model makes use of statements on twit-ter to densify connections among legislators, wewant to explore its ability to deal with the cold startproblem.
although the settings of mem train andmem all have shown the advantage of our modelfor newly-elected legislator modeling, we set upa more general environment.
here, we randomlymask a certain ratio of legislators, that is, discardtheir historical legislative information when con-structing graph, to better investigate the model’sability to mitigate the cold start problem.
figure4b illustrates the performance of our model whenmasking different ratios of legislators in time-basedsetting.
when the ratio increases, performancestays stable and performs better than the best base-line lstm+gcn consistently (87.01% of acc.
and80.91% of maf.).
thus, taking advantage of con-tent generated by legislators, our proposed modelshows good robustness..5.2 legislator representation.
we project learned representation of legislators intoa 2d space using pca.
figure 4c shows legislatorrepresentation of 115th congress based on data of2018 learned by vote-based model, i.e., to train ourframework without hashtag information.
figure.
(a).
(b).
figure 5: comparing hashtag valence and dw-nominate dim1.
(a) house.
(b) senate..4d shows that learned by the overall framework,where democrats clearly fall into two clusters.
anexplanation can be given with a closer look at the re-lations between legislators and hashtags.
while theleft lower group behaves actively on twitter, post-ing hashtags like #trumpcare, #goptaxscam and#protectourcare for multiple times, the other grouprarely expresses their position by using these hash-tags.
while they vote similarly, this divergence cannot be captured relying only on votes.
thus, ourmethod indeed learns nuances between legislators..5.3 consistency of statement and behavior.
we follow hemphill et al.
(2013) to investigatelegislators’ overall tweeting behavior and votingbehavior by comparing hashtag usage and the ﬁrstdimension of dw-nominate (lewis and poole,2004).
we compute hashtag valence proposed byconover et al.
(2011a) and aggregate hashtags alegislator has posted to get hashtag valence forhim or her.
since dw-nominate scores are notcomparable across chambers, figure 5a and fig-ure 5b show conditions for legislators involved inthe 115th session of house and senate respectively.
the ﬁgures and correlation(r(529) = 0.80 p <0.001 for house and r(135) = 0.74 p < 0.001 forsenate) not only indicate that most legislators arepolarized similarly in tweeting and voting, but alsoagain illustrate that some legislators voting simi-larly on average can be hugely different in theirlanguages.
complex similarities and differences oflegislators like this can not be expressed by repre-sentation learned from votes or tweets separately.
besides overall leaning inference, inconsistencyat the level of individual bills is also worthy ofattention.
when predicting on 113s2223, a billfor “an increase in the federal minimum wage”,the vote-based model predicts that senator harryreid will vote nay, which is also the ground truth.
but our model wrongly predicts that he will voteyea.
we probe into his tweets and ﬁnd that he.
1243used #raisethewage frequently to call for raise inminimum wage, as those who support the bill.
onthe one hand, hashtags may have difﬁculty cap-turing more ﬁne-grained decisions, which can beinﬂuenced by various factors; on the other hand,legislators may behave differently from what theysay, since they may make certain statements to getpublic support (spell et al., 2020).
when legislatorsdo not accord their words to deed, our model maybe misled by legislators’ statements.
as it’s difﬁ-cult to ﬁnd hashtags directly and accurately relatedto a speciﬁc bill in an automatic and complete way,we will explore the frequency of inconsistency inthe future..6 related work.
ideal point estimation has become a mainstreamapproach to model ideology of legislators.
classi-cal ideal point model (clinton et al., 2004) repre-sents both legislators and legislation in the samespace, and voting behavior is characterized as thedistance between them.
however, this simple spa-tial model fails to predict votes on new legislation.
text-based models have emerged to address thisissue.
gerrish and blei (2011, 2012); gu et al.
(2014); nguyen et al.
(2015) extended ideal pointmodel with latent topics and issue-adjusted meth-ods.
some embedding methods (kraft et al., 2016)also promote learning of legislators.
more recently,external context information including party, spon-sor and donors (kornilova et al., 2018; yang et al.,2020; davoodi et al., 2020) have been introducedto better describe the legislative process..since votes are not the only way to express po-litical preferences, other sources of data includ-ing speech and knowledge graph (budhwar et al.,2018; gentzkow et al., 2019; patil et al., 2019; vafaet al., 2020) have been applied to estimate ideology.
although previous studies (bruns and highﬁeld,2013; golbeck and hansen, 2014; barber´a, 2015;peng et al., 2016; wong et al., 2016; boutylineand willer, 2017; johnson et al., 2017) have incor-porated social network of following or retweetingon twitter to learn legislators, ﬁne-grained atti-tudes of legislators remain unknown since the textsthemselves have not been mined.
until recently,preot¸iuc-pietro et al.
(2017) started to analyze lin-guistic differences between ideologically differentgroups using a broad range of handcrafted languagefeatures, and studies (vafa et al., 2020; spell et al.,2020) explored to incorporate twitter texts to cap-.
ture nuances in legislators’ preferences via statisti-cal methods.
in spite of this, there has been littleresearch attempting to combine votes with publicstatements to portray legislators from both anglesand predict their behavior..previous studies (conover et al., 2011b; small,2011; bruns and stieglitz, 2012; cohen and ruths,2013) have suggested that modeling on hashtagmetadata is an informative way to analyze tweets,yielding classiﬁcation of political afﬁliations.
sincehashtag is an important mean for people to partic-ipate in political discussion and communication,hashtag usage pattern has also been modeled asfeature vectors in many clustering tasks to helplearn different user groups (conover et al., 2011a;bode et al., 2013, 2015).
hemphill et al.
(2013)and yang et al.
(2016) have analyzed hashtag us-age patterns of different ideologies through featureselection and keyword statistics.
however, hashtagusage can be further utilized based on these anal-yses, e.g., for prediction tasks.
thus, we focus onhashtags to depict statements of legislators on twit-ter, to jointly estimate their political preferences..7 conclusions and future work.
in this paper, we take the ﬁrst step to align votingbehavior with statements on twitter to jointly learnrepresentation of legislators.
we construct a hetero-geneous graph to model the legislative context witha hashtag usage prediction task proposed to jointlytrain.
experiments demonstrate that our frameworkcan learn effective legislative representation andyield improvements for the roll call vote predictiontask.
due to the deﬁciency of background informa-tion, we have not yet detected more ﬁne-grainedstance of legislators towards speciﬁc events.
in thefuture, we aim to conduct more research on thestance modeling of legislators..acknowledgments.
this work is partially supported by nationalnatural science foundation of china (no.
71991471), science and technology commissionof shanghai municipality grant (no.20dz1200600,21qa1400600)..references.
pablo barber´a.
2015. birds of the same feather tweettogether: bayesian ideal point estimation using twit-ter data.
political analysis, 23(1):76–91..1244eric baumer, elisha elovic, ying qin, francesca pol-letta, and geri gay.
2015. testing and comparingcomputational approaches for identifying the lan-guage of framing in political news.
in proceedingsof the 2015 conference of the north american chap-ter of the association for computational linguistics:human language technologies, pages 1472–1482..maryam davoodi, eric waltenburg, and dan gold-wasser.
2020. understanding the language of polit-ical agreement and disagreement in legislative texts.
in proceedings of the 58th annual meeting of theassociation for computational linguistics, pages5358–5368, online.
association for computationallinguistics..leticia bode, alexander hanna, ben sayre, junghwanyang, and dhavan v shah.
2013. mapping the polit-ical twitterverse: finding connections between polit-ical elites..leticia bode, alexander hanna, junghwan yang, anddhavan v shah.
2015. candidate networks, citi-zen clusters, and political expression: strategic hash-tag use in the 2010 midterms.
the annals of theamerican academy of political and social science,659(1):149–165..andrei boutyline and robb willer.
2017. the socialstructure of political echo chambers: variation inideological homophily in online networks.
politicalpsychology, 38(3):551–569..axel bruns and tim highﬁeld.
2013. political net-works on twitter: tweeting the queensland stateinformation, communication & society,election.
16(5):667–691..axel bruns and stefan stieglitz.
2012. quantitative ap-proaches to comparing communication patterns ontwitter.
journal of technology in human services,30(3-4):160–185..aditya budhwar, toshihiro kuboi, alex dekhtyar, andfoaad khosmood.
2018. predicting the vote usingin proceedings of the 19th an-legislative speech.
nual international conference on digital governmentresearch: governance in the data age, pages 1–10..dennis chong and james n druckman.
2007. framing.
theory.
annu.
rev.
polit.
sci., 10:103–126..joshua clinton, simon jackman, and douglas rivers.
2004. the statistical analysis of roll call data.
amer-ican political science review, pages 355–370..raviv cohen and derek ruths.
2013. classifying polit-ical orientation on twitter: it’s not easy!
in proceed-ings of the international aaai conference on weband social media, volume 7..michael conover, jacob ratkiewicz, matthew fran-cisco, bruno gonc¸alves, filippo menczer, andalessandro flammini.
2011a.
political polarizationon twitter.
in proceedings of the international aaaiconference on web and social media, volume 5..michael d conover, bruno gonc¸alves,.
jacobratkiewicz, alessandro flammini, and filippomenczer.
2011b.
predicting the political alignmentin 2011 ieee third internationalof twitter users.
conference on privacy, security, risk and trust and2011 ieee third international conference on socialcomputing, pages 192–199.
ieee..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..robert m entman.
1993. framing: toward clariﬁca-tion of a fractured paradigm.
journal of communi-cation, 43(4):51–58..venkata rama kiran garimella and ingmar weber.
2017. a long-term analysis of polarization on twit-ter.
in proceedings of the international aaai con-ference on web and social media, volume 11..matthew gentzkow,.
jesse m shapiro, and matttaddy.
2019. measuring group differences in high-dimensional choices: method and application tocongressional speech.
econometrica, 87(4):1307–1340..sean gerrish and david blei.
2012. how they vote:issue-adjusted models of legislative behavior.
in ad-vances in neural information processing systems,volume 25, pages 2753–2761.
curran associates,inc..sean m gerrish and david m blei.
2011. predictinglegislative roll calls from text.
in proceedings of the28th international conference on machine learning,icml 2011..jennifer golbeck and derek hansen.
2014. a methodfor computing political preference among twitter fol-lowers.
social networks, 36:177–184..yupeng gu, yizhou sun, ning jiang, bingyu wang,and ting chen.
2014. topic-factorized ideal pointestimation model for legislative voting network.
inproceedings of the 20th acm sigkdd internationalconference on knowledge discovery and data min-ing, pages 183–192..asmelash teka hadgu, kiran garimella, and ingmarweber.
2013. political hashtag hijacking in the us.
in proceedings of the 22nd international conferenceon world wide web, pages 55–56..will hamilton, zhitao ying, and jure leskovec.
2017.inductive representation learning on large graphs.
inadvances in neural information processing systems,pages 1024–1034..1245libby hemphill, aron culotta, and matthew heston.
2013. framing in social media: how the us congressuses twitter hashtags to frame political issues.
ssrnelectronic journal..kristen johnson, di jin, and dan goldwasser.
2017.leveraging behavioral and social information forweakly supervised collective classiﬁcation of polit-in proceedings of theical discourse on twitter.
55th annual meeting of the association for compu-tational linguistics (volume 1: long papers), pages741–752..hamid karimi, tyler derr, aaron brookhouse, and jil-iang tang.
2019. multi-factor congressional voteprediction.
in proceedings of the 2019 ieee/acminternational conference on advances in social net-works analysis and mining, pages 266–273..thomas n. kipf and max welling.
2017..semi-supervised classiﬁcation with graph convolutionalnetworks.
in international conference on learningrepresentations (iclr)..anastassia kornilova, daniel argyle, and vladimir ei-delman.
2018. party matters: enhancing legislativeembeddings with author attributes for vote predic-tion.
in proceedings of the 56th annual meeting ofthe association for computational linguistics (vol-ume 2: short papers), pages 510–515, melbourne,australia.
association for computational linguis-tics..peter kraft, hirsh jain, and alexander m. rush.
2016.an embedding model for predicting roll-call votes.
in proceedings of the 2016 conference on empiri-cal methods in natural language processing, pages2066–2070, austin, texas.
association for compu-tational linguistics..jeffrey b. lewis, poole keith, rosenthal howard,boche adam, rudkin aaron, and sonnet luke.
2021. voteview: congressional roll-call votesdatabase..jeffrey b lewis and keith t poole.
2004. measuringbias and uncertainty in ideal point estimates via theparametric bootstrap.
political analysis, pages 105–127..van-hoang nguyen, kazunari sugiyama, preslavnakov, and min-yen kan. 2020. fang: leveragingsocial context for fake news detection using graphin proceedings of the 29th acmrepresentation.
international conference on information & knowl-edge management, pages 1165–1174..viet-an nguyen, jordan boyd-graber, philip resnik,and kristina miler.
2015. tea party in the house: ahierarchical ideal point topic model and its applica-tion to republican legislators in the 112th congress.
in proceedings of the 53rd annual meeting of theassociation for computational linguistics and the7th international joint conference on natural lan-guage processing (volume 1: long papers), pages1438–1448..pallavi patil, kriti myer, ronak zala, arpit singh,sheshera mysore, andrew mccallum, adrian ben-ton, and amanda stent.
2019. roll call vote pre-diction with knowledge augmented models.
in pro-ceedings of the 23rd conference on computationalnatural language learning (conll), pages 574–581..tai-quan peng, mengchen liu, yingcai wu, andshixia liu.
2016. follower-followee network, com-munication networks, and vote agreement of theus members of congress.
communication research,43(7):996–1024..daniel preot¸iuc-pietro, ye liu, daniel hopkins, andlyle ungar.
2017. beyond binary labels: politicalideology prediction of twitter users.
in proceedingsof the 55th annual meeting of the association forcomputational linguistics (volume 1: long papers),pages 729–740..michael schlichtkrull, thomas n kipf, peter bloem,rianne van den berg, ivan titov, and max welling.
2018. modeling relational data with graph convolu-tional networks.
in european semantic web confer-ence, pages 593–607.
springer..tamara a small.
2011. what the hashtag?
a contentanalysis of canadian politics on twitter.
information,communication & society, 14(6):872–895..gregory spell, brian guay, sunshine hillygus, andlawrence carin.
2020. an embedding model forestimating legislative preferences from the fre-quency and sentiment of tweets.
in proceedings ofthe 2020 conference on empirical methods in natu-ral language processing (emnlp), pages 627–641,online.
association for computational linguistics..keyon vafa, suresh naidu, and david blei.
2020. text-based ideal points.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 5345–5357, online.
associationfor computational linguistics..felix ming fai wong, chee wei tan, soumya sen,and mung chiang.
2016. quantifying political lean-ieeeing from tweets, retweets, and retweeters.
transactions on knowledge and data engineering,28(8):2158–2172..xinxin yang, bo-chiuan chen, mrinmoy maity, andemilio ferrara.
2016. social politics: agenda set-ting and political communication on social media.
in international conference on social informatics,pages 330–344.
springer..yuqiao yang, xiaoqiang lin, geng lin, zengfenghuang, changjian jiang, and zhongyu wei.
2020.joint representation learning of legislator and leg-in proceedings ofislation for roll call prediction.
the twenty-ninth international joint conference onartiﬁcial intelligence, ijcai-20, pages 1424–1430.
international joint conferences on artiﬁcial intelli-gence organization.
main track..1246