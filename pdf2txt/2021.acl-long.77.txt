the possible, the plausible, and the desirable:event-based modality detection for language processingshoval sadde∗valentina pyatkin∗bar ilan universitybar ilan universityshovatz@gmail.compyatkiv@biu.ac.il.
aynat rubinsteinhebrew university of jerusalemaynat.rubinstein@mail.huji.ac.il.
paul portnergeorgetown universitypaul.portner@georgetown.edu.
reut tsarfatybar ilan universityreut.tsarfaty@biu.ac.il.
abstract.
modality is the linguistic ability to describeevents with added information such as how de-sirable, plausible, or feasible they are.
modal-ity is important for many nlp downstreamtasks such as the detection of hedging, uncer-tainty, speculation, and more.
previous studiesthat address modality detection in nlp oftenrestrict modal expressions to a closed syntac-tic class, and the modal sense labels are vastlydifferent across different studies, lacking an ac-cepted standard.
furthermore, these senses areoften analyzed independently of the events thatthey modify.
this work builds on the theoreti-cal foundations of the georgetown gradablemodal expressions (gme) work by rubin-stein et al.
(2013) to propose an event-basedmodality detection task where modal expres-sions can be words of any syntactic class andsense labels are drawn from a comprehensivetaxonomy which harmonizes the modal con-cepts contributed by the different studies.
wepresent experiments on the gme corpus aim-ing to detect and classify ﬁne-grained modalconcepts and associate them with their modi-ﬁed events.
we show that detecting and clas-sifying modal expressions is not only feasi-ble, but also improves the detection of modalevents in their own right..1.introduction.
modality refers to the linguistic ability to describealternative ways the world could be.1 modal ex-pressions aim to identify wishes, rules, beliefs,or norms in texts (kratzer, 1981; portner, 2009),which is a crucial part of natural language under-standing (nlu) (morante and sporleder, 2012)..concretely, events in natural language are oftenreported in a manner that emphasizes non-actualperspectives on them, rather than their actual propo-sitional content.
consider examples (1a)–(1b):.
∗equal contribution1in formal semantics, these alternatives are referred toas possible worlds or situations (kripke, 1959; lewis, 1973;barwise and perry, 1981; kratzer, 2010)..(1).
a. we presented a paper at acl’19.
b. we did not present a paper at acl’20..the propositional content p =“present a paper atacl’x” can be easily veriﬁed for sentences (1a)-(1b) by looking up the proceedings of the confer-ence to (dis)prove the existence of the relevant pub-lication.
the same proposition p is still referred toin sentences (2a)–(2d), but now in each one, p isdescribed from a different perspective:.
(2).
a. we aim to present a paper at acl’21.
b. we want to present a paper at acl’21.
c. we ought to present a paper at acl’21.
d. we are likely to present a paper at.
acl’21..these sentences cannot be veriﬁed or falsiﬁed sim-ply by examining whether p actually came or willcome to pass, and in fact, such veriﬁcation is notthe goal of this way of reporting.
rather, speakersdescribe such events in order to indicate plans(2a), desires (2b), norms (2c), or the assessedplausibility (2d) of the associated propositionalcontent p. investigating how to classify these per-spectives on events has been the focus of exten-sive research on modality in theoretical linguistics(kratzer, 1981; palmer, 1986; portner, 2009)..in terms of nlp technology, modal concepts asexpressed in (2) are relevant to many downstreamtasks, such as the automatic detection of hedgingand speculation (vincze et al., 2008; malhotra et al.,2013), uncertainty (vincze et al., 2008; miwa et al.,2012; zerva et al., 2017; prieto et al., 2020), opin-ion (wiebe et al., 2005; rubin, 2010; miwa et al.,2012), and factuality (saurí and pustejovsky, 2009;rudinger et al., 2018).
although these tasks rely onmodality features, so far there is no accepted stan-dard for modal concepts and labels, which alignswith the semantic space of modal senses that lin-guists identify.
consequently, modality features are.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages953–965august1–6,2021.©2021associationforcomputationallinguistics953either treated idiosyncratically or are absent fromsemantic frameworks (donatelli et al., 2018, §4.6)..in support of such downstream tasks, a differenttype of nlp investigations targets modality anno-tation and detection in its own right (ruppenhoferand rehbein (2012); baker et al.
(2012); zhouet al.
(2015); marasovi´c and frank (2016); hen-drickx et al.
(2012); nissim et al.
(2013); ghia et al.
(2016); mendes et al.
(2016); lavid et al.
(2016),and others).
however, each of these studies createsits own scheme, and none of these schemes hasbeen picked up as an accepted standard by the com-munity.
moreover, different endeavors suffer fromone (or more) of the following types of deﬁciencieswith respect to their expressivity and coverage..first, many studies limit the modal triggers, i.e.,the expressions that trigger the modal meaning, toa closed class of auxiliary verbs (e.g., can, might,should, must in english (ruppenhofer and rehbein,2012; marasovi´c et al., 2016; quaresma et al.,2014)).
however, as acknowledged by linguists(kratzer, 1981) and nlp researchers (rubin, 2010;baker et al., 2012; nissim et al., 2013), wordsof any part-of-speech (pos) can trigger modal-ity.
consider, for instance, the following triggers:we should remain calm (aux); we have a plan toreduce the costs (noun); our agency prefers thisequipment (verb); marx is probably patriotic(adv); devaluation has been necessary (adj)..second, the modal senses, i.e., the labels thatindicate the modal perspectives, differ from onestudy to another, with no accepted standard.
somestudies focus only on a particular sense, such asepistemic modality (rubin, 2010; ghia et al., 2016).
others use labels that mix modal senses with or-thogonal notions (e.g., force, distinguishing permis-sion from requirement as in baker et al.
(2012)),thereby making their deployment into existing an-notations and tasks less transparent.
in general,there is no single annotation standard that coversthe full spectrum of modal senses attested in thedata and conﬁrmed by the latest linguistic theories,as portrayed by portner (2009)..finally, modality detection in nlp has oftenbeen cast as a word-sense disambiguation (wsd)task (ruppenhofer and rehbein, 2012) or as asentence-classiﬁcation task (marasovi´c and frank,2016).
both perspectives are insufﬁcient for anypractical use.
the latter is too coarse-grained, asa sentence may contain multiple events, each ofwhich potentially carries a different modal sense..the former is uninformative, because the modaltrigger is not explicitly associated with the eventbeing modiﬁed.
ghia et al.
(2016) take a step in theright direction, offering to annotate modal senseconstructions..the current work proposes to address all of theaforementioned deﬁciencies as follows.
we deﬁnea prediction task that we term event-based modalitydetection, where, given a sentence as input, we aimto return all of its modal triggers, their associatedmodal senses, and, for each trigger, the respectiveevent being modiﬁed.
crucially, the modal triggerscan be from any syntactic class.
the modal sensesare drawn from a single taxonomy that we motivatebased on linguistic research and which harmonizesthe different modal concepts contributed in previ-ous studies (§3).
finally, we propose to view modaltriggers as semantic modiﬁers of eventive headsin event-based (a.k.a., neo-davidsonian; parsons(1990)) semantics.
this is motivated by practicalconcerns – when extracting events from texts tobeneﬁt downstream tasks, one would want easy ac-cess to the features that indicate the perspective oneach event, above and beyond its participants..the accompanying annotation standard we as-sume for the task is based on the georgetown grad-able modal expressions (gme) framework (rubin-stein et al., 2013), with two simpliﬁcations that aredesigned to allow for more consistent annotationsand increased ease-of-use by non-experts.
first, wechange the modal sense labels to be intuitive andself-explanatory.
second, instead of the event span(a.k.a., prejacent) in the gme, we mark the headof the event being modiﬁed..to assess the feasibility of the proposed task, weuse the gme corpus (rubinstein et al., 2013) totrain and test the automatic detection of modal trig-gers, their senses, and associated events.
our exper-iments show that while identifying a closed set ofauxiliary verbs as modal triggers is straightforward,expanding the set of triggers to any syntactic classindeed makes it a harder task.
notwithstandingthis difﬁculty, we show that a model based on largepre-trained contextualized embeddings (liu et al.,2019) obtains substantial improvements over ourbaseline on the full task.
moreover, we show thatdetecting modalized events in fact improves withthe availability of information about the modal trig-gers.
all in all, we contribute a new task, a newstandard and a set of strong baselines for the event-based modality task we deﬁned..9542 linguistic background.
modal expressions allow language users to discussalternative realities.
for example, the sentence shecan reach the ceiling is modal because it describesthe event of her reaching the ceiling as feasible,but potentially non-actual.
similarly, she hopefullywill reach the ceiling is modal because it describessuch an event as desirable, and likewise potentiallynon-actual.
a sentence like she was reported toreach the ceiling describes the event of her reachingthe ceiling as potentially actual, according to one’sstate of knowledge, yet implying that in reality itcould have been otherwise..over the last 40 years linguists have achieved anincreasingly reﬁned understanding of how to clas-sify modal senses.
the most traditional and fun-damental distinction is between epistemic modalsand non-epistemic modals (also called root modals).
epistemic modals have to do with knowledge andplausibility of the event actually happening.
non-epistemic modals have to do with agent actions andmotivations underlying the events.2.
epistemic modality is not a uniﬁed class.
somemodals express a perspective on the event thatis based on knowledge, while others express aperspective related to the objective chance of theevent happening (a.k.a., circumstantial modalityin kratzer (1981)).
furthermore, linguists posittwo types of non-epistemic modal senses: onewhich focuses on the objective abilities and dy-namic unfolding of events (palmer, 1986), andanother which focuses on subjective reasons toprioritise one event over another (portner, 2009).
within the latter subtype there are further subdivi-sions according to whether the event is prioritisedin terms of norms (deontic), desires/preferences(bouletic), or goals/plans (teleological) (kratzer,1981; portner, 2009; rubinstein, 2012; matthew-son and truckenbrodt, 2018)..the traditional three-way classiﬁcation of modalsenses into deontic, epistemic, and dynamic, whichhas been used in previous nlp work (e.g., ruppen-hofer and rehbein (2012); marasovi´c et al.
(2016)),did not attend to these subdivisions, which arenonetheless expected to be important for reason-ing and other tasks that require deep understanding.
baker et al.
(2012) make ﬁner-grained distinctions.
2the same split is motivated also on syntactic grounds:epistemic modals appear in high positions in the syntacticstructure, in particular above tense and aspect, while rootmodals appear lower in the structure, closer to the verb phrase(see hacquard (2010) for an overview)..in the non-epistemic case, distinguishing betweenrequirements, permissions, wants, and intentions,but not all of these in fact track distinct modalsenses.
for example, their “require” modality con-ﬂates both rule-based obligations and goal-orientedpreferences..most importantly, the discussion of modalityin nlp often resorts to linguistic regimes that arenot understandable by non-linguists and non-expertpractitioners, making the output of these systemsessentially unusable for nlp engineers and design-ers of downstream tasks.
this paper aims to bridgethis gap, offering a single task and annotation stan-dard that cover the rich space of concepts, whilebeing intuitively understandable and easy-to-use..a note on modality vs. factuality.
a relatedbut different line of work in nlp investigates theautomatic identiﬁcation and classiﬁcation of thefactual status of events (saurí and pustejovsky,2009; rudinger et al., 2018).
that is, the factualityclassiﬁcation task has to do with automatically de-tecting whether, in actuality, a reported event hashappened or has not happened.3.
it is important to note that factuality and modal-ity are distinct and completely orthogonal notions(see, e.g., ghia et al.
2016).
for example, the sen-tences the wsj announced that she reached theshore and she was able to reach the shore sharethe propositional content of p = ‘she reached theshore’ and its implied factuality status (happened),but differ in the manner of reporting the event p.the former is based on knowledge, while the latterputs emphasis on the ability of the agent in p. it isprecisely this change of perspective that is missingin the realm of nlu and related downstream tasks.
the upshot of rudinger et al.’s (2018) work isthe claim that factuality is determined at event level,and that expressions contributing to factuality maybe of any syntactic class.
we likewise propose torelate modal triggers to an event being modiﬁed,and we similarly adopt an inclusive view of thesyntactic classes that express modality.
in contrastto event-based factuality detection, as proposed byrudinger et al.
(2018) and others, which classiﬁeswhich events came to pass, event-based modalitydetection as proposed here classiﬁes an orthogonaldimension of meaning related to semantic proper-ties of events that may be non-actual, providinginformation about why they are portrayed as such..3rudinger et al.
(2018) deﬁne factuality status on a scaleof {+3,-3}.
0 indicates an event with unclear factuality status..9553 event-based modality detection:.
proposed task deﬁnition.
we propose an event-based modality detection taskthat rests upon three assumptions: (i) the set ofpossible modal triggers is open-ended, and may beof any pos tag, (ii) the associated modal sensesare ﬁne-grained and form an hierarchical taxonomy,and (iii) each trigger is associated with an event..consider, for instance, the following examples:.
(3).
a. he was reportedi to bei in custody.
b. it is believedj that the glass will makejit possiblek to seek the satellite at night..in these examples, the words in bold indicate themodal expression, which we call a trigger.
theco-indexed items in italics mark the head of theevent for which the modal perspective is ascribed.
in (3a), ‘reported’ triggers a modal perspective onthe event of ‘being (in custody)’.
in (3b), ‘believed’triggers a modal perspective on the ‘making’ event,and ‘possible’ indicates a modal perspective on the‘seeing (the satellite)’ event..clearly, the modal perspectives on these events,i.e., the modal senses, are of different types.
howshould we label these ﬁne-grained modal senses?.
a hierarchical taxonomy of modal senseshaving established that a given expression servesas a modal trigger, we are interested in classifyingthe particular sense, or perspective, that it assignsto the modal event.
figure 1 presents the completetaxonomy that we propose for modal sense classiﬁ-cation in nlp.
it is based on the modal senses pro-posed and justiﬁed by rubinstein et al.
(2013), witha few simpliﬁcations that make it intuitive and easy-to-use by nlp practitioners and non-linguists.4.
the highest level of the hierarchy tracks the dis-tinction between events whose plausibility isbeing assessed, and events whose priority isstated.
more speciﬁcally, plausibility has to do withevents that are expected to happen or not happen,given a relevant set of assumptions which are madeexplicit.
plausibility can be assessed based on ourstate of knowledge (“i heardi she got marriedi"),based on what is objectively probable due to factsabout the world (“the ice cream will deﬁnitelyimelti in the sun"), or based on inherent (physical)abilities of an agent (“i cani easily swimi 10 km")..4cf.
manning’s law,.
item 5.https://en..wikipedia.org/wiki/manning’s_law.
priority.
norms and rules.
desires and wishes.
plans and goals.
plausibility.
state of knowledge.
state of the world.
state of the agent.
the ballot which must beheld by the end of marchwe do support certainlimitations on the villainsa necessity emerged toenter the pilgrim’s house.
the ship is believed tocarry illegal immigrantsthe disease can be contr-acted if a person is bittenthey are able to dowhatever they want.
table 1: modal-sense examples.
in contrast, the priority branch marks a per-spective where events are prioritized, or considered“good” by the speaker (or more generally, by a rele-vant attitude holder) (portner, 2009).
events can bepreferred because they are normatively obliged orcommendable (“you shouldi n’t drink and drivei),because they realize a goal ("the plani to reduceicosts in q2"), or because they are otherwise desir-able, as a matter of personal taste or preference (“iwill preferablyi meeti them over lunch”)..to make these notions accessible, we assign in-tuitive labels to these ﬁne-grained concepts.
onthe plausibility side, we distinguish plausibilitybased on the state of knowledge (previously,epistemic), plausibility based on a state of theworld (circumstantial), and plausibility based onthe objective abilities of the agent (dynamic).
onthe priority side, we distinguish priorities basedon rules and norms (deontic), priorities basedon desires and wishes (bouletic), and prioritiesbased on plans and goals (teleological).
asillustrated in table 2, modal triggers on both sidesof the sense hierarchy may be of any pos tag..the proposed taxonomy uniﬁes and harmonizesthe different modal senses offered by previous stud-ies.
importantly, we enrich the epistemic-deontic-dynamic classiﬁcation used in previous nlp re-search (ruppenhofer and rehbein, 2012; maraso-vi´c and frank, 2016) with the ﬁner-grained no-tions introduced by rubinstein et al.
(2013) andrefer to the various labels in work by baker et al.
(2012); mendes et al.
(2016).
more concretely,in gme and in our taxonomy, what in previousannotations was a monolithic deontic class (rup-penhofer and rehbein, 2012; marasovi´c and frank,2016) now corresponds to the priority node, withthree linguistically-motivated sub-classes (portner,.
956modality.
priority.
plausibility.
by rulesand norms(deontic).
by desiresand wishes(bouletic).
by plansand goals(teleological).
by state ofknowledge(epistemic).
by state ofthe world(circumstantial).
by state ofthe agent(dynamic).
figure 1: the proposed hierarchical taxonomy of modal senses.
priority.
aux we should remain calmverb our agency seriously needs equipmentnoun.
a plan to reduce carbon-dioxide emissions.
adverb marx is sufﬁciently patriotic.
adjective.
devaluation was necessary.
plausibilitythere is little i can dopowers that enable him to defend the rightstheir incapacity to put crime under controlpresident mugabe easily won zimbabwe’s electionthis complex decision was not easy for him.
table 2: modal triggers with diverse parts-of-speech tags: sentence excerpts from the gme corpus..2009): a rules-and-norms class, a desires-and-wishes class, and plans-and-goals..among modal events that do not involve prior-ities or norms, the sub-class which concerns thestate of an agent corresponds to dynamic modal-ity in previous studies (ruppenhofer and rehbein,2012; marasovi´c et al., 2016).
the two other sub-classes of plausibility modality, state of worldand state of knowledge taken together, corre-spond to epistemic in these previous works..to justify our ﬁne-grained distinction, considerhow the latter two senses, state of the world andthe state of knowledge, correspond to interest-ing applications in the bionlp literature, whereit is vital to distinguish fact from analysis (miwaet al., 2012).
the difference is seen in the interpre-tations of may in the following examples from thebioscope corpus (vincze et al., 2008):.
(4).
a. symptoms may include fever, cough or.
itches..b. the presence of urothelial thickeningand mild dilatation of the left ureter sug-gest that the patient may have continuedvesicoureteral reﬂux..in (4a), we classify may to the plausibility branchwith a state of the world sub-class.
in miwaet al.’s terms this would be referred to as fact.
in(4b), we classify may to the plausibility branchwith a state of knowledge sub-class.
in miwaet al.’s terms this would be referred to as analysis..4 experimental setup.
goal we set out to assess the feasibility of ourproposed event-based modality task.
concretely,we would like to gauge how well we can learn to de-tect and classify the different levels of modal sensesafforded by our taxonomy (§3) and to identify theevents modiﬁed by the triggers..data our experiments use the georgetown grad-able modal expressions corpus (gme; rubinsteinet al.
(2013)), a corpus obtained by expert annota-tions of the mpqa opinion corpus (wiebe et al.,2005).
the mpqa corpus is a 301,090-token cor-pus of news articles, which, following ruppenhoferand rehbein (2012), has become a benchmark forthe annotation of modality..the gme corpus annotates various properties ofmodal expressions, including their sense in context,the proposition they apply to, the polarity of theirenvironment, and whether or not they are qualiﬁedby a degree expression.5 rubinstein et al.
(2013)claim inter-annotator agreement scores as follows:krippendorf’s α = 0.89 for a 2-way distinctioncorresponding to priority versus plausibility, α =0.49 for their ﬁnest-grained sense classiﬁcation,and α = 0.65 for prejacent span detection..we processed the corpus by extracting themodal triggers and their corresponding proposi-.
5see rubinstein et al.
(2013) for details about the annota-.
tion process and the full scheme of annotated features..957tional spans (propositional argument in gme) intoa conll-formatted ﬁle.
using spacy (honnibalet al., 2020), we obtained the lemmas, pos tags,and dependencies.
the topmost head of the propo-sitional span is considered the head of the eventbeing modiﬁed.
we transformed the spans of modalpropositions into bio-tags, as shown in table 3..we shufﬂed and split the data into 90% trainingand validation sets, and a 10% test set.
the trainingand validation set was then split into 5 folds, andin each fold, 20% of the sentences were randomlyassigned to validation, 80% to training.
as op-posed to marasovi´c and frank (2016), who trainedand evaluated only on sentences already known tocontain modal triggers, we use the entire dataset,including sentences with no modality.6.
corpus statistics the gme corpus, containing11k sentences, shows that modality is a pervasivephenomenon (modal triggers were found in 96%of the documents and in 48% of the sentences).
we ﬁnd in the corpus 8318 modal triggers whichcorrespond to 1502 unique types..aside from verbs, nouns (e.g., rights, possibil-ity) and adjectives (e.g., fair, important) are amongthe most frequently used modal expressions, withverbs making up 37% of the modals in the corpus,adjectives 30%, and nouns 20%.
the remainingmodals are either adverbials, auxiliaries, or parti-cles.
while most verbal triggers are modal verbs(e.g., could, must, should; mv henceforth), 38%have other pos tags.
736 triggers appear only oncein the entire corpus with a modal meaning.7.
about 25% of modal triggers are ambiguous interms of their modal sense (plausibility vs. prior-ity), posing an additional classiﬁcation challengeon top of the varied distribution of trigger pos tags.
modal triggers can also be multi-word expressions,with about 200 such instances in the corpus (e.g.,have to)..the modal-triggers’ sense-labels are rather bal-anced: 48% of the triggers in the corpus belong to‘plausibility’ and 52% to ‘priority’.
for the ﬁner-grained senses, the most common and least com-mon classes make up 33% and 7% of the corpus,respectively..the proposed tasks we experiment with threetasks, with an increasing level of complexity:.
6the processed data is available at https://github..com/onlplab/modality-corpus..7words like can and right have non-modal meanings in.
addition to modal meanings..1. modal sense classification.
here weaim to classify the modal sense of a trigger, assum-ing a modal trigger is already known.
speciﬁcally,we examine the contribution of the context to thelemma.
we perform sense classiﬁcation with thefollowing variations: (i) vote: a majority vote, (ii)token: out of context token-based classiﬁcationwhere the trigger token is encoded using glove(pennington et al., 2014)), (iii) context: token-in-context classiﬁcation, given the whole sentenceencoded with roberta (liu et al., 2019) as input,with a marked trigger position, (iv) masked: giventhe sentence encoded with roberta but with thetrigger masked, (v) trigger+head: only the trig-ger word and event head are given, encoded withroberta, and ﬁnally, (vi) full+head: the fullsentence is encoded using roberta with both thetrigger and the event head marked..2. modality detection and classifica-tion.
this is a realistic scenario, where we donot assume the trigger is known.
we aim to bothidentify the trigger and label its sense.
we modelthis as a tagging task.
every token in the corpusis assigned a biose tag if it belongs to a modaltrigger, which is appended with a sufﬁx indicatingits modal sense.
we additionally perform varia-tions of this task by including the head of the eventas a feature (with either gold or predicted heads).
table 3 shows an example of the biose tagging ofmodal triggers, with and without the event..3. modal-event detection.
detecting andclassifying modal triggers in isolation is insufﬁ-cient for applications, as it is crucial to detect theevent being modiﬁed.
here we predict a modalevent and aim to relate it to its trigger and modalsense.
we model this as sequence labeling, withthe different tagging schemes to indicate the eventbeing modiﬁed.
first, we aim to detect only theevent.
in (i), we predict bio tags for the proposi-tional spans.
in (ii), we predict a head label forthe event head.
next, we aim to jointly predict themodal triggers and their modiﬁed events.
to thisend, in (iii) we predict biose-{e|t} for the eventspan, concatenating the related modal trigger.
thatis, within a single event span marked with bio,e marks the propositional content and t marksthe trigger.
we experiment with and without themodal sense appended to the trigger.
finally, in (iv)we predict biose-{sense} tags that indicate themodal trigger along with a head tag for the eventhead..958biosetextojapanohasotakenoaoleadingoroleointheointernational os-goalsdriveotorebuildoafghanistan oo....event head event spanooooooooos-goalsohoo.ooooooooob-ti-ei-ei-eo.table 3: representing event-based modality using a biotagging scheme.
on the left, the biose-label tags are usedto label the modal triggers.
in the middle column bio tagstrack the modal triggers, and h indicates the event head.
onthe right, the bio tags track the event span, with the t and elabeling the trigger and event span respectively..vote token mask context head.
coarsefine.
89.172.0.
88.772.4.
78.058.3.
90.776.4.
90.576.2.head+trigger90.175.1.table 4: modal sense classiﬁcation with oracle triggers..the labels that indicate modal sense are drawnfrom the proposed hierarchy, and we experimentwith multiple levels of granularity: modal/notmodal: a binary distinction, indicating if the to-ken is a modal trigger or not.
coarse-grained: a3-way distinction, indicating if the token is a modaltrigger, and if so, what coarse-grained sense it has(plausibility vs. priority).
fine-grained: indicatingif the token is a modal trigger, and if so, which oneof the senses at the lowest level of the hierarchy ithas.
we conﬂated desires/wishes and plans/goalsinto a single type called intentions, since both thesesenses are under-represented in our corpus.
see ap-pendix a for the complete label distribution in ourdata..evaluation metrics we report for all experi-ments biose-chunk precision, recall, and (macro)f1, calculated with the ofﬁcial conlleval script(sang and buchholz, 2000).
when evaluating spantagging for event-based modality we report labeledand unlabeled scores.
when we report unlabeledf1 for trigger classiﬁcation, we check whether thetoken has been correctly identiﬁed as modal vs.not-modal, regardless of its sense..models our baseline for modal trigger detectionis a simple majority vote baseline where each token.
baselinemv.
99.0493.2973.48.all68.2463.9455.23.robertamv.
99.993.378.5.all73.268.958.14.modal/notcoarse-grainedfine-grained.
table 5: the diversity of modal triggers: f1 of mv triggersvs. all triggers, majority vote baseline vs. roberta.
in the test set is tagged with its most frequent labelin the training set.
for detecting modal triggersas well as for event detection, we experiment byﬁne-tuning a roberta-based classiﬁer (liu et al.,2019).8 the encoded sequence is fed through a lin-ear layer with a softmax function predicting theappropriate tag for a given token.
for the shorterspans (modal triggers) we predict the tag for ev-ery token-in-context.
for the longer spans (eventsspans or events+trigger spans) we perform crfdecoding.
the models we used are allennlp(gardner et al., 2018) implementations.
wheneverwe use the trigger or the event as features to themodel, we add special tokens to the input, markingtheir respective spans in the sentence.
the hyper-parameters of the models are as follows: we userobertabase and ﬁne-tune it for 6 epochs witha batch-size of 8, a learning rate of 1e−5 and theadam optimizer.9.
5 results.
setting the stage before evaluating our modelson the proposed tasks, we ﬁrst assess the empiricalchallenge of our event-based modality detectiontask relative to the modal sense sentence classiﬁ-cation (sc) setup of marasovi´c and frank (2016).
their work focuses on 6 modal auxiliary verbs (can,could, may, must, should, and shall) and modalsenses from a restricted set of three labels (deon-tic, dynamic, epistemic).
note that their proposedsetup is not designed to separate modal sentencesfrom non-modal ones, as the marasovi´c and frank(2016) dataset contains only modal sentences.
sec-ond, it cannot directly indicate that a sentence con-tains multiple modal triggers with different senses..8we also experimented with a pytorch-based se-quence tagging model (ncrf++ by yang and zhang(2018)) with googlenews-vectors-negative300 embeddings(https://code.google.com/archive/p/word2vec/), but this set-ting did not outperform our majority vote baseline (and cer-tainly under-performed the model based on contextualizedrepresentations), and we didn’t pursue this direction further.
9the code for data processing, conﬁguration ﬁles and train-ing are available at https://github.com/onlplab/modality..959modal/not modalf1rp68.2462.0775.81baseline73.276.6870.05robertananabaselinenananaroberta na.
coarse-grainedp75.8172.0771.3667.03.r62.0776.1757.9270.89.f168.2474.0463.9468.89.fine-grainedp75.8174.0158.6857.98.r62.0774.4145.5658.32.f168.2474.251.2958.14.unlabeled.
labeled.
table 6: precision, recall, and f1 for baseline and roberta.
in labeled the model tagged each token for modal/not modal andclassiﬁed the identiﬁed modal tokens.
in unlabeled the labels are given, but not counted beyond the modal/not-modal distinction..dataset - triggers sentence sense accuracy.
marasovi`c - mvgme - mvgme - all.
797369.table 7: replicating the setup of marasovi´c and frank(2016) on the gme data.
results drop for gme when usingonly sentences with modal verbs (mv), and even further whenusing all of gme’s sentences (namely with all modal triggers)..we trained and tested a cnn compatible totheirs10 on their data as well as our data (gme),using their proposed settings.
we mapped our pri-ority, agent, and knowledge to their deontic, dy-namic, and epistemic, respectively, and ignored ourstate of the world (circumstantial).
here, we reportthe same sentence-based accuracy metrics as theydo.
table 7 shows the results on the two datasets,theirs and gme.
we see that accuracy on the sctask drops when switching from their data to ours,and that it drops further when moving from a closedset of pos (modal verbs) to all targets.
all in all,sentence classiﬁcation is not sufﬁcient to reﬂectthe richness of event-based modality annotation,and we conjecture that the sc setup would be toorestrictive for real-world applications..modal sense classiﬁcation next we report re-sults for the ﬁrst task we deﬁne, labeling the modalsense of an oracle trigger, as shown in table 4.the majority vote baseline is high, which is partlydue to the trigger lemma overlap between trainand dev/test (between 73%-79% depending on thesplit).
additionally we found only 25% of thetrigger lemmas in the corpus to be ambiguous be-tween plausibility and priority.
exposing the con-text, either by means of the full sentence or onlythe event head, improves results, and the improve-ment is more substantial for the ﬁne-grained distinc-tions.
removing the lemma and using only context(masked) harms the results, but it is still impressive.
10some dependencies in the marasovi´c and frank (2016)code are deprecated, so we use a simple off-the-shelf cnnmodel of allennlp (gardner et al., 2018)..and shows that the environment has non-negligiblecontribution to sense disambiguation.
finally, thesense classiﬁcation is surprisingly effective alsoin cases where different modal events in the samesentence are intertwined.
an interesting example isthe following sentence, with modal triggers in bold(sense in brackets): "how can(plausibility), undersuch circumstances, america allow(priority) itselfto express an opinion(plausibility) over the issueof human rights(priority) in other countries."
evenwhen masking the triggers, the ﬁne-tuned languagemodel was able to correctly identify this alternatingpattern of plausibility and priority..modal triggers detection table 5 shows themodal trigger detection results when applied onlyto the six modal verbs (mvs), as opposed to modaltriggers of unrestricted pos tags (all).
we seethat when targeting only mvs, detecting modal el-ements is almost trivial for both the baseline androberta.
both models are also quite proﬁcient(f1=93) at separating the different high-level modalsenses (priority vs. plausibility) of the modal typesthat we deﬁned.
once we switch to ‘all triggers’,results substantially drop.
also, when switching toﬁner-grained categories we observe an expecteddrop for both the baseline and roberta, withroberta performing signiﬁcantly better..table 6 presents the breakdown of the scores,labeled and unlabeled, for the different levels ofgranularity by the different models.
in all casesroberta shows at least 5 absolute points consis-tent increase in f1 scores over the baseline, for alllevels of granularity.
furthermore, our unlabeledscores demonstrate that predicting the ﬁne-grainedcategories by roberta actually helps to determinethe modal/non-modal decision boundary, with anf1 improvement of about 1 absolute point at alllevels.
for the labeled accuracy, we observe anexpected drop in the f1 scores when taking intoaccount ﬁne-grained labels.
yet, the performanceis better than a majority vote baseline and is farbetter than chance for these nuanced distinctions..960f1.
modal / not-modalcoarse-grainedfine-grained.
no-head headgold87.679.866.7.
73.268.958.14.headpredict69.463.252.1.joint.
73.367.356.0.table 8: modal trigger tagging results, f1 on detectedspans, with and without event head information..in the fine-grained labeled roberta settingthe breakdown of the f1 performance by label is:agent: 72.7, world: 54.7, rules/norms: 60.4, knowl-edge: 59.3, intentional: 46.1. these scores donot correlate with the frequency of each sense inthe training data, e.g.
agent is the least frequentsense, but the model performed best at tagging it.
looking at ambiguous lemmas, i.e., lemmas thatcan have different modal senses depending on con-text, one can see that agent and rules/norms arethe least ambiguous senses, which explains theirhigher performance scores.
breaking down the per-formance by coarse grained pos tag shows thatverbs are easiest to tag (66.5), followed by ad-verbs (59.7), then adjectives (55.9) and lastly,nouns, which, with a score of 43.8, seem to be thehardest to tag.
interestingly, adjectives are moreambiguous than nouns; we thus do not have a sat-isfying explanation for why it is harder to classifythe modality of noun triggers..table 8 shows the effect of event heads on modaltrigger identiﬁcation and classiﬁcation, consider-ing whether to model them separately or jointly inrealistic scenarios, where the trigger is not knownin advance.
gold event information as a feature formodal trigger tagging is helpful, but when this in-formation is predicted, propagated errors decreaseperformance.
jointly predicting both triggers andevent heads only very slightly decreases perfor-mance for the more ﬁne-grained sense categories,making it a viable option for classiﬁcation..event detection based on modal triggers ta-ble 9 shows that event-span detection is a hardertask than merely locating the triggers (cf.
table 6).
interestingly, predicting the span given informationabout the trigger (trigger as feature) works betterthan predicting the span with no such information(no-trigger).
this holds both when the triggeringevent is provided by an oracle (‘gold’), or whetherit is predicted by roberta (‘predict’).
improvingmodal trigger prediction is thus expected to furthercontribute to the accurate identiﬁcation of events,and to event-span boundary detection.
in general,.
f1.
span.
head.
modal / notcoarse-grainedfine-grainedmodal / notcoarse-grainedfine-grained.
notrigger51.151.151.156.356.356.3.trigger triggerpredictgold53.5571.1353.5670.9153.0970.3855.872.356.071.655.270.9.jointjoint50.0549.8548.2456.960.755.3.table 9: event detection results, f1 on detected spans,with and without modal trigger information..head prediction shows better results than span pre-diction, partly due to the f1 score on spans being arestrictive metric in cases of partial overlap..error analysis to qualitatively assess the us-ability of roberta’s output, two trained humanexperts manually inspected the errors in 112 modaltriggers in the dev set.
out of 36 false negatives(fn), 6 (16% of the fn) are in fact correct (incor-rectly tagged by the annotators as modal), and outof 27 false positives, 21 (78% of the fp) are in factcorrect (modals missed by the annotators).
thisleads to the conclusion that the gold annotationby the experts, while being precise, has incom-plete coverage and lower recall.
it implies thatroberta’s precision is in actuality higher, with alarger share of its predictions being correct..6 conclusion.
we propose an event-based modality detection taskwhich is based on solid theoretical foundations yetis adapted to ﬁt the needs of nlp practitioners.
the task has three facets: modal triggers can be ofany syntactic type, sense labels are drawn from auniﬁed taxonomy we propose, and modal triggersare associated with their modiﬁed events.
we pro-pose this task and standard as a potential extensionfor standard semantic representations (amr, sdg,ucca, etc.)
towards easy incorporation of modalevents as features in downstream tasks..acknowledgements.
we thank yoav goldberg, ido dagan, noah smith,graham katz, elena herburger, and members ofthe biu-nlp seminar for thoughtful feedback andfruitful discussion.
we also thank 3 anonymous re-viewers for their insightful remarks.
this researchis supported by an erc-stg grant of the euro-pean research council (no.
677352), the israelscience foundation (grant no.
1739/26 and grantno.
2299/19), and the national science foundation(bcs-1053038), for which we are grateful..961references.
kathryn baker, michael bloodgood, bonnie j. dorr,chris callison-burch, nathaniel w. filardo, chris-tine piatko, lori levin, and scott miller.
2012.use of modality and negation in semantically-informed syntactic mt.
computational linguistics,38(2):411–438..jon barwise and john perry.
1981. situations and atti-tudes.
the journal of philosophy, 78(11):668–691..lucia donatelli, michael regan, william croft, andnathan schneider.
2018. annotation of tense and as-pect semantics for sentential amr.
in proceedingsof the joint workshop on linguistic annotation, mul-tiword expressions and constructions (law-mwe-cxg-2018), pages 96–108, santa fe, new mexico,usa.
association for computational linguistics..matt gardner, joel grus, mark neumann, oyvindtafjord, pradeep dasigi, nelson f liu, matthew pe-ters, michael schmitz, and luke zettlemoyer.
2018.allennlp: a deep semantic natural language process-ing platform.
in proceedings of workshop for nlpopen source software (nlp-oss), pages 1–6..elisa ghia, lennart kloppenburg, malvina nissim, andpaola pietrandrea.
2016. a construction-centeredapproach to the annotation of modality.
in twelfthjoint acl - iso workshop on interoperable se-mantic annotation (isa-12), pages 67–74, portorož,slovenia..valentine hacquard.
2010. on the event relativity ofmodal auxiliaries.
natural language semantics,18:79–114..iris hendrickx, amália mendes, and silvia mencarelli.
2012. modality in text: a proposal for corpus an-notation.
in proceedings of the eight internationalconference on language resources and evaluation(lrec’12), istanbul, turkey.
european languageresources association (elra)..matthew honnibal,.
ines montani, soﬁe van lan-deghem,spacy:and adriane boyd.
2020.industrial-strength natural language processing inpython..angelika kratzer.
1981. the notional category ofmodality.
in hans-jürgen eikmeyer and hannesrieser, editors, words, worlds, and contexts, pages38–74.
walter de gruyter, berlin.
reprinted in for-mal semantics: the essential readings, ed.
paulportner and barbara h. partee (2002), 289–323.
ox-ford: blackwell..angelika kratzer.
2010. situations in natural languagesemantics.
in edward n. zalta, editor, the stanfordencyclopedia of philosophy, fall 2010 edition.
firstpublished february 2007..saul a. kripke.
1959..a completeness theoremin modal logic.
the journal of symbolic logic,24(1):1–14..and juan rafaeljulia lavid, marta carretrero,a linguistically-zamorano-mansilla.
2016.motivated annotation model of modality in englishin lin-and spanish: insights from multinot.
guistic issues in language technology, volume 14,2016 - modality: logic, semantics, annotation, andmachine learning.
csli publications..david lewis.
1973. counterfactuals.
harvard univer-.
sity press, cambridge, mass..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretrainingapproach.
arxiv preprint arxiv:1907.11692..ashutosh malhotra, erfan younesi, harsha gurulin-gappa, and martin hofmann-apitius.
2013.
‘hy-pothesisfinder:’ a strategy for the detection of spec-ulative statements in scientiﬁc text.
plos computa-tional biology, 9(7):e1003117..ana marasovi´c and anette frank.
2016. multilingualmodal sense classiﬁcation using a convolutional neu-ral network.
in proceedings of the 1st workshop onrepresentation learning for nlp, pages 111–120..ana marasovi´c, mengfei zou, alexis palmer, andanette frank.
2016. modal sense classiﬁcation atlarge.
paraphrase-driven sense projection, semanti-cally enriched classiﬁcation models and cross-genreevaluations.
lilt (linguistic issues in languagetechnology), 14..lisa matthewson and hubert truckenbrodt.
2018.modal ﬂavour/modal force interactions in german:soll, sollte, muss and müsste.
linguistische berichte,255:259–312..amália mendes, iris hendrickx, liciana ávila, pauloquaresma, teresa gonçalves, and joão sequeira.
2016. modality annotation for portuguese: frommanual annotation to automatic labeling.
in linguis-tic issues in language technology, volume 14, 2016- modality: logic, semantics, annotation, and ma-chine learning.
csli publications..makoto miwa, paul thompson, john mcnaught, dou-glas b. kell, and sophia ananiadou.
2012. extract-ing semantically enriched events from biomedicalliterature.
bmc bioinformatics, 13(108)..roser morante and caroline sporleder.
2012. modalityand negation: an introduction to the special issue.
computational linguistics, 38(2):223–260..malvina nissim, paola pietrandrea, andrea sansò, andcaterina mauri.
2013. cross-linguistic annotationof modality: a data-driven hierarchical model.
inproceedings of the 9th joint iso - acl sigsemworkshop on interoperable semantic annotation,pages 7–14, potsdam, germany.
association forcomputational linguistics..962veronika vincze, györgy szarvas, richárd farkas,györgy móra, and jános csirik.
2008. the bio-scope corpus: biomedical texts annotated for uncer-tainty, negation and their scopes.
bmc bioinformat-ics, 9:s9..janyce wiebe, theresa wilson, and claire cardie.
2005. annotating expressions of opinions and emo-tions in language.
language resources and evalua-tion, 39(2-3):165–210..jie yang and yue zhang.
2018. ncrf++: an open-arxiv.
source neural sequence labeling toolkit.
preprint arxiv:1806.05626..chrysoula zerva, riza batista-navarro, philip day,and sophia ananiadou.
2017. using uncertainty tolink and rank evidence from biomedical literature formodel curation.
bioinformatics, 33(23):3784–3792..mengfei zhou, anette frank, annemarie friedrich,and alexis palmer.
2015. semantically enrichedmodels for modal sense classiﬁcation.
in proceed-ings of the first workshop on linking computa-tional models of lexical, sentential and discourse-level semantics, pages 44–53, lisbon, portugal.
as-sociation for computational linguistics..frank r. palmer.
1986. mood and modality.
cam-.
bridge university press, cambridge..terence parsons.
1990. events in the semantics of en-glish: a study in subatomic semantics.
mit press,cambridge, ma..jeffrey pennington, richard socher, and christopher dmanning.
2014. glove: global vectors for word rep-resentation.
in proceedings of the 2014 conferenceon empirical methods in natural language process-ing (emnlp), pages 1532–1543..paul portner.
2009. modality.
oxford university.
press..mario prieto, helena deus, anita de waard, erikschultes, beatriz garcía-jiménez, and mark d.wilkinson.
2020. data-driven classiﬁcation of thecertainty of scholarly assertions.
peerj 8, 8:e8871..paulo quaresma, amália mendes, iris hendrickx, andteresa gonçalves.
2014. automatic tagging ofmodality: identifying triggers and modal value.
inthe 10th joint acl sigsem - iso workshop on in-teroperable semantic annotation, pages 95–102..victoria l. rubin.
2010. epistemic modality: fromuncertainty to certainty in the context of informationseeking as interactions with texts.
information pro-cessing & management, 46(5):533–540..aynat rubinstein.
2012. roots of modality.
ph.d. the-.
sis, university of massachusetts amherst..aynat rubinstein, hillary harner, elizabeth krawczyk,dan simonson, graham katz, and paul portner.
2013. toward ﬁne-grained annotation of modalityin text.
in proceedings of the iwcs 2013 workshopon annotation of modal meanings in natural lan-guage (wamm), pages 38–46..rachel rudinger, aaron steven white, and benjaminvan durme.
2018. neural models of factuality.
inproceedings of the 2018 conference of the northamerican chapter of the association for compu-tational linguistics: human language technolo-gies, volume 1 (long papers), pages 731–744, neworleans, louisiana.
association for computationallinguistics..josef ruppenhofer and ines rehbein.
2012. yes wein pro-can!?
annotating english modal verbs.
ceedings of the eighth international conference onlanguage resources and evaluation (lrec-2012),pages 1538–1545..erik tjong kim sang and sabine buchholz.
2000. in-troduction to the conll-2000 shared task chunking.
in fourth conference on computational naturallanguage learning and the second learning lan-guage in logic workshop..roser saurí and james pustejovsky.
2009. factbank:a corpus annotated with event factuality.
languageresources and evaluation, 43:227–268..963a data.
a.1 gme in numbers.
the gme dataset (rubinstein et al., 2013) anno-tates the mpqa corpus (wiebe et al., 2005) withinformation about modality.
the corpus consists of534 documents which in turn contain 11,048 sen-tences.
5288 sentences have modal triggers, and ofthem, in 1141 the modal trigger is an auxiliary verb.
there are 7979 instances of modal triggers (tokens),which belong to 1141 unique words (types).
1229of the modal triggers are modal verbs.
the break-down of the modal triggers into the different modalsenses is given in table 10..c experimental setting.
we had 4 geforce gtx 1080 ti available for train-ing and hyper-parameter search.
our models arebased on roberta-base, which has 82m parame-ters and it takes about 45 minutes to train a singletagging model..tables 11 and 12 show the results of the baselineand roberta respectively.
on the right hand sideof the tables, the scores are split by modal senses.
here too, we observe that roberta obtains sub-stantial improvements on per-label scores over thebaseline..type.
quantity.
2-wayambiguity.
3-wayambiguity.
rules &normsdesires &wishesplans &goalsknowledgeworldagent.
2316.
142.
1077.
15271303447.
537.
210.
557.
202.table 10: label counts in the gme data.
a.2 data pre-processing.
we parsed the data using spacy, and obtained thelemma, pos, and dependency information for alltokens in our corpus.
we split the data into 5 folds,where each fold had a different split of training andvalidation set, but the test set is the same for allfolds.
train and validation sets are of 9894 sen-tences (validation 1975 and training 7919), whilethe test set has 1096 sentences.
the train and vali-dation sets have 7160 modal triggers, while the testset has 819..b additional materials.
please refer to the following github repositories forcode and data:.
code code and models and evaluation scriptsused in our experiments.
https://github.com/onlplab/modality.
data a processed version of the gme corpus, in-cluding all annotation layers and meta-information..https://github.com/onlplab/.
modality-corpus.
964p/r/f1labeled unlabeled.
labels f1.
modal vs.not-modal.
priority vs.plausibility.
fine-grained.
75.8162.0768.2471.3657.9263.9458.6845.5651.29.
75.8162.0768.2475.8162.0768.2475.8162.0768.24.priority.
55.46.plausibility.
72.51.rules.
intentions* knowledge world agent.
50.94.
39.11.
50.95.
52.58.
67.39.table 11: classifying modal events: baseline results (ambiguities not shown).
we uniﬁed wishes and goals into intentions forreasons of data sparsity..p/r/f1labeled unlabeled.
labeled f1.
modal vs.not-modal.
priority vs.plausibility.
fine-grained.
nanana67.0370.8968.8957.9858.3258.14.
70.0576.6873.272.0776.1774.0474.0174.4174.2.priority.
62.98.plausibility.
75.52.rules.
intentions* knowledge world agent.
60.42.
46.1.
59.27.
54.64.
72.72.table 12: classifying modal events: roberta results (ambiguities not shown).
we uniﬁed wishes and goals into intentionsfor reasons of data sparsity..965