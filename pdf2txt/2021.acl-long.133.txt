infosurgeon: cross-media fine-grained information consistencychecking for fake news detection.
yi r. fung1, chris thomas2, revanth reddy1, sandeep polisetty3,heng ji1, shih-fu chang2, kathleen mckeown2, mohit bansal4, avirup sil51university of illinois at urbana-champaign, 2columbia university3umass amherst, 4university of north carolina at chapel hill, 5ibm.
1.yifung2,revanth3,hengjichristopher.thomas,sc250,kathy.
}.
{.
@illinois.edu.
@columbia.edu.
3spolisetty@umass.edu, 4mbansal@cs.unc.edu, 5avi@us.ibm.com.
}.
2.
{.
abstract.
to defend against neural system-generatedfake news, an effective mechanism is urgentlyneeded.
we contribute a novel benchmark forfake news detection at the knowledge elementlevel, as well as a solution for this task whichincorporates cross-media consistency check-ing to detect the ﬁne-grained knowledge el-ements making news articles misinformative.
due to training data scarcity, we also formu-late a novel data synthesis method by manip-ulating knowledge elements within the knowl-edge graph to generate noisy training data withspeciﬁc, hard to detect, known inconsisten-cies.
our detection approach outperforms thestate-of-the-art (up to 16.8% absolute accuracygain), and more critically, yields ﬁne-grainedexplanations.1.
1.introduction.
in recent years, generative neural network mod-els in natural language processing (zellers et al.,2019) and computer vision (choi et al., 2018) havebecome the frontier for malicious actors to con-trollably generate misinformation at scale.
theserealistic-looking ai-generated “fake news” havebeen shown to easily deceive humans, and it is,thus, critical for us to develop robust veriﬁcationtechniques against machine-generated fake news(tan et al., 2020; zellers et al., 2019; kaliyaret al., 2020).
current misinformation detectionapproaches mainly focus on document-level fakenews detection using lexical features and semanticembedding representations (wang, 2017; karimiet al., 2018; tan et al., 2020).
however, fake newsis often generated based on manipulating (misus-ing, exaggerating, or falsifying) only a small partof the true information, namely the knowledge.
1the code, data and resources related to the misinforma-tion detector are made publicly available at https://github.
com/yrf1/infosurgeon for research purposes..elements (kes, including entities, relations andevents).
moreover, recent news oftentimes makesclaims that do not have veriﬁed evidence yet, andevaluating the truthfulness of these real-time claimsdepends more on their consistency with other infor-mation conveyed in other data modalities..in this paper, we propose a new task: ﬁne-grained, knowledge element-level cross-media in-formation consistency checking.
the task involvestreating the entire multimedia news article as onewhole interconnected claim, where the goal is to de-tect misinformative kes across the image, caption,and body text, as revealed by inconsistencies withrespect to itself, or to background knowledge.
thiske-level detection approach directly points out thefake pieces of information in the news, allowingfor better explainability..figure 1 shows an example where both thetext and image provide complementary informa-tion about key argument roles of an event.
wepresent the information surgeon (infosurgeon)model, which takes full advantage of state-of-the-art multimedia joint knowledge extraction tech-niques to analyze ﬁne-grained event, entity, andrelation elements, as well as whether these ex-tracted kes align consistently across modalitiesand background knowledge.
we propose a novelprobabilistic graphical neural network model tofuse the outputs from these indicators..a major challenge to performing ke level mis-information detection is the lack of training data.
hence, we additionally propose a novel approachto generate noisy training data automatically sinceexisting fake news generators (zellers et al., 2019)do not track the speciﬁc pieces of information gen-erated that are fake.
we take a real news article, ex-tract a multimedia knowledge graph, and replace orinsert salient nodes or edges in the graph.
we trackthe speciﬁc manipulation operations, and regen-erate the manipulated version of the news article.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1683–1698august1–6,2021.©2021associationforcomputationallinguistics1683figure 1: the architecture of our ﬁne-grained, ke-level fake news detection system, infosurgeon.
our model usesgraph-based neural network to aggregate cross-modal and external knowledge in a multimedia kg to determinewhether a document is real or fake and provide ke-level explanations.
for instance, the document above shouldideally be detected as fake due to cross-modal inconsistencies (i.e.
the caption conveys <police, located.in, hiddencorner> to surprise-attack protesters, which is inconsistent with the image showing <police, located.near, visiblecrowd of reporters>).
<police, blinded, woman> in the article is also fake information, which is not supported bythe image or caption.
note: the article in this ﬁgure is inspired from materials reported in major news outlet thatwere later taken down due to misinformation..using a graph-to-text approach (ribeiro et al.,2020),while ﬁltering out poor quality unconvincing gen-erations through a neural adversarial ﬁlter..experiment results show that our approachachieves 92%-95% detection accuracy, 16.8% abso-lute higher than the state-of-the-art approach (tanet al., 2020).
ablation tests demonstrate the effec-tiveness of our new detection method.
the majorcontributions of this paper are:.
• we propose a novel approach to perform fakenews detection at the ke level, representing theclaims in the news article as a multimedia knowl-edge graph and detecting the mis-informativepieces in the form of kes for a strong explain-ability..• we contribute infosurgeon, a uniﬁed frameworkfor detecting misinformation in news articles thatcomprehensively incorporates source context, se-mantic representation, multimedia informationelements, and background knowledge in a rea-soning framework..• finally, we present a novel benchmark, ke levelfake news detection, with a silver standard an-notation dataset (15,000 multimedia documentpairs) automatically generated by kg condi-tioned natural language generation..2 task formulation.
given a multimedia news article, x, which con-sists of its body text bt, list of images im1..i,list of accompanying captions c1..i, and meta-data m = (domain, date, author, headline), ourstudy aims to detect the presence of misinforma-tion at two levels.
in document-level detection, weclassify each news article as either real or fake,overall.
in knowledge element-level detection, wepredict the speciﬁc set of knowledge elements inthe news article conveying misinformation.
here,we refer to knowledge elements (kes) comprehen-sively as the entities, relations, events, and sub-graphs/metapaths (fu et al., 2020) in an informa-tion network..to detect the misinformative kes, we treat eachnews article as one ultimate claim represented by amultimedia knowledge graph kg = (n, e) cap-turing the important information conveyed.
thenodes (n ) in the kg consist of entities (t), whilethe edges (e) in the kg consist of relations (r) orevent argument roles (a) connecting the entities.
detecting the kes causing a news article to be fakeboils down to extracting <subject entity, predicate,object entity> triplets from the multimedia inputdata, and labeling all of the triplets in which the re-lation or event between a head entity and tail entityholds false as evidence of misinformation throughbinary edge classiﬁcation.
figure 2 shows exam-.
1684lapata (2019), which averages the encoded tokenembeddings across sentences through a weightedmechanism.
for metadata, we run the text encoderon a string containing the article domain, publica-tion date, author, and headline.
for images, we con-catenate object-based (anderson et al., 2018) andevent-based (pratt et al., 2020) visual features.
fea-tures for the edges between global context nodesare initialized by the attention-based semantic sim-ilarity between the node features (tan et al., 2020)..3.3 local kg representation.
|.
constructing a kg from each multimedianews article: we leverage a publicly availablemultimedia information extraction (ie) system (liet al., 2020; lin et al., 2020) to construct a within-document knowledge graph kg = (nt, era) foreach multimedia article.
the ie system can extract197 types of entities, 61 types of relations, and144 types of events from text and images.
then, itperforms entity linking (pan et al., 2017) to mapentities extracted from both text and images to abackground knowledge base e.g.
freebase (bol-lacker et al., 2008) and nil (unlinkable) entityclustering for name mentions that cannot be linked,followed by cross-media event and entity corefer-ence resolution and grounding (lai et al., 2021;wen et al., 2021; pratt et al., 2020).
initializing the kg embeddings: we deﬁne anattribute function, a : nt, erf , that trans-forms each of the nodes and edges to its initialrepresentation by concatenating the following fea-tures:.
a ).
|.
• background embeddings - for the entity nodesnt that can be linked to freebase, we use datadump from google developers resources2 to mapthem to their respective wikipedia pages, whichserve as a rich source of established backgroundknowledge.
background node embedding fea-tures are initialized from passing a long shortterm memory networks (lstm) based architec-ture (gers et al., 2000) through the word embed-dings (pennington et al., 2014) of the ﬁrst para-graph in the wikipedia page, which usually startswith a mention of the wiki page’s title.
back-ground edge embedding features are initializedfrom passing the lstm through the paragraphsthat contain the mentions of both the head andtail nodes.
these embeddings are set to a defaultzero vector for unlinkable nodes..2https://developers.google.com/freebase/.
4.figure 2: in the case of events, we ignore the event trig-ger denoted byand connect entities by their eventargument roles and event types combined e.g., <hk po-lice, justice.arrest.jailer-justice.arrest.detainee, (un-cooperative) protesters>.
the true/false tags are la-beled for each triplet, which connects a pair of entities..ples of how kes should be detected if they occurin the kg of a news article..we evaluate document-level fake news detectionbased on the established metric of prediction accu-racy.
to evaluate ﬁne-grained ke level fake newsdetection, we compute the f-score: the harmonicmean of precision and recall across kes.
this isan appropriate metric due to the imbalanced natureof fake kes, which usually constitute the minority..3 fake news detection.
3.1 overview.
as shown in figure 1, our ﬁne-grained multimediafake news detection system, infosurgeon, extractsfeatures from both global context and local kg.
the global context nodes capture the semantic rep-resentations of the body text, images, captions, andmetadata in the news article.
the local kg providesan explicit representation of the key informationpieces and their interactions.
as a clarifying exam-ple, the entire image in a news article constitutes aglobal context node, while the speciﬁc objects de-tected in the image make up the node entities in thelocal kg.
infosurgeon combines these two com-plementary components by connecting the globalcontext nodes to the entity nodes in the kg ex-tracted from the news article, thereby propagatingcontext signals into the knowledge elements..3.2 global context representation.
to incorporate general context information andtake advantage of cross-media inconsistencies thatare more likely to exist in fake news, we com-pute semantic representations for each news arti-cle component to initialize the node features.
wefeed the body text and each caption through thesummarization-based bert encoder from liu and.
1685relation:event:events/relations:“hk police”“hidden corner”“hk police”“protesters”physical.locatednear“arrest”justice.arrest.detaineejustice.arrest.jailer“hk police”“people”“shoot”conflict.attack.victimconflict.attack.attacker“real bullets”conflict.attack.instrumentt= true, f= false,tfffflife.die.victimflife.die.killer“died”= entity• news embeddings - these are the surface-levelfeatures circumstantial to the entities, relations,and events extracted.
news-based node featuresare initialized from passing an lstm through theword embeddings of the canonical entity mentionextracted.
news-based edge features are initial-ized from passing the lstm through the wordembeddings of the relation type or event argu-ment role infused with head and tail entity infor-mation, in the triplet format e.g.
“<hk police,physical.locatednear, visible crowd>”..• source attribution - this is a 4-dimensional bi-nary vector indicating whether the ke came fromthe body text, image, caption, or metadata..3.4 feature propagation and joint learning.
a central idea to our misinformation detector isthat edge embeddings are naturally more closelyaligned to the node embeddings they are connectedto for the non-fake triplets.
therefore, we learn aneural network layer to extract the hidden repre-sentations of credibility between node connections.
the graphical representation of the global contextand local kg network is heterogeneous in naturethough, so we propagate features as follows..for the global context subgraph, potential misin-formation lies in whether the images, captions, ormetadata align with the overall news article.
givena global context node, u, we compute the hiddenrepresentations of credibility with all other globalnbr(u) (1), and aggre-context node neighbors vgate the information back to node u itself (2)..2.heuv = relu (wt ·.
[hnu, heuv , hnv ]).
(1).
hnu = relu.
1nbr(u).
|.
0.
@.
nbr(u).
| xv2.heuv 1a.
(2).
for the local kg, potential misinformation liesin the relations or event argument roles connectingentity nodes.
given two local kg nodes u andv that are connected by an edge, we compute thehidden representation of triplet credibility as in eq(1).
to further take advantage of neighborhood in-formation, we propagate features across the globalcontext and local kg network with graph attentionand message passing..3.5 detector component.
document level fake news detection: an es-tablished approach to graph-level classiﬁcation is to.
merge the extracted graph features together throughavg or max pooling.
to strengthen signals, wefurther add primitive indicator values before thedocument level linear classiﬁer.
tan et al.
(2020)use a single binary indicator for the existence ofoverlap between entities in the caption and entitiesin the article body.
we use a broader set of indica-tors reﬂecting the number of overlapping entitiesand events across the caption, body, and image.
knowledge element level fake news detec-tion: detecting misinformative knowledge ele-ments in the kg can be treated as a binary edgeclassiﬁcation problem, in which each edge repre-sents the entire triplet in which it serves as thepredicate.
we run a linear classiﬁer on each ofthe learned edge embeddings that are not directlyconnected to the semantic nodes, to detect if therelation or event argument role connecting two en-tities is normal or not..4 fake news generation.
currently, there exists no annotated dataset for kelevel misinformation detection.
a primary reasonmay be due to explicitly fake (as opposed to subtlybiased) news being edited or taken down by onlineplatforms after initial posting.
because manuallylabeling the misinformative kes in a real-worldnews corpus is expensive, we aim to create a noveldataset with controlled synthesis of news articlesand automatically generated labels for ﬁne-grainedke level explainability in fake news detection.
inthis section, we propose two novel approaches thatgenerate fake news, and at the same time, automati-cally label the misinformative knowledge elements.
given a set of real news articles, xreal, we performdeliberate edit operations on certain salient kes inthe new articles’ kg to derive a manipulated rep-resentation, kg0.
hence, we can generate a newarticle conditioned on kg0.
the correspondingke level label can then be automatically derived,with the manipulated elements as fake and the un-altered elements as real, while the document-levellabel for the new generated article is fake..4.1 manipulated kg-to-text synthesis.
given a pristine, real news article, we aim to per-form controlled fake new synthesis by altering cer-tain entities, relations, and events, while keepingthe rest of the story largely intact.
we observe that,in general, the entity nodes with the strongest de-gree of connection are the centerpiece of a news.
16864.2 manipulated amr-to-text synthesis.
tan et al.
(2020) observe captions to be very signif-icant in detecting fake articles, with performancedropping from 85.6% (when trained on articles gen-erated using grover-mega (zellers et al., 2019))to 56.9% when captions are excluded.
hence, weaim to further manipulate existing captions by gen-erating subtle variations in the relations betweenentities.
we leverage abstract meaning represen-tation (amr) (banarescu et al., 2013) graphs ex-tracted from these captions since they capture richﬁne-grained sentence-level semantic relations ex-pressing who does what to whom.
amr semanticrepresentation includes propbank (palmer et al.,2005) frames, non-core semantic roles, coreference,entity typing and linking, modality, and negation..true caption:in afghanistan,the taliban released to the media thispicture, which it said shows the suicide bombers whoattacked the army base in mazar-i-sharif, april 21, 2017.fake caption:on 21 april 2017 the taliban released this picture to thearmy in afghanistan which they said was a suicide bomberhiding at a media base in the city of mazar-i-sharif.
figure 4: example of amr-to-text fake caption gen-eration.
the roles of army and media (in blue) areswitched and the node corresponding to the event trig-ger (in red) attacked is negated..to obtain the amr graphs, we use the stack-transformer based amr parser from astudillo et al.
(2020) and train it on amr 3.03. given the amrgraph, we vary the manipulation as follows: (1)role switching - we randomly select two entitymentions that are present in different argument sub-graphs of the amr root node and interchange theirpositions in the amr graph.
(2) predicate nega-tion - we randomly pick predicates in the amrgraph corresponding to event triggers and otherverbs, and replace them with their antonyms, whichwe obtain from wordnet (fellbaum, 1998).
thismanipulation also includes reverting nodes withnegative polarity, thereby negating the sentence..3https://catalog.ldc.upenn.edu/ldc2020t02.
figure 3: we show example of manipulating the mul-timedia kg of a news article, swapping geolocation-typed entity “zambia” with “fiji”..article, while the entity nodes with the smallestdegree of connection are less salient.
thus, we ran-domly select entity nodes occurring at mid rangefrequency to manipulate.
we vary the type of kgmanipulation, as follows: (1) entity swapping -we swap the original entity with an alternative en-tity that belongs to the same entity type.
(2) ad-dition of a new relation or event - we take anexisting entity, randomly select a relation or eventargument role that connects to this entity type, andappend a new entity at the other end of the relationor event.
(3) subgraph replacement - we selecta subgraph of the news article that branches offthe randomly selected entity nodes above, and re-place it with a subgraph from another news article.
although we also considered the removal of nodeand edges, we found it intuitively too challengingto detect because lack of information can exist atvarious points across the article in reality but thesilver standard annotation from selective removalwould not cover enough of these for supervisedtraining..next, we generate a fake news article that alignswith this manipulated kg0 by ﬁnetuning a bart-large language model (lewis et al., 2020) on ourtraining set.
to better enforce that manipulated enti-ties actually appear in the generated article, we usea copy mechanism which re-purposes entities fromthe input kg when generating the output article(post and vilar, 2018).
after training, we manip-ulate kgs as described above and feed the manip-ulated kgs into our model to generate syntheticdata (see the example in figure 3).
the manipu-lated knowledge elements serve as silver-standardannotations for the generated fake news articles..1687<team,manufacture.artifact_artifact.artifact_manufacturer, zambiafiji> <zambiafiji,manufacture.artifact_manufacturer, men> ... <bicycle> <hospital> ...manipulated kga team of two californians living in fiji is trying to build the world’s smallest and most affordable bicycle.
they are using bamboo as the frame for their bicycles.
the team is made up of 25 young men who met at a university in the pacific island nation of fiji.
they’re using their...generated articlearticle imageafter manipulating the amr graphs, we convertthem into text using the pretrained models4 pro-vided by ribeiro et al.
(2020).
speciﬁcally, we usea bart-large model that was ﬁne-tuned to gener-ate the sentence from its corresponding linearizedamr graph.
we use top-p top-k sampling (holtz-man et al., 2019), with k = 10 and p = 0.95, topromote diversity in the generated text.
figure 4shows an example of generated fake caption..5 experiments.
5.1 data and setting.
we run experiments on two datasets:(1) thenytimes-neuralnews, an established benchmarkfor multi-media fake news detection with pristinenews articles collected by biten et al.
(2019) andfake news generated by grover in tan et al.
(2020).
following tan et al.
(2020), we use a subset of32k real news articles from new york times and32k grover-generated (zellers et al., 2019) fakearticles.
(2) our new voa-kg2txt dataset, whichconsists of 15k real news article scraped from voiceof america and 15k machine-generated fake newsarticles using the kg-to-text approach in section4..we compare against two recent baselines: (1)(tan et al., 2020) is most similar to infosurgeonas it performs multi-media fake news detection,but does not use kgs, perform ﬁne-grained pre-diction, or leverage kg-driven data synthesis; and(2) (zellers et al., 2019) which uses an adversarialdiscriminator to detect fake news articles based onthe article text while disregarding the informationfrom images and captions..note that in the nytimes experiment, a grover-medium discriminator is used for the zellers et al.
(2019) baseline since fake news in the dataset iscreated using a grover-mega generator and modelleakage would be unfair.
in the voa experiment,the grover-mega discriminator is used becausefake news in the dataset is generated by a separatemodel, bart (lewis et al., 2020).
additional im-plementation details can be found in the appendix..5.2 document-level detection results.
in table 1, we report our accuracy at distinguishingreal news articles from those generated by groverin the nytimes-neuralnews dataset.
we observe alarge gain in performance (16.9%) over tan et al.
(2020).
we believe there are several reasons for.
4https://github.com/ukplab/plms-graph2text.
this gain.
the main reason is due to the use ofmultimedia structured reasoning in our approach.
(tan et al., 2020) trains on articles and images andrelies on the model itself to learn which statementsin text to focus on for inference.
in contrast, ourapproach explicitly extracts relations between enti-ties (e.g.
x locatednear y) and in events (e.g.
x-attacker, attack, y-target).
this structure capturedby the kg allows the model to easily zero-in onthe semantics of assertions made in the text.
bydoing so, the model can more easily discover self-contradictions within articles (as well as betweenarticles and captions).
moreover, our approach in-tegrates external knowledge from wikipedia intoour knowledge graph, which enables our modelto detect factual statements in generated articleswhich conﬂict with background knowledge.
forexample, if a generated article states that a coun-try shares borders with another but it actually doesnot, we can detect the article’s inconsistency withbackground knowledge..table 1 also presents the results on the voa-kg2txt dataset we assembled.
we observe that ourmodel continues to outperform tan et al.
(2020) onthis dataset.
importantly, the synthetic data is cre-ated by our novel kg-to-text fake news synthesisapproach (section 4).
this dataset poses uniquechallenges to our approach, as much of the knowl-edge graph (from real news articles) is preserved inthe input to the generator.
this means many claimsmade within the article are actually true (in con-trast to nytimes-neuralnews, where the generatoris not conditioned on speciﬁc claims)..approach.
zellers et al.
(2019)tan et al.
(2020)infosurgeon.
nytimes-neuralnews56.0%77.6%94.5%.
voa-kg2txt86.4%88.3%92.1%.
table 1: a comparison of document-level misinforma-tion detection accuracy on the two datasets..5.3 knowledge element-level detection.
results.
one novel aspect of our approach for fake newsdetection is we manipulate knowledge graphs togenerate training data for our detector.
while thisenables us to generate more realistic training data,it also allows us to know precisely what elements ofthe generated knowledge graphs are manipulated.
this enables us to make ﬁne-grained, knowledge.
1688element level predictions to better understand howa given article is faked.
thus, we also evaluate ourdetector’s performance at predicting real vs. fakeat the knowledge element level.
these annotationsare only available on the voa-kg2txt dataset wesynthesize and not on nytimes-neuralnews..we present our results in table 2. we see thatour approach achieves 31% -37% accuracy at thistask, signiﬁcantly outperforming the random base-line.
we note that this is an extremely challengingtask, as we manipulate kgs subject to constraintswhich make their manipulations difﬁcult to detect(section 4).
determining which elements are mis-leading requires higher-level reasoning, both acrossmodalities and with background knowledge..approachrandominfosurgeon.
voa0 voa16.6% 16.9%36.5% 31.3%.
table 2: knowledge element-level misinformation de-tection f-score on the voa (voa-kg2txt) dataset, con-sisting of entity swapping,link insertion, and sub-graph replacement manipulations, and its easier variant,voa0, which contains entity swappings..5.4 analysis.
we next test the importance of each componentin the detector.
speciﬁcally, we present resultsshowing performance when the model is used withonly the knowledge graph, semantic features (fromthe text, image, and captions), and primitive in-dicator values.
as expected, we observe the bestperformance when all components are used, as thisprovides the most information to the model, aswell as more opportunities for detecting inconsis-tencies.
semantic features constitute the most pow-erful component for the detector, but kg offerscomplementary information based on ﬁne-grainedknowledge elements, together making infosurgeonmore robust and effective..approach.
accuracy (doc).
infosurgeoninfosurgeonkginfosurgeonfseminfosurgeonfp rim.
92.1%81.6%90.4%54.1%.
table 3: ablation results on the voa dataset, analyz-ing the isolated components of our model using fea-tures from the kg, semantic representations (fsem),and primitive indicators (fp rim)..in table 4, we show an example document whereinfosurgeon is able to correctly predict real vs. fake,but the baseline (tan et al., 2020) is not.
the imageand caption show fort mchenry, while the arti-cle discusses the fort’s role in the battle of 1814.the article mentions how the world trade centerwas destroyed in the battle.
as there is no obvi-ous cross-media inconsistency, tan et al.
(2020)predicts the document as real.
in contrast, infosur-geon leverages background knowledge about thedate of construction and destruction of the worldtrade center to determine the document is fake andpredicts the knowledge element which is falsiﬁed,including the falsely generated entity twin towerswhich does not appear in the image nor caption..our appendix contains additional results, includ-ing “surgery” where manipulated kes are sup-pressed and a new article is then generated..5.5 human turing test on synthesized text.
in order to assess the quality of the synthesized textfrom our kg-to-text generator, we conduct a tur-ing test by 16 human subjects who read news ona daily basis and are not authors of this paper.
werandomly select a subset of 100 documents fromthe test set, half real and half fake, and present themto the human judges.
each human judge assessesall of these documents, without knowing the distri-bution of real and fake news.
the average overalldetection accuracy achieved by human judges is61.6%, with 81.2% accuracy on real documentsand only 41.9% accuracy on fake documents.
athird of the fake news documents were predicted in-correctly by over half of the human subjects.
thisindicates that our automatically generated fake doc-uments are also very hard for humans to detect.
the most common clues humans used to detectfake news include linguistic style, topic coherence,speciﬁc event details and novel entities..6 related work.
fake news detection.
traditional approachesto fake news detection are largely based on fact-checking, text-style, or context from a single modal-ity (ciampaglia et al., 2015; shi and weninger,2016; pan et al., 2018; angeli et al., 2015).
other approaches include detecting previously fact-checked claims (shaar et al., 2020), retrieving sen-tences that explain fact-checking (nadeem et al.,2019; atanasova et al., 2020), and leveraging con-text and discourse information (nakov et al., 2019)..1689image.
caption.
body text.
misinformative kes.
aerial viewof fortmchenry..the battle of fort mchenry, which took place in septem-ber of 1814, was a pivotal moment in the u.s. war ofindependence...when the british ﬁnally left, they left be-hind a trail of destruction, including the destruction ofthe twin towers of the world trade center ....<british,conﬂict.attack,twin towers>.
table 4: an example fake document which tan et al.
(2020) misses, but infosurgeon successfully detects..p´erez-rosas et al.
(2018)pan et al.
(2017)baly et al.
(2018)zellers et al.
(2019)tan et al.
(2020)infosurgeon (ours).
x-xxxx.text features.
source bias multimedia.
structuredknowledge-x---x.
--xx-x.knowledge elementlevel detection-----x.
----xx.table 5: comparison with related work on fake news detection..while style-based (p´erez-rosas et al., 2018;karimi et al., 2018; de sarkar et al., 2018) ap-proaches have been effective in the past, they fallshort against stylistically consistent, machine gen-erated text (schuster et al., 2020).
however, zellerset al.
(2019) demonstrate that a text generator, suchas grover, can serve as a good detector against itsown generations, picking up data artifacts such asexposure bias and sampling variance.
comparedto zellers et al.
(2019), our fake news detectionapproach doesn’t rely on access to the generatorand is more robust against unseen generators..recent approaches focus on using the multime-dia information in news articles, as opposed tousing only a single modality such as text (balyet al., 2018; ma et al., 2018; hanselowski et al.,2018; karimi and tang, 2019) or images (huh et al.,2018; wang et al., 2019).
tan et al.
(2020); wanget al.
(2018) extract multi-media features across thearticle body, images, and captions to detect incon-sistencies.
in comparison, we contribute a morecomprehensive approach to fake news detection, byunifying source bias, semantic features, knowledgeelements, cross-document cross-media consistencychecking, and background knowledge reasoning,each of which offers complementary information,while previous attempts focus on only one or a fewof these aspects (see table 5)..fake news generation.
zellers et al.
(2019)ﬁnetune gpt-2 (radford et al., 2019) on a large-scale news corpus to generate propaganda that canfool humans well.
biten et al.
(2019) introducean approach to generate image captions based oncontextual information derived from news articles..in contrast, we leverage graph-to-text based ap-proaches such as kg-to-text (ribeiro et al., 2020;chen et al., 2020) and amr-to-text (song et al.,2018; ribeiro et al., 2020) to get more direct con-trol in manipulation.
we modify the knowledgeelements in the structured input to produce moresubtle variations in the generated text..existing benchmarks.
the fever (thorneet al., 2018) dataset seeks to retrieve supporting ev-idence for single-sentence claims and classify theclaims as supported, refuted or notenoughinfo.
politifact5 is a website that manually assigns fact-check label to claims, along with the background in-formation.
zlatkova et al.
(2019) propose a datasetfor fact-checking claims about images.
tabfact(chen et al., 2019) presents semi-structural tablesfor fact veriﬁcation.
the semeval-2020 sharedtask (da san martino et al., 2020) centers on thedetection of propaganda techniques in news arti-cles, which is more linguistically oriented.
wecreate a new benchmark which will open up a newresearch direction towards explainable misinforma-tion detection at the knowledge element level..7 conclusions and future work.
we have demonstrated a novel method for multi-media misinformation detection that can achieve92%-95% detection accuracy using cross-mediainformation consistency checking and adversarialfake information generation by knowledge graphmanipulation.
our framework can be used to in-gest and assess news articles, while providing ﬁne-grained knowledge element-level explanations..5https://www.politifact.com.
1690as future work, we plan to extend the problemsuch that any combination of body text, image,video, audio and caption can be “fake”.
we willalso incorporate consistency reasoning across mul-tiple documents and from commonsense knowl-edge, and extend our approach to open-domaindocuments from multiple sources, languages andcultures.
in the long term, we aim to collect morehuman-generated data with different types of in-tent that cause different levels of acceptance byreaders, study more types of human manipulationsto design additional criteria (e.g., entity novelty,newsworthiness, etc.
), jointly detect misinforma-tion and intent, correct detected misinformation,and generate authentic narratives..8 ethical statement and broader impact.
our goal in developing ﬁne-grained informationconsistency checking techniques is to advance thestate-of-the-art and enhance the ﬁeld’s ability to de-tect fake news on the knowledge-element level.
ageneral approach to ensure proper, rather than ma-licious, application of dual-use technology shouldincorporate ethical considerations as the ﬁrst-orderprinciples in every step of the system design, aswell as maintain a high degree of transparency andinterpretability of data, algorithms, models, andfunctionality throughout the system.
in this paper,we focus on creating an interpretable approach sothat users of the system can understand which partsof the article have been falsiﬁed.
we intend to makeour misinformation detector software available asopen source and share docker containers for publicveriﬁcation and auditing so it can be used to com-bat fake news.
but it’s also important to note that,in order to avoid anyone using our frameworks todeliberately generate and spread misinformation,we will not share our misinformation generators..we acknowledge the pros and cons of releasingmethodological details on the generator.
detailson the generator raise awareness of the threat land-scape and what is potentially being developed bymalicious agents, which in turn help advance morerobust countermeasures against adversarial attackson fake news detectors.
in addition, it reinforces an-other important principle - scientiﬁc reproducibility.
the ﬂip side is that unethical parties may apply thenew generator approach in their misconducts.
toachieve a balance between such opposed consider-ations, we leave out ideas on how to improve thegenerator.
we will also omit small details that make.
the generator successful without masking out thebackbone to the scientiﬁc community.
the propercomposition of news content depends ultimately,in part, on regulations and standards that provide alegal framework and professional editorial reviewpractice safeguarding against misinformation withdeceitful intents..whether infosurgeon is beneﬁcial depends onwho uses it.
here are some example scenarioswhere infosurgeon should and should not be used:.
• should-do: anyone who wants to stay informeduses infosurgeon as an assistant to understandnews events..• should-do: journalists use infosurgeon to ver-ify facts and select authentic information to gen-erate news summaries, timelines, and perspec-tives..• should-do: analysts use infosurgeon to mon-itor disaster and assist situation understanding,emergency response and resource allocation.
• should-not-do: anyone using infosurgeon to.
create and spread misinformation..• should-not-do: the detection results of infos-urgeon should not be considered as deﬁnite deter-mination about a news article being real or fake.
it is intended only as an advisory and appropriateveriﬁcation processes should not be dispensed..finally, the types of misinformation we have de-tected are limited to the general news domain, andhence, they are not applicable to other domains.
the performance of our system components as re-ported in the experiment section is based on thespeciﬁc benchmark datasets, which could be af-fected by such data biases.
therefore, questionsconcerning generalizability and fairness should becarefully considered in future work..acknowledgement.
this research is based upon work supported by u.s.darpa semafor program no.
hr001120c0123and darpa aida program no.
fa8750-18-2-0014. the views and conclusions contained hereinare those of the authors and should not be inter-preted as necessarily representing the ofﬁcial poli-cies, either expressed or implied, of darpa, orthe u.s. government.
the u.s. government isauthorized to reproduce and distribute reprints forgovernmental purposes notwithstanding any copy-right annotation therein..1691references.
peter anderson, xiaodong he, chris buehler, damienteney, mark johnson, stephen gould, and leizhang.
2018. bottom-up and top-down attention forimage captioning and visual question answering.
inproceedings of the ieee conference on computer vi-sion and pattern recognition, pages 6077–6086..gabor angeli, melvin jose johnson premkumar, andchristopher d manning.
2015. leveraging linguis-tic structure for open domain information extraction.
in proceedings of the 53rd annual meeting of theassociation for computational linguistics and the7th international joint conference on natural lan-guage processing (volume 1: long papers), pages344–354..ram´on fernandez astudillo, miguel ballesteros,tahira naseem, austin blodgett, and radu flo-rian.
2020. transition-based parsing with stack-in proceedings of the 2020 confer-transformers.
ence on empirical methods in natural languageprocessing: findings, pages 1001–1007..pepa atanasova, jakob grue simonsen, christina li-generat-oma, and isabelle augenstein.
2020.in proceedings ofing fact checking explanations.
the 2020 association of computational linguistics(acl), pages 417–422..ramy baly, georgi karadzhov, dimitar alexandrov,james glass, and preslav nakov.
2018. predict-ing factuality of reporting and bias of news mediasources.
in proceedings of the 2018 conference onempirical methods in natural language processing(emnlp), pages 9054–9065..laura banarescu, claire bonial, shu cai, madalinageorgescu, kira grifﬁtt, ulf hermjakob, kevinknight, philipp koehn, martha palmer, and nathanschneider.
2013. abstract meaning representationfor sembanking.
in proceedings of the 7th linguis-tic annotation workshop and interoperability withdiscourse, law-id@acl 2013, august 8-9, 2013,soﬁa, bulgaria, pages 178–186..ali furkan biten, lluis gomez, marc¸al rusinol, anddimosthenis karatzas.
2019. good news, everyone!
context driven entity-aware captioning for news im-in proceedings of the ieee conference onages.
computer vision and pattern recognition, pages12466–12475..kurt bollacker, colin evans, praveen paritosh, timsturge, and jamie taylor.
2008. freebase: a col-laboratively created graph database for structuringhuman knowledge.
proceedings of the 2008 acmsigmod international conference on managementof data, pages 1247–1250..8635–8648, online.
association for computationallinguistics..wenhu chen, hongmin wang, jianshu chen, yunkaizhang, hong wang, shiyang li, xiyou zhou, andwilliam yang wang.
2019.tabfact: a large-scale dataset for table-based fact veriﬁcation.
arxivpreprint arxiv:1909.02164..yunjey choi, minje choi, munyoung kim, jung-wooha, sunghun kim, and jaegul choo.
2018. stargan:uniﬁed generative adversarial networks for multi-domain image-to-image translation.
in proceedingsof the ieee conference on computer vision and pat-tern recognition, pages 8789–8797..johan bollen, filippo menczer,.
giovanni luca ciampaglia, prashant shiralkar, luis mrocha,andalessandro flammini.
2015. computational factplos one,checking from knowledge networks.
10(6):e0128193..giovanni da san martino, alberto barr´on-cedeno,henning wachsmuth, rostislav petrov, and preslavnakov.
2020. semeval-2020 task 11: detection ofpropaganda techniques in news articles.
in proceed-ings of the fourteenth workshop on semantic evalu-ation, pages 1377–1414..sohan de sarkar, fan yang, and arjun mukherjee.
2018. attending sentences to detect satirical fakenews.
in proceedings of the 27th international con-ference on computational linguistics, pages 3371–3380..christiane fellbaum.
1998. wordnet: an electroniclexical database.
cambridge, ma: mit press..xinyu fu, jiani zhang, ziqiao meng, and irwin king.
2020. magnn: metapath aggregated graph neuralnetwork for heterogeneous graph embedding.
inproceedings of the web conference 2020, pages2331–2341..felix a gers, j¨urgen schmidhuber, and fred cummins.
2000. learning to forget: continual prediction withlstm.
neural computation, 12(10):2451–2471..andreas hanselowski, avinesh pvs, benjaminschiller, felix caspelherr, debanjan chaudhuri,christian m. meyer, and iryna gurevych.
2018. aretrospective analysis of the fake news challengein proceedings of the 27thstance-detection task.
international conference on computational lin-guistics, pages 1859–1874, santa fe, new mexico,usa.
association for computational linguistics..ari holtzman, jan buys, li du, maxwell forbes, andyejin choi.
2019. the curious case of neural text de-in international conference on learn-generation.
ing representations..wenhu chen, yu su, xifeng yan, and william yangwang.
2020. kgpt: knowledge-grounded pre-in proceed-training for data-to-text generation.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages.
minyoung huh, andrew liu, andrew owens, andalexei a efros.
2018. fighting fake news: imagesplice detection via learned self-consistency.
eu-ropean conference on computer vision (eccv),pages 101–117..1692rohit kumar kaliyar, anurag goswami, and pratiknarang.
2020. deepfake: improving fake news de-tection using tensor decomposition-based deep neu-ral network.
the journal of supercomputing..hamid karimi, proteek roy, sari saba-sadiya, andjiliang tang.
2018. multi-source multi-class fakein proceedings of the 27th inter-news detection.
national conference on computational linguistics,pages 1546–1557, santa fe, new mexico, usa.
as-sociation for computational linguistics..hamid karimi and jiliang tang.
2019. learning hier-archical discourse-level structure for fake news de-tection.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, pages 3432–3442..tuan lai, heng ji, trung bui, quan hung tran, franckdernoncourt, and walter chang.
2021. a context-dependent gated module for incorporating symbolicsemantics into event coreference resolution.
arxivpreprint arxiv:2104.01697..mike lewis, yinhan liu, naman goyal, mar-jan ghazvininejad, abdelrahman mohamed, omerlevy, veselin stoyanov, and luke zettlemoyer.
2020. bart: denoising sequence-to-sequence pre-training for natural language generation, translation,and comprehension.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 7871–7880, online.
associationfor computational linguistics..manling li, alireza zareian, qi zeng, spencer white-head, di lu, heng ji, and shih-fu chang.
2020.cross-media structured common space for multime-dia event extraction.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 2557–2568, online.
associationfor computational linguistics..ying lin, heng ji, fei huang, and lingfei wu.
2020.a joint end-to-end neural model for information ex-traction with global features.
in proc.
the 58th an-nual meeting of the association for computationallinguistics (acl2020)..yang liu and mirella lapata.
2019. text summariza-in proceedings oftion with pretrained encoders.
the 2019 conference on empirical methods in nat-ural language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 3730–3740, hong kong,china.
association for computational linguistics..jing ma, wei gao, and kam-fai wong.
2018. ru-mor detection on twitter with tree-structured recur-sive neural networks.
in proceedings of the 56th an-nual meeting of the association for computationallinguistics (volume 1: long papers), pages 1980–1989, melbourne, australia.
association for compu-tational linguistics..moin nadeem, wei fang, brian xu, mitra mohtarami,and james glass.
2019. fakta: an automatic end-in proceedings ofto-end fact checking system.
the 2019 conference of the north american chap-ter of the association for computational linguistics(demonstrations), pages 78–83, minneapolis, min-nesota.
association for computational linguistics..preslav nakov, llu´ıs m`arquez, alberto barr´on-cede˜no, pepa gencheva, georgi karadzhov, tsve-tomila mihaylova, mitra mohtarami, and jamesglass.
2019. automatic fact checking using contextand discourse information.
acm journal of dataand information quality..martha palmer, dan gildea, and paul kingsbury.
2005.the proposition bank: a corpus annotated with se-mantic roles.
computational linguistics journal,31(1):71–106..jeff z pan, siyana pavlova, chenxi li, ningxi li, yang-mei li, and jinshuo liu.
2018. content based fakein inter-news detection using knowledge graphs.
national semantic web conference, pages 669–683.
springer..xiaoman pan, boliang zhang, jonathan may, joelnothman, kevin knight, and heng ji.
2017. cross-lingual name tagging and linking for 282 languages.
in proceedings of the 55th annual meeting of theassociation for computational linguistics (volume1: long papers), pages 1946–1958, vancouver,canada.
association for computational linguistics..jeffrey pennington, richard socher, and christophermanning.
2014. glove: global vectors for wordrepresentation.
in proceedings of the 2014 confer-ence on empirical methods in natural languageprocessing (emnlp), pages 1532–1543, doha,qatar.
association for computational linguistics..ver´onica p´erez-rosas, bennett kleinberg, alexandralefevre, and rada mihalcea.
2018. automatic de-in proceedings of the 27thtection of fake news.
international conference on computational linguis-tics, pages 3391–3401, santa fe, new mexico, usa.
association for computational linguistics..matt post and david vilar.
2018. fast lexically con-strained decoding with dynamic beam allocation forin proceedings of theneural machine translation.
2018 conference of the north american chapter ofthe association for computational linguistics: hu-man language technologies, volume 1 (long pa-pers), pages 1314–1324, new orleans, louisiana.
association for computational linguistics..sarah pratt, mark yatskar, luca weihs, ali farhadi,and aniruddha kembhavi.
2020. grounded situa-tion recognition.
in european conference on com-puter vision, pages 314–332.
springer..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners.
openaiblog, 1(8):9..1693haoyang wen, ying lin, tuan lai, xiaoman pan, shali, xudong lin, ben zhou, manling li, haoyuwang, hongming zhang, et al.
2021. resin: a dock-erized schema-guided cross-document cross-lingualcross-media information extraction and event track-ing system.
in proceedings of the 2021 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies: demonstrations, pages 133–143..rowan zellers, ari holtzman, hannah rashkin,yonatan bisk, ali farhadi, franziska roesner, andyejin choi.
2019. defending against neural fakenews.
in advances in neural information process-ing systems, pages 9054–9065..dimitrina zlatkova, preslav nakov, and ivan koychev.
2019. fact-checking meets fauxtography: verify-in proceedings of theing claims about images.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 2099–2108, hong kong,china.
association for computational linguistics..leonardo f. r. ribeiro, martin schmitt, hinrichsch¨utze, and iryna gurevych.
2020.investigatingpretrained language models for graph-to-text gener-ation.
in arxiv2007.08426..tal schuster, roei schuster, darsh j shah, and reginabarzilay.
2020. the limitations of stylometry fordetecting machine-generated fake news.
computa-tional linguistics, pages 1–12..shaden.
shaar,.
nikolay babulkov,.
giovannida san martino, and preslav nakov.
2020. thatis a known lie: detecting previously fact-checkedclaims.
in proceedings of the 58th annual meetingthe association for computational linguis-oftics, pages 3607–3618, online.
association forcomputational linguistics..baoxu shi and tim weninger.
2016. discriminativepredicate path mining for fact checking in knowl-edge graphs.
knowledge-based systems, 104:123–133..linfeng song, yue zhang, zhiguo wang, and danielgildea.
2018. a graph-to-sequence model for amr-to-text generation.
proceedings of the 56th annualmeeting of the association for computational lin-guistics, pages 1616–1626..reuben tan, bryan plummer, and kate saenko.
2020. detecting cross-modal inconsistency to de-fend against neural fake news.
in proceedings of the2020 conference on empirical methods in naturallanguage processing (emnlp), pages 2081–2106,online.
association for computational linguistics..james.
andreas vlachos,.
and arpit mittal..thorne,christos2018.christodoulopoulos,fever: a large-scale dataset for fact extraction andveriﬁcation.
in proceedings of the 2018 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, pages 809–819..sheng-yu wang, oliver wang, andrew owens,richard zhang, and alexei a efros.
2019. de-tecting photoshopped faces by scripting photoshop.
iccv, pages 10072–10081..william yang wang.
2017.
“liar, liar pants on ﬁre”: anew benchmark dataset for fake news detection.
inproceedings of the 55th annual meeting of the as-sociation for computational linguistics (volume 2:short papers), pages 422–426, vancouver, canada.
association for computational linguistics..yaqing wang, fenglong ma, zhiwei jin, ye yuan,guangxu xun, kishlay jha, lu su, and jing gao.
2018. eann: event adversarial neural networksin proceed-for multi-modal fake news detection.
ings of the 24th acm sigkdd international conferenceon knowledge discovery & data mining, pages 849–857..1694infosurgeon: cross-media fine-grained information consistencychecking for fake news detection.
yi r. fung1, chris thomas2, revanth reddy1, sandeep polisetty3,heng ji1, shih-fu chang2, kathleen mckeown2, mohit bansal4, avirup sil51university of illinois at urbana-champaign, 2columbia university3umass amherst, 4university of north carolina at chapel hill, 5ibm.
1.yifung2,revanth3,hengjichristopher.thomas,sc250,kathy.
}.
{.
@illinois.edu.
@columbia.edu.
3spolisetty@umass.edu, 4mbansal@cs.unc.edu, 5avi@us.ibm.com.
}.
2.
{.
1 appendix.
1.1.implementation setting.
{.
1e.
3, 1e.
we performed hyperparameter search on the learn-ing rate of each model across a standard search4, 1espace,, with the}adam optimizer.
in the scenario where the originalpaper of the baseline model speciﬁed the hyperpa-rameters for the dataset we run it on, we use theconﬁgurations they speciﬁed..5, 1e.
 .
 .
 .
 .
6.
1.2 dataset details.
the nytimes-neuralnewsis a pre-existingdataset available from https://cs-people.bu.edu/rxtan/projects/didan/.
we will release our voa-kg2txt dataset upon publication.
to ensure ma-nipulated knowledge elements are misinformativerather than vanilla swapping of non-salient pieces,we ﬁlter for triplets with at least one node con-nected to a linkable entity as a labeling criteria..1.3 examples of generated data.
figure 2 shows our generated news that fool humanin the turing test.
figures 3, 4, 5 and 6 show moreexamples for fake captions generated using ouramr-to-text manipulation approach..1.4 example of false positive from the.
baseline, correctly predicted by ourmodel.
in figure 1, we see that the image is a map il-lustrating the country of lebanon.
most of theimages in our training set are photorealistic images(non-graphics) and thus, the image model is unac-customed to this type of image.
moreover, neitherof our approaches leverage image text recognitionand thus may struggle to understand the visual con-tent.
thus, tan et al.
(2020), unable to determinethe consistency with the image, incorrectly predictsthat the document is fake.
in contrast, even though.
infosurgeon may be unable to determine the visualcontent, it captures entity consistencies in the cap-tion with the article (of the country name).
thearticle is consistent with background knowledgeand infosurgeon correctly predicts the same is real..image.
caption.
lebanon.
body text.
lebanese officials say rescuers have recoveredtwo bodies from the waters off lebanon’snorthern coast where a cargo ship carrying 83crew members and livestock sank late thursday....figure 1: an example real document which tanet al.
(2020) predicted false, but infosurgeon differ-entiated properly..1.5 example of information surgery.
we include an example of “information surgery” infigure 7. we automatically identify misinforma-tive knowledge elements within a knowledge graphfrom an article detected as manipulated.
we thenremove these elements and regenerate the articleusing our kg-to-text approach.
it can be seen thatthe misinformative part can be correctly removedfrom the article after such ”surgical” steps..referencesreuben tan, bryan plummer, and kate saenko.
2020. detecting cross-modal inconsistency to de-fend against neural fake news.
in proceedings of the2020 conference on empirical methods in naturallanguage processing (emnlp), pages 2081–2106,online.
association for computational linguistics..1695title: burma’s national league of democracy (nld) at historic congress.
real article.
burma's once-outlawed national leaguefor democracy is holding its first partycongress since the opposition group wasfounded 25 years ago.
delegatesinrangoon will draw up a policy frameworkand elect a central committee during thethree-day meeting that began friday.
democracy icon aung san suu kyi is alsoexpected to be reappointed as head of theparty.
the nobel laureate helped the nldto a strong showing in historic april by-elections, which saw the party win 43 ofthe 45 contested seats.
but the nld issetting its sights on 2015, when it hopes totake power during national elections.
butthe party faces several challenges as itattempts to fashion itself into a viablepolitical alternative to the military, whichstill dominates parliament and othergovernment institutions.
one of the most pressing issues is electing younger leaders to replace the party's elderly founding members, many of whom are in their 80s or 90s and in poor health..real article.
mali's acting prime minister promisedduring a visit to the war-torn north onthursday elections would go ahead in julydespite fears his government is failing toreassert its control there after the oustingof islamist rebels.
diango cissoko's visit togao was the first by a senior governmentfigure since a french-led campaign freednorthern mali's largest town from al-qaida-linked rebels in january.
cissoko met withlocal dignitaries and malian troops duringthe visit and thanked french forces whohelped take gao and other northern townsfrom the militants.
he also urged thefrench to stay in mali.
france is planningto reduce its presence in the country fromthe current 4,000 troops to 1,000 by theend of this year.
however, analysts fearthat preparations will not be completed byjuly and warn that a botched election couldsow the seeds for further unrest and north-south conflict in the landlocked formerfrench colony.
meanwhile, human rightswatch says two ethnic tuareg men whowere tortured by malian soldiers have diedin prison.
the men had been arrested infebruary on suspicion they supportedarmed islamist groups..congress delegates prepare to pose for photographs as they arrive to attend the national league for democracy party's (nld) congress in rangoon, march 8, 2013..mali's prime minister diango cissoko (3rd l) reviews nigerian soldiers at their base in the town of banamba,150km (93 miles) from bamako april 9, 2013. cissoko paid a visit to the nigerian army troops base on tuesday, reported local media..fake article.
from the nld gather.
indelegatesrangoon for the party's annual congress.
the nld is headed by nobel peace prizewinner aung san suu kyi.
the party isexpected to win a majority of seats in theparliament.
this year's nld congress is the first timethe party has been able to elect its ownleadership.
nyan win, a member ofnld's executive committee,told voathat the party is looking forward to thenew generation of leaders.
the party has come a long way since themilitary seized power in 1962. the nldwas founded by a briton.
since then,burma has been ruled by a quasi-civilianthe military hasgovernment.
however,still maintained tight control overthephilcountry'srobertson, asia directorfor humanrights watch, said he hopes the party willpush forward with reforms that will allowthe army to step down and allow thecivilian government to take over..institutions..political.
fake article.
cissoko's visit to the northern town ofgao, where malian troops are battlingal-qaida-linked rebels, was the first bya senior malian regime figure sincefrench troops seized control of thenorth in january.
he told reporters in gao thatthecountry will hold a parliamentaryelection in july.
towns in thegao is one of severalnorth that french and malian forceshave recaptured from the militants.
human rights watch says more than1,000 people have been detained in thepast year.
the rights group says theyare mostly tuareg men who werebeaten by malian soldiers.
some analysts say the number ofdetentions is likely to rise in thecoming months.
the islamist groups that took controlof northern maliin january havevowed to crush the malian governmentand impose their strict version ofislamic law..title: mali pm promises july election during gao visit.
figure 2: examples of fake news article generated using our kg-to-text approach vs the original newsarticle.
the fake elements in the generated text are highlighted in red..1696true caption:soldiers loyal to the syrian regime stand in a truck inqusair after the syrian army took control of the city fromrebel fighters, june 5, 2013..fake caption:on june 5 2013, qusair loyalist soldiers stood by a truckafter the qusair army obviated its control over syriancities from rebels fighting..figure 3: example of amr-to-text fake captiongeneration.
the roles of syrian and qusair (inblue) are switched and the node corresponding tothe event trigger (in red) took is negated..true caption:philippine troops arrive at their barracks to reinforce fellowtroops following the siege by muslim militants, on the outskirtsof marawi city in the southern philippines, may 24, 2017..fake caption:on 24 may 2017 the philippines militants left their barrack in the outskirts of southern marawi city to reinforce fellow troops who had been under siege by islamic troops..figure 5: example of amr-to-text fake captiongeneration.
the roles of troops and militants (inblue) are switched and the node corresponding tothe event trigger (in red) arrive is negated..true caption:anis amri (l), the tunisian suspect of the berlin christmas marketattack, is seen in this photo taken from security cameras at the milancentral train station in downtown milan, italy december 23, 2016..fake caption:anis amri, a tunisian suspected of defending the christmas market in milan, was seen in this photo given from a security camera at the central train station of downtown berlin on 23 december 2016 ..figure 4: example of amr-to-text fake captiongeneration.
the roles of berlin and milan (in blue)are switched and the node corresponding to theevent trigger (in red) attack is negated..true caption:israel's prime minister benjamin netanyahu walks withu.s. secretary of state hillary rodham clinton upon herarrival to their meeting in jerusalem, nov. 20, 2012..fake caption:secretary of state hillary rodham clinton rode with u.s. prime minister benjamin netanyahu when he arrived for a meeting in jerusalem..figure 6: example of amr-to-text fake captiongeneration.
the roles of benjamin netanyahu andhilary rodham clinton (in blue) are switched andthe node corresponding to the event trigger (in red)walks is negated..1697figure 7: we show an example of performing “information surgery” with knowledge element levelpredictions.
the article on top discusses various pop-culture news items, but makes false claims aboutlady gaga being arrested.
we detect these misinformative knowledge elements within the knowledgegraph and excise (surgically remove) them.
we then use our kg-to-text model to generate a new articlefrom the repaired knowledge graph..1698information surgerymisinformative textbruno mars’ "bad boys" soundtrack will be released on february 5.on february 4, the red hot chili peppers will kick off their north american tour with a concert in east rutherford, new jersey.
the band will be followed by performances in chicago, grand rapids, michigan, and las vegas.
r&b singer carrie underwood will be inducted into the rock and roll hall of fame on february 6. the ceremony will be held in new york city.
carrie will be the first female inductee into the hall.
other inductees include beyonce, band perry, phillip phillips, queen latifah, vince neil, nikki sixx, mick mars, alice cooper and chantel jeffries…lady gaga has been released from jail in miami after posting bail.
she was charged with possession of marijuana and possession of drug paraphernalia.
she is scheduled to appear on the february 4 episode of "american idol.”… susan ryan and her husband, jim, will take their fans to the historic strawberry fields in central park in orlando, florida, on february 8. the site was named in honor of …misinformative kg<bruno mars> <motley crue> <nfl> <metlife stadium> <red hot chili peppers> <beyonce> <band perry> <phillip phillips> <jersey boys> <renee fleming> <lady gaga,justice.arrestjaildetain.arrestjaildetain_detainee-arrestjaildetain_place, dade county>... <susan ryan, movement.transportartifact_transporter-transportartifact_destination, strawberry fields>...<john williams, personnel.startposition_employee, ...regenerated text from repaired kgbruno mars’ "bad boys" album debuts at number one on the billboard 200 chart this week with its first week of sales.
the album sold more than 100,000 copies in its first three weeks of release.
other top 10 debuts this week include: "lemonade" by taylor swift, "young the giant" (number 2) by toni braxton (number 3) by kenny "babyface" edmonds (number 4) by candice glover (number 5) by eric paslay(number 6) by les claypool (number 7) by marissa nadler (number 9) by mark mcguire (number 10).the rock and roll hall of fame will induct john lennon, yoko ono and bob seger … the band will be supported by the red hot chili peppers, the dave matthews band, phillip phillips, the jersey boys, queen latifah, vince neil, nikki sixx, mick mars, alice cooper and chantel jeffries…susan ryan and her husband, jim, will take fans to the historic strawberry fields in central park on february 2. susan and jim are the parents of singer-songwriter sara evans, who moved from missouri to nashville last year.
susan was diagnosed with lymphoma in january….