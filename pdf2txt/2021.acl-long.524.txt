metaphor generation with conceptual mappings.
kevin stowe1, tuhin chakrabarty2, nanyun peng3smaranda muresan2, iryna gurevych11ubiquitous knowledge processing lab, technical university of darmstadthttps://www.informatik.tu-darmstadt.de/ukp/2columbia university, {tuhin.chakr,smara}@cs.columbia.edu3university of california los angeles, violetpeng@cs.ucla.edu.
abstract.
generating metaphors is a difﬁcult task as itrequires understanding nuanced relationshipsin this paper,between abstract concepts.
we aim to generate a metaphoric sentencegiven a literal expression by replacing rele-vant verbs.
guided by conceptual metaphortheory, we propose to control the generationprocess by encoding conceptual mappings be-tween cognitive domains to generate meaning-ful metaphoric expressions.
to achieve this,we develop two methods: 1) using framenet-based embeddings to learn mappings betweendomains and applying them at the lexical level(cm-lex), and 2) deriving source/target pairsto train a controlled seq-to-seq generationmodel (cm-bart).
we assess our methodsthrough automatic and human evaluation forbasic metaphoricity and conceptual metaphorpresence.
we show that the unsupervised cm-lex model is competitive with recent deeplearning metaphor generation systems, andcm-bart outperforms all other models bothin automatic and human evaluations.1.
1.introduction.
recent neural models have led to importantprogress in natural language generation (nlg)tasks.
while pre-trained models have facilitatedadvances in many areas of generation, the ﬁeld ofmetaphor generation remains relatively unexplored.
moreover, the few existing deep learning modelsfor metaphor generation (yu and wan, 2019; stoweet al., 2020; chakrabarty et al., 2020) lack any con-ceptualization of the meaning of the metaphors..this work proposes the ﬁrst step towardsmetaphor generation informed by the conceptualmetaphor theory (cmt) (lakoff and johnson,1980; lakoff, 1993; reddy, 1979).
cmt holds.
1all.
code, models,at:.
and data.
avail-https://github.com/ukplab/.
are made.
ableacl2021-metaphor-generation-conceptual.
figure 1: metaphor generation guided by concep-tual metaphors.
given a literal input, we can gener-ate metaphoric outputs based on different mappings be-tween conceptual domains..that we use conceptual mappings between domains(conceptual structures that group related concepts)to generate linguistic metaphors.2 metaphoric map-pings consist of a source and a target conceptual do-main.
the source domain is the conceptual domainfrom which we draw the metaphorical expressions,while the target domain is the conceptual domainthat we try to understand.
a classical mappingis argument is war, in which we conceptual-ize the target argumentation domain as the moreconcrete source domain of war:.
• they fought against the contract.
• they defended their new proposal..we focus on verbs, as they are often the keycomponent of metaphoric expressions (steen et al.,2010; martin, 2006).
when used metaphorically,verbs typically evoke source domains (e.g.
fought,defended in the above examples): they are con-crete, and are used to understand more abstract tar-gets (i.e., argumentation verbs such as argued, sup-ported) via conceptual mappings (sullivan, 2013).
we propose a novel framework for metaphor gen-eration informed by conceptual metaphor theory.
given a literal input sentence that evokes a tar-get domain we generate metaphoric sentences that.
2“domains” are also often referred to as “image schema”,.
“frames”, “scenes”, and more; see k¨ovecses (2020).
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6724–6736august1–6,2021.©2021associationforcomputationallinguistics6724evoke desired corresponding source domain(s).3for example, given the literal sentence the partyended as soon as she left evoking the target domaincause to end, we can apply a variety of con-ceptual mappings to generate different metaphoricoutputs evoking different source domains (see fig-ure 1).
this allows us to generate metaphoric ex-pressions that match known metaphoric mappings,as well as generating from unseen mappings toexplore novel metaphors.
our contributions are:.
• two metaphor generation models groundedin cmt: 1) an unsupervised lexical modelrelying on frame embeddings learned fromframenet (cm-lex, section 3.1) and 2) abart (lewis et al., 2020) model encod-ing source/target domain information throughﬁne-tuning (cm-bart, section 3.2)..• two metaphor generation tasks: 1) generatemetaphoric expressions from known conceptmappings, for which we provide gold standardtest data, and 2) generate novel expressionsfrom unknown metaphors using rare and un-seen mappings (section 4)..• a thorough evaluation using both automaticand human evaluations (section 5).
we showthat our cm-bart model improves over allothers in terms of metaphoricity (by ≥ 7%)and domain evocation (by ≥ 33%), and cm-lex is competitive with previous neural mod-els on metaphoricity while outperformingthem on domain evocation (by ≥ 13%)..2 task deﬁnition.
traditional metaphor generation models focus onlyon whether the generated output is in some way“metaphoric” or not.
this ignores the semanticand cognitive properties inherent in metaphoric-ity.
these models can, to some degree, generatemetaphors given a literal input, but these outputsoften do not evoke the intended metaphor..controlled metaphor generation yields criticalbeneﬁts over these uncontrolled systems.
for sen-tences in context, having metaphors that are consis-tent with the text is essential for natural understand-ing.
also, metaphors are not only used to expresshuman knowledge, but can also help shape ourunderstanding of the world: having ﬁne-grainedcontrol over the generation process allows us to.
3we note that this source and target terminology used here.
is opposite to that in machine translation..explore novel metaphoric mappings and perhapsimprove our understanding of the related domains.
to achieve controlled metaphor generation, wedeﬁne our task as follows: given a literal inputsentence which evokes a target domain and an in-tended conceptual mapping, generate a metaphoricsentence such that it evokes a desired source do-main.
thus, our generation models receive threeinputs: 1) a literal input sentence (they arguedagainst the contract), 2) the target domain evokedby the literal input (argument) and 3) the de-sired source domain (war) for the metaphoricalsentence.
the output is a metaphorical sentencewhich evokes the intended mapping (they foughtagainst the contract).
3 methods.
we experiment with two general categories for gen-eration.
first, following previous work in metaphorgeneration and interpretation (mao et al., 2018;stowe et al., 2020), we implement lexical meth-ods for replacement, identifying relevant verbs andreplacing them with potential candidates for evok-ing particular mappings.
second, we experimentwith deep learning models, employing controlledsequence-to-sequence generation..3.1 cm-lex.
metaphor generation can be conceptualized as ﬁnd-ing key words and replacing them with metaphoriccounterparts.
this can be done by employing vec-tor spaces, identifying the word most likely to ﬁtin an appropriate context and subjecting them tosome constraints of metaphoricity.
we build onthis paradigm by incorporating facets of concep-tual metaphor theory..our procedure is as follows: we learn a jointembedded representations for domains and lexicalitems.
we then use the linear transformation be-tween two domains as a mapping, which can be ap-plied to input words from the target domain to gen-erate a word from the source domain.
as a proxyfor domains, we utilize framenet (baker et al.,1998), which contains semantic frames along withthe set of lexical units that evoke them.
frames canbe deﬁned as related systems of concepts (fillmore,1982), which is exchangeable with the term “do-main” used in conceptual metaphor theory (cruseand croft, 2004).
thus, we consider the transfor-mation from one frame to another as a proxy for aconceptual metaphoric mapping..6725we ﬁrst train framenet frame embeddings andemploy evaluation metrics to ensure their quality.
we then apply transformations between domainsto literal verbs to generate metaphors grounded inconceptual metaphor theory..3.1.1 learning frame embeddings.
in order to exploit framenet frames as concep-tual domains, we will embed them in vector space.
while lexical and contextualized embeddings haveproven effective, the ﬁeld of embedding conceptsfrom lexical resources is less well explored (sikosand pad´o, 2018; alhoshan et al., 2019).
thesemethods involve tagging raw corpora using auto-matic framenet parsing and then inputting somecombination of the original text and the framenetinformation into standard embedding algorithms.
to train and evaluate frame embeddings, we use211k sentences of gold annotations used to trainthe open-sesame parser (swayamdipta et al.,2017), along with a variety of other automaticallytagged datasets: 250k individual sentence from thegutenberg poetry corpus (jacobs, 2018), 17k fromvarious ﬁction section of the brown corpus (fran-cis and kucera, 1979), and 80k sentences randomlyselected from wikipedia.
from this, we extract a 5-word context window for each verb, creating 1.8mverb instances.
we then replace the focus verb withits framenet frame label (either provided in thegold data, or tagged via the parser), and train em-bedding models on the resulting data.
this yieldsjoint embedding spaces that contain both commonwords and framenet frame embeddings..we deﬁne two intrinsic metrics to evaluate thequality of our produced embeddings to enable ﬁne-tuning and validation.
first, following sikos andpad´o (2018), we can evaluate quality based on thewords that evoke that frame.
framenet gives aset of lexical units (lus) that evoke each framef .
we calculate the lexical similarity by takingthe distance from the mean embedding of “local”words (w ∈ f ) to the mean embedding of a randomsample k of “distant” words (w (cid:54)∈ f ):.
lex(f ) = (cid:80)w∈f.
cos(ew,ef )|f |.
−.
cos(ew,ef )k.k(cid:80)w(cid:54)∈f.
this lexical metric (lex) is evaluates whetherthe frame embedding is similar to words within itsframe and dissimilar to those without..framenet also contains linking relations be-tween frames (eg.
used-by, uses), yielding ahierarchy of connected frames.
starting with theassumption that frames connected in the structure.
figure 2: lexical generation process.
should be more similar, we also calculate a struc-tural similarity metric str.
we follow the sameprocess as above, taking the distance between themean embedding of the local frames n ∈ n , wheren is the immediate neighbors of f , to the meanembedding of a sample k of distant frames n /∈ n ..str(f ) = (cid:80)n∈n.
cos(en,ef )|n |.
−.
cos(en,ef )k.k(cid:80)n(cid:54)∈n.
we experiment with three lexical embeddingsmodels: word2vec skip-gram (mikolov et al.,2013), glove (pennington et al., 2014), and fast-text (bojanowski et al., 2017).
we experimentwith 50, 100, and 300 dimensional representations;we ﬁnd the 50 dimensional word2vec embeddingsperform best for both evaluation metrics.4.
3.1.2 embedding mappings.
to apply these embeddings to generate metaphorsbased on conceptual mappings, we learn mappingsbetween frames and apply the mappings directly tolexical items to facilitate lexical replacement..we deﬁne a mapping m as the pointwise dis-tance between the target frame embedding andthe source frame embedding.
following the ap-proach for learning connections between concreteand poetic themes of gagliano et al.
(2016), wesum the embedding of the target verb and the map-ping m for the selected conceptual mapping, andselect the most similar word to the resulting vector.
this word is then delemmatized using fitbert(havens and stal, 2019) and inserted into the origi-nal sentence (figure 2)..note that these resulting words are generatedwithout context, as they rely only on the input wordand the conceptual mappings.
this approach hasbeneﬁts: we require no labeled metaphor data, us-ing only embeddings trained on framenet-taggedcorpora.
however, ignoring context is likely detri-mental.
in order to better use contextual infor-mation, we explore state-of-the-art sequence-to-sequence modeling..4for full frame embedding evaluation, see appendix a..6726literal (ﬁlled from lm)that tyranny is destroyedthe house where love had endedas the moments passed onwhat i learned my senses fraught.
target frame.
destructioncause to endprocess end.
metaphoric (original)that tyranny is slainthe house where love had diedas the moments roll on.
coming to believe what i bear my senses fraught.
source frame.
killingdeathcause motionbringing.
table 1: sample of extracted pairs from the data collection process..3.2 cm-bart.
for sequence-to-sequence learning, we ﬁne-tunea pre-trained bart model (lewis et al., 2020),adding source and target information to guide gen-eration towards the intended metaphors.
we ﬁrstoutline a procedure for generating semi-supervisedpaired data, then detail the training and generationprocess..3.2.1 method for creating parallel data.
in order to train sequence-to-sequence modelsfor metaphor generation, we require large scaleparallel corpora.
we follow the approach ofchakrabarty et al.
(2021) and build a corpus ofliteral/metaphoric paraphrases by starting with thegutenberg poetry corpus (jacobs, 2018), identify-ing and masking metaphoric verbs, and replacingthem with inﬁlling from a language model.
weuse a bert-based metaphor classiﬁcation modeltrained on the vua metaphor corpus (steen et al.,2010) to identify metaphoric verbs in a sentence(i.e “died” in the house where love had died).
thenwe convert it to a literal sentence (the house wherelove had ended) using inﬁllings from pre-trainedbert (devlin et al., 2019)..to ensure the literal sentence with replace-ments convey the same semantic meaning as themetaphorical sentence they are then ﬁltered usingsymbolic meaning (symbolof relation) obtainedfrom comet (bosselut et al., 2019), a gpt basedlanguage model ﬁne-tuned on conceptnet (speeret al., 2017).
comet returns top 5 symbolicbeams of (loss, loneliness, despair, sadness andsorrow) for the sentence “the house where lovehad died” whereas it replaces sorrow with life forthe literal version.
while chakrabarty et al.
(2021)ﬁlter down to only those candidates with an exactmatch between the top 5 symbolic beams for theliteral and metaphorical sentences returned by thecomet model, we ease the restriction to caseswhere at least four of ﬁve symbols are the same..in order to learn more direct metaphoric in-formation from this data, we additionally tageach sentence with framenet frames using theopen-sesame parser (swayamdipta et al., 2017)..we extract each pair in which both the focusword in the literal, target-domain sentence and themetaphoric, source-domain sentence are assigneda framenet frame.
we then make the assumptionthat the relation between the frames for the sourceand target domains reﬂects a metaphoric mapping.
this then yields a dataset of paired sentences forwhich we have a metaphoric mapping between do-mains based on framenet for the focus verbs..samples of the created data are shown in table 1.in total this process yields 248k sentences spanning8.5k unique mappings between framenet frames.
each pair comprises a literal and metaphoric sen-tence, along with the literal target frame and themetaphoric source frame.
from these we can di-rectly train a sequence to sequence model for con-ceptual metaphor-based generation..3.2.2 modelswe ﬁne-tune bart (lewis et al., 2020), a pre-trained conditional language model that combinesbidirectional and auto-regressive transformers, onthe created parallel corpora described in section3.2.1. we incorporate representations of the frameinformation to allow this model to control for themetaphoric mappings evoked..to transform a literal sentence from a given tar-get domain to a metaphorical sentence evoking aspeciﬁc source domain, we incorporate both targetand source domains (as framenet frames) into thetextual representation as a control code, followingthe work of schiller et al.
(2020) who used thisprocedure for argument generation.
following theexample from figure 1, the input literal text fed tothe bart encoder would be:.
• death (cid:104)eot (cid:105) the party (cid:104)v (cid:105) ended :cause to end (cid:104)v (cid:105) as soon as she left..where (cid:104)eot (cid:105) and (cid:104)v (cid:105) are delimiters, death isthe source frame, and cause to end the targetframe.
the decoding target is the metaphoric text“the party died as soon as she left”, which evokesthe cause to end is death mapping..note that our training data differs only at thelevel of a single verb.
we use the generative bartseq2seq model to generate metaphoric paraphrases,.
6727but due to the nature of the training data and the im-portance of verbs in metaphoric expressions, this isoften realized in the output as lexical replacement.
post ﬁne-tuning, we use top-k (k=5) sampling(fan et al., 2018) to generate metaphors condi-tioned on the input literal sentence and source andtarget domains for the required metaphoric map-ping.5 we evaluate the lexical model (cm-lex)and the sequence-to-sequence model (cm-bart)under two experimental settings..4 experimental setup.
we evaluate our metaphor generation methodsagainst two previous approaches to metaphoricparaphrase generation:the mermaid system(chakrabarty et al., 2021) and the metaphor mask-ing model (metmask) (stowe et al., 2020).
weexplore two tasks: generating against gold standardmetaphoric expressions, and using rare and unseenmetaphoric mappings.
for the former, we build agold test set of metaphoric paraphrases that evoke aparticular source/target mapping.
for the latter, weapply a variety of source/target mappings to literalinputs for which we do not have gold outputs..4.1 building a test set.
for a test set, we use the same procedure as ourdata collection approach from section 3.2.1. we ap-ply this procedure to two datasets: a sample of thegutenberg poetry corpus and a sample of ﬁctionfrom the brown corpus (francis and kucera, 1979).
this generates an initial set of literal/metaphoricpairs.
we also tagged the pairs from mohammadet al.
(2016) with framenet tags, as these generallycontain novel, well-formed metaphors.
these threedatasets each have different properties with regardto metaphor.
the gutenberg poetry corpus hasconsistent, novel metaphors, but often unconven-tional syntactic constructions, due to the poeticnature of the text.
the mohammad 2016 corpuscontains manually constructed metaphors whichare novel, following relatively basic syntactic pat-terns.
the brown corpus is standard ﬁction texts,so the metaphors within tend to be very conven-tional..from these sources, we draw pairs randomly,checking that they reﬂect strong literal/metaphoricparaphrases until we obtain 50 instances from eachset.
each pair is tagged with framenet frames forthe focus verbs, which comprise the metaphoric.
5full parameter tuning outlined in appendix c..mapping.6 for the brown corpus, metaphoric ex-pressions were relatively rare, and thus valid pair-ings were sparse: to overcome this, we manuallymodiﬁed 11 of the expressions to evoke the appro-priate metaphoric mappings.
lit-processeral/metaphoric pairs, along with the sourceand target frames that they evoke.
we use thisdataset to evaluate generating metaphors based onmappings with gold standard outputs, using bothautomatic and human-based evaluations..yielded.
total.
150.this.
in.
4.2 expanding to unknown metaphors.
to explore the ﬂexibility of the system developed inthis study, we also evaluate them for generation ofmetaphoric expressions that are not directly linkedto gold literal/metaphoric pairs.
for this, we be-gin with our 150 pairs from above, but consideronly the literal sentence and the evoked target do-main.
for each sentence, we generate two sourcedomains that could potentially map to the target.
these are selected in order to identify rare and un-seen mappings based on the observed mappings inour training data.
for rare mappings we select asource domain at random from the mappings withthe median frequency for a given target domain.
for unseen mappings we select a source domain atrandom from the framenet frames that are neverused as a source for the given target domain..this set contains only the tuple (input sentence,target domain, source domain) needed as inputto our models; we do not have gold generatedmetaphorical utterances.
thus, on this set we willonly perform human-based evaluation of the qual-ity of the generated metaphors..4.3 automatic evaluation metrics.
word overlap metrics (eg.
bleu, rouge) areinherently weak for this task, as these sentencesinherently have high overlaps.
so instead, we em-ploy semantic distance metrics.
we generate sen-tence embeddings using sbert7 (reimers andgurevych, 2019) for each of our components: theliteral input l, the original gold metaphoric expres-sion m , and the generated output g..6in 22 cases, parsing errors in framenet frames were man-.
ually corrected..7speciﬁcally using the roberta-large model, which.
shows the best performance for sentence similarity tasks..6728modelmetmaskmermaidcm-lexcm-bart.
dis.191.147.151.085.rel mean %=.087.143.094.133.117.087.107.122.086.293.066.047.table 2: automatic evaluation for metaphor generationsystems.
%= indicates the percentage that matched thegold metaphor exactly..4.3.1 distance from gold metaphor (dis)the generated metaphoric expressions shouldmatch the semantics of the original gold metaphor.
we can evaluate this using the cosine distance,here between m and g. as sbert embeddingshave been shown to reﬂect semantic similarity andentailment between paired sentences, this metricshould be capable of capturing whether the gener-ated metaphoric expression matches the gold..4.3.2 relational distance (rel)assuming that conceptual metaphoric mappingsare responsible for the connecting of meaning be-tween our literal and metaphoric sentences, wewould also expect there to be a relation that holdsbetween the original literal input l and metaphoricoutput m .
this relation should also hold betweenthe l and the generated metaphor g. as a sim-ple metric we can employ cosine distance: we aimfor minimizing the distance between cos(l, m )between cos(l, g)..finally, we include the percentage of times the.
model produced the exact gold output..5 results and analysis.
results for automatic evaluation on the 150 goldmetaphors are shown in table 2. note that we can-not automatically evaluate against rare or unseenmetaphoric mappings, as we lack gold metaphors.
the cm-lex model is competitive with the bestneural baseline, which is encouraging.
this showsthat simply incorporating basic understanding ofconceptual mappings can be a powerful tool formetaphor generation.
the cm-bart yields thebest automatic performance over all metrics, sig-niﬁcantly outperforming all other models (p < .01,paired t-test.)..
automatic metrics allow us to quickly prototypemetaphoric generation systems based in conceptualmetaphor theory.
however, they rely on sbertand inherit the biases and weaknesses therein.
wealso perform human evaluations, against both thegold test data and the set of rare and unseen map-pings..modelmetmaskmermaidcm-lexcm-bart.
gold.
rare.
unseen.
met2.272.562.342.72.src met1.602.122.432.87.
--2.282.41.src met.
--2.102.70.
--1.582.41.src--1.142.01.table 3: human evaluations for metaphoricity (met)and source domain evocation (src)..5.1 human evaluation.
for human evaluation, we deﬁned two objectives.
first, we aim to capture the metaphoricity of theoutput, as a core objective.
the outputs shouldevoke novel, interesting metaphors regardless ofthe domains involved.
second, we want the gen-erated metaphoric outputs to evoke the source do-mains (eg.
“she destroyed his argument” evokesthe source domain of war)..we recruited three domain experts in metaphoric-ity.
they were instructed to rate each instance on ascale from 1 (not at all) to 4 (very) for metaphoric-ity and for whether it evokes the source domain.
if the sentence was completely unintelligible, theywere instructed to mark it as 0 for both categories.
for metaphoricity, annotators were given brief def-initions of metaphoricity which they incorporatedinto their expert knowledge to best rate metaphors.
for source domain evocation, they were addition-ally provided with links to the respective framenetframes..we evaluate three different models for the goldmetaphors: the best performing previous model,mermaid, as well as the lexical and cm-bartmodels.
for all models we evaluate generationusing the mappings for our gold test set.
for the un-known metaphors without gold sentences, we onlyevaluate our two controlled models, as the genericbaselines give the same output regardless of theintended source.
this yields a total of 450 sen-tences (150 gold, 300 without) that are evaluatedfor metaphoricity and source domain..all three experts annotated a random set of 100training sentences, in order to determine the fea-sibility and agreement for this task.
agreementrates were .50 for metaphoricity and .37 for sourcedomain (krippendorff’s α).8.
5.1.1 gold test mappingsresults for human evaluations of gold, rare, andunseen metaphoric mappings are shown in table 3.with regard to the gold mappings, the cm-bartmodel performs best in metaphoricity and source.
8full annotation analysis can be found in appendix b..67291.
2.
3.
1.
2.
3.input/target/source.
he resisted the panic of vertigoself control isquarreling.
a dim aurora rises in my eastchange position on a scaleis residence.
people were running out of the theaterself motion isfluidic motion.
modelgoldmetmaskmermaidcm-lexcm-bartgoldmetmaskmermaidcm-lexcm-bartgoldmetmaskmermaidcm-lexcm-bart.
outputhe fought the panic of vertigohe got the panic of vertigohe felt the panic of vertigohe confrontations the panic of vertigohe disputed the panic of vertigoa dim aurora lives in my easta dim aurora kicked in my easta dim aurora hangs in my easta dim aurora stands in my easta dim aurora lives in my eastpeople were streaming out of the theaterpeople were clogged out of the theaterpeople were running out of the theaterpeople were boiling out of the theaterpeople were spilled out of the theater.
table 4: example outputs of each system along with the mean of their human evaluations..target/sourceoperate vehicle is.
rare: self motion.
unseen: death.
distributed position is.
rare: giving.
dispersal is.
rare: attempt.
unseen: warning.
unseen: surrendering possession.
modelinputcm-lexcm-bartcm-lexcm-bartinputcm-lexcm-bartcm-lexcm-bartinputcm-lexcm-bartcm-lexcm-bart.
outputthe car drove up alongside himthe car drove up alongside himthe car ran up alongside himthe car fell up alongside himthe car died up alongside himthe meat was covered in a fatty gravythe meat was raised in a fatty gravythe meat was given in a fatty gravythe meat was cut in a fatty gravythe meat was yielded in a fatty gravyat last the darkness began to dissolveat last the darkness began to gornat last the darkness began to tryat last the darkness began to giffenat last the darkness began to bite.
table 5: examples of system outputs on rare and unknown metaphoric mappings..met.
src.
3103.
3433.
4144.
1444.
4213.
0404.
1204.
1234.
1443.
1442.
1414.
0401.met.
src.
domain evocation.
cm-lex has middling perfor-mance for metaphoricity, but does well at generat-ing correct source domains.
the mermaid systemperforms well in terms of metaphor generation, butfails to capture the intended source domain..examples of each model’s generation are shownin table 4. in 1, we see that cm-lex generatesnoise, making the results unintelligible.
cm-bartis more robust, generating ﬂuent expressions, andshows evidence of conceptual mapping control,generating a metaphoric expression matching thesource domain.
in 2, the metmask and mermaidmodels generate reasonable metaphors, which donot evoke the intended domain.
cm-lex is better,generating “stand” which can reﬂect residence,while the cm-bart performs best, generating thegold metaphoric expression..in 3, we see that the unconstrained models gen-erate effective expressions: ”clog” is an evocativemetaphor, and ”running”, while literal, can matchthe intended domain via the idea of running water.
however, our controlled methods both generatenovel metaphors that directly evoke the source do-.
main, showing the effectiveness of incorporatingconceptual information in generation..overall, we see that the unconstrained models of-ten generate good metaphors, but lack consistencywith the input, as they are naive with regard tothe conceptual backing of these metaphoric expres-sions.
cm-lex is effective to some degree, evenwithout metaphoric training data, and cm-bartperforms best, generating novel metaphors that fre-quently match the intended metaphoric expression..5.1.2 unknown metaphor mappings.
cm-bart outperforms cm-lex for metaphoricityand source domain evocation for rare and unseensource domains.
examples of the two proposedmodels’ generated for rare and unseen metaphoricmappings are shown in table 5..example 1 shows the ideal case.
when given asource domain from a ”rare” mapping, the resultingmetaphor is fairly reasonable.
cm-bart gener-ates a metaphor consistent with the original seman-tics; cm-lex generates the literal utterance.
whenpresented with an unseen mapping in which oper-.
6730ating a vehicle is framed as death, we get diverseexpressions, both adding meaning to the original ut-terance.
cm-lex uses the verb ”fell” (albeit incor-rectly conjugated), which can be used to abstractlyevoke the death domain, while cm-bart directlyuses the verb ”die”.
the original expression canbe ambiguous as to whether the car stopped: theevoked metaphor enforces the stoppage of the car,and also provides color to the expression..example 3 highlights a key issue: when thesource and target domains are too incongruent, thegenerated expressions can be inconsistent.
cm-lexhere again generates noise.
however, cm-bartgenerates normal, expressive metaphors, which arenonetheless incompatible with the original literalinput, which denotes the lessening of darkness.
rather, cm-bart generates a metaphor express-ing perhaps growing darkness with the verb try anda dangerous darkness with the verb bite..this is a critical point with regard to concep-tual mappings.
not all pairs are available: theyrequire semantic consistency, and while generatingfrom any two pairs may yield insightful, interesting,and perhaps inspiring new metaphoric expressions,generating metaphoric paraphrases requires addi-tional knowledge of which source/target pairingsare compatible.
this generally supports notion ofinvariance and structure mapping, in which there isinherent structure within domains that needs to beconsistent in order to evoke metaphoric mappingsbetween them (gentner, 1983; lakoff, 1993)..it must be noted that the systems proposed herehave a distinct advantage in this task: we addframenet frames, which, while neither perfect nordesigned to capture metaphoricity, provide a strongsignal for which domains to generate in.
this high-lights a possible beneﬁt to the interaction betweendeep, pre-trained models such as bart and avail-able lexical resources: by combining these, weare able to leverage the strength of each to build apowerful metaphor generation system..6 related work.
we broadly cover two areas of related work: previ-ous computational approaches to cmt, and previ-ous approaches to metaphor generation..computational approaches to cmt.
thereare a variety of approaches to identifying con-ceptual metaphors themselves.
the cormet sys-tem (mason, 2004) was built to extract concep-tual metaphors based on selectional preferences.
of verbs.
shaikh et al.
(2014a) builds ”conceptualspaces” for source domains, using rule-based ex-traction of relations between lexical items.
theseconceptual spaces are then used to ﬁnd new concep-tual metaphors.
this process is extended to build arepository of linguistic and conceptual metaphors(shaikh et al., 2014b).
mohler et al.
(2014) fo-cus on identifying appropriate source domains formetaphoric expressions, using vector-based ap-proaches for metaphor interpretation..the idea of using frames to represent metaphoricdomains has been explored in the metanet project(dodge et al., 2015).
we however, restrict our workto framenet due to the coverage and availabilityof reliable automatic parsing..metaphor generation.
early work in metaphorgeneration was based in heuristics, learning to gen-erate relatively simple ”a is like b” representations(abe et al., 2006; terai and nakagawa, 2010).
in asimilar vein, veale (2016) uses template-like struc-tures to generate creative and metaphoric tweets..other works focus on identifying metaphoricmappings using wordnet clustering and selec-tional preferences (mason, 2004; gandy et al.,2013), syntactic relations to build propositiondatabases (ovchinnikova et al., 2014), and embed-ding based approaches to identify poetic relation-ships (gagliano et al., 2016).
however, the goal ofthese works is to generate mappings, rather thanlinguistic expressions that evoke them..amongst deep learning approaches yu and wan(2019) identify literal and metaphoric words incorpora based on selectional restrictions, and us-ing these to train sequence-to-sequence models formetaphor generation, albeit without reference toany input expression.
stowe et al.
(2020) gen-erates metaphors using masked language model-ing, masking metaphoric tokens in training in or-der to encourage metaphoric generation.
otherapproaches use novel methods for collecting lit-eral/metaphor pairs, training sequence-to-sequencemodels for simile generation and metaphoric para-phrasing (chakrabarty et al., 2020, 2021).
theseapproaches effectively generate ﬁgurative language,but the models have no knowledge of the under-lying metaphors, and thus simply generate un-grounded expressions.
this leads to outputs whichare possibly metaphoric, but contain no connec-tion to the input, eschewing the critical connectionsthat make novel metaphors powerful.
we insteadpropose methods for generating metaphoric para-.
6731phrases grounded in cmt..7 conclusions and future work.
in summary, we have shown two methods for in-corporating knowledge of conceptual metaphor the-ory in metaphor generation.
we trained framenetframe embeddings to represent conceptual do-mains, and applied shifts between them to generatemetaphors in an unsupervised fashion.
leverag-ing framenet further, we build a dataset of semi-supervised pairs that evoke conceptual metaphors,which can be used along with bart for controlledmetaphor generation.
this model achieves state-of-the-art performance in metaphor generation byboth automatic and human evaluations..future work can expand these models to go be-yond verbs, incorporating nominal and other typesof metaphors.
the next necessary step is to gobeyond lexicalized metaphors: good, consistentconceptual metaphors often span long stretches oftext, and we need to design models that can learnand generate metaphors over larger texts..ethical considerations.
although we use language models trained on datacollected from the web, which have been shown tohave issues with bias and abusive language (shenget al., 2019; wallace et al., 2019), the inductive biasof our models should limit inadvertent negative im-pacts.
unlike model variants such as gpt, bartis a conditional language model, which providesmore control of the generated output.
it should alsobe noted that our cm-bart model is ﬁne-tunedon the poetry corpus which is devoid of harmfuland toxic text especially targeted at marginalizedcommunities.
advances in generative ai inherently come withconcerns about models’ ability to deceive, per-suade, and misinform.
metaphorical language hasbeen shown to express and elicit stronger emotionthan literal language (citron and goldberg, 2014;mohammad et al., 2016) and to provoke emotionalresponses in the context of political discourse cov-ered by mainstream newspapers (figar, 2014).
weunderstand there may be concerns about buildinggenerative models for metaphors aimed at persua-sion.
social scientists distinguish persuasion frommanipulation based on two aspects: dissimulationand constraint (nettel and roque, 2012).
dissimu-lation involves concealing intention, which requireshiding information, whereas constraint involves re-.
moving options from the audience and forcing themto accept the conclusion.
our work on metaphorgeneration does not aim to hide information abouta topic or present it as the only choice, but aims toprovide the same sentence using more expressivelanguage..references.
keiga abe, sakamoto kayo, and masanori nakagawa.
2006. a computational model of the metaphor gen-eration process.
in proceedings of the 28th annualmeeting of the cognitive science society, pages 937–942, vancouver, canada.
psychology press..waad alhoshan, riza batista-navarro, and lipingzhao.
2019. semantic frame embeddings for de-tecting relations between software requirements.
inproceedings of the 13th international conference oncomputational semantics - student papers, pages44–51, gothenburg, sweden.
association for com-putational linguistics..collin f. baker, charles j. fillmore, and john b. lowe.
1998. the berkeley framenet project.
in 36th an-nual meeting of the association for computationallinguistics and 17th international conference oncomputational linguistics, volume 1, pages 86–90,montreal, quebec, canada.
association for compu-tational linguistics..piotr bojanowski, edouard grave, armand joulin, andtomas mikolov.
2017. enriching word vectors withsubword information.
transactions of the associa-tion for computational linguistics, 5:135–146..antoine bosselut, hannah rashkin, maarten sap, chai-tanya malaviya, asli celikyilmaz, and yejin choi.
2019. comet: commonsense transformers for au-tomatic knowledge graph construction.
in proceed-ings of the 57th annual meeting of the associationfor computational linguistics, pages 4762–4779,florence, italy.
association for computational lin-guistics..tuhin chakrabarty, smaranda muresan, and nanyunpeng.
2020. generating similes effortlessly like apro: a style transfer approach for simile generation.
in proceedings of the 2020 conference on empiricalmethods in natural language processing (emnlp),pages 6455–6469, online.
association for computa-tional linguistics..tuhin chakrabarty, xurui zhang, smaranda muresan,and nanyun peng.
2021. mermaid: metaphorgeneration with symbolism and discriminative de-coding.
in proceedings of the 2021 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, pages 4250–4261, online.
association forcomputational linguistics..6732francesca mm citron and adele e goldberg.
2014.metaphorical sentences are more emotionally engag-ing than their literal counterparts.
journal of cogni-tive neuroscience, 26(11):2585–2595..d. alan cruse and william croft.
2004. cognitive lin-guistics.
cambridge textbooks in linguistics.
cam-bridge university press..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..erik-lˆan do dinh, hannah wieland, and irynagurevych.
2018. weeding out conventionalizedmetaphors: a corpus of novel metaphor annota-in proceedings of the 2018 conference ontions.
empirical methods in natural language processing,pages 1412–1424, brussels, belgium.
associationfor computational linguistics..ellen dodge, jisup hong, and elise stickles.
2015.metanet: deep semantic automatic metaphor anal-in proceedings of the third workshop onysis.
metaphor in nlp, pages 40–49, denver, colorado.
association for computational linguistics..angela fan, mike lewis, and yann dauphin.
2018. hi-in proceedingserarchical neural story generation.
of the 56th annual meeting of the association forcomputational linguistics (volume 1: long papers),pages 889–898, melbourne, australia.
associationfor computational linguistics..vladimir figar.
2014. emotional appeal of conceptualmetaphors of conﬂict in the political discourse ofdaily newspapers.
facta universitatis, linguisticsand literature, 12(1):43–61..charles fillmore.
1982. frame semantics.
linguistics.
in the morning calm, 1:111–138..w. n. francis and h. kucera.
1979. brown corpusmanual.
technical report, department of linguis-tics, brown university, providence, rhode island,us..andrea gagliano, emily paul, kyle booten, andmarti a. hearst.
2016. intersecting word vectors totake ﬁgurative language to new heights.
in proceed-ings of the fifth workshop on computational lin-guistics for literature, pages 20–31, san diego, cal-ifornia, usa.
association for computational lin-guistics..lisa gandy, nadji allan, mark atallah, ophir frieder,newton howard, sergey kanareykin, moshe kop-pel, mark last, yair neuman, and shlomo arg-amon.
2013. automatic identiﬁcation of concep-in pro-tual metaphors with limited knowledge.
ceedings of the 27th aaai conference on artiﬁcial.
intelligence, pages 328–334, bellevue, washington.
aaai press..dedre gentner.
1983. structure-mapping: a theoreti-cal framework for analogy.
cognitive science, 7:1–5..sam havens and aneta stal.
2019. use bert to ﬁll in.
the blanks..arthur m jacobs.
2018. the gutenberg english po-etry corpus: exemplary quantitative narrative analy-ses.
frontiers in digital humanities, 5:5..zolt´an k¨ovecses.
2020..extended conceptual.
metaphor theory.
cambridge university press..george lakoff.
1993. the contemporary theory ofin andrew ortony, editor, metaphormetaphor.
and thought, pages 202–251.
cambridge universitypress..george lakoff and mark johnson.
1980. metaphorswe live by.
university of chicago press, chicagoand london..mike lewis, yinhan liu, naman goyal, mar-jan ghazvininejad, abdelrahman mohamed, omerlevy, veselin stoyanov, and luke zettlemoyer.
2020. bart: denoising sequence-to-sequence pre-training for natural language generation, translation,and comprehension.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 7871–7880, online.
associationfor computational linguistics..rui mao, chenghua lin, and frank guerin.
2018.word embedding and wordnet based metaphor iden-tiﬁcation and interpretation.
in proceedings of the56th annual meeting of the association for compu-tational linguistics, pages 1222–1231, melbourne,australia.
association for computational linguis-tics..james h martin.
2006. a corpus-based analysis of con-text effects on metaphor comprehension.
technicalreport..zachary j. mason.
2004. cormet: a computational,corpus-based conventional metaphor extraction sys-tem.
computational linguistics, 30(1):23–44..tomas mikolov, kai chen, greg corrado, and jeffreydean.
2013. efﬁcient estimation of word represen-tations in vector space.
corr, abs/1301.3781..saif mohammad, ekaterina shutova, and peter tur-ney.
2016. metaphor as a medium for emotion: anin proceedings of the fifth jointempirical study.
conference on lexical and computational seman-tics, pages 23–33, berlin, germany.
association forcomputational linguistics..michael mohler, bryan rink, david bracewell, andmarc tomlinson.
2014. a novel distributional ap-proach to multilingual conceptual metaphor recog-nition.
in proceedings of coling 2014, the 25th.
6733international conference on computational linguis-tics: technical papers, pages 1752–1763, dublin,ireland.
dublin city university and association forcomputational linguistics..ana laura nettel and georges roque.
2012. persua-sive argumentation versus manipulation.
argumen-tation, 26(1):55–69..myle ott, sergey edunov, alexei baevski, angelafan, sam gross, nathan ng, david grangier, andfairseq: a fast, extensiblemichael auli.
2019.in proceedings oftoolkit for sequence modeling.
the 2019 conference of the north american chap-ter of the association for computational linguistics(demonstrations), pages 48–53, minneapolis, min-nesota.
association for computational linguistics..ekatarina ovchinnikova, vladimir zaytsev, suzannewertheim,generat-and ross israel.
2014.ing conceptual metaphors from proposition stores.
cs.cl/1409.7619..jeffrey pennington, richard socher, and christophermanning.
2014. glove: global vectors for wordrepresentation.
in proceedings of the 2014 confer-ence on empirical methods in natural languageprocessing (emnlp), pages 1532–1543, doha,qatar.
association for computational linguistics..michael reddy.
1979. the conduit metaphor : a caseof frame conﬂict in our language about language.
in andrew ortony, editor, metaphor and thought,pages 284–324.
cambridge university press, cam-bridge..nils reimers and iryna gurevych.
2019. sentence-bert: sentence embeddings using siamese bert-networks.
in proceedings of the 2019 conference onempirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages3982–3992, hong kong, china.
association forcomputational linguistics..benjamin schiller, johannes daxenberger, and irynagurevych.
2020. aspect-controlled neural argumentgeneration.
arxiv preprint arxiv:2005.00084..samira shaikh, tomek strzalkowski, kit cho, tingliu, george aaron broadwell, laurie feldman,sarah taylor, boris yamrom, ching-sheng lin,ning sa, ignacio cases, yuliya peshkova, and kyleelliot.
2014a.
discovering conceptual metaphors us-in proceedings of theing source domain spaces.
4th workshop on cognitive aspects of the lexicon(cogalex), pages 210–220, dublin, ireland.
associ-ation for computational linguistics and dublin cityuniversity..samira shaikh, tomek strzalkowski, ting liu,george aaron broadwell, boris yamrom, sarahtaylor, laurie feldman, kit cho, umit boz, igna-cio cases, yuliya peshkova, and ching-sheng lin.
2014b.
a multi-cultural repository of automatically.
discovered linguistic and conceptual metaphors.
inproceedings of the ninth international conferenceon language resources and evaluation (lrec’14),pages 2495–2500, reykjavik, iceland.
europeanlanguage resources association (elra)..emily sheng, kai-wei chang, premkumar natarajan,and nanyun peng.
2019. the woman worked asa babysitter: on biases in language generation.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 3407–3412, hong kong, china.
association for computa-tional linguistics..jennifer sikos and sebastian pad´o.
2018. using em-beddings to compare framenet frames across lan-in proceedings of the first workshop onguages.
linguistic resources for natural language process-ing, pages 91–101, santa fe, new mexico, usa.
as-sociation for computational linguistics..robyn speer, joshua chin, and catherine havasi.
2017.conceptnet 5.5: an open multilingual graph of gen-eral knowledge.
in in thirty-first aaai conferenceon artiﬁcial intelligence., pages 4444–4451, sanfrancisco, california..gerard j. steen, aletta g. dorst, j. berenike herrmann,anna kaal, tina krennmayr, and trijntje pasma.
2010. a method for linguistic metaphor identiﬁ-cation: from mip to mipvu.
john benjamins..kevin stowe, leonardo ribeiro, and iryna gurevych.
arxiv.
2020. metaphoric paraphrase generation.
preprint arxiv:2002.12854..karen sullivan.
2013. frames and constructions in.
metaphoric language.
john benjamins..swabha swayamdipta, sam thomson, chris dyer, andnoah a. smith.
2017. frame-semantic parsing withsoftmax-margin segmental rnns and a syntacticscaffold.
arxiv preprint arxiv:1706.09528..asuka terai and masanori nakagawa.
2010. a com-putational system of metaphor generation with eval-uation mechanism.
in international conference onartiﬁcial neural networks, pages 142–147, thessa-loniki, greece.
springer..tony veale.
2016..round up the usual suspects:knowledge-based metaphor generation.
in proceed-ings of the fourth workshop on metaphor in nlp,pages 34–41, san diego, california.
association forcomputational linguistics..eric wallace, shi feng, nikhil kandpal, matt gardner,and sameer singh.
2019. universal adversarial trig-gers for attacking and analyzing nlp.
in proceed-ings of the 2019 conference on empirical methodsin natural language processing and the 9th inter-national joint conference on natural language pro-cessing (emnlp-ijcnlp), pages 2153–2162, hongkong, china.
association for computational lin-guistics..6734zhiwei yu and xiaojun wan.
2019. how to avoid sen-tences spelling boring?
towards a neural approachin proceed-to unsupervised metaphor generation.
ings of the 2019 conference of the north ameri-can chapter of the association for computationallinguistics: human language technologies, pages861–871, minneapolis, minnesota.
association forcomputational linguistics..figure 3: frame embedding evaluation metrics as datais added..a appendix a.results for each frame embedding method usingthe distance metrics deﬁned in section 3.1 areshown in table 6..figure 3 tracks these evaluation metrics as moredata is added to each algorithm.
the lexical eval-uation relatively stable, peaking in most cases be-tween .1 and .2. the word2vec embeddings main-tain their upward progression even at maximaldata: theoretically additional data could improvethese embeddings further.
the structural evaluationshows something very different: while word2vecand fasttext embeddings improve as data is added,showing some effects of model size, the gloveembeddings trend sharply negative at ﬁrst beforeproceeding beginning to improve..b appendix b.agreement rates were measured using krippen-dorff’s α. for metaphoricity, the mean score was.505, indicating moderate agreement.
however,given the difﬁculty of this task, we believe this tobe relatively stronger: see table 7 for comparisonto other work evaluating metaphor generation..for source domain annotation, annotators variedin the degree to which source domains were evoked.
initial agreement was relatively poor (.249): we per-formed a post-processing step, normalizing theirresults to a consistent mean.
this yields an agree-ment score of .387: which we deemed competitivefor the difﬁculty of the task.
as we have no directcomparison for evaluation, further work is required.
673550dimensionsword2vec .203fasttext .113.179.glove.
lex sim100.208.120.191.
300.205.117.212.str sim100.076.103-.136.
300.104.095-.108.
50.157.077.037.mean100.144.111.028.
300.154.106.052.
50.111.042-.106.table 6.
6. decoding strategy & hyper parameters:for decoding we generate metaphors fromour models using a top-k random samplingscheme (fan et al., 2018).
at each timestep,the model generates the probability of eachword in the vocabulary being the likely nextword.
we randomly sample from the k = 5most likely candidates from this distribution..paperdo dinh et al.
(2018)yu and wan (2019)chakrabarty et al.
(2020)stowe et al.
(2020)chakrabarty et al.
(2021)this work.
n.15,180 mturkmturkmturkmturkmturkexperts.
method agreement.16-.38 α-.36-.49 α--.505 α.
80900513900450.table 7: comparison of agreement rates for variousmetaphor evaluation tasks.
note that do dinh et al.
(2018) developed a real-valued scoring layer over an ex-isting corpus rather than evaluating generated outputs.
“-” indicates agreement is not reported..to reﬁne this type of evaluation process..c appendix c.for retrieving commonsense symbolism of the sen-tences, we use the pre-trained comet model 9and retrieve top 5 candidates for each input..1. no of parameters: we use the bart largecheckpoint (400m parameters) and use thefairseq implementation (ott et al., 2019)10..2. no of epochs: we ﬁne-tune pre-trainedbart for 25 epochs for cm-bart modeland save the best model based on validationperplexity..3. training time: our training time is 60 min-.
4. hardware conﬁguration: we use 4 rtx.
utes for cm-bart..2080 gpus..5. training hyper parameters: we use thesame parameters as the fairseq githubrepository where bart was ﬁne-tuned forthe cnn-dm summarization task with theexception of the size of each mini-batch, interms of the number of tokens, for which weused 1024.
11.
9https://github.com/atcbosselut/.
comet-commonsense.
10https://github.com/pytorch/fairseq/.
tree/master/examples/bart.
11https://github.com/pytorch/fairseq/blob/master/examples/roberta/readme.glue.
md.
6736