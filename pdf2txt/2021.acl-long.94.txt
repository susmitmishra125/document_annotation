more identiﬁable yet equally performant transformersfor text classiﬁcation.
rishabh bhardwaj1, navonil majumder1, soujanya poria1, eduard hovy21 singapore university of technology and design, singapore2 carnegie mellon university, pittsburgh, pa, usarishabh bhardwaj@mymail.sutd.edu.sg{navonil majumder, sporia}@sutd.edu.sghovy@cs.cmu.edu.
abstract.
interpretability is an important aspect ofthe trustworthiness of a model’s predic-tions.
transformer’s predictions are widelyexplained by the attention weights,i.e.,itsa probability distribution generated atself-attention unit (head).
current empiricalstudies provide shreds of evidence thatattention weights are not explanations byproving that they are not unique.
a recentstudy showed theoretical justiﬁcations to thisobservation by proving the non-identiﬁabilityof attention weights.
for a given input to ahead and its output, if the attention weightsgenerated in it are unique, we call the weightsidentiﬁable.
in this work, we provide deepertheoretical analysis and empirical observa-tions on the identiﬁability of attention weights.
ignored in the previous works, we ﬁnd the at-tention weights are more identiﬁable than wecurrently perceive by uncovering the hiddenrole of the key vector.
however, the weightsare still prone to be non-unique attentionsthat make them unﬁt for interpretation.
totackle this issue, we provide a variant of theencoder layer that decouples the relationshipbetween key and value vector and providesidentiﬁable weights up to the desired lengthof the input.
we prove the applicabilityof such variations by providing empiricaljustiﬁcations on varied text classiﬁcationthe implementations are availabletasks.
athttps://github.com/declare-lab/identifiable-transformers..1.introduction.
widely adopted transformer architecture (vaswaniet al., 2017) has obviated the need for sequen-tial processing of the input that is enforced in tra-ditional recurrent neural networks (rnn).
asa result, compared to a single-layered lstm orrnn model, a single-layered transformer modelis computationally more efﬁcient, reﬂecting in arelatively shorter training time (vaswani et al.,.
2017).
this advantage encourages the training ofdeep transformer-based language models on large-scale datasets.
their learning on large corporahas already attained state-of-the-art (sota) per-formances in many downstream natural languageprocessing (nlp) tasks.
a large number of sotamachine learning systems even beyond nlp (luet al., 2019) are inspired by the building blocks oftransformer that is multi-head self-attention (rad-ford et al., 2018; devlin et al., 2018)..an.
a model.
employing.
attention-basedmechanism generates a probability distribu-tion a = {a1, .
.
.
, an} over the n input unitsz = {z1, .
.
.
, zn}.
the idea is to perform aweighted sum of inputs, denoted by (cid:80)ni=1 aizi,to produce a more context-involved output.
theattention vector, a, are commonly interpreted asscores signifying the relative importance of inputunits.
however, counter-intuitively, it is recentlyobserved that the weights generated in the modeldo not provide meaningful explanations (jain andwallace, 2019; wiegreffe and pinter, 2019)..attention weights are (structurally) identiﬁableif we can uniquely determine them from the outputof the attention unit (brunner et al., 2019).
iden-tiﬁability of the attention weights is critical to themodel’s prediction to be interpretable and repli-cable.
if the weights are not unique, explanatoryinsights from them might be misleading..the self -attention transforms an input sequenceof vectors z = {z1, .
.
.
, zn} to a contextual-ized output sequence y = {y1, .
.
.
, yn}, whereyk = (cid:80)ni=1 a(k,i) zi.
the scalar a(k,i) captures howmuch of the ith token contributes to the contextual-ization of kth token.
a transformer layer consistsof multiple heads, where each head performs self-attention computations, we break the head compu-tations in two phases:.
• phase 1: calculation of attention weightsit involves mapping input tokens to.
a(k,i)..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1172–1182august1–6,2021.©2021associationforcomputationallinguistics1172key and query vectors.
the dot product of kthquery vector and ith key vector gives a(k,i)..• phase 2: calculation of a contextualized repre-sentation for each token.
it involves mappinginput tokens to the value vectors.
the con-textualized representation for kth token canbe computed by the weighted average of thevalue vectors, where the weight of ith token isa(k,i) computed in ﬁrst phase..the identiﬁability in transformer has been re-cently studied by brunner et al.
(2019) which pro-vides theoretical claims that under mild conditionsof input length, attention weights are not uniqueto the head’s output.
essentially their proof wasdedicated to the analysis of the computations in thesecond phase, i.e., token contextualization.
how-ever, the theoretical analysis ignored the crucialﬁrst phase where the attention weights are gener-ated.
intrinsic to their analysis, the attention identi-ﬁability can be studied by studying only the secondphase of head computations.
however, even if weﬁnd another set of weights from the second phase,it depends on the ﬁrst phase if those weights can begenerated as the part of key-query multiplication.
in this work, we probe the identiﬁability of at-tention weights in transformer from a perspectivethat was ignored in brunner et al.
(2019).
we ex-plore the previously overlooked ﬁrst phase of self-attention for its contribution to the identiﬁability intransformer.
during our analysis of the ﬁrst phase,we uncover the critical constraint imposed by thesize of the key vector1 dk.
the ﬂow of analysis canbe described as.
• we ﬁrst show that the attention weights areidentiﬁable for the input sequence length ds nolonger than the size of value vector dv (§3.1)(brunner et al., 2019)2.
• for the case when ds > dv, we analyse the at-tention weights as raw dot-product (logits) andthe softmaxed dot-product (probability sim-plex), independently.
an important theoreticalﬁnding is that both versions are prone to beunidentiﬁable..• in the case of attention weights as logits(§3.2.1), we analytically construct another setof attention weights to claim the unidentiﬁ-in the case of attention weights asability..1the size of key and query vector is expected to be the.
same due to the subsequent dot product operation.
2the sequence length denotes number of tokens at input..softmaxed logits (§3.2.2), we ﬁnd the atten-tion identiﬁability to be highly dependent on dk.
thus, the size of key vector plays an importantrole in the identiﬁability of the self-attentionhead.
the pieces of evidence suggest that thecurrent analysis in brunner et al.
(2019) ignoredthe crucial constraints from the ﬁrst phase intheir analysis..to resolve the unidentiﬁability problem, we pro-pose two simple solutions (§4).
for the regular set-ting of the transformer encoder where dv dependson the number of attention heads and token em-bedding dimension, we propose to reduce dk.
thismay lead to more identiﬁable attention weights.
alternatively, as a more concrete solution, we pro-pose to set dv equal to token embedding dimensionwhile adding head outputs as opposed to the regularapproach of concatenation (vaswani et al., 2017).
embedding dimension can be tuned according tothe sequence length up to which identiﬁability isdesired.
we evaluate the performance of the pro-posed variants on varied text classiﬁcation taskscomprising of ten datasets (§5)..in this paper, our goal is to provide concrete the-oretical analysis, experimental observations, andpossible simple solutions to identiﬁability of atten-tion weights in transformer.
the idea behind iden-tiﬁable variants of the transformer is—the harderit is to obtain alternative attention weights, the like-lier is they are identiﬁable, which is a desirableproperty of the architecture.
thus, our contributionare as follows:.
• we provide a concrete theoretical analysis ofidentiﬁability of attention weights which wasmissing in the previous work by brunner et al.
(2019)..• we provide transformer variants that areidentiﬁable and validate them empirically byanalysing the numerical rank of the attentionmatrix generated in the self-attention head ofthe transformer encoder.
the variants havestrong mathematical support and simple toadopt in the standard transformer settings..• we provide empirical evaluations on variedtext classiﬁcation tasks that show higher iden-tiﬁability does not compromise with the task’sperformance..11732 background.
2.1.identiﬁability.
a general trend in machine learning research is tomathematically model the input-output relationshipfrom a dataset.
this is carried out by quantitativelyestimating the set of model parameters that best ﬁtthe data.
the approach warrants prior (to ﬁtting)examination of the following aspects:.
• the sufﬁciency of the informative data to theestimate model parameters, i.e., practical iden-tiﬁability.
thus, the limitation comes from thedataset quality or quantity and may lead to am-biguous data interpretations (raue et al., 2009)..• the possibility that the structure of the modelallows its parameters to be uniquely estimated,irrespective of the quality or quantity of the avail-able data.
this aspect is called structural identiﬁ-ability.
a model is said to be structurally uniden-tiﬁable if a different set of parameters yield thesame outcome..in this work, we focus on the structural identiﬁa-bility (bellman and ˚astr¨om, 1970).
it is noteworthythat the goodness of the ﬁt of a model on the datadoes not dictate its structural identiﬁability.
simi-lar to brunner et al.
(2019), we focus our analysison the identiﬁability of attention weights, whichare not model parameters, yet demands meaningfulinterpretations and are crucial to the stability ofrepresentations learned by the model..2.2 transformer encoder layer.
we base our analysis on the building block oftransformer, i.e., the encoder layer (vaswani et al.,2017).
the layer has two sub-layers.
first sub-layer performs the multi-head self-attention, andsecond is feed-forward network.
given a sequenceof tokens {x1, .
.
.
, xds}, an embedding layer trans-forms it to a set of vector {z1, .
.
.
, zds} ∈ rde,where de denotes token embedding dimension.
tothis set, we add vectors encoding positional infor-mation of tokens {p1, .
.
.
, pds} ∈ rde..multi-head attention.
input to a head of multi-head self-attention module is w ∈ rds×de, i.e., asequence of ds tokens lying in a de-dimensionalembedding space.
tokens are projected to dq-sizequery, dk-size key, and dv-size value vectors usinglinear layers, resulting in the respective matrices -query q ∈ rds×dq , key k ∈ rds×dk , and value.
figure 1: an illustration for a transformer with two-headattention units.
triangles depict matrix weights.
the leftside shows concatenation of head outputs fed to a linear layer.
the right side shows another interpretation of the same set ofoperations where we consider a linear transform applied toeach head ﬁrst.
the transformed head outputs are then added..v ∈ rds×dv .
the attention weights a ∈ rds×dscan be computed by.
a = softmax.
(1).
(cid:32).
(cid:33).
..q kt(cid:112)dq.
the (i, j)th element of a shows how much of ithtoken is inﬂuenced by jth token.
the output of ahead h ∈ rds×de is given by.
h = a v d = a t,(2)where d ∈ rdv×de is a linear layer and the ma-trix t ∈ rds×de denotes the operation v d. therds×de output of multi-head attention can be ex-pressed as a summation over h obtained for eachhead3.
the ith row of multi-head output matrixcorresponds to the de dimensional contextualizedrepresentation of ith input token.
in the originalwork, vaswani et al.
(2017), the multi-head op-eration is described as the concatenation of a vobtained from each head followed by a linear trans-formation d ∈ rde×de.
both the explanations areassociated with the same sequence of matrix opera-tions as shown in ﬁg.
1..in regular transformer setting, a token vectoris ti ∈ {(zj + pj)}dsi=1 is de = 512 dimensional,number of heads h=8, size of dk=dq=dv=de/h=64..feed-forward network.
this sub-layer per-forms the following transformations on each tokenrepresentation at the output of a head:.
y1 = linear1(norm(ti + head output for ti))y2 = norm(ti + relu(linear2(y1))).
linear1 and linear2 are linear layers with 2048and 512 nodes, respectively.
norm denotes mini-batch layer normalization..3for simplicity, we have omitted head indices..11743.identiﬁability of attention.
the output of an attention head h is the product ofa and t (eq.
(2)).
formally, we deﬁne identiﬁabil-ity of attention in a head:deﬁnition 3.1. for an attention head’s output h,attention weights a are identiﬁable if there exists aunique solution of a t = h..the above deﬁnition can be reformulated asdeﬁnition 3.2. a is unidentiﬁable if there exist an˜a, (˜a (cid:54)= 0), such that (a + ˜a) is obtainable fromphase-1 of head computations and satisfy(a + ˜a) t = a t =⇒ ˜a t = 0..(constraint-r1)under this constraint, we get ˜ai t = 0 where ˜aiis the ith row of ˜a.
the set of vectors which whenmultiplied to t gets mapped to zero describes theleft null space of t denoted by ln(t).
the dimen-sion of the left null space of t can be obtained bytaking the difference of the total number of rows(ds) and the number of linearly independent rows,i.e, rank of the matrix t denoted by rank(t).
letdim(·) denotes the dimension of a vector space,then.
ln(t) = {v | vt t = 0}dim (cid:0) ln(t)(cid:1) = ds − rank(t)..(3).
(4).
3.1.
“a” is identiﬁable for ds ≤ dv.
if dim(ln(t)) = 0 then ln(t) = {0}, it leadsto the only solution of constraint-r1 that is ˜a = 0.therefore, the unidentiﬁabilty condition does nothold.
now we will prove such a situation existswhen the number of tokens is not more than thesize of value vector..the matrix t in eq.
(2) is product of ds × dvvalue matrix v and dv × de transformation d. weutilize the fact that the rank of product of twomatrices p and q is upper bounded by the min-imum of rank(p) and rank(q), i.e., rank(p q) ≤min (cid:0) rank(p), rank(q)(cid:1).
thus, the upper boundon rank(t) in eq.
(4) can be determined by.
rank(t) ≤ min.
rank(v), rank(d).
(cid:17).
(cid:16).
(cid:16).
(cid:16).
(cid:16).
(cid:16).
≤ min.
≤ min.
min(ds, dv), min(dv, de)(cid:17).
(cid:17).
ds, dv, dv, de(cid:17).
≤ min.
ds, dv.
(as de > dv).
(5).
= min.
ds, 64.
(cid:17).
where the last inequality is obtained for a head inthe regular transformer for which dv=64..figure 2: numerical rank of t (imdb) and dimension of itsleft null space are scattered in blue and red, respectively..numerical rank.
to substantiate the bounds onrank(t) as derived above, we set up a model witha single encoder layer (§6).
the model is trainedto predict the sentiment of imdb reviews (§5).
wefeed the review tokens to the model and store thevalues generated in t of the ﬁrst head.
a standardtechnique for calculating the rank of a matrix withﬂoating-point values and computations is to usesingular value decomposition.
the rank of the ma-trix will be computed as the number of singularvalues larger than the predeﬁned threshold4.
theﬁg.
2 illustrates how the rank changes with the se-quence length ds.
the numerical rank providesexperimental support to the theoretical analysis.
(cid:26) dsdv.
if ds ≤ dv,if ds > dv..rank(t) =.
(6).
thus,.
dim (cid:0) ln(t)(cid:1) = ds − rank(t).
(cid:26) 0.
=.
(ds − dv)= max (ds − dv, 0).
if ds ≤ dv,if ds > dv..(7)with this, we infer a is identiﬁable if ds ≤ dv = 64.for the identiﬁability study, since we focus ona model’s capability of learning unique attentionweights, we will assume t has the maximum ob-tainable rank set by its upper bound..3.2.idenitiﬁability when ds > dv(the hidden role of dk).
in this case, from eq.
(7), we obtain a non zerovalue of dim (cid:0) ln(t)(cid:1).
it allows us to ﬁnd inﬁ-nite ˜a’s satisfying (a + ˜a) t = a t. however,.
4the threshold value is max(ds, de) ∗ eps ∗ || t ||2.
theeps is ﬂoating-point machine epsilon value, i.e., 1.19209e-07in our experiments.
1175constraint-r1 demands ˜a to be obtainable from theﬁrst phase of self-attention.
as a ﬁrst step, we focusour analysis on the attention matrix without apply-.
(cid:18).
(cid:19).
q kt√dq.
.
the.
ing softmax non-linearity, i.e., a =.
analysis is crucial to identify constraints comingfrom the ﬁrst phase of self-attention in transformerthat impact identiﬁability.
insights from this willhelp us analyse softmax version of a..3.2.1 attention weights as logits.
since the logits matrix a is obtained from the prod-uct of q and kt , we can assert that.
rank(a) ≤ min (cid:0) rank(q), rank(kt )(cid:1)≤ min (cid:0)de, dk, dq, de= dk..(cid:1).
(8).
therefore, the rank of attention matrix producibleby the head in the ﬁrst phase of self-attention canat most be equal to the size of key vectors dk.
onthis basis, the head can produce only those a + ˜asatisfying.
rank(a + ˜a) ≤ dk.
(constraint-r2).
proposition 3.3. there exists a non-trivial ˜a thatsatisfy (a + ˜a) t = a t and constraint-r2.
hence,a is unidentiﬁable..i=1 λj.
proof.
let a1, .
.
.
, ads and ˜a1, .
.
.
, ˜ads denoterows of a and ˜a, respectively.
without the lossof generality, let a1, .
.
.
, adk be linearly indepen-dent rows.
for all j > dk, aj can be repre-sented as a linear combination (cid:80)dki ai, whereλji is a scalar.
next, we independently chooseﬁrst k rows of ˜a that are {˜a1, .
.
.
, ˜adk } fromln(t).
from the same set of coefﬁcients oflinear combination λji for i ∈ {1, .
.
.
, dk} andj ∈ {dk+1, .
.
.
, ds}, we can construct jth row of ˜aas ˜aj = (cid:80)dki ˜ai.
now, since we can constructthe jth row of (a + ˜a) from the linear combina-tion of its ﬁrst dk rows as (cid:80)dki (ai + ˜ai), therank of (a + ˜a) is not more than dk.
for a set ofvectors lying in a linear space, a vector formed bytheir linear combination should also lie in the samespace.
thus, the artiﬁcially constructed rows of˜a belongs to ln(t).
therefore, there exist an ˜athat establishes the proposition which claims theunidentiﬁability of a..i=1 λj.
i=1 λj.
3.2.2 attention weights as softmaxed logitsthe softmax over attention logits generates atten-tion weights with each row of a (i.e., ai’s) is con-strained to be a probability distribution.
hence, wecan deﬁne constraint over ˜a as(a + ˜a) ≥ 0˜a t = 0˜a 1 = 0..(p1).
(p2).
(p3).
p1 is non-negativity constraint on (a + ˜a) as itis supposed to be the output of softmax; p2 de-notes ˜a ∈ ln(t); p3 can be derived from the fact(a + ˜a)1 = 1 =⇒ (a 1 + ˜a 1) = 1 =⇒ ˜a 1 = 0as (a 1 = 1).
where 1 ∈ rds is the vector ofones.
the constraint in p2 and p3 can be com-bined and reformulated as ˜a[t, 1] = 0. followingthe similar analysis as in eq.
(7), we can obtaindim (cid:0) ln([t, 1])(cid:1) = max (cid:0)ds − (dv + 1), 0(cid:1).
dis-regarding the extreme cases when ai is a one-hotdistribution, brunner et al.
(2019) proved the exis-tence and construction of non-trivial ˜a’s satisfyingall the constraints p1, p2, and p3.5.
however, the proof by brunner et al.
(2019)missed the constraint-r2, hence the existence of anon-trivial ˜a satisfying only the set of constraintsp1, p2 and p3 may not be a valid proposition toclaim attention weights unidentiﬁability.
essen-tially, the work largely ignored the constraints com-ing from the rank of the matrix that produces a(cid:19)after softmax 6. let al denote logitsand softmax(al) = (a + ˜a), where softmax isoperated over each row of al.
we add an extraconstraint on al.
q kt√dq.
(cid:18).
rank(al) ≤ dk..(p4).
the constraint p4 conﬁrms if there exists a logitmatrix al that can generate (a + ˜a), given con-straints p1, p2, and p3 are satisﬁed.
the possibilityof such an al will provide sufﬁcient evidence thata is unidentiﬁable.
next, we investigate how theexistence of ˜a is impacted by the size of key vectordk (query and key vector sizes are the same, i.e.,dq=dk)..let (a + ˜a)(i, k) denotes (i, k)th element of thematrix.
we can retrieve the set of matrices al suchthat softmax(al) = a + ˜a, where.
al(i, k) = ci + log(a + ˜a)(i, k)5for the sake of brevity, we skip the construction method.
6(input to the softmax is equivalent to a in §3.2.1).
(9).
1176with token sequence length ds ranging from 66 to128 7. for each review, we construct 1000 ˜a’ssatisfying constraints p1, p2, and p3 —.
first, we train a transformer encoder-basedimdb review sentiment classiﬁer (§6).
we ob-tain an orthonormal basis for the left null space of[t, 1] using singular value decomposition.
to forman ˜a, we generate ds random linear combinationsof the basis vectors (one for each of its row).
eachset of linear combination coefﬁcients is sampleduniformly from [−10, 10].
all the rows are thenscaled to satisfy the constraint p1 as mentioned inbrunner et al.
(2019).
using eq.
(9), we obtain aminimum rank matrix al’s by putting c = −ˆa1.
figure 5 depicts the obtained numerical rank ofal.
we observed all the obtained al from (a + ˜a)(using eq.
(9)) are full-row rank matrices.
however,from the ﬁrst phase of self-attention, the maximumobtainable rank of al is dk = 64. thus, the experi-mentally constructed al’s do not claim unidentiﬁ-ability of a as it fails to satisfy the constraint p4,while for brunner et al.
(2019), it falls under thesolution set to prove unidentiﬁability as it meetsconstraints p1, p2 and p3..figure 3: column vectors (c + ˆak) of al, where a(i,k) rep-resents log(a + ˜a)(i, k)..for some arbitrary ci ∈ r; log denotes naturallogarithm.
as shown in ﬁg.
3, the column vectorsof al can be written as c + ˆa1, .
.
.
, c + ˆads..for an arbitrarily picked ˜a satisfying constraintp1, p2, and p3, the dimensions of afﬁne span s of{ˆa1, .
.
.
, ˆads} could be as high as ds − 1 (ﬁg.
4).
in such cases, the best one could do is to choosea ca ∈ s such that the dimension of the linearspan of {ˆa1 − ca, .
.
.
, ˆads − ca}, i.e., rank(al) isds − 1. hence, to satisfy p4, ds − 1 ≤ dk =⇒ds ≤ dk + 1. thus, the set of (a + ˜a) satisfyingconstraint p1, p2 and p3 are not always obtainablefrom attention head for ds > dk.
we postulate.
although it is easier to construct ˜a satis-fying constraints p1, p2 and p3, it is hardto construct ˜a satisfying constraint p4over the rank of logit matrix al.
there-fore, a becomes more identiﬁable as thesize of key vector decreases..figure 4: this is a simpliﬁed illustration for the caseds = 3. afﬁne space (translated linear subspace)spanned by vectors ˆa1, ˆa2 and ˆa3.
ca can be any ar-bitrary vector in afﬁne space.
by putting c = −ca, wecan obtain a linear subspace whose rank is equal to rankof the afﬁne subspace..experimental evidence.
we conduct an experi-ment to validate the minimum possible numericalrank of al by constructing ˜a.
for ˜a to be obtain-able from the phase 1, the minimum possible rankof al should not be higher than dk.
from imdbdataset (§5), we randomly sample a set of reviews.
figure 5: the blue curve denotes the expected rank of al’sobtained from (a + ˜a), where ˜a satisﬁes the constraints p1,p2, and p3.
the red curve denotes the maximum permissiblerank of al that is obtainable from phase 1 of the head..4 solutions to identiﬁability.
based on the identiﬁability analysis in §3, we pro-pose basic solutions to make transformer’s atten-tion weights identiﬁable..decoupling dk.
contrary to the regular trans-former setting where dk = dv, a simple approachis to decrease the value of dk that is the size of thekey and query vector.
it will reduce the possible.
7dim (cid:0) ln(t, 1)(cid:1) > 0 for ds > dv + 1 = 65.
1177solutions of ˜a by putting harder constraints on therank of attention logits, i.e., al in eq.
(9).
however,theoretically, dk decides the upper bound on di-mensions of the space to which token embeddingsare projected before the dot product.
higher theupper bound, more degree of freedom to choosethe subspace dimensions as compared to the lowerdk variants.
thus, there is a plausible trade-offwhen choosing between dk induced identiﬁabilityand the upper bound on the dimension of projectedspace..head addition.
to resolve the unidentiﬁabilityissue when sequence length exceeds the size ofvalue vector, we propose to keep the value vectorsize and token embedding dimension to be morethan (or equal to) the maximum allowed input to-kens, i.e., dv ≥ ds-max.
in vaswani et al.
(2017), dvwas bound to be equal to de/h, where de is tokenembedding dimension and h is number of heads.
this constraint on dv is because of the concatena-tion of h self-attention heads to produce de-sizedoutput at the ﬁrst sub-layer of the encoder.
thus, todecouple dv from this constraint, we keep dv = deand add each head’s output.8.
5 classiﬁcation tasks.
for the empirical analysis of our proposed solutionsas mentioned in §4, we conduct our experimentson the following varied text classiﬁcation tasks:.
5.1 small scale datasets.
imdb (maas et al., 2011).
the dataset for thetask of sentiment classiﬁcation consist of imdbmovie reviews with their sentiment as positive ornegative.
each of the train and test sets contain25,000 data samples equally distributed in both thesentiment polarities..trec (voorhees and tice, 2000).
we use the6-class version of the dataset for the task ofquestion classiﬁcation consisting of open-domain,facet-based questions.
there are 5,452 and 500samples for training and testing, respectively..sst (socher et al., 2013).
stanford sentimentanalysis dataset consist of 11,855 sentences ob-tained from movie reviews.
we use the 3-classversion of the dataset for the task of sentimentclassiﬁcation.
each review is labeled as positive,neutral, or negative.
the provided train/test/validsplit is 8,544/2,210/1,101..5.2 large scale datasets.
snli (bowman et al., 2015).
the dataset con-tain 549,367 samples in the training set, 9,842 sam-ples in the validation set, and 9,824 samples inthe test set.
for the task of recognizing textualentailment, each sample consists of a premise-hypothesis sentence pair and a label indicatingwhether the hypothesis entails the premise, con-tradicts it, or neutral..please refer to zhang et al.
(2015) for more de-.
tails about the following datasets:.
yelp.
we use the large-scale yelp review datasetfor the task of binary sentiment classiﬁcation.
there are 560,000 samples for training and 38,000samples for testing, equally split into positive andnegative polarities..dbpedia.
the ontology dataset for topic classi-ﬁcation consist of 14 non-overlapping classes eachwith 40,000 samples for training and 5,000 samplesfor testing..sogou news.
the dataset for news article clas-siﬁcation consist of 450,000 samples for trainingand 60,000 for testing.
each article is labeled inone of the 5 news categories.
the dataset is per-fectly balanced..ag news.
the dataset for the news articles clas-siﬁcation partitioned into four categories.
the bal-anced train and test set consist of 120,000 and 7,600samples, respectively..yahoo!
answers.
the balanced dataset for 10-class topic classiﬁcation contain 1,400,000 sam-ples for training and 50,000 samples for testing..amazon reviews.
for the task of sentimentclassiﬁcation, the dataset contain 3,600,000 sam-ples for training and 400,000 samples for testing.
the samples are equally divided into positive andnegative sentiment labels..except for the sst and snli, where the valida-tion split is already provided, we ﬂag 30% of thetrain set as part of the validation set and the rest70% were used for model parameter learning..6 experimental setup.
setting up the encoder.
we normalize the textby lower casing, removing special characters, etc.9.
9https://pytorch.org/text/_modules/.
8ds-max < de as in the regular transformer setting..torchtext/data/utils.html.
1178for each task, we construct separate 1-gram vo-cabulary (u ) and initialize a trainable randomlysampled token embedding (u × de) from n (0, 1).
similarly, we randomly initialize a (ds-max × de)positional embedding..the encoder (§2.2) takes input a sequence of to-ken vectors (ds × de) with added positional vectors.
the input is then projected to key and query vectorof size dk ∈ {1, 2, 4, 8, 16, 32, 64, 128, 256}.
forthe regular transformer setting, we ﬁx the num-ber of heads h to 8 and the size of value vectordv = de/h that is 64. for each token at the in-put, the outputs of attention heads are concatenatedto generate a de-sized vector.
for the identiﬁablevariant of the transformer encoder, dv = de = 512,this is equal to ds-max to keep it identiﬁable up tothe maximum permissible number of tokens.
theoutputs of all the heads are then added.
each to-ken’s contextualized representations (added headoutputs) are then passed through the feed-forwardnetwork (§2.2).
for classiﬁcation, we use the en-coder layer’s output for the ﬁrst token and pass itthrough a linear classiﬁcation layer.
in datasetswith more than two classes, the classiﬁer outputis softmaxed.
in the case of snli, we use theshared encoder for both premise and hypothesis;the output of their ﬁrst tokens is then concatenatedjust before the ﬁnal classiﬁcation layer.
we useadam optimizer, with learning rate =0.001, to min-imize the cross-entropy loss between the target andpredicted label.
for all the experiments, we keepthe batch size as 256 and train for 20 epochs.
wereport the test accuracy obtained at the epoch withthe best validation accuracy..numerical rank.
to generate the numerical rankplot on imdb dataset as shown in ﬁg.
2, we train aseparate transformer encoder-based classiﬁer.
fora particular ds value, we sample 100 reviews fromthe dataset with token length ≥ ds and clip each re-view to the maximum length ds.
the clipping willensure the number of tokens is ds before feedingit to the encoder.
the numerical rank is calculatedfor t’s obtained from the ﬁrst head of the encoder..7 results and discussion.
for the identiﬁable variant, similar to §3.1, weplot the numerical rank of t with input sequencelength as shown in ﬁg.
6. unlike ﬁg.
2, wheredim (cid:0) ln(t)(cid:1) linearly increases after ds = 64, weﬁnd the dimension is zero for a larger ds (∼ 380).
the zero dimensional (left) null space of t con-.
ﬁrms there exist no nontrivial solution to the con-straint constraint-r2, i.e., ˜a = {0}.
thus, theattention weights a are identiﬁable for a largerrange of length of the input sequence..figure 6: scatter plots in red and blue show rank(t)and dim (cid:0) ln(t)(cid:1), respectively, for matrices t ob-tained from the second phase of attention by feedingimdb samples to the encoder.
the green line showsthe desired rank(t) for which dim (cid:0) ln(t)(cid:1) = 0 andthus attention weights are identiﬁable..it is important that the identiﬁability of attentionweights should not come at the cost of reducedperformance of the model.
to investigate this issue,we compare the performance of the identiﬁabletransformer encoder against its regular settings(§6) on varied text classiﬁcation tasks..for the regular setting, as discussed in §4 as oneof the solutions, the transformer can be made iden-tiﬁable by decreasing the size of the key vectordk.
the rows of the table 1 corresponding to condenotes regular transformer setting with varyingsize of key vector.
we observe the classiﬁcationaccuracy at the lower dk is comparable or higherthan large dk values, thus, the enhanced identiﬁa-bility does not compromise with the model’s clas-siﬁcation accuracy.
however, we notice a generalperformance decline with an increase in the size ofthe key vector.
we speculate that for simple clas-siﬁcation tasks, the lower-dimensional projectionfor key and query vector works well.
however, asthe task becomes more involved, a higher dimen-sion for the projected subspace could be essential.
nonetheless, as we do not have strong theoreticalﬁndings, we leave this observation for future work.
another solution to identiﬁability is to increasedv to de and add the heads’ outputs.
this settingcorresponds to the add rows in the table 1. forkey vector size dk= 1, 2, and 4, we ﬁnd the iden-tiﬁable transformer’s performance is comparable.
1179dataset.
version.
imdb.
trec.
sst.
snli.
yelp.
dbpedia.
sogou.
ag news.
yahoo.
amazon.
conaddconaddconaddconaddconaddconaddconaddconaddconaddconadd.
10.8840.8880.8360.8410.6430.5990.6750.6830.9130.9140.9790.9790.9150.9150.9060.9020.6950.6970.9240.925.
20.8880.8850.8360.8420.6250.6180.6740.6770.9110.9150.9770.9780.9070.9080.9030.9080.6900.6950.9250.923.size of key vector (dk)160.8460.8860.8230.8410.6030.6280.6620.6730.8790.9150.9660.9780.8930.9130.8860.8970.6440.6930.9000.924.
80.8880.8840.8220.8420.6090.6330.6720.6760.8980.9140.9710.9770.9000.9040.9040.9060.6640.6930.9220.924.
320.8240.8820.7640.8360.5820.6290.6590.6690.8620.9160.9610.9730.8880.9140.8770.8990.6270.6940.8920.920.
640.8030.8770.7860.8090.5740.5920.6590.6630.8570.9100.9570.9700.8680.9100.8700.9010.6160.6880.8870.907.
40.8860.8870.8400.8350.6270.6280.6730.6740.9070.9160.9770.9790.8980.9060.9040.9070.6840.6960.9230.925.
1280.7880.8320.7060.8090.5730.5810.6550.6640.8490.9090.9510.9690.8580.9060.8700.8970.5970.6490.8820.896.
2560.7550.8250.7370.7710.5540.5860.6480.6550.8370.8910.9490.9640.8380.8990.8690.8930.5740.6830.8730.889.table 1: the test accuracy on varied text classiﬁcation tasks spread over ten datasets.
con means the regularconcatenation of heads with dv = de/h, add denotes encoder variant where dv = de and outputs of heads areadded.
in the regular transformer encoder con, the concatenation of dv-sized output of h heads followed byde × de linear transformation can be understood as ﬁrst doing linear dv × de linear transform of each head andthen addition of the transformed output (ﬁg.
1).
in the add variant, we ﬁrst add h dv-sized head outputs followedby de × de linear transformation..to the regular settings.
for dk ≥ 8, as a generalobservation, we ﬁnd the performance of add doesnot drop as drastically as con with an increase indk.
this could be due to the larger size of valuevector leading to the more number of parameters inadd that compensate for the signiﬁcant reductionin the model’s accuracy..on the large-scale datasets, we observe that addperforms slightly better than con.
intuitively, asshown in ﬁg.
1, we can increase the size of valuevector to increase the dimension of the space onwhich each token is projected.
a higher dimen-sional subspace can contain more semantic infor-mation to perform the speciﬁc task..even though the theoretical analysis shows thepossibility of a full row rank of t and identiﬁableattention weights, the t obtained from a trainedmodel might not contain all the rows linearly in-dependent as ds increases.
we can explain thisfrom the semantic similarities between words co-occurring together (harris, 1954).
the similarity iscaptured as the semantic relationship, such as dotproduct, between vectors in a linear space.
as thenumber of tokens in a sentence, i.e., ds increases, itbecomes more likely to obtain a token vector fromthe linear combination of other tokens..8 conclusion.
this work probed transformer for identiﬁabilityof self-attention, i.e., the attention weights can beuniquely identiﬁed from the head’s output.
withtheoretical analysis and supporting empirical evi-dence, we were able to identify the limitations ofthe existing study by brunner et al.
(2019).
wefound the study largely ignored the constraint com-ing from the ﬁrst phase of self-attention in the en-coder, i.e., the size of the key vector.
later, weproved how we can utilize dk to make the attentionweights more identiﬁable.
to give a more concretesolution, we propose encoder variants that are moreidentiﬁable, theoretically as well as experimentally,for a large range of input sequence lengths.
theidentiﬁable variants do not show any performancedrop when experiments are done on varied textclassiﬁcation tasks.
future works may analyse thecritical impact of identiﬁability on the explainabil-ity and interpretability of the transformer..acknowledgments.
this research is supported by a*star under itsrie 2020 advanced manufacturing and engineer-ing programmatic grant, award no.– a19e2b0098..1180ellen m. voorhees and dawn m. tice.
2000. thein proceed-trec-8 question answering track.
ings ofthe second international conference onlanguage resources and evaluation (lrec’00),athens, greece.
european language resources as-sociation (elra)..sarah wiegreffe and yuval pinter.
2019. attention isnot not explanation.
in proceedings of the 2019 con-ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 11–20..xiang zhang, junbo zhao, and yann lecun.
2015.character-level convolutional networks for text clas-siﬁcation.
arxiv preprint arxiv:1509.01626..references.
ror bellman and karl johan ˚astr¨om.
1970. on struc-tural identiﬁability.
mathematical biosciences, 7(3-4):329–339..samuel r bowman, gabor angeli, christopher potts,and christopher d manning.
2015. a large anno-tated corpus for learning natural language inference.
arxiv preprint arxiv:1508.05326..gino brunner, yang liu, damian pascual, oliverrichter, massimiliano ciaramita, and roger wat-tenhofer.
2019. on identiﬁability in transformers.
arxiv preprint arxiv:1908.04211..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training of deepbidirectional transformers for language understand-ing.
arxiv preprint arxiv:1810.04805..zellig s harris.
1954. distributional structure.
word,.
10(2-3):146–162..sarthak jain and byron c wallace.
2019. attention isnot explanation.
arxiv preprint arxiv:1902.10186..jiasen lu, dhruv batra, devi parikh, and stefanlee.
2019. vilbert: pretraining task-agnostic visi-olinguistic representations for vision-and-languagetasks.
in advances in neural information process-ing systems, pages 13–23..andrew l. maas, raymond e. daly, peter t. pham,dan huang, andrew y. ng, and christopher potts.
2011. learning word vectors for sentiment analy-sis.
in proceedings of the 49th annual meeting ofthe association for computational linguistics: hu-man language technologies, pages 142–150, port-land, oregon, usa.
association for computationallinguistics..alec radford, karthik narasimhan, tim salimans, andimproving language under-.
ilya sutskever.
2018.standing by generative pre-training..andreas raue, clemens kreutz, thomas mai-wald, julie bachmann, marcel schilling, ursulaklingm¨uller, and jens timmer.
2009. structural andpractical identiﬁability analysis of partially observeddynamical models by exploiting the proﬁle likeli-hood.
bioinformatics, 25(15):1923–1929..richard socher, alex perelygin, jean wu, jasonchuang, christopher d manning, andrew y ng,and christopher potts.
2013. recursive deep mod-els for semantic compositionality over a sentimenttreebank.
in proceedings of the 2013 conference onempirical methods in natural language processing,pages 1631–1642..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allin advances in neural information pro-you need.
cessing systems, pages 5998–6008..1181a background on matrices.
a.1 span, column space and row spacegiven a set of vectors v := {v1, v2, .
.
.
, vn}, thespan of v, span(v), is deﬁned as the set obtainedfrom all the possible linear combination of vectorsin v, i.e.,.
span(v) := {.
λivi | λi ∈ r, i ∈ {1, 2, .
.
.
, n}}..n(cid:88).
i=1.
the span(v) can also be seen as the smallest vectorspace that contains the set v..given a matrix a ∈ rm×n, the column spaceof a, cs(a), is deﬁned as space spanned by itscolumn vectors.
similarly, the row space of a,rs(a), is the space spanned by the row vectors ofa. cs(a) and rs(a) are the subspaces of the realspaces rm and rn, respectively.
if the row vectorsof a are linearly independent, the rs(a) will spanrm.
a similar argument holds between cs(a) andrn..a.2 matrix rank.
the rank of a matrix p (denoted as rank(p)) tellsabout the dimensions of the space spanned by therow vectors or column vectors.
it can also beseen as the number of linearly independent rows orcolumns.
the following properties hold.
rank (cid:0) p (cid:1) ≤ min.
(cid:17).
mp, np.
(cid:16).
(cid:16).
rank (cid:0) p q (cid:1) ≤ min.
rank(p), rank(q).
..(cid:17).
where, p and q are mp × np and mq × nq dimen-sional matrices, respectively..a.3 null space.
the left null space of a mp × np matrix p can bedeﬁned as the set of vectors v -.
ln (cid:0) p (cid:1) = {vt ∈ r1×mp | vt p = 0}.
(10).
if the rows of p are linearly independent (p isfull-row rank) the left null space of p is zero dimen-sional.
the only solution to the system of equationsv p = 0 is trivial, i.e., v=0.
the dimensions of thenull space, known as nullity, of p can be calculatedas.
dim (cid:0) ln(p)(cid:1) = mp − rank(p).
the nullity of p sets the dimensions of the spacev lies in.
in §3, we utilize our knowledge of ap-pendix a.2 and appendix a.3 to analyse identiﬁa-bility in a transformer..(11).
1182