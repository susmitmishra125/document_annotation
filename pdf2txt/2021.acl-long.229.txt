rational lamol: a rationale-based lifelong learning framework.
kasidis kanwatchara1∗, thanapapas horsuwan1∗, piyawat lertvittayakumjorn2,boonserm kijsirikul1, peerapon vateekul1†1 department of computer engineering, faculty of engineering,chulalongkorn university, thailand2 department of computing, imperial college london, uk{kanwatchara.k, thanapapas.h}@gmail.com, pl1515@imperial.ac.uk,{boonserm.k, peerapon.v}@chula.ac.th.
abstract.
lifelong learning (ll) aims to train a neu-ral network on a stream of tasks while retain-ing knowledge from previous tasks.
however,many prior attempts in nlp still suffer fromthe catastrophic forgetting issue, where themodel completely forgets what it just learnedin the previous tasks.
in this paper, we in-troduce rational lamol, a novel end-to-endll framework for language models.
in or-der to alleviate catastrophic forgetting, ratio-nal lamol enhances lamol, a recent llmodel, by applying critical freezing guided byhuman rationales.
when the human rationalesare not available, we propose exploiting unsu-pervised generated rationales as substitutions.
in the experiment, we tested rational lamolon permutations of three datasets from theeraser benchmark.
the results show thatour proposed framework outperformed vanillalamol on most permutations.
furthermore,unsupervised rationale generation was able toconsistently improve the overall ll perfor-mance from the baseline without relying onhuman-annotated rationales.
we made ourcode publicly available at https://github.
com/kanwatchara-k/r_lamol..1.introduction.
the grounds of lifelong learning (ll) stem fromthe ability of humans to continually acquire, consol-idate, and transfer knowledge and skills throughouttheir lifespan.
this ability is also important forreal-world natural language processing (nlp) ap-plications, where autonomous agents are requiredto interact with users from various domains throughcontinuous streams of information and language.
∗ equal contributions† corresponding author.
semantic drifts occur over time.
the existing dom-inant paradigm for machine learning, however, isisolated learning (chen and liu, 2016).
whileisolated learning has shown some successes in avariety of domains, their applicability remains lim-ited to the assumption that all samples are availableduring the learning phase.
when a stream of tasksare trained sequentially, machine learning and neu-ral network models face catastrophic forgetting orinterference (mccloskey and cohen, 1989).
thisoccurs due to the non-stationary data distributionthat biases the model..we focus on lifelong language learning (lll),which is lifelong learning on a stream of nlp tasks.
to the best of our knowledge, the grounds of lllare left largely underexplored.
lamol is an lllgeneral framework that has garnered recent interestdue to its simplicity (sun et al., 2020).
in particular,lamol transforms all nlp tasks into the questionanswering (qa) format according to mccann et al.
(2018) and generates pseudo-samples of old tasksusing its language modeling (lm) capability to re-fresh the learned knowledge.
however, there is stilla gap between the performance of lamol and theresult of multi-task learning which is generally con-sidered as the upper bound of lll performance.
this indicates that only pseudo-samples genera-tion may not be sufﬁcient to prevent catastrophicforgetting..in this paper, we improve existing lll strategiesby proposing rational lamol, a rationale-basedlifelong learning framework which equips the orig-inal lamol with critical freezing (nguyen et al.,2020) to further prevent catastrophic forgetting.
particularly, we devise an algorithm to identifycritical components in transformer-based languagemodels using rationales, and the selected compo-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2942–2953august1–6,2021.©2021associationforcomputationallinguistics2942nents will be frozen to maintain learned knowledgewhile being trained on a new task..the contributions of our paper are listed below:.
• we demonstrate the importance of freezingplastic components (i.e., components that aremost susceptible to change) in transformer-based models to strengthen memories of thepreviously learned tasks in the lll setting..• we propose critical component identiﬁcationalgorithm which analyzes the transformer-based lll model with rationales so as to ﬁndthe most plastic component to freeze.
thisstep is so called critical freezing, ﬁrstly de-vised in computer vision (nguyen et al., 2020)but we adapted it to nlp..• we propose that unsupervised generated ra-tionales by invrat (chang et al., 2020) canbe effectively used as substitutions of humanrationales, allowing our framework to be ap-plied to generic nlp datasets..we evaluated rational lamol on six task orderpermutations of three datasets from the eraserbenchmark (deyoung et al., 2020).
the resultsshow that our proposed framework outperformedthe original lamol on ﬁve out of the six permu-tations, achieving average improvements of 1.83%with a lower standard deviation of 4.57%.
more-over, using unsupervised rationale generation in-stead of human rationales also yielded competitiveperformance, achieving average improvements of2.67% from original lamol..2 background and related work.
in this section, we brieﬂy introduce the concept oflifelong learning, catastrophic forgetting, and com-ponent freezing which are relevant to the core ideaof rational lamol.
we also brieﬂy summarizeprominent researches related to rationales..lifelong learning and catastrophic forgettingwhile people ﬁne tune a pre-trained model toperform a single task, lifelong learning (ll) isa setting in which a learner performs sequen-tial learning of inﬁnitely incoming tasks τ ={τ1, τ2, ..., τi, ..., }, where τi is the i-th task to learnat a particular point in time.
the objective of the lllearner is to ideally both optimize the performanceon the new task and maintain optimal performanceon previous tasks τt for t = 0, 1, ..., i. moreover,.
the ability to transfer knowledge across differenttasks is also desired.
however, naively trainingon a sequence of tasks without accounting for thedifference in data distributions would result in anabrupt decrease in old tasks performance.
thisphenomenon is known as catastrophic forgetting(mccloskey and cohen, 1989).
there are multipleexisting works that aim to mitigate catastrophic for-getting in ll.
they can be categorized into threemajor approaches.
first, regularization methodsuse a regularization term to constrain changes whenupdating weights in a new task (kirkpatrick et al.,2017; aljundi et al., 2017; lee et al., 2017).
sec-ond, data-based methods disallow signiﬁcant devi-ation of weights from previous tasks by keeping asmall subset of data from the previous tasks or gen-erating pseudo-data to refresh the learned knowl-edge (lopez-paz and ranzato, 2017; chaudhryet al., 2019; de masson d’autume et al., 2019;li and hoiem, 2018).
third, architecture-basedmethods dynamically transform the neural networkarchitectures in order to accommodate new knowl-edge (rusu et al., 2016; chen et al., 2016)..lifelong language learning or lll is a sce-nario where a model sequentially learns from astream of nlp tasks in an ll manner.
to the bestof our knowledge, lll has rarely been studied andprevious works usually target a single type of nlptasks (chen et al., 2015; liu et al., 2019; de mas-son d’autume et al., 2019).
to go beyond this limi-tation, sun et al.
(2020) proposed lamol, a learn-ing framework that utilizes a language model to si-multaneously predict outputs and learn to generatepseudo-training examples, which are exploited toalleviate catastrophic forgetting.
hence, lamol,as well as our rational lamol, naturally falls intothe data-based ll approach since data from previ-ous tasks, albeit generated, is utilized to constraina model..component freezing while component freez-ing is also a common practice in the ﬁne-tuningprocess, it is done to prevent loss in general knowl-edge in lower layers of the model (raganato andtiedemann, 2018)..by contrast, many architecture-based ll meth-ods, for example rusu et al.
(2016), utilize compo-nent freezing to prevent changes to learned knowl-edge from previous tasks and enlarge the model toaccommodate new tasks, thereby making the modelimmune to forgetting.
our rational lamol also.
2943uses component freezing, but unlike architecture-based methods, only a small part of the model isfrozen and its size is constant throughout the learn-ing process..rationales rationales are reasons for labels orpredictions.
in nlp, they are usually parts of theinput texts which support or contribute to the classlabels.
rationales could be either annotated byhumans or generated by machine learning models.
human rationales have been used to enhance ma-chine learning in multiple studies.
for instance,rajani et al.
(2019) used the rationales to guidea neural network toward better reasoning.
baoet al.
(2018) utilized rationales as auxiliary infor-mation to train a neural network model, reduc-ing training examples required to achieve good re-sults.
recently, deyoung et al.
(2020) introducedthe eraser benchmark consisting of multipledatasets, all of which are annotated with humanrationales.
this facilitates the advancement of re-search on interpretable nlp.
in the experiment, weused human rationales from eraser in the criti-cal component identiﬁcation step to ﬁnd the mostplastic component to be frozen..meanwhile, some researchers attempt to de-sign architectures to predict rationales from la-belled data.
existing rationalization techniquescommonly use the maximum mutual information(mmi) criterion to select rationales, which is proneto choosing spurious correlation between input fea-tures and outputs as rationales (lei et al., 2016;yu et al., 2019).
to ﬁx this issue, invariant ra-tionalization (invrat) (chang et al., 2020) followsthe invariant risk minimization (irm) paradigm,as introduced by arjovsky et al.
(2019).
it utilizesthe environment variable to isolate and select thecausal features that faithfully explain the output.
inorder to allow rational lamol to be applied toany nlp dataset, we choose to leverage invrat toautomatically produce rationales due to its supe-rior performance and straightforward application,removing the need for human rationales..3 methodology.
we introduce rational lamol and its detailed im-plementation in this section.
as rational lamolis based from lamol (sun et al., 2020), we brieﬂyexplain lamol in section 3.1. then we intro-duce the core lifelong learning framework of ra-tional lamol in section 3.2. this is followedby two proposed enhancements including critical.
component identiﬁcation and unsupervised ratio-nale generation, detailed in section 3.3 and 3.4,respectively..3.1 lamol.
language modeling for lifelong language learn-ing (lamol) (sun et al., 2020) utilizes a singlelanguage model (lm) as a multipurpose model.
framing all tasks as question answering (qa), thelm now poses as a generic task-agnostic model.
in addition, lamol trains the lm as a generativemodel upon receiving a special generation token.
using a single model for both providing answersand generating pseudo-samples, lamol truly ex-hibits a model of lm and qa duality..the beneﬁt that comes with the generative partof the model tackles the long-standing issue of ll–catastrophic forgetting.
while other methods makeuse of extra memory or model capacity to preservea subset of real samples (lopez-paz and ranzato,2017; chaudhry et al., 2019) or to accomodate aseparate generator (shin et al., 2017; kemker andkanan, 2017), lamol transfers all the responsi-bilities into a single model.
it learns the abilityto select potentially prominent features beﬁttinglearning by modeling the input.
this allows themodel to replay meaningful pseudo-samples fromprevious tasks while forcing the model to memo-rize knowledge acquired from previous tasks tied tothe generation token.
in this paper, we propose ex-ploiting rationales with lamol to further improvethe lll performance, discussed next..3.2 rational lamol.
rational lamol, illustrated in figure 1 (right), isa learning framework revolving around the origi-nal methodologies of lamol.
we consider an llsetting where τ = {τ1, τ2, ..., τi, ...} is a stream oflearning tasks and τi is the i-th task to train at a par-ticular point in time.
let mi denote the model mafter being trained for task i, where m0 is the ini-tialized pre-trained model.
using these notationsand starting from m0, rational lamol worksiteratively in four steps as follows.
first, givena model mi, it trains mi with the task τi+1 us-ing lamol’s training procedure to obtain ˆmi+1.
second, for i > 0, it applies critical componentidentiﬁcation, which is described in section 3.3,on mi and ˆmi+1 with the rationales of task τi todissect the most plastic layers or blocks.
third, wetake a step back to work at mi and apply criticalfreezing, i.e., freezing the most plastic components,.
2944figure 1: left: the overview of lamol.
right: the overview of rational lamol, our proposed frameworkthat aims to alleviate catastrophic forgetting by freezing the critical component..figure 2: schematic illustration of the calculation of ioum,gt .
a: the input is fed through each attention blockatj, where each block j has multiple heads.
b: a single attention head atj,a consists of the attention of thesequence in relation to all other tokens, as shown in c. finally, the iou calculation f is applied on the hardselection of attention token with percentiles d and the rationale ground truth in e..i.i..
lastly, we train m cf.
to obtain m cfthroughthe task τi+1 again to get a new model mi+1 thatretains the most plastic memories.
note that de-spite the unique nature of lamol, our rationallamol does not limit its usage to a single modelarchitecture.
it has potential applications to generalattention-based models suffering from catastrophicforgetting through domain shifts across tasks..3.3 critical component identiﬁcation (cci).
we propose the critical component identiﬁcation(cci) algorithm, pointing out the most plastic blockof our transformer-based ll model before movingon to a new task completely.
(this shares the samespirit as nguyen et al.
(2020), proposing autodeepvis to ﬁnd the most plastic blocks of cnnmodels for image classiﬁcation.)
the chosen blockis the one that forgets what it has learned fromthe recent task the most when being introduced anew task, so we will freeze the block to preventcatastrophic forgetting in rational lamol..as shown in algorithm 1, for each validationsample x ∈ x of task i, the cci compares theattention maps at produced by the model mi (i.e.,the old model mo in algorithm 1) and ˆmi+1 (i.e.,the new model mn in algorithm 1) to ﬁnd the.
most plastic block b with respect to this sample.
then it returns the block f which is the mode ofall b, voted by most of the samples in x. note thatmost of the variable names are preserved similarto nguyen et al.
(2020) for ease of reference, andsome sections are refactored for readability..in particular, to ﬁnd b for the sample x, we iterateover all blocks j = 1, ..., k and perform two steps.
first, we ﬁnd the representative map of the blockj in mo with respect to the ground truth gt (i.e.,rmmo,gt (j)) by selecting the attention map ofthe attention head a∗ and the token s∗ in x from theblock j that is most similar to the human rationalefor the sample x (i.e., ground truth gt in algo-rithm 1).
although interpretable nlp stands to bea nascent subﬁeld for exploration (deyoung et al.,2020), elementary visualization of attentions arepossible in transformers (vig, 2019; hoover et al.,2020).
these self-attention mechanisms associatedistant positions of a single sequence and manyappear to exhibit behavior related to the sentences’syntactic and semantic structure (vaswani et al.,2017).
we hypothesize that the semantic nature ofthe self-attention mechanisms would opt for tokensmost relating to positive evidence vital for predic-tions, being analogous to rationales–snippets that.
2945algorithm 1 critical component identiﬁcationinput: validation set x, ground truth rationalegt , old model mo, new model mn , number ofblocks k.output: critical block f.ł← ∅for all validation sample x ∈ x do:.
ious ← ∅ato, atn ← [mo(x), mn (x)]for j = 1, k do:rmmo,gt ←.
atj,a∗,s∗ with highest ioumo,gt.
rmmn ,mo ←.
atj,a∗,s∗ with highest ioumn ,mo.
append(ious, max(ioumn ,mo )).
end forb ← arg minj iousappend(ł, b).
end forf = mode(ł)return f.support outputs.
to compute the similarity betweenattention maps and human rationales, we use inter-section over union (iou).
formally, the followingequations explain this step..after we obtain rmmo,gt (j) of the blockj, the second step ﬁnds the representative mapof the block j in mn with respect to mo (i.e.,rmmn ,mo (j)).
this can be done by replacingm and gt in equation 1-3 by mn and mo, re-spectively, and replacing gt on the right side ofequation 3 to be pβ(rmmo,gt (j)).
after that,we collect the maximum ioumn ,mo of the blockj which represents the amount of knowledge oftask i held in the model after we introduce taski + 1. therefore, the most plastic block b for thissample x is the block with the lowest maximumioumn ,mo ..actually, transformer blocks are not the ﬁnestgranularity that we could freeze.
since each blockcontains several attention heads, it is possible tofreeze some attention heads individually.
hence,we propose another algorithm, applying to heads.
this is similar to algorithm 1, but instead of search-ing for blocks with lowest maximum iou, the algo-rithm searches using both the attention blocks andattention heads together as keys.
although the deﬁ-nition of iou stays the same, the deﬁnition of therepresentative map will be at a higher granularity.
formally, for a block index j and attention head a,rmm,gt will be computed as:.
rmm,gt (j) = atj,a∗,s∗.
(1).
rmm,gt (j, a) = atj,a,s∗.
(4).
(a∗, s∗) = arg maxa∈a,s∈s.
(ioum,gt (j, a, s)).
(2).
where.
where.
and.
(s∗) = arg max.
(ioum,gt (j, a, s)).
(5).
s∈s.
ioum,gt (j, a, s) =.
pβ(atj,a,s) ∩ gtpβ(atj,a,s) ∪ gt.
(3).
and we can freeze top n heads that receives mostvotes from the samples in the validation set x..a is the set of all attention heads in the block, ands is the set of all tokens in x. ioum,gt (j, a, s)reﬂects the similarity between the ground truth andthe attention map of the block j, head a, and to-ken s in x. since the ground truth contains binarylabels indicating whether a token is a part of therationale or not, we need to convert the attentionmap atj,a,s into binary labels using pβ – a simplebinary thresholding which returns 1 for the valuegreater than the β-th percentile on the entire se-quence (otherwise, 0).
this is required as iouworks for comparing two binary masks.
figure 2visualizes how to compute the iou score by drillingdown each component of the model..3.4 unsupervised rationale generation.
as described in section 3.2, our framework re-quires rationales as an input.
however, most exist-ing nlp datasets are not annotated with rationales.
to overcome the limitation, we leverage a recentunsupervised rationale generation framework, in-vrat (chang et al., 2020) to generate rationalesas substitutions.
originally, invrat was designedfor single-input tasks such as sentiment analysis.
however, since some of the datasets we experi-mented with are text-pair classiﬁcation, we appendthe query (or question) at the end of each sampleto accommodate these tasks..2946datasetboolqmoviescifact.
# train6,3631,600405.
# val1,491200100.
# test metric2,817200188.em.
table 1: summary of datasets, dataset sizes, and theircorresponding metrics.
em represents an exact matchbetween texts..4 experimental setup.
4.1 datasets.
to evaluate our proposed framework, we conductedan experiment on three english text classiﬁcationdatasets, curated and made publicly available byeraser1 (deyoung et al., 2020).
all of the threedatasets, as listed below, are provided with ratio-nales marked by humans.
table 1 contains a sum-mary of the datasets, dataset sizes, and metrics..• boolq (clark et al., 2019): a dataset com-prises selected passages from wikipedia andnaturally occurring yes/no questions to be an-swered by the model..• movie reviews (zaidan and eisner, 2008): adataset composed of movie reviews.
it con-tains positive and negative sentiment labels tobe predicted by the model..• scifact (wadden et al., 2020): a datasetcontaining expert-written scientiﬁc claimscoupled with evidence-containing abstracts.
given a claim, the model has to identify if theabstract supports or refutes the claim..we ran our proposed framework on all six per-mutations of task order for three times with dif-ferent random seeds.
the average results are thenreported in section 5..4.2.implementation details.
we followed the best lamol conﬁguration fromsun et al.
(2020).
all parameters were kept at thedefault values.
for all methods, we use the smallgpt-2 model (radford et al., 2019) as the languagemodel.
each task was trained for ﬁve epochs.
weapplied greedy decoding during inference.
due toﬁne-tuning instability of neural network, in eachtask order, we used the same ﬁrst task model m1for all methods in each run for fair comparison..1https://www.eraserbenchmark.com/.
figure 3: average runtime in hours of various methods.
r-lamol, r-lamol (g), and partial brute force re-fer to rational lamol, generated rational lamol,and partial brute force block respectively..critical freezing was applied to a model withtwo different levels of granularity: block level andhead level.
the validation set of each task was usedas input to algorithm 1. for block level granularity,we chose to freeze the most frequent block obtainedfrom the algorithm, while for head level granular-ity, 12 heads chosen returned by the algorithm werekept frozen during training.
we used β = 80, i.e.,selecting the top 20 percentile of attention scoresto compare with ground truth rationales.
as theeraser benchmark has an average ratio of ratio-nale tokens to document tokens of around 9.4%,we allowed rationale selection to be two times theaverage ratio (i.e., 20%)..for invrat, we opted for 300-dimensional gloveembeddings (pennington et al., 2014).
the gen-erator and the predictor modules of invrat werebased on 1-layer bidirectional gated recurrent units(chung et al., 2014) with 256 hidden units as inchang et al.
(2020).
maximum model input wasset to 1,024 tokens.
all hyperparameters for eachtask were tuned on the validation set..5 results and discussion.
this section reports the performance of rationalelamol and compares it with lamol as the base-line as well as multitask learning, which is consid-ered as the upper bound of ll.
we also analyze theeffect of each component in the proposed frame-work..5.1 effect of component freezing.
in order to validate if component freezing trulyhelps reduce catastrophic forgetting, we performedpartial brute force block-level freezing on each taskpermutation to approximately determine the upper.
2947methodslamolpartial brute force blockrational lamol blockrational lamol headgen-rational lamol blockgen-rational lamol headmultitask.
bms bsm mbs msb sbm smb average57.3962.9762.4964.3566.8267.35.
60.0869.0559.9460.6264.4965.52.
55.9864.0559.5561.7059.9757.36.
66.7167.7568.0467.7665.1163.85.
67.6365.2268.5556.5966.9463.98.
65.8966.7366.0965.2266.3866.51.
62.2865.9664.1162.7164.9564.10.std.
5.092.304.573.932.633.57.
67.32.table 2: accuracy of different methods evaluated on the models at the last epoch of the last task, averaged overthree seeds.
each column refers to the order of tasks on which the methods were trained.
b, m and, s refer toboolq, movie reviews, and scifact, respectively.
the average and std columns respectively are the average andstandard deviation of the accuracy scores for each row of the methods..bool-q.
scifact.
movies.
ycarucca.ycarucca.ycarucca.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.bound of our rationale lamol block.
due to lim-ited computing resources, we compromised withsearching for all even-numbered block indices, andchoosing the model with maximum average scoreof the ﬁrst two tasks to do the brute force on thelatter two tasks.
since brute force was performedon a per-task basis, our search space would be 6+6,the ﬁrst six being the six blocks on the ﬁrst twotasks, and the latter six being the six blocks onthe last two tasks.
do note that true brute forcewould be 12×12.
although it is possible that ourpartial brute force is sub-optimal, we ﬁnd that it isa good compromise due to limited computing re-sources.
the results are presented in table 2. bruteforce was able to outperform vanilla lamol bya substantial margin of 3.68%, only 1.36% fromthe multitask upper bound.
this suggests that com-ponent freezing is able to further nullify the effectof catastrophic forgetting from lamol.
it alsoachieved a standard deviation of only 2.3% com-pared with lamol’s 5.28%.
this suggests thatfreezing the right component helps with task orderresilience..a sample of accuracy graphs (as the learningprogressed) of the compared methods, with theboolq → scifact → movies (bsm) task order isshown in figure 4 from top to bottom, respectively.
as the ﬁrst task, boolq was not really affectedby scifact, but encountered a heavy drop duringthe third task of movies.
in the baseline, boolqdropped from 61% to a mere 6%, while only re-bounding up to 26% at the end.
however, afterfreezing the most plastic block identiﬁed by partialbrute forcing, boolq dropped from 62% to 15%,and rebounding up to 47%.
comparatively, in thesecond task, scifact encountered a smaller dropduring the third task from 63% to 55%, and then.
lamolpartial brute forcer-lamolblockr-lamolheadr-lamolblock (g)r-lamolhead (g).
bool-q.
5.
10.movies.
15.scifactepoch.
figure 4: learning curves of task order bsm.
thegraphs show accuracy at each epoch for each task.
green background refers to the epochs on which themodel is ﬁrst introduced with a particular task.
in thisﬁgure, for example, the model is trained on bool-q andevaluated on all the three tasks during epoch 1-5..rebounded back to 65%.
as the last task, movieswas not affected by catastrophic forgetting..accuracy graphs for all permutation of tasksis available in appendix 6 from which we makeseveral observations concerning the effect of taskorders on the overall performance:.
2948• there is evidence that movies accelerate theforgetting process of ﬁrst task due to theabrupt change in data distribution..• however, the performance on the task moviesitself is barely affected by the task order.
weattribute it to the low difﬁculty of the task..• there is usually no interference between thetasks bool-q and scifact when these tasksare trained in adjacency since they are similar..5.2 effect of critical component.
identiﬁcation (cci).
it is unrealistic to perform brute force in every sin-gle setting.
so, it is crucial that our algorithmuses reasonable amount of time while still main-taining improvements from the baseline.
the ccialgorithm requires each task except task 1 to berepeated twice.
this doubles the time needed totrain a single task.
combined with time requiredfor cci, rational lamol required approximately2.4 times more time than vanilla lamol to com-pletely train a model as shown in figure 3. onthe other hand, our algorithm used only approxi-mately half of the time it took to train in the partialbrute force fashion.
currently, cci only measuresplasticity in between two models (mi and ˆmi+1).
single model analysis for layer plasticity evalua-tion is left for future work..from table 2, rational lamolblock outper-formed lamol by 1.83% average accuracy(0.97% average macro-f1) over all permutationswhile having smaller standard deviation, indicatingthat it is also more robust to task orders.
ratio-nal lamolhead was able to match or outperformlamol in ﬁve out of six task orders, but the sig-niﬁcant decrease in the sbm order lowered theaverage to a 0.43% gain (and a slight decrease inmacro-f1) from the baseline.
upon further inspec-tion, we found that the pseudo-samples of scifactcontained high variance in quality during pseudo-data replay.
in addition to generation token mis-match, i.e., a situation where a pseudo-sample hasan answer token from a wrong task, the low vol-ume of scifact training data affected the qualityof the pseudo-samples generated.
so, this acceler-ated catastrophic forgetting rather than alleviating.
without the sbm drop, rational lamolhead per-formed comparatively well or slightly higher withthe block-level.
performing a one-tailed paired t-test on all data points of the total 3 random seeds,.
we observed that block-level freezing is able to winagainst the original lamol with statistical signiﬁ-cance (p-value of 0.023 and 0.042 for block-leveland generated block-level respectively).
with thesbm result neglected as an outlier, both block-leveland head-level signiﬁcantly improved the resultscompared with the original lamol (p-value of0.015, 0.014, 0.010, 0.049 for block-level, gener-ated block-level, head-level, and generated head-level respectively).
however, there is no conclusiveevidence of which method (head-level or block-level freezing) being signiﬁcantly better (p-valueof 0.133).
even though our rationale lamol out-performed the baseline, there was still a gap fromthe brute force upper bound.
this could be due tomany incompatibilities between human rationalesand machine attention scores, as mentioned in baoet al.
(2018), which made our algorithm choosesub-optimal layers/heads..5.3 effect of unsupervised rationale.
generation.
due to the difference in focus between human andmachines, it is conceivable that the rationales gen-erated by invrat would be mostly misaligned withhuman rationales.
this is shown in table 3, wherethe f1 scores of invrat are quite low when com-pared with human rationales.
figure 5 shows anexample of generated rationales output by invratcompared with human rationales..despite that, generated rational lamolblockoutperformed both rational lamol and lamolbaseline by 0.84% accuracy (0.31% macro-f1) and2.67% accuracy (1.27% macro-f1) respectively,further reducing the gap to brute force, the approx-imate upper bound of the proposed cci.
this sug-gests that rationales chosen by invrat, regardless ofhow nonsensical they appear, still carry informationthat eliminates the need for human rationales.
theresults are consistent with bao et al.
(2018) whoshowed that signiﬁcant gains are achieved whenusing machines attention scores as an additional su-pervision signal instead of using human rationales..last but not least, figure 3 shows that the pro-cess of generating rationales using invrat, in-cluding training and inference, contributed onlymarginally, about 15 minutes, to the total time usedin the training process..2949invariant rationalization..in pro-jaakkola.
2020.ceedings of the 37th international conference onmachine learning, volume 119 of proceedingsof machine learning research, pages 1448–1458.
pmlr..figure 5: an example of rationales from the moviestask.
the sentiment for this particular example is neg-ative.
the underlined text is a human rationale, whilerationales generated by invrat are shown in red..arslan chaudhry, marc’aurelio ranzato, marcusrohrbach, and mohamed elhoseiny.
2019. efﬁcientlifelong learning with a-gem.
in international con-ference on learning representations (iclr)..p.boolq 14.705.71movie4.90scifact.
r18.4817.895.41.f114.575.904.99.table 3: token-based precision, recall, and f1 show-ing the agreement between the rationales generated byinvrat and the human-annotated rationales..6 conclusion.
to effectively retain learned knowledge in ll fornlp tasks, we proposed rational lamol, a learn-ing framework that uses rationales to identify andfreeze the most critical components of the modelwhile being trained on a new task.
we showed thatrational lamol is able to outperform lamolby a signiﬁcant margin.
furthermore, our frame-work can be applied to any nlp datasets by lever-aging unsupervised rationale generation, eliminat-ing the need for human rationales while maintain-ing comparable improvements.
overall, rationallamol bridges the gap between ll in nlp withmodel understanding through rationales, exhibitingpotential for a true lifelong language learning aswell as limiting catastrophic forgetting..references.
rahaf aljundi, francesca babiloni, mohamed elho-seiny, marcus rohrbach, and tinne tuytelaars.
2017. memory aware synapses: learning what (not)to forget.
corr, abs/1711.09601..martin arjovsky, l´eon bottou, ishaan gulrajani, andinvariant risk minimiza-cite.
arxiv preprint arxiv:1907.02893..david lopez-paz.
2019.tion.
arxiv:1907.02893..yujia bao, shiyu chang, mo yu, and regina barzilay.
2018. deriving machine attention from human ra-tionales.
in proceedings of the 2018 conference onempirical methods in natural language processing,pages 1903–1913, brussels, belgium.
associationfor computational linguistics..shiyu chang, yang zhang, mo yu, and tommi.
tianqi chen, ian goodfellow, and jonathon shlens.
2016. net2net: accelerating learning via knowl-edge transfer.
corr, abs/1511.05641..zhiyuan chen and bing liu.
2016. lifelong machine.
learning.
morgan & claypool publishers..zhiyuan chen, nianzu ma, and bing liu.
2015. life-in pro-long learning for sentiment classiﬁcation.
ceedings of the 53rd annual meeting of the associ-ation for computational linguistics and the 7th in-ternational joint conference on natural languageprocessing (volume 2: short papers), pages 750–756, beijing, china.
association for computationallinguistics..junyoung chung, caglar gulcehre, kyunghyun cho,and yoshua bengio.
2014. empirical evaluation ofgated recurrent neural networks on sequence mod-eling.
cite arxiv:1412.3555comment: presentedin nips 2014 deep learning and representationlearning workshop..christopher clark, kenton lee, ming-wei chang,tom kwiatkowski, michael collins, and kristinatoutanova.
2019. boolq: exploring the surprisingin proceed-difﬁculty of natural yes/no questions.
ings of the 2019 conference of the north americanchapter of the association for computational lin-guistics: human language technologies, volume 1(long and short papers), pages 2924–2936, min-neapolis, minnesota.
association for computationallinguistics..jay deyoung, sarthak jain, nazneen fatema rajani,eric lehman, caiming xiong, richard socher, andbyron c. wallace.
2020. eraser: a benchmark toevaluate rationalized nlp models.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics, pages 4443–4458, on-line.
association for computational linguistics..benjamin hoover, hendrik strobelt, and sebastiangehrmann.
2020. exbert: a visual analysis tool toexplore learned representations in transformer mod-els.
in proceedings of the 58th annual meeting ofthe association for computational linguistics: sys-tem demonstrations, pages 187–196, online.
asso-ciation for computational linguistics..ronald kemker and christopher kanan.
2017. fear-net: brain-inspired model for incremental learning.
corr, abs/1711.10563..2950james kirkpatrick, razvan pascanu, neil rabinowitz,joel veness, guillaume desjardins, andrei a. rusu,kieran milan, john quan, tiago ramalho, ag-nieszka grabska-barwinska, demis hassabis, clau-dia clopath, dharshan kumaran, and raia hadsell.
2017. overcoming catastrophic forgetting in neuralnetworks.
proceedings of the national academy ofsciences, 114(13):3521–3526..sang-woo lee lee, jin-hwa kim, jaehyun jun, jung-woo ha, and byoung-tak zhang.
2017. overcom-ing catastrophic forgetting by incremental momentmatching (imm).
in advances in neural informa-tion processing systems 30..tao lei, regina barzilay, and tommi s. jaakkola.
2016. rationalizing neural predictions.
in emnlp,pages 107–117.
the association for computationallinguistics..z. li and d. hoiem.
2018. learning without forgetting.
ieee transactions on pattern analysis and machineintelligence, 40(12):2935–2947..tianlin liu, lyle ungar, and jo˜ao sedoc.
2019. contin-ual learning for sentence representations using con-in proceedings of the 2019 conferenceceptors.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 3274–3279, minneapolis, minnesota.
associ-ation for computational linguistics..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners.
openaiblog, 1(8):9..alessandro raganato and j¨org tiedemann.
2018. ananalysis of encoder representations in transformer-in proceedings of thebased machine translation.
2018 emnlp workshop blackboxnlp: analyzingand interpreting neural networks for nlp, pages287–297, brussels, belgium.
association for com-putational linguistics..nazneen fatema rajani, bryan mccann, caimingxiong, and richard socher.
2019. explain yourself!
leveraging language models for commonsense rea-in proceedings of the 57th annual meet-soning.
ing of the association for computational linguis-tics, pages 4932–4942, florence, italy.
associationfor computational linguistics..andrei a. rusu, neil c. rabinowitz, guillaumedesjardins, hubert soyer, james kirkpatrick, ko-ray kavukcuoglu, razvan pascanu, and raia had-sell.
2016. progressive neural networks.
corr,abs/1606.04671..hanul shin, jung kwon lee, jaehong kim, and jiwonkim.
2017. continual learning with deep generativereplay.
in advances in neural information process-ing systems, volume 30, pages 2990–2999.
curranassociates, inc..david lopez-paz and marc’aurelio ranzato.
2017.gradient episodic memory for continual learning.
inadvances in neural information processing systems,page 6467–6476..fan-keng sun, cheng-hao ho, and hung-yi lee.
2020. lamol: language modeling for lifelong lan-in international conference onguage learning.
learning representations..cyprien de masson d’autume, sebastian ruder, ling-peng kong, and dani yogatama.
2019. episodiccorr,memory in lifelong language learning.
abs/1906.01076..bryan mccann, nitish shirish keskar, caiming xiong,and richard socher.
2018. the natural language de-cathlon: multitask learning as question answering.
corr, abs/1806.08730..michael mccloskey and neal j cohen.
1989. catas-trophic interference in connectionist networks: thesequential learning problem.
in psychology of learn-ing and motivation, volume 24, pages 109–165.
el-sevier..giang nguyen, shuan chen, thao do, tae joon jun,ho-jin choi, and daeyoung kim.
2020. dissectingcatastrophic forgetting in continual learning by deepvisualization.
corr, abs/2001.01578..jeffrey pennington, richard socher, and christophermanning.
2014. glove: global vectors for wordrepresentation.
in proceedings of the 2014 confer-ence on empirical methods in natural languageprocessing (emnlp), pages 1532–1543, doha,qatar.
association for computational linguistics..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, undeﬁne-dukasz kaiser, and illia polosukhin.
2017. attentionis all you need.
in proceedings of the 31st interna-tional conference on neural information processingsystems, nips’17, page 6000–6010, red hook, ny,usa.
curran associates inc..jesse vig.
2019. a multiscale visualization of atten-tion in the transformer model.
in proceedings of the57th annual meeting of the association for compu-tational linguistics: system demonstrations, pages37–42, florence, italy.
association for computa-tional linguistics..david wadden, shanchuan lin, kyle lo, lucy luwang, madeleine van zuylen, arman cohan, andhannaneh hajishirzi.
2020. fact or ﬁction: verify-in proceedings of the 2020ing scientiﬁc claims.
conference on empirical methods in natural lan-guage processing (emnlp), pages 7534–7550, on-line.
association for computational linguistics..mo yu, shiyu chang, yang zhang, and tommijaakkola.
2019. rethinking cooperative rationaliza-tion: introspective extraction and complement con-in proceedings of the 2019 conference ontrol..2951empirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages4094–4103, hong kong, china.
association forcomputational linguistics..omar zaidan and jason eisner.
2008. modeling anno-tators: a generative approach to learning from an-notator rationales.
in proceedings of the 2008 con-ference on empirical methods in natural languageprocessing, pages 31–40, honolulu, hawaii.
associ-ation for computational linguistics..a learning curves of all task.
permutations.
figure 6 to figure 10 show the learning curves ofall task order permutations of the compared meth-ods..ycarucca.ycarucca.ycarucca.ycarucca.ycarucca.ycarucca.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.bool-q.
movies.
scifact.
movies.
bool-q.
scifact.
lamolpartial brute forcer-lamolblockr-lamolheadr-lamolblock (g)r-lamolhead (g).
bool-q.
5.
10.scifact.
15.moviesepoch.
figure 6: learning curves for task order bms.
lamolpartial brute forcer-lamolblockr-lamolheadr-lamolblock (g)r-lamolhead (g).
movies.
5.
10.scifact.
15.bool-qepoch.
figure 7: learning curves for task order mbs.
2952ycarucca.ycarucca.ycarucca.ycarucca.ycarucca.ycarucca.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.movies.
scifact.
bool-q.
scifact.
bool-q.
movies.
lamolpartial brute forcer-lamolblockr-lamolheadr-lamolblock (g)r-lamolhead (g).
movies.
5.
10.bool-q.
15.scifactepoch.
figure 8: learning curves for task order msb.
lamolpartial brute forcer-lamolblockr-lamolheadr-lamolblock (g)r-lamolhead (g).
scifact.
5.
10.movies.
15.bool-qepoch.
figure 9: learning curves for task order sbm.
scifact.
movies.
bool-q.
ycarucca.ycarucca.ycarucca.
80.
60.
40.
20.
80.
60.
40.
20.
80.
60.
40.
20.lamolpartial brute forcer-lamolblockr-lamolheadr-lamolblock (g)r-lamolhead (g).
scifact.
5.
10.bool-q.
15.moviesepoch.
figure 10: learning curves for task order smb.
2953