socaog: incremental graph parsing for social relation inference indialogues.
liang qiu1, yuan liang2, yizhou zhao1, pan lu1, baolin peng3,zhou yu4, ying nian wu1, song-chun zhu11ucla center for vision, cognition, learning, and autonomy2university of california, los angeles3microsoft research, redmond4university of california, davisliangqiu@ucla.edu.
abstract.
inferring social relations from dialogues is vi-tal for building emotionally intelligent robotsto interpret human language better and act ac-cordingly.
we model the social network as anand-or graph, named socaog, for the con-sistency of relations among a group and lever-aging attributes as inference cues.
moreover,we formulate a sequential structure predictiontask, and propose an α–β–γ strategy to incre-mentally parse socaog for the dynamic infer-ence upon any incoming utterance: (i) an αprocess predicting attributes and relations con-ditioned on the semantics of dialogues, (ii) aβ process updating the social relations basedon related attributes, and (iii) a γ process up-dating individual’s attributes based on interper-sonal social relations.
empirical results on di-alogre and moviegraph show that our modelinfers social relations more accurately than thestate-of-the-art methods.
moreover, the abla-tion study shows the three processes comple-ment each other, and the case study demon-strates the dynamic relational inference.1.
1.introduction.
social relations form the basic structure of our so-ciety, deﬁning not only our self-images but alsoour relationships (sztompka, 2002).
robots with ahigher emotional quotient (eq) have the potentialto understand users’ social relations better and actappropriately.
given a dialogue as context and a setof entities, the task of dialogue relation extraction(dre) predicts the relation types between the enti-ties from a predeﬁned relation set.
table 5 showssuch an example from the dataset dialogre (yuet al., 2020)..existing researches using bert-based mod-els (devlin et al., 2018; yu et al., 2020; xue et al.,2020a) or graph-based models (xue et al., 2020b;.
1the code is released at https://github.com/.
liang-qiu/socaog-dialogues..s1:.
s2:.
well then we’ll-we’ll see you the day after tomorrow.
mom?!
dad?!
what-what.
.
.
what you guys doing here?!.
well you kids talk about this place so much, we thoughtwe’d see what all the fuss is about..s3:.
i certainly see what the girls like coming here..s1: why?!.
s1: gunther?!.
s3: the sexy blonde behind the counter..s2: your mother just added him to her list..s1: what?
your-your list?.
argument pair trigger(s2, s1)(s3, gunther)(s3, s1)(s1, s3)(s1, s2).
dadsexy blondemommomdad.
relation typeper:childrenper:positive impressionper:childrenper:parentsper:parents.
r1r2r3r4r5.
table 1: a dialogue example from dialogre (yu et al.,2020).
trigger word annotations are not used for train-ing, but rather for illustrating purpose only..chen et al., 2020) focus on identifying entities’relations from the semantics of dialogues—theyutilize either the attention mechanism or a reﬁnedtoken graph to locate informative words (e.g., “dad”and “mom”) that imply the argument pairs’ rela-tions.
however, there are still three missing partsin current models for social relation inference ac-cording to our observations.
first, current modelslack the explicit modeling of the relational consis-tency among a group of people—such consistencyhelps humans reason about the social relation oftwo targets by using their relations with a thirdperson.
for the example in table 5, by knowings2 and s3 are s1’s parents and s3 is s1’s mother,we can infer that s2 is s1’s dad.
second, the per-sonal attribute cues (e.g., gender and profession)can also aid the relational inference but are notfully utilized.
in the above example, besides infer-ring s3 is s1’ mother according to s3’s feminineattribute, we can also have a guess that gunther is awaiter, which might be useful for the future social-relational inference.
third, since the bert-based.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages658–670august1–6,2021.©2021associationforcomputationallinguistics658figure 1: our method iteratively updates the robot’s belief of users’ individual attributes and social relations, simi-lar to human’s reasoning process.
the left and right graph show the established and updated belief, respectively..and token-graph-based models take dialogues as awhole for relation prediction, they cannot performdynamic inference—updating the relational beliefwith an incoming dialogic utterance.
this can limittheir ability to track the evolving relations alongsocial interactions, e.g., strangers become friendsover a good chat (kukleva et al., 2020), unveilingintermediate reasoning results, or dealing with longdialogues..motivated by these observations, we proposeto model social relation as an attributed and-orgraph (aog) (zhu et al., 1998; zhu and mumford,2007; wu and zhu, 2011; shu et al., 2016; qi et al.,2018), named socaog, and develop an incremen-tal graph parsing algorithm to jointly infer humanattributes and social relations from a dialogue.
inspeciﬁc, socaog describes social relations andpersonal attributes with contextual constraints ofgroups and hierarchical representations.
to incre-mentally parse socaog and track social relations,we apply markov chain monte carlo (mcmc) tosample from the posterior probability calculated bythree complementary processes (α–β–γ) (qu et al.,2020; zayaraz et al., 2015).
figure 1 schematicallydemonstrates a graph update of both relations (i.e.,disambiguating mom/dad and adding a new party)and attributes (e.g., gender and profession) with theutterance “s2: your mother just added him to thelist.” from the example dialogue in table 5..we evaluate our method on two datasets of di-alogre (yu et al., 2020) and moviegraph (vicolet al., 2018) for relation inference, and the resultsshow that our method outperforms the state-of-the-art (sota) ones.
overall, we make the followingcontributions: (i) we propose to model and infer so-cial relations and individual’s attributes jointly withsocaog for the consistency of attributes and socialrelations among a group.
to the best of our knowl-edge, it is the ﬁrst time done in the dialogue do-.
main; (ii) the mcmc sampling from α–β–γ pos-terior enables dynamic inference—incrementallyparsing the social relation graph, which can be use-ful for tracking relational evolution, reﬂecting thereasoning process, and handling long dialogues;(iii) we perform an ablation study on each processof α–β–γ to investigate the information contribu-tion, and perform case studies to show the effec-tiveness of our dynamic reasoning..2 related work.
we review the related works on the social relationinference from documents, which is a well-studiedtask, and those from dialogues, which is the emerg-ing task that our work is focused on..2.1 relation inference from documents.
most of the existing literature focus on relation ex-traction from professional edited news reports orwebsites.
they typically output a set of “subject-predicate-object” triples after reading the entiredocument (bach and badaskar, 2007; mintz et al.,2009; kumar, 2017).
while early works mostlyutilize feature-based methods (kambhatla, 2004;miwa and sasaki, 2014; gormley et al., 2015) andkernel-based methods (zelenko et al., 2003; zhaoand grishman, 2005; mooney and bunescu, 2006),more recent studies use deep learning methods suchas recurrent neural networks or transformers (ku-mar, 2017).
for example, zhou et al.
(2016) pro-pose bidirectional lstm model to capture the long-term dependency between entity pairs, zhang et al.
(2017) present pa-lstm to encode global positioninformation, and alt et al.
(2019); papanikolaouet al.
(2019) ﬁne-tune pre-trained transformer lan-guage models for relation extraction..two streams of work are closely related to ourmethod.
regarding social network modeling, whilemost works treat pairs of entities isolated (yu et al.,.
659s1s2gmomspouseaggs3achildgpositiveimpressions1s3s2spousechildchildchildmom/dadmom/dadaaaapadadgggwomanmanstudentfarmersingerotherdoctorkidteenageryoung adultadultseniorbaby- gender- age- professionpwaiterprobabilisctic attributes: trans*gagunther2020; xue et al., 2020b; chen et al., 2020), srivas-tava et al.
(2016) formulate the interpersonal rela-tion inference as structured prediction (belangerand mccallum, 2016; qiu et al., 2020; zhao et al.,2020), inferring the collective assignment of re-lations among all entities from a document (liet al., 2020; jin et al., 2020).
regarding relationevolution, a few works are aimed to learn the dy-namics in social networks, i.e., the development ofrelations, from narratives by hidden markov mod-els (chaturvedi et al., 2017), recurrent neural net-works (kim and klinger, 2019), deep recurrent au-toencoders (iyyer et al., 2016).
our method differsfrom the aforementioned works by modeling thestructured social relations and their changes concur-rently, which can be useful for the task of trackingsocial network evolution (doreian and stokman,1997) and unveiling the reasoning process of rela-tions.
we achieve this by parsing the graph incre-mentally per utterance with the proposed α–β–γstrategy..2.2 relation inference from dialogues.
recently, yu et al.
(2020) introduce the ﬁrsthuman-annotated dialogue-based relation extrac-tion dataset dialogre, in which relations are anno-tated between arguments that appear in a dialoguesession.
compared with traditional relation extrac-tion tasks, dialogre emphasizes the importanceof tracking speaker-related information within thecontext across multiple sentences.
sota methodscan be categorized into token-graph models andpre-trained language models.
for typical token-graph models, chen et al.
(2020) present a tokengraph attention network, and xue et al.
(2020b) fur-ther generate a latent multi-view graph to capturerelationships among tokens, which is then reﬁnedto select important words for relation extraction.
for pre-trained models, yu et al.
(2020) evaluate abert-based baseline model (devlin et al., 2018)and a modiﬁed version berts, which takes speakerarguments into consideration.
xue et al.
(2020a)propose a simple yet effective bert-based model,simplere, that takes a novel input format to cap-ture the interrelations among all pairs of entities..both categories of sota models take a discrim-inative approach, whereas ignoring two key con-straints on relations: (i) social relation consistencyin a group and (ii) human attributes.
different fromthem, our method formulates the task as dialoguegeneration from an attributed relation graph, so.
that the posterior relation estimation models bothtwo constraints.
moreover, sota models also as-sume the relations are static—they cannot learnthe dynamics of the relations, while the incremen-tal graph updating strategy naturally enables thedynamic relation inference..3 problem formulation.
our goal is to construct a social network throughutterances in dialogue.
the network is a hetero-geneous physical system (yongqiang et al., 1997)with particles representing entities and differenttypes of edges representing social relations.
eachentity is associated with multiple types of attributes,while each type of relation is governed by a poten-tial function deﬁned in human attribute and valuespace, acting as the social norm.
the relations areoften asymmetric, e.g., a is b’s father does notmean b is a’s father.
to model the network, we uti-lize an attributed and-or graph (a-aog), a prob-abilistic grammar model with attributes on nodes.
such design takes advantage of the reconﬁgura-bility of its probabilistic context-free grammar toreﬂect the alternative attributes and relations, andthe contextual relations deﬁned on markov ran-dom field to model the social norm constraints..the social network graph, named socaog, isdiagrammatically shown in figure 2. formally,socaog is deﬁned as a 5-tuple:.
g =< s, v, e, x, p >.
(1).
t ∪v a., where s is the root node for representing the inter-ested society.
v = vand∪vor ∪v et denotes allnodes’ collection.
among them, and-nodes vandrepresent the set of social communities, which canbe decomposed to a set of entity terminal nodes,v et , representing human members.
communitydetection is based on the social network analysis(bedi and sharma, 2016; du et al., 2007), and canbeneﬁt the modeling of loosely connected socialrelations.
each human entity is associated with anand-node that breakdowns the attributes into sub-types such as gender, age, and profession.
all thesubtypes consist of an or-node set, vor, for repre-senting branches to alternatives of attribute values.
meanwhile, all the attribute values are representedas a set of terminal nodes v at .
we denote e to bethe edge set describing social relations, x(vi) to bethe attributes associated with node vi, and x((cid:126)eij)to be the social relation type of edge (cid:126)eij ∈ e..660figure 2: socaog: attributed and-or graph representation of a social network.
a parse graph determining eachattribute and relation type is marked in blue lines.
dialogues are governed by the word context and associatedhuman attributes and relations..given p to be the probability model deﬁnedon socaog, a parse graph pg is an instantia-tion of socaog with determined attribute selec-tions for every or-node and relation types for ev-ery edge.
for a dialogue session with t turnsdt = {d(1), d(2), ..., d(t )}, where d(t) is theutterance at turn t, our method infers the attributesand social relations incrementally over turns:.
gt = {pg(1), pg(2), ..., pg(t )}.
(2).
, where pg(t) represents the belief of socaog atthe dialogue turn t. we incrementally update thepg by maximizing the posterior probability:.
pg∗ = arg max.
p(pg|d; θ).
(3).
pg.
, where pg∗ is the optimum social relation belief,and θ is the set of model parameters..4 algorithm.
4.1 α–β–γ for graph inference.
for simplicity, we denote x(vi) as vi and x((cid:126)eij)as eij in the rest of the paper.
we introduce threeprocesses, i.e., α, β, and γ process, to infer anysocaog belief pg∗.
we start by rewriting the pos-terior probability as a gibbs distribution:.
=.
p(pg|d; θ) ∝ p(d|pg; θ)p(pg; θ)1z.exp{−e(d|pg; θ) − e(pg; θ)}(4), where z is the partition function.
e(d|pg; θ)and e(pg; θ) are dialogue- and social norm-basedenergy potentials respectively, measuring the costof assigning a graph instantiation..denoting a dialogue as a sequence of words:d = {w1, w2, ..., wt }, the dialogue likelihood en-ergy term e(d|pg; θ) can be expressed with a lan-guage model conditioned on the parse graph:.
e(d|pg; θ) =.
e(wt|ct, pg).
=.
− log(p(wt|ct, pg)).
(5).
t(cid:88).
t=1t(cid:88).
t=1.
, where ct = [w1, ..., wt−1] is the context vec-intuitively, the word selection depends ontor.
the word context,the entities’ attributes andtheir interpersonal relations.
we approximatethe likelihood by ﬁnetuning a bert-basedformattransformer with a customized input(cid:104)[cls]d[sep]vi0ei0j0vj0...vineinjnvjnv0v0...vnvn[sep](cid:105), which is a concatenation of the dia-logue history d and a ﬂattened parse graph stringencoding the current belief.
we call the estimationof pg from the dialogue likelihood p(wt|ct, pg)to be the α process.
α process lacks the explicitconstraints for social norms related to interpersonalrelations and human attributes..for the social norm-based potential, we design.
it to be composed of three potential terms:.
e(pg; θ) = − β.log(p(eij|vi, vj)).
(cid:88).
− γl.
− γr.
vi,vj ∈v (pg)(cid:88).
(cid:126)eij ∈e(pg)(cid:88).
(cid:126)eij ∈e(pg).
log(p(vi|eij)).
log(p(vj|eij)).
(6), where v (pg) and e(pg) are the set of terminalnodes and relations in the parse graph, respectively..661jonahannamothercommunitysocietygenderage...professionkidsenioradultwomandialogheyhowareirenesamjohncolleaguecolleaguemantrans*fatherhusbandand-nodeand-node (attribute)word contextterminal node (attribute)terminal node (character)social relationor-node (attribute subtype)jonahannamothercommunitysociety...and-nodeand-node (attribute)word contextterminal node (attribute)terminal node (character)social relationor-node (attribute subtype)we call the term p(eij|vi, vj) the β process, inwhich we bind the attributes of node vi and vj toupdate their relation edge eij, in order to model theconstraint on relations from human attributes.
re-versely, we call the terms p(vi|eij) and p(vj|eij)the γ process, in which we use the social relationedge eij to update the attributes of node vi and vj.
this models the impact of relation to the attributesof related entities.
β, γl, and γr are weight fac-tors balancing α, β and γ processes.
figure 3(a)shows the graph inference schema with the threeprocesses.
combining equation 4, 5, and 6, we geta posterior probability estimation p(pg|d; θ) ofparse graph pg, with the guarantee of the attributeand social norm consistencies..algorithm 1: incremental socaog parsingfor social relation inference.
input: dialogue dt = {d(1), d(2), ..., d(t )},.
target argument pairs {a1, a2}.
initialize pg(0).
initialize vi and eij.
for t = 1, ..., t do.
for s = 1, ..., s do.
compute the posterior p(pg|d(t); θ).
make proposal moves with probabilitiesq1, q2 to get a new parse graph pg(cid:48).
compute the posterior p(pg(cid:48)|d(t); θ).
compute acceptance rateα(pg(cid:48)|pg, d(t); θ)..accept/reject pg(cid:48) according to the.
acceptance rate..end forreturn ea1,a2 from the average of accepted.
pg samples..end for.
from the posterior probability p(pg(t)|d(t); θ).
weutilize a markov chain monte carlo (mcmc) sam-pler to update our parse graph since the complexityof the problem caused by multiple energy terms..at each dialogue turn t, we initialize the parsegraph with the α classiﬁcation process, by replac-ing all the or-node tokens with a special token[cls].
we sample the parse graph for s stepsand use the average value of obtained samples asan approximation of pg(t).
we design two types ofmarkov chain dynamics used at random probabili-ties qi, i = 1, 2 to make proposal moves:.
• dynamics q1: randomly pick a relation edge(cid:126)eij under the uniform distribution, ﬂip its so-cial relation type eij according to the priordistribution given by β process:.
(cid:89).
vi,vj ∈v (pg).
p(eij|vi, vj)..(8).
• dynamics q2: randomly pick a terminal nodevi and its attribute subtype under the uniformdistribution, and ﬂip the one-hot value of at-tribute vi according to the prior distributiongiven by γ process:.
(cid:89).
p(vi|eij).
p(vi|eji)..(9).
(cid:89).
figure 3: (a) α–β–γ process for socaog.
(b) α–β pro-cess for reduced socaog without attributes.
note thatthis β is only modeling the interrelations among x((cid:126)e)..here we also provide a reduced version of ourmodel, socaogreduced, which applies when char-acters’ attributes annotation are not available fortraining2.
with the same dialogue-based energypotential, we deﬁne the parse graph prior energyover a set of relation triangles:.
e(pg; θ) = −β.
log(p(eij|eik, ejk))..(cid:88).
(cid:126)eij ,(cid:126)eik,(cid:126)ejk∈e(pg).
(7)the method directly models the constraint of twoentities’ relation from their relations to others, withthe inference schema demonstrated in figure 3(b)..4.2.incremental graph parsing.
(cid:126)eij ∈e(pg).
(cid:126)eji∈e(pg).
incrementally parsing the socaog is accomplishedby repeatedly sampling a new parse graph pg(t).
2both socaog and socaogreduced do not need attribute.
annotation during inference once trained..using the metropolis-hastings algorithm (chib andgreenberg, 1995), the proposed new parse graphpg(cid:48) is accepted according to the following accep-.
662binding         a btance probability:.
5.2 experiment settings.
α(pg(cid:48)|pg, d; θ) = min(1,.p(pg(cid:48)|d; θ)p(pg|pg(cid:48))p(pg|d; θ)p(pg(cid:48)|pg)p(pg(cid:48)|d; θ)p(pg|d; θ).
).
).
= min(1,.
(10), where the proposal probability rate is cancelledout since the proposal moves are symmetric in prob-ability.
we summarize the incremental socaogparsing in algorithm 1. dialogues give a continu-ously evolving energy landscape: at the beginningof iterations, p(pg(0)|d; θ) is a “hot” distributionwith a large energy value; by iterating the α–β–γprocesses for pg updates through the dialogue, thepg converges to the pg∗, which is much cooler..5 experiments.
5.1 datasets.
we use dialogre (v2)3 (yu et al., 2020) andmoviegraph4 (vicol et al., 2018) for evaluating ourmethod.
detailed descriptions on the two datasets,e.g., relation and attribute types, are provided inappendix a..dialogre contains 36 relation types (17 of themare interpersonal) that exist between pairs of ar-guments.
for the joint parsing of relation and at-tribute, we further annotate the entity argumentswith attributes from four subtypes (by followingthe practice of moviegraph (vicol et al., 2018)):gender, age, profession, and ethnicity, according tofriends central in fandom5.
dialogre is split intotraining (1073), validation (358), and test (357).
following previous works (yu et al., 2020; xueet al., 2020b), we report macro f1 scores in boththe standard and conversational settings (f1c)..moviegraph provides graph-based annotationsof social situations from 51 movies.
each graphcomprises nodes representing the characters, theiremotional and physical attributes, relationships,and interactions.
we use a subset (40) of movie-graph with available full transcripts and split thedataset into training (26), validation (6), and test(8).
for moviegraph, we only evaluate with f1since the trigger word annotation for computingf1c is not available..3https://github.com/nlpdata/dialogre4http://moviegraphs.cs.toronto.edu/5https://friends.fandom.com/wiki/friends wiki.
we learn the socaog model with a contrastiveloss (hadsell et al., 2006) comparing the posteriorof a positive parse graph against a negative one.
allparameters are learned by gradient descent usingthe adam optimizer (kingma and ba, 2014).
dur-ing the inference stage, for each utterance, we runthe mcmc for s = min{w × (km + k(k −1)n ), smax} steps given k entities, m attributes,n relations, and a sweep number of w. the proba-bility of ﬂipping the relation q1 is set to 0.7 to biastowards the relation prediction at ﬁrst..5.3 baseline models.
we compare our method with both transformer-based (bert, berts, simplere) and graph-based (gdpnet) models.
given dialogue historyd and target argument pair (vi, vj), bert (de-vlin et al., 2018) takes input sequences for-matted as (cid:104)[cls]d[sep]vi[sep]vj[sep](cid:105).
berts (yu et al., 2020) is a speaker-aware modi-ﬁcation of bert, which also takes speaker infor-mation into consideration by converting it into aspecial token.
simplere (xue et al., 2020a) mod-els the relations between each pair of entities witha customized input format.
gdpnet (xue et al.,2020b) takes in token representations from bertand constructs a multi-view graph with a gaussiangraph generator.
the graph is then reﬁned throughgraph convolution and dtwpool to identify indica-tive words..5.4 performance comparison.
table 2 shows the performance comparison be-tween different methods on the two datasets.
itclearly shows that both of our models, socaog andsocaogreduced, outperform the existing methods byall the metrics.
in speciﬁc, without using any ad-ditional information of attributes, socaogreducedsurpasses the state-of-the-art method (simplere)by 1.9% (f1)/2.1% (f1c) on dialogre testingset, and by 5.1% (f1c) on moviegraph testingset.
such improvement shows the importance ofrelational consistency for the modeling, and provesthe effectiveness of our socaog formulation tointroduce the social norm constraints..moreover, by comparing between socaog andsocaogreduced, we see that socaog further im-proves most of the metrics by leveraging the at-tribute information for relation reasoning, e.g.,69.1% vs. 68.6% for dialogre testing f1 and.
663methods.
f1(σ).
f1c(σ).
f1(σ).
f1c(σ).
dialogre (v2).
dev.
test.
moviegraph.
devf1(σ).
testf1(σ).
bert (devlin et al., 2018)berts (yu et al., 2020)gdpnet (xue et al., 2020b)simplere (xue et al., 2020a)socaogreduced (our method)socaog (our method).
59.4 (0.7)62.2 (1.3)67.1 (1.0)68.2 (1.1)69.1 (0.4)69.5 (0.8).
54.7 (0.8)57.0 (1.0)61.5 (0.8)63.4 (0.6)65.7 (0.5)66.1 (0.7).
57.9 (1.0)59.5 (2.1)64.3 (1.1)66.7 (0.7)68.6 (0.9)69.1 (0.5).
53.1 (0.7)54.2 (1.4)60.1 (0.9)63.3 (0.9)65.4 (1.1)66.5 (0.8).
50.6 (1.2)50.7 (1.1)53.1 (1.1)55.2 (0.5)60.7 (0.4)60.1 (0.6).
53.6 (0.3)53.6 (0.4)56.4 (0.8)58.1 (0.7)63.2 (0.3)64.1 (0.8).
table 2: performance comparison between bert, berts, gdpnet, simplere, socaogreduced, and socaog.
wereport 5-run average results and the standard deviation (σ)..figure 4: performance boosts (f1) of socaog compared to simplere (xue et al., 2020a) by relation type.
theleft bars to the dashed line are relations between humans, while the right ones are those between human andnon-human entities..64.1% vs. 63.2% for moviegraph testing f1.
theresults demonstrate our method can effectively takeadvantage of the attributes as cues for social rela-tion predictions.
we compare our socaog modelwith the existing model of highest accuracy (sim-plere) by relation types, and see consistent im-provements for all types.
a part of the results areshown in figure 4. we also observe that there arelarger accuracy boosts for relations between hu-man entities than non-human entities (e.g., human-place), by an average of +2.5% vs. +1.8% in f1,which is also reﬂected from figure 4 (left 10 barsvs. right 10 bars).
this can be explained as rela-tion/attribute constraints are more meaningful forinterpersonal relations, e.g., there are more con-straints for the relation between three humans thanthe relation between two humans and a place..table 2 also sees more accuracy improvementon moviegraph dataset than dialogre (+3.2% vs.+6.0% in test f1c using simplere as baseline).
this is possibly because the dynamic inferencenature of our method makes it effective for deal-ing with dialogues with more turns: while existingmethods either truncate dialogues or use slidingwindows, our method continuously updates the re-lation graph given an incoming turn.
we case studythe dynamic inference in the next subsection..s1, s2: hi!.
hey!.
1.
2.
3.
4.
5.
6.
7.
8.
9.s3:.
s4:.
s1:.
s2:.
s3:.
s5:.
s1:.
s5:.
so glad you came!.
i can’t believe emma is already one!.
i remember your ﬁrst birthday!
ross was jealous of all the attention we were giving you.
he pulled on his testicles so hard!
we had to take him to the emergency room!.
there’s something you didn’t know about your dad!.
hey mr. and mrs. geller!
let me help you with that..thank you!.
oh man, this is great, uh?
the three of us together again!
you know what would be fun?
if we gave this present to emma from all of us!.
table 3: dialogue example from the testing set of di-alogre (yu et al., 2020)..5.5 case study on dynamic inference.
our method incrementally updates the relation andattribute information for a group of entities uponper utterance input with the proposed α–β–γ strat-egy.
such dynamic inference can potentially helpreﬂect the evolving relations, unveil the reasoningprocess, and deal with long dialogues.
figure 5shows the parse graph sequence by socaog infer-ring from a dialogre testing dialogue as shownin table 3. we can see that the method contin-uously reﬁnes the relation/attributes from an ini-tial guess with incoming contexts, e.g.
s2-s3:friends→parents in turn 5. besides, the case alsoshows that attributes can aid relation predictions,.
664figure 5: left: inferred parse graph sequence from socaog based on the test dialogue in table 3. note thatdad/mom are not distinguished in dialogre.
right: model convergence measured by acceptance rate at eachdialogue turn..
e.g., the inferred age of emma clariﬁes her relationwith s3.
moreover, since our method models therelation consistency among a group, it can predictthe relation between two humans that do not talkdirectly.
for example, s1 and s2 are inferred to bea couple by their dialogues with s5 in turn 7..figure 5 also plots the average mcmc accep-tance rate for the case, as deﬁned in formula 10,indicting the convergence of the inference.
we seethat the algorithm only needs to update the currentgraph belief slightly with a new perceived utter-ance.
a peak in the curve can indicate that a keypiece of information is detected that contradicts theexisting belief: e.g., there is a peak of convergencecurve in turn 7, which corresponds to “s5: hey mr.and mrs. geller!”, indicating that s1 and s2 are acouple rather than friends.
as such, we can see thealgorithm get several relations updated accordingly.
we also show the convergence plots for 50 randomtesting cases from dialogre in figure 6, and themean/standard deviation convergence rate as theblack line/blue shade.
we prove that our updatingalgorithm is robust for the converged results..figure 6: mcmc acceptance rate of the incrementalparsing process.
dotted lines, black line, and blueshade are for samples, mean, and standard deviation,respectively..processesγβ.α.f1(σ).
f1c(σ).
(cid:88)67.1 (0.5)(cid:88) (cid:88)68.4 (0.8)(cid:88)(cid:88) 68.3 (0.4)(cid:88) (cid:88) (cid:88) 69.1 (0.5).
64.2 (1.1)65.3 (0.6)65.2 (0.7)66.5 (0.8).
table 4: an ablation study on our parsing algorithm..5.6 ablation study on α–β–γ.
the α–β–γ strategy is designed to update relationsand attributes jointly, having the input informationﬂowing through the parse graph for the consistencyof predictions.
to validate the design, we ablate theprocesses on dialogre to evaluate their impact onperformance.
table 4 shows that α process, whichis the discriminative model, makes the fundamen-tal contribution, whereas β and γ processes alonecannot recognize social relations since they cannotperceive information from dialogues.
signiﬁcantly,removing either one of the two processes will de-crease the overall performance since the inferenceefﬁciency is reduced..6 conclusion.
the paper proposes a socaog model with α–β–γ processes for the consistent inference of socialrelations in dialogues.
the model can also lever-age attribute information to assist the inference.
mcmc is proposed to parse the relation graph in-crementally, enabling the dynamic inference uponany incoming utterance.
experiments show thatour model outperforms state-of-the-art methods;case studies and ablation studies are provided foranalysis.
in the future, we will further explore howdifferent initialization of the parse graph could helpwarm start the inference under various situationsand how multi-modal cues could be leveraged..665s1s2friendss3friendsfriendss1s2friendss3friendsfriendss4friendsfriendsfriendss1s2friendss3friendss4friendsfriendskids1s2s3siblingss4parentsparentsemmafriendsfriendskidemmafriendss1s2s3siblingss4parentsparentskidemmafriendsdads1s2s3siblingss4parentsparentskidspousedads5emmaparentsparentswomankidmom345672s1friendss1s2s3s4momemmaspouses5dadsiblingsdaddadmans28-91table 1123456789101110.79780.70540.46660.37540.30440.2610.19921110.7439942268479510.6455631469778710.3754932001462470.2529254174076060.2590050004580640.1692094220299180.1548065825802511110.770.690.480.560.20.280.231110.840.690.460.330.330.390.281110.830.640.530.360.310.350.231110.750.770.470.50.310.120.241110.780.690.530.360.240.140.21110.850.770.340.260.240.210.221110.830.670.50.220.230.170.251110.890.740.510.520.290.360.191110.850.730.360.20.260.290.211110.750.690.590.510.390.140.211110.820.70.350.420.320.30.141110.890.60.580.20.360.280.211110.820.630.40.410.360.340.141110.810.790.530.40.280.270.181110.80.650.380.440.330.110.171110.810.740.550.210.380.190.261110.790.740.490.460.260.360.291110.760.680.50.270.20.210.151110.730.620.30.320.330.340.281110.70.710.590.30.320.10.171110.740.770.540.370.30.380.231110.860.770.340.230.390.360.21110.80.750.560.330.350.120.171110.860.740.580.570.360.330.161110.70.760.520.320.340.190.141110.790.760.360.280.330.380.131110.740.660.50.290.230.370.211110.710.770.440.590.310.280.151110.870.750.370.560.360.180.141110.750.650.520.260.320.310.141110.750.740.360.340.320.370.251110.710.760.570.520.270.390.271110.740.730.320.40.330.110.211110.840.60.380.360.30.250.171110.890.790.570.540.320.270.151110.810.780.30.460.250.170.161110.70.680.520.540.390.340.251110.760.790.540.230.330.170.121110.820.620.550.380.310.150.191110.810.730.570.250.210.360.151110.840.60.410.240.310.220.191110.760.660.540.290.320.240.21110.830.610.580.450.280.180.221110.780.750.360.260.30.380.21110.860.790.490.30.220.270.171110.770.660.450.380.280.220.251110.820.740.530.390.330.30.251110.790.660.440.30.30.290.221110.840.620.310.580.230.150.191110.880.640.370.510.390.370.230000.05380577315204940.05983685302212870.09110679985375320.1163949995419360.05147458259239430.09179057797008160.04439341741974911110.851605773152050.7652368530221290.5577067998537530.4917949995419360.3558745825923940.3527905779700820.2435934174197491110.7439942268479510.6455631469778710.3754932001462470.2590050004580640.2529254174076060.1692094220299180.15480658258025100.20.40.60.8112345678910acceptance probabilitydialogue turns 1acknowledgments.
y. w. is partially supported by nsf dms 2015577.we would like to thank yaofang zhang and qianlong for help discussion.
we also thank the out-standing reviewers for their helpful comments toimprove our manuscript..ethical considerations.
endowing ai to understand social relations is anessential step towards building emotionally intel-ligent agents.
by jointly inferring individual at-tributes and social relations, our incremental pars-ing algorithm enables consistent and dynamic rela-tional inference in dialogue systems, which can beremarkably useful for a wide range of applicationssuch as a chatbot that constantly perceives newinformation and conducts social relation inference.
however, we never forget the other side of thecoin.
we emphasize that an ethical design princi-ple must be in place throughout all stages of thedevelopment and evaluation.
first, as discussed inlarson (2017), we model the attributes as a socialconstruct from a performative view.
for example,“gender performativity is not merely performance,but rather performances that correspond to, or areconstrained by, norms or conventions and simul-taneously reinforce them.
second, our model re-lies upon the attribute-category ascription providedby moviegraph (vicol et al., 2018) and friendscentral in fandom.
however, we acknowledgethat the annotation could be prone to a partial un-derstanding of human relationships, and the realsituation could be more complicated.
lastly, self-identiﬁcation should be the gold standard for ascrib-ing attribute categories.
practitioners are suggestedto prompt users to provide self-identiﬁcation andrespect the difﬁculties of respondents when ask-ing.
our model helps increase the interpretabilityof the relational inference process by tracking theattributes and updating the relational belief.
weexpect that the biases from relation recognitioncan be easier to measure, and our α–β–γ processesmay provide a multidimensional way for correctingthem..references.
christoph alt, marc h¨ubner, and leonhard hennig.
2019. fine-tuning pre-trained transformer languagemodels to distantly supervised relation extraction.
in proceedings of the 57th annual meeting of the.
association for computational linguistics, pages1388–1398, florence, italy.
association for compu-tational linguistics..nguyen bach and sameer badaskar.
2007. a review ofrelation extraction.
literature review for languageand statistics ii, 2:1–15..punam bedi and chhavi sharma.
2016. communitydetection in social networks.
wiley interdisciplinaryreviews: data mining and knowledge discovery,6(3):115–135..david belanger and andrew mccallum.
2016. struc-tured prediction energy networks.
in internationalconference on machine learning, pages 983–992.
pmlr..snigdha chaturvedi, mohit iyyer, and hal daume iii.
2017. unsupervised learning of evolving relation-ships between literary characters.
in proceedings ofthe aaai conference on artiﬁcial intelligence, vol-ume 31..hui chen, pengfei hong, wei han, navonil majumder,and soujanya poria.
2020. dialogue relation extrac-tion with document-level heterogeneous graph atten-tion networks.
arxiv preprint arxiv:2009.05092..siddhartha chib and edward greenberg.
1995. un-derstanding the metropolis-hastings algorithm.
theamerican statistician, 49(4):327–335..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training of deepbidirectional transformers for language understand-ing.
arxiv preprint arxiv:1810.04805..patrick doreian and frans n stokman.
1997. the dy-namics and evolution of social networks.
evolutionof social networks, 1(1)..nan du, bin wu, xin pei, bai wang, and liutongxu.
2007. community detection in large-scale so-cial networks.
in proceedings of the 9th webkddand 1st sna-kdd 2007 workshop on web miningand social network analysis, pages 16–25..matthew r. gormley, mo yu, and mark dredze.
2015.improved relation extraction with feature-rich com-in proceedings ofpositional embedding models.
the 2015 conference on empirical methods in nat-ural language processing, pages 1774–1784, lis-bon, portugal.
association for computational lin-guistics..raia hadsell, sumit chopra, and yann lecun.
2006.dimensionality reduction by learning an invariantmapping.
in 2006 ieee computer society confer-ence on computer vision and pattern recognition(cvpr’06), volume 2, pages 1735–1742.
ieee..mohit iyyer, anupam guha, snigdha chaturvedi, jor-dan boyd-graber, and hal daum´e iii.
2016. feud-ing families and former friends: unsupervised.
666learning for dynamic ﬁctional relationships.
in pro-ceedings of the 2016 conference of the north amer-ican chapter of the association for computationallinguistics: human language technologies, pages1534–1544, san diego, california.
association forcomputational linguistics..makoto miwa and yutaka sasaki.
2014. modelingjoint entity and relation extraction with table repre-sentation.
in proceedings of the 2014 conference onempirical methods in natural language processing(emnlp), pages 1858–1869, doha, qatar.
associa-tion for computational linguistics..zhijing jin, yongyi yang, xipeng qiu, and zhengzhang.
2020. relation of the relations: a newparadigm of the relation extraction problem.
arxivpreprint arxiv:2006.03719..nanda kambhatla.
2004. combining lexical, syntactic,and semantic features with maximum entropy mod-els for information extraction.
in proceedings of theacl interactive poster and demonstration sessions,pages 178–181, barcelona, spain.
association forcomputational linguistics..evgeny kim and roman klinger.
2019. frowningfrodo, wincing leia, and a seriously great friend-ship: learning to classify emotional relationships ofﬁctional characters.
in proceedings of the 2019 con-ference of the north american chapter of the asso-ciation for computational linguistics: human lan-guage technologies, volume 1 (long and short pa-pers), pages 647–653, minneapolis, minnesota.
as-sociation for computational linguistics..diederik p kingma and jimmy ba.
2014. adam: amethod for stochastic optimization.
arxiv preprintarxiv:1412.6980..anna kukleva, makarand tapaswi, and ivan laptev.
2020. learning interactions and relationships be-in proceedings of thetween movie characters.
ieee/cvf conference on computer vision and pat-tern recognition, pages 9849–9858..shantanu kumar.
2017. a survey of deep learningarxiv preprint.
methods for relation extraction.
arxiv:1705.03645..brian larson.
2017. gender as a variable in natural-language processing: ethical considerations.
in pro-ceedings of the first acl workshop on ethics innatural language processing, pages 1–11, valencia,spain.
association for computational linguistics..zuchao li, hai zhao, rui wang, and kevin parnow.
2020. high-order semantic role labeling.
in find-ings of the association for computational linguis-tics: emnlp 2020, pages 1134–1151, online.
as-sociation for computational linguistics..mike mintz, steven bills, rion snow, and daniel ju-rafsky.
2009. distant supervision for relation ex-in proceedings oftraction without labeled data.
the joint conference of the 47th annual meeting ofthe acl and the 4th international joint conferenceon natural language processing of the afnlp,pages 1003–1011, suntec, singapore.
associationfor computational linguistics..raymond j mooney and razvan c bunescu.
2006.subsequence kernels for relation extraction.
in ad-vances in neural information processing systems,pages 171–178..yannis papanikolaou, ian roberts, and andrea pier-leoni.
2019. deep bidirectional transformers for re-in proceed-lation extraction without supervision.
ings of the 2nd workshop on deep learning ap-proaches for low-resource nlp (deeplo 2019),pages 67–75, hong kong, china.
association forcomputational linguistics..siyuan qi, yixin zhu, siyuan huang, chenfanfu jiang,and song-chun zhu.
2018. human-centric indoorin pro-scene synthesis using stochastic grammar.
ceedings of the ieee conference on computer vi-sion and pattern recognition, pages 5899–5908..liang qiu, yizhou zhao, weiyan shi, yuan liang,feng shi, tao yuan, zhou yu, and song-chun zhu.
structured attention for unsupervised dia-2020.in proceedings of thelogue structure induction.
2020 conference on empirical methods in naturallanguage processing (emnlp), pages 1889–1899,online.
association for computational linguistics..meng qu, tianyu gao, louis-pascal xhonneux, andjian tang.
2020. few-shot relation extraction viain in-bayesian meta-learning on relation graphs.
ternational conference on machine learning, pages7867–7876.
pmlr..tianmin shu, michael s ryoo, and song-chun zhu.
2016. learning social affordance for human-robotinteraction.
arxiv preprint arxiv:1604.03692..shashank srivastava, snigdha chaturvedi, and tommitchell.
2016. inferring interpersonal relations inin proceedings of the aaainarrative summaries.
conference on artiﬁcial intelligence, volume 30..piotr sztompka.
2002..socjologia..analiza.
społecze´nstwa, znak, krak´ow, page 324..paul vicol, makarand tapaswi, lluis castrejon, andsanja fidler.
2018. moviegraphs: towards under-instanding human-centric situations from videos.
proceedings of the ieee conference on computervision and pattern recognition, pages 8581–8590..tianfu wu and song-chun zhu.
2011. a numericalstudy of the bottom-up and top-down inference pro-international journal ofcesses in and-or graphs.
computer vision, 93(2):226–252..fuzhao xue, aixin sun, hao zhang, and eng siongchng.
2020a.
an embarrassingly simple modelarxiv preprintfor dialogue relation extraction.
arxiv:2012.13873..667fuzhao xue, aixin sun, hao zhang, and eng sionggdpnet: reﬁning latent multi-chng.
2020b.
view graph for relation extraction.
arxiv preprintarxiv:2012.06780..xue yongqiang, gao baojiao, and gao jianfeng.
1997.the theory of thermodynamics for chemical reac-tions in dispersed heterogeneous systems.
journalof colloid and interface science, 191(1):81–85..dian yu, kai sun, claire cardie, and dong yu.
2020.dialogue-based relation extraction.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics, pages 4927–4940, on-line.
association for computational linguistics..godandapani zayaraz et al.
2015. concept relationextraction using na¨ıve bayes classiﬁer for ontology-journal ofbased question answering systems.
king saud university-computer and informationsciences, 27(1):13–24..dmitry zelenko, chinatsu aone,.
and anthonyrichardella.
2003. kernel methods for relation ex-journal of machine learning research,traction.
3(feb):1083–1106..yuhao zhang, victor zhong, danqi chen, gabor an-geli, and christopher d. manning.
2017. position-aware attention and supervised data improve slotin proceedings of the 2017 conference onﬁlling.
empirical methods in natural language processing,pages 35–45, copenhagen, denmark.
associationfor computational linguistics..shubin zhao and ralph grishman.
2005. extractingrelations with integrated information using kernelmethods.
in proceedings of the 43rd annual meet-ing of the association for computational linguis-tics (acl’05), pages 419–426, ann arbor, michi-gan.
association for computational linguistics..yizhou zhao, liang qiu, wensi ai, feng shi, andsong-chun zhu.
2020. vertical-horizontal struc-tured attention for generating music with chords.
arxiv preprint arxiv:2011.09078..peng zhou, wei shi, jun tian, zhenyu qi, bingchen li,hongwei hao, and bo xu.
2016. attention-basedbidirectional long short-term memory networks forin proceedings of the 54threlation classiﬁcation.
annual meeting of the association for computa-tional linguistics (volume 2: short papers), pages207–212, berlin, germany.
association for compu-tational linguistics..song-chun zhu and david mumford.
2007. a stochas-.
tic grammar of images.
now publishers inc..song chun zhu, yingnian wu, and david mumford.
1998. filters, random ﬁelds and maximum entropy(frame): towards a uniﬁed theory for texture mod-international journal of computer vision,eling.
27(2):107–126..a appendices.
668id subject relation type.
object.
inverse relation.
12345678910111213141516171819202122232425262728293031323334353637.perperperperperperperperperperperperperperperperperperperperperperperperperperperperperperpergpegpegpeorgorgname.
nameper:positive impressionnameper:negative impressionnameper:acquaintancenameper:alumninameper:bossnameper:subordinatenameper:clientnameper:datesnameper:friendsnameper:girl/boyfriendnameper:neighbornameper:roommatenameper:childrenper:other familynamenameper:parentsnameper:siblingsnameper:spousenameper:place of residencenameper:place of birthnameper:visited placeper:originnameper:employee or member of namenameper:schools attendednameper:worksvalueper:agevalueper:date of birthstringper:majorstringper:place of workstringper:titlename/stringper:alternate namesname/stringper:petnamegpe:residents of placenamegpe:births in placenamegpe:visitors of placenameorg:employees or membersnameorg:studentsname/string/valueunanswerable.
table 5: relation types in dialogre..per:acquaintanceper:alumniper:subordinateper:boss.
per:datesper:friendsper:girl/boyfriendper:neighborper:roommateper:parentsper:other familyper:childrenper:siblingsper:spousegpe:residents of placegpe:births in placegpe:visitors of place.
org:employees or membersorg:students.
per:place of residenceper:place of birthper:visited placeper:employee or member ofper:schools attended.
669attributes.
genderageethnicity.
profession.
relations.
male, femaleadult, kid, young adult, teenager, senior, babycaucasian, asian, arab, south-asian, hispanic, african, native american, other, aboriginal, african-americanphotographer, cab driver, priest, writer, receptionist, delivery man, yoga instructor, chef, bartender, waitress,tailor, parking attendant, student, professional, lawyer, teacher, businessman, secretary, model, prince, banker,court reporter, intern, police ofﬁcer, child psychologist, doctor, salesman/woman, hustler, bull rider, worker,doctors, businessman/woman, nurse, barman, janitor, policeman, inspector, fda agent, counselor, waiter, judge,magician, prostitute, doorman, elevator operator, hotel manager, maid, bellhop, saleswoman, salesman, politician,driver, usher, actress, actor, ﬂorist, pilot, ﬂight attendant, ﬁlm/tv producer, building manager, paramedic, federal agent,postal worker, comic book artist, singer, executive, hockey player, referee, waiter/waitress, ex-soldier, receptionist,maﬁa boss, maﬁa member, musician, drug lord, fruit vendor, barber, masseuse, mental patient, mental patient,bus driver, night guard, housewife, editor, gardener, publisher, builder, elf, security guard, security chief, pedicurist,professor of defense against the dark arts, wandmaker, wizard, caretaker, ghost, villain, philadelphia eagles fan,cowboys america fan, bookmaker, unemployed, high school principal, jobless, racists, nuclear physicist, surgeon,soldier, colonel, professor, engineer, military ofﬁcer, technician, game show host, police, robber, waiter/waitress,hitman, actor/actress, criminal, boxer, drug dealer, restaurant host, impersonator, military, trainer, manager, housekeeper,veterinarian, sportsperson, sports coach, sports agent, accountant, personal assistant, nanny, reporter, tv host, cameraman,tv presenter, cashier, artist, chauffeur, video artist, private investigator, administrator, tennis instructor, professional tennis player,detective, ticket collector, director, medical workers, hospital orderly, pharmacist, security ofﬁcer, dental assistant, dentist,drug addict, registered sex offender, fetish worker, customer support, policemen, ceo, babysitter, assistant, principal,guidance counselor, farmer, entertaining, domestic worker, ﬁsherman, author, psychologist, security person, tv personality,zeppelin crewman, king/queen, knight, journalist, assistant, weatherman, show host, make-up artist, seller, agent, tv show host,makeup artist, treasure hunter, naval ofﬁcer, steward, ship captain, ship designer, sailor, designer, carpenter, valet, bail bondsman,court bailiff, court clerk, blackjack dealer, movie star, casino owner, casino manager, art director, executive recruiter, sports editor,cowboy, cowboy employer, hacker, investment counselor, hairdresser, sports commentator, chemist, government rep, vicar, robot,hotline agent, cook, surrogate date, philosopher, architect, record store owner, movie reviewer, call operator, bride,dog sitter, newspaper employer, vet, insurance broker, union leader, tv reporter, senator, rancher, locksmith, district attorney,store owner, smuggler, insurance agent, video editor, bouncer, trainee, real estate agent, prison guard, tour guide, mobstersibling, parent, cousin, customer, friend, stranger, spouse, colleague, boss, would like to know, lover, mentor, engaged,knows by reputation, acquaintance, roommate, best friend, antagonist, employed by, business partner, student, classmate,patient, teacher, child, heard about, enemy, employer of, psychiatrist, doctor, collaborator, ex-lover, landlord, superior,supervisor, grandchild, divorced, sponsor, ex-boyfriend, neighbor, fan, close friend, sister/brother-in-law, uncle, host,employer, step-mother, foster-son, family friend, godfather, godson, brother-in-law, nanny, grandparent, aunt, aide,students, family, customers, classmates, alleged lover, trainer, slave, hostage, robber, owner, instructor, competitor,ﬁancee, aunt/uncle, mother-in-law, girlfriend, killer, babysitter, one-night stand, boyfriend, tenant, distant cousin,father-in-law, mistress, agent, replacement, argue about the relationship, lawyer, ex-spouse, ex-girlfriend/ex-boyfriend,niece/nephew, parent-in-law, guardian, operative system, couple, goddaughter, customer, ex-neighbor, worker, vet,apprentice, public ofﬁcial, nurse, supporter, interviewee, interviewer, supporters, ex-ﬁance, ﬁance.
table 6: attribute and relation types in moviegraph..670