changing the world by changing the data.
anna rogerscenter for social data scienceuniversity of copenhagenarogers@sodas.ku.dk.
abstract.
nlp community is currently investing a lotmore research and resources into developmentof deep learning models than training data.
while we have made a lot of progress, it is nowclear that our models learn all kinds of spuri-ous patterns, social biases, and annotation ar-tifacts.
algorithmic solutions have so far hadlimited success.
an alternative that is beingactively discussed is more careful design ofdatasets so as to deliver speciﬁc signals.
thisposition paper maps out the arguments for andagainst data curation, and argues that funda-mentally the point is moot: curation already isand will be happening, and it is changing theworld.
the question is only how much thoughtwe want to invest into that process..1.introduction.
the key ingredient behind the recent successes innlp is transformer-based language models.
theparadigm of pre-training followed by ﬁne-tuningon downstream tasks was popularized by bert(devlin et al., 2019), and is actively developed(rogers et al., 2020b).
in december 2020 the hu-man performance baselines on superglue (wanget al., 2019a) were surpassed twice, making thecommunity wonder if it is possible to formulatebenchmarks not solvable in this paradigm..however, the successes are not the full story.
itis becoming increasingly clear that much of the re-markable performance is down to benchmarks thatdo not actually require sophisticated verbal reason-ing skills due to annotation artifacts and spuriouspatterns correlating with the target labels (guru-rangan et al., 2018; mccoy et al., 2019; paulladaet al., 2020).the social biases in nlp models arealso attracting more attention (sheng et al., 2019;davidson et al., 2019; hutchinson et al., 2020)..the “garbage in, garbage out" principle suggeststhat the situation will not change without a dramatic.
reappraisal of how nlp data is collected, both forpre-training and task-speciﬁc resources.
but thatseemingly uncontroversial conclusion is at the coreof the interdisciplinary tension between nlp under-stood as a deep learning (dl) application area, andthe more qualitative approaches of computationallinguistics and ai ethics.
how deep that tensiongoes is illustrated by the recent heated (and some-times less than professional1) debate around “onthe dangers of stochastic parrots: can languagemodels be too big?"
by bender, gebru et al(2021)..this position paper brings together the argu-ments for and against curating data2 from linguisticand ethical perspectives (§2).
it makes the case thatcuration is unavoidable and already happening, andthat any data choices that we make, explicitly orimplicitly, will affect the real world (§3).
thus thedebate is only about how much thought we shouldput into this process.
if we are to at least try tosteer it, we have to overcome the interdisciplinarytension and reconsider what counts as “nlp work”(§4).
§5 outlines some policies that could help..2 to curate or not to curate?.
2.1 why change the data?.
the core argument for active curation/design of thedata that goes into nlp models is that the modelsare representations of the data they were trainedon, and thus data work is necessary to make surethat the models can learn what we need them tolearn.
the supporting evidence for this position.
1https://www.theverge.com/22309962/timnit-gebru-.
google-harassment-campaign-jeff-dean.
2in this paper “data curation" is interpreted broadly as mak-ing choices about what should be included in a nlp resource(either for pre-training or task-speciﬁc data).
the phenomenato be included/excluded could be deﬁned in terms of whatis said (e.g.
soccer commentary), how it is expressed (e.g.
with or without expletives), and/or who is speaking or beingaddressed (e.g.
teenage soccer fans)..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2182–2194august1–6,2021.©2021associationforcomputationallinguistics2182comes independently from several directions: thestudies ﬁnding that the models fail to learn a certainphenomenon and/or learn something undesirable..2.1.1 social biases.
our world is far from perfect, and written texts con-tain plenty of evidence of all kinds of social biasesbased on gender, race, social status, ability, age, etc.
models may learn these biases (from pre-trainingand/or task data) and even amplify them, puttingthe minority groups at a disadvantage by directpsychological harm and propagation of stereotypes(blodgett et al., 2020; bender et al., 2021).
in thiscontext, “data curation” means selecting data basedon its sociocultural characteristics (jo and gebru,2020).
fundamentally, this is about fair representa-tion for different social groups..some dismiss bender et al.
(2021) as “political”,or even “advocacy rather than research” (lissack,2021).
however, “papers advocate for speciﬁc re-search agendas all the time” (venkatasubramanian,2021).
nlp in particular has a growing subﬁeld ofbias mitigation (see e.g.
the survey on such workfor gender bias by sun et al.
(2019)) that pursuesexactly the same social justice agenda, but does notreceive the same pushback..2.1.2 privacy concerns..models may memorize speciﬁc facts in trainingdata, and if those facts happen to be personallyidentiﬁable information, this is a security concern.
for instance, carlini et al.
(2020) showed that gpt-23 was able to memorize personal contact informa-tion, even if it only appeared on a few web pages.
a big problem is that this is not a bug, but a fea-ture: we do want our language models to representsome facts about presidents – just not about privatecitizens.
deciding what should not be rememberedis clearly a data curation issue..2.1.3.
(lack of) progress towards nlu.
dl models are data-hungry, and so far we haveheavily relied on the sources that are easy to scale:web texts for pre-training, and crowdsourcing forannotation or generating shorter texts.
combinedwith most funding and effort allocated to modeldevelopment, this meant a less clear view of whatwas in the data.
consequently, the recent years wit-nessed a lot of ﬁndings along the following lines..3google legal department reportedly requested edits to thearticle by carlini et al.
(2020), in particular to avoid mentionsof google technology (dave, 2021)..dl models learn spurious patterns present inthe data.
these patterns can be the results ofthe heuristics used by crowd workers (gururan-gan et al., 2018), small samples of workers creatinglarge parts of data with traces (geva et al., 2019), orsimply random patterns in the task or pre-trainingdata.
for example, words like football may fre-quently occur in abusive tweets, but this shouldnot give the model the idea that all sports fans areviolent (wiegand et al., 2019).
the result is thatmany current datasets can (and do) get “solved"with shallow cues such as lexical co-occurrence(jia and liang, 2017; mccoy et al., 2019).
thelarger the resource, the more difﬁcult it is to avoidthem (gardner et al., 2021)..dl models are surprisingly vulnerable to basicperturbations.
acl 2020 best paper award wentto ribeiro et al.
(2020)’s demonstration that eventhe successful, commercially deployed nlp sys-tems cannot handle many core linguistic phenom-ena like negation.
pre-trained language models bythemselves do not necessarily cope with them ei-ther (ettinger, 2020).
this suggests that the currentresources do not provide the signal to learn thenecessary linguistic paradigms..dl models struggle to learn rare phenomena.
linguistic phenomena generally follow zipf dis-tribution (zipf, 1945), which means that most ofthem are rare in naturally occurring data, and thusharder for the models to learn.
this applies evento the large pre-training datasets.
for example,zhang et al.
(2020) compared the learning rates fordifferent linguistic phenomena as roberta waspre-trained on more and more data.
english irreg-ular verb forms (highly frequent) were acquiredin under 10m of training tokens, but the modelstruggled with island effects even after 30b tokens.
such results suggest that if something needs to belearned, the model needs to be provided with asufﬁciently strong signal (and it may still fail eventhen (geiger et al., 2019))..the bottom line is that the distributions of lin-guistic phenomena in the current nlp resourcesdo not seem to provide the signal with which thecurrent models could learn to perform human-levellanguage “understanding”.
we do not even knowthe full spectrum of abilities that would qualify forthat.
choosing which aspects of a given “task” (orlanguage, in case of pre-training) a given resourcewould “teach” explicitly is a curation decision..21832.1.4 security concerns..2.2 why not to change the data?.
a relatively recent development is “universal adver-sarial triggers": adversarial attacks on the modelsthat modify the textual input in a way that forces themodels to always output a certain prediction (wal-lace et al., 2019).
for example, the authors make asquad-trained reading comprehension model toalways predict the answer “to kill american peo-ple" for any why-question.
this effect is robust andmodel-independent: i.e.
it is the training data thatgets “hacked", not the model..it is not clear if it is possible to construct adataset that would not have such vulnerabilities,but common sense suggests that the training datashould be curated so as to make them unlikely tooccur in the natural distribution of user input..2.1.5 evaluation methodology..so farthe fundamental paradigm for nlpwork based on machine learning focused on in-distribution evaluation: the test sample would comefrom the same distribution as the train/validationsamples, and the samples would be randomly split.
within that paradigm, it is essential that there areno overlaps between training and test data, whichis an issue for many current resources (lewis et al.,2021; emami et al., 2020)..to do that well, we already have to make de-cisions about what counts as “overlap", and whatshould be in the training and testing data.
for ex-ample, in pre-training gpt-3 (brown et al., 2020)decisions had to be made about which benchmarkswould be used for evaluation.
there was a (par-tially successful) attempt to simply remove doc-uments with signiﬁcant overlap with any test ex-amples from the training data, which raises a newissue: if the goal is to train a “general-purpose”model, what information could we safely excludefrom training purely for evaluation purposes?.
linzen (2020) suggests switching to out-of-distribution testing: given that the training datais unlikely to faithfully represent a full range of lin-guistic phenomena, in-distribution evaluation likelyoverstates how well the model is doing.
but to dothat, we would still need to know what is “in" thetraining distribution, and what we would be testing..to sum up, there are (at least) 4 reasons to makedeliberate decisions about what should be includedin the training data, so as to create more robust,inclusive, and secure nlp models.
what are theobjections?.
since this is a position paper arguing that data cu-ration is unavoidable, the arguments against it arepresented together with the defense.
most of themare applicable to both pre-training and task data(except for §2.2.2, which focuses on pre-training)..2.2.1 studying the world “as it is".
in response to bender et al., goldberg (2021) ar-gued that there are valid use cases in which “amodel of language use should reﬂect how the lan-guage is actually being used", rather than how webelieve it should be used..defense.
this is a completely valid argument,and what follows is elaboration rather than refuta-tion.
in linguistic or social science research, it isuncontroversial that if the corpus is a representa-tive sample of the target phenomena, it should notbe manipulated.
if the goal is to model the world-view of reddit users, the corpus used for traininggpt-2 (comprising articles shared on reddit) is arepresentative sample.
likewise, if the goal is tostudy social biases, we should not eliminate e.g.
racist comments.
the problem raised by benderet al.
(2021) is only that resources should be usedfor what they are: the reddit users are not a repre-sentative sample of the general population, and sogpt-2 is not a “general-purpose” language model.
this argument concerns the qualitative studies ofthe “world as it is”.
most nlp research, however,aims to produce systems that would perform sometask.
in that case the “natural” distribution may noteven be what we want: e.g.
if the goal is a questionanswering system, then the “natural" distribution ofquestions asked in daily life (with most questionsabout time and weather) will not be helpful.
thedevelopers may also prefer for their systems to bee.g.
less racist/sexist than their input data..note that to study the world “as it is" we stillhave to do a lot more data work than we are cur-rently doing (so as to be able to tell whether a givencorpus actually represents the target phenomenon)..2.2.2 our sample is large enough.
an anonymous reviewer of this paper contributedthe following argument: “the size of the data is solarge that, in fact, our training sets are not a sampleat all, they are the entire data universe”..defense.
this argument would stand if the “datauniverse" that we use for training nlp sys-tems were the same as “the totality of human.
2184speech/writing".
it is not, and will hopefully neverbe, because collecting all speech is problematicfor ethical, legal, and practical reasons.
anythingless than that is a sample.
given the existing socialstructures, no matter how big that sample is, it isnot representative due to (at least) unequal access totechnology, unequal possibility to defend one’s pri-vacy and copyright, and limited access to the hugevolumes of speech produced in the “walled garden"platforms like facebook.
the use of uncontrolledsamples (like the common-crawl-based corpora)would have to be justiﬁed by arguing either that theabove types of bias can be safely ignored, or thatthe beneﬁts outweigh the risks..2.2.3 might not be the best approach..do we really have to do hard data work, or couldthere be an algorithmic solution?
for the prob-lem of rare phenomena (§2.1.3), there is ongoingwork on inductive biases that could help the modelslearn them (mccoy et al., 2020).
for social issues(§2.1.1) goldberg (2021) and buckman (2021) sim-ilarly suggest that rather than trying to ﬁlter outproblematic samples (hate speech, racial slurs etc.)
we could use them to build a representation of theundesirable phenomena, and to try to actively iden-tify and ﬁlter them out in generation.
schick et al.
(2021) propose a method for a generative languagemodel to reduce biases in its output, using self-diagnosis with its own internal knowledge..defense.
it is entirely possible that algorithmicalternatives could work better than solutions basedon data curation.
which one will be more success-ful is an empirical question.
as of now, it seemsthat they are complementary rather than mutuallyexclusive: for example, some speciﬁc biases couldbe handled algorithmically, but data curation couldbe used to balance the corpus in some other way(s)..note that the algorithmic solutions would stillrequire much of the same data work for evaluationpurposes: to ﬁnd out whether a system is effectiveat ﬁltering out something undesirable or processingsome rare pattern, these phenomena have to beidentiﬁed, a test set has to be constructed, we wouldneed to make sure that it does not overlap withthe training data, and ideally – to what degree thevarious aspects of these phenomena are supportedby training evidence.
this is a big part of work thatwould go into designing a training dataset..2.2.4 not what we set out to do!.
the history of ai could be viewed as a trajectorytowards decreased amount of implicitly injectedknowledge.
the early ai systems were fully drivenby carefully constructed rules and ontoloties.
theywere replaced by the statistical approaches, relyingon heavy feature engineering.
the great promise ofdl was to stop trying to deﬁne everything, and letthe machine to identify and leverage patterns fromhuge datasets: “we should stop acting as if ourgoal is to author extremely elegant theories, andinstead embrace complexity and make use of thebest ally we have: the unreasonable effectivenessof data" (halevy et al., 2009).
and it seems towork: pre-training larger models with more datakeeps producing state-of-the-art results (sun et al.,2017; brown et al., 2020; fedus et al., 2021)..calls for careful construction of datasets are go-ing in the face of that dream.
we would arguablybe even worse off than when we started: at leastin the early ai days we only needed to deﬁne thephenomenon to be modeled, and now we also haveto ﬁnd hundreds of examples for that phenomenon..defense.
disappointing as it is, we have to ad-mit that although deep-learning-based systems aremuch better than their predecessors, they are stillbrittle and do not work well outside the range ofcases well represented in the training data (andeven there they may work for the wrong reasons).
what is more, we are fundamentally no closer tothe elusive idea of “understanding" language or itsmeaningful production (bender and koller, 2020).
it is true that we were able to “solve” chess andgo without expert knowledge (sutton, 2019), butthese are closed-world games with a known set ofrules describing that world.
attempting to do so inthe areas that feed from the real social world andimpact that world (nlp, facial recognition, algorith-mic decision-making on loans etc.)
could amplifyundesirable patterns present in the big data..as stated in §2.2.3, it is possible that there is analgorithmic approach that will work equally well orbetter.
which one will win is an empirical question.
as of now, it is fair to say that data curation is atleast an alternative to be considered..this is not to say that the current technology can-not yield useful solutions.
the achievements areundeniable: the advances in machine translation,question answering, and dialogue already powerbetter customer service, educate and inform, en-able communication and information ﬂow for peo-.
2185ple who could not afford professional translation.
there is certainly room for useful research to fur-ther improve the current solutions, deﬁne new tasksand transfer to new domains and languages, evenif no fundamental breakthroughs come any timesoon.
the question is only whether we want to beable to tell in what circumstances our models canbe used safely (mitchell et al., 2019).
if so, thatwould require more thinking about data..2.2.5 perfection is not possible..as mentioned in §2.1.3, the distribution of lan-guage phenomena tends to be zipﬁan (zipf, 1945),which means that most phenomena are rare anddifﬁcult to learn.
a perfect dataset would providesa strong signal for each phenomenon that shouldbe learned.
that’s not how language works, so wemay never be able to create something like that.
balanced datasets are an improvement, but not asolution (wang et al., 2019b; rogers et al., 2020a)..defense.
the impossibility of perfection doesnot entail the impossibility of improvement.
forexample, a sentiment analysis system that performsas well as the current systems while handling nega-tion and coreference correctly, and not pre-judgingfootball fans as violent, is a doable next goal..2.2.6 no single correct answer..curation means making conscious choices aboutwhat to include and what to exclude.
these areessentially choices about designing a world.
whatlinguistic patterns, what concepts, what demo-graphic attributes, what values should that worldencode?
this is a daunting question, requiring alot of interdisciplinary expertise and impossible tocasually address within a small nlp applicationproject.
neither social sciences nor linguistics offera ready set of answers, only things to consider invarious contexts.
the discriminated sub-groups,their values, and underlying social constructs mayalso differ across communities: e.g.
both in in-dia and us there is discrimination based on skintone, but in the us context it stands for race, andin india it is a proxy for ethnicity, caste and class(sambasivan et al., 2021a)..defense.
this is an entirely valid point, but itis an objection not to data curation per se, but to“data curation in a way that would inﬂict one set ofvalues and linguistic choices on everyone".
that isindeed to be avoided at all costs, and there is a realdanger of that happening when nlp systems are.
commercially deployed and widely used, but thedata choices behind them are not explicit..the position advocated in this paper, as well asby bender et al.
(2021), is only that whatever cate-gories and demographics went into the data design,they have to be documented (bender and fried-man, 2018; gebru et al., 2020) and made explicit,so that the users could be informed about whatis happening (mitchell et al., 2019).
some stud-ies will just use convenience samples, and somewill intentionally try to create a representation of aworld without racial prejudice or rich with islandeffects.
there are valid use cases for both, as longas it is clear who/what is being represented andfor what purposes.
the tide seems to be turning inthis direction: since this work was submitted forreview, at least two papers came out documentingpopular resources for pre-training language mod-els (dodge et al., 2021; bandy and vincent, 2021).
the popular huggingface nlp dataset library4 isalso working towards data cards for its resources.
documenting the choices made in the dataset de-sign is prerequisite to model cards (mitchell et al.,2019), which could facilitate a healthy interactionbetween the communities served by the system andthe developers of that system.
it is entirely pos-sible for that interaction happen in a democraticprocess: the policies could developed, announcedand updated based on the evolving user preferences.
robustness in handling linguistic and social pecu-liarities of a given community should be a sellingpoint for a product striving to win that commu-nity over: something to compete for and showcase,rather than avoid mentioning..when argument §2.2.6 is made, sometimes itseems to rest on the idea that the distributions inour resources objectively reﬂect the world.
on thatview, the calls to data curation would seem opin-ionated and unnecessary, if not outright dystopian.
but the idea that it is possible to work on “nlpin the vacuum", unmarked by linguistic and socialcategories, is an illusion.
a decision to use a con-venience sample is also a choice, an act of curation.
using any data to derive research conclusions orin commercial applications is only safe if we knowwhat/who it represents..3 why curation is inevitable.
in cognitive and sociolinguistics, one of the meth-ods of studying the linguistic and conceptual reper-.
4https://huggingface.co/docs/datasets/.
2186toire of a certain individual or a demographic isthrough collecting a representative corpus of theirspeech (synchronic or diachronic).
that corpusinevitably reﬂects a particular world view5.
thedifferences in these world views are expressed asvariation in what kinds of linguistic structures peo-ple are likely to use, what they are likely to talkabout, what are their presuppositions and socialcontext and stereotypes, to what extent any of thatis verbally expressed, etc.
some of that variationis idiosyncratic, some attributable to social groups,but even a cursory look at all the variation stronglysuggests that there is no “language in general"..it is still possible to talk about language at acertain level of abstraction (e.g.
“british english"vs the myriad of uk dialects), but only with a goodsample representing all the necessary subsets.
forexample, it would be wrong to construct a “britishenglish" resource based only on london samples,because they do not represent the rest of the country(either linguistically or socioeconomically)..a major achievement of corpus linguists arethe “national corpora" such as bnc (leech, 1992),painstakingly created to represent a diverse sampleof written and spoken genres in a certain geograph-ical region in a certain timeframe, so as to enablestudies of that speciﬁc variety of language.
cre-ating such corpora involves careful sampling, de-tailed documentation of the domains and speakersthat were represented, and much negotiation withpublishers for copyright exceptions..a typical corpus for training language models,or really any nlp dataset, is likewise a sample ofspeech of a certain group of people, who have theirlinguistic preferences and sets of values.
conse-quently, that sample, whether it is coherent or not,and whether it was collected with any speciﬁc in-tentions, represents a certain “picture of the world".
moreover, the purpose of using this data for train-ing is to create a system that would encode thatview of the world and make predictions consistentwith it.
but a typical nlp dataset6 currently hasfew speciﬁcations of the demographics, dialects,or the range of domains and linguistic phenomenait covers.
unfortunately, it does not mean that the.
5this is a key concept in the works of neo-humboldtianscholars: “world image” (weltbild) of weisgerber, “naivepicture of the world” (naivnaja kartina mira) of apresyan(1995), and many others..6corpora generated on crowd worker platforms such asamazon mechanical turk typically impose geographic restric-tions, such as “location in us or canada", but there is noguarantee that the recruited workers are even native speakers..result is some abstract “standard" or “neutral" lan-guage.
it is some kind of interpolation from themixture of signals in the data that we have verylittle idea about..why does it matter?
the linguistic and concep-tual repertoire of humans is dynamic.
our vocabu-lary, grammar, style, cultural competence changeas we go on with our lives, encounter new con-cepts, forget some things and reinforce others.
akey part of that change is the linguistic signals weencounter in communication: on the nativist ac-count children have innate constraints that guide7their learning from the data they encounter (chom-sky, 2014; hornstein and lightfoot, 1985), and onthe usage-based accounts (bybee, 2006; lievenand tomasello, 2008) that process is entirely data-driven.
humans can learn the meaning of wordsfrom a single exposure (carey and bartlett, 1978;borovsky et al., 2010), but there is also robust evi-dence of frequency effects in language acquisition(ambridge et al., 2015; diessel and hilpert, 2016,may 09).
it is not by accident that the frequencyof the vocabulary to be learned is a key variable inlanguage pedagogy (zahar et al., 2001)..in short, humans, like dl models, learn fromthe patterns in the speech that they encounter.
andthose patterns do not have to come from humanspeakers anymore: much speech that we will en-counter in the future is likely to be synthetic.
ac-cording to pilipiszyn (2021), gpt-3 is already gen-erating 4.5b words per day in applications suchas question answering, summarization, interactivegames, and customer support..this cannot but have impact back on the human.
speakers8 in the following ways:.
• an nlp system generating text contributesto a human learner’s input in the same wayas human writers, and probably also speakers(but potentially on a much larger scale)..• an nlp system that processes human input toanswer questions, translate, perform assistingactions etc.
has both direct impact (as a lan-.
7the “radical" nativist position would be that knowledgeof language is entirely innate and is not affected by what thechildren observe, but on that position we would have to claimthe innate knowledge of the word “carburetor" (knight, 2018).
8synthetic speech will also clearly have impact on the fu-ture models if it seeps into the training data.
there is researchon watermarking generated text (venugopal et al., 2011; ab-delnabi and fritz, 2021), but it is not clear what, if anything,the currently deployed systems are doing in this regard.
thereis at least one documented case of gpt-3 used to post onreddit as if it were a human user (philip, 2020)..2187guage model above), and an indirect impact:as these systems become more widespread,the kind of language that they can and can-not successfully interpret will be respectivelyreinforced or made less prominent..• an nlp system that makes decisions in pro-cessing applications, grading student work,curating news feeds, summarizing papers andemails, recommending content has the poten-tial of making long-lasting impact on the livesof its users, and the kinds of language that itcan process successfully clearly play a role..the point to take from all of this is that any mis-match of linguistic and social feature distributionsbetween nlp systems and their users will havesome impact on the world, and for the commercial,widely used nlp systems that impact may be sig-niﬁcant.
so the debate is not about whether weshould change the world by making choices aboutthe data: this is happening either way, because evenour convenience samples still reﬂect numerous im-plicit choices.
the debate is only about how muchthinking we want to invest into changing our world.
this thought is somewhat scary (in what waywill children growing up with alexa be different?
),but also exciting:the educational opportunitiesalone could be breathtaking, reaching far beyondthe students who are already in a good positionto do well in school.
we could also create some-thing simplistic, uninspiring, mindlessly entertain-ing, and/or not-inclusive.
that choice is ours..4 what does it mean to “do nlp"?.
to sum up the above discussion: there are no “neu-tral", one-size-ﬁts-all textual corpora.
there is alsono manual that would provide foolproof instruc-tions for collecting a “correct" corpus for any givencontext.
and all of these complications are noteven the main problem, right?
after all, data onlyserves the task of creating a model, which is thereal contribution of an nlp paper?.
in theory, the ﬁeld of nlp is interdisciplinary.
in practice, it became something closer to “oneof the applied areas of machine learning" ratherthan “computational linguistics".
furthermore, atleast as far as graduate students are concerned, itis something performed as an academic exercise,and as such it does not really have to concern itselfwith its possible effects on the world..the students can hardly be blamed: keeping upwith the latest frameworks and architectures is al-.
ready hard enough.
most dl practitioners haveneither the training nor time to also do the datawork at the level that the linguists and ethicistsare calling for.
the publication system does notprovide the right incentives for that either: mod-eling nlp work is prestigious and welcomed attop conferences, while data work is “janitorial",less well paid, “under-valued and de-glamorised”9(sambasivan et al., 2021b)..it does not help that there seems to be a system-atic miscommunication between the ﬁelds.
whenlinguists or ethicists talk about the issues with thecurrent solutions, the practitioners may take it asan accusation that they are not doing a good job,rather than as an invitation to improve things to-gether.
likewise, when the practitioners proposenew systems, the linguists and ethicists may befrustrated: not by the incremental improvementson leaderboards as such, but by lack of accompa-nying discussion of what the proposed methods aresupposed to do better, and for whom..if anything is to change, we need to overcomethis antagonism.
here are a few suggestions forhow that could be achieved..5 moving forward.
step 1. understand each other better.
the factis, the ai ethics people are not really out to “can-cel" everybody.
it is easy to see why they would befrustrated that the social justice issues have neverbeen a priority, terriﬁed at what “move fast & breakthings" has already done with the social world, anddubious that they just need to wait and changewould come..the linguists are not completely useless.
chances are, many problems that the dl engi-neers are having could be ﬁxed if someone wasjust around to realize that the tokenizer didn’t han-dle the sufﬁxes well..and the engineers are not inherently evil.
theyjust need resources, training, collaborators, time,and better research incentives.
instead, they haveto churn out papers in 2 months just to stay in thepublication race, with no time to dive deeper intowhat their systems are actually doing..step 2. improve the incentive structure.
oneway to change the incentive structure that led to.
9of course, this perception is not universal, and there are(very few) “unicorn" resources like squad (rajpurkar et al.,2016) that highly inﬂuenced the ﬁeld.
but overall the powerbalance in the ﬁeld is currently not in favor of resource work..2188the current situation is through conferences.
therewill be a lot more interest in data work if it be-comes more publishable.
as of now, the “resourcesand evaluation” track is something of a poor rel-ative to the “machine learning” track, which inacl 202010 attracted nearly 3 times more submis-sions.
most task-speciﬁc tracks (question answer-ing, summarization, dialogue etc.)
are supposedto receive both engineering and data submissions,but in that setting the interdisciplinary tension maylead to resource papers voted down simply for be-ing resource papers (rogers and augenstein, 2020).
bawden (2019) cites an acl 2019 reviewer whocomplained that “the paper is mostly a descriptionof the corpus and its collection and contains littlescientiﬁc contribution"..we really need to take the type of contribution11into account in reviewer assignment, into reviewform design, and into reviewer training programs.
we also need to make sure that the resource tracksare consistently offered12, with dedicated best pa-per awards to raise the prestige of this work inthe community.
some conferences already startedto provide reviewer mentoring, double down onethics, consider what signal they send to compa-nies and students by their best paper awards.
wecan all help by lobbying program chairs wheneverwe have a chance, ofﬂine and online..a helpful factor is that the ever-increasing size ofmodels is making the state-of-the-art leaderboardchase ﬁnancially untenable for even well-resourcedlabs, and they are looking for other outlets.
this isa chance for the nlp community to engage moredeeply with the phenomena that we are modeling..step 3. educate.
the idea that “nlp" means“deep learning" may well arise if it is taught as aone-semester course focusing on the engineering.
if the coursework is fully powered by existing re-sources, it creates the impression that data is not apart of the job.
the result is that the students learnthat it is entirely possible to just run off-the-shelfparsers without knowing anything about syntax, ordo sentiment analysis without knowing anythingabout pragmatics.
and if it is possible to not domore work, why would anyone bother?.
we need to provide our students with the skills.
10https://www.aclweb.org/adminwiki/.
images/9/90/acl_program_co-chairs_report_july_2020.pdf11as was done e.g..at coling 2018: http://.
coling2018.org/paper-types/.
to stress-test their systems and critically examinetheir data, so as to be able to spot potential issuesearly on.
for that, they will need the basic lin-guistic theory, the fundamentals of sociolinguisticsand pragmatics.
likewise, some aspects of psy-chology (dual processing theories, memory andattention span, cognitive biases, “nudging") are apre-requisite for designing interfaces not only forannotation projects, but for any kind of interactivenlp systems.
and some awareness of the socialpower structures would help in not propagating theharmful stereotypes.
some strategies for buildingnlp curricula have been discussed at the teach-ingnlp workshop (radev and brew, 2002; brewand radev, 2005; palmer et al., 2008; derzhanskiand radev, 2013; jurgens et al., 2021)..most importantly, nlp courses need to combatthe idea that all the knowledge about the humanworld is just irrelevant in the age of big data anddl.
the “garbage in, garbage out” principle is stillrelevant.
we may be able to sort the garbage andlearn from it anyway, but only if we have at leastsome idea about what kind of garbage we have..step 4. collaborate.
large companies and uni-versities provide a signiﬁcant competitive edge totheir authors just in virtue of the in-house collabora-tion networks they could offer.
but it is becomingincreasingly easy for everyone to ﬁnd external col-laborations, especially in the world in pandemiclockdown.
one opportunity is twitter, used byestimated 40% of emnlp 2020 authors13..what would it mean to “collaborate"?
at thebare minimum, in an engineering project the lin-guists and social scientists could help to at least tryto characterize the data that was used with some-thing like data statements (bender and friedman,2018; gebru et al., 2020).
a more ambitious goalwould be to involve them early on in the data selec-tion, preparation, and iterative development.
ide-ally, there would be joint formulation of researchgoals, thinking together about what kind of worldwe are building..finding collaborators is much easier for estab-lished researchers, not only because they are aknown quantity, but also because they are alreadyaware of what could be done in an interdisciplinaryproject.
they probably even already know the peo-ple who they could ask to join.
but the studentscould use some help, especially those from theless well-connected institutions.
they could bene-.
12e.g.
this track was recently absent at emnlp 2020..13source: emnlp 2020 organizers..2189ﬁt from establishing some kind of skill exchangenetwork, where the students with engineering back-ground could help out in data projects and studentswith linguistics/social science background couldhelp out in engineering projects.
this would prob-ably the best way to ease the interdisciplinary ten-sion, instill respect for each other’s expertise, aswell as the awareness that nlp is a huge problemthat we do not even understand that well, and forwhich we need all the help we can get..step 5. estimate.
the goal of all the above datawork is ultimately to enable informed decisionsby the public, the ceos, and the policy makersabout what kind of world we would live in.
onetakeaway from the heated debate around (benderet al., 2021) is that if one side in an interdisciplinarydebate focuses mostly on the potential beneﬁts ofsomething, and the other mostly on its harms, thestance is likely to become adversarial, and we donot give each other the beneﬁt of the doubt14..nevertheless, the people on both sides of thedebate are researchers, and they want to make in-formed decisions.
that is only possible throughcost-beneﬁt analysis.
it is clear that the ﬁrst stephas to be thorough documentation of the data (ben-der and friedman, 2018; gebru et al., 2020): thislets us compare the represented population and thepopulation of the target users, and think throughthe possible harms.
however, it is not clear how toweigh the harms against the beneﬁts..at the very least, to make informed decisions we.
would probably need to know the following15:.
• which population will get exposed to the pro-.
posed tech?.
• what are the direct and indirect beneﬁts on.
the user population?.
• what are the direct and indirect harms onthe population in general (not limited to theusers of the proposed tech), in particular themarginalized groups?.
• if certain harms are inﬂicted on the user pop-ulation, would they have the political/legalrecourse to be compensated?.
• how compute-efﬁcient the implementationwould be, how would the energy be sourced,and would that affect any other populations?.
14https://twitter.com/nlpnoah/status/.
1354814467633111048.
15many of.
these points are made in the naaclethics faq https://2021.aclweb.org/ethics/ethics-faq/.
• how widely would it be eventually adopted,and how that changes the likelihood of bene-ﬁts and harms to different user groups?.
• what is the potential for further innovationthat would signiﬁcantly change the appeal, de-ployability or risks of the proposed solution?
• what are the risks of human error and delib-erate misuse if the tech is stolen/replicated byterrorists, authoritarian governments, propa-ganda organizations and other bad actors?.
unfortunately, the world is volatile and businessplans change all the time.
there is so much uncer-tainty for each of these points that it is not clearhow to even start.
yet we have to try to come upwith a process for working these things out, andeventually develop templates and calculators thatdevelopers could use to make estimates for best-,worst- and realistic scenarios..this is an area in which nlp is desperately inneed of collaboration with economics, governanceand law.
in that, again, nlp conferences could takethe lead.
there could be regular tracks that wouldincentivize joint publications with experts fromthese ﬁelds.
the search for solutions is alreadygoing on, but this way nlp community would par-ticipate in it rather than just meet with regulationpost-factum.
to be able to provide meaningful peerreview for such work, we would need a mechanismof recruiting external reviewers with the requiredexpertise on as-need basis..6 conclusion.
our data is already changing the world, and willkeep doing so whether we are being intentionalabout it or not.
we might as well at least try: we dowant more robust and linguistically capable models,and we do want models that do not leak sensitivedata or propagate harmful stereotypes..whether.
those goals would be ultimatelyachieved by curating large corpora or by more al-gorithmic solutions, in both cases we need to do alot more data work.
the current dynamic suggeststhat this won’t happen, unless we overcome theinterdisciplinary tensions and turn our conferencesinto truly shared spaces..7 acknowledgements.
many thanks to emily m. bender, yoav goldberg,ryan cotterell, and the anonymous reviewers fortheir thoughtful comments on this paper..2190references.
sahar abdelnabi and mario fritz.
2021. adversarialwatermarking transformer: towards tracing textprovenance with data hiding.
arxiv:2009.03015[cs]..ben ambridge, evan kidd, caroline f. rowland, andanna l. theakston.
2015. the ubiquity of fre-quency effects in ﬁrst language acquisition*.
jour-nal of child language, 42(2):239–273..askell, sandhini agarwal, ariel herbert-voss,gretchen krueger, tom henighan, rewon child,aditya ramesh, daniel m. ziegler, jeffrey wu,clemens winter, christopher hesse, mark chen,eric sigler, mateusz litwin, scott gray, benjaminchess, jack clark, christopher berner, sam mc-candlish, alec radford, ilya sutskever, and darioamodei.
2020. language models are few-shotin advances in neural information pro-learners.
cessing systems 33 (neurips 2020)..yu.d.
apresyan.
1995..izbrannyje trudy, volume 2..yazyki russkoj kultury, moscow..jacob buckman.
2021. fair ml tools require prob-.
lematic ml models.
jacob buckman..jack bandy and nicholas vincent.
2021. address-ing “documentation debt” in machine learning re-search: a retrospective datasheet for bookcorpus.
arxiv:2105.05241 [cs]..rachel bawden.
2019. one paper, nine reviews..rachel bawden’s blog..emily m. bender and batya friedman.
2018. datastatements for natural language processing: to-ward mitigating system bias and enabling betterscience.
transactions of the association for com-putational linguistics, 6:587–604..emily m. bender, timnit gebru, angelina mcmillan-major, and shmargaret shmitchell.
2021. on thedangers of stochastic parrots: can language modelsin proceedings of the 2021 acmbe too big?
conference on fairness, accountability, and trans-parency, facct ’21, page 610–623, new york, ny,usa.
association for computing machinery....emily m. bender and alexander koller.
2020. climb-ing towards nlu: on meaning, form, and under-standing in the age of data.
in proceedings of the58th annual meeting of the association for compu-tational linguistics, pages 5185–5198, online.
as-sociation for computational linguistics..su lin blodgett, solon barocas, hal daumé iii, andhanna wallach.
2020. language (technology) ispower: a critical survey of “bias” in nlp.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5454–5476, online.
association for computational lin-guistics..arielle borovsky, marta kutas, and jeff elman.
2010.learning to use words: event-related potentials in-dex single-shot contextual word learning.
cognition,116(2):289–296..chris brew and dragomir radev, editors.
2005. pro-ceedings of the second acl workshop on effectivetools and methodologies for teaching nlp and cl.
association for computational linguistics, ann ar-bor, michigan..tom b. brown, benjamin mann, nick ryder, melaniesubbiah, jared kaplan, prafulla dhariwal, arvindneelakantan, pranav shyam, girish sastry, amanda.
joan bybee.
2006..the mind’s response to repetition.
82(4):pp.711–733..from usage to grammar:language,.
susan carey and elsa bartlett.
1978. acquiring a sin-gle new word.
technical report, stanford univer-sity, dept.
of linguistics..nicholas carlini, florian tramer, eric wallace,matthew jagielski, ariel herbert-voss, katherinelee, adam roberts, tom brown, dawn song,ulfar erlingsson, alina oprea, and colin raffel.
2020. extracting training data from large lan-guage models.
arxiv:2012.07805 [cs]..noam chomsky.
2014. aspects of the theory of syntax..mit press..jeffrey dastin dave, paresh.
2021. google pledgeschanges to research oversight after internal revolt.
reuters..thomas davidson, debasmita bhattacharya, and ing-mar weber.
2019. racial bias in hate speech andabusive language detection datasets.
in proceed-ings of the third workshop on abusive languageonline, pages 25–35, florence, italy.
associationfor computational linguistics..ivan derzhanski and dragomir radev, editors.
2013.proceedings of the fourth workshop on teachingnlp and cl.
association for computational lin-guistics, soﬁa, bulgaria..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language un-derstanding.
in proceedings of the 2019 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186..holger diessel and martin hilpert.
2016, may 09. fre-quency effects in grammar.
in oxford research en-cyclopedia of linguistics.
oxford university press..jesse dodge, maarten sap, ana marasovic, williamagnew, gabriel ilharco, dirk groeneveld, and mattgardner.
2021. documenting the english colossalclean crawled corpus.
arxiv:2104.08758 [cs]..2191ali emami, kaheer suleman, adam trischler, andjackie chi kit cheung.
2020. an analysis ofdataset overlap on winograd-style tasks.
inproceedings of the 28th international conferenceon computational linguistics, pages 5855–5865,barcelona, spain (online).
international committeeon computational linguistics..allyson ettinger.
2020. what bert is not: lessonsfrom a new suite of psycholinguistic diagnostics forlanguage models.
transactions of the associationfor computational linguistics, 8:34–48..william fedus, barret zoph, and noam shazeer.
2021.switch transformers: scaling to trillion param-eter models with simple and efﬁcient sparsity.
arxiv:2101.03961 [cs]..matt gardner, william merrill,.
jesse dodge,matthew e. peters, alexis ross, sameer singh, andnoah smith.
2021. competency problems: onfinding and removing artifacts in language data.
arxiv:2104.08646 [cs]..timnit gebru, jamie morgenstern, briana vecchione,jennifer wortman vaughan, hanna wallach, haldaumé iii, and kate crawford.
2020. datasheetsfor datasets.
arxiv:1803.09010 [cs]..atticus geiger, ignacio cases, lauri karttunen, andchristopher potts.
2019. posing fair generalizationtasks for natural language inference.
in proceed-ings of the 2019 conference on empirical methodsin natural language processing and the 9th inter-national joint conference on natural language pro-cessing (emnlp-ijcnlp), pages 4475–4485, hongkong, china.
association for computational lin-guistics..mor geva, yoav goldberg, and jonathan berant.
2019.are we modeling the task or the annotator?
an in-vestigation of annotator bias in natural languagein proceedings of theunderstanding datasets.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 1161–1166, hong kong,china.
association for computational linguistics..yoav goldberg.
2021. a criticism of stochastic par-.
rots.
github gist..suchin gururangan, swabha swayamdipta, omerlevy, roy schwartz, samuel bowman, and noah a.smith.
2018. annotation artifacts in natural lan-guage inference data.
in proceedings of the 2018conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 2 (short papers),pages 107–112, new orleans, louisiana.
associa-tion for computational linguistics..a. halevy, p. norvig, and f. pereira.
2009. the un-reasonable effectiveness of data.
ieee intelligentsystems, 24(2):8–12..norbert hornstein and david lightfoot.
1985. ex-planation in linguistics.
the logical problem oflanguage acquisition.
tijdschrift voor filosoﬁe,47(2):338–338..ben hutchinson, vinodkumar prabhakaran, emilydenton, kellie webster, yu zhong, and stephen de-nuyl.
2020. social biases in nlp models as barriersfor persons with disabilities.
in proceedings of the58th annual meeting of the association for compu-tational linguistics, pages 5491–5501, online.
as-sociation for computational linguistics..robin jia and percy liang.
2017. adversarial ex-amples for evaluating reading comprehension sys-in proceedings of the 2017 conference ontems.
empirical methods in natural language processing,pages 2021–2031.
association for computationallinguistics..eun seo jo and timnit gebru.
2020. lessons fromarchives: strategies for collecting sociocultural datain proceedings of the 2020in machine learning.
conference on fairness, accountability, and trans-parency, fat* ’20, pages 306–316, new york, ny,usa.
association for computing machinery..david jurgens, varada kolhatkar, lucy li, margotmieskes, and ted pedersen, editors.
2021. proceed-ings of the fifth workshop on teaching nlp.
asso-ciation for computational linguistics, online..chris knight.
2018. according to chomsky, wordssuch as ’book’ and ’carburetor’ are genetically de-termined.
science and revolution: chris knight’sblog on noam chomsky..geoffrey neil leech.
1992.
100 million words of en-glish: the british national corpus (bnc).
lan-guage research, 1/4..patrick lewis, pontus stenetorp, and sebastian riedel.
2021. question and answer test-train overlapin open-domain question answering datasets.
inproceedings of the 16th conference of the europeanchapter of the association for computational lin-guistics: main volume, pages 1000–1008, online.
association for computational linguistics..elena lieven and michael tomasello.
2008. children’sﬁrst language acquistion from a usage-based per-spective.
in handbook of cognitive linguistics andsecond language acquisition, pages 168–196.
rout-ledge/taylor & francis group, new york, ny, us..tal linzen.
2020. how can we accelerate progresstowards human-like linguistic generalization?
arxiv:2005.00955 [cs]..michael lissack.
2021..the slodderwetenschap.
(sloppy science) of stochastic parrots.
medium..r. thomas mccoy, erin grant, paul smolensky,thomas l. grifﬁths, and tal linzen.
2020. uni-versal linguistic inductive biases via meta-learning.
arxiv:2006.16324 [cs]..2192tom mccoy, ellie pavlick, and tal linzen.
2019.right for the wrong reasons: diagnosing syntacticin pro-heuristics in natural language inference.
ceedings of the 57th annual meeting of the asso-ciation for computational linguistics, pages 3428–3448, florence, italy.
association for computa-tional linguistics..margaret mitchell, simone wu, andrew zaldivar,parker barnes, lucy vasserman, ben hutchinson,elena spitzer, inioluwa deborah raji, and timnitgebru.
2019. model cards for model reporting.
inproceedings of the conference on fairness, account-ability, and transparency, fat* ’19, pages 220–229, new york, ny, usa.
association for comput-ing machinery..martha palmer, chris brew, and fei xia, editors.
2008.proceedings of the third workshop on issues inteaching computational linguistics.
associationfor computational linguistics, columbus, ohio..amandalynne paullada,.
inioluwa deborah raji,emily m. bender, emily denton, and alex hanna.
2020. data and its (dis)contents: a survey ofdataset development and use in machine learningresearch.
arxiv:2012.05345 [cs]..philip.
2020. gpt-3 bot posed as a human on.
askreddit for a week.
kmeme..ashley pilipiszyn.
2021. gpt-3 powers the next gen-.
eration of apps.
openai..dragomir radev and chris brew.
2002. proceedingsof the acl-02 workshop on effective tools andmethodologies for teaching natural language pro-cessing and computational linguistics.
associationfor computational linguistics, philadelphia, penn-sylvania, usa..pranav rajpurkar, jian zhang, konstantin lopyrev, andpercy liang.
2016. squad: 100,000+ questionsin proceed-for machine comprehension of text.
ings of the 2016 conference on empirical methodsin natural language processing, pages 2383–2392.
association for computational linguistics..marco tulio ribeiro, tongshuang wu, carlos guestrin,and sameer singh.
2020. beyond accuracy: be-havioral testing of nlp models with checklist.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4902–4912, online.
association for computational lin-guistics..anna rogers and isabelle augenstein.
2020. what canwe do to improve peer review in nlp?
in findingsof emnlp, pages 1256–1262, online.
associationfor computational linguistics..anna rogers, olga kovaleva, matthew downey, andanna rumshisky.
2020a.
getting closer to ai com-plete question answering: a set of prerequisitereal tasks.
in proceedings of the aaai conferenceon artiﬁcial intelligence, pages 8722–8731..anna rogers, olga kovaleva, and anna rumshisky.
2020b.
a primer in bertology: what we knowabout how bert works.
(accepted to tacl)..nithya sambasivan, erin arnesen, ben hutchinson,tulsee doshi, and vinodkumar prabhakaran.
2021a.
re-imagining algorithmic fairness in india and be-yond.
arxiv:2101.09995 [cs]..nithya sambasivan, shivani kapania, hannah highﬁll,diana akrong, praveen paritosh, and lora m aroyo.
2021b.
"everyone wants to do the model work, notthe data work": data cascades in high-stakes ai.
in proceedings of the 2021 chi conference on hu-man factors in computing systems, chi ’21, pages1–15, new york, ny, usa.
association for comput-ing machinery..timo schick, sahana udupa, and hinrich schütze.
2021. self-diagnosis and self-debiasing: a pro-posal for reducing corpus-based bias in nlp.
arxiv:2103.00453 [cs]..emily sheng, kai-wei chang, premkumar natarajan,and nanyun peng.
2019. the woman worked as ababysitter: on biases in language generation.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 3407–3412, hong kong, china.
association for computa-tional linguistics..chen sun, abhinav shrivastava, saurabh singh, andabhinav gupta.
2017. revisiting unreasonable ef-in pro-fectiveness of data in deep learning era.
ceedings of the ieee international conference oncomputer vision, pages 843–852..tony sun, andrew gaut, shirlyn tang, yuxin huang,mai elsherief, jieyu zhao, diba mirza, elizabethbelding, kai-wei chang, and william yang wang.
2019. mitigating gender bias in natural languagein proceedings ofprocessing: literature review.
the 57th annual meeting of the association for com-putational linguistics, pages 1630–1640, florence,italy.
association for computational linguistics..rich sutton.
2019. the bitter lesson..incomplete.
ideas..suresh venkatasubramanian.
2021. on stochastic par-.
rots.
algorithmic fairness..ashish venugopal, jakob uszkoreit, david talbot,franz och, and juri ganitkevitch.
2011. water-marking the outputs of structured prediction withan application in statistical machine translation.
inproceedings of the 2011 conference on empiricalmethods in natural language processing, pages1363–1372, edinburgh, scotland, uk.
associationfor computational linguistics..eric wallace, shi feng, nikhil kandpal, matt gard-ner, and sameer singh.
2019. universal adversar-inial triggers for attacking and analyzing nlp..2193proceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 2153–2162, hong kong, china.
association for computa-tional linguistics..alex wang, yada pruksachatkun, nikita nangia,amanpreet singh, julian michael, felix hill, omerlevy, and samuel r. bowman.
2019a.
superglue:a stickier benchmark for general-purpose lan-guage understanding systems.
arxiv:1905.00537[cs]..tianlu wang, jieyu zhao, mark yatskar, kai-weichang, and vicente ordonez.
2019b.
balanceddatasets are not enough: estimating and mitigat-ing gender bias in deep image representations.
iniccv 2019..leo weisgerber.
1953. vom weltbild der deutschen.
sprache.
pädagogischer verlag schwann..michael wiegand, josef ruppenhofer, and thomaskleinbauer.
2019. detection of abusive language:the problem of biased datasets.
in proceedings ofthe 2019 conference of the north american chap-ter of the association for computational linguistics:human language technologies, volume 1 (longand short papers), pages 602–608, minneapolis,minnesota.
association for computational linguis-tics..rick zahar, tom cobb, and nina spada.
2001. ac-quiring vocabulary through reading: effects of fre-quency and contextual richness.
canadian modernlanguage review, 57(4):541–572..yian zhang, alex warstadt, haau-sing li, andwhen do yousamuel r. bowman.
2020.need billions of words of pretraining data?
arxiv:2011.04946 [cs]..george kingsley zipf.
1945. the meaning-frequencyrelationship of words.
the journal of general psy-chology, 33(2):251–256..2194