a semantic-based method for unsupervised commonsensequestion answeringyilin niu1∗, fei huang1∗, jiaming liang1, wenkai chen2, xiaoyan zhu1, minlie huang1†1 the coai group, dcst; 1 institute for artiﬁcial intelligence;1 state key lab of intelligent technology and systems;1 beijing national research center for information science and technology;1 tsinghua university, beijing 100084, china.
2 school of computer science and technology,beijing university of posts and telecommunications.
niuyl14@tsinghua.org.cn.
{f-huang,liangjm18}18@mails.tsinghua.edu.cn.
wkchen630@gmail.com.
{zxy-dcs,aihuang}@tsinghua.edu.cn.
abstract.
unsupervised commonsense question answer-ing is appealing since it does not rely on anylabeled task data.
among existing work, apopular solution is to use pre-trained languagemodels to score candidate choices directly con-ditioned on the question or context.
however,such scores from language models can be eas-ily affected by irrelevant factors, such as wordfrequencies, sentence structures, etc.
thesedistracting factors may not only mislead themodel to choose a wrong answer but also makeit oversensitive to lexical perturbations in can-didate answers..in this paper, we present a novel semantic-based question answering method (seqa)for unsupervised commonsense question an-swering.
instead of directly scoring each an-swer choice, our method ﬁrst generates a setof plausible answers with generative models(e.g., gpt-2), and then uses these plausible an-swers to select the correct choice by consider-ing the semantic similarity between each plau-sible answer and each choice.
we devise a sim-ple, yet sound formalism for this idea and ver-ify its effectiveness and robustness with exten-sive experiments.
we evaluate the proposedmethod on four benchmark datasets, and ourmethod achieves the best results in unsuper-vised settings.
moreover, when attacked bytextfooler (jin et al., 2020) with synonym re-placement, seqa demonstrates much less per-formance drops than baselines, thereby indicat-ing stronger robustness..1.introduction.
pre-trained language models have been widely usedfor commonsense question answering.
finetuningpre-trained models on task-speciﬁc data producesmany state-of-the-art results (wang et al., 2020;.
*equal contribution†corresponding author: minlie huang..figure 1: two examples of commonsense question an-swering, where the baseline (pro-a) is oversensitive tolexical perturbations (sr for synonym replacement andst for sentence structure transformation).
the scoresfrom pro-a and our method for each answer choice areshown in the right columns.
the underlined score indi-cates the answer choice selected by a method..khashabi et al., 2020; lin et al., 2019).
however,this requires amounts of labeled task data.
there-fore, it is vital to study unsupervised commonsensequestion answering without relying on any labeleddownstream task data.
in this paper, we investigatemultiple-choice commonsense question answeringtasks in an unsupervised setting: given a questionand a set of answer choices, a model is requiredto predict the most reasonable answer choice forthe question, but without access to any labeled taskdata..many existing unsupervised methods tacklethese tasks by scoring each answer choice usinga language model, e.g., estimating the generativeprobability of the answer choice conditioned onthe question (trinh and le, 2018; shwartz et al.,2020; bosselut and choi, 2019; tamborrino et al.,2020).
table 1 lists several typical score functions.
however, these scores can be easily inﬂuenced byword frequencies, sentence structures, and other.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3037–3049august1–6,2021.©2021associationforcomputationallinguistics3037factors, which can mislead the models and makeexisting methods oversensitive to lexical perturba-tions (abdou et al., 2020; tamborrino et al., 2020).
figure 1 shows two examples.
the correct choicesare paraphrased via synonym replacement or struc-ture transformation.
in these examples, the baseline(pro-a) produces much lower scores for the para-phrased choices and chooses the wrong choices..since existing methods can be easily distractedby irrelevant factors such as lexical perturbations,we argue that a commonsense question answer-ing method should focus on the answers’ se-mantics and assign similar scores to synony-mous choices.
to this end, we introduce anovel semantic-based question answering model,seqa, which aims to robustly select correct an-swers in multi-choice commonsense question an-swering in an unsupervised setting.
instead of di-rectly scoring an answer choice, we calculate theprobability of observing the choice’s semantics.
achoice’s semantic score can be obtained by sum-ming the generative probabilities of sentences thathave the same semantic meanings with the choice,where the sentences are called the choice’s support-ers.
however, it is hard to obtain the supporterswhich have exactly the same semantic meaningswith the choice, so we reformulate the semanticscore into a soft version as explained in section3.2. each supporter is weighed by the semanticsimilarity to the answer choice, which can be com-puted with some off-the-shelf models, such as sen-tencebert (reimers and gurevych, 2019).
sincethe supporters and their weights depend on the se-mantics rather than the surface form of the answerchoice, by this means, the effects of the distract-ing factors can be largely suppressed.
moreover,synonymous choices are likely to share the sameset of supporters, so their scores are expected tobe stably close.
our contributions in this paper aresummarized as follows:.
• we propose a semantic-based question answer-ing model (seqa) for robust commonsensequestion answering in an unsupervised setting.
instead of directly scoring the answer choices,our method ﬁrst generates some plausible an-swers and then uses them to select the correctchoice by considering the semantic similaritybetween each plausible answer and each choice.
• we conduct experiments on four common-sense question answering datasets, whereseqa achieves the best performance com-.
method.
pro-apro-q.
mi-qaseqa (ours) (cid:80).
score function1[plm (a|q)]|a|[plm (q|a)](cid:104) plm (a|q)plm (a)s∈a ω(s|a)plm (s|q).
1|q|(cid:105) 1|a|.
table 1: three existing score functions and our methodfor unsupervised commonsense question answering.
qis the question and a is the choice.
a is the set of allpossible answers and ω(s|a) is a weighting functiondeﬁned in eq.(5).
lm refers to a pre-trained languagemodel, such as gpt-2 or bert1 (devlin et al., 2019)..pared with strong baselines.
when attackedby textfooler (jin et al., 2020) with synonymreplacement, our method performs remarkablymore robustly..2 related work.
previous work has explored pre-trained languagemodels (lms) for unsupervised commonsensequestion answering.
in general, these approachestreat lms as question answering modules..table 1 shows three representative methods,which do not use external knowledge and rely fullyon the implicit knowledge encoded in lms for rea-soning.
probability-a (pro-a) considers the gener-ative probability of the choice conditioned on thequestion.
however, it suffers from the statisticalbias of choices, such as word frequency and sen-tence length (abdou et al., 2020).
to alleviate this,mutualinfo-qa (mi-qa) calculates the mutual in-formation between the question and the choice.
an-other way to reduce the impact of statistical bias isto score each choice using the conditional proba-bility of the question rather than the choice (trinhand le, 2018; tamborrino et al., 2020) , which isdenoted as probability-q (pro-q) in table 1..some recent work claims that external knowl-edge can beneﬁt commonsense reasoning.
besidesstatic knowledge bases (kbs), such as concept-net (speer et al., 2017) and atomic (sap et al.,2019a), there are also numerous studies treatinglms as dynamic kbs.
petroni et al.
(2019) showsthat lms can be used for kb completion.
anddavison et al.
(2019) shows that bert can dis-tinguish true and fake conceptnet triplets.
fur-ther, the extracted knowledge can work as com-plementary information for answering a question.
rajani et al.
(2019) proposes a model for com-.
1pbert (q|a) (cid:44) (cid:81)|q|.
i pbert (qi|q/i, a)..3038monsenseqa (talmor et al., 2019) that generatesexplanations for questions, which are then usedas additional inputs.
the shortcoming of this ap-proach is that it requires collecting human expla-nations for each new dataset to ﬁne-tune lms.
some following researches explore unsupervisedexplanation/knowledge generator.
cga (bosse-lut and choi, 2019) employs comet (bosselutet al., 2019) to generate intermediate inferenceswhich are then used to score the choice.
however,comet is limited by a small set of question typesso that cga is difﬁcult to generalize to different do-mains.
self-talk (shwartz et al., 2020) breaks thelimit by extracting knowledge from gpt-2 (rad-ford et al., 2019), which has no restriction on thequery types.
thus, self-talk can be applied to awide range of domains.
despite the introductionof auxiliary information, these methods are essen-tially dependent on language model scores, so theyare still sensitive to lexical perturbations..besides directly using pre-trained lms, somerecent efforts have been dedicated to automaticallyconstructing task-speciﬁc data to train common-sense reasoners in zero-shot settings.
wang et al.
(2019) and kocijan et al.
(2019) provide some rulesto construct labeled training data from large cor-pus for pronoun disambiguation.
banerjee andbaral (2020), moghimifar et al.
(2020) and maet al.
(2020) collect training data based on knowl-edge bases, such as atomic (sap et al., 2019a).
though effective, they are limited by the speciﬁctask settings or highly dependent on the task-relatedknowledge bases, which makes them difﬁcult totransfer to other commonsense reasoning tasks..3 method.
in this paper, we focus on unsupervised multiple-choice commonsense question answering, which isformalized as follows: given a question and a set ofchoices, models should select the correct choice:.
ˆa = argmax.
s(a|q),.
a.where s refers to a score function.
note that wehave no access to any labeled task data..3.1 motivation.
in existing unsupervised methods, the score func-tions are usually deﬁned based on the languagemodel scores.
taking pro-a (table 1) as an exam-ple, it ﬁrst converts the question into a statement:.
• q: i saw my breath when i exhaled.
what wasthe cause of this?
−→ rewrite: i saw my breathwhen i exhaled because.
and it then takes the statement as a prompt to calcu-late the generative probability of each choice.
notethat the templates for rewriting is not the focus ofthis paper, and hence we directly use the templatesof previous work (shwartz et al., 2020; tamborrinoet al., 2020) for our method and all the baselines inthis paper (see appendix for details)..though successful, language model scores canbe affected by many distracting factors, such asword frequency and sentence structure, etc.
thesefactors can disturb the score functions to a large ex-tent, as shown in figure 1. our goal is to alleviatethe inﬂuence of these distracting factors.
hence wepropose a new method for unsupervised common-sense question answering, which achieves betterresults and performs more robustly..3.2 seqa.
seqa is designed to predict the semantic score ofan answer choice a. instead of directly estimat-ing the probability p (a|q) of the single choicea, the semantic score focuses on the probabilityp (ma|q) where ma represents a’s semantics.
ideally, we decompose p (ma|q) into the sum-mation of the conditional probabilities of a’s sup-porters, where the supporters indicates all possibleanswers that have exactly the same semantics ma.
formally, the semantic score is deﬁned as.
s(a|q) (cid:44) p (ma|q) =.
plm (s|q).
(1).
(cid:88).
s∈sai(s ∈ sa)plm (s|q)..(2).
=.
(cid:88).
s∈a.
sa is the set of supporters of choice a, and a is theset of all possible answers.
i(s ∈ sa) is an indi-cator function indicating whether s is a supporterof a. to obtain the supporter set sa, we adopt amodel to extract the sentence-level semantic fea-tures.
ideally, the indicator function is deﬁned as.
(cid:40).
i(s ∈ sa) =.
1 if cos(hs, ha) = 1,0 if cos(hs, ha) < 1,.
(3).
where ha is the semantic features of sentence a,and we assume that s and a are exactly the same insemantics if hs and ha point in the same direction.
however, eq.
(3) uses a hard constraint thatcos(hs, ha) exactly equals to 1, which can be too.
3039strict to ﬁnd acceptable supporters.
therefore, wereformulate eq.
(2) into a soft version:.
s(a|q) (cid:44) (cid:88)s∈a.
ω(s|a)plm (s|q),.
(4).
where the indicator function in eq.
(2) is replacedby a soft function ω(s|a).
to emulate i(s ∈ sa),ω(s|a) is expected to meet three requirements: (1)ω(s|a) ∈ [0, 1] for any s and a; (2) ω(s|a) = 1if cos(hs, ha) = 1; (3) ω(s|a) increases mono-tonically with cos(hs, ha).
there are several dif-ferent deﬁnitions of ω(s|a) meeting these require-ments, which are explored in section 4.7.3. in thispaper, ω(s|a) is deﬁned as:.
ω(s|a) =.
1z(t ).
exp.
(cid:20) cos(hs, ha)t.(cid:21).
..(5).
t is the temperature, and z(t ) = exp( 1t ) is a nor-malization term that makes ω(a|a) = 1. if t → 0,ω(s|a) degenerates to the indicator function.
ift > 0, ω(s|a) relates to the von mises-fishersdistribution over the unit sphere in the feature space,where the acceptable feature vectors are distributedaround the mean direction ha.
||ha|| ..since it is intractable to enumerate all possibleanswers in a, we convert eq.
(4) to an expectationover plm (s|q):.
s(a|q) = es∼plm (s|q) [ω(s|a)].
1k.k(cid:88).
i=1.
ω(si|a).
≈.
=.
1k · z(t ).
k(cid:88).
i=1.
exp.
(cid:20) cos(hsi , ha)t.(cid:21).
,.
(6).
(7).
where s1, · · · , sk are sentences sampled fromplm (·|q), and k is the sample size.
ha and hsican be extracted from a pre-trained model, e.g.,sentencebert (reimers and gurevych, 2019)..from eq.
(7), we can see the semantic scores(a|q) is only dependent on the semantic featureha and regardless of a’s surface form.
therefore,our method will produce similar semantic scoresfor synonymous choices, assuming that the synony-mous choices have similar semantic features..3.3 the voting view of seqa.
at the beginning of section 3.2, we deﬁne the se-mantic score as the summation of the conditionalprobabilities over the supporters.
however, ineq.
(7), the sampled sentences s1, · · · , sk are nota’s supporters because they may not be semanti-cally similar to a. to address the differences, we.
figure 2: process of seqa in the view of voting.
weuse the same templates with previous work (shwartzet al., 2020; tamborrino et al., 2020) to rewrite inter-rogative sentences into declarative ones.
and then usegpt-2 to generate some plausible answers as voters si,conditioned on the rewritten question.
the choices andvoters are encoded via sentenceroberta to obtain se-mantic features, haj and hsi, which are then used tocalculate the voting weights ω(si|aj).
the choice withthe largest score s(aj|q) is selected as the answer..name the sampled sentences s1, · · · , sk as vot-ers, which are plausible answers to the questionq. in this section, we will show another view ofour method, which works like a procedure that thevoters vote out the correct choice..suppose there are two candidate choices a1and a2, our method is to ﬁnd the correct choiceaccording to the semantic scores, s(a1|q) ands(a2|q).
following eq.
(6), our method can bedecomposed into two steps: first, sample somevoters s1, · · · , sk from plm (·|q).
this step onlyconsiders the question q but no candidate choices.
second, each voter votes for the choices with thesemantic similarity weights.
for example, si votesfor aj with the weight of ω(si|aj).
the candidatechoice that receives more votes will have a highersemantic score and be selected as the ﬁnal answer.
figure 2 shows the process of seqa in the viewof voting.
although the voting view is intuitive, theformalism in section 3.2 provides more insights:(1) our method approximates the probability ofsemantics, which works as the theoretical basis ofseqa.
(2) our method can be seen as an extensionof pro-a (see table 1), since pro-a only calculatesthe language model score for a single sentence,whereas our method calculates the semantic scorefor a set of supporters.
(3) eq.
(4) provides guid-ance, the three requirements mention before, forthe design of the voting weight function ω(s|a).
speciﬁcally, the guidance explains the rationalityof the formulation of eq.(5)..
3040dataset.
copa.
sct.
socialiqa.
cosmosqa.
method.
pre-trainedmodelsgpt-2pro-arobertapro-qmi-qagpt-2self-talk comet+gpt-2gpt-2cgaseqagpt-2+srobertagpt-2pro-arobertapro-qmi-qagpt-2self-talk comet+gpt-2gpt-2cgaseqagpt-2+srobertagpt-2pro-arobertapro-qmi-qagpt-2self-talk comet+gpt-2cometcgaseqagpt-2+srobertagpt-2pro-arobertapro-qmi-qagpt-2self-talk comet+gpt-2gpt-2cgaseqagpt-2+sroberta.
originalaccuracy (↑)73.679.474.668.672.279.472.356.366.170.471.583.246.042.241.247.545.447.536.821.529.336.142.456.1.after-attackaccuracy (↑)4.623.016.28.44.859.04.822.329.24.74.869.416.227.824.612.318.438.21.35.07.41.21.732.6.attacksuccess rate (↓)93.871.078.387.893.425.793.360.355.893.393.216.564.734.240.474.059.419.596.476.674.896.796.041.8.percentage ofperturbed words17.322.919.919.817.121.714.318.116.214.214.318.321.023.225.322.222.323.59.213.712.18.99.613.9.semanticsimilarity0.8830.8280.8650.8550.8860.8270.9170.8720.8850.9150.9160.8560.8760.8430.8660.8720.8670.8390.9270.8590.8860.9280.9240.859.table 2: evaluation results, including the original selection accuracy before attack, the accuracy after attack, theattack success rate, the percentage of perturbed words with respect to the original sentence length in successful at-tacks, and the semantic similarity between the original and paraphrased choices.
gpt-2, roberta and srobertarefer to gpt-2-xlarge, roberta-large (liu et al., 2019) and sentenceroberta-large, respectively..4 experiments.
4.1 datasets.
we conducted experiments on four multiple-choice commonsense question answering tasks,copa (roemmele et al., 2011), storyclozetest(sct) (mostafazadeh et al., 2016), socialiqa (sapet al., 2019b) and cosmosqa (huang et al., 2019).
for each instance, only one choice is correct.
seeappendix for more description about datasets..for copa, we reported the results on its testset.
as the test sets of another three datasets arehidden, for convenience of analysis, we reportedthe experiment results on their development sets..4.2 baselines.
we employed ﬁve strong baselines.
table 1 showsthree of them, pro-a, pro-q and mi-qa.
there isno explicit auxiliary information used in these threemethods, while another two baselines rely on ex-plicit information supplementation.
cga (bosse-lut and choi, 2019) and self-talk (shwartz et al.,2020) query pre-trained language models (e.g.,gpt-2, comet (bosselut et al., 2019)) for rele-vant knowledge, which forms part of contexts.
andthen, similar to pro-a, they take the generativeprobabilities of choices as scores..4.3 experiment settings.
for each method, we tried different pre-trained lan-guage models (see appendix for details), and thenselected the pre-trained lms that maximized the ac-curacy on each dataset.
the details of the selectionof pre-trained lms can be found in table 2..for seqa, we used gpt-2 to generate votersvia nucleus sampling (holtzman et al., 2020) withp = 0.9. the sample size k of voters is set to 500.in section 4.7.2, we show that a small sample sizecan also lead to superior performance.
self-talkand cga also rely on the generated answers fromgpt-2 or comet.
different from seqa, for thesetwo baselines, more generated answers will not al-ways lead to better performance (see section 4.7.2).
thus, we selected the optimal sample size for themrather than the same sample size with seqa..when evaluating seqa on copa, we tuned thetemperature t on its development set, and thenreported the results on the test set with the tunedtemperature t = 0.1. due to the absence of testsets of other datasets, we evaluated seqa on theirdevelopment sets without tuning the temperatureand directly set t = 0.1..4.4 main results.
table 2 shows the evaluation results about accuracyand robustness..30414.4.1 accuracyamong all the methods, seqa achieved the bestperformance on all the datasets.
especially on sctand cosmosqa, seqa outperformed the best base-lines by more than 10 points.
it can be inferred thatthe semantic scores are beneﬁcial for commonsensequestion answering due to the reduction of dis-tracting factors.
pro-q performed better than otherbaselines on copa, perhaps because it sufferedless from the statistic bias of choices (tamborrinoet al., 2020).
however, pro-q lost its superiorityon another three datasets, because it is unsuitablefor processing long or complex contexts..4.4.2 robustnessto test the robustness under the synonym replace-ment attack, we used textfooler (jin et al., 2020)to attack the methods by perturbing the correctchoices of the correctly predicted examples.
thepercentage of perturbed words refers to what per-centage of words in choices are replaced in success-ful attacks.
the semantic similarity is measuredbetween the paraphrased choice and the originalchoice.
considering the attack success rate and theafter-attack accuracy, seqa is much more robustthan all baselines.
to be speciﬁc, the attack successrates on seqa are at least 39 points lower thanthose of pro-a, cga, and self-talk on all datasets.
mi-qa and pro-q are designed to reduce the im-pact of statistic bias in choices, so that they canresist lexical perturbation to some extent.
even so,seqa is remarkably lower than mi-qa and pro-qin terms of attack success rates on all datasets..an observation is that the attack success rateon seqa on cosmosqa is higher than those onthe other datasets.
the reason is that, the contextsin cosmosqa are so complex that gpt-2 is moredifﬁcult to generate high-quality answers.
if thereis a more powerful generator, the robustness ofseqa is expected to have a further improvement..4.5 consistency testing.
we have claimed that a commonsense questionanswering method should assign close scores tosynonymous choices.
to verify that seqa bettermeets this requirement, we conducted consistencytesting for all the methods on four datasets.
foreach example, the consistency testing of a methodis conducted in three steps: (1) originally, the ex-ample has one correct and several wrong answerchoices.
we randomly sample some choices fromother examples as additional wrong choices.
after.
socialiqa cosmosqa.
method / dataset copa sct11.0pro-a8.5pro-q5.8mi-qa9.5self-talk11.0cga3.2seqa.
9.16.97.513.39.74.1.
11.711.611.110.710.95.8.
9.412.37.910.19.54.7.table 3: consistency testing where the methods rank80 choices to ﬁnd 4 correct ones for each example.
themetric is the standard deviation of the ranks of 4 correctsynonymous choices averaged over 500 examples..that, the example will have one correct choice and19 wrong choices.
(2) leverage a commonly usedautomatic translation service, baidu translation, totranslate each choice from english into an interme-diate language, and then back-translate it into en-glish.
during this process, we employ three inter-mediate languages, chinese, spanish, and russian,because the translation quality of these languagesis better than others.
as a result, each choice isaccompanied with three synonymous choices.
(3)use the commonsense question answering methodto calculate the scores for each choice as well as itssynonymous choices, and then sort all the choicesaccording to their scores.
because the scoringscales of these methods are different, we calculatethe standard deviation of the ranks of the correctchoice and its synonymous choices..table 3 shows the average standard deviationof the ranks.
as expected, the average standarddeviation of seqa is much lower than any othermethod on all the datasets, conﬁrming that seqaassigns more similar ranks and closer scores tosynonymous choices.
we also observed that mi-qa provided relatively stable predictions comparedwith other baseline methods.
a possible explana-tion is that, the normalization term plm (a) helpsalleviate the inﬂuence of lexical perturbations..4.6 trends of accuracy with answer length.
answer length is also a type of distracting factorwhich may mislead baseline methods.
to exploreto which extent answer lengths affect the perfor-mance of methods, we divided the development setof cosmosqa into four subsets according to thelength of correct choice.
table 4 shows the resultsof seqa and a robust baseline, mi-qa.
comparedwith mi-qa, seqa has much more stable perfor-mance as answer lengths vary.
the reason is that,seqa focuses on semantic information so that ithas stronger resistance to such distracting factors..3042method.
allmi-qa 29.356.1seqa.
answer length.
[1,5]51.658.6.
[6,10]27.958.0.
[11,15]24.454.1.
[16,20]23.851.2.table 4: the trends of accuracy with answer length forseqa and mi-qa on cosmosqa..t.1010.20.10.05.copa.
sct.
bef75.676.477.079.480.2.aft48.848.852.859.054.6.bef82.082.483.683.280.8.aft64.764.566.369.461.4.socialiqaaftbef35.946.336.146.636.846.938.247.536.546.0.cosmosqaaftbef22.352.722.453.326.154.832.656.128.855.1.table 5: the before-attack (bef) and after-attack (aft)accuracy of seqa with different temperatures..4.7 ablation study.
4.7.1 analysis on temperature.
in the previous experiments, the temperature t ofseqa was set to 0.1 by default.
to investigatethe inﬂuence of t , we varied t in a wide rangefrom 0.05 to 10 and report the results in table 5.considering that the temperature varied greatly,the performance of seqa is relatively stable, in-dicating that seqa is not so sensitive to the selec-tion of t .
another observation is that, althoughthe four datasets are different in domains and textlength, the trends of performance with temperatureon them are relatively similar, illustrating that thetemperature selected on one task can be generalizedto other tasks..4.7.2 analysis on sample size.
figure 3 shows the effect of the sample size k onseqa.
for comparison, figure 3 also includes theresults of baselines in the settings of before- andafter-attack, respectively.
due to the limitation ofspace, the results on the other datasets are shown inappendix.
as expected, the before-attack and after-attack accuracy on sct increased with the samplesize.
in detail, the rapid increase in performanceoccurred when k < 100, and then the improve-ment slowed down when k > 100. finally, seqaachieved a stable and relatively high performance.
cga and self-talk also leverage lms to gen-erate some plausible answers.
different from ourmethod, they use the generated answers to formpart of the question, and then calculate the gener-ative probability of the choice based on the aug-mented question.
we also tried different samplesizes for the two methods, and figure 3 (a) shows.
figure 3: the before-attack (a) and after-attack accu-racy (b) of methods with different sample sizes on sct.
the after-attack accuracy of pro-a, cga and self-talkis below 5.0%, and thus omitted in (b)..f (1) f (cos(hs, ha)).
ω(s|a) = 1f (x) = i(x > α)f (x) = relu(x − β)f (x) = sigmoid( xt )f (x) = exp (cid:0) x.
(cid:1).
t.bef77.277.675.679.4.aft47.245.248.659.0.table 6: the before-attack (bef) and after-attack (aft)accuracy of seqa on the test set of copa with differ-ent deﬁnitions of ω(s|a).
α, β, t1, t2 are hyperparam-eters tuned on the development set of copa..that their accuracy will not stably increase with alarger sample size..4.7.3 analysis on ω(s|a).
ω(s|a) in seqa can be deﬁned in different forms,as long as the three requirements mentioned in sec-tion 3.2 are met.
besides the default deﬁnition, weexplored another three forms of ω(s|a), and theexperiment results on copa are shown in table 6.although the performance varies with ω(s|a), thebefore-attack accuracy of seqa still outperformedmost of the baselines with any deﬁnition of ω(s|a).
moreover, seqa maintains its obvious advantagein after-attack accuracy, which reﬂects the inherentrobustness of seqa..avg.
glovesbert-basesroberta-basesroberta-large.
gpt-2medium large59.672.672.075.2.
56.671.272.474.2.xlarge61.274.875.479.4.table 7: seqa’s accuracy with different feature ex-tractors and language models on copa.
avg.
glovemeans the average pooling of the pre-trained word em-beddings (pennington et al., 2014) over the sentence..3043scoregrammarlogic.
3.
284.8% 12.8% 2.4%40.8% 25.6% 33.6%.
1.table 8: manual evaluation of the quality of voters(generated by gpt-2-xlarge conditioned on questions).
score 3/2/1 correspond to high, middle and low quality,respectively, in terms of grammar and logicality..4.7.4 analysis on pre-trained languagemodel and feature extractor.
seqa has no limit on the selection of the pre-trained language model and the feature extractor.
table 7 shows how the accuracy of seqa on copavaried with the language model and the feature ex-tractor.
as expected, more powerful extractor usu-ally led to higher accuracy under the same settingsof language models.
similar conclusion can be ob-tained for the language model.
it can be inferredthat, if there are more powerful language modelsor feature extractors in the future, the performanceof seqa may be further improved..4.8 analysis on the quality of voters.
while the performance of seqa served as an ex-trinsic evaluation for the quality of the voters (plau-sible answers sampled from plm (·|q), describedin section 3.3), we were also interested in eval-uating it intrinsically.
we sampled 125 votersfrom copa.
for each voter, we provided crowd-sourcing workers with the original question, andasked them: 1) whether the voter is grammati-cal, not entirely grammatical but understandable,or completely not understandable, 2) whether thevoter is a reasonable answer to the question, notreasonable but relevant, or completely irrelevant.
these evaluation tasks comprehensively examinedthe voters in grammar and logicality.
the annota-tion tasks were carried out in amazon mechanicalturk, and we aggregated annotations from 3 work-ers using majority vote..table 8 shows the results of the human evalua-tion of the voters.
score 3/2/1 correspond to thehigh, middle and low quality, respectively.
accord-ing to the grammar scores, 97.6% of the voters aregrammatical or at least understandable, for whichmost of the voters belong to the natural languagespace.
in terms of logicality, 40.8% of the votersare reasonable answers to the questions, which maynot be very satisfying.
however, in section 4.9, wewill show that seqa makes prediction based ona small part of voters, and hence seqa is robust.
figure 4: the cumulative proportion of voters favor-ing the correct answer ac or the wrong answer awon copa.
each point (δ, p) means that p% of voterssatisfy |ω(s|ac) − ω(s|aw )| ≥ δ, where s refers toa voter.
the area between the two curves equals to thedifference of the semantic scores s(ac|q)−s(aw |q)..even though there are some irrelevant voters..4.9 voting weight distribution.
we visualize the cumulative proportion of votersfavoring the correct or the wrong choices (see fig-ure 4).
the curve is averaged over all instances inthe test set of copa, where we sampled 500 votersfor each instance and set t = 0.1..from the curves, we can ﬁnd several prop-erties of voters:(1) the voters favor the cor-rect choices over the wrong choices, where thecurve for correct choices is consistently above thecurve for wrong ones.
the area between twocurves shows the difference of semantic scoress(ac|q) − s(aw |q), which is a large gap com-pared with the area under the bottom curve.
(2)93.5% of voters do not strongly favor any choices(|ω(s|ac) − ω(s|aw )| < 0.05), indicating thatthey are semantically irrelevant to both candidatechoices.
however, table 8 shows that 40.8% ofvoters are logically reasonable, so many voters arereasonable but irrelevant to both answers.
it sug-gests that there can be several reasonable answersfor a single question, and the sampled voters arediverse in the semantics.
(3) although there areonly 5.3% of voters strongly favoring the correctchoices, there are much less voters (1.2%) favoringthe wrong ones.
it explains why our method is ableto predict the correct answer..to help understand the relationship between vot-ers and choices, table 9 provides an instance withvoters and their voting weights to the choices.
weshow four types of voters: favoring the correctchoice, favoring the wrong choice, logically rea-sonable but not favoring either choices, and unrea-sonable and irrelevant to both choices.
we can see.
3044q: the car ran out of gas.
what happened as a result?
ac : the driver was stranded on the road.
((cid:51))aw : the driver picked up a hitchhiker.
((cid:56)).
antoine bosselut and yejin choi.
2019. dynamicknowledge graph construction for zero-shot com-monsense question answering.
corr..ω(si|ac ).
voter.
ω(si|aw ).
0.1610.008.
0.0130.018.i had to park on a dead end road.
we picked up a hitchhiker andshe drove us to the diner.
we stopped at a gas station.
it was time to hit the road again..0.0080.137.
0.0110.010.table 9: an example of voters as well as their votingweights.
ac is the correct choice, while aw is wrong.
si refers to a voter..that the last two types of voters can hardly affect themethod’s prediction, because their voting weightsare much smaller than the ﬁrst two types of voters..5 conclusion.
we present a semantic-based question answeringmethod, seqa, which can answer commonsensequestions more accurately and robustly in an unsu-pervised setting.
instead of directly scoring eachanswer choice, our method focuses on the prob-ability of observing a choice’s semantics.
in theview of voting, seqa ﬁrst generates some plausi-ble answers (voters) and then utilizes them to votefor the correct choice by considering the seman-tic similarity between each choice and each voter.
experiment results show that seqa achieves thebest performance on four datasets, and it is remark-ably more robust than all the baselines when beingattacked by textfooler..acknowledgments.
this work was partly supported by the nsfcprojects (key project with no.
61936010 and reg-ular project with no.
61876096).
this work wasalso supported by the guoqiang institute of ts-inghua university, with grant no.
2019gqg1 and2020gqg0005.
this work was also supported byhuawei noah’s ark lab..references.
mostafa abdou, vinit ravishankar, maria barrett,yonatan belinkov, desmond elliott, and anderssøgaard.
2020. the sensitivity of language modelsand humans to winograd schema perturbations.
inacl, pages 7590–7604..pratyay banerjee and chitta baral.
2020..self-supervised knowledge triplet learning for zero-shotquestion answering.
corr..antoine bosselut, hannah rashkin, maarten sap, chai-tanya malaviya, asli c¸ elikyilmaz, and yejin choi.
2019. comet: commonsense transformers for au-in acl,tomatic knowledge graph construction.
pages 4762–4779..joe davison, joshua feldman, and alexander m. rush.
2019. commonsense knowledge mining from pre-in emnlp-ijcnlp, pages 1173–trained models.
1178..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in naacl-hlt, pages 4171–4186..ari holtzman, jan buys, li du, maxwell forbes, andyejin choi.
2020. the curious case of neural textdegeneration.
in iclr..lifu huang, ronan le bras, chandra bhagavatula, andyejin choi.
2019. cosmos qa: machine readingcomprehension with contextual commonsense rea-soning.
in emnlp, pages 2391–2401..di jin, zhijing jin, joey tianyi zhou, and peterszolovits.
2020. is bert really robust?
a strongbaseline for natural language attack on text classiﬁ-cation and entailment.
in aaai, pages 8018–8025..daniel khashabi, sewon min, tushar khot, ashishsabharwal, oyvind tafjord, peter clark, and han-naneh hajishirzi.
2020. uniﬁedqa: crossing formatin findings,boundaries with a single qa system.
emnlp, pages 1896–1907..vid kocijan, ana-maria cretu, oana-maria camburu,yordan yordanov, and thomas lukasiewicz.
2019.a surprisingly robust trick for the winograd schemachallenge.
in acl, pages 4837–4842..bill yuchen lin, xinyue chen, jamin chen, and xi-ang ren.
2019. kagnet: knowledge-aware graphnetworks for commonsense reasoning.
in emnlp-ijcnlp, pages 2829–2839..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
corr..kaixin ma, filip ilievski, jonathan francis, yonatanbisk, eric nyberg, and alessandro oltramari.
2020.knowledge-driven data construction for zero-shotevaluation in commonsense question answering.
corr..farhad moghimifar, lizhen qu, yue zhuo, mahsabaktashmotlagh, and gholamreza haffari.
2020.cosmo: conditional seq2seq-based mixture modelfor zero-shot commonsense question answering.
incoling, pages 5347–5359..3045nasrin mostafazadeh, nathanael chambers, xiaodonghe, devi parikh, dhruv batra, lucy vanderwende,pushmeet kohli, and james allen.
2016. a cor-pus and cloze evaluation for deeper understandingof commonsense stories.
in naacl..peifeng wang, nanyun peng, filip ilievski, pedro a.szekely, and xiang ren.
2020. connecting the dots:a knowledgeable path generator for commonsensein findings, emnlp, pagesquestion answering.
4129–4140..shuohang wang, sheng zhang, yelong shen, xi-aodong liu, jingjing liu, jianfeng gao, and jingjiang.
2019. unsupervised deep structured seman-tic models for commonsense reasoning.
in naacl-hlt, pages 882–891..jeffrey pennington, richard socher, and christopher d.manning.
2014. glove: global vectors for word rep-resentation.
in emnlp, pages 1532–1543..fabio petroni, tim rockt¨aschel, sebastian riedel,patrick s. h. lewis, anton bakhtin, yuxiang wu,and alexander h. miller.
2019. language modelsin emnlp-ijcnlp, pagesas knowledge bases?
2463–2473..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners..nazneen fatema rajani, bryan mccann, caimingxiong, and richard socher.
2019. explain yourself!
leveraging language models for commonsense rea-soning.
in acl, pages 4932–4942..nils reimers and iryna gurevych.
2019. sentence-bert: sentence embeddings using siamese bert-networks.
in emnlp-ijcnlp, pages 3980–3990..melissa roemmele, cosmin adrian bejan, and an-drew s. gordon.
2011. choice of plausible alterna-tives: an evaluation of commonsense causal reason-ing.
in aaai..maarten sap, ronan le bras, emily allaway, chan-dra bhagavatula, nicholas lourie, hannah rashkin,brendan roof, noah a. smith, and yejin choi.
2019a.
atomic: an atlas of machine commonsensefor if-then reasoning.
in aaai, pages 3027–3035..maarten sap, hannah rashkin, derek chen, ronan lebras, and yejin choi.
2019b.
social iqa: com-monsense reasoning about social interactions.
inemnlp, pages 4462–4472..vered shwartz, peter west, ronan le bras, chandrabhagavatula, and yejin choi.
2020. unsupervisedcommonsense question answering with self-talk.
inemnlp..robyn speer, joshua chin, and catherine havasi.
2017.conceptnet 5.5: an open multilingual graph of gen-eral knowledge.
in aaai, pages 4444–4451..alon talmor, jonathan herzig, nicholas lourie, andjonathan berant.
2019. commonsenseqa: a ques-tion answering challenge targeting commonsenseknowledge.
in naacl-hlt, pages 4149–4158..alexandre tamborrino, nicola pellican`o, baptiste pan-nier, pascal voitot, and louise naudin.
2020. pre-training is (almost) all you need: an applicationin acl, pages 3878–to commonsense reasoning.
3887..trieu h. trinh and quoc v. le.
2018. a simple method.
for commonsense reasoning.
corr..3046datasetnumber of examplesnumber of choicesquestion length (mean, std)choice length (mean, std).
copa-dev5002(7.3, 1.8)(5.1, 1.6).
copa-test5002(7.1, 1.7)(5.0, 1.5).
sct-dev15712(35.3, 6.5)(7.4, 2.5).
socialiqa-dev cosmosqa-dev.
19543(15.3, 4.4)(3.7, 2.3).
27263/4(83.0, 24.5)(10.0, 4.3).
table 10: statistic information of each dataset.
due to the removal of the choice “none of the above”, each instanceof cosmosqa may have 3 or 4 answer choices..a datasets.
the four datasets used in this work are multiple-choice commonsense question answering tasks..copa2 (roemmele et al., 2011) evaluates theability of causal reasoning about a certain event,which is expressed in a simple sentence.
each ques-tion is accompanied with two candidate choices..storyclozetest (sct)3 (mostafazadeh et al.,2016) requires models to select the reasonable storyending, from two alternatives, conditioned on a de-scription about the story context..socialiqa4 (sap et al., 2019b) evaluates the rea-soning ability on social events.
in each example,the question describes a social event and asks mod-els to make some inferences based on the event,such as its cause or effect..cosmosqa5 (huang et al., 2019) is a read-ing comprehension task.
different from the threedatasets above, the examples of cosmosqa havelong and complex contexts.
the original datasetcontains a type of choices “none of the above”to test whether models can identify unanswerablequestions.
this is not the focus of our work, so weremoved such choices..for copa, we reported the results on its testset.
as the test sets of sct, socialiqa and cos-mosqa are hidden, for convenience of analysis,we reported the experiment results on their devel-opment sets.
see table 10 for statistic informationof each dataset..b templates for rewriting questions.
we use the same templates for our method and allthe baselines.
note that the templates for rewritingquestions is not the focus of this paper, and we in-herit the templates from previous work if available..tamborrino et al.
(2020) provides templates forcopa (table 11) and shwartz et al.
(2020) pro-vides templates for socialiqa (table 12).
sincethe instances in sct have no questions, sct doesnot need templates.
there is no related work dis-cussing templates for cosmosqa, so we designsome templates by ourselves (table 13).
sourcecode for rewriting questions and seqa will bemade publicly available..c selection of pre-trained models.
for each method, we tried to adopt different pre-trained models and ﬁnd the pre-trained models thatmaximized the accuracy on the development set ofeach dataset.
table 14 shows the set of candidatepre-trained models for each method, with the se-lected models in bold.
because of the nature of pro-q, it can only use bidirectional language models,so we only evaluated pro-q with roberta-largeand sentenceroberta-large..as shown in table 14, for each method exceptcga, the best selection of pre-trained models isconsistent on all the datasets.
cga achieved itsbest performance with comet on socialiqa andwith gpt2-xlarge on the other datasets..d hyperparameter search.
for seqa, we only tuned the temperature t .
to bemore speciﬁc, we selected t from ﬁve candidatevalues according to the accuracy on the develop-ment set of copa.
table 15 shows that seqa witht = 0.1 achieved the best performance on the de-velopment set of copa.
and then we evaluatedseqa with t = 0.1 on the test set of copa aswell as the development sets of sct, socialiqaand cosmosqa..e analysis on sample size.
2https://people.ict.usc.edu/ gordon/copa.html3https://www.cs.rochester.edu/nlp/rocstories/4https://leaderboard.allenai.org/socialiqa/submissions/get-.
5https://leaderboard.allenai.org/cosmosqa/submissions/get-.
started.
started.
figure 5,6,7 shows the effect of the sample sizek on seqa.
for comparison, these ﬁgures alsoinclude the results of baselines in the settings ofbefore- and after-attack, respectively.
on the over-all trend, the performance of seqa improved as.
3047original questionwhat was the cause of this?
what happened as a result?
original examplei saw my breath when i exhaled.
what wasthe cause of this?
the weather was chilly..rewritebecausesorewritei saw my breath when i exhaled because theweather was chilly..table 11: templates and a rewritten example of copa.
the templates are inherited from tamborrino et al.
(2020)..original questionwhat will [subj] want to do next?
how would [subj] feel as a result?
what will [subj] do next?
how would you describe [subj]?
why did [subj] do that?
what does [subj] need to do before?
original examplesydney went trick or treating and theothers joined him happily.
what willothers want to do next?
get candy.
rewrite 1as a result, [subj] wanted toas a result, [subj] felt[subj] then[subj] is seen asbefore, [subj] wantedbefore, [subj] needed torewrite 1sydney went trick or treating and theothers joined him happily.
as a result,others wanted to get candy..rewrite 2<xwant><xeffect><xreact><xattr><xintent><xneed>rewrite 2sydney went trick or treating and theothers joined him happily.
<xwant>get candy..table 12: some templates and a rewritten example of socialiqa.
[subj] refers to a subject.
there are two groupsof templates, rewrite1 for gpt-2 and rewrite2 for comet (bosselut et al., 2019).
the relations in rewrite2are deﬁned in sap et al.
(2019a) and used for training comet.
these templates are inherited from shwartz et al.
(2020).
more details can be found in shwartz et al.
(2020) and https://github.com/vered1986/self talk..the sample size increased.
another observation isthat a smaller sample size can already make seqaoutperform most baseline methods..figure 6: the before-attack (a) and after-attack accu-racy (b) of methods with different sample sizes on so-cialiqa.
the after-attack accuracy of pro-a, cga andself-talk is below 20.0%, and thus omitted in (b)..figure 5: the before-attack (a) and after-attack ac-curacy (b) of methods with different sample sizes oncopa.
the after-attack accuracy of pro-a, cga andself-talk is below 10.0%, and thus omitted in (b)..figure 7: the before-attack (a) and after-attack accu-racy (b) of methods with different sample sizes on cos-mosqa.
the after-attack accuracy of pro-a, cga andself-talk is below 2.0%, and thus omitted in (b)..3048original questionwhy [sentence] [clause] ?
what [noun] [sentence] [clause] ?
what [sentence] [clause] ?
original example... he was conscious but seemed dazed and prob-ably intoxicated .
nearby there was a youngman dialing his cell phone .
what may hap-pen after the young man makes his call ?
anambulance would likely come to the scene ..rewrite[clause] [sentence] because[clause] the [noun] [sentence] is that[clause] it [sentence] thatrewrite... he was conscious but seemed dazed and prob-ably intoxicated .
nearby there was a youngman dialing his cell phone .
after the youngman makes his call , it may happen that an am-bulance would likely come to the scene ..table 13: templates and a rewritten example of cosmosqa.
[noun], [sentence] and [clause] refer to anoun, a sentence fragment and an adverbial clause, respectively..methodpro-apro-qmi-qa.
self-talk.
cga.
seqa.
set of candidate pre-trained modelslm as qa model: (gpt2-xlarge, comet, roberta-large, sentenceroberta-large)lm as qa model: (roberta-large, sentenceroberta-large)lm as qa model: (gpt2-xlarge, comet, roberta-large, sentenceroberta-large)lm as generator: (gpt2-xlarge, comet)lm as qa model: (gpt2-xlarge, comet, roberta-large, sentenceroberta-large)lm as qa model and generator: (gpt2-xlarge, comet)lm as generator: (gpt2-xlarge, comet)feature extractor: sentenceroberta-large.
table 14: the set of candidate pre-trained models.
the selected pre-trained models for each method are markedin bold.
note that cga achieved its best performance with comet on socialiqa and with gpt2-xlarge on theother datasets..t1010.20.10.05.dev test75.670.076.470.477.071.875.479.480.274.4.table 15: hyperparameter search of seqa.
the tem-perature is selected according to the accuracy on thedevelopment set of copa..3049