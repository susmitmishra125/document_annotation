generating relevant and coherent dialogue responses usingself-separated conditional variational autoencoders.
bin sun1, shaoxiong feng1, yiwei li1, jiamou liu2, kan li1∗1school of computer science & technology, beijing institute of technology2school of computer science, the university of auckland{binsun,shaoxiongfeng,liyiwei,likan}@bit.edu.cnjiamou.liu@auckland.ac.nz.
abstract.
conditional variational autoencoder (cvae)effectively increases the diversity and informa-tiveness of responses in open-ended dialoguegeneration tasks through enriching the contextvector with sampled latent variables.
however,due to the inherent one-to-many and many-to-one phenomena in human dialogues, the sam-pled latent variables may not correctly reﬂectthe contexts’ semantics, leading to irrelevantand incoherent generated responses.
to re-solve this problem, we propose self-separatedconditional variational autoencoder (abbre-viated as sepacvae) that introduces groupinformation to regularize the latent variables,which enhances cvae by improving the re-sponses’ relevance and coherence while main-taining their diversity and informativeness.
sepacvae actively divides the input datainto groups, and then widens the absolutedifference between data pairs from distinctgroups, while narrowing the relative distancebetween data pairs in the same group.
em-pirical results from automatic evaluation anddetailed analysis demonstrate that sepac-vae can signiﬁcantly boost responses in well-established open-domain dialogue datasets..1.introduction.
when conversing with a human user, an open-domain dialogue system is expected to generatehuman-like responses – responses that not only arediverse and informative, but also contain relevantand cohesive information that correctly addressesthe context dialogue.
through using sampled latentvariables, conditional variational autoencoders(cvae) are powerful tools to ensure diversity andinformativeness of the generated responses (bow-man et al., 2016; serban et al., 2017; shen et al.,2017; zhao et al., 2017; chen et al., 2018).
yet,it is challenging for a cvae-based dialogue gen-eration model to keep the responses relevant and.
in this example,.
the semantic relationship of.
figure 1:the latent variables(z1, z2, z3) sampled by a general cvae model don’tinheritthe contexts(c1, c2, c3).
although c1 and c2 have a high similarity,the similarity between z1 and z2 is low.
c2 and c3 havea low similarity, but z2 and z3 have a high similarity..coherent.
the challenge arises as human dialoguesinherently exhibit the one-to-many and many-to-one phenomena (csaky et al., 2019), meaning thatthe same context could lead to very different re-sponses, and different contexts could lead to thesame response, respectively.
as a result, the la-tent variables sampled by cvae often fail to cap-ture the correct contextual semantics, as shown infig.
1, leaving open the possibility that similar con-texts producing drastically different latent variables.
this has two particular drawbacks:.
first, the discrepancy between latent variablescould lead to irrelevant and incoherent generatedresponses.
different latent variables in a continu-ous latent space correspond to different responses(bowman et al., 2016).
as dissimilar latent vari-ables may be sampled for similar contexts, the gen-erated responses for contexts in the test set couldbe drastically different from responses to similarcontexts in the training set.
for instance, given acontext “everything about this movie is awesome!”,a standard cvae may generate response as dis-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5624–5637august1–6,2021.©2021associationforcomputationallinguistics5624c1z1c2z2latent spacelow similaritysemantic spacehigh similarityc1c2z1z2latentspacelowysimilaritysemanticspacehighhihsimilarityc3z3high similaritylow similaritysimilar as“smartphones of the best games!.” and“caves would never say yes, but i’d love to know.”(gao et al., 2019).
thus this approach sacriﬁcestoo much relevance and coherence for diversity andinformativeness..second, the disparity between contexts and la-tent variables hurts model generalizability.
modelgeneralizability is often evaluated using a separatedataset taken from a similar distribution as the train-ing set (e.g., a validation or a noisy version of thetraining set).
high generalizability is indicated ifthe model can transfer favourable abilities from thetraining set to this second dataset, in the sense thatit produces consistent responses between similarcontexts across the two datasets.
this suggests thatthe model has acquired certain semantic relationsbetween sentences from the training set.
however,if the sampled latent variable departs signiﬁcantlyfrom the contextual semantics, the model may per-form quite differently on the second dataset fromthe training set..to address these drawbacks, we propose a novelmodel, namely self-separated conditional vari-ational autoencoder (sepacvae).
sepacvaeproactively partitions the input data into a numberof groups, and then widens the absolute differencesbetween data pairs across different groups whilenarrowing the relative distance between data pairswithin the same group.
in this way, sepacvaeaims to put the contexts that sample similar latentvariables into the same groups, thereby regular-izing the latent variables.
the design of sepac-vaeinvolves three components that are built on topof standard cvae.
first, inspired from image aug-mentation, we propose a dialogue augmentationmethod to partition data without any prior knowl-edge.
for this, we construct n orthogonal vectorsto classify data into n groups, which retain theoriginal semantic relationships of data within agroup.
we directly enlarge the semantic distance ofthe data across different groups.
then, we proposea gradient blocking algorithm to select the mostsuitable group for each data according to gains ob-tained from different groups.
here, the gains areevaluated using reconstruction loss.
finally, in-spired from the contrastive learning paradigm (caiet al., 2020; chen et al., 2020a,b; mitrovic et al.,2020), we propose relationship enhancement toincrease similarity between the representations ofdata within the same group, and differentiate therepresentations of data between different groups..contributions: our ﬁrst contribution is a theoret-ical analysis on why sampled latent variables failto reﬂect the contexts’ semantics.
the next contri-bution lies in the proposal of sepacvae to over-come issues of irrelevant and incoherent responsescaused by standard cvae.
our third contributioninvolves a series of experiments.
the results showthat our sepacvae can generate more relevantand coherent responses compared to existing meth-ods..2 related work.
2.1 dialogue models.
open-domain dialogue generation is a challengingtask in natural language processing.
early dialoguemodels (shang et al., 2015; sordoni et al., 2015b)often tend to generate dull responses.
to improvethe quality of these responses, two pathways havebeen adopted: one is to introduce external seman-tic information, such as dialogue history (sordoniet al., 2015a; serban et al., 2016), topic (xing et al.,2017), sentiment (huber et al., 2018), knowledge(ghazvininejad et al., 2018), persona-style (li et al.,2016c), and other information (li et al., 2016a;wang et al., 2017; baheti et al., 2018; feng et al.,2020b).
the other is through more complex mod-els or frameworks, such as attention mechanisms(bahdanau et al., 2015; luong et al., 2015), rein-forcement learning (rl) (li et al., 2016d; zhanget al., 2018a; liu et al., 2020), generative adver-sarial network (gan) (yu et al., 2017; li et al.,2017a; zhang et al., 2018b; feng et al., 2020a),and variational reasoning (bowman et al., 2016;serban et al., 2017; shen et al., 2017; zhao et al.,2017; chen et al., 2018)..cvae models are conversational models thatare based on variational reasoning.
many existingcvae models have achieved state-of-the-art per-formance by generating diverse and informativeresponses.
moreover, as opposed to methods thatintroduce external semantic information, cvaemodels use latent variables to represent such in-formation.
hence they can be applied when exter-nal information is not available.
comparing withthe models based on rl or gan, cvae modelsare simpler and can be easily trained.
in addition,cvae models can be enhanced by methods thatuse rl or gan as generators to further improvetheir performances..however, empirical evidences (gao et al., 2019;gu et al., 2019) have indicated that while the use of.
5625latent variables may make the generated responsesmore diverse and informative, it could also reducerelevance and coherence.
to alleviate this apparentissue, cvae models have been used in combina-tion with external information such as persona in-formation, dialogue history and dialogue act (shenet al., 2017; serban et al., 2017; zhao et al., 2017).
however, simply borrowing external informationis not sufﬁcient to resolve the one-to-many issue,especially when the amount of data is very large.
no existing model resolves the core issue of theproblem, that is, the latent variable inherits littlesemantic information from the context sentence,a consequence of the inherent one-to-many andmany-to-one phenomena of human conversations.
to address this issue, we propose the sepacvaemodel which trains latent variables that inherit con-textual semantics..2.2 self-supervised method used in dialogue.
generation task.
recently, self-supervised methods such as con-trastive learning – popularized in computer vision(chen et al., 2020a,b) – are drawing increasing at-tention in nlp (wu et al., 2019; clark et al., 2020;cai et al., 2020).
generally speaking, the majorissue with applying contrastive learning is how pos-itive and negative examples are constructed.
manyexisting work explore ways to design reasonablepairs of positive and negative examples to accu-rately capture the semantic relations of these pairs,so that the obtained representation can be better-used on downstream tasks..3 problem formulation.
the problem with the standard cvae model lies inthat the sampled latent variables may not accuratelyreﬂect the contextual semantics due to the apparentone-to-many (one context may correspond to manyresponses) and many-to-one (many contexts mayalso correspond to one response) phenomena.
thisleads to irrelevant and incoherent responses, andharms model generalizability.
our aim is to adaptsampled latent variables to capture the contextualsemantics, so that the effects of these phenomenaare neutralized.
this will in turn be helpful to gener-ate relevant and coherent responses.
with this goal,we focus on single-turn dialogue datasets wherethe one-to-many situations appear more frequentlythan multi-turn dialogue datasets..3.1 preconditions.
this section formally analyzes the many-to-one andone-to-many phenomena and we present severalimportant assumptions and contextual information(i.e., preconditions) for the cvae model.
notations: θ and φ are parameters of cvae’srecognition network and prior network, respec-tively; c represents the condition information, xand r represent the generation target, and z repre-sents the latent variable.
precondition 1: bowman et al.
(2016) conﬁrmedthat the latent space is continuous; the latent vari-able z is highly correlated with the target data x,meaning that different z will reconstruct differentx.precondition 2: cvae has a recognition networkqφ(z|c, x) and a prior network pθ(z|c) to approx-imate the true posterior distribution p(z|c, x) andprior distribution p(z|c), respectively.
these distri-butions are assumed to follow the gaussian distri-bution, e.g., qφ(z|c, x) ∼ n (µ, σ2).
precondition 3: to efﬁciently train a cvaemodel, the stochastic gradient variational bayes(sgvb) framework (sohn et al., 2015; yan et al.,2016; kingma and welling, 2014) is adopted whichaims to maximize the variational lower bound ofthe conditional log likelihood:.
l(θ, φ; c, x) = −kl(qφ(z|c, x)||pθ(z|c)).
+ eqφ(z|c,x) [log p(x|z, c)].
(1).
where kl represents kullback–leibler divergence.
during training, the σ of q(z|x, c) will get smallerand smaller, and the µ of q(z|x, c) will get closerand closer to z that corresponding to x, which aimsto stabilize the eqφ(z|x,c) [log p(x|z, c)] and makeit converge..3.2 demonstrating the existence of the.
problem.
we use fig.
2 to illustrate the impact of one-to-many phenomenon and many-to-one phenomenonon a trained standard cvae model.
consider thesituation in fig.
2(a) where the context c1 has twodifferent responses r1 and r2.
by precondition 2,we assume two approximate posterior distributionsp(z|c1, r1) ∼ n (µ1, σ21), p(z|c1, r2) ∼ n (µ2, σ22)and one approximate prior distribution p(z|c1) ∼n (µ, σ2).
by precondition 3, during training,µ1 and µ2 will get closer to the latent variablesthat could be reconstructed to r1 and r2, respec-tively.
by precondition 1, as r1 is different from.
5626problem caused by the one-to-many phenomenain fig.
2(a): after training, the prior conditionalprobability p(z|c1) ∼ n (µ∗, σ∗2), which will beif the difference between r1used in inference.
and r2 widens, the difference between µ1 and µ2will also widen and µ∗ will become further awayfrom µ1 and µ2.
during inference, the latent vari-ables sampled from p(z|c1) have a high probabilityto differ from those sampled from p(z|c1, r1) andp(z|c1, r2).
these latent variables will introduceirrelevant information and contribute to the gener-ation of irrelevant responses.
in addition, as oneresponse r1 may correspond to different contexts c1and c2, as shown in fig.
2(b), p(z|c1) and p(z|c2)tend to be the same, which contributes to the phe-nomenon that different context could sample sim-ilar latent variables.
in a word, similar contextscould correspond to different latent variables anddifferent contexts could correspond to similar latentvariables, which explains why the latent variablescan not accurately reﬂect the contexts’ semantics..4 method.
in this section, we introduce in detail the proposedsepacvae model and its three key components,dialogue augmentation, gradient blocking, and re-lationship enhancement..4.1 self-separated cvae.
figure 3: trend of the change of the probability distri-butions of latent variables of sepacvae during train-ing..as shown in fig.
3, sepacvae uses g(·) toseparate the contexts into different groups.
forthe one-to-many phenomenon, the contexts in dif-ferent groups will have different prior distributionsp(z|g∗(·)), which is easily affected by the differentposterior distributions.
as for the many-to-one phe-nomenon, sepacvae makes the contexts (c1, c2)generate latent variables related to the responser1 only when it contains group information g1(·).
the other group would help the contexts to alignwith the other latent variables..figure 2: the change to the probability distributions ofthe latent variables of a standard cvae during train-(a) one-to-many phenomenon: since a contexting.
may correspond to two different possible responsesr1 and r2, the posterior distributions p(z|c1, r1) andp(z|c1, r2) are also different.
this jeopardizes the re-quirement of the standard cvae that these posteriordistributions should be similar to the prior distributionp(z|c1).
therefore, the sampled latent variables fromp(z|c1) may lead to irrelevant and incoherent responses(b) many-and harm the generalization performance.
to-one phenomenon: since two different contexts c1and c2 may have the same response r1, the two priordistributions p(z|c1) and p(z|c2) have two correspond-ing posterior distributions p(z|c1, r1) and p(z|c2, r1).
since the latent variable z is mainly corresponding toresponse r, p(z|c1, r1) and p(z|c2, r1) can be assumedas the same, i.e., p(z|∗, r1).
therefore, the prior distri-butions p(z|c1) and p(z|c2) also tend to be the same..r2, µ1 should also be different from µ2.
otherwise,the latent variables sampled from p(z|c1, r1) andp(z|c1, r2) tend to be the same, making these latentvariables irrelevant to the responses.
this leadsto the vanishing latent variable problem (bowmanet al., 2016).
therefore, µ1 and µ2 cannot be thesame, and their discrepancy can be considered sta-ble; only in this way we can ensure one-to-onecorrespondence between latent variables and re-sponses.
from precondition 3, it is easy to see thatp(z|c) is only affected by p(z|c, r).
hence, we ig-nore e∗ [·] in eq.
(1) and use kl(p(z|c, r)||p(z|c))to analyze the trend of p(z|c) during training.
considering fig.
2(a) where kl(·) of (c1, r1)and (c1, r2) equals to kl(p(z|c1, r1)||p(z|c1)) +kl(p(z|c1, r2)||p(z|c1)).
we provide details ofthe computation in appendix a. the formula-+tion can then be simpliﬁed as:σ21+σ2− 1.hence, we can compute µ∗ and σ∗ that mini-.
2+(µ1−µ)2+(µ2−µ)2.
(cid:16) σ2σ1σ2.
log.
2σ2.
(cid:17).
mizes the above using lagrange multiplier:.
µ∗ = (µ1 + µ2)/2.
(cid:113).
σ∗ =.
(σ2.
1 + σ2.
2)/2 + (µ1 − µ2)2/4..the derivation above provides insights on the.
5627p(z|c1,r1)p(z|c1,r2)p(z|c1)p(z|c((1,r1)p(z|c((1,r2r)p(z|c((1)latent variable z(a)one-to-manyp(z|c1)p(z|c2)p(z|*,r1)p(z|c((1)p(z|c((2)p(z|*((,r1)latent variable z(b)many-to-oneprobabilityprobabilityp(z|c1,r1)p(z|c1,r2)p(z|g1(c1))p(z|c((1,r1)p(z|c((1,r2r))p(z|g((1(c1))latent variable zp(z|g2(c1))(a)one-to-manyp(z|*,r1)p(z|*,r2)p(z|g1(*))latent variable zp(z|g2(*))(b)many-to-onep(z|*,r((1)p(z|*((,r2r))p(z|((g1(*))p(z|g((2(*))probabilityprobability4.2 dialogue augmentation.
in sepacvae, we ﬁrst propose dialogue augmen-tation (see algorithm 1), which designs a groupof orthogonal vectors (y1, y2, .
.
.
, yn ) to separatethe contexts into different groups.
these vectors(y1, y2, .
.
.
, yn ) are called group information..algorithm 1 dialogue augmentationinput: cori.
1×m : the vector representation of orig-inal context sentence after word embeddingprocess;n : the hyper-parameter;m : the dimension of word embedding;.
output: cext.
n ×m : vector representations of con-.
text sentences after augmentation;y extn ×1 : the labels of the augmented contexts;.
augment.
n ×m and y ext.
1: initialize cextn ×1;2: set d ← the integer of m/n ;3: for i = 1 to n doinitialize4:(0, 0, .
.
.
, 0)1×m;set yi((i − 1) × d + 1 :(1, 1, .
.
.
, 1)1×d;cextn ×m(i, :) ← coriy extn ×1(i) ← i;7:8: end for9: return cext.
1×m + yi;.
n ×m, y extn ×1.
5:.
6:.
vector.
yi.
←.
i × d) ←.
in sepacvae, we apply algorithm 1 to extendeach dialogue pair (ci, ri) to [(ci + y1, ri), (ci +y2, ri), .
.
.
, (ci + yn , ri)] before feeding them tostart training.
if different contexts ci, cj, .
.
.
havethe same yi added, then these contexts belong tothe same group.
in this way, all contexts will keepa certain relationship within the same group.
inthis work, the value n is set to 8. since we usec + y to replace the original c, the variational lowerbound of sepacvae is re-written as:.
l(θ, φ;r, c, y) = eqφ(z|r,c+y)[log p(r|z, c + y)]− kl(qφ(z|r, c + y)||pθ(z|c + y)) (2).
4.3 gradient blocking.
before the gradient back-propagation, we pro-pose gradient blocking (see algorithm 2 in ap-pendix b for implementation details) to ﬁlter thegradients.
since we extend the dialogue pair (c, r)to [(c + y1, r), (c + y2, r), .
.
.
, (c + yn , r)], if weoptimize the model through all calculated gradients,y1, y2, .
.
.
, yn would be regarded as noise.
there-fore, we choose the largest variational lower bound.
that is calculated through the dialogue pair (c, r)with the positive group information y+, which canbe represented as (3):.
l(θ, φ; r, c, y+) = maxθ,φ,yi∈y.
l(θ, φ; r, c, yi).
(3).
for each [(c + y1, r), (c + y2, r), .
.
.
, (c + yn , r)],we only pass l(·, y+) to optimize the model..4.4 relationship enhancement.
through dialogue augmentation and gradientblocking, the positive y+ for each dialogue pair(c, r) is captured.
we then propose relationshipenhancement, which is inspired from contrastivelearning, to adjust the separated results.
those re-sponses under the same y+ are considered to be inthe same group, and thus can be seen as positivesamples; similarly, those responses under differ-ent y+ are seen as negative samples.
from theperspective of contrastive learning, we design arelationship-enhancement-loss named lre to helpour model achieve the representation learning:.
lre =.
− log.
(cid:80)p os.
j=1 f (x.
(cid:48)i)t f (x.
(cid:48)+j ).
e.(cid:80)p ose.j=1 f (x(cid:48).
i)t f (x.
(cid:48)+j ) + e.(cid:80)n eg.
m=1 f (x.
(cid:48)in −1.
)t f (x.
(cid:48)−m ).
(4).
,.
where x(cid:48)represents the embedded generated re-sponse, f (·) represents our model’ encoder, p osmeans the number of positive samples, and n egmeans the number of negative samples..in addition, we introduce an mlp to predict y+based on vector representation of the generatedresponse f (x(cid:48)).
we therefore deﬁne ly :.
ly = epψ(x|z,c+y+).
(cid:104)log(p(y+|x.
(cid:48).
(cid:105))).
(5).
overall, sepacvae is trained by maximizing:.
lall = l(θ, φ; r, c, y+) − α ∗ lre − ly.
(6).
quoting the kl annealing trick (bowman et al.,2016), α increases linearly from 0 to 1 in the ﬁrst10,000 batches..5 experiments.
5.1 dataset.
we use two public dialogue datasets in our experi-ments, and change them as single-turn dialog data.
the ﬁrst dataset, named dailydialog (li et al.,2017b), consists of dialogues that resemble human.
5628dataset name vocab traindailydialogopensubtitles 87,840 5m.
valid test10,064 18,406 2,008 988100k 50k.
table 1: statistics for dailydialog and opensubtitlesdatasets..daily communication.
the second dataset, namedopensubtitles (tiedemann, 2009), includes a largecollection of conversations converted from movietranscripts in english..5.2 data pre-processing.
in this work, we extract single-turn dialogues fromtwo dialogue datasets, dailydialog and opensub-titles.
from a multi-turn dialogue (u1, u2, ..., ut ),we can extract t − 1 single-turn dialogues[(u1, u2), (u2, u3), ..., (ut −1, ut )], where u repre-sents an utterance.
as discussed above, comparedwith multi-turn dialogue dataset the single-turn dia-logue dataset contains a more serious one-to-manyproblem.
therefore, using the single-turn dialoguedataset for experimentations can highlight the prob-lem of general cvae model and reﬂect the effectof our method..we utilize 300-dimensional glove embeddings(pennington et al., 2014) to represent these dia-logues in vectors.
since the tokens in glove donot cover all tokens in dailydialog and opensub-titles datasets, we extract the token-list of gloveto ﬁlter these datasets.
table 1 lists key statisticsof the dataset after processing.
in addition, wecount the one-to-many samples of both datasetsand found that 408 contexts in dailydialog and90,149 contexts in opensubtitles have multiple re-sponses.
in particular, a context in opensubtitleshas a maximum of 623 responses, while a contextin dailydialog has a maximum of 29 responses,which shows that the one-to-many phenomenon ismore prevalent in opensubtitles dataset..5.3 automatic evaluation metrics.
we use ppl (neubig, 2017), response length anddistinct-n (li et al., 2016b) to evaluate the diver-sity of generated responses.
we also use bleu(papineni et al., 2002) to evaluate the degree ofthe word-overlap between generated responses andground truth.
moreover, we use embedding av-erage (average) (liu et al., 2016)) to evaluate thesemantic relationship of generated responses andground-truth responses.
finally, we introduce the.
coherence (xu et al., 2018b) to assess the coher-ence between contexts and generated responses..5.4 human evaluation.
we conduct human evaluation to further evaluateour model and baseline models.
following thework of li et al.
(2017a); xu et al.
(2018a), we ran-domly extract 200 samples from the test sets of thetwo dialogue datasets, respectively.
each samplecontains one context and the response generated bydifferent models.
three annotators are invited torank the generated responses with respect to threeaspects: diversity, relevance and ﬂuency.
ties areallowed.
diversity indicates how much the gener-ated response provides speciﬁc information, ratherthan generic and repeated information.
relevancemeans how likely the generated response is rele-vant to the context.
fluency speciﬁes how likelythe generated response is produced by human..5.5 baseline models.
our baseline models include sequence-to-sequence(seq2seq) model, cvae model, and cluster-cvaemodel.
they are all implemented based on a 2-layer gru kgcvae model (zhao et al., 2017).
the cluster-cvae model represents that kgcvaeutilize the cluster results as the knowledge.
weemploy three cluster methods, i.e.
k-means(k),spectral(s), agglomerative(a)..5.6 training details.
for a fair comparison among all models, we uti-lized 300-dimensional glove embeddings as theword embedding matrix.
the numbers of hiddennodes are all set to 300. the parameter max lenis set to 25. we set the batch sizes to 64 and 32 fordailydialog and opensubtitles datasets, respec-tively.
adam is utilized for optimization.
theparameter init lr is set to 0.001. we train all mod-els in 50 epochs on a rtx 2080ti gpu card withtensorﬂow, and save the generated responses whenthe ppl reaching minimum.
greedy search is usedto generate responses for evaluation..6 results and discussion.
6.1 automatic evaluation results.
table 2 and table 3 report the automatic evalua-tion results of sepacvae and baseline modelson validation and test data of both two datasets,respectively.
for the validation stage, we ﬁrst se-lect and save the positive group information (y+).
5629bleu-1 average.
distinct-1 distinct-2.
pplcoherencelengthmode42.9±.18 0.033±.01 0.119±.02 9.1±.22 0.386±.00 0.858±.00 0.763±.00seq2seq13.3±.09 0.074±.00 0.407±.01 11.3±.33 0.405±.01 0.853±.00 0.763±.00cvaecvae+bow 13.0±.30 0.078±.00 0.415±.01 11.4±.21 0.402±.01 0.855±.00 0.762±.00k-cvae+bow 13.1±.11 0.074±.00 0.406±.01 11.5±.14 0.424±.00 0.868±.00 0.766±.00s-cvae+bow 12.9±.12 0.075±.00 0.414±.01 11.5±.17 0.426±.01 0.867±.00 0.765±.00a-cvae+bow 13.0±.22 0.076±.00 0.418±.02 11.6±.11 0.418±.00 0.863±.00 0.765±.000.078±.00 0.504±.01 11.5±.10 0.461±.00 0.862±.00 0.767±.009.8±.17sepacvae45.9±.13 0.002±.00 0.010±.00 11.8±.81 0.236±.04 0.465±.08 0.281±.05seq2seqcvae+bow 12.2±.17 0.005±.00 0.095±.00 13.1±.26 0.172±.02 0.285±.04 0.195±.03k-cvae+bow 12.1±.20 0.006±.00 0.098±.00 13.1±.10 0.203±.02 0.311±.06 0.200±.050.016±.00 0.282±.01 12.6±.11 0.417±.00 0.836±.01 0.707±.01sepacvae.
2.0±.06.
table 2: metrics results on validation data of dailydialog (up) and opensubtitles (down).
the best score in eachcolumn is in bold.
note that our bleu-1 scores are normalized to [0, 1]..length.
bleu-3 average.
coherencebleu-2distinct-1 distinct-2mode0.054±.01 0.180±.03 9.0±.32 0.300±.01 0.247±.00 0.856±.00 0.756±.01seq2seq0.106±.00 0.499±.01 11.3±.25 0.324±.01 0.272±.01 0.854±.00 0.756±.00cvaecvae+bow 0.114±.00 0.514±.01 11.2±.13 0.326±.01 0.274±.01 0.856±.00 0.755±.00k-cvae+bow 0.108±.00 0.501±.02 11.6±.16 0.342±.01 0.287±.00 0.869±.00 0.759±.00s-cvae+bow 0.110±.00 0.511±.01 11.4±.19 0.339±.00 0.284±.00 0.867±.00 0.758±.00a-cvae+bow 0.111±.01 0.509±.02 11.5±.16 0.331±.00 0.278±.00 0.862±.00 0.757±.000.082±.00 0.471±.01 17.9±.57 0.409±.01 0.350±.01 0.877±.00 0.809±.00sepacvae0.003±.00 0.015±.00 11.8±.82 0.193±.03 0.163±.03 0.465±.08 0.281±.05seq2seqcvae+bow 0.009±.00 0.131±.00 13.1±.24 0.144±.02 0.123±.02 0.285±.04 0.195±.03k-cvae+bow 0.010±.00 0.135±.00 13.1±.10 0.169±.02 0.144±.01 0.308±.06 0.198±.050.025±.00 0.330±.03 13.5±.58 0.326±.01 0.276±.01 0.807±.02 0.677±.01sepacvae.
table 3: mterics results on test data of dailydialog (up) and opensubtitles (down).
the best score in each columnis in bold.
note that our bleu-2,3 scores are normalized to [0, 1]..for each context, and then generate responses un-der this y+.
for the test data where no groundtruth response is available to select the positivegroup information, we ﬁrst generate n responsesfor each context through n group information, andthen choose the most possible generated responsethrough calculating the cosine score between thegenerated responses and context.
both generatedresponses and contexts are input into sepacvae’sencoder to obtain the vector representations..spectral and agglomerative cluster methodswould not work well under the large-scale dataset(i.e.
opensubtitles), and the general cvaemodel suffers from the vanishing latent variableproblem while training on such dataset.
there-fore, we remove the results of s-cvae+bow, a-cvae+bow and cvae on table 2 and table 3..as shown in table 2 and table 3, the resultson large-scale dataset (opensubtitles) are better.
than that on small dataset (dailydialog), that is,the results on opensubtitles show an obvious pat-tern that veriﬁes our hypothesis.
on both valida-tion and test data of opensubtitles, cvae and k-cvae achieve better performance on diversity met-ric (distinct) but worse performance on relevantmetrics (i.e.
bleu, average and coherence) thanseq2seq model.
moreover, our proposed sepac-vae outperforms all baseline models in terms of allmetrics with statistical signiﬁcance.
however, theresults obtained on the dailydialog dataset do notshow a clear pattern.
for dailydialog’s validationdata, sepacvae achieves good performance ondiversity but on relevance the results is unimpres-sive.
on the other hand, for test data, sepacvaeachieves good performance on relevance but gener-ally poor results on diversity.
we believe that thereason for this phenomenon is related to the level ofprevalence of the one-to-many phenomenon in the.
5630modelseq2seqcvae+bowk-cvae+bowsepacvaeground-truthseq2seqcvae+bowk-cvae+bowsepacvaeground-truth.
diversity3.643.163.272.111.883.122.692.592.572.49.relevance3.123.583.712.951.023.112.983.532.361.12.ﬂuency2.163.423.493.491.003.243.053.722.251.02.table 4: human evaluation results on test data of daily-dialog (up) and opensubtitles (down).
the best scorein each column is in bold.
note that “ground-truth” isthe true response..dataset.
for instance, only 66,260 contexts havemultiple responses among the 90,149 contexts onthe opensubtitles that was added the cluster re-sults.
moreover, one context has a maximum of296 responses, which amounts to almost half of623. since the dailydialog dataset is very smalland contains few samples that we focus on, whichcause the not speciﬁc tendency on its results.
ina word, the evaluation results illustrate the effec-tiveness of sepacvae in terms of improving therelevance and coherence of responses..6.2 human evaluation results.
the results of the human evaluation are shown intable 4. to evaluate the consistency of the rankingresults assessed by three annotators, we use pear-son’s correlation coefﬁcient.
this coefﬁcient is0.22 on diversity, 0.63 on relevance, and 0.70 onﬂuency, with p < 0.0001 and below 0.001, whichindicates high correlation and agreement.
similarlywith the automatic evaluation results in table 3,this result shows that our sepacvae signiﬁcantlyoutperforms baselines in term of relevance and di-versity.
except the ground-truth responses, oursepacvae achieve the best scores of relevanceand diversity metrics.
the ﬂuency result of sepa-cvae on the dailydialog dataset is slightly worsethan that of baselines, which is mainly due to thelength of responses generated by sepacvae isalmost two times than that of baselines (see ta-ble 3).
when the response lengths are similar onthe opensubtitles dataset, sepacvae could alsoachieve the best ﬂuency score..6.3 effectiveness analysis.
we further analyze the effectiveness of sepacvaeon regularizing latent variables.
for the contexts.
figure 4: the average inner-class distance and the av-erage inter-class distance of the jointly vectors.
..t-sne visualization of the posterior z forfigure 5:validation responses with 8 group information that ob-tained though sepacvae or cluster methods..in the validation data of dailydialog dataset, wecollect their generated responses and the sampledlatent variables of both sepacvae and baselinemodels on the ﬁrst 2,500 batches.
then we cal-culate the average inner-group distance and theaverage inter-group distance for each context basedon jointly vector representations (concatenatingthe context vector and the latent variable).
alldistances are calculated by cosine scores, and thehigher the distance, the greater the similarity..for each context, sepacvae outputs a positivegroup information y+, which is used to distinguishwhether other contexts are in the same group.
asfor the standard cvae, we set a threshold of the co-sine score to replace the group information.
in thiswork, the threshold is set to 0.9. finally, we takethe average of all contexts’ inner-group distanceresults and inter-group distance results as inner-dis.
and inter-dis.
of each batch, which are shown infig.
4. sepacvae achieves signiﬁcantly higher.
563105001000150020002500batch0.00.10.20.30.40.50.60.70.8cosine scoreinner-dis of (context+latent virables)baselineseparacvae05001000150020002500batch0.00.10.20.30.40.50.60.70.8cosine scoreinter-dis of (context+latent virables)baselineseparacvae402002040402002040kmeans-cvae01234567402002040402002040spectral-cvae0234567402002040402002040agglomerative-cvae01234567402002040402002040separacvae01234567inner-dis.
than baseline (standard cvae) model,while the inter-dis.
are similar.
meanwhile, ourmethod also gets the similar average distance of alljointly vectors with the standard cvae..in addition, past studies conjecture that the poste-rior z sampled from the recognition network shouldcluster the responses into meaningful groups thatcorrelate with the knowledge.
fig.
5 visualizesthe posterior z of responses in the validation dataof dailydialog dataset in 2d space using t-sne(van der maaten and hinton, 2008).
we found thatthe learned latent space of our sepacvae is morecorrelated with the group information.
these re-sults demonstrate that sepacvae can effectivelyregularize latent variables..6.4 case study.
we collected the generated responses of contextsin validation and test set, which are similar to thetraining set, and showed a sample in table 4. thecontext in training set has two contradictory re-sponses.
as we analyzed, the standard cvae andcvae+bow generated irrelevant and incoherentresponse for the similar context in validation andtest set.
in contrast, our sepacvae outputted sure,it will be happy and sure.
i go with my parents aremore relevant and coherent than the response gen-erated by baselines, and it also similar with the trueresponse 1 (oh, that sounds great!
), which meansthe sepacvae is able to handle the one-to-manysituation..7 conclusion.
in this paper, we theoretically prove that latentvariables hardly reﬂect the semantics of contextsdue to the one-to-many and many-to-one phenom-ena of dialogues.
for the standard cvae model,these issues lead to irrelevant and incoherent re-sponses during the validation or test stage, and alsodamaging the generalization performance.
to ad-dress these problems, we proposed the sepacvaemodel.
there are three main technical noveltiesof sepacvae: dialogue augmentation, gradientblocking, and relationship enhancement, which en-able the latent variables to reﬂect semantic rela-tionships between contexts.
as demonstrated inthe experimental results, sepacvae could get thebest performance for large-scale dataset..true response 1true response 2.similar context.
samples in training datasetcontext would you like to have dinnerwith me tonight?
oh, that sounds great!
sorry, i have to work over-time.
sample in validation dataseti would always be ready to goshopping with you!
shouldwe talk about other basics?
sure.
we will go to themovies..cvae i’m not interested in your arenot a good thing!.
seq2seq.
cvae+bow it will smell and better if.
whatever, whatever..sepacvae sure, it will be happy, mary,.
similar context me, too..most music is well.
sample in test dataset.
do you want togo out to celebrate my goodnews?
yes, i’m going to go to thebeach..seq2seq.
cvae it really really talking from.
the street.
mom..cvae+bow there may live in the rocks,.
please..sepacvae sure.
i go with my parents.
i am so excited about thesefriends!.
table 5: generated responses from the baselines andsepacvae..acknowledgements.
we would like to thank the anonymous reviewersfor their constructive comments.
this research issupported by beijing natural science foundation(no.
l181010 and 4172054), national key r&dprogram of china (no.
2016yfb0801100).
kanli is the corresponding author..references.
dzmitry bahdanau, kyunghyun cho, and yoshua ben-gio.
2015. neural machine translation by jointlylearning to align and translate.
in iclr..ashutosh baheti, alan ritter, jiwei li, and bill dolan.
2018. generating more interesting responses inneural conversation models with distributional con-.
5632straints.
in emnlp, pages 3970–3980.
associationfor computational linguistics..samuel r. bowman, luke vilnis, oriol vinyals, an-drew m. dai, rafal j´ozefowicz, and samy ben-gio.
2016. generating sentences from a continuousspace.
in conll, pages 10–21.
acl..hengyi cai, hongshen chen, yonghao song, zhuoyeding, yongjun bao, weipeng yan, and xiaofangzhao.
2020. group-wise contrastive learning forneural dialogue generation.
in emnlp, pages 793–802. association for computational linguistics..hongshen chen, zhaochun ren, jiliang tang, yi-hong eric zhao, and dawei yin.
2018. hierarchicalvariational memory network for dialogue generation.
in www, pages 1653–1662.
acm..ting chen, simon kornblith, mohammad norouzi,and geoffrey e. hinton.
2020a.
a simple frame-work for contrastive learning of visual representa-tions.
in icml, volume 119 of proceedings of ma-chine learning research, pages 1597–1607.
pmlr..xinlei chen, haoqi fan, ross b. girshick, and kaim-ing he.
2020b.
improved baselines with momentumcontrastive learning.
corr, abs/2003.04297..kevin clark, minh-thang luong, quoc v. le, andchristopher d. manning.
2020. electra: pre-training text encoders as discriminators rather thangenerators.
in iclr.
openreview.net..richard csaky, patrik purgai, and g´abor recski.
2019. improving neural conversational models within acl (1), pagesentropy-based data ﬁltering.
5650–5669.
association for computational linguis-tics..shaoxiong feng, hongshen chen, kan li, and daweiyin.
2020a.
posterior-gan: towards informative andcoherent response generation with posterior genera-tive adversarial network.
in aaai, pages 7708–7715.
aaai press..shaoxiong feng, xuancheng ren, hongshen chen,bin sun, kan li, and xu sun.
2020b.
regularizingdialogue generation by imitating implicit scenarios.
in emnlp, pages 6592–6604.
association for com-putational linguistics..xiang gao, sungjin lee, yizhe zhang, chris brockett,michel galley, jianfeng gao, and bill dolan.
2019.jointly optimizing diversity and relevance in neu-ral response generation.
in naacl-hlt (1), pages1229–1238.
association for computational linguis-tics..marjan ghazvininejad, chris brockett, ming-weichang, bill dolan, jianfeng gao, wen-tau yih, andmichel galley.
2018. a knowledge-grounded neu-ral conversation model.
in aaai, pages 5110–5117.
aaai press..xiaodong gu, kyunghyun cho, jung-woo ha, andsunghun kim.
2019. dialogwae: multimodal re-sponse generation with conditional wasserstein auto-encoder.
in iclr (poster).
openreview.net..bernd huber, daniel j. mcduff, chris brockett,michel galley, and bill dolan.
2018. emotional di-alogue generation using image-grounded languagemodels.
in chi, page 277. acm..diederik p. kingma and max welling.
2014. auto-.
encoding variational bayes.
in iclr..jiwei li, michel galley, chris brockett, jianfeng gao,and bill dolan.
2016a.
a diversity-promoting ob-jective function for neural conversation models.
inhlt-naacl, pages 110–119.
the association forcomputational linguistics..jiwei li, michel galley, chris brockett, jianfeng gao,and bill dolan.
2016b.
a diversity-promoting ob-jective function for neural conversation models.
inhlt-naacl, pages 110–119.
acl..jiwei li, michel galley, chris brockett, georgios p.spithourakis, jianfeng gao, and william b. dolan.
2016c.
a persona-based neural conversation model.
in acl (1).
acl..jiwei li, will monroe, alan ritter, dan jurafsky,michel galley, and jianfeng gao.
2016d.
deep re-inforcement learning for dialogue generation.
inemnlp, pages 1192–1202.
acl..jiwei li, will monroe, tianlin shi, s´ebastien jean,alan ritter, and dan jurafsky.
2017a.
adversariallearning for neural dialogue generation.
in emnlp,pages 2157–2169.
acl..yanran li, hui su, xiaoyu shen, wenjie li, ziqiangcao, and shuzi niu.
2017b.
dailydialog: a man-in ijc-ually labelled multi-turn dialogue dataset.
nlp(1), pages 986–995.
asian federation of natu-ral language processing..chia-wei liu, ryan lowe, iulian serban, michaelnoseworthy, laurent charlin, and joelle pineau.
2016. how not to evaluate your dialogue system:an empirical study of unsupervised evaluation met-in emnlp,rics for dialogue response generation.
pages 2122–2132.
acl..qian liu, yihong chen, bei chen, jian-guang lou,zixuan chen, bin zhou, and dongmei zhang.
2020.you impress me: dialogue generation via mutualpersona perception.
in acl, pages 1417–1427.
as-sociation for computational linguistics..thang luong, hieu pham, and christopher d. man-ning.
2015. effective approaches to attention-basedneural machine translation.
in emnlp, pages 1412–1421. the association for computational linguis-tics..laurens van der maaten and geoffrey hinton.
2008.visualizing data using t-sne.
journal of machinelearning research, 9(86):2579–2605..5633jovana mitrovic, brian mcwilliams, jacob walker,lars buesing, and charles blundell.
2020. repre-sentation learning via invariant causal mechanisms.
corr, abs/2010.07922..jiawei wu, xin wang, and william yang wang.
2019.in acl (1),self-supervised dialogue learning.
pages 3857–3867.
association for computationallinguistics..chen xing, wei wu, yu wu, jie liu, yalou huang,ming zhou, and wei-ying ma.
2017. topic awarein aaai, pages 3351–neural response generation.
3357. aaai press..jingjing xu, xuancheng ren,.
junyang lin, andxu sun.
2018a.
diversity-promoting gan: a cross-entropy based generative adversarial network for di-in emnlp, pages 3940–versiﬁed text generation.
3949. acl..xinnuo xu, ondrej dusek, ioannis konstas, and ver-ena rieser.
2018b.
better conversations by model-ing, ﬁltering, and optimizing for coherence and di-versity.
in emnlp, pages 3981–3991.
acl..xinchen yan, jimei yang, kihyuk sohn, and honglaklee.
2016. attribute2image: conditional image gen-eration from visual attributes.
in eccv (4), volume9908 of lecture notes in computer science, pages776–791.
springer..lantao yu, weinan zhang, jun wang, and yong yu.
2017. seqgan: sequence generative adversarial netsin aaai, pages 2852–2858.
with policy gradient.
aaai press..hainan zhang, yanyan lan, jiafeng guo, jun xu, andxueqi cheng.
2018a.
reinforcing coherence for se-quence to sequence model in dialogue generation.
inijcai, pages 4567–4573.
ijcai.org..yizhe zhang, michel galley, jianfeng gao, zhe gan,xiujun li, chris brockett, and bill dolan.
2018b.
generating informative and diverse conversationalresponses via adversarial information maximization.
in neurips, pages 1815–1825..tiancheng zhao, ran zhao, and maxine esk´enazi.
2017. learning discourse-level diversity for neuraldialog models using conditional variational autoen-coders.
in acl (1), pages 654–664.
acl..graham neubig.
2017. neural machine translation andsequence-to-sequence models: a tutorial.
corr,abs/1703.01619..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2002. bleu: a method for automatic eval-uation of machine translation.
in acl, pages 311–318. acl..jeffrey pennington, richard socher, and christopher d.manning.
2014. glove: global vectors for word rep-resentation.
in emnlp, pages 1532–1543.
acl..iulian vlad serban, alessandro sordoni, yoshua ben-gio, aaron c. courville, and joelle pineau.
2016.building end-to-end dialogue systems using gener-ative hierarchical neural network models.
in aaai,pages 3776–3784.
aaai press..iulian vlad serban, alessandro sordoni, ryan lowe,laurent charlin, joelle pineau, aaron c. courville,and yoshua bengio.
2017. a hierarchical latentvariable encoder-decoder model for generating dia-logues.
in aaai, pages 3295–3301.
aaai press..lifeng shang, zhengdong lu, and hang li.
2015. neu-ral responding machine for short-text conversation.
in acl (1), pages 1577–1586.
acl..xiaoyu shen, hui su, yanran li, wenjie li, shuziniu, yang zhao, akiko aizawa, and guoping long.
2017. a conditional variational framework for dia-log generation.
in acl (2), pages 504–509.
associ-ation for computational linguistics..kihyuk sohn, honglak lee, and xinchen yan.
2015.learning structured outputrepresentation usingdeep conditional generative models.
in nips, pages3483–3491..alessandro sordoni, yoshua bengio, hossein vahabi,christina lioma, jakob grue simonsen, and jian-yun nie.
2015a.
a hierarchical recurrent encoder-decoder for generative context-aware query sugges-tion.
in cikm, pages 553–562.
acm..alessandro sordoni, michel galley, michael auli,chris brockett, yangfeng ji, margaret mitchell,jian-yun nie, jianfeng gao, and bill dolan.
2015b.
a neural network approach to context-sensitive gen-eration of conversational responses.
in hlt-naacl,pages 196–205.
acl..j¨org tiedemann.
2009. news from opus—a collec-tion of multilingual parallel corpora with tools andinterfaces..di wang, nebojsa jojic, chris brockett, and eric ny-berg.
2017. steering output style and topic in neuralresponse generation.
in emnlp, pages 2140–2150.
association for computational linguistics..5634− (z−µ1)22σ2e1(cid:112)2πσ2.
1.a the computation of prior probability.
distribution through kl-divergenceon the one-to-many situation.
we assume that p(z|c1, r1) ∼ n (µ1, σ2p(z|c1, r2) ∼ n (µ2, σ2then, we have:.
1),2) and p(z|c1) ∼ n (µ, σ2)..kl(p(z|c1, r1)||p(z|c1)).
p(z|c1, r1) log.
p(z|c1, r1)p(z|c1).
dz.
p(z|c1, r1)[log p(z|c1, r1) − log p(z|c1)]dz.
(cid:90).
(cid:90).
(cid:90).
(cid:90).
(cid:90).
(cid:90).
(cid:90).
(cid:90).
=.
=.
=.
−.
=.
+.
−.
=.
p(z|c1, r1)[log.
− log.
2σ2.
e− (z−µ)2√2πσ2.
]dz.
12.
(z − µ1)22σ21.
12.p(z|c1, r1)[log.
+ (.
(z − µ)2.
2σ2 −.
=.
p(z|c1, r1) log.
p(z|c1, r1).
p(z|c1, r1).
p(z|c1, r1)[−.
log 2π − log σ1.
+.
log 2π + log σ +.
(z − µ)22σ2.
]dz.
dz.
)]dz.
σσ1(z − µ1)22σ21σσ1(z − µ)22σ2(z − µ1)22σ21is a constant, and the.
dz..dz.
since the log σσ1.
(cid:82) p(z|c1, r1)dz = 1, we have:.
(cid:90).
p(z|c1, r1) log.
dz = log.
σσ1.
..σσ1e− (z−µ1)2.
2σ2.
since p(z|c1, r1) =.
1√.
2πσ1.
(cid:82) p(z|c1, r1) (z−µ1)2.
2σ21.dz can be calculated as follow:.
,.
the.
p(z|c1, r1).
(cid:90).
(cid:90).
(cid:90).
(cid:90).
=.
=.
=.
p(z|c1, r1).
dz.
(z − µ1)22σ21e− (z−µ1)2.
2σ2.
dz.
√.
√.
√.
12πσ112πσ1e− (z−µ1)21√π.
2σ2.
(z − µ1)22σ21(z − µ1)22σ21(z − µ1)22σ21.d.e− (z−µ1)2.
2σ2.
z − µ1√2σ1.
..2σ1d.
z − µ1√2σ1.
let the x= z−µ1√2σ1.
, we have:.
(cid:90).
p(z|c1, r1).
dz.
(z − µ1)22σ21x2dx.
e−x2.
(cid:90).
xde−x2.
(cid:90).
=.
1√π.
= −.
= −.
1√.
1√.
2.
2.π.π.
(xe−x2.
|+∞−∞ −.
e−x2.
dx)..(cid:90).
according to the l’hospital’s.
rule,.
the.
limx→−∞ xe−x2.
=limx→+∞ xe−x2 = 0..to calculate the (cid:82) e−x2dx, we ﬁrst compute the.
e−x2dx)2, so we have:.
((cid:82) +∞0(cid:90) +∞(.
0.e−x2.
dx)2 =.
e−x2.
dx.
(cid:90) +∞.
0(cid:90) +∞.
·.
e−y2.
dy.
0(cid:90) +∞.
(cid:90) +∞.
=.
e−x2−y2.
dxdy..0let x = r sin θ and y = r cos θ, we have:.
0.e−x2−y2.
dxdy.
e−r2.
rdrdθ.
(cid:90) +∞.
(cid:90) +∞.
0.
=.
=.
0(cid:90) +∞.
(cid:90) π2.
0(cid:90) +∞.
0π2.
0.e−r2.
rdr =.
e−x2dx =−∞ e−x2dx=.
..π4√π2 .
according√π. and the.
0.therefore, the (cid:82) +∞to the symmetry, the (cid:82) +∞(cid:82) p(z|c1, r1) (z−µ1)2dz = 12 .
2σ21for the (cid:82) p(z|c1, r1) (z−µ)2(cid:90).
p(z|c1, r1).
2σ2 dz, we have:.
dz.
(z − µ)22σ2(z − µ1 + µ1 − µ)22σ2.
dz.
(z − µ1)2p(z|c1, r1)dz.
(cid:90)12σ2 [(cid:90)(µ1 − µ)2p(z|c1, r1)dz.
(z − µ1)(µ1 − µ2)p(z|c1, r1)dz].
2σ21.
(cid:82) (z−µ1)22σ21.p(z|c1, r1)dz + (µ1 − µ)2.
2σ2.
1 + (µ1 − µ)2σ22σ2.
..(cid:90).
(cid:90).
=.
=.
+.
+.
=.
=.
5635therefore, we have:.
kl(p(z|c1, r1)||p(z|c1)).
= log.
+.
σσ1.
1 + (µ1 − µ)2σ22σ2.
−.
12.
..where a means the base of the logarithmic formula.
∂σ = 0, since the σ3 can not be 0,.let the ∂φ(µ,σ).
we have:.
2σ2 − [σ2.
1 + σ2.
2 + (µ1 − µ)2 + (µ2 − µ)2] = 0..in the same way, the kl(p(z|c1, r2)||p(z|c1))2 .
and then, we can.
2+(µ2−µ)22σ2.
+ σ2.
− 1.equals log σσ2know:.
therefore, the σ∗ is:.
(cid:114).
σ∗ =.
1 + σ2σ2.
2 + (µ1 − µ)2 + (µ2 − µ)2.
..replace the µ with the µ∗, we have:.
(cid:115).
σ∗ =.
1 + σ2σ2.
2 + (µ1−µ2)2.
2.
2.
2.
..4.we use a constant c to replace (µ1−µ2)2., the σ∗.
equals.
(cid:113) σ2.
1+σ22 + c.2.the µ∗= µ1+µ2.
2 means the latent variables sam-pled from this prior probability distribution easilytend to be different from the latent variables sam-pled form the posterior probability distributions.
since the latent variables are highly correlated withthe generated responses, the responses generatedthrough prior probability distribution would be dif-ferent from that generated from posterior probabil-ity distributions.
if the difference between µ1 andµ2 is very large, the σ∗ would be large too, thus re-sulting in high probability of more irrelevant latentvariables..b the implementation of gradient.
blocking.
we present the implementation of gradient block-ing method in algorithm 2. in algorithm 2, webuild a mask tensor loss m ask to ﬁlter the lossresults form each batch data, which can same ob-struct the gradient backpropagation.
since we usedgradient descent to optimize the neural model, thesmallest loss result equals the largest variationallower bound.
the elements in loss m ask are 0or 1, so loss ∗ loss m ask can be considered asthe selection of the existing loss..kl(p(z|c1, r1)||p(z|c1)).
+ kl(p(z|c1, r2)||p(z|c1)).
).
= log(.
σ2σ1σ21 + σ2σ2.
+.
2 + (µ1 − µ)2 + (µ2 − µ)2.
− 1..2σ2.
since the latent vanish problem is not expectedby the vae and cvae methods, the p(z|c1, r1)should be different from p(z|c1, r2), which meansthe n (µ1, σ1) is different from the n (µ2, σ2)..after.
that, wethe.
rep-kl(p(z|c1, r1)||p(z|c1)) +.
the φ(µ, σ).
resentkl(p(z|c1, r2)||p(z|c2)), then we have:.
use.
φ(µ, σ) = log(.
σ2σ1σ2.
).
2σ2.
1 + σ2σ2.
2 + (µ1 − µ)2 + (µ2 − µ)2.
+.
− 1..according to the lagrange multiplier method,we can calculate the conditional extremum and theextreme point (µ∗,σ∗) of φ(µ, σ)..to obtain the µ∗, we have to calculate the.
∂φ(µ,σ)∂µ.
:.
∂φ(µ, σ)∂µ.
∂ (µ1−µ)2+(µ2−µ)22σ2∂µ.
2µ − µ1 − µ2σ2.
..=.
=.
let the ∂φ(µ,σ).
∂µ.
equals 0, we have the µ∗= µ1+µ2.
..2.in the same way, to obtain the σ∗, we have:.
∂φ(µ, σ)∂σ.
=.
∂ log( σ2σ1σ2∂σ.
).
+ [σ2.
2 + (µ1 − µ)2 + (µ2 − µ)2]1 + σ21 + σ2σ2.
∂ 12σ2∂σ2 + (µ1 − µ)2 + (µ2 − µ)2.
−.
2σ2σ2 − [σ2.
=.
=.
1 + σ2.
2 + (µ1 − µ)2 + (µ2 − µ)2].
,.
σ3.
σ3.
5636algorithm 2 gradient blockinginput: loss : loss-results of extended dialogue.
data in one batch;n : the number of group information;batchsize : the number of data contained onone batch;.
output: loss m ask : the mask tensor with [0,1].
elements;.
1: loss ← tf.reshape(loss, [batchsize, n ])2: ministlossp oss ← tf.argmin(loss, 1) #.
ﬁnd the posision of the minist loss;.
3: ones ← onestensor(1, dtype=tf.ﬂoat32)4: zeros ← zerosvector(1, dtype=tf.ﬂoat32)5: loss m ask ← tf.cond(.
tf.equal(ministlossp oss[0],tf.constant([0])[0],lambda:ones, lambda:zeros).
6: for i = 1 to batchsize dofor j = 1 to n do7:.
if i = 1 and j = 1 then.
8:.
9:.
10:.
11:.
continue.
else.
loss m ask ← tf.concat([loss m ask, tf.cond(tf.equal(ministlossp oss[i],tf.constant([j]))[0],lambda:zeros)],0).
lambda:ones,.
12:.
end ifend for.
13:14: end for15: p ass loss ← loss*loss m ask16: return p ass loss.
5637