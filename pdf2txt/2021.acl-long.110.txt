assessing emoji use in modern text processing tools.
abu awal md shoebdept.
of computer sciencerutgers universitynew brunswick, nj, usaabu.shoeb@rutgers.edu.
gerard de melohasso plattner institute /university of potsdampotsdam, germanygdm@demelo.org.
abstract.
emojis have become ubiquitous in digital com-munication, due to their visual appeal as wellas their ability to vividly convey human emo-tion, among other factors.
this also leads toan increased need for systems and tools to op-erate on text containing emojis.
in this study,we assess this support by considering test setsof tweets with emojis, based on which we per-form a series of experiments investigating theability of prominent nlp and text processingtools to adequately process them.
in particu-lar, we consider tokenization, part-of-speechtagging, dependency parsing, as well as senti-ment analysis.
our findings show that manysystems still have notable shortcomings whenoperating on text containing emojis..1 introduction.
in our modern digital era, interpersonal communi-cation often takes place via online channels suchas instant messaging, email, social media, etc.
thisentails an increasing need for tools that operate onthe resulting digital data.
for instance, online con-versations can be invaluable sources of insights thatreveal fine-grained consumer preferences with re-gard to products, services, or businesses (dong andde melo, 2018)..however, the shifts in modality and medium alsoshape the way we express ourselves, making it in-creasingly natural for us to embed emojis, images,hashtags into our conversations.
in this paper, wefocus specifically on emojis, which have recentlybecome fairly ubiquitous in digital communication,with a 2017 study reporting 5 billion emojis be-ing sent daily just on facebook messenger (burge,2017).
emojis are textual elements that are encodedas characters but rendered as small digital images oricons that can be used to express an idea or emotion..goals.
due to their increasing prominence, thereis a growing need to properly handle emojis when-.
ever one deals with text.
we consider a set of popu-lar nlp tools and empirically assess to what extentthey support emojis across a set of standard tasks,encompassing tokenization, part-of-speech tagging,dependency parsing, and sentiment analysis..although emojis can be encoded as unicodecharacters, there are unique properties of emoji en-coding that merit special consideration, such as skintone modifiers and composite emoji incorporatingmultiple basic emojis.
moreover, text harboringemojis may adhere to subtly different conventionsthan more traditional forms of text, e.g., with regardto token and sentence boundaries.
emojis can takethe place of words with different parts-of-speechand assume different grammatical roles.
finally,emojis may of course also alter the semantics ofthe text, which in turn may, for instance, affect itssentiment polarity..overview.
for our analysis, we draw primarilyon social media and study diverse forms of emojiuse.
we run a series of experiments on such dataevaluating each nlp tool to observe its behaviourat different stages in the processing pipeline.
theresults show that current tools have notable defi-ciencies in coping with modern emoji use in text..2 related work.
while emoji characters have a long history, theyhave substantially grown in popularity since theirincorporation into unicode 6.0 in 2010 followed byincreasing support for them on mobile devices.
ac-cordingly, numerous studies have sought to explainhow the broad availability of emojis has affectedhuman communication, considering grammatical,semantic, as well as pragmatic aspects (kaye et al.,2017; mcculloch, 2019).
only few studies havespecifically considered some of the more advancedtechnical possibilities that the unicode standard af-fords, such as zero width joiners to express more.
complex concepts.
for instance, with regard toemoji skin tone modifiers, robertson et al.
(2020)study in depth how the use of such modifiers varieson social media, including cases of users modulat-ing their skintone, i.e., using a different tone thanthe one they usually pick..given the widespread use of emojis in every-day communication, there is an increasing need fornlp tools that can handle them.
prominent nlptoolkits such as stanford’s stanza (qi et al., 2020)and nltk (bird et al., 2009) power a wide rangeof user-facing applications.
a number of reportscompare the pros and cons of popular nlp libraries(wolff, 2020; kozaczko, 2018; choudhury, 2019;bilyk, 2020), but these primarily consider the fea-tures and popularity of the tools, as well as theirperformance.
there have not been studies assessingthem with regard to their ability to cope with mod-ern emoji-laden text.
since emojis are becomingincreasingly ubiquitous, it is crucial for developersand institutions deploying such software to knowwhether it can properly handle the kinds of text thatnowadays may quite likely arrive as input data.
inmany real-world settings, applications and servicesare expected to operate on text containing emojis,and thus it is important to investigate these capabil-ities..many academic studies present new models forparticular nlp tasks relating to emojis.
for in-stance, felbo et al.
(2017) developed an emojiprediction model for tweets.
weerasooriya et al.
(2016) discussed how to extract essential keywordsfrom a tweet using nlp tools.
cohn et al.
(2019)attempted to understand the use of emojis froma grammatical perspective, seeking to determinethe parts-of-speech of emoji occurrences in a sen-tence or tweet.
owoputi et al.
(2013) proposed animproved part-of-speech tagging model for onlineconversational text based on word clusters.
proisl(2018) developed a part-of-speech tagger for ger-man social media and kong et al.
(2014) developeda dependency parser for english tweets.
however,such work mostly targets just one specific task andis typically not well-integrated with common opensource toolkits, which we focus on in our study..3 experimental data.
as we wish to assess the support of emojis providedby different text processing tools, we first considersome of the different cases of emoji use that onemay encounter, in order to compile relevant data..3.1 emoji use in text.
emojis can appear in a sentence or tweet in dif-ferent circumstances.
they may show up at thebeginning or at the end of a tweet.
likewise, theymay appear as part of a series of emojis separatedby spaces, or can be clustered within a text withoutany interleaved spacing.
based on observations ona collection of tweets crawled from twitter (shoebet al., 2019), we defined a series of cases distin-guishing different aspects of emoji use, includingthe number of emojis (i.e., single emojis vs. multi-ple emojis), position of emojis, the use of skin tonemodifiers, and so on..skin tone (e.g.,.
light skin tone (e.g.,.
for skin tone emojis, the unicode standardadopts the fitzpatrick scale (fitzpatrick, 1975), ac-cording to which the skin tone for selected emojiscan be modulated with five different color settings:), medium-light), medium skin tone (e.g.,), and).
internally, an emojimodifier sequence is assumed when a modifiercharacter follows a supported base emoji character,resulting in a single emoji with skin tone..), medium-dark skin tone (e.g.,dark skin tone (e.g.,.
some characters now classified emojis are en-coded in plane 0, the basic multilingual plane,where 16 bits suffice to encode individual char-acters.
however, the majority of emojis residein plane 1, the supplementary multilingual plane,which in the past had mainly been reserved for rarehistoric scripts.
when including the latter, individ-ual characters can no longer be encoded directlywithin just 16 bits.
hence, we consider whether atool handles both non-bmp and bmp emojis..emojis with zero width joiner (zwj) join twoor more other characters together in sequence tocompose a new one.
popular emoji zwj sequences,include group ones such as the family emojiconsisting in this case of man, woman, girl, boyemojis, and encoded by combiningman, theu+200d zwj code, woman, u+200d again,boy.
these arerendered as a single emoji on supported platforms..girl, u+200d, and finally.
3.2 tweet selection.
given the different cases of emoji use discussedabove, we searched for relevant examples in a col-lection of tweets that we compiled earlier fromtwitter (shoeb et al., 2019).
the purpose of this en-deavor was to assemble a collection of tweets basedon a set of most frequently used emojis so that ev-.
tweets.
totaluniqueno more than 5 tweets from one useronly single emojimultiple emojisskin tone modifiers emojislight skin tone emojismedium light skin tone emojismedium skin tone emojismedium dark skin tone emojisdark skin tone emojiszero width joiner (zwj) emojis.
%count10022.3 m21.4 m 95.8420.8 m 93.275.67 m 25.3816.48 m 73.775.851.31 m1.71382 k1.73386 k1.51337 k1.23274 k0.2453 k0.4397 k.words, keywords, phrases, symbols, and other el-ements, referred to as tokens.
in the process oftokenization, some characters such as punctuationmarks may be discarded.
it is important for a tok-enizer to generate meaningful results, as the outputof this step becomes the input for subsequent pro-cessing steps such as parsing and text mining inthe pipeline.
in our study, we expect a tokenizer tosegment a text into tokens such as words, emojis,and other special characters..table 1: emoji centric twitter corpus statistics – thedistribution of emojis over the ~22 million tweets withregard to the considered emoji use in text.
4.1 task setup.
ery single tweet contains at least one emoji.
thepopularity of the emojis was determined using no-vak et al.
(2015) and emoji tracker1, a website thatmonitors the use of emojis on twitter in real time.
in total, we obtained a set of 22.3 million tweetsover a span of one year.
this collection, namedas emotag, is readily available online2.
table 1provides corresponding statistics of our collection,showing that even rare phenomena do occur in sub-stantial numbers of tweets..next, we chose representative samples for eachcase.
we restricted our search to english languagetweets and ensured that not all tweets simply con-sisted of urls or mentions.
the latter are fairlycommon on social media, and since it would notbe very uncommon for a text processing tool toencounter them in tweets, we did also incorporate afew such tweets along with tweets containing gen-uine text.
ultimately, we obtain a diverse collectionof short input texts, including different skintones,zwj emojis, and other cases mentioned in section3.1 and table 1..we drew upon the compiled input texts for as-sessments with regard to different nlp tasks.
thefollowing sections describe each of the consideredtasks, i.e., tokenization (section 4), part-of-speechtagging (section 5), dependency parsing (section6), and sentiment analysis (section 7) separately.
the full dataset for the following experiments canbe found at http://emoji.nlproc.org..4 tokenization.
tokenization is the act of breaking up a sequenceof strings into a sequence of basic pieces such as.
1http://emojitracker.com/2https://github.com/abushoeb/emotag.
while tokenizing a sentence, or a tweet with emojis,in particular, we focus on the position and type ofemojis presented earlier in section 3. an emoji canaccompany a word with both leading and trailingspaces, or it can be attached to words without anyseparating whitespace.
we typically expect a to-kenizer to distinguish an emoji from a word evenin the absence of a space delimiter if it appears toconstitute a separate concept.
the same principleshould be followed for emoji clusters, i.e., if multi-ple emojis occur in a sequence such as “”,they are expected to be recognized as individualtokens..another aspect of successful tokenization is ad-equately handling emoji skin tone modifiers.
asemojis can have five different skin tone modifiers,we ensure that our test data contains the same num-ber of tweets from all skin tones.
an ideal tokenizershould not split skin tone emoji into two individualcharacters.
for example, the waving hand lightemoji should not be split into a reg-skin toneand a tone modifierular waving hand emoji.
.
we also test the abilities of tools in terms of han-dling zwj emoji sequences.
we randomly picka small set of tweets containing zwj sequencesfor this purpose.
for example, an ideal tokenizershould not split up a family emoji as four individ-ual emojis such as man, woman, girl, boy, as theemoji is meant to be rendered as a single one..note that some tokenizers discard punctuationduring the tokenization process, while others retainthem as tokens.
for example, gensim removes allpunctuation, including all emojis.
furthermore, thenltk tweet tokenizer does not split up a hashtagas “#” followed by a word, but rather keeps it intact,as hashtags usually convey meaningful informationin tweets.
thus, to generalize the tokenization pro-cess across tools, we apply certain post-processingtechniques before comparing the list of tokens with.
toolsgensimnltknltk-ttpynlplspacyspacymojistanzatextblob.
task - tokenization.
se me001000100100100.
070100901001008070.ste0680680927068.bmp nb0801008010010010080.
070100601001008070.zwj0700700104070.table 2: tokenization accuracy (%) of tools for differ-ent test set subsets.
se: single emoji, me: multiple,ste: skin tone emojis, bmp: basic multilingual plane,nb: non-bmp, zwj: zero width joiner emojis..the expected list.
one such technique is to discardall punctuation from the list of tokens, while for#hashtag occurrences, we treat both “hashtag” and“#hashtag” as valid options..tools.
in total, we consider 8 libraries for ourexperiments.
these are the regular english tok-enizer of the natural language toolkit (nltk)by bird et al.
(2009), the nltk tweet tokenizer(i.e., its twitter-aware tokenizer), the stanford nlpgroup’s stanza (formerly known as stanfordnlp)(qi et al., 2020), spacy and spacymoji, pynlpl(the python library for natural language process-ing, pronounced as pineapple), gensim (řehůřekand sojka, 2010), textblob, and allennlp (gard-ner et al., 2018).3.
4.2 results.
table 2 presents the results of tokenizing the givencase-specific test data, based on an overall set of100 input texts.
we partitioned this test data withregard to different cases of emoji use for a morefine-grained analysis..for single emoji (se), intended to be the sim-plest case, where each input cannot contain morethan one emoji, we observe that most tools exceptfor gensim obtain acceptable results.
since gen-sim discards emoji characters, it also fails all othertest cases.
in contrast, both spacy and spacymojiachieve 100% accuracy.
other tools may fail to seg-ment off emojis that have been attached to wordswithout whitespace..the multiple emojis (me) case considers inputswith more than a single emoji, including clustersof emojis.
some tools, such as nltk and pynlpl,.
3we rely on python 3.8 along with the latest version of alltools (gensim 3.8.3, nltk 3.4.5, pynlpl 1.2.9, spacy 2.2.4,spacymoji 2.0.0, stanza 1.1.1, textblob 0.15.3) availableuntil november 2020..failed for this part despite having done well on sin-gle emoji utterances.
apart from separating offemojis from words, tools here differ mostly basedon whether they split up groups of emojis..for skin tone emojis, there are 50 test cases withskin tones.
note that these can have single or mul-tiple emojis, but it is ensured that they bear at leastone skin tone emoji.
in some cases, the problemsare the same as for regular emojis, e.g., splitting offemojis from words.
however, some tools generallysplit off skin tone modifiers from the emojis theyare intended to modify.
stanza only breaks a colortone emoji into the base emojis and tone modifierswhen it is concatenated with text.
otherwise it canhandle a skin tone emoji without splitting it.
spa-cymoji obtains a near-perfect result but still doesnot manage to preserve all skintone emojis..the next test is designed to assess basic mul-tilingual plane (bmp) and non-bmp emojis, re-spectively.
for each of these cases, a distinct setof 10 tweets was used to assess the performance.
interestingly, non-bmp emojis appear to be better-supported, presumably because they include themost popular emojis.., u+200d,.
finally, we consider emojis with zero width join-ers (zjw), where each tweet contains no more thantwo emojis with at least one zwj emoji.
the toolsthat fail in this case, such as nltk-tt, insteadof preserving a zjw emoji such as, producemultiple separate tokens, including the unicode,zero-width joiners as individual tokens, e.g.,u+200d,.
infact, none of the tools could achieve 100% accuracyacross all zwj emojis.
this is because they mayfail when a regular emoji and a zwj one appeartogether.
for example, one of the inputs containsthe emojis, which nltk treats as a singletoken, although it successfully handles other zwjemojis when they are space-separated.
in contrast,nltk-tt appears to be the best option for deal-ing with emoji clusters, but when it comes to zwjemojis, it separates all emojis and joiners.., u+200d, and.
5 part-of-speech tagging.
part-of-speech (pos) tagging is the process of as-signing each token a label that reflects its wordclass.
this may be with respect to traditional partsof speech, such as noun, verb, adjective, etc., orusing a more fine-grained inventory of classes..task - parts-of-speech (pos) tagging.
punctuation~17.3%.
average100%.
tools.
nltknltk-ttspacyspacymojistanzatextblob.
noun26%100.083.366.766.783.383.3.adjective22%.
verb~17.3%0100100100100100.adverb~17.3%0000250.
0100002020.modifiedtokenizer26.160.934.834.8↑ 52.2↑ 60.9.
26.160.934.834.847.843.5.
000000.table 3: the percentage of success of tools at labeling emojis with different parts-of-speech.
the last columnreports the average percentage of success when a modified tokenizer is used..tweets.
targetemoji.
expectedpos.
tools.
stanza.
stanza.
stanza.
dog.
she kept herbut had to sell hermodified: she kept herbut had to sell heri made a picturewhat do you think.
..........dog.
noun.
noun.
punctuation.
defaulttokenizer(adj)....
(.)
(noun)....
(.)
(.)
(nnp).
textblob.
i made a picturewhat do you think.
punctuation.
(nns).
textblob.
yes, she is.
and i like it.
adjective.
is.
and (verb).
modifiedtokenizer(adj)(nn)(noun)(noun)(nn)(.)
(nnp)(nnp)(nn)(adj).
table 4: examples of tweets in which an emoji assumes the role of different parts-of-speech.
the last columnreports how the tagging accuracy can be improved by utilizing a unified tweet-aware tokenizer across all tools..5.1 task setup.
to understand how different pos taggers handleemojis in a sentence, we evaluate all tools for asubset of inputs covering the majority of emoji sce-narios mentioned in section 3..for evaluation, we compiled a set of 23 realtweets, in which emojis are used as different parts-of-speech, namely as nouns, adjectives, verbs, ad-verbs, or as punctuation.
we mapped the originalpart-of-speech tags to these coarse-grained cate-gories and then checked for correctness with regardto human annotations obtained for our tweets.
onlythe part-of-speech tags assigned to the emojis wereconsidered, while the tagging of all other non-emojitokens was deemed irrelevant for the purposes ofthis experiment.
note also that this test suite islimited to clear-cut cases of emojis used within sen-tences and we do not claim that every potential useof an emoji has an obvious well-defined part-of-speech tag..tools.
for this task, we evaluated all tools ex-cept gensim and pynlpl, as they do not directlyoffer any pos tagging functionality.
since tok-enization is a prerequisite for pos tagging, a tool.
is likely to fail to correctly tag a word or emoji ifthe emoji is not properly tokenized in the precedingstep.
however, for a more extensive evaluation,we considered two setups.
first, we conducted thepos tagging experiment based on the output of theintegrated tokenizer of the respective tool.
thus,are” asif a tool was unable to tokenize “emojis”, and “are”,three separate tokens “emojis”, “we still proceeded with the task treating it as onetoken for the respective tool’s pos tagger.
subse-quently, we conducted the pos tagging experimentwhile considering a unified ground truth tokeniza-tion as input for all tools.
for example, in the caseare”, the tagger could expect to re-of “emojisceive them as separate tokens “emojis”, “”, and“are”..5.2 results.
table 3 reports the results of our part-of-speechtagging experiments.
the final two columns sum-marize the results with the original tokenizer andthe modified tokenizer.
none of the tools in ourexperiment could handle the case of emojis actingas adverbs or as punctuation.
for instance, “my” is one suchcredit score went.
7 points.
example where the upwards button emojias-sumes an adverbial role, which none of the taggersrecognize, despite the emoji being space-delimited.
similarly, occurrences of the question mark.
or double exclamation mark emoji.
emojiused as punctuation are labeled as nouns by all con-sidered tools..interestingly, we obtained a 100% success ratefor handling verb emojis, except with nltk.
al-though the latter is the only tool that passes all testcases for noun emojis, it fails for all other cases.
overall, nltk-tt and stanza obtain the highestsuccess rates as reported in the penultimate columnof the table..when considering the harmonized ground truthtokenization, as reported in the final column oftable 3, the results for textblob are boosted sig-nificantly and for stanza a more modest gain isobserved.
textblob and stanza for instance mayfail when emojis are not separated by whitespacefrom regular words (e.g., “love”) or from an-other emoji (e.g., “”).
rectifying the tok-enization in such cases improves the results of bothtools..the first example in table 4 shows the interest-ing phenomenon of redundancy causing incorrectpredictions.
in this tweet, both the dog emojiand the cat emojiare expected to be taggedas nouns, but stanza assumes the former to be anadjective due to the additional presence of the reg-ular word “dog”.
to examine this further, we alsoconsidered several modifications of the originaltweet.
first, we considered the tweet without theadditional word “dog” word after the dog emoji, in which case stanza can easily identify it asa noun.
this is reported in the second row of ta-ble 4. we also tried replacing the dog emoji withthe word “dog” to see if stanza can cope with er-roneous word reduplication, and it turned out thatstanza could correctly identify both occurrences asnouns.
finally, we considered replacing the wordemoji.
in this case, the tool“dog” with anothermarked the firstas punctuation..as a noun and the second.
6 dependency parsing.
in dependency grammar, the syntactic structure ofa sentence is described as a tree capturing relation-ships between head words and dependent words.
given that emojis can have different grammaticalroles within a sentence, we thus assessed to what.
extent popular dependency parsers are affected bythe presence of emojis in the input..6.1 task setup.
we rely on the english web treebank (ewt), oneof the around 200 treebanks in the universal de-pendency (ud) collection4, which seeks to define aconsistent annotation of grammar (including partsof speech, morphological features, and syntacticdependencies) across over 100 languages.
theenglish web treebank ud corpus provides goldstandard universal dependency annotations , builtover the source material of the english web tree-bank (bies et al., 2012).
we randomly pick a setof sentences from ewt and then replace certainobvious words with matching emojis in both theplain text sentences and their corresponding depen-dency trees to obtain a ground truth set.
examplesof such word–emoji replacements include fire,, etc.
to further examine thedeathrobustness of the tools, we also incorporate multi-emojis, skin tone emojis, and zwj emojis in theinput.
for instance, one of the ewt sentences in-cludes “chicken salad salad is great too.” for whichwe embed theis greattoo.”.
the purpose of this approach is to assess howwell a dependency parser can handle such forms ofemoji use.
again, our test suite is limited to clear-cut instances and we do not make the assumptionthat any possible emoji use will have an unambigu-ous well-defined ground truth annotation..emoji as “chicken.
, salad.
tools.
not all of the previously considered toolsprovide their own dependency parser.
for thisevaluation, we thus considered only stanford’scorenlp, spacy, and stanza..6.2 results.
table 5 reports both labeled attachment score(las) and unlabeled attachment score (uas) re-sults, where the latter consider just the location ofthe edge, i.e., just the structure of the tree, whilethe former as well mandate that the edge labels beidentified correctly.
the first two columns reportthe average attachment score based on the entiredependency tree for the given set of inputs.
thenext two columns (i.e.
single emoji sub-tree) con-sider only the parent and child nodes of emojis inthe tree, i.e., an emoji-centered sub-tree (or forest).
finally, the last two columns report las and uas.
4version 2.7 https://universaldependencies.org/.
#download.
toolscorenlpspacystanza.
single emojiuaslas0.7660.7290.4590.3590.8360.821.single emoji sub-treelas0.6310.2110.758.uas0.7150.2560.796.multi emojiuaslas0.6550.6250.4010.3110.7330.725.table 5: labeled attachment score (las) and unlabeled attachment score (uas) of dependency parser basedon the english web treebanks (ewt).
for complex emojis including multi-emojis, skintone emojis, and zwj emojis in the given testcases.
the results show a clear degradation of both thetree structure (uas) and the dependency labels(las) when it comes to tackling edges in the graphconnecting other tokens to emojis.
this becomesmore evident with the presence of complex emo-jis in the tree.
in general, stanford corenlp andstanza appear to be more robust than spacy..7 sentiment analysis.
although the word “emoji” is not etymologicallyrelated to the word “emotion”, several studies showhow emojis can help to express emotions (shoeband de melo, 2020) and sentiment in textual com-munication (novak et al., 2015).
keeping this inmind, we further assessed how well nlp tools fareat the task of predicting the sentiment polarity ofa text harboring emojis.
table 6 shows examplesof texts with different emojis.
while the text alonemay be ambiguous with respect to its sentimentpolarity, the emoji appears to eliminate much ofthe ambiguity if it is appended to the end of thetext.
the goal of this endeavor is to examine ifthe sentiment polarity is predicted correctly when ahigh-intensity emoji is incorporated into a neutralsentence..7.1 task setup.
for this task, we leverage a set of custom sentencesand tweets from the sentiment140 dataset (go et al.,2009).
we considered a set of texts with neutralor ambiguous sentiment.
the sentiment label wasverified by multiple tools before considering themin our experiment.
a sentence as well as a tweetwere only considered when their sentiment labelswere consistent across multiple tools.
althoughthe specific sentiment score may vary from onetool to another, we ensured that the sentiment la-bel remained consistent.
each example was thenmodified with both positive and negative emojisappended to the end, giving us the opportunity to ob-serve whether the predicted polarity of the originalsentence changes in accordance with the polarity.
of the emojis.
for example, i’ll explain it later isa neutral sentence that is modified either with aor with a negative one such aspositive emoji.
we use different sets of positive and negativeemojis to modify the sentiment of the text, cover-ing a broad spectrum of the sentiment polarity ofemojis.
the sentiment of emojis was determinedbased on the data by novak et al.
(2015)..tools.
although many tools could be trained ona labeled set of tweets, we sought to assess pre-existing systems as they are often used out-of-the-box without additional training or fine-tuning.
hence, this study considers nltk and textblob,as they can readily be used on the fly without re-quiring new labeled data.
note that textblob’ssentiment module contains two sentiment analyz-ers, patternanalyzer and naivebayesanalyzer, thelatter trained on movie reviews.
for nltk, we usevader (valence aware dictionary and sentimentreasoner), a lexicon and rule-based sentiment anal-ysis tool that is specifically attuned to sentiment asexpressed in social media.
additionally, we eval-uate the standalone vader library directly as itis meant to support emoji sentiment (hutto andgilbert, 2014)..7.2 results.
the results are given in table 7. in the sentimentprediction task for a given tweet with emojis, nei-ther nltk nor the textblob models appear to beable to consider the emojis as part of their sen-timent polarity prediction.
only the stand-alonevader library is able to discern any differencewhen positive or negative emojis are provided withthe sentence, as reflected in the final row of table7. the discrepancies between nltk’s vadercomponent and the stand-alone vader stem fromdifferences in the lexicon used by the tools.
thestand-alone vader includes a dedicated emojilexicon that is omitted in the nltk version.
somestudies (jain et al., 2019) show that an emoji canmoderate the sentiment of a given tweet if the sen-timent of an emoji is considered during training..sentences.
they decided to release itlet’s go for iti’ll explain it laterthere is a book on the deskthis is the endmy passport is expired by little over a monthit’s good that they have a direct flight now.
modifiers.
+veemoji.
–veemoji.
sentiment predictionstext with+ve emoji.
text with–ve emoji.
onlytext.
expectedneutralobservedneutral–ve+ve.
expected+veobservedneutralnochange.
expected–veobservedneutralnochange.
table 6: example sentences with relatively high polarity emojis that could moderate the overall sentiment of thegiven sentences – nlp tools, in general, fail to capture the combined (text+emoji) sentiment.
modelvaderpatternanalyzer.
toolsnltktextblobtextblob naivebayesanalyzervader.
vader.
emojis.
nt100.0100.0100.0100.0.
+ve0.00.00.057.1.
-ve0.00.00.050.0.table 7: accuracy (in %) of different tools at predictingsentiment scores of neutral text alone (nt) or neutraltext along with positive (+ve) or negative (-ve) emojis.
emoji.
nearest neighbouremojis.
clapping hands (regular)clapping hands (light)clapping hands(medium light)clapping hands (medium)clapping hands(medium dark)clapping hands (dark)zwj family(man, woman, girl, boy).
[.
[.
].
].
table 8: nearest neighbour emojis for the clappinghands and family emojis.
all nearest neighbours fol-low mostly the same color tone of the respective emojisexcept some indicated with [ ]..clearly, systems trained on emoji-bearing data canlearn to consider them during prediction if theirtokenization is handled properly and they are notdiscarded during preprocessing.
however, giventhe importance of emojis in conveying sentiment,it appears that most out-of-the-box tools ought toconsider emojis as well..8 discussion.
overall, based on table 9, we can see that none ofthe considered tools perfectly handles all evaluatedtasks with emojis.
indeed, many text preprocess-ing pipelines, especially deep learning ones with alimited vocabulary, routinely discard emojis alongwith punctuation characters as non-standard char-.
acters.
gensim by default follows this commonapproach, which is likely suboptimal for emojis.
nltk-tt as well as stanza help keep track of hash-tags as they retain them with the “#” sign intact,whereas other tools split them up as two individ-ual tokens or remove the “#”.
nltk, stanza, andtextblob fail to tokenize emojis if emojis are tiedup with other words, while spacy, spacymoji, andnltk-tt handle such cases.
note that accuratetokenization, e.g., splitting off emojis attached towords, can also be a prerequisite for many down-stream tasks, such as enabling higher-quality textclassification and information retrieval..for pos tagging, somewhat surprisingly, almostall tools did well with verbs, while they all strug-gled with punctuation emojis as well as adverbs.
the results for adjectives were as well quite mixed.
overall, nltk-tt and textblob achieved the high-est success rate for pos tagging, although both stillstruggle with adverbs and punctuation, which canalso lead to adverse effects in downstream taskssuch as syntactic parsing.
moreover, textblob re-quires the use of a modified tokenizer.
for depen-dency parsing, we found stanford corenlp andstanza to be the most robust in correctly assessingemojis.
spacy, in contrast, does not appear to gen-eralize well enough to lexical items such as emojisthat may be lacking in the training data.
in general,there is a need for dependency parsers to be trainedon more diverse data..thus, in practice one may wish to consider a mix-and-match approach, using a tokenizer from onelibrary, a tagger from another, and a dependencyparser from yet another library..in our pos tagging and dependency parsing eval-uations, we sought to study clear-cut cases to ob-serve whether tools have basic support for emojis.
further discussion is necessary on recommendedannotation schemes for more diverse forms of emoji.
toolsgensimnltkpynlplstanzatextbloballennlpnltk-ttspacyspacymoji.
se ge(cid:55)(cid:55).
ste(cid:55).
bmp(cid:55).
zwj(cid:55).
(cid:51).
(cid:55).
(cid:51).
(cid:51).
(cid:51).
(cid:51).
(cid:51).
(cid:55).
(cid:51).
(cid:51).
(cid:51).
(cid:51).
(cid:51).
(cid:55).
(cid:55).
table 9: an overview of popular text processing nlptools and their emoji support.
se: single emoji, ge:groups of emojis, ste: skin tone emojis, bmp: basicmultilingual plane, zwj: zero width joiner emojis..use for which the ground truth may not be as ob-vious.
some researchers argue that the defaulttagging of emoji should be as adverbials, interjec-tions, or punctuation (grosz et al., 2021).
simi-larly, emojis are syntactically comparable to freeadjuncts, which constrains the set of valid parsetrees.
hence, further work is necessary to devisebroader-coverage benchmarks for the tasks consid-ered in our study..semantic associations.
finally, we also in-spected semantic associations for particular kindsof emojis.
we considered a 300-dimensionalword2vec sgns model trained on the emotag(shoeb et al., 2019) dataset, and generated a setof nearest neighbours for selected target emojis..table 8 reports the nearest emoji neighbours fordifferent skin tone variants of the clapping handemoji.
most of the top 5 neighbours for each emojibear the same skin tone color except one each formedium light and medium tone emojis reportedin rows 4 and 5, respectively.
we conjecture thatspeakers who use skin tone modifiers frequentlyalso use additional emojis that support such modi-fication and that they naturally tend to use the re-spective modifier fairly consistently..the last row of the same table shows the nearestneighbours for a zwj family emoji.
all of thenearest neighbours of this zwj emoji contain azwj sequence as well, suggesting that they occurin similar contexts..9 conclusion.
deeper understanding of this wealth of data but alsoto properly preserve and process them correctly..in this study, we assessed how well prominentnlp tools cope with text containing emoji charac-ters.
to this end, we evaluated a set of tools on threedifferent tasks across a range of challenging testsets capturing particular phenomena and encodings.
our study demonstrates that there are notable short-comings in widely used nlp tools.
although manytools are partially capable of operating on emojis,none of them proved fully equipped to tackle thefull set of aspects considered in our study.
hence,special care needs to be taken when developingapplications that may encounter emojis..references.
ann bies, justin mott, colin warner, and seth kulick..2012. english web treebank..volodymyr bilyk.
2020. natural language processing.
tools and libraries 2020..steven bird, ewan klein, and edward loper.
2009.natural language processing with python: an-alyzing text with the natural language toolkit.
o’reilly, beijing..jeremy burge.
2017.
5 billion emojis sent daily on mes-.
senger..ambika choudhury.
2019. top 10 python nlp li-.
braries for 2019..neil cohn, jan engelen, and joost schilperoord.
2019.the grammar of emoji?
constraints on communica-tive pictorial sequencing.
cognitive research: prin-ciples and implications, 4(1):33..xin dong and gerard de melo.
2018. cross-lingualpropagation for deep sentiment analysis.
in proceed-ings of aaai 2018. aaai press..bjarke felbo, alan mislove, anders søgaard, iyad rah-wan, and sune lehmann.
2017. using millions ofemoji occurrences to learn any-domain representa-tions for detecting sentiment, emotion and sarcasm.
in proceedings of the 2017 conference on empiri-cal methods in natural language processing, pages1615–1625, copenhagen, denmark.
association forcomputational linguistics..thomas b. fitzpatrick.
1975..fitzpatrick scale -.
wikipedia..emojis have become an integral part of moderninterpersonal communication and text encounteredin chat messages, social media, or emails is oftenladen with emojis.
hence, it is important to endownlp tools with emoji support not only to obtain a.matt gardner, joel grus, mark neumann, oyvindtafjord, pradeep dasigi, nelson f. liu, matthew pe-ters, michael schmitz, and luke zettlemoyer.
2018.allennlp: a deep semantic natural language pro-cessing platform.
in proceedings of workshopfor nlp open source software (nlp-oss), pages.
peng qi, yuhao zhang, yuhui zhang, jason bolton,stanza: aand christopher d. manning.
2020.python natural language processing toolkit for manyhuman languages.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics: system demonstrations..radim řehůřek and petr sojka.
2010. software frame-work for topic modelling with large corpora.
inproceedings of the lrec 2010 workshop on newchallenges for nlp frameworks, pages 45–50, val-letta, malta.
elra..alexander robertson, walid magdy, and sharon gold-water.
2020. emoji skin tone modifiers: analyzingvariation in usage on social media.
trans.
soc.
com-put., 3(2)..abu awal md shoeb and gerard de melo.
2020. emo-tag1200: understanding the association betweenin proceedings of emnlpemojis and emotions.
2020..abu awal md shoeb, shahab raji, and gerard de melo.
2019. emotag – towards an emotion-based analy-sis of emojis.
in proceedings of ranlp 2019, pages1094–1103..t. weerasooriya, n. perera, and s. r. liyanage.
2016.a method to extract essential keywords from a tweetusing nlp tools.
in 2016 sixteenth internationalconference on advances in ict for emerging re-gions (icter), pages 29–34..rachel wolff.
2020.
10 natural language processing.
tools – saas & open-source..1–6, melbourne, australia.
association for compu-tational linguistics..alec go, richa bhayani, and lei huang.
2009. twit-ter sentiment classification using distant supervision.
cs224n project report, stanford, 1(12):2009..patrick g grosz, elsi kaiser, and francesco pierini.
2021. discourse anaphoricity and first-person index-icality in emoji resolution..clayton hutto and eric gilbert.
2014. vader: a par-simonious rule-based model for sentiment analysisof social media text.
in proceedings of the interna-tional aaai conference on web and social media,volume 8..akansha jain, ishita aggarwal, and ankit singh.
2019.paralleldots at semeval-2019 task 3: domain adap-tation with feature embeddings for contextual emo-tion analysis.
in proceedings of the 13th inter-national workshop on semantic evaluation, pages185–189, minneapolis, minnesota, usa.
associa-tion for computational linguistics..linda k. kaye, stephanie a. malone, and helen j. wall.
2017. emojis: insights, affordances, and possibili-ties for psychological science.
trends in cognitivesciences, 21(2):66 – 68..lingpeng kong, nathan.
schneider,.
swabhaswayamdipta, archna bhatia, chris dyer, andnoah a. smith.
2014. a dependency parser forin proceedings of the 2014 conferencetweets.
on empirical methods in natural language pro-cessing (emnlp), pages 1001–1012, doha, qatar.
association for computational linguistics..dominik kozaczko.
2018.
8 best python natural lan-.
guage processing (nlp) libraries..gretchen mcculloch.
2019. because internet: under-standing the new rules of language.
penguin pub-lishing group..petra kralj novak, jasmina smailović, borut sluban,and igor mozetič.
2015. sentiment of emojis.
plosone, 10(12)..olutobi owoputi, brendan o’connor, chris dyer,kevin gimpel, nathan schneider, and noah a.improved part-of-speech tagging forsmith.
2013.online conversational text with word clusters.
in pro-ceedings of the 2013 conference of the north amer-ican chapter of the association for computationallinguistics: human language technologies, pages380–390, atlanta, georgia.
association for compu-tational linguistics..thomas proisl.
2018. someweta: a part-of-speechintagger for german social media and web texts.
proceedings of the eleventh international confer-ence on language resources and evaluation (lrec2018)..