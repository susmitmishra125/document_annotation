exploring the efﬁcacy of automatically generated counterfactuals forsentiment analysislinyi yang 1,2,3,4, jiazheng li 2, p´adraig cunningham 2, yue zhang 3,4.barry smyth 1,2, ruihai dong 1,21 the insight centre for data analytics, university college dublin2 school of computer science, university college dublin3 school of engineering, westlake university4 institute of advanced technology, westlake institute for advanced study{linyi.yang, ruihai.dong, barry.smyth}@insight-centre.org{padraig.cunningham}@ucd.ie{jiazheng.li}@ucdconnect.ie{yue.zhang}@westlake.edu.cn.
abstract.
while state-of-the-art nlp models have beenachieving the excellent performance of a widerange of tasks in recent years, important ques-tions are being raised about their robustnessand their underlying sensitivity to systematicbiases that may exist in their training and testdata.
such issues come to be manifest in per-formance problems when faced with out-of-distribution data in the ﬁeld.
one recent so-lution has been to use counterfactually aug-mented datasets in order to reduce any relianceon spurious patterns that may exist in the orig-inal data.
producing high-quality augmenteddata can be costly and time-consuming as itusually needs to involve human feedback andcrowdsourcing efforts.
in this work, we pro-pose an alternative by describing and evalu-ating an approach to automatically generatingcounterfactual data for the purpose of data aug-mentation and explanation.
a comprehensiveevaluation on several different datasets and us-ing a variety of state-of-the-art benchmarksdemonstrate how our approach can achieve sig-niﬁcant improvements in model performancewhen compared to models training on the orig-inal data and even when compared to modelstrained with the beneﬁt of human-generatedaugmented data..1.introduction.
deep neural models have recently made remark-able advances on sentiment analysis (devlin et al.,2018; liu et al., 2019; yang et al., 2019; xie et al.,2020).
however, their implementation in practicalapplications still encounters signiﬁcant challenges.
of particular concern, these models tend to learn in-tended behavior that is often associated with spuri-ous patterns (artifacts) (jo and bengio, 2017; slack.
et al., 2020a).
as an example, in the sentence“nolan’s ﬁlms always shock people, thanks to hissuperb directing skills”, the most inﬂuential wordfor the prediction of a positive sentiment should be“superb” instead of “nolan” or “ﬁlm”.
the issue ofspurious patterns also partially affects the out-of-domain (ood) generalization of the models trainedon independent, identical distribution (iid) data,leading to performance decay under distributionshift (quionero-candela et al., 2009; sugiyamaand kawanabe, 2012; ovadia et al., 2019)..researchers have recently found that such con-cerns about model performance decay and socialbias in nlp come about out-of-domain becauseof a sensitivity to semantically spurious signals(gardner et al., 2020), and recent studies have un-covered a problematic tendency for gender bias insentiment analysis (zmigrod et al., 2019; maudslayet al., 2019; lu et al., 2020).
to this end, one ofthe possible solutions is data augmentation withcounterfactual examples (kaushik et al., 2020) toensure that models learn real causal associationsbetween the input text and labels.
for example,a sentiment-ﬂipped counterfactual of last exam-ple could be “nolan’s movies always bore peo-ple, thanks to his poor directorial skills.”.
whenadded to the original set of training data, such kindsof counterfactually augmented data (cad) haveshown their beneﬁts on learning real causal asso-ciations and improving the model robustness inrecent studies (kaushik et al., 2020, 2021; wangand culotta, 2021).
unlike gradient-based adver-sarial examples (wang and wan, 2019; zhang et al.,2019; zang et al., 2020), which cannot provide aclear boundary between positive and negative in-stances to humans, counterfactuals could provide“human-like” logic to show a modiﬁcation to the.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages306–316august1–6,2021.©2021associationforcomputationallinguistics306input that makes a difference to the output classiﬁ-cation (byrne, 2019)..recent attempts for generating counterfactualexamples (also known as minimal pairs) rely onhuman-in-the-loop systems.
kaushik et al.
(2020)proposed a human-in-the-loop method to generatecad by employing human annotators to generatesentiment-ﬂipped reviews.
the human labeler isasked to make minimal and faithful edits to producecounterfactual reviews.
similarly, srivastava et al.
(2020) presented a framework to leverage strongprior (human) knowledge to understand the possi-ble distribution shifts for a speciﬁc machine learn-ing task; they use human commonsense reasoningas a source of information to build a more robustmodel against spurious patterns.
although usefulfor reducing sensitivity to spurious correlations,collecting enough high-quality human annotationsis costly and time-consuming..the theory behind the ability of cad to improvemodel robustness in sentiment analysis is discussedby kaushik et al.
(2021), where researchers presenta theoretical characterization of the impact of noisein causal and non-causal features on model gener-alization.
however, methods for automatically gen-erating cad have received less attention.
the onlyexisting approach (wang and culotta, 2021) hasbeen tested on the logistic regression model only,despite the fact that recent state-of-the-art methodsfor sentiment classiﬁcation are driven by neuralmodels.
also, their automatically generated cadcannot produce competitive performance comparedto human-generated cad.
we believe that theirmethod does not sufﬁciently leverage the power ofpre-trained language models and fails to generateﬂuent and effective cad.
in addition, the relation-ships between out-of-domain generalization andsensitivity to spurious patterns were not explicitlyinvestigated by wang and culotta (2021)..to address these issues, we use four benchmarkdatasets (imdb movie reviews as hold-out testwhile amazon, yelp, and twitter datasets for out-of-domain generalization test) to further explorethe efﬁcacy of cad for sentiment analysis.
first,we conduct a systematic comparison of severaldifferent state-of-the-art models (wang and cu-lotta, 2021).
this reveals how large transformer-based models (vaswani et al., 2017) with largerparameter sizes may improve the resilience of ma-chine learning models.
speciﬁcally, we have foundthat for increasing parameter spaces, cad’s per-.
formance beneﬁt tends to decrease, regardless ofwhether cad is controlled manually or automat-ically.
second, we introduce a novel masked lan-guage model for helping improve the ﬂuency andgrammar correctness of the generated cad.
third,we add a ﬁne-tuned model as a discriminator forautomatically evaluating the edit-distance, usingdata generated with minimal and ﬂuent edits (samerequirements for human annotators in kaushik et al.
(2020)) to ensure the quality of generated counter-factuals.
experimental results show that it leads tosigniﬁcant prediction beneﬁts using both hold-outtests and generalization tests..to the best of our knowledge, we are the ﬁrst toautomatically generate counterfactuals for use asaugmented data to improve the robustness of neuralclassiﬁers, which can outperform existing, state-of-the-art, human-in-the-loop approaches.
we willrelease our code and datasets on github 1..2 related work.
this work mainly touches on three important ar-eas: approaches to evaluation that go beyond tradi-tional accuracy measures (bender and koller, 2020;warstadt et al., 2020), the importance of counterfac-tuals in explainable ai (xai) (byrne, 2019; keaneand smyth, 2020), and out-of-domain generaliza-tion in sentiment analysis (kim and hovy, 2004;zhang et al., 2018; zhang and zhang, 2019)..there has been an increasing interest in the roleof robustness causal thinking in ml, often byleveraging human feedback.
recently, some of thestandard benchmark datasets have been challenged(gardner et al., 2020; ribeiro et al., 2020), in whichthe model performance is signiﬁcantly lower oncontrast sets than on original test sets; a differenceof up to 25% in some cases.
researchers proposecounterfactual data augmentation approaches forbuilding robust models (maudslay et al., 2019; zmi-grod et al., 2019; lu et al., 2020), and ﬁnd thatspurious correlations threaten the model’s validityand reliability.
in an attempt to address this prob-lem, kaushik et al.
(2020) explore opportunitiesfor developing human-in-the-loop systems by us-ing crowd-sourcing to generate counterfactual datafrom original data, for data augmentation.
teneyet al.
(2020) shows the continuous effectiveness ofcad in computer vision (cv) and nlp..the idea of generating counterfactuals in xai.
1https://github.com/lijiazheng99/counterfactuals-for-.
sentiment-analysis.
307figure 1: overview of previous cad methods are shown on the left side, while the pipeline of our method is shownon the right.
hierarchical rm-ct (removing the casual terms) and hierarchical rep-ct (replacing the casualterms) are our methods for automatically generating cad, respectively.
scd denotes sampling and sensitivity ofcontextual decomposition.
sentiment dictionary refers to the opinion lexicon published by (hu and liu, 2004)..also shares important conceptual features with ourwork.
since human counterfactual explanations areminimal in the sense that they select a few relevantcauses (byrne, 2019; keane and smyth, 2020) as isthe requirement of minimal edits in our generationprocess.
this has been explored more in the ﬁeld ofcv (goyal et al., 2019; kenny and keane, 2021),but investigated less in nlp.
recent work (jacoviand goldberg, 2020) highlight explanations of agiven causal format, and yang et al.
(2020a) gener-ate counterfactuals for explaining the prediction ofﬁnancial text classiﬁcation.
we propose a similarbut different research question, that is, whether theautomatically generated counterfactual can be usedfor data augmentation to build more robust mod-els, which has not been considered by the previousmethods in xai (pedreschi et al., 2019; slack et al.,2020b; yang et al., 2020b; ding et al., 2020)..in the case of sentiment analysis, most of theprevious works report experiments using a hold-out test on the iid dataset (liu, 2012; yang et al.,2016; johnson and zhang, 2017).
the current state-of-the-art methods make use of large pre-trainedlanguage models (e.g., bert (devlin et al., 2018),roberta (liu et al., 2019) and smart-roberta(jiang et al., 2020)) for calculating input represnta-tions.
it has been shown that these methods cansuffer from spurious patterns (kaushik et al., 2020;wang and culotta, 2021).
very recently, wang andculotta (2021) provide a starting point for explor-ing the efﬁcacy of automatically generated cadfor sentiment analysis, but it is still based on iidhold-out tests only.
however, spurious patternsin the training and test sets could be tightly cou-pled, which may limit the possibility of observing.
their attendant accuracy issues using a hold-out testmethodology.
for this reason, we designed an indi-rect method for evaluating the robustness of models,by comparing the performance of models trained onoriginal and augmented data using out-of-domaindata.
the prediction beneﬁt for out-of-domain datashould provide some evidence about whether amodel’s sensitivity to spurious patterns has beensuccessfully mitigated.
the resulting counterfactu-als can be used for data augmentation and can alsoprovide contrastive explanations for classiﬁers, andimportant and desirable consideration for the re-cent move towards more xai (ribeiro et al., 2016;lundberg and lee, 2017; lipton, 2018; pedreschiet al., 2019; slack et al., 2020b)..3 detailed implementation.
we propose a new approach for automatically gen-erating counterfactuals to enhance the robustnessof sentiment analysis models by inverting the sen-timent of causally important terms according toalgorithm 1 and based on the following stages:.
1. the identiﬁcation of genuine causal terms us-ing self-supervised contextual decomposition(section 3.1)..2. generating counterfactual samples by (a) rm-ct (removing causal terms) and (b) rep-ct(replacing the causal terms) (section 3.2)..3. selecting the human-like counterfactuals us-ing moverscore.
(zhao et al., 2019) (section3.3)..the end result will be a set of counterfactuals.
that can be used to augment an existing dataset..308original datasetidentify causal terms with mlmclassifierssentiment dictionaryhierarchical rm-cthierarchical rep-ctmoverscoremoverscoreis used to control the minimal edits of the automatically generated counterfactualsclassifierscounterfactually augmented datasetoriginal datasetsampleddata pointshuman annotatorshuman-generatedcounterfactualsthe approved counterfactual is added to the original datasetour methodkaushik, hovy, and lipton (2020)wang and culotta(2021)original datasetidentify likely causal featuresreplace causal features with antonymsbased on pydictionaryoriginal datasetclassifierscounterfactually augmented datasetour methodsentiment dictionaryhierarchical rm-cthierarchical rep-ctidentify causal terms with scdmoverscoreclassifiersmoverscoreis used to control the minimal edits of the automatically generated cad.
3.1.identifying causal terms.
to identify causally important terms, we proposea hierarchical method, based on the sampling andsensitivity of contextual decomposition techniquefrom jin et al.
(2019), by incrementally remov-ing words from a sentence in order to evaluatethe model’s sensitivity to these words.
signiﬁcantchanges in model outputs suggest the removal ofimportant terms.
for example, removing the word“best” from “the movie is the best that i have everseen.”, is likely to alter a model’s sentiment predic-tion more than the removal of other words from thesentence; thus “best” is an important word withrespect to this sentence’s sentiment.
in a similarway, phrases beginning with negative pronouns willlikely be important; for instance, “not satisfy you”is important in “this movie could not satisfy you”.
given a word (or phrase starting with negativelimitations) w in the sentence s, the importance ofw can be calculated as in equation 1 where s β\pdenotes the sentence that resulting after maskingout a single word (or a negative phrase as above).
we use l (s β\p; (cid:98)s) to represent the model predic-tion after replacing the masked-out context, while(cid:98)sβ is a input sequence sampled from the input s. \pindicates the operation of masking out the phrase pin a input document d from the training set.
thespeciﬁc candidate causal terms found by this mask-ing operation vary for different prediction models..φ(w, (cid:98)s) = esβ.
(cid:20) l (s β; (cid:98)sβ) − l (s β\p; (cid:98)sβ)l (s β; (cid:98)sβ).
(cid:21).
(1).
3.2 generating human-like counterfactuals.
this approach and the scoring function in equation1 is used in algorithm 1 in two ways, to generatetwo types of plausible counterfactuals.
first, it isused to identify words to remove from a sentence toproduce a plausible counterfactual.
this is referredto as rm-ct and is performed by lines 3–5 in al-gorithm 1; for a sentence s(i), it’s correctly labeledsentiment words are identiﬁed (line 3), and sortedbased on equation 1 (line 4) with classiﬁer c, andthe most important of these words is removed froms(i) to produce s(i).
rm (line 5)..second, the rep-ct technique instead replaceseach causally important sentiment word in s(i)with an alternative word that has an opposing sen-timent polarity (lines 6-11 in algorithm 1).
to dothis the words in s(i) are each considered for re-placement in order of their importance (lines 6 & 7).
algorithm 1 generating plausible counterfactualinstances.
input: test document d(n)= {p1, p2, ..., pn}, with corre-sponding ground-truth labels y, pre-trained mask languagemodel mlm, ﬁne-tuned transformer classiﬁer c, positiveword dictionaries pos, negative word dictionaries neg.
(pos and neg are predicates for positive and negative labels)output: plausible counterfactual d(k)1: for pk in d(n) do2:3:.
(cid:98)s(i) ← (cid:8)w ∈ s(i) | (w ∈ p os ∧ yi = pos).
for s(i), yi in pk do.
cf = {d(k).
rep, d(k)rm}.
∨ (w ∈ n eg ∧ yi = neg)(cid:9).
(cid:98)s(i), key = φ(w, (cid:98)s(i))(cid:1)(eq.1).
sorted ← sort(cid:0)s(i)s(i)rm ← s(i)rep ← s(i)s(i)for w ∈ s(i).
sorted[1 :].
sortedrep dowp ← m lm (cid:0)s(i)mask(w), s(i)wc ← {w ∈ wp | (w ∈ p os ∧ yi!
=.
rep.(cid:1).
pos) ∨ (w ∈ n eg ∧ yi!
= neg)(cid:9).
rm + s(i)rmrep + s(i)rep.rm ← p (k)rep ← p (k).
rep(w) ← sort(cid:0)wc, key = φ(w, wc)(cid:1)[0]s(i)10:end for11:p (k)12:p (k)13:end for14:d(n)15:d(n)16:17: end for18: return d(n).
rm ← d(n)rep ← d(n).
rm + p (k)rmrep + p (k)rep.rm , d(n)rep.4:5:6:7:8:9:.
to create a new sentence s(i)rep. for each word w weuse a masked language model (mlm) to generatea set of plausible replacements, wp (line 8), anda subset of these, wc, as replacement candidatesif their sentiment is different from the sentimentof s(i), which is given by yi (line 9).
here we areusing the bert-base-uncased as the pre-trainedmlm for svm and bilstm models 1. the sizeof candidate substitutions found by mlm outputis set to 100 for all models.then, wc is sorted indescending order of importance using equation 1and the most important candidate is selected andused to replace w in s(i).
rep (line 10)..algorithm 1 continues in this fashion to gen-erate counterfactual sentences using rm-ct andrep-ct for each sentence in each paragraph ofthe target document 2. it returns two counterfac-tual documents, which correspond to documentsproduced from the rm-ct and rep-ct sentences;see lines 15–18..the above approach is not guaranteed to alwaysgenerate counterfactuals.
typically, reviews that.
1for transformers-based models, we use their own pre-.
trained mlm (e.g., roberta and xlnet) as the generator.
2generating one counterfactual edit for an imdb instancetakes an average of ≈ 3.4 seconds based on the roberta-large model..309cannot be transformed into plausible counterfac-tuals contain spurious associations that interferewith the model’s predictions.
for example, in ourmethod, the negative review “the ﬁlm is prettybad, and her performance is overacted” will beﬁrst modiﬁed as “the ﬁlm is pretty good, and herperformance is lifelike”.
the revised review’s pre-diction will remain negative.
meanwhile, the word“her” will be identiﬁed as a potential causal term.
toalleviate this problem, we further conduct the sub-stitution of synonyms for those instances that havebeen already modiﬁed with antonym substitutionby using causal terms.
as an example, we will con-tinue replacing the word “her” with “their” untilthe prediction has been ﬂipped; see also zmigrodet al.
(2019) for related ideas..in conclusion, then, the ﬁnal augmented datasetthat is produced of three parts: (1) counterfactualsgenerated by rm-ct; (2) counterfactuals generatedby rep-ct; (3) adversarial examples generated bysynonym substitutions..sst-2 imdbstate-of-the-art models97.5smart-roberta (jiang et al., 2020)roberta-large (liu et al., 2019)96.7rtc-attention (zhang and zhang, 2019) 90.386.7bi-lstm.
96.396.388.786.0.table 1: the performance of state-of-the-art models insentiment analysis..4.1.in-domain data.
we ﬁrst adopt two of the most popular benchmarkdatasets – sst-2 and imdb (maas et al., 2011) –to show the recent advances on sentiment analysiswith the beneﬁt of pre-trained models.
however,we mainly focus on the robustness of various mod-els for sentiment analysis in this work, rather thanin-domain accuracy.
hence, following wang andculotta (2021) and kaushik et al.
(2020), we per-form binary sentiment classiﬁcation experimentson the imdb dataset sampled from maas et al.
(2011) that contains 1707 training, 245 validation,and 488 testing examples with challenge dataset(paired counterfactuals)..3.3 ensuring minimal changes.
4.2 challenge data.
when generating plausible counterfactuals, it isdesirable to make minimal changes so that theresulting counterfactual is as similar as possibleto the original instance (miller, 2019; keane andsmyth, 2020).
to evaluate this for the approachdescribed we use the moverscore (zhao et al.,2019) – an edit-distance scoring metric originallydesigned for machine translation – which conﬁrmsthat the moverscore for the automatic cad in-stances is marginally higher when compared tohuman-generated counterfactuals, indicated greatersimilarity between counterfactuals and their orig-inal instances.
the moverscore between human-generated counterfactuals and original reviews is0.74 on average (minimum value of 0.55) and ouraugmented data results in a slightly higher averagescore than human-generated data for all models.
the generated counterfactuals and synonym sub-stitutions that achieve a moverscore above 0.55are combined with the original dataset for trainingrobust classiﬁers..4 datasets.
our evaluation uses three different kinds ofdatasets, in-domain data, challenge data, and out-of-domain data..based on the in-domain imdb data, kaushik et al.
(2020) employ crowd workers not to label docu-ments, but to revise movie review to reverse itssentiment, without making any gratuitous changes.
we directly use human-generated counterfactualsby kaushik et al.
(2020) as our challenge data, en-forcing a 50:50 class balance..4.3 out-of-domain data.
we also evaluate our method on different out-of-domain datasets, including amazon reviews (niet al., 2019) from six genres: beauty, fashion, ap-pliances, gift cards, magazines, and software, ayelp review dataset, and the semeval-2017 twitterdataset (rosenthal et al., 2017).
these have allbeen sampled to provide a 50:50 label split.
thesize of the training data has been kept the same forall methods, and the results reported are the aver-age from ﬁve runs to facilitate a direct comparisonwith baselines (kaushik et al., 2020, 2021)..5 results and discussions.
we ﬁrst describe the performance of the cur-rent state-of-the-art methods on sentiment analysisbased on the sst-2 and imdb benchmark datasets.
next, we will discuss the performance beneﬁts byusing our automatically generated counterfactuals.
310models.
parameter.
-svm(tf-idf)bi-lstm0.2mtransformer-based models110mbert [iclr,2021]335mwwm-bert-large340mxlnet-large355mroberta-large.
training / testing datao/o cf/o cf/cf o/cf c/o ac/o c/cf ac/cf80.079.3.ac: (our method).
84.882.2.
83.781.5.
87.392.0.
91.289.1.
58.362.5.
86.188.5.
51.055.7.
87.491.295.393.4.
80.486.990.891.6.
90.896.998.096.9.
82.293.093.993.0.
88.591.093.993.6.
90.691.894.994.1.
95.195.396.996.7.
92.294.195.594.3.table 2: the accuracy of various models for sentiment analysis using different datasets, including the human-generated counterfactual data and counterfactual samples generated by our pipeline.
o denotes the original imdbreview dataset, cf represents the human-revised counterfactual samples, c denotes the combined dataset con-sisting of original and human-revised dataset, and ac denotes the original dataset combined with automaticallygenerated counterfactuals.
c and ac contain the same size of training samples (3.4k)..original samples.
nolan’s ﬁlm...superbdirecting skills (pos).
it’s a poor ﬁlm, but imust give it to the leadactress in this one (neg).
originalsuperb:0.213ﬁlm:0.446nolan:0.028poor:-0.551ﬁlm:-0.257actress:-0.02.robust0.6270.0190.029-0.999-7e-7-1e-6.
table 3: less sensitivity to spurious patterns has beenshown in the robust bert-base-uncased model..on an in-domain test.
we further compare ourmethod, human-label method, and two state-of-the-art style-transfer methods (sudhakar et al., 2019;madaan et al., 2020) in terms of the model robust-ness on generalization test.
notably, we providean ablation study lastly to discuss the inﬂuence ofedit-distance for performance beneﬁts..5.1 state-of-the-art models.
as the human-generated counterfactuals (kaushiket al., 2020) are sampled from maas et al.
(2011),the results in table 1 cannot be directly comparedwith table 2 3. as shown in table 1, by comparingbilstm to transformer-base methods, it can beseen that remarkable advances in sentiment analy-sis have been achieved in recent years.
on sst-2,smart-roberta (jiang et al., 2020) outperformsbi-lstm by 10.8% (97.5% vs. 86.7%) accuracy,where a similar improvement is observed on imdb(96.3% vs. 86.0%)..according to the results, we select the followingmodels for our experiments, which covers a spec-trum of statistical, neural and pre-trained neuralmethods: svm (suykens and vandewalle, 1999),bi-lstm (graves and schmidhuber, 2005), bert-base (devlin et al., 2018), roberta-large (liuet al., 2019), and xlnet-large (yang et al., 2019)..the svm model for sentiment analysis is fromscikit-learn and uses tf-idf (term frequency-inverse document frequency) scores, while thetransformer-based models are built based on thepytorch-transformer package 4. we keep the pre-diction models the same as kaushik et al.
(2020),except for naive bayes, which has been abandoneddue to its high-variance performance shown in ourexperiments..in the following experiments, we only care aboutwhether the robustness of models has been im-proved when training on the augmented dataset(original data & cad).
different counterfactual ex-amples have been generated for different models interms of their own causal terms in practice, whilethe hyper-parameters for different prediction mod-els are all identiﬁed using a grid search conductedover the validation set..5.2 comparison with original data.
on the inﬂuence of spurious patterns.
asshown in table 2, we ﬁnd thatthe linearmodel (svm) trained on the original and chal-lenge (human-generated counterfactuals) data canachieve 80% and 91.2% accuracy testing on theiid hold-out data, respectively.
however, the ac-curacy of the svm model trained on the originalset when testing on the challenge data drops dra-matically (91.2% vs. 51%), and vice versa (80%vs. 58.3%).
similar ﬁndings were reported bykaushik et al.
(2020), where a similar pattern wasobserved in the bi-lstm model and bert-basemodel.
this provides further evidence supportingthe idea that the spurious association in machinelearning models is harmful to the performance onthe challenge set for sentiment analysis..3we can only get the human-generated counterfactual ex-amples (kaushik et al., 2020) sampled from the imdb dataset..4https://github.com/huggingface/.
pytorch-transformers.
311on the beneﬁts of robust bert.
as shownin table 3, we also test whether the sensitivity tospurious patterns has been eliminated in the robustbert model.
we notice that the correlations of thereal causal association “superb” and “poor” areimproved from 0.213 to 0.627 and -0.551 to -0.999,respectively.
while the correlation of spurious as-sociation “ﬁlm” is decreased from 0.446 to 0.019and -0.257 to -7e-7 on positive and the negativesamples, respectively.
this shows that the modeltrained with our cad data does provide robustnessagainst spurious patterns..on the inﬂuence of model size.
previousworks (kaushik et al., 2021; wang and culotta,2021) have not investigated the performance bene-ﬁts on larger pre-trained models.
while we furtherconduct experiments on various transformer-basedmodels with different parameter sizes to explorewhether the larger transformer-based models canstill enjoy the performance beneﬁts of cad (table2).
we observe that although the test result canincrease with the parameter size increasing (bestfor 94.9% using xlnet), the performance beneﬁtsbrought by human-generated cad and the auto-generated cad declines continuously with the pa-rameter size increase.
for example, the bert-base-uncased model trained on the auto-generated com-bined dataset can receive 3.2% (90.6% vs. 87.4%)improvement on accuracy while performance in-creases only 0.6% (91.8% vs. 91.2%) on accuracyfor wwm-bert-large.
it suggests that larger pre-trained transformer models may be less sensitiveto spurious patterns..5.3 comparison with human cad.
robustness in the in-domain test.
we can seethat all of the models trained on automatic cad– shown as ac in the table 2 – can outperformthe human-generated cad varying with the mod-els (ac/o vs. c/o) as follows: svm (+1.1%),bi-lstm (+0.7%), bert-base-uncased (+2.1%),bert-large (+0.8%), xlnet-large (+1.0%), androberta-large (+0.5%) when testing on the orig-inal data.
if we adopt the automatic cad (ac), wenote a distinct improvement in table 2 across allmodels trained on the challenge data in terms of11.3% in average (ac/o vs. cf/o), whereas thehuman-generated cad can achieve 10.2% accu-racy improvement (c/o vs. cf/o) in average.
itis noteworthy that the human-generated cad canslightly outperform our method when testing on the.
out-of-domain test usingdifferent training data.
svm bert.
orig & cad (our method) (3.4k)orig & cad (by human) (3.4k)orig.
& (sudhakar et al., 2019)orig.
& (madaan et al., 2020)orig.
(3.4k).
accuracy on amazon reviews78.679.364.074.374.5.
84.783.377.271.380.0accuracy on semeval 2017 task b (twitter)83.882.872.579.372.6.orig & cad (our method) (3.4k)orig & cad (by human) (3.4k)orig.
& (sudhakar et al., 2019)orig.
& (madaan et al., 2020)orig.
(3.4k).
69.766.859.462.863.1.accuracy on yelp reviews.
orig & cad (our method) (3.4k)orig & cad (by human) (3.4k)orig.
& (sudhakar et al., 2019)orig.
& (madaan et al., 2020)orig.
(3.4k).
85.585.669.481.381.9.
87.986.684.578.884.3.table 4: out-of-domain test accuracy of svm andbert-base-uncased models trained on the original(orig.)
imdb review only, counterfactually aug-mented data (cad) combining with original data, andsentiment-ﬂipped style-transfer examples..human-generated (cf) data, it may be because thetraining and test sets of the human-generated (cf)data are generated by the same group of labelers..robustness in the generalization test.
we ex-plore how our approach makes prediction modelsmore robust out-of-domain in table 4. for directcomparison between our method and the human-generated method, we adopt the ﬁne-tuned bert-base model trained with the augmented dataset(original & automatically revised data).
the ﬁne-tuned model is directly tested for out-of-domaindata without any adjustment.
as shown in table 4,only our method and the human-label method canoutperform the bert model trained on the originaldata with average 6.5% and 5.3% accuracy im-provements, respectively.
our method also offersperformance beneﬁts over three datasets even whencompared to the human-label method on bert..neural method vs. statistical method.
asshown in table 4, the performance of the svmmodel with automatic cad is more robust thanother automated methods (sudhakar et al., 2019;madaan et al., 2020) across all datasets.
however,the human-labeled cad can improve amazon re-views’ accuracy compared to our method usingthe svm model by 0.7%.
it indicates that human-generated data may lead to more performance ben-eﬁts on a statistical model..312types of algorithms.
hierarchical rm-ct:remove negative limitations.
hierarchical re-ct:replacing the causal terms.
combined method:.
examplesori: some ﬁlms just simply should not be remade.
this is one of them.
in and ofitself it is not a bad ﬁlm.
rev: some ﬁlms just simply should be remade.
this is one of them.
in and of itself itis a bad ﬁlm.
ori: it is badly directed, badly acted and boring.
rev: it is well directed, well acted and entertaining.
ori: this movie is so bad, it can only be compared to the all-time worst “comedy”:police academy 7. no laughs throughout the movie.
rev: this movie is so good, it can only be compared to the all-time best “comedy”:police academy 7. laughs throughout the movie..table 5: most prominent categories of edits for ﬂipping the sentiment performed by our algorithms, namely hier-archical rm-ct and hierarchical rep-ct..5.4 comparison with automatic methods.
automatic cad vs. style-transfer methods.
asshown in table 4, the style-transfer results areconsistent with kaushik et al.
(2021).
we ﬁndthat the sentiment-ﬂipped instances generated bystyle-transfer methods degrade the test accuracyfor all models on all kinds of datasets, whereasour method has achieved the best performance forall settings.
it suggests that our method have itsabsolute advantage for data augmentation in senti-ment analysis when compared to the state-of-the-art style-transfer models..our methods vs. implausible cad.
the au-thors of the only existing approach for automati-cally generating cad (wang and culotta, 2021)report that their methods are not able to match theperformance of human-generated cad.
our meth-ods consistently outperform human-labeled meth-ods on both in-domain and out-of-domain tests.
to further provide quantitative evidence of the in-ﬂuence of the edit-distance in automatic cad, wedemonstrate an ablation study in table 6. the re-sult shows that the quality of the generated cad,which is ignored in the previous work wang andculotta (2021), is crucial when training the robustin particular, the bert model ﬁne-classiﬁers.
tuned with implausible cad (below the threshold)can receive comparable negative results with thestyle-transfer samples, alongside the performancedecrease on all datasets, except for twitter..5.5 case study and limitations.
the three most popular kinds of edits are shownin table 5. these are, negation words removal,sentiment words replacement, and the combinationof these.
it can be observed from these examplesthat we ensure the edits on original samples shouldbe minimal and ﬂuent as was required previouslywith human-annotated counterfactuals (kaushik.
imdb out-of-domain testtraining databert-base-uncasedorig.
orig.
& cad ↑ (3.4k) 90.6orig.
& cad ↓ (3.4k) 87.187.4orig.
(1.7k).
amazon twitter yelp87.983.884.779.073.879.584.372.680.0.table 6: ablation study on the inﬂuence of the edit-distance controlled by the threshold of moverscore.
↑indicates the cad (1.7k) above the threshold, while ↓denotes the cad (1.7k) below the threshold..et al., 2020).
as shown in table 5, we ﬂipped themodel’s prediction by replacing the causal terms inthe phrase “badly directed, badly acted and boring”to “well directed, well acted and entertaining”, orremoving “no laughs throughout the movie.” to“laughs throughout the movie” for a movie review.
we also noticed that our method may face thechallenge when handling more complex reviews.
for example, the sentence “watch this only if some-one has a gun to your head ... maybe.” is an ap-parent negative review for a human.
however, ouralgorithm is hard to ﬂip the sentiment of such re-views with no explicit casual terms.
the techniqueon sarcasm and irony detection may have beneﬁtsfor dealing with this challenge..6 conclusion.
we proposed a new framework to automaticallygenerate counterfactual augmented data (cad) forenhancing the robustness of sentiment analysismodels.
by combining the automatically generatedcad with the original training data, we can pro-duce more robust classiﬁers.
we further show thatour methods can achieve better performance evenwhen compared to models trained with human-generated counterfactuals.
more importantly, ourevaluation based on several datasets has demon-strated that models trained on the augmented data(original & automatic cad) appear to be less af-.
313fected by spurious patterns and generalize betterto out-of-domain data.
this suggests there existsa signiﬁcant opportunity to explore the use of thecad in a range of tasks (e.g., natural language in-ference, natural language understanding, and socialbias correction.)..
matt gardner, yoav artzi, victoria basmov, jonathanberant, ben bogin, sihao chen, pradeep dasigi,dheeru dua, yanai elazar, ananth gottumukkala,et al.
2020.evaluating models’ local decisionboundaries via contrast sets.
in proceedings of the2020 conference on empirical methods in naturallanguage processing: findings, pages 1307–1323..impact statement.
although the experiments in this paper are con-ducted only in the sentiment classiﬁcation task,this study could be a good starting point to investi-gate the efﬁcacy of automatically generated cadfor building robust systems in many nlp tasks, in-cluding natural language inference (nli), namedentity recognition (ner), question answering(qa) system, etc..acknowledgment.
we would like to thank eoin kenny and prof. markkeane from insight centre for their helpful adviceand discussion during this work.
also, we wouldlike to thank the anonymous reviewers for theirinsightful comments and suggestions to help im-prove the paper.
this publication has emanatedfrom research conducted with the ﬁnancial supportof science foundation ireland under grant number12/rc/2289 p2..references.
emily m. bender and alexander koller.
2020. climb-ing towards nlu: on meaning, form, and under-in proceedings of thestanding in the age of data.
58th annual meeting of the association for compu-tational linguistics, pages 5185–5198, online.
as-sociation for computational linguistics..ruth mj byrne.
2019. counterfactuals in explain-able artiﬁcial intelligence (xai): evidence from hu-in proceedings of the 28th inter-man reasoning.
national joint conference on artiﬁcial intelligence,pages 6276–6282.
aaai press..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training of deepbidirectional transformers for language understand-ing.
arxiv preprint arxiv:1810.04805..xiao ding, dingkui hao, yuewei zhang, kuo liao,zhongyang li, bing qin, and ting liu.
2020. hit-scir at semeval-2020 task 5: training pre-trainedlanguage model with pseudo-labeling data for coun-in proceedings of the four-terfactuals detection.
teenth workshop on semantic evaluation, pages354–360, barcelona (online).
international commit-tee for computational linguistics..yash goyal, ziyan wu, jan ernst, dhruv batra, deviparikh, and stefan lee.
2019. counterfactual visualexplanations.
in icml..alex graves and j¨urgen schmidhuber.
2005. frame-wise phoneme classiﬁcation with bidirectional lstmand other neural network architectures.
neural net-works, 18(5-6):602–610..minqing hu and bing liu.
2004. mining and summa-rizing customer reviews.
in proceedings of the tenthacm sigkdd international conference on knowl-edge discovery and data mining, pages 168–177..alon jacovi and yoav goldberg.
2020. aligning faith-ful interpretations with their social attribution.
arxivpreprint arxiv:2006.01067..haoming jiang, pengcheng he, weizhu chen, xi-aodong liu, jianfeng gao, and tuo zhao.
2020.smart: robust and efﬁcient ﬁne-tuning for pre-trained natural language models through principledregularized optimization.
in proceedings of the 58thannual meeting of the association for computa-tional linguistics, pages 2177–2190, online.
asso-ciation for computational linguistics..xisen jin, zhongyu wei, junyi du, xiangyang xue,and xiang ren.
2019. towards hierarchical impor-tance attribution: explaining compositional seman-in internationaltics for neural sequence models.
conference on learning representations..jason jo and yoshua bengio.
2017. measuring the ten-dency of cnns to learn surface statistical regularities.
arxiv preprint arxiv:1711.11561..rie johnson and tong zhang.
2017. deep pyramidconvolutional neural networks for text categoriza-tion.
in proceedings of the 55th annual meeting ofthe association for computational linguistics (vol-ume 1: long papers), pages 562–570..divyansh kaushik, eduard hovy, and zachary lipton.
2020. learning the difference that makes a differ-ence with counterfactually-augmented data.
in inter-national conference on learning representations..divyansh kaushik, amrith setlur, eduard hovy, andzachary c lipton.
2021. explaining the efﬁcacy ofin internationalcounterfactually augmented data.
conference on learning representations..mark t keane and barry smyth.
2020. good counter-factuals and where to ﬁnd them: a case-based tech-nique for generating counterfactuals for explainableai (xai).
in international conference on case-basedreasoning (iccbr)..314eoin m kenny and mark t keane.
2021. on generat-ing plausible counterfactual and semi-factual expla-nations for deep learning.
in aaai..soo-min kim and eduard hovy.
2004. determiningthe sentiment of opinions.
in coling 2004: pro-ceedings of the 20th international conference oncomputational linguistics, pages 1367–1373..zachary c lipton.
2018. the mythos of model inter-.
pretability.
queue, 16(3):31–57..bing liu.
2012. sentiment analysis and opinion min-ing.
synthesis lectures on human language technolo-gies, 5(1):1–167..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
arxiv preprint arxiv:1907.11692..kaiji lu, piotr mardziel, fangjing wu, preetam aman-charla, and anupam datta.
2020. gender bias inneural natural language processing.
in logic, lan-guage, and security, pages 189–202.
springer..scott m lundberg and su-in lee.
2017. a uniﬁedin ad-approach to interpreting model predictions.
vances in neural information processing systems,pages 4765–4774..andrew l. maas, raymond e. daly, peter t. pham,dan huang, andrew y. ng, and christopher potts.
2011. learning word vectors for sentiment analy-sis.
in proceedings of the 49th annual meeting ofthe association for computational linguistics: hu-man language technologies, pages 142–150, port-land, oregon, usa.
association for computationallinguistics..aman madaan, amrith setlur, tanmay parekh, barn-abas poczos, graham neubig, yiming yang, ruslansalakhutdinov, alan w black, and shrimai prabhu-moye.
2020. politeness transfer: a tag and generateapproach.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,pages 1869–1881, online.
association for computa-tional linguistics..rowan hall maudslay, hila gonen, ryan cotterell,and simone teufel.
2019. it’s all in the name: mit-igating gender bias with name-based counterfactualdata substitution.
in proceedings of the 2019 con-ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 5270–5278..tim miller.
2019. explanation in artiﬁcial intelligence:insights from the social sciences.
artiﬁcial intelli-gence, 267:1–38..jianmo ni, jiacheng li, and julian mcauley.
2019.justifying recommendations using distantly-labeledreviews and ﬁne-grained aspects.
in proceedings of.
the 2019 conference on empirical methods in nat-ural language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 188–197..yaniv ovadia, emily fertig, jie ren, zachary nado,david sculley, sebastian nowozin, joshua dillon,balaji lakshminarayanan, and jasper snoek.
2019.can you trust your model’s uncertainty?
evaluatingin ad-predictive uncertainty under dataset shift.
vances in neural information processing systems,pages 13991–14002..dino pedreschi, fosca giannotti, riccardo guidotti,anna monreale, salvatore ruggieri, and francoturini.
2019. meaningful explanations of black boxin proceedings of the aaaiai decision systems.
conference on artiﬁcial intelligence, volume 33,pages 9780–9784..joaquin quionero-candela, masashi sugiyama, antonschwaighofer, and neil d lawrence.
2009. datasetshift in machine learning.
the mit press..marco tulio ribeiro, sameer singh, and carlosguestrin.
2016.
” why should i trust you?” explain-in proceed-ing the predictions of any classiﬁer.
ings of the 22nd acm sigkdd international con-ference on knowledge discovery and data mining,pages 1135–1144..marco tulio ribeiro, tongshuang wu, carlos guestrin,and sameer singh.
2020. beyond accuracy: be-havioral testing of nlp models with checklist.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4902–4912, online.
association for computational lin-guistics..sara rosenthal, noura farra, and preslav nakov.
2017.semeval-2017 task 4: sentiment analysis in twitter.
in proceedings of the 11th international workshopon semantic evaluation (semeval-2017), pages 502–518..dylan slack, sophie hilgard, emily jia, sameer singh,and himabindu lakkaraju.
2020a.
fooling lime andshap: adversarial attacks on post hoc explanationmethods.
in proceedings of the aaai/acm confer-ence on ai, ethics, and society, pages 180–186..dylan slack, sophie hilgard, sameer singh, andhimabindu lakkaraju.
2020b.
how much should itrust you?
modeling uncertainty of black box expla-nations.
arxiv preprint arxiv:2008.05030..megha srivastava, tatsunori hashimoto, and percyliang.
2020. robustness to spurious correlations viahuman annotations.
in international conference onmachine learning, pages 9109–9119.
pmlr..akhilesh sudhakar, bhargav upadhyay, and arjun ma-“transforming” delete, retrieve,heswaran.
2019.generate approach for controlled text style transfer.
in proceedings of the 2019 conference on empiricalmethods in natural language processing and the.
3159th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 3260–3270..american chapter of the association for computa-tional linguistics: human language technologies,pages 1480–1489..masashi sugiyama and motoaki kawanabe.
2012. ma-chine learning in non-stationary environments: in-troduction to covariate shift adaptation.
mit press..johan ak suykens and joos vandewalle.
1999. leastsquares support vector machine classiﬁers.
neuralprocessing letters, 9(3):293–300..damien teney, ehsan abbasnedjad, and anton van denhengel.
2020. learning what makes a differencefrom counterfactual examples and gradient supervi-sion.
arxiv preprint arxiv:2004.09034..yuan zang, fanchao qi, chenghao yang, zhiyuan liu,meng zhang, qun liu, and maosong sun.
2020.word-level textual adversarial attacking as combina-torial optimization.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 6066–6080..huangzhao zhang, hao zhou, ning miao, and lei li.
2019. generating ﬂuent adversarial examples forin proceedings of the 57th an-natural languages.
nual meeting of the association for computationallinguistics, pages 5564–5569..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in nips..yuan zhang and yue zhang.
2019. tree communica-tion models for sentiment analysis.
in proceedingsof the 57th annual meeting of the association forcomputational linguistics, pages 3518–3527..yue zhang, qi liu, and linfeng song.
2018. sentence-in proceedingsstate lstm for text representation.
of the 56th annual meeting of the association forcomputational linguistics (volume 1: long papers),pages 317–327..wei zhao, maxime peyrard, fei liu, yang gao, chris-tian m meyer, and steffen eger.
2019. moverscore:text generation evaluating with contextualized em-beddings and earth mover distance.
in proceedingsof the 2019 conference on empirical methods innatural language processing and the 9th interna-tional joint conference on natural language pro-cessing (emnlp-ijcnlp), pages 563–578..ran zmigrod, sebastian j mielke, hanna wallach, andryan cotterell.
2019. counterfactual data augmen-tation for mitigating gender stereotypes in languagesin proceedings of the 57thwith rich morphology.
annual meeting of the association for computa-tional linguistics, pages 1651–1661..ke wang and xiaojun wan.
2019. automatic genera-tion of sentimental texts via mixture adversarial net-works.
artiﬁcial intelligence, 275:540–558..zhao wang and aron culotta.
2021. robustness to spu-rious correlations in text classiﬁcation via automati-cally generated counterfactuals.
in aaai..alex warstadt, alicia parrish, haokun liu, anhad mo-hananey, wei peng, sheng-fu wang, and samuel rbowman.
2020. blimp: the benchmark of linguis-tic minimal pairs for english.
transactions of the as-sociation for computational linguistics, 8:377–392..qizhe xie, zihang dai, eduard hovy, thang luong,and quoc le.
2020. unsupervised data augmenta-tion for consistency training.
advances in neuralinformation processing systems, 33..linyi yang, eoin kenny, tin lok james ng, yi yang,barry smyth, and ruihai dong.
2020a.
generatingplausible counterfactual explanations for deep trans-formers in ﬁnancial text classiﬁcation.
in proceed-ings of the 28th international conference on com-putational linguistics, pages 6150–6160..xiaoyu yang, stephen obadinma, huasha zhao, qiongzhang, stan matwin, and xiaodan zhu.
2020b.
semeval-2020 task 5: counterfactual recognition.
in proceedings of the fourteenth workshop on se-mantic evaluation, pages 322–335, barcelona (on-line).
international committee for computationallinguistics..zhilin yang, zihang dai, yiming yang, jaime car-bonell, russ r salakhutdinov, and quoc v le.
2019.xlnet: generalized autoregressive pretraining forlanguage understanding.
in advances in neural in-formation processing systems, pages 5753–5763..zichao yang, diyi yang, chris dyer, xiaodong he,alex smola, and eduard hovy.
2016. hierarchi-cal attention networks for document classiﬁcation.
in proceedings of the 2016 conference of the north.
316