towards argument mining for social good:a survey.
eva maria vecchi, neele falk, iman jundi and gabriella lapesainstitute for natural language processinguniversity of stuttgart (germany)first[-middle].last@ims.uni-stuttgart.de.
abstract.
this survey builds an interdisciplinary pictureof argument mining (am), with a strong fo-cus on its potential to address issues related tosocial and political science.
more speciﬁcally,we focus on am challenges related to its ap-plications to social media and in the multilin-gual domain, and then proceed to the widelydebated notion of argument quality.
we pro-pose a novel deﬁnition of argument qualitywhich is integrated with that of deliberativequality from the social science literature.
un-der our deﬁnition, the quality of a contribu-tion needs to be assessed at multiple levels:the contribution itself, its preceding context,and the consequential effect on the develop-ment of the upcoming discourse.
the latterhas not received the deserved attention withinthe community.
we ﬁnally deﬁne an applica-tion of am for social good: (semi-)automaticmoderation, a highly integrative applicationwhich (a) represents a challenging testbed forthe integrated notion of quality we advocate,(b) allows the empirical quantiﬁcation of argu-ment/deliberative quality to beneﬁt from thedevelopments in other nlp ﬁelds (i.e.
hatespeech detection, fact checking, debiasing),and (c) has a clearly beneﬁcial potential at thelevel of its societal thanks to its real-world ap-plication (even if extremely ambitious)..1.introduction.
considering argument mining (am) for socialgood implies a strong conceptual shift: the dis-course exchange is not to be interpreted as a com-petition to be won by the most persuasive contribu-tion1, but rather as a cooperative endeavor in which.
1in this paper, we use the term ”contribution” to refer to aturn in a discourse exchange; more concretely a contributionis a textual unit in a discourse contex, e.g., a post in a forum,a tweet in a discussion thread; a speech in a parliamentarydebate)..each individual contribution represents a move to-wards a shared goal.
if argumentative discourse iscooperation, it is not to be taken for granted that theperfect debater, most often the primary objectivein am research, is necessarily also the best teamplayer..building on this assumption, we review recentdevelopments in the ﬁeld of am from the perspec-tive of its application in socially relevant contexts.
our survey has a strong interdisciplinary perspec-tive, putting the focus on the collaboration betweennlp and the social sciences and, more speciﬁ-cally, in argumentation targeted at decision-making(deliberation).
deliberative discourse historicallycharacterizes parliamentary debates; however, itpervades, more and more frequently, discussionsin digital democracy forums and, beyond that, spe-ciﬁc strands of discussions in “generalistic” socialmedia.
looking at argumentation through the lensof deliberation has a 2-fold beneﬁt.
from a purelynlp perspective, the insights gained through mod-eling deliberative features can in turn be employedin applications targeting discourse in deliberativeforums and social media more broadly, allowingsystems to be more adaptable to real-world dis-course settings.
social sciences, in turn, can enor-mously beneﬁt from the possibility of scaling up toa larger public with the support of nlp methods..the novelty of this survey with respect to litera-ture (cabrio and villata, 2018; lawrence and reed,2019) is precisely in its interdisciplinary focus,which leads us to a novel formulation of the widelydebated notion of argument quality (wachsmuthet al., 2017a,b), which we put in direct comparisonto deliberative quality (b¨achtiger and parkinson,2019).
the take-home message of this comparisonis that the quality of a contribution to an argumentcannot only be quantiﬁed in terms of its textual(linguistic/logical) properties and the relation tothe preceding contributions (as commonly done.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1338–1352august1–6,2021.©2021associationforcomputationallinguistics1338in argument quality), but also the relation to the“cooperation challenge” needs to be brought in thepicture.
in other words, a good contribution is onethat ensures the discourse to unfold productively.2we conclude the survey by deﬁning the concep-tual coordinates and the practical challenges of(semi-)automatic moderation, a highly integrativeapplication of am for social good which repre-sents a natural testbed for the integrated deﬁnitionof quality discussed above.
we propose to imple-ment moderation as a form of discourse optimiza-tion, and spell out the objective of such optimiza-tion – that is to say, the desiderata for an nlp-basedmoderator.
we discuss the concrete challenges re-lated to the tasks of an nlp moderator, and re-view existing work that, albeit not targeted at nlpmoderation directly, can be brought in as part of apuzzle which is both ambitious and worthwhile topursue..2 argument mining.
argument(ation) mining (am) is a ﬁeld encom-passing varying tasks that deal with the automatedanalysis of arguments from natural language text.
habernal and gurevych (2017) deﬁnes am as “thegeneral task of analyzing discourse on the prag-matics level and applying a certain argumentationtheory to model and automatically analyze the dataat hand”.
the progress in the ﬁeld of nlp in re-cent years has also inﬂuenced this research area:automatic recognition and identiﬁcation of argu-ments has been enabled in various domains anddifferent models for the analysis and representationof argumentative structure have been developed.
furthermore, there is a growing research interest inother aspects of am, such as argument quality..2.1 framework.
cabrio and villata (2018) provide an elaborateoverview of the am framework in their data-drivenanalysis of the state of the art after ﬁve years ofsigniﬁcant developments in the ﬁeld of am.
gen-erally speaking, given a collection of natural lan-guage texts, the task at hand is implemented in twostages:.
argument extraction the system ﬁrst identiﬁesthe documents which contain the argumentativestructure and the speciﬁc textual spans in which.
2the productive quality of a contribution can be deﬁned inrelation to social sciences literature (steenbergen et al., 2003;steiner et al., 2005), c.f.
section 3.argumentation is encoded.
once the textual bound-aries are deﬁned, subportions of the argumenta-tive spans are assigned to a set of pre-establishedargument components (e.g.
claims, premises, re-buttal, etc.).
a variety of models were used forthis including n¨aive bayes (moens et al., 2007),svms (mochales and moens, 2011), rnns (nicu-lae et al., 2017; eger et al., 2017), pre-trained lan-guage models (chakrabarty et al., 2019; luginiand litman, 2020), and other supervised–learningtechniques (ein-dor et al., 2020)..relation assignment the goal of the secondstage is to model the relations between the argu-mentative spans identiﬁed in the ﬁrst stage.
theserelations can exist between different arguments(support, attack) as well as within an argument(connecting the premises with the claim).
recentapproaches to argumentative relation classiﬁcationinvestigate for example relational models (traut-mann et al., 2020) or inject background knowledgeby leveraging features from different knowledgebases (kobbe et al., 2019).
detecting these rela-tions is necessary to model the overall structureof the argumentation (discourse/debate).
as thisstructure can be complex, the task is difﬁcult, in-volving high-level knowledge representation andreasoning issues.
after the relations are detected,the discourse structure can then be mapped to agraph representation, called argumentation graph,with the arguments as nodes and relations as edges.
to simplify the problem, some approaches re-duce the graph to a tree-structure representation(peldszus and stede, 2015; stab and gurevych,2017).
different methods to generate the structurehave been investigated, e.g.
svms (habernal andgurevych, 2017; niculae et al., 2017) or textualentailment (cabrio and villata, 2013; cocarascuet al., 2020).
modeling the relations and argumen-tation ﬂow within a debate is an important fac-tor when deﬁning the notion of argument quality,which will be presented in section 3..consider the following example taken froman online debate about compulsory vaccinations3which demonstrates the framework quite clearly.
given a statement presenting background and con-text, participants are asked to discuss the ques-tion “does public health demand vaccinations?”(claims are in bold, and premises are underlined.).
3http://debatepedia.idebate.org/en/index.php/debate:_compulsory_vaccination.
1339a1: a vaccine is the best way to prevent an outbreak ofa disease or to reduce its negative effects.
vaccinatedpeople become immune to a certain pathogen and do not.
develop a disease.
although there are occasionally side.
effects, these affect only a tiny number of people compared.
to the protection offered to the vast majority.
a2: many vaccines have serious and sometimes deadlyside effects.
with many vaccines the immunity is not life-long.
sometimes the vaccines itself can cause a serious.
disease to develop as a side effect.
if governments know.
that compulsory mass vaccination is likely to cause death.
or permanent disability in even a few cases, it is immoral.
for them to make it compulsory..here, the argumentative text boundaries areﬁrst determined from the natural language discus-sion and the argument components (claims andpremises) are extracted.
then, the relations be-tween the two arguments are as follows: a1 sup-ports the argument while a2 attacks it..however, consider another example, extractedfrom an online debate platform kialo4.
here, theparticipants’ contribution and the structure mirrora more direct and conversational dynamic to argu-mentation..a1: marvel universe is better than dc universe.
a2: stan lee’s vision contains clarity and purpose, whiledc is simply interested in churning entertainment to the.
masses.
a3: stan lee no-longer has control over any of marvel,which can cloud the purpose of marvel due to it being.
owned by disney.
a4: this is especially true due to his unfortunate passing.
a5: dc has been more apt to recycle parts of intellectualproperty, they even made an entire movie using the ideasof the 1960’s characters and comics..the seemingly simple example of an online ex-change shows how a more conversational environ-ment provides vaguer boundaries of argumenta-tion structure and components.
each argument ismore direct, not necessarily consisting of a claim-premise conﬁguration, and the strength and pro-ductive quality of each argument is particularlyrelative to the context, each contribution affectingthe argument differently either at a local or globallevel.
note, however, that the relations between ar-guments and claim are still relatively clear (e.g.
a2supports while a5 attacks the main claim in a1;a3 attacks a2 directly; and a4 closes any further.
4https://www.kialo.com/explore/.
featured.
discussion on a3’s premise)..clearly, the environment and type of platformunder consideration have a signiﬁcant impact on asystem’s capacity to implement such a frameworkand on the degree of complexity found in the com-ponents and relations to extract, assign, and predict.
working in the realm of overtly argumentative text(such as persuasive essays (stab and gurevych,2017)), while challenging of course, can be quitestandardized.
the language use is generally in linewith natural language expectations and often stan-dard (e.g.
claim, premise and stance are clear), thestructure and collective goal of the debate are rathercontrolled and topic-speciﬁc, and the collection ofparticipants involved is often a closed or an easily-classiﬁed set (e.g.
in parliamentary debates, newsforums, etc.)..
2.2 scaling up argument mining.
in social media while overtly argumentativetext, like those described above, represents the nat-ural domain of application for am, social mediaconstitute a powerful source of large amounts ofdata (billions of words) despite facing particularchallenges in am..social media plays an increasingly signiﬁcantrole in modern political and social discourse, yetresources built for conducting am on this typeof data structure remain limited for clear reasons.
these platforms inherently collect and spread awide range of content, including personal opin-ions, facts, fake news, and additional informationof interest to users.
distinguishing between per-sonal opinion, fact, and fake news, for example, isnot always straightforward, as seen in recent workon fake news detection (kotonya and toni, 2020).
further, the language used on such platforms isinfamously chaotic and often non-standard in com-parison to the language use in more structured envi-ronments, like parliamentary debates.
the combi-nation of these aspects introduces the unique chal-lenge of implementing am to particularly hetero-geneous, poorly annotated data..recent work has aimed to tackle such challengesin social media.
dusmanu et al.
(2017) apply asupervised classiﬁcation approach to identify ar-guments on twitter, focusing on the tasks of factsrecognition and source identiﬁcation.
they studythe feasibility of the approaches proposed to ad-dress these tasks on a set of tweets related tothe grexit and brexitnews topics.
habernal and.
1340gurevych (2017) provide an extensive analysis ofthe steps and the modeling strategies necessaryto analyze social media data (e.g.
forum posts) interms of their argumentative structure, while simp-son and gurevych (2018) tackle the issue of thescalability of am algorithms..despite the rising attention and developmentsto am in social media, one of the major chal-lenges currently facing the ﬁeld is the lack ofconsensus on how exactly to analyse argumenta-tive user-generated texts such as online comments(bauwelinck and lefever, 2020).
on the one hand,the amount of annotations available for the scaleof this heterogeneous data remains limited.
recentwork by schaefer and stede (2020), among others,have aimed to construct large twitter corpora an-notated for argument components, including argu-mentative spans within tweets.
on the other hand,annotation guidelines are not necessarily clear, andthe theoretical motivations underlying the proposedguidelines used to generate labelled corpora rarelyinclude motivation for the use of a particular the-oretical basis.
bauwelinck and lefever (2020) in-troduce a pilot study and aim to provide a clearjustiﬁcation of the theories and deﬁnitions underly-ing the design of a set of guidelines..the linguistic, structural, and logistic complexityand “openness” of such platforms clearly presentunique challenges.
however, being able to workwell with argumentative text from social mediaand discussion forums is essential considering thecontinuously growing impact on the political andsocial framework of modern times..multilingual argument mining multilingualityis an important area of research in nlp that hasgained more attention recently because of the cross-lingual transfer potentials of pre-trained languagemodels (devlin et al., 2019; conneau et al., 2020)and because of the potentials for a societal impactat a global scale.
the latter is particularly impor-tant when considering am for social good sincelanguage should not be a barrier for participation ifthe goal is to allow any productive contribution..various recent studies have investigated multi-linguality for am.
eger et al.
(2019) discuss a se-ries of experiments on using machine translationand annotation projection for am, speciﬁcally ar-gument components extraction and classiﬁcationin german, english, and chinese.
a similar ap-proach to build training data in other languagesusing machine translation is done in toledo-ronen.
et al.
(2020), which use a pre-trained multilingualbert (devlin et al., 2019) for modeling.
thisapproach is shown to perform well for classifyingargument stance and detecting evidence, but notfor predicting argument quality scores.
multilin-gual stance detection in political social media text(vamvas and sennrich, 2020) is also investigated inlai et al.
(2020) using stylistic, structural, affectiveand contextual features from text and analysingthe scenarios in which each of these features iseffective..other work has also dealt with building non-english datasets (lindahl, 2020; bauwelinck andlefever, 2020; schaefer and stede, 2020; zotovaet al., 2020), but there still seems to be a focus onindo-european languages (and sometimes chinese)with a lack of datasets and analysis extending toother languages.
this is a general issue in nlp re-search that extends to performance bias in favor ofstandard dialects for example in english (blodgettet al., 2016) and bias that could target certain usergroups instead of protecting them as was shownfor hate speech detection (davidson et al., 2019).
this is an important limitation to address in amas well for more inclusivity and towards a morepositive societal impact..3 argument quality: an integrated.
deﬁnition.
the second stage in the framework of am is de-ﬁned as relation assignment (c.f.
section 2.1); acomplex task that aims to predict the relations hold-ing between the arguments deﬁned in the ﬁrst stage.
being able to model the relations between argu-ments and components within the structure, forexample in argument graphs (besnard and hunter,2014; craven and toni, 2016), allows us to actuallywork with the argumentative text in an application-based setting, understand the stance and context ofarguments, and develop a story for the consequen-tial impact of arguments on the discourse, amongother things.
generally speaking, we can use thistask as an approach to analyze argument quality(aq)..however, within the am community, an openquestion concerns the adequate deﬁnition and op-erationalization of the notion of aq.
despite this,to move forward with the task of aq analysis andto create large corpora with crowd-sourced annota-tions, some approaches rely on the relative assess-ment of quality: given two arguments, which is.
1341more convincing?
(habernal and gurevych, 2016;toledo et al., 2019; gretz et al., 2020).
thus the natural way of quantifying the successof an argument is in terms of its persuasiveness.
indeed, plenty of previous work has explored themany factors which contribute to the persuasive-ness of a message: the linguistic features employedby the authors (persing and ng, 2017), the seman-tic type of claims and premises (hidey et al., 2017),the different sources of evidence produced to sup-port an argument (addawood and bashir, 2016),the effects of the personality traits and prior beliefson persuasiveness (lukin et al., 2017; durmus andcardie, 2018; al khatib et al., 2020), the interac-tion with other participants (ji et al., 2018; egawaet al., 2020), the use of argument invention whendebating about unknown topics (bilu et al., 2019),the structure of the arguments (li et al., 2020), andthe effect of the style of the text in achieving per-suasion (el baff et al., 2020)..persuasiveness is, however, not the only way todeﬁne whether an argument is good – at least notfrom a deliberation point of view.
a good contribu-tion to a debate is one which uncovers a previouslyunnoticed aspect of a problem, thus generating aperturbation in the discourse (controversies can beproductive!).
or else, a good contribution is onethat settles an issue, by stating the differences be-tween opposing views and allowing the discourse tostabilize in a series of clusters (convergence on justone position is not necessarily a good outcome)..most recent research projects (wachsmuth et al.,2017b) aim to address the challenge of redeﬁningthe notion of aq, away from persuasiveness andtowards a more “situated” deﬁnition which has todo with the needs of argumentation in a real-worldscenario.
this new deﬁnition has been the basis forthe creation of new corpora from different domains(ng et al., 2020), where feature-based (wachsmuthand werner, 2020) and neural models were testedfor automatic prediction (lauscher et al., 2020).
other aspects of aq have become the subject ofam research such as the relevance and impact ofarguments (durmus et al., 2019), the veriﬁability(park and cardie, 2018), local acceptability (yanget al., 2019) and the best “deliberative move” (al-khatib et al., 2018)..we argue that this shift is necessary for two rea-sons: (1) working with real-world applicationsof am naturally forces us into the more hetero-geneous realm of data structures, such as social.
media, in which language, structure, and contentare less uniform and conﬁned to the classic notionof logical debate; and (2) in order to encouragedeliberation from an open audience of citizens, weneed to redeﬁne our concept of aq and productivediscourse such that there is equal worth and partici-pation granted to each contributor of the argument..deliberative quality we therefore proposeadapting the deﬁnition of quality to integrate theabundant research on the topic from the ﬁeld ofsocial sciences.
here, the quality of a discoursehas been investigated in the context of deliberationwith the focus on inclusivity: how can the inter-play of the different participants in the discourselead to an optimal outcome for the collective?
thefocus here is not on the quality of the individualcontributions.
instead, an overall quality of the dis-course is determined by the fact that the individualquality dimensions are distributed among differentcontributions (e.g some participants do more ratio-nal reasoning, others share personal experiences).
we would like to integrate those aspects that focuson inclusivity and cooperation..similar to wachsmuth et al.
(2017b), social sci-entists have developed a taxonomy, the discoursequality index (dqi), that describes the differentdesirable aspects of a discourse (steenbergen et al.,2003).
this taxonomy has been used to analyze thequality of deliberation in different contexts, rangingfrom more formal contexts, such as parliamentarydebates (steiner et al., 2005), to informal discus-sions in online forums (tr´enel, 2004).
both im-plementations integrate logical coherence as onedimension, cogency in wachsmuth et al.
(2017b),justiﬁcation in the dqi.
some aspects of inclusivityare also being touched upon in the rhetorical anddialectical dimension of wachsmuth et al.
(2017b),such as using appropriate language (appropriate-ness) or whether an argument supports conﬂict res-olution (global relevance).
we concentrate on thefollowing dimensions from the dqi, which particu-larly focus on the collaborative aspect of discourse..• respect: this dimension includes respectful tone,respect for other social groups/backgrounds, andopenness towards other opinions..• equality / participation: it is not desirable thatsome dominant participants make the bulk ofcontributions while many others remain passive.
all participants should have equal opportunitiesto contribute and all topics, including those that.
1342dqi (steenbergen et al., 2003) aq (wachsmuth et al., 2017b) descriptionlogical coherencejustiﬁcation level—personal experiencesemotional balance—topic relevance—respectconstructiveness—equalityinteractivity.
local acceptabilitylocal sufﬁciencylocal relevanceemotional appealappropriatenesscredibilityclarityarrangementglobal acceptabilityglobal relevanceglobal sufﬁciency——.
argument should be sound, rationally worthy(enough) premises should support the claimpremises should be suitable to support claimargumentation should increase empathysuitable language and amount of emotionsis the participant credible?
(e.g.
an expert)use of clear and correct language, contribution on topicproper arrangement of premises and claimother participants value / support contributionsargument contributes to the resolution of the issuepossible counterarguments are rebutteddiscourse should not be dominated by few participantscontributions are linked to other contributions.
table 1: comparing argument quality and discourse quality.
may only affect minorities, are equally relevant..• interactivity: beyond simply sharing opinions,acknowledging other viewpoints and interactingwith other participants through listening and re-sponding lead to new perspectives arising – com-promises can emerge..• testimoniality / report of personal accounts:sharing stories and personal narratives as an alter-native form of communication can involve morepeople in the discourse, especially those whocannot identify themselves with rational argu-mentation.
it can also make other participantsaware of other perspectives as it generally in-creases empathy.
especially when traditional oruniversal norms need to be questioned, narrativesare particularly well suited, as their ambiguityand vagueness creates room for interpretation.
this is particularly important when new ideasor perspectives are introduced, since they cannotyet be rationally articulated..table 1 establishes a direct comparison betweendiscourse quality dimensions of the dqi (steenber-gen et al., 2003; steiner et al., 2005) and argumentquality dimensions as deﬁned in wachsmuth et al.
(2017b).
apart from the potential theoretical in-sights, the existing guidelines can be applied toannotate new or enrich existing corpora for am.
despite the small size, the data already annotatedbased on the dqi can be made usable and extendedfor nlp.
in addition, some of the quality dimen-sions can be further quantiﬁed or approximated us-ing statistical methods.
for example, interactivityor equality can be assessed with frequency-basedmethods, such as frequency of posts by distinctparticipants and response rate..summing up the overview of the deﬁnitions ofaq along with the discussion of the potential of theintegration of deliberative quality features into an.
am framework has one strong take-home message:the need for the scope of the investigation to gobeyond (a) the persuasiveness of a an argumenta-tive text (speeches, forum posts, tweets), and (b)their relation to the immediate preceding discourse.
instead, we pointed out the need to also assess thepotential of the impact of that argumentative texton the upcoming discourse: this dimension of qual-ity, inherently related to the interpretation of argu-mentation as a cooperation challenge, is currentlylacking in current approaches to aq..4 grounding aq in deliberation:.
moderation as a real-world application.
grounding aq in a discourse perspective whichquantiﬁes “team-playing” and its impact on dis-course dynamics is a clear challenge, both theoret-ically, in the social sciences and argumentationtheory, and concretely, as the empirical quantiﬁca-tion of discourse-grounded aq will require largeannotation efforts, real-time implementations, andthorough evaluation strategies.
we propose to makea ﬁrst step in tackling this challenge by mappingit into a concrete application: (semi-)automaticmoderation implemented as a form of discourseoptimization, or, as it is commonly referred to inthe social sciences, facilitation (kaner et al., 2007;tr´enel, 2009)..to illustrate the dynamics of moderation, let usstart from concrete examples from a deliberationplatform, regulationroom.
this discussion forumhas been employed by public institutions to gathercitizens contributions on discussions targeting veryheterogeneous issues (more details can be foundin appendix).
let us consider the following exam-ple from a discussion on the distracted driving bycommercial vehicle operators (e.g., truckers andbus drivers).
the posts we selected (arrows in-dicate comment nesting) are from the discussion.
1343sub-thread: texting – what are the risks?5.
user 1: in 2004,... the driver failed to move out of thelow-clearance lane while talking on a cellphone.” this “ac-.
cident” happened in 2004!
he was talking on a cell-.
phone!
imo, “turn off cell b/4 driving!” shouldhave become law long b/4 now!!
all these years havegone by, hundreds of lives have been lost, & our society.
is just now starting to work on this issue?
and we think.
we need to start with small steps like banning texting.
(& sometimes in just commercial vehicles?)?
[...].
→ user 2: a driver in california recently caused an acci-dent because he spilled his coffee.
another driver almost.
wrecked because he was trying to light a cigarette.
the.
bottom line is that any distraction while driving a car can.
cause an accident.
where do we draw the line?
also, thereare millions of people out there who are completely capa-.
ble of using their cell phone and driving, at the same time..are we proposing that they should be punished, for theinabilities of others?
for people who spend much of theirtime in the car, this time might be their only chance to com-.
municate with loved ones, do business, or make important.
calls.
if they are physically capable to use their phones.
safely while driving, why restrict their freedoms?.
→ → moderator: it’s true that any distraction can causean accident.
the agency decided that texting was partic-.
ularly unsafe, in part on the basis of the vtti study that.
we reference lower on the page.
click the graphic to get a.sense of the safety risks associated with different activities..a question: do you think that this rule imposes an undue.
burden on personal communication?
what alternative re-.
strictions on texting, if any, would you propose to impose.
on professional drivers?.
the example involves two users who clearly dif-fer in their argumentation style and position.
user 1has a clear position on the topic (claim in bold: notjust texting, but all cellphone interactions shouldbe banned), which she/he supports with personalreports (underlined text) an emotional tone, and astyle which is typical of social media text.
user 2replies, opening the post on a sarcastic note, whichserves as the ﬁrst premise to her/his (implicit) claimwhich is encoded in three rethorical questions (inbold): there should be no restrictions at all, becauseimposing them would be unfair.
this is the casebecause (premises underlined): any distraction cancause an accident, some people are capable of us-ing their phone while driving, people who spend lotof time in the car for professional reasons still need.
5archive.regulationroom.org/texting/.
design-and-operation/index.html.
to communicate with loved ones.
a moderator thenjoins the discussion to (a) provide a clariﬁcation asto why the focus is on texting and a link to furtherinformation on the matter, and (b) ask user 2 toelaborate on the personal communication issue, andto propose alternatives.
in the appendix we reportanother example from the same topic and thread,where the user acts as a problematizer, challengingthe scope and deﬁnition of the rule under discus-sion and the moderator acts as a “discourse trafﬁcdirector”, pointing out that the user should read andcontribute to different threads in the discussion..the guidelines for human moderators in reg-ulationroom have been deﬁned in advance in a’moderator protocol’ (erulemaking initiative et al.,2017) which reﬂect the moderator actions men-tioned in the examples.
in the protocol the mod-erator roles were divided into two main classes.
supervision functions include general moderatoractions that do not necessarily target the speciﬁccontent of the posts, e.g., greeting participants,monitoring compliance with netiquette (policing),or helping with technical difﬁculties.
substantivemoderator functions aim to improve the qualityof comments and promote fruitful discourse.
asthe examples above clearly show, this can bothmean that the moderator encourages exchanges be-tween discourse participants and participation inother posts (broadening the scope of the discus-sion), or helping users to improve the content oftheir posts (requests for clariﬁcation, focusing onone topic, substantive reasoning, sharing personalexperiences)..regulationroom represents an excellent exam-ple of the beneﬁcial role of the moderator in main-taining productive argumentation from participants.
however, to the best of our knowledge, there islittle to no nlp work targeting moderation mod-eling.
park et al.
(2012) used data from regula-tionroom and conducted an annotation study toempirically categorize the types of moderator inter-ventions speciﬁed in the moderator protocol.
clas-siﬁcation experiments were conducted using svmto predict the type of action a moderator wouldperform, given the previous comment.
howeverthis work is limited as it only focuses on two typesof moderator interventions (broadening the scopeof the discussion, improving argument quality) andas it does not predict whether the moderator shouldintervene, building on the assumption that a givencomment has already been ﬂagged as ”in need for.
1344moderation”..besides the concrete example of regulation-room, moderation and discourse facilitation havebeen, and still are, a crucial topic in digital democ-racy.6 the know-how of digital democracy expertsis an invaluable starting point for the applicationof am to moderation, as current research targetsboth the integration of digital solutions to facili-tate online campaigns, and a critical reﬂection ofthe effects of such innovations on the deliberationoutcomes..digital innovation supporting deliberation ar-gument maps (walton, 2005) are widely employedto support online discussions, as an emerging opti-mization of the deliberation.
given a speciﬁc topic,for example possible reactions to climate change,users who wish to contribute to the discussion arerequested to structure their contribution by produc-ing an item in a conceptual map and optionallywriting an accompanying post.
their contributionto the argument maps is often reviewed by a mod-erator.
so in a sense, the argument map for a givendeliberation process is the outcome of a processthat comes both from below (the user) and above(the moderator)..thanks to argument maps, the overall discoursepicture can be overviewed and it is easier for thegroup of contributors to express support for one (ormany) of the available options, without having toread a large number of long posts.
an example ofthis approach is represented in deliberatorium7, ane-deliberation platform which has been extensivelyemployed in many reference studies on the effectof digital innovation on deliberation (klein, 2011).
another example of a digital deliberation platformwhich integrates argument maps and offers an op-tion for moderation is colagree (yang et al.,2021; ito, 2018).
among the studies testing theimpact of such digital platforms on online delibera-tion, spada et al.
(2015) tests the effect of deliber-atorium’s argument maps on an online discussionamong the supporters of the italian democraticparty concerning the desired features of electorallaw to be proposed by the party to the parliament.
this study compared the discussion of users em-ploying deliberatorium and a control group usinga traditional forum format which was then encodedinto argument maps.
the comparison showed that.
6see dahlberg (2011) for an outline of positions in delib-.
erative democracy..7http://deliberatorium.mit.edu.
the argument map modality did not discourage par-ticipation, and while it appeared to make users lesscreative (fewer new ideas as compared to the tra-ditional forum), it also reduced the rate of claimswithout further discussion..yet, the need for trained moderators tends to be asigniﬁcant bottleneck (both in terms of time and ofcosts) in digital deliberation.
moreover, empiricalresearch on the effect of moderation on deliberationhas uncovered the risks of biased moderation.
forexample, the experiment in spada and vreeland(2013) tests the extent to which moderators caninﬂuence participants’ behavior by expressing theirviews during the moderation process..4.1 nlp-supported moderation: desiderata.
and challenges.
nlp-supported moderation represents a clear so-lution to the bottleneck problem affecting facili-tation in digital democracy.
automatic tools cantake over some of the tasks that human moderatorstypically perform when monitoring online discus-sions.
for example, in social sciences, one of themost discussed issues in crowd-scale deliberation is“ﬂaming”, i.e., aggressive and disrespectful commu-nicative behavior (lampe et al., 2014).
here, mod-erators could beneﬁt from hate-speech and trollingdetection methods in nlp..nlp methods to support deliberative decision-making have already been applied for the real-time visualisation of argument maps (el-assadyet al., 2017).
deliberation in real-time applicationshas the clear potential of structured arguments ex-traction from the news media (daxenberger andgurevych, 2020), the identiﬁcation of the argumen-tative structure in deliberative contexts (liebecket al., 2016), as well as automatic argument sum-marization (lawrence et al., 2017)..beyond the real-time support to users (and mod-erators) provided by the methods described above,further tasks speciﬁc to am which are part of therole of a human or (semi-)automoated modera-tor include: detecting fallacies (habernal et al.,2018b), reasoning and common-sense (habernalet al., 2018a), relevance estimation (potthast et al.,2019).
in addition, detecting and highlighting partsof an argument that are a good target for attacks (joet al., 2020a) can help the moderator to motivatemore participation and argumentation from oppos-ing sides of a discussion.
another important sourceis the detection of implicitly asserted prepositions.
1345(jo et al., 2020b) which has a counterpart in theframing detection task (card et al., 2015; aky¨ureket al., 2020), as framing is a manipulation strategywhich highlights speciﬁc aspects of an issue underdiscussion to promote certain interpretations..further nlp tasks which can play a crucial rolein ensuring a healthy interaction are, for example,hate speech detection (warner and hirschberg,2012; waseem and hovy, 2016; schmidt and wie-gand, 2017), fact checking (vlachos and riedel,2014; kotonya and toni, 2020), facts recognitionand source identiﬁcation (dusmanu et al., 2017)..how to represent discourse?
thus far, wehave discussed the main ingredients of a richnlp-informed approach to deliberative discourse.
these components, together with the deliberation-augmented deﬁnition of aq sketched in section 3are the features that the nlp moderator takes asan input.
one question remains open: how to rep-resent the argumentative discourse within a contri-bution (e.g.
a forum post) and across contributions(e.g.
an entire online deliberation campaign)?
wecan approach also this question from an interdis-ciplinary perspective.
reference work in politicalscience aims at modeling the mechanisms of polit-ical discourse in forms of discourse networks, asdeﬁned in leifeld (2017).
a discourse network isa bipartite graph, containing two classes of nodes:actors (e.g.
angela merkel; the left-wing party;etc.)
and claims (e.g.
housing opportunities shouldbe established for refugees); edges between ac-tors and claims indicate the support or oppositionof a certain actor to a speciﬁc claim.
discoursecoalitions (hajer, 1993) and argumentative clustersare the projection of the afﬁliation network on theactor and claim sides of the network (leifeld andhaunss, 2012; haunss et al., 2013).
recent nlpresearch has targeted integration machine learningin the discourse network analysis workﬂow (pad´oet al., 2019; haunss et al., 2020).
crucially for am,discourse networks can integrate claims and actorswith a third class of nodes, the frame nodes, whichencode the reason put forward by an actor to sup-port or reject a claim.
this type of representation isperfectly compatible with a graph-based approachon argument representation which has already beenestablished as to be preferred to a tree-structure rep-resentation both empirically (niculae et al., 2017)and theoretically (afantenos and asher, 2014)..moderation can thus be modeled as optimizationof speciﬁc quantitative properties of the discourse.
network: participant inclusion, can be enforced byensuring that the contributions of peripheric actornodes receive the deserved salience; argument map-ping and summarization can be modeled by identi-fying “hot” sub-graphs in the network; the impactof a contribution (the grounded notion of aq wehave been advocating thus far) can be quantiﬁed asthe perturbation introduced in the network, with itslong term effects on convergence or polarization..who moderates the (nlp) moderators?
theproblem of biased moderation obviously relatesto the issue of bias in nlp (blodgett et al., 2020;caliskan et al., 2017; bolukbasi et al., 2016; spli-eth¨over and wachsmuth, 2020) and it has a clearimplication in the application of nlp methods tomoderation.
for example, we would not want ournlp models to infer a negative impact on aq fromcues which just reveal that the user belongs to cer-tain groups.
this is a real risk when quality isequated to “success”, in turn quantiﬁed in termsof likes, replies, retweets.
the public of a forummay be sensitive to such cues, but the moderatorshould be unbiased with respect to them.
anothersource of bias is the degree of literacy of a contri-bution: while users who express themselves poorlyare likely to be less popular with the forum public,their contributions may still be a very good movein the “cooperation challenge” – one that modera-tors (nlp or humans, online or in-person) have toensure will not be left unexploited..5 conclusion.
while there are clear social drawbacks to workingwith data and approaches to am that limit the par-ticipation of the argumentation/deliberation, open-ing the ﬂoodgates to unregulated, evenly weightedcontribution of all arguments also presents adilemma.
we present an interdisciplinary formu-lation of the notion of argument quality, which ismore apt to work with heterogeneous data and plat-forms, such as discussion forums and social media.
with the goal of ensuring a productive developmentof the discourse, we propose nlp-supported mod-eration to facilitate argumentation and deliberationin digital democracy..acknowledgments.
we acknowledge funding by the bundesministeri-umfur bildung und forschung (bmbf) throughthe project e-delib (powering up e-deliberation:towards ai-supported moderation)..1346references.
assel a. addawood and masooda n. bashir.
2016.what is your evidence?
a study of controversialin proceedings of the 3rdtopics on social media.
workshop on argument mining, pages 1–11, berlin,germany..stergos afantenos and nicholas asher.
2014. counter-argumentation and discourse: a case study.
ceurworkshop proceedings, 1341..afra feyza aky¨urek, lei guo, randa elanwar, prakashishwar, margrit betke, and derry tanti wijaya.
2020. multi-label and multilingual news framinganalysis.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,pages 8614–8624, online.
association for computa-tional linguistics..khalid al khatib, michael v¨olske, shahbaz syed,nikolay kolyada, and benno stein.
2020. exploit-ing personal characteristics of debaters for predict-ing persuasiveness.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 7067–7072, online.
associationfor computational linguistics..khalid al-khatib, henning wachsmuth, kevin lang,jakob herpel, matthias hagen, and benno stein.
2018. modeling deliberative argumentation strate-gies on wikipedia.
in proceedings of the 56th an-nual meeting of the association for computationallinguistics (volume 1: long papers), pages 2545–2555, melbourne, australia.
association for com-putational linguistics..andre b¨achtiger and john parkinson.
2019. towards anew deliberative quality.
oxford university press,cambridge, ma, usa..nina bauwelinck and els lefever.
2020. annotat-ing topics, stance, argumentativeness and claims indutch social media comments: a pilot study.
inproceedings of the 7th workshop on argument min-ing, pages 8–18, online.
association for computa-tional linguistics..philippe besnard and anthony hunter.
2014. con-structing argument graphs with deductive arguments:a tutorial.
argument & computation, 5(1):5–30..yonatan bilu, ariel gera, daniel hershcovich, ben-jamin sznajder, dan lahav, guy moshkowich,anael malet, assaf gavron, and noam slonim.
2019. argument invention from ﬁrst principles.
inproceedings of the 57th annual meeting of the asso-ciation for computational linguistics, pages 1013–1026..su lin blodgett, solon barocas, hal daum´e iii, andhanna wallach.
2020. language (technology) ispower: a critical survey of “bias” in nlp.
in pro-ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5454–5476, online.
association for computational lin-guistics..su lin blodgett, lisa green, and brendan o’connor.
2016. demographic dialectal variation in socialmedia: a case study of african-american english.
in proceedings of the 2016 conference on empiri-cal methods in natural language processing, pages1119–1130, austin, texas.
association for compu-tational linguistics..tolga bolukbasi, kai-wei chang,.
james zou,venkatesh saligrama,and adam kalai.
2016.man is to computer programmer as woman is tohomemaker?
debiasing word embeddings.
in pro-ceedings of the 30th international conference onneural information processing systems, nips’16,page 4356–4364, red hook, ny, usa.
curranassociates inc..elena cabrio and serena villata.
2013. a natural lan-guage bipolar argumentation approach to supportusers in online debate interactions.
argument &computation, 4(3):209–230..elena cabrio and serena villata.
2018. five years of ar-gument mining: a data-driven analysis.
in proceed-ings of the twenty-seventh international joint con-ference on artiﬁcial intelligence, ijcai-18, pages5427–5433.
international joint conferences on ar-tiﬁcial intelligence organization..aylin caliskan,.
and arvindjoanna j bryson,narayanan.
2017. semantics derived automaticallyfrom language corpora contain human-like biases.
science, 356(6334):183–186..dallas card, amber e. boydstun, justin h. gross,philip resnik, and noah a. smith.
2015. the mediaframes corpus: annotations of frames across issues.
in proceedings of the 53rd annual meeting of theassociation for computational linguistics and the7th international joint conference on natural lan-guage processing (volume 2: short papers), pages438–444, beijing, china.
association for computa-tional linguistics..tuhin chakrabarty, christopher hidey, smarandamuresan, kathy mckeown, and alyssa hwang.
2019. ampersand: argument mining for per-suasive online discussions.
in proceedings of the2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 2933–2943, hong kong,china.
association for computational linguistics..oana cocarascu, elena cabrio, serena villata, andfrancesca toni.
2020. dataset independent base-lines for relation prediction in argument mining.
incomputational models of argument - proceedingsof comma 2020, perugia, italy, september 4-11,2020, volume 326 of frontiers in artiﬁcial intelli-gence and applications, pages 45–52.
ios press..alexis conneau, kartikay khandelwal, naman goyal,vishrav chaudhary, guillaume wenzek, franciscoguzm´an, edouard grave, myle ott, luke zettle-moyer, and veselin stoyanov.
2020. unsupervised.
1347cross-lingual representation learning at scale.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 8440–8451, online.
association for computational lin-guistics..in proceed-computational argumentation mining.
ings of the 55th annual meeting of the associationfor computational linguistics (volume 1: long pa-pers), pages 11–22, vancouver, canada.
associationfor computational linguistics..robert craven and francesca toni.
2016. argumentgraphs and assumption-based argumentation.
artiﬁ-cial intelligence, 233:1–59..lincoln dahlberg.
2011..re-constructing digitaldemocracy: an outline of four ‘positions’.
new me-dia & society, 13(6):855–872..thomas davidson, debasmita bhattacharya, and ing-mar weber.
2019. racial bias in hate speech andabusive language detection datasets.
in proceedingsof the third workshop on abusive language online,pages 25–35, florence, italy.
association for com-putational linguistics..johannes daxenberger and irina gurevych.
2020. ar-guments as social good: good arguments in times ofcrisis.
in proocedings of the aaai fall 2020 sympo-sium on ai for social good..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of naacl-hlt, pagesstanding.
4171–4186, minneapolis, minnesota..esin durmus and claire cardie.
2018. exploring therole of prior beliefs for argument persuasion.
inproceedings of the 2018 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long papers), pages 1035–1045, neworleans, louisiana.
association for computationallinguistics..esin durmus, faisal ladhak, and claire cardie.
2019.the role of pragmatic and discourse context in de-in proceedings of thetermining argument impact.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 5668–5678, hong kong,china.
association for computational linguistics..mihai dusmanu, elena cabrio, and serena villata.
2017. argument mining on twitter: arguments,facts and sources.
in proceedings of the 2017 con-ference on empirical methods in natural languageprocessing, pages 2317–2322..ryo egawa, gaku morio, and katsuhide fujita.
2020.corpus for modeling user interactions in online per-suasive discussions.
in proceedings of the 12th lan-guage resources and evaluation conference, pages1135–1141, marseille, france.
european languageresources association..steffen eger,.
and irynajohannes daxenberger,gurevych.
2017. neural end-to-end learning for.
steffen eger, johannes daxenberger, christian stab,and iryna gurevych.
2019. cross-lingual argumen-tation mining: machine translation (and a bit of pro-jection) is all you need!
in proceedings of the 27thinternational conference on computational linguis-tics, pages 831–844..liat ein-dor, eyal shnarch, lena dankin, alon hal-fon, benjamin sznajder, ariel gera, carlos alzate,martin gleize, leshem choshen, yufang hou, et al.
2020. corpus wide argument mining—a workingsolution.
in proceedings of the aaai conference onartiﬁcial intelligence, volume 34, pages 7683–7691..mennatallah.
el-assady,.
annette hautli-janisz,valentin gold, miriam butt, katharina holzinger,and daniel keim.
2017. interactive visual analysisof transcribed multi-party discourse.
in proceedingsof the 55th annual meeting of the association forcomputational linguistics-system demonstrations,pages 49–54, vancouver, canada..roxanne el baff, henning wachsmuth, khalidal khatib, and benno stein.
2020. analyzing thepersuasive effect of style in news editorial argu-mentation.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,pages 3154–3160, online.
association for computa-tional linguistics..shai gretz, roni friedman, edo cohen-karlik, as-saf toledo, dan lahav, ranit aharonov, and noamslonim.
2020. a large-scale dataset for argumentquality ranking: construction and analysis.
pro-ceedings of the aaai conference on artiﬁcial intel-ligence, 34(05):7805–7813..ivan habernal and iryna gurevych.
2016. which ar-gument is more convincing?
analyzing and predict-ing convincingness of web arguments using bidi-in proceedings of the 54th an-rectional lstm.
nual meeting of the association for computationallinguistics (volume 1: long papers), pages 1589–1599, berlin, germany.
association for computa-tional linguistics..ivan habernal and iryna gurevych.
2017. argumenta-tion mining in user-generated web discourse.
com-putational linguistics, 43(1)..ivan habernal, henning wachsmuth, iryna gurevych,and benno stein.
2018a.
the argument reasoningcomprehension task: identiﬁcation and reconstruc-tion of implicit warrants.
in proceedings of the 2018conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 1 (long papers),pages 1930–1940, new orleans, louisiana.
associ-ation for computational linguistics..1348ivan habernal, henning wachsmuth, iryna gurevych,and benno stein.
2018b.
before name-calling: dy-namics and triggers of ad hominem fallacies in webargumentation.
in proceedings of the 2018 confer-ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1 (long papers), pages386–396, new orleans, louisiana.
association forcomputational linguistics..maarten a hajer.
1993. discourse coalitions and theinstitutionalization of practice: the case of acidrain in britain.
in the argumentative turn in pol-icy analysis and planning, pages 43–76.
duke uni-versity press..sebastian haunss, matthias dietz,.
and franknullmeier.
2013. der ausstieg aus der atom-energie.
diskursnetzwerkanalyse als beitrag zurerkl¨arung einer radikalen politikwende.
zeitschriftf¨ur diskursforschung, 1(3):288–316..sebastian haunss, jonas kuhn, sebastian pado, an-dre blessing, nico blokker, erenay dayanik, andgabriella lapesa.
2020. integrating manual and au-tomatic annotation for the creation of discourse net-work data sets.
politics and governance, 8(2)..christopher hidey, elena musi, alyssa hwang,smaranda muresan, and kathleen mckeown.
2017.analyzing the semantic types of claims and premisesin an online persuasive forum.
in proceedings of the4th workshop on argument mining, pages 11–21..cornell erulemaking initiative et al.
2017. ceri (cor-.
nell e-rulemaking) moderator protocol..takayuki ito.
2018. towards agent-based large-scaledecision support system: the effect of facilitator.
inproceedings of the 51st hawaii international con-ference on system sciences, pages 351–360..lu ji, zhongyu wei, xiangkun hu, yang liu,qi zhang, and xuanjing huang.
2018. incorporat-ing argument-level interactions for persuasion com-ments evaluation using co-attention model.
in pro-ceedings of the 27th international conference oncomputational linguistics, pages 3703–3714, santafe, new mexico, usa.
association for computa-tional linguistics..yohan jo, seojin bang, emaad manzoor, eduard hovy,and chris reed.
2020a.
detecting attackable sen-in proceedings of the 2020tences in arguments.
conference on empirical methods in natural lan-guage processing (emnlp), pages 1–23, online.
association for computational linguistics..yohan jo, jacky visser, chris reed, and eduard hovy.
2020b.
extracting implicitly asserted propositionsin argumentation.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing (emnlp), pages 24–38, online.
associ-ation for computational linguistics..sam kaner, lenny lind, catherine tolid, sarahfisk, and duane berger.
2007. facilitator’s guideto participatory decision-making.
john wiley &sons/jossey-bass, san francisco..mark klein.
2011. the mit deliberatorium: en-abling large-scale deliberation about complex sys-temic problems.
in 2011 international conferenceon collaboration technologies and systems (cts)..jonathan kobbe, juri opitz, maria becker,.
ioanahulpus, heiner stuckenschmidt, and anette frank.
2019. exploiting background knowledge for argu-mentative relation classiﬁcation.
in 2nd conferenceon language, data and knowledge, ldk 2019, may20-23, 2019, leipzig, germany, volume 70 of oa-sics, pages 8:1–8:14. schloss dagstuhl - leibniz-zentrum f¨ur informatik..neema kotonya and francesca toni.
2020. explain-able automated fact-checking: a survey.
in proceed-ings of the 28th international conference on compu-tational linguistics, pages 5430–5443..mirko lai, alessandra teresa cignarella, deliairaz´u hern´andez far´ıas, cristina bosco, vivianapatti, and paolo rosso.
2020. multilingual stancedetection in social media political debates.
com-puter speech & language, 63:101075..cliff lampe, paul zube, jusil lee, chul hyun park,and erik johnston.
2014. crowdsourcing civility:a natural experiment examining the effects of dis-tributed moderation in online forums.
governmentinformation quarterly, 31(2):317 – 326..anne lauscher, lily ng, courtney napoles, and joeltetreault.
2020. rhetoric, logic, and dialectic: ad-vancing theory-based argument quality assessmentin proceedingsin natural language processing.
of the 28th international conference on compu-tational linguistics, pages 4563–4574, barcelona,spain (online).
international committee on compu-tational linguistics..john lawrence, joonsuk park, katarzyna budzynska,claire cardie, barbara konat, and chris reed.
2017.using argumentative structure to interpret debatesin online deliberative democracy and erulemaking.
acm trans.
internet technol., 17(3 - 25)..john lawrence and chris reed.
2019. argumentcomputational linguistics,.
mining: a survey.
45(4):765–818..philip leifeld.
2017. discourse network analysis.
pol-icy debates as dynamic networks.
in jennifer n. vic-tor, mark n. lubell, and alexander h. montgomery,editors, the oxford handbook of political networks,chapter 12, pages 301–325.
oxford university press,oxford..philip leifeld and sebastian haunss.
2012. politicaldiscourse networks and the conﬂict over softwarepatents in europe.
european journal of political re-search, 51(3):382–409..1349jialu li, esin durmus, and claire cardie.
2020. ex-ploring the role of argument structure in online de-in proceedings of the 2020 con-bate persuasion.
ference on empirical methods in natural languageprocessing (emnlp), pages 8905–8912, online.
as-sociation for computational linguistics..matthias liebeck, katharina esau, and stefan conrad.
2016. what to do with an airport?
mining argumentsin the german online participation project tempel-hofer feld.
in proceedings of the 3rd workshop onargument mining, pages 144–153, berlin, germany..anna lindahl.
2020. annotating argumentation inin proceedings of the 7thswedish social media.
workshop on argument mining, pages 100–105,barcelona, spain (online).
association for compu-tational linguistics..luca lugini and diane litman.
2020. contextual ar-gument component classiﬁcation for class discus-sions.
in proceedings of the 28th international con-ference on computational linguistics, pages 1475–1480, barcelona, spain (online).
international com-mittee on computational linguistics..stephanie lukin, pranav arand, marilyn walker, andsteve whittaker.
2017. argument strength is in theeye of the beholder: audience effects in persuasion.
in proceedings of the 15th conference of the euro-pean chapter of the association for computationallinguistics, pages 742–753, valencia, spain..raquel mochales and marie-francine moens.
2011.argumentation mining.
artiﬁcial intelligence andlaw, 19(1):1–22..marie-francine moens, erik boiy, raquel mochalespalau, and chris reed.
2007. automatic detec-tion of arguments in legal texts.
in proceedings ofthe 11th international conference on artiﬁcial intel-ligence and law, pages 225–230..lily ng, anne lauscher, joel tetreault, and courtneynapoles.
2020. creating a domain-diverse corpusfor theory-based argument quality assessment.
inproceedings of the 7th workshop on argument min-ing, pages 117–126, online.
association for compu-tational linguistics..vlad niculae, joonsuk park, and claire cardie.
2017.argument mining with structured svms and rnns.
in proceedings of the 55th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 985–995, vancouver, canada.
association for computational linguistics..sebastian pad´o, andr´e blessing, nico blokker, erenaydayanik, sebastian haunss, and jonas kuhn.
2019.who sides with whom?
towards computational con-struction of discourse networks for political debates.
in proceedings of acl, florence, italy..joonsuk park and claire cardie.
2018. a corpus oferulemaking user comments for measuring evalua-bility of arguments.
in proceedings of the eleventh.
international conference on language resourcesand evaluation (lrec 2018), miyazaki, japan.
eu-ropean language resources association (elra)..joonsuk park, sally klingel, claire cardie, mary j.newhart, cynthia farina, and j. vallb´e.
2012. facil-itative moderation for online participation in erule-making.
in dg.o ’12..andreas peldszus and manfred stede.
2015. joint pre-diction in mst-style discourse parsing for argumen-in proceedings of the 2015 confer-tation mining.
ence on empirical methods in natural languageprocessing, pages 938–948, lisbon, portugal.
asso-ciation for computational linguistics..isaac persing and vincent ng.
2017. why can’t youconvince me?
modeling weaknesses in unpersuasivearguments.
in proceedings of the twenty-sixth inter-national joint conference on artiﬁcial intelligence(ijcai-17), pages 4082–4088..martin potthast, lukas gienapp, florian euchner, nickheilenk¨otter, nico weidmann, henning wachsmuth,benno stein, and matthias hagen.
2019. argumentsearch: assessing argument relevance.
in proceed-ings of the 42nd international acm sigir confer-ence on research and development in informationretrieval, sigir’19, page 1117–1120, new york,ny, usa.
association for computing machinery..robin schaefer and manfred stede.
2020. annotationin proceed-and detection of arguments in tweets.
ings of the 7th workshop on argument mining, pages53–58, online.
association for computational lin-guistics..anna schmidt and michael wiegand.
2017. a surveyon hate speech detection using natural language pro-in proceedings of the fifth internationalcessing.
workshop on natural language processing for so-cial media, pages 1–10, valencia, spain.
associa-tion for computational linguistics..edwin simpson and iryna gurevych.
2018. findingconvincing arguments using scalable bayesian pref-erence learning.
transactions of the association forcomputational linguistics, 6..paolo spada, mark klein, raffaele calabretta, lucaiandoli, and ivana quinto.
2015. a ﬁrst step towardscaling-up deliberation: optimizing large group e-deliberation using argument maps.
in american po-litical science association (apsa), 110th annualmeeting.
politics after the digital revolution, wash-ington dc..paolo spada and james raymond vreeland.
2013.who moderates the moderators?
the effect of non-neutral moderators in deliberative decision making.
journal of public deliberation, 9(2,3)..maximilian splieth¨over and henning wachsmuth.
2020. argument from old man’s view: assessing so-cial bias in argumentation.
in proceedings of the 7thworkshop on argument mining, pages 76–87, on-line.
association for computational linguistics..1350christian stab and iryna gurevych.
2017. parsing ar-gumentation structures in persuasive essays.
com-putational linguistics, 43(3):619–659..m. steenbergen, andre baechtiger, markus sp¨orndli,and j. steiner.
2003. measuring political delibera-tion: a discourse quality index.
comparative euro-pean politics, 1:21–48..j¨urg steiner, andr´e b¨achtiger, markus sp¨orndli, andmarco r. steenbergen.
2005. deliberative politicsin action: analyzing parliamentary discourse.
the-ories of institutional design.
cambridge universitypress..assaf toledo, shai gretz, edo cohen-karlik, ronifriedman, elad venezian, dan lahav, michal ja-covi, ranit aharonov, and noam slonim.
2019. au-tomatic argument quality assessment - new datasetsin proceedings of the 2019 confer-and methods.
ence on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 5625–5635, hong kong, china.
as-sociation for computational linguistics..orith toledo-ronen, matan orbach, yonatan bilu,artem spector, and noam slonim.
2020. multilin-gual argument mining: datasets and analysis.
infindings of the association for computational lin-guistics: emnlp 2020, pages 303–317, online.
as-sociation for computational linguistics..dietrich trautmann, michael fromm, volker tresp,thomas seidl, and hinrich sch¨utze.
2020. re-lational and ﬁne-grained argument mining: thelmu munich project remlav within the dfg prior-ity program ratio “robust argumentation machines”.
datenbank-spektrum, 20..mathias tr´enel.
2004. measuring the deliberativenessreport,.
of online discussions.
coding scheme 2.4.berlin: social science research centrex..matthias tr´enel.
2009. facilitation and inclusive delib-eration.
online deliberation: design, research, andpractice, pages 253–257..jannis vamvas and rico sennrich.
2020. x-stance: amultilingual multi-target dataset for stance detection.
in 5th swiss text analytics conference (swisstext)& 16th conference on natural language processing(konvens).
ceur workshop proceedings..andreas vlachos and sebastian riedel.
2014. factchecking: task deﬁnition and dataset construction.
in proceedings of the acl 2014 workshop on lan-guage technologies and computational social sci-ence, pages 18–22, baltimore, md, usa.
associa-tion for computational linguistics..henning wachsmuth, nona naderi, ivan habernal,yufang hou, graeme hirst, iryna gurevych, andbenno stein.
2017a.
argumentation quality assess-in proceedings of thement: theory vs. practice..55th annual meeting of the association for compu-tational linguistics (volume 2: short papers), pages250–255, vancouver, canada.
association for com-putational linguistics..henning wachsmuth, nona naderi, yufang hou,yonatan bilu, vinodkumar prabhakaran, tim al-berdingk thijm, graeme hirst, and benno stein.
2017b.
computational argumentation quality assess-ment in natural language.
in proceedings of the 15thconference of the european chapter of the associa-tion for computational linguistics: volume 1, longpapers, pages 176–187, valencia, spain.
associa-tion for computational linguistics..henning wachsmuth and till werner.
2020..intrin-in proceed-sic quality assessment of arguments.
ings of the 28th international conference on com-putational linguistics, pages 6739–6745, barcelona,spain (online).
international committee on compu-tational linguistics..douglas walton.
2005. argumentation methods forartiﬁcial intelligence in law.
springer science &business media..william warner and julia hirschberg.
2012. detectinghate speech on the world wide web.
in proceedingsof the second workshop on language in social me-dia, pages 19–26, montr´eal, canada.
association forcomputational linguistics..zeerak waseem and dirk hovy.
2016. hateful sym-bols or hateful people?
predictive features for hatespeech detection on twitter.
in proceedings of thenaacl student research workshop, pages 88–93,san diego, california.
association for computa-tional linguistics..chunsheng yang, wen gu, takayuki ito, and xiao-hua yang.
2021. machine learning-based consen-sus decision-making support for crowd-scale delib-eration.
applied intelligence..wonsuk yang, seungwon yoon, ada carpenter, andjong park.
2019.
nonsense!
: quality control viatwo-step reason selection for annotating local accept-ability and related attributes in news editorials.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 2954–2963, hong kong, china.
association for computa-tional linguistics..elena zotova, rodrigo agerri, manuel nu˜nez, andgerman rigau.
2020. multilingual stance detec-tion in tweets: the catalonia independence cor-pus.
in proceedings of the 12th language resourcesand evaluation conference, pages 1368–1375, mar-seille, france.
european language resources asso-ciation..1351additional moderation exampleuser 3: i don’t dispute the distraction factor.
10 minuteson any highway in the country should offer enough proof for.
all but the most obtuse.
what i object to is the singling out.
of any particular group of drivers as the focus of anotherun-enforceable law (or, shall we say, really only enforceableafter the fact)..truckers already face a huge pile of regulations that apply.
only to them, and not to other drivers on the road.
in most.
cases, these regulations are at least tangentally appropriate.
given the nature of the vehicle driven.
in this case, however,.
the activity in question is one engaged in by drivers off all.
classes of vehicle.
it seems to me to be more appropriate for.
the regulation or non-regulation to come at the state level,.
and cover all vehicle operators.
→ moderator: thanks for your thoughtful comments.
formore information about why fmcsa has proposed to im-.
poses regulations against commercial drivers, please see our.
next post called “which drivers are covered.” after reading.
through this material, let the community know if your opinion.
has changed..as to your comment about enforcement, you’ve identiﬁed one.
of the most difﬁcult questions about this proposed regulation..feel free to continue to discuss this question in the post called.
“who & how of enforcement.”.
a appendix.
e-rulemaking & regulationroom.
e-rulemaking is a type of (e-)deliberation pro-cess which originated in the united states.
its goalis to use digital innovations to increase participa-tion and transparency in the decision-making pro-cess of the federal government.
more concretely,given a new regulation to be written (or the needto signiﬁcantly update an existing one), a govern-ment agency directly involves the citizens in thediscussion of speciﬁc aspects of that rule, sharingrelevant data with the citizens and committing toincorporate the output of their deliberation in theﬁnal rule.
a crucial role is obviously paid by thee-rulemaking ”provider”, who sets up the infras-tructure both practically (e.g., creating websitesand portals for citizens to participate) and qualita-tively (by monitoring the discussion and creatingsummaries to be submitted to the agency)..regulationroom is a deliberation platform de-signed by the cornell erulemaking initiative(ceri) to support various large scale e-deliberation,hosted by the legal information institute (lii) atthe cornell law school, has been employed bypublic institutions to gather citizens contributionson rules targeting very heterogeneous issues, suchas airline passengers rights, home mortgage con-sumer protection, distracted driving by commercialmotor vehicles, among others..the example provided in the paper and the addi-tional example in this appendix are an excerpt fromthe distracted driving discussion, which is publiclyavailable at http://archive.regulationroom.
org/texting/index.html..before proceeding to the additional example, weelaborate on the deliberation context from whichthe examples are extracted..the federal motor carrier safety administra-tion had been planning new federal regulations toaddress distracted driving by truckers, and the ex-amples show a discussion about a speciﬁc subtopic:what are the risks of texting while driving?
ex-amples of other subtopics for the same discussionare: what counts as texting?
which drivers arecovered?
what penalties should caught drivers re-ceive?
how will any law enforcement entity knowwhen a driver is texting?.
the discussion took place in april 2010. orig-inal posts are time-stamped and organized in dis-cussion threads; we anonymized the user names..1352