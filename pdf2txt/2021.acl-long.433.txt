exploring distantly-labeled rationales in neural network models.
quzhe huang, shengqi zhu, yansong feng∗ , dongyan zhaowangxuan institute of computer technology, peking university, chinathe moe key laboratory of computational linguistics, peking university, china{huangquzhe, zhusq, fengyansong, zhaody}@pku.edu.cn.
abstract.
recent studies strive to incorporate varioushuman rationales into neural networks to im-prove model performance, but few pay atten-tion to the quality of the rationales.
mostexisting methods distribute their models’ fo-cus to distantly-labeled rationale words en-tirely and equally, while ignoring the potentialimportant non-rationale words and not distin-guishing the importance of different rationalewords.
in this paper, we propose two novelauxiliary loss functions to make better use ofdistantly-labeled rationales, which encouragemodels to maintain their focus on importantwords beyond labeled rationales (pins) and al-leviate redundant training on non-helpful ra-tionales (noirs).
experiments on two repre-sentative classiﬁcation tasks show that our pro-posed methods can push a classiﬁcation modelto effectively learn crucial clues from non-perfect rationales while maintaining the abilityto spread its focus to other unlabeled importantwords, thus signiﬁcantly outperform existingmethods..1.introduction.
recent studies have shown an increasing interest inincorporating human knowledge into neural net-work models (xu et al., 2018; vashishth et al.,2018; luo et al., 2018; li and srikumar, 2019;jiang et al., 2020).
for many natural languageprocessing (nlp) tasks, such domain knowledgeoften refers to salient words annotated by humanexperts, which are also called rationales.
table 1(top) shows an example of expert-annotated ratio-nales for sentiment analysis, which highlight note-worthy tokens and score the contributions of thesetokens.
the detailed annotations reﬂect the impor-tance of these words from the expert annotator’sviewpoint and are expected to help training bettersentiment classiﬁcation models..∗ corresponding author..expertlabeled.
painful[0.1] to watch, but[0.7] viewers willing totake a chance will be rewarded[0.6] with two of theyear’s most accomplished[0.6] and riveting[0.9]ﬁlm performance..distantlylabeled.
painful to watch, but viewers willing to take(cid:58)(cid:58)(cid:58)(cid:58)(cid:58)a chance will be rewarded with two of theyear’s most accomplished and (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)riveting ﬁlm per-formance..table 1: an example of rationale annotation for senti-ment analysis.
words in underline are rationales anno-tated by human experts, and (cid:58)(cid:58)(cid:58)(cid:58)(cid:58)words in wavy underlineare annotated via sentiment lexicon matching.
num-bers in [] are salience scores labeled by experts..nonetheless, careful, case-by-case rationale an-notations inevitably involve large amounts of man-ual efforts, and are often extravagant or not evenavailable.
in practice, distantly-labeled rationalesserve as a plausible alternative.
instead of labellingcase by case, annotators could design heuristicrules to generate rationales for the whole dataset.
for instance, in sentiment analysis, annotators cancollect words with strong sentiment polarity (posi-tive or negative) to construct a sentiment lexicon,with which they can automatically annotate ratio-nales in a short time through word matching, suchas painful and riveting in the bottom case of ta-ble 1. when comparing the bottom annotation withthe top one, we should admit that the automaticannotations are not perfect, where they indeed in-clude useful clue words towards sentiment predic-tion.
but there should be differences of importanceamong those automatically annotated words, e.g.,compared to painful, riveting is more important todecide the sentiment of the sentence, and severalimportant clues are still missing, e.g., but, accom-plished, rewarded, etc.
distantly-labeled rationalesdrastically reduce the cost of generating precisecase-speciﬁc annotations while preserving a cer-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5571–5582august1–6,2021.©2021associationforcomputationallinguistics5571tain degree of reliability, thus are widely used..however, just as researchers apply auxiliary mea-sures to enforce higher concentration on distantly-labeled rationales and expect substantial modelgains, potential ﬂaws in the quality of those ratio-nales quietly arise to hinder the model from bene-ﬁting from human priors.
speciﬁcally, as discussedin the sample annotations, we ﬁnd there are, amongothers, mainly two types of quality issues lying indistantly-labeled rationales:.
insufﬁciency.
since distantly-labeled rationalesdo not include case-speciﬁc checking and only con-tain universally helpful words according to prede-ﬁned rules/lexicons, such rationales may not pro-vide sufﬁcient supporting evidence in individualcases, and more information from non-rationalewords may be necessary towards the ﬁnal classi-ﬁcation.
given an instance with distantly-labeledrationales, we call the unlabeled words that arecontributing to the ﬁnal prediction as potential im-portant non-rationales, or pins for short, e.g., butand rewarded in the bottom of table 1..indiscrimination.
although distantly-labeledrationale words are often universally helpful, givena speciﬁc context, different rationale words may ex-hibit varied importance.
if those distantly-labeledrationales are applied in a 0-1 form to all instancesand treated equally important, the tremendous di-versity of actual importance in individual cases isjust ignored.
we refer to the distantly-labeled ratio-nale words that are not helpful in a speciﬁc instanceas non-important rationales, or noirs for short.
although many existing works have attemptedto incorporate automatically-obtained rationalesin different ways and achieved promising resultsin various applications (liu et al., 2017; nguyenand nguyen, 2018; ghaeini et al., 2019; liu andavci, 2019), they do not explicitly examine thequality issues of distantly-labeled rationales, norformally consider them during modeling, except(poulis and dasgupta, 2017), which incorporatevague feature feedback into a linear classiﬁer.
onthe one hand, most existing methods try to applystrict constraints to require model focus to con-form to rationales, often encouraging those wordsto share all the model focus (nguyen and nguyen,2018; liu and avci, 2019).
however, as distantly-labeled rationales are often insufﬁcient to draw cor-rect conclusions, the rigid requirements may turnout to incorrectly ignore the pins.
on the otherhand, rationale words are often expected to share.
equal importance, which is not the case in practiceand can falsely lift the focus on noirs..in this paper, we seek better ways to exploitdistantly-labeled rationales, and analyze to whatextent the aforementioned quality issues can be al-leviated with our methods.
we propose two novelgradient-based schemes, namely order loss andgate loss, to handle the insufﬁciency and indis-crimination problems, respectively.
order losspresents a relaxed constraint on rationales by re-quiring them to have higher gradients than non-rationales, instead of occupying the entire modelfocus.
gate loss introduces an early stop mecha-nism, which prevents over training that enhancesthe signiﬁcance of non-helpful rationales.
we eval-uated our methods on two nlp tasks, sentimentanalysis and event detection, and the experimentalresults show that our methods can better exploitnon-perfect distantly-labeled rationales, paying at-tention to pins while avoiding over-training onnoirs, thus outperforms competitive counterparts.
our main contributions are as follows: (1) weformally address the quality issues of distantly-labeled rationales, namely insufﬁciency and indis-crimination, and propose two novel loss functionsto push the model training process while taking thepotential important non-rationales (pins) and non-important rationales (noirs) into account.
thetwo new losses can also be jointly used and leadto further improvement.
(2) we conduct compre-hensive evaluations on two classiﬁcation tasks andour analysis shows that our proposed methods canbetter deal with automatically-annotated rationales,even in a lower quality..2 word salience.
before elaborating on our proposed methods, weﬁrst introduce the deﬁnition of word salience, ameasure of the importance of words, which iswidely applied in previous works (luo et al., 2018;nguyen and nguyen, 2018; jin et al., 2020).
given a model f and an input word sequencex = (x1, x2, ..., xn), the word salience is a vectors = (s1, s2, ..., sn) that denotes the importance ofevery word in x, where si indicates how much xicontributes to the model f ..prior works have explored different methods todetermine word salience (ribeiro et al., 2016; jinet al., 2020).
among them, we choose gradient-based methods since they are model-agnostic andeasy to obtain.
moreover, since gradient-based.
5572word salience is differentiable with respect tomodel parameters, taking it as part of the objec-tive makes it more convenient to optimize the loss.
for a function f , the magnitude (absolute value)of its gradients with respect to input x indicateshow sensitive the ﬁnal decision is to the changeof x (li et al., 2016).
in most nlp settings, thegradient of a word is the sum of gradients for eachdimension of word embeddings.
formally, the gra-dient of an input word xi to a function f can becalculated as:(cid:13)(cid:13)(cid:13)(cid:13).
∂f∂xi.
gi =.
(1).
(cid:13)(cid:13)(cid:13)(cid:13)1.where (cid:107)·(cid:107)1 is the l1 norm that sums up the absolutevalue of gradients over the embedding dimensions.
for gradient-based methods, we use the normal-ized gradients to calculate word salience, whichrepresents the proportion of a word’s contributionin a sentence:.
si =.
gij=1 gj.
(cid:80)n.(2).
there exist more complicated gradient-basedmethods for calculating word salience (sundarara-jan et al., 2017).
here, we base the salience on thevanilla gradient method, for the following reasons:1) it is simple yet sufﬁciently effective to representword salience (ross et al., 2017); 2) the calcula-tion cost of the vanilla version is minimal amongall gradient-based methods..3 our methods.
to incorporate human rationales into neural mod-els, most existing works introduce an auxiliary lossto impel the neural network model to put more em-phasis on rationale annotations.
formally, for amulti-class classiﬁcation problem, the joint objec-tive can be formalized as:.
minimize the inﬂuence of noirs and leave enoughspace for pins as well..3.1 base loss.
most previous works consider all rationale wordsas carefully annotated and ﬂawless, without takingthe quality issues into account (liu et al., 2017; liuand avci, 2019).
generally, their main assumptioncould be written as: a1: all rationales contributeequally to the model, while other words shouldnot contribute.
according to this assumption, thesalience of every rationale word should be equalto each other, which is 1k for a sentence with kannotated rationale words.
meanwhile, the salienceof non-rationale words is set as 0. when using l2norm to measure the difference between the currentword salience and the expected values (0 or 1) foreach word, we can write the constraint loss as:.
la base =.
si −.
(cid:33)2.
(cid:80)n.zij=1 zj(cid:19)2.
(cid:32).
(cid:88).
zi=1.
(cid:88).
(cid:18).
zi=1.
=.
si −.
1k.(4).
zij=1 zj.
where si is the salience of rationale word xi andis the expected value for xi, which equals(cid:80)n1/k for a sentence with k annotated rationalewords, since z is a binary vector..although this loss exhibits a feasible way to al-low rationales to receive higher concentration, italso has two distinct shortcomings.
firstly, ratio-nales often possess varied importance in real-worldcases, which makes it improper to strictly requireequal concentration.
second, for the importantwords not covered in rationales, they are totallyignored and cannot contribute to the prediction..ljoint = lc(x, y) + λla(s, z).
(3).
3.2 order loss: exploiting pins.
where lc is the classiﬁcation loss based on in-put sentence x and ground truth label y, and lais a constraint function which conforms wordsalience s with a binary vector of rationale labelsz = (z1, z2, ..., zn) where zi is 1 if xi is important,otherwise, zi is set to 0. λ is the hyper-parametercontrolling the weight of the auxiliary loss..we start with a discussion on a base loss cur-rently in use, which suffers from the insufﬁciencyand indiscrimination of non-perfect rationales.
al-ternatively, we introduce two methods, namely or-der loss and gate loss, which help models to.
for distantly-labeled rationales, a1 pushes the clas-siﬁcation model not to make use of potential im-portant words outside rationale annotations, andsqueezes them to receive little focus.
to make bet-ter use of these pins, we seek to relax the restric-tions between rationales and non-rationales, andpropose the following assumption as an alternative:a2: rationale words should get more focus thannon-rationales.
based on this assumption, we candirectly build up a formal restriction between anypair of rationale word and non-rationale word:.
si > sj ∀xi ∈ sr, ∀xj ∈ sn.
(5).
5573where sr is the set of annotated rationale words,sn is the non-rationale set, and si and sj are thesalience of words xi and xj, respectively.
thisrestriction enumerates all the possible pairs of an-notated rationale and non-rationale words, and in-volves massive computation.
for a sentence oflength n with k labeled rationale words, constrain-ing the above order relationship (eq.
5) leads toconsidering k(n − k) terms in the auxiliary loss.
this is expensive for longer sentences with sparserationale annotations.
it is worth looking for a moreefﬁcient constraint method that is irrelevant to sen-tence length and only involves rationale numbers.
if we know the maximum valuemax sj in sn in advance, most of the comparisonsin (eq.
5) can be omitted, because requiring an sito be greater than every sj is equivalent to requir-ing si > max sj.
therefore, we can simplify therestriction in eq.
5 to:.
however,.
si > max sj ∀xi ∈ sr, ∀xj ∈ sn.
(6).
since salience can vary enormously in ordersof magnitude, it is hard to determine λ in eq.
3and converge to a stable state if we just calculatethe loss regarding the difference between si andmax sj.
in order to obtain a loss that is insensi-tive to the magnitude of salience, we adjust therestriction to an equivalent form:.
simax sj.
> 1 ∀xi ∈ sr, ∀xj ∈ sn.
(7).
and its corresponding auxiliary loss can be writtenas:.
.
.
min.
.
(cid:88).
zi=1.
simaxzj =0.
sj.
.
.
2.
− 1, 0.
.
.
(8)sj is the maximum salience among all.
la order =.
where maxzj =0.
non-rationale words.
the min function guaran-tees that no restrictions will be applied as long asthe maximum salience of non-rationale words issmaller than any rationale word..3.3 gate loss: handling noirs.
distantly-labeled rationale words may vary dramat-ically in quality.
non-helpful rationale words mayincorrectly attract the model focus, which may con-fuse the model and affect its performance.
to ad-dress this problem, we thus make a new assumption,which prevents the model from overly focusing onthe rationales that are not helpful: a3: only part.
of the rationales, or crucial rationales, should at-tain higher focus.
this could encourage a model togive little focus to certain annotated rationale wordsthat are identiﬁed as non-helpful during training..since base loss explicitly requires an equal fo-cus on all rationale words, the model will drag thesalience of rationales to be equal after long peri-ods of training.
this is not expected for distantly-labeled rationales, as some of them may not be help-ful.
we expect an adaptive early-stop mechanismfor such losses in order to prevent over-training onthose non-helpful rationales..speciﬁcally, we consider halting the auxiliaryconstraining process when rationale words in an in-stance have gained adequate focus in total.
this in-dicates that some rationale words are already iden-tiﬁed as important during training.
as those ratio-nal words are sufﬁcient towards ﬁnal classiﬁcation,there is no need to enhance the others.
in contrast,for instances where the total focus for all rationalewords remains at a lower level, they should possessa higher priority in the remaining training process.
to this end, we add a gate term to base lossto form gate loss, in order to adaptively deter-mine whether to skip the gradient constraints forthe current instance:.
la gate = bern(1−.
(cid:88).
(cid:88).
si).
(si −1)2 (9).
xi∈sr.
xi∈sr.
where bern(p) is the bernoulli distribution with pa-rameter p.1 the gate term can be similarly attachedto order loss to jointly apply the two methods:.
la gate+order = bern(1 −.
si)la order.
(cid:88).
xi∈sr.
(10)with this term eq.
9, constraints are givenless and less opportunity as the sum of rationalesalience rises.
the more focus the current ratio-nales receive in total, the less likely the instancewill be further trained on.
thus, the gate termacts as a gate for sentences with both helpful andnon-helpful rationales: as the most helpful ratio-nale words quickly stand out and take up a higherproportion in salience, rationales in these sentenceswill have lower chances to receive training in the fu-ture iterations.
in other words, the gate term allowsthe model to focus on instances whose rationalewords are not well modeled..1we have also tried other common methods besidesbernoulli distribution, and the results are shown in the ap-pendix..55744 experiments.
we evaluate our methods on two sentence classiﬁ-cation tasks, sentiment analysis and event triggerdetection, on stanford sentiment treebank (sst)and ace-2005, respectively, which have been con-sidered as a suitable testbed to investigate how addi-tional rationales can help to improve a base model.
stanford sentiment treebank (sst) (socheret al., 2013) includes 10,662 sentences tagged withsentiment on a scale of 1 (most negative) to 5 (mostpositive).
we ﬁlter out neutral instances and dividethe remaining sentences into positive (4, 5) andnegative (1, 2), making it a binary classiﬁcationtask.
there are 6920 sentences in training set, 872sentences in validation set and 1821 sentences intest set.
in sst, words are labeled with 5 levels ofsentiment polarity.
we take the words with extremepositive polarity (label 1) or negative polarity (la-bel 5) as our sentiment lexicon, which is used toautomatically annotate rationale words in each sen-tence.
56.7% training instances have at least onerationale word.
there are 0.85 annotated rationalewords per sentence on average, and the averagesentence length for training is 19.3 words..ace-2005 (christopher et al., 2006) is an eventdetection (ed) dataset.
following previous worksin event detection (nguyen and grishman, 2015),we consider event trigger detection as a classiﬁ-cation task.
that is, for every token in a givensentence, we aim to predict whether the currenttoken is an event trigger or not.
here, we do notconsider identifying event types and formulate it asa binary classiﬁcation task for ease of exposure..previous studies show that trigger words arestrong, universal features that can indicate eventsof speciﬁc types.
therefore, in each sentence, weautomatically label a word as rationale if and onlyif it has been labelled at least once as a trigger inthe training set.
we use the same split as (ji andgrishman, 2008), with 14,849 sentences for train-ing, 836 for validation, and 672 for testing.
88.7%of training sentences have been annotated with atleast one rationale word.
on average, there are 4.66rationale words per sentence..evaluation metrics following previous works,we use accuracy (acc) and f1-scores (f1) as theevaluation metrics on sst.
we use f1-score as theonly metrics on ace-2005 and do not examine ac-curacy, since this dataset is extremely unbalanced,where a model predicting all instances into negative.
can achieve over 97.5% acc.
we run each setting5 times and report mean and standard deviations..implementation details our basic classiﬁca-tion model is a convolutional neural network(cnn)(ghaeini et al., 2019).
the input tokens areﬁrst transformed to word embeddings, which are300-dimension glove vectors (pennington et al.,2014) in sst, and the combination of a 300-dimension glove embedding and a 50-dimensionentity (originally labeled) embedding in ace-2005.
then, a convolution layer with 200 kernels, viz.
50kernels with width 2, 3, 4 and 5 respectively, is usedto extract local features, followed by a feed forwardneural network to gain hidden representations ofwords.
we then calculate the sentence representa-tion using the attention mechanism, and feed it intoa softmax regression to obtain estimated probabil-ity distribution.
all activation functions are tanh,the dropout rate is 0.5, and the batch size is 512for sst and 256 for ace.
we optimize the modelwith adam (kingma and ba, 2015) with learningrate = 10−3, β1 = 0.9, β2 = 0.999 and (cid:15) = 10−8.
the l2-normalization rate is set to 10−4..for instances without any annotated rationale.
words, we do not apply auxiliary losses to them..comparison methods besides the base cnnmodel, we compare our methods with 2 recentworks that combine the same cnn architecturewith additional rationales: cnn: the vanillacnn classiﬁer trained with the cross-entropy loss.
saliency learning (sl): ghaeini et al.
(2019) pro-poses a broad constraint that requires all rationalewords to have positive gradients.
integrated gradi-ent attribution (iga): liu and avci (2019) use theintegrated gradient (sundararajan et al., 2017) tocalculate the attributions of a classiﬁcation model,and force the model to focus on rationales by re-stricting their attributions to be 1 , where the wordattribution is similar to word salience in our work..4.1 main results.
table 2 shows the performance of different methodson sst and ace-2005..we ﬁrst notice that previous approaches, bothsaliency learning and ig attribution, performslightly better than the baseline cnn classiﬁer,without signiﬁcant improvement.
this is not sur-prising, since in our setup, the rationale annotationsare automatically collected, far from perfect com-pared to expert-annotated ones.
although both.
5575model.
baseline.
sliga.
+ base loss+ gate loss+ order loss+ gate + order.
accuracy (sst).
f1-score (sst).
f1-score (ace-2005).
mean + std..sig.
p.mean + std..sig.
p.mean + std..sig.
p.0.847 ± 0.002.
0.849 ± 0.0030.848 ± 0.002.
0.851 ± 0.0040.852 ± 0.0030.862 ± 0.0030.861 ± 0.004.
-.
--.
--0.0080.013.
0.851 ± 0.003.
0.851 ± 0.0040.852 ± 0.002.
0.854 ± 0.0040.854 ± 0.0050.862 ± 0.0030.862 ± 0.003.
-.
--.
--0.0410.047.
0.698 ± 0.004.
0.704 ± 0.0040.703 ± 0.003.
0.705 ± 0.0050.714 ± 0.0060.715 ± 0.0050.726 ± 0.008.
-.
--.
-0.0440.0320.002.table 2: performance of our approaches on two dataset with cnn as base model.
saliency learning and igattribution are our implementations of two previous gradient constraint methods.
+base, +order, +gate stand formodels with corresponding auxiliary losses, and +gate+order is order loss combined with the gate term.
sig.
pcolumns report the p-value of t-test with +base loss..sl and iga push the classiﬁcation model to fo-cus on those rationales, neither of them takes intoaccount the quality issues of distantly-labeled ratio-nales, i.e., insufﬁciency and indiscrimination, thusit is difﬁcult for them to bring more signiﬁcant im-provement regarding vanilla cnn.
the base lossmethod also poses strong emphases on the rationalewords without considering pins.
it can bring a bitmore improvement than sl and iga, though notsigniﬁcant enough.
when we push the classiﬁca-tion model to consider the different importance ofthese non-perfect rationale words, our gate lossmethod obtains more signiﬁcant improvement onace-2005.
when formally considering to spreadthe model focus to pins, our order loss methodobtains signiﬁcant improvement, 1.1% and 1.7%improvement in f1 than vanilla cnn on sst andace-2005, respectively..now we look closer at the performance of ourproposed methods.
on ace-2005, applying orderloss and gate loss can both signiﬁcantly outper-form vanilla cnn in f1-scores, by 1.7% and 1.6%,respectively.
this is more than twice the improve-ment gained by the base loss (0.7%), which indi-cates that properly modeling the insufﬁciency andindiscrimination issues are indeed necessary whenworking with distantly-labeled rationales.
it is note-worthy that combining order loss and gate lossfurther improves the f1-score by as much as 2.8%,which is larger than any of their separate applica-tions.
this illustrates that the two new methods,aiming at different quality issues, can be appliedtogether in a natural/integral form to jointly exploitdistantly-labeled rationales..although our order loss method can bringnoticeable improvement, 0.8% in f1 than baseloss, on sst, our gate loss and the base loss.
only achieves comparable performance with vanillacnn.
we believe the reason is that sst actuallysuffers from severe insufﬁciency issues.
there areonly 0.85 rationale words per sentence in sst, but4.66 rationales per sentence in ace-2005.
giventhat 76.7% sentences hold only 1 annotated ratio-nale word, there is not much for the early-stopmechanism in our gate loss to do on sst.
in thiscase, the gate loss boils down to the base version.
that is also why the order loss obtains signiﬁcantimprovement (1.1% more in f1 than base loss) onsst, which is designed to encourage those pins tocontribute to model training as well..5 analysis.
5.1 efﬁcacy analysis.
in order to understand the running mechanisms ofour methods, we should look at what our methodshave done with the non-perfect rationales.
to thisend, we examine the inﬂuence of our proposedlosses by analyzing the average salience scores oftwo speciﬁc types of words in ace-2005, eventarguments and gold triggers, corresponding to thetarget of order loss and gate loss, respectively.
arguments refer to entities (mentions) involvedin an event.
they are not annotated as rationalesby us, but previous studies show the importanceof these words for event extraction (nguyen andgrishman, 2018).
we expect the order loss couldmaintain enough focus on them..gold triggers in a sentence refer to the gold-standard event trigger annotations in ace 2005,which are considered to indeed cause that sentenceto be labeled as an event mention by the ace an-notators.
as the decisive factor for event detection,the gold triggers deﬁnitely serve as essential indi-.
5576figure 1: average salience scores of argument wordswith base loss and order loss on ace-2005.
as train-ing proceeds, base loss forces the argument to littlefocus, while salience scores in order loss maintain ahigh level..figure 2: average salience scores of crucial rationales(gold triggers) and the average salience of all ratio-nales with base loss and gate loss on ace-2005.
af-ter around 1500 training steps, base loss drives thesalience of gold triggers towards average, while gateloss remains high discernment compared with baseloss, with a higher focus on gold triggers and a loweraverage for all rationales..cators, and consistently deserve high focus fromthe detection model.
we will explore whether gateloss can successfully perceive them and renderthem lasting, sufﬁcient focus..give weight to helpful non-rationales we cal-culate the average salience scores of argumentwords on ace-2005 with the base loss and orderloss methods, respectively.
as shown in fig 1, theaverage salience score of arguments when applyingthe base loss is much lower compared with theorder loss during the whole training procedure.
equipped with the order loss, the salience tends tostabilize at a high level.
this illustrates that, unlikebase loss, order loss allows arguments to obtainmodel emphasis.
thus, potential important wordsbeyond rationales are able to contribute, makingthe model prediction more accurate..focus on crucial rationales the averagesalience scores of gold triggers and all rationalewords are plotted in figure 2. as can be seen, forboth gate loss and base loss, the salience score.
figure 3: results of perturbation experiments on ace-2005.
(a) shows the consequences of randomly remov-ing 10%, 20%, 30% of the distantly-labeled rationales,and (b) shows the effects of randomly adding 5%, 10%,15% extra words to rationale annotations..of gold triggers increases quickly and surpassesthe average salience scores of all rationales at thebeginning.
however, the salience score of goldtriggers in base loss begins to decline as trainingproceeds, to ﬁnally comparable with other ratio-nales.
in contrast, with gate loss, the salience ofgold triggers remains rather stable at a high value.
such stability shows that the early-stop mechanismintroduced by gate loss helps maintain the focuson these crucial rationales, instead of forcing themto approach average..5.2 robustness analysis.
as shown in the previous section, our proposedmethods can alleviate the insufﬁciency and indis-crimination issues of the non-perfect rationales.
here, we take a step forward to the robustness ofour proposed methods, e.g., how our methods willperform when given a much lower quality of ratio-nales..working with scarcer rationales now the ques-tion is: how our method will perform if therationale-labeling rules are less inclusive and therationales are even scarcer?
to study the stabilityof the order loss, we create a more tough situ-ation of scarcer rationales by gradually throwingaway a small, random proportion of words fromthe original rationales on ace-2005..figure 3(a) shows the performance of order loss.
55770500100015002000training step0.0150.0200.0250.0300.0350.040average salienceorder lossbase loss0500100015002000training step0.050.100.150.0200.0250.0300.0350.0400.045average saliencegate-triggerbase-triggerbase-rationalegate-rationale02468101214(b) random adding percentage of the rationales70.070.571.071.572.0f1 scores(%)gate lossbase lossbaseline02468101214(a) random dropping percentage of the rationales70.2570.5070.7571.0071.2571.5071.7572.00f1 scores(%)order lossbase lossbaselineunder up to 30% reduction of rationales, comparedwith base loss.
we see that order loss undergoesonly minor losses of performance as more rationalewords are transferred to non-rationales, since orderloss is designed to consider the pins by spreadingthe model focus to those non-rationale words thatcan contribute to the ﬁnal classiﬁcation.
however,base loss gradually loses its ability to incorporatepriors, since it attempts to give the model focusentirely to the rationales, and ﬁnally slides to nearbaseline performance at around 30% amount ofperturbation.
this indicates that our order losscan stably and efﬁciently learn from insufﬁcientrationales while keeping an eye on other helpfulwords that are left out..working with noisy rationales a robust modelshould be capable of discerning whether a word isimportant indeed by itself, instead of simply check-ing the rationale label.
we seek to examine whetherthe gate loss can still take effect under more andmore severe pollution of false rationales.
specif-ically, we intentionally introduce noises to the ra-tionale annotations by randomly labeling severalnon-rationale words in each case as “rationale” inace-2005, and see how the performance of differ-ent methods is affected..as can be seen in figure 3(b), more noises donot pose a big threat to gate loss, with only a0.6% decline in its performance under at most 15%amount of perturbation.
however, base loss turnsout to be highly dependent on the purity and reli-ability of the rationales, as its performance drasti-cally falls to even below baseline within less than10% perturbation.
this is not surprising, since baseloss requires equally high attention on rationales,which is unreasonable for noisy rationale annota-tions.
nonetheless, the early-stop mechanism ofgate loss circumvents overtraining on noises, thusoutperforming the rigid requirements of base loss..6 related works.
incorporating human priors has been well studiedin different nlp applications with different formsof rationales.
zaidan et al.
(2007) attains a morereliable support vector machine by adding con-trast training examples, which mask out importantsubstrings.
yu et al.
(2019) exploit pre-annotatedrationales to train an extractor and use the extractedwords for classiﬁcation.
luo et al.
(2018) concate-nates information of regular expressions to wordembeddings for spoken language understanding..jiang et al.
(2020) uses an rnn to model regular ex-pressions for text classiﬁcation tasks.
most of theseworks provide effective ways to utilize word-levelknowledge, but none of them formally considersthe quality issues with the distantly-labeled ratio-nales.
additionally, poulis and dasgupta (2017)discuss the insufﬁciency issue in the feature feed-back framework, and try to incorporate vague fea-ture feedback into a linear classiﬁer..as a widely-used explanation method, the atten-tion mechanism is often applied with constraintsto guide model focus towards the signiﬁcant partof inputs (liu et al., 2017; nguyen and nguyen,2018; bao et al., 2018).
our proposed methods arecurrently based on gradient-based salience calcula-tion, which is easier to obtain and model-agnostic,thus can be applied to a wider range with ease.
butour methods do not depend on speciﬁc calculationmethods for word salience, and can be easily trans-planted to attention-based constraints, which wewill leave for future work..recent studies have provided various techniquesto constrain gradient-based word salience.
rosset al.
(2017) forces the gradient of features, whichare annotated non-helpful, to be zero, to alter thedecision boundary of the model.
liu and avci(2019) calculates l2 distance between path inte-grated gradients attribution for selected tokens anda target value in the objective function, to mitigateunintended bias in toxic comment classiﬁcation andimprove classiﬁer performance in scarce settings.
ghaeini et al.
(2019) requires the gradients of allrationales to be positive to encourage the modelto focus on salient words.
the success of theseworks motivates us to further explore the impact ofdistantly-labeled rationales, which are easier to ob-tain but will bring challenges to previous methodsas we have shown in experiments.
in our method,we formally consider the insufﬁciency and indis-crimination issues, and design two losses to notonly push the classiﬁcation model to take care ofthose potentially important non-rationales, but alsodiscriminatively focus on rationales to avoid over-training on those non-helpful annotations..there is another line of works that try to ex-plicitly produce human-readable rationales duringmodel learning.
lei et al.
(2016) use reinforce-ment learning to identify keywords as rationalesto improve model interpretability.
deyoung et al.
(2020) further constructs a benchmark dataset toengage the research about interpretable model de-.
5578sign.
while, our work is to examine how to betterincorporate non-perfect rationales into neural net-work models, which is orthogonal to that line ofresearch..7 conclusions.
while distantly-labeled rationales are easy to ob-tain, they are often insufﬁcient and indiscriminative,compared with high quality expert annotations.
inthis paper, we provide new perspectives on how todeal with such rationales, and propose two novelmethods to guide a classiﬁcation model to learnfrom potentially important non-rationales whileavoiding over-training on noisy annotations.
ex-periments on two nlp classiﬁcation tasks showthat our methods can effectively tackle the men-tioned quality issues and are robust enough to ex-ploit the non-perfect rationales even in more toughsituations.
our methods are not limited to spe-ciﬁc salience calculations, we hope to explore moreforms of word salience and rationales in the future.
we also expect our approaches to be beneﬁcial inother scenarios where rationales are noisy and in-complete.
this even includes scenarios when ratio-nales are not distantly labeled, e.g., crowdsourcedhuman annotations with low agreement (sen et al.,2020)..acknowledgments.
we thank the anonymous reviewers for the helpfulcomments and suggestions.
this work is supportedin part by the national hi-tech r&d program ofchina (2018yfc0831900) and the nsfc grants(no.61672057, 61672058)..references.
yujia bao, shiyu chang, mo yu, and regina barzilay.
2018. deriving machine attention from human ra-tionales.
in proceedings of the 2018 conference onempirical methods in natural language processing,pages 1903–1913, brussels, belgium.
associationfor computational linguistics..walker christopher, strassel stephanie, medero julie,and kazuaki maeda.
2006. ace 2005 multilingualtraining corpus..jay deyoung, sarthak jain, nazneen fatema rajani,eric lehman, caiming xiong, richard socher, andbyron c. wallace.
2020. eraser: a benchmark toevaluate rationalized nlp models.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics, pages 4443–4458, on-line.
association for computational linguistics..reza ghaeini, xiaoli fern, hamed shahbazi, andprasad tadepalli.
2019. saliency learning: teach-ing the model where to pay attention.
in proceed-ings of the 2019 conference of the north americanchapter of the association for computational lin-guistics: human language technologies, volume 1(long and short papers), pages 4016–4025, min-neapolis, minnesota.
association for computationallinguistics..heng ji and ralph grishman.
2008. reﬁning event ex-traction through cross-document inference.
in pro-ceedings of acl-08: hlt, pages 254–262, colum-bus, ohio.
association for computational linguis-tics..chengyue jiang, yinggong zhao, shanbo chu, libinshen, and kewei tu.
2020. cold-start and inter-pretability: turning regular expressions into train-in proceedings ofable recurrent neural networks.
the 2020 conference on empirical methods in nat-ural language processing (emnlp), pages 3193–3207, online.
association for computational lin-guistics..xisen jin, zhongyu wei, junyi du, xiangyang xue,and xiang ren.
2020. towards hierarchical im-portance attribution: explaining compositional se-in 8th inter-mantics for neural sequence models.
national conference on learning representations,iclr 2020, addis ababa, ethiopia, april 26-30,2020. openreview.net..diederik p. kingma and jimmy ba.
2015. adam: ain 3rd inter-method for stochastic optimization.
national conference on learning representations,iclr 2015, san diego, ca, usa, may 7-9, 2015,conference track proceedings..tao lei, regina barzilay, and tommi jaakkola.
2016.rationalizing neural predictions.
in proceedings ofthe 2016 conference on empirical methods in nat-ural language processing, pages 107–117, austin,texas.
association for computational linguistics..jiwei li, xinlei chen, eduard hovy, and dan jurafsky.
2016. visualizing and understanding neural modelsin nlp.
in proceedings of the 2016 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, pages 681–691, san diego, california.
as-sociation for computational linguistics..tao li and vivek srikumar.
2019. augmenting neu-in proceed-ral networks with ﬁrst-order logic.
ings of the 57th annual meeting of the associationfor computational linguistics, pages 292–302, flo-rence, italy.
association for computational linguis-tics..frederick liu and besim avci.
2019..incorporatingpriors with feature attribution on text classiﬁcation.
in proceedings of the 57th annual meeting of theassociation for computational linguistics, pages6274–6283, florence, italy.
association for compu-tational linguistics..5579shulin liu, yubo chen, kang liu, and jun zhao.
2017. exploiting argument information to improveevent detection via supervised attention mechanisms.
in proceedings of the 55th annual meeting of theassociation for computational linguistics (volume1: long papers), pages 1789–1798, vancouver,canada.
association for computational linguistics..andrew slavin ross, michael c. hughes, and finaledoshi-velez.
2017. right for the right reasons:training differentiable models by constraining theirin proceedings of the twenty-sixthexplanations.
international joint conference on artiﬁcial intelli-gence, ijcai 2017, melbourne, australia, august19-25, 2017, pages 2662–2670.
ijcai.org..bingfeng luo, yansong feng, zheng wang, songfanghuang, rui yan, and dongyan zhao.
2018. marry-ing up regular expressions with neural networks: acase study for spoken language understanding.
inproceedings of the 56th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 2083–2093, melbourne, aus-tralia.
association for computational linguistics..cansu sen, thomas hartvigsen, biao yin, xiangnankong, and elke rundensteiner.
2020. human at-tention maps for text classiﬁcation: do humans andneural networks focus on the same words?
in pro-ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4596–4608, online.
association for computational lin-guistics..minh nguyen and thien huu nguyen.
2018. whois killed by police: introducing supervised attentionfor hierarchical lstms.
in proceedings of the 27thinternational conference on computational linguis-tics, pages 2277–2287, santa fe, new mexico, usa.
association for computational linguistics..thien huu nguyen and ralph grishman.
2015. eventdetection and domain adaptation with convolutionalneural networks.
in proceedings of the 53rd annualmeeting of the association for computational lin-guistics and the 7th international joint conferenceon natural language processing (volume 2: shortpapers), pages 365–371, beijing, china.
associa-tion for computational linguistics..thien huu nguyen and ralph grishman.
2018. graphconvolutional networks with argument-aware pool-ing for event detection.
in proceedings of the thirty-second aaai conference on artiﬁcial intelligence,(aaai-18), the 30th innovative applications of arti-ﬁcial intelligence (iaai-18), and the 8th aaai sym-posium on educational advances in artiﬁcial intel-ligence (eaai-18), new orleans, louisiana, usa,february 2-7, 2018, pages 5900–5907.
aaai press..jeffrey pennington, richard socher, and christophermanning.
2014. glove: global vectors for wordrepresentation.
in proceedings of the 2014 confer-ence on empirical methods in natural languageprocessing (emnlp), pages 1532–1543, doha,qatar.
association for computational linguistics..stefanos poulis and sanjoy dasgupta.
2017. learningwith feature feedback: from theory to practice.
inproceedings of the 20th international conference onartiﬁcial intelligence and statistics, volume 54 ofproceedings of machine learning research, pages1104–1113, fort lauderdale, fl, usa.
pmlr..marco t´ulio ribeiro, sameer singh, and carlosguestrin.
2016.
”why should i trust you?”: explain-in proceed-ing the predictions of any classiﬁer.
ings of the 22nd acm sigkdd international con-ference on knowledge discovery and data mining,san francisco, ca, usa, august 13-17, 2016, pages1135–1144.
acm..richard socher, alex perelygin, jean wu, jasonchuang, christopher d. manning, andrew ng, andchristopher potts.
2013. recursive deep modelsfor semantic compositionality over a sentiment tree-in proceedings of the 2013 conference onbank.
empirical methods in natural language processing,pages 1631–1642, seattle, washington, usa.
asso-ciation for computational linguistics..mukund sundararajan, ankur taly, and qiqi yan.
2017.in pro-axiomatic attribution for deep networks.
ceedings of the 34th international conference onmachine learning, icml 2017, sydney, nsw, aus-tralia, 6-11 august 2017, volume 70 of proceedingsof machine learning research, pages 3319–3328.
pmlr..shikhar vashishth, rishabh joshi, sai suman prayaga,chiranjib bhattacharyya, and partha talukdar.
2018.reside: improving distantly-supervised neural re-lation extraction using side information.
in proceed-ings of the 2018 conference on empirical methodsin natural language processing, pages 1257–1266,brussels, belgium.
association for computationallinguistics..jingyi xu, zilu zhang, tal friedman, yitao liang, andguy van den broeck.
2018. a semantic loss func-tion for deep learning with symbolic knowledge.
inproceedings of the 35th international conference onmachine learning, icml 2018, stockholmsm¨assan,stockholm, sweden, july 10-15, 2018, volume 80 ofproceedings of machine learning research, pages5498–5507.
pmlr..mo yu, shiyu chang, yang zhang, and tommijaakkola.
2019. rethinking cooperative rationaliza-tion: introspective extraction and complement con-in proceedings of the 2019 conference ontrol.
empirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages4094–4103, hong kong, china.
association forcomputational linguistics..omar zaidan, jason eisner, and christine piatko.
2007.using “annotator rationales” to improve machine.
5580in human lan-learning for text categorization.
guage technologies 2007: the conference of thenorth american chapter of the association for com-putational linguistics; proceedings of the mainconference, pages 260–267, rochester, new york.
association for computational linguistics..5581appendix.
different implementation of gate loss.
considering the sum of rationale words salienceshows whether the rational words have gained ade-quate focus in total, we use bernoulli distributionas a gate to control the constraint in our gate loss:.
la gate = bern(1 −.
(cid:88).
(cid:88).
si).
(si − 1)2.xi∈sr.
xi∈sr.
(11)we have tried other ways to perform the gate.
first, we try to use the sum of rationale salience asa weight directly.
we deﬁne soft gate loss as.
la sof t gate = (.
(cid:88).
(cid:88).
si).
(si − 1)2.
(12).
xi∈sr.
xi∈sr.
another way is to use a threshold to determinewhether the focus rational words gained are sufﬁ-cient.
we deﬁne marginal gate loss as.
la marginal gate = i(.
si ≤ t).
(cid:88).
(cid:88).
(si − 1)2.xi∈sr.
xi∈sr.
(13)where i is an indicator function and t is a prede-ﬁned threshold..the performance of soft gate loss and marginalgate loss is shown in table 3. as can be seen, ourbernoulli gate performs best among all the threegate calculation methods.
soft gate loss can bringa bit more improvement than base loss, but notsigniﬁcant enough, which illustrates that a soft con-trol may not be suitable.
as for the marginal gateloss, its performance is very sensitive to the se-lection of threshold and the best f1 is only 71.1%,which is still lower than bernoulli gate..thus, taking both performance and stability intoconsideration, we choose bernoulli gate as ourimplementation of gate loss..baseline.
+base loss.
+soft.
+marginal (0.9)+marginal (0.7)+marginal (0.5)+marginal (0.3).
+bernoulli.
f1.
0.698.
0.704.
0.707.
0.7090.7110.6980.699.
0.715.table 3: the performance of different gate calculationson ace-2005.
+soft, +marginal, +bernoulli meansuse soft gate loss, marginal gate loss and gateloss respectively.
and the number in the bracket formarginal gate represents the threshold..5582