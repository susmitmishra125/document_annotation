phmospell: phonological and morphological knowledgeguided chinese spelling check.
li huang1,2, junjie li2, weiwei jiang2, zhiyu zhang2,minchuan chen2, shaojun wang2 and jing xiao2.
1fudan university2ping an technologylhuang9703@gmail.com, junjielee815@gmail.com.
abstract.
chinese spelling check (csc) is a challeng-ing task due to the complex characteristics ofchinese characters.
statistics reveal that mostchinese spelling errors belong to phonologicalor visual errors.
however, previous methodsrarely utilize phonological and morphologicalknowledge of chinese characters or heavilyrely on external resources to model their sim-ilarities.
to address the above issues, we pro-pose a novel end-to-end trainable model calledphmospell, which promotes the performanceof csc with multi-modal information.
specif-ically, we derive pinyin and glyph representa-tions for chinese characters from audio andvisual modalities respectively, which are inte-grated into a pre-trained language model by awell-designed adaptive gating mechanism.
toverify its effectiveness, we conduct compre-hensive experiments and ablation tests.
ex-perimental results on three shared benchmarksdemonstrate that our model consistently out-performs previous state-of-the-art models..1.introduction.
chinese spelling check (csc) is a fundamen-tal task in chinese natural language processing(nlp), which aims to automatically detect and cor-rect spelling errors in chinese sentences.
theseerrors typically consist of human writing errors andmachine recognition errors by automatic speechrecognition (asr) or optical character recognition(ocr) systems (yu et al., 2014).
csc serves as apreliminary component for other downstream taskslike information retrieval (ir) in search engine,thus signiï¬cantly affects the ï¬nal performance ofthese tasks..chinese is an ideograph language which containsnumerous characters and has no between-word de-limiters.
these characteristics make its spellingcheck more difï¬cult than other alphabetical lan-guages such as english.
speciï¬cally, for error.
p-s error:wrong sentence: äººä»¬å¿…(pinyin: bi4) ç”Ÿå»è¿½æ±‚çš„ç›®æ ‡ã€‚äººä»¬æ¯•(pinyin: bi4) ç”Ÿå»è¿½æ±‚çš„ç›®æ ‡ã€‚ground truth:v-s error:wrong sentence: è¿æ¥æ¯ä¸€ä¸ªå›º(radicals: å¤,å£) éš¾ã€‚è¿æ¥æ¯ä¸€ä¸ªå›°(radicals: æœ¨,å£) éš¾ã€‚ground truth:.
table 1: examples of p-s (phonological similarity) er-ror and v-s (visual similarity) error from sighan13(wu et al., 2013).
here, the ground truth of the p-serror means â€œthe goal that people pursue throughouttheir livesâ€ and the ground truth of the v-s error meansâ€œget prepared for every difï¬cultyâ€..detection, chinese words usually consist of sev-eral characters and have no clear word boundaries,which makes it impossible to detect spelling errorsjust using individual word or character.
they mustbe put in a speciï¬c sentence to capture contextualsemantic information.
for error correction, howto select correct candidates from tremendous char-acter sets remains a great challenge.
in contrastto english words that are composed of a small setof alphabet letters, there are more than 10k chi-nese characters, and 3.5k of them are frequentlyused (wang et al., 2019b).
besides, unlike english,almost all chinese spelling errors are real-worderrors which means the misspelling one is also avalid character in the vocabulary.
(kukich, 1992;jia et al., 2013; yu and li, 2014)..since a great number of chinese characters aresimilar either in phonology or morphology, theyare easily misused with each other.
according to(liu et al., 2011), 76% of chinese spelling errorsbelong to phonological similarity error and 46%belong to visual similarity error.
table 1 presentsexamples of these two common errors.
the pronun-ciation and the shape of chinese characters can becharacterized by pinyin1 and radicals2, respectively..1pinyin is the ofï¬cial phonetic system of mandarin chi-nese, which usually consists of three parts: initials, ï¬nals andtones..2radical is the basic building blocks of all chinese charac-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5958â€“5967august1â€“6,2021.Â©2021associationforcomputationallinguistics5958previous methods have made attempts to fuse thesetwo information into the process of csc (jin et al.,2014; han et al., 2019; hong et al., 2019; nguyenet al., 2020).
however, pinyin or radicals in thesemethods were used as external resources or heuris-tic ï¬lters and can not be trained with the model inan end-to-end style.
more recently, cheng et al.
(2020) proposed spellgcn, which incorporatedphonological and morphological similarities into apre-trained language model by graph convolutionalnetwork (gcn).
however, their similarity graphsrelied on speciï¬c confusion sets.
since confusionsets are unable to cover all characters, spellgcncan only fuse limited information.
furthermore,they just used a simple aggregate strategy for fea-ture fusion..to tackle the above issues, we propose a novelframework called phmospell.
phmospell incor-porates pinyin and glyph features into a pre-trainedlanguage model via an adaptive gating module forcsc.
these features are derived from intermediaterepresentations of dominant tacotron2 (shen et al.,2018) in text-to-speech (tts) task and vgg19(simonyan and zisserman, 2014) in computer vi-sion (cv) task.
we combine them with semanticrepresentation from a pre-trained language modelby the proposed adaptive gating module, enablingthe model to be trained end-to-end.
comprehen-sive experiments are conducted on three sharedbenchmarks to prove that latent representationsin our method can capture not only semantic butalso phonological and morphological information.
experimental results demonstrate that our methodoutperforms all baseline methods on three bench-marks..the contributions of this paper are in three folds:1) we derive both phonological and morphologi-cal knowledge of chinese characters from multi-modality and apply them to csc.
2) we designa novel adaptive gating mechanism, which effec-tively incorporates the multi-modal informationinto a pre-trained language model in an end-to-endtrainable way.
3) we achieve state-of-the-art per-formance on three benchmark datasets using theproposed model..2 related work.
methods and deep learning based methods.
manguand brill (1997) proposed a rule based approachfor automatically acquiring linguistic knowledgefrom a small set of easily understood rules.
jianget al.
(2012) arranged a new grammar system ofrules to solve both chinese grammar errors andspelling errors.
xiong et al.
(2015)â€™s hanspellerwas based on an extended hmm, ranker based mod-els and a rule based model.
for statistical basedmethods, noisy channel model (brill and moore,2000, 2008; chiu et al., 2014; noaman et al., 2016;bao et al., 2020) is the most widely used model.
statistical based methods usually narrowed the can-didates choice by utilizing a predeï¬ned confusionset (chen et al., 2013; hsieh et al., 2013; wanget al., 2019a), which contains a set of similar char-acter pairs.
these similar characters were used toreplace each other and language models were lever-aged to measure the quality of the modiï¬ed sen-tences (liu et al., 2013; yu and li, 2014; xie et al.,2015).
more recently, deep learning has achievedexcellent results on many nlp tasks, includingcsc.
wang et al.
(2019a) proposed an end-to-end confusionset-guided encoder-decoder model,which treated csc as a sequence-to-sequence taskand infused confusion sets information by copymechanism.
faspell (hong et al., 2019) employedbert (devlin et al., 2019) as a denoising autoen-coder (dae) for csc.
spellgcn (cheng et al.,2020) constructed two similarity graphs over thecharacters in confusion sets and employed graphconvolutional network on these two graphs to cap-ture the pronunciation/shape similarities betweencharacters.
soft-masked bert (zhang et al., 2020)was proposed to combine a bi-gru based detec-tion network and a bert based correction network,where the former passed its prediction results to thelatter using soft masking mechanism.
nguyen et al.
(2020) applied treelstm (tai et al., 2015; zhuet al., 2015) on the tree structure of the characterradicals to get hierarchical character embeddings,which was used as an adaptable ï¬ltering componentfor candidates selection..3 approach.
3.1 problem formulation.
csc has received active research in recent years.
previous studies on csc can be divided into threecategories: rule based methods, statistical based.
ters, there are about 216 different radicals in chinese..generally, csc can be regarded as a revision taskon chinese sentences.
given a chinese sentencex = {x1, x2, ..., xn} of length n, the model needsto detect spelling errors on character level andoutput its correct corresponding sentence y =.
5959figure 1: the architecture of our model.
(cid:74) and (cid:76) denote element-wise multiplication and addition operation,respectively.
correct sentence means â€™please tell meâ€™..{y1, y2, ..., yn}.
although csc can be viewed asa kind of sequence-to-sequence (seq2seq) task, itis different from other seq2seq tasks (e.g., textsummarization, machine translation): the inputand output sequences of the former are equal inlength.
most or even all of the characters in theinput sequence remain unchanged, only a few ofthem need to be corrected..3.2 model.
our model consists of three feature extractor mod-ules and an adaptive gating module used to fusekinds of features.
figure 1 illustrates the architec-ture of our model.
given a sentence, our modelï¬rstly extracts pinyin feature, glyph feature andcontext-sensitive semantic feature for every char-acter, then integrates three features by the adaptivegating module.
finally, the integrated representa-tion of each character is fed into a fully-connectedlayer to calculate the probabilities over the wholevocabulary, where the character with the highestprobability is picked as the substitute..in the following subsections, we will elaborate.
the implementation of each module..3.3 pinyin feature extractor.
neural tts models, like tacotron2 (shen et al.,2018), have achieved high-quality performance inproducing natural-sounding synthetic speech.
wepropose to generate the phonological representa-tions of chinese characters through a tts model.
so that csc can beneï¬t from realistic pronunci-ation similarities between characters.
in this pa-per, we leverage tacotron2, a recurrent sequence-to-sequence mel spectrograms prediction network,to help modeling the phonological representationssince its location-sensitive attention can create ef-fective time alignment between the character se-quence and the acoustic sequence.
when training achinese tts system with tacotron2, characters areï¬rst converted to pinyin sequence as phoneme form.
then the sequence is represented by the encoderusing an embedding layer and the hidden repre-sentations are consumed by the decoder to predicta corresponding mel spectrogram one frame at atime.
motivated by this, we train tacotron2 sepa-rately using public chinese female voice datasets3 with teacher forcing.
during training, we utilizepinyin transcription and mel spectrograms as inputto help modeling pinyin representations.
then weextract pinyin embedding layer of the encoder asour pinyin feature extractor to generate the phono-logical representations for csc.
when given a chi-nese sentence x, our model ï¬rst converts it to apinyin sequence using pypinyin4.
then dense fea-ture for pinyin sequence fp = {f pn} canbe obtained by using pinyin feature extractor as alookup table, where f pi âˆˆ rdp and dp is the dimen-.
2 , ..., f p.1 , f p.3https://test.data-baker.com/#/data/.
index/source.
python-pinyin.
4https://github.com/mozillazg/.
5960semantic feature extractormlpmlpfc layersoftmaxactivation functionactivation functionpinyin featuressemantic featuresglyph featuresvgg19tacotron2glyph feature extractoræƒ…å‘Šæ–¥æˆ‘â€¦â€¦lookuplookuppinyin feature extractorpinyinmel spectrogramsè¯·å‘Šè¯‰æˆ‘qing2gao4 chi4wo3glyphimagesfeature extractorsadaptive gatingtrained separatelytrained separatelyÃ—ğœ†!Ã—ğœ†"sion of the pinyin feature..features.
it is deï¬ned as follows:.
3.4 glyph feature extractor.
as chinese characters are composed of graphi-cal components, it is intuitive that the represen-tations for chinese characters could beneï¬t fromthe spatial layout of these components.
motivatedby meng et al.
(2019) and sehanobish and song(2019)â€™s exploration on using glyph images for chi-nese named entity recognition (ner) and chineseword segmentation (cws), we employ a glyph fea-ture extractor to extract glyph features for chinesecharacters.
we make use of 8106 chinese glyph im-ages released by (sehanobish and song, 2019).
totake advantage of powerful pre-trained models andavoid training from scratch, vgg19 (simonyanand zisserman, 2014) pretrained on imagenet isadopted as the backbone of the glyph feature ex-tractor.
following (meng et al., 2019), we furtherï¬netune it with the objective of recovering the iden-tiï¬ers from glyph images to solve the problem ofdomain adaptation.
after that, we drop the last clas-siï¬cation layer and use the outputs of vgg19â€™s lastmax pooling layer as glyph features.
for a givensentence x, our glyph feature extractor is able toï¬rst retrieve images for its characters and then gen-erate glyph features: fg = {f gn}, wheref gi âˆˆ rdg is the glyph feature of the ith characterxi and dg is the dimension of the glyph feature..2 , ..., f g.1 , f g.3.5 semantic feature extractor.
beyond the phonological and the morphologicalinformation, we adopt empirically dominant pre-trained language model to capture semantic infor-mation from context.
following (hong et al., 2019;cheng et al., 2020; zhang et al., 2020), bert isemployed as the backbone of our semantic featureextractor.
given an input sentence x, the extractoroutputs hidden states fs = {f sn} at theï¬nal layer of bert as semantic features, wherei âˆˆ rds and ds is the dimension of the semanticf sfeature..2 , ..., f s.1 , f s.3.6 adaptive gating.
ag(fp, fs) = Ïƒ(fpwp + bp) Â· fs.
ag(fg, fs) = Ïƒ(fgwg + bg) Â· fs.
(1).
(2).
where wp âˆˆ rdpÃ—ds, bp âˆˆ rnÃ—ds, wg âˆˆrdgÃ—ds, bg âˆˆ rnÃ—ds are parameters to be learned.
Ïƒ is a nonlinear activation function, which is arelu function in our implementation.
â€œÂ·â€ rep-resents element-wise multiplication.
we employthe proposed gating mechanism to control howmuch information in pinyin and glyph featuresis fused with semantic feature and transferred tothe next classiï¬er module.
the enriched featurefe âˆˆ rnÃ—ds is calculated as follows:.
fe = Î»p Â· ag(fp, fs) + Î»g Â· ag(fg, fs).
(3).
where Î»p + Î»g = 1 are coefï¬cients.
finally, weadd residual connection to fe and fs by linearcombination:.
fes = fe + fs.
(4).
3.7 trainingduring the training process, the representation fesis fed into a fully-connected layer for the ï¬nal clas-siï¬cation, which is deï¬ned as follows:.
p (yp|x) = sof tmax(feswf c + bf c).
(5).
where wf c âˆˆ rdsÃ—v , bf c âˆˆ rnÃ—v are learnableparameters for the fully-connected layer, v is thesize of the vocabulary and yp is the predicted sen-tence given the erroneous sentence x..the goal of training the model is to match thepredicted sequence yp and the ground truth se-quence yg.
overall, the learning process is drivenby minimizing negative log-likelihood of the char-acters:.
l = âˆ’.
logp ( Ë†yi = yi|x).
(6).
n(cid:88).
i=1.
where Ë†yi, yi are the ith characters of yp and yg,respectively..most previous methods for csc simply used ad-dition or concatenation to fuse different features.
however, these fusion strategies ignore the relation-ship between the features.
to tackle this issue, wepropose an innovative adaptive gating mechanismserved like a gate to ï¬nely control the fusion of.
3.8.inference.
at inference time, we select candidates with thehighest probability given by the model for eachcharacterâ€™s correction.
as for detection task, itis accomplished by checking whether the pickedcandidate is different with the input character..5961# erroneous sent / sent avg.length.
training datasighan13sighan14sighan15(wang et al., 2018)totaltest datasighan13sighan14sighan15.
340 / 7003358 / 34372273 / 2339271009 / 271329276980 / 277805.
971 / 1000520 / 1062541 / 1100.
41.849.631.342.542.5.
74.350.030.6.
# erroneous sent / sent avg.length.
table 2: statistics of datasets..4 experiments.
4.1 datasets.
to investigate the effectiveness of our proposedmethod, we conduct extensive experiments onthree shared benchmark datasets for csc task.
speciï¬cally, we make use of training datasetsfrom sighan13 (wu et al., 2013), sighan14(yu et al., 2014) and sighan15 (tseng et al.,2015).
we also include 271k training samplesautomatically generated by ocr-based and asr-based methods (wang et al., 2018) as in (chenget al., 2020; nguyen et al., 2020).
we employ testdatasets of sighan13, sighan14, sighan15for evaluation.
following the same data pre-processing procedure with (cheng et al., 2020;nguyen et al., 2020), characters in all sighandatasets are converted to simpliï¬ed form usingopencc5.
we adopt sighanâ€™s standard split oftraining and test data.
the detailed statistic of thedata is presented in table 2..4.2 baseline methods.
we compare our method against several advancedmethods proposed recently to investigate the poten-tial of our framework.
they are listed below:.
â€¢ faspell (hong et al., 2019): this methodemploys bert as a denoising autoencoder togenerate candidates for wrong characters andï¬lters the visually/phonologically irrelevantcandidates by a conï¬dence-similarity decoder..â€¢ spellgcn (cheng et al., 2020): this methodlearns the pronunciation/shape relationship be-tween the characters by applying graph con-volutional network on two similarity graphs.
it predicts candidates for corrections by com-bining graph representations with semanticrepresentations from bert..â€¢ headfilt (nguyen et al., 2020): this methoduses adaptable ï¬lter learned from hierarchicalcharacter embeddings to estimate the similar-ity between characters and ï¬lter candidatesproduced by bert..â€¢ bert: this method ï¬netunes bert with thetraining data and selects the character with thehighest probability for correction..4.3 evaluation metrics.
we adopt sentence-level metrics for evaluation,which are widely used in previous methods forcsc task.
sentence-level metrics are stricter thancharacter-level metrics since all errors in a sen-tence need to be detected and corrected.
metricsincluding accuracy, precision, recall and f1 scoreare calculated for errors detection and correction,respectively..4.4 experimental setup.
our model is implemented based on huggingfaceâ€™spytorch implementation of transformers6.
we ini-tialize weights of the semantic feature extractorusing bert-base-chinese and weights of the glyphfeature extractor using pretrained vgg19 fromtorchvision library7.
weights of the adaptive gatingare randomly initialized.
we train our model usingadamw optimizer for 5 epochs with learning rate1eâˆ’4.
batch size is 64 for training and 32 for eval-uation.
best Î»p, Î»g are 0.6, 0.4 for sighan13,0.8, 0.2 for sighan14 and sighan15.
we traintacotron2 using its open-source implementation8for 130k steps with default parameters, except thedecay step is set to 15000. the number of ourpinyin is 1920 and the dimension of the pinyin fea-ture is 512. characters are written using hei tifont9 in 8106 glyph images.
we ï¬netune vgg19on glyph images for 50 epochs with a batch size32 and a learning rate 5eâˆ’4.
the dimension ofthe glyph feature is 25088. all experiments areconducted on 2 tesla v100 with 16g memory..4.5 main results.
table 3 presents the results of all methods on threetest datasets.
our method outperforms all previous.
6https://github.com/huggingface/.
transformers.
7https://github.com/pytorch/vision8https://github.com/rayhane-mamah/.
tacotron-2.
9hei ti font is a very formal sans serif font for chinese.
5https://github.com/byvoid/opencc.
writing..5962test dataset.
method.
faspell (2019)spellgcn (2020)headfilt (2020)bertphmospellfaspell (2019)spellgcn (2020)headfilt (2020)bertphmospellfaspell (2019)spellgcn (2020)headfilt (2020)bertphmospell.
detection levelprec.
rec.
63.276.274.480.1100.074.970.698.776.899.561.065.182.578.685.3.f1 acc.
69.177.285.782.386.7.
--74.167.875.4.
53.569.561.660.767.660.080.771.872.972.7.
57.067.270.568.575.5.
63.577.777.678.180.5.
--73.571.276.9.
--78.577.580.9.
67.674.884.584.190.1.correction levelprec.
rec.
60.573.172.778.3100.074.167.898.675.199.559.463.182.177.884.7.
52.067.260.257.664.359.177.770.268.069.2.
66.672.184.283.189.6.f166.275.485.180.485.6.
55.465.369.466.273.1.
62.675.976.574.878.1.acc.
--74.970.677.1.
--74.272.778.5.
--79.379.982.6.sighan13.
sighan14.
sighan15.
table 3: performances of our method and baseline methods, where accuracy (acc.
), precision (prec.
), recall (rec.
),f1 on detection level and correction level are reported (%).
best results are in bold..methods and achieves new state-of-the-art perfor-mance on all three datasets.
compared with thebest baseline method (headfilt), the improvementsof our method are 1.0%, 5.0%, 2.9% on detection-level f1 and 0.5%, 3.7%, 1.6% on correction-levelf1 respectively, which veriï¬es the effectiveness ofour method..we observe that our method substantially outper-forms spellgcn on the precision and f1 scores,which indicates that our method is superior to spell-gcn in fusing similarity knowledge.
althoughspellgcn incorporates such knowledge, it relieson a predeï¬ned confusion set, which limits its gen-eralization.
firstly, similarity knowledge cannotbe obtained adequately since the confusion set islimited and unable to cover all characters.
sec-ondly, the confusion set is manually constructedand has no golden-standard, which may bring aboutcascading errors.
our method achieves better f1scores than headfilt, apparently because head-filt only leverages morphological knowledge in itspost-ï¬ltering component.
finally, our method con-sistently beats vanilla bert on all three datasetsin terms of all metrics, which demonstrates theimportance of incorporating the phonological andmorphological knowledge into the semantic spacefor the csc task..4.6 ablation study.
to study the effectiveness of each component inour method, we carry out ablation tests on threedatasets.
all ablation experiments with pinyin and.
glyph features are conducted using equal weightsfor pinyin feature and glyph feature (Î»p = Î»g)to avoid unnecessary biases they bring.
table 4presents the results.
first, replacing adaptive gatingwith a simple aggregate strategy leads to worse per-formance for both detection and correction, whichdemonstrates the beneï¬t of using adaptive gating.
we then remove pinyin feature extractor or glyphfeature extractor from the model.
the performancedegrades more when removing pinyin feature com-pared with removing glyph feature, which impliesthat phonological information is more crucial forcsc.
this is consistent with the ï¬nding that mostchinese spelling errors are caused by phonologicalsimilarity (liu et al., 2011).
the result further de-grades when removing both features and adaptivegating module, and this trend intuitively indicatesthat both phonological and morphological informa-tion contribute to the ï¬nal performance..4.7 effect of hyper parameters.
in this subsection, we conduct experiments to an-alyze the effect of weights of features and the di-mension of the pinyin feature..figure 2 shows how different weights inï¬‚uencethe performance of the model.
in this compari-son, the value of Î»p (Î»g) changes from 0.0 (1.0)to 1.0 (0.0) with the gap of 0.2. we plot thedetection-level and correction-level f1 scores onthree datasets in figure 2. the results consis-tently show that our model performs better whenÎ»p is set larger (e.g., 0.6 for sighan13, 0.8 for.
5963test dataset.
method.
sighan13.
sighan14.
sighan15.
phmospell (w/o pga)phmospell (w/o ge)phmospell (w/o pe)phmospell (w/ as)phmospellphmospell (w/o pga)phmospell (w/o ge)phmospell (w/o pe)phmospell (w/ as)phmospellphmospell (w/o pga)phmospell (w/o ge)phmospell (w/o pe)phmospell (w/ as)phmospell.
detection level.
correction level.
acc.
prec.
rec.
70.698.770.676.199.176.171.898.971.971.199.471.676.999.577.2.
72.776.476.273.476.6.
79.981.281.078.981.3.
78.683.682.981.382.484.188.788.387.588.6.
60.764.364.759.166.372.970.770.766.571.2.
98.699.098.899.499.5.
67.874.969.570.375.1.f1 acc.
prec.
rec.
67.882.374.886.169.383.269.882.986.874.757.662.061.857.063.6.
68.572.772.768.573.5.
71.275.374.872.475.3.
78.178.778.575.679.0.
77.580.079.577.980.0.
68.068.267.764.768.4.
77.883.182.280.881.883.188.487.987.288.2.f180.485.281.582.085.4.
66.271.170.666.871.6.
74.877.076.574.377.1.table 4: ablation results on three datasets.
phmospell (w/ as) denotes replacing adaptive gating modulewith aggregate strategy for feature fusion.
phmospell (w/o pe) denotes model without pinyin feature extractor.
phmospell (w/o ge) denotes model without glyph feature extractor.
phmospell (w/o pga) denotes modelwithout pinyin, glyph feature extractor and adaptive gating, which is a vanilla bert implementation..figure 2: effect of different weights for features.
we show results (%) of detection-level f1 (d-f) andcorrection-level f1 (c-f) on three datasets..figure 3: the results of correction-level f1 score (%)w.r.t.
the dimension of the pinyin feature..sighan14, sighan15), which means a higherweight on pinyin feature.
moreover, all of themoutperform the model without any features..previous ablation tests show that the pinyin fea-ture has more inï¬‚uence on the performance than theglyph feature.
we further perform experiments byvarying the dimension of the pinyin feature since itdirectly impacts the quality of the feature.
figure 3shows larger dimensions perform better.
however,it should be noted that the performance degradeswhen the dimension is larger than 512. this isreasonable due to the bias-variance phenomenonexplained in (yin and shen, 2018).
feature with asmall dimensionality can not capture all possiblepinyin relations (high bias).
on the other hand, fea-.
ture with a large dimensionality includes too muchnoise (high variance).
one must make a trade-off indimensionality selection for high-quality features..4.8 features visualization.
to understand the effectiveness of our featuresmore intuitively, we reduce features from high-dimensional space to low-dimensional space and vi-sualize some of them using t-sne (van der maatenand hinton, 2008)..figure 4 illustrates the embeddings of pinyinwhose initial begins with â€œdâ€, â€œfâ€, â€œhâ€ and â€œjâ€.
onecan ï¬nd from the ï¬gure that embeddings form sev-eral clusters based on their pronunciations.
pinyinembeddings with more similar pronunciations (eg.
â€œfu4â€ and â€œhu2â€) are closer in distance than dissim-.
5964                  p             6 , * + $ 1    &  ) 6 , * + $ 1    '  ) 6 , * + $ 1    &  ) 6 , * + $ 1    '  ) 6 , * + $ 1    &  ) 6 , * + $ 1    '  ) 6 , * + $ 1   6 , * + $ 1   6 , * + $ 1                             ilar ones (eg.
â€œhu2â€ and â€œdao4â€).
this suggeststhat the model has learned alignment between thepinyin feature and the realistic acoustic feature.
wealso plot glyph embeddings of characters with radi-cal â€œå£â€, â€œåœŸâ€ at left side and characters with radi-cal â€œå£â€ at outside in figure 5. they show the sametrends as that of pinyin embeddings.
above all, thisfurther veriï¬es the effectiveness of both phonolog-ical and morphological knowledge derived frommulti-modality..figure 4: the scatter of similar pinyin in terms of pro-nunciation.
pinyin whose initial begins with â€œdâ€, â€œfâ€,â€œhâ€, â€œjâ€ are shown in red, purple, blue, orange respec-tively..figure 5: the scatter of similar characters in terms ofshape.
characters with â€œå£â€ and â€œåœŸâ€ at left side areshown in red and orange, characters with â€œå£â€ at out-side are shown in blue..4.9 discussion.
to demonstrate how our model can handle phono-logical and visual errors, we showcase some repre-sentative cases from the test datasets.
for instance,for the erroneous sentence â€œ...ä¸æƒœå¨±(pinyin: yu2)å¼„ å¤§ è‡£...â€, vanilla bert corrects â€œå¨± å¼„â€ asâ€œç©(pinyin: wan2) å¼„ (play)â€ without consider-ing phonological information, which is only se-mantically reasonable.
our model, however, takesboth semantic and phonological knowledge intoconsideration and successfully generates a moreproper correction â€œ...ä¸æƒœæ„š(pinyin: yu2) å¼„å¤§è‡£... (...not hesitate to fool the minister...)â€.
an-other case is â€œ...é‚£åˆ«äººçš„æ¬¢(radicals: åˆ,æ¬ ) è¯´.
æ˜¯ æ²¡ åŠ æ³• æ”¹ å˜ ä½  çš„...â€.
our model is capa-ble of modifying it into correct sentence â€œ...é‚£åˆ« äºº çš„ åŠ(radicals: åˆ,åŠ›) è¯´ æ˜¯ æ²¡ åŠ æ³• æ”¹ å˜ä½ çš„...(...the persuasion of others canâ€™t changeyou...)â€ under morphological constraint, whereasvanilla bert produces an inferior correctionâ€œå°(radicals: å°) è¯´ (ï¬ction)â€..we also manually analyze the error cases of ourmodel on the test datasets and ï¬nd there are twocommon types of errors.
one type is continuouserrors, where several continuous characters in a sen-tence are wrong.
for example, in sentence â€œ...ä»–ä»¬æœ‰æ—¶å€™ï¼Œæœ‰ä¸€ç‚¹æåˆ°...â€, â€œæåˆ°(caught)â€ arecontinuous errors, which should be â€œå” å¨â€ (thecorrect sentence means â€™sometimes they are a littlenaggingâ€™).
the model fails to correct such continu-ous errors since the meaning of the whole sentenceis more disturbed.
correcting another type of er-rors requires strong external knowledge.
for in-stance, â€œå¿ƒæ™º (mind)â€ in poem â€œ...å¤©å°†é™å¤§ä»»äºæ–¯äººä¹Ÿï¼Œå¿…å…ˆè‹¦å…¶å¿ƒæ™ºï¼ŒåŠ³å…¶ç­‹éª¨... (...whenheaven is going to give a great responsibility tosomeone, it will ï¬rst ï¬ll his mind with suffering,toil his sinews and bones...)â€ is erroneous but se-mantic plausible in chinese.
the model is stillunable to correct it into â€œå¿ƒå¿— (mind)â€ since themodel lacks knowledge of poem..5 conclusion.
in this research, we propose a novel end-to-endtrainable model called phmospell for csc, whichincorporates both phonological and morphologicalknowledge from two feature extractors into a pre-trained language model by an effective adaptive gat-ing mechanism.
extensive experiments and empir-ical comparisons show that phmospell achievesstate-of-the-art results on three widely used bench-marks for csc, demonstrating the effectiveness ofthe proposed method..we remain extending the multi-modal knowl-edge to other nlp tasks (e.g., grammar error cor-rection) as our future work.
another fruitful fu-ture work is exploring the integration of externalknowledge so that the model can deal with errorsin poems, proverbs, etc..references.
zuyi bao, chen li, and rui wang.
2020. chunk-basedchinese spelling check with global optimization.
inproceedings of the 2020 conference on empirical.
596530201001020301001020da2dai3dan1dao4de4deng2di2di3di5dian4diao3die2dir4diu1dong4duan2duan4dui4dun3duo3fa5fang2fang4fei2fei4fen4fo2fou2fou3han3han4hang2he5hen3heng1hong1hong3hu2hui5huo2huor2ji1ji2ji4jia1jiao4jie4jin1jin2jing2jing5jingr3jiong2jiong3jiu5fu3 fu4                               methods in natural language processing: findings,pages 2031â€“2040..eric brill and robert moore.
2008. spell checkerwith arbitrary length string-to-string transformationsto improve noisy channel spelling correction.
uspatent 7,366,983..eric brill and robert c moore.
2000. an improved er-ror model for noisy channel spelling correction.
inproceedings of the 38th annual meeting of the as-sociation for computational linguistics, pages 286â€“293..kuan-yu chen, hung-shin lee, chung-han lee, hsin-min wang, and hsin-hsi chen.
2013. a study oflanguage modeling for chinese spelling check.
inproceedings of the seventh sighan workshop onchinese language processing, pages 79â€“83..xingyi cheng, weidi xu, kunlong chen, shaohuajiang, feng wang, taifeng wang, wei chu, andyuan qi.
2020.incorporating phono-logical and visual similarities into language modelsin proceedings of thefor chinese spelling check.
58th annual meeting of the association for compu-tational linguistics, pages 871â€“881..spellgcn:.
hsun-wen chiu, jian-cheng wu, and jason s chang.
2014. chinese spell checking based on noisy chan-in proceedings of the third cips-nel model.
sighan joint conference on chinese languageprocessing, pages 202â€“209..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 1 (long and short papers), pages4171â€“4186..zijia han, chengguo lv, qiansheng wang, and guo-hong fu.
2019. chinese spelling check based on se-quence labeling.
in 2019 international conferenceon asian language processing (ialp), pages 373â€“378. ieee..yuzhong hong, xianguo yu, neng he, nan liu, andjunhui liu.
2019. faspell: a fast, adaptable, sim-ple, powerful chinese spell checker based on dae-decoder paradigm.
in proceedings of the 5th work-shop on noisy user-generated text (w-nut 2019),pages 160â€“169..yu-ming hsieh, ming-hong bai, and keh-jiann chen.
2013.introduction to ckip chinese spelling checksystem for sighan bakeoff 2013 evaluation.
in pro-ceedings of the seventh sighan workshop on chi-nese language processing, pages 59â€“63..zhongye jia, peilu wang, and hai zhao.
2013. graphin proceedingsmodel for chinese spell checking.
of the seventh sighan workshop on chinese lan-guage processing, pages 88â€“92..ying jiang, tong wang, tao lin, fangjie wang, went-ing cheng, xiaofei liu, chenghui wang, and wei-jian zhang.
2012. a rule based chinese spelling andgrammar detection system utility.
in 2012 interna-tional conference on system science and engineer-ing (icsse), pages 437â€“440.
ieee..peng jin, xingyuan chen, zhaoyi guo, and pengyuanintegrating pinyin to improve spellingliu.
2014.in 2014errors detection for chinese language.
ieee/wic/acm international joint conferences onweb intelligence (wi) and intelligent agent tech-nologies (iat), volume 1, pages 455â€“458.
ieee..karen kukich.
1992. techniques for automaticallycorrecting words in text.
acm computing surveys(csur), 24(4):377â€“439..c-l liu, m-h lai, k-w tien, y-h chuang, s-h wu,and c-y lee.
2011. visually and phonologicallysimilar characters in incorrect chinese words: anal-yses, identiï¬cation, and applications.
acm trans-actions on asian language information processing(talip), 10(2):1â€“39..xiaodong liu, kevin cheng, yanyan luo, kevin duh,and yuji matsumoto.
2013. a hybrid chinesespelling correction using language model and statis-tical machine translation with reranking.
in proceed-ings of the seventh sighan workshop on chineselanguage processing, pages 54â€“58..laurens van der maaten and geoffrey hinton.
2008.journal of machine.
visualizing data using t-sne.
learning research, 9(11)..lidia mangu and eric brill.
1997. automatic rulein icml, vol-.
acquisition for spelling correction.
ume 97, pages 187â€“194.
citeseer..yuxian meng, wei wu, fei wang, xiaoya li, ping nie,fan yin, muyu li, qinghong han, xiaofei sun, andjiwei li.
2019. glyce: glyph-vectors for chinesecharacter representations.
in advances in neural in-formation processing systems, pages 2746â€“2757..minh nguyen, gia h ngo, and nancy f chen.
2020. adaptable ï¬ltering using hierarchical em-beddings for chinese spell check.
arxiv preprintarxiv:2008.12281..hatem m noaman, shahenda s sarhan, and m rash-wan.
2016. automatic arabic spelling errors de-tection and correction based on confusion matrix-noisy channel hybrid system.
egypt comput sci j,40(2):2016..arijit sehanobish and chan hee song.
2019. usingchinese glyphs for named entity recognition.
arxivpreprint arxiv:1909.09922..jonathan shen, ruoming pang, ron j weiss, mikeschuster, navdeep jaitly, zongheng yang, zhifengchen, yu zhang, yuxuan wang, rj skerrv-ryan,et al.
2018. natural tts synthesis by condition-ining wavenet on mel spectrogram predictions..5966junjie yu and zhenghua li.
2014. chinese spellingerror detection and correction based on languagemodel, pronunciation, and shape.
in proceedings ofthe third cips-sighan joint conference on chi-nese language processing, pages 220â€“223..liang-chih yu, lung-hao lee, yuen-hsien tseng, andhsin-hsi chen.
2014. overview of sighan 2014in proceed-bake-off for chinese spelling check.
ings of the third cips-sighan joint conferenceon chinese language processing, pages 126â€“132..shaohua zhang, haoran huang, jicong liu, and hangli.
2020. spelling error correction with soft-maskedin proceedings of the 58th annual meetingbert.
of the association for computational linguistics,pages 882â€“890..xiaodan zhu, parinaz sobihani, and hongyu guo.
2015. long short-term memory over recursive struc-in international conference on machinetures.
learning, pages 1604â€“1612..2018 ieee international conference on acoustics,speech and signal processing (icassp), pages4779â€“4783.
ieee..karen simonyan and andrew zisserman.
2014. verydeep convolutional networks for large-scale imagerecognition.
arxiv preprint arxiv:1409.1556..kai sheng tai, richard socher, and christopher dmanning.
2015. improved semantic representationsfrom tree-structured long short-term memory net-in proceedings of the 53rd annual meet-works.
ing of the association for computational linguisticsand the 7th international joint conference on natu-ral language processing (volume 1: long papers),pages 1556â€“1566..yuen-hsien tseng, lung-hao lee, li-ping chang, andhsin-hsi chen.
2015. introduction to sighan 2015bake-off for chinese spelling check.
in proceedingsof the eighth sighan workshop on chinese lan-guage processing, pages 32â€“37..dingmin wang, yan song, jing li, jialong han, andhaisong zhang.
2018. a hybrid approach to auto-matic corpus generation for chinese spelling check.
in proceedings of the 2018 conference on empiri-cal methods in natural language processing, pages2517â€“2527..dingmin wang, yi tay, and li zhong.
2019a.
confusionset-guided pointer networks for chinesespelling check.
in proceedings of the 57th annualmeeting of the association for computational lin-guistics, pages 5780â€“5785..hao wang, bing wang, jianyong duan, and jia-jun zhang.
2019b.
chinese spelling error detec-arxiv preprinttion using a fusion lattice lstm.
arxiv:1911.10750..shih-hung wu, chao-lin liu, and lung-hao lee.
2013. chinese spelling check evaluation at sighanthe seventhbake-off 2013.sighan workshop on chinese language process-ing, pages 35â€“42..in proceedings of.
weijian xie, peijie huang, xinrui zhang, kaiduohong, qiang huang, bingzhou chen, and leihuang.
2015. chinese spelling check system basedin proceedings of the eighthon n-gram model.
sighan workshop on chinese language process-ing, pages 128â€“136..jinhua xiong, qiao zhang, shuiyuan zhang, jianpenghou, and xueqi cheng.
2015. hanspeller: a uni-ï¬ed framework for chinese spelling correction.
ininternational journal of computational linguistics& chinese language processing, volume 20, num-ber 1, june 2015-special issue on chinese as a for-eign language..zi yin and yuanyuan shen.
2018. on the dimension-in proceedings of theality of word embedding.
32nd international conference on neural informa-tion processing systems, pages 895â€“906..5967