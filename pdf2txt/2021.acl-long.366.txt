employing argumentation knowledge graphsfor neural argument generation.
khalid al-khatib1 lukas trautner2 henning wachsmuth3 yufang hou4 benno stein51 leipzig university, germany, khalid.alkhatib@uni-leipzig.de2 university of erlangen-nuremberg, germany, lukas.trautner@fau.de3 paderborn university, germany, henningw@upb.de4 ibm research europe, ireland, yhou@ie.ibm.com5 bauhaus-universität weimar, germany, benno.stein@uni-weimar.de.
abstract.
generating high-quality arguments, while be-ing challenging, may beneﬁt a wide range ofdownstream applications, such as writing as-sistants and argument search engines.
moti-vated by the effectiveness of utilizing knowl-edge graphs for supporting general text gener-ation tasks, this paper investigates the usageof argumentation-related knowledge graphs tocontrol the generation of arguments.
in partic-ular, we construct and populate three knowl-edge graphs, employing several compositionsof them to encode various knowledge into textsof debate portals and relevant paragraphs fromwikipedia.
then, the texts with the encodedknowledge are used to ﬁne-tune a pre-trainedtext generation model, gpt-2.
we evaluate thenewly created arguments manually and auto-matically, based on several dimensions impor-tant in argumentative contexts, including ar-gumentativeness and plausibility.
the resultsdemonstrate the positive impact of encodingthe graphs’ knowledge into debate portal textsfor generating arguments with superior qualitythan those generated without knowledge..1.introduction.
arguments are our means to build stances on con-troversial topics, to persuade others, or to negotiate.
automatic argument generation has the potentialto effectively support such tasks: it may not onlyregenerate known arguments but also uncover newfacets of a topic.
existing argument generation ap-proaches work either in an end-to-end fashion (huaand wang, 2018) or they are controlled with respectto the argument’s topic, aspects, or stance (gretzet al., 2020; schiller et al., 2021).
in contrast, noapproach integrates external knowledge into thegeneration process so far, even though knowledgegraphs have been shown to be useful for support-ing text generation models in other areas (koncel-kedziorski et al., 2019a; ribeiro et al., 2020)..previous research has proposed argumentationknowledge graphs (akgs) that model supportingand attacking interactions between concepts (al-khatib et al., 2020).
such an akg may assistargument generation models in different ways.
forexample, meaningful prompts on controversial top-ics can be constructed from an akg with sim-ple hand-deﬁned rules, such as ‘geoengineering re-duces atmospheric greenhouse gas’ for generatingan argument on ‘geoengineering.’ alternatively, anakg may be employed to control the generation,making arguments adhere to knowledge covered inthe graph.
we hypothesize this to be particularlybeneﬁcial for the quality of arguments in terms offactuality, the richness of evidence, and similar..this paper concentrates on such controlled ar-gument generation, investigating for the ﬁrst timethe ability to generate high-quality and content-richarguments by integrating knowledge from akgsinto standard neural-based generation models.
tothis end, we exploit multiple manually and auto-matically created knowledge graphs, devoting par-ticular attention to causal knowledge (al-khatibet al., 2020; heindorf et al., 2020).
causality playsa major role in argumentation due to its frequentusage in real-life discussions; argument from causeto effect and argument from consequences are fre-quently used argumentation schemes (feng andhirst, 2011; reisert et al., 2018)..to utilize akgs for argument generation, wecollect argumentative texts from diverse sourcessuch as online debate portals.
in these texts, we ﬁndarguments that contain instances of the knowledgecovered in the graphs.
we encode this knowledgeas keyphrases in the arguments.
unlike gretz et al.
(2020) and schiller et al.
(2021), our keyphrasescover multiple aspects and stances related to thesame topic.
the resulting texts are used to ﬁne-tune a transformer-based generation model, gpt-2(radford et al., 2019).
the underlying hypothesis is.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4744–4754august1–6,2021.©2021associationforcomputationallinguistics4744figure 1: the main steps of our approach: (1) given an argumentation knowledge graph, (possibly) extended byknowledge mined automatically, (2) texts are retrieved from the web to augment argument generation.
(3) pairs oftext and knowledge are used to ﬁne-tune gpt-2.
(4) the model generates an argumentative text for a given prompt..that gpt-2 will use the keyphrases to constrain thegeneration of arguments.
during application, weprovide the model with knowledge (as keyphrases)to obtain new arguments that further elaborate theknowledge.
figure 1 gives an overview of the mainsteps of our approach..we evaluate the ability of our approach to gen-erating new arguments for a variety of claim-likeprompts: 400 generated arguments are manuallyassessed for their relevance to the prompt, argu-mentativeness, content richness, and plausibility.
as a recent study indicates the adoption of biasfrom argumentative source data in word embed-dings (spliethöver and wachsmuth, 2020), we alsoinspect potential social bias and abusive languagein the generated arguments.
moreover, we evalu-ate the generated arguments automatically usingrecently developed argument mining techniques, inorder to then examine correlations between man-ual and automatic evaluations.
the results revealan evident beneﬁt of using the graphs’ knowledgein generating controlled arguments that are rich incontent and plausible.
however, we also observethe presence of social bias in the outputs of gpt-2,suggesting the need for careful postproceeing stepin argument generation..both the resources and the code developed in.
this paper will be made available.1.
2 knowledge graphs for argumentation.
we use knowledge graphs (kgs) to plan the contentof an argument to be generated and to control itstalking points.
a talking point is a speciﬁc aspectrelated to a given discussion topic.
for instance,.
1https://github.com/webis-de/acl-21.
“health” is a talking point related to “smoking.”.
in this section, we describe the construction ofthree graphs related to argumentation: (1) a ground-truth argumentation knowledge graph, which isutilized based on al-khatib et al.
(2020), (2) agenerated argumentation knowledge graph, whichis newly constructed from a set of argumentativetexts, and (3) a causality graph, which is built uponheindorf et al.
(2020)..2.1 ground-truth knowledge graph.
al-khatib et al.
(2020) propose a graph model thatencodes the knowledge contained in arguments asrelations (identiﬁed as the graph’s edges) betweenconcepts (identiﬁed as the graph’s nodes).
a con-cept is a noun phrase that represents an entity, anevent, or an abstract idea.
a relation representsthe positive or negative effect that a concept has onanother one.
a relation is positive if concept a pro-motes/causes/increases concept b, and it is nega-tive if concept a suppresses/prevents/stops conceptb. a concept has two types of attributes: (1) ground-ings, which link concepts to the corresponding en-tries in a knowledge base such as wikidata, (2) con-sequences, stating whether a concept is viewed aspredominantly good or bad..we slightly modify the outlined model to renderthe processing of the graph more amenable for ourpurposes.
instead of considering consequences asconcept attributes, they are here modeled as aneffect relation type: a good consequence is mappedto a positive effect, and a bad consequence to anegative effect.
for example, “smoking is bad forhealth” is mapped to “smoking has a negative effecton health.”.
accordingly, we populate the graph using the ar-.
4745geoengineering is goodfor society because...geoengineeringis goodground-truth knowledge graphextended knowledge graphgeneral language modelhuman-written claimtextual web dataargumentative training dataargumentative language modelmachine-generated argumentknowledge extractiontextual augmentationmodel fine-tuningargument generationwikipediadebate portalsgpt-2training stageapplication stagegeoengi-neeringclimatechangesociety––––+geoengi-neeringclimatechangesocietygeoengineering stopsclimate change to some...1234autocracy–+graph.
#nodes.
#edges.
#pos.
#neg..(a) ground-truth(b) generated(c) causality.
4,9049,1004,60719,18113,00314,64374,356 179,701 179,701.
4,1961,6400.table 1: counds of nodes and edges in the three graphs,the latter separated into positive and negative effect..gumentation knowledge corpus of al-khatib et al.
(2020), which comprises 16,429 manual annota-tions of 4,740 claims crawled from the online de-bate portal debatepedia.org.
the population stepresults in the respective concept nodes (along withtheir groundings), which are connected by the twotypes of relations mentioned above..we conduct a post-processing step to reﬁne thegraph including the removal of special charactersand stop words at the beginning of the concepts, thechanging of concepts from the plural to singular,and the decomposition of some concepts into two ormore based on a set of conjunctions such as “and,”“or,” etc.
for example, the concept of “depressionand anxiety problems” will be decomposed into“depression” and “anxiety problems.”.
table 1 (row a) shows statistics of this argu-mentation knowledge graph, which contains 4,607nodes and 9,100 relations..2.2 generated knowledge graph.
since the ground-truth graph is limited in size, andsince we aim for a higher coverage of knowledgefrom different controversial topics, we construct anadditional new graph automatically..data source the newly generated graph is de-rived from two resources: args.me and kialo.2.
args.me is the corpus underlying the argumentsearch engine args.me (ajjour et al., 2019).
it com-prises arguments from four online debate portals:debate.org, debatewise.org, debatepedia.org andidebate.org.
we exclude debate.org, since it con-tains argumentative dialogues with frequent debateand user-meta information.
in total, the corpus in-cludes 30,748 arguments from the three considereddebate portals..kialo is a debate portal in which argumentationis structured as trees.
the platform comprises high-quality arguments as a result of the careful and.
2we also experimented with cmv, a discussion forum onthe portal reddit (i.e., a subreddit) which hosts argumenta-tive discussions.
however, due to the subreddit’s dialogicalnature and the use of informal language, the results were notconvincing even when considering only the top-level posts..substantial moderation.
we crawled 1,640 discus-sions from kialo.com.
from these, we obtainedarguments by concatenating texts in the discussionlevels of the tree (i.e., premises) with the texts inthe tree roots (i.e., claims).
overall, we got 82,728arguments from kialo..graph construction we followed the schemeof the manually generated argumentation knowl-edge graph described in the previous section, andidentiﬁed concepts and relations in argumentativetexts using the argument knowledge relation ex-traction approach of al-khatib et al.
(2020).
theapproach comprised two main steps: (1) identify-ing whether a given text encodes an effect relation,and its type if any, and (2) ﬁnding the conceptsof the identiﬁed relation.
speciﬁcally, for a givensentence, we extracted zero, one, or several argu-ment knowledge relation instances in the format{concept a, positive/negative effect, concept b}..we segmented all the arguments from the twosources into sentences and applied the argumentknowledge relation extraction approach to all sen-tences, obtaining 11,537 and 17,688 relation in-stances from args.me and kialo, respectively..to improve the quality of the generated knowl-edge graph, we conducted the post-processing thatwe did for the manually generated argumentationknowledge graph.
to reduce the observed noiseand to exclude ill-formed concepts, we addition-ally ﬁltered out concepts that are longer than sevenwords as well as those that comprise only one word,if it is not a noun.
to increase the precision of theidentiﬁed relation types, we extract the main verbof each sentence, and check the effect type of theverb using three lexicons: +/-effectwordnet (choiand wiebe, 2014), connotation frames (rashkinet al., 2015), and connotationwordnet (kang et al.,2014).
if the effect type of the knowledge relationinstance obtained from this sentence contrastedwith the effect type of its main verb (identiﬁed byany of the three lexicons), we excluded the instanceobtained from this sentence..our new automatically-generated argumentationknowledge graph is built on top of these post-processed argument knowledge relation instances.
table 1 (row b) shows statistics of the new graph.
it contains 19,181 nodes and 14,643 relations..2.3 causality knowledge graph.
recently, heindorf et al.
(2020) built a new causalknowledge graph which focuses on causal relations.
4746between concepts.
the construction of the kg wasdone by applying different information extractiontechniques including bootstrapping, linguistic pat-terns, and sequence tagging on clueweb12 andwikipedia.
the corpus comes with two versions:a high-recall version with more than 11 millioncausal relations and a high-precision version withonly around 200k relations.
we make use of thehigh-precision version to build a new graph whichis inline with the scheme of the two argumentationknowledge graphs described above.
in particular,we map the cause relation to the positive effectrelation since the former is a special case of thelatter.
we further exclude some noisy instancesthat contain the same concepts in a causal relation(e.g., concept a causes concept a).
in total, the ﬁnalgraph comprises 74,356 nodes and 179,701 edgesas shown in table 1 (row c)..2.4 graph analysis.
table 2 shows examples of the knowledge in thegraphs.
to gain insights into the three graphs andtheir relationships, we analyzed the central con-cepts in each graph and the overlap between them..graph central concepts we use the centralitydegree to get the most central nodes in each graph.
for the graph constructed manually, we found themost central nodes to be controversial topics as wellas some general concepts that affect our lives ingeneral.
a similar observation can be made for thesecond knowledge graph, but with an additional setof controversial topics.
most central concepts in thecausality graph are related to health.
table 3 showsexamples of the central concepts in the graphs..graph overlap.
we checked overlap betweennodes among the three graphs.
the ground-truthgraph and the generated graphs have 1,424 over-lapping nodes.
concretely, 908 nodes from theground-truth kg match with those from the causal-ity kg, and 2,326 from the generated kg matchwith those from the causality kg.
we note thatthe causality graph, albeit mostly covering generaland health-related concepts, overlaps with the othertwo graphs in several controversial topics such as“climate change" and “abortion"..3 neural argument generation.
we now present our approach to integrate the ar-gumentation knowledge graphs such as those de-scribed above into a neural text generation model..stability of a country bank system.
(cid:55)−→ economic stability.
positive.
raise oil price.
(cid:55)−→ world oil industry.
negative.
legalizing marijuana.
(cid:55)−→ tourism industry.
positive.
online social vigilantismpositive.
economic growth.
(cid:55)−→ global warmingpositive.
negative.
(cid:55)−→ insulting behavimy.
human parainﬂuenza viruse.
(cid:55)−→ viral pneumonium.
table 2: examples of the knowledge in the three con-structed knowledge graphs..(a) ground-truth.
(b) generated.
(c) causality.
global warmingfree speechpublic safetypublic insurancecircumcisionglobalization.
liquid democracy diseasepovertyunisex bathroomafﬁrmative action violencereligionpolygamycapitalism.
confusiondepressionobesity.
table 3: examples of the central concepts in the threeconstructed knowledge graphs..3.1 text collection.
to construct a dataset for ﬁne-tuning a generationmodel, we ﬁrst collect a set of argumentative textswhich are likely aligned with the knowledge graphswe have constructed in section 2..since our goal is to lead the text generation pro-cess towards arguments, we use texts from args.meand kialo (see section 2).
the two resources con-tain mostly argumentative texts, many of whichcover concepts from the graphs.
in addition, weuse wikipedia as we expect it to cover various factsfor a large portion of concepts in the graphs.
specif-ically, we sample a set of articles from wikipediathat address the concept groundings present in theground-truth argumentation knowledge graph (al-together 2,050 articles).
the articles are split into81,872 paragraphs based on their structure..3.2 text-knowledge encoding.
in each paragraph from all three sources describedabove, we identify all concepts found in the knowl-edge graphs using string matching.
we add pairs ofconcepts that are connected in the graph to the be-ginning of the paragraph, encoding them with thetype of effect relation between them as keyphrasesseparated by special tokens.
we use ‘positive’ and‘negative’ to represent the effect relations.
for ex-ample, the paragraph.
“animal studies suggests marijuana causes phys-.
ical dependence, and serious problems”.
will be transformed into:.
4747“<|startoftext|>’[’marijuana»positive»physical-dependence’, ’mariguana»positive»problems’] @animal studies suggests ...’<|endoftext|>”.
while this way of matching and encoding haslimitations, it has shown good results in practicewhen used with pre-trained neural models (wit-teveen and andrews, 2019; cachola et al., 2020)..3.3 neural language model fine-tuning.
we use our text-knowledge encoding dataset toﬁne-tune the gpt-2 neural language model (rad-ford et al., 2019) for argument generation.
sincegpt-2 cannot deal with graph structure as input di-rectly, we ﬁne-tune it on all paragraphs, includingthose with encoded relations as textual represen-tations (i.e., keyphrases).
we expect to therebyleverage the powerful generation capabilities ofgpt-2 while biasing it to generate texts related tothe encoded relations..it is worth noting that, in training, we encodemultiple relations at once and the generated argu-ments are paragraphs.
the encoded relations areoften related to different aspects of the same topic.
this is different from previous studies (gretz et al.,2020; schiller et al., 2021) which only focus ongenerating an argumentative sentence based on asingle topic or one aspect/stance of a topic.
as aresult, we expect that our ﬁne-tuning strategy basedon knowledge graphs can assist users to plan sev-eral “talking points” and generate the correspond-ing argument which covers the different aspects..4 experiments and results.
in this section, we report on the manual and auto-matic evaluation of our approach from section 3 toemploy the three argumentation knowledge graphsfrom section 2 for neural argument generation:.
a. the ground-truth graph.
b. the generated graph.
c. the causality graph.
4.1 experimental set-up.
we used the following experimental setup:.
batch_size to 2 and the steps to 1500. we specifythe length of the generated arguments to be 100(approximately, the mean number of words of thearguments in our data).
as postprocessing, we re-moved non-ascii characters and several impropersymbols from the generated arguments.
the ﬁne-tuning took around 16 hours on a gpu tesla t4..argument generation models for ﬁne-tuningthe generation model, there are various possiblecombinations of the three constructed graphs andthe datasets.
based on initial tests of potentiallypromising combinations, we decided to address thefollowing models in order to examine the impactof the graphs as well as the data:.
1. gpt-2.
as a baseline, we use the raw gpt-2model without any ﬁne-tuning or graph usage..2. argdata.
this model is based on ﬁne-tuninggpt-2 using the argumentative texts fromkialo and args.me in our constructed data.
noknowledge from the graphs is used here..3. ab-argdata.
similar to the previous model,but the knowledge of the graphs a and b areencoded into the argumentative texts.
con-cretely, we combine a and b as follows: first,we compute the intersection of a and b. then,we add the nodes and edges of a to the result-ing intersection subgraph of b, including thenodes of this subgraph as well as their neigh-bors.
thereby, we reduce the usage of noisyknowledge, preferring knowledge with directconnections.4.
4. abc-argdata.
just like the previous model,but we consider the knowledge of graph c inaddition to a and b. we compose the graphabove and c analog to above.
the rationale ishere to prefer argumentative knowledge overmore general knowledge.
the graph c is sev-eral orders of magnitude larger than a and b;considering the complete graph of c wouldthus likely eliminate the impact of a and b..5. abc-fulldata.
analogous to the model be-fore, but here we use the wikipedia subset ofour data in addition to the argumentative one..model parametersin all experiments, we ﬁne-tuned the pre-trained gpt-2 model with 127m pa-rameters using gpt-2-simple library.3 for argumentgeneration, we follow gretz et al.
(2020) in settingtop_k to 40 and temperature to 0.7. also, we set the.
3https://github.com/minimaxir/gpt-2-simple.
in general, those models help investigate the im-pact of adding one type of information (data or.
4in other words, we consider the complete graph a, sincea is the one with highest precision, and we induce a subsetof graph b that is related to a. our inspections suggestedthat this subset has much higher precision than the completegraph b..4748prompt: multiculturalism is positive for tolerant society..gpt-2: no guarantee that the world of cultural evolution is going to be one of a kind.
in a world where the majority of peopleare now tolerant, where many people still believe in evolution, we have to accept the world of cultural evolution as being a farmore complicated...argdata: multiculturalism is a good way to go about making the world a more tolerant place.
in the u.s., more than halfamericans think their country has more tolerance and diversity than other countries...ab-argdata: multiculturalism will allow for more tolerant societies.
multiculturalism is already a force for good, helping tobring tolerance and diversity to the world.
a multicultural society will bring such things as tolerance, kindness, and respect foreveryone...abc-argdata: multiculturalism will increase the diversity of the population.
the european union eu was created to fostertolerance towards many cultures, but it is still intolerant towards many other cultures...abc-fulldata: multiculturalism is an accepted part of a multicultural society.
the majority of the population of a multiculturalsociety are not religious, not socially or culturally dominant, and do not have political power....table 4: examples of the arguments generated in response to the prompt by each of the evaluated approaches..model.
args.me.
kialo wikipedia.
4.2 manual evaluation.
ab-argdataabc-argdataabc-fulldata.
104,923367,697367,697.
65,617204,651204,651.
––943,070.table 5: number of relations (knowledge instances) foreach of the graph models encoded in the argumentativetexts from args.me and kialo as well as in wikipedia..graph) on the quality of the generated arguments.
statistics of the knowledge encoded in the argu-mentative and full datasets are given in table 5..train-test data split we processed the data ex-cluding all paragraphs related to ﬁve randomly-selected controversial topics: ‘geoengineering’,‘renewable energy’, ‘illegal immigration’, ‘elec-toral college’, and ‘multiculturalism’.
the re-sulting paragraphs are used for training the mod-els, while the ﬁve topics are used for generatingprompts to test the models.
accordingly, the arg-data training set includes 112,658 arguments, andthe fulldata training set comprises 194,032 argu-ments and wikipedia paragraphs..model prompts we chose different knowledgeinstances related to the ﬁve selected topics and usedthem as prompts for the generation models.
theknowledge includes the topic name (e.g., ‘geoengi-neering’), edges from the graphs (e.g., ‘geoengi-neering positive for climate change’), and graphpaths (e.g., ‘geoengineering solutions are negativefor atmospheric greenhouse gas, and atmosphericgreenhouse gas are negative for earth’).
for gpt-2and argdata, we represented the knowledge as co-herent texts similar to the examples above.
for theremaining models, we represented it in the sameway that we encoded it in the data (e.g., ‘geoengi-neering»positive»unexpected consequences’)..for evaluation, we generated 400 arguments usingthe prompts discussed above.
speciﬁcally, eachmodel generated 16 arguments for each of the ﬁvetest topics (80 arguments in total).
table 4 showssome examples of the generated arguments..annotation task the evaluation was done byﬁve workers hired on the freelancing platform, up-work.
the workers were writing experts, with asolid background in argumentation.
they had atleast 94% job success with more than 40 previousjobs on the platform.
each worker assessed thegenerated arguments from all models for two testtopics, seeing all variants at the same time.
thus,each model was evaluated by two different work-ers.
we paid each worker eur 140 in total.
theaverage time to complete the task was nine hours.
the assessment of the arguments given theirprompts was conducted based on ﬁve dimensions:.
• relevance.
does the text comprise content.
relevant to the given knowledge?.
• argumentativeness.
does the text convey anexplicit or implicit pro or con stance towardsany topic?.
• content richness.
does the text contain usefulinformation and cover different aspects?.
• plausibility.
does the text comprise plausiblecontent and does it not contrast with common-sense knowledge?.
• bias.
does the text include any social bias or.
abusive language?.
the ﬁrst four are adopted from hua and wang(2018) and gretz et al.
(2020).
we added the lastone in light of the observations of spliethöver andwachsmuth (2020).
the ﬁrst four dimensions were.
4749# model.
relevance argumentativeness content richness.
plausibility.
1 gpt-22 argdata3 ab-argdata4 abc-argdata5 abc-fulldata.
1.801.912.002.101.85.
2.232.502.502.452.26.
2.112.102.142.162.10.
2.332.202.342.272.04.bias.
6%13%6%13%6%.
table 6: manual evaluation: average scores between 1 (worst) and 3 (best) for the ﬁrst four dimensions andproportion of generated arguments reported to have bias.
the best values are marked bold..scored from 1 to 3 (1 being worst), while the lastone was answered with “yes” or “no”..we directed the workers to consider the lengthof the argument (100 words) in their assessments.
we also asked them to keep in mind that the textshould be self-contained; it should not be necessaryto see the prompts to understand the text.
as re-gards the argumentativeness dimension, we deﬁnedthe scores to indicate ‘no stance’ (score 1), ‘mixedstances’ (2), and ‘one stance’ (3) of the generatedargument.
unlike previous work, we omitted ﬂu-ency as a dimension in our evaluation, since all themodels are based on gpt-2, which is known togenerate mostly ﬂuent text.
we manually checkeda few samples, though, to conﬁrm the reasonableﬂuency of the generated arguments..results table 6 shows the resulting scores of allapproaches in the manual evaluation.
the inter-annotator agreement between the workers is 0.40in terms of fleiss’ κ..all models constructed with our data and graphsoutperform the raw gpt-2 model in most cases.
for relevance, the model with the three graphs andthe argumentative data, abc-argdata, performsbest (2.10), followed by ab-argdata (2.00).
suchresults clearly demonstrate the impact of the graphsin controlling the generated arguments.
one excep-tion is abc-fulldata, where it seems that usingwikipedia produces some shifts in topics in the gen-erated arguments.
regarding argumentativeness,the models that were developed using the argu-mentative data achieve the highest score, leavinggpt-2 and abc-fulldata behind.
as for contentrichness, abc-argdata reaches the highest scores,marginally higher than ab-argdata and the othermodels.
in general, all models show comparableperformance for this dimension.
for plausibility,the score of ab-argdata is highest, closely fol-lowed by gpt-2, though.
despite failing on theother dimensions, gpt-2 apparently generates com-parably plausible texts when having argumentationknowledge as prompts..as regards the last dimension, it seems that theoutput of all models sometimes conveys bias.
how-ever, this dimension appears to be very subjective,as only two workers reported biased arguments atall.
most of the reported arguments are about ille-gal immigration and multiculturalism.
examplesinclude “the british are a big threat to the idea ofmulticulturalism” and “the latest attempt to bringthe problem under control is the proposal to banblack people from entering the country.”.
4.3 automatic evaluation.
in the automatic evaluation of arguments, we aimedto approximate dimensions from the manual evalu-ation.
on one hand, this was to keep the focus onargumentation-related aspects.
on the other hand,it allows for a rough comparison between the man-ual and the automatic evaluation results.
based onrecent computational argumentation technologies,we assessed three dimensions as follows:.
• relevance.
we computed the overlap betweenan argument’s words and the prompt’s words,after excluding stop words.
to match the man-ual evaluation scores, we mapped full overlapto 3, partial overlap to 2, and no overlap to 1..• argumentativeness.
we detected the stance ofeach argument using the approach of stab et al.
(2018), which has been shown to be effectivein dealing with arguments from heterogeneoussources, topics, and domains.
in particular,we checked the stance (pro or con) for eachsentence, considering its topic.
we scored theargument with 1 in case no stance is detected,2 if two different stances are detected (pro andcon), and 3 if only one stance is detected..• content richness.
as we consider an argu-ment to be rich in content if it covers differ-ent aspects of a topic, we used the model ofschiller et al.
(2021) for identifying aspectsin arguments.
we then mapped the numberof detected aspects to scores heuristically: we.
4750model.
relevance argumentativeness richness.
gpt2argdataab-argdataabc-argdataabc-fulldata.
1.822.262.362.352.10.
2.522.702.792.852.67.
1.591.942.022.102.08.table 7: the results of the automatic evaluation of theﬁve models on the 400 generated arguments.
the high-est average score of each dimension is marked bold..gave score 1 to arguments with maximum twoaspects, score 2 for three to ﬁve aspects, andscore 3 for more than ﬁve..results table 7 presents the results of our auto-matic evaluation..again, all models perform better than gpt-2.
interms of relevance, ab-argdata (2.36) and abc-argdata (2.35) are on par.
regarding argumenta-tiveness, abc-argdata is the best with an aver-age score of 2.85, and ab-argdata follows with2.79. lastly, for content richness, abc-argdataagain achieves the highest score (2.10), followedby abc-fulldata and ab-argdata with 2.08 and2.02, respectively.
the results suggest that abc-argdata is the best model overall, followed by ab-argdata.
this emphasizes the impact of encodingthe knowledge of the graphs into argumentativedata for argument generation..comparing the scores of the automatic evalu-ation to the manual one, we observe rather com-parable ranks of the models regarding the threedimensions considered..4.4 discussion.
inspecting the arguments generated by the models,we observe that their quality varies depending onthe topic of the knowledge (e.g., nuclear energy)and their complexity (single or multiple-relations).
we also ﬁnd that the beginning of a generated ar-gument often has higher quality than the end part.
for example, some models start generating rela-tions such as ‘x is positive for y’ instead of a textat the end of the arguments.
the reason for thisdifference in quality could be the minimum lengthof arguments that we force the model to satisfy.
be-sides, the arguments have several problems, relatedto those that occur frequently with neural text gen-eration models, such as duplication, contradictingstatements, and topic shifting..in general, we see that the quality of the auto-matically generated arguments still not on par with.
human written arguments.
nevertheless, the exper-iment results show that our approach for control-ling the generated arguments using argumentationknowledge graphs improves the quality..still, our approach can be improved in severalrespects.
first, argumentation knowledge graphs,especially those which are constructed automati-cally, might contain knowledge that is noisy, toospeciﬁc, very abstract, or difﬁcult to be interpretedwithout context.
while we tried to limit such noiseas much as possible (see section 2.2), more sophis-ticated noise ﬁltering and a ranking of knowledgebased on its quality could be an essential improve-ment step.
besides, we used the simple method ofstring matching for ﬁnding the graphs’ knowledgein the collected argumentative texts.
advancedmethods utilizing semantic similarity could leadto more accurate matching.
moreover, althoughencoding the knowledge as keyphrases seems areasonable method, different representations thatconsider the structure of the knowledge are worthinvestigating (see section 3.2).
lastly, since our ap-proach is meant as a proof of concept, we used thesmall gpt-2 model with the parameters adoptedfrom gretz et al.
(2020).
using a larger model andexploring different sampling methods and parame-ter settings will probably result in a higher qualityof the arguments generated..5 related work.
in this section, we outline related studies on argu-ment generation, argumentation knowledge graphs,and graph-to-text generation..argument generation different approaches tothe generation of arguments, or of componentsthereof, have been proposed in the last years.
tocreate new claims, bilu and slonim (2016) recom-posed predicates from existing claims with new top-ics.
el baff et al.
(2019) composed complete argu-ments from given claims following speciﬁc rhetor-ical strategies based on the theoretical model ofwachsmuth et al.
(2018).
unlike these approaches,we make use of neural language models..hidey and mckeown (2019) built a sequence-to-sequence model to rewrite claims into opposingclaims, and hua et al.
(2019) presented a sophis-ticated approach that, given a stance on a contro-versial topic, combines retrieval with neural gen-eration techniques to create full arguments withthe opposite stance.
gretz et al.
(2020) developeda transformer-based pipeline to generate coherent.
4751and plausible claims, whereas schiller et al.
(2021)proposed a language model that controls argumentgeneration on a ﬁne-grained level for a given topic,stance, and aspect.
lastly, alshomary et al.
(2021)generated belief-based claims, encoding the beliefsvia conditional language models..most similar to our work are the studies of gretzet al.
(2020) and schiller et al.
(2021).
like us, theformer also exploits the power of gpt-2, addingcontext to the model’s training data.
the latter iscomparable in that it attempts to steer the gener-ation towards aspect-speciﬁc arguments.
to thebest of our knowledge, however, our approach isthe ﬁrst to employ external knowledge from knowl-edge graphs for the task of argument generation..argumentation knowledge graphs besidesthe argumentation knowledge graph of al-khatibet al.
(2020), toledo-ronen et al.
(2016) created anexpert stance graph to support stance classiﬁcation.
gemechu and reed (2019) encoded the relationsbetween segments of an argument into a graph anddemonstrated the graph’s effectiveness for argu-ment mining.
in our work, we utilize one of theavailable graphs, among others, using its knowl-edge to control the argument generation process..closely related to argumentation knowledge,causality graphs gained some attention recently.
while general knowledge bases such as concept-net (speer et al., 2017) contain causal knowledge,the causality graph of heindorf et al.
(2020) that weutilized is the largest source of causal knowledge,exceeding others by orders of magnitude..graph-to-text generation in the related areaof neural graph-to-text generation, researchers haveused various techniques (song et al., 2018; koncel-kedziorski et al., 2019b; schmitt et al., 2020).
within this area, the approaches most related toours are those that exploit the usage of knowledgein graphs as input to sequence-to-sequence mod-els (moryossef et al., 2019) as well as those thatmake use of large pre-trained language models suchas liu et al.
(2021), where the pretrained modelbart is augmented by knowledge from a graphfor generative commonsense reasoning..overall, our work concentrates on the contextof argumentation, with an approach to encodingdifferent types of argumentation knowledge intothe pretrained model gpt-2 in order to allow formore controlled argument generation..6 conclusion.
this paper tackles argument generation through theuse of argumentation knowledge graphs.
we havediscussed how to take advantage of different manu-ally and automatically created knowledge graphs toencode knowledge in argumentative texts, and howto utilize these texts to ﬁne-tune gpt-2.
our ap-proach is able to generate high-quality argumentsfor various inputs, including complex relationalknowledge.
besides, we proposed a simple methodfor evaluating arguments automatically, with re-sults correlating to those observed in the manualevaluation.
in our future research, we plan to lever-age more sources and evaluate other knowledgeencoding methods.
moreover, we will study differ-ent directions to illuminate the possible social biasin argument generation methods..ethics statement.
as this paper presents a computational method forgenerating arguments automatically, different ethi-cal restrictions deserve discussion..first, we have used only publicly available, non-personalized sources for our text collection.
whencrawling data from web platforms, we followed theplatforms’ policies, adhering to their usage rules.
second, although we restricted the sources of ourdataset and knowledge graphs to those trustworthyof having high quality, the generated argumentsincluded some undesirable materials, such as abu-sive language and social bias.
to account for theseﬁndings, we strongly suggest a postprocessing stepto ﬁlter out such content when using respectivedata.
moreover, we explicitly checked for bias inthe arguments we generated, as presented..arguments are a powerful means for changingpeople’s stances and impact the attitude of commu-nities.
to prevent unethical use, such as generat-ing arguments on controversial topics with speciﬁcstances and deploying them on social platforms,we will try to restrict the distribution of the dataand code to researchers and academic institutions.
this seems necessary since we are aware that thereis no guarantee that the generated arguments arealways factually correct..acknowledgments.
the ﬁrst author is supported by the german fed-eral ministry of education and research (bmbf,01/s18026a-f) by funding the competence centerfor big data and ai (scads.ai dresden/leipzig)..4752references.
yamen ajjour, henning wachsmuth, johannes kiesel,martin potthast, matthias hagen, and benno stein.
2019. data acquisition for argument search: theargs.me corpus.
in ki 2019: advances in artiﬁcialintelligence - 42nd german conference on ai, kas-sel, germany, september 23-26, 2019, proceedings,pages 48–59..khalid al-khatib, yufang hou, henning wachsmuth,charles jochim, francesca bonin, and benno stein.
2020. end-to-end argumentation knowledge graphin proceedings of the thirty-fourthconstruction.
aaai conference on artiﬁcial intelligence, pages7367–7374.
aaai..milad alshomary, wei-fan chen, timon gurcke, andhenning wachsmuth.
2021. belief-based genera-tion of argumentative claims.
in proceedings of the16th conference of the european chapter of the as-sociation for computational linguistics: main vol-ume, pages 224–233, online.
association for com-putational linguistics..for computational linguistics, pages 516–526, flo-rence, italy.
association for computational linguis-tics..shai gretz, yonatan bilu, edo cohen-karlik, andnoam slonim.
2020. the workweek is the best timeto start a family – a study of gpt-2 based claim gen-eration.
in findings of the association for compu-tational linguistics: emnlp 2020, pages 528–544,online.
association for computational linguistics..stefan heindorf, yan scholten, henning wachsmuth,axel-cyrille ngonga ngomo, and martin potthast.
2020. causenet: towards a causality graph ex-tracted from the web.
in cikm.
acm..christopher hidey and kathy mckeown.
2019. fixedthat for you: generating contrastive claims with se-mantic edits.
in proceedings of the 2019 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 1756–1767, minneapolis, minnesota.
associ-ation for computational linguistics..yonatan bilu and noam slonim.
2016. claim synthe-in proceedings of thesis via predicate recycling.
54th annual meeting of the association for compu-tational linguistics (volume 2: short papers), pages525–530, berlin, germany.
association for compu-tational linguistics..xinyu hua, zhe hu, and lu wang.
2019. argumentgeneration with retrieval, planning, and realization.
in proceedings of the 57th annual meeting of theassociation for computational linguistics, pages2661–2672, florence, italy.
association for compu-tational linguistics..isabel cachola, kyle lo, arman cohan, and danielweld.
2020. tldr: extreme summarization of sci-in findings of the associationentiﬁc documents.
for computational linguistics: emnlp 2020, pages4766–4777, online.
association for computationallinguistics..yoonjung choi and janyce wiebe.
2014..+/-effectwordnet: sense-level lexicon acquisition foropinion inference.
in proceedings of the 2014 con-ference on empirical methods in natural languageprocessing (emnlp), pages 1181–1191, doha,qatar.
association for computational linguistics..roxanne el baff, henning wachsmuth, khalidal khatib, manfred stede, and benno stein.
2019.computational argumentation synthesis as a lan-in proceedings of the 12thguage modeling task.
international conference on natural language gen-eration, pages 54–64, tokyo, japan.
association forcomputational linguistics..vanessa wei feng and graeme hirst.
2011. classify-in proceedings of theing arguments by scheme.
49th annual meeting of the association for com-putational linguistics: human language technolo-gies, pages 987–996, portland, oregon, usa.
asso-ciation for computational linguistics..debela gemechu and chris reed.
2019. decompo-sitional argument mining: a general purpose ap-proach for argument graph construction.
in proceed-ings of the 57th annual meeting of the association.
xinyu hua and lu wang.
2018. neural argumentgeneration augmented with externally retrieved evi-dence.
in proceedings of the 56th annual meeting ofthe association for computational linguistics (vol-ume 1: long papers), pages 219–230, melbourne,australia.
association for computational linguis-tics..jun seok kang, song feng, leman akoglu, and yejinchoi.
2014. connotationwordnet: learning conno-tation over the word+sense network.
in proceedingsof the 52nd annual meeting of the association forcomputational linguistics, acl 2014, june 22-27,2014, baltimore, md, usa, volume 1: long pa-pers, pages 1544–1554.
the association for com-puter linguistics..rik koncel-kedziorski, dhanush bekal, yi luan,mirella lapata, and hannaneh hajishirzi.
2019a.
text generation from knowledge graphs within proceedings of the 2019graph transformers.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 1 (long and shortpapers), pages 2284–2293.
association for compu-tational linguistics..rik koncel-kedziorski, dhanush bekal, yi luan,mirella lapata, and hannaneh hajishirzi.
2019b.
text generation from knowledge graphs within proceedings of the 2019graph transformers.
conference of the north american chapter of theassociation for computational linguistics: human.
4753robyn speer, joshua chin, and catherine havasi.
2017.conceptnet 5.5: an open multilingual graph ofin proceedings of the thirty-general knowledge.
first aaai conference on artiﬁcial intelligence,aaai’17, page 4444–4451.
aaai press..maximilian spliethöver and henning wachsmuth.
2020. argument from old man’s view: assessing so-cial bias in argumentation.
in proceedings of the 7thworkshop on argument mining, pages 76–87, on-line.
association for computational linguistics..christian stab, johannes daxenberger, chris stahlhut,tristan miller, benjamin schiller, christophertauchmann, steffen eger, and iryna gurevych.
2018.argumentext: searching for arguments in hetero-geneous sources.
in proceedings of the 2018 con-ference of the north american chapter of the asso-ciation for computational linguistics: demonstra-tions, pages 21–25.
association for computationallinguistics..orith toledo-ronen, roy bar-haim,.
and noamslonim.
2016. expert stance graphs for computa-in proceedings of the thirdtional argumentation.
workshop on argument mining (argmining2016),pages 119–123, berlin, germany.
association forcomputational linguistics..henning wachsmuth, manfred stede, roxanne el baff,khalid al khatib, maria skeppstedt, and bennostein.
2018. argumentation synthesis followingrhetorical strategies.
in proceedings of the 27th in-ternational conference on computational linguis-tics, pages 3753–3765.
association for computa-tional linguistics..sam witteveen and martin andrews.
2019. paraphras-ing with large language models.
in proceedings ofthe 3rd workshop on neural generation and trans-lation, pages 215–220, hong kong.
association forcomputational linguistics..language technologies, volume 1 (long and shortpapers), pages 2284–2293.
association for compu-tational linguistics..ye liu, yao wan, lifang he, hao peng, and philip s.yu.
2021. kg-bart: knowledge graph-augmentedbart for generative commonsense reasoning.
in pro-ceedings of the thirty-fifth aaai conference on ar-tiﬁcial intelligence.
aaai..amit moryossef, yoav goldberg, and ido dagan.
2019.step-by-step: separating planning from realizationin neural data-to-text generation.
in proceedings ofthe 2019 conference of the north american chap-ter of the association for computational linguistics:human language technologies, volume 1 (longand short papers), pages 2267–2277.
associationfor computational linguistics..alec radford, jeff wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners..hannah rashkin, sameer singh, and yejin choi.
2015.connotation frames: typed relations of impliedsentiment in predicate-argument structure.
corr,abs/1506.02739..paul reisert, naoya inoue, tatsuki kuribayashi, andkentaro inui.
2018. feasible annotation scheme forcapturing policy argument reasoning using argumenttemplates.
in proceedings of the 5th workshop onargument mining, pages 79–89, brussels, belgium.
association for computational linguistics..leonardo f. r. ribeiro, martin schmitt, hinrichschütze, and iryna gurevych.
2020.investigatingpretrained language models for graph-to-text gener-ation..benjamin schiller, johannes daxenberger, and irynagurevych.
2021. aspect-controlled neural argumentgeneration.
in proceedings of the 2021 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, pages 380–396, online.
associationfor computational linguistics..martin schmitt, sahand sharifzadeh, volker tresp, andhinrich schütze.
2020. an unsupervised joint sys-tem for text generation from knowledge graphs andsemantic parsing.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing (emnlp), pages 7117–7130, online.
as-sociation for computational linguistics..linfeng song, yue zhang, zhiguo wang, and danielgildea.
2018. a graph-to-sequence model for amr-in proceedings of the 56th an-to-text generation.
nual meeting of the association for computationallinguistics (volume 1: long papers), pages 1616–1626, melbourne, australia.
association for compu-tational linguistics..4754