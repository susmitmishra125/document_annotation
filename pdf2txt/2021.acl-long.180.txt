chase: a large-scale and pragmatic chinese dataset forcross-database context-dependent text-to-sql.
jiaqi guo†∗ ziliang si† yu wang† qian liu‡∗ ming fan†jian-guang lou§ zijiang yang†¶ and ting liu†.
†xi’an jiaotong university, xi’an, china.
‡beihang university, beijing, china.
§microsoft research, beijing, china.
¶guardstrike inc..{jasperguo2013,szl123,uyleewang}@stu.xjtu.edu.cn.
yang@guardstrike.com.
qian.liu@buaa.edu.cn.
jlou@microsoft.com{mingfan,tingliu}@mail.xjtu.edu.cn.
abstract.
the cross-database context-dependent text-to-sql (xdts) problem has attracted consid-erable attention in recent years due to itswide range of potential applications.
however,we identify two biases in existing datasetsfor xdts: (1) a high proportion of context-independent questions and (2) a high propor-tion of easy sql queries.
these biases con-ceal the major challenges in xdts to someextent.
in this work, we present chase,a large-scale and pragmatic chinese datasetfor xdts.
it consists of 5,459 coherent ques-tion sequences (17,940 questions with theirsql queries annotated) over 280 databases,in which only 35% of questions are context-independent, and 28% of sql queries are easy.
we experiment on chase with three state-of-the-art xdts approaches.
the best approachonly achieves an exact match accuracy of 40%over all questions and 16% over all question se-quences, indicating that chase highlights thechallenging problems of xdts.
we believethat chase can provide fertile soil for address-ing the problems..1.introduction.
the problem of mapping a natural language utter-ance into an executable sql query in the cross-database and context-dependent setting has at-tracted considerable attention due to its wide rangeof applications (wang et al., 2020b; zhong et al.,2020).
this problem is notoriously challenging,due to the complex contextual dependencies amongquestions in a sequence.
consider the question se-in order to understand thequence in figure 1.last question, one needs to ﬁgure out the ellipti-cal object of the verb “培养(have)” from the ﬁrsttwo questions in the sequence, which is “状 元球员(ﬁrst pick player)”.
questions like this are.
∗work done during an internship at microsoft research..figure 1: a question sequence from our chase dataset.
each question is annotated with its corresponding sqlquery.
the second and third questions are context-dependent, requiring resolutions of ellipsis..context-dependent, since they require resolutionsof contextual dependencies such as ellipsis in thisquestion.
there are also context-independent ques-tions that can be understood individually, such asthe ﬁrst question in figure 1. for ease of reference,we refer to this cross-database context-dependenttext-to-sql problem as xdts.
to study the chal-lenges in xdts, a continuous effort has been dedi-cated to constructing datasets, including sparc (yuet al., 2019a) and cosql (yu et al., 2019b)..however, through a careful analysis on exist-ing datasets, we identify two biases in them andthese biases conceal the major challenges in xdtsto some extent.
first, there are only a limitednumber of context-dependent questions in exist-ing datasets.
speciﬁcally, only 32% of questionsin cosql are context-dependent, and only 66% ofquestion sequences have context-dependent ques-tions.
sparc has more context-dependent ques-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2316–2331august1–6,2021.©2021associationforcomputationallinguistics2316哪所大学培养了最多mvp球员？which university has the most mvp players?selectt2.毕业院校frommvp记录ast1 join球员ast2 ont1.球员id = t2.球员id group byt2.毕业院校order bycount(distinctt2.球员id) desc limit1;selectt2.college frommvp_recordast1 joinplayerast2 ont1.player_id = t2.player_id group byt2.college order bycount(distinctt2.player_id) desclimit1;状元呢？how about the first overall pick?居然还是肯塔基！杜克也很出名啊，它培养了多少呢？still kentucky!
duke is also very famous!
how many does it have?select毕业院校from球员where是否状元=“是”group by毕业院校order bycount(*) desc limit1;selectcollege fromplayerwhereis_first_pick= “yes”group bycollege order bycount(*) desclimit1;selectcount(*) from球员where是否状元=“是” and毕业院校like“%杜克%”;selectcount(*) fromplayerwhereis_first_pick= “yes”and collegelike “%duke%”;tions than cosql, but it still has 48% of context-independent questions.
such a limited numberof context-dependent questions is unexpected, be-cause prior work (bertomeu et al., 2006) hasshown that questions within a database dialogueare highly likely to be context-dependent, and howto effectively model the context to understand acontext-dependent question is one of the majorchallenges in xdts.
second, 40% of sql queriesin both sparc and cosql are particularly easy,involving at most one condition expression.
thisbiased distribution of sql queries is potentiallycaused by their construction methods.
in fact, weﬁnd that sql queries for question sequences cre-ated from scratch are much more challenging..upon identifying the limitations of existingdatasets, we present chase, a large-scale andpragmatic chinese dataset for xdts.
chase con-sists of 5,459 question sequences (17,940 questionswith their sql queries annotated) over 280 multi-table relational databases.
compared with sparcand cosql, the number of context-independentquestions in chase is reduced from 48% and 68%to 35%, and the number of easy sql queries isreduced from 40% and 41% to 28%.
moreover,chase has richer semantic annotations, includingthe contextual dependency and schema linking (leiet al., 2020) of each question.
chase is also theﬁrst chinese dataset for xdts..chase is made up of two parts: chase-cand chase-t. in chase-c, we recruit 12 chi-nese college students who are proﬁcient in sqlto create question sequences from scratch and an-notate corresponding sql queries.
to ensure thediversity and cohesion of question sequences, wepropose an intent recommendation method.
whena student is going to raise a question, an intent cate-gory is randomly sampled with the method, and thestudent is recommended to write the question andsql query according to it.
in chase-t, inspiredby the construction of cspider (min et al., 2019),we translate all the questions, sql queries, anddatabases in sparc from english to chinese.
wealso try our best to mitigate the biases in sparc..to understand the characteristics of chase,we conduct a detailed data analysis and experi-ment with three state-of-the-art (sota) xdtsapproaches, namely, editsql (zhang et al., 2019),igsql (cai and wan, 2020), and our extension ofrat-sql (wang et al., 2020a).
the best approachonly achieves an exact match accuracy of 40% over.
all questions and 16% over all question sequences,indicating that chase presents signiﬁcant chal-lenges for future research.
the dataset, benchmarkapproaches, and our annotation tools are availableat https://xjtu-intsoft.github.io/chase..in summary, this paper makes the following.
main contributions:.
• we identify two biases in existing datasetsfor xdts: (1) a high proportion of context-independent questions and (2) a high propor-tion of easy sql queries..• we propose an intent.
recommendationmethod to guide the question sequence cre-ation.
the analysis on chase shows that ourmethod is useful to enrich the diversity andcohesion of question sequences..• chase, to the best of our knowledge, is theﬁrst large-scale and pragmatic chinese datasetfor xdts.
experimental results on chasewith three state-of-the-art approaches showthat there is still a long way to solve the chal-lenging problems of xdts..2 study of existing datasets.
in this section, we ﬁrst formally deﬁne the prob-lem of xdts and its evaluation metrics.
then,we present our study to understand the limitationsand biases of existing datasets in contextual de-pendency and sql hardness distribution..1, · · · , qi.
n(cid:105) and y i = (cid:104)yi.
2.1 deﬁnition of xdts1, · · · , yilet qi = (cid:104)qin(cid:105)denote a question sequence and its sql queries,where qij is the j-th question in qi and yij is thecorresponding sql query for qij. given a databasedbi, a question qij, and the question’s context(cid:104)qij−1(cid:105), the goal of xdts is to generatej for qithe sql query yij. an xdts dataset is a setof question sequences {qi, y i, dbi}n.1, · · · , qi.
i=1..two metrics are widely used to evaluate the pre-diction accuracy for xdts: question match andinteraction match.
question match is 1 when thepredicted sql query of qij.1 interactionmatch is 1 when all predicted sql queries of qimatch y i..j matches yi.
1following (yu et al., 2018), we decompose a predictedquery into different clauses, such as select, where, andcompute scores for each clause using set matching separately..23172.2 study setup.
dataset there are two datasets for study-ing xdts, all of which are english corpora.
(1) sparc (yu et al., 2019b) sparc is the ﬁrstdataset for xdts.
it is constructed upon the spiderdataset (yu et al., 2018).
given a pair of questionand sql query chosen from spider, an annota-tor was asked to write a sequence of questions toachieve the gold speciﬁed in the chosen pair.
(2) cosql (yu et al., 2019a) cosql is a corpusfor task-oriented dialogue.
it uses sql queries fordialogue state tracking.
hence, it is also used tostudy xdts.
question sequences in cosql werecollected under the wizard-of-oz setup (kelley,1984).
an annotator was assigned a pair of questionand sql query chosen from spider, and she wasasked to raise interrelated questions towards thegoal speciﬁed in the pair.
another annotator wrotethe sql query for the question if it was answerable..benchmark approach we consider three sotaapproaches as our benchmark approaches to under-stand the characteristics of existing datasets: edit-sql (zhang et al., 2019), igsql (cai and wan,2020), and rat-con.
rat-con is our exten-sion of rat-sql (wang et al., 2020a), which isthe sota approach for the context-independenttext-to-sql problem.
appendix a.1 provides thedetails of our extension.
all of the three approachesutilize bert (devlin et al., 2019) for encodings..2.3 contextual dependency.
prior work (bertomeu et al., 2006) on databasequestion answering dialogues reveals that questionswithin a dialogue tend to be context-dependent,i.e., the meaning of a question cannot be under-stood without its context.
the last two questions infigure 1 are typical context-dependent questions,requiring resolutions of ellipsis.
in fact, how to ef-fectively model the context to understand a context-dependent question is one of the major challengesin xdts (liu et al., 2020).
hence, we study thischaracteristic of existing datasets to understandhow pragmatic and challenging they are..to measure the contextual dependency ofan xdts dataset, we manually classify all thequestions in its development set into context-dependent and context-independent.
if a question iscontext-dependent, we further label whether it hascoreference or ellipsis, which are two frequentlyobserved linguistic phenomena in dialogues (an-droutsopoulos et al., 1995).
note that a question.
dataset.
sparccosql.
chasechase-cchase-t.contextindependent.
context dependentoverall coreference ellipsis.
47.5%68.2%.
35.3%28.8%42.2%.
52.5%31.8%.
64.7%71.2%57.8%.
36.6%18.1%.
36.2%40.3%33.1%.
20.9%4.9%.
29.0%31.4%26.4%.
table 1: measurement of contextual dependency.
8.8%of context-dependent questions in cosql do not havecoreference or ellipsis phenomena..dataset approach.
question match (%)indep.
dep.
overall.
interactionmatch (%).
sparc.
cosql.
editsqligsqlrat-con.
editsqligsqlrat-con.
47.149.560.1.
39.942.650.8.
58.359.467.4.
47.150.157.1.
37.040.753.5.
24.526.437.5.
29.430.138.6.
12.314.720.1.table 2: experimental results on the development setof sparc and cosql.
‘indep.’ and ‘dep.’ are short for‘context-independent’ and ‘context-dependent’..can have both coreference and ellipsis.
each ques-tion is ﬁrst classiﬁed by one author of this paper,and then cross-checked and corrected by another.
as shown in table 1, there are only a limitednumber of context-dependent questions in exist-ing datasets.
speciﬁcally, only 32% of questionsin cosql are context-dependent, and the remain-ing 68% questions can be understood without thecontext.
among the 293 question sequences in thedevelopment set of cosql, 34% of them do nothave any context-dependent question.
table 15 inappendix provides a set of cosql question se-quences and our classiﬁcation results.
comparedwith cosql, sparc has more context-dependentquestions and more questions that require resolu-tions of coreference and ellipsis.
nevertheless, 48%of its questions are still context-independent..table 2 shows the question match (qm) andinteraction match (im) of our benchmark ap-proaches on sparc and cosql.
the qm oncontext-dependent questions is substantially lowerthan that on context-independent ones, showingthat it is challenging for sota approaches to gen-erate sql queries for context-dependent questions.
in view of this challenge and the limited number ofcontext-dependent questions in existing datasets, itis necessary to construct a more pragmatic dataset,involving more context-dependent questions, forstudying xdts..2318dataset.
easy medium hard extra hard.
sparccosql.
40.1%36.7%41.4% 31.8%.
12.1%16.2%.
chasechase-c 18.6%37.4%chase-t.27.7% 37.5% 18.8%37.3% 24.4%12.8%37.8%.
11.1%10.5%.
16.0%19.7%12.0%.
table 3: sql hardness distribution..2.4 sql hardness distribution.
sql hardness is deﬁned as a four-level complexityfor sql queries: easy, medium, hard, and extrahard, according to the number of components, se-lections, and conditions in a sql query (yu et al.,2018).
the more components a sql query has,the more complex it is.
intuitively, the more hardand extra hard sql queries a dataset has, the morechallenging the dataset is..table 3 presents the sql hardness distributionin the development set of sparc and cosql.
wecan observe a biased distribution in both datasets,i.e., more than 40% of sql queries are easy.
thisbiased distribution is potentially caused by theirconstruction methods.
take sparc as an example.
a question sequence is constructed by decompos-ing a complex sql query into multiple themati-cally related ones.
although this method is cost-effective, there is little chance that a sql queryis more complicated than the one that it is decom-posed from.
as we will show in section 4.3, thesql hardness distribution of question sequencescreated from scratch differs a lot from those createdvia decomposition..3 dataset construction.
given the limitations of existing datasets, wepresent chase, a large-scale and pragmatic chi-nese dataset for xdts.
unlike the constructionof sparc and cosql, we do not specify a ﬁnalgoal for each question sequence.
instead, we mo-tivate our annotators to raise diverse and coherentquestions via an intent recommendation method.
based on this method, we collect a set of relationaldatabases, and we recruit annotators to create ques-tion sequences from scratch and annotate corre-sponding sql queries.
data collected in this wayare referred as chase-c..besides, inspired by the construction of cspi-der (min et al., 2019) and vietnamese spi-der (tuan nguyen et al., 2020), we translateall the questions, sql queries, and databases.
in sparc from english to chinese.
during trans-lation, we also try out best to mitigate the bi-ases in sparc.
data collected with this methodare referred as chase-t. chase is make up ofboth chase-c and chase-t..since all existing datasets for xdts are con-structed for english, prior work on this problem pri-marily focuses on english, leaving other languagesunderexplored.
to enrich the language diversity,in this paper, we construct chase for chinese,and we leave the support of more languages as ourimportant future work..3.1.intent recommendation.
j−1 and yi.
j based on yi.
in xdts, the intent of a question qij is fully re-ﬂected by its sql query yij. hence, by deﬁning arich set of relations between yij, we canderive diverse yij−1.
consequently, wecan motivate annotators to raise questions with di-verse intents.
we deﬁne four basic intent categoriesj−1 and yiof relations between yij:(1) same instances.
yij focuses on the other prop-erties of the instances queried in yij−1, e.g., byreplacing columns in the select clause of yij−1.
(2) different instances of the same entity.
yijqueries the same type of entity and properties as inyij−1, but it focuses on different instances, e.g., byadding an extra condition in the where clause.
(3) different entity.
yientity than yifrom clause of yi(4) display.
yij alters the way to display the infor-mation queried in yij−1, e.g., by adding an orderby clause or distinct in the select clause..j queries a different type ofj−1, e.g., by altering the tables in the.
j−1..we deﬁne 16 relations in these four categories,and we also allow combinations of them.
due tothe limit of space, we only present 8 relations withtheir examples in table 4. complete relations areavailable in table 12 of appendix..when an annotator is going to raise a follow-upquestion, one of the ﬁve intent categories in table 4will be randomly selected.
the annotator is thenrecommended to choose a relation belonging to theselected category and raise the question accordingto the relation.
also, the annotator is allowed tochange the intent category when it is not applica-ble or she has a better choice.
with this intentrecommendation method, follow-up questions willbe closely related to their previous questions andpresent rich intent diversity..2319category.
relation.
same instances.
r1.
add property.
r2.
add group.
different instancesof the same entity.
r3.
subset.
r4.
overlap.
precedent sql query yi.
j−1.
current sql query yij.example.
select name from student;.
select count(*) from student;.
select name from student;.
select name, age from student;select country, count(*) from student.
group by country;.
select name from studentwhere country = “us”;.
select name from student join student course.
select name from student join student course.
where course name = “python”;.
where course name = “c++”;.
different entity.
r5.
change entity.
select name from student;.
select course name from course;.
display.
r6.
add order.
r7.
distinct.
select country, count(*) from student.
select country, count(*) from student.
group by country;.
select country from student;.
group by country order by count(*);.
select distinct country from student;.
combination.
r8.
add property (r1) & subset (r3).
select name from student;.
select name, age from studentwhere country = “us”;.
table 4: a subset of relations between precedent sql query yi.
j−1 and current sql query yij..3.2 construction of chase-c.data in chase-c are collected in three stages: (1)database collection; (2) question sequence creation;and (3) data review..3.2.1 database collection.
we collect 120 chinese multi-table relationaldatabases from the dusql dataset (wang et al.,2020c).
there are 200 databases and 813 tables indusql, but most of the tables are crawled fromencyclopedias and forums.
hence, there are a lot ofmissing entries and noises (e.g., duplicated or con-ﬂicted columns, tables in a database describing un-related topics, and missing foreign key constraints).
to obtain high-quality databases, we manuallyrevise all the databases, dropping those withoutrelated tables, resolving duplicated or conﬂictedcolumns, and complementing missing entries.
as aresult, we collect 120 high-quality databases, cover-ing 60 different domains such as sport, education,and entertainment..3.2.2 question sequence creation.
we recruit 12 chinese college students that areskilled at sql to create question sequences fordatabases from scratch.
they are also asked towrite the sql query for each question.
when astudent starts a question sequence creation session,she is shown all the contents from a database, andshe can get familiar with the database by executingarbitrary sql queries.
once she gets ready, shewill receive a speciﬁcation of the minimum numberof questions in the sequence.2 she can raise theﬁrst question with her interests.
take the creationof question sequence in figure 1 as an example..the student asks the ﬁrst question “哪所大学培养了最多mvp球员？” and writes its correspondingsql query.
the execution results of the sql querywill be shown to the student, helping her raise thefollow-up question.
after that, she receives theintent category different instances of the same en-tity, which is randomly sampled by our annotationtool.3 she chooses the overlap relation in this cat-egory and raises the second question “状元呢？”.
this creation session continues until the minimumnumber of questions is reached..to help study the characteristics of questions andaddress the schema linking challenge (guo et al.,2019b; lei et al., 2020) in text-to-sql, we alsoask the students to label each question’s contextualdependency as in section 2.3 and the linking be-tween database schema items (tables and columnsin databases) and their mentions in questions..3.2.3 data review.
to ensure the data quality, we conduct two roundsof data review.
first, when a student creates her ﬁrst20 question sequences, we carefully review all theannotations to check whether the questions in eachsequence are thematically related and whether thesemantics of sql queries match their questions.
ifnot, we run a new round of training for the student.
through this round of review, we can resolve mis-understandings of annotations as early as possible.
after the ﬁnish of the question sequence creationstage, we review all the question sequences like inthe ﬁrst round, and we ask the students to modifytheir annotations if there are any problems..2following (yu et al., 2019b), the minimum number of.
3appendix a.2 provides an introduction of our annotation.
questions in a sequence ranges from 3 to 5..tool for question sequence creation..2320dataset.
language.
# db # table.
# seq..# pair.
# avg.
turn # avg.
qlen.
atissparccosql.
englishenglishenglish.
chasechinesechase-c chinesechase-t chinese.
1200200.
280120160.
271,0201,020.
1,280462818.
1,6584,2983,007.
5,4592,0033,456.
11,65312,72615,598.
17,9407,69410,246.
7.03.05.2.
3.33.83.0.
10.28.111.2.
13.014.312.1.contextualdependency.
schemalinking.
(cid:55)(cid:55)(cid:55).
(cid:51)(cid:51)(cid:51).
(cid:55)(cid:55)(cid:55).
(cid:51)(cid:51)(cid:51).
table 5: statistics of chase and existing datasets for the context-dependent text-to-sql problem..3.3 construction of chase-t.dataset.
split.
# db # seq..# pair.
the original sparc dataset consists of 4,298 ques-tion sequences and 200 databases, but only 3,456and 160 of them are publicly available for trainingand development.
hence, we could only translatethose to construct chase-t..the translation work is performed by 11 collegestudents, 10 of whom also participate in the ques-tion sequence creation stage of chase-c. eachdatabase and all its question sequences are trans-lated by one student.
the student also needs tolabel each question’s contextual dependency andthe linking between schema items and their men-tions in the translated questions.
we encourage thestudent to translate a question based on its seman-tics to obtain the most natural question in chinese.
to mitigate the biases in sparc, we ask our stu-dents to modify those context-independent or the-matically unrelated questions and sql queries tomake the question sequences more coherent andnatural.
our intent recommendation method is alsoapplied to guide the modiﬁcation.
to ensure thedata quality, we also run a two-round data reviewas in section 3.2.3..during the construction of chase-t, we identi-ﬁed and ﬁxed 150 incorrect sql queries in sparc.4also, we modiﬁed 1,470 sql queries to make thequestion sequences in chase-t more coherent..4 data statistics and analysis.
we compute the statistics of chase and conduct athorough analysis to understand its three character-istics: contextual dependency, sql hardness distri-bution, and mention of database schema items..4.1 data statistics.
table 5 summarizes the statistics of chase.
chase has 5,459 questions sequences (17,940.
4we have emailed the authors of sparc to apply our patch.
to ﬁx the incorrect sql queries..chase.
chase-c.chase-t.traindevtest.
traindevtest.
traindevtest.
2004040.
802020.
14020-.
3,949755755.
1,377333333.
3,034422-.
12,9142,4942,532.
5,1411,2911,262.
9,0431,203-.
table 6: dataset split statistics..questions with their corresponding sql queries an-notated) over 280 databases.
chase-c contributes37% question sequences and 43% question-sqlpairs; chase-t takes the rest part.
chase is thelargest dataset for xdts to date, consisting ofthe most question sequences, sql queries, anddatabases.
chase also has rich semantic annota-tions, including contextual dependency and schemalinking, which can inspire innovations to addresschallenges in xdts.
table 16 in appendix pro-vides a list of question sequences in chase..data split according to the cross-database set-ting of xdts, we split chase such that a databaseappears in only one of the train, development, andtest set.
to understand the characteristics of thedata collected in chase-c and chase-t, we alsosplit them accordingly.
since chase-t is con-structed from sparc, we follow the train and devel-opment split of the original sparc dataset.
table 6shows the data split statistics..4.2 contextual dependency.
table 1 presents the contextual dependency char-acteristic of chase.
the numbers are computedon the development set in consistency with ourstudy setup in section 2.3. the number of context-dependent questions in chase (65%) is substan-tially larger than existing datasets.
also, chasehas more questions that require resolutions of coref-.
2321dataset.
chasechase-cchase-t.exact stringmatch.
fuzzy stringmatch.
semanticmatch.
48.2%41.2%53.7%.
40.2%44.8%37.0%.
11.6%14.0%9.9%.
table 7: mention of database schema items..match.
schema item question.
fuzzystring.
fuzzystring.
semantic.
歌名song name.
售价selling price.
售价selling price.
这首 歌曲的名字 是？.
what is the name of this song ?.
均价 是多少？.
what is the average price ?.
哪些音箱比这 便宜 ？which speakers are cheaper than this?.
semantic.
成立时间founding date.
哪只球队 历史 最悠久？.
which team has the longest history ?.
table 8: examples of fuzzy string match and semanticmatch.
each item’s mention is highlighted..erence and ellipsis.
from this point of view, chaseis a better testbed for xdts.
when it comesto chase-c and chase-t, 71% of questionsin chase-c are context-dependent, showing thatquestion sequences collected with our method havericher contextual dependencies than those collectedvia decomposition.
compared with sparc, thenumber of context-dependent questions in chase-t increases from 53% to 58% through our effort..4.3 sql hardness distribution.
table 3 shows the sql hardness distributionof chase.
sql queries in different hardness lev-els are more evenly distributed in chase, and only28% of them are easy.
by comparing chase-cwith existing datasets, we can observe a remark-able difference between their hardness distributions.
speciﬁcally, the number of easy queries (19%)in chase-c is less than that of hard (24%) andextra hard (20%) queries, indicating that questionsequences created from scratch with our methodare much more challenging.
in terms of chase-t,the number of easy queries decreases from 40% to37% through our effort, compared with sparc..4.4 mention of database schema items.
to understand how database schema items (tablesand columns) are mentioned in questions, for eachitem annotated in the schema linking, we examinewhether or not it can exactly match its mentionin the question (suhr et al., 2020).
as shown intable 7, among the 26,464 items annotated in the.
schema linking of chase, 48% of them are exactlymentioned in questions (exact string match), and40% of them have at least one token that appearsin their mentions (fuzzy string match).
the re-maining 12% items cannot be matched with theirmentions via any string-match based methods (se-mantic match).
table 8 presents four typical exam-ples for fuzzy string match and semantic match..compared with chase-t, whose data are con-structed from sparc, chase-c has more items inthe fuzzy string match and semantic match groups,implying that chase-c is more challenging andits mentions of schema items are more diverse..5 experiments.
to understand the performance of the sota ap-proaches on chase, chase-c, and chase-t, weexperiment with the three approaches introducedin section 2.2. appendix a.3 provides the detailsof our adaptations for chinese inputs and the ex-perimental setup..5.1 experimental results.
table 9 presents the experimental results, fromwhich we make four main observations..first, the performance of the sota approacheson chase is far from satisfactory.
the best ap-proach on chase, igsql, only achieves 40.4%question match (qm), which is signiﬁcantly lowerthan the sota qm on sparc (60.1%) and cosql(50.8%).
in terms of interaction match (im), thebest approach on chase only achieves 15.6%,lagging behind the sota im on sparc (38.1%)and cosql (20.1%) by a large margin.5 theseresults show that chase presents signiﬁcant chal-lenges for future research on xdts..lower.
second,.
the performance of the sota ap-than thatproaches on chase-c ison chase-t. speciﬁcally, igsql can achieve43.3% qm and 26.3% im on chase-t, but only32.6% qm and 9.3% im on chase-c. it showsthat question sequences created from scratch withour method is much more challenging, which isconsistent with our analysis in section 4..third, the performance of the sota approacheson chase-t is lower than that on sparc.
thereare two reasons for the degradation.
first, dur-ing the construction of chase-t, we try our bestto mitigate the two biases found in section 2,.
5cosql has more questions in a question sequence (5.2).
than sparc (3.0) and chase (3.3) on average..2322approach.
dev.
testqm im qm im qm im qm im qm im qm im qm im.
test.
dev.
chase-tdev.
sparcdev.
cosqldev.
chase.
chase-c.editsqligsqlrat-con.
37.741.435.1.
17.420.014.6.
37.840.432.5.
14.715.69.8.
33.631.424.6.
8.410.85.4.
32.632.623.9.
8.79.34.5.
41.643.343.7.
21.626.321.6.
47.149.560.1.
29.430.138.6.
39.942.650.8.
12.314.720.1.table 9: question match (qm) and interaction match (im) of the three benchmark approaches..dataset.
contextual dependency.
sql hardness.
indep.
dep.
coref.
ellipsis easy medium hard extra hard.
1.question position3.
4.
2.chasechase-cchase-t.56.345.456.2.
33.325.733.9.
33.125.835.1.
33.225.231.1.
65.652.366.2.
41.136.636.9.
27.323.524.0.
16.611.412.5.
59.148.658.8.
42.334.240.3.
29.422.532.6.
24.519.017.0.
>=5.
20.517.10.0.table 10: question match of igsql on the development sets.
‘coref.’ is short for ‘coreference’..select t2.college from mvp record as t1 join player as t2 group by t2.college order by count(distinct t2.player id) desc limit 1select college from player group by college order by count(*) desc limit 1.q1 哪所大学培养了最多mvp球员？(which university has the most mvp players?)
y1ˆy1q2 状元呢？(how about the ﬁrst overall pick?)
y2ˆy2q3 居然还是肯塔基！杜克也非常出名啊，它培养了多少呢？ (still kentucky!
duke is also very famous!
how many does it have?)
y3ˆy3.
select college from player where is ﬁrst pick = “yes” group by college order by count(*) desc limit 1select is ﬁrst pick from player group by college order by count(*) desc limit 1.select count(*) from player where is ﬁrst pick = “yes” and college like “%duke%”select count(*) from player where college like “%duke%”.
table 11: predictions ˆyj of igsql for the question sequence in figure 1. sql queries are translated to english..which makes chase-t more pragmatic and chal-lenging than sparc.
second, existing approachesfor xdts are tuned for english only, and somecomponents of these approaches cannot processchinese inputs as well as english inputs..finally, although rat-con achieves the sotaperformance on sparc and cosql, it lags be-hind editsql and igsql by a large marginon chase and chase-c. through a careful exami-nation, we ﬁnd that rat-sql (wang et al., 2020a),the model that rat-con builds upon, adopts astring-match based method to ﬁnd the linking be-tween database schema items and their mentionsin questions.
however, this string-match basedmethod struggles when many schema items are notexactly mentioned in questions.
also, this methodstruggles in chinese probably because it is onlytuned for english.
the annotations of schema link-ing in chase can provide a great opportunity forfuture research to tackle this problem..5.2 fine-grained analysis.
pendency, sql hardness, and question position.6we can observe a remarkable discrepancy betweenqm on context-independent and context-dependentquestions.
to tackle this problem, more advancedcontext modeling methods are needed.
our an-notations of contextual dependency in chasecan enable a ﬁne-grained analysis on xdts ap-proaches, and they potentially can be used to ad-dress this problem.
besides, we observe that theqm of igsql on medium, hard, and extra hardqueries of chase is higher than that of chase-cand chase-t, implying that more training sam-ples for these complex queries can improve an ap-proach’s performance on them.
a similar observa-tion can be obtained in the question position.
theqm of igsql on questions in turn 4 and >=5 ishigher than that of chase-c and chase-t..5.3 case study.
table 11 shows the predictions of igsql for thequestion sequence shown in figure 1. q1 queriesthe players that have won mvp, but igsql missesthe “mvp record” table, probably because the.
table 10 shows the qm of igsql on the devel-opment set of chase, stratiﬁed by contextual de-.
6table 13 and 14 in appendix present the detailed experi-.
mental results of editsql and rat-con..2323from clause of sql is synthesized based on theother predicted clauses.
q2 requires a resolution ofellipsis.
it queries the college with the most ﬁrstpick players, but igsql fails to resolve the ellipsisand predicts the wrong column in the selectclause.
the last question omits the object “ﬁrstpick players” of the verb “have”, but the approachcannot fully resolve it and misses the ﬁrst pickconstraint in the where clause..6 related work.
dataset xdts is a sub-task of context-dependent semantic parsing (cdsp) (suhr et al.,2018; guo et al., 2019a; li et al., 2020).
manydatasets have been constructed for cdsp.
theycan be categorized into two groups according totheir annotations.
(1) denotation utterances in this group of datasetsare only labelled with their denotations, i.e., theexecution results of logical forms.
sequen-tialqa (iyyer et al., 2017), scone (long et al.,2016), and csqa (saha et al., 2018) are represen-tative datasets in this group.
sequentialqa wasconstructed by decomposing some complicatedquestions from wikitablequestions (pasupat andliang, 2015) into sequences of simple questions.
aquestion sequence in scone was collected by ran-domly generating a sequence of world states andasking annotators to write an utterance betweeneach pair of successive states.
csqa was con-structed by collecting a large number of individualquestions and converting them into question se-quences via a set of manually crafted templates.
(2) logical form utterances in this group are la-belled with their logical forms.
except for sparcand cosql, atis (hemphill et al., 1990; dahlet al., 1994) and tempstructure (chen andbunescu, 2019) also fall into this group.
atis wasconstructed under the wizard-of-oz (woz) setup.
an annotator raised a question, and another anno-tator wrote the corresponding sql query.
unlikedatasets for xdts, atis only focuses on the ﬂightplanning domain, which limits the possible sqllogic it contains.
tempstructure was also con-structed under the woz setup, but it synthesizedmany artiﬁcial question sequences with templatesto enlarge the dataset..chase belongs to the group of logical form.
to the best of our knowledge, it is the largestdataset with logical forms annotated for cdsp.
also, chase is the ﬁrst chinese dataset for cdsp..approach a lot of approaches have been pro-posed to address xdts (zhang et al., 2019; caiand wan, 2020; zhong et al., 2020; hui et al., 2021;yu et al., 2021).
zhang et al.
(2019) proposed ed-itsql, which generates a sql query by editingthe query generated for previous turns.
editsqlalso uses an interaction-level encoder (suhr et al.,2018) to model the interactions between the currentquestion and previous questions.
igsql (cai andwan, 2020) improves over editsql by introducinga graph encoder to model database schema itemstogether with historically mentioned items.
huiet al.
(2021) jointly modeled a question sequence,schema items, and their interactions via a dynamicgraph and a graph encoder.
they also proposed a re-ranking module to improve the generation accuracy.
liu et al.
(2020) systematically compared differentcontext modeling methods on sparc and cosql.
they found that concatenating all questions as in-puts rivals or even outperforms more complicatedcontext modeling methods.
this ﬁnding also mo-tivates us to implement the strong benchmark ap-proach, rat-con..7 conclusion and future work.
this work presents chase, to date the largestdataset for xdts, consisting of 5,459 questionsequences over 280 databases.
each questionin chase has rich semantic annotations, includingits sql query, contextual dependency, and schemalinking.
experimental results show that chasehighlights the challenging problems of xdts andthere is a long way for us to achieve real text-to-sql demands of users.
currently, chase isconstructed for chinese.
we plan to support morelanguages in the future.
besides, we plan to explorethe ways to utilize the rich semantic annotationsin chase to address the challenges in xdts..acknowledgments.
we thank wuxia jin and the anonymous review-ers for their helpful discussion and detailed com-ments.
we thank weixu zhang, jiawei lin, xi-aotong zheng, nan hu, tingting zhang, zekunqi, chengzu li, junjie tao, jinghan he, and yuma for participating in the construction of chase.
ming fan was partially supported by nsfc(61902306), china postdoctoral science founda-tion (2019tq0251, 2020m673439), youth talentsupport plan of xi’an association for science andtechnology (095920201303)..2324ethical considerations.
this work presents chase, a free and open datasetfor the research community to study the cross-database context-dependent text-to-sql problem(xdts).
data in chase are collected from twosources.
first, we collect 120 databases from thedusql (wang et al., 2020c) dataset, a free andopen dataset for the chinese text-to-sql prob-lem.
to collect question sequences on these 120databases, we recruit 12 chinese college students(5 females and 7 males).
each student is paid10 yuan ($1.6 usd) for creating each questionsequence.
this compensation is determined ac-cording to prior work on similar dataset construc-tion (yu et al., 2019a).
since all question sequencesare collected against open-access databases, thereis no privacy issue.
second, to enlarge our dataset,we translate all the data, including questions, sqlqueries, and databases, from english to chinesein sparc (yu et al., 2019b).
sparc is a free andopen english dataset for xdts.
11 college stu-dents (5 females and 6 males) are recruited to per-form the translation, each of whom is paid 2 yuan($0.3 usd) for translating each question.
the de-tails of our data collection and characteristics areintroduced in section 3 and 4..references.
i. androutsopoulos, g.d. ritchie, and p. thanisch.
1995. natural language interfaces to databases –an introduction.
natural language engineering,1(1):29–81..n´uria bertomeu, hans uszkoreit, anette frank, hans-ulrich krieger, and brigitte j¨org.
2006. contextualphenomena and thematic relations in database qadialogues: results from a wizard-of-oz experiment.
in proceedings of the interactive question answer-ing workshop at hlt-naacl 2006, pages 1–8, newyork, ny, usa.
association for computational lin-guistics..yitao cai and xiaojun wan.
2020. igsql: databaseschema interaction graph based neural model forcontext-dependent text-to-sql generation.
in pro-ceedings of the 2020 conference on empirical meth-ods in natural language processing (emnlp),pages 6903–6912, online.
association for compu-tational linguistics..charles chen and razvan bunescu.
2019. contextdependent semantic parsing over temporally struc-tured data.
in proceedings of the 2019 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),.
pages 3576–3585, minneapolis, minnesota.
associ-ation for computational linguistics..deborah a. dahl, madeleine bates, michael brown,william fisher, kate hunicke-smith, david pallett,christine pao, alexander rudnicky, and elizabethshriberg.
1994. expanding the scope of the atistask: the atis-3 corpus.
in human language tech-nology: proceedings of a workshop held at plains-boro, new jersey, march 8-11, 1994..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..daya guo, duyu tang, nan duan, ming zhou, andjian yin.
2019a.
coupling retrieval and meta-learning for context-dependent semantic parsing.
inproceedings of the 57th annual meeting of the as-sociation for computational linguistics, pages 855–866, florence, italy.
association for computationallinguistics..jiaqi guo, zecheng zhan, yan gao, yan xiao,jian-guang lou, ting liu, and dongmei zhang.
2019b.
towards complex text-to-sql in cross-domain database with intermediate representation.
in proceedings of the 57th annual meeting of theassociation for computational linguistics, pages4524–4535, florence, italy.
association for compu-tational linguistics..charles t. hemphill, john j. godfrey, and george r.doddington.
1990. the atis spoken language sys-tems pilot corpus.
in speech and natural language:proceedings of a workshop held at hidden valley,pennsylvania, june 24-27,1990..binyuan hui, ruiying geng, qiyu ren, binhua li,yongbin li, jian sun, fei huang, luo si, pengfeidynamic hy-zhu, and xiaodan zhu.
2021.brid relation exploration network for cross-domaincontext-dependent semantic parsing.
proceedingsof the aaai conference on artiﬁcial intelligence,35(14):13116–13124..mohit iyyer, wen-tau yih, and ming-wei chang.
2017.search-based neural structured learning for sequen-in proceedings of thetial question answering.
55th annual meeting of the association for com-putational linguistics (volume 1: long papers),pages 1821–1831, vancouver, canada.
associationfor computational linguistics..j. f. kelley.
1984. an iterative design methodologyfor user-friendly natural language ofﬁce informationapplications.
acm trans.
inf.
syst., 2(1):26–41..2325wenqiang lei, weixin wang, zhixin ma, tian gan,wei lu, min-yen kan, and tat-seng chua.
2020.re-examining the role of schema linking in text-to-in proceedings of the 2020 conference onsql.
empirical methods in natural language process-ing (emnlp), pages 6943–6954, online.
associa-tion for computational linguistics..zhuang li, lizhen qu, and gholamreza haffari.
2020.context dependent semantic parsing: a survey.
inproceedings of the 28th international conferenceon computational linguistics, pages 2509–2521,barcelona, spain (online).
international committeeon computational linguistics..qian liu, bei chen, jiaqi guo, jian-guang lou, binzhou, and dongmei zhang.
2020. how far are wean exploratoryfrom effective context modeling?
in proceed-study on semantic parsing in context.
ings of the twenty-ninth international joint con-ference on artiﬁcial intelligence, ijcai-20, pages3580–3586.
international joint conferences on ar-tiﬁcial intelligence organization.
main track..reginald long, panupong pasupat, and percy liang.
2016. simpler context-dependent logical forms viain proceedings of the 54th an-model projections.
nual meeting of the association for computationallinguistics (volume 1: long papers), pages 1456–1465, berlin, germany.
association for computa-tional linguistics..christopher manning, mihai surdeanu, john bauer,jenny finkel, steven bethard, and david mcclosky.
2014. the stanford corenlp natural language pro-in proceedings of 52nd annualcessing toolkit.
meeting of the association for computational lin-guistics: system demonstrations, pages 55–60, bal-timore, maryland.
association for computationallinguistics..qingkai min, yuefeng shi, and yue zhang.
2019. apilot study for chinese sql semantic parsing.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 3652–3658, hong kong, china.
association for computa-tional linguistics..panupong pasupat and percy liang.
2015. compo-sitional semantic parsing on semi-structured tables.
in proceedings of the 53rd annual meeting of theassociation for computational linguistics and the7th international joint conference on natural lan-guage processing (volume 1: long papers), pages1470–1480, beijing, china.
association for compu-tational linguistics..amrita saha, vardaan pahuja, mitesh m. khapra,karthik sankaranarayanan, and sarath chandar.
2018. complex sequential question answering: to-wards learning to converse over linked question an-in proceed-swer pairs with a knowledge graph.
ings of the thirty-second aaai conference on ar-tiﬁcial intelligence, (aaai-18), the 30th innovative.
applications of artiﬁcial intelligence (iaai-18), andthe 8th aaai symposium on educational advancesin artiﬁcial intelligence (eaai-18), new orleans,louisiana, usa, february 2-7, 2018, pages 705–713. aaai press..torsten scholak, raymond li, dzmitry bahdanau,harm de vries, and chris pal.
2021. duorat: to-wards simpler text-to-sql models.
in proceedingsof the 2021 conference of the north american chap-ter of the association for computational linguistics:human language technologies, pages 1313–1321,online.
association for computational linguistics..peter shaw, jakob uszkoreit, and ashish vaswani.
2018. self-attention with relative position represen-in proceedings of the 2018 conference oftations.
the north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 2 (short papers), pages 464–468,new orleans, louisiana.
association for computa-tional linguistics..alane suhr, ming-wei chang, peter shaw, and ken-ton lee.
2020. exploring unexplored generalizationchallenges for cross-database semantic parsing.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 8372–8388, online.
association for computational lin-guistics..alane suhr, srinivasan iyer, and yoav artzi.
2018.learning to map context-dependent sentences to ex-ecutable formal queries.
in proceedings of the 2018conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 1 (long papers),pages 2238–2249, new orleans, louisiana.
associ-ation for computational linguistics..anh tuan nguyen, mai hoang dao, and dat quocnguyen.
2020. a pilot study of text-to-sql seman-in findings of the as-tic parsing for vietnamese.
sociation for computational linguistics: emnlp2020, pages 4079–4085, online.
association forcomputational linguistics..bailin wang, richard shin, xiaodong liu, oleksandrpolozov, and matthew richardson.
2020a.
rat-sql: relation-aware schema encoding and linkingfor text-to-sql parsers.
in proceedings of the 58thannual meeting of the association for computa-tional linguistics, pages 7567–7578, online.
asso-ciation for computational linguistics..huajie wang, mei li, and lei chen.
2020b.
pg-gsql: pointer-generator network with guide de-coding for cross-domain context-dependent text-to-in proceedings of the 28th inter-sql generation.
national conference on computational linguistics,pages 370–380, barcelona, spain (online).
interna-tional committee on computational linguistics..lijie wang, ao zhang, kun wu, ke sun, zhenghuali, hua wu, min zhang, and haifeng wang.
2020c..2326processing (emnlp-ijcnlp), pages 5338–5349,hong kong, china.
association for computationallinguistics..victor zhong, mike lewis, sida i. wang, and lukezettlemoyer.
2020. grounded adaptation for zero-shot executable semantic parsing.
in proceedings ofthe 2020 conference on empirical methods in nat-ural language processing (emnlp), pages 6869–6882, online.
association for computational lin-guistics..dusql: a large-scale and pragmatic chinese text-in proceedings of the 2020 con-to-sql dataset.
ference on empirical methods in natural languageprocessing (emnlp), pages 6923–6935, online.
as-sociation for computational linguistics..pengcheng yin and graham neubig.
2017. a syntacticneural model for general-purpose code generation.
in proceedings of the 55th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 440–450, vancouver, canada.
association for computational linguistics..tao yu, rui zhang, heyang er, suyi li, eric xue,bo pang, xi victoria lin, yi chern tan, tianzeshi, zihan li, youxuan jiang, michihiro yasunaga,sungrok shim, tao chen, alexander fabbri, zifanli, luyao chen, yuwen zhang, shreya dixit, vin-cent zhang, caiming xiong, richard socher, walterlasecki, and dragomir radev.
2019a.
cosql: aconversational text-to-sql challenge towards cross-domain natural language interfaces to databases.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 1962–1979, hong kong, china.
association for computa-tional linguistics..tao yu, rui zhang, alex polozov, christopher meek,and ahmed hassan awadallah.
2021.
{sc}ore: pre-training for context representation in conversationalin international conference onsemantic parsing.
learning representations..tao yu, rui zhang, kai yang, michihiro yasunaga,dongxu wang, zifan li, james ma,irene li,qingning yao, shanelle roman, zilin zhang,spider: a large-and dragomir radev.
2018.scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task.
inproceedings of the 2018 conference on empiricalmethods in natural language processing, pages3911–3921, brussels, belgium.
association forcomputational linguistics..tao yu, rui zhang, michihiro yasunaga, yi cherntan, xi victoria lin, suyi li, heyang er, ireneli, bo pang, tao chen, emily ji, shreya dixit,david proctor, sungrok shim, jonathan kraft, vin-cent zhang, caiming xiong, richard socher, anddragomir radev.
2019b.
sparc: cross-domain se-in proceedings of themantic parsing in context.
57th annual meeting of the association for com-putational linguistics, pages 4511–4523, florence,italy.
association for computational linguistics..rui zhang, tao yu, heyang er, sungrok shim,eric xue, xi victoria lin, tianze shi, caim-ing xiong, richard socher, and dragomir radev.
2019.editing-based sql query generation forcross-domain context-dependent questions.
in pro-ceedings of the 2019 conference on empirical meth-ods in natural language processing and the 9th in-ternational joint conference on natural language.
2327a appendix.
a.1 rat-con.
rat-con is our extension of rat-sql (wanget al., 2020a), the sota approach for the context-independent text-to-sql problem.
given a ques-tion q and a database db, rat-sql ﬁrst linksthe database schema items with their mentions inquestions via a string-match based method.
then,the linking results are jointly encoded with q anddb using a relation-aware self-attention trans-former (shaw et al., 2018).
to generate a sqlquery y, rat-sql adopts a grammar-based de-coder (yin and neubig, 2017)..to extend rat-sql to the context-dependentsetting, we use the simple concatenation contextmodeling method, which has shown to be compet-itive with other more complex context modelingmethods (liu et al., 2020).
speciﬁcally, to generatesql query yij, we concatenate all its priorquestions (cid:104)qij−1(cid:105) with a special symbol[sep]: (cid:104)qi1(cid:105).
theother components of rat-sql remain the same.
figure 2 shows the architecture of rat-con withan illustrative example..j for qi1, · · · , qij, [sep], qi.
j−1, · · · , [sep], qi.
we implement rat-con on the codebase ofduorat (scholak et al., 2021).
we use the defaulthyper-parameters in duorat except for the batchsize, which is altered to 24..a.2 annotation tool for chase-c.figure 3 shows the user interface of our annotationtool for collecting question sequences in chase-c.when an annotator is going to raise a follow-upquestion, an intent category is randomly sampledfrom one of the ﬁve categories in table 4. thechosen category is highlighted in the row “意图”of the left panel.
the annotator is recommendedto raise a question that meets one of the relationsin the category.
after raising the question, the an-notator is asked to label the contextual dependencyand the corresponding sql query of the question.
the sql query should be executable in the sqlitedatabase engine.
the execution results are shownto the annotator.
besides, we extract all the tables,columns, and values in the query, and we ask theannotator to link them to their mentions in the ques-tion.
the linked characters are highlighted in therow “tokens” of the left panel..a.3 experimental details.
to study existing datasets for xdts, we need toget the predictions on the development sets fromthe benchmark approaches.
the predictions of ed-itsql are released with its source code.
hence,we directly use them for analysis.
as for igsql,we train it with the default hyper-parameters spec-iﬁed in its source code, but we cannot reproducethe numbers reported in its paper.
nevertheless,igsql still outperforms editsql in both sparcand cosql.
in terms of rat-con, we train itfrom scratch.
all our experiments were conductedon titan rtx with 24gb memory..a.3.1 adaptation to chinese inputssince all the benchmark approaches use bert forencodings and chase is constructed for chinese,we replace bert with chinese-bert.7 duringthe adaptations of editsql and igsql, we iden-tiﬁed and ﬁxed 3 bugs in their pre-process andpost-process procedures.
the string-match basedschema linking method in rat-sql utilizes thestanford corenlp toolkit (manning et al., 2014)to tokenize a question, and the method performsstring matches between the resulting words andschema items.
to adapt this method to chinese,we try to use the chinese package of corenlp totokenize questions.
however, we ﬁnd that doingso fails to link a lot of schema items.
considerthe question “这首歌曲的名字是？” and the col-umn “歌名” which is an abbreviation for “歌曲的名字”.
the question is tokenized by corenlpinto (cid:104) 这, 首, 歌曲, 的, 名字, 是, ?
(cid:105).
none ofthe resulting words can be matched with “歌名”.
consequently, the method cannot link the columnto the question.
to solve this problem, we simplytokenize a chinese question character by charac-ter.
in this way, the character ‘歌’ and ‘名’ can bepartly matched to “歌名”.
although this solutionwould introduce a lot of noises, our experimentalresults show that this solution outperforms the oneusing corenlp.
it would be very useful to explorethe ways to conduct schema linking in chinese..7https://github.com/google-research/bert.
2328figure 2: the architecture of rat-con..figure 3: the user interface of our annotation tool..category.
relation.
precedent sql query yi.
j−1.
current sql query yij.example.
same instances.
different instancesof the same entity.
r1r2r3.
r4.
r5r6r7.
r8.
add propertyremove propertyreplace property.
select name from student;select name, age from student;select name from student;.
add group.
select count(*) from student;.
add aggregationalter aggregationdelete aggregation.
select name from student;select max(age) from student;select count(*) from student;.
subset.
select name from student;.
r9.
superset.
r10 disjoint.
r11 complement.
r12 overlap.
select name from studentwhere country = “us”;select name from studentwhere country = “us”;select name from studentwhere country = “us”;.
select name, age from student;select name from student;select country from student;select country, count(*) from student.
group by country;.
select count(*) from studentselect avg(age) from student;select name from student;.
select name from studentwhere country = “us”;select name from student.
select name from student.
where country = “china”;.
select name from student.
where country != “us”;.
where country = “us” or country = “china”;.
select name from student join student course.
select name from student join student course.
where course name = “python”;.
where course name = “c++”;.
different entity.
r13 change entity.
select name from student;.
select course name from course;.
display.
r14 add order.
r15 alter order.
select country, count(*) from student.
select country, count(*) from student.
group by country;.
group by country order by count(*);.
select country, count(*) from student.
select country, count(*) from student.
group by country order by count(*) asc;.
group by country order by count(*) desc;.
r16 distinct.
select country from student;.
select distinct country from student;.
table 12: all the 16 relations in the four basic intent categories presented in section 3. except for the relations inthe different entity category, all the others can be combined..2329[cls]how about the first overall pick ?
[sep]which university has trained the most mvp players ?
[cls]bool is first pick ⋯[cls]number player id [cls]player ⋯[cls]mvp recordbertrelation-aware self-attention transformer encoder  grammar-based decoderselectcollege fromplayer whereis_first_pick= “yes” group by college order bycount(*) desc limit 1 𝑞"𝑞#column names and typestablenamesdataset.
approach.
contextual dependency.
sql hardness.
indep.
dep.
coref.
ellipsis easy medium hard extra hard.
1.chase.
chase-c.chase-t.editsqligsqlrat-con.
editsqligsqlrat-con.
editsqligsqlrat-con.
52.856.349.3.
51.145.435.8.
55.856.256.4.
29.533.327.3.
26.625.720.0.
30.233.934.5.
29.433.127.1.
27.125.819.8.
29.435.133.2.
29.233.228.1.
25.425.220.2.
31.131.136.8.
63.265.660.9.
58.552.346.5.
65.766.268.0.
37.041.135.4.
36.836.629.5.
34.736.937.4.
22.027.316.4.
24.423.513.3.
20.824.018.2.table 13: fine-grained experimental results on the development set of chase, chase-c, and chase-t. ‘indep.’and ‘dep.’ are short for ‘context-independent’ and ‘context-dependent’.
‘coref.’ indicates ‘coreference’..dataset.
approach.
contextual dependency.
sql hardness.
indep.
dep.
coref.
ellipsis easy medium hard extra hard.
1.chase.
chase-c.editsqligsqlrat-con.
editsqligsqlrat-con.
54.155.745.7.
49.346.734.7.
28.031.224.5.
25.326.519.2.
30.135.125.0.
28.629.821.5.
24.525.823.8.
20.221.615.6.
63.065.956.0.
59.161.248.3.
34.338.529.1.
33.633.824.9.
26.127.118.4.
25.622.914.3.table 14: fine-grained experimental results on the test set of chase and chase-c..question position3.
4.
2.
55.959.151.1.
55.348.638.7.
58.558.859.7.
40.442.337.6.
37.234.229.1.
37.740.338.4.
25.729.424.9.
22.822.518.3.
25.632.633.7.
16.424.516.4.
17.619.011.4.
20.517.023.9.
>=5.
12.020.57.2.
15.917.17.3.
0.00.00.0.question position3.
4.
2.
36.640.031.8.
32.734.526.7.
25.026.720.2.
22.822.517.4.
20.623.718.6.
19.821.911.5.
>=5.
18.421.110.5.
18.318.38.5.
58.861.251.4.
52.650.238.1.
13.816.611.6.
15.411.48.3.
14.612.515.3.
10.810.211.7.
8.09.05.2.
# question & sql query.
question sequence q1.
q11 how many templates are there?
y1select count(*) from templates1q12 what is the date effective of template 1?
y12q13 what is the template type code template id 4?
y13q14 what is the version number of template id 0?
y14question sequence q2.
select template type code from templates where template id = 4.select version number from templates where template id = 0.select date effective from, date effective to from templates where template id = 1.q21 what is the ﬁrst name of player id 2000001?
y21.select ﬁrst name from player where player id = 2000001.q22.what is the birth date for martina?
there are a lot of martina.
do you mean the marina with id 200001?
martina with id 2000001select birth date from player where player id = 2000001.y22q23 what is the country code for player id 2000003?
y23question sequence q3.
select country code from player where player id = 2000003.q31 what unique cities are in asian countries?
y31q32 which of those cities have a population over 200,000?
y32q33 what is the average population of all cities in china?
y33q34 what is the average population of all cities that speak the dutch language?
y34.select distinct t3.name from country as t1 join countrylanguage as t2 join city as t3 where t1.continent = “asia”.
select distinct t3.name from country as t1 join countrylanguage as t2 join city as t3 where t1.continent = “asia” and t3.population >200000.
select avg(t3.population) from country as t1 join countrylanguage as t2 join city as t3 where t1.name = “china”.
select avg(t3.population) from country as t1 join countrylanguage as t2 join city as t3 where t2.language = “dutch”.
table 15: question sequence examples in cosql.
since cosql is a task-oriented dialogue corpus, it has some2 in question sequence q2.
we also consider thesequestions involving clariﬁcation, e.g., the second question q2questions as context-dependent.
among the 1,007 questions in the development set of cosql, 95 of them involveclariﬁcations.
sparc and chase do not have this kind of questions..contextualdependency.
independent.
independent.
independent.
independent.
independent.
dependent(other).
independent.
independent.
dependent(coreference).
independent.
independent.
2330# question & sql query.
question sequence q1.
q11y11.q12y12.q13.y13.q14.y14.q21.y21.q22.y22.q23.y23.q24.y24.q31y31.q32.y32.q33.y33.q34.y34.q41y41.q42y42.q43.y43.
哪个专业可以本硕博连读？(which major has a continuous academic program?)
select 专业名称 from 专业 where 学科类型 = “本硕博”(select name from major where enrollment mode = “continuous academic program”)要读多少年？(how many years does one have to study?)
select 学制 from 专业 where 学科类型 = “本硕博”(select duration from major where enrollment mode = “continuous academic program”)该专业的招考类型 (enrollment type of this major)select t2.招考类型 from 专业 as t1 join 清华大学招生计划 as t2 on t1.id = t2.专业id where t1.学科类型 = “本硕博”(select t2.enrollment type from major as t1 join enrollment plan as t2 on t1.id = t2.major id where t1.enrollment mode= “continuous academic program”)除了这个专业，我还能报考哪些专业的专项计划？(among the majors in special plan, which can i study except this major?)
select t1.专业名称 from 专业 as t1 join 清华大学招生计划 as t2 on t1.id = t2.专业id where t2.招考类型 = “专项”except select 专业名称 from 专业 where 学科类型 = “本硕博”(select t1.name from major as t1 join enrollment plan as t2 on t1.id = t2.major id where t2.enrollment type = “special plan”except select name from major where enrollment type = “continuous academic program”).
question sequence q2.
我要寄一个快递到浙江。哪家公司的价格会最便宜？(i’m going to send an express package to zhejiang.
which company offers the lowest price?)
select t2.公司名 from 快递费 as t1 join 快递公司 as t2 on t1.快递公司id = t2.公司id join 省份 as t3 on t1.区域 = t3.省idwhere t3.省名 = “浙江” order by t1.每公斤价格 asc limit 1(select t2.name from express cost as t1 join express company as t2 on t1.express company id = t2.company id join provinceas t3 on t1.region = t3.province id where t3.province name = “zhejiang” order by t1.price per kg asc limit 1)至少需要多少公斤才能寄？(how many kilograms at least?)
select t1.起步公斤数 from 快递费 as t1 join 快递公司 as t2 on t1.快递公司id = t2.公司id join 省份 as t3 on t1.区域 = t3.省idwhere t3.省名 = “浙江” order by t1.每公斤价格 asc limit 1(select t1.starting kgs from express cost as t1 join express company as t2 on t1.express company id = t2.company id join provinceas t3 on t1.region = t3.province id where t3.province name = “zhejiang” order by t1.price per kg asc limit 1)有起步价格吗？如果有的话请告诉我。(please tell me the starting price, if any.)
select t1.起步价格 from 快递费 as t1 join 快递公司 as t2 on t1.快递公司id = t2.公司id join 省份 as t3 on t1.区域 = t3.省idwhere t3.省名 = “浙江” order by t1.每公斤价格 asc limit 1(select t1.starting price from express cost as t1 join express company as t2 on t1.express company id = t2.company id join provinceas t3 on t1.region = t3.province id where t3.province name = “zhejiang” order by t1.price per kg asc limit 1)那我需要认真考虑了。它有多少网点？(i’d like to think it over, how many branches does it have?)
select t2.网点数量 from 快递费 as t1 join 快递公司 as t2 on t1.快递公司id = t2.公司id join 省份 as t3 on t1.区域 = t3.省idwhere t3.省名 = “浙江” order by t1.每公斤价格 asc limit 1(select t2.branch number from express cost as t1 join express company as t2 on t1.express company id = t2.company id join provinceas t3 on t1.region = t3.province id where t3.province name = “zhejiang” order by t1.price per kg asc limit 1).
question sequence q3.
哪些水果适合在秋季种植？(what fruit is suitable for autumn planting?)
select 名称 from 水果 where 适合季节 = “秋季”(select name from fruit where suitable season = “autumn”)有哪些省份种植这些水果？(which province is the fruit planted in?)
select t3.名称 from 种植水果 as t1 join 水果 as t2 on t1.水果id = t2.id join 省份 as t3 on t1.省份id = t3.idwhere t2.适合季节 = “秋季”(select t3.name from fruit planting as t1 join fruit as t2 on t1.fruit id = t2.id join province as t3 on t1.province id = t3.idwhere t2.suitable season = “autumn”)去除重复的 (remove the duplicated!)
select distinct t3.名称 from 种植水果 as t1 join 水果 as t2 on t1.水果id = t2.id join 省份 as t3 on t1.省份id = t3.idwhere t2.适合季节 = “秋季”(select distinct t3.name from fruit planting as t1 join fruit as t2 on t1.fruit id = t2.id join province as t3 on t1.province id = t3.idwhere t2.suitable season = “autumn”)这些地方分别种植多少种水果？(how many kinds of fruit are planted in these provinces respectively?)
select t2.名称, count(*) from 种植水果 as t1 join 省份 as t2 on t1.省份id = t2.id where t2.名称 in (select distinct t5.名称from 种植水果 as t3 join 水果 as t4 on t3.水果id = t4.id join 省份 as t5 on t3.省份id = t5.id where t4.适合季节 = “秋季”)group by t2.名称(select t2.name, count(*) from fruit planting as t1 join province as t2 on t1.province id = t2.id where t2.name in (selectdistinct t5.name from fruit planting as t3 join fruit as t4 on t3.fruit id = t4.id join province as t5 on t3.province id= t5.id where t4.suitable season = “autumn”) group by t2.name).
question sequence q4.
微软赞助了哪些大会？(what ai summits did microsoft sponsor?)
select t2.名称 from 峰会赞助公司 as t1 join 峰会 as t2 on t1.峰会id = t2.峰会id where t1.公司 = “微软集团”(select t2.name from sponsor company as t1 join summit as t2 on t1.summit id = t2.summit id where t1.company = “microsoft”)该会是谁主办的？(what’s the organizer of this summit?)
select t2.主办单位 from 峰会赞助公司 as t1 join 峰会 as t2 on t1.峰会id = t2.峰会id where t1.公司 = “微软集团”(select t2.organizer from sponsor company as t1 join summit as t2 on t1.summit id = t2.summit id where t1.company = “microsoft”)有多少嘉宾参与？(how many honoured guests attended?)
select count(*) from 嘉宾参与峰会 as t1 join 嘉宾 as t2 on t1.嘉宾id = t2.嘉宾编号 join 峰会 as t3 on t1.峰会id = t3.峰会idjoin 峰会赞助公司 as t4 on t3.峰会id = t4.峰会id where t4.公司 = “微软集团”(select count(*) from guests of summits as t1 join guests as t2 on t1.guest id = t2.guest id join summit as t3 on t1.summit id= t3.summit id join sponsor company as t4 on t3.summit id = t4.summit id where t4.company = “microsoft”).
table 16: question sequence examples in chase..contextualdependency.
independent.
dependent(ellipsis).
dependent(coreference).
dependent(coreference).
independent.
dependent(ellipsis).
dependent(ellipsis).
dependent(coreference).
independent.
dependent(coreference).
dependent(ellipsis).
dependent(coreference).
independent.
dependent(coreference).
dependent(ellipsis).
2331