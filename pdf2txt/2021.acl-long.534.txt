are missing links predictable?
an inferential benchmark forknowledge graph completion.
yixin cao12 xiang ji1 xin lv3juanzi li3 yonggang wen1 hanwang zhang11school of cse, nanyang technological university, singapore2s-lab, nanyang technological university, singapore3department of cst, tsinghua university, beijing, chinacaoyixin2011@gmail.com, lv-x18@mails.tsinghua.edu.cnlijuanzi@tsinghua.edu.cn, {ygwen,hanwangzhang}@ntu.edu.sg.
abstract.
we present inferwiki, a knowledge graphcompletion (kgc) dataset that improves uponexisting benchmarks in inferential ability, as-sumptions, and patterns.
first, each testingsample is predictable with supportive data inthe training set.
to ensure it, we proposeto utilize rule-guided train/test generation, in-stead of conventional random split.
second,inferwiki initiates the evaluation following theopen-world assumption and improves the in-ferential difﬁculty of the closed-world assump-tion, by providing manually annotated nega-tive and unknown triples.
third, we includevarious inference patterns (e.g., reasoning pathlength and types) for comprehensive evalua-in experiments, we curate two settingstion.
of inferwiki varying in sizes and structures,and apply the construction process on codexas comparative datasets.
the results and em-pirical analyses demonstrate the necessity andhigh-quality of inferwiki.
nevertheless, theperformance gap among various inferential as-sumptions and patterns presents the difﬁcultyand inspires future research direction.
ourdatasets can be found in https://github.
com/taominer/inferwiki..1.introduction.
knowledge graph completion (kgc) aims to pre-dict missing links in kg by inferring new knowl-edge from existing ones.
attributed to its reasoningability, kgc models are crucial in alleviating thekg’s incompleteness issue and beneﬁting manydownstream applications, such as recommenda-tion (cao et al., 2019b) and information extrac-tion (hu et al., 2021; cao et al., 2020a).
however,the kgc performance on existing benchmarks arestill unsatisfactory — 0.51 hit ratio@1 and 187mean rank of the top-ranked model (wang et al.,2019) on the widely used fb15k237 (toutanovaand chen, 2015).
do we have a slow progress of.
testtrain.
testtrain.
headdaviddaviddavidzurichzurich.
predicatelocationplaceofbirthnationalitytravelmonthtravelmonth.
tail?
(ans: florida)atlantau.s.a.?
(ans: october)jan., feb., mar., apr.,may., jun., jul., aug.,sep., nov., dec..table 1: low-quality examples in fb15k237.
we onlypresent related triples.
ans denotes the missing entity..models (akrami et al., 2020)?
or should we blamefor the low-quality of benchmarks?.
in this paper, we re-think the task of kgc andconstruct a new benchmark dubbed inferwiki thathighlights three fundamental objectives:.
test triples should be inferential: this is the es-sential requirement of kgc.
each test triple shouldhave supportive samples in the train set.
how-ever, we observe two major issues of current kgcdatasets: unpredictable and meaningless test triples,which may hinder evaluating and advancing state-of-the-arts.
as shown in table 1, the ﬁrst exampleof inferring the location for david (i.e., florida)is even impossible for humans — not to mentionmachines — merely based on his birthplace andnationality (i.e., atlanta and usa).
in contrast, thesecond one is predictable but meaningless to ﬁndthe missing month from a list of months within ayear.
the above cases are very common in existingdatasets, e.g., yago3-10 (dettmers et al., 2018)and codex (safavi and koutra, 2020), mainly dueto their construction process: ﬁrst collecting a high-frequency subset of entities and then randomlysplitting their triples into train/test.
in this setting,kgc models may be over- or under-estimated, aswe are even unsure if a human can perform better.
test triples may be inferred positive, nega-tive, or unknown.
following open-world assump-tion: what is not observed in kg is not necessar-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages6855–6865august1–6,2021.©2021associationforcomputationallinguistics6855sourceinferential#entity#relation#train#valid (+)(-\unk)#test (+)(-\unk).
fb15k237 wn18rr yago3-10 codex-m kinship countryfreebase(cid:55)14,541237272,11517,535-\-20,466-\-.
yago(cid:55)123,182371,079,0405,000-\-5,000-\-.
wordnet(cid:55)40,9431186,8353,034-\-3,134-\-.
wikidata(cid:55)17,05051185,58410,31010,310\-10,31110,311\-.
(cid:51)27221,11124-\-24-\-.
(cid:51)104268,5481,069-\-1,069-\-.
artiﬁcial.
inferwiki16k/64kwikidata.
(cid:51)16,288197162,4243,3981,910\1,4563,3981,868\1,501.
(cid:51)64,718239782,2437,7476,125\1,6057,7476,062\1,685.
table 2: statistics of kgc datasets.
a more detailed survey table can be found in appendix a..ily false, but unknown (shi and weninger, 2018).
however, existing benchmarks generate unseentriples as negatives (i.e., the closed-world assump-tion), because kg contains only positive triples.
they usually randomly corrupt the head or tail en-tity in a triple, sometimes with type constraints (liet al., 2019a).
this leads to trivial evaluation (al-most 100% accuracy in triple classiﬁcation (safaviand koutra, 2020)).
besides, the lack of unknowntest ignores a critical inference capacity and maycause false negative errors in knowledge-driventasks (kotnis and nastase, 2017)..inference has various patterns.
concentrat-ing on limited patterns in evaluation may bringin severe bias.
domain-speciﬁc datasets kin-ship (kemp et al., 2006) and country (bouchardet al., 2015) only focus on a few relations and arenearly solved (das et al., 2017).
general-domainwn18rr (dettmers et al., 2018) contains prevalentsymmetry relation types, which incorrectly booststhe performance of rotate (abboud et al., 2020).
clearly, limited patterns leads to unfair compar-isons among kgc models..to this end, we curated an inferential kgcdataset extracted from wikidata and establish thebenchmark with two settings of varying in sizesand structures: inferwiki64k and inferwiki16k.
instead of random split, we mine rules via any-burl (meilicke et al., 2019) to guide train/testgeneration.
all test triples are thus guaranteedinferential from training data.
to avoid the ruleleakage, we utilize two sets of triples: a large setfor high-quality rule extraction and a small set fortrain/test split.
moreover, we infer unseen triplesand manually annotate them with positive, negativeand unknown labels to improve the difﬁculty ofevaluation following both closed-world and open-world assumptions.
for inference patterns, we in-clude and balance triples with different reasoningpath length, relation types and patterns (e.g., sym-metry and composition)..our contributions can be summarized as follows:.
• we summarize three principles of kgc: infer-ential ability, assumptions and patterns, andconstruct a rule-guided dataset..• we highlight the importance of negatives andunknowns, and initiate open-world evaluation..• we conduct extensive experiments to establishthe benchmark.
the results and deep analysesverify the necessity and challenge of infer-wiki, providing insights for future research..2 related work.
we can roughly classify current kgc datasetsinto two groups:inferential and non-inferentialdatasets.
the ﬁrst group is usually manually cu-rated to ensure each testing sample can be inferredfrom training data through reasoning paths, whilethey only focus on speciﬁc relations, such as fam-ilies (garcia-duran et al., 2015), kinship (kempet al., 2006), and country (bouchard et al., 2015).
the limited scale and inference patterns makethem not challenging.
hole (nickel et al., 2016)achieves 99.7% acu-pr on the dataset of country.
the second group of datasets are automaticallyderived from public kgs and randomly split posi-tive triples into train/test, leading to a risk of testingsamples non-inferential from training data.
pop-ular datasets include fb15k-237 (toutanova andchen, 2015), wn18rr (dettmers et al., 2018), andyago3-10 (dettmers et al., 2018).
codex (safaviand koutra, 2020) argues the scope and difﬁculty ofthe above datasets, thus propose a comprehensivedataset with manually veriﬁed hard negatives..in fact, inference is an important ability for in-telligence.
various ﬁelds study how inference isdone in practice, ranging from logic to cognitivepsychology.
inference helps people make reliablepredictions, which is also an expected ability for aimodels.
indeed, once deployed, a model may have.
6856to make a prediction when there is no evidence inthe training set.
but, instead of an unreliable guess,we highlight the ability to know unknown, a.k.a.
open-world assumption.
therefore, we aim to cu-rate an large-scale inferential benchmark inferwikiincluding various inference patterns and testingsamples (i.e., positive, negative, and unknown), forbetter evaluation.
we list the statistics in table 2..3 dataset design.
we describe our dataset construction that comprisesfour steps: data preprocessing, rule mining, rule-guided train/test generation, and inferred test label-ing.
we then give a detailed analysis..3.1 data preprocessingmore and more studies utilize wikidata1 as aknowledge resource due to its high quality andlarge quantity.
we utilize the september 2019 en-glish dump in experiments.
data preprocessingaims to deﬁne relation vocabulary and extract twosets of triples from wikidata: a large one for rulemining t r and a relatively small one for datasetgeneration t d. the reason for using two sets is toavoid the leakage of rules.
in other words, somefrequent rules on the large set may be very few onthe small set.
the different distributions shall avoidthat rule mining methods will easily achieve highperformance.
besides, more triples can improvethe quality of mined rules.
in contrast, the relativelysmall set is enough for efﬁcient kgc training andevaluation..in speciﬁc, we ﬁrst extract all triples that consistof two entity items and one relation with englishlabels.
we then remove the repeated triples andobtain 40,199,175 triples with 7,734,841 entitiesand 1,170 different relation types.
considering rulemining efﬁciency, we reduce the relation vocabu-lary by (1) manually ﬁltering out meaningless rela-tions, such as movie id or ﬁlm rating, (2) removingrelations of instanceof and subclassof followingexisting benchmarks (toutanova and chen, 2015),(3) select the most frequent 500 relation types.
wefocus on the most frequent 800,000 entities, whichresult in 8,632,777 triples as the large set for rulemining.
to obtain the small set for dataset construc-tion, we further select the most frequent 120,000entities and 300 relations, which result in 1,283,246triples.
note that we also infer new triples and labelthem as positive, negative, or unknown later..3.2 rule mining.
since developing advanced rule mining models isnot the focus of this paper and several mature toolsare available online, such as amie+ (gal´arragaet al., 2015) and anyburl (meilicke et al., 2019).
we utilize anyburl2 in experiments due to itsefﬁciency and effectiveness..given a set of triples (i.e., the large set t r),this step aims to automatically learn rules f ={(fp, λp)}pp=1, where fp denotes a horn rule, e.g.,spouse(x, y) ∧ father(x, z) ⇒ mother(y, z), andλp ∈ [0, 1] denotes the conﬁdence of fp.
for eachrule fp, the left side of ⇒ is called the premise, andthe right side is called the conclusion, where theconclusion contains a single atom and the premiseis a conjunction of several atoms in the horn rulescheme.
we can ground speciﬁc entities to replacex, y, z in fp, which shall denote an inferential re-lationship between premise and conclusion triples.
for example, given spouse(lebron james, savan-nah brinson) and father(lebron james, bronnyjames), we may infer a new triple mother(savannahbrinson, bronny james)..of course, not all of the mined rules are reason-able.
to alleviate the negative impacts of unrea-sonable rules, we rely on more data (a large set oftriples) and keep high-conﬁdence rules only.
par-ticularly, we follow the suggested conﬁguration ofanyburl.
we run it for 500 seconds to ensure thatall triples can be traversed at least once and obtain251,317 rules, where 168,996 out of them whoseconﬁdence meets λp > 0.1 have been selected asthe rule set to guide dataset construction..3.3 rule-guided dataset construction.
different from existing benchmarks, inferwiki pro-vides inferential testing triples with supportive datain the training set.
moreover, it aims to include asmany inference patterns as possible and these pat-terns are better evenly distributed to avoid biasedevaluation.
thus, this step has four objectives: rule-guided split, path extension, negative supplement,and inference pattern balance.
rule-guided split grounds the mined rules f ontriples t d to obtain premise triples and correspond-ing conclusion triples.
all premise triples form atraining set, and all conclusion triples form a testset.
thus, they are naturally guaranteed to be in-ferential.
for correctness, all of premise triples.
2http://web.informatik.uni-mannheim..1https://www.wikidata.org/.
de/anyburl/.
6857must exist in the given triple set t d, while conclu-sion triples are not necessarily in t d and may begenerated for further annotation (i.e., section 3.4).
for example, given a rule spouse(x, y) ∧ fa-ther(x, z) ⇒ mother(y, z), we traverse all of thegiven triples and ﬁnd entities lebron james, sa-vannah brinson, and bronny james that meetthe premise.
we then add the premise triplesspouse(lebron james, savannah brinson) andfather(lebron james, bronny james) into thetraining set, and generate the conclusion triplemother(savannah brinson, bronny james) for test-ing, no matter it is given or not..path extension aims to increase the inference pathpatterns by (1) adding more reasoning paths for thesame testing triple, and (2) elongating paths byreplacing those premise triples that have reason-ing paths.
for example, we replace father(lebronjames, bronny james) with two triples that caninfer it: father(lebron james, bryce james) andbrother(bronny james, bryce james).
the originalpath is then extended by one hop.
correspondingly,we deﬁne the conﬁdence of extended paths as themultiplication of all involved rules.
longer pathswill challenge long-distance reasoning ability..negative supplement is to generate negativetriples if we cannot annotate the same number ofnegatives with positive triples.
otherwise, we willface an imbalance issue.
following conventions,we randomly corrupt the head or tail entities in apositive triple with the following constraints: (1)the relation of the positive triple is exclusive, e.g.,placeofbirth, if the ratio from head to tail entitiesis smaller than a threshold (we choose 1.2 heuris-tically in experiments); otherwise, the corruptednegative triple may be actually positive, leading tofalse negative errors.
(2) we choose positive triplesfrom the test set for corruption to improve the dif-ﬁculty — the model has to correctly infer the cor-responding positive triple from training data, thenclassify the corrupted triple as negative through theconﬂiction.
particularly, for non-exclusive relationtypes, most of their corrupted results should beunknown following open-world assumption.
theinferred test set covers such cases, which will bediscussed in section 3.4..inference pattern balance aims to balance vari-ous inference patterns, including path length, rela-tion types, and relation patterns (i.e., symmetry, in-version, hierarchy, composition, and others).
thisis because concentrating on some patterns may.
lead to severe bias and unfair comparison betweenkgc models (zhang et al., 2020).
we ﬁrst countthe frequency of testing triples according to thepath lengths, relation types and patterns, respec-tively.
for each of them, we rank their countingand choose highest ranked groups of triples as fre-quent ones, instead of setting a threshold.
we thencarefully remove some frequent triples randomly,until the new distributions reach an accepted range(checked by humans)..3.4.inferred test triple labeling.
different from existing datasets, inferwiki aimsto include positive, negative, and unknown testingtriples, to evaluate the model under two types ofassumptions: open-world assumption and closed-world assumption.
the main difference betweenthem is whether unknown triples are regarded asnegatives.
that is, the open-world evaluation isa three-class classiﬁcation problem (i.e., positive,negative, and unknown).
the closed-world evalua-tion targets only positive and negative triples, andwe can simply relabel unknown triples as negativeswithout changing the test set..so far, we have two test sets: one is generatedvia rule guidance, and the other contains the sup-plemented negatives.
this section aims to labelthe generated triples.
first, we automatically labelthe triples with positive if they exist in wikidata.
then, we manually annotate the remaining 4,053triples.
the annotation guideline can be found inappendix b. note that all of the unknowns are fac-tually incorrect but not inferential.
to assess thequality of annotations, we verify a random selec-tion of 300 test triples (100 for each label).
theannotators agree with our labels 84.3% of the time.
we further investigate the disagreements by relabel-ing 100 samples.
85% of the time, humans preferan unknown, while automatic labeling tends to as-sign them with positive or negative labels.
thissuggests the inferential difference between humansand machines — the capacity of knowing unknown..finally, we remove the entities that are not inany of the grounded paths and their triples.
werandomly select half of the test set as valid.
thisforms inferwiki64k.
we further extract a densesubset inferwiki16k by ﬁltering out the positivetriples whose conﬁdence is smaller than 0.6. corre-spondingly, negative/unknown triples are reducedto keep balance.
the statistics is listed in table 2..6858test (+)traintest (+)train.
japan national route 1q1191191, connectswith, japan national route 4q1055023japan national route 4, terminus, japan national route 1agneseq2726556, sibling, luciaq3838490maddalenaq329555, sibling, agnese ∧ maddalena, mother, beatriceq51089 ∧ valentina, mother, beatrice∧viridisq271827, sibling, valentinaq943180 ∧ viridis, sibling, estorreq3733572 ∧ elisabettaq1941886, sibling,estorre ∧ lucia, sibling, elisabettaquimperq702161, capital, versaillesq621 (⊥ yvelinesq12820, capital, versailles)yvelines, replaces, seine-et-oiseq979470 ∧ seine-et-oise, capital, versaillesrobertoq53003, placeofbirth, batonq28218 (⊥ roberto, placeofbirth, romeq220)renzoq1397252, sibling, roberto ∧ renzo, placeofbirth, rome.
test (-)traintest (-)traintest (unk) mid¯osuji lineq1192413, connectswith, keiy¯o lineq741145train.
shin- ¯osaka stationq801438, connectingline, mid¯osuji line ∧ t¯okaid¯o shinkansenq660895, terminus, shin-¯osaka station ∧ t¯okaid¯o shinkansen, connectswith, keihin-t¯ohoku lineq1197028 ∧ keiy¯o line, connectswith,keihin-t¯ohoku line.
test (unk) maryq104109, worklocation, londonq84train.
mary, memberofpoliticalparty, republican partyq29468 ∧ carlq127437, memberofpoliticalparty, republicanparty ∧ carlq127437 worklocation, london ∧ mary, occupation, actorq33999 ∧ mary, spouse owenq966972.
table 3: positive, negative, and unknown examples of inferwiki, where the triples with brackets are not in trainset (inferred from related training triples), ⊥ denotes contradicted triples and subscripts denote wikidata id..3.5 dataset analysis.
table 3 shows positive, negative, and unknownexamples of inferwiki and their (possible) support-ive training data.
for positives, their paths seemreasonable and vary in length, relation types, andpatterns.
the 7-hop path of the sibling exampleis even difﬁcult for a human.
for negatives andunknowns, they are indeed incorrect and more chal-lenging.
there are no direct contradicted triples inthe train set — the model is encouraged to reasonrelated triples and justify if there is a conﬂiction(i.e., negative) or not (i.e., unknown).
nevertheless,there are two minor issues.
first, some unreason-able paths may corrupt the predictability.
we thusincrease the rule conﬁdence threshold λ > 0.6 forinferwiki16k and manually annotate uncertain testtriples for the correctness of labels.
more advancedrule mining models can improve the constructionpipeline.
we leave it in the future.
second, does un-known triples have a bias on certain relation types?
the answer is yes but not exactly.
as shown intable 3, the relation connectsw ith is involved inboth positive and unknown triples, which is alsodetermined by the paths..next, we analyze the relation patterns and pathlength distribution through comparisons with exist-ing kgc datasets.
due to the different construc-tion pipelines, existing datasets are difﬁcult to offerquantitative statistics.
we thus apply our pipelineon codex (safavi and koutra, 2020).
only in-ferential test triples remain, and the training setkeeps unchanged, namely codex-m-infer, whichreduces the test and valid positives from 20,622.figure 1: distribution of paths in relation patterns..to 7,050. this agree with the original paper thatreports 20.56% triples are symmetry or compo-sitional through amie+ analysis.
we ﬁnd morepaths due to more extensive rules extracted from alarge set of triples.
this also demonstrates the ne-cessity of rule-guided train/test generation — mosttest triples are not guaranteed inferential when us-ing random split.
relation pattern following convention, we countreasoning paths for various patterns: symmetry, in-version, hierarchy, composition, and others, whosedetailed explanations and examples can be foundin appendix c. if a triple has multiple paths, wecount all of them.
as figure 1 shows, we can seethat (1) there are no inversion and only a few sym-metry and hierarchy patterns in codex-m, as mostcurrent datasets remove them to avoid train/testleakage.
but, we argue that learning and remem-bering such patterns are also an essential capacityof inference.
it just needs to control their numbersfor a fair comparison.
(2) the patterns of inferwikiis more evenly distributed.
note that the patterns.
6859inferwiki16k, all of whose testing negatives areveriﬁed by humans.
the second type of errors isdue to unreasonable rules for dataset split, which iscaused by prediction errors of existing rule miningmodels.
however, there is no suitable evaluationin this ﬁeld to provide quantitative analysis.
ourongoing work aims to develop an automatic eval-uation for path rationality to improve the miningquality, and thus facilitate our inferential pipeline..4 benchmarking.
4.1 tasks.
we benchmark performance on inferwiki for thetasks: (1) link prediction, the task of predict-ing the missing head/tail entity for a given querytriple (?, r, t) or (h, r, ?).
models are encouragedto rank correct entities higher than others in thevocabulary.
we adopt the ﬁltering setting (bor-des et al., 2013) that excludes those entities, ifthe predicted triples have been seen in the trainset.
mean reciprocal rank (mrr) and hits@k arestandard metrics for evaluation.
(2) triple clas-siﬁcation aims to predict a label for each giventriple (h, r, t).
the label following open-world as-sumption is trinary y ∈ {−1, 0, 1} and becomesbinary y ∈ {−1, 1} when adopting closed-worldassumption — all 0-label triples are re-labeled with−1, since our unknown triples are factually nega-tive yet non-inferential from training data.
sincekgc models output real-value scores for triples,we classify scores into labels by choosing one ortwo thresholds per relation type on valid.
accuracy,precision, recall, and f1 are measurements..4.2 models.
for comprehensive comparison, we choose threetypes of representative models as baselines: (1)knowledge graph embedding models, includingtranse (bordes et al., 2013), complex (trouil-lon et al., 2016), rotate (sun et al., 2019),conve (dettmers et al., 2018), and tucker (bal-azevic et al., 2019), (2) multihop reasoning modelmultihop (lin et al., 2018), and (3) rule-basedanyburl (meilicke et al., 2019).
note that thelatter two are specially designed for link prediction.
the detailed implementation including parametersand thresholds can be found in appendix f..4.3 triple classiﬁcation results.
table 4 shows micro scores for triple classiﬁca-tion.
we can see that all of the baselines perform.
figure 2: comparison of paths in different lengths..of symmetry, inversion, and hierarchy refer to 1-hop paths, while composition and others refer tomulti-hop paths.
so, the total number of the formerthree is almost the same as that of the latter two, tobalance paths with varying lengths, which will bediscussed next.
path length distribution the reasoning pathscan ensure test triples’ predictability but may notbe the shortest ones, as there may be undiscoveredpaths connecting two entities.
thus, our statisticsconcerning path length offer a conservative anal-ysis and give an upper bound.
for a test triplewith multiple paths, we count the shortest one.
asshown in figure 2, we can see that inferwiki hasmore long-distance paths, while codex-m-infernormally concentrates on maximum 3-hop reason-ing paths.
in speciﬁc, the maximum path lengthof inferwiki is 9 (4 before path extension) and theaverage length is 2.9 (1.5 before path extension).
further analysis of relation, entity and neighbor.
distributions can be found in appendix d&e..3.6 limitation.
although we carefully design the construction of in-ferwiki, there are still two types of limitations: rulebiases and dataset errors, that can to be addressedalong with the development of kg techniques inthe future.
in terms of rule biases, anyburl maybe over-estimated due to its role in the construction.
although we utilize two triple sets to avoid ruleleakage, their overlap may still bring unfair perfor-mance gain to anyburl.
we consider synthesizeseveral rule mining results to improve inferwiki inthe next version.
in terms of dataset errors, ﬁrst, tobalance positive and negative triples in the largerinferwiki64k, we follow conventions to randomlysample a portion of negatives.
these negatives maybe unknown if following open-world assumption.
we manually assess the randomly sampled nega-tives and ﬁnd a 15.7% error rate.
therefore, weconduct open-world experiments on the smaller.
6860complex.
acctranse .823.812rotate .852conve .881tucker .862.inferwiki64krecallprec.895.782.872.779.924.808.906.864.897.817.f1.835.823.862.884.855.acc.796.811.811.897.861.inferwiki16krecallprec.926.736.778.835.891.769.887.911899.836.f1.820.805.825.899.866.codex-m-inferrecallprec.891.792.936.805.945.790.948.853.919.784.acc.763.798.788.851.803.f1.839.866.861.898.846.table 4: overall performance of triple classiﬁcation (closed-world assumption), where acc and prec stand foraccuracy and precision, respectively..complex.
acctranse .711.723rotate .745conve .803tucker .709.prec recall.668.687.709.703.750.746.777.763.657.639.f1.676.701.736.768.618.table 5: performance of triple classiﬁcation on infer-wiki16k (open-world assumption)..nizing unknown triples.
table 5 shows the macroperformance3 on inferwiki16k.
we can see that allof the baseline models perform worse than thoseunder the closed-world assumption.
on one hand,the trinary classiﬁcation is intuitively more difﬁcultthan binary classiﬁcation.
on the other hand, itis a rather straightforward method to search twodecision thresholds — one between positive andunknown and the other between unknown and neg-ative.
this motivates us future works on advancedmodels to represent kg, which should also be ableto detect the limitation and boundaries of givenkg.
it is a fundamental capacity of inference torespond “i do not know”, to avoid false negativesin downstream applications..figure 4 presents a detailed analysis of eachmodel regarding their search thresholds.
we cansee that although their best performance seems notbad, the worst scores are only around 10%.
that is,they are very sensitive to thresholds.
besides, mostof the time, the average f1 scores of complex, ro-tate, and tucker are around 20%, while transeachieves higher scores.
maybe that is the reasonwhy it is still the most widely used kgc method.
conve stably outperforms other baselines, no mat-ter in terms of best, worst, or average performance..4.4 link prediction results.
table 6 shows the average scores for head and tailprediction.
we can see that (1) anyburl performsthe best most of the time, but the performance gapis not signiﬁcant.
this is mainly due to its role in.
3micro performance is only applicable to binary classiﬁca-.
tion, while open-world evaluation is trinary..figure 3: accuracy regarding various negative types,where random neg denotes supplemented negatives,and annotation neg denotes annotated negatives (includ-ing unknowns)..well — around 90% f1 scores.
this is consistentwith recent ﬁndings that triple classiﬁcation is anearly solved task (around 98% f1 scores) (safaviand koutra, 2020).
nevertheless, the lower perfor-mance demonstrates the difﬁculty of our curateddatasets, mainly due to the manually annotated hardnegatives of inferwiki (and codex).
impacts of hard negatives.
figure 3 presents the accuracy on inferwiki16kregarding various types of triples: positive, randomsupplemented negatives, and annotated negatives(including relabeled unknowns).
we can see that(1) random negative triples are indeed trivial forall of baseline models, which motivates the ne-cessity of harder negative triples to push this re-search direction forward, (2) positive triples areslightly difﬁcult to judge than random negatives,and (3) the accuracy signiﬁcantly drops on anno-tation negatives.
this is mainly because most an-notated triples are actually unknown — they arefactually incorrect, but there are no obvious ab-normal patterns.
such non-inferential cases mayunderestimate kgc models.
open-world assumption.
since most baselines fail in judging unknownas negative, we now investigate them followingopen-world assumption to see their ability in recog-.
6861inferwiki64k.
inferwiki16kmrr hit@1 hit@10 mrr hit@1 hit@10 mrr hit@1 hit@10.214.357.377.350.450.465.575.678.677.573.714-.
.363.160.476.369.365.394.
.474.537.629.748.754-.
.366.252.352.450.451-.
.567.430.561.585.603.620.
.842.789.883.868.886.892.
.709.595.735.747.755.783.
.129.218.297.475.466.559.codex-m-infer.
transecomplexrotateconvetuckeranyburl.
table 6: results of link prediction.
bold fonts denote the best scores and underlines highlight the second best..figure 4: macro f1 variance when we search the bestthresholds for open-world triple classiﬁcation..dataset construction, although we utilize two setsof triples to minimize rule leakage.
actually, in-ference of rules may be more important than wethought to improve the reliability and interpretabil-ity of knowledge-driven models.
this also moti-vates us to incorporate rule knowledge into kgctraining for advanced reasoning ability (guo et al.,2018; li et al., 2019b).
(2) kgc models performbetter on inferwiki16k than inferwiki64k, due tothe higher structure density and rule conﬁdence.
(3)models have higher hit@10 and lower hit@1 oninferwiki than other datasets (e.g., codex).
thisagrees with an intuition that most entities are ir-relevant, making it trivial to judge these corruptedtriples as in triple classiﬁcation.
and, only a smallportion of entities is difﬁcult to predict, which re-quires strong inference ability.
besides, hit@1varies a lot, so that we can better compare amongmodels.
impacts of inferential path length.
figure 5 presents hit@1 curves for tail pre-diction regarding varying path length on infer-wiki64k4.
we can see an overall downwards trendalong with the increasing path length.
meanwhile,the large ﬂuctuation may be due to two possiblereasons: (1) as discussed in section 3.5, the inferen-tial paths ensure the predictability, but may not bethe shortest ones.
this thus offers a conservative.
figure 5: hit@1 curves of baseline models for tail pre-diction.
the x-axis denotes the number of hops, andthe bars denote the number of examples that have cor-responding hops.
red solid line is a performance trendline of six models..analysis and give an upper bound of the perfor-mance concerning k-hop paths.
our paths are ofhigh coverage and quality compared with existingdatasets, which either conduct case study or post-process datasets via rule mining.
(2) relation typesand patterns also have signiﬁcant impacts.
shorterpaths contain more long-tail relations, and longerpaths tend to cover many common relations.
thisimproves the difﬁculty of shorter paths and makeslonger paths easier.
impacts of relation patterns.
we present the hit@1 tail prediction on infer-wiki64k regarding relation patterns in table 7. wecan see that symmetry and inversion are not well-solved, which should be considered into evalua-tion but limited in scale.
transe performs worseon symmetry and inversion relations, consistentwith the analysis in abboud et al.
(2020).
evenif complex and rotate can capture such patterns,they fail to rank corresponding entities at the top.
embedding-based models perform well on hierar-chy relations, even outperforms anyburl.
forcompositional relations, it is still quite challengingand worthwhile further investigation..4.5 comparison of codex-infer and codex.
4multihop is designed for tail prediction, and hit@1 on.
inferwiki64k is more distinct for following ablation study..we investigate the impacts of rule-based train/testgeneratation by comparing codex-m-infer with.
6862complex.
transe .000.130rotate .191conve .558tucker .527multihop.231anyburl .782.sym inv.049.279.246.668.612.309.793.hier comp others.479.502.694.855.850.345.782.
.296.414.610.784.753.296.809.
.211.368.477.602.625.240.686.table 7: hit@1 tail prediction on relation patterns..(a) triple classiﬁcation (f1)..(b) link prediction (mrr)..figure 6: comparison of codex-infer and codex..figure 7: distribution of most frequent relation typesin inferwiki64k.
a comparison with inferwiki16k isin appendix d..codex-m. the two datasets share the same train-ing set.
the only difference lies in how we obtainthe test triples, either using our proposed pipeline(codex-m-infer) or randomly (codex-m).
thus,the results reﬂect the impacts of inferential guar-antee for dataset construction and demonstratethe necessity to avoid over-estimation or under-estimation of the inferential ability of kgc models.
we report the performance on codex-m from theoriginal paper (safavi and koutra, 2020)..we can see that all of models perform better withinferential path guarantee on codex-m-infer thancodex-m, except complex for link prediction.
this is because rule guidance elimites those non-inferential testing triples, making the task easier.
nevertheless, the scores on hard cases are actuallydecreased (as discussed in figure 3 and table 7).
models are excepted a stronger reasoning abilityamong several related entities, instead of triviallyﬁltering out massive irrelevant entities.
this alsodemonstrates the necessity of inferwiki to avoidover- or under- estimation of the inferential abilityof kgc models — learning new knowledge fromexisting ones..5 case study of relation types.
we illustrate the most frequent relation typesand their distribution of inferwiki64k and infer-wiki16k in figure 8. we can see that inferwiki hasa diverse relation types that are not limited to spe-ciﬁc domains.
besides, the triples of each relationtype are well balanced..6 conclusion.
we highlighted three principles for kgc datasets:inferential ability, assumptions, and patterns, andcontribute a large-scale dataset inferwiki.
we es-tablished a benchmark with three types of sevenkgc models on two tasks of triple classiﬁcationand link prediction.
the results present a de-tailed analysis regarding various inference patterns,which demonstrates the necessity of an inferentialguarantee for better evaluation and the difﬁculty ofnew open-world triple classiﬁcation..in the future, we are interested in cross-kgs in-ference and transfer (cao et al., 2019a), and inves-tigating how to inject knowledge into deep learn-ing architectures, such as for information extrac-tion (tong et al., 2020) or text generation (caoet al., 2020b)..acknowledgments.
this research was conducted in collaboration withsensetime.
this work is partially supported bya*star through the industry alignment fund -industry collaboration projects grant, by ntu(ntu–ace2020-01) and ministry of education(rg96/20), and by the national research founda-tion, prime minister’s ofﬁce, singapore under itsenergy programme (ep award no.
nrf2017ewt-ep003-023) administrated by the energy marketauthority of singapore.
this work is partially sup-ported by singapore moe acrf t1..6863references.
ralph abboud, ismail ceylan, thomas lukasiewicz,and tommaso salvatori.
2020.boxe: a boxembedding model for knowledge base completion.
neurips..farahnaz akrami, mohammed.
saeef,qingheng zhang, wei hu, and chengkai li.
2020. realistic re-evaluation of knowledge graphincompletion methods: an experimental study.
sigmod..samiul.
ivana balazevic, carl allen, and timothy hospedales.
2019. tucker: tensor factorization for knowledgegraph completion.
in emnlp-ijcnlp..shu guo, quan wang, lihong wang, bin wang, andli guo.
2018. knowledge graph embedding withiterative guidance from soft rules.
in aaai..zikun hu, yixin cao, lifu huang, and tat-seng chua.
2021. how does knowledge graph and attentionhelp?
a qualitative analysis into bag-level relationextraction.
in acl..charles kemp, joshua b tenenbaum, thomas l grif-ﬁths, takeshi yamada, and naonori ueda.
2006.learning systems of concepts with an inﬁnite rela-tional model.
in aaai..stanley kok and pedro domingos.
2007. statistical.
predicate invention.
in icml..antoine bordes, nicolas usunier, alberto garcia-duran,jason weston, and oksana yakhnenko.
2013. translating embeddings for modeling multi-relational data.
neurips..bhushan kotnis and vivi nastase.
2017..analy-sis of the impact of negative sampling on linkarxiv preprintprediction in knowledge graphs.
arxiv:1708.06816..guillaume bouchard, sameer singh, and theo trouil-lon.
2015. on approximate reasoning capabilities oflow-rank vector spaces.
in aaai spring symposia..yixin cao, jun kuang, ming gao, aoying zhou, yong-gang wen, and tat-seng chua.
2020a.
learning re-lation prototype from unlabeled texts for long-tail re-lation extraction.
arxiv preprint arxiv:2011.13574..yixin cao, zhiyuan liu, chengjiang li, juanzi li, andtat-seng chua.
2019a.
multi-channel graph neuralnetwork for entity alignment.
in acl..yixin cao, ruihao shui, liangming pan, min-yen kan,zhiyuan liu, and tat-seng chua.
2020b.
expertisestyle transfer: a new task towards better communi-cation between experts and laymen.
in acl..yixin cao, xiang wang, xiangnan he, zikun hu, andtat-seng chua.
2019b.
unifying knowledge graphlearning and recommendation: towards a better un-derstanding of user preferences.
in the world wideweb conference..rajarshi das, shehzaad dhuliawala, manzil zaheer,ishan durugkar, akshay krishna-luke vilnis,murthy, alex smola, and andrew mccallum.
2017.go for a walk and arrive at the answer: reasoningover paths in knowledge bases using reinforcementlearning.
arxiv preprint arxiv:1711.05851..tim dettmers, pasquale minervini, pontus stenetorp,convolutional 2d.
and sebastian riedel.
2018.knowledge graph embeddings.
in aaai..luis gal´arraga, christina teﬂioudi, katja hose, andfabian m suchanek.
2015. fast rule mining in onto-logical knowledge bases with amie+.
vldb..chengjiang li, yixin cao, lei hou, jiaxin shi, juanzili, and tat-seng chua.
2019a.
semi-supervisedentity alignment via joint knowledge embeddingmodel and cross-graph model.
in emnlp-ijcnlp..tao li, vivek gupta, maitrey mehta, and vivek sriku-mar.
2019b.
a logic-driven framework for consis-tency of neural models.
in emnlp-ijcnlp..xi victoria lin, richard socher, and caiming xiong.
2018. multi-hop knowledge graph reasoning withreward shaping.
in emnlp..yankai lin, zhiyuan liu, and maosong sun.
2016.knowledge representation learning with entities, at-tributes and relations.
in ijcai..yankai lin, zhiyuan liu, maosong sun, yang liu, andxuan zhu.
2015. learning entity and relation em-beddings for knowledge graph completion.
in aaai..christian meilicke, melisachew wudage chekol,daniel rufﬁnelli, and heiner stuckenschmidt.
2019.anytime bottom-up rule learning for knowledgegraph completion.
in ijcai..maximilian nickel, lorenzo rosasco, and tomasopoggio.
2016. holographic embeddings of knowl-edge graphs.
in aaai..sebastian riedel, limin yao, and andrew mccallum.
2010. modeling relations and their mentions with-out labeled text.
in ecml pkdd..tara safavi and danai koutra.
2020. codex: a com-prehensive knowledge graph completion benchmark.
arxiv preprint arxiv:2009.07810..baoxu shi and tim weninger.
2018. open-world.
knowledge graph completion.
in aaai..alberto garcia-duran, antoine bordes, and nicolasusunier.
2015. composing relationships with trans-lations.
in emnlp..richard socher, danqi chen, christopher d manning,and andrew ng.
2013. reasoning with neural tensornetworks for knowledge base completion.
neurips..6864zhiqing sun, zhi-hong deng, jian-yun nie, and jiantang.
2019. rotate: knowledge graph embeddingby relational rotation in complex space.
in iclr..meihan tong, bin xu, shuai wang, yixin cao, leihou, juanzi li, and jun xie.
2020. improving eventindetection via open-domain trigger knowledge.
acl..kristina toutanova and danqi chen.
2015. observedversus latent features for knowledge base and textinference.
acl cvsc workshop..th´eo trouillon, johannes welbl, sebastian riedel, ´ericgaussier, and guillaume bouchard.
2016. complexin icml,embeddings for simple link prediction.
pages 2071–2080..quan wang, bin wang, and li guo.
2015. knowledgebase completion using embeddings and rules.
in ij-cai..rui wang, bicheng li, shengwei hu, wenqian du, andmin zhang.
2019. knowledge graph embedding viagraph attenuated attention networks.
ieee access..zhen wang, jianwen zhang, jianlin feng, and zhengchen.
2014. knowledge graph embedding by trans-lating on hyperplanes.
in aaai..ruobing xie, zhiyuan liu, and maosong sun.
2016.representation learning of knowledge graphs withhierarchical types.
in ijcai..wenhan xiong, thien hoang, and william yang wang.
2017. deeppath: a reinforcement learning methodfor knowledge graph reasoning.
in emnlp..bishan yang, wen-tau yih, xiaodong he, jianfenggao, and li deng.
2014. embedding entities andrelations for learning and inference in knowledgebases.
arxiv preprint arxiv:1412.6575..chuxu zhang, huaxiu yao, chao huang, meng jiang,zhenhui li, and nitesh v chawla.
2020. few-shotknowledge graph completion.
in aaai..6865a literature review.
table 8 lists existing kgc datasets.
we can roughlyclassify them into two groups: inferential and non-inferential datasets.
the ﬁrst group are usuallymanually curated to ensure each testing samplecan be inferred from training data through reason-ing paths.
families (garcia-duran et al., 2015)test family relationships including cousin, ances-tor, marriage, parent, sibling, and uncle, amongthe members of 5 families along 6 generations.
such that there are obvious compositional relation-ships like uncle ≈ sibling + parent or parent ≈married + parent.
kinship (kemp et al., 2006)contains kinship relationships among members ofthe alyawarra tribe from central australia, whilecountry (bouchard et al., 2015) contains coun-tries, regions, and subregions as entities and iscarefully designed to explicitly test the locationrelationship (i.e., locatedin and neighbor) amongthem.
the above datasets are clearly limited inscale and inference patterns, thus become not chal-lenging.
hole (nickel et al., 2016) even achieves99.7% acu-pr on dataset country (bouchardet al., 2015)..the second group of datasets are automaticallyderived from public kgs and randomly split pos-itive triples into train/valid/test, leading to a riskof testing samples non-inferential from trainingdata.
fb13 (socher et al., 2013) and fb15k (bor-des et al., 2013) are commonly used benchmarkfrom freebase.
fb15k401 (yang et al., 2014) isa subset of fb15k containing only frequent rela-tions (relations with at least 100 training examples).
to remove test leakage, fb15k-237 (toutanovaand chen, 2015) removes all equivalent or inverserelations.
similarly, fb5m (wang et al., 2014)removes all the entity pairs that appear in thetesting set.
wn18rr (dettmers et al., 2018) isthe challenging version of wn18 (bordes et al.,2013) extracted from wordnet.
textual informa-tion is also included for speciﬁc task, such asfb40k (lin et al., 2015) targeting relation ex-traction dataset new york times (riedel et al.,2010).
fb24k (lin et al., 2016) introduce at-tributes.
fb15k+ (xie et al., 2016) introduce typesand make fb15k more sparse by only ﬁlterring outrelation with a frequency lower than one.
anotherpopular knowledge source is yago, and the cor-responding datasets include yago3-10 (dettmerset al., 2018) and yago37 (guo et al., 2018).
ex-cept for open-domain kg, nell (wang et al.,.
2015) concentrates on location and sports, andumls (kok and domingos, 2007) targets med-ical knowledge.
codex (safavi and koutra, 2020)argues the quality of the above benchmarks, suchas nell995 (xiong et al., 2017) are nonsensical oroverly generic.
thus they propose a comprehensivedataset consisting of three knowledge graphs vary-ing in size and structure, entity types, multilinguallabels and descriptions, and hard negatives..b annotation guideline.
we provide the following annotation guidelines forannotators to label inferred triples in section 3.4..task this is a two-step annotations.
first,you must annotate each triple with the label y ∈{1, −1}, where 1 denotes that the triple is correctand −1 denotes that the triple is incorrect.
you canﬁnd the answer from anywhere you want, such ascommonsense, wikipedia, and professional web-sites.
if you cannot ﬁnd any evidence to supportthe statement, you shall choose label −1.
second,you must annotate each incorrect triple with thelabel ˆy ∈ {0, −1}, where 0 denotes that you do notknow the answer.
now, you can ﬁnd the answerfrom our provided triples.
if you cannot ﬁnd anyevidence to support the statement, you shall chooselabel 0..examples here are some examples judged using.
three types of knowledge sources..• commonsense:.
(cypriot fourth division,haspart, 2018–19 cypriot third division) isclearly incorrect, since the fourth division can-not has a part of third division..2019,.
(bahrain-merida.
• professional websites: to annotate thetriplehaspart,carlos betancur), you may search theperson in professional websites, such ashttps://www.procyclingstats.com/team/bahrain-merida-2019.
since thereis no carlos betancur listed in that website,please choose false..• wikipedia: given the triples (t¯okaid¯oshinkansen, connectswith, osaka higashiand (t¯okaid¯o shinkansen,line)con-nectswith, san’y¯o main line), you can ﬁndrelated station information from the pageof t¯okaid¯o shinkansen.
you can ﬁnd thatosaka higashi line shares a transfer stationwith t¯okaid¯o shinkansen, thus label it with 1..datasetsfb13 (socher et al., 2013)fb15k (bordes et al., 2013)fb15k237 (toutanova and chen, 2015)fb15k+ (xie et al., 2016)fb15k401 (yang et al., 2014)fb24k (lin et al., 2016)fb40k (lin et al., 2015)fb5m (wang et al., 2014)wn11 (socher et al., 2013)wn18 (bordes et al., 2013)wn18rr (dettmers et al., 2018)yago3-10 (dettmers et al., 2018)yago37 (guo et al., 2018)codex (safavi and koutra, 2020)nell995 (xiong et al., 2017)nellloc (wang et al., 2015)family (garcia-duran et al., 2015)kinship (kemp et al., 2006)countries (bouchard et al., 2015)umls (kok and domingos, 2007).
sourcefreebasefreebasefreebasefreebasefreebasefreebasefreebasefreebasewordnetwordnetwordnetyagoyagowikidatanellnellartiﬁcialartiﬁcialartiﬁcialumls.
#entity75,04314,95114,54114,95114,54123,63439,5285,385,32238,69640,94340,943123,182123,18977,95175,492672721104272135.
#relation131,3452371,8554019871,3361,19211181137376920010726249.
#triples (train/valid/test)316,232/5,908/23,733483,142/50,000/59,071272,115/17,535/20,466486,446/50,000/62,374560,209/-/-402,493/-/21,067370,648/67,946/96,67819,193,556/50,000/59,071112,581/2,609/10,544141,442/5,000/5,00086,835/3,034/3,1341,079,040/5,000/5,000989,132/50,000/50,000551,193/30,622/30,622154,213/-/-941/-/-8,461/2,820/2,8218,548/2,820/2,8211,111/24/245,216/-/-.
table 8: an overview of knowledge graph completion datasets..hop8, and anyburl9.
because we utilize varioustypes of kgc models including embedding-based,multi-hop reasoning (reinforcement learning), andrule-based models, these models largely have theirown hyperparameters.
to avoid exhaustive param-eter search in a large range, we conduct a seriesof preliminary experiments and ﬁnd that the sug-gested parameters work well on wikidata-baseddata.
we then search the embedding size in therange of {256, 512}, number of negative samplesin the range of {15, 25} and margin in the rangeof {4, 8}.
the optimal parameters of each modelon all of three datasets are listed in table 10. thethresholds in triples classiﬁcation are listed in ta-ble 11.and, san’y¯o main line doesn’t show up inthe page, you may label it with −1..c relation patterns.
inferwiki is able to analyze relation patterns foreach path, including symmetry, inversion, hierar-chy, and composition, where detailed explanationsand examples are listed in table 9..d relation types.
we illustrate the most frequent relation typesand their distribution of inferwiki64k and infer-wiki16k in figure 8..e comparison with existing datasets.
figure 9 shows the distribution of entities and theirneighbors as compared to widely used datasets:fb15k237 and codex-m..f experiment setup.
our experiments are run on the server with thefollowing conﬁgurations: os of ubuntu 16.04.6lts, cpu of intel(r) xeon(r) cpu e5-2680 v4 @2.40ghz, and gpu of geforce rtx 2080 ti.
weuse openke5 for re-implementing transe, com-plex, and rotate.
for the rest models, we usethe original codes for conve6, tucker 7, multi-.
5https://github.com/thunlp/openke6https://github.com/timdettmers/conve7https://github.com/ibalazevic/tucker.
multihopkg.
de/anyburl/.
8https://github.com/salesforce/.
9http://web.informatik.uni-mannheim..patternsymmetry.
notationr1(x, y) ⇒ r1(y, x).
inversion.
r1(x, y) ⇔ r2(y, x).
hierarchy.
r1(x, y) ⇒ r2(y, x).
composition.
r1(x, y) ∧ · · · ∧ rp(y, z) ⇒rp+1(x, z).
example(prince christopherq44775, partner, friederikeq93614) ⇒ (friederike, partner,prince christopher)(amravati districtq1771774, capital, amravatiq269899) ⇒ (amravati, capitalof,amravati district)(supermanq79015, derivativework, superman returnsq328695) ⇒ (superman,presentinwork, superman returns)(eleanorq156045, mother, joannaq171136) ∧ (ferdinand iq150611, mother,joanna) ∧ (isabellaq157884, sibling, ferdinand i) ⇒ (eleanor, sibling, isabella).
table 9: explanations and examples for various relation patterns..hyperparameter.
transe complex rotate conve.
tucker multihop.
embedding size# negativesmarginlearning rateoptimizerbatch size.
embedding size# negativesmarginlearning rateoptimizerbatch size.
embedding size# negativesmarginlearning rateoptimizerbatch size.
2561541.0sgd1,625.
2561541.0sgd7,823.
5122581.0sgd1,856.
5122540.5adagrad1,625.inferwiki16k5122582e-5adam2,000inferwiki64k5122582e-5adam2,000codex-m-infer2562540.5adagrad1,856.
5121540.5adagrad7,823.
5122542e-5adam2000.
512--1e-4adam256.
256--1e-4adam256.
256--1e-4adam256.
512--1e-4adam256.
512--1e-4adam256.
512--1e-4adam256.table 10: best hyperparameter conﬁgurations..256--1e-3-128.
256--1e-3-128.
256--1e-3-128.inferwiki.
64k.
16k.
16k.
transe[-24.4663, -9.0235]-16.7449[-24.0588, -4.333]-13.4069[-24.0588, -4.333]-16.1685, -11.8288.complex[-43.0342, 30.6942]-0.2717[-21.5906, 24.7742]2.5191[-21.5906, 24.7742]-3.5084, 3.4464.rotate[-15.7235, 7.8291]-0.6498[-21.2362, 7.8282]-0.6005[-21.2362, 7.8282]-2.3444, 0.8527.conve[0.0, 0.9999]0.1[0.0, 1.0]0.19[0.0, 1.0]0.01, 0.37.tucker[0.0, 0.9982]0.01[0.0, 0.9734]0.0097[0.0, 0.9734]0.0097, 0.0389.closedworld.
openworld.
table 11: best thresholds in triple classiﬁcation, where the upper side is the search range and the lower side is thebest values.
they are searched on validation..(a) inferwiki64k..(b) inferwiki16k..figure 8: distribution of most frequent relation types..(a) distribution of entities, where x-axis denotes different ranges regarding entity frequency in the train set..(b) distribution of entity neighbors, where x-axis denotes ranges regarding average number of neighbors in the train set..figure 9: distribution of entities and their neighbors..