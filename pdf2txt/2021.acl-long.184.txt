distributed representations of emotion categories in emotion space.
xiangyu wang1,2 and chengqing zong1,2,3∗1national laboratory of pattern recognition, institute of automation, cas2school of artiﬁcial intelligence, university of chinese academy of sciences3cas center for excellence in brain science and intelligence technology{xiangyu.wang, cqzong}@nlpr.ia.ac.cn.
abstract.
emotion category is usually divided into dif-ferent ones by human beings, but it is in-deed difﬁcult to clearly distinguish and deﬁnethe boundaries between different emotion cat-egories.
the existing studies working on emo-tion detection usually focus on how to improvethe performance of model prediction, in whichemotions are represented with one-hot vectors.
however, emotion relations are ignored in one-hot representations.
in this article, we ﬁrstpropose a general framework to learn the dis-tributed representations for emotion categoriesin emotion space from a given emotion classiﬁ-cation dataset.
furthermore, based on the softlabels predicted by the pre-trained neural net-work model, we derive a simple and effectivealgorithm.
experiments have validated thatthe proposed representations in emotion spacecan express emotion relations much better thanword vectors in semantic space..1.introduction.
in the past decades, a lot of tasks have been pro-posed in the ﬁeld of text emotion analysis.
themost primary one among them is emotion classiﬁca-tion task (alm et al., 2005).
based on emotion clas-siﬁcation task, many new tasks have been proposedfrom different considerations.
lee et al.
(2010) pro-posed the task of emotion cause extraction, whichaims at predicting the reason of a given emotionin a document.
based on the emotion cause ex-traction task, xia and ding (2019) introduced theemotion-cause pair extraction task for the purposeof extracting the potential pairs of emotions andcorresponding causes in a document.
jiang et al.
(2011) proposed a target-dependent emotion recog-nition task, which aims at predicting the sentimentwith the given query.
to express the intensity of.
∗ corresponding author..a speciﬁc emotion in text, mohammad and bravo-marquez (2017) proposed the emotion intensitydetection task.
however, all the above tasks treatemotions as independent ones and represent emo-tions with one-hot vectors, which deﬁnitely ignorethe underlying emotion relations..based on existing emotion detection tasks, manyefforts have been made to achieve better perfor-mance (danisman and alpkocak, 2008; xia et al.,2011; kim, 2014; xia et al., 2015; li et al., 2018;zong et al., 2019) and many datasets have beenintroduced to train and evaluate the correspond-ing models (ghazi et al., 2015; mohammad et al.,2018; liu et al., 2019).
the vast majority of ex-isting emotion annotation work assumes that theemotions are orthogonal to each other and repre-sent the emotion categories with one-hot vectors(mohammad, 2012; gui et al., 2016; klinger et al.,2018).
actually, the boundaries as well as the re-lations among emotion categories are not clearlydistinguished and deﬁned..typical word embedding learning algorithmsonly use the contexts but ignore the sentiment oftexts (turian et al., 2010; mikolov et al., 2013).
toencode emotional information into word embed-ding, sentiment embedding and emotion(al) em-bedding have been proposed (tang et al., 2014; yuet al., 2017; xu et al., 2018).
tang et al.
(2015)proposed a learning algorithm dubbed sentiment-speciﬁc word embedding (sswe).
agrawal et al.
(2018) proposed a method to learn emotion-enriched word embedding (ewe).
however, allthe above algorithms represent emotions in seman-tic space rather than emotion space.
as shownin table 1, each emotion category represented insemantic space reﬂect a piece of semantic infor-mation rather than a speciﬁc emotional state.
inthis work, we regard each emotion category as aspeciﬁc emotional state in emotion space and repre-sent each emotion category with a point in emotion.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2364–2375august1–6,2021.©2021associationforcomputationallinguistics2364semantic spaceeach word corresponds to a point in semantic space.
words cannot be represented in emotion space.
each emotional state corresponds to a point inemotional states cannot be represented in semanticemotion space.
space.
each emotion category is encoded with a spe-each emotion category is encoded with a piece ofciﬁc emotional state.
speciﬁc semantic information..emotion space.
table 1: differences between semantic space and emotion space..space.
the further experiments show that our rep-resentations in emotion space can express emotionrelations much better than word vectors in semanticspace..from the perspective of psychology, some stud-ies have discussed the complexity of the humanemotional state (russell, 1980; grifﬁths, 2002;fontaine et al., 2007; clark, 2010) and the sharedpsychological features across emotions (fehr andrussell, 1984; mauss and robinson, 2009; camposet al., 2013).
however, psychological researchesmainly focus on the human emotional state itselfand do not pay attention to emotion relations hid-den in the text.
as there are lots of emotion detec-tion tasks and corresponding datasets in nlp ﬁeld,it is very meaningful to investigate what is the rela-tions among emotion categories hidden in corpora.
in this paper, we detect the underlying relationsamong emotion categories labeled in corpora fromthe perspective of nlp..distributed representations of emotion cate-gories in emotion space can also beneﬁt nlp appli-cations.
take depression recognition for example,depression is a serious mood disorder and mani-fested by a complex emotional state (blatt, 2004;beck et al., 2014).
most existing emotion tax-onomies or datasets do not contain depression asa speciﬁc category.
in this article, we generate thelatent encoding for each emotion category.
basedon the psychological researches (rottenberg, 2005;joormann and stanton, 2016) on relations betweendepression and existing emotion categories, we canpredict the distributed representations of depressionin the text even if there are no samples annotatedas depression..the main contributions of this work are summa-.
rized as follows:.
• a general framework to learn distributed emo-tion representations from an emotion classiﬁ-cation dataset is ﬁrst proposed.
based on softlabels predicted by the pre-trained neural net-work model, a simple and effective approach.
is derived.
as far as we know, this is the ﬁrstwork to learn the distributed representationsfor emotion categories in emotion space ratherthan semantic space..• experiments have been conducted to validatethe effectiveness of our emotion representa-tions.
the results have shown that our emotionrepresentations in emotion space can expressemotion relations much better than word vec-tors, and is competitive with human results..• emotion similarities across datasets have beendetected to validate the quality of our emo-tion representations across corpora.
the re-sults have shown the good consistency of ourrepresentations in emotion similarities acrossdatasets although they are created for a varietyof domains and applications..2 related work.
emotion taxonomy: the existing studies onemotion taxonomy usually divide emotion spaceinto speciﬁc emotion categories.
ekman (1992)classiﬁed emotions into six discrete states (anger,disgust, fear, joy, sadness and surprise), which arecontained in vast majority of the existing emotionclassiﬁcation datasets.
with the discrete emotionquestionnaire method, harmon-jones et al.
(2016)captured eight distinct state emotions in their study:anger, disgust, fear, anxiety, sadness, happiness,relaxation, and desire.
similarly, cowen and kelt-ner (2017) introduced a conceptual framework toanalyze reported emotional states and elicited 27distinct varieties of reported emotional experience.
however, above work only gives the basic emotionsof human emotional state from a psychological per-spective.
the quantitative relations among basicemotions remain to be detected.
in this work, emo-tion relations are quantitatively revealed based onour emotion representations..2365emotion datasets: strapparava and mihalcea(2007) introduced ﬁrst emotion recognition dataset,affective text, in the domain of news headlines.
after that, many emotion datasets that vary indomain, size and taxonomy have been devel-oped.
wang et al.
(2012) automatically createda large emotion-labeled dataset (of about 2.5 mil-lion tweets) by harnessing emotion-related hash-tags available in the tweets.
abdul-mageed and un-gar (2017) introduced a ﬁne-grained dataset withup to 24 types of emotion categories with twitterdata.
li et al.
(2017) developed a multi-turn dialogdataset, dailydialog, for detecting the emotions inthe ﬁeld of dialog systems.
¨ohman et al.
(2018) pre-sented a multi-dimensional emotion dataset withannotations in movie subtitles for the purpose ofcreating a robust multilingual emotion detectiontool.
demszky et al.
(2020) built a manually datasetwith up to 27 ﬁne-grained emotion categories onreddit comments for emotion prediction.
however,all above datasets are annotated with discrete basicemotion categories, which means the emotion cate-gories are represented with one-hot vectors.
one-hot representations ignore the underlying relationsamong emotion categories.
in this work, the under-lying emotion relations contained in the datasetsare revealed with our emotion representations..soft labels: hinton et al.
(2015) observed thatit is easier to train classiﬁer using the soft targetsoutput by trained classiﬁer as target values than us-ing manual ground-truth labels.
phuong and lam-pert (2019) provided their insights into the workingmechanisms of distillation by studying the specialcase of linear and deep linear classiﬁers.
szegedyet al.
(2016) proposed a label smoothing mecha-nism for the purpose of encouraging the model tobe less conﬁdent by smoothing the initial one-hotlabels.
imani and white (2018) investigated thereasons for the improvement of the model perfor-mance by converting hard targets to soft labels insupervised learning.
zhao et al.
(2020) proposed arobust training method for machine reading com-prehension by learning soft labels.
in this work,soft labels output by the trained neural networkmodel are used to generate distributed representa-tions for emotion categories..3 methodology.
in this section, we describe how to learn the dis-tributed representations for emotion categories.
first, a general framework is proposed.
then, a.simple and effective algorithm is derived based onthe soft labels from a pre-trained neural networkmodel.
after that, we extend our method to multi-label datasets.
at last, detailed approaches of thealgorithm are listed..3.1 the general framework.
as shown in table 2, the four instances fromdataset semeval-2007 task 14 (strapparava andmihalcea, 2007) are annotated with both emotioncategories and valence values.
although both in-stance 1 and instance 2 are labeled with joy cate-gory, their valence values are very different, whichmeans there is a big difference between their emo-tional states.
actually, emotions in instance 1 seemto be more excited while emotions in instance 2seem to be more hopeful.
on the other hand, in-stances 3 and 4 are annotated with the same va-lence value while they are divided into differentcategories.
fontaine et al.
(2007) also ﬁnd thatemotional state is high-dimensional and valence-arousal-dominance representation model is not suf-ﬁcient to describe the emotional state..the above examples show emotional states con-tained in different documents, even if they are an-notated with the same emotion category or valencevalue, are not exactly the same.
in this work, weregard text emotional states as an emotion space.
the emotion contained in a speciﬁc document cor-responds to a speciﬁc emotional state, further cor-responds to a point in the space.
as a result, docu-ments annotated with same emotion category prob-ably correspond to different emotional states andpoints in the space, which means the emotion cat-egory is a random variable rather than a speciﬁcvector in the space..for category k, we deﬁne x as the sample anno-tated with category k and v k as the speciﬁc dis-tributed representations of category k. let v(x)be the distributed representations of sample x andp(x) be the probability density of sample x. letω be the integral domain of x. we further usel(v k, v(x)) as the distance function betweenv k and v(x).
in order to obtain a better dis-tributed representation for category k, we mustminimize the expectation of l. thus, we obtainthe calculation formula for speciﬁc distributed rep-resentation of category k as the following:.
v k = arg min.
l(v , v(x))p(x)dx..(1).
(cid:90).
v.ω.
2366index1234.instancesgoal delight for shevamaking peace from victory over povertynew indonesia calamity, a mud bath, is man-madewaste plant ﬁre forces 5,000 to evacuate.
emotion valencejoyjoyangersadness.
8739-59-59.table 2: four instances in dataset affectivetext..3.2 a simple method.
although we can not directly obtain the strict prob-ability distribution of each emotion category inemotion space, there are many available emotionclassiﬁcation dataset, in which the instances can beregarded as samples of the corresponding annotatedemotion categories..for emotion dataset d and emotion category k,we use all samples annotated as category k in thedataset to estimate the distribution of category k.thus, we can rewrite formula 1 as:.
v k = arg min.
l(v , v(x)),.
(2).
(cid:88).
x∈sk.
v.where sk is the set of all instances labeled withcategory k in dataset d..in this paper, we use squared euclidean distanceas the distance metric between two representations.
therefore, formula 2 can be simpliﬁed as follows:.
v k = arg min.
v.(cid:88).
x∈sk.
||v − v(x)||22..(3).
by solving formula 3, we have:.
v k =.
(cid:80).
v(x).
,.
x∈sknk.
(4).
where nk is the size of sk..since then we have derived that the distributedrepresentation of emotion category k is exactlythe average of the distributed representation of allinstances labeled as category k in dataset d..now, let’s discuss how to obtain the distributedrepresentation for the instances in the dataset.
asshown in figure 1, the output of the neural networkmodel is a soft label regardless of the speciﬁc ar-chitecture of the model.
it has been veriﬁed thatsoft labels output by the trained model tend to havehigher entropy and contain more information thanmanual one-hot labels (hinton et al., 2015; phuongand lampert, 2019).
inspired by previous work onsoft labels, we directly take the soft labels output bythe trained neural network model as the distributed.
figure 1: schematic diagram of emotion classiﬁcationmodels based on word vectors..representation of the input instance.
as a result,the dimension of v k is equal to the number ofcategories annotated in dataset d..we deﬁne soft labels output by the trained neuralnetwork model of the input instance x as f (x).
thus, we derive a simple method to calculate thespeciﬁc distributed representation for category k:.
v k =.
(cid:80).
f (x).
..x∈sknk.
(5).
3.3 how to deal with multilabel data?.
in some corpora, instances are annotated with mul-tiple emotion categories (strapparava and mihalcea,2007; demszky et al., 2020).
to deal with multil-abel instances, we regard each multilabel instanceas multiple single label instances with weights sum-ming to 1, and the weight of each single label datais set to the reciprocal of the number of the anno-tated labels.
for example, suppose document d islabeled with category a and b. we regard d astwo half instances, one half is labeled with categorya and the other half is labeled with category b..let y(x) denote the set of the annotated labelsof sample x and |y(x)| denote the size of set y(x).
take above document d as an example, then y(d)is equal to {a, b} and |y(d)| is equal to 2 as.
2367positive(p):.
negative(n):.
ambiguous(a):.
admiration, amusement, approval, caring, desire, excitement, gratitude,joy, love, optimism, pride, reliefanger, annoyance, disappointment, disapproval, disgust, embarrassment,fear, grief, nervousness, remorse, sadnessconfusion, curiosity, realization, surprise.
table 3: artiﬁcial classiﬁcation results of 27 emotion categories by the creators of goemotions..there are two labels contained in y(d).
there-fore, we obtain the calculation formula of speciﬁcdistributed representation for category k:.
v k =.
(cid:80).
x∈sk(cid:80).
x∈sk.
wk(x)f (x)wk(x).
,.
(6).
where wk(x) is equal to 1/|y(x)|, which is theweight of instance x in category k,.
3.4 algorithm.
in this part, we describe the algorithm of learn-ing the distributed representations for emotioncategories (drec).
first, go through every in-stance in the dataset, and calculate the total weightand weighted sum of soft labels output by thetrained model for each category.
theweighted sum is divided by the total weight to ob-tain the ﬁnal distributed representation for eachemotion category.
the detailed approaches arestated in algorithm 1..then,.
algorithm 1 drecinput: d = {(t (n), y (n))noutput: v = {v 1, v 2, ..., v c}.
n=1}.
// dataset.
for each j ∈ y (n) do.
// distributed representations for emotions01: f ← d // train a neural network model02: v ← {0, 0, ..., 0}03: {w1, w2, ..., wc} ← {0, 0, ..., 0} // weight04: for n = 1 to n do05:06:07:08:09:10: end for11: for i = 1 to c dov i ← v i/wi12:13: end for.
sl ← f (t (n)) // soft labelsv j ← v j + sl/|y (n)|wj ← wj + 1/|y (n)|.
end for.
4 experiments.
in order to validate the intrinsic quality of our emo-tion representations, we conducted three experi-.
ments in this section.
first of all, arrangementexperiment is conducted to show the emotion distri-bution.
then, relations between different emotiontaxonomies are detected in mapping experiment.
at last, the emotion representations extracted fromvarious corpora are compared to show the consis-tency of our approach across corpora..4.1 datasets.
there are four datasets we use to detect emotionrelations.
the detailed information of each datasetis described as follows:.
goemotions: goemotions is annotated of 58kenglish reddit comments extracted from popularenglish subreddits (demszky et al., 2020), multi-labeled for 27 emotion categories, which is pro-posed by cowen and keltner (2017).
goemotionsis created for the purpose of building a large datasetwith a large number of positive, negative, and am-biguous emotion categories.
the detailed emotioncategories are shown in table 3..affectivetext: affectivetext consists of 1250instances on the domain of news headlines (strap-parava and mihalcea, 2007).
the dataset is multi-label annotated.
there are six emotion categories(anger, disgust, fear, joy, sadness and surprise) andvalence contained in the dataset..isear: isear is created from questionnairesby scherer and wallbott (1994).
each instance isannotated with only one label.
there are sevenemotion categories contained in isear: anger, dis-gust, fear, guilt, joy, sadness, and shame..affect in tweets: “affect in tweets” is cre-ated from tweets (mohammad et al., 2018).
thereare ten emotions contained in “affect in tweets”:anger, anticipation, disgust, fear, joy, love, opti-mism, pessimism, sadness, surprise, and trust..goemotions is used to conduct the ﬁrst two ex-periments (arrangement and mapping), and theabove four datasets are used to validate our repre-sentations across corpora in last experiment..23684.2 model settings.
any model that outputs are soft labels can be em-ployed to learn the distributed representations foremotion categories.
in our experiments, textcnn(kim, 2014), bilstm (schuster and paliwal, 1997)and bert (devlin et al., 2019) are used as thetraining models.
for comparison, experiments onword embedding learning algorithms are conductedto show emotion relations in semantic space.
fora speciﬁc emotion category, we use its word em-bedding as its representations in semantic space.
100-dimensional glove (pennington et al., 2014)is the word vectors used in textcnn and bilstm.
the detailed model settings are listed as follows:.
textcnn: the height of convolutional kernelsize is divided into three groups (3,4,5) and thewidth is 100, which is equal to the dimension ofthe word vectors.
there are 32 channels in eachgroup.
batch size and learning rate are set to 16and 0.001..bilstm: there is only one layer in this model.
batch size and learning rate are set to 16 and 0.001separately, which are the same as for textcnn.
there are 32 neurons in the hidden layer in eachdirection..bert: bert-based model is used in this exper-iment.
a fully connected layer is added on top ofthe pre-trained model.
batch size and learning rateare separately set to 8 and 2e-5 for ﬁne-tuning..4.3 arrangement.
as shown in table 3, the emotion categories aredivided into three groups corresponding to the pos-itive, negative, and ambiguous emotions, which aredivided by the creators of goemotions1 (demszkyet al., 2020)..we conduct the experiments 10 times with samemodel and different initial parameters, and the av-erage representations are employed to show the fol-lowing results.
after ﬁnal emotion representationsobtained, to better understand the arrangement ofemotion categories in emotion space, we reducethe dimension of the emotion representations totwo with singular value decomposition (wall et al.,2003).
the two-dimensional average vectors aredisplayed as shown in figure 2. three color-shapepairs, red-circle, gray-square and black-triangle,correspond to positive, negative and ambiguousemotions respectively.
figure 2 (a)-(c) correspond.
to the results of word representations in seman-tic space.
figure 2 (d)-(f) show the results oftextcnn, bilstm and bert in emotion space.
as shown in figure 2 (a)-(c), the results of threeword embedding algorithms (glove, sswe andewe) are displayed.
we can ﬁnd that the wordvectors of emotion terms are displayed relativelyrandom in semantic space and there are no clearlinear boundaries among positive, negative and am-biguous emotions..as shown in figure 2 (d)-(f), it can be foundthat in emotion space, regardless of the constructedmodel, there are obvious boundaries among posi-tive, negative and ambiguous emotions.
the twoblue dashed lines separate each type of emotion cat-egory from the others, which means that differenttypes of emotion categories are linearly separablefrom each other in emotion space.
the ambigu-ous emotions are just located between positive andnegative emotions in figure 2 (d)-(f), which showsour representations in emotion space can betterdescribe the relative relation between ambiguousemotions and the others.
in addition, the arrange-ment of emotions in figure 2 (d) and (e) are verysimilar, which means textcnn and bilstm havesimilar emotion relation extraction capabilities..from this experiment, we can conclude that sim-ilar emotions are more likely to get together in emo-tion space than in semantic space, which furtherdemonstrates that our representations can expressemotion relations much better than word vectors..4.4 mapping.
demszky et al.
(2020) manually mapped these 27emotion categories to ekman’s basic emotions (ek-man, 1992).2 in this experiment, we automaticallygenerate these mapping relations based on the pro-posed distribution representations of emotion cate-gories..in this experiment, we take ekman’s basic emo-tions as target emotions and the remaining 21 cat-egories as source emotions.
for each source emo-tion, we select the most similar one from the targetemotions as its mapping result.
the calculationformula is listed as follows:.
e = arg max.
sim(es, et),.
(7).
et.
where et is the emotion category in target emotions,es is the emotion category in source emotions and.
1https://github.com/google-research/google-.
2https://github.com/google-research/google-.
research/tree/master/goemotions/data/sentiment mapping.json.
research/tree/master/goemotions/data/ekman mapping.json.
2369(a) glove.
(b) sswe.
(c) ewe.
(d) textcnn.
(e) bilstm.
(f) bert.
(a)-(c) in semantic space, there are no linearfigure 2: visualization of emotion vectors in different spaces.
boundaries among positive, negative and ambiguous emotions.
(glove: global vectors for word representation(pennington et al., 2014); sswe: sentiment-speciﬁc word embedding (tang et al., 2015); ewe: emotion-enrichedword embedding (agrawal et al., 2018).)
(d)-(f) in emotion space, each type of emotions is linear separated withthe others by blue lines..e is the mapping result of es.
sim is the similarityfunction and the cosine similarity is selected here.
the emotion representations are calculated 10times with same model and different initial param-eters and the average results are employed to con-duct this experiment.
table 4 shows the mappingresults with different models.
we also calculate theresults of word vectors for comparison.
manualresults are chosen as the gold answers.
glove cor-rectly maps 3 out of 21 emotions, which is compa-rable to a random result.
by encoding emotional in-formation into word representations, sswe (tanget al., 2015) maps 10 emotions correctly and ewe(agrawal et al., 2018) maps 7 emotions correctly.
the results indicate that although sentiment em-bedding (sswe) and emotion embedding (ewe)map more emotions correctly than typical word em-bedding (glove), sswe and ewe still mismatchmore than half of the source emotions as they areconstructed under semantic space..in emotion space, our emotion representationscorrectly map 18 out of 21 emotions, which is muchbetter than the result in semantic space.
the scoresundoubtedly show that our emotion representationscan describe emotion relations much better thanword vectors.
besides, detailed mapping resultsfor each emotion can be seen in table 4. results.
of textcnn and bilstm are exactly the same,which is consistent with their similar arrangementin emotion space in ﬁrst experiment.
bert mapsdisapproval to disgust while the others map it toanger.
the most confusing emotions are caringand embarrassment, human maps them to joy andsadness respectively, while our representations inemotion space map them to sadness and disgust..the inconsistency of the two emotions (embar-rassment and caring) in emotion space and in hu-man results shows the complexity of emotion rela-tions.
existing psychological study (scherer, 2005)shows that embarrassment is close to both sadnessand disgust, which means sadness and disgust canboth be regarded as the mapping result for embar-rassment.
as for caring, it has been discussed(scherer et al., 2013) that caring is a positive emo-tion in nature but accompanied by the occurrenceof negative events..the mapping results of the three models areroughly the same as human-provided mapping re-sults, which shows our emotion representations areeffective.
however, when a certain emotion hashigh similarities to multiple emotions (such as em-barrassment to disgust and sadness), there mayexist some differences between different mappingresults.
in other words, there are no absolutely cor-.
2370source emotions human.
admirationamusementannoyanceapprovalcaringconfusioncuriositydesiredisappointmentdisapprovalembarrassmentexcitementgratitudegrieflovenervousnessoptimismpriderealizationreliefremorsescore.
semantic spacessweangerjoydisgustdisgustangerjoysurprisejoyfearangersadnessjoyjoydisgustsurprisejoyjoyjoyjoyjoyanger10.eweangerdisgustangerfearangerangersurprisejoyangerdisgustfearjoyjoysadnesssurprisesadnessangerangerjoyangersadness7.glovedisgustangerangerfearangerangerfearfearfeardisgustdisgustangerjoyangerjoyangerangerangersadnessangerdisgust3.emotion spacetextcnn bilstm bertjoyjoyangersurprisesadnesssurprisesurprisejoysadnessangerdisgustjoyjoysadnessjoyfearjoyjoysurprisejoysadness18.joyjoyangersurprisesadnesssurprisesurprisejoysadnessangerdisgustjoyjoysadnessjoyfearjoyjoysurprisejoysadness18.joyjoyangerjoysadnesssurprisesurprisejoysadnessdisgustdisgustjoyjoysadnessjoyfearjoyjoysurprisejoysadness18.joyjoyangerjoyjoysurprisesurprisejoysadnessangersadnessjoyjoysadnessjoyfearjoyjoysurprisejoysadness—.
table 4: the results of mapping cowen taxonomy to ekman taxonomy.
human results are chosen as the goldanswers and wrong results are marked in red..rect mapping results for all emotions, which furtherindicates the relations among emotions are indeedcomplex..4.5 emotion relations across corpora.
due to the deviations in different corpora (such asdata source bias and annotation bias), there may ex-ist some differences in emotion relations betweendifferent corpora.
in this part, we analyze the dif-ference in emotion relations across corpora.
bertis chosen as the training model here to eliminatethe potential impact caused by models.
for eachdataset, the experiments are repeated 10 times withsame model and different initial parameters, andthe average results are reported here..there are ﬁve emotion categories (anger, disgust,fear, joy and sadness) shared in the four datasets.
the shared ﬁve emotions are basic emotion cat-egories in many emotion taxonomy theories (ek-man, 1992; harmon-jones et al., 2016; cowen andkeltner, 2017).
as a result, the cosine similari-ties among these emotion categories as shown infigure 3 are not high.
for each dataset, all co-.
sine similarities are not greater than 0.3 except thesimilarity between anger and disgust..on the other hand, the datasets are created basedon different annotation standards from differentdomains.
thus, for speciﬁc emotion pair, the simi-larities across datasets may be quite different.
how-ever, the relative magnitude of similarities is con-sistent across datasets.
for each dataset, there isa moderate similarity between anger and disgust(ranging from 0.52 to 0.65) while the similaritiesamong remaining emotion pairs are relatively small(ranging from 0.04 to 0.30)..in order to quantitatively measure the consis-tency of emotion relations in different datasets,pearson correlation coefﬁcients between cosinesimilarities across datasets are calculated as shownin table 5. the pearson correlation coefﬁcientsamong datasets are pretty high (ranging from 0.867to 0.949), which indicates the underlying emotionrelations are quite similar across datasets even ifthey are created in different domains..in this experiment, we detect emotion relationsacross corpora.
the results reveal that there is a.
2371(a) affectivetext.
(b) goemotions.
(c) isear.
(d) affect in tweets.
figure 3: cosine similarities among emotions in different datasets..a.a 1.000g 0.949i0.917t 0.936.g0.9491.0000.8730.926.i0.9170.8731.0000.867.t0.9360.9260.8671.000.resentations, such as improving the performance ofemotion classiﬁcation models and studying emo-tion spaces across languages..acknowledgments.
table 5: pearson correlation coefﬁcients between co-sine similarities.
(a: affectivetext; g: goemotions; i:isear; t: affect in tweets.).
we would like to thank the anonymous reviewersfor their helpful comments..good consistency of our emotion representationsacross datasets even if they are created on the ba-sis of different annotation standards from differentdomains..5 conclusion and future work.
in this paper, we argued that the emotion categoriesare not orthogonal to each other and the relationsamong emotion categories are very complex.
weproposed a general framework to learn the dis-tributed representation for each emotion categoryin emotion space from a given emotion dataset.
then, a simple and effective algorithm was alsoderived based on the soft labels predicted by thepre-trained neural network model.
we conductedthree experiments to validate the effectiveness ofour emotion representations and the experimen-tal results demonstrated that our representations inemotion space can express emotion relations muchbetter than representations from word embeddings.
there are three avenues of future work we wouldlike to explore.
first, the distributed representationsfor emotion categories are derived from a speciﬁcemotion classiﬁcation dataset.
it would be inter-esting to build a universal emotion representationthat is irrelevant to a speciﬁc corpus.
second, thecomputation of our emotion representations relieson the soft labels predicted by the neural networkmodel, and we would like to investigate a more gen-eral method in the future.
finally, we would like toexplore more nlp applications of our emotion rep-.
references.
muhammad abdul-mageed and lyle ungar.
2017.emonet: fine-grained emotion detection with gatedin proceedings of therecurrent neural networks.
55th annual meeting of the association for compu-tational linguistics (volume 1: long papers), pages718–728..ameeta agrawal, aijun an, and manos papagelis.
2018. learning emotion-enriched word representa-tions.
in proceedings of the 27th international con-ference on computational linguistics, pages 950–961..cecilia ovesdotter alm, dan roth, and richard sproat.
2005. emotions from text: machine learning forin proceedings oftext-based emotion prediction.
human language technology conference and confer-ence on empirical methods in natural language pro-cessing, pages 579–586..aaron t beck, brad a alford, md aaron t beck, andph d brad a alford.
2014. depression.
universityof pennsylvania press..sidney j blatt.
2004. experiences of depression: the-oretical, clinical, and research perspectives.
ameri-can psychological association..belinda campos, michelle n shiota, dacher keltner,gian c gonzaga, and jennifer l goetz.
2013. whatis shared, what is different?
core relational themesand expressive displays of eight positive emotions.
cognition & emotion, 27(1):37–52..jason a clark.
2010. relations of homology betweenhigher cognitive emotions and basic emotions.
biol-ogy & philosophy, 25(1):75–94..2372alan s cowen and dacher keltner.
2017. self-reportcaptures 27 distinct categories of emotion bridged bycontinuous gradients.
proceedings of the nationalacademy of sciences, 114(38):e7900–e7909..ehsan imani and martha white.
2018..improvingregression performance with distributional losses.
in international conference on machine learning,pages 2157–2166.
pmlr..taner danisman and adil alpkocak.
2008. feeler:emotion classiﬁcation of text using vector spacein aisb 2008 convention communica-model.
tion, interaction and social intelligence, volume 1,page 53..dorottya demszky, dana movshovitz-attias, jeong-woo ko, alan cowen, gaurav nemade, and sujithravi.
2020. goemotions: a dataset of ﬁne-grainedemotions.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,pages 4040–4054, online.
association for computa-tional linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 1 (long and short papers), pages4171–4186..paul ekman.
1992. an argument for basic emotions..cognition & emotion, 6(3-4):169–200..beverley fehr and james a russell.
1984. con-cept of emotion viewed from a prototype perspec-tive.
journal of experimental psychology: general,113(3):464..johnny rj fontaine, klaus r scherer, etienne broesch, and phoebe c ellsworth.
2007. the worldof emotions is not two-dimensional.
psychologicalscience, 18(12):1050–1057..diman ghazi, diana inkpen, and stan szpakowicz.
2015. detecting emotion stimuli in emotion-bearingin international conference on intelli-sentences.
gent text processing and computational linguistics,pages 152–165.
springer..paul e grifﬁths.
2002. basic emotions, complex emo-.
tions, machiavellian emotions..lin gui, dongyin wu, ruifeng xu, qin lu, andyu zhou.
2016. event-driven emotion cause extrac-in emnlp, pagestion with corpus construction.
1639–1649.
world scientiﬁc..cindy harmon-jones, brock bastian, and eddieharmon-jones.
2016. the discrete emotions ques-tionnaire: a new tool for measuring state self-reported emotions.
plos one, 11(8):e0159915..geoffrey hinton, oriol vinyals, and jeff dean.
2015.distilling the knowledge in a neural network.
arxivpreprint arxiv:1503.02531..long jiang, mo yu, ming zhou, xiaohua liu, andtiejun zhao.
2011. target-dependent twitter senti-ment classiﬁcation.
in proceedings of the 49th an-nual meeting of the association for computationallinguistics: human language technologies, pages151–160..jutta joormann and colin h stanton.
2016. examin-ing emotion regulation in depression: a review andfuture directions.
behaviour research and therapy,86:35–49..yoon kim.
2014. convolutional neural networks forsentence classiﬁcation.
in proceedings of the 2014conference on empirical methods in natural lan-guage processing (emnlp), pages 1746–1751..roman klinger et al.
2018. an analysis of annotatedin pro-corpora for emotion classiﬁcation in text.
ceedings of the 27th international conference oncomputational linguistics, pages 2104–2119..sophia yat mei lee, ying chen, and chu-ren huang.
2010. a text-driven rule-based system for emotioncause detection.
in proceedings of the naacl hlt2010 workshop on computational approaches toanalysis and generation of emotion in text, pages45–53..junjie li, haitong yang, and chengqing zong.
2018.document-level multi-aspect sentiment classiﬁca-tion by jointly modeling users, aspects, and overallin proceedings of the 27th internationalratings.
conference on computational linguistics, pages925–936..yanran li, hui su, xiaoyu shen, wenjie li, ziqiangcao, and shuzi niu.
2017. dailydialog: a manuallylabelled multi-turn dialogue dataset.
in proceedingsof the eighth international joint conference on nat-ural language processing (volume 1: long papers),pages 986–995..chen liu, muhammad osama, and anderson de an-drade.
2019. dens: a dataset for multi-class emo-in proceedings of the 2019 confer-tion analysis.
ence on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 6294–6299..iris b mauss and michael d robinson.
2009. mea-sures of emotion: a review.
cognition and emotion,23(2):209–237..tomas mikolov, kai chen, greg corrado, and jef-efﬁcient estimation of wordarxiv preprint.
frey dean.
2013.representations in vector space.
arxiv:1301.3781..2373saif mohammad.
2012.
# emotional tweets.
in * sem2012: the first joint conference on lexical andcomputational semantics–volume 1: proceedingsof the main conference and the shared task, and vol-ume 2: proceedings of the sixth international work-shop on semantic evaluation (semeval 2012), pages246–255..saif mohammad and felipe bravo-marquez.
2017.emotion intensities in tweets.
in proceedings of the6th joint conference on lexical and computationalsemantics (* sem 2017), pages 65–77..saif mohammad, felipe bravo-marquez, mohammadsalameh, and svetlana kiritchenko.
2018. semeval-2018 task 1: affect in tweets.
in proceedings of the12th international workshop on semantic evaluation,pages 1–17..creating a dataset.
emily ¨ohman, kaisla kajava, j¨org tiedemann, andtimo honkela.
2018.formultilingual ﬁne-grained emotion-detection usingin proceedings ofgamiﬁcation-based annotation.
the 9th workshop on computational approaches tosubjectivity, sentiment and social media analysis,pages 24–30..jeffrey pennington, richard socher, and christopher dmanning.
2014. glove: global vectors for word rep-resentation.
in proceedings of the 2014 conferenceon empirical methods in natural language process-ing (emnlp), pages 1532–1543..to-mary phuong and christoph lampert.
2019.in in-wards understanding knowledge distillation.
ternational conference on machine learning, pages5142–5151..jonathan rottenberg.
2005. mood and emotion in ma-jor depression.
current directions in psychologicalscience, 14(3):167–170..james a russell.
1980. a circumplex model of af-fect.
journal of personality and social psychology,39(6):1161..klaus r scherer.
2005. what are emotions?
and howcan they be measured?
social science information,44(4):695–729..klaus r scherer, vera shuman, johnny fontaine, andcristina soriano salinas.
2013. the grid meets thewheel: assessing emotional feeling via self-report.
components of emotional meaning: a sourcebook..klaus r scherer and harald g wallbott.
1994. evi-dence for universality and cultural variation of differ-ential emotion response patterning.
journal of per-sonality and social psychology, 66(2):310..mike schuster and kuldip k paliwal.
1997. bidirec-tional recurrent neural networks.
ieee transactionson signal processing, 45(11):2673–2681..carlo strapparava and rada mihalcea.
2007. semeval-2007 task 14: affective text.
in proceedings of thefourth international workshop on semantic evalua-tions (semeval-2007), pages 70–74..christian szegedy, vincent vanhoucke, sergey ioffe,jon shlens, and zbigniew wojna.
2016. rethinkingthe inception architecture for computer vision.
inproceedings of the ieee conference on computer vi-sion and pattern recognition, pages 2818–2826..duyu tang, furu wei, bing qin, nan yang, tingliu, and ming zhou.
2015.sentiment embed-dings with applications to sentiment analysis.
ieeetransactions on knowledge and data engineering,28(2):496–509..duyu tang, furu wei, nan yang, ming zhou, ting liu,and bing qin.
2014. learning sentiment-speciﬁcword embedding for twitter sentiment classiﬁcation.
in proceedings of the 52nd annual meeting of theassociation for computational linguistics (volume1: long papers), pages 1555–1565..joseph turian, lev ratinov, and yoshua bengio.
2010.word representations: a simple and general methodfor semi-supervised learning.
in proceedings of the48th annual meeting of the association for computa-tional linguistics, pages 384–394..michael e wall, andreas rechtsteiner, and luis mrocha.
2003. singular value decomposition andin a practical ap-principal component analysis.
proach to microarray data analysis, pages 91–109.
springer..wenbo wang, lu chen, krishnaprasad thirunarayan,and amit p sheth.
2012. harnessing twitter” bigdata” for automatic emotion identiﬁcation.
in 2012international conference on privacy, security, riskand trust and 2012 international confernece on so-cial computing, pages 587–592.
ieee..rui xia and zixiang ding.
2019. emotion-cause pairextraction: a new task to emotion analysis in texts.
in proceedings of the 57th annual meeting of theassociation for computational linguistics, pages1003–1012..rui xia, feng xu, chengqing zong, qianmu li, yongqi, and tao li.
2015. dual sentiment analysis: con-sidering two sides of one review.
ieee transactionson knowledge and data engineering, 27(8):2120–2133..rui xia, chengqing zong, and shoushan li.
2011. en-semble of feature sets and classiﬁcation algorithmsinformation sciences,for sentiment classiﬁcation.
181(6):1138–1152..peng xu, andrea madotto, chien-sheng wu, ji hopark, and pascale fung.
2018. emo2vec: learn-ing generalized emotion representation by multi-in proceedings of the 9th workshoptask training.
on computational approaches to subjectivity, senti-ment and social media analysis, pages 292–298..2374liang-chih yu, jin wang, k robert lai, and xuejiezhang.
2017. reﬁning word embeddings for senti-in proceedings of the 2017 confer-ment analysis.
ence on empirical methods in natural language pro-cessing, pages 534–539..zhenyu zhao, shuangzhi wu, muyun yang, kehaichen, and tiejun zhao.
2020. robust machine read-ing comprehension by learning soft labels.
in pro-ceedings of the 28th international conference oncomputational linguistics, pages 2754–2759..chengqing zong, rui xia, and jiajun zhang.
2019.text data mining (in chinese).
tsinghua universitypress, beijing..2375