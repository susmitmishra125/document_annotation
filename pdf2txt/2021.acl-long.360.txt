trigger is not sufﬁcient: exploiting frame-aware knowledge for implicitevent argument extraction.
kaiwen wei1,2, sun xian1,2, zequn zhang∗1,2,jingyuan zhang1,2, zhi guo1,2 and li jin1,21key laboratory of network information system technology, aerospaceinformation research institute, chinese academy of sciences2school of electronic, electrical and communication engineering, universityof chinese academy of sciencesweikaiwen19@mails.ucas.ac.cn, zqzhang1@mail.ie.ac.cn.
abstract.
implicit event argument extraction seeks toidentify arguments that play direct or implicitroles in a given event.
however, most priorworks focus on capturing direct relations be-tween arguments and the event trigger.
the lackof reasoning ability brings many challenges tothe extraction of implicit arguments.
in thiswork, we present a frame-aware event argu-ment extraction (feae) learning frameworkto tackle this issue through reasoning in eventframe-level scope.
the proposed method lever-ages related arguments of the expected one asclues to guide the reasoning process.
to bridgethe gap between oracle knowledge used in thetraining phase and the imperfect related argu-ments in the test stage, we further introduce acurriculum knowledge distillation strategy todrive a ﬁnal model that could operate withoutextra inputs through mimicking the behavior ofa well-informed teacher model.
experimentalresults demonstrate feae obtains new state-of-the-art performance on the rams dataset..1.introduction.
in this work, we investigate the problem of im-plicit event argument extraction (ieae) (ebneret al., 2020), which seeks to identify argumentsthat play speciﬁc roles respect to a given trig-ger (chen et al., 2020).
unlike previous eventargument extraction task that only processes a sin-gle sentence, arguments in ieae could span mul-tiple sentences.
as shown in figure 1, given aconﬂict/attack/ﬁrearmattack event triggered by theword shooting, an ieae system is required to ex-tract four corresponding arguments with their rolesin brackets: mass murder (target), ﬁrearms (instru-ment), andrey shpagonov (attacker), and tatarstan(place)..∗corresponding author..figure 1: instance of implicit event argument extractionon rams.
solid lines link the event trigger, eventtype, arguments, and argument roles.
the dashed lineconnects two implicitly related arguments that could beinferred from each other..mainstream methods to extract event argumentsfocus on learning pair-wise information between ar-guments and the given trigger.
chen et al.
(2015a);nguyen et al.
(2016a); liu et al.
(2018); sha et al.
(2018) cast argument extraction as a relation classi-ﬁcation problem to extract pairs of trigger and can-didate arguments.
ebner et al.
(2020); zhang et al.
(2020b) utilize event trigger as the predicate andleverage semantic role labeling model (surdeanuet al., 2008; hajic et al., 2009) to identify argu-ments.
former state-of-the-art approaches (du andcardie, 2020; li et al., 2020; zhang et al., 2020a)formulate event argument extraction as a machinereading comprehension (mrc) problem throughasking trigger and role-speciﬁc questions.
despitethe success of these works in single sentence eventargument extraction, current methods struggle inieae due to the following critical issues:.
1.long-range dependency: since argumentscould span multiple sentences, there exist long-range and cross-sentence dependencies betweenarguments and the given trigger, which is hard tobe captured through existing methods..2.implicit arguments: extracting implicit eventarguments requires the ability to reason over event.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4672–4682august1–6,2021.©2021associationforcomputationallinguistics4672the 1992 tatarstan shooting was a mass murder.
on 26 april 1992, 23-year-old andrey shpagonov, for spain tatarstan, hunting camp, april 26, 1992: 9 killed and 1 wounded.
former huntsman went to a hunting camp.examples1s2s3s4he went to steal firearms.s5confilict/attack/firearmattacktargetplaceattackerinstrumentroles, and it is difﬁcult for prior methods to learnthese indirect relations..we attribute these limitations to that currentworks are mainly designed to capture direct rela-tions between arguments and the given event trig-ger.
this pair-wise learning paradigm lacks theability of effective reasoning.
instead of only usingtrigger information, we observe that in mrc-basedevent argument extraction methods, the related ar-guments, which refer to arguments (also their roles)in the same event except for the required one, couldprovide information to perform reasoning.
for ex-ample, as shown in figure 1, if we have alreadyknown andrey shpagonov plays the attacker role ofa ﬁrearmattack event, intuitively, ﬁrearms could bethe instrument of attacker.
implicit relations maylie between the two arguments, helping identifyingﬁrearms.
in this manner, arguments correspondingto roles deﬁned in the event frame-level scope couldact as clues to perform reasoning and be utilized asrelay nodes to capture long-range dependencies..nevertheless, the importance of related argu-ments is under-exploited.
liu et al.
(2017) modelevent arguments as supervising attention informa-tion to promote trigger extraction.
chen et al.
(2020) propose to learn the association of argu-ments, but their method works on golden-standardcandidate spans, which is unavailable in real-worldapplications.
existing methods could also beextended to incorporate related arguments andtheir roles by taking such information as inputs.
however, since the model is trained with golden-standard arguments, predicted imperfect argumentsmight introduce noise and affect the performancein the test stage..in this work, we introduce a frame-aware eventargument extraction (feae) learning frameworkfor ieae.
we extend the mrc-based method toallow reasoning in event frame-level scope by ex-ploiting related arguments and their roles as cluesto capture the argument-argument dependencies.
this method could learn to extract implicit argu-ments of an event trigger and handle the long-range dependency problem.
to bridge the gapbetween the unavailable oracle knowledge (fanget al., 2021) and the imperfect test inputs, we in-troduce a teacher-student framework that drives aﬁnal model that could operate without extra inputsthrough mimicking the behavior of well-informedteachers.
inspired by the curriculum theory (ben-gio et al., 2009), we further introduce a curricu-.
lum distillation strategy that gradually increasesthe learning complexity of the student model tomake it more compatible with the real situation,thus driving a better model.
in summary, our con-tributions in this work are as follows:.
1) we introduce a frame-aware event argu-ment extraction framework to train models for im-plicit event argument extraction.
event frame-levelknowledge is incorporated to reason and capturelong-range dependencies among triggers and argu-ments..2) the proposed model learns to incorporateframe-level knowledge implicitly.
knowledge dis-tillation and curriculum learning are utilized todrive a model that does not require extra tools toproduce reasoning clues, and could incorporateframe-level knowledge implicitly..3) our approach outperforms existing methodssigniﬁcantly.
we achieve new state-of-the-art per-formance on the rams dataset..2 related work.
event argument extraction (eae) seeks to ex-tract entities with speciﬁc roles in an event.
meth-ods that learn direct relation between argumentsand triggers have achieved signiﬁcant progress inthis ﬁeld (chen et al., 2015b; nguyen et al., 2016b;zhang et al., 2019; liu et al., 2018).
recently,there is a trend to formulate eae as a questionanswering (qa) problem, and several mrc mod-els report performing well (zhang et al., 2020a;du and cardie, 2020; liu et al., 2020).
thesemethods leverage role-speciﬁc questions to extractboundaries of the expected arguments.
implicitevent argument extraction (ieae) is a less stud-ied problem where arguments could span multiplesentences and appear in an implicit way.
therehave been only a few works for ieae.
ebner et al.
(2020); zhang et al.
(2020b) formulate ieae as asemantic role labeling task and extract argumentsby classifying phrase pairs.
these methods onlyexplicitly consider direct relations between triggersand arguments.
chen et al.
(2020) also consider therelation among arguments, however, their methodcould only deal with argument linking task thatidentiﬁes the role of a given argument span, whichis not available in a realistic situation.
knowledge distillation is proposed to guide a stu-dent model to imitate a well-trained teacher model.
it is ﬁrst proposed by hinton et al.
(2015) and hasbeen widely used in the natural language process-.
4673ing (nlp) ﬁeld (ruder and plank, 2018; gonget al., 2018; lee et al., 2018; jiao et al., 2020).
in this work, we employ the knowledge distillationtraining strategy to handle the train-test disparitycaused by unavailable oracle knowledge in the teststage through driving a student model to learn thebehavior of a well-informed teacher.
curriculum learning is a learning strategy ﬁrstlyproposed by bengio et al.
(2009) that trains a neu-ral network better through increasing data complex-ity of training data.
it is broadly adopted in manynlp domains (platanios et al., 2019; huang anddu, 2019; xu et al., 2020).
in this work, sincedata with rich related arguments is easier to belearned than those without extra inputs, we pro-mote the training of our student model by graduallyincreasing the learning complexity of the distilla-tion process by decreasing the proportion of givenarguments..3 method.
our feae framework consists of two trainingsteps to drive a model that could utilize frame-level knowledge for ieae, and details are shownin figure 2. for single teacher situations, ﬁrstlywe train an mrc-based teacher model m t withoracle knowledge composing of golden-standardrelevant arguments to exploit frame-aware infor-mation and obtain the capacity to reason.
then astudent model m s that does not have access to thisoracle information is driven with the guidance ofm t to be used in practice.
our framework can alsobe extended to multi-teacher circumstances..in the following sub-sections, we will give theformulation of our task and our mrc-based model.
after that, we will illustrate the curriculum knowl-edge distillation strategy to bridge the gap betweenthe training and inference stage..3.1 task formulation.
we formulate ieae as a qa problem and lever-age the mrc-based model to extract answer spans.
for each argument type, the provided informationconsists of a tuple < q, c >, where q and c refer tothe question and context, respectively.
in practice,the question q should contain information about atrigger, the event type, and the role of the expectedargument.
we aim to extract a span s in the contextthat contains the answer to the question..formally, given the context c = {wi}n.i=1 con-sisting of n words and a known event trigger with.
the corresponding event type, we seek to identifya set of argument tuples (cid:8)(cid:0)ysj , yej , rolejj=1,where ysj and yej are the start and end index ofthe j-th argument, respectively; rolej is the roleof this argument..(cid:1)(cid:9)m.3.2 frame-aware question generation.
the key of mrc-based qa is to generate questionsthat contain information about text spans to beextracted.
we leverage a template-based questiongeneration strategy to acquire meaningful descrip-tions about the desired event argument in thiswork.
the question template we used to extractarguments with the role of arg t ype is as follows:.
[event t ype] [arg t ype] with [arg1] as [role1]and [arg2] as [role2] .
.
.
and [argn] as [rolen] in[t rigger]..where [t rigger] and [event t ype]shouldbe ﬁlled in with event trigger and the correspond-ing event type, respectively; [arg t ype] denotesthe role of the expected argument; [arg] and [role]are related arguments and their role types in thesame event.
elements in underlines contain oracleknowledge and are excluded during the test stage.
the mrc-based model could be explicitly awareof the frame-level information by ﬁlling in thistemplate, thus making better predictions..3.3 mrc-based argument extraction.
we employ the pre-trained language model bert(devlin et al., 2019) as the backbone of ourmrc-based argument extraction model.
the textinput is formulated as:.
[cls] question [sep ] context [sep ].
where [cls] and [sep ] are specialtokensdeﬁned in bert; question refers to the querygenerated with our template, and context denotesthe context words where arguments are extracted.
this input sequence is then converted into an em-bedding matrix e and used as inputs of the mrcmodel.
we leverage bert to build semantic rep-resentation for each word in the context.
after theencoding stage, we utilize hidden states from thelast bert layer to represent each token:.
h = bert(e).
(1).
this encoding stage makes a deep fusion be-tween the question and the context by interactions.
4674figure 2: architecture of the feae learning framework.
training and test stages are shown in (a) and (b),respectively.
(c) shows the curriculum distillation strategy.
data ﬂow of oracle knowledge in the training step isillustrated with dashed lines and ’role’ in the box is short for the argument role..between multi-head and multi-layer attention.
inorder to explicitly inform the model with the loca-tion of trigger word, we further introduce positionalembedding to reﬂect the relevant distances betweenwords and the speciﬁc trigger.
the concatenationsof positional embedding and hidden states are thenutilized to produce two probability vectors of thestart and end positions:.
pstart = softmax(ws (h ⊕ ep) /τ )pend = softmax(we (h ⊕ ep) /τ ).
(2).
where ep is the positional embedding matrix; ⊕ isthe operator of concatenation and τ is the parameterof softmax temperature..we use cross-entropy between the prediction andgolden labels as our training criterion to optimizeour model.
the following two losses are used fortraining start and end index predictions:.
assist reasoning in the training stage, this golden-standard information is not available for the teststage in practice.
this train-test disparity may leadto a performance drop when noisy, or even unre-lated arguments are used in the test stage..to bridge this gap, we adopt the teacher-studentframework to drive a model that is capable ofreasoning without the requirement of extra clues.
speciﬁcally, as shown in figure 2 (a), we ﬁrst in-put frame-aware question qf ull that contains allcategories of oracle knowledge to obtain a well-trained teacher model m t .
then m t is utilizedto generate hidden states h t and the span distri-butions ptend.
likewise, a student modelm s, which does not utilize oracle information, pro-duces hidden states h s and index distributionspsend.
the m s distills knowledge fromstart and psm t through learning to have similar behavior inboth hidden vectors and prediction distributions:.
start and pt.
lstart = ce(pstart, ystart)lend = ce(pend, yend).
(3).
where ystart and yend are ground-truth labels forthe index of desired span, respectively.
for thesituation where no answer exists in the context(missing role of the event), we point these twoheads to the [cls] token.
the overall loss of thebasic mrc model is formulated as:.
lce = lstart + lend.
(4).
3.4 teacher-student framework.
although oracle knowledge about related argu-ments in the same event could provide clues to.
lkl = (kl(ptend, pskl(pt.
start, psend))/2lm se = mse(h t , h s).
start)+.
(5).
where kl and mse are short for kl-divergenceloss and mean squared error loss, respectively..both the teacher m t and the student m s sharethe same architecture but with diverse parameters.
the weights of m t are ﬁxed and we only opti-mize the parameters of the student model duringthe knowledge distillation stage.
the overall lossof m s under our teacher-student framework is for-mulated as:.
lt,s = lce + αlkl + βlm se.
(6).
4675(c) curriculum knowledge distillation stage(b) knowledge distillation test stage(a) knowledge distillation training stageoracle knowldegeevent-aware contextevent-aware contextstudentanswerteacherstudentoracle knowldegeevent-aware contextteacherknowledge distillationrelated role1related role2related role3expected rolestudentknowledge distillationanswersamplerepochsamplerepocha a%where α and β are two weight coefﬁcients..note that oracle knowledge in the question tem-plate, marked with underlines, is not available ina realistic test situation.
in this work, we only uti-lize them to guide our teacher model to captureframe-aware information in the training stage.
asillustrated in figure 2(b), for the test stage of ourstudent model m s, we discard these extra inputsand ﬁll in slots with event-aware context, whichonly consists of the event trigger, event type, andthe expected argument type.
besides, as oracleknowledge is included in the input of the teachermodel, during the distillation process we mask outthe question part of the text input in both teacherand student models, and only distill the knowledgeof context part..this teacher-student framework could be furtherextended to a multi-teacher manner which enables astudent model to capture knowledge from multipleperspectives.
a teacher model could learn to focuson several patterns to apply reasoning by providingdifferent combinations of related arguments.
wedrive four teachers trained with diverse templatesto capture different categories of oracle knowledgeamong roles, which are represented with all,all − 1, all − 2, and n on e, respectively.
these templates utilize arguments of different pro-portions.
take the example of the knowledge dis-tillation training stage in figure 2 (a), there is oneexpected argument to be extracted and three relatedarguments.
all indicates we ﬁll in the input tem-plate with all related arguments.
all − 1 denotesthat we randomly enumerate the possibilities oftwo out of the three other arguments and leave oneslot unﬁlled.
questions for all − 2 and n on eare generated in the same method where two or allslots remain unﬁlled..for the multi-teacher situation, we distill knowl-edge into the student model from the four teach-ers mentioned above simultaneously.
the overallmulti-teacher distillation loss is formulated as:(cid:88).
(7).
l =.
ωkltk,s.
k.where ωk and ltk,s are the weighting factor andthe loss function calculated with the k-th teachermodel using equation 6, respectively..3.5 curriculum distillation.
in this subsection, we view the disparity betweenthe training and test stage from the perspective oflearning complexity and introduce our curriculum.
algorithm 1 curriculum distillation strategyk=1, m sinput: i all, i, {m tk }4output: psstart, psfor a←100 to 0 do.
end.
// build training question set.
i t rain = sample(i all, i, a%)for k←1 to 4 do.
// cache teacher statush tk , ptk.
start, ptk.
end = m tk (i all).
end// get student status.
start, p s.h s, psapply knowledge distilling to m s following equation 7.end = m s(i t rain).
endwhile not coverage do.
end.
utilize i to train m s following equation 7.distillation strategy.
clues in the form of relatedarguments and their roles are explicitly given forthe teacher model to promote reasoning.
while forthe student model (the inference stage), there areno golden-standard clues, making it challengingfor the model to extract the expected argument byrelying on associated ones.
intuitively, the trainingprocess of the student model is harder than that ofthe teacher..inspired by the curriculum theory that a machinelearning model could be trained better by feedingdata following the easier to harder order, we intro-duce a curriculum distillation strategy to promotethe learning of student model.
we utilize the pro-portion of given arguments to measure the complex-ity of the learning task and data points in ieae task.
as in figure 2 (c), at the beginning of the distilla-tion stage, we utilize questions containing oracleknowledge with all related arguments to train thestudent as a warm-up procedure.
then we gradu-ally reduce the proportion of given arguments andﬁnally transit to using no extra arguments as in a re-alistic situation.
note that all teacher models utilizeoracle knowledge as they are trained throughoutthe whole process..details of the curriculum distillation strategy areshown in algorithm 1. i all and i are two setsof training instances with all golden-standard ar-guments and no extra knowledge are used to buildquestions, respectively.
{m tk }4k=1 are four well-informed teacher models trained with diverse tem-plates that capture different categories of oracleknowledge.
m s is the student model.
for eachtraining step, ﬁrstly, we sample a batch of instancesfollowing bernoulli distribution and the probabil-ity of selecting an example from the i all is a%..4676argument identiﬁcation argument classiﬁcation.
p-ebner’s47.93zhang’s55.28student57.63student-sup57.34student-gcnstudent-mkd 56.8761.23student-da57.56student-bagteacher∗54.2754.61teacher-r55.73teacher-mt60.87feae.
r-35.0744.0444.4944.9844.8842.0743.9951.8537.6240.3347.70.f1-40.5049.0350.2150.4250.1749.8749.8753.0344.5546.8053.49.p68.8-47.4751.8249.3749.4454.0650.2650.6432.2948.7253.17.r14.3-39.4040.2940.4839.3036.7338.5649.1332.8734.8042.76.f123.7-43.0645.3344.4943.7943.7443.6449.8832.5740.6047.40.table 1: overall performance on the test set of rams dataset (%) and baseline methods.
* indicates ground-truthrelated arguments are used in the test stage.
bold numbers denote the best results that can be obtained without extraknowledge..secondly, we cache the hidden state, start and enddistribution of the four teachers with i all as input.
finally, we utilize all cached status from teachermodels to simultaneously distill knowledge to stu-dent network.
as the training stage progresses, thevalue of a gradually decreases from 100 to 0, lead-ing to the learning difﬁculty of batches of data fromeasier to harder.
note that we evaluate the perfor-mance of m s using data without extra argumentsin questions.
we apply the early stop strategy toavoid over-ﬁtting when the obtained f1 score onthe development set no longer improves after sev-eral iterations..4 experiments.
4.1 experiment setupdataset.
we conduct experiments on the rams1dataset, which is annotated with 139 event typesand 65 corresponding argument roles.
each in-stance consists of a 5-sentences context around thetyped event trigger, and there are several typed ar-guments to be extracted.
rams dataset consists of7329, 924, and 871 instances in the training, devel-opment, and test set, respectively.
evaluation and hyperparameters.
an argu-ment is considered correctly identiﬁed when thepredicted offset ﬁts the golden-standard span.
ifboth the span and the role of an extracted argumentare matched with golden-standard one, then this ar-gument is correctly classiﬁed.
precision (p), recall(r), and f measure (f1) are adopted as valuationmetrics.
besides, gold event type information isused in the type constrained decoding (tcd) set-ting..1https://nlp.jhu.edu/rams/.
in experiments, we adopt bert-base, which has12 layers, 768 hidden units, and 12 attention headsin every layer, as our mrc model.
the batch sizeis set to 4 and the max sequence length is 512. weset the dimension of the trigger position embed-ding to 76 and the epoch is set to 7. we train themodels with an adam weight decay optimizer withan initial learning rate of 3e-5.
the warming upportion for learning rate is 10%.
temperature τis set to 1. and we set α as 0.5, β as 2e-3 to bal-ance cross-entropy, kl-divergence, and mse loss.
the proportionality factor a in every epoch is set to100, 70, 40, 30, 20, 10, 0. and the weighting fac-tors {ωk}4k=1 from all, all − 1, all − 2, andn on e are conﬁgured as 0.35, 0.25, 0.25, 0.15,respectively..4.2 overall performance.
baselines.
(1) ebner’s (ebner et al., 2020) is asemantic role labeling-based method with greedydecoding.
(2) zhang’s (zhang et al., 2020b) is atwo-step head-based model that ﬁrst predicts head-words of an argument and then expands to the fullspan.
since ieae is a newly proposed task, thereare only a few existing works.
to demonstrate theeffectiveness of our method, we also adopt sev-eral strong methods from the eae task and re-port performances of these baselines and their vari-ants.
(3) student is our base model that extractsarguments with mrc framework based on du and(4) student-sup is the variantcardie (2020).
where argument information is explicitly modeledwith supervising attention mechanism based onliu et al.
(2017).
(5) student-gcn is the variantwhere graph nodes are built by named entities ex-.
4677teacher∗feae - multi - cl - kdfeae - multi - clfeae - multifeae - clfeae.
f i53.0349.0350.3552.0351.2653.49.f c49.8843.0644.7546.2545.8247.40.none all-2 all-145.9845.2345.11.all46.25.feae47.40.f1 c.table 3: argument classiﬁcation study with differentproportions of arguments.
all, all-1, all-2, andnone denote models trained with various templates..table 2: ablation study on the test set of feae.
f iand f c mean f1 scores of argument identiﬁcation andclassiﬁcation..tracted from stanford corenlp toolkit2, and adoptsmulti-hop graph convolutional network for reason-ing based on liu et al.
(2018).
(6) student-mkd isa multi-teacher knowledge distillation frameworkwhere four student models trained with various ran-dom seeds are used as teachers, and then distillto another student model.
(7) student-da is thevariant that utilizes questions with different propor-tions of oracle knowledge as the data augmentationstrategy.
(8) student-bag is the variant that en-sembles 5 well-trained student models through abagging paradigm.
(9) teacher is the variant withthe same architecture as the student, and it is trainedand tested with oracle knowledge.
(10) teacher-rhas the same setting as the teacher but tested withraw text.
(11) teacher-mt is the variant whereanswering histories from previous turns are fusedto the current question in a multi-turn manner..from experimental results shown in table 1, wecan conclude that: (1) mrc-based methods exceedthose directly learn pair-wise relations among eventtargets and candidate arguments, leading to strongbaselines for ieae.
we attribute these improve-ments to that mrc models could capture relationsamong arguments implicitly during the encodingstage through the qa framework.
these methodsalso beneﬁt from the prior knowledge containedin task descriptions.
(2) with the same architec-ture, student-sup, student-gcn, student-da, andfeae surpass the student, and the teacher thatutilizes oracle knowledge in both the training andtest stage performs best.
these results indicate theeffectiveness of related arguments and verify our in-tuition that reasoning in the event frame-level scopecontributes to ieae.
(3) the result gaps amongteacher, teacher-r, and teacher-mt clearly showthat the train-test disparity could affect the infer-ence procedure.
compared with teacher-mt, ourfeae obtains a gain of 6.80 points in f1, indicat-ing the effectiveness of our teach-student learning.
2http://stanfordnlp.github.io/corenlp/.
pebner’s -tcd62.8ebner’s +tcd 78.185.566.482.0.teacher∗studentfeae.
r74.969.287.577.371.6.f168.373.386.571.576.6.table 4: performance on argument linking..strategy.
an explanation is that in teacher-mt,incorrect answers in the previous turn may bringnoise and seriously affect the results of subsequentanswers.
however, feae is trained with golden-standard related arguments, thus could alleviate(4) student-such error accumulation problem.
sup that does not require extra nlp tools to buildan explicit graph outperforms student-gcn.
ourmethod further obtains an improvement of 2.07 ab-solute points in the argument classiﬁcation task.
these results demonstrate that implicit reasoningis a powerful way to capture the interrelation be-tween arguments.
another reason is that buildingexplicit reasoning graphs could not avoid intro-ducing noises.
(5) the improvements of student-mkd, student-da, and student-bag are marginal,illustrating that the improvement in our method ismainly from the architecture of knowledge distilla-tion rather than introducing additional factors.
(6)the proposed feae outperforms strong baselinesand achieves new state-of-the-art results for bothargument identiﬁcation and argument classiﬁcation.
without using extra inputs, our approach achievesresults similar to the one with oracle knowledge.
the performance gain clearly indicates that ourfeae could capture frame-aware information ef-fectively.
ablation study.
to investigate the effect of eachcomponent, we conduct an ablation study by re-moving multi-teacher (-multi), curriculum learning(-cl), and knowledge distillation framework (-kd).
we train the model with oracle knowledge contain-ing all related arguments when eliminating multi-teacher(-multi), results are shown in table 2. wecan observe that: (1) knowledge distillation bringsas large as 1.69 absolute points in f1 for argumentclassiﬁcation.
by mimicking the behavior of a well-informed teacher, our method could effectively ob-.
4678d =-2.
d =-1.
d =0.
d =1.
d =2.
f1 i-27.593.7725.96.f1 c14.027.593.7723.72.f1 i-23.9514.4923.61.f1 c14.022.4913.7719.33.f1 i-56.2051.7555.65.f1 c41.252.3844.0049.20.f1 i-30.0720.4826.10.f1 c15.727.6217.7825.00.f1 i-9.885.797.65.f1 c4.29.882.895.35.zhang’steacher∗studentfeae.
table 5: performance breakdown by argument-trigger distance d on rams development set..category.
long-rangedependency.
implicitargument.
examplee1: genocide will never remain in the past .
by recognizing the genocide , it will forcethe {turkish}killer government to take a brave step and look into its own history... from the turkish and {armenian}victim embassies were present in the germanparliament while the vote was taking place ...e2:.
.
.
critics of {putin}granter ’s land grab plan say it will only increase the amountof {chinese workers}transporter immigrating in masses across the border to work onnewly - developed destination .
countered one chinese businessman : ” i think therussians need to understand that if they do n’t allow [chinese investment]destinationor japanese ....table 6: case study on rams test set.
the bold text indicates the trigger word.
ground-truth relevant argumentsare marked in blue with {curly braces} span indicator, while arguments correctly predicted by feae are representedby the [square brackets] spans with red role types..tain the ability of reasoning in event frame-levelscope, thus achieving better performances.
(2) thecurriculum strategy could promote the training pro-cess of our student model by gradually ﬁlling inthe gap between train and test inputs.
(3) intro-ducing multiple teachers could provide more accu-rate guidance from different views and enhance theknowledge distillation framework.
impact of frame-aware knowledge.
to get abetter understanding of the impact of frame-awareknowledge, we show results with different teachersettings in table 3, where we adopt a single-teachercurriculum knowledge distillation strategy in exper-iment.
the main difference between these variantsis the percentage of oracle knowledge utilized totrain teachers, as shown in section 3.4. we ﬁnd thatwith the increase of the percentage of ground-truthrelated argument (the completeness in event frame-level scope), the student could achieve better perfor-mance, verifying our assumption that frame-awareknowledge could provide essential information forieae.
feae achieves the best results and showsthe importance of capturing multi-view guidances.
performance on argument linking.
we presentthe performances of feae and baselines on the ar-gument linking task in table 4, where ground-truthargument spans are provided and these models arerequired to identify the role of each span.
for ourmrc variants, we add the expected argument intothe question and apply binary classiﬁcation on thevector of [cls] token to decide whether the argu-ment plays the given role in the event.
we ﬁnd that.
feae has an 8.3 points improvement in f1 scorecompared to ebner’s -tcd, and our feae alsosurpasses baselines.
results of this study indicatethat frame-aware knowledge also contributes to im-proving the performance of argument linking.
performance breakdown by distance.
to testour method’s ability to capture long-range depen-dencies, we list the performance breakdown on dif-ferent sentence distances between arguments andthe given trigger in table 5. similar to zhang et al.
(2020b), we observe that all models have a perfor-mance drop for the non-local arguments (whered = ±2 or d = ±1).
compared with student,feae achieves a gain of more than 4 times by sum-ming the results in the condition of d = ±2, and thef1 score even increases by 6 times when d = −2.
to explore the reasons, we sort all argument rolesin the d = ±2 cases by the number of occurrencesand ﬁnd the top ﬁve categories are place, recipient,instrument, participant, and attacker, which coversmore than 56% of the total number.
intuitively,there are strong semantic associations between theaforementioned roles and other roles deﬁned in theframe scope.
since our feae enables the modelto reason with frame-level knowledge, it is naturalthat our method could mitigate the performancedegradation in long-range dependency situations..4.3 further discussion.
4.3.1 bert attention analysis.
to have a better understanding of how feae im-proves the mrc model, we conduct an experiment.
4679related argumentdamager destroyerbeneﬁciaryorigingiverretreater.
expected argumentplaceparticipantextraditerartifact moneydestination.
feae1.211.141.131.121.11.table 7: results on the top 10 bert attention heads.
these values are averaged over all instances with suchrelevant argument role pairs..to illustrate the reasoning process with attentionweights of the bert backbone.
following clarket al.
(2019), we extract the top 10 most signiﬁ-cant attention heads from all the 144 bert-baseheads pointing from expected argument to relatedargument.
we enumerate and average those top 10attention heads from 314 all possible argument rolepairs on rams test set and ﬁnd that teacher andfeae have larger averaged values than studentwith 295 and 269 argument pairs, respectively.
theresult indicates that our approach is able to wellguide the bert model to learn oracle informationby modifying the corresponding attention weightsand guide expected argument to focus more on theclues brought by related argument.
in addition, welist the 5 most notable samples where the valuesare normalized by student averaged values in ta-ble 7. it should be noted that the averaged attentionweights among different role-pairs are numericallyincomparable.
but in a particular pair, feae tendsto have a larger value than that of the student model,indicating that feae learns to reason by payingmore attention to the relevant arguments.
for exam-ple, in the ﬁrst instance, intuitively, when lookingfor place, arguments with the role of damager de-stroyer could provide clues..4.3.2 case study.
in this section, we further illustrate how feaecould alleviate long-range dependencies and im-plicit argument problems.
as shown in table 6, wegive representative examples where student modelmisses the correct answers, while feae is able tocorrectly ﬁnd them.
for the scenario of long-rangedependencies in e1, it is difﬁcult to identify theargument of role victim because there are too manywords between the argument armenian and the trig-ger genocide.
however, there is a strong implicitsemantic relationship between killer and victim.
feae could better capture such oracle knowledgethan student model, thus feae successfully ﬁndand classify armenian as victim.
for the implicit.
argument situations in e2, since there is no directassociation between argument russian farms andtrigger word immigrating, student model falls toidentify russian farms.
but frame-aware knowl-edge provides the priory that there is an implicitconnection between argument role transporter andpassenger.
consequently, feae successfully re-calls argument russian farms..5 conclusion and future work.
in this paper, we exploit frame-aware knowledgefor extracting implicit event arguments.
speciﬁ-cally, we introduce a curriculum knowledge distil-lation strategy, feae, to train an mrc model thatcould focus on frame-aware information to identifyimplicit arguments.
the proposed method lever-ages a teacher-student framework to avoid the re-quirement of extra clues and could perform reason-ing with the guidance in event frame-level scope.
experiments show that our method surpasses strongstate-of-the-art baselines in rams, and could sci-entiﬁcally alleviate long-range dependency and im-plicit argument problems..references.
yoshua bengio, j´erˆome louradour, ronan collobert,and jason weston.
2009. curriculum learning.
inproceedings of the 26th annual international confer-ence on machine learning, pages 41–48..yubo chen, liheng xu, kang liu, daojian zeng, andjun zhao.
2015a.
event extraction via dynamic multi-pooling convolutional neural networks.
in proceed-ings of the 53rd annual meeting of the associationfor computational linguistics and the 7th interna-tional joint conference on natural language pro-cessing of the asian federation of natural languageprocessing, acl 2015, july 26-31, 2015, beijing,china, volume 1: long papers, pages 167–176.
theassociation for computer linguistics..yubo chen, liheng xu, kang liu, daojian zeng, andjun zhao.
2015b.
event extraction via dynamic multi-pooling convolutional neural networks.
in proceed-ings of the 53rd annual meeting of the associationfor computational linguistics and the 7th interna-tional joint conference on natural language pro-cessing (volume 1: long papers), pages 167–176..yunmo chen, tongfei chen, and benjamin van durme.
2020. joint modeling of arguments for event un-derstanding.
in proceedings of the first workshopon computational approaches to discourse, pages96–101..kevin clark, urvashi khandelwal, omer levy, andchristopher d. manning.
2019. what does bert.
4680look at?
an analysis of bert’s attention.
corr,abs/1906.04341..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, naacl-hlt 2019, minneapolis, mn, usa,june 2-7, 2019, volume 1 (long and short papers),pages 4171–4186.
association for computationallinguistics..xinya du and claire cardie.
2020. event extraction byanswering (almost) natural questions.
in proceedingsof the 2020 conference on empirical methods innatural language processing, emnlp 2020, online,november 16-20, 2020, pages 671–683.
associationfor computational linguistics..seth ebner, patrick xia, ryan culkin, kyle rawlins,and benjamin van durme.
2020. multi-sentence ar-gument linking.
in proceedings of the 58th annualmeeting of the association for computational lin-guistics, acl 2020, online, july 5-10, 2020, pages8057–8077.
association for computational linguis-tics..yuchen fang, kan ren, weiqing liu, dong zhou,weinan zhang, jiang bian, yong yu, and tie-yanliu.
2021. universal trading for order execution withoracle policy distillation.
in aaai..chen gong, xiaojun chang, meng fang, and jian yang.
2018. teaching semi-supervised classiﬁer via gener-alized distillation.
in ijcai, pages 2156–2162..jan hajic, massimiliano ciaramita, richard johans-son, daisuke kawahara, maria ant`onia mart´ı, llu´ısm`arquez, adam meyers, joakim nivre, sebastianpad´o, jan step´anek, pavel stran´ak, mihai surdeanu,nianwen xue, and yi zhang.
2009. the conll-2009shared task: syntactic and semantic dependenciesin multiple languages.
in proceedings of the thir-teenth conference on computational natural lan-guage learning: shared task, conll 2009, boulder,colorado, usa, june 4, 2009, pages 1–18.
acl..geoffrey e. hinton, oriol vinyals, and jeffrey dean.
2015. distilling the knowledge in a neural network.
corr, abs/1503.02531..yuyun huang and jinhua du.
2019. self-attentionenhanced cnns and collaborative curriculum learn-ing for distantly supervised relation extraction.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing, emnlp-ijcnlp 2019, hongkong, china, november 3-7, 2019, pages 389–398.
association for computational linguistics..xiaoqi jiao, yichun yin, lifeng shang, xin jiang, xiaochen, linlin li, fang wang, and qun liu.
2020..tinybert: distilling bert for natural language un-derstanding.
in proceedings of the 2020 conferenceon empirical methods in natural language process-ing: findings, emnlp 2020, online event, 16-20november 2020, pages 4163–4174.
association forcomputational linguistics..seung hyun lee, dae ha kim, and byung cheol song.
2018. self-supervised knowledge distillation usingsingular value decomposition.
in european confer-ence on computer vision, pages 339–354.
springer..fayuan li, weihua peng, yuguang chen, quan wang,lu pan, yajuan lyu, and yong zhu.
2020. eventextraction as multi-turn question answering.
inproceedings of the 2020 conference on empiricalmethods in natural language processing: findings,emnlp 2020, online event, 16-20 november 2020,pages 829–838.
association for computational lin-guistics..jian liu, yubo chen, kang liu, wei bi, and xiaojiangliu.
2020. event extraction as machine reading com-prehension.
in proceedings of the 2020 conferenceon empirical methods in natural language process-ing (emnlp), pages 1641–1651..shulin liu, yubo chen, kang liu, and jun zhao.
2017.exploiting argument information to improve eventdetection via supervised attention mechanisms.
inproceedings of the 55th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 1789–1798..xiao liu, zhunchen luo, and heyan huang.
2018.jointly multiple events extraction via attention-basedgraph information aggregation.
in proceedings of the2018 conference on empirical methods in naturallanguage processing, brussels, belgium, october 31- november 4, 2018, pages 1247–1256.
associationfor computational linguistics..thien huu nguyen, kyunghyun cho, and ralph gr-ishman.
2016a.
joint event extraction via recurrentneural networks.
in naacl hlt 2016, the 2016conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, san diego california, usa,june 12-17, 2016, pages 300–309.
the associationfor computational linguistics..thien huu nguyen, kyunghyun cho, and ralph grish-man.
2016b.
joint event extraction via recurrent neu-ral networks.
in proceedings of the 2016 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, pages 300–309..emmanouil antonios platanios, otilia stretcu, grahamneubig, barnab´as p´oczos, and tom m. mitchell.
2019. competence-based curriculum learning forneural machine translation.
in proceedings of the2019 conference of the north american chapterof the association for computational linguistics:human language technologies, naacl-hlt 2019,.
4681minneapolis, mn, usa, june 2-7, 2019, volume 1(long and short papers), pages 1162–1172.
associa-tion for computational linguistics..sebastian ruder and barbara plank.
2018. strong base-lines for neural semi-supervised learning under do-main shift.
in proceedings of the 56th annual meet-ing of the association for computational linguistics,acl 2018, melbourne, australia, july 15-20, 2018,volume 1: long papers, pages 1044–1054.
associa-tion for computational linguistics..lei sha, feng qian, baobao chang, and zhifang sui.
2018.jointly extracting event triggers and argu-ments by dependency-bridge rnn and tensor-basedargument interaction.
in proceedings of the thirty-second aaai conference on artiﬁcial intelligence,(aaai-18), the 30th innovative applications of arti-ﬁcial intelligence (iaai-18), and the 8th aaai sym-posium on educational advances in artiﬁcial intel-ligence (eaai-18), new orleans, louisiana, usa,february 2-7, 2018, pages 5916–5923.
aaai press..mihai surdeanu, richard johansson, adam meyers,llu´ıs m`arquez, and joakim nivre.
2008. the conll2008 shared task on joint parsing of syntactic and se-mantic dependencies.
in proceedings of the twelfthconference on computational natural languagelearning, conll 2008, manchester, uk, august 16-17, 2008, pages 159–177.
acl..benfeng xu, licheng zhang, zhendong mao, quanwang, hongtao xie, and yongdong zhang.
2020.curriculum learning for natural language understand-ing.
in proceedings of the 58th annual meeting ofthe association for computational linguistics, acl2020, online, july 5-10, 2020, pages 6095–6104.
association for computational linguistics..tongtao zhang, heng ji, and avirup sil.
2019. joint en-tity and event extraction with generative adversarialimitation learning.
data intelligence, 1(2):99–120..yunyan zhang, guangluan xu, yang wang, daoyulin, feng li, chenglong wu, jingyuan zhang, andtinglei huang.
2020a.
a question answering-basedframework for one-step event argument extraction.
ieee access, 8:65420–65431..zhisong zhang, xiang kong, zhengzhong liu, xuezhema, and eduard hovy.
2020b.
a two-step approachfor implicit event argument detection.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics, pages 7479–7485..4682