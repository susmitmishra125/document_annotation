dialogue response selection with hierarchical curriculum learningyixuan su♠,∗ deng cai♥,∗ qingyu zhou♦ zibo lin♦ simon baker♠yunbo cao♦ shuming shi♦ nigel collier♠ yan wang♦♠language technology lab, university of cambridge♥the chinese university of hong kong♦tencent inc..{ys484,sb895,nhc30}@cam.ac.ukthisisjcykcd@gmail.com{qingyuzhou,jimblin,yunbocao,shumingshi,brandenwang}@tencent.com.
abstract.
we study the learning of a matching model fordialogue response selection.
motivated by therecent ﬁnding that models trained with randomnegative samples are not ideal in real-worldscenarios, we propose a hierarchical curricu-lum learning framework that trains the match-ing model in an “easy-to-difﬁcult” scheme.
our learning framework consists of two com-plementary curricula: (1) corpus-level curricu-lum (cc); and (2) instance-level curriculum(ic).
in cc, the model gradually increasesits ability in ﬁnding the matching clues be-tween the dialogue context and a response can-didate.
as for ic, it progressively strength-ens the model’s ability in identifying the mis-matching information between the dialoguecontext and a response candidate.
empiricalstudies on three benchmark datasets with threestate-of-the-art matching models demonstratethat the proposed learning framework signiﬁ-cantly improves the model performance acrossvarious evaluation metrics..1.introduction.
building intelligent conversation systems is a long-standing goal of artiﬁcial intelligence and has at-tracted much attention in recent years (shum et al.,2018; kollar et al., 2018).
an important challengefor building such conversation systems is the re-sponse selection problem, that is, selecting the bestresponse to a given dialogue context from a set ofcandidate responses (ritter et al., 2011)..to tackle this problem, different matching mod-els are developed to measure the matching degreebetween a dialogue context and a response candi-date (wu et al., 2017; zhou et al., 2018; lu et al.,2019; gu et al., 2019).
despite their differences,.
∗ the main body of this work was done during internship attencent inc. the ﬁrst two authors contributed equally.
yanwang is the corresponding author..dialogue context between two speakers a and ba: would you please recommend me a good tv series.
to watch during my spare time?.
b: absolutely!
which kind of tv series are you most.
interested in?.
a: my favorite type is fantasy drama.
b: i think both game of thrones and the vampire.
diaries are good choices..positive response.
p1: awesome, i believe both of them are great tv.
series!
i will ﬁrst watch game of thrones.
(easy).
p2: cool!
i think i ﬁnd the perfect thing to kill my.
weekends..(difﬁcult).
negative responsen1: this restaurant is very expensive.
(easy)n2: iain glen played ser jorah mormont in the hbo(difﬁcult).
fantasy series game of thrones..table 1: an example dialogue context between speak-ers a and b, where p1 and p2 are easy and difﬁcultpositives; n1 and n2 are easy and difﬁcult negatives..most prior works train the model with data con-structed by a simple heuristic.
for each context, thehuman-written response is considered as positive(i.e., an appropriate response) and the responsesfrom other dialogue contexts are considered as neg-atives (i.e., inappropriate responses).
in practice,the negative responses are often randomly sampledand the training objective ensures that the positiveresponse scores are higher than the negative ones.
recently, some researchers (li et al., 2019; linet al., 2020) have raised the concern that randomlysampled negative responses are often too trivial(i.e., totally irrelevant to the dialogue context).
models trained with trivial negative responses mayfail to handle strong distractors in real-world sce-narios.
essentially, the problem stems from the ig-norance of the diversity in context-response match-ing degree.
in other words, all random responsesare treated as equally negative regardless of theirdifferent distracting strengths.
for example, ta-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1740–1751august1–6,2021.©2021associationforcomputationallinguistics1740ble 1 shows a conversation between two speakersand two negative responses (n1, n2) are presented.
for n1, one can easily dispel its appropriatenessas it unnaturally diverges from the tv show topic.
on the other hand, n2 is a strong distractor as itoverlaps signiﬁcantly with the context (e.g., fan-tasy series and game of thrones).
only with closeobservation we can ﬁnd that n2 does not maintainthe coherence of the discussion, i.e., it starts a par-allel discussion about an actor in game of thronesrather than elaborating on the enjoyable propertiesof the tv series.
in addition, we also observe asimilar phenomenon on the positive side.
for differ-ent training context-response pairs, their pairwiserelevance also varies.
in table 1, two positive re-sponses (p1, p2) are provided for the given context.
for p1, one can easily conﬁrm its validity as itnaturally replies the context.
as for p2, while itexpatiates on the enjoyable properties of the tv se-ries, it does not exhibit any obvious matching clues(e.g., lexical overlap with the context).
therefore,to correctly identify p2, its relationship with thecontext must be carefully reasoned by the model.
inspired by the above observations, in this work,we propose to employ the idea of curriculum learn-ing (cl) (bengio et al., 2009).
the key to applyingcl is to specify a proper learning scheme underwhich all training examples are learned.
by an-alyzing the characteristics of the concerned task,we tailor-design a hierarchical curriculum learn-ing (hcl) framework.
speciﬁcally, our learningframework consists of two complementary cur-riculum strategies, corpus-level curriculum (cc)and instance-level curriculum (ic), covering thetwo distinct aspects of response selection.
in cc,the model gradually increases its ability in ﬁndingmatching clues through an easy-to-difﬁcult arrange-ment of positive context-response pairs.
in ic, wesort all negative responses according to their dis-tracting strength such that the model’s capabilityof identifying the mismatching information can beprogressively strengthened..notably, our learning framework is independentto the choice of matching models.
for a compre-hensive evaluation, we evaluate our approach onthree representative matching models, includingthe current state of the art.
results on three bench-mark datasets demonstrate that the proposed learn-ing framework leads to remarkable performanceimprovements across all evaluation metrics..in a nutshell, our contributions can be summa-.
rized as: (1) we propose a hierarchical curriculumlearning framework to tackle the task of dialogueresponse selection; and (2) empirical results onthree benchmark datasets show that our approachcan signiﬁcantly improve the performance of vari-ous strong matching models, including the currentstate of the art..2 background.
given a dataset d = {(ci, ri)}|d|i=1, the learning ofa matching model s(·, ·) is to correctly identify thepositive response ri conditioned on the dialoguecontext ci from a set of negative responses r−i .
the learning objective is typically deﬁned as.
ls =.
max{0, 1 − s(ci, ri) + s(ci, r−.
ij)}, (1).
m(cid:88).
j=1.
where m is the number of negative responses as-sociated with each training context-response pair.
in most existing studies (wu et al., 2017; zhouet al., 2018; gu et al., 2019), the training nega-tive responses r−i are randomly selected from thedataset d. recently, li et al.
(2019) and lin et al.
(2020) proposed different approaches to strengthenthe training negatives.
in testing, for any context-response (c, r), the models give a score s(c, r) thatreﬂects their pairwise matching degree.
therefore,it allows the user to rank a set of response candi-dates according to the scores for response selection..3 methodology.
3.1 overview.
we propose a hierarchical curriculum learning(hcl) framework for training neural matchingmodels.
it consists of two complementary cur-ricula: (1) corpus-level curriculum (cc); and (2)instance-level curriculum (ic).
figure 1 illustratesthe relationship between these two strategies.
incc (§3.2), the training context-response pairs withlower difﬁculty are presented to the model beforeharder pairs.
this way, the model gradually in-creases its ability to ﬁnd the matching clues con-tained in the response candidate.
as for ic (§3.3),it controls the difﬁculty of negative responses thatassociated with each training context-response pair.
starting from easier negatives, the model progres-sively strengthens its ability to identify the mis-matching information (e.g., semantic incoherence)in the response candidate.
the following gives adetailed description of the proposed approach..1741figure 1: an illustration of the proposed learning framework: on the left part, two training context-response pairswith different difﬁculty levels are presented (the upper one is more difﬁcult than the lower one, and p denotesthe positive response).
for each training instance, we show three associated negative responses (n1, n2 and n3)with increasing difﬁculty from the bottom to the top.
in the negative responses, the words that also appear in thedialogue context are marked as italic..3.2 corpus-level curriculumgiven the dataset d = {(ci, ri)}|d|i=1, the corpus-level curriculum (cc) arranges the ordering of dif-ferent training context-response pairs.
the modelﬁrst learns to ﬁnd easier matching clues from thepairs with lower difﬁculty.
as the training pro-gresses, harder cases are presented to the model tolearn less obvious matching signals.
two examplesare shown in the left part of figure 1. for the easierpair, the context and the positive response are se-mantically coherent as well as lexically overlapped(e.g., tv series and game of thrones) with eachother and such matching clues are simple for themodel to learn.
as for the harder case, the posi-tive response can only be identiﬁed via numericalreasoning, which makes it harder to learn..difﬁculty function.
to measure the difﬁcultyof each training context-response pair (ci, ri), weadopt a pre-trained ranking model g(·, ·) (§3.4) tocalculate its relevance score as g(ci, ri).
here, ahigher score of g(ci, ri) corresponds to a higherrelevance between ci and ri and vice versa.
then,for each pair (ci, ri) ∈ d, its corpus-level difﬁcultydcc(ci, ri) is deﬁned as.
dcc(ci, ri) = 1.0 −.
g(ci, ri)max(ck,rk)∈d g(ck, rk).
,.
(2).
easier for the model to learn and vise versa..pacing function.
in training, to select the train-ing context-response pairs with appropriate difﬁ-culty, we deﬁne a corpus-level pacing function,pcc(t), which controls the pace of learning fromeasy to hard instances.
in other words, at time stept, pcc(t) represents the upper limit of difﬁculty andthe model is only allowed to use the training in-stances (ci, ri) whose corpus-level difﬁculty scoredcc(ci, ri) is lower than pcc(t).
in this work, wepropose a simple functional form for pcc(t)1 as.
pcc(t) =.
(cid:40) 1.0−pcc(0)t.1.0.
· t + pcc(0).
if t ≤ t,otherwise,.
where pcc(0) is a predeﬁned initial value.
at thetraining warm up stage (ﬁrst t steps), we learna basic matching model with a easy subset of thetraining data.
in this subset, the difﬁculty of all sam-ples are lower than pcc(t).
after pcc(t) becomes1.0 (at time step t ), the corpus-level curriculum iscompleted and the model can then freely access theentire dataset.
in figure 2(a), we give an illustra-tion of the corpus-level curriculum..3.3.instance-level curriculum.
as a complement of cc, the instance-level cur-riculum (ic) controls the difﬁculty of negative re-sponses.
for an arbitrary training context-response.
where dcc(ci, ri) is normalized to [0.0, 1.0].
here,a lower difﬁculty score indicates the pair (ci, ri) is.
1more sophisticated designs for the function pcc(t) are possi-ble, but we do not consider them in this work..1742figure 2: (a) illustration of the corpus-level curriculum.
at each step: (1) pcc(t) is computed based on the currentstep t; and (2) a batch of context-response pairs are uniformly sampled from the training instances whose corpus-level difﬁculty is lower than pcc(t) (shaded area in the example).
in this example, pcc(0) = 0.3 and t = 20000;(b) illustration of the instance-level pacing function.
in this example, k0 = log|d|.
10 = 6, kt = 3, and t = 20000..pair (ci, ri), while its associated negative responsescan be any responses rj (s.t.
j (cid:54)= i) in the trainingset, the difﬁculties of different rj are diverse.
someexamples are presented in the right part of figure 1.we see that the negative responses with lower dif-ﬁculty are always simple to spot as they are oftenobviously off the topic.
as for the harder negatives,the model need to identify the ﬁne-grained seman-tic incoherence between them and the context..the main purpose of ic is to select negative re-sponses with appropriate difﬁculty based on thestate of the learning process.
at the beginning, thenegative responses are randomly sampled from theentire training set, so that most of them are easyto distinguish.
as the training evolves, ic gradu-ally increases the difﬁculty of negative responsesby sampling them from the responses with higherdifﬁculty (i.e., from a harder subset of the trainingdata).
in this way, the model’s ability in ﬁnding themismatching information is progressively strength-ened and will be more robust when handling thosestrong distractors in real-world scenarios..difﬁculty function.
given a speciﬁc training in-stance (ci, ri), we deﬁne the difﬁculty of an arbi-trary response rj (s.t.
j (cid:54)= i) as its rank in a sortedlist of relevance score in descending order,.
dic(ci, rj) = sortrj ∈d,j(cid:54)=i(g(ci, rj))..(3).
in this formula, the response rh with the highestrelevance score, i.e., rh = maxrj ∈d,j(cid:54)=i g(ci, rj),has a rank of 1, thus dic(ci, rh) = 1. for theresponse rl with the lowest relevance score, i.e.,rl = minrj ∈d,j(cid:54)=i g(ci, rj), has a rank of |d|, thusdic(ci, rl) = |d|.
here, a smaller rank means thecorresponding negative response is more relevantto the context ci, thus it is more difﬁcult for themodel to distinguish..pacing function.
similar to cc, in ic, the paceof learning from easy to difﬁcult negative responsesis controlled by an instance-level pacing function,pic(t).
it adjusts the size of the sampling space (inlog scale) from which the negative responses aresampled from.
given a training instance (ci, ri),at time step t, the negative examples are sampledfrom the responses rj (s.t.
j (cid:54)= i) whose rank issmaller than 10pic(t) (dic(ci, rj) ≤ 10pic(t)), i.e.,the negative responses are sampled from a subset ofthe training data which consists of the top-10pic(t)relevant responses in relation to ci.
the smaller thepic(t) is, the harder the sampled negatives will be.
in this work, we deﬁne the function pic(t) as.
pic(t) =.
(cid:40) (k0−kt )t.kt.
· (t − t) + kt.
if t ≤ t,if t > t,.
where t is the same as the one in the corpus-levelpacing function pcc(t).
k0 = log|d|10 , meaning that,at the start of training, the negative responses aresampled from the entire training set d. kt is ahyperparameter and it is smaller than k0.
afterpic(t) becomes kt (at step t ), the instance-levelcurriculum is completed.
for the following trainingsteps, the size of the sampling space is ﬁxed at 10kt .
an example of pic(t) is depicted in figure 2(b)..3.4 hierarchical curriculum learning.
model training.
our learning framework jointlyemploys the corpus-level and instance-level cur-riculum.
for each training step, we construct abatch of training data as follows: first, we selectthe positive context-response pairs according to thecorpus-level pacing function pcc(t).
then, for eachinstance in the selected batch, we sample its asso-ciated negative examples according to the instance-.
1743input.
i=1; model trainer,.
algorithm 1: hierarchical curriculum learning:dataset, d = {(ci, ri)}|d|t , that takes batches of training data asinput to optimize the matching model;corpus-level difﬁculty and pacing function,dcc and pcc; instance-level difﬁculty andpacing function, dic and pic; number ofnegative responses, m;.
1 for train step t = 1, ... do2.uniformly sample one batch of context-response.
pairs, bt, from all (ci, ri) ∈ d, such thatdcc(ci, ri) ≤ pcc(t), as shown in figure 2(a)..3.
4.
5.
6.for (cj, rj) in bt do.
sample m negative responses, r−.
j , from all.
responses r, where r (cid:54)= rj, that satisﬁesthe condition dic(cj, r) ≤ 10pic(t)..endk )}|bt|invoke the trainer, t , using {(ck, rk, r−k=1as input to optimize the model using eq.
(1)..7 end.
output :trained matching model.
level pacing function pic(t).
details of our learningframework are presented in algorithm 1..fast ranking model.
as described in eq.
(2)and (3), our framework requires a ranking modelg(·, ·) that efﬁciently measures the pairwise rel-evance of millions of possible context-responsecombinations.
in this work, we construct g(·, ·)as an non-interaction matching model with dual-encoder structure such that we can precompute allcontexts and responses ofﬂine and store them incache.
for any context-response pair (c, r), its pair-wise relevance g(c, r) is deﬁned as.
g(c, r) = ec(c)t er(r),.
(4).
where ec(c) and er(r) are the dense context andresponse representations produced by a context en-coder ec(·) and a response encoder er(·)2..ofﬂine index.
after training the ranking modelon the same response selection dataset d usingthe in-batch negative objective (karpukhin et al.,2020), we compute the dense representations of allcontexts and responses contained in d. then, asdescribed in eq.
(4), the relevance scores of all pos-sible combinations of the contexts and responses ind can be easily computed through the dot productbetween their representations.
after this step, wecan compute the corpus-level and instance-leveldifﬁculty of all possible combinations and cachethem in memory for a fast access in training..4 related work.
dialogue response selection.
early studies inthis area devoted to the response selection forsingle-turn conversations (wang et al., 2013; tanet al., 2016; su et al., 2020).
recently, researchersturned to the scenario of multi-turn conversationsand many sophisticated neural network architec-tures have been devised (wu et al., 2017; gu et al.,2019; zhou et al., 2018; gu et al., 2020)..there is an emerging line of research studyinghow to improve existing matching models with bet-ter learning algorithms.
wu et al.
(2018) proposedto adopt a seq2seq model as weak teacher to guidethe training process.
feng et al.
(2019) designeda co-teaching framework to eliminate the trainingnoises.
similar to our work, li et al.
(2019) pro-posed to alleviate the problem of trivial negativesby sampling stronger negatives.
lin et al.
(2020)attempted to create negative examples with a re-trieval system and a pre-trained generation model.
in contrast to their studies, we not only enlargethe set of negative examples but also arrange thenegative examples in an easy-to-diffuclt fashion..curriculum learning.
curriculum learning(bengio et al., 2009) is reminiscent of the cognitiveprocess of human being.
its core idea is ﬁrst learn-ing easier concepts and then gradually transitioningto more complex concepts based on some prede-ﬁned learning schemes.
curriculum learning (cl)has demonstrated its beneﬁts in various machinelearning tasks (spitkovsky et al., 2010; ilg et al.,2017; li et al., 2017; svetlik et al., 2017; liu et al.,2018; platanios et al., 2019).
recently, penha andhauff (2020) employed the idea of cl to tacklethe response selection task.
however, they onlyapply curriculum learning for the positive-side re-sponse selection, while ignoring the diversity ofthe negative responses..5 experiment setups.
5.1 datasets and evaluation metrics.
we test our approach on three benchmark datasets..douban dataset.
this dataset (wu et al., 2017)consists of multi-turn chinese conversation datacrawled from douban group3.
the size of training,validation and test set are 500k, 25k and 1k.
inthe test set, each dialogue context is paired with10 candidate responses.
following previous works,.
2the encoders can be any model, e.g., lstm (hochreiter andschmidhuber, 1997) and transformers (vaswani et al., 2017)..3https://www.douban.com/group.
1744model.
rnncnnlstmbilstmmv-lstmmatch-lstmdl2rmulti-viewduadammrfnioismnmsnsa-bertsmn+hclmsn+hclsa-bert+hcl.
douban.
ubuntu.
e-commerce.
map mrr p@1 r10@1 r10@2 r10@5 r2@1 r10@1 r10@2 r10@5 r10@1 r10@2 r10@50.7750.3900.7920.4170.8280.4850.8250.4790.8570.4980.8580.5000.8420.4880.8610.5050.9210.5510.9330.550-0.5710.9500.5730.8860.5290.9370.5870.9850.6190.9350.5750.9680.6200.9930.639.
0.7680.8480.9010.8950.9060.9040.8990.908-0.9380.9450.9470.926-0.9650.9470.9690.977.
0.4220.4400.5270.5140.5380.5370.5270.5430.5990.6010.6170.6210.5690.6320.6590.6200.6680.681.
0.2080.2260.3200.3130.3480.3450.3300.3420.4210.4270.4480.4440.3970.4700.4960.4460.5070.514.
0.1180.1210.1870.1840.2020.2020.1930.2020.2430.2540.2760.2690.2330.2950.3130.2810.3210.330.
0.4030.5490.6380.6300.6530.6530.6260.6620.7520.7670.7860.7960.7260.8000.8550.7770.8260.867.
0.2230.2520.3430.3300.3510.3480.3420.3500.4210.4100.4350.4510.3960.4520.4810.4520.5080.531.
0.8190.8960.9490.9440.9460.9440.9440.9510.9620.9690.9760.9740.9610.9780.9830.9810.9890.992.
0.3250.3280.3650.3550.4120.4100.3990.4210.5010.526-0.5630.4530.6060.7040.5070.6420.721.
0.5890.6470.7200.7160.7100.7200.7050.7290.7800.7570.7830.7860.7240.7880.8470.8070.8410.858.
0.5470.6840.7840.7800.8040.7990.7830.8010.8680.8740.8860.8940.8470.8990.9280.8850.9240.940.
0.4630.5150.5360.5250.5910.5900.5710.6010.7000.727-0.7680.6540.7700.8790.7230.8140.896.table 2: experimental results of different models trained with our approach on douban, ubuntu, and e-commercedatasets.
all results acquired using hcl outperforms the original results with a signiﬁcance level p-value < 0.01..we report the results of mean average precision(map), mean reciprocal rank (mrr) and pre-cision at position 1 (p@1).
in addition, we alsoreport the results of r10@1, r10@2, r10@5, wherern@k means recall at position k in n candidates..ubuntu dataset.
this dataset (lowe et al., 2015)contains multi-turn dialogues collected from chatlogs of the ubuntu forum.
the training, valida-tion and test size are 500k, 50k and 50k.
eachdialogue context is paired with 10 response candi-dates.
following previous studies, we use r2@1,r10@1, r10@2 and r10@5 as evaluation metrics..e-commerce dataset.
this dataset(zhanget al., 2018) consists of chinese conversations be-tween customers and customer service staff fromtaobao4.
the size of training, validation and testset are 500k, 25k and 1k.
in the test set, each dia-logue context is paired with 10 candidate responses.
rn@k are employed as the evaluation metrics..5.2 baseline models.
in the experiments, we compare our approach withthe following models that can be summarized intothree categories..single-turn matching models.
this type ofmodels treats all dialogue context as a single longutterance and then measures the relevance scorebetween the context and response candidates, in-cluding rnn (lowe et al., 2015), cnn (loweet al., 2015), lstm (lowe et al., 2015), bi-lstm.
4www.taobao.com.
(kadlec et al., 2015), mv-lstm (wan et al., 2016)and match-lstm (wang and jiang, 2016)..multi-turn matching models.
instead of treat-ing the dialogue context as one single utterance,these models aggregate information from differentutterances in more sophisticated ways, includingdl2r (yan et al., 2016), multi-view (zhou et al.,2016), dua (zhang et al., 2018), dam (zhouet al., 2018), mrfn (tao et al., 2019a), ioi (taoet al., 2019b), smn (wu et al., 2017) and msn(yuan et al., 2019)..bert-based matching models.
given the re-cent advances of pre-trained language models (de-vlin et al., 2019), gu et al.
(2020) proposed thesa-bert model which adapts bert for the taskof response selection and it is the current state-of-the-art model on the douban and ubuntu dataset..5.3.implementation details.
for all experiments, we set the value of pcc(0)in the corpus-level pacing function pcc(t) as 0.3,meaning that all models start training with thecontext-response pairs whose corpus-level difﬁ-culty is lower than 0.3. for the instance-levelpacing function pic(t), the value of kt is set as3, meaning that, after ic is completed, the negativeresponses of each training instance are sampledfrom the top-103 relevant responses.
in the experi-ments, each matching model is trained for 40, 000steps with a batch size of 128, and we set the t inboth pcc(t) and pic(t) as half of the total trainingsteps, i.e., t = 20, 000. to build the context and.
1745cc ic.
smn.
msn.
sa-bert.
p@1 r10@1 r10@2 p@1 r10@1 r10@2 p@1 r10@1 r10@20.4930.2980.5110.3050.5240.3150.5310.321.
0.4620.4790.4920.508.
0.4990.5040.5110.514.
0.2380.2530.2710.281.
0.4740.4820.4990.507.
0.3150.3200.3250.330.
0.4100.4290.4440.452.
× 0.402× 0.422(cid:88) 0.441(cid:88) 0.446.
×(cid:88).
×(cid:88).
table 3: ablation study on douban dataset using different combinations of the proposed curriculum strategies..model.
strategy.
douban.
ubuntu.
smn.
msn.
sa-bert.
semicir‡grayhclsemi‡cir‡grayhclsemi‡cir‡gray‡hcl.
map mrr p@1 r10@1 r10@2 r2@1 r10@1 r10@2 r10@50.9670.5540.9630.5610.9690.5640.9810.5750.9830.5910.9850.5950.9870.5990.9890.6200.9890.6230.9900.6240.9910.6280.9920.639.
0.4250.4320.4430.4460.4730.4720.4760.5070.5000.5030.5030.514.
0.8650.8700.8730.8850.9030.9100.9110.9240.9310.9350.9340.940.
0.7620.7600.7650.7770.8040.8080.8120.8260.8580.8600.8610.867.
0.2530.2670.2710.2810.3010.3040.3080.3210.3170.3180.3200.330.
0.6050.6110.6150.6200.6380.6400.6450.6680.6640.6660.6700.681.
0.9340.9350.9380.9470.9520.9550.9580.9690.9680.9690.9700.977.
0.4120.4330.4390.4520.4610.4660.4680.5080.4900.4970.5030.531.table 4: comparisons on douban and ubuntu datasets using different training strategies on various models.
resultsmarked with ‡ are from our runs with their released code..response encoders in the ranking model g(·, ·), weuse a 3-layer transformers with a hidden size of256. we select two representative models (smnand msn) along with the state-of-the-art sa-bertto test the proposed learning framework.
to bettersimulate the true testing environment, the numberof negative responses (m in eq.
(1)) is set to be 5..6 result and analysis.
6.1 main results.
table 2 shows the results on douban, ubuntu, ande-commerce datasets, where x+hcl means train-ing the model x with the proposed learning hcl.
we can see that hcl signiﬁcantly improves theperformance of all three matching models in termsof all evaluation metrics, showing the robustnessand universality of our approach.
we also observethat, by training with hcl, a model (msn) with-out using pre-trained language model can even sur-pass the state-of-the-art model using pre-trainedlanguage model (sa-bert) on douban dataset.
these results suggest that, while the training strat-egy is under-explored in previous studies, it couldbe very decisive for building a competent responseselection model..6.2 effect of cc and ic.
to reveal the individual effects of cc and ic, wetrain different models on douban dataset by remov-.
ing either cc or ic.
the experimental results areshown in table 3, from which we see that both ccand ic make positive contributions to the overallperformance when used alone.
only utilizing icleads to larger improvements than only using cc.
this observation suggests that the ability of iden-tifying the mismatching information is a more im-portant factor for the model to achieve its optimalperformance.
however, the optimal performance isachieved when cc and ic are combined, indicatingthat cc and ic are complementary to each other..6.3 contrast to existing learning strategies.
next, we compare our approach with other learn-ing strategies proposed recently (li et al., 2019;penha and hauff, 2020; lin et al., 2020).
we usesemi, cir, and gray to denote the approaches in liet al.
(2019), penha and hauff (2020), and lin et al.
(2020) respectively, where gray is the current stateof the art.
we conduct experiments on douban andubuntu datasets and the experimental results ofthree matching models are listed in table 4. fromthe results, we can see that our approach consis-tently outperforms other learning strategies in allsettings.
the performance gains of our approachare even more remarkable given its simplicity; itdoes not require running additional generation mod-els (lin et al., 2020) or re-scoring negative samplesat different epochs (li et al., 2019)..1746ranking model.
transformers.
bilstm.
bert-base.
modelranking modelsmnmsnsa-bertranking modelsmnmsnsa-bertranking modelsmnmsnsa-bert.
p@1 r10@1 r10@20.4160.2530.4000.2810.4520.4460.5080.5070.3210.3300.5140.5310.3930.2270.3770.4410.2730.4380.4870.3130.4910.5130.3230.5070.4430.2750.4370.4570.4510.2790.3230.5070.5070.5350.3290.511.table 5: comparisons of different ranking model ar-chitectures.
best results of each matching model arebold-faced.
the “ranking model” rows represent theperformances of different ranking models..a too small or too large kt results in performancedegradation.
when kt is too small, after ic iscompleted, the negative examples are only sampledfrom a very small subset of the training data thatconsists of responses with high relevance.
in thiscase, the sampled responses might be false nega-tives that should be deemed as positive cases.
thus,learning to treat those responses as true negativescould harm the model performance.
on the otherhand, as kt increases, the effect of ic becomesless obvious.
when kt = log500k(|d|= 500k),ic is completely disabled, leading to the furtherdecrease of model performances..10.ranking model architecture.
lastly, we exam-ine the effect of the choice of the ranking modelarchitecture.
we build two ranking model variantsby replacing the transformers module ec(·) ander(·) in eq.
(4) with other modules.
for the ﬁrstcase, we use 3-layer bilstm with a hidden sizeof 256. for the second one, we use bert-base(devlin et al., 2019) model.
then, we train thematching models using the proposed hcl but withdifferent ranking models as the scoring basis..the results on douban dataset are shown in ta-ble 5. we ﬁrst compare the performance of differ-ent ranking models by directly using them to selectthe best response.
the results are shown in the“ranking model” row of table 5. among all threevariants, bert performs the best but it is still lessaccurate than these sophisticated matching models.
second, we study the effect of different rankingmodels on the matching model performance.
wesee that, for different matching models, transform-ers and bert perform comparably but the resultsfrom bilstm are much worse.
this further leadsto a conclusion that, while the choice of ranking.
figure 3: plots illustrating the effect of curriculumhyper-parameters, (a) pcc(0) and (b) kt , on the smnmodel performance in douban dataset..6.4 further analysis on hcl.
in this part, we study how the key hyper-parametersaffect the performance of hcl, including the initialdifﬁculty of cc, pcc(0), and the curriculum lengthof ic, kt .5 in addition, we also investigate theeffect of different ranking model choices..initial difﬁculty of cc.
we run sensitivity anal-ysis experiments on douban dataset with the smnmodel by tuning pcc(0) in the corpus-level pacingfunction pcc(t).
the results of p@1 and r10@2in terms of pcc(0) and kt are shown in figure3(a).
we observe that when pcc(0) is small (i.e.,pcc(0) ≤ 0.3), the model performances are rela-tively similar.
when pcc(0) approaches to 1.0, theresults drop signiﬁcantly.
it concurs with our expec-tation that, in cc, the model should start learningwith training context-response pairs of lower difﬁ-culty.
once pcc(0) becomes 1.0, the cc is disabled,resulting the lowest model performances..curriculum length of ic.
similair to pcc(0),we also run sensitivity analysis experiments by tun-ing kt in the instance-level pacing function pic(t)and figure 3(b) shows the results.
we observe that.
5our experiments show that other hyper-parameter settingshave little impact on the model performance..1747model does have impact on the overall results, theimprovement of the ranking model does not neces-sarily lead to the improvement of matching modelsonce the ranking model achieves certain accuracy..7 conclusion.
in this work, we propose a novel hierarchical cur-riculum learning framework for training responseselection models for multi-turn conversations.
dur-ing training, the proposed framework simultane-ously employs corpus-level and instance-level cur-ricula to dynamically select suitable training databased on the state of the learning process.
exten-sive experiments and analysis on two benchmarkdatasets show that our approach can signiﬁcantlyimprove the performance of various strong match-ing models on all evaluation metrics..acknowledgments.
the authors wish to thank jialu xu and sihui wangfor their insightful discussions and support.
manythanks to our anonymous reviewers for their sug-gestions and comments..ethical statement.
we honor and support the acl code of ethics.
di-alogue response selection aims to build a retrieval-based dialogue system which better interacts withusers.
the selection of the best response does notinvolve any bias towards to the participants.
alldatasets used in this work are from previously pub-lished works, and in our view, do not have anyattached privacy or ethical issues..references.
yoshua bengio, j´erˆome louradour, ronan collobert,and jason weston.
2009. curriculum learning.
inproceedings of the 26th annual international con-ference on machine learning, icml 2009, mon-treal, quebec, canada, june 14-18, 2009, pages 41–48..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, naacl-hlt 2019, minneapolis, mn,usa, june 2-7, 2019, volume 1 (long and short pa-pers), pages 4171–4186.
association for computa-tional linguistics..jeffrey l. elman.
1990. finding structure in time..cogn.
sci., 14(2):179–211..jiazhan feng, chongyang tao, wei wu, yansong feng,dongyan zhao, and rui yan.
2019. learning amatching model with co-teaching for multi-turn re-sponse selection in retrieval-based dialogue systems.
in proceedings of the 57th conference of the as-sociation for computational linguistics, acl 2019,florence, italy, july 28- august 2, 2019, volume1: long papers, pages 3805–3815.
association forcomputational linguistics..jia-chen gu, tianda li, quan liu, zhen-hua ling,zhiming su, si wei, and xiaodan zhu.
2020.speaker-aware bert for multi-turn response selec-tion in retrieval-based chatbots.
in cikm ’20: the29th acm international conference on informationand knowledge management, virtual event, ireland,october 19-23, 2020, pages 2041–2044.
acm..jia-chen gu, zhen-hua ling, and quan liu.
2019. in-teractive matching network for multi-turn responseselection in retrieval-based chatbots.
in proceedingsof the 28th acm international conference on infor-mation and knowledge management, cikm 2019,beijing, china, november 3-7, 2019, pages 2321–2324..sepp hochreiter and j¨urgen schmidhuber.
1997. longshort-term memory.
neural comput., 9(8):1735–1780..eddy ilg, nikolaus mayer, tonmoy saikia, margret ke-uper, alexey dosovitskiy, and thomas brox.
2017.flownet 2.0: evolution of optical ﬂow estimationwith deep networks.
in 2017 ieee conference oncomputer vision and pattern recognition, cvpr2017, honolulu, hi, usa, july 21-26, 2017, pages1647–1655.
ieee computer society..rudolf kadlec, martin schmid, and jan kleindienst.
2015. improved deep learning baselines for ubuntucorpus dialogs.
corr, abs/1510.03753..vladimir karpukhin, barlas oguz, sewon min, patricks. h. lewis, ledell wu, sergey edunov, danqichen, and wen-tau yih.
2020. dense passage re-trieval for open-domain question answering.
in pro-ceedings of the 2020 conference on empirical meth-ods in natural language processing, emnlp 2020,online, november 16-20, 2020, pages 6769–6781.
association for computational linguistics..diederik p. kingma and jimmy ba.
2015. adam: ain 3rd inter-method for stochastic optimization.
national conference on learning representations,iclr 2015, san diego, ca, usa, may 7-9, 2015,conference track proceedings..thomas kollar, danielle berry, lauren stuart,karolina owczarzak, tagyoung chung, lambertmathias, michael kayser, bradford snow, and spy-ros matsoukas.
2018. the alexa meaning represen-tation language.
in proceedings of the 2018 confer-.
1748ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, naacl-hlt 2018, new or-leans, louisiana, usa, june 1-6, 2018, volume 3(industry papers), pages 177–184..jia li, chongyang tao, wei wu, yansong feng,dongyan zhao, and rui yan.
2019. sampling mat-ters!
an empirical study of negative sampling strate-gies for learning of matching models in retrieval-in proceedings of thebased dialogue systems.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 1291–1296, hong kong,china.
association for computational linguistics..siyang li, xiangxin zhu, qin huang, hao xu, andc.-c. jay kuo.
2017. multiple instance curricu-lum learning for weakly supervised object detection.
in british machine vision conference 2017, bmvc2017, london, uk, september 4-7, 2017. bmvapress..zibo lin, deng cai, yan wang, xiaojiang liu, hai-tao zheng, and shuming shi.
2020. the world isnot binary: learning to rank with grayscale data fordialogue response selection..cao liu, shizhu he, kang liu, and jun zhao.
2018.curriculum learning for natural answer generation.
in proceedings of the twenty-seventh internationaljoint conference on artiﬁcial intelligence, ijcai2018, july 13-19, 2018, stockholm, sweden, pages4223–4229.
ijcai.org..ryan lowe, nissan pow, iulian serban, and joellepineau.
2015. the ubuntu dialogue corpus: a largedataset for research in unstructured multi-turn dia-logue systems.
in proceedings of the sigdial 2015conference, the 16th annual meeting of the spe-cial interest group on discourse and dialogue, 2-4 september 2015, prague, czech republic, pages285–294.
the association for computer linguis-tics..junyu lu, chenbin zhang, zeying xie, guang ling,tom chao zhou, and zenglin xu.
2019. construct-ing interpretive spatio-temporal features for multi-turn responses selection.
in proceedings of the 57thconference of the association for computationallinguistics, acl 2019, florence, italy, july 28- au-gust 2, 2019, volume 1: long papers, pages 44–50..gustavo penha and claudia hauff.
2020. curriculumin advances in infor-learning strategies for ir.
mation retrieval - 42nd european conference onir research, ecir 2020, lisbon, portugal, april14-17, 2020, proceedings, part i, volume 12035 oflecture notes in computer science, pages 699–713.
springer..emmanouil antonios platanios, otilia stretcu, grahamneubig, barnab´as p´oczos, and tom m. mitchell.
2019. competence-based curriculum learning for.
in proceedings of theneural machine translation.
2019 conference of the north american chapterof the association for computational linguistics:human language technologies, naacl-hlt 2019,minneapolis, mn, usa, june 2-7, 2019, volume 1(long and short papers), pages 1162–1172.
associ-ation for computational linguistics..alan ritter, colin cherry, and william b. dolan.
2011.data-driven response generation in social media.
inproceedings of the 2011 conference on empiricalmethods in natural language processing, emnlp2011, 27-31 july 2011, john mcintyre conferencecentre, edinburgh, uk, a meeting of sigdat, a spe-cial interest group of the acl, pages 583–593..heung-yeung shum, xiaodong he, and di li.
2018.from eliza to xiaoice: challenges and opportunitieswith social chatbots.
corr, abs/1801.01957..valentin i. spitkovsky, hiyan alshawi, and daniel ju-rafsky.
2010. from baby steps to leapfrog: how”less is more” in unsupervised dependency parsing.
in human language technologies: conference ofthe north american chapter of the association ofcomputational linguistics, proceedings, june 2-4,2010, los angeles, california, usa, pages 751–759.
the association for computational linguistics..yixuan su, yan wang, simon baker, deng cai, xi-aojiang liu, anna korhonen, and nigel collier.
2020. prototype-to-style: dialogue generation withstyle-aware editing on retrieval memory.
corr,abs/2004.02214..maxwell svetlik, matteo leonetti, jivko sinapov, rishishah, nick walker, and peter stone.
2017. au-tomatic curriculum graph generation for reinforce-ment learning agents.
in proceedings of the thirty-first aaai conference on artiﬁcial intelligence,february 4-9, 2017, san francisco, california, usa,pages 2590–2596.
aaai press..ming tan, cicero dos santos, bing xiang, and bowenzhou.
2016. lstm-based deep learning models fornon-factoid answer selection..chongyang tao, wei wu, can xu, wenpeng hu,dongyan zhao, and rui yan.
2019a.
multi-representation fusion network for multi-turn re-sponse selection in retrieval-based chatbots.
in pro-ceedings of the twelfth acm international con-ference on web search and data mining, page267–275, new york, ny, usa.
association forcomputing machinery..chongyang tao, wei wu, can xu, wenpeng hu,dongyan zhao, and rui yan.
2019b.
one time ofinteraction may not be enough: go deep with aninteraction-over-interaction network for response se-lection in dialogues.
in proceedings of the 57th con-ference of the association for computational lin-guistics, acl 2019, florence, italy, july 28- august2, 2019, volume 1: long papers, pages 1–11..1749natural language processing and the 9th interna-tional joint conference on natural language pro-cessing, emnlp-ijcnlp 2019, hong kong, china,november 3-7, 2019, pages 111–120.
associationfor computational linguistics..zhuosheng zhang, jiangtong li, pengfei zhu, haizhao, and gongshen liu.
2018. modeling multi-turn conversation with deep utterance aggregation.
in proceedings of the 27th international conferenceon computational linguistics, coling 2018, santafe, new mexico, usa, august 20-26, 2018, pages3740–3752.
association for computational linguis-tics..xiangyang zhou, daxiang dong, hua wu, shiqi zhao,dianhai yu, hao tian, xuan liu, and rui yan.
2016. multi-view response selection for human-computer conversation.
in proceedings of the 2016conference on empirical methods in natural lan-guage processing, emnlp 2016, austin, texas,usa, november 1-4, 2016, pages 372–381.
the as-sociation for computational linguistics..xiangyang zhou, lu li, daxiang dong, yi liu, yingchen, wayne xin zhao, dianhai yu, and hua wu.
2018. multi-turn response selection for chatbotswith deep attention matching network.
in proceed-ings of the 56th annual meeting of the associa-tion for computational linguistics, acl 2018, mel-bourne, australia, july 15-20, 2018, volume 1: longpapers, pages 1118–1127..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n. gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in advances in neural information pro-cessing systems 30: annual conference on neuralinformation processing systems 2017, 4-9 decem-ber 2017, long beach, ca, usa, pages 5998–6008..shengxian wan, yanyan lan, jun xu, jiafeng guo,liang pang, and xueqi cheng.
2016. match-srnn:modeling the recursive matching structure with spa-tial rnn.
in proceedings of the twenty-fifth inter-national joint conference on artiﬁcial intelligence,ijcai 2016, new york, ny, usa, 9-15 july 2016,pages 2922–2928.
ijcai/aaai press..hao wang, zhengdong lu, hang li, and enhong chen.
2013. a dataset for research on short-text conversa-in proceedings of the 2013 conference ontions.
empirical methods in natural language process-ing, emnlp 2013, 18-21 october 2013, grand hy-att seattle, seattle, washington, usa, a meeting ofsigdat, a special interest group of the acl, pages935–945.
acl..shuohang wang and jing jiang.
2016. learning natu-ral language inference with lstm.
in naacl hlt2016, the 2016 conference of the north americanchapter of the association for computational lin-guistics: human language technologies, san diegocalifornia, usa, june 12-17, 2016, pages 1442–1451. the association for computational linguis-tics..yu wu, wei wu, zhoujun li, and ming zhou.
2018.learning matching models with weak supervisionfor response selection in retrieval-based chatbots.
inproceedings of the 56th annual meeting of the as-sociation for computational linguistics, acl 2018,melbourne, australia, july 15-20, 2018, volume 2:short papers, pages 420–425..yu wu, wei wu, chen xing, ming zhou, and zhou-jun li.
2017.sequential matching network: anew architecture for multi-turn response selectionin proceedings of thein retrieval-based chatbots.
55th annual meeting of the association for compu-tational linguistics, acl 2017, vancouver, canada,july 30 - august 4, volume 1: long papers, pages496–505..rui yan, yiping song, and hua wu.
2016. learningto respond with deep neural networks for retrieval-based human-computer conversation system.
in pro-ceedings of the 39th international acm sigir con-ference on research and development in informa-tion retrieval, sigir 2016, pisa, italy, july 17-21,2016, pages 55–64.
acm..chunyuan yuan, wei zhou, mingming li, shangwenlv, fuqing zhu, jizhong han, and songlin hu.
2019.multi-hop selector network for multi-turn responseselection in retrieval-based chatbots.
in proceedingsof the 2019 conference on empirical methods in.
1750optimizer (kingma and ba, 2015) with a learningrate of 2e-5.
for more details, we refer the readersto the original paper (karpukhin et al., 2020)..b hyper-parameter setup.
in the following, we provide details on the searchspace for the hyperparameters.
for number of neg-ative responses m in eq.
(1), the search space is{1, 5, 10, 15, 20}, where the underline indicatesthe number selected based on the model perfor-mance on the validation set.
the search space forthe pcc(0) in corpus-level pacing function pcc(t) is{0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}.
forthe kt in instance-level pacing function pic(t), thesearch space is {1, 2, 3, 4, 5, log500k10 }, where 500kis the size of the training set..each matching model is optimized with adamoptimizer (kingma and ba, 2015) with a learningrate of 2e-5 and a batch size of 128. the totaltraining step is set as 40, 000. t in the corpus-level pacing fucntion pcc(t) and the instance-levelpacing function pic(t) is set as the half of the totaltraining steps (i.e., t = 20000)..a ranking model training.
here we provide more details on how to train theneural ranking model g(·, ·) that serves as the scor-ing basis in the proposed hcl framework..modelling.
given a dialogue context c and a re-sponse r, their context-response relevance score isdeﬁned as.
g(c, r) = ec(c)t er(r)..(5).
note that, the context c is a long sequence whichis acquired by concatenating all utterances in thedialogue context.
the ec(c) and er(r) are thecontext and response encoder.
the context encoderec(·) takes the token sequence c = c0, ..., c|c| andreturns the context representation ec(c) by takingthe output state corresponds to the last token c|c|.
the same operation is applied when computingthe response representation er(r).
in practice, thechoice of e(·) could be any sequence model, e.g.,lstm (hochreiter and schmidhuber, 1997), rnn(elman, 1990), transformers (vaswani et al., 2017),and bert (devlin et al., 2019).
in this work, wechoose transformers as our modelling basis..learning.
the goal of training the rankingmodel is to create a vector space such that simi-lar pair of dialogue contexts and responses havehigher relevance score than the dissimilar ones..we train the ranking model with the same re-sponse selection data set d using the in-batch neg-ative objective (karpukhin et al., 2020).
for a sam-pled batch of training data {(ck, rk)}bk=1, whereb is the batch size, the sampled contexts and re-sponses are separately encoded using eq.
(4) asec(c) ∈ rb×n and er(r) ∈ rb×n, where n is theoutput size of encoder modules.
next, the scorematrix s is computed as ec(c)t er(r) ∈ rb×b.
the in-batch negative objective (karpukhin et al.,2020) is then deﬁned as minimizing the negativelog likelihood of positive responses.
lg = −.
log.
1b.b(cid:88).
i=1.
exp(sii).
exp(sii) + (cid:80).
j(cid:54)=i exp(sij).
,.
(6).
where sij = g(ci, rj)..in this work, we build the context and responseencoder with a 3-layer transformers and its outputsize is 256. for all considered datasets, we pre-trainthe ranking model with a batch size b = 128 for20, 000 steps.
for optimization, we use the adam.
1751