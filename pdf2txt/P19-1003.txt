improving multi-turn dialogue modelling with utterance rewriter.
hui su1∗, xiaoyu shen2∗, rongzhi zhang3, fei sun4, pengwei hu5cheng niu1 and jie zhou11pattern recognition center, wechat ai, tencent inc, china2mpi informatics & spoken language systems (lsv), saarland informatics campus3institute of software, university of chinese academy of science.
4alibaba group.
5ibm research, china.
aaronsu@tencent.com,xshen@mpi-inf.mpg.de.
abstract.
recent research has made impressive progressin single-turn dialogue modelling.
in themulti-turn setting, however, current models arestill far from satisfactory.
one major chal-lenge is the frequently occurred coreferenceand information omission in our daily con-versation, making it hard for machines to un-derstand the real intention.
in this paper, wepropose rewriting the human utterance as apre-process to help multi-turn dialgoue mod-elling.
each utterance is ﬁrst rewritten to re-cover all coreferred and omitted information.
the next processing steps are then performedbased on the rewritten utterance.
to properlytrain the utterance rewriter, we collect a newdataset with human annotations and introducea transformer-based utterance rewriting archi-tecture using the pointer network.
we showthe proposed architecture achieves remarkablygood performance on the utterance rewritingtask.
the trained utterance rewriter can be eas-ily integrated into online chatbots and bringsgeneral improvement over different domains.1.
1.introduction.
dialogue systems have made dramatic progress inrecent years, especially in single-turn chit-chat andfaq matching (shang et al., 2015; ghazvinine-jad et al., 2018; molino et al., 2018; chen et al.,2019).
nonethless, multi-turn dialogue modellingstill remains extremely challenging (vinyals andle, 2015; serban et al., 2016, 2017; shen et al.,2018a,b).
the challenge is multi-sided.
onemost important difﬁculty is the frequently oc-curred coreference and information omission inour daily conversations, especially in pro-droplanguages like chinese or japanese.
from our pre-liminary study of 2,000 chinese multi-turn con-.
∗both authors contributed equally.
1the code is available on https://github.com/.
chin-gyou/dialogue-utterance-rewriter..utterance 1(translation)utterance 2.utterance 3.context 1human: 梅西有多高？human: how tall is messi?
chatbot: 官方说法他的身高是5英尺7英寸。chatbot: ofﬁcially he is 5ft 7 inches.
human: 他和c罗谁是最好的球员？human: who is the best, he or c.ronaldo?.
utterance 3(cid:48) human: 梅西和c罗谁是最好的球员？.
utterance 1.utterance 2.utterance 3.human: who is the best, messi or c.ronaldo?
context 2human: 你最喜欢什么电影？human: what movie do you like most?
chatbot: 泰坦尼克。chatbot: titanic.
human: 为什么呢？human: why?.
utterance 3(cid:48) human: 为什么最喜欢泰坦尼克？.
human: why do you like titanic most?.
table 1: an example of multi-turn dialogue.
each ut-terance 3 is rewritten into utterance 3(cid:48).
green meanscoreference and blue means omission..versations, different degrees of coreference andomission exist in more than 70% of the utterances.
capturing the hidden intention beneath them re-quires deeper understanding of the dialogue con-text, which is difﬁcult for current neural network-based systems.
table 1 shows two typical exam-ples in multi-turn dialogues.
“他”(he) from con-text 1 is a coreference to “梅西”(messi) and “为什么”(why) from context 2 omits the further ques-tion of “为什么最喜欢泰坦尼克”(why do youlike tatanic most)?.
without expanding the coref-erence or omission to recover the full information,the chatbot has no idea how to continue the talk..to address this concern, we propose simplifyingthe multi-turn dialogue modelling into a single-turn problem by rewriting the current utterance.
the utterance rewriter is expected to perform (1)coreference resolution and (2) information com-pletion to recover all coreferred and omitted men-tions.
in the two examples from table 1, each ut-terance 3 will be rewritten into utterance 3(cid:48).
af-terwards, the system will generate a reply by onlylooking into the utterance 3(cid:48) without consideringthe previous turns utterance 1 and 2. this sim-pliﬁcation shortens the length of dialogue con-.
proceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages22–31florence,italy,july28-august2,2019.c(cid:13)2019associationforcomputationallinguistics22text while still maintaining necessary informationneeded to provide proper responses, which we be-lieve will help ease the difﬁculty of multi-turn di-alogue modelling.
compared with other methodslike memory networks (sukhbaatar et al., 2015) orexplicit belief tracking (mrkˇsi´c et al., 2017), thetrained utterance rewriter is model-agnostic andcan be easily integrated into other black-box dia-logue systems.
it is also more memory-efﬁcientbecause the dialogue history information is re-ﬂected in a single rewritten utterance..to get supervised training data for the utterancerewriting, we construct a chinese dialogue datasetcontaining 20k multi-turn dialogues.
each utter-ance is paired with corresponding manually anno-tated rewritings.
we model this problem as an ex-tractive generation problem using the pointer net-work (vinyals et al., 2015).
the rewritten utter-ance is generated by copying words from either thedialogue history or the current utterance based onthe attention mechanism (bahdanau et al., 2014).
inspired by the recently proposed transformerarchitecture (vaswani et al., 2017) in machinetranslation which can capture better intra-sentenceword dependencies, we modify the transformerarchitecture to include the pointer network mech-anism.
the resulting model outperforms the re-current neural network (rnn) and original trans-former models, achieving an f1 score of over 0.85for both the coreference resolution and informa-tion completion.
furthermore, we integrate ourtrained utterance rewriter into two online chatbotplatforms and ﬁnd it leads to more accurate inten-tion detection and improves the user engagement.
in summary, our contributions are:.
1. we collect a high-quality annotated datasetfor coreference resolution and informationcompletion in multi-turn dialogues, whichmight beneﬁt future related research..2. we propose a highly effective transformer-based utterance rewriter outperforming sev-eral strong baselines..3. the trained utterance rewriter, when inte-grated into two real-life online chatbots, isshown to bring signiﬁcant improvement overthe original system..in the next section, we will ﬁrst go over some re-lated work.
afterwards, in section 3 and 4, ourcollected dataset and proposed model are intro-duced.
the experiment results and analysis are.
presented in section 5. finally, some conclusionsare drawn in section 6..2 related work.
2.1 sentence rewriting.
sentence rewriting has been widely adopted invarious nlp tasks.
in machine translation, peoplehave used it to reﬁne the output generations fromseq2seq models (niehues et al., 2016; junczys-dowmunt and grundkiewicz, 2017; grangier andauli, 2017; gu et al., 2017).
in text summariza-tion, reediting the retrieved candidates can providemore accurate and abstractive summaries (seeet al., 2017; chen and bansal, 2018; cao et al.,2018).
in dialogue modelling, weston et al.
(2018)applied it to rewrite outputs from a retrieval model,but they pay no attention to recovering the hiddeninformation under the coreference and omission.
concurrent with our work, rastogi et al.
(2019)adopts a similar idea on english conversations tosimplify the downstream slu task by reformulat-ing the original utterance.
rewriting the sourceinput into some easy-to-process standard formathas also gained signiﬁcant improvements in in-formation retrieval (riezler and liu, 2010), se-mantic parsing (chen et al., 2016) or question an-swering (abujabal et al., 2018), but most of themadopt a simple dictionary or template based rewrit-ing strategy.
for multi-turn dialogues, due to thecomplexity of human languages, designing suit-able template-based rewriting rules would be time-consuming..2.2 coreference resolution.
coreference resolution aims to link an antecedentfor each possible mention.
traditional approachesoften adopt a pipeline structure which ﬁrst iden-tify all pronouns and entities then run clusteringalgorithms (haghighi and klein, 2009; lee et al.,2011; durrett and klein, 2013; bj¨orkelund andat both stages, they rely heav-kuhn, 2014).
ily on complicated, ﬁne-grained features.
re-cently, several neural coreference resolution sys-tems (clark and manning, 2016a,b) utilize dis-tributed representations to reduce human labors.
lee et al.
(2017) reported state-of-the-art resultswith an end-to-end neural coreference resolutionsystem.
however, it requires computing the scoresfor all possible spans, which is computationallyinefﬁcient on online dialogue systems.
the re-cently proposed transformer adopted the self-.
23attention mechanism which could implicitly cap-ture inter-word dependencies in an unsupervisedway (vaswani et al., 2017).
however, when mul-tiple coreferences occur, it has problems properlydistinguishing them.
our proposed architecture isbuilt upon the transformer architecture, but per-form coreference resolution in a supervised settingto help deal with ambiguous mentions..3 dataset.
to get paralleltraining data for the sentencerewriting, we crawled 200k candidate multi-turnconversational data from several popular chinesesocial media platforms for human annotators towork on.
sensitive information is ﬁltered be-forehand for later processing.
before starting theannotation, we randomly sample 2,000 conversa-tional data and analyze how often coreference andomission occurs in multi-turn dialogues.
table 2lists the statistics.
as can be seen, only less than30% utterances have neither coreference nor omis-sion and quite a few utterances have both.
thisfurther validates the importance of addressing thethese situations in multi-turn dialogues..% rate.
coreferenceomissionneither.
33.552.429.7.table 2: proportion of utterances containing corefer-ence and omission in multi-turn conversation.
in the annotation process, human annotatorsneed to identify these two situations then rewritethe utterance to cover all hidden information.
anexample is shown in table 1. annotators are re-quired to provide the rewritten utterance 3(cid:48) giventhe original conversation [utterance 1,2 and 3].
toensure the annotation quality, 10% of the annota-tions from each annotator are daily examined by aproject manager and feedbacks are provided.
theannotation is considered valid only when the ac-curacy of examined results surpasses 95%.
apartfrom the accuracy examination, the project man-age is also required to (1) select topics that aremore likely to be talked about in daily conversa-tions, (2) try to cover broader domains and (3) bal-ance the proportion of different coreference andomission patterns.
the whole annotation takes 4in the end, we get 40k high-months to ﬁnish..quality parallel samples.
half of them are nega-tive samples which do not need any rewriting.
theother half are positive samples where rewriting isneeded.
table 3 lists the statistics.
the rewrittenutterance contains 10.5 tokens in average, reduc-ing the context length by 80%..dataset size:avg.
length of original conversation:avg.
length of rewritten utterance:.
40,00048.810.5.table 3: statistics of dataset.
length is counted in theunit of chinese characters..4 model.
4.1 problem formalization.
we denote each training sample as (h, un → r).
h = {u1, u2, .
.
.
, un−1} represents the dialoguehistory containing the ﬁrst n − 1 turn of utter-ances.
un is the nth turn of utterance, the onethat needs to be rewritten.
r is the rewritten ut-terance after recovering all corefernced and omit-ted information in un.
r could be identical to unif no coreference or omission is detected (nega-tive sample).
our goal is to learn a mapping func-tion p(r|(h, un)) that can automatically rewriteun based on the history information h. the pro-cess is to ﬁrst encode (h, un) into s sequence ofvectors, then decode r using the pointer network.
the next section will explain the steps in order..4.2 encoder.
in.
all.
unfold.
(h, un).
intotokenswe(w1, w2, .
.
.
, wm).
m is the number of to-kens in the whole dialogue.
an end-of-turndelimiter is inserted between each two turns.
theunfolded sequence of tokens are then encodedwith transformer.
we concatenate all tokens in(h, un) as the input, in hope that the transformercan learn rudimentary coreference informationwithin them by means of the self-attention mech-anism.
for each token wi, the input embeddingis the sum of its word embedding, positionembedding and turn embedding:.
i(wi) = w e(wi) + p e(wi) + t e(wi).
the word embedding w e(wi) and position em-bedding p e(wi) are the same as in normal trans-former architectures (vaswani et al., 2017).
we.
24figure 1: architecture of our proposed model.
green box is the transformer encoder and pink box is the decoder.
the decoder computes the probability λ at each step to decide whether to copy from the context or utterance..add an additional turn embedding t e(wi) to in-dicate which turn each token belongs to.
to-kens from the same turn will share the same turnembedding.
the input embeddings are then for-warded into l stacked encoders to get the ﬁnalencoding representations.
each encoder containsa self-attention layer followed by a feedforwardneural network.
:(cid:104)i(w1), i(w2), .
.
.
, i(wm).
e(0) =.
(cid:105).
e(l) = fnn(multihead(e(l−1), e(l−1), e(l−1))).
fnn is the feedforward neural network andmultihead(q, k, v) is a multi-head attentionfunction taking a query matrix q, a key matrix k,and a value matrix v as inputs.
each self-attentionand feedforward component comes with a residualconnection and layer-normalization step, whichwe refer to vaswani et al.
(2017) for more details.
the ﬁnal encodings are the output from the lthencoder e(l)..4.3 decoder.
the decoder also contains l layers, each layer iscomposed of three sub-layers.
the ﬁrst sub-layeris a multi-head self-attention:.
ml = multihead(d(l−1), d(l−1), d(l−1)).
d(0) = r. the second sub-layer is encoder-decoder attention that integrates e(l) into the de-coder.
in our task, as h and un serve different pur-poses, we use separate key-value matrix for tokens.
coming from the dialogue history h and thosecoming from un.
the encoded sequence e(l) ob-tained from the last section is split into e(l)h (en-codings of tokens from h) and e(l)(encodingsunof tokens from un) then processed separately.
theencoder-decoder vectors are computed as follows:.
c(h)l = multihead(m(l), e(l)c(un)l = multihead(m(l), e(l)un.
h , e(l)h ), e(l))un.
the third sub-layer is a position-wise fully con-nected feed-forward neural network:.
d(l) = fnn([c(h)l ◦ c(un)l]).
where ◦ denotes vector concatenation..4.4 output distribution.
in the decoding process, we hope our model couldlearn whether to copy words from h or un atdifferent steps.
therefore, we impose a soft gat-ing weight λ to make the decision.
the decodingprobability is computed by combining the atten-.
25tion distribution from the last decoding layer:.
p(rt=w|h, un, r<t)=λ.
(cid:88).
at,i.
i:(wi=w)∧(wi∈h)(cid:88).
a(cid:48)t,jj:(wj =w)∧(wj ∈un).
+(1−λ).
a = attention(m(l), e(l))una(cid:48) = attention(m(l), e(l)h )u c(un)lt + w(cid:62)d dlt.h c(h)l.t + w(cid:62).
(cid:1).
λ = σ(cid:0)w(cid:62).
a and a(cid:48) are the attention distribution over tokensin h and un respectively.
wd, wh , and wu areparameters to be learned, σ is the sigmoid func-tion to output a value between 0 and 1. the gat-ing weight λ works like a sentinel to inform thedecoder whether to extract information from thedialogue history h or directly copy from un.
ifun contains neither coreference nor informationomission.
λ would be always 1 to copy the origi-nal un as the output.
otherwise λ becomes 0 whena coreference or omission is detected.
the atten-tion mechanism is then responsible of ﬁnding theproper coreferred or omitted information from thedialogue history.
the whole model is trained end-to-end by maximizing p(r|h, un)..5 experiments.
to perform the utterancewe train our modelin thisrewriting task on our collected dataset.
section, we focus on answering the following twoquestions: (1) how accurately our proposed modelcan perform coreference resolution and informa-tion completion respectively and (2) how goodthe trained utterance rewriter is at helping off-the-shelf dialogue systems provide more appropriateresponses.
to answer the ﬁrst question, we com-pare our models with several strong baselines andtest them by both automatic evaluation and hu-man judgement.
for the second question, we in-tegrate our rewriting model to two online dialoguesystems and analyze how it affects the human-computer interactions.
the following section willﬁrst introduce the compared models and basic set-tings, then report our evaluation results..5.1 compared models.
when choosing compared models, we are mainlycurious to see (1) whether the self-attention basedtransformer architecture is superior to other net-works like lstms, (2) whether the pointer-based.
generator is better than pure generation-basedmodels and (3) whether it is preferred to split theattention by a coefﬁcient λ as in our model.
withthese intentions, we implement the following fourtypes of models for comparison:.
1.
(l/t)-gen: pure generation-based model.
words are generated from a ﬁxed vocabulary..2.
(l/t)-ptr-net: pure pointer-based model asin vinyals et al.
(2015).
words can only becopied from the input..3.
(l/t)-ptr-gen: hybrid pointer+generationmodel as in see et al.
(2017).
words canbe either copied from the input or generatedfrom a ﬁxed vocabulary..4.
(l/t)-ptr-λ: our proposed model which.
split the attention by a coefﬁcient λ..(l/t) denotes the encoder-decoder structure is thelstm or transformer.
for the ﬁrst three typesof models, we unfold all tokens from the dialogueas the input.
no difference is made between thedialogue history and the utterance to be rewritten..5.2 experiment settings.
transformer-based models we set the hiddensize as 512. the attention has 8 individual headsand the encoder/decoder have 6 individual stackedlayers.
models are optimized with the adam opti-mizer.
the initial learning rate is 0.0001 and batchsize is 64. all hyperparameters are tuned base onthe performance on the validation data..lstm-based models we encode words with asingle-layer bidirectional lstm and decode witha uni-directional lstm.
we use 128-dimensionalword embeddings and 256-dimensional hiddenstates for both the encoder and decoder.2 thebatch size is set as 128. models are trained usingadagrad with learning rate 0.15 and initial accu-mulator value 0.1, same as in see et al.
(2017)..general setup we built our vocabulary basedon character-based segmentation for chineselike fre-for non-chinese characters,scripts.
quently mentioned entity names “kobe” and“nba”, we split them by space and keep allunique tokens which appear more than twice.
theresulting vocabulary size is 5629 (4813 chinese.
2we tried increasing the dimension but ﬁnd it degrades.
the performance..26bleu-1 bleu-2 bleu-4 rouge-1 rouge-2 rouge-l.em.
l-genl-ptr-genl-ptr-netl-ptr-λ.
t-gent-ptr-gent-ptr-nett-ptr-λ.
65.4969.7871.7072.26.
68.7470.6775.1077.85.
55.3859.2560.2962.15.
59.0962.8066.8968.21.
38.6943.0744.7247.11.
42.5745.1748.1152.47.
65.5768.2470.8173.47.
69.1273.9676.1078.49.
48.5754.1356.3557.51.
50.9253.1458.5160.53.
66.3870.3672.3374.55.
69.7072.0775.5477.70.
47.14|80.1847.35|84.0948.24|91.9451.66|93.01.
48.59|87.6149.86|89.6253.30|94.7155.84|98.14.
table 4: bleu, rouge (f1), and em scores on the test set.
em score is split into the results on the positive (left)and negative (right) test samples.
the ﬁrst half is lstm-based models and the second half is transformer-based.
bold denotes best results..characters and 816 other tokens), including theend-of-turn delimiter and a special unk token forall unknown words.
in the testing stage, all mod-els decode words by beam search with beam sizeset to 4..5.3 quality of sentence rewriting.
lee et al.
(2017).
l-genl-ptr-genl-ptr-netl-ptr-λ.
t-gent-ptr-gent-ptr-nett-ptr-λ.
precision recall.
f1.
0.82.
0.760.810.830.85.
0.800.850.880.93.
0.78.
0.660.760.780.82.
0.750.810.870.90.
0.80.
0.710.780.810.83.
0.770.830.880.92.table 5: precision, recall and f1 score of corefer-ence resolution.
first row is the current state-of-the-artcoreference resolution model.
accuracy of generation we ﬁrst evaluate theaccuracy of generation leveraging three metrics:bleu, rouge, and the exact match score(em)(the percentage of decoded sequences that exactlymatch the human references).
for the em score,we report separately on the positive and negativesamples to see the difference.
we report bleu-1,2, 4 scores and the f1 scores of rouge-1, 2, l.the results are listed in table 4. we can have sev-eral observations in response to the three questionsproposed in the beginning of section 5.1:.
1. transformer-based models lead to signif-.
improvement compare with lstm-icantbased counterparts.
this implies the self-attention mechanism is helpful in identifyingcoreferred and omitted information.
moreanalysis on how it helps coreference resolu-tion can be seen in the next section..2. the generation mode does not work well inour setting since all words can be retrievedfrom either h or un.
pointer-based mod-els outperform the more complex generation-based and hybrid ones..3. separately processing h and un then com-bine their attention with a learned λ performsbetter than treating the whole dialogue tokensas s single input, though the improvement isless signiﬁcant compared with previous twomentions..overall our proposed model achieves remarkablygood performance, with 55.84% of its genera-tions exactly matches the human reference onthe positive samples.
for negative samples, ourmodel properly copied the the original utterancesin 98.14% of the cases.
it suggests our model isalready able to identify the utterances that do notneed rewriting.
future work should work on im-proving the rewriting ability on positive samples..coreference resolution apart from the stan-dard metrics for text generation, we speciﬁcallytest the precision, recall and f1 score of coref-erence resolution on our task.
a pronoun or anoun is considered as properly coreferred if therewritten utterance contains the correct mention inthe corresponding referent.
the result is shownin table 5. to compare with current state-of-the-.
27ground truth 你喜欢罗密欧与朱丽叶哪个角色.
u1: 你看莎士比亚吗 u2: 特别喜欢罗密欧与朱丽叶history(translation) u1: do you read shakespeare u2: i especially like romeo and juliet.
u3:喜欢哪个角色u3: which character do you like.
which character do you like in romeo and juliet你喜欢莎士比亚吗 // do you like shakespeare你喜欢罗密欧角色角色 // you like romeo character character你喜欢罗密欧与朱丽叶 // you like romeo and juliet你喜欢罗密欧与朱丽叶角色 // you like romeo and juliet character你喜欢罗密欧与朱丽叶 // you like romeo and juliet你喜欢罗密欧与朱丽叶哪个 // which do you like in romeo and juliet你喜欢罗密欧与朱丽叶角色 // character you like romeo and juliet你你你喜喜喜欢欢欢罗罗罗密密密欧欧欧与与与朱朱朱丽丽丽叶叶叶哪哪哪个个个角角角色色色 // which character do you like romeo and juliet 什什什么么么时时时候候候开开开始始始玩玩玩英英英雄雄雄联联联盟盟盟的的的 // when did you start to play league of legends.
u1: 你玩英雄联盟吗 u2: 是的u1: do you play league of legends u2: yes.
u3: 什么时候开始的u3: when did it start什么时候开始玩英雄联盟的when did you start to play league of legends什么时候开始开始开始 // when start start start什么时候开始的 // when did it start什么时候英雄联盟开始的 // when did league of legends start什什什么么么时时时候候候开开开始始始玩玩玩英英英雄雄雄联联联盟盟盟的的的 // when did you start to play league of legends是的什么时候开始玩的 // yes when start to play什么时候开始的 // when did it start英雄联盟什么时候开始玩的 // league of legends when did you start to play.
utterance.
l-genl-ptr-genl-ptr-netl-ptr-λt-gent-ptr-gent-ptr-nett-ptr-λ.
table 6: examples of rewritten utterances.
highlighted utterances are exactly the same as the ground truth..model.
recall.
precision.
f1.
fluency.
l-genl-ptr-genl-ptr-netl-ptr-λ.
t-gent-ptr-gent-ptr-nett-ptr-λ.
human.
0.650.700.780.80.
0.710.770.820.85.
-.
0.700.740.810.82.
0.740.810.840.87.
-.
0.670.720.790.81.
0.730.790.830.86.
-.
4.314.524.744.82.
4.744.854.874.90.
4.97.table 7: recall, precision, f1 score on informationcompletion and human evaluation results on ﬂuency..information completion similar as corefer-ence resolution, we evaluate the quality of infor-mation completeness separately.
one omitted in-formation is considered as properly completed ifthe rewritten utterance recovers the omitted words.
since it inserts new words to the original utter-ance, we further conduct a human evaluation tomeasure the ﬂuency of rewritten utterances.
werandomly sample 600 samples from our positivetest set.
three participants were asked to judgewhether the rewritten utterance is a ﬂuent sentencewith the score 1(not ﬂuent)-5(ﬂuent).
the ﬂuencyscore for each model is averaged over all humanevaluated scores..the results are shown in table 7. basicallythe condition is similar as in table 5. t-ptr-λachieves the best performance, with the f1 scoreof 0.86. the performance is slightly worse thancoreference resolution since information omissionis more implicit.
retrieving all hidden informa-tion is sometimes difﬁcult even for humans.
more-over, the ﬂuency of our model’s generations isvery good, only slightly worse than the human ref-erence (4.90 vs 4.97).
information completenessdoes not have much effects on the ﬂuency.
exam-.
figure 2: visualization of the self-attention weightsin transformer.
“他”(he) is properly aligned to “梅西”(messi)..art models.
we train the model from lee et al.
(2017) on our task and report the results on the ﬁrstrow.
the result is quite consistent with the ﬁnd-ings from the last section.
our ﬁnal model outper-forms the others by a large margin, reaching a pre-cision score of 93% and recall score of 90%.
it im-plies our model is already quite good at ﬁnding theproper coreference.
future challenges would bemore about information completion.
figure 2 fur-ther provides an examples of how the transformercan help implicitly learn the coreference resolu-tion through the self-attention mechanism.
thesame example is also shown in table 1. the pro-noun “他”(he) in the utterance is properly alignedto the mention “梅西”(messi) in the dialogue his-tory, also partially to “球员”(player) which is theoccupation of him.
the implicitly learned coref-erence relation should be part of the reason thattransformers outperform lstm models on thecoreference resolution task..28u1: 北京天气怎么样 u2: 天气晴朗，温度适宜u1: how is the weather in beijing u2: the weather is ﬁne and the temperature is suitableu3: 那穿什么衣服合适u3: then what clothes are suitable to wear u3: what clothes are suitable for weather in beijing城市天气生活购物city weatherlife shopping根据天气推荐穿一件外套you’d better wear a coat according to the weather.
what type of clothes do you want to buy.
u3: 北京天气穿什么合适.
chatbot answer 您想要购买什么类型的衣服.
task-oriented chatbot.
context(translation)utterance.
intention.
chit-chat chatbot.
context.
utterance.
u1: 库里的三分真准啊 u2: 勇士今年又是冠军u1: curry’s 3-pointer is really good u2: the warriors are the champion again this yearu3: 我也觉得u3: i agreechatbot answer 觉得什么agree what.
u3: 我也觉得勇士今年又是冠军u3: i agree that the warriors are the champion again this year勇士真的厉害啊the warriors are so strong.
table 8: examples of integrated test.
left column is the original system and right is the one with utterance rewriter.
blue words denote completed information by the utterance rewriter..model.
intention precision cps.
originalwith rewrite.
80.7789.91.
6.37.7.intentiontable 9: results of integrated testing.
precision for task-oriented and conversation-turns-per-session (cps) for chitchat..ples of rewritten utterances are shown in table 6..5.4.integration testing.
in this section, we study how the proposed utter-ance rewriter can be integrated into off-the-shelfonline chatbots to improve the quality of gener-ated responses.
we use our best model t-ptr-λ torewrite each utterance based on the dialogue con-text.
the rewritten utterance is then forwarded tothe system for response generation.
we apply onboth a task-oriented and chitchat setting.
the re-sults are compared with the original system havingno utterance rewriter..task-oriented our task-oriented dialogue sys-tem contains an intention classiﬁer built on fast-text(bojanowski et al., 2017) and a set of tem-plates that perform policy decision and slot-valueﬁlling sequentially.
intention detection is a mostimportant component in task-oriented dialoguesand its accuracy will affect all the following steps.
we deﬁne 30 intention classes like weather, ho-tel booking and shopping.
the training data con-tains 35,447 human annotations.
with the combi-nation of our rewriter, the intention classier is able.
to achieve a precision of 89.91%, outperformingthe original system by over 9%.
the improved in-tention classiﬁcation further lead to better conver-sations.
an example is shown in table 8, a multi-turn conversation about the weather.
the user ﬁrstasks “how is the weather in beijing”, then followswith a further question about “then what clothesare suitable to wear”.
the original system wronglyclassiﬁed the user intention as shopping since thisis a common conversational pattern in shopping.
in contrast, our utterance rewriter is able to re-cover the omitted information “under the weatherin beijing”.
based on the rewritten utterance, theclassiﬁer is able to correctly detect the intentionand provide proper responses..chitchat our social chatbot contains two sep-arate engines for multi-turn and single-turn dia-logues.
each engine is a hybrid retrieval and gen-eration model.
in real-life applications, a userquery would be simultaneously distributed to thesetwo engines.
the returned candidate responsesare then reranked to provide the ﬁnal response.
generally the model is already able to providerather high-quality responses under the single-turncondition, but under multi-turn conversations, thecomplex context dependency makes the genera-tion difﬁcult.
we integrate our utterance rewriterinto the single-turn engine and compare with theoriginal model by conducting the online a/b test.
speciﬁcally, we randomly split the users into twogroups.
one talks with the original system and theother talks with the system integrated with the ut-terance rewriter.
all users are unconscious of the.
29details about our system.
the whole test lastedone month.
table 9 shows the conversation-turnsper session (cps), which is the average num-ber of conversation-turns between the chatbot andthe user in a session.
the utterance rewriter in-creases the average cps from 6.3 to 7.7, indicat-ing the user is more engaged with the integratedmodel.
table 8 shows an example of how the ut-terance rewriter helps with the generation.
afterthe rewriting, the model can better understand thedialogue is about the nba team warriors, but theoriginal model feels confused and only provides ageneric response..6 conclusion.
in this paper, we propose improving multi-turn di-alogue modelling by imposing a separate utterancerewriter.
the rewriter is trained to recover thecoreferred and omitted information of user utter-ances.
we collect a high-quality manually anno-tated dataset and designed a transformer-pointerbased architecture to train the utterance rewriter.
the trained utterance rewriter performs remark-ably well and, when integrated into two onlinechatbot applications, signiﬁcantly improves the in-tention detection and user engagement.
we hopethe collected dataset and proposed model can ben-eﬁt future related research..acknowledgments.
we thank all anonymous reviewers and the dia-logue system team of wechat ai for valuable com-ments.
xiaoyu shen is supported by imprs-csfellowship..references.
abdalghani abujabal, rishiraj saha roy, mohamedyahya, and gerhard weikum.
2018. never-endinglearning for open-domain question answering overknowledge bases.
in proceedings of the 2018 worldwide web conference on world wide web, pages1053–1062.
international world wide web confer-ences steering committee..dzmitry bahdanau, kyunghyun cho, and yoshua ben-gio.
2014. neural machine translation by jointlyarxiv preprintlearning to align and translate.
arxiv:1409.0473..anders bj¨orkelund and jonas kuhn.
2014. learn-ing structured perceptrons for coreference resolutioninwith latent antecedents and non-local features..proceedings of the 52nd annual meeting of the as-sociation for computational linguistics (volume 1:long papers), volume 1, pages 47–57..piotr bojanowski, edouard grave, armand joulin, andtomas mikolov.
2017. enriching word vectors withsubword information.
transactions of the associa-tion for computational linguistics, 5:135–146..ziqiang cao, wenjie li, sujian li, and furu wei.
2018. retrieve, rerank and rewrite: soft templatebased neural summarization.
in proceedings of the56th annual meeting of the association for compu-tational linguistics (volume 1: long papers), vol-ume 1, pages 152–161..bo chen, le sun, xianpei han, and bo an.
2016.sentence rewriting for semantic parsing.
corr,abs/1901.02998..shiqian chen, chenliang li, feng ji, wei zhou, andhaiqing chen.
2019. driven answer generation forin pro-product-related questions in e-commerce.
ceedings of the twelfth acm international confer-ence on web search and data mining, pages 411–419. acm..yen-chun chen and mohit bansal.
2018. fast abstrac-tive summarization with reinforce-selected sentencerewriting.
arxiv preprint arxiv:1805.11080..kevin clark and christopher d manning.
2016a.
deepreinforcement learning for mention-ranking corefer-ence models.
arxiv preprint arxiv:1609.08667..kevin clark and christopher d manning.
2016b.
im-proving coreference resolution by learning entity-arxiv preprintlevel distributed representations.
arxiv:1606.01323..greg durrett and dan klein.
2013. easy victories anduphill battles in coreference resolution.
in proceed-ings of the 2013 conference on empirical methodsin natural language processing, pages 1971–1982..marjan ghazvininejad, chris brockett, ming-weichang, bill dolan, jianfeng gao, wen-tau yih, andmichel galley.
2018. a knowledge-grounded neuralconversation model.
in thirty-second aaai confer-ence on artiﬁcial intelligence..david grangier and michael auli.
2017. quickedit:editing text & translations via simple delete actions.
arxiv preprint arxiv:1711.04805..jiatao gu, yong wang, kyunghyun cho, and vic-search engine guided non-arxiv.
tor ok li.
2017.parametric neural machine translation.
preprint arxiv:1705.07267..aria haghighi and dan klein.
2009. simple corefer-ence resolution with rich syntactic and semantic fea-in proceedings of the 2009 conference ontures.
empirical methods in natural language process-ing: volume 3-volume 3, pages 1152–1161.
asso-ciation for computational linguistics..30xiaoyu shen, hui su, wenjie li, and dietrich klakow.
2018a.
nexus network: connecting the precedingin pro-and the following in dialogue generation.
ceedings of the 2018 conference on empirical meth-ods in natural language processing, pages 4316–4327..xiaoyu shen, hui su, shuzi niu, and vera demberg.
improving variational encoder-decoders inin thirty-second aaai con-.
2018b.
dialogue generation.
ference on artiﬁcial intelligence..sainbayar sukhbaatar, jason weston, rob fergus, et al.
2015. end-to-end memory networks.
in advancesin neural information processing systems, pages2440–2448..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in advances in neural information pro-cessing systems, pages 5998–6008..oriol vinyals, meire fortunato, and navdeep jaitly.
2015. pointer networks.
in advances in neural in-formation processing systems, pages 2692–2700..oriol vinyals and quoc le.
2015. a neural conversa-tional model.
arxiv preprint arxiv:1506.05869..jason weston, emily dinan, and alexander miller.
2018. retrieve and reﬁne: improved sequence gen-eration models for dialogue.
in proceedings of the2018 emnlp workshop scai: the 2nd interna-tional workshop on search-oriented conversationalai, pages 87–92..marcin junczys-dowmunt and roman grundkiewicz.
an exploration of neural sequence-to-2017.sequence architectures for automatic post-editing.
arxiv preprint arxiv:1706.04138..heeyoung lee, yves peirsman, angel chang,nathanael chambers, mihai surdeanu, and dan ju-rafsky.
2011. stanford’s multi-pass sieve corefer-ence resolution system at the conll-2011 shared task.
in proceedings of the ﬁfteenth conference on com-putational natural language learning: shared task,pages 28–34.
association for computational lin-guistics..kenton lee, luheng he, mike lewis, and luke zettle-moyer.
2017. end-to-end neural coreference resolu-tion.
arxiv preprint arxiv:1707.07045..piero molino, huaixiu zheng, and yi-chia wang.
improving the speed and accuracy2018. cota:of customer support through ranking and deep net-in proceedings of the 24th acm sigkddworks.
international conference on knowledge discovery& data mining, pages 586–595.
acm..nikola mrkˇsi´c, diarmuid ´o s´eaghdha, tsung-hsienwen, blaise thomson, and steve young.
2017.neural belief tracker: data-driven dialogue statetracking.
in proceedings of the 55th annual meet-ing of the association for computational linguistics(volume 1: long papers), pages 1777–1788..jan niehues, eunah cho, thanh-le ha, and alexwaibel.
2016. pre-translation for neural machinetranslation.
arxiv preprint arxiv:1610.05243..pushpendre rastogi, arpit gupta, tongfei chen, andscaling multi-domainlambert mathias.
2019.dialogue state tracking via query reformulation.
naacl..stefan riezler and yi liu.
2010. query rewriting usingmonolingual statistical machine translation.
com-putational linguistics, 36(3):569–582..abigail see, peter j liu, and christopher d man-to the point: summarizationarxiv preprint.
ning.
2017. getwith pointer-generator networks.
arxiv:1704.04368..iulian v serban, alessandro sordoni, yoshua bengio,aaron courville, and joelle pineau.
2016. buildingend-to-end dialogue systems using generative hier-archical neural network models.
aaai..iulian vlad serban, alessandro sordoni, ryan lowe,laurent charlin, joelle pineau, aaron courville,and yoshua bengio.
2017. a hierarchical latentvariable encoder-decoder model for generating di-alogues.
aaai..lifeng shang, zhengdong lu, and hang li.
2015.neural responding machine for short-text conversa-tion.
arxiv preprint arxiv:1503.02364..31