few-shot text ranking with meta adapted synthetic weak supervisionsi sun1, yingzhuo qian2, zhenghao liu2, chenyan xiong3,kaitao zhang2, jie bao1, zhiyuan liu2, paul bennett31department of electronic engineering, tsinghua university, beijing, china2department of computer science and technology, tsinghua university, beijing, chinainstitute for artiï¬cial intelligence, tsinghua university, beijing, chinabeijing national research center for information science and technology, china3microsoft research, redmond, usa{s-sun17, qyz17, liu-zh16, zkt18}@mails.tsinghua.edu.cn{bao, liuzy}@tsinghua.edu.cn{chenyan.xiong, paul.n.bennett}@microsoft.com.
abstract.
the effectiveness of neural information re-trieval (neu-ir) often depends on a large scaleof in-domain relevance training signals, whichare not always available in real-world rankingscenarios.
to democratize the beneï¬ts of neu-ir, this paper presents metaadaptrank, a do-main adaptive learning method that general-izes neu-ir models from label-rich source do-mains to few-shot target domains.
drawing onsource-domain massive relevance supervision,metaadaptrank contrastively synthesizes alarge number of weak supervision signals fortarget domains and meta-learns to reweightthese synthetic â€œweakâ€ data based on their ben-eï¬ts to the target-domain ranking accuracy ofneu-ir models.
experiments on three trecbenchmarks in the web, news, and biomed-ical domains show that metaadaptrank sig-niï¬cantly improves the few-shot ranking accu-racy of neu-ir models.
further analyses in-dicate that metaadaptrank thrives from bothits contrastive weak data synthesis and meta-reweighted data selection.
the code and dataof this paper can be obtained from https://github.com/thunlp/metaadaptrank..1.introduction.
text retrieval aims to rank documents to either di-rectly satisfy usersâ€™ search needs or ï¬nd textualinformation for later processing components, e.g.,question answering (chen et al., 2017) and factveriï¬cation (liu et al., 2020).
neural informationretrieval (neu-ir) models have recently shown ad-vanced results in many ranking scenarios wheremassive relevance labels or clickthrough data areavailable (mitra et al., 2018; craswell et al., 2020).
the ï¬‚ip side is that the â€œdata-hungryâ€ nature ofneu-ir models yields mixed results in few-shotranking scenarios that suffer from the shortage oflabeled data and implicit user feedback (lin, 2019;yang et al., 2019).
on ranking benchmarks with.
only hundreds of labeled queries, there have beendebates about whether neu-ir, even with billionsof pre-trained parameters (zhang et al., 2020a), re-ally outperforms traditional ir techniques such asfeature-based models and latent semantic index-ing (yang et al., 2019; roberts et al., 2020).
infact, many real-world ranking scenarios are few-shot, e.g., tail web queries that innately lack largesupervision (downey et al., 2007), applicationswith strong privacy constraints like personal andenterprise search (chirita et al., 2005; hawking,2004), and domains where labeling requires pro-fessional expertise such as biomedical and legalsearch (roberts et al., 2020; arora et al., 2018)..to broaden the beneï¬ts of neu-ir to few-shotscenarios, we present an adaptive learning methodmetaadaptrank that meta-learns to adapt neu-irmodels to target domains with synthetic weak su-pervision.
for synthesizing weak supervision, wetake inspiration from the work (ma et al., 2021) thatgenerates related queries for unlabeled documentsin a zero-shot way, but we generate discriminativequeries based on contrastive pairs of relevant (posi-tive) and irrelevant (negative) documents.
by intro-ducing the negative contrast, metaadaptrank cansubtly capture the difference between documentsto synthesize more ranking-aware weak supervi-sion signals.
given that synthetic weak supervisioninevitably contains noises, metaadaptrank meta-learns to reweight these synthetic weak data andtrains neu-ir models to achieve the best accuracyon a small volume of target data.
in this way, neuralrankers can distinguish more useful synthetic weaksupervision based on the similarity of the gradientdirections of synthetic data and target data (renet al., 2018) instead of manual heuristics or trial-and-error data selection (zhang et al., 2020b)..we conduct experiments on three trec bench-marks, clueweb09, robust04, and trec-covid,which come from the web, news, and biomedi-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5030â€“5043august1â€“6,2021.Â©2021associationforcomputationallinguistics5030cal domains, respectively.
metaadaptrank signiï¬-cantly improves the few-shot ranking accuracy ofneu-ir models across all benchmarks.
we alsoempirically indicate that both contrastive weakdata synthesis and meta-reweighted data selec-tion contribute to metaadaptrankâ€™s effectiveness.
compared to prior work (ma et al., 2021; zhanget al., 2020b), metaadaptrank not only synthe-sizes more informative queries and effective weakrelevance signals but customizes more diverse andï¬ne-grained weights on synthetic weak data to bet-ter adapt neural rankers to target few-shot domains..2 related work.
recent neu-ir methods have achieved promisingresults in modeling relevance matching patterns be-tween queries and documents (guo et al., 2016; huiet al., 2017; mitra et al., 2018).
they have been ex-tensively employed in ad-hoc text retrieval (xionget al., 2017b; dai et al., 2018; nogueira and cho,2019; xiong et al., 2021) and later natural languageprocessing (nlp) tasks (lee et al., 2019; liu et al.,2020; qu et al., 2020)..the effectiveness of neu-ir methods heavilyrelies on the end-to-end training with a large num-ber of relevance supervision signals, e.g., relevancelabels or user clicks.
nevertheless, such supervi-sion signals are often insufï¬cient in many rankingscenarios.
the less availability of relevance super-vision pushes some neu-ir methods to freeze theirembeddings to avoid overï¬tting (yates et al., 2020).
the powerful deep pre-trained language models,such as bert (devlin et al., 2019), also do noteffectively alleviate the dependence of neu-ir ona large scale of relevance training signals.
recentresearch even observes that bert-based neuralrankers might require more training data than shal-low neural ranking models (hofstÂ¨atter et al., 2020;craswell et al., 2020).
moreover, they may often beoverly conï¬dent and more unstable in the learningprocess (qiao et al., 2019)..a promising direction to alleviate the depen-dence of neu-ir models on large-scale relevancesupervision is to leverage weak supervision signalsthat are noisy but available at mass quantity (zhenget al., 2019b; dehghani et al., 2017; yu et al.,2020).
through ir history, various weak supervi-sion sources have been used to approximate query-document relevance signals, e.g., pseudo relevancelabels generated by unsupervised retrieval meth-ods (dehghani et al., 2017; zheng et al., 2019b),.
and title-document pairs (macavaney et al., 2019).
recently, zhang et al.
(2020b) treat paired anchortexts and linked pages as weak relevance signalsand propose a reinforcement-based data selectionmethod reinfoselect, which learns to ï¬lter noisyanchor signals with trial-and-error policy gradients.
despite their convincing results, anchor signals areonly available in web domains.
directly applyingthem to non-web domains may suffer from subopti-mal outcomes due to domain gaps.
to obtain weaksupervision that adapts arbitrary domains, ma et al.
(2021) present a synthetic query generation method,which can be trained with source-domain relevancesignals and applied on target-domain documents togenerate related queries..more recently, a novel meta-learning techniquehas shown encouraging progress on solving datanoises and label biases in computer vision (renet al., 2018; shu et al., 2019; zheng et al., 2019a)and some nlp tasks (zheng et al., 2019a; wanget al., 2020b).
to the best of our knowledge, thisnovel technique has not been well utilized in infor-mation retrieval and synthetic supervision settings..3 methodology.
this section ï¬rst recaps the preliminary of neu-irand then introduces our proposed metaadaptrank.
the framework of our method is shown in figure 1..3.1 preliminary of neu-ir.
the ad-hoc retrieval task is to calculate a rankingscore f (q, d; Î¸) for a query q and a document dfrom a document set.
in neu-ir, the ranking scoref (Â·; Î¸) is calculated by a neural model, e.g., bert,with parameters Î¸. the query q and the documentd are encoded to the token-level representations h:.
h = bert([cls] â—¦ q â—¦ [sep] â—¦ d â—¦ [sep]),.
(1).
where â—¦ represents the concatenation operation.
[cls] and [sep] are special tokens.
the ï¬rst token(â€œ[cls]â€) representation h0 is regarded as the rep-resentation of the q-d pair.
then the ranking scoref (q, d; Î¸) of the pair can be calculated as:.
f (q, d; Î¸) = tanh(linear(h0))..(2).
the standard learning to rank loss li(Î¸) (liu,2009), e.g., pairwise loss, can be used to optimizethe neural model with relevance supervision signals{(qi, d+.
i ), 1 â‰¤ i â‰¤ m }:.
i , dâˆ’.
li(Î¸) = relu(1 âˆ’ (f (qi, d+.
i ; Î¸) âˆ’ f (qi, dâˆ’.
i ; Î¸))),.
(3).
5031figure 1: the illustration of metaadaptrank, which ï¬rst synthesizes massive weak supervision signals for targetdomains, and then meta-learns to reweight these synthetic data based on small target-domain relevance labels..i and dâˆ’.
where d+i denote the relevant (positive)and irrelevant (negative) documents of the query qi.
in few-shot ranking scenarios, the number of rele-vance supervision signals (m ) is limited, makingit difï¬cult to train an accurate neu-ir model..to mitigate the few-shot challenge in neu-ir,metaadaptrank ï¬rst transfers source-domain su-pervision signals to target-domain weak supervi-sion signals (sec 3.2); then meta-learns to reweightthe synthetic weak supervision (sec 3.3) for selec-tively training neu-ir models (sec 3.4)..3.2 contrastive synthetic supervision.
metaadaptrank transfers the relevance supervi-sion signals from source domains to few-shot targetdomains in a zero-shot way.
in this way, a naturallanguage generation (nlg) model is trained onsource domain relevance signals (source-domainnlg training) and is employed in target domainsto synthesize weak supervision signals (target-domain nlg inference).
we will ï¬rst recap theprevious synthetic method (ma et al., 2021) andthen introduce our contrastive synthetic approach.
preliminary of synthetic supervision.
givena large volume of source-domain relevance pairs(q, d+), previous synthetic method (ma et al., 2021)trains a nlg model such as t5 (raffel et al., 2020)that learns to generate a query q based on its rele-vant document d+:.
q = t5-nlg([pos] â—¦ d+ â—¦ [sep]),.
(4).
where [pos] and [sep] are special tokens.
in infer-ence, the trained query generator is directly usedto generate new queries qâˆ— for target-domain docu-ments dâˆ—, where dâˆ— is regarded as the related (posi-.
tive) document of qâˆ—, while the unrelated (negative)document can be sampled from the target corpus.
despite some promising results, the vanilla train-ing strategy may cause the nlg model to prefer togenerate broad and general queries that are likelyrelated to a crowd of documents in the target corpus.
as a consequence, the synthetic relevance super-vision does not have enough ranking awareness totrain robust neu-ir models..source-domain nlg training.
to synthesizeranking-aware weak supervision, metaadaptranktrains the nlg model to capture the differencebetween the contrastive document pair (d+, dâˆ’)and generate a discriminative query q:.
q = t5-nlg([pos] â—¦ d+ â—¦ [neg] â—¦ dâˆ’ â—¦ [sep]),.
(5).
where [neg] is another special token.
the traininginstances (q, d+, dâˆ’) can be obtained from sourcedomains in which d+ and dâˆ’ are annotated as therelevant and irrelevant documents for the query q.target-domain nlg inference.
during infer-ence, we ï¬rst pick out a mass of confusable docu-ment pairs from target domains and then feed theminto our trained contrastive query generator (eq.
5)to synthesize more valuable weak supervision data.
to get confusable document pairs, we ï¬rst gen-erate a seed query qâˆ— for each target-domain docu-ment dâˆ— using the trained query generator (eq.
4).
then the seed query is used to retrieve a subset ofdocuments with bm25, where other retrieval meth-ods can also be utilized.
the confusable documentpairs (d+(cid:48), dâˆ’(cid:48)) are pairwise sampled from the re-trieved subset without considering their rankings.
given the confusable document pair, we leverageour trained contrastive query generator to generate.
5032!ğ’˜ğ’‹ğ’ğ’‹#ğŸğ’â€²ğ’‹ğœ½ğ’•neural rankerğœ½ğ’•target domainsynthetic signalstarget domainfew-shot labelsneural rankerğœ½$ğ’•&ğŸ(ğ’˜)ğ’˜ğ’‹ğ’‹#ğŸğ’initial weightsweighted loss!ğŸğ’ğ’ğ’Š#ğŸğ’ğ’Š(ğœ½$ğ’•&ğŸ(ğ’˜))average lossoptimal weightsmeta-forward updatemeta-backward updatetrainingğ’’ğ’‹â€™ğ’…ğ’‹#â€™ğ’…ğ’‹$â€™source domainrelevance signalst5-nlginferencesamplingtarget domain documentsâ€¦contrast doc pairmeta-reweightedsynthetic signalsğ’˜ğ’‹âˆ—ğ’‹#ğŸğ’ğ’…ğ’‹"â€™ğ’…ğ’‹#â€™a new query q(cid:48):.
q(cid:48) = t5-nlg([pos] â—¦ d+(cid:48).
â—¦ [neg] â—¦ dâˆ’(cid:48).
â—¦ [sep]),.
(6).
where d+(cid:48) and dâˆ’(cid:48) are regarded as the related (pos-itive) and unrelated (negative) documents of q(cid:48).
inthis way, we can synthesize massive target-domain(cid:48), d+weak supervision {(qjj.
(cid:48)), 1 â‰¤ j â‰¤ n }..(cid:48), dâˆ’j.
3.3 meta learning to reweight.
the synthetic weak data inevitably contain noises.
to distinguish more useful training data for neuralrankers, metaadaptrank meta-learns to reweightthese synthetic data, following ren et al.
(2018)..(cid:48), d+j.
(cid:48), dâˆ’j.meta learning objective.
given a large vol-(cid:48)), 1 â‰¤ j â‰¤ume of synthetic data {(qjn } and a handful of target data {(qi, d+i , dâˆ’i ), 1 â‰¤i â‰¤ m } (m (cid:28) n ), our meta-learning objectiveis to ï¬nd the optimal weights wâˆ— on synthetic datato better train neural rankers.
the learning of wâˆ—involves two nested loops of optimization: initial-weighted synthetic data is used to pseudo-optimizethe neural ranker; the weights is then optimized byminimizing the neural ranking loss on target data.
to be speciï¬c, the ï¬rst loop (meta-forward up-date) incorporates the initial weights w into thelearning parameters (cid:101)Î¸(w) instead of truly optimiz-ing the neural ranker:.
where Î± is the learning rate.
the description hereuses vanilla sgd and other optimizers can be used.
meta-backward update.
we leverage the neu-ral ranker (cid:101)Î¸t+1(w) to calculate the ranking loss onthe target data batch and obtain the optimal weightswâˆ— = {wâˆ—j=1 through a single optimization step:.
j }n.wâˆ—.
j = wj âˆ’ Î·.li((cid:101)Î¸t+1(w)),.
(10).
âˆ‚âˆ‚(wj).
m(cid:88).
i=1.
1m.where Î· is the learning rate for optimizing weights.
the weights are further normalized for stable train-ing.
more details are shown in appendices a.1..3.4 training with meta-weightsafter obtaining the optimal weights wâˆ—, the opti-mization of the neural ranker is a standard back-propagation on the weighted loss of synthetic data:.
Î¸t+1 = arg minÎ¸t.
j l(cid:48)wâˆ—.
j(Î¸t)..(11).
n(cid:88).
j=1.
in each training step, metaadaptrank ï¬rst learnsto reweight the synthetic batch based on their meta-impact on the target batch and then updates the neu-ral ranker with the weighted synthetic batch.
in thisway, the few-shot target data can serve more as aâ€œregularizerâ€ to help the neural ranker to generalizewith synthetic data, instead of as direct supervisionwhich requires more labels (ren et al., 2018)..(cid:101)Î¸(w) = arg min.
Î¸.wjl(cid:48).
j(Î¸),.
n(cid:88).
j=1.
(7).
4 experimental methodology.
where l(cid:48)j(Î¸) is the ranking loss on a synthetic in-(cid:48)).
in the second loop (meta-stance (qjbackward update), the optimal weights wâˆ— can beobtained by minimizing the target ranking loss:.
(cid:48), dâˆ’j.
(cid:48), d+j.wâˆ— = arg minw.li((cid:101)Î¸(w)),.
(8).
m(cid:88).
i=1.
i , dâˆ’.
where li(Î¸) is the ranking loss on a target instance(qi, d+i ).
the calculation of each loop can bevery expensive.
in practice, we only perform one-step optimization in the two loops with mini-batchdata, consistent with prior work (ren et al., 2018).
meta-forward update.
taking the t-th trainingstep as an example, we ï¬rst assign a set of initialweights w = {wj}nj=1 to the synthetic training databatch and then pseudo-update the neural rankerâ€™sparameters to (cid:101)Î¸t+1(w):.
(cid:101)Î¸t+1(w) = Î¸t âˆ’ Î±.wjl(cid:48).
j(Î¸t),.
(9).
âˆ‚âˆ‚(Î¸t).
n(cid:88).
j=1.
this section describes our experimental settings.
and implementation details..datasets.
as shown in table 1, three standardtrec datasets with different domains are usedin our experiments: clueweb09-b (callan et al.,2009), robust04 (kwok et al., 2004), and trec-covid (roberts et al., 2020).
they are all few-shot ad-hoc retrieval datasets where the number oflabeled queries is limited.
we leverage the â€œcom-pleteâ€ version of trec-covid whose retrievaldocument set is the july 16, 2020 release of cord-19 (wang et al., 2020a), a growing collection of sci-entiï¬c papers on covid-19 and related research.
evaluation settings.
we evaluate supervisedir methods through re-ranking the top 100 docu-ments from the ï¬rst-stage retrieval with ï¬ve-foldcross-validation, consistent with prior work (xionget al., 2017a; dai and callan, 2019; zhang et al.,2020b).
the ï¬rst-stage retrieval for clueweb09-band robust04 is the sequential dependence model.
5033(sdm) (metzler and croft, 2005) released by daiand callan (2019), and the ï¬rst-stage retrieval fortrec-covid is bm25 (robertson and zaragoza,2009) well-tuned by anserini (yang et al., 2017).
metrics.
ndcg@20 is used as the primary met-ric for all datasets.
we also report err@20 forclueweb09-b and robust04, which is the samewith prior work (zhang et al., 2020b), and reportp@20 for trec-covid.
statistic signiï¬cance isexamined by permutation test with p < 0.05..baselines.
two groups of baselines are com-pared in our experiments, including traditional irbaselines and neural ir baselines..traditional ir baselines.
following previous re-search (dai and callan, 2019; zhang et al., 2020b),we compare four traditional ir methods in ourexperiments.
they are two unsupervised meth-ods, bm25 (robertson and zaragoza, 2009) andsdm (metzler and croft, 2005), and two learning-to-rank (ltr) methods using bag-of-word features,ranksvm (joachims, 2002) and coor-ascent(coordinate ascent) (metzler and croft, 2007)..neural ir baselines.
we also compare sevenneu-ir baselines that utilize different methodolo-gies to train neural rankers.
in our experiments,all neu-ir methods adopt the widely-used bertranker (nogueira and cho, 2019), bert-firstp,which only uses the ï¬rst paragraph of documents.
the vanilla neural baseline only leverages the ex-isting small-scale relevance labels of target datasetsto train bert rankers, which is named few-shotsupervision.
we also compare bert rankerstrained with two large-scale supervision sources:bing user click and ms marco.
dai andcallan (2019) train bert rankers with 5 millionuser click logs in bing.
we borrow their reportedresults because commercial logs are not publiclyavailable.
ms marco is a human supervisionsource (nguyen et al., 2016), which provides overone million bing queries with relevance labels..four weak supervision methods are also com-pared.
one baseline is title fitler, whichtreats ï¬ltered title-document pairs as weak super-vision signals (macavaney et al., 2019) for train-ing bert rankers (zhang et al., 2020b).
anothertwo baselines are anchor and reinfoselect.
anchor leverages 100k pairs of anchor texts andweb pages to train bert rankers (zhang et al.,2020b).
reinfoselect ï¬rst employs reinforce-ment learning to select these anchor signals (zhanget al., 2020b) and then trains bert rankers.
the.
datasetdomainclueweb09-bweb pagesnews articlesrobust04trec-covid biomed papers.
50m528k191k.
20025050.corpus size labeled queries.
table 1: statistics of three trec datasets used in ourexperiments.
they are few-shot ranking datasets con-taining only tens to hundreds of labeled queries..last baseline syncsup trains bert rankers withsynthetic weak supervision data, which are synthe-sized based on the previous work (ma et al., 2021).
implementation details.
this part introducesthe implement details of our method and baselines.
bert ranker.
for our methods and all neu-irbaselines, we use the base version of bert (devlinet al., 2019) on clueweb09-b and robust04, andpubmedbert (base) (gu et al., 2020) on trec-covid.
we leverage the openmatch (liu et al.,2021) implementation and obtain the pre-trainedweights from hugging face (wolf et al., 2020)..for all neu-ir methods, we ï¬rst use additionalsupervision sources such as weak supervision sig-nals to train bert rankers (except for few-shotsupervision); then ï¬ne-tune the bert rankerswith the training folds of target datasets in the cross-validation.
following prior work (dai and callan,2019; zhang et al., 2020b), the ranking features([cls] embeddings) of bert are combined withthe ï¬rst-stage retrieval scores using coor-ascentfor clueweb09-b and robust04.
we set the maxinput length to 512 and use adam optimizer with alearning rate of 2e-5 and a batch size of 8..contrastive supervision synthesis.
we use thesmall version of t5 (60 million parameters) as thenlg models in metaadaptrank, and leverage msmarco as the training data for t5-nlg mod-els.
we set the maximum input length to 512 anduse adam to optimize the t5-nlg models with alearning rate of 2e-5 and a batch size of 4. in in-ference, the t5-nlg models are applied on targetdatasets with greedy search.
additionally, we con-sider ctsyncsup as our ablation baseline, whichdirectly trains bert rankers on contrastive syn-thetic supervision data without meta-reweighting.
meta learning to reweight.
the training foldsof the target dataset are used as target data to guidethe meta-reweighting to synthetic data.
we set thebatch size of synthetic data (n) and target data (m)to 8. the second-order gradient of the target rank-ing loss with regard to the initial weight (eq.
10) isimplemented using the automatic differentiation inpytorch (paszke et al., 2017)..5034methods.
bm25 (yang et al., 2017)sdm (dai and callan, 2019)ranksvm (dai and callan, 2019)ranksvm (openmatch)coor-ascent (dai and callan, 2019)coor-ascent (openmatch)few-shot supervision (zhang et al., 2020b)few-shot supervision (ours)bing user click (dai and callan, 2019)ms marco (nguyen et al., 2016)title filter (macavaney et al., 2019)anchor (zhang et al., 2020b)reinfoselect (zhang et al., 2020b)syncsup (ma et al., 2021)ctsyncsupmetaadaptrank.
clueweb09-b (web)ndcg@20 err@200.27730.27740.2890.28250.2950.2969â€ 0.29990.3033â€ 0.3330.3205â€ â€¡(cid:91)Â§0.30210.3072â€ 0.3261â€ â€¡(cid:91)Â§0.3036â€ 0.3123â€ 0.3416â€ â€¡(cid:91)(cid:92)Â§.
0.14260.1380n.a.
0.1476n.a.
0.1581â€ 0.16310.1519n.a.
0.1690â€ (cid:91)0.15130.1609â€ 0.1669â€ (cid:91)0.1602â€ 0.1764â€ (cid:91)Â§0.1893â€ â€¡(cid:91)(cid:92)(cid:93)Â§.
robust04 (news).
ndcg@200.41290.42690.4200.43090.4270.4340â€ 0.42580.4572â€ â€¡n.a.
0.4674â€ â€¡0.43790.4449â€ â€¡0.4703â€ â€¡(cid:91)0.4685â€ â€¡0.4769â€ â€¡(cid:91)0.4916â€ â€¡(cid:91)(cid:92)(cid:93)Â§.
err@200.11170.1172n.a.
0.1173n.a.
0.11710.11630.1234n.a.
0.1304â€ â€¡(cid:91)0.12020.1223â€ â€¡0.1313â€ â€¡(cid:91)0.1311â€ â€¡(cid:91)0.1293â€ â€¡(cid:91)0.1362â€ â€¡(cid:91)(cid:92)Â§.
trec-covid (biomed)ndcg@200.69790.7030n.a.
0.6995n.a.
0.7041n.a.
0.7713â€ â€¡n.a.
0.8054â€ â€¡(cid:91)n.a.
0.7677â€ â€¡0.7833â€ â€¡0.7867â€ â€¡0.8006â€ â€¡(cid:91)0.8378â€ â€¡(cid:91)(cid:92)(cid:93)Â§.
p@200.76700.7770n.a.
0.7570n.a.
0.7770n.a0.8400â€ â€¡n.a.
0.8610â€ â€¡(cid:91)n.a.
0.8260â€ â€¡0.8420â€ â€¡0.8470â€ â€¡0.8610â€ â€¡0.8790â€ â€¡(cid:91)(cid:93)Â§.
table 2: ranking accuracy of metaadaptrank and baselines.
â€ , â€¡, (cid:91), (cid:92), (cid:93), Â§ indicate statistically signiï¬cant improve-ments over sdmâ€ , coor-ascentâ€¡, few-shot supervision(cid:91), ms marco(cid:92), reinfoselect(cid:93) and syncsupÂ§..supervision sources.
(a) ms marco (nguyen et al., 2016)(b) anchor (zhang et al., 2020b)(c)(d) ctsyncsup(e) marco + ctsyncsup.
syncsup (ma et al., 2021).
clueweb09-b (web).
robust04 (news).
trec-covid (biomed).
ndcg@20 err@20 ndcg@20 err@20 ndcg@200.3205(cid:91)0.30720.30360.31230.3214(cid:91).
0.8054â€¡0.76770.78670.8006â€¡0.8182â€¡(cid:91).
0.16900.16090.16020.1764(cid:91)0.1739â€¡(cid:91).
0.1304â€¡0.12230.1311â€¡0.1293â€¡0.1297â€¡.
0.4674â€¡0.44490.4685â€¡0.4769â€¡0.4727â€¡.
p@200.8610â€¡0.82600.84700.8610â€¡0.8720â€¡(cid:91).
table 3: ranking accuracy with different supervision sources.
marco + ctsyncsup denotes the hybrid sourceof ms marco and ctsyncsup.
â€ , â€¡, (cid:91) indicate statistically signiï¬cant improvements over (a)â€ , (b)â€¡ and (c)(cid:91)..5 evaluation results.
in this section, we present the evaluation results ofmetaadaptrank and conduct a series of analysesand case studies to study its effectiveness..5.1 overall accuracy.
the ranking results of metaadaptrank and base-lines are presented in table 2..on all benchmarks and metrics, metaadaptrankoutperforms all baselines stably.
compared to thebest feature-based letor method, coor-ascent,metaadaptrank outperforms it by more than 15%.
metaadaptrank even outperforms the strong neu-ir baselines supervised with bing user click andms marco, which demonstrates its effectiveness.
speciï¬cally, ctsyncsup directly improves thefew-shot ranking accuracy of bert rankers by 3%on all benchmarks.
in comparison to other weak su-pervision sources, ï¬ltered title-document relations,anchor and syncsup, ctsyncsup shows more sta-ble effectiveness across different benchmarks, re-vealing its domain-adaption advantages.
moreover,meta-reweighting ctsyncsup brings further im-provement and helps metaadaptrank outperformthe latest selective neu-ir method reinfoselect..next, we go ahead to analyze metaadaptrankâ€™s.
contrastive synthesis and meta-reweighting..5.2 effectiveness of contrastive synthesis.
we analyze contrastive synthesisâ€™s effectiveness byits effect on ranking results and synthetic quality.
table 3 presents the ranking accuracy based onour ctsyncsup and four other supervision sources.
ctsyncsup outperforms anchor and syncsup sta-bly across all datasets.
on robust04, ctsyncsupeven shows better performance than ms marcohuman labels.
besides, combining the sources ofms marco and ctsyncsup can further improvethe ranking accuracy on clueweb09-b and trec-covid, revealing that ctsyncsup provides usefulsupervision signals applicable to various domains.
we further evaluate the quality of the queriesgenerated in syncsup and our ctsyncsup, whichare both synthetic methods for generating queriesbased on target documents.
following previousresearch (ma et al., 2021; yu et al., 2020; celiky-ilmaz et al., 2020), eight auto evaluation metricsare used in our evaluation.
as shown in table 4,ctsyncsup outperforms syncsup on all metrics.
the results demonstrate that the contrastive pairof positive and negative documents does help the.
5035synthetic methodssyncsup (ma et al., 2021)reverse-ctsyncsupctsyncsup.
bleu-10.56720.31850.5909.bleu-2 rouge-1 rouge-2 rouge-l nist@1 nist@2 meteor0.57450.45270.33950.18070.59550.4627.
5.80703.00766.1282.
0.59280.35280.6238.
7.33153.36657.6314.
0.37640.10880.3844.
0.30890.16100.3191.table 4: evaluation results of the queries generated by different synthetic methods.
in reverse-ctsyncsup, weswap the encoding order of contrastive document pairs, using original negative documents as positive documents..methods (supervision sources).
(a) reinfoselect (ms marco)(b) reinfoselect (anchor)(c)reinfoselect (ctsyncsup)(d) metaadaptrank (ms marco)(e) metaadaptrank (anchor)(f) metaadaptrank (ctsyncsup)(g) metaadaptrank (marco + ctsyncsup).
clueweb09-b (web)ndcg@20 err@200.32940.32610.32430.3453â€ â€¡(cid:91)0.33740.3416(cid:91)0.3498â€ â€¡(cid:93).
0.17600.16690.17420.2018â€ â€¡(cid:91)(cid:93)0.17300.1893â€¡(cid:93)0.1926â€¡(cid:91)(cid:93).
robust04 (news).
trec-covid (biomed).
ndcg@20 err@20 ndcg@200.47560.47030.4816â€¡0.4853â€¡0.47970.4916â€ â€¡(cid:93)0.4989â€ â€¡(cid:91)(cid:92)(cid:93).
0.8229â€¡0.78910.8230â€¡0.8354â€¡(cid:93)0.80450.8378â€¡(cid:93)0.8488â€ â€¡(cid:91)(cid:92)(cid:93).
0.12910.13130.13340.13310.13140.1362â€ (cid:93)0.1366â€ (cid:92).
p@200.8780â€¡0.84300.8800â€¡0.8730â€¡0.86500.8790â€¡0.8910â€¡(cid:92)(cid:93).
table 5: ranking accuracy of reinfoselect and metaadaptrank using different supervision sources.
superscriptsâ€ , â€¡, (cid:91), (cid:92), (cid:93), Â§ indicate statistically signiï¬cant improvements over (a)â€ , (b)â€¡, (c)(cid:91), (d)(cid:92), (e)(cid:93) and (f)Â§..(a) reinfoselect..(b) metaadaptrank..(a) win/tie percentage..(b) marco weight variation..figure 2: the state of learned weights on ctsyncsupdata from reinfoselect and metaadaptrank.
we use aclueweb09 few-shot fold as target data.
training stepsare marked on x-axes.
the mean and 95% conï¬denceinterval (ci) of data weights in the same batch are plot-ted.
a 95% ci is an interval that will contain the truemean of weights with 95% probability.
its width is pro-portional to the standard deviation of data weights..figure 3: the analysis of metaadaptrank on the hy-brid source of ms marco and ctsyncsup.
the ratioof win/tie queries between ms marco and the hy-brid source is shown in (a).
the statistics are based onndcg@20 scores.
cw09, rb04, covid are short fordatasets.
(b) illustrates the variation in the meta-learnedweights of 2k ms marco data points with (w/) andwithout (w/o) merging ctsyncsup..nlg model better approximate the golden queries.
in addition, reversing the encoding order of the con-trastive document pair causes a dramatic decreasein all evaluation scores of the generated queries.
this further shows that our contrastive query gen-erator can extract more speciï¬c and representativeinformation from the positive documents, therebygenerating more discriminative queries..5.3 effectiveness of meta reweighting.
to analyze the effectiveness of meta reweighting,we employ metaadaptrank on different supervi-sion sources and study its data weighting behaviorsin the learning process.
the reinforcement data se-lector reinfoselect is used as a comparison, whichutilizes the trial-and-error weighting mechanism.
the ranking accuracy of metaadaptrank and.
reinfoselect trained with ms marco, anchor,and ctsyncsup is presented in table 5. for allsupervision sources, metaadaptrank outperformsreinfoselect on all benchmarks.
the results showthat the meta-reweighting mechanism can more ef-fectively explore the potential of different supervi-sion sources compared to the trial-and-error weight-ing mechanism.
moreover, the advantages of metareweighting can be extended to the hybrid supervi-sion source of ms marco and ctsyncsup..to further understand the behaviors of metareweighting, we compare the state of weights as-signed to synthetic supervision by metaadaptrankand reinfoselect in the learning process, usingctsyncsup as synthetic data and clueweb09 astarget data.
the results are shown in figure 2. eventhough each synthetic batch is likely to include both.
503602004006008001000step0.00.20.40.60.81.0weight meanreinfoselect95% ci02004006008001000step0.000.050.100.150.200.25weight meanmetaadaptrank95% cicw09rb04covid0%20%40%60%80%100%win/tie percentage(web)(news)(biomed)tiewin (marco)win (marco + ctsyncsup)0.00.20.40.60.81.0weight (w/o ctsyncsup)0.00.20.40.60.81.0weight (w/ ctsyncsup)unchangetrec-covid r5 methods.
(a)r5.fusion1 (anserini bm25)(b)r5.fusion2 (anserini bm25)(c)covidex.r5.2s (rrf)(d) metaadaptrank (rerank (a))(e)covidex.r5.d2q.2s (rrf)(f) metaadaptrank (rerank (b))(g) metaadaptrank (rrf).
all queries.
old queries.
new queries.
ndcg@200.53130.6007â€ 0.7457â€ â€¡0.7536â€ â€¡0.7539â€ â€¡0.7904â€ â€¡(cid:91)(cid:92)0.7992â€ â€¡(cid:91)(cid:92)(cid:93).
p@200.58400.6440â€ 0.7610â€ â€¡0.7820â€ â€¡0.7700â€ â€¡0.8270â€ â€¡(cid:91)(cid:92)(cid:93)0.8380â€ â€¡(cid:91)(cid:92)(cid:93).
ndcg@200.52020.5937â€ 0.7303â€ â€¡0.7405â€ â€¡0.7385â€ â€¡0.7790â€ â€¡(cid:91)(cid:92)0.7899â€ â€¡(cid:91)(cid:92)(cid:93).
p@200.57220.6344â€ 0.7456â€ â€¡0.7656â€ â€¡0.7544â€ â€¡0.8144â€ â€¡(cid:91)(cid:92)(cid:93)0.8267â€ â€¡(cid:91)(cid:92)(cid:93).
ndcg@200.63200.66410.8837â€ 0.8712â€ â€¡0.8929â€ 0.8933â€ â€¡(cid:91)0.8833â€ â€¡(cid:91).
p@200.69000.73000.90000.9300â€ â€¡0.91000.9400â€ â€¡(cid:91)0.9400â€ â€¡(cid:91).
table 6: evaluation results of trec-covid r5.
all queries denotes all queries in r5.
old and new queriesdenote queries that have been judged or not in previous rounds (r1-r4).
(a) and (b) are the ï¬rst-stage retrieval ofother methods in this table.
(c) and (e) are r5â€™s top 2 automatic systems.
(g) is the reciprocal rank fusion (rrf) of(d) and (f).
â€ , â€¡, (cid:91), (cid:92), (cid:93), Â§ indicate statistically signiï¬cant improvements over (a)â€ , (b)â€¡, (c)(cid:91), (d)(cid:92), (e)(cid:93) and (f)Â§..(â†‘).
(â†“).
synthetic query.
ctsyncsup: how does shoppingwith the planet make a big differ-ence in msn ecosyncsup: what is green energyecosystem.
ctsyncsup: what is the history ofbermudasyncsup: where is jamestownbeach.
positive document.
.
.
green at msn shopping shoppingwith the planet in mind can makea big difference by msn shoppingmsn green updated: energy savingsolutions conserving energy reducesco2 emissions ...... bermuda beach resorts: websitededicated to advertising in bermudalarge helpful travel forum bermudalinks: activities hotels resorts beachbermuda history bermuda hotels ....negative document... eco adventure tours energy starpledge donate resources boater guidemarinas harbormasters green thumbride share candle light dinner brightidea ....... your art history reference guideart history search jamestown, colo-nial history virginia (redirected fromjamestown settlement)jamestownwas a village on an island ....table 7: cases of meta-reweighted contrastive synthetic data targeting clueweb09.
the weights are marked in theparenthesis â†‘ (more important) and â†“ (down-weight).
the red texts are speciï¬c contents of positive documents andthe blue texts are shared by both positive and negative documents.
the document snippets are manually selected..useful and noisy data points, reinfoselect alwaysassigns very high weights at the beginning and dis-cards almost all synthetic data points later.
besides,its tight conï¬dence interval reveals that data pointsin the same batch received almost identical weights.
these observations indicate that reinfoselect doesnot effectively distinguish useful synthetic datapoints from the noisy ones during the learning pro-cess.
by contrast, metaadaptrank assigns higherweights initially and steadily reduces the weightsas training goes on.
more importantly, its wide con-ï¬dence interval reveals that the data weights in thesame synthetic batch vary signiï¬cantly, which arethus expected to be more diverse and ï¬ne-grained..5.4 effectiveness of hybrid supervision.
we also analyze metaadaptrankâ€™s advantages onthe hybrid supervision source of ms marco andctsyncsup.
the impact of the hybrid source on itsranking accuracy and meta-reweighting behavioris studied.
besides, we evaluate metaadaptranktrained with the hybrid source in round 5 of thetrec-covid shared task in which many strongbaselines have been well-tuned for four rounds..figure 3a shows the win/tie ranking accuracy ofmetaadaptrank trained with ms marco and the.
hybrid supervision source.
compared to the singlems marco, the hybrid source has more advan-tages across all benchmarks.
besides, the hybridadvantage seems to be more evident in non-webdomain benchmarks, especially on trec-covid..we further investigate the weighting behavior ofmetaadaptrank on ms marco and the hybridsource, using the same clueweb09 target data inprevious analyses.
figure 3b illustrates the changesin meta-learned weights of randomly sampled 2kms marco data points before and after mergingctsyncsup source.
there are signiï¬cant weightvariations on most ms marco data points beforeand after merging ctsyncsup.
additionally, merg-ing ctsyncsup reduces the weight of more msmarco data points, revealing that ctsyncsupdata are assigned higher weights.
this also revealsthat metaadaptrank can tailor diversiï¬ed weightsfor the same data points in different sources andup-weights more useful training data ï¬‚exibly..lastly, we report the trec-covid r5 rankingresults of metaadaptrank trained with the hybridsource.
the top 2 automatic search systems in ther5 leaderboard are compared, which outperformsother systems on the newly added queries in r5.
the evaluation of these new queries is fair to our.
5037methods and those systems that underwent previousrounds (r1-r4).
as shown in table 6, our singlemodel outperforms the top 2 fusion-based systemson all evaluation of the new, old, and all queries, fur-ther showing the effectiveness of metaadaptrankwith the hybrid supervision source.
more detailsand ranking results are shown in appendices a.2..5.5 case studies.
table 7 exhibits some cases of contrastive syntheticdata for clueweb09 and their meta-learned weights.
more cases are shown in appendices a.3..ctsyncsup can extract more speciï¬c contentsfrom the positive documents, e.g., â€œshopping withthe planetâ€ and â€œmake a big differenceâ€ in theï¬rst case; syncsup captures more general informa-tion, e.g., â€œgreen energyâ€.
compared to syncsupâ€™squeries such as â€œwhere is jamestown beachâ€ in thesecond case, the synthetic queries in ctsyncsupare more informative and discriminative.
notice-ably, the second case exhibits the synthetic noise,where the positive document is actually related toâ€œbermudaâ€™s tourismâ€ instead of the query â€œhistoryof bermudaâ€.
metaadaptrank effectively ï¬ltersthis noisy instance by assigning a zero weight to it..6 conclusion.
this paper presents metaadaptrank, a domainadaption method for few-shot neu-ir with con-trastive weak data synthesis and meta-reweighteddata selection.
contrastive synthesis generates in-formative queries and useful synthetic supervisionsignals.
meta-learned weights form high-resolutionchannels between target labels and synthetic sig-nals, providing robust and ï¬ne-grained data selec-tion for synthetic weak supervision.
both of themcollaborate to signiï¬cantly improve the neural rank-ing accuracy in various few-shot search scenarios..acknowledgments.
this work is partly supported by the national keyresearch and development program of china (no.
2020aaa0106501) and beijing academy of arti-ï¬cial intelligence (baai).
we thank zhuyun daiand jamie callan for sharing the sdm results onclueweb09-b and robust04 and thank shi yu fordiscussions in the query generation methodologies..references.
piyush arora, murhaf hossari, alfredo maldonado,clare conran, and gareth jf jones.
2018. chal-.
lenges in the development of effective systemsin proceedings offor professional legal search.
profs/kg4ir/data: search@ sigir, pages 29â€“34..jamie callan, mark hoy, changkuk yoo, and le zhao..2009. clueweb09 data set..asli celikyilmaz, elizabeth clark, and jianfeng gao.
2020. evaluation of text generation: a survey.
arxiv preprint arxiv:2006.14799..danqi chen, adam fisch, jason weston, and antoinebordes.
2017. reading wikipedia to answer open-in proceedings of acl, pagesdomain questions.
1870â€“1879..paul alexandru chirita, wolfgang nejdl, raluca paiu,and christian kohlschÂ¨utter.
2005. using odp meta-data to personalize search.
in proceedings of sigir,pages 178â€“185..nick craswell, bhaskar mitra, emine yilmaz, danielcampos, and ellen m voorhees.
2020. overview ofthe trec 2019 deep learning track.
arxiv preprintarxiv:2003.07820..zhuyun dai and jamie callan.
2019. deeper text un-derstanding for ir with contextual neural languagemodeling.
in proceedings of sigir, pages 985â€“988..zhuyun dai, chenyan xiong, jamie callan, andzhiyuan liu.
2018. convolutional neural networksfor soft-matching n-grams in ad-hoc search.
in pro-ceedings of wsdm, pages 126â€“134..mostafa dehghani, hamed zamani, aliaksei severyn,jaap kamps, and w bruce croft.
2017. neural rank-ing models with weak supervision.
in proceedingsof sigir, pages 65â€“74..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of naacl-hlt, pagesstanding.
4171â€“4186..doug downey, susan dumais, and eric horvitz.
2007.heads and tails: studies of web search with commonin proceedings of sigir, pagesand rare queries.
847â€“848..yu gu, robert tinn, hao cheng, michael lucas,naoto usuyama, xiaodong liu, tristan naumann,jianfeng gao, and hoifung poon.
2020. domain-speciï¬c language model pretraining for biomedi-arxiv preprintcal natural language processing.
arxiv:2007.15779..jiafeng guo, yixing fan, qingyao ai, and w. brucecroft.
2016. a deep relevance matching model forad-hoc retrieval.
in proceedings of cikm, pages 55â€“64..david hawking.
2004. challenges in enterprise search..in proceedings of adc, pages 15â€“24..5038sebastian hofstÂ¨atter, hamed zamani, bhaskar mitra,nick craswell, and allan hanbury.
2020. localself-attention over long text for efï¬cient documentretrieval.
in proceedings of sigir, page 2021â€“2024..zhiting hu, bowen tan, russ r salakhutdinov, tom mmitchell, and eric p xing.
2019. learning data ma-nipulation for augmentation and weighting.
in pro-ceedings of neurips, pages 15764â€“15775..tri nguyen, mir rosenberg, xia song, jianfeng gao,saurabh tiwary, rangan majumder, and li deng.
2016. ms marco: a human generated machinein proceedings ofreading comprehension dataset.
coco@ nips, volume 1773..rodrigo nogueira and kyunghyun cho.
2019. pas-arxiv preprint.
sage re-ranking with bert.
arxiv:1901.04085..kai hui, andrew yates, klaus berberich, and gerardde melo.
2017. pacrr: a position-aware neuralir model for relevance matching.
in proceedings ofemnlp, pages 1049â€“1058..thorsten joachims.
2002. optimizing search enginesin proceedings of kdd,.
using clickthrough data.
pages 133â€“142..kui-lam kwok, laszlo grunfeld, hl sun, peter deng,and n dinstl.
2004. trec 2004 robust track exper-iments using pircs.
in proceedings of trec..kenton lee, ming-wei chang, and kristina toutanova.
2019. latent retrieval for weakly supervised opendomain question answering.
in proceedings of acl,pages 6086â€“6096..jimmy lin.
2019. the neural hype and comparisonsagainst weak baselines.
in acm sigir forum, vol-ume 52, pages 40â€“51..tie-yan liu.
2009. learning to rank for information re-trieval.
foundations and trends in information re-trieval, 3(3):225â€“331..zhenghao liu, chenyan xiong, maosong sun, andzhiyuan liu.
2020. fine-grained fact veriï¬cationwith kernel graph attention network.
in proceedingsof acl, pages 7342â€“7351..zhenghao liu, kaitao zhang, chenyan xiong, zhiyuanliu, and maosong sun.
2021. openmatch: an opensource library for neu-ir research.
arxiv preprintarxiv:2102.00166..ji ma, ivan korotkov, yinfei yang, keith hall, andryan mcdonald.
2021. zero-shot neural passageretrieval via domain-targeted synthetic question gen-eration.
in proceedings of eacl, pages 1075â€“1088..sean macavaney, andrew yates, kai hui, and ophirfrieder.
2019. content-based weak supervision forad-hoc re-ranking.
in proceedings of sigir, pages993â€“996..donald metzler and w bruce croft.
2005. a markovrandom ï¬eld model for term dependencies.
in pro-ceedings of sigir, pages 472â€“479..donald metzler and w bruce croft.
2007. linearin-feature-based models for information retrieval.
formation retrieval, 10(3):257â€“274..bhaskar mitra, nick craswell, et al.
2018. an intro-duction to neural information retrieval.
foundationsand trendsÂ® in information retrieval, 13(1):1â€“126..joao palotti, harrisen scells, and guido zuccon.
2019.trectools: an open-source python library for infor-mation retrieval practitioners involved in trec-likecampaigns.
in proceedings of sigir, pages 1325â€“1328..adam paszke, sam gross, soumith chintala, gregorychanan, edward yang, zachary devito, zeminglin, alban desmaison, luca antiga, and adamlerer.
2017. automatic differentiation in pytorch.
in proceedings of neurips autodiff workshop..yifan qiao, chenyan xiong, zheng-hao liu, andzhiyuan liu.
2019. understanding the behaviors ofbert in ranking.
arxiv preprint arxiv:1904.07531..chen qu, liu yang, cen chen, minghui qiu, w brucecroft, and mohit iyyer.
2020. open-retrieval con-in proceedings ofversational question answering.
sigir, pages 539â€“548..colin raffel, noam shazeer, adam roberts, katherinelee, sharan narang, michael matena, yanqi zhou,wei li, and peter j liu.
2020. exploring the limitsof transfer learning with a uniï¬ed text-to-text trans-journal of machine learning research,former.
21(140):1â€“67..mengye ren, wenyuan zeng, bin yang, and raquelurtasun.
2018. learning to reweight examples forin proceedings of icml,robust deep learning.
pages 4331â€“4340..kirk roberts, tasmeer alam, steven bedrick, dinademner-fushman, kyle lo, ian soboroff, ellenvoorhees, lucy lu wang, and william r hersh.
2020. trec-covid: rationale and structure ofan information retrieval shared task for covid-19.
journal of the american medical informatics asso-ciation, 27(9):1431â€“1436..stephen robertson and hugo zaragoza.
2009. theprobabilistic relevance framework: bm25 and be-yond.
foundations and trendsÂ® in information re-trieval, 3(4):333â€“389..g. salton and chris buckley.
1997. improving retrievalperformance by relevance feedback.
journal of theassociation for information science and technology,41(4):355â€“364..jun shu, qi xie, lixuan yi, qian zhao, sanping zhou,zongben xu, and deyu meng.
2019. meta-weight-net: learning an explicit mapping for sample weight-ing.
in proceedings of neurips, pages 1919â€“1930..5039lucy lu wang, kyle lo, yoganand chandrasekhar,russell reas, jiangjiang yang, darrin eide, kathrynfunk, rodney kinney, ziyang liu, william merrill,et al.
2020a.
cord-19: the covid-19 open researchdataset.
in proceedings of the 1st workshop on nlpfor covid-19 at acl 2020..xinyi wang, yulia tsvetkov, and graham neubig.
2020b.
balancing training for multilingual neuralmachine translation.
in proceedings of acl, pages8526â€“8537..thomas wolf, julien chaumond, lysandre debut, vic-tor sanh, clement delangue, anthony moi, pier-ric cistac, morgan funtowicz, joe davison, samshleifer, et al.
2020. transformers: state-of-the-art natural language processing.
in proceedings ofemnlp, pages 38â€“45..chenyan xiong, jamie callan, and tie-yan liu.
2017a.
word-entity duet representations for document rank-ing.
in proceedings of sigir, pages 763â€“772..chenyan xiong, zhuyun dai, jamie callan, zhiyuanliu, and russell power.
2017b.
end-to-end neuralad-hoc ranking with kernel pooling.
in proceedingsof sigir, pages 55â€“64..lee xiong, chenyan xiong, ye li, kwok-fung tang,jialin liu, paul n. bennett, junaid ahmed, andarnold overwijk.
2021. approximate nearest neigh-bor negative contrastive learning for dense text re-trieval.
in proceedings of iclr..peilin yang, hui fang, and jimmy lin.
2017. anserini:enabling the use of lucene for information retrievalin proceedings of sigir, pages 1253â€“research.
1256..wei yang, kuang lu, peilin yang, and jimmy lin.
2019. critically examining the â€neural hypeâ€: weakbaselines and the additivity of effectiveness gainsfrom neural ranking models.
in proceedings of si-gir, pages 1129â€“1132..andrew yates, siddhant arora, xinyu zhang, weiyang, kevin martin jose, and jimmy lin.
2020.capreolus: a toolkit for end-to-end neural ad hocretrieval.
in proceedings of wsdm, pages 861â€“864..shi yu, jiahua liu, jingqin yang, chenyan xiong, paulbennett, jianfeng gao, and zhiyuan liu.
2020. few-shot generative conversational query rewriting.
pro-ceedings of sigir, page 1933â€“1936..edwin zhang, nikhil gupta, rodrigo nogueira,kyunghyun cho, and jimmy lin.
2020a.
rapidlydeploying a neural search engine for the covid-19 open research dataset.
in proceedings of the 1stworkshop on nlp for covid-19 at acl 2020..kaitao zhang, chenyan xiong, zhenghao liu, andzhiyuan liu.
2020b.
selective weak supervisionfor neural information retrieval.
in proceedings ofwww, pages 474â€“485..guoqing zheng, ahmed hassan awadallah, and su-san dumais.
2019a.
meta label correction forarxiv preprintlearning with weak supervision.
arxiv:1911.03809..yukun zheng, yiqun liu, zhi-qiang fan, chengluo, qingyao ai, min zhang, and shaoping ma.
2019b.
investigating weak supervision in deep rank-ing.
data and information management, 3:155â€“164..5040methods/run iduprrf102-r5uprrf93-r5covidex.r5.1s.lrelhuyar prf nof99dcovidex.r5.d2q.1s.lrelhuyar prf nof99pmetaadaptrank (rerank fusion.1)uprrf102-wt-r5metaadaptrank (rrf)covidex.r5.2s.lruprrf93-wt-r5covidex.r5.d2q.2s.lrmetaadaptrank (rerank fusion.2).
ndcg@200.78730.79670.80190.82090.82870.83330.87120.88040.88330.88370.88490.89290.8933.p@200.80000.82000.83000.87000.84000.90000.93000.91000.94000.90000.91000.91000.9400.table 8: ranking results of our methods and baselineson the new queries of trec-covid r5.
the baselinesare the top 10 feedback systems in the r5 leaderboard,marked with their submitted id.
the three variants ofmetaadaptrank are the same as those in table 6..a appendices.
a.1 batch normalization of meta-weights.
this part elaborates the batch normalization pro-cess for meta-learned weights.
following priorresearch (ren et al., 2018), we ï¬rst set the initialweights w to zeros and obtain the new weights Ëœw:.
Ëœwj = âˆ’Î·.
âˆ‚âˆ‚(wj).
m(cid:88).
i=1.
1m.(cid:12)li((cid:101)Î¸t+1(w))(cid:12)(cid:12)wj =0.
..(12).
then we clip Ëœw to get non-negative weights Ë†w andfurther normalize them in the batch to obtain theï¬nal weights wâˆ—:.
Ë†wj = max(0, Ëœwj),.
wâˆ—.
j =.
Ë†wjp=1 Ë†wp) + Î´((cid:80)n.((cid:80)n...p=1 Ë†wp).
p=1 Ë†wp) = 1 when (cid:80)n.(13)here Î´((cid:80)np=1 Ë†wp = 0, toprevent division errors, otherwise it is 0. with thebatch-normalization process, the hyperparameter Î·can be effectively eliminated.
the normalizationmethod is not constrained and other approachescan also be used (shu et al., 2019; hu et al., 2019)..a.2 supplementary results oftrec-covid r5.
this part supplements our evaluation results in thetrec-covid r5 shared task.
we will ï¬rst recapthe shared task and then present more evaluationresults and our implementation details..trec-covid r5.
the trec-covid chal-lenge is an ad-hoc ranking task for covid-19 liter-ature, consisting of ï¬ve rounds.
trec-covid r5is the last round of this challenge, where the docu-ment set is the july 16, 2020 version of cord-19,.
and the query set contains 50 testing queries.
theï¬rst 45 queries have been used in previous rounds(r1-r4), and the last ï¬ve queries are newly addedin r5.
as in previous rounds, trec-covid r5adopts residual collection evaluation (salton andbuckley, 1997).
in residual collection evaluation,the relevance labels from previous rounds can beused, but any document that has been annotated fora query will be removed before the evaluation.
wefocus more on the evaluation of r5â€™s new queriesbecause these queries have no prior relevance la-bels, which is fairer to our models and those searchsystems that underwent previous rounds..evaluation results.
table 8 shows the evalua-tion results on the new queries of trec-covidr5, including three variants of our metaadaptrankand the top 10 feedback systems in the r5 leader-board.
compared with the top 10 feedback systems(many are fusion-based systems), our single modelmetaadaptrank (rerank fusion.2) outperforms allbaselines, demonstrating the generalization abilityof our method on new queries..additionally, what catches our attention is thatthe best and worst of the top 10 feedback systemsonly have a 5.1% difference in ndcg@20 scoreson all queries, while their ndcg@20 scores onthe new queries differ by 13.4%.
this discrepancyindicates that the residual collection evaluation mayhave biases between the seen and unseen queries.
implementation details.
we next describe theimplementation details of the three variants of ourmetaadaptrank in trec-covid r5.
consistentwith the implementation methods described in sec-tion 4, we rerank the top 100 documents from theï¬rst-stage retrieval.
we ï¬rst borrow two retrievalresults with different settings provided by anserinibm25 (row 7 and 8 of table round 51).
thenpudmedbert (base) is used to rerank these tworetrieval results to obtain metaadaptrank (rerankfusion.1) and metaadaptrank (rerank fusion.2),respectively.
metaadaptrank (rrf) is the recipro-cal rank fusion of these two models.
we utilize theopen-source library trec-tools (palotti et al., 2019)to implement rrf and set the fusion weight k to 1.to train metaadaptrank, we ï¬rst synthesizectsyncsup data based on r5â€™s document set andleverage the hybrid source of ctsyncsup and msmarco as the additional supervision signals.
thetraining process contains two stages.
we ï¬rst train.
1https://github.com/castorini/.
anserini/blob/master/docs/experiments-covid.md.
5041synthetic query.
ctsyncsup: us military radarsin colombiasyncsup: what is the pentagon.
1 (â†‘).
2 (â†‘).
3 (â†“).
4 (â†‘).
5 (â†‘).
6 (â†“).
ctsyncsup: what percent of theeconomy was increased in 1993syncsup: what is the economicissue in peru.
ctsyncsup: what language is os-valdo rodriguezsyncsup: what is economic im-pact of cuba.
ctsyncsup: which receptors areexpressed in the human lungsyncsup: what is sars cov recep-tor.
ctsyncsup: how does quaran-tine prevent covid outbreaksyncsup: covid outbreak symp-toms.
ctsyncsup: covid-19 pandemiceffects on societysyncsup: what is the antiasia sen-timent in the united states.
positive document... one month ago, the pentagon is-sued an order to suspend operationsof the two radars that detect aircraft.
these radars operate in colombia asa result of that agreement ...this letter explains the peru-...vian governmentâ€™s economic policy.
the development of the economy in1993 was in general much better.
itis estimated that the real gdp has in-creased by 7 percent ...... program with host osvaldo ro-driguez the dialogue that was pro-posed by opponents to the revolu-tionary project.
well, the word dia-logue, is one that connotes cordial-ity.
it is a positive word.
but in thecurrent political language, the coun-terrevolutionâ€™s political language ...... results both sars-cov receptors oface2 and cd209l were expressed inthe 8 organ/tissue-derived endothe-lial cells.
the expression of ace2 re-ceptor was the highest in the humanlung microvascular endothelial cells,and lowest ...... the importance of the timing ofquarantine measures before symp-tom onset to prevent covid-19 out-breaks how quarantine-based mea-sures can prevent or suppress an out-break ...... examination of community senti-ment dynamics due to covid-19 pan-demic:the outbreak of covid-19has caused unprecedented impacts topeopleâ€™s daily life around the world.
virus may cause different mentalhealth issues to people such as de-pression, anxiety, sadness ....negative document... provide for more funding andretain more forces than the $1.5-trillion ï¬ve-year budget cheney pre-sented to congress in january, pen-tagon ofï¬cials say ...... only three economies - guyana,argentina and peru - grew by morethan than 5 per cent this year, withperu expanding by 11 percent ....program with host juan car-...los roque garcia, and osvaldo ro-driguez.
this program could not ig-nore cubaâ€™s presentation of a docu-ment by the u.s. interests section inhavana to the un human rights com-mission in geneva ....outbreaks.
2019 novel.
clearly indicate.
coronavirus...(2019-ncov)ofthe2002/2003 sars, 2012/2015 mersand 2019/2020 wuhan respiratorysyndromethatgenome evolution of an animalcoronavirus (cov) may enable ...... furthermore, the effect of infec-tiousness prior to symptom onsetcombined with a signiï¬cant propor-tion we evaluate two procedures:monitoring individuals for symp-toms onset ...... mood of india during covid-19- an interactive web portal basedon emotion analysis of twitter datathe covid-19 pandemic has affectedmany countries across the world, anddisrupted the day to day activities ofmany people ....table 9: the contrastive synthetic data reweighted by metaadaptrank, where the top 3 cases are from robust04(news) and the last 3 cases come from trec-covid (biomed).
their meta-weights are marked in the parenthesisâ†‘ (more important) and â†“ (down-weight).
the red texts are the speciï¬c contents of the positive documents, and theblue texts are mentioned in both positive and negative documents.
the document snippets are manually selected..metaadaptrank with the hybrid source and regardthe labeled data from previous rounds (r1-r4) astarget data in meta-reweighting.
then we continu-ously train metaadaptrank using the labeled datafrom the previous rounds.
in the training processes,we utilize adam optimizer with a learning rate of2e-5.
both the batch size and the accumulation stepare set to 8. in addition, to ensure a fair comparisonwith the submitted search systems, we post-processour results according to ofï¬cial guidelines..a.3 supplementary case studies.
table 9 shows more cases for the other two datasets,robust04 (news) and trec-covid (biomed), toverify the effectiveness of metaadaptrank in dif-ferent domains.
the ï¬rst three cases are from ro-bust04, and the rest cases are from trec-covid..for the ï¬rst synthetic cases, our ctsyncsup canextract characteristic keywords, e.g., â€œradarsâ€ andâ€œcolombiaâ€, from the positive documents to gener-ate more informative queries, while syncsup tendsto capture general keywords to create broad queries,which may lack the ability to distinguish betweendifferent documents.
besides, ctsyncsup can ex-tract some necessary themes from the speciï¬c doc-uments, such as the particular time â€œ1993â€ and theadjective â€œincreasedâ€, as shown in the second case.
moreover, cases 4 and 5 show the effectivenessof our contrastive synthesis for biomedical domains.
ctsyncsup can capture â€œlungâ€ and â€œquarantinepreventâ€ instead of general keywords, such as â€œsarscovâ€ and â€œsymptomsâ€ often mentioned in covid-related documents.
these observations show thatctsyncsup can extract more speciï¬c information.
5042to generate more informative and discriminativequeries for different target domains..we further explore those synthetic instancesthat are assigned zero weights by metaadaptrank,such as the third and sixth cases.
in the third case,although ctsyncsup captures the two keywordsâ€œlanguageâ€ and â€œosvaldo rodrigrezâ€ from the posi-tive document, its synthetic query is actually lessrelevant to the main topic of the positive document.
for the sixth case, ctsyncsup fails to exclude the.
phrase â€œcovid-19 pandemicâ€ related to both thepositive and negative documents, which causes thesynthetic query unable to distinguish between them.
fortunately, metaadaptrank can effectively iden-tify the synthetic instances whose relevance match-ing patterns between synthetic queries and positivedocuments are unclear or non-unique and then pre-cludes such misleading synthetic supervision databy assigning them zero weights..5043