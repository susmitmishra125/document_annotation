robustness testing of language understanding in task-oriented dialog.
jiexi liu1∗, ryuichi takanobu1∗, jiaxin wen1, dazhen wan1,hongguang li2, weiran nie2, cheng li2, wei peng2, minlie huang1†1coai group, dcst, iai, bnrist, tsinghua university, beijing, china2huawei technologies, shenzhen, china{liujiexi19, gxly19}@mails.tsinghua.edu.cn, aihuang@tsinghua.edu.cn.
abstract.
most language understanding models in task-oriented dialog systems are trained on a smallamount of annotated training data, and evalu-ated in a small set from the same distribution.
however, these models can lead to system fail-ure or undesirable output when being exposedto natural language perturbation or variation inin this paper, we conduct compre-practice.
hensive evaluation and analysis with respect tothe robustness of natural language understand-ing models, and introduce three important as-pects related to language understanding in real-world dialog systems, namely, language vari-ety, speech characteristics, and noise pertur-bation.
we propose a model-agnostic toolkitlaug to approximate natural language pertur-bations for testing the robustness issues in task-oriented dialog.
four data augmentation ap-proaches covering the three aspects are assem-bled in laug, which reveals critical robust-ness issues in state-of-the-art models.
the aug-mented dataset through laug can be used tofacilitate future research on the robustness test-ing of language understanding in task-orienteddialog..1.introduction.
recently task-oriented dialog systems have been at-tracting more and more research efforts (gao et al.,2019; zhang et al., 2020b), where understandinguser utterances is a critical precursor to the suc-cess of such dialog systems.
while modern neuralnetworks have achieved state-of-the-art results onlanguage understanding (lu) (wang et al., 2018;zhao and feng, 2018; goo et al., 2018; liu et al.,2019; shah et al., 2019), their robustness to changesin the input distribution is still one of the biggestchallenges in practical use..∗equal contribution.
†corresponding author..real dialogs between human participants in-volve language phenomena that do not contributeso much to the intent of communication.
as shownin fig.
1, user expressions can be of high lexicaland syntactic diversity when a system is deployedto users; typed texts may differ signiﬁcantly fromthose recognized from voice speech; interactionenvironments may be full of chaos and even usersthemselves may introduce irrelevant noises suchthat the system can hardly get clean user input..unfortunately, neural lu models are vulnerableto these natural perturbations that are legitimateinputs but not observed in training data.
for ex-ample, bickmore et al.
(2018) found that popularconversational assistants frequently failed to under-stand real health-related scenarios and were unableto deliver adequate responses on time.
althoughmany studies have discussed the lu robustness(ray et al., 2018; zhu et al., 2018; iyyer et al.,2018; yoo et al., 2019; ren et al., 2019; jin et al.,2020; he et al., 2020), there is a lack of systematicstudies for real-life robustness issues and corre-sponding benchmarks for evaluating task-orienteddialog systems..in order to study the real-world robustness is-sues, we deﬁne the lu robustness from three as-pects: language variety, speech characteristics andnoise perturbation.
while collecting dialogs fromdeployed systems could obtain realistic data distri-bution, it is quite costly and not scalable since alarge number of conversational interactions withreal users are required.
therefore, we propose anautomatic method laug for language understand-ing augmentation in this paper to approximate thenatural perturbations to existing data.
laug is ablack-box testing toolkit on lu robustness com-posed of four data augmentation methods, includ-ing word perturbation, text paraphrasing, speechrecognition, and speech disﬂuency..we instantiate laug on two dialog corpora.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2467–2480august1–6,2021.©2021associationforcomputationallinguistics2467frames (el asri et al., 2017) and multiwoz(budzianowski et al., 2018) to demonstrate thetoolkit’s effectiveness.
quality evaluation by an-notators indicates that the utterances augmentedby laug are reasonable and appropriate with re-gards to each augmentation approach’s target.
anumber of lu models with different categories andtraining paradigms are tested as base models within-depth analysis.
experiments indicate a sharpperformance decline in most baselines in terms ofeach robustness aspect.
real user evaluation furtherveriﬁes that laug well reﬂects real-world robust-ness issues.
since our toolkit is model-agnostic anddoes not require model parameters or gradients, theaugmented data can be easily obtained for bothtraining and testing to build a robust dialog system.
our contributions can be summarized as follows:(1) we classify the lu robustness systematicallyinto three aspects that occur in real-world dialog,including linguistic variety, speech characteristicsand noise perturbation; (2) we propose a generaland model-agnostic toolkit, laug, which is an in-tegration of four data augmentation methods on luthat covers the three aspects.
(3) we conduct anin-depth analysis of lu robustness on two dialogcorpora with a variety of baselines and standardizedevaluation measures.
(4) quality and user evalua-tion results demonstrate that the augmented dataare representative of real-world noisy data, there-fore can be used for future research to test the lurobustness in task-oriented dialog1..2 robustness type.
we summarize several common interleaved chal-lenges in language understanding from three as-pects, as shown in fig.
1b:.
language variety a modern dialog system in atext form has to interact with a large variety of realusers.
the user utterances can be characterized bya series of linguistic phenomena with a long tailof variations in terms of spelling, vocabulary, lex-ical/syntactic/pragmatic choice (ray et al., 2018;jin et al., 2020; he et al., 2020; zhao et al., 2019;ganhotra et al., 2020)..speech characteristics the dialog system cantake voice input or typed text, but these two dif-fer in many ways.
for example, written language.
1the data, toolkit, and codes are available at https://github.com/thu-coai/laug, and will be mergedinto https://github.com/thu-coai/convlab-2(zhu et al., 2020)..(a) dataset construction.
(b) real-world application.
figure 1: difference between dialogs collected fortraining and those for real-world applications..tends to be more complex and intricate with longersentences and many subordinate clauses, whereasspoken language can contain repetitions, incom-plete sentences, self-corrections and interruptions(wang et al., 2020a; park et al., 2019; wang et al.,2020b; honal and schultz, 2003; zhu et al., 2018)..noise perturbation most dialog systems aretrained only on noise-free interactions.
however,there are various noises in the real world, includingbackground noise, channel noise, misspelling, andgrammar mistakes (xu and sarikaya, 2014; li andqiu, 2020; yoo et al., 2019; henderson et al., 2012;ren et al., 2019)..3 laug: language understanding.
augmentation.
this section introduces commonly observed out-of-distribution data in real-world dialog into existingcorpora.
we approximate natural perturbations inan automatic way instead of collecting real data byasking users to converse with a dialog system..to achieve our goals, we propose a toolkit laug,for black-box evaluation of lu robustness.
it is anensemble of four data augmentation approaches,including word perturbation (wp), text paraphras-ing (tp), speech recognition (sr), and speechdisﬂuency (sd).
noting that laug is model-agnostic and can be applied to any lu datasettheoretically.
each augmentation approach tests.
2468workerwritetext datai want to go to leicester.diverse inputreal userspeechasrrandom noisenoisy inputuser crowdi’m planning a trip to leicester.a ticket to leicester, pleasei want to umgo to lester.i wamtto go to leicester.
one or two proposed aspects of robustness as table1 shows.
the intrinsic evaluation of the chosenapproaches will be given in sec.
4..capacityword perturbation (wp)text paraphrasing (tp)speech recognition (sr)speech disﬂuency (sd).
lv sc np√√√.
√.
√√.
table 1: the capacity that each augmentation methodevaluates, including language variety (lv), speechcharacteristics (sc) and noise perturbation (np)..task formulation given the dialog contextxt = {x2t−m, .
.
.
, x2t−1, x2t} at dialog turn t,where each x is an utterance and m is the sizeof sliding window that controls the length of uti-lizing dialog history, the model should recognizeyt, the dialog act (da) of x2t.
empirically, weset m = 2 in the experiment.
let u, s denote theset of user/system utterances, respectively.
then,we have x2t−2i ∈ u and x2t−2i−1 ∈ s. thetask of this paper is to examine different lu mod-els whether they can predict yt correctly given aperturbed input ˜xt.
the perturbation is only per-formed on user utterances..word perturbation inspired by eda (easydata augmentation) (wei and zou, 2019), we pro-pose its semantically conditioned version, sc-eda,which considers task-speciﬁc augmentation oper-ations in lu.
sc-eda injects word-level pertur-bation into each utterance x(cid:48) and updates its corre-sponding semantic label y(cid:48)..originaldasyno.
insertswapdeletesvrda.
i want to go to cambridge .
attraction { inform (dest = cambridge) }i wishing to go to cambridge .
i need want to go to cambridge .
i to want go to cambridge .
i want to go to cambridge .
i want to go to liverpool .
attraction { inform (dest = liverpool) }.
table 2: an sc-eda example.
syno., insert, swap anddelete are four operations described in eda, of whichthe dialog act is identical to the original one.
svr de-notes slot value replacement..table 2 shows an example of sc-eda.
originaleda randomly performs one of the four operations,including synonym replacement, random insertion,random swap and random deletion2.
noting that,to keep the label unchanged, words related to slot.
2see the eda paper for details of each operation..values of dialog acts are not modiﬁed in these fouroperations.
additionally, we design slot value re-placement, which changes the utterance and labelat the same time to test model’s generalization tounseen entities.
some randomly picked slot valuesare replaced by unseen values with the same slotname in the database or crawled from web sources.
for example in table 2, “cambridge” is replacedby “liverpool”, where both belong to the same slotname “dest” (destination)..synonym replacement and slot value replace-ment aim at increasing the language variety, whilerandom word insertion/deletion/swap test the ro-bustness of noise perturbation.
from another per-spective, four operations from eda perform aninvariance test, while slot value replacement con-ducts a directional expectation test according tochecklist (ribeiro et al., 2020)..text paraphrasing the target of text paraphras-ing is to generate a new utterance x(cid:48)(cid:54)= x whilemaintaining its dialog act unchanged, i.e.
y(cid:48) = y.we applied sc-gpt (peng et al., 2020), a ﬁne-tuned language model conditioned on the dialogacts, to paraphrase the sentences as data augmenta-tion.
speciﬁcally, it characterizes the conditionalprobability pθ(x|y) = (cid:81)kk=1 pθ(xk|x<k, y), wherex<k denotes all the tokens before the k-th position.
the model parameters θ are trained by maximizingthe log-likelihood of pθ..da train * { inform ( dest = cambridge ; arrive = 20:45 ) }text hi, i’m looking for a train that is going to cambridgeand arriving there by 20:45, is there anything like that?
da train { inform ( dest = cambridge ; arrive = 20:45 ) }text yes, to cambridge, and i would like to arrive by 20:45..table 3: a pair of examples that consider contextualresolution or not.
in the second example, the user omitsto claim that he wants a train in the second utterancesince he has mentioned this before..we observe that co-reference and ellipsis fre-quently occurs in user utterances.
therefore, wepropose different encoding strategies during para-phrasing to further evaluate each model’s capacityfor context resolution.
in particular, if the usermentions a certain domain for the ﬁrst time in adialog, we will insert a “*” mark into the sequen-tial dialog act y(cid:48) to indicate that the user tends toexpress without co-references or ellipsis, as shownin table 3. then sc-gpt is ﬁnetuned on the pro-cessed data so that it can be aware of dialog contextwhen generating paraphrases.
as a result, we ﬁnd.
2469that the average token length of generated utter-ances with/without “*” is 15.96/12.67 respectivelyafter sc-gpt’s ﬁnetuning on multiwoz..it should be noted that slot values of an utterancecan be paraphrased by models, resulting in a dif-ferent semantic meaning y(cid:48).
to prevent generatingirrelevant sentences, we apply automatic value de-tection in paraphrases with original slot values byfuzzy matching3 , and replace the detected valuesin bad paraphrases with original values.
in addi-tion, we ﬁlter out paraphrases that have missingor redundant information compared to the originalutterance..speech recognition we simulate the speechrecognition (sr) process with a tts-asr pipeline(park et al., 2019).
first we transfer textual userutterance x to its audio form a using gtts4 (oordet al., 2016), a text-to-speech system.
then audiodata is translated back into text x(cid:48) by deepspeech2(amodei et al., 2016), an automatic speech recog-nition (asr) system.
we directly use the releasedmodels in the deepspeech2 repository5 with theoriginal conﬁguration, where the speech model istrained on baidu internal english dataset, and thelanguage model is trained on commoncrawl data..typesimilar soundsliaisonspoken numbers.
originalleicesterfor 3 people13:45.augmentedlesterfree peoplethirteen forty ﬁve.
table 4: examples of speech recognition perturbation..table 4 shows some typical examples of our sraugmentation.
asr sometimes wrongly identiﬁesone word as another with similar pronunciation.
li-aison constantly occurs between successive words.
expressions with numbers including time and priceare written in numerical form but different in spo-ken language..since sr may modify the slot values in the trans-lated utterances, fuzzy value detection is employedhere to handle similar sounds and liaison problemswhen it extracts slot values to obtain a semantic la-bel y(cid:48).
however, we do not replace the noisy valuewith the original value as we encourage such mis-recognition in sr, thus y(cid:48) (cid:54)= y is allowed.
more-over, numerical terms are normalized to deal withthe spoken number problem.
most slot values could.
3https://pypi.org/project/fuzzywuzzy/4https://pypi.org/project/gtts/5https://github.com/paddlepaddle/.
deepspeech.
be relocated by our automatic value detection rules.
the remainder slot values which vary too muchto recognize are discarded along with their corre-sponding labels..speech disﬂuency disﬂuency is a common fea-ture of spoken language.
we follow the catego-rization of disﬂuency in previous works (lickley,1995; wang et al., 2020b): ﬁlled pauses, repeats,restarts, and repairs..i want to um go to uh cambridge..original i want to go to cambridge.
pausesrepeats i, i want to go to, go to cambridge.
restarts i just i want to go to cambridge.
repairs i want to go to liverpool, sorry i mean cambridge..table 5: example of four types of speech disﬂuency..we present some examples of sd in table 5.filler words (“um”, “uh”) are injected into the sen-tence to present pauses.
repeats are inserted by re-peating the previous word.
in order to approximatethe real distribution of disﬂuency, the interruptionpoints of ﬁlled pauses and repeats are predictedby a bi-lstm+crf model (zayats et al., 2016)trained on an annotated dataset switchboard (god-frey et al., 1992), which was collected from realhuman talks.
for restarts, we insert false start terms(“i just”) as a preﬁx of the utterance to simulateself-correction.
in lu task, we apply repairs on slotvalues to fool the models to predict wrong labels.
we take the original slot value as repair (“cam-bridge”) and take another value with the same slotname as reparandum (“liverpool”).
an edit term(“sorry, i mean”) is inserted between repair andreparandum to construct a correction.
the ﬁllerwords, restart terms, and edit terms and their occur-rence frequency are all sampled from their distribu-tion in switchboard..in order to keep the spans of slot values intact,each span is regarded as one whole word.
no inser-tions are allowed to operate inside the span.
there-fore, sd augmentation do not change the originalsemantic and labels of the utterance, i.e.
y(cid:48) = y..4 experimental setup.
4.1 data preparationin our experiments we adopt frames6 (el asri et al.,2017) and multiwoz (budzianowski et al., 2018),which are two task-oriented dialog datasets where.
6as data division was not deﬁned in frames, we split the.
data into training/validation/test set with a ratio of 8:1:1..2470(a) classiﬁcation-based language understanding.
(b) generation-based language understanding.
figure 2: an illustration of two categories of language understanding models.
dialog history is ﬁrst encoded asconditions (not depicted here)..semantic labels of user utterances are annotated.
in particular, multiwoz is one of the most chal-lenging datasets due to its multi-domain settingand complex ontology, and we conduct our exper-iments on the latest annotation-enhanced versionmultiwoz 2.3 (han et al., 2020), which providescleaned annotations of user dialog acts (i.e.
seman-tic labels).
the dialog act consists of four parts:domain, intent, slot names, and slot values.
thestatistics of two datasets are shown in table 6. fol-lowing takanobu et al.
(2020), we calculate overallf1 scores as evaluation metrics due to the multi-intent setting in lu..datasets# training dialogs# validation / test dialogs# domains / # intentsavg.
# turns per dialogavg.
# tokens per turnavg.
# das per turn.
frames1,095137 / 1372 / 127.6011.671.87.multiwoz8,4381,000 / 1,0007 / 56.8513.551.66.table 6: statistics of frames and multiwoz 2.3. onlyuser turns u are counted here..the data are augmented with the inclusion of itscopies, leading to a composite of all 4 augmenta-tion types with equal proportion.
other setups aredescribed in each experiment7..method.
wptpsrsd.
change rate/%.
char word16.017.974.460.314.57.930.422.7.slot36.313.340.80.4.human annot./%utter.
95.297.195.198.8.da97.097.796.799.2.table 7: statistics of augmented multiwoz data andtheir results of quality annotation.
automatic metricsinclude change rate of characters, words and slot val-ues.
quality evaluation includes appropriateness at ut-terance level (utter.)
and at dialog act level (da)..table 7 shows the change rates in different as-.
7see appendix for the hyperparameter setting of laug..pects by comparing our augmented utterances withthe original counterparts.
we could ﬁnd each aug-mentation method has a distinct effect on the data.
for instance, tp rewrites the text without changingthe original meaning, thus lexical and syntactic rep-resentations dramatically change, while most slotvalues remain unchanged.
in contrast, sr makesthe lowest change rate in characters and words butmodiﬁes the most slot values due to the speechmisrecognition..4.2 quality evaluation.
to ensure the quality of our augmented test set,we conduct human annotation on 1,000 sampledutterances in each augmented test set of multi-woz.
we ask annotators to check whether ouraugmented utterances are reasonable and our auto-detected value annotations are correct (two true-or-false questions).
according to the feature of eachaugmentation method, different evaluation proto-cols are used.
for tp and sd, annotators checkwhether the meaning of utterances and dialog actsare unchanged.
for wp, changing slot values isallowed due to slot value replacement, but the slotname should be the same.
for sr, annotators areasked to judge on the similarity of pronunciationrather than semantics.
in summary, all the highscores in table 7 demonstrate that laug makesreasonable augmented examples..4.3 baselines.
lu models roughly fallinto two categories:classiﬁcation-based and generation-based models.
classiﬁcation based models (hakkani-t¨ur et al.,2016; goo et al., 2018) extract semantics by intentdetection and slot tagging.
intent detection is com-monly regarded as a multi-label classiﬁcation task,and slot tagging is often treated as a sequence label-ing task with bio format (ramshaw and marcus,1999), as shown in fig.
2a.
generation-based mod-.
2471nlupleasefindmeatrainfromlosangelestosanfranciscooooooodepart-bdepart-iodest-bdest-itrain-informplease find me a train from los angeles to san franciscoencoderdecodertrain { inform ( depart = los angeles ; dest= san francisco ) }model.
milu.
bert.
tod-bert.
copynet.
gpt-2.
model.
milu.
bert.
tod-bert.
copynet.
gpt-2.
trainoriginalaugmentedoriginalaugmentedoriginalaugmentedoriginalaugmentedoriginalaugmented.
trainoriginalaugmentedoriginalaugmentedoriginalaugmentedoriginalaugmentedoriginalaugmented.
ori.
74.1575.7878.8278.2180.6180.3767.8469.3578.7879.15.ori.
91.3391.3993.4093.3293.2893.2990.9790.4991.5391.59.wp71.0572.4975.9276.7077.3077.3263.9067.1074.9675.25.tp69.5871.9674.5775.6376.1977.2661.4165.9072.8573.86.sr61.5364.7670.3172.0470.8872.5456.1160.9869.0071.37.
(a) framestp87.2088.0488.5189.4588.9589.7187.4089.5388.2389.92.wp88.2690.0190.9692.2391.2792.4085.2589.1985.3590.26.sr77.9886.9782.3589.8681.1690.0671.0685.6980.7486.55.
(b) multiwoz.
sd65.2770.9270.3177.3471.9479.0459.2667.7169.1974.19.sd83.6789.5485.9892.7187.1892.8577.6689.8384.3390.55.avg.
66.8670.0372.7875.4374.0876.5460.1765.4271.5073.67.avg.
84.2888.6486.9591.0687.1491.2680.3488.5684.6689.32.drop-7.29-5.75-6.04-2.78-6.53-3.83-7.67-3.93-7.28-5.48.drop-7.05-2.75-6.45-2.26-6.14-2.03-10.63-1.93-6.87-2.27.recov.
/+3.17/+2.65/+2.46/+5.25/+2.17.
recov.
/+4.36/+4.11/+4.12/+8.22/+4.66.
table 8: robustness test results.
ori.
stands for the original test set, wp, tp, sr, sd for 4 augmented test setsand avg.
for the average performance on 4 augmented test sets.
the additional data in augmented training set hasthe same utterance amount as the original training set and is composed of 4 types of augmented data with equalproportion.
drop shows the performance decline between avg.
and ori.
while recov.
denotes the performancerecovery of avg.
between training on augmented/original data (e.g., 88.64%-84.28% for milu on multiwoz)..els (liu and lane, 2016; zhao and feng, 2018) gen-erate a dialog act containing intent and slot values.
they treat lu as a sequence-to-sequence problemand transform a dialog act into a sequential struc-ture as shown in fig.
2b.
five base models withdifferent categories are used in the experiments, asshown in table 9..modelmilu (hakkani-t¨ur et al., 2016)bert (devlin et al., 2019)tod-bert (wu et al., 2020)copynet (gu et al., 2016)gpt-2 (radford et al., 2019).
cls.
gen.√√√.
√√.
plm.
√√.
√.
table 9: features of base models.
cls./gen.
denotesclassiﬁcation/generation-based models.
plm standsfor pre-trained language models..to support a multi-intent setting in classiﬁcation-based models, we decouple the lu process as fol-lows: ﬁrst perform domain classiﬁcation and in-tent detection, then concatenate two special tokenswhich indicate the detected domain and intent (e.g.
[restaurant][inf orm]) at the beginning of the in-put sequence, and last encode the new sequence topredict slot tags.
in this way, the model can addressoverlapping slot values when values are shared in.
different dialog acts..5 evaluation results.
5.1 main results.
we conduct robustness testing on all three capaci-ties for ﬁve base models using four augmentationmethods in laug.
all baselines are ﬁrst trainedon the original datasets, then ﬁnetuned on the aug-mented datasets.
overall f1-measure performanceon frames and multiwoz is shown in table 8.all experiments are conducted over 5 runs, andaveraged results are reported..robustness for each capacity can be measuredby performance drops on the corresponding aug-mented test sets.
all models achieve some perfor-mance recovery on augmented test sets after trainedon the augmented data, while keeping a compara-ble result on the original test set.
this indicates theeffectiveness of laug in improving the model’srobustness..we observe that pre-trained models outperformnon-pre-trained ones on both original and aug-mented test sets.
classiﬁcation-based modelshave better performance and are more robust thangeneration-based models.
tod-bert, the state-.
2472(a) bert.
(b) gpt-2.
figure 3: performance on multiwoz with different ratios of augmented training data amount to the original one.
the total amount of training data varies but they are always composed of 4 types of augmented data with evenproportion.
different test sets are shown with different colored lines..of-the-art model which was further pre-trained ontask-oriented dialog data, has comparable perfor-mance with bert.
with most augmentation meth-ods, tod-bert shows slightly better robustnessthan bert..since the data volume of frames is far less thanthat of multiwoz, the performance improvementof pre-trained models on frames is larger than thaton multiwoz.
due to the same reason, augmentedtraining data beneﬁts the non-pre-trained modelsperformance of on ori.
test set more remarkably inframes where data is not sufﬁcient..among the four augmentation methods, sr hasthe largest impact on the models’ performance, andsd comes the second.
the dramatic performancedrop when testing on sr and sd data indicates thatrobustness for speech characteristics may be themost challenging issue..fig.
3 shows how the performance of bert andgpt-2 changes on multiwoz when the ratio ofaugmented training data to the original data variesfrom 0.1 to 4.0. f1 scores on augmented test setsincrease when there are more augmented data fortraining.
the performance of bert on augmentedtest sets is improved when augmentation ratio isless than 0.5 but becomes almost unchanged af-ter 0.5 while gpt-2 keeps increasing stably.
thisresult shows the different characteristics betweenclassiﬁcation-based models and generation-basedmodels when ﬁnetuned with augmented data..5.2 ablation study.
in laug, we test the performance changes whenone augmentation approach is removed from con-structing augmented training data.
results on mul-tiwoz are shown in table 10..trainaug.-wp-tp-sr-sdori..trainaug.-wp-tp-sr-sdori..ori.
91.3991.2991.5591.2391.5691.33.ori.
93.3293.2393.0893.4393.1193.40.wp90.0188.4290.1590.1390.2488.26.wp92.2390.9492.2492.3092.1590.96.tp88.0488.4387.8188.3088.6087.20.
(a) milutp89.4589.4288.6289.5089.4488.51.
(b) bert.
sr86.9786.9886.8277.9086.7877.98.sr89.8689.9389.8083.4890.0082.35.sd89.5489.2089.4289.5183.9683.67.sd92.7192.8292.6293.0785.2285.98.avg.
88.6488.2688.5586.4687.4084.28.avg.
91.0690.7890.8289.5989.2086.95.table 10: ablation study between augmentation ap-proaches for two models on multiwoz.
highlightednumbers denote the most sharp decline for each aug-mented test set..large performance decline on each augmentedtest set is observed when the corresponding aug-mentation approach is removed in constructingtraining data.
the performance after removingan augmentation method is comparable to theone without augmented training data.
only slightchanges are observed without other approaches.
these results indicate that our four augmentationapproaches are relatively orthogonal..between augmentation approachesin order tostudy the inﬂuence of each augmentation approach.
within augmentation approach our imple-mentation of wp and sd consist of several func-.
247393.4493.2493.3292.7492.8291.0892.0292.2392.0692.3689.0789.3289.4589.7890.1988.0289.5589.8689.7390.2390.4592.5792.7192.7793.1989.66 90.87 91.06 91.09 91.49 84858687888990919293940.10.5124f1-measureaugmentationratioori.wptpsrsdavg.91.6491.5791.5990.8690.9589.4889.7290.2690.4590.4389.1989.4689.9290.3791.1284.0785.8686.5586.8887.6387.4389.7990.5590.7391.4487.54 88.71 89.32 89.61 90.16 84858687888990919293940.10.5124f1-measureaugmentationratioori.wptpsrsdavg.
tional components.
ablation experiments hereshow how much performance is affected by eachcomponent in augmented test sets..constructing a new test set in real scenarios8.
re-sults on this real test set are shown in table 12..testwp-syno.
-insert-delete-swap-slotori..testsd-repair-pause-restart-repeatori..milu diff.
88.2688.9088.9088.9789.1589.4591.33.
/0.640.640.710.891.193.05.bert diff.
90.9691.2791.3091.2091.3391.3093.40.
/0.480.510.410.540.512.61.
(a) word perturbation.
milu diff.
83.6789.4785.2184.0383.6491.33.
/5.801.540.36-0.037.66.bert diff.
85.9891.0588.0686.2285.6893.40.
/5.072.080.24-0.307.42.
(b) speech disﬂuency.
table 11: ablation study within two augmentation ap-proaches.
models are trained on original training set.
highlight stands for the component with the most inﬂu-ence on model performance..original eda consists of four functions as de-scribed in table 2. performance differences (diff.)
can reﬂect the inﬂuences of those components intable 11a.
the additional function of our sc-edais slot value replacement.
we can also observean increase in performance when it is removed,especially for milu.
this implies a lack of lurobustness in detecting unseen entities..table 11b shows the results of ablation studyon sd.
among the four types of disﬂuencies de-scribed in table 5, repairs has the largest impact onmodels’ performance.
the performance is also af-fected by pauses but to a less extent.
the inﬂuencesof repeats and restarts are small, which indicatesthat neural models are robust to handle these twoproblems..5.3 user evaluation.
in order to test whether the data automatically aug-mented by laug can reﬂect and alleviate practicalrobustness problems, we conduct a real user evalua-tion.
we collected 240 speech utterances from realhumans as follows: first, we sampled 120 com-binations of da from the test set of multiwoz.
given a combination, each user was asked to speaktwo utterances with different expressions, in theirown language habits.
then the audio signals wererecognized into text using deepspeech2, thereby.
model.
milu.
bert.
trainoriginalaugmentedoriginalaugmented.
ori.
91.3391.3993.4093.32.avg.
84.2888.6486.9591.06.real63.5566.7765.2269.12.table 12: user evaluation results on multiwoz.
ori.
and avg.
have the same meaning as the ones in table8, and real is the real user evaluation set..the performance on the real test set is substan-tially lower than that on ori.
and avg., indicatingthat real user evaluation is much more challenging.
this is because multiple robustness issues may beincluded in one real case, while each augmenta-tion method in laug evaluates them separately.
despite the difference, model performance on thereal data is remarkably improved after every modelis ﬁnetuned on the augmented data, verifying thatlaug effectively enhances the model’s real-worldrobustness..5.4 error analysis.
error type.
language varietyspeech characteristicsnoise perturbationothersmultiple issues.
bert ori.
%num43.82129.21425.01229.21425.012.bert aug.num%45.52025.01122.71031.81425.011.table 13: error analysis of bert in user evaluation..table 13 investigates which error type the modelhas made on the real test set by manually checkingall the error outputs of bert ori.
“others” arethe error cases which are not caused by robustnessissues, for example, because of the model’s poorperformance.
it can be observed that the modelseriously suffers to lu robustness (over 70%), andthat almost half of the error is due to languagevariety.
we ﬁnd that this is because there are morediverse expressions in real user evaluation than inthe original data.
after augmented training, we canobserve that the number of error cases of speechcharacteristics and noise perturbation is relativelydecreased.
this shows that bert aug. can solvethese two kinds of problems better.
noting thatthe sum of four percentages is over 100% since25% error cases involve multiple robustness issues..8see appendix for details on real data collection..2474this again demonstrates that real user evaluation ismore challenging than the original test set9..6 related work.
robustness in lu has always been a challenge intask-oriented dialog.
several studies have investi-gated the model’s sensitivity to the collected datadistribution, in order to prevent models from over-ﬁtting to the training data and improve robustnessin the real world.
kang et al.
(2018) collected di-alogs with templates and paraphrased with crowd-sourcing to achieve high coverage and diversity intraining data.
dinan et al.
(2019) proposed a train-ing schema that involves human in the loop in dia-log systems to enhance the model’s defense againsthuman attack in an iterative way.
ganhotra et al.
(2020) injected natural perturbation into the dialoghistory manually to reﬁne over-controlled data gen-erated through crowd-sourcing.
all these methodsrequire laborious human intervention.
this paperaims to provide an automatic way to test the lurobustness in task-oriented dialog..various textual adversarial attacks (zhang et al.,2020a) have been proposed and received increasingattentions these years to measure the robustness of avictim model.
most attack methods perform white-box attacks (papernot et al., 2016; li et al., 2019;ebrahimi et al., 2018) based on the model’s internalstructure or gradient signals.
even some black-boxattack models are not purely “black-box”, whichrequire the prediction scores (classiﬁcation proba-bilities) of the victim model (jin et al., 2020; renet al., 2019; alzantot et al., 2018).
however, allthese methods address random perturbation but donot consider linguistic phenomena to evaluate thereal-life generalization of lu models..while data augmentation can be an efﬁcientmethod to address data sparsity, it can improve thegeneralization abilities and measure the model ro-bustness as well (eshghi et al., 2017).
paraphrasingthat rewrites the utterances in dialog has been usedto get diverse representation and thus enhancing ro-bustness (ray et al., 2018; zhao et al., 2019; iyyeret al., 2018).
word-level operations (kolomiyetset al., 2011; li and qiu, 2020; wei and zou, 2019)including replacement, insertion, and deletion werealso proposed to increase language variety.
otherstudies (shah et al., 2019; xu and sarikaya, 2014)worked on the out-of-vocabulary problem when fac-ing unseen user expression.
some other research.
9see appendix for case study..focused on building robust spoken language under-standing (zhu et al., 2018; henderson et al., 2012;huang and chen, 2019) from audio signals beyondtext transcripts.
simulating asr errors (schatz-mann et al., 2007; park et al., 2019; wang et al.,2020a) and speaker disﬂuency (wang et al., 2020b;qader et al., 2018) can be promising solutions toenhance robustness to voice input when only tex-tual data are provided.
as most work tackles lurobustness from only one perspective, we presenta comprehensive study to reveal three critical is-sues in this paper, and shed light on a thoroughrobustness evaluation of lu in dialog systems..7 conclusion and discussion.
in this paper, we present a systematic robustnessevaluation of language understanding (lu) in task-oriented dialog from three aspects: language va-riety, speech characteristics, and noise perturba-tion.
accordingly, we develop four data augmenta-tion methods to approximate these language phe-nomena.
in-depth experiments and analysis areconducted on multiwoz and frames, with bothclassiﬁcation- and generation-based lu models.
the performance drop of all models on augmentedtest data indicates that these robustness issues arechallenging and critical, while pre-trained modelsare relatively more robust to lu.
ablation studiesare carried out to show the effect and orthogonalityof each augmentation approach.
we also conduct areal user evaluation and veriﬁes that our augmen-tation methods can reﬂect and help alleviate realrobustness problems..existing and future dialog models can be eval-uated in terms of robustness with our toolkit anddata, as our augmentation model does not dependon any particular lu models.
moreover, our pro-posed robustness evaluation scheme is extensible.
in addition to the four approaches in laug, moremethods to evaluate lu robustness can be consid-ered in the future..acknowledgments.
this work was partly supported by the nsfcprojects (key project with no.
61936010 and reg-ular project with no.
61876096).
this work wasalso supported by the guoqiang institute of ts-inghua university, with grant no.
2019gqg1 and2020gqg0005.
we would like to thank colleaguesfrom huawei for their constant support and valu-able discussion..2475references.
moustafa alzantot, yash sharma, ahmed elgohary,bo-jhang ho, mani srivastava, and kai-wei chang.
2018. generating natural language adversarial ex-amples.
in proceedings of the 2018 conference onempirical methods in natural language processing,pages 2890–2896..dario amodei, sundaram ananthanarayanan, rishitaanubhai, jingliang bai, eric battenberg, carl case,jared casper, bryan catanzaro, qiang cheng, guo-liang chen, et al.
2016. deep speech 2: end-to-endspeech recognition in english and mandarin.
in in-ternational conference on machine learning, pages173–182..timothy w bickmore, ha trinh, stefan olafsson,teresa k o’leary, reza asadi, nathaniel m rick-les, and ricardo cruz.
2018. patient and consumersafety risks when using conversational assistants formedical information: an observational study of siri,alexa, and google assistant.
journal of medical in-ternet research, 20(9):e11510..paweł budzianowski, tsung-hsien wen, bo-hsiangtseng, i˜nigo casanueva, stefan ultes, osman ra-madan, and milica gasic.
2018. multiwoz-a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling.
in proceedings of the2018 conference on empirical methods in naturallanguage processing, pages 5016–5026..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 1 (long and short papers), pages4171–4186..emily dinan, samuel humeau, bharath chintagunta,and jason weston.
2019. build it break it ﬁx it fordialogue safety: robustness from adversarial humanin proceedings of the 2019 conference onattack.
empirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages4529–4538..javid ebrahimi, anyi rao, daniel lowd, and dejingdou.
2018. hotﬂip: white-box adversarial exam-in proceedings of theples for text classiﬁcation.
56th annual meeting of the association for compu-tational linguistics (volume 2: short papers), pages31–36..layla el asri, hannes schulz, shikhar kr sarma,jeremie zumer, justin harris, emery fine, rahulmehrotra, and kaheer suleman.
2017. frames: acorpus for adding memory to goal-oriented dialoguein proceedings of the 18th annual sig-systems.
dial meeting on discourse and dialogue, pages 207–219..arash eshghi, igor shalyminov, and oliver lemon.
2017. bootstrapping incremental dialogue systemsfrom minimal data: the generalisation power of di-alogue grammars.
in proceedings of the 2017 con-ference on empirical methods in natural languageprocessing, pages 2220–2230..jatin ganhotra, robert c moore, sachindra joshi, andkahini wadhawan.
2020. effects of naturalistic vari-ation in goal-oriented dialog.
in proceedings of the2020 conference on empirical methods in naturallanguage processing: findings, pages 4013–4020..jianfeng gao, michel galley, and lihong li.
2019.neural approaches to conversational ai.
founda-tions and trends r(cid:13) in information retrieval, 13(2-3):127–298..john j godfrey, edward c holliman, and jane mc-daniel.
1992. switchboard: telephone speech cor-in acoustics,pus for research and development.
speech, and signal processing, ieee internationalconference on, volume 1, pages 517–520.
ieeecomputer society..chih-wen goo, guang gao, yun-kai hsu, chih-lihuo, tsung-chieh chen, keng-wei hsu, and yun-nung chen.
2018. slot-gated modeling for jointslot ﬁlling and intent prediction.
in proceedings ofthe 2018 conference of the north american chap-ter of the association for computational linguistics:human language technologies, volume 2 (short pa-pers), pages 753–757..jiatao gu, zhengdong lu, hang li, and victor okincorporating copying mechanism inli.
2016.in proceedings ofsequence-to-sequence learning.
the 54th annual meeting of the association for com-putational linguistics (volume 1: long papers),pages 1631–1640..dilek hakkani-t¨ur, gokhan tur, asli celikyilmaz,yun-nung chen, jianfeng gao, li deng, and ye-yi wang.
2016. multi-domain joint semantic frameinterspeechparsing using bi-directional rnn-lstm.
2016, pages 715–719..ting han, ximing liu, ryuichi takanobu, yixinlian, chongxuan huang, wei peng, and minliehuang.
2020. multiwoz 2.3: a multi-domain task-oriented dataset enhanced with annotation correc-tions and co-reference annotation.
arxiv preprintarxiv:2010.05594..keqing he, yuanmeng yan, and xu weiran.
2020.learning to tag oov tokens by integrating contextualrepresentation and background knowledge.
in pro-ceedings of the 58th annual meeting of the associa-tion for computational linguistics, pages 619–624..matthew henderson, milica gaˇsi´c, blaise thomson,pirros tsiakoulis, kai yu, and steve young.
2012.discriminative spoken language understanding us-ing word confusion networks.
in 2012 ieee spokenlanguage technology workshop (slt), pages 176–181. ieee..2476matthias honal and tanja schultz.
2003. correctionof disﬂuencies in spontaneous speech using a noisy-channel approach.
in eighth european conferenceon speech communication and technology, pages2781–2784..chao-wei huang and yun-nung chen.
2019. adapt-ing pretrained transformer to lattices for spokenin 2019 ieee automaticlanguage understanding.
speech recognition and understanding workshop(asru), pages 845–852.
ieee..mohit iyyer, john wieting, kevin gimpel, and lukezettlemoyer.
2018. adversarial example generationwith syntactically controlled paraphrase networks.
in proceedings of the 2018 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long papers), pages 1875–1885..di jin, zhijing jin, joey tianyi zhou, and peterszolovits.
2020. is bert really robust?
a strong base-line for natural language attack on text classiﬁcationin proceedings of the aaai con-and entailment.
ference on artiﬁcial intelligence, volume 34, pages8018–8025..yiping kang, yunqi zhang, jonathan k kummerfeld,lingjia tang, and jason mars.
2018. data collec-tion for dialogue system: a startup perspective.
inproceedings of the 2018 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 3 (industry papers), pages 33–40..oleksandr kolomiyets, steven bethard, and marie-francine moens.
2011. model-portability experi-in proceed-ments for textual temporal analysis.
ings of the 49th annual meeting of the associationfor computational linguistics: human language tech-nologies, volume 2, pages 271–276..sungjin lee, qi zhu, ryuichi takanobu, zheng zhang,yaoqin zhang, xiang li, jinchao li, baolin peng,xiujun li, minlie huang, et al.
2019. convlab:multi-domain end-to-end dialog system platform.
in proceedings of the 57th annual meeting of theassociation for computational linguistics: systemdemonstrations, pages 64–69..jinfeng li, shouling ji, tianyu du, bo li, and tingwang.
2019. textbugger: generating adversarialin 26th an-text against real-world applications.
nual network and distributed system security sym-posium..linyang li and xipeng qiu.
2020..textat: ad-versarial training for natural language understand-ing with token-level perturbation.
arxiv preprintarxiv:2004.14543..robin j lickley.
1995. missing disﬂuencies.
in pro-ceedings of the international congress of phoneticsciences, volume 4, pages 192–195..bing liu and ian lane.
2016. attention-based recur-rent neural network models for joint intent detectionand slot ﬁlling.
interspeech 2016, pages 685–689..yijin liu, fandong meng, jinchao zhang, jie zhou,yufeng chen, and jinan xu.
2019. cm-net: a novelcollaborative memory network for spoken languageunderstanding.
in proceedings of the 2019 confer-ence on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 1050–1059..aaron van den oord, sander dieleman, heiga zen,karen simonyan, oriol vinyals, alex graves,nal kalchbrenner, andrew senior, and koraykavukcuoglu.
2016. wavenet: a generative modelfor raw audio.
arxiv preprint arxiv:1609.03499..nicolas papernot, patrick mcdaniel, ananthramswami, and richard harang.
2016. crafting adver-sarial input sequences for recurrent neural networks.
in milcom 2016-2016 ieee military communica-tions conference, pages 49–54.
ieee..daniel s park, william chan, yu zhang, chung-chengchiu, barret zoph, ekin d cubuk, and quoc vle.
2019. specaugment: a simple data augmenta-tion method for automatic speech recognition.
inter-speech 2019, pages 2613–2617..baolin peng, chenguang zhu, chunyuan li, xiujunli, jinchao li, michael zeng, and jianfeng gao.
few-shot natural language generation for2020.in proceedings of the 2020task-oriented dialog.
conference on empirical methods in natural lan-guage processing: findings, pages 172–182..raheel qader, gw´enol´e lecorv´e, damien lolive, andpascale s´ebillot.
2018. disﬂuency insertion forspontaneous tts: formalization and proof of concept.
in international conference on statistical languageand speech processing, pages 32–44.
springer..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners.
openaiblog, 1(8):9..lance a ramshaw and mitchell p marcus.
1999. textchunking using transformation-based learning.
innatural language processing using very large cor-pora, pages 157–176.
springer..avik ray, yilin shen, and hongxia jin.
2018. ro-bust spoken language understanding via paraphras-ing.
interspeech 2018, pages 3454–3458..shuhuai ren, yihe deng, kun he, and wanxiang che.
2019. generating natural language adversarial ex-amples through probability weighted word saliency.
in proceedings of the 57th annual meeting of the as-sociation for computational linguistics, pages 1085–1097..2477kang min yoo, youhyun shin, and sang-goo lee.
2019. data augmentation for spoken language un-derstanding via joint variational generation.
in pro-ceedings of the aaai conference on artiﬁcial intelli-gence, volume 33, pages 7402–7409..vicky zayats, mari ostendorf, and hannaneh ha-jishirzi.
2016. disﬂuency detection using a bidirec-tional lstm.
interspeech 2016, pages 2523–2527..wei emma zhang, quan z sheng, ahoud alhazmi,and chenliang li.
2020a.
adversarial attacks ondeep-learning models in natural language process-ing: a survey.
acm transactions on intelligent sys-tems and technology (tist), 11(3):1–41..zheng zhang, ryuichi takanobu, qi zhu, minliehuang, and xiaoyan zhu.
2020b.
recent advancesand challenges in task-oriented dialog systems.
sci-ence china technological sciences, pages 1–17..lin zhao and zhe feng.
2018. improving slot ﬁllingin spoken language understanding with joint pointerin proceedings of the 56th annualand attention.
meeting of the association for computational lin-guistics (volume 2: short papers), pages 426–431..zijian zhao, su zhu, and kai yu.
2019. data augmen-tation with atomic templates for spoken languageunderstanding.
in proceedings of the 2019 confer-ence on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 3628–3634..qi zhu, zheng zhang, yan fang, xiang li, ryuichitakanobu, jinchao li, baolin peng, jianfeng gao,xiaoyan zhu, and minlie huang.
2020. convlab-2: an open-source toolkit for building, evaluating,in proceedingsand diagnosing dialogue systems.
of the 58th annual meeting of the association forcomputational linguistics: system demonstrations,pages 142–149..su zhu, ouyu lan, and kai yu.
2018. robust spo-ken language understanding with unsupervised asr-error adaptation.
in 2018 ieee international con-ference on acoustics, speech and signal processing(icassp), pages 6179–6183.
ieee..marco tulio ribeiro, tongshuang wu, carlos guestrin,and sameer singh.
2020. beyond accuracy: behav-in pro-ioral testing of nlp models with checklist.
ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4902–4912..jost schatzmann, blaise thomson, and steve young.
2007. error simulation for training statistical dia-in 2007 ieee workshop on auto-logue systems.
matic speech recognition & understanding (asru),pages 526–531.
ieee..darsh shah, raghav gupta, amir fayazi, and dilekhakkani-tur.
2019. robust zero-shot cross-domainslot ﬁlling with example values.
in proceedings ofthe 57th annual meeting of the association for com-putational linguistics, pages 5484–5490..ryuichi takanobu, qi zhu, jinchao li, baolin peng,jianfeng gao, and minlie huang.
2020. is your goal-oriented dialog model performing really well?
em-in pro-pirical analysis of system-wise evaluation.
ceedings of the 21th annual meeting of the specialinterest group on discourse and dialogue, pages297–310..longshaokan wang, maryam fazel-zarandi, aditya ti-wari, spyros matsoukas, and lazaros polymenakos.
2020a.
data augmentation for training dialog mod-els robust to speech recognition errors.
in proceed-ings of the 2nd workshop on natural language pro-cessing for conversational ai, pages 63–70..shaolei wang, wangxiang che, qi liu, pengda qin,ting liu, and william yang wang.
2020b.
multi-task self-supervised learning for disﬂuency detec-tion.
in proceedings of the aaai conference on ar-tiﬁcial intelligence, volume 34, pages 9193–9200..yu wang, yilin shen, and hongxia jin.
2018. a bi-model based rnn semantic frame parsing model forin proceedings ofintent detection and slot ﬁlling.
the 2018 conference of the north american chap-ter of the association for computational linguistics:human language technologies, volume 2 (short pa-pers), pages 309–314..jason wei and kai zou.
2019. eda: easy data augmen-tation techniques for boosting performance on textclassiﬁcation tasks.
in proceedings of the 2019 con-ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 6383–6389..chien-sheng wu, steven ch hoi, richard socher, andcaiming xiong.
2020. tod-bert: pre-trained naturallanguage understanding for task-oriented dialogue.
in proceedings of the 2020 conference on empiricalmethods in natural language processing (emnlp),pages 917–929..puyang xu and ruhi sarikaya.
2014. targeted featuredropout for robust slot ﬁlling in natural language un-derstanding.
in interspeech 2014, pages 258–262..2478a experimental setup.
a.1 hyperparameters.
as for hyperparameters in laug, we set the ratioof perturbation number to text length α = n/l =0.1 in eda .
the learning rate used to ﬁnetunesc-gpt in tp is 1e-4, the number of trainingepoch is 5, and the beam size during inferenceis 5. in sr, the beam size of the language modelin deepspeech2 is set to 50. the learning rate ofbi-lstm+crf in sd is 1e-3.
the threshold offuzzy matching in automatic value detection is setto 0.9 in tp and 0.7 in sr..for hyperparameters of base models.
the learn-ing rate is set to 1e-4 for bert, 1e-5 for gpt2,and 1e-3 for milu and copynet.
the beam-sizeof gpt2 and copynet is 5 during the decodingstep..a.2 real data collection.
among the 120 sampled da combinations, eachcombination contains 1 to 3 das.
users can or-ganize the das in any order provided that theydescribe das with the correct meaning so as toimitate diverse user expressions in real scenarios.
users are also asked to keep natural in both into-nation and expression, and communication noisecaused by users in speech and language is includedduring collection.
the audios are recorded by users’pcs under their real environmental noises.
we usethe same settings of deepspeech2 in sr to rec-ognize the collected audios.
after automatic spandetection (also the same as sr’s) are applied, weconduct human check and annotation to ensure thequality of labels..b evaluation results.
b.1 prediction schemes.
model.
train.
milu.
bert.
ori.
scheme85.52coupleddecoupled 91.3390.00coupleddecoupled 91.3988.94coupleddecoupled 93.4088.84coupleddecoupled 93.32.ori..aug..ori..aug..avg.
82.9184.2888.1588.6480.3386.9588.6391.06.drop-2.61-7.05-1.85-2.75-8.61-6.45-0.21-2.26.table 14: robustness on different schemes on multi-woz.
the coupled scheme predicts dialog acts witha joint tagging scheme; the decoupled scheme ﬁrst de-tects domains and intents, then recognizes the slot tags..in this section, we study the inﬂuence of train-ing/prediction schemes on lu robustness.
as de-scribed in sec.
4.3 of the main paper, the processof classiﬁcation-based lu models is decoupledinto two steps to handle multiple labels: one fordomain/intent classiﬁcation and the other for slottagging.
another strategy is to use the cartesianproduct of all the components of dialog acts, whichyields a joint tagging scheme as presented in con-vlab (lee et al., 2019).
to give an intuitive illus-tration, the slot tag of the token “los” becomes“train-inform-depart-b” in the example describedin fig.
2 of the main paper.
the classiﬁcation-based models can predict the dialog acts within asingle step in this way..table 14 shows that milu and bert gainfrom the decoupled scheme on the original testset.
this indicates that the decoupled scheme de-creases the model complexity by decomposing theinterestingly, there is no consis-output space.
tency between two models in terms of robustness.
milu via the coupled scheme behaves more ro-bustly than the decoupled counterpart (-2.61 vs.-7.05), while bert with the decoupled scheme out-performs its coupled version in robustness (-6.45vs. -8.61).
meanwhile, bert beneﬁts from thedecoupled scheme and still achieves 86.95% accu-racy, but bert training with the coupled schemeseems more susceptible.
in addition, both miluand bert recover more performance by the pro-posed decoupled scheme.
all these results demon-strate the superiority of the decoupled scheme inclassiﬁcation-based lu models..b.2 case study.
in table 15, we present some examples of aug-mented utterances in multiwoz.
in terms of modelperformance, milu, bert and gpt-2 performwell on wp and tp in the example while copy-net misses some dialog acts.
for the sr utterance,only bert obtains all the correct labels.
miluand copynet both fail to ﬁnd the changed valuespans “lester” and “thirteen forty ﬁve”.
copynet’scopy mechanism is fully confused by recognitionerror and even predicts discontinuous slot values.
gpt-2 successfully ﬁnds the non-numerical timebut misses “leseter”.
in the sd utterance, the repairterm fools all the models.
overall, in this example,bert performs quite well while milu and copy-net expose some of their defects in robustness..table 16 shows some examples from real user.
2479ori.
goldenwpgoldenmilubertcopygpt-2tpgoldenmilubertcopygpt-2srgoldenmilubertcopygpt-2sd.
goldenmilubertcopygpt-2.
i ’m leaving from leicester and should arrive in cambridge by 13:45.train { inform ( dest = cambridge ; arrive = 13:45 ; depart = leicester ) }i ’m leaving from leicester and {in}swap arrive {should}swap cambridge by {06:54}replace.
train { inform ( dest = cambridge ; arrive = 06:54 ; depart = leicester ) }train { inform ( dest = cambridge ; arrive = 06:54 ; depart = leicester ) }train { inform ( dest = cambridge ; arrive = 06:54 ; depart = leicester ) }train { inform ( dest = cambridge ; depart = leicester ) }train { inform ( dest = cambridge ; arrive = 06:54 ; depart = leicester ) }departing from leicester and going to cambridge.
i need to arrive by 13:45.train { inform ( dest = cambridge ; arrive = 13:45 ; depart = leicester ) }train { inform ( dest = cambridge ; arrive = 13:45 ; depart = leicester ) }train { inform ( dest = cambridge ; arrive = 13:45 ; depart = leicester ) }train { inform ( arrive = 13:45 ; depart = leicester ) }train { inform ( dest = cambridge ; arrive = 13:45 ; depart = leicester ) }i’m leaving from {lester}similar and should arrive in cambridge by {thirteen forty ﬁve}spoken.
train { inform ( dest = cambridge ; arrive = thirteen forty ﬁve ; depart = lester ) }train { inform ( dest = cambridge ) }train { inform ( dest = cambridge ; arrive = thirteen forty ﬁve ; depart = lester ) }train { inform ( dest = cambridge forty ; depart = lester ) }train { inform ( dest = cambridge ; arrive = thirteen forty ﬁve ) }{well, you know,}restart i ’m leaving from leicester and should arrive in {king’s college sorry, i mean}repaircambridge by 13:45.train { inform ( dest = cambridge ; arrive = 13:45 ; depart = leicester ) }train { inform ( dest = king ; arrive = 13:45 ; depart = leicester ) }train { inform ( dest = king ’s college ; arrive = 13:45 ; depart = leicester ) }train { inform ( arrive = 13:45 ; depart = leicester ) }train { inform ( dest = king ’s college ; arrive = 13:45 ; depart = leicester ) }.
table 15: augmented examples and corresponding model outputs.
all models are trained on the original data only.
wrong values are colored in blue..the train from cambridge arrives at seventeen o’clock.
case-1train { inform ( dest = cambridge ; arrive = seventeen o’clock ) }goldentrain { inform ( dest = cambridge ) }milu ori.
train { inform ( dest = cambridge ; arrive = seventeen o’clock ) }milu aug.train { inform ( dest = cambridge ; arrive = seventeen ) }bert ori.
train { inform ( dest = cambridge ; arrive = seventeen o’clock ) }bert aug.a ticket departs from cambridge and arrives at bishops stortford the police.
case-2train { inform ( depart = cambridge ; dest= bishops stortford ) }goldentrain { inform ( depart = cambridge ; dest= bishops stortford ; dest= police) }milu ori.
train { inform ( depart = cambridge ; dest= bishops stortford ) }milu aug.train { inform ( depart = cambridge ; dest= bishops stortford ) }bert ori.
train { inform ( depart = cambridge ; dest= bishops stortford ) }bert aug.how much should i pay for the train ticket?
case-3train { request ( ticket = ? )
}goldennonemilu ori.
train { request ( ticket = ? )
}milu aug.bert ori.
nonebert aug. none.
table 16: user evaluation examples and corresponding model outputs.
ori.
and aug. stand for model before/afteraugmented training..different way comparing to the dataset.
milu andbert failed in most of these cases but ﬁxed someerror after augmented training..evaluation.
in case-1, the user says “seventeeno’clock” while time is always represented in nu-meric formats (e.g.
“17:00”) in the dataset, whichis a typical speech characteristics problem.
case-2 could be regarded as a speech characteristicsor noise perturbation case because “please” iswrongly recognized as “police” by asr models.
case-3 is an example of language variety, the userexpresses the request of getting ticket price in a.
2480