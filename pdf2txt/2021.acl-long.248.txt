few-nerd: a few-shot named entity recognition dataset.
ning ding1,3∗ , guangwei xu2∗, yulin chen3∗, xiaobin wang2,xu han1, pengjun xie2, hai-tao zheng3†, zhiyuan liu1†1department of computer science and technology, tsinghua university2alibaba group, 3shenzhen international graduate school, tsinghua university{dingn18, yl-chen17, hanxu17}@mails.tsinghua.edu.cn{kunka.xgw, xuanjie.wxb, chengchen.xpj}@alibaba-inc.com{zheng.haitao}@sz.tsinghua.edu.cn, {liuzy}@tsinghua.edu.cnhttps://ningding97.github.io/fewnerd/.
abstract.
recently, considerable literature has grown uparound the theme of few-shot named entityrecognition (ner), but little published bench-mark data speciﬁcally focused on the practicaland challenging task.
current approaches col-lect existing supervised ner datasets and re-organize them into the few-shot setting for em-pirical study.
these strategies conventionallyaim to recognize coarse-grained entity typeswith few examples, while in practice, mostunseen entity types are ﬁne-grained.
in thispaper, we present few-nerd, a large-scalehuman-annotated few-shot ner dataset witha hierarchy of 8 coarse-grained and 66 ﬁne-grained entity types.
few-nerd consists of188,238 sentences from wikipedia, 4,601,160words are included and each is annotated ascontext or a part of a two-level entity type.
to the best of our knowledge, this is the ﬁrstfew-shot ner dataset and the largest human-crafted ner dataset.
we construct bench-mark tasks with different emphases to com-prehensively assess the generalization capabil-ity of models.
extensive empirical results andanalysis show that few-nerd is challeng-ing and the problem requires further research.
we make few-nerd public at https://ningding97.github.io/fewnerd/.
1.
1.introduction.
named entity recognition (ner), as a fundamentaltask in information extraction, aims to locate andclassify named entities from unstructured naturallanguage.
a considerable number of approachesequipped with deep neural networks have shownpromising performance (chiu and nichols, 2016)on fully supervised ner.
notably, pre-trained lan-guage models (e.g., bert (devlin et al., 2019a)).
∗ equal contributions† corresponding authors1the baselines are available at https://github..com/thunlp/few-nerd.
figure 1: an overview of few-nerd.
the inner cir-cle represents the coarse-grained entity types and theouter circle represents the ﬁne-grained entity types,some types are denoted by abbreviations..with an additional classiﬁer achieve signiﬁcant suc-cess on this task and gradually become the baseparadigm.
such studies demonstrate that deep mod-els could yield remarkable results accompanied bya large amount of annotated corpora..with the emerging of knowledge from variousdomains, named entities, especially ones that needprofessional knowledge to understand, are difﬁ-cult to be manually annotated on a large scale.
under this circumstance, studying ner systemsthat could learn unseen entity types with few ex-amples, i.e., few-shot ner, plays a critical rolein this area.
there is a growing body of litera-ture that recognizes the importance of few-shotner and contributes to the task (hofer et al., 2018;fritzler et al., 2019; yang and katiyar, 2020; liet al., 2020a; huang et al., 2020).
unfortunately,there is still no dataset speciﬁcally designed for.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3198–3213august1–6,2021.©2021associationforcomputationallinguistics3198    organization      location  person artbuildingevent  misc product      airport       war     gpebodiesofwaterisland    companyeducationgovernmentmediaotherpoliticalparty    astronomy           actorartist/authorathletedirectorother   airplane        broadcastfilmmusic            disasterelection      mountain         religionshoworgsportsleague  awardbiologychemicalcurrencydisease               carfood         otherpainting  hospitalhotellibraryother             otherparktransit         sportsteam      edudegreegodlanguagelawlivingthingmedical     politicianscholarsoldier   gameothershipsoftwaretrain                                                                   few-shot ner.
hence, these methods collect pre-viously proposed supervised ner datasets and re-organize them into a few-shot setting.
commonoptions of datasets include ontonotes (weischedelet al., 2013), conll’03 (tjong kim sang, 2002),wnut’17 (derczynski et al., 2017), etc.
theseresearch efforts of few-shot learning for namedentities mainly face two challenges: first, mostdatasets used for few-shot learning have only 4-18 coarse-grained entity types, making it hard toconstruct an adequate variety of “n-way” meta-tasks and learn correlation features.
and in real-ity, we observe that most unseen entities are ﬁne-grained.
second, because of the lack of benchmarkdatasets, the settings of different works are inconsis-tent (huang et al., 2020; yang and katiyar, 2020),leading to unclear comparisons.
to sum up, thesemethods make promising contributions to few-shotner, nevertheless, a speciﬁc dataset is urgentlyneeded to provide a uniﬁed benchmark dataset forrigorous comparisons..to alleviate the above challenges, we present alarge-scale human-annotated few-shot ner dataset,few-nerd, which consists of 188.2k sentencesextracted from the wikipedia articles and 491.7kentities are manually annotated by well-trained an-notators (section 4.3).
to the best of our knowl-edge, few-nerd is the ﬁrst dataset specially con-structed for few-shot ner and also one of thelargest human-annotated ner dataset (statisticsin section 5.1).
we carefully design an annota-tion schema of 8 coarse-grained entity types and66 ﬁne-grained entity types by conducting severalpre-annotation rounds.
(section 4.1).
in contrast,as the most widely-used ner datasets, conllhas 4 entity types, wnut’17 has 6 entity typesand ontonotes has 18 entity types (7 of them arevalue types).
the variety of entity types makesfew-nerd contain rich contextual features witha ﬁner granularity for better evaluation of few-shot ner.
the distribution of the entity types infew-nerd is shown in figure 1, more details arereported in section 5.1. we conduct an analysis ofthe mutual similarities among all the entity typesof few-nerd to study knowledge transfer (sec-tion 5.2).
the results show that our dataset canprovide sufﬁcient correlation information betweendifferent entity types for few-shot learning..for benchmark settings, we design three taskson the basis of few-nerd, including a stan-dard supervised task (few-nerd (sup)) and two.
few-shot tasks (few-nerd-intra) and few-nrtd (inter)), for more details see section 6.few-nerd (sup), few-nerd (intra), andfew-nerd (inter) assess instance-level gener-alization, type-level generalization and knowledgetransfer of ner methods, respectively.
we im-plement models based on the recent state-of-the-art approaches and evaluate them on few-nerd(section 7).
and empirical results show thatfew-nerd is challenging on all these three set-tings.
we also conduct sets of subsidiary experi-ments to analyze promising directions of few-shotner.
hopefully, the research of few-shot nercould be further facilitated by few-nerd..2 related work.
as a pivotal task of information extraction, neris essential for a wide range of technologies (cuiet al., 2017; li et al., 2019b; ding et al., 2019; shenet al., 2020).
and a considerable number of nerdatasets have been proposed over the years.
forexample, conll’03 (tjong kim sang, 2002) is re-garded as one of the most popular datasets, which iscurated from reuters news and includes 4 coarse-grained entity types.
subsequently, a series of nerdatasets from various domains are proposed (bala-suriya et al., 2009; ritter et al., 2011; weischedelet al., 2013; stubbs and uzuner, 2015; derczynskiet al., 2017).
these datasets formulate a sequencelabeling task and most of them contain 4-18 entitytypes.
among them, due to the high quality andsize, ontonotes 5.0 (weischedel et al., 2013) isconsidered as one of the most widely used nerdatasets recently..as approaches equipped with deep neural net-works have shown satisfactory performance onner with sufﬁcient supervision (lample et al.,2016; ma and hovy, 2016), few-shot ner hasreceived increasing attention (hofer et al., 2018;fritzler et al., 2019; yang and katiyar, 2020; liet al., 2020a).
few-shot ner is a considerablychallenging and practical problem that could facil-itate the understanding of textual knowledge forneural model (huang et al., 2020).
due to the lackof speciﬁc benchmarks of few-shot ner, currentmethods collect existing ner datasets and use dif-ferent few-shot settings.
to provide a benchmarkthat could comprehensively assess the generaliza-tion of models under few examples, we annotatefew-nerd.
to make the dataset practical andclose to reality, we adopt a ﬁne-grained schema of.
3199entity annotation, which is inspired and modiﬁedfrom previous ﬁne-grained entity recognition stud-ies (ling and weld, 2012; gillick et al., 2014; choiet al., 2018; ringland et al., 2019)..with dense entities.
thus, as shown in algorithm 1we adopt a n -way k∼2k-shot setting in our pa-per, the primary principle of which is to ensure thateach class in s contain k∼2k examples, effec-tively alleviating the limitations of sampling..3 problem formulation.
3.1 named entity recognition.
ner is normally formulated as a sequence labelingproblem.
speciﬁcally, for an input sequence oftokens x = {x1, x2, ..., xt}, ner aims to assigneach token xi a label yi ∈ y to indicate either thetoken is a part of a named entity (such as person,organization, location) or not belong toany entities (denoted as o class), y being a set ofpre-deﬁned entity-types..3.2 few-shot named entity recognition.
n -way k-shot learning is conducted by iterativelyconstructing episodes.
for each episode in train-ing, n classes (n -way) and k examples (k-shot)for each class are sampled to build a support setstrain = {x(i), y(i)}n ∗ki=1 , and k(cid:48) examples foreach of n classes are sampled to construct a queryj=1 , and s (cid:84) q = ∅.
set qtrain = {x(j), y(j)}n ∗k(cid:48)few-shot learning systems are trained by predict-ing labels of query set qtrain with the informationof support set strain.
the supervision of strain andqtrain are available in training.
in the testing pro-cedure, all the classes are unseen in the trainingphase, and by using few labeled examples of sup-port set stest, few-shot learning systems need tomake predictions of the unlabeled query set qtest(s (cid:84) q = ∅).
however, in the sequence labelingproblem like ner, a sentence may contain multipleentities from different classes.
and it is imperativeto sample examples in sentence-level since contex-tual information is crucial for sequence labelingproblems, especially for ner.
thus the samplingis more difﬁcult than conventional classiﬁcationtasks like relation extraction (han et al., 2018)..some previous works (yang and katiyar, 2020;li et al., 2020a) use greedy-based sampling strate-gies to iteratively judge if a sentence could beadded into the support set, but the limitation be-comes gradually strict during the sampling.
forexample, when it comes to a 5-way 5-shot setting,if the support set already had 4 classes with 5 exam-ples and 1 class with 4 examples, the next sampledsentence must only contain the speciﬁc one entityto strictly meet the requirement of 5 way 5 shot.
itis not suitable for few-nerd since it is annotated.
algorithm 1: greedy n -way k∼2k-shotsampling algorithminput: dataset x , label set y, n , koutput: output result.
1 s ← ∅; // init the support set.
// init the count of entity types.
2 for i = 1 to n docount[i] = 0 ;.
3.
4 repeat.
5.
6.
7.
8.
9.
10.
11.randomly sample (x, y) ∈ x ;compute |count| and counti afterupdate ;if |count| > n or ∃count[i] > 2kthen.
continue ;.
else.
s = s (cid:83)(x, y) ;update counti ;.
12 until counti ≥ k for i = 1 to n;.
4 collection of few-nerd.
4.1 schema of entity types.
the primary goal of few-nerd is to construct aﬁne-grained dataset that could speciﬁcally be usedin the few-shot ner scenario.
hence, schemasof traditional ner datasets such as conll’03,ontonotes that only contain 4-18 coarse-grainedtypes could not meet the requirements.
the schemaof few-nerd is inspired by figer (ling andweld, 2012), which contains 112 entity tags withgood coverage.
on this basis, we make some mod-iﬁcations according to the practical situation.
it isworth noting that few-nerd focuses on namedentities, omitting value/numerical/time/date entitytypes (weischedel et al., 2013; ringland et al.,2019) like cardinal, day, percent, etc..first, we modify the figer schema into atwo-level hierarchy to incorporate simple do-main information (gillick et al., 2014).
thecoarse-grained types are {person, location,organization, art, building, product,event, miscellaneous }.
then we statisti-cally count the frequency of entity types in the.
3200automatically annotated figer.
by removing en-tity types with low frequency, there are 80 ﬁne-grained types remaining.
finally, to ensure thepracticality of the annotation process, we conductrounds of pre-annotation and make further mod-iﬁcations to the schema.
for example, we com-bine the types of country, province/state,city, restrict into a class gpe, since it isdifﬁcult to distinguish these types only based oncontext (especially gpes at different times).
foranother example, we create a person-scholartype, because in the pre-annotation step, we foundthat there are numerous person entities that expressthe semantics of research, such as mathematician,physicist, chemist, biologist, paleontologist, butthe figer schema does not deﬁne this kind of entitytype.
we also conduct rounds of manual denoisingto select types with truly high frequency..consequently, the ﬁnalized schema of few-nerd includes 8 coarse-grained types and 66ﬁne-grained types, which is detailedly shown ac-companied by selected examples in appendix..4.2 paragraph selection.
the raw corpus we use is the entire wikipediadump in english, which has been widely used inconstructions of nlp datasets (han et al., 2018;yang et al., 2018; wang et al., 2020).
wikipediacontains a large variety of entities and rich contex-tual information for each entity..few-nerd is annotated in paragraph-level,and it is crucial to effectively select paragraphswith sufﬁcient entity information.
moreover, thecategory distribution of the data is expected tobe balanced since the data is applied in a few-shot scenario.
it is also a key difference betweenfew-nerd and previous ner datasets, whoseentity distributions are usually considerably uneven.
in order to do so, we construct a dictionary for eachﬁne-grained type by automatically collecting entitymentions annotated in figer, then the dictionariesare manually denoised.
we develop a search engineto retrieve paragraphs including entity mentions ofthe distant dictionary.
for each entity, we choose10 paragraphs and construct a candidate set.
then,for each ﬁne-grained class, we randomly select1000 paragraphs for manual annotation.
eventu-ally, 66,000 paragraphs are selected, consisting of66 ﬁne-grained entity types, and each paragraphcontains an average of 61.3 tokens..paragraph.
is.
in.
the.
ﬁfth.
rock.
2001.london[art-music].
the british[loc-gpe].
al-bandbum byjesus jones[org-showorg]throughkoch records[org-company].
following the com-mercial failure of 1997’s ”already[art-music]”which led to the band and emi[org-company] part-ing ways, the band took a hiatus before regatheringfor the recording of ”london[art-music]” forkoch/mi5 recordings, with a more alternativerock approach as opposed to the techno soundson their previous albums.
the album had low-keypromotion, initially only being released in theunited states[loc-gpe].
two ep’s were releasedfrom the album, ”nowhere slow[art-music]” and”in the face of all this[art-music]”..table 1: an annotated case of few-nerd.
4.3 human annotation.
as named entities are expected to be context-dependent, annotation of named entities is com-plicated, especially with such a large number ofentity types.
for example, shown in table 1,“london is the ﬁfth album by the british rockband jesus jones..”, where london should be an-notated as an entity of art-music rather thanlocation-gpe.
such a situation requires thatthe annotator has basic linguistic training and canmake reasonable judgments based on the context.
annotators of few-nerd include 70 annota-tors and 10 experienced experts.
all the annotatorshave linguistic knowledge and are instructed withdetailed and formal annotation principles.
eachparagraph is independently annotated by two well-trained annotators.
then, an experienced expertgoes over the paragraph for possible wrong or omis-sive annotations, and make the ﬁnal decision.
with70 annotators participated, each annotator spendsan average of 32 hours during the annotation pro-cess.
we ensure that all the annotators are fairlycompensated by market price according to theirworkload (the number of examples per hour).
thedata is annotated and submitted in batches, andeach batch contains 1000∼3000 sentences.
to en-sure the quality of few-nerd, for each batchof data, we randomly select 10% sentences andconduct double-checking.
if the accuracy of the an-notation is lower than 95 % (measured in sentence-level), the batch will be re-annotated.
furthermore,we calculate the cohen’s kappa (cohen, 1960) tomeasure the aggreements between two annotators,.
3201the result is 76.44%, which indicates a high degreeof consistency..5 data analysis.
5.1 size and distribution of few-nerd.
few-nerd is not only the ﬁrst few-shot datasetfor ner, but it also is one of the biggest human-annotated ner datasets.
we report the the statisticsof the number of sentences, tokens, entity types andentities of few-nerd and several widely-usedner datasets in table 2, including conll’03,wikigold, ontonotes 5.0, wnut’17 and i2b2.
we observe that although ontonotes and i2b2 areconsidered as large-scale datasets, few-nerd issigniﬁcantly larger than all these datasets.
more-over, few-nerd contains more entity types andannotated entities.
as introduced in section 4.2,few-nerd is designed for few-shot learningand the distribution could not be severely uneven.
hence, we balance the dataset by selecting para-graphs through a distant dictionary.
the data distri-bution is illustrated in figure 1, where location(especially gpe) and person are entity types withthe most examples.
although utilizing a distantdictionary to balance the entity types could notproduce a fully balanced data distribution, it stillensures that each ﬁne-grained type has a sufﬁcientnumber of examples for few-shot learning..5.2 knowledge correlations among types.
knowledge transfer is crucial for few-shot learn-ing (li et al., 2019a).
to explore the knowledge cor-relations among all the entity types of few-nerd,we conduct an empirical study about entity typesimilarities in this section.
we train a bert-tagger(details in section 7.1) of 70% arbitrarily selecteddata on few-nerd and use 10% data to select themodel with best performance (it is actually the set-ting of few-nerd (sup) in section 6.1).
afterobtaining a contextualized encoder, we produce en-tity mention representations of the remaining 20%data of few-nerd.
then, for each ﬁne-grainedtypes, we randomly select 100 instances of entityembeddings.
we mutually compute the dot productamong entity embeddings for each type two by twoand average them to obtain the similarities amongtypes, which is illustrated in figure 2. we observethat entity types shared identical coarse-grainedtypes typically have larger similarities, resulting inan easier knowledge transfer.
in contrast, althoughsome of the ﬁne-grained types have large similari-.
figure 2: a heat map to illustrate knowledge correla-tions among type in few-nerd, each small coloredsquare represents the similarity of two entity types..ties, most of them across coarse-grained types sharelittle correlations due to distinct contextual features.
this result is consistent with intuition.
moreover,it inspires our benchmark-setting from the perspec-tive of knowledge transfer (see section 6.2)..6 benchmark settings.
we collect and manually annotate 188,238 sen-tences with 66 ﬁne-grained entity types in to-tal, which makes few-nerd one of the largesthuman-annotated ner datasets.
to comprehen-sively exploit such rich information of entities andcontexts, as well as evaluate the generalization ofmodels from different perspectives, we constructthree tasks based on few-nerd (statistics arereported in table 3)..6.1 standard supervised ner.
few-nerd (sup) we ﬁrst adopt a standard su-pervised setting for ner by randomly splitting70% data as the training data, 10% as the validationdata and 20% as the testing data.
in this setting,the training set, dev set, and test set contain thewhole 66 entity types.
although the supervisedsetting is not the ultimate goal of the constructionof few-nerd, it is still meaningful to assess theinstance-level generalization for ner models.
asshown in section 6.2, due to the large number ofentity types, few-nerd is very challenging evenin a standard supervised setting..32020 100 200 300 400 z 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 x 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 y art building event loc org misc person product datasets.
# sentences.
# tokens.
# entities.
# entity types.
domain.
conll’03 (tjong kim sang, 2002)wikigold (balasuriya et al., 2009)ontonotes (weischedel et al., 2013)wnut’17 (derczynski et al., 2017)i2b2 (stubbs and uzuner, 2015).
22.1k1.7k103.8k4.7k107.9k.
301.4k39k2067k86.1k805.1k.
35.1k3.6k161.8k3.1k28.9k.
few-nerd.
188.2k.
4601.2k.
491.7k.
newswire4general418general6 socialmediamedical23.
66.general.
table 2: statistics of few-nerd and multiple widely used ner datasets.
for conll’03, wikigold, and i2b2,we report the statistics in the original paper.
for ontonotes 5.0 (ldc2013t19), we download and count all the data(english) annotated by the ner labels, some works use different split of ontonotes 5.0 and may report differentstatistics.
for wnut’17, we download and count all the data..6.2 few-shot ner.
(cid:83) edev.
(cid:84) edev.
the core intuition of few-shot learning is to learnnew classes from few examples.
hence, we ﬁrstsplit the overall entity set (denoted as e) into threemutually disjoint subsets, respectively denoted(cid:83) etest = e,as etrain, edev, etest, and etrain(cid:84) etest = ∅.
note that all the entityetraintypes are ﬁne-grained types.
under this circum-stance, instances in train, dev and test datasets onlyconsist of instances with entities in etrain, edev, etestrespectively.
however, ner is a sequence labelingproblem, and it is possible that a sentence containsseveral different entities.
to avoid the observationof new entity types in the training phase, we replacethe labels of entities that belong to etest with o inthe training set.
similarly, in the test set, entitiesthat belongs to etrain and edev are also replaced byo. based on this setting, we develop two few-shotner tasks adopting different splitting strategies.
few-nerd (intra) firstly, we constructetrain, edev and etest according to the coarse-grainedin other words, all the entities in differ-types.
ent sets belong to different coarse-grained types.
in the basis of the principle that we should re-place as few as possible entities with o, weassign all the ﬁne-grained entity types belong-ing to people, misc, art, product toetrain, all the ﬁne-grained entity types belongingto event, building to edev, and all the ﬁne-grained entity types belonging to org, loc toetest, respectively.
based on figure 2, in this set-ting, the training set, dev set and test set share littleknowledge, making it a difﬁcult benchmark.
few-nerd (inter)in this task, although allthe ﬁne-grained entity types are mutually disjointin etrain, edev, the coarse-grained types are shared.
speciﬁcally, we roughly assign 60% ﬁne-grainedtypes of all the 8 coarse-grained types to etrain, 20%to edev and 20% etest, respectively.
the intuition of.
split.
#train.
#dev.
#test.
few-nerd (sup)few-nerd (intra)few-nerd (inter).
131,76799,519130,112.
18,82419,35818,817.
37,64844,05914,007.table 3: statistics of train, dev and test sets for threetasks of few-nerd.
we remove the sentences withno entities for the few-shot benchmarks..this setting is to explore if the coarse informationwill affect the prediction of new entities..7 experiments.
7.1 models.
recent studies show that pre-trained language mod-els with deep transformers (e.g., bert (devlinet al., 2019a)) have become a strong encoder forner (li et al., 2020b).
we thus follow the em-pirical settings and use bert as the backbone en-coder in our experiments.
we denote the parame-ters as θ and the encoder as fθ.
given a sequencex = {x1, ..., xn}, for each token xi, the encoderproduces contextualized representations as:.
h = [h1, ..., hn] = fθ([x1, ..., xn])..(1).
speciﬁcally, we implement four bert-based mod-els for supervised and few-shot ner, whichare bert-tagger (devlin et al., 2019b), proto-bert (snell et al., 2017), nnshot (yang andkatiyar, 2020) and structshot (yang and katiyar,2020).
bert-taggeras stated in section 6.1, weconstruct a standard supervised task based onfew-nerd, thus we implement a simple butstrong baseline bert-tagger for supervised ner.
bert-tagger is built by adding a linear classiﬁeron top of bert and trained with a cross-entropyobjective under a full supervision setting..3203protobert inspired by achievements of meta-learning approaches (finn et al., 2017; snell et al.,2017; ding et al., 2021) on few-shot learning.
the ﬁrst baseline model we implement is proto-bert, which is a method based on prototypicalnetwork (snell et al., 2017) with a backbone ofbert (devlin et al., 2019a) encoder.
this ap-proach derives a prototype z for each entity typeby computing the average of the embeddings of thetokens that share the same entity type.
the compu-tation is conducted in support set s. for the i-thtype, the prototype is denoted as zi and the supportset is si,.
zi =.
fθ(x)..(2).
1|si|.
(cid:88).
x∈si.
while in the query set q, for each token x ∈ q,we ﬁrstly compute the distance between x and allthe prototypes.
we use the l-2 distance as the met-ric function d(fθ(x), z) = ||fθ(x) − z||22. then,through the distances between x and all other pro-totypes, we compute the prediction probability ofx over all types.
in the training step, parametersare updated in each meta-task.
in the testing step,the prediction is the label of the nearest prototypeto x. that is, for a support set sy with types of yand a query x, the prediction process is given as.
y∗ = arg miny∈y.
dy(x),.
dy(x) = d(fθ(x), zy)..(3).
nnshot & structshotnnshot and struct-shot (yang and katiyar, 2020) are the state-of-the-art methods based on token-level nearest neighborclassiﬁcation.
in our experiments, we use bertas the backbone encoder to produce contextualizedrepresentations for fair comparison.
different fromthe prototype-based method, nnshot determinesthe tag of one query based on the token-level dis-tance, which is computed as d(fθ(x), fθ(x(cid:48))) =||fθ(x) − fθ(x(cid:48))||22. hence, for a support set sywith type of y and a query x,.
y∗ = arg miny∈y.
dy(x),.
dy(x) = minx(cid:48)∈sy.
d(fθ(x), fθ(x(cid:48)))..(4).
with the identical basic structure as nnshot,structshot adopts an additional viterbi decoderduring the inference phase (hou et al., 2020) (notin training phase), where we estimate a transitiondistribution p(y(cid:48)|y) and an emission distribution.
datasets.
conll’03ontonotes 5.0.p.90.6290.00.r.92.0788.24.f1.
91.3489.11.few-nerd (sup).
67.39 (↓).
70.45 (↓).
68.88 (↓).
table 4: results of bert-tagger on previous nerdatasets and the supervised setting of few-nerd..p(y|x) and solve the problem:.
y∗ = arg max.
y.t(cid:89).
t=1.
p(yt|x) × p(yt|yt−1)..(5).
is.
that.
to sum up, bert-tagger.
a well-acknowledged baselinecould producepronounced results on supervised ner.
proto-bert, and nnshot & structshot respectively useprototype-level and token-level similarity scores totackle the few-shot ner problem.
these baselinesare strong and representative models of the nertask.
for implementation details, please refer toappendix..we evaluate models by considering query setsqtest of test episodes.
we calculate the precision(p), recall (r) and micro f1-score over all testepisodes.
instead of the popular bio schema, weutilize the io schema in our experiments, usingi-type to denote all the tokens of a named entityand o to denote other tokens..7.2 the overall results.
we evaluate all baseline models on the three bench-mark settings introduced in section 6, includingfew-nerd (sup), few-nerd (intra) andfew-nerd (inter).
supervised ner as mentioned in section 6.1,we ﬁrst split the few-nerd as a standard super-vised ner dataset.
as shown in table 4, bert-tagger yields promising results on the two widelyused supervised datasets.
the f1-score is 91.34%,89.11%, respectively.
however, the model suffersa grave drop in the performance on few-nerd(sup) because the number of types of few-nerd(sup) is larger than others.
the results indicatethat few-nerd is challenging in the supervisedsetting and worth studying..we further analyze the performance of differententity types (see figure 3).
we ﬁnd that the modelachieves the best performance on the person typeand yields the worst performance on the producttype.
and almost for all the coarse-grained types,the coarse-other type has the lowest f1-score..3204figure 3: f1-scores of different entity types on few-nerd (sup), we report the average performance of eachcoarse-grained entity type on the legends..model.
5 way 1∼2 shot.
5 way 5∼10 shot.
10 way 1∼2 shot.
10 way 5∼10 shot.
p.r.f1.
p.r.f1.
p.r.f1.
p.r.f1.
protonnshotstruct.
16.35±0.6320.47±0.4031.40±1.34.
28.35±2.4123.05±1.1219.63±2.61.
20.71±1.1621.58±0.7023.95±2.39.
31.43±1.1423.88±0.7945.20±1.08.
45.28±0.7128.35±0.8822.80±0.99.
37.08±1.0125.66±0.7829.68±1.11.
12.05±1.0914.83±0.5623.15±0.77.
21.27±1.3516.90±0.688.61±0.69.
15.32±0.6815.72±0.5312.31±0.72.
23.15±0.4218.18±1.2040.40±2.46.
35.83±0.9722.45±1.0311.35±1.32.
28.02±0.5619.82±1.1117.10±1.75.
few-nerd(intra).
table 5: performance of state-of-art models on few-nerd (intra)..model.
5 way 1∼2 shot.
5 way 5∼10 shot.
10 way 1∼2 shot.
10 way 5∼10 shot.
p.r.f1.
p.r.f1.
p.r.f1.
p.r.f1.
protonnshotstruct.
31.45±0.7438.32±2.2449.45±0.60.
46.44±3.4042.82±2.3432.44±7.77.
37.49±1.6340.31±2.3038.78±5.70.
46.88±0.2739.40±1.4242.62±6.46.
59.54±1.1043.34±7.3232.47±5.37.
52.42±0.6042.66±1.0735.95±1.09.
22.17±0.9229.52±1.1532.54±1.42.
34.72±0.5234.06±2.2717.54±0.72.
26.98±0.7931.54±1.6322.61±0.95.
50.87±1.0133.74±0.4441.82±0.50.
63.30±0.6641.82±0.5244.52±0.74.
56.29±0.7937.09±0.1342.75±0.62.
few-nerd(inter).
table 6: performance of state-of-art models on few-nerd (inter)..this is because the semantics of such ﬁne-grainedtypes are relatively sparse and difﬁcult to be recog-nized.
a natural intuition is that the performance ofeach entity type is related to the portion of the type.
but surprisingly, we ﬁnd that they are not linearlycorrelated.
for examples, the model performs verywell on the art type, although this type representsonly a small fraction of few-nerd.
few-shot ner for the few-shot benchmarks,we adopt 4 sampling settings, which are 5 way1∼2 shot, 5 way 5∼10 shot, 10 way 1∼2 shot,and 10 way 5∼10 shot.
intuitively, 10 way 1∼2shot is the hardest setting because it has the largestnumber of entity types and the fewest number ofexamples, and similarly, 5 way 5∼10 shot is theeasiest setting.
all results of few-nerd (intra)and few-nerd (inter) are reported in table 5and table 6 respectively.
overall, we observethat the previous state-of-the-art methods equippedby bert encoder could not yield promising re-sults on few-nerd.
from a perspective ofhigh level, models generally perform better on.
few-nerd (inter) than few-nerd (intra),and the latter is regarded as a more difﬁcult task aswe analyze in section 5.2 and section 6, it splits thedata according to the coarse-grained entity types,which means entity types between the training setand test set share less knowledge..in a horizontal comparison, consistent with in-tuition, almost all the methods produce the worstresults on 10 way 1∼2 shot and achieve the bestperformance on 5 way 5∼10.
in the comparisonacross models, protobert generally achieves bet-ter performance than nnshot and structshot, es-pecially in 5∼10 shot setting where calculation byprototype may differ more from calculation by en-tity.
structshot has seen a large improvement inprecision in few-nerd (intra).
it shows thatviterbi decoder at the inference stage can help re-move false positive predictions when knowledgetransfer is hard.
it is also observed that nnshot andstructshot may suffer from the instability of thenearest neighbor mechanism in the training phase,and prototypical models are more stable because.
3205020406080100broadcastfilmmusicpaintingwrittenart-otherairporthospitalhotellibraryrestaurantsportstheaterbuilding-otherattackdisasterelectionevent-otherprotestsportsgpewaterislandmountainloc-otherparktransitcompanyeducationgovernmentnewspaperorg-otherpartyreligionshowsportsleaguesportsteamactorauthorathletedirectorper-otherpoliticianscholarsoldierairplanecarfoodgameproduct-othershipsoftwaretrainweaponastronomyawardbiologychemicalcurrencydiseasedegreegodlanguagelawlivingthingmedicalart - 77%building - 67%event - 67%location - 79%organization - 73%person - 85%product - 60%miscellaneous - 63%models.
span error.
type error.
fp.
fn within outer.
protonetnnshotstructshot.
6.01% 3.25% 5.13% 11.69%4.73% 5.77% 5.77% 14.98%3.11% 8.42% 5.59% 13.62%.
that few-shot ner remains a challenging problemand worth exploring.
in the future, we will extendfew-nerd by adding cross-domain annotations,distant annotations, and ﬁner-grained entity types.
few-nerd also has the potential to advance theconstruction of continual knowledge graphs..table 7: error analysis of 5 way 5∼10 shot onfew-nerd (inter), “within” indicates “within thecoarse types” and “outer” is “outer the coarse types”..acknowledgements.
the calculation of prototypes essentially serves asregularization..7.3 error analysiswe conduct error analysis to explore the challengesof few-nerd, the results are reported in table 7.we choose the setting of few-nerd (inter) be-cause the test set contains all the coarse-grainedtypes.
we analyze the errors of models from twoperspectives.
span error denotes the misclassify-ing in token-level classiﬁcation.
if an o token ismisclassiﬁed as a part of entity, i.e., i-type, it isan fp case, and if a token with the type i-type ismisclassiﬁed to o, it is fn.
type error indicates themisclassiﬁcation of entity types when the spans arecorrectly classiﬁed.
a “within” error representsthe entity is misclassiﬁed to another type within thesame coarse-grained type, while “outer” denotesthe entity is misclassiﬁed to another type in a dif-ferent coarse-grained type.
as the statistics of typeerrors may be impacted by the sampled episodesin testing, we conduct 5 rounds of experiments andreport the average results.
the results demonstratethat the token-level accuracy is not that low sincemost o tokens could be detected.
but an entity men-tion is considered to be wrong if one token is wrong,which becomes the main reason for the challengeof few-nerd.
if an entity span could be accu-rately detected, the models could yield relativelygood performance on entity typing, indicating theeffectiveness of metric learning..8 conclusion and future work.
we propose few-nerd, a large-scale few-shotner dataset with ﬁne-grained entity types.
thisis the ﬁrst few-shot ner dataset and also oneof the largest human-annotated ner dataset.
few-nerd provides three uniﬁed benchmarksto assess approaches of few-shot ner and couldfacilitate future research in this area.
by imple-menting state-of-the-art methods, we carry out a se-ries of experiments on few-nerd, demonstrating.
this research is supported by national natu-ral science foundation of china (grant no.
61773229 and 6201101015), national key re-search and development program of china(no.
2020aaa0106501), alibaba innovation re-search (air) programme, the general researchproject (grand no.
jcyj20190813165003837,no.jcyj20190808182805919), and overseas co-operation research fund of graduate school attsinghua university (grant no.
hw2018002).
fi-nally, we thank the valuable help of ronny, xiaozhi,ziyu and comments of anonymous reviewers..ethical considerations.
in this paper, we present a human-annotateddataset, few-nerd, for few-shot learning inner.
we describe the details of the collection pro-cess and conditions, the compensation of annota-tors, the measurements to ensure the quality in themain text.
the corpus of the dataset is publicly ob-tained from wikipedia and we have not modiﬁed orinterfered with the content.
few-nerd is likelyto directly facilitate the research of few-shot ner,and further increase the progress of the constructionof large-scale knowledge graphs (kgs).
modelsand systems built on few-nerd may contributeto construct kgs in various domains, includingbiomedical, ﬁnancial, and legal ﬁelds, and furtherpromote the development of nlp applications onspeciﬁc domains.
few-nerd is annotated in en-glish, thus the dataset may mainly facilitate nlpresearch in english.
for the sake of energy saving,we will not only open source the dataset and thecode, but also release the checkpoints of our mod-els from the experiments to reduce unnecessarycarbon emission..references.
dominic balasuriya, nicky ringland, joel nothman,tara murphy, and james r. curran.
2009. namedentity recognition in wikipedia.
in proceedings ofthe 2009 workshop on the people’s web meets nlp:collaboratively constructed semantic resources.
3206(people’s web), pages 10–18, suntec, singapore.
as-sociation for computational linguistics..jason p.c.
chiu and eric nichols.
2016. named entityrecognition with bidirectional lstm-cnns.
trans-actions of the association for computational lin-guistics, 4:357–370..eunsol choi, omer levy, yejin choi, and luke zettle-moyer.
2018. ultra-ﬁne entity typing.
in proceed-ings of the 56th annual meeting of the associationfor computational linguistics (volume 1: long pa-pers), pages 87–96, melbourne, australia.
associa-tion for computational linguistics..jacob cohen.
1960. a coefﬁcient of agreement fornominal scales.
educational and psychological mea-surement, 20(1):37–46..wanyun cui, yanghua xiao, haixun wang, yangqiusong, seung-won hwang, and wei wang.
2017.kbqa:learning question answering over qa cor-pora and knowledge bases.
in proceedings of 43rdvery large data base conference endowment, vol-ume 10..leon derczynski, eric nichols, marieke van erp, andnut limsopatham.
2017. results of the wnut2017shared task on novel and emerging entity recogni-tion.
in proceedings of the 3rd workshop on noisyuser-generated text, pages 140–147, copenhagen,denmark.
association for computational linguis-tics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019a.
bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019b.
bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..ning ding, ziran li, zhiyuan liu, haitao zheng,and zibo lin.
2019. event detection with trigger-in proceedings ofaware lattice neural network.
the 2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language process-ing (emnlp-ijcnlp), pages 347–356, hong kong,china.
association for computational linguistics..ning ding, xiaobin wang, yao fu, guangwei xu, ruiwang, pengjun xie, ying shen, fei huang, hai-tao.
zheng, and rui zhang.
2021. prototypical repre-in inter-sentation learning for relation extraction.
national conference on learning representations..chelsea finn, pieter abbeel, and sergey levine.
2017.model-agnostic meta-learning for fast adaptation ofin proceedings of the 34th inter-deep networks.
national conference on machine learning, icml2017, sydney, nsw, australia, 6-11 august 2017,volume 70 of proceedings of machine learning re-search, pages 1126–1135.
pmlr..alexander fritzler, varvara logacheva, and maksimkretov.
2019. few-shot classiﬁcation in named en-in proceedings of the 34thtity recognition task.
acm/sigapp symposium on applied computing,pages 993–1000..dan gillick, nevena lazic, kuzman ganchev, jessecontext-kirchner, and david huynh.
2014.dependent ﬁne-grained entity type tagging.
arxivpreprint arxiv:1412.1820..xu han, hao zhu, pengfei yu, ziyun wang, yuanyao, zhiyuan liu, and maosong sun.
2018. fewrel:a large-scale supervised few-shot relation classiﬁca-tion dataset with state-of-the-art evaluation.
in pro-ceedings of the 2018 conference on empirical meth-ods in natural language processing, pages 4803–4809, brussels, belgium.
association for computa-tional linguistics..maximilian hofer, andrey kormilitzin, paul goldberg,and alejo nevado-holgado.
2018. few-shot learn-ing for named entity recognition in medical text.
arxiv preprint arxiv:1811.05468..yutai hou, wanxiang che, yongkui lai, zhihan zhou,yijia liu, han liu, and ting liu.
2020. few-shotslot tagging with collapsed dependency transfer andlabel-enhanced task-adaptive projection network.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 1381–1393, online.
association for computational lin-guistics..jiaxin huang, chunyuan li, krishan subudhi, damienjose, shobana balakrishnan, weizhu chen, baolinpeng, jianfeng gao, and jiawei han.
2020. few-shot named entity recognition: a comprehensivestudy.
arxiv preprint arxiv:2012.14978..guillaume lample, miguel ballesteros, sandeep sub-ramanian, kazuya kawakami, and chris dyer.
2016.neural architectures for named entity recognition.
in proceedings of the 2016 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,pages 260–270, san diego, california.
associationfor computational linguistics..aoxue li, tiange luo, zhiwu lu, tao xiang, and li-wei wang.
2019a.
large-scale few-shot learning:in ieeeknowledge transfer with class hierarchy..3207conference on computer vision and pattern recog-nition, cvpr 2019, long beach, ca, usa, june 16-20, 2019, pages 7212–7220.
computer vision foun-dation / ieee..jing li, billy chiu, shanshan feng, and hao wang.
2020a.
few-shot named entity recognition via meta-ieee transactions on knowledge andlearning.
data engineering..xiaoya li, jingrong feng, yuxian meng, qinghonghan, fei wu, and jiwei li.
2020b.
a uniﬁed mrcin pro-framework for named entity recognition.
ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5849–5859, online.
association for computational lin-guistics..ziran li, ning ding, zhiyuan liu, haitao zheng,and ying shen.
2019b.
chinese relation extractionwith multi-grained information and external linguis-in proceedings of the 57th annualtic knowledge.
meeting of the association for computational lin-guistics, pages 4377–4386, florence, italy.
associa-tion for computational linguistics..xiao ling and daniel s. weld.
2012. fine-grained en-tity recognition.
in proceedings of the twenty-sixthaaai conference on artiﬁcial intelligence, july 22-26, 2012, toronto, ontario, canada.
aaai press..ilya loshchilov and frank hutter.
2019. decoupledin international con-.
weight decay regularization.
ference on learning representations..xuezhe ma and eduard hovy.
2016..end-to-endsequence labeling via bi-directional lstm-cnns-crf.
in proceedings of the 54th annual meeting ofthe association for computational linguistics (vol-ume 1: long papers), pages 1064–1074, berlin, ger-many.
association for computational linguistics..adam paszke, sam gross, francisco massa, adamlerer, james bradbury, gregory chanan, trevorkilleen, zeming lin, natalia gimelshein, lucaantiga, alban desmaison, andreas k¨opf, edwardyang, zachary devito, martin raison, alykhan te-jani, sasank chilamkurthy, benoit steiner, lu fang,junjie bai, and soumith chintala.
2019.py-torch: an imperative style, high-performance deepin advances in neural informa-learning library.
tion processing systems 32: annual conferenceon neural information processing systems 2019,neurips 2019, december 8-14, 2019, vancouver,bc, canada, pages 8024–8035..nicky ringland, xiang dai, ben hachey, sarvnazkarimi, cecile paris, and james r. curran.
2019.nne: a dataset for nested named entity recognitionin english newswire.
in proceedings of the 57th an-nual meeting of the association for computationallinguistics, pages 5176–5181, florence, italy.
asso-ciation for computational linguistics..alan ritter, sam clark, mausam, and oren etzioni.
2011. named entity recognition in tweets: an ex-perimental study.
in proceedings of the 2011 con-ference on empirical methods in natural languageprocessing, pages 1524–1534, edinburgh, scotland,uk.
association for computational linguistics..ying shen, ning ding, hai-tao zheng, yaliang li,and min yang.
2020. modeling relation paths forieee transactionsknowledge graph completion.
on knowledge and data engineering..jake snell, kevin swersky, and richard s. zemel.
2017. prototypical networks for few-shot learning.
in advances in neural information processing sys-tems 30: annual conference on neural informa-tion processing systems 2017, december 4-9, 2017,long beach, ca, usa, pages 4077–4087..amber stubbs and ¨ozlem uzuner.
2015. annotatinglongitudinal clinical narratives for de-identiﬁcation:the 2014 i2b2/uthealth corpus.
journal of biomedi-cal informatics, 58:s20–s29..erik f. tjong kim sang.
2002..introduction to theconll-2002 shared task: language-independentin coling-02: thenamed entity recognition.
6th conference on natural language learning 2002(conll-2002)..xiaozhi wang, ziqi wang, xu han, wangyi jiang,rong han, zhiyuan liu, juanzi li, peng li, yankailin, and jie zhou.
2020. maven: a massive gen-eral domain event detection dataset.
in proceed-ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages1652–1671, online.
association for computationallinguistics..ralph weischedel, martha palmer, mitchell marcus,eduard hovy, sameer pradhan, lance ramshaw, ni-anwen xue, ann taylor, jeff kaufman, michellefranchini, et al.
2013.ontonotes release 5.0ldc2013t19.
linguistic data consortium, philadel-phia, pa, 23..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, remi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander rush.
2020. trans-formers: state-of-the-art natural language process-ing.
in proceedings of the 2020 conference on em-pirical methods in natural language processing:system demonstrations, pages 38–45, online.
asso-ciation for computational linguistics..yi yang and arzoo katiyar.
2020. simple and effectivefew-shot named entity recognition with structuredin proceedings of thenearest neighbor learning.
2020 conference on empirical methods in naturallanguage processing (emnlp), pages 6365–6375,online.
association for computational linguistics..3208zhilin yang, peng qi, saizheng zhang, yoshua bengio,william cohen, ruslan salakhutdinov, and christo-pher d. manning.
2018. hotpotqa: a datasetfor diverse, explainable multi-hop question answer-ing.
in proceedings of the 2018 conference on em-pirical methods in natural language processing,pages 2369–2380, brussels, belgium.
associationfor computational linguistics..3209a data details.
a.1 processing.
we use the dump2 of english wikipedia, and ex-tract the raw text by wikiextractor3.
nltk lan-guage tool4 is used for word and sentence tok-enization in the preprocessing stage.
as statedin section 4.2, we develope a search engine toindex and select paragraphs with key words in dis-tant dictionaries.
if the search is performed withlinear operations, the calculation process will beextremely slow, instead, we adopt a search enginewith lucene5 to conduct effective indexing andsearching..a.2 more details of the schema.
as stated in section 4.1, we use figer (ling andweld, 2012) as the start point and conduct rounds ofmake a series of modiﬁcations.
despite the modiﬁ-cations mentioned in section 4.1, we also conductmanual denoising of the automatically annotateddata of fier.
for each entity type and the cor-responding automatically annotated mentions, werandomly select 500 mentions and compute theaccuracy to obtain the real frequency.
for exam-ple, statistics report that cemetery is a type withhigh frequency.
however, a plenty number of thementions labeled as cemetery are actually gpe.
similarly, engineer is also affected by noise..a.3.
interface.
the interface in shown in figure 4, where anno-tators could expediently select entity spans andannotate the corresponding coarse and ﬁne types.
and annotators could check the current annotationinformation on the interface..b implementation details.
all the four models use bertbase (devlin et al.,2019a) and the backbone encoder and initial-ized with the corresponding pre-trained uncasedweights6.
the hidden size is 768, and thenumber of layers and heads are 12. modelsare implemented by pytorch framework7 (paszkeet al., 2019) and huggingface transformers8 (wolfet al., 2020).
bert models are optimized byadamw9 (loshchilov and hutter, 2019) with thelearning rate of 1e-4.
we evaluate our implemen-tations of nnshot and structshot on the datasetsused in the original paper, producing similar results.
for supervised ner, the batch size is 8, and wetrain bert-tagger for 70000 steps and evaluateit on the test set.
for 5 way 1∼2 and 5∼10 shotsettings, the batch sizes are 16 and 4, and for 10way 1∼2 and 5∼10 shot settings, the batch sizesare 8 and 1. we train 12000 episodes and use 500episodes of the dev set to select the best model,and test it on 5000 episodes of the test set.
mosthyper-parameters are from original settings.
wemanually tune the hyper-parameter τ in viterbi forstructshot, and the value for 1∼2 settings shot is0.320, for 5∼10 shot settings is 0.434. all the ex-periments are conducted with cuda on nvidiatesla v100 gpus.
with 2 gpus used, the averagetime to train 10000 episodes is 135 minutes.
thenumber of parameters of the models is 120m..c entity types.
as introduced in section 4.1 in main text,few-nerd is manually annotated with 8 coarse-grained and 66 ﬁne-grained entity types, and welist all the types in table 8. the schema is designedunder practical situation, we hope the schema couldhelp to better understand few-nerd.
note thatorg is the abbreviation of organization, andmisc is the abbreviation of miscellaneous..figure 4: screeshot of the interface used to annotatefew-nerd..2https://dumps.wikimedia.org/enwiki/3https://github.com/attardi/.
wikiextractor.
4https://www.nltk.org5https://lucene.apache.org/.
6https://github.com/google-research/.
bert.
7https://pytorch.org8https://github.com/huggingface/.
transformers.
9https://www.fast.ai/2018/07/02/.
adam-weight-decay/#adamw.
3210coarse type.
fine type.
example.
location.
artist/author.
a ﬁlm adaption was made by arne bornebusch in 1936..person.
athlete.
director.
politician.
gpe.
body of water.
island.
mountain.
park.
road/transit.
other.
actor.
scholar.
soldier.
other.
company.
education.
government.
media.
religion.
sports team.
show org.
other.
airport.
hospital.
library.
restaurant.
org.
building.
hotel.
the company moved to a new ofﬁce in las vegas, nevada..the finke river normally drains into the simpson desert to the north westof the macumba..an invading army of teutonic knights conquered gotland in 1398..c.g.e.
mannerheim met thubten gyatso in wutai shan during the course ofhis expedition from turkestan to peking..victoria park contains examples of work by several architects includingalfred waterhouse (xaverian college)..the thirty-ﬁrst race of the 1951 season was held on october 7 at the one-miledirt occoneechee speedway..herodotus (7.59) reports that doriscus was the ﬁrst place xerxes the greatstopped to review his troops..the ﬁrst performance of any work of gustav holst given in that capital..smith was named co-player of the week in the big ten on offense..margin for error is a 1943 american drama ﬁlm directed by otto preminger..then-president gloria macapagal arroyo led the inauguration rites of thefacility on august 19, 2002..jeffery westbrook and robert tarjan (1992) developed an efﬁcient datastructure for this problem based on disjoint-set data structures..sadowski was promoted to general, and took command of the freshly createdfortiﬁed area of silesia..in albany, doane planned a cathedral like those in england..a vocaloid voicebank developed and distributed by yamaha corporation forvocaloid 4..long volunteer coached the offensive line for briarcrest christian schoolfor 9 seasons..it was constructed using the savings of the quezon provincial government..he was the editor in chief of grenada’s national newspaper ”the free westindian”..the pirates won the game and the world series with oldham on the mound..standing in the way of control is the third studio album by american indierock band gossip..he is the creative director of the oliver sacks foundation..the city is served by the sir seretse khama international airport..then he did residency in ophthalmology at farabi eye hospital from 1979to 1982..nick also played at the regular sunday evening sessions that were held atthe ramada inn in schenectady..rmit university library consists of six academic branch libraries in aus-tralia and vietnam..the ﬁrst panda express restaurant opened in galleria ii in the same year, onlevel 3 near bloomingdale’s..political/party.
stanley norman evans was a british industrialist and labour party politician..d’souza was born on 10 november 1985 into a goan catholic family ingoa, india..sports league.
his strong performances convinced him that he was ready for the nba..sports facility.
this was the last year that the razorbacks would play in barnhill arena..theater.
from 1954, she became a guest singer at the vienna state opera..3211eissler designated masson to succeed him as director of the sigmund freudarchives after his and anna freud’s death..”get right” is a song recorded by american singer jennifer lopez for herfourth studio album..art.
film.
margin for error is a 1943 american drama ﬁlm directed by otto preminger..written art.
the count is a text adventure written by scott adams and published byadventure international in 1979..product.
other.
music.
broadcast.
painting.
other.
airplane.
car.
food.
game.
ship.
software.
train.
weapon.
other.
attack.
event.
election.
protest.
sports event.
other.
astronomy.
award.
biology.
chemistry.
currency.
disease.
misc.
in the fall of 1957, mitchell starred in abc’s ”the guy mitchell show”..his painting ’rooftops’ has been in the collection of the city of londoncorporation since 1989..kirwan appeared on stage at the chichester festival theatre in a jeremyherrin production of uncle vanya..the royal norwegian air force’s 330 squadron operates a westland seaking search and rescue helicopter out of florø..the byd tang plug-in hybrid suv was the top selling plug-in car with31,405 units delivered..the words ”time to make the donuts” are printed on the side of dunkin’donuts boxes in memory of michael vale/fred the baker..team andromeda wanted to create a fully 3d arcade game, having workedon similar games such as ”out run” which were not truly 3d..as night fell, marine corps general holland smith studied reports aboardthe command ship ”eldorado”..it allows communication between the wolfram mathematica kernel andfront-end..on 9 june 1929, railcar no.
220 ”waterwitch” overran signals at marshgatejunction..mannerheim gave tibet’s spiritual pontiff a browning revolver and showedhim how to reload the weapon..rhinestone is as artiﬁcial and synthetic a concoction as has ever made itsway to the screen..it was on this route that tecumseh was killed at the battle of the thames onoctober 5, 1813..at the 1935 united kingdom general election, mcgleenan stood in armaghas an independent republican..in 1832, following the failed polish november uprising, the dominicanmonastery was sequestrated..carle received a new defense partner when the flyers traded for chrispronger at the 2009 nhl entry draft..one of tmg’s ﬁrst performances was in september 1972 at the waitarafestival..he discovered a number of double stars and took many photographs of mars..he was awarded the bialik prize eight years later for these efforts..estradiol valerate is rapidly hydrolyzed into estradiol in the intestines..it was the ﬁrst gas manufacturer in kuwait to provide industrial gases suchas oxygen and nitrogen to the local petroleum industry..total investment has been 19 billion norwegian krone..the 2020 competition was cancelled as part of the effort to minimize thecovid-19 pandemic..natural disaster.
he was originally from chicago, but moved to japan after the second greatkanto earthquake that all but decimated japan’s infrastructure..educational degree.
sigurlaug enrolled into the medical department of the university of icelandand graduated as a medical doctor in 2010..god.
originally a farmer, viking ragnar lothbrok claims to be descended fromthe god odin..3212language.
law.
living thing.
medical.
the play was translated into english by michael hofmann and published in1987 by hamish hamilton..four of his ﬁve policy recommendations were incorporated into the u.s.federal financial law of 1966..schistura horai is a species of ray-ﬁnned ﬁsh in the stone loach genus”schistura”..precious blood hospital offers specialist outpatient and inpatient services ingeneral medicine..table 8: all the coarse-grained and ﬁne-grained entity types in few-nerd, we only highlight the entities withthe corresponding entity types in “example”..3213