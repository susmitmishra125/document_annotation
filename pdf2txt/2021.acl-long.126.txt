syntopical graphs for computational argumentation tasks.
joe barrow∗university of marylandjdbarrow@cs.umd.edu.
rajiv jainadobe researchrajijain@adobe.com.
nedim lipkaadobe researchlipka@adobe.com.
franck dernoncourtadobe researchdernonco@adobe.com.
vlad i. morariuadobe researchmorariu@adobe.com.
varun manjunathaadobe researchvmanjuna@adobe.com.
douglas w. oarduniversity of marylandoard@umd.edu.
philip resnikuniversity of marylandresnik@umd.edu.
henning wachsmuthpaderborn universityhenningw@upb.de.
abstract.
approaches to computational argumentationtasks such as stance detection and aspect de-tection have largely focused on the text of in-dividual claims, losing out on potentially valu-able context from the broader collection of text.
we present a general approach to these tasksmotivated by syntopical reading, a reading pro-cess that emphasizes comparing and contrast-ing viewpoints in order to improve topic under-standing.
to capture collection-level context,we introduce the syntopical graph, a data struc-ture for linking claims within a collection.
asyntopical graph is a typed multi-graph wherenodes represent claims and edges represent dif-ferent possible pairwise relationships, such asentailment, paraphrase, or support.
experi-ments applying syntopical graphs to stance de-tection and aspect detection demonstrate state-of-the-art performance in each domain, signif-icantly outperforming approaches that do notutilize collection-level information..1.introduction.
collections of text about the same topic such asnews articles and research reports often present avariety of viewpoints.
adler and van doren (1940)proposed a formalized manual process for under-standing a topic based on multiple viewpoints intheir book, how to read a book, applying dialec-tics to collection browsing.
this process consistsof four levels of reading, the highest of which issyntopical reading.
syntopical reading is focusedon understanding a core concept by reading a col-lection of works.
it requires ﬁnding passages on the.
∗(cid:63) work done while interning at adobe research..core concept that agree or disagree with each other,deﬁning the issues, and analyzing the discussionto gain a better understanding of the core concept.
the goal of the paper at hand is to operationalizethe syntopical reading process computationally inorder to help individuals make sense of a collectionof documents for a given topic..viewed through the lens of computational argu-mentation, these documents state claims or con-clusions that can be grouped by the aspects of thetopic they discuss as well as by the stance they con-vey towards the topic (stede and schneider, 2018).
an individual aiming to form a thorough under-standing of the topic needs to get an overview ofthese viewpoints and their interactions.
this maybe hard even if adequate tool support for brows-ing the collection is available (wachsmuth et al.,2017a; stab et al., 2018; chen et al., 2019)..we seek to enable systems that are capableof reconstructing viewpoints within a collection,where a viewpoint is expressed as a triple v =(topic, aspect, stance).
we consider the argumenta-tive unit of a claim to be the minimal expression ofa viewpoint in natural language, such that a singleviewpoint can have many claims expressing it.
asan example, consider the following two claims:.
“nuclear energy emits zero co2.”“nuclear can provide a clean baseload, elimi-nating the need for fracking and coal mining.”.
within a collection these claims express:.
v = (nuclear energy, env.
impact, pro).
the goal of the systems we envision is thus toidentify, group, and summarize the latent view-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1583–1595august1–6,2021.©2021associationforcomputationallinguistics1583figure 1: we introduce the idea of a syntopical graph, a data structure that represents the context of claims.
thegraph is a typed multi-graph (multiple edges allowed between nodes), where nodes are claims or documents, andedges are pairwise relationships such as entailment, paraphrase, topical similarity, or term similarity.
by using thisgraph as input to graph neural networks or traditional graph algorithms, we can signiﬁcantly improve on the tasksof aspect and stance detection, which allow us to identify viewpoints in a collection..points underlying the claims in a collection, suchthat a reader can investigate and engage with them..many existing approaches attempt to identifyviewpoints within a collection largely from the textof individual claims only, which we refer to as“content-only approaches.” however, as the latentviewpoints are a global property of a collection, itis necessary to account not only for the text butalso its context.
for instance, in order to identifythe stance of a claim with respect to a topic, it mayhelp to consider the claim’s stance relative to otherclaims on the topic.
although a few researchershave accounted for connections between claimsand other information (details in section 2), nosystematic model of their interactions exists yet..we therefore introduce a syntopical graph thatmodels pairwise textual relationships betweenclaims in order to enable a better reconstructionof the latent viewpoints in a collection.
in line withthe idea of adler and van doren (1940), the syn-topical graph makes the points of agreement anddisagreement within the collection explicit.
tech-nically, it denotes a multi-graph (where a pair ofnodes can have many typed edges) that simulta-neously represents relationships such as relativestance, relative speciﬁcity, or whether a claim para-phrases another.
we build syntopical graphs bytransferring pretrained pairwise models, requiringno additional training data to be annotated..we decompose the problem of viewpoint recon-struction into the subtasks of stance detection andaspect detection, and evaluate the beneﬁts of syn-.
topical graphs — which are a collection-level ap-proach — on both tasks.
for stance detection,we use the sentential argumentation mining col-lection (stab et al., 2018) and the ibm claim stancedataset (bar-haim et al., 2017a).
for aspect detec-tion we use the argument frames collection (ajjouret al., 2019).
we treat the graph as an input to: (a) agraph neural network architecture for stance de-tection, and (b) graph algorithms for unsupervisedtasks such as aspect clustering.
in both settings,our results show that the syntopical graph approachimproves signiﬁcantly over content-only baselines.
the contributions of the work are two-fold:1. a well-motivated data structure for capturingthe latent structure of an argumentative corpus,the syntopical graph..2. an instantiation of syntopical graphs thatyields state-of-the-art results on stance detec-tion and aspect detection..2 related work.
first attempts at stance detection used content-oriented features (somasundaran and wiebe, 2009).
later approaches, such as those by ranade et al.
(2013) and hasan and ng (2013), exploited com-mon patterns in dialogic structure to improve stancedetection.
more tailored to argumentation, bar-haim et al.
(2017a) ﬁrst identiﬁed the aspects of adiscussed topic in two related claims and the senti-ment towards these aspects.
from this information,they derived stance based on the contrastiveness ofthe aspects.
later, bar-haim et al.
(2017b) mod-.
1584viewpoints                 (topic, aspect, stance)syntopical graphconstructionpairwise judgements are used to as edges in atyped multigraph, where claims and documents arethe nodes.
.inputsthe newly created graph is then used forstance and aspect detection, to reconstructviewpoints.a topic andrelevant claimsextracted fromdocuments.nuclear energyc1nlipara.entailmentparaphrasec2c3c1c1c2c3c4c3c1c2c4(nuclear energy, a2,     )c2(nuclear energy, a1,     )c1(nuclear energy, a1,     )c3c4applicationsc3c1c2c4++----+++--eled the context of a claim to account for caseswithout sentiment.
our work follows up on andgeneralizes this idea, systematically incorporatingimplicit and explicit structure induced by the topics,aspects, claims, and participants in a debate..in a similar vein, li et al.
(2018) embedded de-bate posts and authors jointly based on their inter-actions, in order to classify a post’s stance towardsthe debate topic.
durmus et al.
(2019) encodedrelated pairs of claims using bert to predict thestance and speciﬁcity of any claim in a complexstructure of online debates.
however, neither ofthese exploited the full graph structure resultingfrom all the relations and interactions in a debate,which is the gap we ﬁll in this paper.
sridhar et al.
(2015) model collective information about debateposts, authors, and their agreement and disagree-ment using probabilistic soft logic.
whereas theyare restricted to the structure available in a forum,our approach can in principle be applied to arbitrarycollections of text..we also tackle aspect detection, which may atﬁrst seem more content-oriented in nature.
accord-ingly, previous research such as the works of misraet al.
(2015) and reimers et al.
(2019b) employedword-based features or contextualized word embed-dings for topic-speciﬁc aspect clustering.
ajjouret al.
(2019), whose argument frames dataset weuse, instead clustered aspects with latent seman-tic analysis (lsa) and topic modeling.
but, ingeneral, aspects might not be mentioned in a textexplicitly.
therefore, we follow these other ap-proaches, treating the task as a clustering problem.
unlike them, however, we do not model only thecontent and linguistic structure of texts, but wecombine them with the debate structure..different types of argumentation graphs havebeen proposed, covering expert-stance informa-tion (toledo-ronen et al., 2016), basic argumentand debate structure (peldszus and stede, 2015;gemechu and reed, 2019), speciﬁc effect rela-tions (al-khatib et al., 2020; kobbe et al., 2020),social media graphs (aldayel and magdy, 2019),and knowledge graphs (zhang et al., 2020).
ourmain focus is not learning to construct ground-truthgraphs, but how to use an approximated graph to de-rive properties such as stance and aspect.
our workresembles approaches that derive the relevance ofarguments (wachsmuth et al., 2017b) or their cen-trality and divisiveness in a discussion (lawrenceand reed, 2017) from respective graphs.
sawhney.
et al.
(2020) used a neural graph attention networkto classify speech stance based on a graph withtexts, speakers, and topics as nodes.
while we alsouse a relational graph convolutional network forlearning, the graph we propose captures implicitclaim relations as well as explicit structure..in addition, text-based graph neural models havebeen proposed to facilitate classiﬁcation, such astextgcn (yao et al., 2019) as well as the follow-up work bertgcn (lin et al., 2021).
these ap-proaches build a graph over terms (using normal-ized mutual information for edge weights) as wellas sentences and documents (using tf-idf foredge weights) to improve sentence- or document-level classiﬁcation.
our work generalizes this ap-proach, focusing on incorporating many edge typeswith different meanings, such as relative stance orrelative speciﬁcity.
we compare our approach witha bertgcn baseline, and we ablate all considerededge types, in order to show the importance ofcapturing these different textual relationships..ultimately, we seek to facilitate understandingof the main viewpoints in a text collection.
qiuand jiang (2013) used clustering-based viewpointdiscovery to study the impact of the interaction oftopics and users in forum discussions.
egan et al.
(2016) used multi-document summarization tech-niques to mine and organize the main points in adebate, and vilares and he (2017) mined the maintopics and their aspects using a bayesian model.
bar-haim et al.
(2020) introduced the idea of key-point analysis, grouping arguments found in a col-lection by the viewpoint they reﬂect and summa-rizing each group to a salient keypoint.
while ourgraph-based analysis is likely to be suitable for ﬁnd-ing keypoints, we instead focus on reconstructinglatent viewpoints by grouping claims, leaving openthe option to identify the key claims in future workas it would require manual evaluation..3 syntopical graphs.
we now introduce the concept of a syntopicalgraph.
the goal of our syntopical graph is to sys-tematically model the salient interactions of allclaims in a collection of documents.
then, proper-ties of claims (say, their stance towards a topic orthe aspects they cover) can be assessed based notonly on the content of the claim alone, but on theentirety of information available in their context..to capture this context, we build a graph wheredocuments and claims are nodes.
edges between.
1585figure 2: an example syntopical graph created from a collection of documents on the topic of nuclear energy.
the nodes are documents and claims, and there are 0+ weighted and typed edges between any pair of nodes.
indownstream applications, we add the representation of the topic to the claim nodes..claims are constructed using pairwise scoring func-tions, such as pretrained natural language inference(nli) models.
claims may relate to each other inmany different ways: they can support or refuteeach other, they can paraphrase each other, theycan entail or contradict each other, they can be topi-cally similar, etc.
we hypothesize that being able toaccount for these relationships helps computationalargumentation tasks such as stance detection..3.1 graph components.
intuitively, if it is known that claim (a) refutes claim(b), and claim (b) has a positive stance to the topic,it seems more reasonable to believe that claim (a)has a negative stance.
we can represent all of thiswith a graph if we allow multiple edges betweennodes.
for instance, claims can have edges that la-bel both relative agreement and relative speciﬁcity,as exempliﬁed in the graph in figure 2. the processof constructing a graph is shown in figure 1..technically, we capture this intuition as a typedmulti-graph: typed in that the nodes have differ-ent types drawn from {document, claim}, and amulti-graph because multiple edges (of differenttypes) are allowed between nodes.
we then for-mally deﬁne a syntopical graph as a labeled multi-graph in terms of a 5-tuple g:.
g = (σn , σe, n, e, ln , le),where σn is the alphabet of node types, σe is thealphabet of edge types, n is the set of nodes, eis the set of multi-edges, ln : n → σn mapseach node to its type, and le : e → σe mapseach edge to its type.
in the following, we showhow to construct the graph and what each of its.
components look like..the node types, σn , are used to represent struc-.
tured metadata in the graph:.
σn = {claim, document}each node in the graph is mapped to its type withthe function ln .
accordingly, the edge alphabet is.
σe = σe:claim ∪ σe:document,where σe:claim is the set of types of claim-claimedges and σe:document is the set of types of claim-document edges..claim nodes the central node type in a syntopi-cal graph is a claim node.
a claim node representsa topically relevant claim in a collection.
by treat-ing a claim as a node embedded in a graph, we cantake advantage of rich graph structures to repre-sent the context in which the claim occurs, such asthe document the claim appears in or the claim’srelationship with other claims..document nodesin general, two claims fromthe same source are more likely to represent thesame viewpoint than a pair of claims sampled ran-domly.
to capture this intuition, we allow claimsfrom the same source to share information witheach other via document nodes, which enables mod-els to pool information about groups of claims andshare the information amongst them.
similar in-formation about claims can be aggregated in themetadata node and broadcast out to all claims..pairwise relationships as multi-edges thereare two classes of edge types:.
• claim-claim edges (σe:claim) model the re-lationship between pairs of claims: do they.
1586claim: nuclear energy emits zero co2.topic: nuclear energyclaim: nuclear can provide a cleanbaseload and eliminate the need forfracking and coal mining.topic: nuclear energyclaim:  however, uranium mining ishardly a clean process.topic: nuclear energysupportmore spec.refuterefutesupportrefutecontainscontainscontainssupport each other, is one more speciﬁc thanthe other, etc.
different tasks can make use ofthis information (e.g., a claim is likely to havea speciﬁc stance if other claims that support ithave the same stance)..• claim-document edges (σe:document) allowgroups of claims to share information witheach other through common ancestors (e.g.,claims in a document pro nuclear energy aresomewhat likely to have a pro stance)..any pair of nodes can have multiple edges ofdifferent types between them; a claim can bothcontradict and refute another claim, for instance..edge weights an edge can have a real-valuedweight associated with it on the range (−1, 1), rep-resenting the strength of the connection.
the rel-ative stance edge between a claim which stronglyrefutes another would receive a weight close to −1..3.2 graph construction.
for graph edges, we combine four pretrained mod-els and two similarity measures.
the pretrainededge types are: relative stance and relative speci-ﬁcity from durmus et al.
(2019), paraphrase edgesfrom dolan et al.
(2004); morris et al.
(2020), andnatural language inference edges from williamset al.
(2018); liu et al.
(2019).
the edge weightsare the conﬁdence scores deﬁned by.
weight(u, v, r) = ppos(u,v) − pneg(u,v),where u and v are claims, r is the relation type,and ppos(u,v) is the probability of a positive asso-ciation between the claims (e.g., “is a paraphrase”or “does entail”), pneg(u,v) for a negative one.
forsimilarity-based edges, we use standard tf-idffor term-based similarity and lda for topic-basedsimilarity (blei et al., 2003), using cosine similar-ity as the edge weight.
the document-claim edgeshave a single type, contains, with an edge weight of1. we compute each of the pairwise relationshipsfor all pairs of claims that share the same topic,and then ﬁlter out edges using a threshold τ on theabsolute value of the edge weight.
τ is tuned asa hyperparameter on a validation dataset for eachtask..for node representations, we initialize the claimnode representations with the output of a naturallanguage inference model that predicts whether theclaim entails the topic.
we initialize the documentrepresentations with a sentence vectorizer over thetext of the document..4 viewpoint reconstruction.
a viewpoint can be understood as a judgment ofsome aspect of a topic that conveys a stance towardsthe topic.
the goal of viewpoint reconstruction is toidentify the set of viewpoints in a collection givena topic, starting with the claims.
an example ofthis process is shown on the right in figure 1. todenote viewpoints, we borrow notation in line withthe idea of aspect-based argument mining (traut-mann, 2020), which in turn was inspired by aspect-based sentiment analysis.
in particular, we expressa viewpoint as a triple v :.
v = (topic, aspect, stance).
a claim is an expression of a viewpoint in nat-ural language, and a single viewpoint can be ex-pressed in several ways throughout a collection inmany claims.
aspects are facets of the broader ar-gument around the topic.
while some actual claimsmay encode multiple viewpoints simultaneously,henceforth we consider each claim to encode oneviewpoint for simplicity.
to tackle viewpoint re-construction computationally, we decompose it intotwo sub-tasks, stance detection and aspect detec-tion, along with a ﬁnal grouping of claims withsame aspect and stance..stance detection stance detection requires as-signing a valence label to a claim with respect toa particular topic.
though content-only baselinescan work in many cases, there are also cases wherethe stance of a claim might only make sense in rela-tion to a broader argument.
for example, the claim“nuclear power plants take 5 years to construct” isdifﬁcult to assign a stance a priori.
however, in thecontext of other claims such as “solar farms oftentake less than 2 years to commission”, it might beviewed as having a negative stance.
to exploit thisadditional contextual information, we use syntopi-cal graphs as input to a graph neural network, inparticular a relational graph convolutional net-work (r-gcn) (schlichtkrull et al., 2018)..we treat stance detection as a supervised nodeclassiﬁcation task.
the goal is to output a predic-tion in the set {pro, con} for each claim noderelative to a topic.
r-gcns were developed toperform node classiﬁcation and edge predictionfor knowledge bases, which are also typed multi-graphs.
as such, the abstractions of the syntopicalgraph slot neatly into the abstractions of r-gcns.
the input to an r-gcn is a weighted, typedmultigraph with some initial node representation..1587the network is made up of stacked relational graphconvolutional layers; each layer computes a newset of node representations based on each node’sneighborhood.
in effect, each layer combines theedge-type-speciﬁc representation of all of a node’sneighbors with its own representation.
the repre-sentations are inﬂuenced by the node, and all ofits neighbors, attenuated through the edge weight.
an r-gcn thus consumes a set of initial claimrepresentations, transforms them through stacks ofrelational graph convolutional layers, and outputsa ﬁnal set of node vectors, which are fed into aclassiﬁer to predict the claim stance..aspect detection following the work of ajjouret al.
(2019), we treat aspect detection as an unsu-pervised task.
as aspects are an open class, we usea community detection approach, modularity-basedcommunity detection (clauset et al., 2004).
thekey intuition of modularity-based community de-tection is that communities are graph partitions thathave more edges within communities than acrosscommunities.
modularity is a value assigned toa graph partition, which is higher when there arefewer edges across communities than within them;a modularity of 0 represents a random partition,while higher modularities indicate tighter commu-nities.
the goal of modularity-based communitydetection is to maximize modularity by ﬁndingdense partitions.
this intuition works well for as-pects in a syntopical graph — claims that discuss asimilar aspect are likely to have salient interactions.
as aspects themselves are independent of stance,the direction of the interactions (e.g., support orrefute) does not matter, but their salience does.
tocapture only the intensity of the interaction betweentwo claims, we apply a transformation to signedcollapse the multi-edges of a syntopical graph (de-noted sg) to a positive-weighted graph (g):.
(cid:80).
t∈σe.
wg(u, v) =.
δsg(u, v, t) · |wsg(u, v, t)|(cid:80)δsg(u, v, t).
,.
t∈σewhere wg(u, v) is the weight between nodes u andv in the new graph g, δsg(u, v, t) = 1 if an edgeof type t exists between nodes u and v in the syn-topical graph (sg), and wsg(u, v, t) is the edgeweight for type t between nodes u and v in thesyntopical graph.
this is equivalent to taking theaverage across types of the absolute values of theweights.
the newly constructed single-edge graphis then used to identify aspects, which should havemore interactions between them than across them..5 experiments.
to evaluate the effectiveness of our approach at re-constructing viewpoints, we consider three datasetsacross the two subtasks of stance and aspect de-tection.
we hypothesize that syntopical graph ap-proaches will outperform content-only baselines —including the ones used to initialize the claim repre-sentations — because they are able to make use ofnot only the claim content, but also the claim con-text.
we further hypothesize that syntopical graphapproaches will outperform graph-based baselinesthat use only textual similarity edges, because thelatter’s claim context is not as rich.
for our experi-ments, we construct a syntopical graph as describedin section 3..we further evaluate our model by conductingseveral additional experiments, including removingthe use of document nodes or initial claim repre-sentations, analyzing the performance of each edgetype in isolation and when left out, and an anal-ysis of the differences in predictions between thesyntopical graph and the content-only baselines..stance detection for the stance detection exper-iments, we use two datasets: ﬁrst, the heteroge-neous cross-topic argumentation mining dataset(argmin) from stab et al.
(2018), and second, theclaim-stance dataset (ibmcs) from bar-haim et al.
(2017a).
the argmin dataset contains about 25ksentences from 400 documents across eight con-troversial topics, ranging from abortion to schooluniforms.
following schiller et al.
(2020), we ﬁl-ter only the claims, resulting in 11.1k claims.
theibmcs dataset contains 2.4k claims across 55 top-ics.
we use the splits from schiller et al.
(2020),which ensure that the topics in the training and testsets are mutually exclusive.
claims are given astance label drawn from {pro, con}.
we evaluateusing macro-averaged f1 and accuracy..we use a syntopical graph for each dataset as theinput to a relational graph convolutional network(r-gcn), implemented in dgl (wang et al., 2019)and pytorch (paszke et al., 2019).
for documentnode representations, we use a pretrained sentencetransformer and concatenate all of the sentencesas input (reimers et al., 2019a).
for the claimnode representations, we use a roberta modelpretrained on an nli task (liu et al., 2019) to en-code both the claim and topic; the resulting vectorsare ﬁxed throughout training..1588ibmcs.
macro f1.
argmin.
macro f1.
model.
majority baselineroberta large nlibertgcn (lin et al., 2021)mt-dnn, 1 dataset (schiller et al., 2020)*mt-dnn, 10 datasets (schiller et al., 2020)*.
syntopical graph (r-gcn, structure only)syntopical graph (r-gcn, no documents)syntopical graph (r-gcn).
34.0652.3466.1670.6677.72.
44.3283.0383.40.acc.
51.6652.6966.2671.1677.87.
47.8283.1083.54.
33.8360.5658.5161.6561.38.
42.5967.5267.77.acc.
51.1460.9358.7362.4062.11.
52.7168.3468.01.table 1: results on the two stance detection datasets.
the full syntopical graph, as well as the variant withoutdocument nodes, outperforms the content only baselines by both a signiﬁcant and substantial margin (p < 10−7for argmin, and p < 10−4 for ibmcs).
a * on the model means we retrained a previously reported baseline..model.
b-cubed f1.
b-cubed p.b-cubed r.ldaclustering (roberta large mnli)syntopical graph (modularity).
47.0145.6955.42.
47.1944.7666.11.
49.8250.1553.82.table 2: aspect detection results on the argument frames dataset (ajjour et al., 2019).
the syntopical graphoutperformed both lda and clustering of roberta embeddings, recovering latent aspects substantially betterthan either approach.
the syntopical graph approach signiﬁcantly outperforms lda (p < 10−19)..aspect detection for clustering-based aspectdetection, we use the argument frames datasetfrom ajjour et al.
(2019).
the dataset containsroughly 11k sentences drawn from 465 differenttopics.
each sentence has a speciﬁc aspect (orframe, in the original paper), drawn from a set ofover a thousand possible aspects.
following theauthors, we evaluate with a clustering metric, b-cubed f1 (amig´o et al., 2009).
we transform thegraph as described in section 4 to use as an inputto modularity-based community detection, using τof 0.6 tuned on held-out topics..6 results and analysis.
the main results for stance detection are shownin table 1. the most important ﬁnding is thatthe fusion of signals from content and from struc-ture done by our approach syntopical graph (r-gcn) outperforms the existing state-of-the-art(schiller et al., 2020) for both the ibmcs dataset(83.40 macro f1, +5.68 absolute) and the argmindataset (67.7 macro f1, +6.12 absolute).
thecontent-oriented roberta large nli model andthe structure-only syntopical graph have signiﬁ-cantly reduced performance independently, empha-sizing the complementarity of the two signals.
ourbest network is the one which includes both claimand document node, except for the argmin dataset.
aspect detection results are shown in table 2.our modularity approach outperforms the state-of-.
the-art (ajjour et al., 2019) on the argument framesdataset (55.42 b-cubed f1, +8.41 absolute)..the remainder of this section investigates the ro-bustness of the syntopical graph approach to stanceand aspect detection: first, we analyze the con-tribution of each edge type, running experimentswithout and with only each edge type.
we alsoexamine the accuracy of the edges in our graphwhen applied out of domain as well as analysis tounderstand the types of claims for which this modelimproves performance..edge analysis we conducted an ablation studyto analyze the usefulness of each considered edgetype.
to do so, we built graphs containing eachedge independently, and graphs dropping each edgeindependently.
table 3 presents the results..for the supervised task of stance detection, weuse the ibmcs dataset.
no single edge performsas well as the combination of edges, the best beingrelative stance with a macro-f1 score of 80.72.this indicates that our model is capable of takingadvantage of the different kinds of relationshipsrepresented by the edge types.
we see the largestperformance drops when we remove relative stance(79.39), relative speciﬁcity (79.39), or nli (78.95)edges respectively, indicating the highest amount ofunique information being captured by these edges.
in contrast, paraphrase can be removed withoutloss for stance detection according to the results..1589edge.
model.
stance detection (macro f1)without.
alone.
aspect detection.
relative stanceroberta baserelative speciﬁcity roberta baseroberta largeparaphraseroberta basenlitf-idf + cosineterm similaritylda + cosinetopic similarity.
80.7270.2275.5780.2973.6272.67.
79.3979.3583.4278.9581.8382.54.alone.
52.2243.5956.3153.1652.4051.11.without.
53.5255.7353.7753.5254.7454.92.all edges.
83.40.
55.42.table 3: importance of each edge type for both evaluated tasks.
we examine each edge type alone and wheneliminated from the graph entirely (without).
for supervised stance detection, no single edge performs as well asthe combination of all edges.
for unsupervised aspect detection paraphrase edges provide the best signal..edge(all roberta).
stancespeciﬁcityparaphrasenli.
top.
53%82%93%93%.
accuracybottom.
random.
44%52%65%50%.
52%56%74%60%.
table 4: performance of each edge type across domainsconsidering the 100 strongest edges, the 100 weakestedges, and 100 random edges.
there is a clear trendof the strongest edges being more accurate and theweakest edges being less accurate, meaning that theedge weight does have some predictive effect about theedge’s accuracy..this is opposite for aspect detection, whichwe treat as an unsupervised community detectiontask; here paraphrase alone outperforms the graphwith all edge relationships (macro f1 56.31 versus55.42).
the other edges even have a slight negativeeffect on the overall results (55.42); being unsuper-vised, our approach here has no way of ﬁltering outuninformative edges..edge domain transfer one possible con-founder of the contribution of each edge type is theout-of-domain performance of the pairwise modelused to predict that edge.
a poor model wouldprovide little more than random noise, even if theedge type were expected to be helpful.
to investi-gate this possibility, we sampled 100 each of theedges (above τ = 0.6) with the highest weight, thelowest weight, and a random sample.
we then an-notated each edge as being correctly or incorrectlypredicted.
results are shown in table 4..there is a clear trend that the edge weight iscorrelated with edge correctness, meaning that themodels retain some level of calibration across do-mains.
as we incorporate the edge weight in ther-gcn, this helps to lessen the effect of the noisier,.
weaker edges.
another trend is that an edge type’susefulness across tasks is not solely a function ofthat edge type’s accuracy.
the type of failure modeis also important.
for instance, the relative stanceedges have poor surface-level accuracy, but themost common failure was not predicting the wrongrelative stance; it was predicting any stance forpairs of claims about different aspects..flip analysis finally, we analyze ”ﬂipped”cases in stance detection in which the baseline pre-dicted stance incorrectly but the model predictedstance correctly, or vice-versa, to understand areasfor which this model improves performance.
asample of these is shown in table 5..perhaps the most surprising result is how differ-ent the predictions of the syntopical graph-basedapproach are from those of the content-only mt-dnn baseline.
for the ibmcs dataset, there were1355 claims in the test set, and we ﬂipped 219(16.2%) correctly relative to the mt-dnn base-line, but also 140 (10.3%) incorrectly compared tothat baseline.
thus, we ﬂipped 26.5% of the over-all predictions for the 5.68 point improvement inf1.
this holds across the argmin dataset as well,where we ﬂipped 536 (19.6%) claims correctly and373 (13.7%) claims incorrectly, out of a total 2726claims in the test set.
though we show substan-tial gains overall, it seems that the models capturedifferent signals.
we thus believe that future im-provements through improved model combinationmay still be possible..7 conclusion.
in this paper, we have introduced a data structure,the syntopical graph, which provides context forclaims in collections.
we have provided empiricalevidence that syntopical graphs can be used as in-put representations for graph-structured approaches.
1590example.
true mt-dnn syn.
gr.
reason.
topic: wind power should be a primary focus of future energy supplyclaim: predictability of wind plant output remains lowstrongest neighbor (+): the non-dispatchable nature of wind energyproduction can raise costs.
topic: wind power should be a primary focus of future energy supplyclaim: wind power uses little landstrongest neighbor (-): wind power ”cannot be relied upon to providesigniﬁcant levels of power.
topic: build the keystone xl pipelineclaim: the pipeline would be ”game over for the planetstrongest neighbor (-): this is the most technologically advanced andsafest pipeline ever proposed.
con.
pro.
con.
good neighbors.
pro.
pro.
con.
bad neighbors.
con.
pro.
con.
good neighbors.
table 5: stance detection examples with the true stance label where the output label of our syntopical graph wasdifferent from that of the mt-dnn baseline, along with a potential reason..(such as graph neural networks and graph cluster-ing algorithms) to obtain signiﬁcant improvementsover content-only baselines..we believe there are several opportunities to ex-tend this work in the future.
first, we believe thegraph construction could be improved by avoid-ing the inefﬁcient pairwise analysis, expanding theedge types, and utilizing a more robust classiﬁerfor the graph.
second, we would relax the con-straint that a claim represents a single viewpoint, orthe limitation of aspect detection to unsupervisedapproaches.
finally, we would like to apply ourapproach to the original problem ﬁrst motivatedby syntopical reading to see if this system can aidusers in browsing or understanding a collection..8 ethics impact statement.
we anticipate that the syntopical graph exploredin this work will have a beneﬁcial impact in realworld systems to aid users in improved comprehen-sion and reduce susceptibility to misinformation.
the goal of our work is motivated by syntopicalreading, which theorizes that individuals exposedto agreement and disagreement within a collectiongain a deeper understanding of the central topics.
our work on syntopical graphs provides an algo-rithmic foundation to aid readers in understandingthe key viewpoints (aspect and stance for a giventopic) present in a collection..acknowledgments.
we would like to thank many others for their invalu-able feedback and patient discussions, includingcharlotte ellison, ani nenkova, tong sun, han-chin shing, and pedro rodriguez.
this work wasgenerously supported through adobe gift funding,.
which supports an adobe research-university ofmaryland collaboration.
it was completed whilethe primary author was interning at adobe re-search..references.
mortimer j adler and charles van doren.
1940. howto read a book.
simon and schuster, new york..yamen ajjour, milad alshomary, henning wachsmuth,and benno stein.
2019. modeling frames in ar-in proceedings of the 2019 confer-gumentation.
ence on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 2922–2932, hong kong, china.
as-sociation for computational linguistics..khalid al-khatib, yufang hou, henning wachsmuth,charles jochim, francesca bonin, and benno stein.
2020. end-to-end argumentation knowledge graphin proceedings of the thirty-fourthconstruction.
aaai conference on artiﬁcial intelligence, pages7367–7374.
aaai..abeer aldayel and walid magdy.
2019. your stanceis exposed!
analysing possible factors for stance de-tection on social media.
proceedings of the acm onhuman-computer interaction, 3(cscw):1–20..enrique amig´o, julio gonzalo, javier artiles, andfelisa verdejo.
2009. a comparison of extrinsicclustering evaluation metrics based on formal con-straints.
information retrieval, 12(4):461–486..roy bar-haim, indrajit bhattacharya, francesco din-uzzo, amrita saha, and noam slonim.
2017a.
stance classiﬁcation of context-dependent claims.
in proceedings of the 15th conference of the euro-pean chapter of the association for computationallinguistics: volume 1, long papers, pages 251–261,valencia, spain.
association for computational lin-guistics..1591roy bar-haim, lilach edelstein, charles jochim, andnoam slonim.
2017b.
improving claim stance clas-siﬁcation with lexical knowledge expansion and con-text utilization.
in proceedings of the 4th workshopon argument mining, pages 32–38, copenhagen,denmark.
association for computational linguis-tics..roy bar-haim, yoav kantor, lilach eden, roni fried-man, dan lahav, and noam slonim.
2020. quanti-tative argument summarization and beyond: cross-in proceedings of thedomain key point analysis.
2020 conference on empirical methods in naturallanguage processing (emnlp), pages 39–49, on-line.
association for computational linguistics..david m blei, andrew y ng, and michael i jordan.
2003. latent dirichlet allocation.
the journal of ma-chine learning research, 3:993–1022..sihao chen, daniel khashabi, chris callison-burch,and dan roth.
2019. perspectroscope: a windowin proceed-to the world of diverse perspectives.
ings of the 57th annual meeting of the associationfor computational linguistics: system demonstra-tions, pages 129–134, florence, italy.
associationfor computational linguistics..aaron clauset, mark ej newman, and cristophermoore.
2004. finding community structure in verylarge networks.
physical review e, 70(6):066111..bill dolan, chris quirk, and chris brockett.
2004.unsupervised construction of large paraphrase cor-pora: exploiting massively parallel news sources.
in coling 2004: proceedings of the 20th inter-national conference on computational linguistics,pages 350–356, geneva, switzerland.
coling..esin durmus, faisal ladhak, and claire cardie.
2019.determining relative argument speciﬁcity and stancein proceed-for complex argumentative structures.
ings of the 57th annual meeting of the associationfor computational linguistics, pages 4630–4641,florence, italy.
association for computational lin-guistics..charlie egan, advaith siddharthan, and adam wyner.
2016. summarising the points made in online po-in proceedings of the third work-litical debates.
shop on argument mining (argmining2016), pages134–143, berlin, germany.
association for compu-tational linguistics..debela gemechu and chris reed.
2019. decompo-sitional argument mining: a general purpose ap-proach for argument graph construction.
in proceed-ings of the 57th annual meeting of the associationfor computational linguistics, pages 516–526, flo-rence, italy.
association for computational linguis-tics..kazi saidul hasan and vincent ng.
2013..stanceclassiﬁcation of ideological debates: data, models,in proceedings of thefeatures, and constraints..sixth international joint conference on natural lan-guage processing, pages 1348–1356, nagoya, japan.
asian federation of natural language processing..jonathan kobbe, ioana hulpus, , and heiner stucken-schmidt.
2020. unsupervised stance detection forin proceedings ofarguments from consequences.
the 2020 conference on empirical methods in natu-ral language processing (emnlp), pages 50–60..john lawrence and chris reed.
2017. using complexargumentative interactions to reconstruct the argu-in pro-mentative structure of large-scale debates.
ceedings of the 4th workshop on argument mining,pages 108–117, copenhagen, denmark.
associationfor computational linguistics..chang li, aldo porco, and dan goldwasser.
2018.structured representation learning for online debatestance prediction.
in proceedings of the 27th inter-national conference on computational linguistics,pages 3728–3739, santa fe, new mexico, usa.
as-sociation for computational linguistics..yuxiao lin, yuxian meng, xiaofei sun, qinghong han,kun kuang, jiwei li, and fei wu.
2021. bertgcn:transductive text classiﬁcation by combining gcnand bert.
arxiv preprint arxiv:2105.05727..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretrainingapproach.
arxiv preprint arxiv:1907.11692..amita misra, pranav anand, jean e. fox tree, andmarilyn walker.
2015. using summarization to dis-cover argument facets in online idealogical dialog.
in proceedings of the 2015 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,pages 430–440, denver, colorado.
association forcomputational linguistics..john x. morris, eli liﬂand, jin yong yoo, jakegrigsby, di jin, and yanjun qi.
2020. textattack:a framework for adversarial attacks, data augmenta-tion, and adversarial training in nlp..adam paszke, sam gross, francisco massa, adamlerer, james bradbury, gregory chanan, trevorkilleen, zeming lin, natalia gimelshein, lucaantiga, alban desmaison, andreas kopf, edwardyang, zachary devito, martin raison, alykhan te-jani, sasank chilamkurthy, benoit steiner, lu fang,junjie bai, and soumith chintala.
2019.py-torch: an imperative style, high-performance deeplearning library.
in h. wallach, h. larochelle,a. beygelzimer, f. d’ alch´e-buc, e. fox, and r. gar-nett, editors, advances in neural information pro-cessing systems 32, pages 8024–8035.
curran asso-ciates, inc..andreas peldszus and manfred stede.
2015. joint pre-diction in mst-style discourse parsing for argumen-tation mining.
in proceedings of the 2015 confer-ence on empirical methods in natural language.
1592processing, pages 938–948, lisbon, portugal.
asso-ciation for computational linguistics..minghui qiu and jing jiang.
2013. a latent variablemodel for viewpoint discovery from threaded forumposts.
in proceedings of the 2013 conference of thenorth american chapter of the association for com-putational linguistics: human language technolo-gies, pages 1031–1040, atlanta, georgia.
associa-tion for computational linguistics..sarvesh ranade, rajeev sangal, and radhika mamidi.
2013. stance classiﬁcation in online debates byin proceedings ofrecognizing users’ intentions.
the sigdial 2013 conference, pages 61–69, metz,france.
association for computational linguistics..nils reimers, iryna gurevych, nils reimers, irynagurevych, nandan thakur, nils reimers, johannesdaxenberger, and iryna gurevych.
2019a.
sentence-bert: sentence embeddings using siamese bert-networks.
in proceedings of the 2019 conference onempirical methods in natural language processing.
association for computational linguistics..nils reimers, benjamin schiller, tilman beck, jo-hannes daxenberger, christian stab, and irynagurevych.
2019b.
classiﬁcation and clustering ofarguments with contextualized word embeddings.
in proceedings of the 57th annual meeting of the as-sociation for computational linguistics, pages 567–578, florence, italy.
association for computationallinguistics..ramit sawhney, arnav wadhwa, shivam agarwal,and rajiv ratn shah.
2020. gpols: a contextualgraph-based language model for analyzing parlia-mentary debates and political cohesion.
in proceed-ings of the 28th international conference on com-putational linguistics, pages 4847–4859, barcelona,spain (online).
international committee on compu-tational linguistics..benjamin schiller, johannes daxenberger, and irynastance detection benchmark:corr,.
is your stance detection?.
gurevych.
2020.how robustabs/2001.01565..michael schlichtkrull, thomas n kipf, peter bloem,rianne van den berg, ivan titov, and max welling.
2018. modeling relational data with graph convolu-tional networks.
in european semantic web confer-ence, pages 593–607.
springer..swapna somasundaran and janyce wiebe.
2009. rec-in proceed-ognizing stances in online debates.
ings of the joint conference of the 47th annualmeeting of the acl and the 4th international jointconference on natural language processing of theafnlp, pages 226–234, suntec, singapore.
associ-ation for computational linguistics..dhanya sridhar, james foulds, bert huang, lisegetoor, and marilyn walker.
2015. joint models of.
in pro-disagreement and stance in online debate.
ceedings of the 53rd annual meeting of the associa-tion for computational linguistics and the 7th inter-national joint conference on natural language pro-cessing (volume 1: long papers), pages 116–125,beijing, china.
association for computational lin-guistics..christian stab, tristan miller, benjamin schiller,pranav rai, and iryna gurevych.
2018. cross-topic argument mining from heterogeneous sources.
in proceedings ofthe 2018 conference on em-pirical methods in natural language processing,pages 3664–3674, brussels, belgium.
associationfor computational linguistics..manfred stede and jodi schneider.
2018. argumen-tation mining.
number 40 in synthesis lectureson human language technologies.
morgan & clay-pool..orith toledo-ronen, roy bar-haim,.
and noamslonim.
2016. expert stance graphs for computa-in proceedings of the thirdtional argumentation.
workshop on argument mining (argmining2016),pages 119–123, berlin, germany.
association forcomputational linguistics..dietrich trautmann.
2020. aspect-based argumentmining.
in proceedings of the 7th workshop on ar-gument mining, pages 41–52, online.
associationfor computational linguistics..david vilares and yulan he.
2017. detecting perspec-tives in political debates.
in proceedings of the 2017conference on empirical methods in natural lan-guage processing, pages 1573–1582, copenhagen,denmark.
association for computational linguis-tics..henning wachsmuth, martin potthast, khalid al-khatib, yamen ajjour, jana puschmann, jiani qu,jonas dorsch, viorel morari, janek bevendorff, andbenno stein.
2017a.
building an argument searchengine for the web.
in proceedings of the 4th work-shop on argument mining, pages 49–59.
associa-tion for computational linguistics..henning wachsmuth, benno stein, and yamen ajjour.
2017b.
“pagerank” for argument relevance.
in pro-ceedings of the 15th conference of the europeanchapter of the association for computational lin-guistics: volume 1, long papers, pages 1117–1127.
association for computational linguistics..minjie wang, da zheng, zihao ye, quan gan, mufeili, xiang song, jinjing zhou, chao ma, ling-fan yu, yu gai, tianjun xiao, tong he, georgekarypis, jinyang li, and zheng zhang.
2019. deepgraph library: a graph-centric, highly-performantpackage for graph neural networks.
arxiv preprintarxiv:1909.01315..adina williams, nikita nangia, and samuel bowman.
2018. a broad-coverage challenge corpus for sen-tence understanding through inference.
in proceed-ings of the 2018 conference of the north american.
1593chapter of the association for computational lin-guistics: human language technologies, volume1 (long papers), pages 1112–1122.
association forcomputational linguistics..liang yao, chengsheng mao, and yuan luo.
2019.graph convolutional networks for text classiﬁcation.
in proceedings of the aaai conference on artiﬁcialintelligence, volume 33, pages 7370–7377..bowen zhang, min yang, xutao li, yunming ye, xi-aofei xu, and kuai dai.
2020. enhancing cross-target stance detection with transferable semantic-emotion knowledge.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 3188–3197..1594parameter.
type.
low high.
ﬂoat.
threshold (τ )learning rate ﬂoat (log)lr decay (γ)hidden layershidden unitsnumber of basesdropout.
ﬂoatintintintﬂoat.
0.510−60.615010.
1.010−21.0320060.5.table 6: the range of hyperparameters we sweep overwhen training the relational graph convolutional net-work..trained each model for 10 epochs.
the ibmcsmodel took roughly 20 minutes to train, and theargmin model took roughly 3 and a half hours totrain.
we ran each model 5 times to account forrandom variations, and selected the run with thelowest validation score..the ibmcs model has roughly 248k parametersand the argmin model has roughly 330k tunableparameters..the bertgcn baseline used the robertagcnconﬁguration from lin et al.
(2021).
per the orig-inal paper, we ﬁrst trained a roberta model onthe task for 50 epochs using a batch size of 64and a learning rate of 0.00001, then trained therobertagcn model for 60 epochs using a batchsize of 8, a gcn learning rate of 0.001, and aroberta learning rate of 0.00001..a relational graph convolutional.
networks.
the input to an r-gcn is a weighted, typed multi-graph with some initial node representation.
thenetwork is made up of stacked relational graphconvolutional layers; each layer computes a newset of node representations based on each node’sneighborhood.
in effect, each layer combines theedge-type-speciﬁc representation of all of a node’sneighbors with its own representation.
the prop-agation equation is deﬁned per schlichtkrull et al.
(2018):.
h(l+1)u.
= σ.
.
.
(cid:88).
(cid:88).
r∈σe.
v∈n ru.
1|n ru |.
w (l).
r h(l).
v wu,v,r + w (l).
0 h(l)u.
.
.
where u and v are nodes in the graph, n ru is the1neighborhood for node u of edge types r,u | is|n rthe normalization term, wr is the per-relationshiptransformation, wu,v,r is the edge weight betweennodes u and v of edge type r, and w0 is the self-loop weight..b claim node representations.
for the claim node representations, we format theinput to the roberta large nli model as:.
[cls] claim [sep] topic [sep].
we use the output representations (1024 dimsper claim node) as the node representations for thegraph..c hyperparameter tuning.
to tune hyperparameters, we used optuna1 andthe tree of parzen estimators optimizer.
we tunedthe ibmcs dataset with 100 samples on a 1080ti,training 10 epochs for each sample.
for theargmin dataset, we tuned for 3 samples on annvidia quadro rtx 6000, ﬁxing all parametersfrom the best ibmcs dataset, except for the num-ber of layers.
we selected each based on the lowestvalidation loss..d selected models.
for both datasets, we tune the r-gcn on the vali-dation set, ending up with the following parametersettings: number of 3 graph convolutional layersfor argmin and 2 for ibmcs; 128 hidden dimen-sions per layer; a learning rate or 0.00856 and de-cay (γ) of 0.797; dropout of 0.005; τ of 0.6; batchsize of 10; and 4 bases for edge relations.
we.
1https://optuna.org.
1595