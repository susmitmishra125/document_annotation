locate and label: a two-stage identiﬁer for nested named entityrecognition.
yongliang shen1, xinyin ma1, zeqi tan1, shuai zhang1, wen wang2, weiming lu1∗1college of computer science and technology, zhejiang university2university of science and technology of china{syl, luwm}@zju.edu.cn.
abstract.
named entity recognition (ner) is a well-studied task in natural language processing.
traditional ner research only deals with ﬂatentities and ignores nested entities.
thespan-based methods treat entity recognitionas a span classiﬁcation task.
although thesemethods have the innate ability to handlenested ner, they suffer from high computa-tional cost, ignorance of boundary informa-tion, under-utilization of the spans that par-tially match with entities, and difﬁculties inlong entity recognition.
to tackle these issues,we propose a two-stage entity identiﬁer.
firstwe generate span proposals by ﬁltering andboundary regression on the seed spans to lo-cate the entities, and then label the boundary-adjusted span proposals with the correspond-ing categories.
our method effectively utilizesthe boundary information of entities and par-tially matched spans during training.
throughboundary regression, entities of any length canbe covered theoretically, which improves theability to recognize long entities.
in addition,many low-quality seed spans are ﬁltered outin the ﬁrst stage, which reduces the time com-plexity of inference.
experiments on nestedner datasets demonstrate that our proposedmethod outperforms previous state-of-the-artmodels..1.introduction.
named entity recognition (ner) is a fundamentaltask in natural language processing, focusing onidentifying the spans of text that refer to entities.
ner is widely used in downstream tasks, suchas entity linking (ganea and hofmann, 2017; leand titov, 2018) and relation extraction (li and ji,2014; miwa and bansal, 2016)..previous works usually treat ner as a sequencelabeling task, assigning a single tag to each to-.
∗∗ corresponding author.
figure 1: a comparison of named entity recognitionand object detection.
examples of ﬂat and nesetd en-tities or objects sampled from the coco 2017 datasetand the ace04 dataset, respectively..ken in a sentence.
such models lack the abil-ity to identify nested named entities.
various ap-proaches for nested ner have been proposed inrecent years.
some works revised sequence modelsto support nested entities using different strategies(alex et al., 2007; ju et al., 2018; strakov´a et al.,2019; wang et al., 2020a) and some works adoptthe hyper-graph to capture all possible entity men-tions in a sentence (lu and roth, 2015; katiyar andcardie, 2018).
we focus on the span-based meth-ods (sohrab and miwa, 2018; zheng et al., 2019;tan et al., 2020), which treat named entity recog-nition as a classiﬁcation task on a span with theinnate ability to recognize nested named entities.
for example, sohrab and miwa (2018) exhausts allpossible spans in a text sequence and then predictstheir categories.
however, these methods sufferfrom some serious weaknesses.
first, due to nu-merous low-quality candidate spans, these meth-ods require high computational costs.
then, it ishard to identify long entities because the length ofthe span enumerated during training is not inﬁnite.
next, boundary information is not fully utilized,while it is important for the model to locate entities..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2782–2794august1–6,2021.©2021associationforcomputationallinguistics2782object detectionnamed entityrecognitionflatnestedcowcowtenis racketpersona u .
s .
tourist was detained and accused of spying after photographing a riot in the province of irian jaya .gpepergpegpefache said that 47,000 cars drive by the site daily and because the players have to drive by it every day it could become a hangout for them .
vehperperfacperfacalthough some methods (zheng et al., 2019; tanet al., 2020) have used a sequence labeling modelto predict boundaries, yet without dynamic adjust-ment, the boundary information is not fully utilized.
finally, the spans which partially match with en-tities are not effectively utilized.
these methodssimply treat the partially matched spans as nega-tive examples, which can introduce noise into themodel..different from the above studies, we observedthat ner and object detection tasks in computervision have a high degree of consistency.
theyboth need to locate regions of interest (rois) in thecontext (image/text) and then assign correspondingcategories to them.
furthermore, both ﬂat ner andnested ner have corresponding structures in theobject detection task, as shown in figure 1. for theﬂat structure, there is no overlap between entities orbetween objects.
while for nested structures, ﬁne-grained entities are nested inside coarse-grainedentities, and small objects are nested inside largeobjects correspondingly.
in computer vision, thetwo-stage object detectors (girshick et al., 2014;girshick, 2015; ren et al., 2017; dai et al., 2016;he et al., 2017; cai and vasconcelos, 2018) arethe most popular object detection algorithm.
theydivide the detection task into two stages, ﬁrst gen-erating candidate regions, and then classifying andﬁne-tuning the positions of the candidate regions.
inspired by these, we propose a two-stage entityidentiﬁer and treat ner as a joint task of boundaryregression and span classiﬁcation to address theweaknesses mentioned above.
in the ﬁrst stage,we design a span proposal module, which containstwo components: a ﬁlter and a regressor.
the ﬁl-ter divides the seed spans into contextual spansand span proposals, and ﬁlters out the former toreduce the candidate spans.
the regressor locatesentities by adjusting the boundaries of span pro-posals to improve the quality of candidate spans.
then in the second stage, we use an entity classiﬁerto label entity categories for the number-reducedand quality-improved span proposals.
during train-ing, to better utilize the spans that partially matchwith the entities, we construct soft examples byweighting the loss of the model based on the iou.
in addition, we apply the soft non-maximum sup-pression (soft-nms) (bodla et al., 2017) algorithmto entity decoding for dropping the false positives..our main contributions are as follow:.
• inspired by the two-stage detector popular.
in object detection, we propose a novel two-stage identiﬁer for ner of locating entitiesﬁrst and labeling them later.
we treat ner asa joint task of boundary regression and spanclassiﬁcation..• we make effective use of boundary informa-tion.
taking the identiﬁcation of entity bound-aries a step further, our model can adjust theboundaries to accurately locate entities.
andwhen training the boundary regressor, in addi-tion to the boundary-level smoothl1 loss, wealso use a span-level loss, which measures theoverlap between two spans..• during training, instead of simply treatingthe partially matched spans as negative ex-amples, we construct soft examples based onthe iou.
this not only alleviates the imbal-ance between positive and negative examples,but also effectively utilizes the spans whichpartially match with the ground-truth entities..• experiments show that our model achievesstate-of-the-art performance consistently onthe kbp17, ace04 and ace05 datasets,and outperforms several competing baselinemodels on f1-score by +3.08% on kbp17,+0.71% on ace04 and +1.27% on ace05..2 model.
figure 2 illustrates an overview of the modelstructure.
we ﬁrst obtain the word representa-tion through the encoder and generate seed spans.
among these seed spans, some with higher overlapwith the entities are the proposal spans, and otherswith lower overlap are the contextual spans.
inthe span proposal module, we use a ﬁlter to keepthe proposal spans and drop the contextual spans.
meanwhile, a regressor regresses the boundary ofeach span to locate the left and right boundaries ofentities.
next, we adjust the boundaries of the spanproposals based on the output of the regressor, andthen feed them into the entity classiﬁer module.
fi-nally, the entity decoder decodes the entities usingthe soft-nms algorithm.
we will cover our modelin the following sections..2.1 token representation.
consider the i-th word in a sentence with n words,we represent it by concatenating its word embed-i , contextualized word embedding xlmding xw, part-i.
2783figure 2: the overall architecture of the two-stage identiﬁer..i.i.of-speech(pos) embedding xposand character-level embedding xchartogether.
the character-level embedding is generated by a bilstm mod-ule with the same setting as (ju et al., 2018).
forthe contextualized word embedding, we follow (yuet al., 2020) to obtain the context-dependent em-bedding for a target token with one surroundingsentence on each side.
then, the concatenation ofthem is fed into another bilstm to obtain the hid-den state as the ﬁnal word representation hi ∈ rd..2.2 seed span generation.
seed spans are subsequences sampled from a se-quence of words.
by ﬁltering, adjusting boundaries,and classifying on them, we can extract entitiesfrom the sentence.
under the constraint of a pre-speciﬁed set of lengths, where the maximum doesnot exceed l, we enumerate all possible start andend positions to generate the seed spans.
we denotethe set of seed spans as b = {b0, .
.
.
, bk}, wherebi = (sti, edi) denotes i-th seed span, k denotesthe number of the generated seed spans, and sti,edi denote the start and end positions of the spanrespectively..for training the ﬁlter and the regressor, we needto assign a corresponding category and regressiontarget to each seed span.
speciﬁcally, we paireach seed span in b and the ground-truth entitywith which the span has the largest iou.
the ioumeasure the overlap between spans, deﬁned asiou(a, b) = a∩ba∪b , where a and b are two spans.
then we divide them into positive and negativespans based on the iou between the pair.
the spans.
whose iou with the paired ground truth is abovethe threshold α1 are classiﬁed as positive examples,and those less than threshold α1 are classiﬁed asnegative examples.
for the positive span, we assignit the same category ˆy with the paired ground truthand compute the boundary offset ˆt between them.
for the negative span, we only assign a none label.
we downsample the negative examples such thatthe ratio of positive to negative is 1:5..2.3 span proposal module.
the quality of the generated seed spans is vari-able.
if we directly input them into the entity clas-siﬁer, it will lead to a lot of computational waste.
high-quality spans have higher overlap with enti-ties, while low-quality spans have lower overlap.
we denote them as span proposals and contextualspans, respectively.
our span proposal moduleconsists of two components: span proposal fil-ter and boundary regressor.
the former is used todrop the contextual spans and keep the span propos-als, while the latter is used to adjust the boundariesof the span proposals to locate entities..span proposal filter forthe seed spanbi(sti, edi), we concatenate the maximum pooledspan representation hpi with the inner boundaryword representations (hsti, hedi) to obtain the spanrepresentation hf ilter.
based on it we calculate theiprobability pf ilterthat the span bi belongs to thespan proposals, computed as follows:.
i.hpi = maxpooling(hsti, hsti+1, .
.
.
, hedi).
(1).
2784representation israelisusuallylookinguptothepresidentoftheunitedstatesforsomehelp span proposalsboundary offsetsseed span generationfilterlossreg lossisraelindex: (0, 1)looking upindex: (3, 5)the president of theindex: (6, 10)states for someindex: (11, 14)spanproposal filterboundaryoffset regressor61011.965.87011.110.09token indextoken indexisraelindex: (0, 1)the president of theindex: (6, 10)span proposal moduleseed span representation    entity classifier modulecls lossentity classifierboundary adjusted span proposalsthe president of the united statesindex: (6, 12)israelindex: (0, 1)(2).
(3).
hf ilteri.
= [hp.
i ; hsti; hedi].
pf ilteri.
= sigmoid.
mlp.
(cid:16).
(cid:16).
hf ilteri.
(cid:17)(cid:17).
where [; ] denotes the concatenate operation,mlp consists of two linear layers and a gelu(hendrycks and gimpel, 2016) activation function..boundary regressor although the span pro-posal has a high overlap with the entity, it cannothit the entity exactly.
we design another bound-ary regression branch where a regressor locatesentities by adjusting the left and right boundariesof the span proposals.
the boundaries regressionrequires not only the information of span itselfbut also the outer boundary words.
thus we con-catenate the maximum pooled span representationhpi with the outer boundary word representations(hsti−1, hedi+1) to obtain the span representationhreg.
then we calculate the offsets ti of left andiright boundaries:.
i = [hphreg.
i ; hsti−1; hedi+1].
(4).
ti = w2 · gelu(w1hreg.
(5)where w1 ∈ r3d×d, w2 ∈ rd×2, b1 ∈ rd andb2 ∈ r2 are learnable parameters..i + b1) + b2.
2.4 entity classiﬁer module.
with the boundary offsets ti predicted by the bound-ary regressor, we adjust the boundaries of spanproposals.
the adjusted start postion (cid:101)sti and endposition (cid:101)edi of bi are calculated as follow:.
(cid:101)sti = max(0, sti +.
(cid:101)edi = min(l − 1, edi +.
(cid:22).
tli +.
(cid:23).
).
12.
(cid:22).
tri +.
(cid:23)).
12.
(6).
(7).
i and tr.
where tli denote the left and right offsets,respectively.
as in the ﬁlter above, we concate-nate the maximum pooled span representation(cid:101)hpi with the inner boundary word representations).
then we perform entity classiﬁcation:(h(cid:101)sti.
, h.(cid:101)edi.
(cid:101)hpi = maxpooling(h., h.(cid:101)sti+1, .
.
.
, h.(cid:101)edi.
).
(cid:101)sti.
(8).
i = [(cid:101)hphcls.
i ; h.; h.].
(cid:101)edi.
(cid:101)sti.
(9).
pi = softmax.
mlp.
(cid:16).
(cid:17)(cid:17).
(cid:16).
hclsi ).
(10).
where mlp consists of two linear layers and agelu activation function, as in the ﬁlter above..for training the entity classiﬁer, we need to reas-sign the categories based on the iou between thenew adjusted span proposal and paired ground-truthentity.
speciﬁcally, if the iou between a span andits corresponding entity is higher than the thresholdα2, we assign the span the same category with theentity, otherwise we assign it a none category andtreat the span as a negative example..2.5 training objective.
the spans that partially match with the entitiesare very important, but previous span-based ap-proaches simply treat them as negative examples.
such practice not only fails to take advantage ofthese spans but also introduces noise into the model.
we treat partially matched spans as soft examplesby weighting its loss based on its iou with the cor-responding ground truth.
for the i-th span bi, theweight wi is calculated as follows:.
(cid:26) iou(bi, ei)η,.
(1 − iou(bi, ei))η ,.
iou(bi, ei) ≥ αiou(bi, ei) < α.
(11).
where α ∈ {α1, α2} denotes the iou thresholdused in the ﬁrst or the second stage and ei de-notes corresponding ground-truth entity of bi.
ηis a focusing parameter that can smoothly adjustthe rate at which partially matched examples aredown-weighted.
we can ﬁnd that if we set η = 0,the above formula degenerates to a hard one.
also,if a span does not overlap with any entity or matchexactly with some entity, the loss weight wi = 1..then, we calculate the losses for the span pro-posal ﬁlter, boundary regressor and entity classiﬁerrespectively.
for the span proposal ﬁlter, we usefocal loss (lin et al., 2017) to solve the imbalanceproblem:.
lf ilter = −.
(cid:88).
wiiˆy(cid:54)=0(1 − pf ilter.
)γ log(pf ilter.
).
i.i.i+ wiiˆy=0(pf ilter.
i.
)γ log(1 − pf ilter.
).
i.
(12)where wi is the weight of i-th example calculatedat equation 11 and γ denotes focusing parameterof focal loss.
for the boundary regressor, the lossconsists of two components, the smooth l1 loss at.
2785the boundary level and the overlap loss at the spanlevel, calculated as follows:.
then adjust the scores of other span proposals sj tof (si, sj), which is deﬁned as:.
lreg.
(cid:0)ˆt, t(cid:1) = lf 1 + lolp.
(13).
lf 1.
(cid:0)ˆt, t(cid:1) =.
(cid:88).
(cid:88).
smoothl1.
(cid:17).
(cid:16).
i , tjˆtj.
i.
(14).
i.j∈{l,r}.
(cid:18).
(cid:88).
1 −.
lolp =.
min (di) − max (ei)max (di) − min (ei).
(cid:19).
i.
(15).
(cid:101)sti, ˆsti.
(cid:110)(cid:101)edi, ˆedi.
(cid:111)(cid:9).
ˆsti, ˆedi,, ei = (cid:8)where di =i and ˆtrˆtli denote the ground-truth left boundary,right boundary, left offset and right offset, respec-tively.
for the entity classiﬁer, we simply use thecross-entropy loss:.
lcls =.
wi celoss(ˆy, pi).
(16).
(cid:88).
i.where wi is the weight of i-th example calculatedat equation 11. we train the ﬁlter, regressor andclassiﬁer jointly, thus the total loss is computed as:.
(cid:26) scorej ∗ u,scorej,.
iou(si, sj) ≥ kiou(si, sj) < k.(18).
where u ∈ (0, 1) denotes the decay coefﬁcient ofthe score and k denotes is the iou threshold.
thenwe keep all span proposals with a score > δ as theﬁnal extracted entities..algorithm 1: soft-nms algorithminput: s = {si, .
.
.
, sn }, δ, wheresi = (li, ri, yi, scorei).
output: o.
1 o ← {};2 sort(s) by the score of each element in.
descend order;.
3 for si in s do4.
5.
6.
7.
8.o ← o ∪ {si} ;for sj in s [i : n ] dos ← s − {sj};sj ← (lj, rj, yj, f (si, sj));insert (s, k, sj) where k denotesthe insertion position of sj in sordered by score;.
l = λ1lf ilter + λ2lreg + λ3lcls.
(17).
where λ1, λ2 and λ3 are the weights of ﬁlter, re-gressor and classiﬁer losses respectively..end.
910 end.
2.6 entity decoding.
in the model prediction phase, after the above steps,we get the classiﬁcation probability and boundaryoffset regression results for each span proposal.
based on them, we need to extract all entities in thesentence (i.e., ﬁnd the exact start and end positionsof the entities as well as their corresponding cate-gories).
we assign label yi = argmax(pi) to spansi and use scorei = max(pi) as the conﬁdence ofspan si belonging to the yi category..now for each span proposal, our model has pre-dicted the exact start and end positions, the en-tity class and the corresponding score, denoted assi = (li, ri, yi, scorei).
given the score thresholdδ and the set of span proposals s = {s1, .
.
.
, sn },where n denotes as the number of span proposals,we use the soft-nms (bodla et al., 2017) algorithmto ﬁlter the false positives.
as shown in algorithm1, we traverse the span proposals by the order oftheir score (the traversal term is denoted as si) and.
3 experiment settings.
3.1 datasets.
to provide empirical evidence for effectiveness ofthe proposed model, we conduct our experimentson four nested ner datasets: ace04 1, ace05 2,kbp173 and genia 4. please refer to appendixa.1 for statistical information about the datasets..ace 2004 and ace 2005(doddington et al.,2004; christopher walker and maeda, 2006) aretwo nested datasets, each of them contains 7 entitycategories.
we follow the same setup as previouswork katiyar and cardie (2018); lin et al.
(2019)split them into train, dev and test sets by 8:1:1..1 https://catalog.ldc.upenn.edu/ldc2005t092 https://catalog.ldc.upenn.edu/ldc2006t063 https://catalog.ldc.upenn.edu/ldc2019t024 http://www.geniaproject.org/genia-corpus.
2786kbp17 (ji et al., 2017) has 5 entity categories,including gpe, org, per, loc, and fac.
wefollow lin et al.
(2019) to split all documents into866/20/167 documents for train/dev/test set..genia (ohta et al., 2002) is a biology nestednamed entity dataset and contains ﬁve entity types,including dna, rna, protein, cell line, and celltype categories.
following yu et al.
(2020), we use90%/10% train/test split..3.2 evaluation metrics.
we use strict evaluation metrics that an entity isconﬁrmed correct when the entity boundary andthe entity label are correct simultaneously.
weemploy precision, recall and f1-score to evaluatethe performance..3.3 parameter settings.
, xposi., xchari.i , xlmi.in most experiments, we use glove (penningtonet al., 2014) and bert (devlin et al., 2019) inour encoder.
for the genia dataset, we replaceglove with biowordvec (chiu et al., 2016), bertwith biobert (lee et al., 2019).
the dimensionsfor xwand hi are 100, 1024, 50,50 and 1024, respectively.
for all datasets, we trainour model for 35 epochs and use the adam op-timizer with a linear warmup-decay learning rateschedule, a dropout before the ﬁlter, regressor andentity classiﬁer with a rate of 0.5. see appendix afor more detailed parameter settings and baselinemodels we compared 5..4 results and comparisons.
4.1 overall evaluation.
table 1 illustrates the performance of the proposedmodel as well as baselines on ace04, ace05, ge-nia and kbp17.
our model outperforms the state-of-the-art models consistently on three nested nerdatasets.
speciﬁcally, the f1-scores of our modeladvance previous models by +3.08%, +0.71%,+1.27% on kbp17, ace04 and ace05 respec-tively.
and on genia, we achieve comparableperformance.
we analyze the performance on en-tities of different lengths on ace04, as shown intable 2. we observe that the model works wellon the entities whose lengths are not enumeratedduring training.
for example, although entities oflength 6 are not enumerated, while those of length.
5 our code is available at https://github.com/.
tricktreat/locate-and-label..katiyar and cardie (2018)shibuya and hovy (2020)strakov´a et al.
(2019)wang et al.
(2020a)yu et al.
(2020).
katiyar and cardie (2018)lin et al.
(2019)luo and zhao (2020)strakov´a et al.
(2019)wang et al.
(2020a)yu et al.
(2020).
model.
ours.
model.
ours.
model.
ours.
model.
ji et al.
(2017)lin et al.
(2019)luo and zhao (2020)li et al.
(2020b).
lin et al.
(2019)luo and zhao (2020)wang et al.
(2020b)strakov´a et al.
(2019)wang et al.
(2020a)yu et al.
(2020).
87.44.
87.38.
87.41.ace04.
rec..71.8081.91-86.4886.00.ace05.
rec..70.4073.6075.20-85.3985.60.kbp17.
rec..73.0071.8074.3081.12.genia.
rec..73.9074.6074.40-78.9479.30.f1.
72.7082.8184.4086.2886.70.f1.
70.5074.9075.1084.3384.6685.40.f1.
72.8074.6075.6080.97.f1.
74.8076.0076.2078.3179.1980.50.pr..73.6083.73-86.0887.30.pr..70.6076.2075.00-83.9585.20.pr..76.2077.7077.1080.97.pr..75.8077.4078.10-79.4581.80.
86.09.
87.27.
86.67.
85.46.
82.67.
84.05.ours.
80.19.
80.89.
80.54.table 1: results for nested ner tasks.
5 and 7 are enumerated, our model can achieve acomparable f1-score for entities of length 6. in par-ticular, the entities whose lengths exceed the maxi-mum length (15) enumerated during training, arestill well recognized.
this veriﬁes that our modelhas the ability to identify length-uncovered entitiesand long entities by boundary regression.
we alsoevaluated our model on two ﬂat ner datasets, asshown in appendix b..4.2 ablation study.
we choose the ace04 and kbp17 datasets to con-duct several ablation experiments to elucidate themain components of our proposed model.
to il-lustrate the performance of the model on entitiesof different lengths, we divide the entities intothree groups according to their lengths.
the re-.
2787length.
ace04.
f1.
support.
pr..89.6287.9389.6779.0485.5884.6285.0779.3181.4876.4768.7566.67100.0055.5655.5680.0066.6783.3333.3366.67.
87.46.
12345678910111213141516171819≥ 20.all.
rec..90.9886.1084.5988.5983.1886.8485.0779.3173.3376.4768.7580.0085.7183.3371.4357.1480.0083.3333.3324.00.
87.35.
90.3087.0187.0683.5484.3685.7185.0779.3177.1976.4768.7572.7392.3166.6762.5066.6772.7383.3333.3335.29.
87.41.
151962631814910776672930171615767756325.
3035.table 2: a comparison of recognition f1-score on enti-ties of different lengths.
regular rows indicate that theentity lengths are enumerated, while bold ones indicatethat the entity lengths are not enumerated..sults are shown in table 3. firstly, we observethat the boundary regressor is very effective for theidentiﬁcation of long entities.
lack of the bound-ary regressor leads to a decrease in f1-score forlong entities (l ≥ 10) on ace04 by 36.73% andkbp17 by 30.54%.
then, compared with the w/oﬁlter setting, the f1-scores of our full model onthe two datasets improved by 0.52% and 0.75%,respectively.
in addition, experimental results alsodemonstrate that the soft examples we constructedare effective.
this allows the model to take fulladvantage of the information of partially matchedspans in training, improving the f1-score by 0.87%on ace04 and 0.16% on kbp17.
however, soft-nms play a limited role and improve the modelperformance only a little.
we believe that text issparse data compared to images and the numberof false positives predicted by our model is quitesmall, so the soft-nms can hardly perform the roleof a ﬁlter..4.3 time complexity.
theoretically, the number of possible spans of asentence of length n is n (n +1).
previous span-based methods need to classify almost all spans intocorresponding categories, which leads to the highcomputational cost with o(cn 2) time complexity.
2.where c is the number of categories.
the wordsin a sentence can be divided into two categories:contextual words and entity words.
traditional ap-proaches waste a lot of computation on the spanscomposed of contextual words.
however, our ap-proach retains only the span proposals containingentity words by the ﬁlter, and the time complexityis o(n 2).
although in the worst case the modelkeeps all seed spans, generating n (n +1)span pro-posals, we observe that we generate approximatelythree times as many span proposals as the entitiesin practice.
assuming that the number of entitiesin the sentence is k, the total time complexity ofour model is o(n 2 + ck) where k << n 2..2.
5 case study.
examples of model predictions are shown in table4. the ﬁrst line illustrates that our model can recog-nize entities with multi-level nested structures.
wecan see that the three nested entities from insideto outside are united nations secretary general koﬁannan, united nations secretary general and unitednations, all of which can be accurately recognizedby our model.
the second line illustrates that ourmodel can recognize long entities well, althoughtrained without seed spans of the same length as it.
the long entity aceh, which is rich in oil and gasand has a population of about 4.1 million people,with a length of 20, exceeds the maximum lengthof generated seed spans, but can still be correctlylocated and classiﬁed.
however, our model has dif-ﬁculties in resolving ambiguous entity references.
as shown in the third line, our model incorrectlyclassiﬁes the reference phrase both sides, whichrefers to org, into the per category..6 related work.
6.1 nested named entity recognition.
ner is usually modeled as a sequence labelingtask, and a sequence model (e.g., lstm-crf(huang et al., 2015)) is employed to output the se-quence of labels with maximum probability.
how-ever, traditional sequence labeling models cannothandle nested structures because they can only as-sign one label to each token.
in recent years, sev-eral approaches have been proposed to solve thenested named entity recognition task, mainly in-cluding tagging-based (alex et al., 2007; wanget al., 2020a), hypergraph-based (muis and lu,2017; katiyar and cardie, 2018), and span-based.
2788f1-score on ace04.
f1-score on kbp17.
1≤l<5.
5≤l<10.
l≥10.
1≤l<5.
5≤l<10.
l≥10.
all.
model.
support.
full model.
w/o regressorw/o ﬁlterw/o ﬁlter & regressorw/o soft-nmsw/o soft examples.
2612.
88.7388.6388.3588.5988.6688.39.
309.
83.7166.4183.8765.6583.5080.39.
114.
66.0629.3360.5531.0865.1655.96.all.
3035.
87.4185.1886.8985.1287.2886.54.
11594.
85.5283.9984.7785.2885.4985.27.
756.
67.6750.5067.0451.7667.6268.95.
250.
12600.
58.5828.0459.0626.0358.7760.85.
84.0582.5483.3082.8584.0283.89.table 3: ablation study on ace04 and kbp17.
to compare the performance of the model on entities of differentlengths, we divided the entities into three groups: 1 ≤ l < 5, 5 ≤ l < 10 and l ≥ 10..[3[3[2[2[1[1united nations1]orgwith [1[1the host1]per.
1]org secretary general2]per.
2]per koﬁ annan3]per.
1]per , [3[3[2[2[1[1egyptian1]gpe.
1]gpe president2]per.
3]per today discussed plans for the summit3]per ..2]per hosni mubarak3]per.
[1[1separatists1]perand has [2[2a population of [1about 4 .
1 million people1]per.
1]per have fought since 1975 for independence in [3[3aceh , [1[1which1]gep.
3]gep ..3]gep.
2]per.
2]per.
1]gep is rich in oil and gas.
[2[2the [1us1]gpe supreme court2]org[2[2[1[1florida1]gpe[1[1state1]gpe.
1]gpe ballots on saturday ..1]gpe ’ s [1[1leon county1]gpe.
2]org will hear arguments from [1[1both sides1]per.
1]org on friday and2]org will consider the arguments on disputed.
1]gpe circuit court2]org.
table 4: cases study.
blue brackets indicate entities predicted by the model, red brackets indicate true entities, thelabels in the lower right corner indicate the type of entity, and the superscripts indicate the level of the nesting..(sohrab and miwa, 2018; zheng et al., 2019) ap-proaches.
the tagging based nested ner modeltransforms the nested ner task into a special se-quential tagging task by designing a suitable tag-ging schema.
layered-crf (alex et al., 2007)dynamically stacks ﬂat ner layers to identify en-tities from inner to outer.
pyramid (wang et al.,2020a) designs a pyramid structured tagging frame-work that uses cnn networks to identify entitiesfrom the bottom up.
the hypergraph-based modelconstructs the hypergraph by the structure of nestedner and decodes the nested entities on the hyper-graph.
lu and roth (2015) is the ﬁrst to proposethe use of mention hypergraphs to solve the over-lapping mentions recognition problem.
katiyar andcardie (2018) proposed hypergraph representationfor the nested ner task and learned the hypergraphstructure in a greedy way by lstm networks.
thespan-based nested ner model ﬁrst extracts the sub-sequences (spans) in a sequence and then classiﬁesthese spans.
exhaustive model (sohrab and miwa,2018) exhausts all possible spans in a text sequenceand then predicts their classes.
zheng et al.
(2019);tan et al.
(2020) took a sequence labeling modelto identify entity boundaries and then predicted thecategories of boundary-relevant regions.
differentfrom the above methods, some works adopt themethods from other tasks.
for example, yu et al.
(2020) reformulated ner as a structured predic-.
tion task and adopted a biafﬁne model for nestedand ﬂat ner.
while li et al.
(2020b) treated neras a reading comprehension task, and constructedtype-speciﬁc queries to extract entities from thecontext..6.2 object detection.
object detection is a computer vision techniquethat can localize and identify objects in an image.
with this identiﬁcation and localization, object de-tection can determine the exact location of objectswhile assigning them categories.
neural-based ob-ject detection algorithms are divided into two maincategories: one-stage and two-stage approach.
theone-stage object detector densely proposes anchorboxes by covering the possible positions, scales,and aspect ratios, and then predicts the categoriesand accurate positions based on them in a single-shot way, such as overfeat (sermanet et al., 2013),yolo (redmon et al., 2016) and ssd (liu et al.,2016).
the two-stage object detector can be seenas an extension of the dense detector and has beenthe most dominant object detection algorithm formany years (girshick et al., 2014; girshick, 2015;ren et al., 2017; dai et al., 2016; he et al., 2017;cai and vasconcelos, 2018).
it ﬁrst obtains sparseproposal boxes containing objects from a dense setof region candidates, and then adjusts the positionand predicts a category for each proposal..27897 conclusion.
in this paper, we treat ner as a joint task of bound-ary regression and span classiﬁcation and proposea two-stage entity identiﬁer.
first we generate spanproposals through a ﬁlter and regressor, then clas-sify them into the corresponding categories.
ourproposed model can make full use of the boundaryinformation of entities and reduce the computa-tional cost.
moreover, by constructing soft samplesduring training, our model can exploit the spansthat partially match with the entities.
experimentsillustrate that our method achieves state-of-the-artperformance on several nested ner datasets.
forfuture work, we will combine named entity recog-nition and object detection tasks, and try to use auniﬁed framework to address joint identiﬁcation onmultimodal data..acknowledgments.
this work is supported by the key researchand development program of zhejiang province,china(no.
2021c01013), the national key re-search and development project of china (no.
2018aaa0101900), the chinese knowledge cen-ter of engineering science and technology (ck-cest) and moe engineering research center ofdigital library..references.
beatrice alex, barry haddow, and claire grover.
2007.recognising nested named entities in biomedicalin biological, translational, and clinical lan-text.
guage processing, pages 65–72, prague, czech re-public.
association for computational linguistics..n. bodla, b. singh, r. chellappa, and l. s. davis.
2017. soft-nms — improving object detection withone line of code.
in 2017 ieee international con-ference on computer vision (iccv), pages 5562–5570..z. cai and n. vasconcelos.
2018. cascade r-cnn: delv-in 2018ing into high quality object detection.
ieee/cvf conference on computer vision and pat-tern recognition, pages 6154–6162..billy chiu, gamal crichton, anna korhonen, andsampo pyysalo.
2016. how to train good word em-in proceedings ofbeddings for biomedical nlp.
the 15th workshop on biomedical natural languageprocessing, pages 166–174, berlin, germany.
asso-ciation for computational linguistics..stephanie strassel christopher walker and kazuakimaeda.
2006. ace 2005 multilingual training cor-.
pus.
linguistic.
philadelphia 57..in linguistic data consortium,.
jifeng dai, yi li, kaiming he, and jian sun.
2016. r-fcn: object detection via region-based fully convolu-tional networks.
in proceedings of the 30th interna-tional conference on neural information processingsystems, nips’16, page 379–387, red hook, ny,usa.
curran associates inc..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..george doddington, alexis mitchell, mark przybocki,lance ramshaw, stephanie strassel, and ralphweischedel.
2004. the automatic content extraction(ace) program – tasks, data, and evaluation.
inproceedings of the fourth international conferenceon language resources and evaluation (lrec’04),lisbon, portugal.
european language resources as-sociation (elra)..octavian-eugen ganea and thomas hofmann.
2017.deep joint entity disambiguation with local neuralattention.
in proceedings of the 2017 conference onempirical methods in natural language processing,pages 2619–2629, copenhagen, denmark.
associa-tion for computational linguistics..ross girshick.
2015. fast r-cnn.
in proceedings of the2015 ieee international conference on computervision (iccv), iccv ’15, page 1440–1448, usa.
ieee computer society..ross girshick, jeff donahue, trevor darrell, and jiten-dra malik.
2014. rich feature hierarchies for accu-rate object detection and semantic segmentation.
inproceedings of the 2014 ieee conference on com-puter vision and pattern recognition, cvpr ’14,page 580–587, usa.
ieee computer society..k. he, g. gkioxari, p. doll´ar, and r. girshick.
2017.mask r-cnn.
in 2017 ieee international conferenceon computer vision (iccv), pages 2980–2988..dan hendrycks and kevin gimpel.
2016. bridgingnonlinearities and stochastic regularizers with gaus-sian error linear units.
corr, abs/1606.08415..dou hu and lingwei wei.
2020. slk-ner: exploitingsecond-order lexicon knowledge for chinese ner.
inthe 32nd international conference on software &knowledge engineering..zhiheng huang, wei xu, and kai yu.
2015. bidirec-tional lstm-crf models for sequence tagging.
arxivpreprint arxiv:1508.01991..2790heng ji, xiaoman pan, boliang zhang, joel noth-man, james mayﬁeld, paul mcnamee, and cashcostello.
2017. overview of tac-kbp2017 13 lan-in proceed-guages entity discovery and linking.
ings of the 2017 text analysis conference, tac2017, gaithersburg, maryland, usa, november 13-14, 2017. nist..meizhi ju, makoto miwa, and sophia ananiadou.
2018. a neural layered model for nested named en-in proceedings of the 2018 con-tity recognition.
ference of the north american chapter of the asso-ciation for computational linguistics: human lan-guage technologies, volume 1 (long papers), pages1446–1459, new orleans, louisiana.
associationfor computational linguistics..arzoo katiyar and claire cardie.
2018. nested namedin proceedings of theentity recognition revisited.
2018 conference of the north american chapter ofthe association for computational linguistics: hu-man language technologies, volume 1 (long pa-pers), pages 861–871, new orleans, louisiana.
as-sociation for computational linguistics..phong le and ivan titov.
2018. improving entity link-ing by modeling latent relations between mentions.
in proceedings of the 56th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 1595–1604, melbourne, aus-tralia.
association for computational linguistics..jinhyuk lee, wonjin yoon,.
sungdong kim,donghyeon kim, sunkyu kim, chan ho so,and jaewoo kang.
2019. biobert: a pre-trainedbiomedicalforbiomedical text mining.
bioinformatics..language representation model.
qi li and heng ji.
2014. incremental joint extractionin proceedingsof entity mentions and relations.
of the 52nd annual meeting of the association forcomputational linguistics (volume 1: long papers),pages 402–412, baltimore, maryland.
associationfor computational linguistics..xiaonan li, hang yan, xipeng qiu, and xuanjinghuang.
2020a.
flat: chinese ner using ﬂat-lattice transformer.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 6836–6842, online.
associationfor computational linguistics..xiaoya li, jingrong feng, yuxian meng, qinghonghan, fei wu, and jiwei li.
2020b.
a uniﬁed mrcin pro-framework for named entity recognition.
ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5849–5859, online.
association for computational lin-guistics..hongyu lin, yaojie lu, xianpei han, and le sun.
2019. sequence-to-nuggets: nested entity mentionin proceed-detection via anchor-region networks.
ings of the 57th annual meeting of the associationfor computational linguistics, pages 5182–5192,.
florence, italy.
association for computational lin-guistics..t. lin, p. goyal, r. girshick, k. he, and p. doll´ar.
2017. focal loss for dense object detection.
in 2017ieee international conference on computer vision(iccv), pages 2999–3007..wei liu, dragomir anguelov, dumitru erhan, chris-tian szegedy, scott reed, cheng-yang fu, andalexander c berg.
2016. ssd: single shot multi-box detector.
in european conference on computervision, pages 21–37.
springer..wei lu and dan roth.
2015..joint mention extrac-tion and classiﬁcation with mention hypergraphs.
in proceedings of the 2015 conference on empiri-cal methods in natural language processing, pages857–867, lisbon, portugal.
association for compu-tational linguistics..ying luo and hai zhao.
2020. bipartite ﬂat-graph net-in pro-work for nested named entity recognition.
ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 6408–6418, online.
association for computational lin-guistics..yuxian meng, wei wu, fei wang, xiaoya li, ping nie,fan yin, muyu li, qinghong han, xiaofei sun, andjiwei li.
2019. glyce: glyph-vectors for chinesein advances in neuralcharacter representations.
information processing systems, volume 32, pages2746–2757.
curran associates, inc..makoto miwa and mohit bansal.
2016. end-to-end re-lation extraction using lstms on sequences and treestructures.
in proceedings of the 54th annual meet-ing of the association for computational linguistics(volume 1: long papers), pages 1105–1116, berlin,germany.
association for computational linguis-tics..aldrian obaja muis and wei lu.
2017. labeling gapsbetween words: recognizing overlapping mentionswith mention separators.
in proceedings of the 2017conference on empirical methods in natural lan-guage processing, pages 2608–2618, copenhagen,denmark.
association for computational linguis-tics..tomoko ohta, yuka tateisi, and jin-dong kim.
2002.the genia corpus: an annotated research abstractin proceed-corpus in molecular biology domain.
ings of the second international conference on hu-man language technology research, hlt ’02, page82–86, san francisco, ca, usa.
morgan kaufmannpublishers inc..nanyun peng and mark dredze.
2015. named entityrecognition for chinese social media with jointlyin proceedings of the 2015trained embeddings.
conference on empirical methods in natural lan-guage processing, pages 548–554, lisbon, portugal.
association for computational linguistics..2791jeffrey pennington, richard socher, and christophermanning.
2014. glove: global vectors for wordrepresentation.
in proceedings of the 2014 confer-ence on empirical methods in natural languageprocessing (emnlp), pages 1532–1543, doha,qatar.
association for computational linguistics..jue wang, lidan shou, ke chen, and gang chen.
2020a.
pyramid: a layered model for nested namedin proceedings of the 58th an-entity recognition.
nual meeting of the association for computationallinguistics, pages 5918–5928, online.
associationfor computational linguistics..yu wang, yun li, hanghang tong, and ziye zhu.
2020b.
hit: nested named entity recognition viain proceed-head-tail pair and token interaction.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages6027–6036, online.
association for computationallinguistics..juntao yu, bernd bohnet, and massimo poesio.
2020.named entity recognition as dependency parsing.
inproceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 6470–6476, online.
association for computational lin-guistics..changmeng zheng, yi cai, jingyun xu, ho-fung le-ung, and guandong xu.
2019. a boundary-awareneural model for nested named entity recognition.
inproceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 357–366, hong kong, china.
association for computa-tional linguistics..matthew peters, mark neumann, mohit iyyer, mattgardner, christopher clark, kenton lee, and lukezettlemoyer.
2018. deep contextualized word rep-in proceedings of the 2018 confer-resentations.
ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1 (long papers), pages2227–2237, new orleans, louisiana.
associationfor computational linguistics..j. redmon, s. divvala, r. girshick, and a. farhadi.
2016. you only look once: uniﬁed, real-time objectdetection.
in 2016 ieee conference on computervision and pattern recognition (cvpr), pages 779–788..shaoqing ren, kaiming he, ross girshick, and jiansun.
2017. faster r-cnn: towards real-time ob-ject detection with region proposal networks.
ieeetrans.
pattern anal.
mach.
intell., 39(6):1137–1149..pierre sermanet, david eigen, xiang zhang, micha¨elmathieu, rob fergus, and yann lecun.
2013. over-feat: integrated recognition, localization and detec-2nd interna-tion using convolutional networks.
tional conference on learning representations..takashi shibuya and eduard hovy.
2020. nestednamed entity recognition via second-best sequencelearning and decoding.
transactions of the associa-tion for computational linguistics, 8:605–620..mohammad golam sohrab and makoto miwa.
2018.deep exhaustive model for nested named entityrecognition.
in proceedings of the 2018 conferenceon empirical methods in natural language process-ing, pages 2843–2849, brussels, belgium.
associa-tion for computational linguistics..jana strakov´a, milan straka, and jan hajic.
2019. neu-ral architectures for nested ner through lineariza-in proceedings of the 57th annual meetingtion.
of the association for computational linguistics,pages 5326–5331, florence, italy.
association forcomputational linguistics..chuanqi tan, wei qiu, mosha chen, rui wang, andfei huang.
2020. boundary enhanced neural spanclassiﬁcation for nested named entity recognition.
proceedings of the aaai conference on artiﬁcial in-telligence, 34(05):9016–9023..erik f. tjong kim sang and fien de meulder.
2003. introduction to the conll-2003 shared task:language-independent named entity recognition.
inproceedings of the seventh conference on natu-ral language learning at hlt-naacl 2003, pages142–147..2792a experiments on nested ner.
a.4 analysis of boundary offset regression.
a.1 statistics of nested datasets.
in table 5, we report the number of sentences, thenumber of sentences containing nested entities, theaverage sentence length, the total number of enti-ties, the number of nested entities and the nestingratio on the ace04, ace05, genia and kbp17datasets..a.2 baseline methods.
we use the following models as baselines for nestedner:.
we analyzed the distribution of the boundary off-sets predicted by the model on the ace04 dataset,as shown in figure 3. we can ﬁnd that the numbersof offsets by 0, 1, 2, 3 and ≥ 4 are 2162, 2440,888, 368 and 202, respectively.
most of the offsetsare 1, indicating that most of the seed spans requireslight boundary adjustments to accurately locatethe entities.
there are also many offsets of 0. thisis because many entities in the dataset are short andthe seed spans can cover them, and their boundariesdo not need to be adjusted..• biafﬁne (yu et al., 2020) reformulates neras a structured prediction task and adopts adependency parsing approach for ner..• pyramid (wang et al., 2020a) consists of astack of inter-connected layers.
each layerpredicts whether a text region of certain lengthis a complete entity mention..• biflag (yu et al., 2020) designs a bipartiteﬂat-graph network with two interacting sub-graph modules for outermost entities and innerentities, respectively..• hit (wang et al., 2020b) leverages the head-tail pair and token interaction to express thenested entities..• arn (lin et al., 2019) designs a sequence-to-nuggets architecture by modeling and levrag-ing the head-driven phrase structures of entitymentions..• seq2seq (strakov´a et al., 2019) views thenested ner as a sequence-to-sequence prob-lem..• kbp17-best.
(ji et al., 2017) gives anoverview of the entity discovery task andreports previous best results for the task ofnested ner..we didn’t compare our model with bert-mrc(li et al., 2020b), because it uses additional exter-nal resources to construct the questions, which es-sentially introduces descriptive information aboutthe categories..a.3 detailed parameter settings.
in our experiments, the detailed parameter settingsfor the model are shown in table 6..figure 3: boundary offset statistics.
b experiments on flat ner.
b.1 datasets.
we use two ﬂat ner datasets to evaluate ourmodel:.
conll03 english is an english dataset (tjongkim sang and de meulder, 2003) with four typesof ﬂat entities: location, organization, person andmiscellaneous.
following lin et al.
(2019), wetrain our model on the concatenation of the trainand dev set..weibo chineseis a chinese dataset (peng anddredze, 2015) sampled from weibo with four typesof ﬂat entities, including person, organization, lo-cation and geo-political.
and we evaluate ourmodel using the same setting with li et al.
(2020a)..b.2 baselines.
for english ﬂat ner, we use several taggers asbaseline models, including elmo-tagger (peterset al., 2018), bert-tagger (peters et al., 2018),which using elmo, bert as encoder respectively.
and for chinese ﬂat ner, we use glyce (meng.
2793offset = 0offset = 1offset = 2offset = 3offset  40500100015002000250021622440888368202dataset statistics.
ace04.
ace05.
kbp17.
genia.
train.
dev.
test.
train.
dev.
test.
train.
dev.
test.
train.
test.
# sentences# sent.
nested entitiesavg sentence length# total entities# nested entitiesnested percentage (%).
6200271222.50222041014945.71.
74529423.022514109246.69.
81238823.053035141745.61.
7194269119.2124441938938.41.
96933818.933200111234.75.
104732017.22993111837.35.
10546280919.6231236877328.09.
54518220.61187960532.20.
4267122319.2612601370729.42.
16692352225.3550509906417.95.
185444625.995506119921.78.table 5: statistics of the datasets used in the experiments..ace04 ace05 kbp17 genia.
3e-05.
3e-05.
5e-5.
windows.
[1-7, 9, 11, 13, 15].
batch size.
8.
8.
4.
5e-6.
[1-10].
6.
2.0.
0.7.
1.0.
1.0.p.lr.
γ.α1.
α2.
η.u.k.δ.
0.9.
0.6.
0.55.
0.8.
0.7.
0.5.
0.9.
0.6.
0.5.
0.9.
0.7.
0.45.λ1, λ2, λ3.
[1.0, 0.1 ,1.0].
table 6: detailed parameter(p) settings.
model.
et al., 2019), flat (li et al., 2020a) and slk-ner (hu and wei, 2020) as baseline models.
theyincoprate glyph information, phrase embeddingsand second-order lexicon knowledge for chinesener respectively..b.3 results.
we evaluated our model on the ﬂat ner dataset,as shown in table 7. our model outperforms thebaseline models on weibo chinese, improving thef1-score by 0.61%.
on conll03, our model alsoachieves comparable results, with less than 1% per-formance drop compared to the (yu et al., 2020)..conll03 english.
pr..--93.70.rec..--93.30.f1.
92.2292.8093.50.
92.13.
93.73.
92.94.weibo chinese.
pr..61.8067.6-.
rec..66.3067.68-.
f1.
64.0067.7168.55.
70.11.
68.12.
69.16.peters et al.
(2018)devlin et al.
(2019)yu et al.
(2020).
ours.
model.
hu and wei (2020)meng et al.
(2019)li et al.
(2020a).
ours.
table 7: results for ﬂat ner tasks.
2794