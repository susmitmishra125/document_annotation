modeling transitions of focal entities for conversational knowledgebase question answering.
yunshi lansingapore management universityyslan@smu.edu.sg.
jing jiangsingapore management universityjingjiang@smu.edu.sg.
abstract.
conversational kbqa is about answering a se-quence of questions related to a kb.
follow-upquestions in conversational kbqa often havemissing information referring to entities fromthe conversation history.
in this paper, we pro-pose to model these implied entities, which werefer to as the focal entities of the conversation.
we propose a novel graph-based model to cap-ture the transitions of focal entities and applya graph neural network to derive a probabilitydistribution of focal entities for each question,which is then combined with a standard kbqamodule to perform answer ranking.
our exper-iments on two datasets demonstrate the effec-tiveness of our proposed method..1.introduction.
recently, conversational knowledge base ques-tion answering (kbqa) has started to attract peo-ple’s attention (saha et al., 2018; christmann et al.,2019; guo et al., 2018; shen et al., 2019).
mo-tivated by real-world conversational applications,particularly personal assistants such as apple siriand amazon alexa, the task aims to answer ques-tions over kbs in a conversational manner..figure 1 shows an example of conversationalkbqa.
as we can see, the conversation can beroughly divided into two parts: q1, q2 and q3revolve around the book “the great gatsby,” whileq4 and q5 revolve around its author, “f.
scottfitzgerald”.
although these entities are not explic-itly mentioned in the questions, they are implied bythe conversation history, and they are critical foranswering the questions.
for example, q3, whentaken out of context, cannot be answered becauseq3 itself does not state the title of the book beingdiscussed.
but since q3 is a follow-up questionof q1, humans can easily infer that the book ofinterest here is “the great gatsby” and can henceanswer the question correctly.
we therefore can.
figure 1: an example conversation in conversationalkbqa.
the entities shown in blue are what we callthe focal entities, which are implicit but important foranswering the questions..regard the entity “the great gatsby” as the focusof the conversation at this point.
when we moveon to q4, again, if the question is taken out of con-text, we cannot answer it.
but by following theconversation ﬂow, humans can guess that at thispoint the focus of the conversation has shifted to be“f.
scott fitzgerald” (the answer to q3), and basedon this understanding, humans would have no prob-lem answering q4.
we refer to “the great gatsby”and “f.
scott fitzgerald” as the focal entities of theconversation..based on the observation above, we hypothesizethat it is important to explicitly model how a con-versation transits from one focal entity to anotherin order to effectively address the conversationalkbqa task.
there are at least two scenarios whereknowing the current focal entity helps answer thecurrent question.
(1) the current focal entity is theunspeciﬁed topic entity1 of the current question.
e.g., “the great gatsby” is the unspeciﬁed topicentity for q3, which effectively should be “whatis the name of the author of the great gatsby?”(2) the current focal entity is closely related to the.
1in kbqa, a topic entity is an entity mentioned in thequestion and the starting point in the kb to search for answers..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3288–3297august1–6,2021.©2021associationforcomputationallinguistics3288conversationbasedkbqa𝐐𝟏:whichactorvoicedtheunicorninthelastunicorn?𝐑𝟏:miafarrow𝐐𝟐:andalanarkinwasbehind…?𝐑𝟐:schmendrick𝐐𝟑:so,whosangforthefilm?r𝟑:america𝐐𝟒:genreofthisband’smusic?r𝟒:folkrock,softrock𝐐𝟓:bytheway,whowasthedirector?r𝟓:julesbass𝐐𝟏:what novel has the character named nick carraway?𝐑𝟏:the great gatsbyq2:whereisjay gatsbyborn?thegreatgatsbyr2:north dakota𝐐𝟑:what is the name of the author?thegreatgatsby𝐑𝟑:f. scott fitzgerald𝐐𝟒:what’s his first novel?f.
scott fitzgeraldr𝟒:this side of paradise𝐐𝟓:who was his child?f.
scott fitzgeraldr𝟓:frances scott fitzgeraldtopic entity of the current question and can helpnarrow down the search space in case of ambigu-ity.
e.g., knowing the focal entity is “the greatgatsby” for q2, the system can identify the correctsubgraph of the kb that contains both “jay gatsby”(the topic entity) and “the great gatsby” for an-swer prediction, which is critical if there are morethan one entities in the kb named “jay gatsby.”we can also see that simple entity coreference res-olution techniques (e.g., lee et al.
(2017)) maynot always help for conversational kbqa as nopronouns are used in many cases..although existing work on conversationalkbqa has tried to address the challenges of miss-ing information in follow-up questions by modelingconversation history, most of it simply includes ev-erything in the conversation history without consid-ering focal entities.
for example, saha et al.
(2018)leveraged a hierarchical encoder to encode all thequestions and responses in the conversation history,but there was no explicit modeling of anything sim-ilar to focal entities.
guo et al.
(2018) concatenatedprevious questions with the current question to ﬁllin the missing information, but again there wasno special treatment of entities.
a more recentwork (christmann et al., 2019) believed that the an-swers to sequential questions should be closely con-nected to each other in the kb.
thus, they proposedan algorithm to keep a context graph in memory,expanding it as the conversation evolves to increasethe connections between the questions.
however,their method is inefﬁcient in capturing the mostsigniﬁcant information related to focal entities in aconversation history..in this paper, we explicitly model the focal enti-ties and their transitions in a conversation in orderto improve conversational kbqa.
based on severalobservations we have with focal entities, such astheir tendencies to be topic entities or answer enti-ties in the conversation history and their stickinessin a conversation, we propose to construct an en-tity transition graph to elaborately model entitiesinvolved in the conversation as well as their inter-actions, and apply a graph-based neural networkto derive a focal score for each entity in the graph,which represents the probability of this entity beingthe focal entity at the current stage of the conver-sation.
the key intuition behind the graph neuralnetwork is to propagate an entity’s focal score inthe i-th turn of the conversation to its neighboringentities in the (i + 1)-th turn of the conversation..this derived focal entity distribution is then incor-porated into a standard single-turn kbqa systemto handle the current question in the conversation.
we evaluate our proposed method on two conver-sational kbqa datasets, convquestions (christ-mann et al., 2019) and convcsqa (which is asubset we derived from csqa (saha et al., 2018)).
experiment results show that compared with eithera single-turn kbqa system or a system that sim-ply encodes the entire conversation history withouthandling focal entities in a special way, our methodcan clearly perform better on both datasets.
ourmethod also outperforms several existing systemsthat represent the state of the art on these bench-mark datasets.
we also conduct error analysis thatsheds light on where further improvement is de-sired..we summarize our contributions of this paperas follows: (1) we propose to explicitly model thefocal entities of a conversation in order to improveconversational kbqa.
(2) we propose a graph-based neural network model to capture the tran-sitions of focal entities and derive a focal entitydistribution that can be plugged into a standardsingle-turn kbqa system.
(3) we empiricallydemonstrate the effectiveness of our method ontwo datasets.
our method can outperform the stateof the art by 9.5 percentage points on convques-tions and 14.3 percentage points on convcsqa2..2 background.
2.1 problem formulation.
a kb k consists of a large nubmer of triplets(cid:104)es, r, eo(cid:105), where es and eo are entities and r in-dicates their relation..we ﬁrst deﬁne single-turn kbqa as fol-lows.
given a kb k and a question q,thesystem is supposed to return one or more en-tities from k as the answer to q.in single-turn kbqa, different question-answer pairs d ={(q1, a1), (q2, a2), .
.
.}
are independent..conversational kbqa is a multiple-turn kbqaproblem, where a sequence of question-answerpairs c = ((q1, a1), (q2, a2), ..., (qm, am)) formsa complete conversation and a set of independentconversations d = {c1, c2, .
.
.}
forms a conversa-tional kbqa dataset.
we refer to each question-answer pair as one turn of the conversation.
aconversational kbqa system is supposed to return.
2our code is available at https://github.com/.
lanyunshi/conversationalkbqa..3289the correct answer to the current question qt basedon not only qt but also the preceding questions(q1, q2, ..., qt−1) in the same conversation..2.2 pipeline for single-turn kbqa.
a standard single-turn kbqa includes two maincomponents: a query generator and an answerpredictor.
the query generator generates a set ofcandidate query graphs c for a given q. speciﬁ-cally, we ﬁrst assume that some entities relevant toq are ﬁrst identiﬁed.
these can be entities directlymentioned in q or other entities relevant to q butimplicitly mentioned, such as the focal entities weintroduced earlier.
starting from these entities, thequery generator generates a set of candidate querygraphs (yih et al., 2016) from k, which lead tosome candidate answers to the question.
the sec-ond component of a single-turn kbqa system, theanswer predictor, is a neural-network-based rankerthat takes in the question as well as the generatedquery graphs as input and outputs a predicted an-swer ˆa..for conversational kbqa, the initial question q0in a conversation c can be answered directly usingan existing single-turn kbqa approach (yu et al.,2017; luo et al., 2018; yih et al., 2016; lan et al.,2019).
when the single-turn kbqa system is usedfor answering follow-up questions, we make thefollowing modiﬁcations: first, we assume that afocal entity distribution (which is the core of ourmethod and will be presented in detail below) isderived from the conversation history.
then eachfocal entity is considered relevant to the currentquestion and will be used to generate candidatequery graphs by the query generator.
meanwhile,the probabilities of these focal entities (i.e., theirfocal scores) will be used by the answer predictorwhen it ranks the candidate query graphs..3 our method.
3.1 overview.
our proposed method hinges on the notion of focalentities that we introduced in section 1. recall thata focal entity is the focus of the conversation at itscurrent stage.
to model focal entities, we proposeto ﬁrst use an entity transition graph to modelall the entities involved in the conversation so farand their interactions.
these entities are candidatefocal entities.
the edges of the graph reﬂect howthe conversation has shifted from one entity to an-other, and such transitions can help us estimate how.
likely an entity is the current focal entity, as we willexplain in section 3.2. this graph is incrementallyconstructed by a graph constructor after each turnof the conversation.
to derive a focal score (i.e., aprobability) for each entity in this graph, a focalentity predictor employs a graph-based neural net-work and generates a new focal entity distributionbased on the previous focal entity distribution aswell as the conversation history, which is encodedby a conversation history encoder using a stan-dard sequence model.
finally, the derived focal en-tity distribution is incorporated into the single-turnkbqa module presented in section 2.2 to performanswer prediction.
the overall architecture of ourmethod is illustrated in figure 2..3.2 entity transition graph and graph.
constructor.
our graph constructor builds the entity transi-tion graph as follows.
the initial entity transitiongraph g(0) is set to be an empty graph.
let g(t−1)denote the entity transition graph before the t-th turn of the conversation, and suppose we haveprocessed the t-th question and obtained the an-swer entity ˆat (which is predicted) with the help ofg(t−1).
we now need to construct gt, which willbe used to help answer qt+1.
recall that the an-swer predictor presented in section 2.2 obtains theanswer entity ˆat by identifying a top-ranked querygraph, which starts from either an entity in g(t−1)or a topic entity mentioned in qt.
let st denoteall the entities except ˆat in this top-ranked querygraph.
the graph constructor adds the followingnodes and edges to g(t−1) in order to build gt..• for each entity e ∈ st, add e to the graph as anode if it does not exist in the graph yet.
alsoadd ˆat to the graph as a node if it does notexist yet..• for each newly added node e, add a “self-loop”.
edge from e to itself..• for each entity e ∈ st, add a “forward” edge.
• for each entity e ∈ st, add a “backward” edge.
from e to ˆat..from ˆat to e..• for each entity e ∈ s1, i.e., the entities rel-evant to the ﬁrst question, add a “backward”edge from ˆat to e..the way we construct the entity transitiongraph as described above is based on the followingobservations with focal entities: (1) a focal entityis often an answer entity to a previous question..3290figure 2: architecture of our method.
q1, ˆa1, q2 and ˆa2 correspond to the example conversation in figure 1.speciﬁcally, we show the prediction procedure for q3, where the entities “nick carraway”, “the great gatsby”,“jay gatsby” and “north dakota” form the entity transition graph.
after predicting the focal entity distribution atthat stage, we leverage both the distribution and q3 to generate ˆa3.
the single-turn kbqa system is shown insidethe rectangle on the right and our proposed component is shown inside the rectangle on the left..therefore we include all previous answer entitiesin the graph.
(2) a focal entity is also likely to bean entity relevant to a previous question that hasled to the answer entity.
we therefore also includethose entities in the query graphs into the entitytransition graph.
(3) the focal entity tends to stayunchanged and thus has a “stickiness” property ina conversation.
thus we add a self-loop edge foreach node.
(4) the focal entity may often go backto some entity relevant to the ﬁrst question.
there-fore, we always add an edge from the latest answerentity to entities relevant to the ﬁrst question.
(5) ifan entity is frequently discussed in the conversationhistory, it might be more likely to be a focal entity.
we thus give such entities more connectivities inthe graph..to give a concrete example of the entity tran-sition graph, let us take a look at figure 3. whenwe answer q2, “nick carrayway” and “the greatgatsby” are included in the graph because thetop-ranked query graph of q1 contains the entity“nick carrayway” and returns the entity “the greatgatsby”.
as the conversation proceeds, the entitytransition graph grows dynamically and we even-tually obtain figure 3 (d) when we answer q5..3.3 conversation history encoder.
the objective of the conversation history encoderis to encode the textual context of the previousquestions and their predicted answers, particularlyinformation other than the entities (which is alreadycaptured by the entity transition graph).
the out-put of the conversation history encoder is a singlevector and it will be fed into the focal entity pre-dictor as an additional input..figure 3: an example of the construction process ofthe entity transition graph.
(a) to (d) show the graphwhen we answer q2 to q5, respectively.
the nodesin gray are the most recently added entities.
the num-bers in blue are the out-degrees of the entities in thekb, which are used in section 3.4. the edges shown insolid, dashed or dotted lines indicate “forward”, “back-ward” and “self-loop”, respectively.
the nodes high-lighted with thick borders are the actual focal entitiesof the current questions..similar to previous methods (serban et al., 2017;saha et al., 2018), we leverage a hierarchical en-coder to encode the conversation history, where alower layer encodes individual questions and pre-dicted answers independently and an upper layerconnects the sequence of questions and answersto derive a single vector.
speciﬁcally, suppose wehave completed (t − 1) turns of the conversation.
the lower-layer encoder employs a standard se-quence encoder (in our case a bilstm) to encodeeach question and each predicted answer so far.
let qi ∈ rd (1 ≤ i ≤ (t − 1)) denote the en-coded vector representation of qi, and similarly, letˆai ∈ rd denote the encoded vector for ˆai.
next, the.
3291𝑞"𝑎$"𝑞%𝑞&𝑎$%northdakotathegreatgatsbynickcarrawayjaygatsby652010entitytransitiongraphfocalentitydistributionnickcarrawaythegreatgatsbynorthdakotajaygatsbyconversationhistoryquestion𝑎$&datakbmodelfocalentitypredictorgraphconstructorconversationhistoryencoderanswerpredictorquerygenerator(a)northdakotathegreatgatsbynickcarrawayjaygatsbythegreatgatsbynickcarraway652010620(b)(c)(d)northdakotathegreatgatsbynickcarraway6520jaygatsby10f.
scott fitzgeraldk30thissideofparadise23northdakotathegreatgatsbynickcarrawayjaygatsbyf.
scott fitzgeraldk65201030upper-layer encoder leverages a recurrent networkto encode the vector sequence q1, ˆa1, q2, ˆa2, .
.
.
and generate a sequence of hidden vectors.
thelast hidden vector, which we denote as ht−1 ∈ rd,will be used as the representation of the conversa-tion history..it is worth noting that although our conversationhistory encoder is similar to how previous workencodes conversation history (serban et al., 2017),previous work uses the representation ht−1 directlyas part of the representation of the current question,which introduces noise.
in contrast, we use it tohelp predict our focal entity distribution only..3.4 focal entity predictor.
the focal entity predictor employs a graph con-volution network (gcn) (kipf and welling, 2017;schlichtkrull et al., 2018) to derive a focal score foreach node in the entity transition graph at eachturn of the conversation.
first, we assume that eachentity (i.e., node) e in the graph has a vector repre-sentation, and this representation is updated at eachturn.
let us use et to represent this vector at thet-th turn.
for each interaction relation label (i.e.,“forward”, “backward” and “self-loop”), we alsouse a vector to represent it at each turn, which wedenote as rt..at the t-th turn, the vector representations ofthe entities and interaction relations are updated asfollows:.
et =.
(cid:88).
αre(cid:48).
t−1,.
(r,e(cid:48))∈n (e).
αr = softmax(r,e(cid:48))∈n (e)(h.(cid:124)t−1rt−1),.
(1).
(2).
where n (e) is the set of nodes connect to e togetherwith the connecting edges, and ht−1 is the outputof the conversation history encoder as we have ex-plained earlier.
the formulas above show that therepresentation of e will be aggregated from the rep-resentations of its neighborhood entities from thelast turn of the conversation, and the aggregationweights α are derived based on the conversationhistory ht−1 as well as the nature of the interactionrelation..for each node that is newly added to the entitytransition graph and each of the interaction rela-tion labels, we initialize its vector representation toa random vector..to derive the focal score of entity e at the currentturn, we make use of both et and two additionalfeatures.
speciﬁcally, we obtain the out degree of.
each entity from the entire kb as one additionalfeature.
we also assign a label to each entity toindicate whether it is from st (as deﬁned in sec-tion 3.2) or is ˆat.
we denote these two features aseout-degree and etemporal, where eout-degree is a scalarand etemporal ∈ rd is represented using embed-dings..we now concatenate et and etemporal as well as.
eout-degree to derive focal scores as follows:.
˜et = [et ⊕ etemporal ⊕ eout-degree], (3)(cid:124)t ˜et + bt), (4).
focalscoret(e) = softmaxe∈gc(w.where ⊕ denotes concatenation, both wt and btare parameters to be learned and they are speciﬁcto the t-th turn.
here focalscoret(e) denotes thefocal score, i.e., the probability that entity e wouldbe the focal entity for the t-th question..3.5 training objectives.
our training objective comes from two parts: first,we want to minimize the loss from incorrectly an-swering a question.
for this, we use a standardcross entropy loss.
second, we want to supervisethe training of the focal entity predictor, but we donot have any ground truth for the focal entity distri-butions.
we therefore produce pseudo ground truthas follows: if there is an entity that could generateat least one query graph resulting in the correctanswer, we treat it as a correct focal entity for thatquestion and assign a value of 1 to the entry forthis entity in the distribution; otherwise, the valueremains 0. finally, we normalize the distributionand obtain a pseudo distribution.
we then try tominimize the kl-divergence between this pseudoground truth of focal entity distribution and ourpredicted focal entity distribution..4 experiments.
in this section, we ﬁrst introduce two benchmarkdatasets and our experiment settings in section 4.1and section 4.2. next, we discuss the main resultsand analysis in section 4.3 and section 4.4. wefurther show the comparison with sota systems insection 4.5 and some error analysis in section 4.6..4.1 data sets.
we use two datasets to evaluate our proposedmethod.
the latest wikidata dump3 is used asthe kb for both datasets.
average accuracy and f1score are employed to measure the performance..3https://query.wikidata.org.
3292convquestions: this is a large-scale conversa-tional kbqa dataset4 created via amazon me-chanical turk (christmann et al., 2019).
the ques-tions cover topics in ﬁve domains.
each conver-sation contains 5 sequential questions with anno-tated ground truth answers.
there are many ques-tions with missing information in the conversations,which makes the dataset very suitable for evaluat-ing our method.
the dataset contains 6k, 2k and2k conversations for training, development andtesting, each evenly distributed across domains..convcsqa: this dataset comes from the thecsqa dataset5 (saha et al., 2018), originally cre-ated for a setting similar to conversational kbqa.
however, one of the focuses of the original csqadata was complex questions, which is not relatedto our work.
also, the csqa data contains manyquestions in a conversation that do not have con-nections with preceding questions.
we thereforeelaborately selected conversational questions fromcsqa to suit our needs, using the following strate-gies: 1) we collected the topic entities as well asthe answer entities in the conversation history.
ifa follow-up question contains one of these entities,we kept the question; otherwise, we omitted it.
2)if the question type description did not explicitlymention that this question contains an “indirect”subject, we removed it.
3) we also ﬁltered out theconversations with a length smaller than 5. as aresult, we obtained a subset of csqa that consistsof 7k, 0.5k and 1k conversations for training, de-velopment and testing, respectively.
the averagenumber of questions per conversation is 5.36. wecall this the convcsqa dataset..4.2 experiment settings.
to evaluate the effectiveness of our proposed entitytransition graph and focal entity predictor, wemainly compare the following three methods:.
singleturn: this is the method described in sec-tion 2.2. speciﬁcally, we ﬁrst recognize the namedentities in the questions via the allennlp nertool6 and retrieve the corresponding entities viasparql.
to generate candidate query graphs, weconsider all subgraphs that are 1 hop or 2 hopsaway from the topic entities (or focal entities in.
4https://convex.mpi-inf.mpg.de/5https://amritasaha1812.github.io/.
csqa/.
6https://demo.allennlp.org/.
named-entity-recognition.
the case when the singleturn system is used inour method).
next, we employ the answer pre-dictor that consists of two bilstms to encode thequestion as well as each candidate subgraph inde-pendently.
the ﬁnal score is computed via the dotproduct of these two vectors..convhistory: this method follows a standardway of encoding the conversational history using atwo-level hierarchical encoder (serban et al., 2017).
it does not explicitly model any focal entity..our method: this is our proposed methodwhere we model the focal entities through the en-tity transition graph and the focal entity predic-tor.
this method also uses the same hierarchicalencoder as above to encode the conversation his-tory..implementation details: we implement ourmethod by pytorch on nvidia v440.64.00-32gbgpu cards.
we employ glove7 as our initializedword embeddings and set the maximum number ofgcn layers as 10. we apply grid search throughpre-deﬁned hyper-parameter spaces, speciﬁcally,hidden dimensionality amongst {200, 300, 400},learning rate amongst {3e − 3, 3e − 4, 3e − 5} anddropout ratio amongst {0.2, 0.1, 0.0}.
the besthyper-parameter conﬁguration is based on the bestf1 score on the development set.
eventually, foreach neural network model, we set the hidden di-mensionality to 300. a dropout layer is set beforeeach mlp with a ratio of 0.1. we use the adamoptimizer (kingma and ba, 2015) with a learningrate of 3e − 5, and the batch size is 1. the trainingepoch number is 100..4.3 main results.
table 1 shows the overall results.
as we can see,our method clearly outperforms both singleturnand convhistory on both datasets.
this conﬁrmsthat with the additional components we added thatmodel the focal entities, the method is able to makeuse of the conversation history more effectivelyto answer the follow-up questions compared withconvhistory (which simply encode the entire his-tory without speciﬁcally modeling focal entities).
surprisingly, we ﬁnd that simply modeling the con-versation history through a standard two-level hi-erarchical sequence model does not consistently.
7https://nlp.stanford.edu/projects/.
glove/.
3293methods.
convquestionsdev.
test.
convcsqatest.
dev.
singleturnconvhistoryour method.
29.729.131.9.
27.3/30.527.2/30.229.8/33.3.
61.862.063.2.
56.8/65.057.0/65.157.8/66.9.
methods.
singleturnconvhistoryour method.
q1.
49.250.150.0.q2.
33.531.735.0.q3.
22.123.528.7.q4.
19.619.220.1.q5.
12.39.215.4.table 1: f1 results on development and acc/f1 resultson test of convquestions and convcsqa..table 3: accuracy results breakdown by conversationturns on convquestions..model conﬁguration.
acc/f1.
our method (full model).
29.8/33.3.
- historical conversation- entity transition graph- entity property.
28.7/32.128.2/31.628.3/31.7.
table 2: the ablation results on convquestions..improve the performance.
it suggests that includ-ing all the historical conversation information ina brute-force manner may not capture the mostimportant conversation contexts effectively..case studies.
to verify if our predicted focalentities are meaningful, we use two concrete exam-ples to conduct a case study.
figure 4 displays twoexample conversations from convquestions.
weshow the focal entity distributions for the sequenceof questions in bar charts.
we can see that the pre-dicted focal entity distribution indeed follows theﬂow of the conversation.
for example, the entitywith the largest focal score in the ﬁrst conversationtransits from “f.scott fitzgerald” to “zelda fitzger-ald,” and then to “st.
patrick’s cathedral,” whilein the second conversation it remains as “tupacshakur” throughout the conversation..4.4 further analysis.
4.5 comparison with sota.
ablation studies.
next, we remove the majorcomponents in our method one at a time and showthe ablation results conducted on convquestionsin table 2. speciﬁcally, we 1) remove the effectof modeling conversation history by replacing αrin eqn.
(1) with a uniform distribution; 2) removegraph information by replacing et with ht−1 ineqn.
(3); 3) remove entity property by omittingeout-degree in eqn.
(3).
the results in table 2 showthat all the above information helps our methodto predict focal entities accurately and achieve thebest kbqa results..breakdown by turns of conversation.
ourmethod is speciﬁcally designed for follow-up ques-tions.
therefore, it would be interesting to see howthe method fares for questions at different turnsof the conversation.
is it more difﬁcult to answera question at a later turn of the conversation thanan earlier question?
we therefore show the resultsbreakdown by turns of conversation in table 3. weobserve that as expected, for questions at later turnsof a conversation, the performance drops for allthree methods.
we believe that for both conhis-tory and our method, this is partially due to errorpropagation.
on the other hand, compared withsingleturn and convhistory, our method is stillmore robust when handling the follow-up questionsat later turns of a conversation..we compare our proposed method with existingstate-of-the-art systems in table 4. our methodoutperforms other systems on most questions andachieves overall 9.5 and 14.3 percentage pointsof improvement on convquestions and convc-sqa, respectively.
convex, star and chainemploy expansion-based or rule-based strategiesto identify the answer entities for follow-up ques-tions.
hred+kvmem combines the hierarchicalencoder with a key-value memory network.
d2aand masp are two seq2seq models to translate thequestions into logical forms.
our system is de-veloped based on a standard single-turn kbqasystem.
we strengthen it by modeling focal entitytransitions, and it shows outstanding capability inanswering co-referenced, ellipsis and veriﬁcationquestions..4.6 error analysis.
to better understand where our method has failed,we randomly sampled and analysed 100 questionswith wrong predictions and manually inspectedthem.
we ﬁnd that the errors are mainly due to thefollowing reasons.
mis-prediction of relations (43%) the major er-rors come from relation mis-predictions.
in ourmodel, relation prediction is done by a simple an-swer predictor.
we expect that employing a moreadvanced encoder could reduce this type of errors..3294figure 4: two conversations in convquestions and our predicted focal entity distributions.
each stacked bar showsthe probabilities of the focal entity candidates for each question, where each entity is shown in its own color..methods.
movies.
convquestionstv series music books.
soccer qt1 qt2 qt3 qt4.
convex (christmann et al., 2019)star (christmann et al., 2019)chain (christmann et al., 2019)hred+kvmem (saha et al., 2018)d2a (guo et al., 2018)masp (shen et al., 2019).
our method.
25.925.79.4-9.0-.
29.0.
17.819.43.1-6.7-.
30.4.
19.024.14.0-7.2-.
30.1.
19.824.15.3-12.1-.
30.1.
18.817.91.6-10.7-.
29.6.
38.9--13.661.082.7.
81.2.convcsqa.
14.8--7.143.445.2.
64.6.
4.6--8.84.73.8.
23.1.
47.8--21.445.846.3.
58.0.table 4: comparison with other systems.
convquestions results (acc) are shown with different domains andconvcsqa results (f1) are shown with different question types (“simple”, “co-referenced”, “ellipsis” and “veri-ﬁcation”).
results of convquestions are copied from (christmann et al., 2019).
results of convcsqa are basedon our re-implementation using the ofﬁcial source code8..query generation failure (29%) there are manycases where the correct query graphs are difﬁcult tobe collected from the kb due to the incompletenessof the kb or the limitation of the query generator.
mis-linking of topic entities (22%) the errorscaused by wrong identiﬁcation of the topic entitiesof questions also lead to incorrectness of the ﬁnalanswers, because if the entity linker links the ques-tion to a wrong entity, it is unlikely to answer thequestion correctly.
this is a general challenge forkbqa..5 related work.
single-turn kbqa task has been studied fordecades.
traditional methods tried to retrieve thecorrect answers from the kb via either embedding-based methods (bordes et al., 2014; xu et al., 2019;sun et al., 2018, 2019; qiu et al., 2020; he et al.,2021) or semantic parsing-based methods (berantet al., 2013; yih et al., 2015; luo et al., 2018; zhanget al., 2019; lan and jiang, 2020).
conversationalkbqa is a relatively new direction that builds ontop of single-turn kbqa..8since the original d2a and masp codes leverage theground truth topic entities and relations to pre-train the entitylinker and relation predictor but we do not, we skip the pre-training procedure in our re-implementation..conversational kbqa is related to dialogue sys-tems and conversational qa in general, which re-quire techniques to sequentially generate responsesbased on the interactions with users (ghazvinine-jad et al., 2018; rajendran et al., 2018; das et al.,2017).
a conversation history can be encoded viadifferent techniques such as a hierarchical neuralnetwork (serban et al., 2017; reddy et al., 2019) ormodeling the ﬂow of the conversation along witha passage (huang et al., 2019; gao et al., 2019,2020).
our work also intends to capture the ﬂowof the conversation but we speciﬁcally model thetransitions of focal entities..regarding.
conversational kbqa,.
sahaet al.
(2018) proposed a model consisting ofa hierarchical encoder, a key-value memorynetwork and a decoder.
guo et al.
(2018) andshen et al.
(2019) employed a seq2seq modelto encode the conversation history then outputa sequence of actions to form an executablecommand.
some follow-up work (guo et al., 2019;shen et al., 2020) focused on the meta-learningsetting or the effective search strategy underweak supervision, which is beyond the focus ofthis paper.
christmann et al.
(2019) detectedfrontier nodes by expanding a subgraph, which arepotential answer entities to the current question..3295𝐐𝟏:what was the birth name of tupac shakur?𝐑𝟏:lesaneparish crooks𝐐𝟐:place of birth?𝐑𝟐:east harlem𝐐𝟑:how did he die?r𝟑:drive-by shooting𝐐𝟒:shakur's mother?r𝟒:afenishakur𝐐𝟓:date of death?r𝟓:13 september 1996(a)(b)𝐐𝟏:who is the author of the great gatsby?𝐑𝟏:f. scott fitzgerald𝐐𝟐:what year did fitzgerald write the great gatsby?𝐑𝟐:1925𝐐𝟑:who was fitzgerald married to?r𝟑:zelda fitzgerald𝐐𝟒:where were the fitzgeraldsmarried?r𝟒:st. patrick's cathedral𝐐𝟓:where is it?r𝟓:new york citytheir motivation is relevant to ours but we target atmodeling the focal entities in the conversation..6 conclusion.
in this paper, we present a method to model thetransitions of focal entities in a conversation in or-der to improve conversational kbqa.
our methodcan outperform two baselines and achieve state-of-the-art performance on two benchmark datasets..acknowledgements.
this research was supported by the singaporeministry of education (moe) academic researchfund (acrf) tier 1 grant..references.
jonathan berant, andrew chou, roy frostig, and percyliang.
2013. semantic parsing on freebase fromquestion-answer pairs.
in proceedings of the 2013conference on empirical methods in natural lan-guage processing, pages 1533–1544..antoine bordes, sumit chopra, and jason weston.
2014. question answering with subgraph embed-in proceedings of the 2014 conference ondings.
empirical methods in natural language processing,pages 615–620..philipp christmann, rishiraj saha roy, abdalghaniabujabal, jyotsna singh, and gerhard weikum.
2019. look before you hop: conversational ques-tion answering over knowledge graphs using judi-cious context expansion.
in proceedings of the 28thacm international conference on information andknowledge management, pages 729–738..michel galley.
2018. a knowledge-grounded neu-ral conversation model.
in proceedings of the aaaiconference on artiﬁcial intelligence, pages 5110–5117..daya guo, duyu tang, nan duan, ming zhou, andjian yin.
2018. dialog-to-action: conversationalquestion answering over a large-scale knowledgebase.
in proceedings of the 32nd international con-ference on neural information processing systems,pages 2942–2951..daya guo, duyu tang, nan duan, ming zhou, andjian yin.
2019.coupling retrieval and meta-learning for context-dependent semantic parsing.
inproceedings of the 57th annual meeting of the as-sociation for computational linguistics, pages 855–866..gaole he, yunshi lan, jing jiang, xin zhao, and ji-rong wen.
2021. improving multi-hop knowledgebase question answering by learning intermediate su-pervision signals.
in proceedings of the 14th acminternational conference on web search and datamining..hsin-yuan huang, eunsol choi, and wen tau yih.
2019. flowqa: grasping ﬂow in history for conver-in proceedingssational machine comprehension.
of international conference on learning represen-tations..diederik p. kingma and jimmy ba.
2015. adam: amethod for stochastic optimization.
in proceedingsof international conference on learning represen-tations..thomas n. kipf and max welling.
2017..semi-supervised classiﬁcation with graph convolutionalin proceedings of international confer-networks.
ence on learning representations..abhishek das, satwik kottur, khushi gupta, avisingh, deshraj yadav, jos´e m.f.
moura, deviparikh, and dhruv batra.
2017. visual dialog.
inproceedings of 2017 ieee conference on computervision and pattern recognition, pages 326–335..yunshi lan and jing jiang.
2020. query graph gen-eration for answering multi-hop complex questionsfrom knowledge bases.
in proceedings of the 58thannual meeting of the association for computa-tional linguistics, pages 969–974..yifan gao, piji li, irwin king, and michael r. lyu.
2019.interconnected question generation withcoreference alignment and conversation ﬂow mod-in proceedings of the 57th annual meet-eling.
ing of the association for computational linguistics,pages 4853–4862..yifan gao, chien-sheng wu, shaﬁq joty, caimingxiong, richard socher, irwin king, michael r. lyu,and steven c.h.
hoi.
2020. explicit memory trackerwith coarse-to-ﬁne reasoning for conversational ma-in proceedings of the 58th annualchine reading.
meeting of the association for computational lin-guistics..marjan ghazvininejad, chris brockett, ming-weichang, bill dolan, jianfeng gao, wen-tau yih, and.
yunshi lan, shuohang wang, and jing jiang.
2019.knowledge base question answering with topic units.
in proceedings of the twenty-eighth internationaljoint conference on artiﬁcial intelligence, pages5046–5052..kenton lee, luheng he, mike lewis, and luke zettle-moyer.
2017. end-to-end neural coreference reso-in proceedings of the 2017 conference onlution.
empirical methods in natural language processing,pages 188–197..kangqi luo, fengli lin, xusheng luo, and kenny zhu.
2018. knowledge base question answering via en-coding of complex query graphs.
in proceedings ofthe 2018 conference on empirical methods in natu-ral language processing, pages 2185–2194..3296haitian sun, bhuwan dhingra, manzil zaheer, kathrynmazaitis, ruslan salakhutdinov, and william w. co-hen.
2018. open domain question answering usingin pro-early fusion of knowledge bases and text.
ceedings of the 2018 conference on empirical meth-ods in natural language processing, pages 4231–4242..kun xu, yuxuan lai, yansong feng, and zhiguo wang.
2019. enhancing key-value memory neural net-works for knowledge based question answering.
inproceedings of the 17th annual conference of thenorth american chapter of the association for com-putational linguistics, pages 2937–2947..wen-tau yih, ming-wei chang, xiaodong he, andjianfeng gao.
2015. semantic parsing via stagedquery graph generation: question answering withknowledge base.
in proceedings of the 53rd annualmeeting of the association for computational lin-guistics and the 7th international joint conferenceon natural language processing (volume 1: longpapers), pages 1321–1331..wen-tau yih, matthew richardson, christopher meek,ming-wei chang, and jina suh.
2016. the value ofsemantic parse labeling for knowledge base questionanswering.
in proceedings of the 54th annual meet-ing of the association for computational linguistics(volume 2: short papers), pages 201–206..mo yu, wenpeng yin, kazi saidul hasan, cicero dossantos, bing xiang, and bowen zhou.
2017.im-proved neural relation detection for knowledge basequestion answering.
in proceedings of the 55th an-nual meeting of the association for computationallinguistics (volume 1: long papers), pages 571–581..haoyu zhang, jingjing cai, jianjun xu, and ji wang.
2019. complex question decomposition for seman-tic parsing.
in proceedings of the 57th annual meet-ing of the association for computational linguistics,pages 4477–4486..yunqi qiu, yuanzhuo wang, xiaolong jin, and kunzhang.
2020. stepwise reasoning for multi-relationquestion answering over knowledge graph withweak supervision.
in proceedings of the 13th inter-national conference on web search and data min-ing, pages 474–482..janarthanan rajendran, jatin ganhotra, satinder singh,and lazaros polymenakos.
2018. learning end-to-end goal-oriented dialog with multiple answers.
in proceedings of the 2018 conference on empiri-cal methods in natural language processing, pages3834–3843..siva reddy, danqi chen, and christopher d. manning.
2019. coqa: a conversational question answeringchallenge.
transactions of the association for com-putational linguistics, 7:249–266..amrita saha, vardaan pahuja, mitesh m. khapra,karthik sankaranarayanan, and sarath chandar.
2018. complex sequential question answering: to-wards learning to converse over linked question an-swer pairs with a knowledge graph.
in proceedingsof the thirty-second aaai conference on artiﬁcialintelligence, pages 705–713..michael sejr schlichtkrull, thomas n. kipf, peterbloem, rianne van den berg, ivan titov, and maxwelling.
2018. modeling relational data with graphin proceedings of euro-convolutional networks.
pean semantic web conference, pages 593–607..iulian vlad serban, alessandro sordoni, ryan lowe,laurent charlin, joelle pineau, aaron courville, andyoshua bengio.
2017. a hierarchical latent variableencoder-decoder model for generating dialogues.
inproceedings of the thirty-first aaai conference onartiﬁcial intelligence, page 3295–3301..tao shen, xiubo geng, guodong long, jing jiang,chengqi zhang, and daxin jiang.
2020. effec-tive search of logical forms for weakly supervisedin proceed-knowledge-based question answering.
ings of the twenty-ninth international joint con-ference on artiﬁcial intelligence, ijcai-20, pages2227–2233..tao shen, xiubo geng, tao qin, daya guo, duyutang, nan duan, guodong long, and daxin jiang.
2019. multi-task learning for conversational ques-tion answering over a large-scale knowledge base.
in proceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 2442–2451..haitian sun, tania bedrax-weiss, and william w. co-hen.
2019. pullnet: open domain question answer-ing with iterative retrieval on knowledge bases andin proceedings of the 2019 conference ontext.
empirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages2380–2390..3297