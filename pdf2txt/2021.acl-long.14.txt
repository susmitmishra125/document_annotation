bob: bert over bert for training persona-based dialogue modelsfrom limited personalized data.
haoyu song1, yan wang, kaiyan zhang1, wei-nan zhang1∗, ting liu11research center for social computing and information retrievalharbin institute of technology, heilongjiang, china{hysong,kyzhang,wnzhang,tliu}@ir.hit.edu.cnyanwang.branden@gmail.com.
abstract.
maintaining consistent personas is essentialfor dialogue agents.
although tremendous ad-vancements have been brought, the limited-scale of annotated persona-dense data are stillbarriers towards training robust and consistentpersona-based dialogue models.
in this work,we show how the challenges can be addressedby disentangling persona-based dialogue gen-eration into two sub-tasks with a novel bert-over-bert (bob) model.
speciﬁcally, themodel consists of a bert-based encoder andtwo bert-based decoders, where one decoderis for response generation, and another is forconsistency understanding.
in particular, tolearn the ability of consistency understandingfrom large-scale non-dialogue inference data,we train the second decoder in an unlikeli-hood manner.
under different limited data set-tings, both automatic and human evaluationsdemonstrate that the proposed model outper-forms strong baselines in response quality andpersona consistency..1.introduction.
various approaches have been explored to intro-duce explicit personas in dialogue models (qianet al., 2018; song et al., 2019; zheng et al., 2020;liu et al., 2020).
the persona can be deﬁned asa composite of elements of identity, such as proﬁlesand background personal facts.
in persona-baseddialogues, the generated responses are conditionednot only on the dialogue context but also on somepredeﬁned personas, so the presenting personalitycould be more consistent..existing persona-based dialogue models heavilyutilize a set of persona-related dialogue data (wolfet al., 2019; golovanov et al., 2019), such as thepersonachat (zhang et al., 2018).
this kind ofcrowd-sourced dataset covers rich persona features,.
∗wei-nan zhang is the corresponding author..figure 1: a 12-layer gpt2 ﬁnetuned on personachatdataset still generates an inconsistent response..namely “persona-dense”.
nevertheless, the scaleof such crowd-sourced datasets is limited by theexpensive costs: two annotators are asked to actthe part of a given provided persona and chat natu-rally to get to know each other during the conversa-tion.
on the other hand, conversations in dailylife are not always persona-related.
accordingto twitter content analysis, less than 10% mes-sages on twitter reveal personal anecdote or ac-tivities at home or work and even less for person-ally identiﬁable information (naaman et al., 2010;humphreys et al., 2014).
as a result, the large-scaledata collected from social media would only con-tain a limited amount of persona-related dialogues,which is “persona-sparse”.
the limited-scale ofcrowd-sourced data and the persona-sparsity inlarge-scale data present one common challenge:a model trained on limited personalized data can-not sufﬁciently understand persona consistency.
asshown in figure 1, a 12-layer gpt2 (radford et al.,2019) ﬁnetuned on the personachat dataset stillshows a lack of consistency..after rethinking the essence of persona-baseddialogue generation, we can ﬁnd that it requiresthe dialogue agent to own the capabilities to 1) un-derstand the persona-response consistency and 2)generate a persona-related response given the dia-logue context.
obviously, an ideal dataset that sat-isﬁes both features are difﬁcult to annotate.
how-ever, once we disentangle persona-based dialoguegeneration into two sub-tasks: consistency under-standing and dialogue generation, it is easy to ﬁnd.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages167–177august1–6,2021.©2021associationforcomputationallinguistics167persona:i've a son who is in junior high schoolquery:you have any children?gpt-2:no kids.
i work at home depot so i’m busy.
abundant data resources for them.
for consistencyunderstanding, we may leverage large-scale non-dialogue inference data, such as snli (bowmanet al., 2015) and mnli (williams et al., 2018)as the training data.
as for dialogue generation,we already have various large-scale persona-sparsedatasets..inspired by the aforementioned motivation, inthis work, we explore to learn a consistent persona-based dialogue model from limited personalizeddialogues, with the assistance of large-scale non-dialogue inference data.
speciﬁcally, the proposedmodel consists of an encoder e, an auto-regressivedecoder d1 for response generation, and a bidirec-tional decoder d2 for consistency understanding.
given personas p and dialogue query q, the eand d1 jointly work in an encoder-decoder man-ner to capture a typical query to response mappingfg(s|q, p ), and generate a coarse response rep-resentation r1.
then r1 and personas p are fedinto the bidirectional decoder d2 to map r1 to ﬁnalresponse representations r2: fu (r2|s, p ).
sincethe consistency understanding part fu (r|s, p ) isindependent of the dialogue query q, it can belearned on non-dialogue inference datasets.
herean unlikelihood training objective (welleck et al.,2019a) is applied to make contradicted cases in theinference data less likely so that d2 could acquirethe ability of consistency understanding..we initialize all modules from bert (devlinet al., 2019) and name the proposed model bert-over-bert (bob).
to verify the effectiveness ofour model, we experiment on two limited datascenarios: 1) a persona-dense scenario (zhanget al., 2018) with low-resource settings (zhao et al.,2019), and 2) a persona-sparse scenario (zhenget al., 2019).
both automatic and human evalua-tions indicate that our model generalizes well underdifferent settings and outperforms strong baselineson most metrics, especially on persona consistency..contributions in this work are three-fold:.
• we disentangled the task of persona-based di-alogue generation into two sub-tasks: consis-tency understanding and dialogue generation..• a bert-based generative framework, bob,was proposed for training persona-based dia-logue models from limited data..• an unlikelihood training method with non-dialogue inference data was introduced to en-hance persona consistency understanding..2 related work.
persona-based dialogues recent studies onpersona-based dialogue generation focus on a data-driven manner.
they learn persona-related featuresdirectly from personalized dialogue datasets, eitherwith implicit persona embeddings (li et al., 2016b)or with explicit proﬁles (qian et al., 2018) and per-sonal facts (mazar´e et al., 2018).
following thisresearch line, more sophisticated neural models areemerging, such as modeling mutual-persona (liuet al., 2020) and multi-stage persona-based dia-logue generation (song et al., 2020a)..meanwhile, various pre-training methods havealso been applied in this ﬁeld.
wolf et al.
(2019)and golovanov et al.
(2019) show that ﬁne-tuningpre-trained gpt on the persona-dense dataset canimprove the quality of generated responses.
zhenget al.
(2020) propose an attention-routing mecha-nism in a gpt-based model to control the ﬂow ofpersona information.
lin et al.
(2020) explore howto leverage bert model for dialogue generation.
different large-scale pretrained chatbots (rolleret al., 2020; madotto et al., 2020) also show theireffectiveness on persona-based dialogues..disentangled representation the concept of“disentangling” can be deﬁned as transformationsthat only change some properties of the underly-ing model while leaving all other properties in-variant (higgins et al., 2018).
the variational au-toencoder (kingma and welling, 2013) could beregarded as a disentangled representation learningframework, and various methods are built withinit (kim and mnih, 2018; locatello et al., 2019)..unlikelihood training likelihood tries to max-imize the probability of target sequence, whileunlikelihood corrects known biases by minimiz-ing the probability of negative candidates (wellecket al., 2019a).
closely related to our work, li et al.
(2020) ﬁrst explored unlikelihood training in ad-dressing dialogue logical contradictions.
they getcontradicted dialogues from personachat accord-ing to dnli (welleck et al., 2019b), a personachat-oriented dialogue inference dataset.
then unlike-lihood training is applied to reduce the probabil-ity of contradicted responses.
different from liet al.
(2020), with carefully designed decoders, ourmodel could learn from large-scale non-dialogueinference datasets, making it generalizable to differ-ent scenarios, such as persona-dense and persona-sparse datasets, as will be seen in our experiments..168figure 2: (1) the framework of the proposed bob model, including an encoder (bert e), a response generationdecoder (bert d1), and a consistency understanding decoder (bert d2).
the italics denote the inputs andoutputs of each submodule.
(2) transformer attention masks for generation (d1) and understanding (d2), and darksquare means no attention.
(3) training objectives and the utilized data.
nll denotes negative log-likelihood..3 model.
3.1 overview.
in this work, our goal is to learn a persona-baseddialogue model from limited personalized data.
toaddress the challenges of consistency understand-ing brought by limited data, we leverage large-scalenon-dialogue inference data in our model..formally, let q = q1, q2, ..., qn denote the dia-logue query, r = r1, r2, ..., rm denote the target re-sponse, and p denote the personas.
in addition, letn denote the non-dialogue inference data, whichconsists of premise, hypothesis, and their label.
the premise and hypothesis are both natural sen-tences.
note that in the following sections, we usefonts to distinguish between sentences (p, q, r)and their vector representations (p , q, r1, r2)..the task of the proposed model m is to generatea persona consistent response ˆr = ˆr1, ˆr2, ..., ˆrm,based on both persona p and query q, i.e., ˆr =m(q, p).
as shown in figure 2, the proposedmodel m consists of three bert-based submod-ules: an encoder e, a response decoder d1, anda consistency understanding decoder d2.
moreconcretely, e encodes the embeddings of personaand query, i.e., p and q, into hidden states h. d1performs cross-attention on h in a typical encoder-decoder manner, and generate a coarse representa-tion r1.
d2 learns consistency understanding fromnon-dialogue inference data n and further convertsp and r1 into ﬁnal representations r2.
at last, aconsistent response ˆr could be generated from r2..3.2 disentangling.
for response generation, a typical persona-based di-alogue model needs persona p and dialogue queryq to generate a response.
for consistency under-standing, a model needs persona p, response r,and the consistency labels between p and r. how-ever, if we entangle generation and understanding,it is not easy to obtain sufﬁcient annotated data thatsatisfy the format of {p, q, r, label}..instead, in our model, we design the decoderd2 to disentangle generation and understanding,where d2 maps r1, rather than q, to r2.
the keyto “disentangling” is we can get r1 without theparticipation of q, as r1 is the representation ofr. as a result, the mapping from r1 to r2 couldbe independent of q. in this way, it becomes possi-ble to 1) learn persona-based dialogue generationfrom {p, q, r}, i.e., the personalized data, and2) learn consistency understanding from {p, r,label}.
moreover, considering the limited amountof such annotated data, we could approximate {p,r, label} by the abundant non-dialogue inferencedata n ={premise, hypothesis, label}, where pand r corresponds to the premise and hypothesis.
given data p and r, suppose d2 understandspersona consistency, it should maximize the like-lihood of generating r if r is not contradicted top. otherwise, it should minimize the likelihoodof generating r. motivated by this observation,we choose to apply unlikelihood training on d2to make it understand consistency.
the detailedtraining objectives will be provided in sec 3.4..169pr1bert d1bert ebert d2embedding layerpqhr1personaqueryr2(1) the framework of bobr1hquerykey, value(2) attention masks d1d2(3) training objectivesbert d1hs1sn…bert d2r1pr1rn…nll nll bert d2hypothesispremisehyp1hypn…unlikelihood contradictedquerykey, valuenon-contradicted non-dialogueinferencedatapersonalizeddialoguedatapersonalizeddialoguedatawordvector…3.3 bert-over-bert.
3.3.1 encoderthe encoder e works like a standard bert model,which bidirectionally encodes the input embed-dings to a sequence of hidden vectors, from whichthe downstream tasks will be performed on..in our model, the input consists of persona pand dialogue query q. for persona, whether p ispersonal facts (e.g., “i have two dogs”) or proﬁles(e.g., “location: seattle”), we could always con-vert it into a sequence of words.
a special tokenis placed between persona sequence and dialoguequery, and the input is formated as:.
input = p(0).
1 , p(0).
2 , ..., p(t).
ut , [s], q1, q2, ..., qn (1).
then the embedding layer will convert input intorepresentations.
following usual practice, the inputrepresentations are the sum of the corresponding to-ken, type, and position embeddings, where the typeembedding is 0 and 1 for persona and query, re-spectively.
p and q can also get their independentrepresentations.
the resulted representations arep and q, which could be jointly denoted as emb1, ep= epl , where l is the maximum length ofthe input..2, ..., eq.
once we get the input representations, encodere will perform multi-head attetnion (vaswani et al.,2017) on the emb to transform the embeddings intoa sequence of hidden vectors h. the multi-headattetnion could be denoted as multihead(query,key, value), where scaled dot-product attention isperformed on query, key, and value.
there are nidentical layers in e, for each layer:.
training.
in the cross-attention, the query comesfrom the previous layer of d1, and the key andvalue come from h:.
ri+11 = fnn(multihead(ri.
1, h, h))..(3).
this attention is similar to the typical encoder-decoder attention mechanism in sequence to se-quence models (bahdanau et al., 2015), which at-tends to all positions in the context representationsh according to the variations of r1.
in training,r01 is initialized from the embeddings of the targetresponse.
at each generation step, future tokensin the target response should not be considered.
therefore, as shown in figure 2, a left-to-rightmask is applied to d1 to ensure that the predictionscan only depend on the known outputs..d1 also has n identical layers.
and the output1 , i.e., r1, is further fed to d2..of the last layer rn.
3.3.3 consistency understanding decoderlike e and d1, the consistency understanding de-coder d2 is also initialized from bert, from whered2 initializes a good semantic representation forunderstanding tasks..in each layer of d2, the multi-head attention is.
performed twice:.
pi+1 = fnn(multihead(ri.
2, p, p )),ri+12 = fnn(multihead(pi+1, r1, r1))..(4).
(5).
2.the resulted ri+1in each layer thus fuses informa-tion from both p and r1.
the output of the lastlayer of d2 is the ﬁnal representations r2.
withan output layer, e.g.
linear layers, upon the r2, wecan get the generated response ˆr..hi+1 = fnn(multihead(hi, hi, hi)),.
(2).
3.4 training objectives.
where h0 = emb, and fnn is a fully connectedfeed-forward network containing two linear trans-formations with a relu activation in between.
hnis the ﬁnal output of encoder e, i.e., h..3.3.2 response generation decoderthe response generation decoder d1 is initializedfrom bert to inherit its robust language modelbut works in an auto-regressive decoder manner.
first, a cross-attention is inserted between e andd1 to pass the context information.
second, a left-to-right mask is applied to d1 to preserve the auto-regressive generation property..as the cross-attention does not exist in the bertmodel, it is randomly initialized and updated during.
we employ negative log-likelihood (nll) lossand unlikelihood loss for dialogue generation andconsistency understanding.
a brief illustration isshown in the last column of figure 2 and detaileddescriptions will be provided in this section..response generation in our model, the widelyadopted negative log-likelihood loss is applied inthe training.
for e and d1, they read the persona pand dialogue query q to predict the target responser, which yields the raw representations r1:.
l.d1n ll = −log(pθ(r|p, q)).
= −.
log(pθ(ri|p, q, r<i))..(6).
|r|(cid:88).
i=1.
170the generation part in d2 is also trained by nll.
d2 reads persona embeddings p and raw represen-tations r1 to predict the target response r:.
4 experiments.
4.1 datasets.
l.d2n ll = −log(pγ(r|p, r1)).
= −.
log(pγ(ri|p, r1, r<i))..|r|(cid:88).
i=1.
(7).
to evaluate the performance of the proposed model,we carried out persona-based dialogue generationexperiments in a persona-dense scenario and apersona-sparse scenario with two publicly avail-able datasets:.
unlikelihood training given large-scale non-dialogue inference dataset, we collect positive datad+ from the entailed category and collect negativedata d− from the contradicted category:.
d+ = {( ¯p (i), ¯r(i)+)}, d− = {( ¯p (j), ¯r(j)−)},(8).
where ¯p and ¯r are premise and hypothesis fromthe non-dialogue inference data, and their represen-tations in our model are denoted as ¯p and ¯r.
fordata from d+, we still apply the nll loss:.
d+u l = −2.l.| ¯r|(cid:88).
i=1.
log(pγ(¯ri| ¯p , ¯r, ¯r<i)),.
(9).
for data from d−, we apply the unlikelihood ob-jective to minimize the likelihood of contradictions:.
d−u l = −2.l.| ¯r|(cid:88).
i=1.
log(1 − pγ(¯ri| ¯p , ¯r, ¯r<i)),.
(10).
which penalizes every token in the contradictedd−2u l makes generating.
target.
therefore, the loss lcontradicted responses less likely..training procedure the training steps can besummarized as follows:.
1) response generation.
given p, q, and rfrom personalized dialogue data, we calculate thed2response generation loss l1 = ln ll;2) consistency understanding.
given d+ andd− from non-dialogue inference data, we calculated−the unlikelihood loss l2 = βl2u l;3) optimization.
sum up l1 and l2.
update.
d+u l + (1 − β)l2.d1n ll + αl.
parameters with back-propagation..we initialize our model from the publicly avail-able bert base model, with 12 layers and hiddensize 768. we employ an adam optimizer with alearning rate of varying from 5e-6 to 5e-5.
empiri-cally, we set α to 5e-3 and β to 0.1. the training ofthe proposed model was done on an nvidia telsav100 32g gpu.
other details please refer to thereleased projects..• personachat (zhang et al., 2018) is a crowd-sourced dataset covering rich persona features.
the dialogues in this dataset are grounded onspeciﬁc personal facts.
here we use the con-vai2 personachat (dinan et al., 2019), so theresults are comparable to existing methods..• personaldialog (zheng et al., 2019) is alarge-scale persona-sparse dataset, which iscollected from chinese social media weibo.
this dataset provides persona proﬁles and di-alogues, but the majority of the dialoguesare not persona-related.
two testsets are pro-vided: a random testset, which is identicallydistributed as the training data, and a biasedtestset, which is manually selected to coverpersona-related features..we summarize the key statistics of two personal-ized dialogue datasets in tabel 1..as aforementioned, we leverage non-dialogueinference data to address the consistency under-standing issue brought by limited personalized data.
here we use the non-dialogue inference datasetmnli (williams et al., 2018) and its chinese ver-sion cmnli (xu et al., 2020) as our auxiliary data.
moreover, to better compare models’ performanceon persona consistency, we leverage two dialogueinference datasets, dnli (welleck et al., 2019b)and kvpi (song et al., 2020b), for evaluations.
thestatistics1 of these inference datasets are summa-rized in table2..4.2 compared methods.
the following models,including both non-pretrained and pretrained ones, have been com-pared in the experiments..baselines.
vanilla transformer (vaswani et al.,2017) is employed as baselines for the experimentson both personachat and personaldialog.
personasare concatenated to the dialogue queries..1note that for the dnli, we only count the tuples that canbe restored as {persona, query, response} in our experiments..171dataset.
# train.
# valid.
# test.
personachatperonaldialog.
121,8805,014,349.
9,558423,817.
7,80110,000 / 521.table 1: statistics of persona-based dialogue datasets..dataset.
# entailed # neutral.
# contra..mnlicmnlidnlikvpi.
130,615130,61215,49533,114.
130,590130,55520,92754,426.
130,590130,61616,48831,000.table 2: statistics of different inference datasets..non-pretrained models.
meta-learning has re-cently been explored in addressing the limitedpersonalized data issue.
cmaml (song et al.,2020c) is a meta-learning based method that learnsfrom few shot personas by customizing the modelstructures.
besides the meta-learning methods,gdr (song et al., 2020a) introduces inference abil-ity on the personachat with a generate-reﬁne frame-work.
however, the two models are elaboratelydesigned for the persona-dense dataset and not ap-pliable for the persona-sparse scenario.
thus weonly employ them for experiments on personachat..pre-training models.
in the convai2 chal-lenge (dinan et al., 2019), which utilizes per-sonachat as the competition dataset, lic (golo-vanov et al., 2019) is the best performing model.
thus we compare this model in the experimentson both personachat and personaldialog.
atten-tionrouting (zheng et al., 2020) is a pre-trainingmethod specially designed for the persona-sparsedataset, and it is also the latest model on personal-dialog.
we also ﬁnetune a gpt2 (radford et al.,2019) for a thorough comparison on personachat..4.3 evaluation metrics.
we focus on two main aspects of the persona-baseddialogues: response quality and persona consis-tency.
to compare different models, we employboth automatic metrics and human evaluations..automatic metrics for dialogue quality, we em-ploy perplexity (ppl.)
and distinct 1/2 (dist.1/2)following common practice (zhang et al., 2018;zheng et al., 2020).
lower perplexity means betterlanguage modeling.
distinct 1/2 (li et al., 2016a)are the ratio of distinct uni-grams / bi-grams, andhigher distinct means better reponse diversity..for persona consistency, we employ two metrics.
the ﬁrst is consistency score (c.score) (madottoet al., 2019), which leverages a referee model topredict consistency and can be deﬁned as:.
nli(r, pi) =.
−1,.
.
0,.
1,.
(cid:88)t.if r contradicts pi,if r is irrelevant to pi,if r entails pi..c.score(r) =.
nli(r, pi)..i=1.
(11)here the nli is a pre-trained roberta model (liuet al., 2019) ﬁnetuned with the dialogue inferencedatasets, i.e., dnli and kvpi, as descriped in ta-ble 2. the robert model achieves testset ac-curacy of 89.3% and 88.9% on dnli and kvpi,which is aligned to the reported 88.20% (wellecket al., 2019b) and 88.0% (song et al., 2020b)..the second metric is delta perplexity (∆p),which evaluates consistency from model’s inter-nal distributions.
li et al.
(2020) ﬁrst calculatesthe perplexity of entailed (p.ent) and contradicted(p.ctd) dialogues in the inference dataset.
adialogue model with good understanding abilityshould assign lower perplexity to the entailed dia-logues while higher perplexity to the contradictions.
from this intuition, the ∆p can be deﬁned as:.
∆p = ppl(contradicted) − ppl(entailed),.
(12)where a larger ∆p means the model has a betterability to distinguish entailment from contradiction.
in our experiments, we get entailed and contra-dicted {persona, query, response} tuples from thedialogue inference datasets dnli and kvpi..human evaluations we recruit two teams (onefor english and another for chinese), each consistsof ﬁve professional annotators, from a third-partycompany.
these annotators are proﬁcient in lan-guage tasks but know nothing about the models.
we sample 100 {persona, query, response} tuplesfor each model’s evaluation under every setting..human annotators are asked to evaluate dia-logue quality from three conventional criteria: ﬂu-ency (flue.
), informativeness (info.
), and rele-vance (relv.).
each criterion is rated on a ﬁve-scale, where 1, 3, and 5 indicate unacceptable,moderate, and perfect performance, respectively.
the annotators are also instructed to label the con-sistency (per.c.)
between persona and response,where 1 means persona-related and consistent, 0means irrelevant, and -1 means contradicted..172ppl dist.1 dist.2 d.avg p.ent p.ctd ∆p c.score flue..info.
relv.
per.c..transformer.
28.8cmaml 36.7gdr 16.7lic 17.314.4.gpt2.
3.141.003.766.297.29.
8.40.
17.802.1023.1028.9928.12.
10.471.5513.4317.6417.71.bob (ours).
7.8.
36.08.
22.24.
31.532.319.713.712.0.
7.3.
35.537.532.320.420.2.
83.4.
4.05.212.66.78.2.
1.206.967.8914.1215.88.
76.1.
17.18.
3.053.363.383.703.79.
4.12.
2.572.402.743.533.22.
4.03.
2.723.093.133.473.79.
4.09.
0.050.240.210.390.47.
0.60.table 3: automatic and human evaluation results on the full personachat dataset.
the best results are in bold..ppl dist.1 dist.2 d.avg p.ent p.ctd ∆p.
c.score flue..info.
relv.
per.c..baselines’ best.
ours 1/8 dataours 1/4 dataours 1/2 data.
14.411.6†9.78.9.
7.297.49†7.978.13.
28.99.
17.71.
27.1030.20†33.08.
17.3019.09†20.61.
12.011.3†11.88.1.
37.583.6†85.881.9.
12.672.3†74.073.8.
15.88.
15.8716.04†16.36.
3.794.17†4.194.03.
3.53.
3.483.473.70†.
3.794.12†4.173.94.
0.470.62†0.600.61.table 4: automatic and human evaluation results of the low resource settings on the personachat dataset.
the †means the minimum amount of data our model needed to outperform baselines’ best results..4.4 persona-dense results.
full personachat we ﬁrst report the full per-sonachat experimental results in table 3. ourmethod achieves better performance consistentlyacross all automatic and human evaluation metrics,which shows the effectiveness of our model..among all the metrics, our model obtains sig-niﬁcant improvements on ppl and ∆p.
the lowesttestset ppl means our model has learned a goodlanguage model ﬁtting this dataset.
moreover, thehighest ∆p shows that our model could more ef-fectively distinguish entailment from contradictionthan other baselines, which indicates our model hasa better understanding of persona consistency..less personalized data now that our modelachieves better performance with a large margin onthe full personachat dataset, we want to test ourmodel by simulating a low-resource scenario (zhaoet al., 2019), where we gradually reduce the num-ber of examples by halving the training set.
wereport the low-resource settings’ results in table 4.as we can see, our model can outperform mostof the baselines’ best results even by using only1/8 of the training data.
the performance gainslargely beneﬁt from the powerful language modelof the backbone bert model.
furthermore, due tothe disentangling of generation and understanding,our model presents a stable performance on ∆pregardless of the size of the training set.
this isin line with our expectations because the proposedmodel learns consistency understanding from the.
non-dialogue inference data rather than the persona-dense dialogue data.
we observe that the methodalso improves ﬂuency and informativeness.
it ismainly due to the introduction of the non-dialogueinference data in the training procedure, which po-tentially enriches the dialogue language model..4.5 validations on persona-sparse.
we further validate our model on a persona-sparsescenario.
to have a more intuitive understandingof “sparsity”, we recruit the same annotation teamto annotate whether the dataset response is persona-related in the sampled random and biased test data.
results show that only 1% responses are persona-related in the random test data and 28% in thebiased test data.
we calculate the fleiss’ kappaamong the ﬁve annotators and obtain a kappa of0.774, which means substantial agreement (landisand koch, 1977).
we report the evaluation resultson both random and biased testsets in table 5..on the random test set, experimental resultsdemonstrate that our model has some advantagesover other methods, but no method can consistentlyoutperform the others.
one possible reason is thatthe task has degenerated into the ordinary dialoguegeneration in the random test set, so our model’sadvantages can not be effectively leveraged.
incontrast, on the biased test set, our model achievesthe best performance on most metrics.
the goodperformance on the metrics c.score and per.c.
in-dicates that our model can be effectively trainedfrom a dataset with limited personalized dialogues..173random testset.
biased testset.
ppl c.score flue..info.
relv.
per.c.
ppl c.score flue..info.
relv.
per.c.
∆p.
trans.
43.7lic 47.8ar 34.2.
0.954.08-2.14.ours.
18.5.
2.10.w/o ul 19.331.7e 35.5.e+d1.
-3.130.151.64.
3.263.683.71.
3.75.
3.733.743.67.
2.382.662.58.
2.69.
2.572.682.57.
2.722.923.02.
2.98.
2.932.962.96.
0.000.02-0.03.
0.01.
-0.06-0.010.01.
83.243.338.7.
1.048.2511.72.
19.5.
12.76.
20.138.041.1.
10.539.757.41.
3.543.723.78.
3.84.
3.793.743.72.
2.583.013.11.
3.13.
2.923.153.05.
2.843.043.10.
3.17.
3.103.063.04.
0.030.080.13.
0.15.
0.090.080.04.kvpi.
3.282.863.08.
85.40.
4.102.804.60.table 5: automatic and human evaluation results on the random testset and biased testset of personaldialog, alongwith the ablation results.
trans denotes transformer, and ar denotes attentionrouting.
best results in bold..ppl ∆p.
flue..info.
relv.
per.c..persona.
i’ve a son who is in junior high school.
ours.
7.8.
76.1.
4.12.w/o ul 8.1.e+d1.
23.6e 25.7.
7.84.97.1.
3.813.653.69.
4.03.
3.503.183.28.
4.09.
3.803.603.60.
0.60.
0.480.450.42.table 6: ablation results of automatic metrics and hu-man evaluations with full personachat dataset..4.6 analysis and ablation study.
in addition to the good performance of the bobmodel, we are also curious about q1: what is thekey to the bob model’s understanding ability?
q2:can the pre-trained models understand persona con-sistency just through ﬁnetuning on the personalizeddialogues?
and q3: does the extremely low pplcome from the initialization of the bert model orthe architecture of the proposed bob model?.
to better answer the above questions, we ab-late the bob model in the following three ways:1) w/o ul.
it removes the unlikelihood objective.
2) e+d1.
it removes the unlikelihood objectiveand the second decoder d2.
3) e. it removes theunlikelihood objective and both decoders and thusdegenerates into a vanilla bert model.
we reportthe ablation results on personaldialog in table 5and full personachat in table 6. from these results:answer to q1: the key to our model’s under-standing is the unlikelihood training.
in training,our model assigns large perplexity to the contra-dictions.
in generating, the non-contradicted re-sponses are more likely to be generated as they arewith much smaller losses.
table 7 shows an exam-ple.
and as presented in the results, after removingthe unlikelihood objective, all ablated models suf-fer from signiﬁcant performance degradations inconsistency-related metrics, such as per.c.
and ∆p..query you have any children?.
gpt2 no kids.
i work at home depot so i’m busy.
ours yes, i have a son in the 8th grade..table 7: a generated example from our model..answer to q2: pretrained models barely un-derstand consistency from personalized dialogues.
according to the poor performances on ∆p, thethree bert-based ablated models can hardly dis-tinguish contradiction from entailment.
althoughtheir per.c.
metric still looks good, it may comefrom just mimicking and copying words rather thanunderstanding.
a similar phenomenon also occursto the pre-trained gpt2, as shown in table 3. it isalso this phenomenon that motivates us to introducethe unlikelihood training into the bob model..answer to q3: d2 in the bob architecture con-tributes most to the ppl.
as shown in both datasets’ablation results, the ppl decreases the most afterremoving d2.
we can also see an apparent gapbetween the models with d2 and the vanilla berton ppl.
nevertheless, the bert model still offersa good initialization for the bob model to achievethe best performance on different metrics..4.7 reproducibility.
the implementation for the bob model is releasedat https://github.com/songhaoyu/bob..5 conclusions.
in this work, we propose a novel bert-based di-alogue model to learn from limited personalizeddata by disentangling response generation and con-sistency understanding.
unlikelihood training withnon-dialogue inference data is introduced to en-.
174hance the model’s understanding ability.
experi-ments on two publicly available datasets demon-strate that our model can be trained with limitedpersonalized dialogue data while still obtain signif-icant improvements over strong methods..acknowledgments.
this paper is supported by the national natu-ral science foundation of china under grantno.62076081, no.61772153, and no.61936010,and supported by the science and technology in-novation 2030 major project of china under grantno.2020aaa0108605.
we thank all the anony-mous reviewers for their helpful comments andsuggestions..ethical statement.
persona-based dialogue research intends to addressthe persona inconsistency issue in open-domain di-alogue to facilitate human-computer interactions.
giving dialogue system a speciﬁc persona is a main-stream to alleviate the inconsistency issue of dia-logues under the current stage.
the purpose is toendow the dialogue system with self logical con-sistency rather than imitate speciﬁc human beings.
simultaneously, in this work, the data resourceswe use are all from published works and do not in-volve privacy issues related to data collection.
wealso conﬁrm that this work neither automaticallyinfers or attributes identity characteristics to theparticipants nor categorizes them in the trainingdatasets..references.
dzmitry bahdanau, kyunghyun cho, and yoshua ben-gio.
2015. neural machine translation by jointlyin 3rd inter-learning to align and translate.
national conference on learning representations,iclr 2015, san diego, ca, usa, may 7-9, 2015,conference track proceedings..samuel r. bowman, gabor angeli, christopher potts,and christopher d. manning.
2015. a large anno-tated corpus for learning natural language inference.
in proceedings of the 2015 conference on empiri-cal methods in natural language processing, pages632–642, lisbon, portugal.
association for compu-tational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the association.
for computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..emily dinan, varvara logacheva, valentin malykh,jack urbanek,alexander miller, kurt shuster,douwe kiela, arthur szlam, iulian serban, ryanthe second conversationallowe, et al.
2019.arxiv preprintintelligence challenge (convai2).
arxiv:1902.00098..sergey golovanov, rauf kurbanov, sergey nikolenko,kyryl truskovskyi, alexander tselousov,andthomas wolf.
2019. large-scale transfer learningfor natural language generation.
in proceedings ofthe 57th annual meeting of the association for com-putational linguistics, pages 6053–6058, florence,italy.
association for computational linguistics..irina higgins, david amos, david pfau, s´ebastienracani`ere, lo¨ıc matthey, danilo j. rezende, andtowards a deﬁ-alexander lerchner.
2018.corr,nition of disentangled representations.
abs/1812.02230..lee humphreys, phillipa gill, and balachander krish-namurthy.
2014. twitter: a content analysis of per-sonal information.
information, communication &society, 17(7):843–857..hyunjik kim and andriy mnih.
2018. disentanglingby factorising.
in international conference on ma-chine learning, pages 2649–2658.
pmlr..diederik p kingma and max welling.
2013. auto-arxiv preprint.
encoding variational bayes.
arxiv:1312.6114..j richard landis and gary g koch.
1977. the mea-surement of observer agreement for categorical data.
biometrics, pages 159–174..jiwei li, michel galley, chris brockett, jianfeng gao,and bill dolan.
2016a.
a diversity-promoting ob-jective function for neural conversation models.
inproceedings of the 2016 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,pages 110–119, san diego, california.
associationfor computational linguistics..jiwei li, michel galley, chris brockett, georgios sp-ithourakis, jianfeng gao, and bill dolan.
2016b.
ain pro-persona-based neural conversation model.
ceedings of the 54th annual meeting of the associa-tion for computational linguistics (volume 1: longpapers), pages 994–1003, berlin, germany.
associ-ation for computational linguistics..margaret li, stephen roller,.
ilia kulikov, seanwelleck, y-lan boureau, kyunghyun cho, and ja-son weston.
2020. don’t say that!
making inconsis-tent dialogue unlikely with unlikelihood training.
in.
175proceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 4715–4728, online.
association for computational lin-guistics..alec radford, jeffrey wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners.
openaiblog, 1(8):9..zhaojiang lin, zihan liu, genta indra winata, samuelcahyawijaya, andrea madotto, yejin bang, etsukoishii, and pascale fung.
2020. xpersona: eval-arxivuating multilingual personalized chatbot.
preprint arxiv:2003.07568..qian liu, yihong chen, bei chen, jian-guang lou,zixuan chen, bin zhou, and dongmei zhang.
2020.you impress me: dialogue generation via mutualpersona perception.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 1417–1427, online.
associationfor computational linguistics..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach..francesco locatello, michael tschannen, stefanbauer, gunnar r¨atsch, bernhard sch¨olkopf, andolivier bachem.
2019. disentangling factors of vari-ations using few labels.
in international conferenceon learning representations..andrea madotto, zhaojiang lin, yejin bang, andpascale fung.
2020. the adapter-bot: all-in-onecontrollable conversational model.
arxiv preprintarxiv:2008.12579..andrea madotto, zhaojiang lin, chien-sheng wu, andpascale fung.
2019. personalizing dialogue agentsin proceedings of the 57th an-via meta-learning.
nual meeting of the association for computationallinguistics, pages 5454–5459, florence, italy.
asso-ciation for computational linguistics..pierre-emmanuel mazar´e, samuel humeau, martinraison, and antoine bordes.
2018. training mil-in proceed-lions of personalized dialogue agents.
ings of the 2018 conference on empirical methodsin natural language processing, pages 2775–2779,brussels, belgium.
association for computationallinguistics..mor naaman, jeffrey boase, and chih-hui lai.
2010.is it really about me?
message content in socialin proceedings of the 2010awareness streams.
acm conference on computer supported coopera-tive work, pages 189–192..qiao qian, minlie huang, haizhou zhao, jingfangxu, and xiaoyan zhu.
2018. assigning personal-ity/proﬁle to a chatting machine for coherent con-versation generation.
in proceedings of the twenty-seventh international joint conference on artiﬁcialintelligence, ijcai-18, pages 4279–4285.
interna-tional joint conferences on artiﬁcial intelligenceorganization..stephen roller, emily dinan, naman goyal, da ju,mary williamson, yinhan liu, jing xu, myle ott,kurt shuster, eric m smith, et al.
2020. recipesfor building an open-domain chatbot.
arxiv preprintarxiv:2004.13637..haoyu song, yan wang, wei-nan zhang, xiaojiangliu, and ting liu.
2020a.
generate, delete andrewrite: a three-stage framework for improving per-in pro-sona consistency of dialogue generation.
ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5821–5831, online.
association for computational lin-guistics..haoyu song, yan wang, wei-nan zhang, zhengyuzhao, ting liu, and xiaojiang liu.
2020b.
proﬁleconsistency identiﬁcation for open-domain dialogueagents.
in proceedings of the 2020 conference onempirical methods in natural language process-ing (emnlp), pages 6651–6662, online.
associa-tion for computational linguistics..haoyu song, wei-nan zhang, yiming cui, dongwang, and ting liu.
2019. exploiting persona in-formation for diverse generation of conversationalin proceedings of the twenty-eighthresponses.
international joint conference on artiﬁcial intel-ligence, ijcai-19, pages 5190–5196.
internationaljoint conferences on artiﬁcial intelligence organi-zation..yiping song, zequn liu, wei bi, rui yan, and mingzhang.
2020c.
learning to customize model struc-tures for few-shot dialogue generation tasks.
in pro-ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5832–5841, online.
association for computational lin-guistics..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in nips..sean welleck, ilia kulikov, stephen roller, emily di-nan, kyunghyun cho, and jason weston.
2019a.
neural text generation with unlikelihood training.
ininternational conference on learning representa-tions..sean welleck, jason weston, arthur szlam, andkyunghyun cho.
2019b.
dialogue natural languageinference.
in proceedings of the 57th annual meet-ing of the association for computational linguistics,pages 3731–3741, florence, italy.
association forcomputational linguistics..adina williams, nikita nangia, and samuel bowman.
2018. a broad-coverage challenge corpus for sen-tence understanding through inference.
in proceed-ings of the 2018 conference of the north american.
176chapter of the association for computational lin-guistics: human language technologies, volume1 (long papers), pages 1112–1122, new orleans,louisiana.
association for computational linguis-tics..thomas wolf, victor sanh, julien chaumond, andtransfertransfo: alearning approach for neural networkarxiv preprint.
clement delangue.
2019.transferbased conversational agents.
arxiv:1901.08149..liang xu, hai hu, xuanwei zhang, lu li, chenjiecao, yudong li, yechen xu, kai sun, dian yu,cong yu, yin tian, qianqian dong, weitang liu,bo shi, yiming cui, junyi li, jun zeng, rongzhaowang, weijian xie, yanting li, yina patterson,zuoyu tian, yiwen zhang, he zhou, shaoweihualiu, zhe zhao, qipeng zhao, cong yue, xinruizhang, zhengliang yang, kyle richardson, andzhenzhong lan.
2020. clue: a chinese languagein proceed-understanding evaluation benchmark.
ings of the 28th international conference on com-putational linguistics, pages 4762–4772, barcelona,spain (online).
international committee on compu-tational linguistics..saizheng zhang, emily dinan, jack urbanek, arthurszlam, douwe kiela, and jason weston.
2018. per-sonalizing dialogue agents: i have a dog, do youin proceedings of the 56th an-have pets too?
nual meeting of the association for computationallinguistics (volume 1: long papers), pages 2204–2213, melbourne, australia.
association for com-putational linguistics..xueliang zhao, wei wu, chongyang tao, can xu,dongyan zhao, and rui yan.
2019. low-resourceknowledge-grounded dialogue generation.
in inter-national conference on learning representations..yinhe zheng, guanyi chen, minlie huang, song liu,and xuan zhu.
2019. personalized dialogue genera-tion with diversiﬁed traits.
arxiv, abs/1901.09672..yinhe zheng, rongsheng zhang, minlie huang, andxiaoxi mao.
2020. a pre-training based personal-ized dialogue generation model with persona-sparsedata.
proceedings of the aaai conference on artiﬁ-cial intelligence, 34(05):9693–9700..177