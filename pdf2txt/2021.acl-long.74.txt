span-based semantic parsing for compositional generalization.
jonathan herzig1.
jonathan berant1,2.
1blavatnik school of computer science, tel-aviv university2allen institute for artiﬁcial intelligence{jonathan.herzig,joberant}@cs.tau.ac.il.
abstract.
despite the success of sequence-to-sequence(seq2seq) models in semantic parsing, recentwork has shown that they fail in composi-tional generalization, i.e., the ability to gen-eralize to new structures built of componentsobserved during training.
in this work, weposit that a span-based parser should lead tobetter compositional generalization.
we pro-pose spanbasedsp, a parser that predictsa span tree over an input utterance, explic-itly encoding how partial programs composeover spans in the input.
spanbasedsp ex-tends pasupat et al.
(2019) to be comparableto seq2seq models by (i) training from pro-grams, without access to gold trees, treatingtrees as latent variables, (ii) parsing a classof non-projective trees through an extensionto standard cky.
on geoquery, scanand closure datasets, spanbasedsp per-forms similarly to strong seq2seq baselines onrandom splits, but dramatically improves per-formance compared to baselines on splits thatrequire compositional generalization:from61.0 → 88.9 average accuracy..1.introduction.
the most dominant approach in recent years forsemantic parsing, the task of mapping a natural lan-guage utterance to an executable program, has beenbased on sequence-to-sequence (seq2seq) models(jia and liang, 2016; dong and lapata, 2016;wang et al., 2020, inter alia).
in these models,the output program is decoded step-by-step (au-toregressively), using an attention mechanism thatsoftly ties output tokens to the utterance..despite the success of seq2seq models, recently,finegan-dollak et al.
(2018) and keysers et al.
(2020) and herzig and berant (2019) demonstratedthat such models fail at compositional generaliza-tion, that is, they do not generalize to programstructures that were not seen at training time.
for.
example, a model that observes at training timethe questions “what states border china?” and“what is the largest state?” fails to generalize toquestions such as “what states border the largeststate?”.
this is manifested in large performancedrops on data splits designed to measure composi-tional generalization (compositional splits), and isin contrast to the generalization abilities of humans(fodor and pylyshyn, 1988)..in this work, we posit that the poor generaliza-tion of seq2seq models is due to fact that the inpututterance and output program are only tied softlythrough attention.
we revisit a more traditionalapproach for semantic parsing (zelle and mooney,1996; zettlemoyer and collins, 2005; liang et al.,2011), where partial programs are predicted overshort spans in the utterance, and are composed tobuild the program for the entire utterance.
suchexplicit inductive bias for compositionality shouldencourage compositional generalization..speciﬁcally, we propose to introduce such induc-tive bias via a span-based parser (stern et al., 2017;pasupat et al., 2019), equipped with the advantagesof modern neural architectures.
our model, span-basedsp, predicts for every span in the input acategory, which is either a constant from the un-derlying knowledge-base, a composition category,or a null category.
given the category predictionsfor all spans, we can construct a tree over the inpututterance and deterministically compute the outputprogram.
for example, in figure 1, the category forthe tree node covering the span “new york borders?” is the composition category join, indicatingthe composition of the predicate next_to_1 withthe entity stateid(’new york’)..categories are predicted for each span indepen-dently, resulting in a very simple training procedure.
cky is used at inference time to ﬁnd the best spantree, which is a tree with a category predicted atevery node.
the output program is computed from.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages908–921august1–6,2021.©2021associationforcomputationallinguistics908join: capital(loc_2(state(next_to_1(ny))).
φ.join: capital(loc_2(state(next_to_1(ny))).
capital.
join: loc_2(state(next_to_1(ny))).
loc_2.
join: state(next_to_1(ny)).
join: state.
join: next_to_1(ny).
state.
φ.stateid(’new york’).
join: next_to_1.
next_to_1.
φ.what1.
is2.
the3.
capital4.
of 5.states6.
that7.
new8 york9.
borders10.
?11.
figure 1: an example span tree.
nodes are annotated with categories (in bold).
a node with a category join overthe span (i, j), is annotated with its sub-program zi:j. we abbreviate stateid(’new york’) to ny..this tree in a bottom-up manner..we enhance the applicability of span-based se-mantic parsers (pasupat et al., 2019) in terms ofboth supervision and expressivity, by overcomingtwo technical challenges.
first, we do not use goldtrees as supervision, only programs with no ex-plicit decomposition over the input utterance.
totrain with latent trees, we use a hard-em approach,where we search for the best tree under the currentmodel corresponding to the gold program, and up-date the model based on this tree.
second, somegold trees are non-projective, and cannot be parsedwith a binary grammar.
thus, we extend the gram-mar of cky to capture a class of non-projectivestructures that are common in semantic parsing.
this leads to a model that is comparable and com-petitive with the prevailing seq2seq approach..we evaluate our approach on three datasets, andﬁnd that spanbasedsp performs similarly tostrong seq2seq baselines on standard i.i.d (random)splits, but dramatically improves performance oncompositional splits, by 32.9, 34.6 and 13.5 abso-lute accuracy points on geoquery (zelle andmooney, 1996), closure (bahdanau et al.,2019), and scan (lake and baroni, 2018) respec-tively.
our code and data are available at https://github.com/jonathanherzig/span-based-sp..2 problem setup.
we deﬁne span-based semantic parsing as follows.
given a training set {(xi, zi)}mi=1, where xi is anutterance and zi is the corresponding program, ourgoal is to learn a model that maps a new utter-ance x to a span tree t (deﬁned below), such thatprogram(t )= z. the deterministic functionprogram(·) maps span trees to programs..span trees a span tree t is a tree (see fig-ure 1) where, similar to constituency trees, eachnode covers a span (i, j) with tokens xi:j =(xi, xi+1, .
.
.
, xj).
a span tree can be viewed as amapping from every span (i, j) to a single categoryc ∈ c, where categories describe how the mean-ing of a node is derived from the meaning of itschildren.
a category c is one of the following:• σ: a set of domain-speciﬁc categories represent-ing domain constants, including entities and pred-icates.
e.g., in figure 1, capital, state,loc_2 and next_to_1 are binary predicates,and stateid(’new york’) is an entity.
• join: a category for a node whose meaning isderived from the meaning of its two children.
atmost one of the children’s categories can be theφ category..• φ: a category for (i) a node that does not affect themeaning of the utterance.
for example, in figure1, the nodes that cover “what is the” and “?” aretagged by φ; (ii) spans that do not correspond toconstituents (tree nodes).
overall, the category set is c = σ ∪ {φ, join}.
we also deﬁne the terminal nodes set σ+ = σ ∪{φ}, corresponding to categories that are directlyover the utterance..computing programs for span trees given amapping from spans to categories specifying a spantree t , we use the function program(·) to ﬁnd theprogram for t .
concretely, program(t ) iteratesover the nodes in t bottom-up, and generates aprogram zi:j for each node covering the span (i, j).
the program zi:j is computed deterministically.
for a node with category c ∈ σ, zi:j = c.for a join node over the span (i, j), we de-termine zi:j by composing the programs of its.
909children, zi:s and zs,j where s is the split point.
as in combinatory categorical grammar (steed-man, 2000), composition is simply function ap-plication, where a domain-speciﬁc type systemis used to determine which child is the functionand which is the argument (along with the ex-act argument position for predicates with multi-ple arguments).
if the category of one of the chil-dren is φ, the program for zi:j is copied from theother child.
e.g., in figure 1, the span (8, 9),where z8:9 = stateid(’new york’) com-bines with the span (10, 11), where z10:11 =next_to_1.
as z10:11 is a binary predicate thattakes an argument of type state, and z8:9 is an en-tity of type state, the output program is z8:11 =next_to_1(stateid(’new york’)).
ifno combination is possible according to the typesystem, the execution of program(t ) fails (§3.2).
unlike seq2seq models, computing programswith span trees is explicitly compositional.
ourmain hypothesis is that this strong inductive biasshould improve compositional generalization..3 a span-based semantic parser.
span-based parsing had success in both syntactic(stern et al., 2017; kitaev and klein, 2018) and se-mantic parsing (pasupat et al., 2019).
the intuitionis that modern sequence encoders are powerful, andthus we can predict a category for every span in-dependently, reducing the role of global structure.
this leads to simple and fast training..speciﬁcally, our parser is based on a modelpθ(t [i, j] = c), parameterized by θ, that providesfor every span (i, j) a distribution over categoriesc ∈ c. due to the above independence assumption,the log-likelihood of a tree t is deﬁned as:.
3.1 model.
we describe the architecture and training procedureof our model (spanbasedsp), assuming we aregiven for every utterance x a gold tree t , for whichprogram(t) = z..similar to pasupat et al.
(2019), we minimizethe negative log-likelihood − log p(t ) (eq.
1) forthe gold tree t .
the loss decomposes over spansinto cross-entropy terms for every span (i, j).
thiseffectively results in multi-class problem, wherefor every span xi:j we predict a category c ∈ c.training in this setup is trivial and does not requireany structured inference..concretely, the architecture of spanbasedspis based on a bert-base encoder (devlin et al.,2019) that yields a contextual representation hi ∈rhdim for each token xi in the input utterance.
werepresent each span (i, j) by concatenating its startand end representations [hi; hj], and apply a 1-hidden layer network to produce a real-valued scores(xi:j, c) for a span (i, j) and category c:.
s(xi:j, c) = [w2relu(w1[hi; hj])]ind(c),.
(2).
where w1 ∈ r250×2hdim, w2 ∈ r|c|×250, andind(c) is the index of the category c. we take asoftmax to produce the probabilities:.
pθ(t [i, j] = c) =.
exp[s(xi:j, c)]c(cid:48) exp[s(xi:j, c(cid:48))].
,.
(cid:80).
(3).
and train the model with a cross-entropy loss aver-aged over all spans, as mentioned above..log p(t ) =.
log pθ(t [i, j]),.
(1).
3.2 cky-based inference.
(cid:88).
i<j.
where, similar to pasupat et al.
(2019), the sum isover all spans i < j and not only over constituents.
we next describe the model pθ(t [i, j]) and its train-ing, assuming we have access to gold span trees attraining time (§3.1).
we will later (§3.3) removethis assumption, and describe a cky-based infer-ence procedure (§3.2) that ﬁnds for every trainingexample (x, z) the (approximately) most probablespan tree t ∗train, such that program(t ∗train) = z.we use t ∗train as a replacement for the gold tree.
last, we present an extension of our model thatcovers a class of span trees that are non-projective(§3.4)..while we assume span-independence at trainingtime, at test time we must output a valid span tree.
we now describe an approximate k-best cky al-gorithm that searches for the k most probable treesunder p(t ), and returns the highest-scoring onethat is semantically valid, i.e., that can be mappedto a program.1 as we elaborate below, some treescannot be mapped to a program, due to violationsof the type system..we start by re-writing our objective function,as proposed in pasupat et al.
(2019).
given our.
1the requirement that trees are semantically valid is what.
prevents exact search..910s := join join | φ joinjoin := join join | join φ.figure 2: cky grammar deﬁning the possible outputtrees..deﬁnition for pθ(t [i, j] = c), the log-likelihood is:.
log p(t ) =.
log pθ(t [i, j]) =.
algorithm 1: cky inference algorithminput: ∀i, j, c : s(xi:j, c), g = (n, σ+, r, s), xoutput: π - scores for each span and non-terminal.
s’(xij, c).
// equals zero.
1 for 1 ≤ i ≤ j ≤ |x| do2 π(i, j, join) ← maxc∈σ.
3 π(i, j, φ) ← s’(xij, φ)4 for 1 ≤ i ≤ j ≤ |x| do5.for x ∈ n dotemp ← max.
6.
[s’(xij, join) +.
(x→y z)∈rs∈i...(j−1)π(i, s, y ) + π(s + 1, j, z)].
π(i, j, x) ← max(temp, π(i, j, join)).
s(xi:j, t [i, j]) − log.
(cid:35)exp[s(xi:j, c(cid:48))].
..78 return π.
(cid:34).
(cid:88).
i<j.
(cid:88).
i<j.
(cid:88).
c(cid:48).
we shift the scoring function s(·) for each span,such that the score for the φ category is zero:.
s’(xi:j, ·) := s(xi:j, ·) − s(xi:j, φ)..because softmax is shift-invariant, we can replaces(·) for s(cid:48)(·) and preserve correctness.
this ismotivated by the fact that φ nodes, such as the onecovering “what is the” in figure 1, do not affectthe semantics of utterance.
by shifting scores suchthat for all spans s’(xi:j, φ) = 0, their score doesnot affect the overall tree score.
spans that do notcorrespond to tree nodes are labeled by φ and alsodo not affect the tree score.
furthermore, as (cid:80).
i<j log (cid:80)c(cid:48) exp[s’(xi:j, c(cid:48))]does not depend on t at all, maximizing log p(t )is equivalent to maximizing the tree score:.
s(t ) :=.
s’(xi:j, t [i, j])..(cid:88).
i<j.
this scoring function can be maximized using cky(cocke, 1969; kasami, 1965; younger, 1967).
wenow propose a grammar, which imposes furtherrestrictions on the space of possible output trees atinference time..we use a small grammar g = (n, σ+, r, s),where n = {s, join} is the set of non-terminals,σ+ is the set of terminals (deﬁned in §2), r is a setof four rules detailed in figure 2, and s is a specialstart symbol.
the four grammar rules impose thefollowing constraints on the set of possible outputtrees: (a) a join or s node can have at most oneφ child, as explained in §2; (b) nodes with no se-mantics combine with semantic elements on theirleft; (c) except at the root where they combine withelements on their right.
imposing such consistenttree structure is useful for training spanbasedspwhen predicted trees are used for training (§3.3)..the grammar g can generate trees that are notsemantically valid.
for example, we could gener-ate the program capital(placeid(’mountmckinley’)), which is semantically vacuous.
we use a domain-speciﬁc type system and assignthe score s(t ) = −∞ to every tree that yields asemantically invalid program.
this global factorprevents exact inference, and thus we perform k-best parsing, keeping the top-k (k = 5) best treesfor every span (i, j) and non-terminal..alg.
1 summarizes cky inference, that outputsπ(i, j, x), the maximal score for a tree with non-terminal root x over the span (i, j).
in lines 1-3we initialize the parse chart, by going over all spansand setting π(i, j, join) to the top-k highest scor-ing domain constants (σ), and ﬁxing the score for φto be zero.
we then perform the typical cky recur-sion to ﬁnd the top-k trees that can be constructedthrough composition (line 6), merge them withthe domain constants found during initialization(line 7), and keep the overall top-k trees..once inference is done, we retrieve the top-ktrees from π(1, |x|, s), iterate over them in de-scending score order, and return the ﬁrst tree t ∗that is semantically valid..3.3 training without gold trees.
we now remove the assumption of access to goldtrees at training time, in line with standard super-vised semantic parsing, where only the gold pro-gram z is given, without its decomposition overx. this can be viewed as a weakly-supervised set-ting, where the correct span tree is a discrete latentvariable.
in this setup, our goal is to maximize.
log p(z | x) = log.
(cid:88).
p(t ).
t :program(t )=z.
≈ log.
argmaxt :program(t )=z.
p(t )..911because marginalizing over trees is intractable, wetake a hard-em approach (liang et al., 2017; minet al., 2019), and replace the sum over trees with anargmax.
more concretely, to approximately solvethe argmax and ﬁnd the highest scoring tree, t ∗train,we employ a constrained version of alg.
1, thatprunes out trees that cannot generate z..we ﬁrst remove all predictions of constants that.
do not appear in z by setting their score to −∞:.
∀c ∈ {σ \ const(z)}, i, j : s(cid:48)(xi:j, c) := −∞,.
where const(z) is the set of domain constantsappearing in z. second, we allow a compositionof two nodes covering spans (i, s) and (s, j) onlyif their sub-programs zi:s and zs:j can compose ac-cording to z. for instance, in figure 1, a span withthe sub-program capital can only compose witha span with the sub-program loc_2(·).
after run-ning this constrained cky procedure we return thehighest scoring tree that yields the correct program,t ∗train, if one is found.
we then treat the span struc-ture of t ∗train as labels for training the parametersof spanbasedsp..past work on weakly-supervised semantic pars-ing often used maximum marginal likelihood, es-pecially when training from denotations only (guuet al., 2017).
in this work, we found hard-em tobe simple and sufﬁcient, since we are given theprogram z that provides a rich signal for guidingsearch in the space of latent trees..exact match features the challenge of weakly-supervised parsing is that spanbasedsp mustlearn to map language phrases to constants, andhow the span tree is structured.
to alleviate thelanguage-to-constant problem we add an exactmatch feature, based on a small lexicon, indicatingwhether a phrase in x matches the language descrip-tion of a category c ∈ σ. these features are consid-ered in spanbasedsp when some phrase matchesa category from σ, updating the score s(xi:j, c)to be: [w2relu(w1[hi; hj])]ind(c) + λδ(xi:j, c),where δ(xi:j, c) is an indicator that returns 1 ifc ∈ lexicon[xi:j], and 0 otherwise, and λ is ahyper-parameter that sets the feature’s importance.
we use two types of lexicon[·] functions.
in the ﬁrst,the lexicon is created automati-cally to map the names of entities (not pred-icates), as they appear in σ,to their corre-sponding constant (e.g., lexicon[“new york”] =stateid(’new york’)).
this endows span-basedsp with a copying mechanism, similar to.
join: largest_one(pop_1(state(all))).
-.
join: state.
largest_one.
join: pop_1.
state.
φ.pop_1.
φ.state1.
that2 has3 the4.
most5.
people6.
?7.
figure 3: an example of a non-projective tree.
thecorresponding program z is at the root..seq2seq models, for predicting entities unseen dur-ing training.
in the second lexicon we manually addno more than two examples of language phrasesfor each constant in σ.
e.g., for the predicatenext_to_1, we update the lexicon to includelexicon[“border”] = lexicon[“borders”] =next_to_1.
this requires minimal manual work(if no language phrases are available), but is doneonly once, and is common in semantic parsing(zettlemoyer and collins, 2005; wang et al., 2015;liang et al., 2017)..3.4 non-projective trees.
our span-based parser assumes composition canonly be done for adjacent spans that form togethera contiguous span.
however, this assumption doesnot always hold (liang et al., 2011).
for example,in figure 3, while the predicate pop_1 shouldcombine with the predicate state, the spans theyalign to (“people” and “state” respectively) arenot contiguous, as they are separated by “most”,which contributes the semantics of a superlative..in constituency parsing, such non-projectivestructures are treated by adding rules to the gram-mar g (maier et al., 2012; corro, 2020; stanojevi´cand steedman, 2020).
we identify one speciﬁcclass of non-projective structures that is frequentin semantic parsing (figure 3), and expand thegrammar g and the cky algorithm to support thisstructure.
speciﬁcally, we add the ternary grammarrule join := join join join.
during cky,when calculating the top-k trees for spans (i, j)(line 6 in alg.
1), we also consider the followingtop-k scores for the non-terminal join:.
[s’(xij, join) + π(i, s1, join).
maxs1∈i...(j−2)s2∈(s1+1)...(j−1)+ π(s1 + 1, s2, join) + π(s2 + 1, j, join)]..these additional trees are created by going over allpossible ways of dividing a span (i, j) into three.
912dataset.
scan-sp.
split.
iid.
clevr.
train.
dev.
test.
13,38312,18012,180.
694,689694,689.
540544540.
3,3453,0453,045.
5,0005,000.
606060.
4,1824,4764,476.
149,99125,200.
280276280.rightaroundright.
iidclosure.
iid.
length.
geoquery.
template.
table 1: number of examples for all datasets..parts.
the score of the sub-tree is then the sumof the score of the root added to the scores of thethree children.
to compute the program for suchternary nodes, we again use our type system, wherewe ﬁrst compose the programs of the two outerspans (i, s1) and (s2 + 1, j) and then compose theresulting program with the program correspondingto the span (s1 + 1, s2).
supporting ternary nodesin the tree increases the time complexity of ckyfrom o(n3) to o(n4) for our implementation.2.
4 experiments and results.
we now present our experimental evaluation, whichdemonstrates the advantage of span-based parsingfor compositional generalization.
we compare tobaseline models over two types of data splits: (a)iid split, where the training and test sets are sam-pled from the same distribution, and (b) composi-tional split, where the test set includes structuresthat are unseen at training time.
details on theexperimental setup are given in appendix a..4.1 datasets.
we evaluate on the following datasets (table 1)..geoquery contains 880 questions about usgeography (zelle and mooney, 1996), using thefunql formalism (kate et al., 2005).
for the iidsplit, we use the standard train/test split, randomlysampling 10% of the training set for development.
we additionally use two compositional splits basedon program templates (template) and on programlengths (length)..for the compositional split, template, weuse the procedure from finegan-dollak et al.
(2018) and split the 880 examples by templates.
a template is created by anonymizing entities inthe program to their type (both stateid(’new.
2corro (2020) show an o(n3) algorithm for this type of.
non-projective structure..and.
stateid(’utah’).
york’)areanonymized to state).
we then splittotrain/development/test sets, such that all examplesthat share a template are assigned to the same set.
we also verify that the sizes of theses sets are asclose as possible to the iid split..for the compositional split, length, we sortthe dataset by program token length and take thelongest 280 examples to be the test set.
we thenrandomly split the shortest 600 examples betweenthe train and development set, where we take 10%of the 600 examples for the latter..clevr and closure clevr (johnsonet al., 2017) contains synthetic questions, createdusing 80 templates, over synthetic images with mul-tiple objects of different shapes, colors, materialsand sizes (example in fig.
4 in the appendix).
therecent closure dataset (bahdanau et al., 2019),includes seven new question templates that are cre-ated by combining referring expressions of varioustypes from clevr in new ways..we use the semantic parsing version of thesedatasets, where each image is described by a scene(knowledge-base) that holds the attributes and po-sitional relations of all objects.
we use programsin the dsl version from mao et al.
(2019)..for our experiments, we take 5k examples fromthe original clevr training set and treat themas our development set.
we use the other 695kexamples as training data for our baselines.
im-portantly, we only use 10k training examples forspanbasedsp to reduce training time.
we thencreate an iid split where we test on the clevroriginal development set (test scenes are not pub-licly available).
we additionally deﬁne the clo-sure split, that tests compositional generaliza-tion, where we test on closure..scan-sp scan (lake and baroni, 2018) con-tains natural language navigation commands thatare mapped to action sequences (x and y in fig.
5 in the appendix).
as scan lacks programs,we automatically translate the input to programs (zin fig.
5) to crate the semantic parsing version ofscan, denoted scan-sp (more details are givenin appendix b).
we experiment with the randomsimple split from lake and baroni (2018) as ouriid split.
we further use the primitive right (right)and primitive around right (aroundright) com-positional splits from loula et al.
(2018).
for eachsplit we randomly assign 20% of the training set.
913scan-sp.
clevr.
geoquery.
iid.
right.
aroundright.
iid.
closure.
iid.
template.
length.
model.
seq2seq.
+elmo.
bert2seq.
grammar.
bart.
end2end.
spanbasedsp.
-lexicon-non projective.
dev.
100.
100.
99.9.
100.
100.
-.
100100-.
test.
99.9.
100.
100.
100.
100.
-.
100100-.
dev.
100.
100.
99.9.
100.
100.
-.
100100-.
test.
11.6.
54.9.
77.7.
0.0.
50.5.
-.
100100-.
dev.
100.
100.
99.9.
100.
100.
-.
100100-.
test.
0.0.
41.6.
95.3.
4.2.
100.
-.
100100-.
100.dev.
100.
100.
100.
100.
100.test.
100.
100.
100.
100.
100.dev.
100.
100.
100.
100.
100.
99.9.
99.8.
99.9.
97.099.4-.
96.799.3-.
98.998.5-.
test.
59.5.
64.2.
56.4.
51.3.
51.5.
63.3.
98.888.6-.
dev.
test.
dev.
test.
dev.
test.
83.3.
83.3.
88.3.
78.3.
93.3.
-.
88.388.385.0.
78.5.
79.3.
81.1.
72.1.
87.1.
-.
86.178.980.0.
71.6.
83.3.
85.0.
76.7.
86.7.
-.
93.386.790.0.
46.0.
50.0.
49.6.
54.0.
67.0.
-.
82.265.980.2.
86.7.
86.7.
90.0.
81.7.
90.0.
-.
95.090.093.3.
24.3.
25.7.
26.1.
24.6.
19.3.
-.
63.641.459.3.
+gold trees.
100.
100.
100.
100.
100.
100.
96.8.
100.
96.7.
91.2.
86.4.
100.
81.8.
96.7.
68.6.table 2: denotation accuracies for all models, including spanbasedsp ablations.
for both clevr splits,spanbasedsp only trains on 10k examples, in comparison to 695k for the baselines..for development..4.2 baselines.
seq2seq similar to finegan-dollak et al.
(2018),our baseline parser is a standard seq2seq model (jiaand liang, 2016) that encodes the utterance x witha bilstm encoder over pre-trained glove (pen-nington et al., 2014) or elmo (peters et al., 2018)embeddings, and decodes the program with anattention-based lstm decoder (bahdanau et al.,2015) assisted by a copying mechanism for han-dling entities unseen during training time (gu et al.,2016)..bert2seq same as seq2seq, but we replacethe bilstm encoder with bert-base, which isidentical to the encoder of spanbasedsp..grammar grammar-based decoding has beenshown to improve performance on iid splits (kr-ishnamurthy et al., 2017; yin and neubig, 2017).
because decoding is constrained by the grammar,the model outputs only valid programs, whichcould potentially improve performance on composi-tional splits.
we use the grammar from (wong andmooney, 2007) for geoquery, and write gram-mars for scan-sp and clevr + closure.
the model architecture is identical to seq2seq..additionally.
bart weexperiment withbart-base (lewis et al., 2020), a seq2seqmodel pre-trained as a denoising autoencoder..end2end semantic parsers generate a programthat is executed to retrieve an answer.
however,other end-to-end models directly predict the an-swer from the context without an executor, where.
the context can be an image (hudson and manning,2018; perez et al., 2018), a table (herzig et al.,2020), etc.
because clevr and closure havea closed set of 28 possible answers and a short con-text (the scene), they are a good ﬁt for end-to-endapproaches.
to check whether end-to-end modelsgeneralize compositionally, we implement the fol-lowing model.
we use bert-base to encode theconcatenation of the input x to a representation ofall objects in the scene.
each scene object is repre-sented by adding learned embeddings of all of itsattributes: shape, material, size, color, and relativepositional rank (from left to right, and from frontto back).
we ﬁne-tune the model on the training setusing cross-entropy loss, where the [cls] tokenis used to predict the answer..4.3 main results.
table 2 shows denotation accuracies for all base-lines (top part) and our spanbasedsp model(middle part).
for spanbasedsp, we also ablatethe use of the manually constructed lexicon (§3.3)and the non-projective extension to cky (§3.4),which is relevant only for geoquery, where non-projective structures are more frequent..the table shows that all baselines generalizewell on the iid split, but suffer from a large ac-curacy drop on the compositional splits (exceptbert2seq and bart on aroundright).
forinstance, on the compositional closure split,all baselines achieve accuracy in the range of51.3 − 64.2, while performing perfectly on theiid split.
conversely, spanbasedsp performsalmost identically on both splits.
spanbasedsp.
914attains near-perfect performance on all scan-spand clevr splits, despite training on only 10kexamples from clevr compared to 695k train-ing examples for the baselines (70x less data).
ongeoquery, spanbasedsp performs similarlyto other semantic parsers on the iid split (dongand lapata, 2016), and loses just 4 points on thecompositional template split.
on the lengthsplit, spanbasedsp yields an accuracy of 63.6,substantially outperforming all baselines by morethan 37 accuracy points..our ablations show that the lexicon is crucialfor geoquery, which has a small training set.
inthis setting, learning the mapping from languagephrases to predicates is challenging.
ablating non-projective parsing also hurts performance for geo-query, and leads to a reduction of 2-6 points forall of the splits..4.4 decomposition analysis.
we now analyze whether trees learned by span-basedsp are similar to gold trees.
for this anal-ysis we semi-automatically annotate our datasetswith gold trees.
we do this by manually creating adomain-speciﬁc lexicon for each dataset (extendingthe lexicon from §3.3), mapping domain constantsto possible phrases in the input utterances.
we then,for each example, traverse the program tree (ratherthan the span tree) bottom-up and annotate joinand φ categories for spans in the utterance, aided bymanually-written domain-speciﬁc rules.
in caseswhere the annotation is ambiguous, e.g., exampleswith more than two instances of a speciﬁc domainconstant, we do not produce a gold tree..we manage to annotate 100%/94.9%/95.9% ofthe examples in scan-sp/ geoquery/ clevr+ closure respectively in this manner.
weverify the correctness of our annotation by train-ing spanbasedsp from our annotated gold trees(bottom part of table 2).
the results shows thattraining from these “gold” trees leads to similarperformance as training only from programs..we then train spanbasedsp from gold pro-grams, as explained in §3.3, and calculate f1 testscores, comparing the predicted span trees to thegold ones.
f1 is computed between the two sets oflabeled spans, taking into account both the spansand their categories, but excluding spans with theφ category that do not contribute to the semantics.
table 3 shows that for geoquery the treesspanbasedsp predicts are similar to the gold.
dataset.
scan-sp.
split.
iid.
clevr.
f1.
100100100.
70.670.6.
94.791.693.7.rightaroundright.
iidclosure.
iid.
length.
geoquery.
template.
table 3: f1 scores on the test set w.r.t to the semi-automatically annotated gold trees..trees (with 94.7, 91.6 and 93.7 f1 scores for theiid, template and length splits respectively),and in scan-sp we predict perfect trees.
onclevr, we get a lower f1 score of 70.6 for boththe iid and closure splits.
however, whenmanually inspecting predicted trees on the iid split,we notice that predicted trees that are not identi-cal to gold trees, are actually correct.
this hap-pens in cases where multiple gold trees are possi-ble.
for instance, in figure 4 (in the appendix),the span x13:15 =“matte block ?” can be eitherparsed as [matte [block ?
]], as in the ﬁgure, or[[matte block] ?].
this phenomena is common inclevr and closure, as span trees tend to bedeep, and thus have more ambiguity..4.5 limitations.
our approach assumes a one-to-one mapping be-tween domain constants and their manifestation asphrases in language.
this leads to strong results oncompositional generalization, but hurts the ﬂexibil-ity that is sometimes necessary in semantic parsing.
for example, in some cases predicates do not alignexplicitly to a phrase in the utterance or appear sev-eral times in the program but only once in the utter-ance (berant et al., 2013; pasupat and liang, 2015).
this is evident in text-to-sql parsing, where anutterance such as “what is the minimum, and max-imum age of all singers from france?” is mappedto select min(age) , max(age) fromsinger where country=’france’.
here,the constant age is mentioned only once in lan-guage (but twice in the program), and countryis not mentioned at all.
thus, our approach is moresuitable for formalisms where there is tighter align-ment between the natural and formal language..in addition, while we handle a class of non-projective trees (§3.4),there are other non-projective structures that spanbasedsp can not.
915parse.
extending cky to support all structuresfrom corro (2020) leads to a time complexity ofo(n6), which might be impractical..compositional bias, inherent to spanbasedsp,directly into seq2seq models..acknowledgments.
5 related work.
until the neural era, semantic parsers used a lexiconand composition rules to predict partial programsfor spans and compose them until a full programis predicted, and typically scored with a log-linearmodel given features over the utterance and the pro-gram (zettlemoyer and collins, 2005; liang et al.,2011).
in this work, we use a similar compositionalapproach, but take advantage of powerful span rep-resentations based on modern neural architectures.
the most similar work to ours is by pasupat et al.
(2019), who presented a neural span-based seman-tic parser.
while they focused on training usingprojective gold trees (having more supervision andless expressivity than seq2seq models) and testingon i.i.d examples, we handle non-projective trees,given only program supervision, rather than trees.
more importantly, we show that this approach leadsto dramatic gains in compositional generalizationcompared to autoregressive parsers..in recent years, work on compositional general-ization in semantic parsing mainly focused on thepoor performance of parsers in compositional splits(finegan-dollak et al., 2018), creating new datasetsthat require compositional generalization (keyserset al., 2020; lake and baroni, 2018; bahdanauet al., 2019), and proposing specialized architec-tures mainly for the scan task (lake, 2019; nyeet al., 2020; gordon et al., 2020; liu et al., 2020;gupta and lewis, 2018).
in this work we present ageneral-purpose architecture for semantic parsingthat incorporates an inductive bias towards compo-sitional generalization.
finally, concurrently to us,shaw et al.
(2020) induced a synchronous gram-mar over program and utterance pairs and used itto introduce a compositional bias, showing certainimprovements over compositional splits..6 conclusion.
seq2seq models have become unprecedentedlypopular in semantic parsing but struggle to general-ize to unobserved structures.
in this work, we showthat our span-based parser, spanbasedsp, thatprecisely describes how meaning is composed overthe input utterance leads to dramatic improvementsin compositional generalization.
in future work, weplan to investigate ways to introduce the explicit.
we thank ben bogin, nitish gupta, matt gardnerand the anonymous reviewers for their construc-tive feedback, useful comments and suggestions.
this work was completed in partial fulﬁllment forthe phd degree of the ﬁrst author, which was alsosupported by a google phd fellowship.
this re-search was partially supported by the yandex ini-tiative for machine learning, and the european re-search council (erc) under the european unionhorizons 2020 research and innovation programme.
(grant erc delphi 802800)..references.
dzmitry bahdanau, kyunghyun cho, and yoshua ben-gio.
2015. neural machine translation by jointlyin 3rd inter-learning to align and translate.
national conference on learning representations,iclr 2015, san diego, ca, usa, may 7-9, 2015,conference track proceedings..dzmitry bahdanau, harm de vries, timothy jo’donnell, shikhar murty, philippe beaudoin,yoshua bengio, and aaron courville.
2019. clo-sure: assessing systematic generalization of clevrmodels.
arxiv preprint arxiv:1912.05783..jonathan berant, andrew chou, roy frostig, and percyliang.
2013. semantic parsing on freebase fromquestion-answer pairs.
in proceedings of the 2013conference on empirical methods in natural lan-guage processing, pages 1533–1544, seattle, wash-ington, usa.
association for computational lin-guistics..john cocke.
1969. programming languages and theircompilers: preliminary notes.
new york univer-sity, usa..caio corro.
2020..span-based discontinuous con-stituency parsing: a family of exact chart-based al-gorithms with time complexities from o(nˆ6) downto o(nˆ3).
in proceedings of the 2020 conferenceon empirical methods in natural language process-ing (emnlp), pages 2753–2764, online.
associa-tion for computational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..916li dong and mirella lapata.
2016. language to logi-cal form with neural attention.
in proceedings of the54th annual meeting of the association for compu-tational linguistics (volume 1: long papers), pages33–43, berlin, germany.
association for computa-tional linguistics..catherine finegan-dollak, jonathan k. kummerfeld,li zhang, karthik ramanathan, sesh sadasivam,rui zhang, and dragomir radev.
2018. improvingtext-to-sql evaluation methodology.
in proceedingsof the 56th annual meeting of the association forcomputational linguistics (volume 1: long papers),pages 351–360, melbourne, australia.
associationfor computational linguistics..(emnlp-ijcnlp), pages 3810–3820, hong kong,china.
association for computational linguistics..jonathan herzig, pawel krzysztof nowak, thomasmüller, francesco piccinno, and julian eisenschlos.
2020. tapas: weakly supervised table parsing viain proceedings of the 58th annualpre-training.
meeting of the association for computational lin-guistics, pages 4320–4333, online.
association forcomputational linguistics..drew a hudson and christopher d manning.
2018.compositional attention networks for machine rea-in international conference on learningsoning.
representations (iclr)..jerry a. fodor and zenon w. pylyshyn.
1988. connec-tionism and cognitive architecture: a critical anal-ysis, page 3–71.
mit press, cambridge, ma, usa..r. jia and p. liang.
2016. data recombination for neu-in association for computa-.
ral semantic parsing.
tional linguistics (acl)..matt gardner, joel grus, mark neumann, oyvindtafjord, pradeep dasigi, nelson f. liu, matthew pe-ters, michael schmitz, and luke zettlemoyer.
2018.allennlp: a deep semantic natural language pro-in proceedings of workshop forcessing platform.
nlp open source software (nlp-oss), pages 1–6, melbourne, australia.
association for computa-tional linguistics..jonathan gordon, david lopez-paz, marco baroni,and diane bouchacourt.
2020. permutation equiv-ariant models for compositional generalization inlanguage.
in international conference on learningrepresentations..jiatao gu, zhengdong lu, hang li, and victor o.k.
incorporating copying mechanism inli.
2016.in proceedings ofsequence-to-sequence learning.
the 54th annual meeting of the association for com-putational linguistics (volume 1: long papers),pages 1631–1640, berlin, germany.
association forcomputational linguistics..nitish gupta and mike lewis.
2018. neural compo-sitional denotational semantics for question answer-ing.
in proceedings of the 2018 conference on em-pirical methods in natural language processing,pages 2152–2161, brussels, belgium.
associationfor computational linguistics..kelvin guu, panupong pasupat, evan liu, and percyliang.
2017. from language to programs: bridg-ing reinforcement learning and maximum marginallikelihood.
in proceedings of the 55th annual meet-ing of the association for computational linguistics(volume 1: long papers), pages 1051–1062, van-couver, canada.
association for computational lin-guistics..jonathan herzig and jonathan berant.
2019. don’tparaphrase, detect!
rapid and effective data collec-in proceedings of thetion for semantic parsing.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing.
justin johnson, bharath hariharan, laurens van dermaaten, li fei-fei, c lawrence zitnick, and rossgirshick.
2017. clevr: a diagnostic dataset for com-positional language and elementary visual reasoning.
in cvpr..t. kasami.
1965. an efﬁcient recognition and syntaxanalysis algorithm for context-free languages.
tech-nical report afcrl-65-758, air force cambridgeresearch laboratory, bedford, ma†..rohit j. kate, yuk wah wong, and raymond j.mooney.
2005. learning to transform natural toin proceedings of the 20th na-formal languages.
tional conference on artiﬁcial intelligence - volume3, aaai’05, page 1062–1068.
aaai press..daniel keysers, nathanael schärli, nathan scales,hylke buisman, daniel furrer, sergii kashubin,nikola momchev, danila sinopalnikov, lukaszstaﬁniak, tibor tihon, et al.
2020. measuring com-positional generalization: a comprehensive methodon realistic data.
in iclr..nikita kitaev and dan klein.
2018. constituency pars-in proceedingsing with a self-attentive encoder.
of the 56th annual meeting of the association forcomputational linguistics (volume 1: long papers),pages 2676–2686, melbourne, australia.
associa-tion for computational linguistics..jayant krishnamurthy, pradeep dasigi, and matt gard-ner.
2017. neural semantic parsing with type con-straints for semi-structured tables.
in emnlp..brenden m lake.
2019. compositional generalizationthrough meta sequence-to-sequence learning.
in ad-vances in neural information processing systems32, pages 9791–9801.
curran associates, inc..brenden m. lake and marco baroni.
2018. general-ization without systematicity: on the compositionalskills of sequence-to-sequence recurrent networks.
in icml..917mike lewis, yinhan liu, naman goyal, mar-jan ghazvininejad, abdelrahman mohamed, omerlevy, veselin stoyanov, and luke zettlemoyer.
2020. bart: denoising sequence-to-sequence pre-training for natural language generation, translation,and comprehension.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 7871–7880, online.
associationfor computational linguistics..panupong pasupat, sonal gupta, karishma mandyam,rushin shah, mike lewis, and luke zettlemoyer.
span-based hierarchical semantic parsing2019.in proceedings of thefor task-oriented dialog.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 1520–1526, hong kong,china.
association for computational linguistics..c. liang, j. berant, q. le, and k. d. f. n. lao.
2017. neural symbolic machines: learning seman-tic parsers on freebase with weak supervision.
inassociation for computational linguistics (acl)..percy liang, michael jordan, and dan klein.
2011.learning dependency-based compositional seman-tics.
in proceedings of the 49th annual meeting ofthe association for computational linguistics: hu-man language technologies, pages 590–599, port-land, oregon, usa.
association for computationallinguistics..q. liu, shengnan an, jianguang lou, b. chen, zeqilin, yan gao, bin zhou, nanning zheng, anddongmei zhang.
2020.compositional general-ization by learning analytical expressions.
arxiv,abs/2006.10627..joão loula, marco baroni, and brenden lake.
2018.rearranging the familiar: testing compositionalin proceed-generalization in recurrent networks.
ings of the 2018 emnlp workshop blackboxnlp:analyzing and interpreting neural networks fornlp, pages 108–114, brussels, belgium.
associa-tion for computational linguistics..wolfgang maier, miriam kaeshammer, and laurakallmeyer.
2012. plcfrs parsing revisited: re-in proceedings ofstricting the fan-out to two.
the 11th international workshop on tree adjoin-ing grammars and related formalisms (tag+11),pages 126–134, paris, france..jiayuan mao, chuang gan, pushmeet kohli, joshua b.the neuro-tenenbaum, and jiajun wu.
2019.symbolic concept learner:interpreting scenes,words, and sentences from natural supervision.
ininternational conference on learning representa-tions..sewon min, danqi chen, hannaneh hajishirzi, andluke zettlemoyer.
2019. a discrete hard em ap-proach for weakly supervised question answering.
in proceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 2851–2864, hong kong, china.
association for computa-tional linguistics..maxwell i nye, armando solar-lezama, joshua btenenbaum, and brenden m lake.
2020. learn-ing compositional rules via neural program synthe-sis.
arxiv preprint arxiv:2003.05562..panupong pasupat and percy liang.
2015. composi-tional semantic parsing on semi-structured tables.
inproceedings of the 53rd annual meeting of the asso-ciation for computational linguistics and the 7th in-ternational joint conference on natural languageprocessing (volume 1: long papers)..j. pennington, r. socher, and c. d. manning.
2014.glove: global vectors for word representation.
inempirical methods in natural language processing(emnlp), pages 1532–1543..ethan perez, florian strub, harm de vries, vincent du-moulin, and aaron c. courville.
2018. film: vi-sual reasoning with a general conditioning layer.
inaaai..matthew peters, mark neumann, mohit iyyer, mattgardner, christopher clark, kenton lee, and lukezettlemoyer.
2018. deep contextualized word repre-sentations.
in proceedings of the 2018 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long papers)..peter shaw, ming-wei chang, panupong pasupat, andkristina toutanova.
2020. compositional general-ization and natural language variation: can a seman-arxiv preprinttic parsing approach handle both?
arxiv:2010.12725..miloš stanojevi´c and mark steedman.
2020. span-based lcfrs-2 parsing.
in proceedings of the 16thinternational conference on parsing technologiesand the iwpt 2020 shared task on parsing intoenhanced universal dependencies, pages 111–121,online.
association for computational linguistics..mark steedman.
2000. the syntactic process, vol-.
ume 24. mit press cambridge, ma..mitchell stern, jacob andreas, and dan klein.
2017. aminimal span-based neural constituency parser.
inproceedings of the 55th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 818–827, vancouver, canada.
association for computational linguistics..bailin wang, richard shin, xiaodong liu, oleksandrpolozov, and matthew richardson.
2020. rat-sql:relation-aware schema encoding and linking fortext-to-sql parsers.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, pages 7567–7578, online.
associationfor computational linguistics..918yushi wang, jonathan berant, and percy liang.
2015.in proceed-building a semantic parser overnight.
ings of the 53rd annual meeting of the associationfor computational linguistics and the 7th interna-tional joint conference on natural language pro-cessing (volume 1: long papers), pages 1332–1342,beijing, china.
association for computational lin-guistics..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, r’emi louf, morgan funtow-icz, and jamie brew.
2019. huggingface’s trans-formers: state-of-the-art natural language process-ing.
arxiv, abs/1910.03771..yuk wah wong and raymond mooney.
2007. learn-ing synchronous grammars for semantic parsingin proceedings of the 45thwith lambda calculus.
annual meeting of the association of computationallinguistics, pages 960–967, prague, czech repub-lic.
association for computational linguistics..pengcheng yin and graham neubig.
2017. a syntacticneural model for general-purpose code generation.
in proceedings of the 55th annual meeting of the as-sociation for computational linguistics (volume 1:long papers), pages 440–450, vancouver, canada.
association for computational linguistics..d.h. younger.
1967. recognition and parsing ofcontext-free languages in time n3.
information andcontrol, 10(2):189–208..john m zelle and raymond j mooney.
1996. learn-ing to parse database queries using inductive logicprogramming.
in proceedings of the national con-ference on artiﬁcial intelligence, pages 1050–1055..luke s. zettlemoyer and michael collins.
2005. learn-ing to map sentences to logical form: structuredclassiﬁcation with probabilistic categorial grammars.
in proceedings of the twenty-first conference onuncertainty in artiﬁcial intelligence, uai’05, page658–666, arlington, virginia, usa.
auai press..919appendix.
a experimental setup.
we evaluate models with denotation accuracy,that is, the proportion of questions for which thedenotations of the predicted and gold programsare identical.
for spanbasedsp, we selecteda learning rate of 1e−5, considering the values[1e−4, 1e−5, 1e−6], and use a batch size of 5. forour baselines, we tune the learning rate, batch size,and dropout.
we choose all hyper-parameters byearly-stopping with respect to development set de-notation accuracy.
training spanbasedsp takesbetween 2 hours for geoquery up to 20 hours forclevr on a single geforce gtx 1080 gpu.
ourseq2seq baselines are from allennlp (gardneret al., 2018), and all bert-base (110m param-eters) implementations are from the transformerslibrary (wolf et al., 2019)..we additionally implement executors that cal-culate the denotation of a program with respect tothe corresponding scene for clevr +closureand retrieve an action sequence as the denotationfor scan-sp..b generating scan-sp.
to create a semantic parsing version of scan,we introduce the binary predicates and, after,walk, jump, run, look and turn.
we ad-ditionally introduce the unary predicates twiceand thrice.
finally, we introduce the constantsleft, right, opposite and around.
wethen construct a synchronous context-free gram-mar (scfg) that parses utterances in scan intoprograms in scan-sp by utilizing the constantsabove and simple composition rules.
finally, weuse our grammar to parse all utterances in scanto generate the programs in scan-sp..920join.
φ.join.
exist.
join.
join.
join.
metal.
φ.join.
join.
relate_att_eq.
join.
rubber.
join.
color.
φ.cube.
φ.are1 there2.
any3.
shiny4.
objects5 that6 have7 the8.
same9.
color10.
as11 the12.
matte13.
block14.
?15.
x: are there any shiny objects that have the same color as the matte block?
z: exist(filter(metal,relate_att_eq(color,filter(rubber,cube,scene())))).
figure 4: an example span tree from clevr, along with its utterance x and program z. here, the type system isused in join nodes to deterministically invoke the predicates filter and scene where needed.
sub-programsare omitted due to space reasons..j: after(walk(r),twice(turn(l,op))).
j: after(walk(r),·).
j: twice(turn(l,op)).
j: walk(r).
after.
j: turn(l,op).
twice.
walk.
r.j: turn(·,op).
l.turn.
op.
walk1.
right2.
after3.
turn4.
opposite5.
left6.
twice7.
x: walk right after turn opposite left twicez: after(walk(r),twice(turn(l,op)))y: lturn lturn lturn lturn rturn walk.
figure 5: an example span tree from scan-sp, alongwith its utterance x, program z and action sequence y.the category join is abbreviated to j..921