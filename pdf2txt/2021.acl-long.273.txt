out-of-scope intent detection with self-supervision anddiscriminative training.
li-ming zhan1 haowen liang1∗ bo liu1∗ lu fan1 xiao-ming wu1†albert y.s.
lam2department of computing, the hong kong polytechnic university, hong kong s.a.r.1fano labs, hong kong s.a.r.2{lmzhan.zhan, michael.liang, doc-bo.liu}@connect.polyu.edu.hk{cslfan, csxmwu}@comp.polyu.edu.hk, albert@fano.ai.
abstract.
out-of-scope intent detection is of practicalimportance in task-oriented dialogue systems.
since the distribution of outlier utterances isarbitrary and unknown in the training stage,existing methods commonly rely on strong as-sumptions on data distribution such as mixtureof gaussians to make inference, resulting in ei-ther complex multi-step training procedures orhand-crafted rules such as conﬁdence thresh-old selection for outlier detection.
in this pa-per, we propose a simple yet effective methodto train an out-of-scope intent classiﬁer in afully end-to-end manner by simulating the testscenario in training, which requires no assump-tion on data distribution and no additional post-processing or threshold setting.
speciﬁcally,we construct a set of pseudo outliers in thetraining stage, by generating synthetic outliersusing inliner features via self-supervision andsampling out-of-scope sentences from easilyavailable open-domain datasets.
the pseudooutliers are used to train a discriminative clas-siﬁer that can be directly applied to and gen-eralize well on the test task.
we evaluateour method extensively on four benchmarkdialogue datasets and observe signiﬁcant im-provements over state-of-the-art approaches.
our code has been released at https://github.com/liam0949/dcloos..1.introduction.
conversational system is becoming an indispens-able component in a variety of ai applications andacts as an interactive interface provided to users toimprove user experience.
language understandingis essential for conversational systems to provideappropriate responses to users, and intent detectionis usually the ﬁrst step of language understanding.
the primary goal is to identify diverse intentions.
∗equal contribution.
† corresponding author..figure 1:t-sne visualization of the learned embed-dings of the test samples of clinc150.
top: previousk-way training; bottom: our proposed (k + 1)-waytraining.
better view in color and enlarged..behind user utterances, which is often formalizedas a classiﬁcation task.
however, intent classesdeﬁned during training are inevitably inadequate tocover all possible user intents at the test stage dueto the diversity and randomness of user utterances.
hence, out-of-scope (or unknown) intent detectionis essential, which aims to develop a model that canaccurately identify known (seen in training) intentclasses while detecting the out-of-scope classes thatare not encountered during training..due to the practical importance of out-of-scopeintent detection, recent efforts have attempted tosolve this problem by developing effective intentclassiﬁcation models.
in general, previous worksapproach this problem by learning decision bound-aries for known intents and then using some conﬁ-dence measure to distinguish known and unknownintents.
for examples, lmcl (lin and xu, 2019).
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3521–3532august1–6,2021.©2021associationforcomputationallinguistics3521learns the decision boundaries with a margin-basedoptimization objective, and seg (yan et al., 2020b)assumes the known intent classes follow the dis-tribution of mixture of gaussians.
after learningthe decision boundaries, an off-the-shell outlierdetection algorithm such as lof (breunig et al.,2000) is commonly employed to derive conﬁdencescores (yan et al., 2020b; shu et al., 2017; lin andxu, 2019; hendrycks and gimpel, 2017).
if theconﬁdence score of a test sample is lower than apredeﬁned threshold, it is identiﬁed as an outlier..however, it may be problematic to learn decisionboundaries solely based on the training examplesof known intent classes.
first, if there are sufﬁcienttraining examples, the learned decision boundariescan be expected to generalize well on known intentclasses, but not on the unknown.
therefore, extrasteps are required in previous methods, such asusing an additional outlier detection algorithm atthe test stage or adjusting the conﬁdence thresholdby cross-validation.
on the other hand, if thereare not sufﬁcient training examples, the learnedboundaries may not generalize well on both knownand unknown intents.
as a result, these methodsoften underperform when not enough training datais given.
hence, it is important to provide learningsignals of unknown intents at the training stage toovercome these limitations..in contrast to previous works, we adopt a differ-ent approach by explicitly modeling the distribu-tion of unknown intents.
particularly, we constructa set of pseudo out-of-scope examples to aid thetraining process.
we hypothesize that in the se-mantic feature space, real-world outliers can bewell represented in two types: “hard” outliers thatare geometrically close to the inliers and “easy”outliers that are distant from the inliners.
for the“hard” ones, we construct them in a self-supervisedmanner by forming convex combination of the fea-tures of inliers from different classes.
for the “easy”ones, the assumption is that they are very unrelatedto the known intent classes, so they can be usedto simulate the randomness and diversity of userutterances.
they can be easily constructed usingpublic datasets.
for example, in our experiments,we randomly collect sentences from datasets ofother nlp tasks such as question answering andsentiment analysis as open-domain outliers..in effect, by constructing pseudo outliers for theunknown class during training, we form a consis-tent (k + 1) classiﬁcation task (k known classes.
+ 1 unknown class) for both training and test.
ourmodel can be trained with a cross-entropy loss anddirectly applied to test data for intent classiﬁca-tion and outlier detection without requiring anyfurther steps.
as shown in figure 1 (better viewin color and enlarged), our method can learn betterutterance representations, which make each knownintent class more compact and push the outliersaway from the inliers.
our main contributions aresummarized as follows..• we propose a novel out-of-scope intent detec-tion approach by matching training and testtasks to bridge the gap between ﬁtting to train-ing data and generalizing to test data..• we propose to efﬁciently construct two typesof pseudo outliers by using a simple self-supervised method and leveraging publiclyavailable auxiliary datasets..• we conduct extensive experiments on fourreal-world dialogue datasets to demonstratethe effectiveness of our method and perform adetailed ablation study..2 related work.
2.1 out-of-distribution detection.
early studies on outlier detection often adopt unsu-pervised clustering methods to detect malformeddata (hodge and austin, 2004; chandola et al.,2009; zimek et al., 2012).
in recent years, asubstantial body of work has been directed to-wards improving the generalization capacity ofmachine learning models on out-of-distribution(ood) data (ruff et al., 2021; hendrycks et al.,2020a).
hendrycks and gimpel (2017) ﬁnd thatsimple statistics derived from the outputting soft-max probabilities of deep neural networks can behelpful for detecting ood samples.
following thiswork, liang et al.
(2018) propose to use temper-ature scaling and add small perturbation to inputimages to enlarge the gap between in-scope andood samples.
lee et al.
(2017) propose to add akullback-leibler divergence term in the loss func-tion to encourage assigning lower maximum scoresto ood data..recently, there is a line of work that employssynthetic or real-world auxiliary datasets to providelearning signals for improving model robustnessunder various forms of distribution shift (goodfel-low et al., 2015; orhan, 2019; hendrycks et al.,.
35222019; lee et al., 2017).
particularly, hendryckset al.
(2018) propose to leverage large-scale publicdatasets to represent outliers during training timeand form a regularization term based on that.
thisidea is similar to our proposal of constructing open-domain outliers, but we use a simpler, end-to-end,(k+1)-way discriminative training procedure with-out any regularization term or threshold parameter..2.2 out-of-scope intent detection.
while hendrycks et al.
(2020b) ﬁnd that pretrainedtransformer-based models like bert are intrinsi-cally more robust to ood data, they suggest thatthere are still margins for improvement.
there-fore, we build our model on top of bert to im-prove intent detection under signiﬁcant distribu-tion shift.
previous methods for out-of-scope (orout-of-distribution) intent detection are commonlythreshold-based, where models output a decisionscore and then compare it with a threshold that ispredeﬁned or selected by cross-validation..there are mainly three branches of related work.
the ﬁrst group uses a conﬁdence score which de-termines the likelihood of an utterance being out-of-scope.
for example, shu et al.
(2017) build mbinary sigmoid classiﬁers for m known classesrespectively and select a threshold to reject oodinputs that may have lower probabilities than thethreshold across all m classiﬁers.
similar to theood data generation method used in lee et al.
(2017), ryu et al.
(2018) employ gan (goodfel-low et al., 2014) to generate simulated ood exam-ples with the generator and learn to reject simulatedood examples with the discriminator..the second group identiﬁes out-of-scope sen-tences through reconstruction loss.
for example,ryu et al.
(2017) build an autoencoder to encodeand decode in-scope utterances and obtain recon-struction loss by comparing input embeddings withdecoded ones.
out-of-scope utterances result inhigher reconstruction loss..the third group leverages off-the-shell out-lier detection algorithms such as local outlierfactor (lof) (breunig et al., 2000), one-classsvm (sch¨olkopf et al., 2001), robust covarianceestimators (rousseeuw and driessen, 1999), andisolation forest (liu et al., 2008) to detect out-of-scope examples.
utterance embeddings belongingto a speciﬁc class will be mapped to the corre-sponding cluster (usually modeled by a gaussiandistribution) while out-of-scope samples will be.
pushed away from all in-scope clusters.
examplesof this kind include seg (yan et al., 2020a) andlmcl (lin and xu, 2019).
very recently, zhanget al.
(2021) propose to learn adaptive decisionboundaries after pre-training instead of using off-the-shell outlier detection algorithms..in addition, some other work focuses on out-of-scope detection in few-shot scenarios.
tan et al.
(2019) leverage independent source datasets as sim-ulated ood examples to form a hinge loss term.
zhang et al.
(2020) propose to pretrain bert bya natual language understanding task with large-scale training data to transfer useful informationfor few-shot intent detection..finally, for our proposal of constructing syn-thetic outliers, the most similar method is mixupproposed by zhang et al.
(2018).
however, theirmethod is designed for data augmentation to en-hance in-distribution performance and requires cor-responding combinations in the label space (thu-lasidasan et al., 2019)..3 methodology.
problem statementin a dialogue system, givenk predeﬁned intent classes sknown = {ci}ki=1, anunknown intent detection model aims at predictingthe category of an utterance u, which may be oneof the known intents or an out-of-scope intent coos.
essentially, it is a k + 1 classiﬁcation problem atthe test stage.
at the training stage, a set of n la-beled utterances dl = {(xi, ci) | ci ∈ sknown)}ni=1is provided for training.
previous methods typicallytrain a k-way classiﬁer for the known intents..overview of our approach the mismatch be-tween the training and test tasks, i.e., k-way clas-siﬁcation vs. (k + 1)-way classiﬁcation, leads tothe use of strong assumptions and additional com-plexity in previous methods.
inspired by recentpractice in meta learning to simulate test condi-tions in training (vinyals et al., 2016), we proposeto match the training and test settings.
in essence,as shown in figure 2, we formalize a (k + 1)-wayclassiﬁcation task in the training stage by construct-ing out-of-scope samples via self-supervision andfrom open-domain data.
our method simply trainsa (k + 1)-way classiﬁer without making any as-sumption on the data distribution.
after training,the classiﬁer can be readily applied to the test taskwithout any adaptation or post-processing.
in thefollowing, we elaborate on the details of our pro-posed method, including representation learning,.
3523figure 2: an illustration of our proposed method.
we use bert as the utterance encoder.
at training stage, wetrain a (k+1)-way classiﬁer by constructing two types of pseudo outliers.
the open-domain outliers are collectedfrom an auxiliary dataset disjoint from both the training and test data.
the synthetic self-supervised outliers aregenerated during training by random convex combinations of features of inliers from different known classes..construction of pseudo outliers, and discriminativetraining..3.1 representation learning.
we employ bert (devlin et al., 2019) – a deeptransformer network as text encoder.
speciﬁcally,we take the d-dimensional output vector of the spe-cial classiﬁcation token [cls] as the representationof an utterance u, i.e.,.
h = bert(u) ∈ rd,.
where d = 768 by default.
the training setdl is then mapped to dtrl = {(hi, ci) | hi =bert(ui), (ui, ci) ∈ dl}ni=1 in the feature space..3.2 construction of outliers.
we construct two different types of pseudo outliersto be used in the training stage: synthetic outliersthat are generated by self-supervision, and open-domain outliers that can be easily acquired..synthetic outliers by self-supervision to im-prove the generalization ability of the unknown in-tent detection model, we propose to generate “hard”outliers in the feature space, which may have sim-ilar representations to the inliers of known intentclasses.
we hypothesize that those outliers maybe geometrically close to the inliers in the featurespace.
based on this assumption, we propose a self-supervised method to generate the “hard” outliersusing the training set dtrl ..speciﬁcally, in the feature space, we generatesynthetic outliers by using convex combinations ofthe features of inliers from different intent classes:.
hoos = θ ∗ hβ + (1 − θ) ∗ hα,.
(1).
where hβ and hα are the representations of twoutterances which are randomly sampled from dif-ferent intent classes in dtrl , i.e., cβ (cid:54)= cα, and hoosis the synthetic outlier.
for example, θ can besampled from a uniform distribution u (0, 1).
inthis case, when θ is close to 0 or 1, it will gen-erate “harder” outliers that only contain a smallproportion of mix-up from different classes.
inessence, “hard” outliers act like support vectorsin svm (cortes and vapnik, 1995), and “harder”outliers could help to train a more discriminativeclassiﬁer..the generated outliers hoos are assigned to theclass of coos, the (k + 1)-th class in the featurespace, forming a training set.
dtr.
co = {(hoos.
i., ci = coos)}m.i=1..(2).
notice that since the outliers are generated in thefeature space, it is very efﬁcient to construct a largeoutlier set dtrco..open-domain outliersin practical dialoguesystems, user input can be arbitrary free-form sen-tences.
to simulate real-world outliers and providelearning signals representing them in training, wepropose to construct a set of open-domain outliers,.
3524which can be easily obtained.
speciﬁcally, the setof free-form outliers df o can be constructed by col-lecting sentences from various public datasets thatare disjoint from the training and test tasks.
thereare many datasets available, including the ques-tion answering dataset squad 2.0 (rajpurkar et al.,2018), the sentiment analysis datasets yelp (menget al., 2018) and imdb (maas et al., 2011), anddialogue datasets from different domains..in the feature space, df o is mapped to dtr.
f o =i = bert(ui), ui ∈.
{(hoosidf o}h., ci = coos) | hoosi=1..both synthetic outliers and open-domain outliersare easy to construct.
as will be demonstrated insection 4, both of them are useful, but syntheticoutliers are much more effective than open-domainoutliers in improving the generalization ability ofthe trained (k + 1)-way intent classiﬁer..3.3 discriminative training.
f o, i.e., dtr = dtr.
l and two sets of outliers dtrco ∪ dtr.
after constructing the pseudo outliers, in the fea-ture space, our training set dtr now consists of aset of inliers dtrco andl ∪ dtrf o and |dtr| =dtrn + m + h. therefore, in the training stage, wecan train a (k + 1)-way classiﬁer with the intentlabel set s = sknown ∪ {coos}, which can be di-rectly applied in the test stage to identify unknownintent and classify known ones.
in particular, weuse a multilayer perceptron network, φ(·), as theclassiﬁer in the feature space.
the selection of theclassiﬁer is ﬂexible, and the only requirement isthat it is differentiable.
then, we train our modelusing a cross-entropy loss:.
l = −.
1|dtr|.
(cid:88).
dtr.
log.
(cid:80).
exp(φ(hi)ci/τ )j∈s exp(φ(hi)j/τ ).
,.
where φ(hi)ci refers to the output logit of φ(·)for the ground-truth class ci, and τ ∈ r+ is anadjustable scalar temperature parameter..4 experiments.
in this section, we present the experimental resultsof our proposed method on the targeted task of un-known intent detection.
given a test set comprisedof known and unknown intent classes, the primarygoal of an unknown intent detection model is toassign correct intent labels to utterances in the testset.
notice that the unknown intent label coos isalso included as a special class for prediction..4.1 datasets and baselines.
we evaluate our proposed method on four bench-mark datasets as follows, three of which are newlyreleased dialogue datasets designed for intent detec-tion.
the statistics of the datasets are summarizedin table 2..clinc150 (larson et al., 2019) is a datasetspecially designed for out-of-scope intent detection,which consists of 150 known intent classes from10 domains.
the dataset includes 22, 500 in-scopequeries and 1, 200 out-of-scope queries.
for thein-scope ones, we follow the original splitting, i.e.,15, 000, 3, 000 and 4, 500 for training, validation,and testing respectively.
for the out-of-scope ones,we group all of the 1, 200 queries into the test set.
stackoverﬂow (xu et al., 2015) consists of 20classes with 1, 000 examples in each class.
we fol-low the original splitting, i.e., 12, 000 for training,2, 000 for validation, and 6, 000 for test..banking (casanueva et al., 2020) is a ﬁne-grained intent detection dataset in the banking do-main.
it consists of 9, 003, 1, 000, and 3, 080 userqueries in the training, validation, and test sets re-spectively..m-cid (arora et al., 2020) is a recently releaseddataset related to covid-19.
we use the englishsubset of this dataset referred to as m-cid-en inour experiments, which covers 16 intent classes.
the splitting of m-cid-en is 1, 258 for training,148 for validation, and 339 for test..we extensively compare our method with the.
following unknown intent detection methods..softmax.
• maximumprobability(msp)(hendrycks and gimpel, 2017)employs the conﬁdence score derived fromthe maximum softmax probability to predictthe class of a sample.
the idea under thehood is that the lower the conﬁdence score is,the more likely the sample is of an unknownintent class..• doc (shu et al., 2017) considers to constructm 1-vs-rest sigmoid classiﬁers for m seenclasses respectively.
it uses the maximumprobability from these classiﬁers as the conﬁ-dence score to conduct classiﬁcation..• seg (yan et al., 2020a) models the intentdistribution as a margin-constrained gaus-sian mixture distribution and uses an addi-tional outlier detector – local outlier factor.
3525clinc150.
stackoverﬂow.
banking.
m-cid-en.
methods accuracy macro-f1 accuracy macro-f1 accuracy macro-f1 accuracy macro-f1.
25%.
50%.
75%.
mspdocseglmclsoftmaxours.
mspdocseglmclsoftmaxours.
mspdocseglmclsoftmaxours.
66.6064.4372.8668.5776.5088.44.
68.6162.4677.0578.6382.4788.33.
73.4174.6381.9284.5986.2688.08.
51.2044.6065.4462.4267.7480.73.
51.2070.0179.4280.4282.8686.67.
81.8178.6386.5788.2189.0189.43.
33.9460.6847.0041.6046.1768.74.
56.3361.6268.5064.3465.9675.08.
76.7363.9880.8380.0277.4181.71.
45.6860.5152.8348.2150.7865.64.
62.9268.9774.1871.8071.9478.55.
77.6362.0784.7884.4782.2885.85.
48.1537.7851.1152.7757.8874.11.
53.8358.2968.4463.5967.4472.69.
71.9272.0278.8778.6678.2081.07.
48.4746.3555.6856.7358.3269.93.
65.3357.3076.4873.9974.1979.21.
80.7778.0485.6685.3384.3186.98.
52.0549.3244.5141.4441.9587.08.
61.2159.9767.9163.4264.7281.05.
72.8969.7975.7377.1176.9980.24.
43.1446.5950.1446.9945.4679.67.
54.3362.2872.3769.0469.3579.73.
77.3471.1879.9780.9680.8282.75.table 1: overall accuracy and macro f1-score for unknown intent detection with different proportion of seenclasses.
for each setting, the best result is marked in bold..dataset.
vocab avg.
length samples classes.
8,376clinc150stackoverﬂow 17,1825028bankingm-cid-en1,254.
8.319.1811.96.74.
23,70020,00013,0831,745.
150207716.table 2: dataset statistics..(lof) (breunig et al., 2000) to achieve un-known intent detection..• lmcl (lin and xu, 2019) considers to learndiscriminative embeddings with a large mar-gin cosine loss.
it also uses lof as the outlierdetection algorithm..• softmax (yan et al., 2020a) uses a softmaxloss to learn discriminative features based onthe training dataset, which also requires anadditional outlier detector such as lof fordetecting the unknown intents..4.2 experimental setup and evaluation.
metrics.
to compare with existing methods, we follow thesetting in lmcl (lin and xu, 2019).
speciﬁcally,for each dataset, we randomly sample 75%, 50%,and 25% of the intent classes from the training setas the known classes to conduct training, and weset aside the rest as the unknown classes for test..notice that for training and validation, we onlyuse data within the chosen known classes and donot expose our model to any of test-time outliers.
unless otherwise speciﬁed, in each training batch,we keep the ratio of inliers, open-domain outliersand self-supervised outliers roughly as 1 : 1 : 4.this setting is empirically chosen and affected bythe memory limit of nvidia 2080ti gpu, whichwe use for conducting the experiments.
the num-ber of pseudo outliers can be adjusted accordingto different environments, and a larger number ofself-supervised outliers typically takes more timeto converge..we use pytorch (paszke et al., 2019) as the back-end to conduct the experiments.
we use the pre-trained bert mdoel (bert-base-uncased) providedby wolf et al.
(2019) as the encoder for utterances.
we use the output vector of the special classiﬁca-tion token [cls] as the utterance embedding andﬁx its dimension as 768 by default throughout allof our experiments.
to ensure a fair comparison,all baselines and our model use the same encoder..for model optimization, we use adamw pro-vided by wolf et al.
(2019) to ﬁne-tune bert andadam proposed by kingma and ba (2015) to trainthe mlp clasisﬁer φ(·).
we set the learning ratefor bert as 1e−5 as suggested by devlin et al.
(2019).
for the mlp clasisﬁer, the learning rate isﬁxed as 1e−4.
notice that the ﬁne-tuning of bert.
3526clinc150.
stackoverﬂow.
banking.
m-cid-en.
methods unknown known unknown known unknown known unknown known.
25%.
50%.
75%.
mspdocseglmclsoftmaxours.
mspdocseglmclsoftmaxours.
mspdocseglmclsoftmaxours.
73.2071.0879.9075.6183.0492.35.
57.7857.6278.0279.8984.1990.30.
57.8364.6276.1280.4283.1286.28.
50.6243.9165.0662.0167.3480.43.
68.0370.1779.4380.4282.8486.54.
82.0278.7686.6788.2889.6189.46.
22.5966.1146.1738.8545.5274.86.
35.1847.9660.8953.1256.8071.88.
41.7349.5062.3061.4054.0765.44.
50.3059.3954.1650.1551.8363.80.
70.0971.0775.5171.8073.4579.22.
80.0362.9186.2884.4784.1187.22.
49.9831.4153.2255.2962.5280.12.
29.3149.8860.4250.3060.2867.26.
23.8639.4754.4353.2656.9060.71.
48.3947.1455.8156.8158.1069.39.
66.2857.5076.9074.6274.5679.52.
81.7578.7286.2085.8984.7887.47.
56.2753.0842.7336.9935.3991.15.
58.5547.2261.0451.1156.3082.44.
39.5649.4151.5154.6158.7369.00.
37.8644.9251.9949.5046.2276.80.
53.8064.1673.8071.2970.9879.39.
80.5072.9982.3483.1682.6683.89.table 3: macro f1-score of the known classes and f1-score of the unknown class with different proportion of seenclasses.
for each setting, the best result is marked in bold..is conducted simultaneously with the training ofthe classiﬁer φ(·) with the same cross-entropy loss.
the mlp classiﬁer φ(·) has a two-layer architec-ture with [1024, 1024] as hidden units.
the tem-perature parameter τ is selected by cross-validationand set as 0.1 in all experiments..following lmcl (lin and xu, 2019), we useoverall accuracy and macro f1-score as evaluationmetrics.
all results reported in this section are theaverage of 10 runs with different random seeds,and each run is stopped until reaching a plateau onthe validation set.
for baselines, we follow theiroriginal training settings except using the afore-mentioned bert as text encoder..4.3 result analysis.
we present our main results in table 1 and table 3.speciﬁcally, table 1 gives results in overall accu-racy and macro f1-score for all classes includingthe outlier class, while table 3 shows results inmacro f1-score for the known classes and f1-scorefor the outlier class respectively.
it can be seen that,on all benchmarks and in almost every setting, ourmodel signiﬁcantly outperforms the baselines.
asshown in table 3, our method achieves favorableperformance on both unknown and known intentclasses simultaneously..it is worth mentioning that the large improve-.
ments of our method in scenarios with small la-beled training sets (25% and 50% settings) indicateits great potential in real-life applications, since apractical dialogue system often needs to deal with alarger proportion of outliers than inliers due to dif-ferent user demographic, ignorance/unfamiliarityof/with the platform, and limited intent classes rec-ognized by the system (especially at the early de-velopment stage)..more importantly, referring to table 3, as the pro-portion of known intents increases, it can be seenthat the performance gains of the baselines mainlylie in the known classes.
in contrast, our methodcan strike a better balance between the known andunknown classes without relying on additional out-lier detector, margin tuning, and threshold selection,demonstrating its high effectiveness and generality.
take the softmax baseline for example, in the 75%case of clinc150, it achieves a slightly higherresult than our model on the known classes but asubstantially lower result on the unknown ones..4.4 effect of pseudo outliers.
we conduct an ablation study on the effectivenessof the two kinds of pseudo outliers and summarizethe results in table 4. the ﬁrst row of the threesettings (25%, 50%, and 75%) stands for trainingsolely with the labeled examples of clinc150.
3527(a).
(b).
(c).
(d).
(e).
(f).
figure 3: effect of the number of pseudo outliers on clinc150.
(a), (b), and (c) display overall accuracy, f1-scoreon the unknown class and overall macro f1-score with varying number of self-supervised outliers respectively.
(d),(e), and (f) display the corresponding results with varying number of open-domain outliers..pseudo outliers separately, as shown in figure 3.we ﬁrst ﬁx the number of open-domain outliersas zero and then increase the number of self-supervised outliers.
the results are displayed infigure 3 (a), (b) and (c).
in particular, as thenumber of self-supervised outliers grows, the per-formance ﬁrst increases quickly and then growsslowly.
on the other hand, we ﬁx the number ofself-supervised outliers as zero and then increasesthe number of open-domain outliers.
the resultsare shown in figure 3 (d), (e) and (f), where itcan be seen that dozens of open-domain outliersalready can bring signiﬁcant improvements, thoughthe gain is much smaller compared to that of theself-supervised outliers..finally, we investigate the impact of the numberof self-supervised outliers on overall intent detec-tion accuracy with both the number of inliers andthe number of open-domain outliers ﬁxed as 100per training batch.
as shown in figure 4, we in-crease the number of self-supervised outliers from0 to 5000. note that 400 is the default setting usedin table 1 and table 3. we can see that compa-rable results can be obtained for a wide range ofnumbers.
however, when the number grows to5000, the performance exhibits a signiﬁcant drop.
we hypothesize that as the number increases, the.
figure 4: effect of the number of self-supervised out-liers on overall intent detection accuracy under the 75%setting of banking..without using any pseudo outliers.
in general, self-supervised synthetic outliers and open-domain out-liers both lead to positive effects on classiﬁcationperformance.
for each setting, comparing the sec-ond row with the third, we can observe that the syn-thetic outliers produced by convex combinationslead to a much larger performance gain than that ofpre-collected open-domain outliers.
finally, com-bining them for training leads to the best results, asshown in the fourth row of each setting..next, we conduct experiments to study the im-pact of varying the number of the two kinds of.
3528dtr.
co dtrf o.acc macro-f1 f1 unknown.
25%.
50%.
75%.
(cid:88).
(cid:88).
(cid:88).
(cid:88).
(cid:88).
(cid:88).
19.7981.96(cid:88) 37.55(cid:88) 88.4438.7883.12(cid:88) 48.62(cid:88) 88.3357.4384.16(cid:88) 69.61(cid:88) 88.08.
41.0571.1545.1480.73.
60.3582.6263.1986.67.
73.686.979.4289.43.
-87.836.9192.35.
-85.0328.8290.30.
-80.3648.2986.28.table 4: an ablation study on the effectiveness ofpseudo outliers..acc macro-f1.
dtrf oopen-bankopen-stackopen-big.
open-bankopen-stackopen-big.
open-bankopen-stackopen-big.
89.3688.3888.44.
87.3588.2388.33.
87.1987.5288.08.
25%.
50%.
75%.
81.2280.4280.73.
86.4186.3786.67.
89.3389.1789.43.table 5: results on clinc150 with different sets ofopen-domain outliers..generated synthetic outliers may be less accurate,because some convex combinations may fall withinthe scope of known classes..to summarize, self-supervised outliers playa much more important role than open-domainoutliers for unknown intent classiﬁcation.
self-supervised outliers not only provide better learningsignals for the unknown intents, but also imposean important positive effect on the known ones.
for the open-domain outliers, if used alone, theycan only provide limited beneﬁt.
but in combina-tion with the self-supervised ones, they can furtherenhance the performance..4.5 selection of open-domain outliers.
to demonstrate the ﬂexibility of our method inselecting open-domain outliers as described in sec-tion 3.2, we train our model on clinc150 us-ing open-domain outliers from different sources.
the results are summarized in table 5. speciﬁ-cally, open-bank and open-stack stand for using.
figure 5: comparison of training time (per epoch) andtest time with baselines..the training set of banking and stackoverﬂow asthe source of open-domain outliers respectively.
open-big stands for the source of open-domain out-liers used in other experiments, which consists of∼ 0.5 million sentences randomly selected fromsquad 2.0 (rajpurkar et al., 2018), yelp (menget al., 2018), and imdb (maas et al., 2011).
itcan be seen that the performance of our model isinsensitive to the selection of open-domain outliers..4.6 efﬁciency.
we provide a quantitative comparison on the train-ing and test efﬁciency for our method and the base-lines, by calculating the average time (in seconds)for training per epoch and the total time for test-ing under the 75% setting.
here, we only comparewith the strongest baselines.
as shown in figure 5,even with the pseudo outliers, the training time ofour method is comparable to that of the baselines.
importantly, in the test stage, our method demon-strates signiﬁcant advantages in efﬁciency, whichneeds much less time to predict intent classes forall samples in the test set..5 conclusion.
we have proposed a simple, effective, and efﬁ-cient approach for out-of-scope intent detectionby overcoming the limitation of previous methodsvia matching train-test conditions.
particularly, atthe training stage, we construct self-supervised andopen-domain outliers to improve model general-ization and simulate real outliers in the test stage.
extensive experiments on four dialogue datasetsshow that our approach signiﬁcantly outperformsstate-of-the-art methods.
in the future, we planto investigate the theoretical underpinnings of ourapproach and apply it to more applications..acknowledgments.
we would like to thank the anonymous reviewersfor their helpful comments.
this research was sup-ported by the grant hk itf uim/377..3529references.
abhinav arora, akshat shrivastava, mrinal mohit,lorena sainz-maza lecanda, and ahmed aly.
2020.cross-lingual transfer learning for intent detection ofcovid-19 utterances..markus m. breunig, hans-peter kriegel, raymond t.ng, and j¨org sander.
2000. lof: identifying density-based local outliers.
sigmod rec., 29(2):93–104..i˜nigo casanueva, tadas temcinas, daniela gerz,matthew henderson, and ivan vulic.
2020. efﬁcientintent detection with dual sentence encoders.
corr,abs/2003.04807..varun chandola, arindam banerjee, and vipin kumar.
2009. anomaly detection: a survey.
acm comput-ing surveys (csur), 41(3):1–58..corinna cortes and vladimir vapnik.
1995. support-vector networks.
machine learning, 20(3):273–297..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, naacl-hlt 2019, minneapolis, mn,usa, june 2-7, 2019, volume 1 (long and short pa-pers), pages 4171–4186.
association for computa-tional linguistics..ian j goodfellow, jean pouget-abadie, mehdi mirza,bing xu, david warde-farley, sherjil ozair, aaroncourville, and yoshua bengio.
2014. generative ad-versarial networks.
arxiv preprint arxiv:1406.2661..ian j. goodfellow, jonathon shlens, and christianszegedy.
2015. explaining and harnessing adversar-in 3rd international conference onial examples.
learning representations, iclr 2015, san diego,ca, usa, may 7-9, 2015, conference track proceed-ings..dan hendrycks, steven basart, norman mu, sauravkadavath, frank wang, evan dorundo, rahul desai,tyler zhu, samyak parajuli, mike guo, et al.
2020a.
the many faces of robustness: a critical analysisof out-of-distribution generalization.
arxiv preprintarxiv:2006.16241..dan hendrycks and kevin gimpel.
2017. a baselinefor detecting misclassiﬁed and out-of-distributionin 5th internationalexamples in neural networks.
conference on learning representations,iclr2017, toulon, france, april 24-26, 2017, confer-ence track proceedings.
openreview.net..dan hendrycks, kimin lee, and mantas mazeika.
2019. using pre-training can improve model robust-ness and uncertainty.
in proceedings of the 36th in-ternational conference on machine learning, icml2019, 9-15 june 2019, long beach, california, usa,volume 97 of proceedings of machine learning re-search, pages 2712–2721.
pmlr..dan hendrycks, xiaoyuan liu, eric wallace, adamdziedzic, rishabh krishnan, and dawn song.
2020b.
pretrained transformers improve out-of-distribution robustness.
in proceedings of the 58thannual meeting of the association for computa-tional linguistics, acl 2020, online, july 5-10,2020, pages 2744–2751.
association for computa-tional linguistics..dan hendrycks, mantas mazeika, and thomas diet-terich.
2018. deep anomaly detection with outlierexposure.
arxiv preprint arxiv:1812.04606..victoria j. hodge and jim austin.
2004. a survey ofoutlier detection methodologies.
artif.
intell.
rev.,22(2):85–126..diederik p. kingma and jimmy ba.
2015. adam: ain 3rd inter-method for stochastic optimization.
national conference on learning representations,iclr 2015, san diego, ca, usa, may 7-9, 2015,conference track proceedings..stefan larson, anish mahendran, joseph j peper,christopher clarke, andrew lee, parker hill,jonathan k kummerfeld, kevin leach, michael alaurenzano, lingjia tang, et al.
2019. an eval-uation dataset for intent classiﬁcation and out-of-scope prediction.
in proceedings of the 2019 con-ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 1311–1316..kimin lee, honglak lee, kibok lee, and jinwooshin.
2017. training conﬁdence-calibrated classi-ﬁers for detecting out-of-distribution samples.
arxivpreprint arxiv:1711.09325..shiyu liang, yixuan li, and r. srikant.
2018. en-hancing the reliability of out-of-distribution imagedetection in neural networks.
6th international con-ference on learning representations, iclr 2018 ;conference date: 30-04-2018 through 03-05-2018..ting-en lin and hua xu.
2019. deep unknown in-tent detection with margin loss.
in proceedings ofthe 57th conference of the association for compu-tational linguistics, acl 2019, florence, italy, july28- august 2, 2019, volume 1: long papers, pages5491–5496.
association for computational linguis-tics..fei tony liu, kai ming ting, and zhi-hua zhou.
2008. isolation forest.
in proceedings of the 2008eighth ieee international conference on data min-ing, icdm ’08, page 413–422, usa.
ieee com-puter society..andrew l. maas, raymond e. daly, peter t. pham,dan huang, andrew y. ng, and christopher potts.
2011. learning word vectors for sentiment analysis.
in the 49th annual meeting of the association forcomputational linguistics: human language tech-nologies, proceedings of the conference, 19-24 june,.
35302011, portland, oregon, usa, pages 142–150.
theassociation for computer linguistics..yu meng, jiaming shen, chao zhang, and jiaweihan.
2018. weakly-supervised neural text classiﬁ-in proceedings of the 27th acm interna-cation.
tional conference on information and knowledgemanagement, cikm 2018, torino, italy, october 22-26, 2018, pages 983–992.
acm..a. emin orhan.
2019..facebook’s resnext wsl models..ofabs/1907.07640..robustness propertiescorr,.
adam paszke, sam gross, francisco massa, adamlerer, james bradbury, gregory chanan, trevorkilleen, zeming lin, natalia gimelshein, lucaantiga, alban desmaison, andreas k¨opf, edwardyang, zachary devito, martin raison, alykhan te-jani, sasank chilamkurthy, benoit steiner, lu fang,py-junjie bai, and soumith chintala.
2019.torch: an imperative style, high-performance deepin advances in neural informa-learning library.
tion processing systems 32: annual conferenceon neural information processing systems 2019,neurips 2019, december 8-14, 2019, vancouver,bc, canada, pages 8024–8035..pranav rajpurkar, robin jia, and percy liang.
2018.know what you don’t know: unanswerable ques-tions for squad.
in proceedings of the 56th annualmeeting of the association for computational lin-guistics, acl 2018, melbourne, australia, july 15-20, 2018, volume 2: short papers, pages 784–789.
association for computational linguistics..peter rousseeuw and katrien driessen.
1999. a fastalgorithm for the minimum covariance determinantestimator.
technometrics, 41:212–223..lukas ruff, jacob r. kauffmann, robert a. vander-meulen, gr´egoire montavon, wojciech samek, mar-ius kloft, thomas g. dietterich, and klaus-robertm¨uller.
2021. a unifying review of deep and shal-low anomaly detection.
proc.
ieee, 109(5):756–795..seonghan ryu, seokhwan kim, junhwi choi, hwanjoyu, and gary geunbae lee.
2017. neural sentenceembedding using only in-domain sentences for out-of-domain sentence detection in dialog systems.
pat-tern recogn.
lett., 88(c):26–32..seonghan ryu, sangjun koo, hwanjo yu, andgary geunbae lee.
2018. out-of-domain detectionin pro-based on generative adversarial network.
ceedings of the 2018 conference on empirical meth-ods in natural language processing, pages 714–718, brussels, belgium.
association for computa-tional linguistics..b. sch¨olkopf, j. c. platt, j. shawe-taylor, a. j. smola,and r. c. williamson.
2001. estimating the supportof a high-dimensional distribution.
neural compu-tation, 13(7):1443–1471..lei shu, hu xu, and bing liu.
2017. doc: deep openclassiﬁcation of text documents.
in proceedings ofthe 2017 conference on empirical methods in nat-ural language processing, emnlp 2017, copen-hagen, denmark, september 9-11, 2017, pages2911–2916.
association for computational linguis-tics..ming tan, yang yu, haoyu wang, dakuo wang, sa-loni potdar, shiyu chang, and mo yu.
2019. out-of-domain detection for low-resource text classiﬁcationin proceedings of the 2019 conference ontasks.
empirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages3566–3572, hong kong, china.
association forcomputational linguistics..sunil thulasidasan, gopinath chennupati, jeff a.bilmes, tanmoy bhattacharya, and sarah michalak.
2019. on mixup training: improved calibration andpredictive uncertainty for deep neural networks.
inadvances in neural information processing systems32: annual conference on neural information pro-cessing systems 2019, neurips 2019, december 8-14, 2019, vancouver, bc, canada, pages 13888–13899..oriol vinyals, charles blundell, timothy lillicrap, ko-ray kavukcuoglu, and daan wierstra.
2016. match-ing networks for one shot learning.
in proceedingsof the 30th international conference on neural in-formation processing systems, pages 3637–3645..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, r´emi louf, morgan fun-towicz, et al.
2019. huggingface’s transformers:state-of-the-art natural language processing.
arxivpreprint arxiv:1910.03771..jiaming xu, peng wang, guanhua tian, bo xu, junzhao, fangyuan wang, and hongwei hao.
2015.short text clustering via convolutional neural net-works.
in proceedings of the 1st workshop on vec-tor space modeling for natural language process-ing, vs@naacl-hlt 2015, june 5, 2015, denver,colorado, usa, pages 62–69.
the association forcomputational linguistics..guangfeng yan, lu fan, qimai li, han liu, xiaotongzhang, xiao-ming wu, and albert y. s. lam.
2020a.
unknown intent detection using gaussian mixturemodel with an application to zero-shot intent clas-siﬁcation.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,acl 2020, online, july 5-10, 2020, pages 1050–1060. association for computational linguistics..guangfeng yan, lu fan, qimai li, han liu, xiaotongzhang, xiao-ming wu, and albert y.s.
lam.
2020b.
unknown intent detection using gaussian mixturemodel with an application to zero-shot intent clas-siﬁcation.
in proceedings of the 58th annual meet-ing of the association for computational linguistics,.
3531pages 1050–1060, online.
association for computa-tional linguistics..hanlei zhang, hua xu, and ting-en lin.
2021. deepopen intent classiﬁcation with adaptive decisionboundary.
proceedings of the aaai conference onartiﬁcial intelligence, 35(16):14374–14382..hongyi zhang, moustapha ciss´e, yann n. dauphin,and david lopez-paz.
2018. mixup: beyond empir-ical risk minimization.
in 6th international confer-ence on learning representations, iclr 2018, van-couver, bc, canada, april 30 - may 3, 2018, con-ference track proceedings.
openreview.net..jianguo zhang, kazuma hashimoto, wenhao liu,chien-sheng wu, yao wan, philip yu, richardsocher, and caiming xiong.
2020. discrimina-tive nearest neighbor few-shot intent detection bytransferring natural language inference.
in proceed-ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages5064–5082, online.
association for computationallinguistics..arthur zimek, erich schubert, and hans-peter kriegel.
2012. a survey on unsupervised outlier detection inhigh-dimensional numerical data.
statistical analy-sis and data mining: the asa data science jour-nal, 5(5):363–387..3532