hate speech detection based on sentiment knowledge sharing.
xianbing zhou1, yong yang1, xiaochao fan1∗,ge ren1, yunfeng song1, yufeng diao2, liang yang2, hongfei lin2∗1school of computer science and technology, xinjiang normal university, china2department of computer science and technology, dalian university of technology, china{1783696285, 68523593, 37769630, 236789497, 1697277502}@qq.com{diaoyufeng, liang}@mail.dlut.edu.cn, hflin@dlut.edu.cn.
abstract.
the wanton spread of hate speech on the in-ternet brings great harm to society and fami-lies.
it is urgent to establish and improve au-tomatic detection and active avoidance mecha-nisms for hate speech.
while there exist meth-ods for hate speech detection, they stereotypewords and hence suffer from inherently biasedtraining.
in other words, getting more affec-tive features from other affective resources willsignificantly affect the performance of hatespeech detection.
in this paper, we proposea hate speech detection framework based onsentiment knowledge sharing.
while extract-ing the affective features of the target sentenceitself, we make better use of the sentiment fea-tures from external resources, and finally fusefeatures from different feature extraction unitsto detect hate speech.
experimental results ontwo public datasets demonstrate the effective-ness of our model..1.introducon.
with the prevalence of mobile internet and socialmedia, phenomena such as the malicious spreadof hate speech have gradually become widespread.
this often has incalculable consequences and hasbecome a serious social problem.
how to quicklyand accurately detect hate speech automatically,and then better intervene to prevent it has becomeone of the hot research issues in the field of nat-ural language processing.
the automatic detec-tion of hate speech can prevent the viral spread ofhate speech, thereby reducing the malicious spreadof cyberbullying and harmful information.
in thefield of public opinion analysis, monitoring andintervention, hate speech detection has extensivevalue in application..in recent years, the hate speech detection hasbeen paid more attention, and many research re-sults have appeared.
however, the task is quite.
challenging due to the inherent complexity of thenatural language constructs.
most of the existingworks revolves either around rules (krause andgrassegger, 2016) or manual feature extraction(gitari et al., 2015).
rule-based methods do not in-volve learning and typically rely on a pre-compiledlist or dictionary of subjectivity clues (haralam-bous and lenca, 2014).
chen et al.
(2012) pro-posed a variety of linguistic rules to determinewhether a sentence constitutes hate speech or not.
for example, if a second-person pronoun and aderogatory word appear at the same time, such as“<you, gay>”, the sentence is judged to be insult-ing.
this type of method not only requires manualformulation of rules, but also requires dictionariesof derogatory words.
there have also been manyattempts to detect hate speech using traditional ma-chine learning methods.
mehdad and tetreault(2016) extracted the n-gram, character-level andsentiment features of text and used support vectormachines (svm) to detect hate speech.
however,artificial features can only reflect the shallow fea-tures of text and cannot understand content fromthe deep semantic features..deep learning methods have been widely usedin the field of hate speech detection and haveachieved good performance (badjatiya et al., 2019;qian et al., 2018) in recent years.
wang (2018)compared the performance of various neural net-work models in detecting hate speech and used vi-sualization techniques to give the models better in-terpretability.
the semantics of hate speech con-tains a strong negative sentiment tendency.
thedeep learning methods of predecessors often onlyused pre-trained models or deeper networks to ob-tain semantic features, ignoring the sentiment fea-tures of the target sentences and external sentimentresources, which also makes the performance ofneural networks unsatisfactory in hate speech de-tection..∗corresponding author: xiaochao fan, hongfei lin..to overcome the weaknesses of previous works,.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages7158–7166august1–6,2021.©2021associationforcomputationallinguistics7158we propose a hate speech detection frameworkbased on sentiment knowledge sharing (sks)1.our intuition is that most hate speech containswords with strong negative emotions, which areusually the most direct clues to hate speech.
mean-while, as claimed by davidson et al.
(2017), lex-ical detection methods tend to have low preci-sion because they classify all messages contain-ing particular terms as hate speech.
therefore, wehope to make better use of external sentiment re-sources so that the model can learn sentiment fea-tures and share them, which will greatly affect thein addi-performance of hate speech detection.
tion, inspired by the recent moe layer (shazeeret al., 2017) and the multi-gate mixture-of-experts(mmoe) model (ma et al., 2018), we use multiplefeature extraction units and use a gated attentionmechanism to fuse features.
the main contribu-tions of this work are summarised as follows:.
(1) in view of the lack of the use of sentiment in-formation in previous works, we not only integratethe derogatory words of target sentences into theneural network, but also use multi-task learning tomake the model learn and share external sentimentknowledge..(2) in order to better capture shared task or task-specific information, we propose a new frameworkwhich uses multiple feature extraction units whereeach extraction unit uses the multi-head attentionmechanism and a feedforward neural network toextract features, and finally uses gated attentionfuse features..(3) experimental results on the semeval-2019task-5 and davidson datasets demonstrate that ourmethod achieves state-of-the-art performance com-pared with strong baselines, and then further de-tailed examples verify the effectiveness of our pre-sented model for hate speech detection..2 related work.
hate speech is very dependent on the nuance oflanguage.
even if it is manually distinguishedwhether certain sentences contain hate seman-tics, consensus is rare (waseem, 2016).
re-cently, automatically detecting hate speech hasin thisbeen widely studied by researchers.
section, we will review related works on tra-ditional machine learning-based methods, deeplearning-based methods, and multi-task learning-based methods of hate speech detection..1code is available at https://github.com/1783696285/sks..machine learning-based methods based on fea-ture engineering are widely used in the field of hatespeech detection.
malmasi and zampieri (2018)provided empirical evidence that n-gram featuresand sentiment features can be successfully appliedto the task of hate speech detection.
rodríguezet al.
(2019) constructed a dataset of hate speechfrom facebook, and proposed a rich set of senti-ment features, including negative sentiment wordsand negative sentiment symbols, to detect hatespeech.
del vigna12 et al.
(2017) used the senti-mental value of words as the main feature to mea-sure whether a sentence constitutes hate speech.
gitari et al.
(2015) designed several sentiment fea-tures and achieved good performance in experi-ments.
previous studies have shown that sentimentfeatures play an important role in hate speech de-tection..recently, deep learning-based methods havegarnered considerable success in hate speech detec-tion.
zhang et al.
(2018) fed input into a convolu-tional neural network (cnn) and a gated recurrentunit (gru) to learn higher-level features.
kshir-sagar et al.
(2018) proposed a transformed wordembedding model (twem), which had a simplestructure but can achieve better performance thanmany complex models.
badjatiya et al.
(2019)found that due to the limitation of the training set,the deep learning model would have “bias” and hedesigned and implemented a “bias removal” strat-egy to detect hate speech.
tekiroglu et al.
(2020)constructed a large-scale dataset based on hatespeech and its responses and used the pre-trainedlanguage model, gpt-2, to detect hate speech.
ob-viously, deep learning models can extract the latentsemantic features of text, which can provide themost direct clues for detecting hate speech..multi-task learning can learn multiple relatedtasks and share knowledge at the same time.
inrecent years, there have been some achievementsin the field of hate speech detection.
kapil andekbal (2020) proposed a deep multi-task learning(mtl) framework to leverage useful informationfrom multiple related classification tasks in orderto improve the performance of hate speech detec-tion.
liu et al.
(2019) introduced a novel formu-lation of a hate speech type identification prob-lem in the setting of multi-task learning throughtheir proposed fuzzy ensemble approach.
ousid-houm et al.
(2019) presented a new multilingualmulti-aspect hate speech analysis dataset and used.
7159figure 1: the overall framework of our proposed hate speech detection based on sentiment knowledge shar-ing(sks)..it to test the current state-of-the-art multilingualmultitask learning approaches.
ousidhoum et al.
(2019) proposed bert-based multi-task learningfor offensive language detection.
some studieshave shown that multi-task learning can improvethe performance and generalization ability of mod-els in hate speech detection by using the correlationbetween the task of sentiment analysis and hatespeech detection..3 methodology.
in this section we introduce our model, sks.
ourmodel is able to improve hate speech detection byconsidering both target sentence sentiment and ex-ternal sentiment knowledge..the overall architecture of sks is shown in fig-ure 1. the framework consists mainly of three lay-ers: 1) input layer.
in order to better obtain thesentiment features of the sentence itself, we use aderogatory words dictionary to judge whether eachword is a hate word, and then append the categoryinformation to the word embedding.
2) sentimentknowledge sharing layer.
since sentiment analy-sis and hate speech detection are highly correlated,we use the multi-task learning framework to modeltask relationships and learn task-specific featuresto take advantage of shared sentiment knowledge..we use multiple feature extraction units composedof a multi-head attention layer and a feedforwardneural network.
3) gated attention layer.
a gatedattention mechanism is used to output the probabil-ity that the feature extraction unit is selected.
fi-nally, a feedforward neural network is used to de-tect hate speech..3.1 input layer.
hate speech often contains obvious negative sen-timent words because of the strong negative senti-ment..exp1: go fucking kill yourself and die already.
useless ugly pile of shit scumbag..the words “fucking”, “ugly”, and “shit scum-bag” in exp1 are all obviously insulting and offen-sive, and they contain strong negative sentiment.
obviously, whether the word in the target sentenceis a derogatory word is the most direct clue to judgehate speech.
therefore, paying attention to captur-ing derogatory words in a sentence can help us im-prove hate speech detection..word embedding.
word embedding is basedon distributed assumptions and mapped words intoa high dimension feature space and maintainingthe semantic information.
for each target sentences = {w1, w2, , wn }, we transform each token wi.
7160multi-head attentionfeed forwardmax poolingavg poolingfeed forwardmulti-head attentionfeed forwardmax poolingavg poolingfeed forwardmulti-head attentionfeed forwardmax poolingavg poolingfeed forward(cid:17)(cid:17)(cid:17)word embeddingcategory embeddinggate1feed forwardfeed forwardhate speech tasksentiment taskgate2into a real valued vector xi using word embedding,where xi ∈ rd is the word vector, d is dimensionsof word vectors..category embedding.
our work is stronglybased on the intuition that hate speech arises fromderogatory words.
in other words, some specificwords that are extremely insulting will make agreater contribution to judging hate speech.
there-fore, we have established a derogatory word dic-tionary.
the vocabulary comes from wikipedia2and another website3, including hate speech, dis-ability, lgbt, ethnic, and religious, with 5 cate-gories.
since the vocabulary contains 2 or 3 wordphrases, when judging whether it is a dirty word,we use n-gram, n ∈ [1,2,3]..the derogatory word dictionary is used to dividetweet into two categories, either containing deroga-tory words or not containing derogatory words,andthen assign the two categories to each word in thetweet.
the category of each word is initialized ran-domly as vector c = (c1, c2, , cn), ci ∈ rd′.
..since the common word embedding representa-tions exhibit a linear structure, that makes it possi-ble to meaningfully combine words by an element-wise addition of their vector representations.
in or-der to better take advantage of information withinderogatory words, we append the category repre-sentation to each word embedding.
the embed-ding of a word xi for a category embedding ci isi = xi ⊕ ci, where ⊕ is the vector concatenationxoperation..′.
3.2 sentiment knowledge sharing layer.
due to the influence of different countries, regions,religions and cultures, insulting meanings in manylanguages are hidden in the underlying semantics,rather than just reflected in sentiment words..exp2: jews are lower class pigs.
exp3: i’m so fucking ready!
there are no obvious negative sentiment wordsin exp2, but the sentence constitutes hate speech.
although “pig” is a neutral word, most peopleequate the word “pig” with stupid and clumsy.
comparing “jews” and “pig” is obviously an insultto “jews”.
latent semantics and common senseof sentiment are the keys to correctly judging thesentence.
exp3 contains the word “fucking” witha strong negative sentiment.
this word often ap-pears in hate speech.
however, in this sentence,.
2https://www.wikipedia.org/3https://www.noswearing.com/.
“fucking” does not specifically refer to a person,but is just an adverb of degree, which strengthensthe tone.
it is not hate speech.
it can be seen fromthe above example that although hate speech oftencontains negative sentiment words, only using thesentiment information of the target sentence itselfto detect hate speech often makes it difficult to ob-tain satisfactory performance..deep learning methods require a large amountof labelled data for supervised learning, whichneeds more human effort and prior knowledge ofthis particular task.
high-quality annotation datais scarce in hate speech detection, which makesthe task stereotype words and hence suffer frominherently biased training.
sentiment analysis re-search has been carried out for many years, andthere are abundant high-quality labelled datasets.
there is a high degree of correlation between twotasks, and multi-task learning can use the correla-tion between multiple tasks to improve the perfor-mance and generalization ability of the model ineach task.
therefore, we adopt a multi-task learn-ing method for sentiment knowledge sharing, so asto better extract sentiment features and apply themto hate speech detection..the framework of multi-task learning widelyuses a shared-bottom structure, and different tasksshare the bottom hidden layer.
this structure canessentially reduce the risk of overfitting, but the ef-fect may be affected by task differences and datadistribution.
we adopt the framework structure ofmix-of-expert (moe).
the moe layer has multi-ple identical feature extraction units, which sharethe output of the previous layer as input and out-puts to a successive layer.
then, the whole modelis trained in an end-to-end way.
our feature extrac-tion units layer is composed of a multi-head atten-tion layer and two feed forward neural networks..multi-head attention layer..the self-attention mechanism connects any two words ina sentence by calculating the semantic similarityand semantic features of each word in the sen-tence and other words so as to better obtain thelong-distance dependency.
the multi-head self-attention proposed by vaswani et al.
(2017) is usedin this section.
for a given query q ∈ r(n1×d1),key k ∈ r(n1×d1), value v ∈ r(n1×d1), we usethe dot product to calculate attention parameters.
the formula is as follows:.
attention(q, k, v) = softmax.
v.(1).
(.
).
qk td1.
7161where d1 is the number of hidden layer unites..the multi-head attention mechanism maps theinput vector x to query, key, and value using lin-ear changes.
in our task, key=value.
then, themodel learns the semantic features between wordsthrough the l-time attention.
for the i-th attention∈ rn1× d1head, let the parameter matrix wql ,iwkl ,wvl , we use the dotiiproduct to calculate the semantic features betweenthem:.
∈ rn1× d1.
∈ rn1× d1.
mi = attention(qwq.
i , kwk.
i , vwvi ).
(2).
the vector representation obtained by the multi-head attention mechanism is concatenated to ob-tain the final feature representation:.
h s = concat (m1, m2, .
.
.
, ml) wo.
(3).
pooling layer.
shen et al.
(2018) used maxi-mum pooling and average pooling to fuse features.
experimental results showed that the performanceof this method is significantly better than using asingle pooling strategy.
therefore, we use maxi-mum pooling and average pooling at the same time.
the formula is as follows:.
pm = pooling_max (hs).
pa = pooling_average (hs).
ps = concat (pm, pa).
(4).
(5).
(6).
3.3 gated attention.
gated attention can learn to select a subset of thefeature extraction units to use, conditioned on theinput.
for different tasks, the weight selection ofthe model is different, so each task has a gate.
theoutput of a specific gate k represents the probabil-ity of a different feature extract unit being selected,and multiple units are weighted and summed to ob-tain the final representation of the sentence, whichwill be passed into the exclusive layer of the task.
our gating unit has the same structure as the fea-ture extraction unit.
the formula is as follows:.
gk(x) = softmax (wgn ∗ gate (x)).
(7).
f k(x) =.
gk(x)ifi(x).
(8).
n∑.
i=1.
dataset.
total.
se.
11,971.dv.
24,783.sa.
31,962.classeshate (5,035)non-hate (6,936)hate (1,430)non-hate (23,353)negative(2,242)positive(29,720).
table 1: statistics of datasets used in the experiment..yk = hkf k(x).
(9).
where k is the number of tasks and h is the hiddenlayer representation..3.4 model training.
for training process, the whole parameters can beoptimized from our networks.
then, cross entropyis applied with l2 regularization as the loss func-tion, which is defined as:.
loss = −.
i log ˆyjyj.
i + λ∥θ∥2.
(10).
∑.
∑.
i.j.where i is the index of sentences, j is the index ofclass, λ is the l2 regularization term, θ is the pa-rameter set..4 experiments.
in this section, we first introduce the datasets andevaluation metrics.
then we compare the perfor-mance of our model with several strong baselines.
finally, a detailed analysis is given..4.1 datasets and evaluation metrics.
we try to explore whether sharing sentimentknowledge can improve the performance of hatetwo public hatespeech detection.
speech datasets and one sentiment dataset is usedin our experiment.
the details of the datasets areshown in table 1..therefore,.
semeval2019 task5 (se) (basile et al., 2019).
the se comes from semeval 2019 task 5, and sub-task a is hate speech detection.
the dataset isdivided into three subsets.
the training contains9000 cases, the validation contains 1000 cases, andthe test contains 2971 cases..davidson dataset (dv) (davidson et al., 2017).
the dv dataset was constructed by davidson whoimplemented a web-based bootstrapping algorithmto automatically collect a large number of hate.
7162speech examples from tweets.
this is an unbal-anced dataset with less hate speech..sentiment analysis (sa)4. the sa is a sen-timent dataset from kaggle2018.
the sa con-tains more positive cases, but fewer negative cases.
since the test set is unlabelled, we only use thetraining set..for comparison with baseline methods, accu-racy (acc) and f-measure (f1) are used as eval-uation metrics in our hate speech detection..4.2 training details.
in semeval2019 evaluation, the performance ofthe test set is the final result.
to compare with pub-lished papers, the results of the test set are used onthe dataset and we use acc and micro f1 as met-rics.
for the dv dataset, we use a 5-fold cross-validation method to measure the performance ofthe proposed model.
to compare with previousworks, we report results of dv using the standardaccuracy and weighted f1..in our experiments, for the input layer, all wordvectors are initialized by glove common crawlembeddings (840b token), and the dimension is300. the category embeddings are initialized ran-domly, and the dimension is 100. for the senti-ment knowledge sharing layer, the multi-head at-tention has 4 heads.
the first feed-forward net-work has one layer with 400 neurons and the sec-ond has two layers with 200 neurons.
the dropoutis used after each layer, and the rate is 0.1. the op-timizer is rmsprop, and the learning rate is 0.001.the models are trained by a mini-batch of 512 in-stances.
to prevent overfitting, we use the learningrate decay and early stop in the training process..4.3 comparison with baselines.
we compare our proposed model with severalstrong baselines:.
svm.
it is proposed by zhang et al.
(2018) andbasile et al.
(2019).
the author implemented sev-eral features, such as n-gram, misspellings, deroga-tory words..lstm and gru.
the method was proposed byding et al.
(2019).
lstm and gru were used toextract the features of target sentences..cnn-gru.
zhang et al.
(2018) employed wordembedding and learnt the latent semantic repre-sentations through a hybrid neural network cnn-gru..4https://www.kaggle.com/dv1453/twitter-sentiment-.
analysis-analytics-vidya.
bigru-capsule.
this baseline was proposedby ding et al.
(2019).
two-layer bigru and a cap-sule layer were used to detect hate speech..universal encoder..it was proposed by in-durthi et al.
(2019).
the author used sentence em-beddings, such as lexical vectors and deep con-textualized word representations, to detect hatespeech..bert and gpt.
they were proposed by ben-balla et al.
(2019).
the pre-trained model bertand gpt were used to capture the features to de-tect hate speech..sks.
sks is our proposed model which detectshate speech based on sentiment knowledge shar-ing..the overall performance comparison of sks isshown in table 2. from table 2, we can see that:(1) overall, the performance of the model isquite different on the two datasets.
for the dvdataset, the f1 value is about 90%, while for these dataset, the f1 value is less than 60%.
this ismainly because there are few negative examples inteh dv, and the model does not learn enough use-ful features.
furthermore, the nuance of the lan-guage can significantly affect the performance ofthe model..(2) the performance of svm based on featuresis much worse than the neural network.
espe-cially on the se dataset, performance is unaccept-able.
this indicates that the neural network canbetter capture the semantic relationships of wordsfor hate speech detection..(3) the performance of the hybrid neural net-work is better than the simple recurrent neuralnetwork (rnn).
compared with the traditionalrnns, such as lstm and so on, whether cnn-gru or bigru-capsule, its performance has asmall improvement.
by stacking a layer of a neu-ral network onto another, a deep learning modelis helpful for better learning of high-level features.
the traditional rnns, such as lstm and gru,have almost the same performance..(4) bert achieves better performance on thedv dataset.
however, both bert and gptachieve worse performance on the se dataset.
theexperimental results show that the pre-trainingmodel is very dependent on the training data.
forthe specific field, it is difficult to provide good fea-ture representations without suitable and sufficientdata..(5) our proposed method, sks, achieves the.
7163model.
svm*lstm*gru*cnn-gru*bilstm*bigru_stacked*use_svm*bert*gpt*sks.
dv.
f1(wei) acc49.255.054.062.053.556.065.3--65.9.
87.093.793.994.093.7--95.8-96.3.acc-94.594.5-94.4--94.8-95.1.sef1(macro)45.153.052.061.551.954.665.148.851.565.2.table 2: comparison with existing methods.
the results with superscript * are imported from the literature.
thebest results in each type are highlighted..model.
-sc-ssks.
dv.
acc94.094.595.1.f1(wei) acc59.661.365.9.
94.094.396.3.sef1(macro)59.361.365.2.table 3: the results of ablation experiments the bestresults in each type are highlighted..best performance for f1.
compared with otherneural networks, including lstm, gru and bil-stm, the f1 value of sks is increased by nearly3% on the dv dataset, and on the se dataset, theperformance of sks greatly improves to nearly10%.
even compared with the strong baselinemodel, universal encoder, our model is superior.
the sks is easier to implement and has fewer pa-rameters..4.4 ablation experiments.
we then analyze the influence of different partsof our model.
the results are shown in table 3,where “–sc” denotes ablation of sentiment knowl-edge sharing and the category embedding.
simi-larly, “-s” means that sentiment data is not used asinput for the model, and it only uses category em-bedding..based on the results in table 3, we can see that:1) the performance on the two datasets decreasessignificantly with the model ablation of sentimentknowledge sharing and category embedding.
how-ever, the performance of the model is better thanthe existing hybrid neural networks.
it is shownthat this framework can better learn the latent se-mantic features of the target sentence.
2) the per-.
model.
no-gatesks.
dv.
acc94.895.1.f1(wei) acc64.765.9.
95.996.3.sef1(macro)64.365.2.table 4: the influence of gated attention..formance of our model is improved slightly whenthe category embedding is used.
the main rea-son is that the information of derogatory words ishighly related to hate speech, but it will also makethe model too sensitive.
therefore, the direct ex-traction of derogatory words’ sentiment featureshas a limited impact on the performance.
3) sksoutperforms the other models, which proves theeffectiveness of sentiment knowledge sharing di-rectly..we also analyse the role of gated attention inour model.
as shown in table 4, the performanceof the model is further improved on both datasetswhen the gated attention is used.
this frameworkis able to model the task relationships in a sophisti-cated way by deciding how the separations result-ing from different gates overlap with each other(ma et al., 2018).
each gated network can learnto select which feature extraction unit is used onthe input cases.
if the tasks are highly related,then sharing knowledge will achieve better perfor-mance..4.5 the influence of the scale of sentiment.
dataset.
hate speech detection and sentiment analysis arehighly correlated, so that sentiment knowledgesharing can improve the performance of hate.
71646 acknowledgments.
we thank our anonymous reviewers for theirhelpful comments.
this work was supportedby grant from the natural science foundationof china (no.62066044, 61632011, 62076046).
this work was also supported by xinjiang uygurautonomous region natural science foundationproject no.2021d01b72 and national youth sci-ence fund project no.62006130..references.
pinkesh badjatiya, manish gupta, and vasudevavarma.
2019. stereotypical bias removal for hatespeech detection task using knowledge-based gen-eralizations.
in the world wide web conference,pages 49–59..patti,.
valerio basile, cristina bosco, elisabetta fersini,nozza debora,franciscovivianamanuel rangel pardo, paolo rosso, manuelasemeval-2019 task 5:sanguinetti, et al.
2019.multilingual detection of hate speech against immi-grants and women in twitter.
in 13th internationalworkshop on semantic evaluation, pages 54–63.
association for computational linguistics..miriam benballa, sebastien collet, and romain picot-clemente.
2019. saagie at semeval-2019 task 5:from universal text embeddings and classical fea-tures to domain-specific text classification.
in pro-ceedings of the 13th international workshop on se-mantic evaluation, pages 469–475..ying chen, yilu zhou, sencun zhu, and heng xu.
2012.detecting offensive language in social media to pro-tect adolescent online safety.
in 2012 internationalconference on privacy, security, risk and trust and2012 international confernece on social computing,pages 71–80.
ieee..thomas davidson, dana warmsley, michael macy,and ingmar weber.
2017. automated hate speechdetection and the problem of offensive language.
inproceedings of the international aaai conferenceon web and social media, volume 11..fabio del vigna12, andrea cimino23, felicedell’orletta, marinella petrocchi, and mauriziotesconi.
2017. hate me, hate me not: hate speechdetection on facebook.
in proceedings of the firstitalian conference on cybersecurity (itasec17),pages 86–95..yunxia ding, xiaobing zhou, and xuejie zhang.
2019.ynu_dyx at semeval-2019 task 5: a stacked bigrumodel based on capsule network in detection of hate.
in proceedings of the 13th international workshopon semantic evaluation, pages 535–539..njagi dennis gitari, zhang zuping, hanyurwimfuradamien, and jun long.
2015. a lexicon-based.
figure 2: the influence of the scale of sentiment dataset..speech detection.
but we cannot ignore the im-pact of the scale of the sentiment dataset on theperformance.
since the scale of the dv is similarto the sa dataset, we focus our analysis on the sedataset..as shown in figure 2, the performance of themodel is poor when the ratio of the two types ofdata is 1:2. as the ratio of sentiment data increases,the performance of the model is improved.
whenthe ratio is 2:1, the performance reaches a peak,and then maintains a declining trend.
it is observedthat the ratio of multi-task data will also directlyaffect the performance..5 conclusion and future work.
in this paper, we explore the effectiveness of multi-task learning in hate speech detection tasks.
themain idea is to use multiple feature extraction unitsto share multi-task parameters so that the modelcan better share sentiment knowledge, and thengated attention is used to fuse features for hatespeech detection.
the proposed model can makefull use of the sentiment information of the tar-get and external sentiment resources.
we showthat sentiment knowledge sharing improves sys-tem performance over the baselines and advanceshate speech detection.
finally, the detailed analy-sis further proves the validity and interpretabilityof our model..overall, our experiments give us a better under-standing of the relationship between hate speechdetection and sentiment analysis through multi-task learning.
we have laid the groundwork for fu-ture efforts in better modelling and data selection,including different types of hate speech, the typeand scale of sentiment data, and so on..7165approach for hate speech detection.
internationaljournal of multimedia and ubiquitous engineering,10(4):215–230..international conference on artificial intelligencein information and communication (icaiic), pages169–174.
ieee..noam shazeer, azalia mirhoseini, krzysztof maziarz,andy davis, quoc le, geoffrey hinton, and jeffdean.
2017. outrageously large neural networks:the sparsely-gated mixture-of-experts layer.
arxivpreprint arxiv:1701.06538..dinghan shen, guoyin wang, wenlin wang, mar-tin renqiang min, qinliang su, yizhe zhang, ri-cardo henao, and lawrence carin.
2018. on the useof word embeddings alone to represent natural lan-guage sequences..serra sinem tekiroglu, yi-ling chung, and marcoguerini.
2020. generating counter narratives againstonline hate speech: data and strategies.
arxivpreprint arxiv:2004.04216..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, lukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
arxiv preprint arxiv:1706.03762..cindy wang.
2018..interpreting neural network hatespeech classifiers.
in proceedings of the 2nd work-shop on abusive language online (alw2), pages86–92..zeerak waseem.
2016. are you a racist or am i seeingthings?
annotator influence on hate speech detectionon twitter.
in proceedings of the first workshop onnlp and computational social science, pages 138–142..ziqi zhang, david robinson, and jonathan tepper.
2018. detecting hate speech on twitter using aconvolution-gru based deep neural network.
in eu-ropean semantic web conference, pages 745–760.
springer..yannis haralambous and philippe lenca.
2014. textclassification using association rules, dependencyarxiv preprintpruning and hyperonymization.
arxiv:1407.7357..vijayasaradhi indurthi, bakhtiyar syed, manish shri-vastava, nikhil chakravartula, manish gupta, andvasudeva varma.
2019.fermi at semeval-2019task 5: using sentence embeddings to identify hatespeech against immigrants and women in twitter.
inproceedings of the 13th international workshop onsemantic evaluation, pages 70–74..prashant kapil and asif ekbal.
2020. a deep neu-ral network based multi-task learning approach tohate speech detection.
knowledge-based systems,210:106458..till krause and hannes grassegger.
2016. facebook’s.
secret rules of deletion.
süddeutsche zeitung..rohan kshirsagar, tyrus cukuvac, kathy mckeown,and susan mcgregor.
2018. predictive embeddingsfor hate speech detection on twitter.
in proceedingsof the 2nd workshop on abusive language online,emnlp 2018, brussels, belgium, pages 26–32..han liu, pete burnap, wafa alorainy, and matthew lwilliams.
2019. fuzzy multi-task learning for hatespeech type identification.
in the world wide webconference, pages 3006–3012..jiaqi ma, zhe zhao, xinyang yi, jilin chen, lichanhong, and ed h chi.
2018. modeling task re-lationships in multi-task learning with multi-gatemixture-of-experts.
in proceedings of the 24th acmsigkdd international conference on knowledgediscovery & data mining, pages 1930–1939..shervin malmasi and marcos zampieri.
2018. chal-lenges in discriminating profanity from hate speech.
journal of experimental & theoretical artificial in-telligence, 30(2):187–202..yashar mehdad and joel tetreault.
2016. do charac-ters abuse more than words?
in proceedings of the17th annual meeting of the special interest groupon discourse and dialogue, pages 299–303..nedjma ousidhoum, zizheng lin, hongming zhang,yangqiu song, and dit-yan yeung.
2019. multilin-gual and multi-aspect hate speech analysis.
arxivpreprint arxiv:1908.11049..jing qian, mai elsherief, elizabeth belding, andwilliam yang wang.
2018.hierarchical cvaefor fine-grained hate speech classification.
arxivpreprint arxiv:1809.00088..axel rodríguez, carlos argueta, and yi-ling chen.
2019. automatic detection of hate speech on face-book using sentiment and emotion analysis.
in 2019.
7166