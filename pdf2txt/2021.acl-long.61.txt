advpicker: effectively leveraging unlabeled data via adversarialdiscriminator for cross-lingual ner.
weile chen1, huiqiang jiang2, qianhui wu3, b¨orje f. karlsson4, and yi guan11harbin institute of technology, harbin, 15000, china2peking university, beijing, 100871, china3department of automation, tsinghua university, beijing, 100084, china4microsoft research, beijing, 100080, chinachen.weile7@gmail.com, jhq@pku.edu.cn, guanyi@hit.edu.cn,wuqianhui@tsinghua.org.cn, borje.karlsson@microsoft.com.
abstract.
neural methods have been shown to achievehigh performance in named entity recogni-tion (ner), but rely on costly high-quality la-beled data for training, which is not alwaysavailable across languages.
while previousworks have shown that unlabeled data in a tar-get language can be used to improve cross-lingual model performance, we propose anovel adversarial approach (advpicker) to bet-ter leverage such data and further improve re-sults.
we design an adversarial learning frame-work in which an encoder learns entity domainknowledge from labeled source-language dataand better shared features are captured via ad-versarial training - where a discriminator se-lects less language-dependent target-languagedata via similarity to the source language.
experimental results on standard benchmarkdatasets well demonstrate that the proposedmethod beneﬁts strongly from this data selec-tion process and outperforms existing state-of-the-art methods; without requiring any addi-tional external resources (e.g., gazetteers or viamachine translation).
1.
1.introduction.
named entity recognition (ner) is a fundamentalinformation extraction task, which seeks to identifynamed entities in text and classify them into pre-deﬁned entity types (such as person, organization,location, etc.)
and it is key in various downstreamtasks, e.g., question answering (moll´a et al., 2006).
neural ner models are highly successful for lan-guages with a large amount of quality annotateddata.
however, most languages don’t have enoughlabeled data to train a fully supervised model.
thismotivates research on cross-lingual transfer, whichleverages labeled data from a source language (e.g.,.
1code is publicly available at https://aka.ms/.
advpicker.
english) to address the lack of training data prob-lem in a target language.
in this paper, followingwu and dredze (2019) and wu et al.
(2020a), we fo-cus on zero-shot cross-lingual ner, where labeleddata is not available in the target language..features of.
the state-of-the-art methods for zero-shotcross-lingual ner are mainly divided into threecategories: i) feature-based methods (wu anddredze, 2019; wu et al., 2020b; pfeiffer et al.,to capture2020), which train a ner modellanguage-independentthe labeledsource-language data and then apply it to the targetlanguage; ii) translation-based methods (mayhewet al., 2017; xie et al., 2018), which build pseudotarget-language dataset via translating from labeledsource-language data and mapping entity labels;and iii) pseudo-labeling methods, which generatepseudo-labeled data for training a target-languagener model via a source-language model (wu et al.,2020a) or annotation projection (ni et al., 2017)..however, each method has its own disadvan-tages.
feature-based methods only learn the knowl-edge in the source language, but cannot leverageany target-language information.
translation-basedmethods require high-quality translation resources,which are expensive to obtain.
and pseudo-labeledmethods assume that all pseudo-labeled data is ben-eﬁcial for cross-lingual transfer learning, which isnot always the case..therefore, here we propose a novel approach– advpicker – which combines feature-based andpseudo-labeling methods, while not requiring anyextra costly resources (e.g., translation modelsor parallel data).
furthermore, to address the de-scribed problems, we enhance the source-languagener model with unlabeled target language datavia adversarialtraining.
unlike other pseudo-labeling methods, we only leverage the language-independent pseudo-labeled data selected by an ad-versarial discriminator, to alleviate overﬁtting the.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages743–753august1–6,2021.©2021associationforcomputationallinguistics743model in language-speciﬁc features of the source-language..speciﬁcally, we ﬁrst train an encoder and a nerclassiﬁer on labeled source-language data to learnentity domain knowledge.
meanwhile, a languagediscriminator and the encoder are trained on atoken-level adversarial task which enhances theability of the encoder to capture shared features.
wethen apply the encoder and the ner classiﬁer onunlabeled target-language data to generate pseudo-labels and use an adversarial discriminator to se-lect less language-speciﬁc data samples.
finally,we utilize knowledge distillation to train a target-language ner model on this selected dataset..we evaluate our proposed advpicker over 3target languages on standard benchmark datasets.
our experimental results show that the proposedmethod beneﬁts strongly from this data selectionprocess and outperforms existing sota methods;without requiring any additional external resources(e.g., gazetteers or machine translation)..our major contributions are as follows:.
• we propose a novel approach to combinefeature-based and pseudo-labeling methodsvia language adversarial learning for cross-lingual ner;.
• we adopt an adversarial discriminator to se-lect what language-independent data to lever-age in training a cross-lingual ner modelto improved performance.
to the best of ourknowledge, this is the ﬁrst successful attemptin selecting data by adversarial discriminatorfor xl-ner;.
• experiments on standard multi-lingualdatasets showcase advpicker achieves newstate-of-the-art results in cross-lingual ner..2 related work.
2.1 cross-lingual ner.
cross-lingual transfer for ner has been widelystudied in recent years.
prior works are divided intothree categories: feature-based, translation-based,and pseudo-labeling..feature-based methods generally use language-independent features to train a ner model in thelabeled source-language data, which include wordclusters (t¨ackstr¨om et al., 2012), wikiﬁer features(tsai et al., 2016), gazetteers (zirikly and hagi-wara, 2015), and aligned word representations (niet al., 2017; wu and dredze, 2019), etc.
more-over, for language-independent features, adversar-.
ial learning was applied on word/char embeddinglayers (huang et al., 2019; bari et al., 2020) orencoders (zhou et al., 2019; keung et al., 2019).
translation-based methods generally use pseudotarget-language data translated from labeled source-language data.
ni et al.
(2017) proposed to projectlabels from the source language into the target lan-guage by using word alignment information.
mostrecent methods translate the annotated corpus inthe source language to the target language word-by-word (xie et al., 2018) or phrase-by-phrase (may-hew et al., 2017) and then copy the labels for eachword/phrase to their translations.
while (jain et al.,2019) proposed to translate full sentences in thesource language and project entity labels to target-language sentences..to leverage unlabeled target-language data,pseudo-labeling methods generate the pseudo-labels by annotation projection on comparable cor-pora (ni et al., 2017) or via models trained onsource-language labeled data (wu et al., 2020a)..in this paper, we propose advpicker, an ap-proach that requires no translation and combinesfeature-based and pseudo-labeling methods.
more-over, we leverage pseudo-labeled data differentlyfrom other pseudo-labeling methods.
through ad-versarial training, we select language-independentpseudo-labeled data for training a new target-language model..2.2 language adversarial learning.
language-adversarial training (zhang et al., 2017)was proposed for the unsupervised bilingual lex-icon induction task.
and it has been applied ininducing language-independent features for cross-lingual tasks in ner (zhou et al., 2019; xie et al.,2018), text classiﬁcation (chen et al., 2019b), andsentiment classiﬁcation (chen et al., 2018)..keung et al.
(2019) proposed a multilingualbert with sentence-level adversarial learning.
however, this method does not improve cross-lingual ner performance signiﬁcantly.
to ad-dress this limitation, advpicker uses multilingualbert with token-level adversarial training forcross-lingual ner, which induces more language-independent features for each token embedding..2.3 knowledge distillation.
knowledge distillation was proposed to compressmodels (bucilu˘a et al., 2006) or ensembles of mod-els (rusu et al., 2016; hinton et al., 2015; sanhet al., 2019; mukherjee and hassan awadallah,.
7442020) via transferring knowledge from one or moremodels (teacher models) to a smaller one (studentmodel).
besides model compression, knowledgedistillation has also been applied to various tasks,like cross-modal learning (hu et al., 2020), ma-chine translation (weng et al., 2020), and auto-mated machine learning (kang et al., 2020)..in this paper, we adapt knowledge distillation toleverage unlabeled data in the cross-lingual nertask.
this helps the student model learn richer in-formation from easily obtainable data (with pseudo-labels)..3 advpicker.
in this section, we introduce our approach (ad-vpicker) which utilizes the adversarial learningapproach to select language-independent pseudo-labeled data for training an effective target-language ner model.
figure 1 illustrates theframework of the proposed advpicker.
speciﬁcally,as shown in figure 1(a), we train an encoder anda ner classiﬁer on the labeled source-languagedata.
meanwhile, a language discriminator and theencoder are trained on the token-level adversarialtask.
we then apply encoder and classiﬁer overunlabeled target-language data to generate pseudo-labels and use the adversarial discriminator to se-lect the most language-independent pseudo-labeleddata samples.
finally, we utilize knowledge distil-lation to train a target-language ner model on thisselected dataset..in the following section, we describe thelanguage-independent data selection process, in-cluding the token-level adversarial training, dataselection by the discriminator, and knowledge dis-tillation on select language-independent data..3.1 token-level adversarial training for.
cross-lingual ner.
to avoid the model overﬁtting on language-speciﬁcfeatures of the source-language, we propose thetoken-level adversarial learning (tladv) frame-work, which is shown in figure 1(a)..following keung et al.
(2019), we formulateadversarial cross-lingual ner as a multi-task prob-lem: i) ner and ii) binary language classiﬁcation(i.e source vs. target language).
for the ner task,we train the encoder and classiﬁcation layer onner annotated text in the source language.
theencoder learns to capture the ner features of the in-put sentences and then the classiﬁcation layer tries.
to predict the entity labels for each word based ontheir feature vectors..for the language classiﬁcation task, we train alanguage discriminator and an encoder on the la-beled source-language dataset and unlabeled target-language data.
the language discriminator is addedto classify whether an embedding generated by theencoder is associated to the source or the targetlanguage.
the encoder tries to produce language-independent embeddings that are difﬁcult for thelanguage discriminator to classify correctly.
we de-ﬁne the encoder, the language discriminator, andtheir objectives as follows:encoder given an input sentence x = [xi]1≤i≤nwith n words, we feed it into encoder e to obtainfeature vectors h = [hi]1≤i≤n for all words:.
h = e(x).
(1).
where e is the feature encoder which generateslanguage-independent feature vectors h for eachsentence x. following keung et al.
(2019), we usemultilingual bert as the feature encoder here anddenote the encoder as mbert-tladv.
ner classiﬁer we feed h into the ner classi-ﬁer which is a linear classiﬁcation layer with thesoftmax activation function to predict the entitylabel of token x..pθ(y ner) = softmax(w nerh + bner).
(2).
where pθ(y ner) ∈ r|c| is the probability distribu-tion of entity labels for token x and c is the entitylabel set.
w ner ∈ rde×|c| and bner ∈ r|c| de-note the to-be-learned parameters with de being thedimension of vector h.language discriminator the language discrimi-nator is comprised of two linear transformationsand a relu function for classifying token embed-ding.
the sigmoid function is used to predict theprobability of whether h belongs to the source lan-guage..pθ(y dis) = σ(w dis1 relu(w dis2h)).
(3).
where w dis1 ∈ rdd×de and w dis2 ∈ rd(cid:96)×dd,with dd being the hidden dimension of discrimina-tor and d(cid:96) the language classiﬁcation task label size.
σ is the sigmoid function to obtain the languageprobability of each word..for language-adversarial training, we have 3 lossfunctions: the encoder loss le, the language dis-criminator loss ldis, and the ner task loss lner..745figure 1: framework of the proposed advpicker.
a) overview of the token-level adversarial training process.
thelines illustrate the training ﬂows and the arrows indicate forward or backward propagation.
blue lines show theﬂow for source-language samples and grey ones are for the target language.
lner, le, and ldis are the lossesof the ner classiﬁer, encoder and discriminator modules in advpicker respectively (section 3.1).
encoder andner classiﬁer are trained together on source-language samples (blue solid lines on the left side).
encoder anddiscriminator are trained for the adversarial task (on the right side).
b) language-independent data selection onpseudo-labeled data.
c) knowledge distillation on selected data..note that we don’t add these three loss functionstogether for backward propagation.
parameters ofdifferent components in adversarial learning are al-ternatively updated based on the corresponding lossfunction, similarly to keung et al.
(2019).
specif-ically, for the ner task, the parameters of the en-coder and the ner classiﬁer are updated based onlner.
for the adversarial task, the parameters ofthe encoder are updated based on le, while theparameters of the discriminator are updated basedon ldis.
algorithm 1 shows the pseudocode forthe adversarial training process..le = −.
log pθ(y dis.
i = (cid:101)ydis.
i.
).
ldis = −.
log pθ(y dis.
+ log pθ(y dis.
i.i = ydisi = ydis.
i.
).
).
1n.1n.(cid:88).
i∈[1,n ].
(cid:88).
i∈[1,n ].
(4).
lner = −.
1n.(cid:88).
i∈[1,n ].
+ log pθ(y dis.
log pθ(y ner.
i.i.i = (cid:101)ydis= yneri.
).
).
where x is the sentence, ydis ∈ {0, 1} is theground truth label for the language classiﬁcationtask, (cid:101)ydis ∈ {0, 1} is the negative label for thelanguage classiﬁcation task, and yner ∈ rn ×|c|is the ground truth of named entity recognition taskfor corresponding input x..3.2 language-independent data selectionto obtain the pseudo labels ˆyt-ner for target-language examples, we apply the learned mbert-tladv model on the unlabeled target-languagedata xt.
however, the pseudo-labeled dataset d ={xt, ˆyt-ner} may then contain lots of language-speciﬁc samples.
we then leverage the adver-sarial discriminator to select pseudo language-independent samples from the generated set..the language discriminator tries to make theencoder unable to distinguish the language of atoken through confrontation.
in this way, the en-coder should pay more attention to features thatare less related to the source language when learn-ing the ner task.
after adversarial training, thelanguage discriminator can still correctly classifycertain embeddings with a high probability.
wedeﬁne these as language-speciﬁc samples.
othersamples are ambiguous regarding language (for ex-ample, sentences with probability close to 0.5), andthey are deﬁned as samples that are more language-independent..in order to quantify the language independenceof each sample, we use the language discriminatorto calculate the probability of whether the sentencext is from the source language pθ(y dis, xt), theformula is as follows:.
pθ(y dis, xt) = σ(w dis1 relu(w dis2ht)).
(5)where xt and ht, respectively, denote the target-.
7461nerclassifierlanguagediscriminatormbert-tladvmbert-tladv𝑥!unlabeledtarget-language examples!𝔻={𝑥!,’y!"#$%,𝒫&(𝑌’(),𝑥!
)languagediscriminatorsamples with ℓ"#$%&𝑥!*,𝒫&*(𝑌’(),𝑥!),1.00,𝑥!+,𝒫&+(𝑌’(),𝑥!),0.97,𝑥!,,𝒫&,(𝑌’(),𝑥!
),0.94,….ℓ"#$%&in top 𝜌student modelℎ’()!source language texttarget language textℒ!
"#(a) token-level adversarial training(b) data selection(c) knowledge distillationℒ"ℒ$%&ℒ’$!𝔻-./-01={𝑥-./-01!,’y-./-01!
"#$%algorithm 1 pseudocode for token-level adversar-ial training on zero-shot cross-lingual ner.
require: training set de = ddis = {(x, ydis)}and dner = {(x, yner)}, batch size bs = 1for clarity, batch number b, the output proba-bility of model pθ(y m), the hidden vector ofmodel h..1: initialize hidden vector of w ∗, b∗;2: for i = 1, · · · , b do3:.
for model m in {ner, e, dis} dosample batch (x, y) ∈ dm;# calculate model hidden vector;h = e(x), refer to equ(1)if model m equal to model ner then.
calculate pθ(y ner), eq.(2).
else.
calculate pθ(y dis), eq.(3).
end ifcalculate model loss lm using x, y andpθ(y m), eq.
(4)update parameters of embeddings w.r.t.
the gradients using ∇lm with parame-ters w m, bm and the encoder e (if m in{ner, e})..4:.
5:.
6:.
7:.
8:.
9:.
10:.
11:.
12:.
13:.
end for.
14:15: end for.
language sentence and its feature vector, andpθ(y dis, xt) is the probability of xt mentionedin eq.
( 3)..in order to select from the pseudo-labeled data,we design an index (cid:96)score to represent the languageindependence of a sentence xt (the degree ofmodel confusion on different languages).
we as-sume it follows a uniform distribution and reachesits maximum when pθ(y dis, xt) = 0.5. con-versely, the index is at its minimal value whenpθ(y dis, xt) is equal to 0 or 1..(cid:96)score(xt) = 1 − (cid:13).
(cid:13)pθ(y dis, xt) − 0.5(cid:13)(cid:13).
(6).
we select target-language samples with the high-est (cid:96)score in the top ρ as language-independentdata.
ρ is a hyper-parameter which is the dataratio of pseudo-labeled data.
finally, we obtainthe selected target-language pseudo-labeled datasetdsubset = {xtsubset }, a subset of target lan-guage pseudo-labeled dataset..subset, ˆyt-ner.
there are two reasons for selecting language-independent samples by the language discrimina-tor.
first, these samples’ feature vectors contain.
less language-speciﬁc information which is help-ful for cross-lingual transfer learning.
second, thener classiﬁer is trained on source-language la-beled data.
therefore, it is more likely to generatehigh-quality predictive labels on selected target-language samples that have similar feature vectorsto source-language samples..3.3 knowledge distillation on.
language-independent data.
to leverage such less language-dependent data, wetrain a target-language ner model on the selectedpseudo-labeled data dsubset.
considering a lot ofhelpful information can be carried in soft targetsinstead of hard targets (hinton et al., 2015), we usethe soft labels of the selected pseudo-data to traina student model htstu via knowledge distillation.
to construct the student model, we used the pre-trained cased multilingual bert(mbert) (devlinet al., 2019) as the initialization and a linear layerwith softmax function:.
pθ(y t-ner) = softmax(w t-nerht.
stu + bt-ner)(7)where pθ(y t-ner) is the distribution of entity la-bels probability output from the student model.
w t-ner ∈ rds×|c| and bt-ner ∈ r|c| are learn-able parameters of the student ner model..following wu et al.
(2020a), the loss functionlkd is deﬁned as the mean squared error (mse)between the prediction output pθ(y t-ner) and thesoft labels of the selected data, which is formulatedas:.
lkd =.
1n.(cid:88).
i∈[1,n ].
(pθ(y t-ner) − ˆyt-ner.
subset )2.
(8).
subset ∈ dsubset are the selected soft la-where ˆyt-nerbels with n tokens and pθ(y t-ner) is the predic-tion probability of the selected sentence xt.
byminimizing the mse loss, the student model istrained supervised on the target-language selecteddata pseudo-labels..for inference in the target language, we onlyapply the student model on test cases to predictthe probability distribution of entity labels for eachtoken in sentences, as eq.(7).
to ensure the entitylabels follow the ner tagging scheme, the predic-tion result is generated by viterbi decoding (chenet al., 2019a)..747language.
type.
train dev test.
english [en](conll-2003)german [de](conll-2003)spanish [es](conll-2002)dutch [nl](conll-2002).
# of entity.
# of entity.
# of sentence 14,987 3,466 3,68423,499 5,942 5,648# of sentence 12,705 3,068 3,16011,851 4,833 3,673# of sentence 8,323 1,915 1,51718,798 4,351 3,558# of sentence 15,806 2,895 5,19513,344 2,616 3,941.
# of entity.
# of entity.
table 1: statistics of the benchmark datasets..4 experiments.
4.1 experiment settings.
datasetswe conduct experiments in 4 different languages:english [en], spanish [es], dutch [nl], german [de].
spanish and dutch data is from the conll-2002ner shared task (tjong kim sang, 2002a)2, whileenglish and german are from conll-2003 (tjongkim sang, 2002b)3. table 1 presents some basicstatistics of the datasets used in our experiments..conll-2002/2003 data uses gold standard la-belling and it is tagged with four entity types:per, loc, org, and misc.
following wuand dredze (2019), we use the bio labelingscheme (farber et al., 2008) and the ofﬁcial splitof train/validation/test sets.
as previous works(t¨ackstr¨om et al., 2012; jain et al., 2019; wu et al.,2020b), for all experiments, we always use englishas source language and the others as target lan-guages.
our models are trained on the training setof english and evaluated on the test sets of eachtarget language..note that for each target language, we only usetext in its training set to train our model with theseunlabeled target language data.
in adversarial learn-ing, we randomly sample data from all target lan-guages and construct a target-language dataset ofthe same size as the english training dataset..implementation detailswe implement advpicker using pytorch 1.6.0. fordata pre-processing, we leverage wordpiece (wuet al., 2016) to tokenize each sentence into a se-quence of sub-words which are then fed into themodel.
for the encoder (i.e.
e in eq.
(1)) and stu-dent model (i.e.
htstu in eq.
(7)), we employ the.
2https://www.clips.uantwerpen.be/conll2002/ner/3https://www.clips.uantwerpen.be/conll2003/ner/.
pre-trained cased multilingual bert in hugging-face’s transformers (wolf et al., 2020)4 as back-bone model, which has 12 transformer blocks, 12attention heads, and 768 hidden units..we empirically select.
the following hyper-parameters.
speciﬁcally, referring to the settingsof wu et al.
(2020b), we freeze the parameters ofthe embedding layer and the bottom three layers ofthe multilingual bert used in the encoder and thener student model.
we train all models using abatch size of 32, maximum sequence length of 128,a dropout rate of 0.1, and use adamw (loshchilovand hutter, 2019) as optimizer.
for sequence pre-diction, we apply viterbi decoding (chen et al.,2019a) on all models in our experiments..following keung et al.
(2020), in all experimentsthe other hyper-parameters are tuned on each targetlanguage dev set.
we train all models for 10 epochsand choose the best model checkpoint with thetarget dev set.
for adversarial learning, we set thelearning rate of 6e-5 for the ner loss lner and6e-7 for both loss encoder le and discriminatorloss ldis.
for knowledge distillation, we use alearning rate of 6e-5 for the student models.
weset the hidden dimension of the discriminator as500. for data selection, ρ is set to 0.8. followingtjong kim sang (2002a), we use the entity level f1-score as evaluation metric.
moreover, experimentsare repeated 5 times for different random seeds oneach corpus..note that the selected data from the discrimina-tor is generated by combination of output frommbert-tladvs with different random seeds,as we observe only a small number of sampleswith high (cid:96)score in the selected data generated byeach model.
speciﬁcally, for each target-languagesentence xt, there are 5 corresponding soft la-bel sequences generated from 5 different mbert-tladv models.
from those, only sequences thathave the highest sum of each predicted label conﬁ-dence are kept..our models are trained on a tesla p100 gpu(16gb).
mbert-tladv has 178m parametersand trains in ≈130min, while the student modelshtstu have 177m parameters and take ≈21min..4.2 comparison with state-of-the-art.
results.
table 2 reports the zero-shot cross-lingual ner re-sults of different methods on the 3 target languages..4https://github.com/huggingface.
748model.
t¨ackstr¨om et al.
(2012)tsai et al.
(2016)ni et al.
(2017)mayhew et al.
(2017)xie et al.
(2018)jain et al.
(2019)bari et al.
(2020)wu and dredze (2019)keung et al.
(2019)wu et al.
(2020b)wu et al.
(2020a)*mbert-ftmbert-tladvadvpicker.
de.
40.4048.1258.5057.2357.7661.565.2469.5671.973.16.es.
59.3060.5565.1064.1072.3773.575.9374.9674.376.75.nl.
58.4061.5665.4063.3771.2569.974.6177.5777.680.44.avg.
52.7056.7463.0061.5767.1368.3071.9373.5774.6076.78.
81.2 ± 0.83 77.37 ± 0.6773.61 ± 0.39 77.3 ± 0.7872.59 ± 0.31 75.12 ± 0.83 80.34 ± 0.27 76.02 ± 0.4773.89 ± 0.56 76.92 ± 0.62 80.62 ± 0.56 77.14 ± 0.5875.01 ± 0.50 79.00 ± 0.21 82.90 ± 0.44 78.97 ± 0.38.table 2: results of our approach and prior state-of-the-art methods for zero-shot cross-lingual ner.
* denotes theversion of the method without additional data..these include advpicker, prior sota methods,and two re-implemented baseline methods, i.e.,mbert-tladv (section 3.1) and mbert-ft(mbert ﬁne-tuned on labeled source-languagedata).
note that some existing methods use thetranslation model as an additional data transfersource, whereas our method does not.
for a faircomparison, we compare against the version ofunitrans (wu et al., 2020a) w/o translation (as re-ported in their paper).
our method outperformsthe existing methods with f1-scores of 75.01,79.90, and 82.90, when using only source-languagelabeled data and target-language unlabeled data.
particularly, compared with unitrans* (previoussota), advpicker achieves an improvement off1-score ranging from 1.41 in german to 1.71 indutch.
furthermore, our result is comparable tothe full unitrans using also translation (0.04 f1difference on average)..besides, advpicker achieves an average f1-score improvement of 1.83 over mbert-tladvand 2.95 over mbert-ft. these results well demon-strate the effectiveness of the proposed approach,which is mainly attributed to more effectively lever-aging unlabeled target language data and selectingthe language-independent data for cross-lingualtransfer..de.
es.
nl.
avg.
mbert99.08 99.66 98.98 99.2498.38 98.66 97.27 98.10mbert-ftmbert-tladv 79.62 82.89 77.45 79.99.table 3: accuracy of discriminators for different mod-els in the three target languages..language selected other ∆.
deesnlavg.
77.8776.4584.3379.55.
63.83 14.0469.237.2266.97 17.3666.68 12.87.table 4: teacher model f1 scores over target languagetraining sets, w/o adversarial approach and distillation..data type.
de.
es.
nl.
total.
selected data 9733 6724 12668 291257283other data.
2434 1681 3168.table 5: sentence numbers of the selected/other splitsin the target language training sets..4.3 quality of selected data.
language-independence we use the selecteddataset dsubset to train student models via knowl-edge distillation.
pθ(y t-ner) in dsubset is calcu-.
lated over feature vectors generated by mbert-tladv.
to validate the language-independence ofthese feature vectors, we apply three discrimina-tors deﬁned as in eq.
(3) to classify the token fea-.
749ture vectors from three different encoders: mbert,mbert-ft, and mbert-tladv..unlike in the adversarial learning setting, we ﬁxthe parameters of the three encoders and only trainthe discriminators.
we use each language trainingset to train discriminators and evaluate on eachtarget language corresponding test set.
table 3 re-ports the discriminator accuracy for 3 differentencoders.
we can see that the classiﬁcation accu-racy is reduced with adversarial training, whichsuggests that the similarity of feature vectors be-tween the source language and the target languageis improved; which further demonstrates the fea-ture vectors become more language-independentwhen adversarial training is applied.
pseudo labels to evaluatelanguage-independent quality of pseudo labels, we calculatethe f1 scores of the pseudo labels and the numberof sentences involved.
we denote language-independent data and language-speciﬁc data as“selected data” and “other data” respectively..the.
table 4 reports the pseudo labels f1 scoresof both language-independent data and language-language usingspeciﬁc data for each targetmbert-tladv.
generally, the average f1 scoreof language-independent data is 12.87 pointshigher than language-speciﬁc data, which suggeststhat language-independent data has higher qual-ity pseudo-labels.
furthermore, the selected datacontains less language-speciﬁc information..table 5 reports the number of.
language-independent and language-speciﬁc examples foreach language.
from these results (tables 4, 5), weobserve that the selected data is still high-quality,even if we set a very loose threshold (80% of unla-beled data being selected)..4.4 model performance over selected/other.
data splits.
in order to better analyse the behaviour of ad-vpicker across data variations, we use the trainedlanguage discriminator to split the target languagetest sets into selected and other partitions (simi-larly to how the training set is processed).
table7 shows the different models’s f1 scores for thepartitioned data..from table 7, we can draw these conclusions:1) as expected, models perform better over se-.
lected data than over other data;.
2) advpicker is only trained on selected data,but nonetheless outperforms all baseline models in.
both data partitions;.
3) advpicker’s approach effectively selects ex-amples with better features and is not over-biasedtowards selected data..4.5 ablation study.
to validate the contributions of different processin the proposed advpicker, we introduce the fol-lowing variants of advpicker and baselines to per-form an ablation study: 1) advpicker w/o kd,which directly combines the prediction of test datafrom mbert-tladvs with different seeds withoutknowledge distillation on pseudo-labeled trainingdata.
2) advpicker w all-data, which trains a stu-dent model on all target-language pseudo-labeleddata generated by mbert-tladv.
3) mbert-ft,mbert ﬁne-tuned on source-language labeleddata.
4) mbert-tladv (section 3.1), meaningmbert trained on source-language labeled datawith token-level adversarial learning..table 6 reports the performance of each methodand their performance drops compared to ad-vpicker.
moreover, we can draw more in-depthobservations as follows:.
1) comparing advpicker with advpicker w/okd and advpicker w all-data, we can see thatselecting the language-independent data is reason-able.
that also validates the effectiveness of themodel trained on language-independent data viaknowledge distillation..2) mbert-ft outperforms mbert-tladv.
suchresults well demonstrate that token-level adver-sarial learning is helpful to train a language-independent feature encoder and brings perfor-mance improvement..3) by comparing the f1 scores of advpicker wall-data and advpicker on the target languages, weobserve that training on selected data brings higherperformance improvements on larger datasets, e.g.,german [de] and dutch [nl], and lower improve-ments on the smaller spanish [es] dataset.
al-though selected data has high-quality pseudo la-bels, smaller sizes of selected datasets may limitperformance improvements..4.6 stability analysis.
because bert ﬁne-tuning is known to be unsta-ble in few-shot tasks, as discussed in zhang et al.
(2021).
mbert-based methods’ performances onthe conll ner dataset are likely also unstable.
to evaluate the stability of advpicker, we compare.
750model.
de.
es.
nl.
avg.
75.02.advpicker72.59 (-2.43) 75.12 (-3.88) 80.34 (-2.56) 76.02 (-2.95)mbert-ft73.89 (-1.13) 76.92 (-2.08) 80.62 (-2.28) 77.14 (-1.83)mbert-tladvadvpicker w/o kd73.98 (-1.04) 77.91 (-1.09) 80.55 (-2.35) 77.48 (-1.49)advpicker w all-data 74.02 (-1.00) 78.72 (-0.28) 80.69 (-2.21) 77.81 (-1.16).
78.97.
82.90.
79.00.table 6: ablation study for the proposed advpicker, where numbers in parenthesis denote performance change..methods.
de (selected) de (other) es (selected) es (other) nl (selected) nl (other).
mbert-ftmbert-tladvunitrans w/o translationadvpicker.
73.6574.0574.4875.11.
70.6672.4971.7173.76.
77.2978.0477.2979.19.
70.3973.8673.1875.68.
81.6781.8383.1584.19.
69.8977.8970.3979.15.table 7: f1 scores over the select/other test set splits in different target languages.
advpicker has better perfor-mance also on other data for all languages..the standard deviation of f1 scores for mbert-ft,unitrans, and advpicker..table 2 includes the standard deviation of f1scores over ﬁve runs for each model.
advpickerhas a lower average standard deviation in the threetarget languages than the other mbert-based meth-ods.
such results demonstrate that selected data canbring a degree of stability to the model, or limitinstability, as the student model in advpicker istrained on selected data with the soft labels fromother trained models..5 conclusion.
in this paper, we propose a novel approach to com-bine the feature-based method and pseudo labelingvia language adversarial learning for cross-lingualner.
advpicker is the ﬁrst successful attempt inselecting language-independent data by adversarialdiscriminator to cross-lingual ner.
our experi-mental results show that the proposed system bene-ﬁts strongly from this new data selection processand outperforms existing state-of-the-art methods,even without requiring additional extra resources..references.
m. saiful bari, shaﬁq r. joty, and prathyusha jwalapu-ram.
2020. zero-resource cross-lingual named en-in the thirty-fourth aaai con-tity recognition.
ference on artiﬁcial intelligence, aaai 2020, thethirty-second innovative applications of artiﬁcialintelligence conference, iaai 2020, the tenth aaai.
symposium on educational advances in artiﬁcial in-telligence, eaai 2020, new york, ny, usa, febru-ary 7-12, 2020, pages 7415–7423.
aaai press..cristian bucilu˘a, rich caruana, and alexandruniculescu-mizil.
2006. model compression.
in pro-ceedings of the 12th acm sigkdd internationalconference on knowledge discovery and data min-ing, pages 535–541..hui chen, zijia lin, guiguang ding, jian-guang lou,yusen zhang, and b¨orje f. karlsson.
2019a.
grn:gated relation network to enhance convolutionalneural network for named entity recognition.
in thethirty-third aaai conference on artiﬁcial intelli-gence, aaai 2019, the thirty-first innovative ap-plications of artiﬁcial intelligence conference, iaai2019, the ninth aaai symposium on educationaladvances in artiﬁcial intelligence, eaai 2019, hon-olulu, hawaii, usa, january 27 - february 1, 2019,pages 6236–6243.
aaai press..xilun chen, ahmed hassan awadallah, hany has-san, wei wang, and claire cardie.
2019b.
multi-source cross-lingual model transfer: learning whatto share.
in proceedings of the 57th annual meet-ing of the association for computational linguis-tics, pages 3098–3112, florence, italy.
associationfor computational linguistics..xilun chen, yu sun, ben athiwaratkun, claire cardie,and kilian weinberger.
2018. adversarial deep av-eraging networks for cross-lingual sentiment classi-ﬁcation.
transactions of the association for compu-tational linguistics, 6:557–570..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding..751of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..benjamin farber, dayne freitag, nizar habash, andimproving ner in arabicowen rambow.
2008.in proceedings ofusing a morphological tagger.
the sixth international conference on language re-sources and evaluation (lrec’08), marrakech, mo-rocco.
european language resources association(elra)..geoffrey hinton, oriol vinyals, and jeff dean.
2015.distilling the knowledge in a neural network.
arxivpreprint arxiv:1503.02531..hengtong hu, lingxi xie, richang hong, and qi tian.
2020. creating something from nothing: unsuper-vised knowledge distillation for cross-modal hash-in 2020 ieee/cvf conference on computering.
vision and pattern recognition, cvpr 2020, seat-tle, wa, usa, june 13-19, 2020, pages 3120–3129.
ieee..lifu huang, heng ji, and jonathan may.
2019. cross-lingual multi-level adversarial transfer to enhancein proceedings of thelow-resource name tagging.
2019 conference of the north american chapter ofthe association for computational linguistics: hu-man language technologies, volume 1 (long andshort papers), pages 3823–3833, minneapolis, min-nesota.
association for computational linguistics..alankar jain, bhargavi paranjape, and zachary c. lip-ton.
2019. entity projection via machine transla-in proceedings of thetion for cross-lingual ner.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 1083–1092, hong kong,china.
association for computational linguistics..minsoo kang, jonghwan mun, and bohyung han.
2020. towards oracle knowledge distillation within the thirty-fourthneural architecture search.
aaai conference on artiﬁcial intelligence, aaai2020, the thirty-second innovative applications ofartiﬁcial intelligence conference, iaai 2020, thetenth aaai symposium on educational advancesin artiﬁcial intelligence, eaai 2020, new york, ny,usa, february 7-12, 2020, pages 4404–4411.
aaaipress..phillip keung, yichao lu, and vikas bhardwaj.
2019.adversarial learning with contextual embeddings forzero-resource cross-lingual classiﬁcation and ner.
in proceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 1355–1360, hong kong, china.
association for computa-tional linguistics..phillip keung, yichao lu, julian salazar, and vikasbhardwaj.
2020. don’t use english dev: on thezero-shot cross-lingual evaluation of contextual em-beddings.
in proceedings of the 2020 conference onempirical methods in natural language processing(emnlp), pages 549–554, online.
association forcomputational linguistics..ilya loshchilov and frank hutter.
2019. decou-in 7th inter-pled weight decay regularization.
national conference on learning representations,iclr 2019, new orleans, la, usa, may 6-9, 2019.openreview.net..stephen mayhew, chen-tse tsai, and dan roth.
2017.cheap translation for cross-lingual named entityrecognition.
in proceedings of the 2017 conferenceon empirical methods in natural language process-ing, pages 2536–2545, copenhagen, denmark.
as-sociation for computational linguistics..diego moll´a, menno van zaanen, and daniel smith.
2006. named entity recognition for question an-in proceedings of the australasian lan-swering.
guage technology workshop 2006, pages 51–58,sydney, australia..subhabrata mukherjee and ahmed hassan awadallah.
2020. xtremedistil: multi-stage distillation for mas-in proceedings of thesive multilingual models.
58th annual meeting of the association for compu-tational linguistics, pages 2221–2234, online.
as-sociation for computational linguistics..jian ni, georgiana dinu, and radu florian.
2017.weakly supervised cross-lingual named entity recog-nition via effective annotation and representationprojection.
in proceedings of the 55th annual meet-ing of the association for computational linguistics(volume 1: long papers), pages 1470–1480, vancou-ver, canada.
association for computational linguis-tics..jonas pfeiffer, ivan vuli´c, iryna gurevych, and se-bastian ruder.
2020. mad-x: an adapter-basedframework for multi-task cross-lingual transfer.
in proceedings of the 2020 conference on empiricalmethods in natural language processing (emnlp),pages 7654–7673, online.
association for computa-tional linguistics..andrei a. rusu, sergio gomez colmenarejo, c¸ aglarg¨ulc¸ehre, guillaume desjardins,james kirk-patrick, razvan pascanu, volodymyr mnih, koraykavukcuoglu, and raia hadsell.
2016.policyin 4th international conference ondistillation.
learning representations, iclr 2016, san juan,puerto rico, may 2-4, 2016, conference trackproceedings..victor sanh, lysandre debut, julien chaumond, andthomas wolf.
2019. distilbert, a distilled version ofbert: smaller, faster, cheaper and lighter.
in pro-ceedings of the neurips workshop on energy efﬁ-cient machine learning and cognitive computing(emc2)..752bert.
in proceedings of the 2019 conference onempirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages833–844, hong kong, china.
association for com-putational linguistics..yonghui wu, mike schuster, zhifeng chen, quoc v le,mohammad norouzi, wolfgang macherey, maximkrikun, yuan cao, qin gao, klaus macherey, et al.
2016. google’s neural machine translation system:bridging the gap between human and machine trans-lation.
arxiv preprint arxiv:1609.08144..jiateng xie, zhilin yang, graham neubig, noah a.smith, and jaime carbonell.
2018. neural cross-lingual named entity recognition with minimal re-sources.
in proceedings of the 2018 conference onempirical methods in natural language processing,pages 369–379, brussels, belgium.
association forcomputational linguistics..meng zhang, yang liu, huanbo luan, and maosongsun.
2017. adversarial training for unsupervisedin proceedings of thebilingual lexicon induction.
55th annual meeting of the association for com-putational linguistics (volume 1: long papers),pages 1959–1970, vancouver, canada.
associationfor computational linguistics..tianyi zhang, felix wu, arzoo katiyar, kilian qweinberger, and yoav artzi.
2021. revisiting few-sample bert ﬁne-tuning.
in international confer-ence on learning representations..joey tianyi zhou, hao zhang, di jin, hongyuan zhu,meng fang, rick siow mong goh, and kennethkwok.
2019. dual adversarial neural transfer forlow-resource named entity recognition.
in proceed-ings of the 57th annual meeting of the associationfor computational linguistics, pages 3461–3471,florence, italy.
association for computational lin-guistics..ayah zirikly and masato hagiwara.
2015. cross-lingual transfer of named entity recognizers withoutin proceedings of the 53rd an-parallel corpora.
nual meeting of the association for computationallinguistics and the 7th international joint confer-ence on natural language processing (volume 2:short papers), pages 390–396, beijing, china.
as-sociation for computational linguistics..oscar t¨ackstr¨om, ryan mcdonald, and jakob uszko-reit.
2012. cross-lingual word clusters for directin proceedings oftransfer of linguistic structure.
the 2012 conference of the north american chap-ter of the association for computational linguis-tics: human language technologies, pages 477–487, montr´eal, canada.
association for computa-tional linguistics..erik f. tjong kim sang.
2002a..introduction to theconll-2002 shared task: language-independentnamed entity recognition.
in coling-02: the 6thconference on natural language learning 2002(conll-2002)..erik f. tjong kim sang.
2002b..introduction to theconll-2002 shared task: language-independentnamed entity recognition.
in coling-02: the 6thconference on natural language learning 2002(conll-2002)..chen-tse tsai, stephen mayhew, and dan roth.
2016.cross-lingual named entity recognition via wikiﬁ-in proceedings of the 20th signll con-cation.
ference on computational natural language learn-ing, pages 219–228, berlin, germany.
associationfor computational linguistics..rongxiang weng, heng yu, shujian huang, shanbocheng, and weihua luo.
2020. acquiring knowl-edge from pre-trained modelto neural machinetranslation.
in proceedings of the aaai conferenceon artiﬁcial intelligence, volume 34, pages 9266–9273..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, remi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander rush.
2020. trans-formers: state-of-the-art natural language process-ing.
in proceedings of the 2020 conference on em-pirical methods in natural language processing:system demonstrations, pages 38–45, online.
asso-ciation for computational linguistics..qianhui wu, zijia lin, b¨orje f. karlsson, biqinghuang, and jian-guang lou.
2020a.
unitrans: uni-fying model transfer and data transfer for cross-lingual named entity recognition with unlabeledin proceedings of the twenty-ninth interna-data.
tional joint conference on artiﬁcial intelligence, ij-cai 2020, pages 3926–3932.
ijcai.org..qianhui wu, zijia lin, guoxin wang, hui chen,b¨orje f. karlsson, biqing huang, and chin-yew lin.
2020b.
enhanced meta-learning for cross-lingualnamed entity recognition with minimal resources.
inproceedings of the aaai conference on artiﬁcial in-telligence, volume 34, pages 9274–9281..shijie wu and mark dredze.
2019. beto, bentz, be-cas: the surprising cross-lingual effectiveness of.
753