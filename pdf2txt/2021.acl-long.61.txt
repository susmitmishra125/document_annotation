advpicker: effectively leveraging unlabeled data via adversarialdiscriminator for cross-lingual ner.
weile chen1, huiqiang jiang2, qianhui wu3, bÂ¨orje f. karlsson4, and yi guan11harbin institute of technology, harbin, 15000, china2peking university, beijing, 100871, china3department of automation, tsinghua university, beijing, 100084, china4microsoft research, beijing, 100080, chinachen.weile7@gmail.com, jhq@pku.edu.cn, guanyi@hit.edu.cn,wuqianhui@tsinghua.org.cn, borje.karlsson@microsoft.com.
abstract.
neural methods have been shown to achievehigh performance in named entity recogni-tion (ner), but rely on costly high-quality la-beled data for training, which is not alwaysavailable across languages.
while previousworks have shown that unlabeled data in a tar-get language can be used to improve cross-lingual model performance, we propose anovel adversarial approach (advpicker) to bet-ter leverage such data and further improve re-sults.
we design an adversarial learning frame-work in which an encoder learns entity domainknowledge from labeled source-language dataand better shared features are captured via ad-versarial training - where a discriminator se-lects less language-dependent target-languagedata via similarity to the source language.
experimental results on standard benchmarkdatasets well demonstrate that the proposedmethod beneï¬ts strongly from this data selec-tion process and outperforms existing state-of-the-art methods; without requiring any addi-tional external resources (e.g., gazetteers or viamachine translation).
1.
1.introduction.
named entity recognition (ner) is a fundamentalinformation extraction task, which seeks to identifynamed entities in text and classify them into pre-deï¬ned entity types (such as person, organization,location, etc.)
and it is key in various downstreamtasks, e.g., question answering (mollÂ´a et al., 2006).
neural ner models are highly successful for lan-guages with a large amount of quality annotateddata.
however, most languages donâ€™t have enoughlabeled data to train a fully supervised model.
thismotivates research on cross-lingual transfer, whichleverages labeled data from a source language (e.g.,.
1code is publicly available at https://aka.ms/.
advpicker.
english) to address the lack of training data prob-lem in a target language.
in this paper, followingwu and dredze (2019) and wu et al.
(2020a), we fo-cus on zero-shot cross-lingual ner, where labeleddata is not available in the target language..features of.
the state-of-the-art methods for zero-shotcross-lingual ner are mainly divided into threecategories: i) feature-based methods (wu anddredze, 2019; wu et al., 2020b; pfeiffer et al.,to capture2020), which train a ner modellanguage-independentthe labeledsource-language data and then apply it to the targetlanguage; ii) translation-based methods (mayhewet al., 2017; xie et al., 2018), which build pseudotarget-language dataset via translating from labeledsource-language data and mapping entity labels;and iii) pseudo-labeling methods, which generatepseudo-labeled data for training a target-languagener model via a source-language model (wu et al.,2020a) or annotation projection (ni et al., 2017)..however, each method has its own disadvan-tages.
feature-based methods only learn the knowl-edge in the source language, but cannot leverageany target-language information.
translation-basedmethods require high-quality translation resources,which are expensive to obtain.
and pseudo-labeledmethods assume that all pseudo-labeled data is ben-eï¬cial for cross-lingual transfer learning, which isnot always the case..therefore, here we propose a novel approachâ€“ advpicker â€“ which combines feature-based andpseudo-labeling methods, while not requiring anyextra costly resources (e.g., translation modelsor parallel data).
furthermore, to address the de-scribed problems, we enhance the source-languagener model with unlabeled target language datavia adversarialtraining.
unlike other pseudo-labeling methods, we only leverage the language-independent pseudo-labeled data selected by an ad-versarial discriminator, to alleviate overï¬tting the.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages743â€“753august1â€“6,2021.Â©2021associationforcomputationallinguistics743model in language-speciï¬c features of the source-language..speciï¬cally, we ï¬rst train an encoder and a nerclassiï¬er on labeled source-language data to learnentity domain knowledge.
meanwhile, a languagediscriminator and the encoder are trained on atoken-level adversarial task which enhances theability of the encoder to capture shared features.
wethen apply the encoder and the ner classiï¬er onunlabeled target-language data to generate pseudo-labels and use an adversarial discriminator to se-lect less language-speciï¬c data samples.
finally,we utilize knowledge distillation to train a target-language ner model on this selected dataset..we evaluate our proposed advpicker over 3target languages on standard benchmark datasets.
our experimental results show that the proposedmethod beneï¬ts strongly from this data selectionprocess and outperforms existing sota methods;without requiring any additional external resources(e.g., gazetteers or machine translation)..our major contributions are as follows:.
â€¢ we propose a novel approach to combinefeature-based and pseudo-labeling methodsvia language adversarial learning for cross-lingual ner;.
â€¢ we adopt an adversarial discriminator to se-lect what language-independent data to lever-age in training a cross-lingual ner modelto improved performance.
to the best of ourknowledge, this is the ï¬rst successful attemptin selecting data by adversarial discriminatorfor xl-ner;.
â€¢ experiments on standard multi-lingualdatasets showcase advpicker achieves newstate-of-the-art results in cross-lingual ner..2 related work.
2.1 cross-lingual ner.
cross-lingual transfer for ner has been widelystudied in recent years.
prior works are divided intothree categories: feature-based, translation-based,and pseudo-labeling..feature-based methods generally use language-independent features to train a ner model in thelabeled source-language data, which include wordclusters (tÂ¨ackstrÂ¨om et al., 2012), wikiï¬er features(tsai et al., 2016), gazetteers (zirikly and hagi-wara, 2015), and aligned word representations (niet al., 2017; wu and dredze, 2019), etc.
more-over, for language-independent features, adversar-.
ial learning was applied on word/char embeddinglayers (huang et al., 2019; bari et al., 2020) orencoders (zhou et al., 2019; keung et al., 2019).
translation-based methods generally use pseudotarget-language data translated from labeled source-language data.
ni et al.
(2017) proposed to projectlabels from the source language into the target lan-guage by using word alignment information.
mostrecent methods translate the annotated corpus inthe source language to the target language word-by-word (xie et al., 2018) or phrase-by-phrase (may-hew et al., 2017) and then copy the labels for eachword/phrase to their translations.
while (jain et al.,2019) proposed to translate full sentences in thesource language and project entity labels to target-language sentences..to leverage unlabeled target-language data,pseudo-labeling methods generate the pseudo-labels by annotation projection on comparable cor-pora (ni et al., 2017) or via models trained onsource-language labeled data (wu et al., 2020a)..in this paper, we propose advpicker, an ap-proach that requires no translation and combinesfeature-based and pseudo-labeling methods.
more-over, we leverage pseudo-labeled data differentlyfrom other pseudo-labeling methods.
through ad-versarial training, we select language-independentpseudo-labeled data for training a new target-language model..2.2 language adversarial learning.
language-adversarial training (zhang et al., 2017)was proposed for the unsupervised bilingual lex-icon induction task.
and it has been applied ininducing language-independent features for cross-lingual tasks in ner (zhou et al., 2019; xie et al.,2018), text classiï¬cation (chen et al., 2019b), andsentiment classiï¬cation (chen et al., 2018)..keung et al.
(2019) proposed a multilingualbert with sentence-level adversarial learning.
however, this method does not improve cross-lingual ner performance signiï¬cantly.
to ad-dress this limitation, advpicker uses multilingualbert with token-level adversarial training forcross-lingual ner, which induces more language-independent features for each token embedding..2.3 knowledge distillation.
knowledge distillation was proposed to compressmodels (buciluË˜a et al., 2006) or ensembles of mod-els (rusu et al., 2016; hinton et al., 2015; sanhet al., 2019; mukherjee and hassan awadallah,.
7442020) via transferring knowledge from one or moremodels (teacher models) to a smaller one (studentmodel).
besides model compression, knowledgedistillation has also been applied to various tasks,like cross-modal learning (hu et al., 2020), ma-chine translation (weng et al., 2020), and auto-mated machine learning (kang et al., 2020)..in this paper, we adapt knowledge distillation toleverage unlabeled data in the cross-lingual nertask.
this helps the student model learn richer in-formation from easily obtainable data (with pseudo-labels)..3 advpicker.
in this section, we introduce our approach (ad-vpicker) which utilizes the adversarial learningapproach to select language-independent pseudo-labeled data for training an effective target-language ner model.
figure 1 illustrates theframework of the proposed advpicker.
speciï¬cally,as shown in figure 1(a), we train an encoder anda ner classiï¬er on the labeled source-languagedata.
meanwhile, a language discriminator and theencoder are trained on the token-level adversarialtask.
we then apply encoder and classiï¬er overunlabeled target-language data to generate pseudo-labels and use the adversarial discriminator to se-lect the most language-independent pseudo-labeleddata samples.
finally, we utilize knowledge distil-lation to train a target-language ner model on thisselected dataset..in the following section, we describe thelanguage-independent data selection process, in-cluding the token-level adversarial training, dataselection by the discriminator, and knowledge dis-tillation on select language-independent data..3.1 token-level adversarial training for.
cross-lingual ner.
to avoid the model overï¬tting on language-speciï¬cfeatures of the source-language, we propose thetoken-level adversarial learning (tladv) frame-work, which is shown in figure 1(a)..following keung et al.
(2019), we formulateadversarial cross-lingual ner as a multi-task prob-lem: i) ner and ii) binary language classiï¬cation(i.e source vs. target language).
for the ner task,we train the encoder and classiï¬cation layer onner annotated text in the source language.
theencoder learns to capture the ner features of the in-put sentences and then the classiï¬cation layer tries.
to predict the entity labels for each word based ontheir feature vectors..for the language classiï¬cation task, we train alanguage discriminator and an encoder on the la-beled source-language dataset and unlabeled target-language data.
the language discriminator is addedto classify whether an embedding generated by theencoder is associated to the source or the targetlanguage.
the encoder tries to produce language-independent embeddings that are difï¬cult for thelanguage discriminator to classify correctly.
we de-ï¬ne the encoder, the language discriminator, andtheir objectives as follows:encoder given an input sentence x = [xi]1â‰¤iâ‰¤nwith n words, we feed it into encoder e to obtainfeature vectors h = [hi]1â‰¤iâ‰¤n for all words:.
h = e(x).
(1).
where e is the feature encoder which generateslanguage-independent feature vectors h for eachsentence x. following keung et al.
(2019), we usemultilingual bert as the feature encoder here anddenote the encoder as mbert-tladv.
ner classiï¬er we feed h into the ner classi-ï¬er which is a linear classiï¬cation layer with thesoftmax activation function to predict the entitylabel of token x..pÎ¸(y ner) = softmax(w nerh + bner).
(2).
where pÎ¸(y ner) âˆˆ r|c| is the probability distribu-tion of entity labels for token x and c is the entitylabel set.
w ner âˆˆ rdeÃ—|c| and bner âˆˆ r|c| de-note the to-be-learned parameters with de being thedimension of vector h.language discriminator the language discrimi-nator is comprised of two linear transformationsand a relu function for classifying token embed-ding.
the sigmoid function is used to predict theprobability of whether h belongs to the source lan-guage..pÎ¸(y dis) = Ïƒ(w dis1 relu(w dis2h)).
(3).
where w dis1 âˆˆ rddÃ—de and w dis2 âˆˆ rd(cid:96)Ã—dd,with dd being the hidden dimension of discrimina-tor and d(cid:96) the language classiï¬cation task label size.
Ïƒ is the sigmoid function to obtain the languageprobability of each word..for language-adversarial training, we have 3 lossfunctions: the encoder loss le, the language dis-criminator loss ldis, and the ner task loss lner..745figure 1: framework of the proposed advpicker.
a) overview of the token-level adversarial training process.
thelines illustrate the training ï¬‚ows and the arrows indicate forward or backward propagation.
blue lines show theï¬‚ow for source-language samples and grey ones are for the target language.
lner, le, and ldis are the lossesof the ner classiï¬er, encoder and discriminator modules in advpicker respectively (section 3.1).
encoder andner classiï¬er are trained together on source-language samples (blue solid lines on the left side).
encoder anddiscriminator are trained for the adversarial task (on the right side).
b) language-independent data selection onpseudo-labeled data.
c) knowledge distillation on selected data..note that we donâ€™t add these three loss functionstogether for backward propagation.
parameters ofdifferent components in adversarial learning are al-ternatively updated based on the corresponding lossfunction, similarly to keung et al.
(2019).
specif-ically, for the ner task, the parameters of the en-coder and the ner classiï¬er are updated based onlner.
for the adversarial task, the parameters ofthe encoder are updated based on le, while theparameters of the discriminator are updated basedon ldis.
algorithm 1 shows the pseudocode forthe adversarial training process..le = âˆ’.
log pÎ¸(y dis.
i = (cid:101)ydis.
i.
).
ldis = âˆ’.
log pÎ¸(y dis.
+ log pÎ¸(y dis.
i.i = ydisi = ydis.
i.
).
).
1n.1n.(cid:88).
iâˆˆ[1,n ].
(cid:88).
iâˆˆ[1,n ].
(4).
lner = âˆ’.
1n.(cid:88).
iâˆˆ[1,n ].
+ log pÎ¸(y dis.
log pÎ¸(y ner.
i.i.i = (cid:101)ydis= yneri.
).
).
where x is the sentence, ydis âˆˆ {0, 1} is theground truth label for the language classiï¬cationtask, (cid:101)ydis âˆˆ {0, 1} is the negative label for thelanguage classiï¬cation task, and yner âˆˆ rn Ã—|c|is the ground truth of named entity recognition taskfor corresponding input x..3.2 language-independent data selectionto obtain the pseudo labels Ë†yt-ner for target-language examples, we apply the learned mbert-tladv model on the unlabeled target-languagedata xt.
however, the pseudo-labeled dataset d ={xt, Ë†yt-ner} may then contain lots of language-speciï¬c samples.
we then leverage the adver-sarial discriminator to select pseudo language-independent samples from the generated set..the language discriminator tries to make theencoder unable to distinguish the language of atoken through confrontation.
in this way, the en-coder should pay more attention to features thatare less related to the source language when learn-ing the ner task.
after adversarial training, thelanguage discriminator can still correctly classifycertain embeddings with a high probability.
wedeï¬ne these as language-speciï¬c samples.
othersamples are ambiguous regarding language (for ex-ample, sentences with probability close to 0.5), andthey are deï¬ned as samples that are more language-independent..in order to quantify the language independenceof each sample, we use the language discriminatorto calculate the probability of whether the sentencext is from the source language pÎ¸(y dis, xt), theformula is as follows:.
pÎ¸(y dis, xt) = Ïƒ(w dis1 relu(w dis2ht)).
(5)where xt and ht, respectively, denote the target-.
7461nerclassifierlanguagediscriminatormbert-tladvmbert-tladvğ‘¥!unlabeledtarget-language examples!ğ”»={ğ‘¥!,â€™y!"#$%,ğ’«&(ğ‘Œâ€™(),ğ‘¥!
)languagediscriminatorsamples with â„“"#$%&ğ‘¥!*,ğ’«&*(ğ‘Œâ€™(),ğ‘¥!),1.00,ğ‘¥!+,ğ’«&+(ğ‘Œâ€™(),ğ‘¥!),0.97,ğ‘¥!,,ğ’«&,(ğ‘Œâ€™(),ğ‘¥!
),0.94,â€¦.â„“"#$%&in top ğœŒstudent modelâ„â€™()!source language texttarget language textâ„’!
"#(a) token-level adversarial training(b) data selection(c) knowledge distillationâ„’"â„’$%&â„’â€™$!ğ”»-./-01={ğ‘¥-./-01!,â€™y-./-01!
"#$%algorithm 1 pseudocode for token-level adversar-ial training on zero-shot cross-lingual ner.
require: training set de = ddis = {(x, ydis)}and dner = {(x, yner)}, batch size bs = 1for clarity, batch number b, the output proba-bility of model pÎ¸(y m), the hidden vector ofmodel h..1: initialize hidden vector of w âˆ—, bâˆ—;2: for i = 1, Â· Â· Â· , b do3:.
for model m in {ner, e, dis} dosample batch (x, y) âˆˆ dm;# calculate model hidden vector;h = e(x), refer to equ(1)if model m equal to model ner then.
calculate pÎ¸(y ner), eq.(2).
else.
calculate pÎ¸(y dis), eq.(3).
end ifcalculate model loss lm using x, y andpÎ¸(y m), eq.
(4)update parameters of embeddings w.r.t.
the gradients using âˆ‡lm with parame-ters w m, bm and the encoder e (if m in{ner, e})..4:.
5:.
6:.
7:.
8:.
9:.
10:.
11:.
12:.
13:.
end for.
14:15: end for.
language sentence and its feature vector, andpÎ¸(y dis, xt) is the probability of xt mentionedin eq.
( 3)..in order to select from the pseudo-labeled data,we design an index (cid:96)score to represent the languageindependence of a sentence xt (the degree ofmodel confusion on different languages).
we as-sume it follows a uniform distribution and reachesits maximum when pÎ¸(y dis, xt) = 0.5. con-versely, the index is at its minimal value whenpÎ¸(y dis, xt) is equal to 0 or 1..(cid:96)score(xt) = 1 âˆ’ (cid:13).
(cid:13)pÎ¸(y dis, xt) âˆ’ 0.5(cid:13)(cid:13).
(6).
we select target-language samples with the high-est (cid:96)score in the top Ï as language-independentdata.
Ï is a hyper-parameter which is the dataratio of pseudo-labeled data.
finally, we obtainthe selected target-language pseudo-labeled datasetdsubset = {xtsubset }, a subset of target lan-guage pseudo-labeled dataset..subset, Ë†yt-ner.
there are two reasons for selecting language-independent samples by the language discrimina-tor.
first, these samplesâ€™ feature vectors contain.
less language-speciï¬c information which is help-ful for cross-lingual transfer learning.
second, thener classiï¬er is trained on source-language la-beled data.
therefore, it is more likely to generatehigh-quality predictive labels on selected target-language samples that have similar feature vectorsto source-language samples..3.3 knowledge distillation on.
language-independent data.
to leverage such less language-dependent data, wetrain a target-language ner model on the selectedpseudo-labeled data dsubset.
considering a lot ofhelpful information can be carried in soft targetsinstead of hard targets (hinton et al., 2015), we usethe soft labels of the selected pseudo-data to traina student model htstu via knowledge distillation.
to construct the student model, we used the pre-trained cased multilingual bert(mbert) (devlinet al., 2019) as the initialization and a linear layerwith softmax function:.
pÎ¸(y t-ner) = softmax(w t-nerht.
stu + bt-ner)(7)where pÎ¸(y t-ner) is the distribution of entity la-bels probability output from the student model.
w t-ner âˆˆ rdsÃ—|c| and bt-ner âˆˆ r|c| are learn-able parameters of the student ner model..following wu et al.
(2020a), the loss functionlkd is deï¬ned as the mean squared error (mse)between the prediction output pÎ¸(y t-ner) and thesoft labels of the selected data, which is formulatedas:.
lkd =.
1n.(cid:88).
iâˆˆ[1,n ].
(pÎ¸(y t-ner) âˆ’ Ë†yt-ner.
subset )2.
(8).
subset âˆˆ dsubset are the selected soft la-where Ë†yt-nerbels with n tokens and pÎ¸(y t-ner) is the predic-tion probability of the selected sentence xt.
byminimizing the mse loss, the student model istrained supervised on the target-language selecteddata pseudo-labels..for inference in the target language, we onlyapply the student model on test cases to predictthe probability distribution of entity labels for eachtoken in sentences, as eq.(7).
to ensure the entitylabels follow the ner tagging scheme, the predic-tion result is generated by viterbi decoding (chenet al., 2019a)..747language.
type.
train dev test.
english [en](conll-2003)german [de](conll-2003)spanish [es](conll-2002)dutch [nl](conll-2002).
# of entity.
# of entity.
# of sentence 14,987 3,466 3,68423,499 5,942 5,648# of sentence 12,705 3,068 3,16011,851 4,833 3,673# of sentence 8,323 1,915 1,51718,798 4,351 3,558# of sentence 15,806 2,895 5,19513,344 2,616 3,941.
# of entity.
# of entity.
table 1: statistics of the benchmark datasets..4 experiments.
4.1 experiment settings.
datasetswe conduct experiments in 4 different languages:english [en], spanish [es], dutch [nl], german [de].
spanish and dutch data is from the conll-2002ner shared task (tjong kim sang, 2002a)2, whileenglish and german are from conll-2003 (tjongkim sang, 2002b)3. table 1 presents some basicstatistics of the datasets used in our experiments..conll-2002/2003 data uses gold standard la-belling and it is tagged with four entity types:per, loc, org, and misc.
following wuand dredze (2019), we use the bio labelingscheme (farber et al., 2008) and the ofï¬cial splitof train/validation/test sets.
as previous works(tÂ¨ackstrÂ¨om et al., 2012; jain et al., 2019; wu et al.,2020b), for all experiments, we always use englishas source language and the others as target lan-guages.
our models are trained on the training setof english and evaluated on the test sets of eachtarget language..note that for each target language, we only usetext in its training set to train our model with theseunlabeled target language data.
in adversarial learn-ing, we randomly sample data from all target lan-guages and construct a target-language dataset ofthe same size as the english training dataset..implementation detailswe implement advpicker using pytorch 1.6.0. fordata pre-processing, we leverage wordpiece (wuet al., 2016) to tokenize each sentence into a se-quence of sub-words which are then fed into themodel.
for the encoder (i.e.
e in eq.
(1)) and stu-dent model (i.e.
htstu in eq.
(7)), we employ the.
2https://www.clips.uantwerpen.be/conll2002/ner/3https://www.clips.uantwerpen.be/conll2003/ner/.
pre-trained cased multilingual bert in hugging-faceâ€™s transformers (wolf et al., 2020)4 as back-bone model, which has 12 transformer blocks, 12attention heads, and 768 hidden units..we empirically select.
the following hyper-parameters.
speciï¬cally, referring to the settingsof wu et al.
(2020b), we freeze the parameters ofthe embedding layer and the bottom three layers ofthe multilingual bert used in the encoder and thener student model.
we train all models using abatch size of 32, maximum sequence length of 128,a dropout rate of 0.1, and use adamw (loshchilovand hutter, 2019) as optimizer.
for sequence pre-diction, we apply viterbi decoding (chen et al.,2019a) on all models in our experiments..following keung et al.
(2020), in all experimentsthe other hyper-parameters are tuned on each targetlanguage dev set.
we train all models for 10 epochsand choose the best model checkpoint with thetarget dev set.
for adversarial learning, we set thelearning rate of 6e-5 for the ner loss lner and6e-7 for both loss encoder le and discriminatorloss ldis.
for knowledge distillation, we use alearning rate of 6e-5 for the student models.
weset the hidden dimension of the discriminator as500. for data selection, Ï is set to 0.8. followingtjong kim sang (2002a), we use the entity level f1-score as evaluation metric.
moreover, experimentsare repeated 5 times for different random seeds oneach corpus..note that the selected data from the discrimina-tor is generated by combination of output frommbert-tladvs with different random seeds,as we observe only a small number of sampleswith high (cid:96)score in the selected data generated byeach model.
speciï¬cally, for each target-languagesentence xt, there are 5 corresponding soft la-bel sequences generated from 5 different mbert-tladv models.
from those, only sequences thathave the highest sum of each predicted label conï¬-dence are kept..our models are trained on a tesla p100 gpu(16gb).
mbert-tladv has 178m parametersand trains in â‰ˆ130min, while the student modelshtstu have 177m parameters and take â‰ˆ21min..4.2 comparison with state-of-the-art.
results.
table 2 reports the zero-shot cross-lingual ner re-sults of different methods on the 3 target languages..4https://github.com/huggingface.
748model.
tÂ¨ackstrÂ¨om et al.
(2012)tsai et al.
(2016)ni et al.
(2017)mayhew et al.
(2017)xie et al.
(2018)jain et al.
(2019)bari et al.
(2020)wu and dredze (2019)keung et al.
(2019)wu et al.
(2020b)wu et al.
(2020a)*mbert-ftmbert-tladvadvpicker.
de.
40.4048.1258.5057.2357.7661.565.2469.5671.973.16.es.
59.3060.5565.1064.1072.3773.575.9374.9674.376.75.nl.
58.4061.5665.4063.3771.2569.974.6177.5777.680.44.avg.
52.7056.7463.0061.5767.1368.3071.9373.5774.6076.78.
81.2 Â± 0.83 77.37 Â± 0.6773.61 Â± 0.39 77.3 Â± 0.7872.59 Â± 0.31 75.12 Â± 0.83 80.34 Â± 0.27 76.02 Â± 0.4773.89 Â± 0.56 76.92 Â± 0.62 80.62 Â± 0.56 77.14 Â± 0.5875.01 Â± 0.50 79.00 Â± 0.21 82.90 Â± 0.44 78.97 Â± 0.38.table 2: results of our approach and prior state-of-the-art methods for zero-shot cross-lingual ner.
* denotes theversion of the method without additional data..these include advpicker, prior sota methods,and two re-implemented baseline methods, i.e.,mbert-tladv (section 3.1) and mbert-ft(mbert ï¬ne-tuned on labeled source-languagedata).
note that some existing methods use thetranslation model as an additional data transfersource, whereas our method does not.
for a faircomparison, we compare against the version ofunitrans (wu et al., 2020a) w/o translation (as re-ported in their paper).
our method outperformsthe existing methods with f1-scores of 75.01,79.90, and 82.90, when using only source-languagelabeled data and target-language unlabeled data.
particularly, compared with unitrans* (previoussota), advpicker achieves an improvement off1-score ranging from 1.41 in german to 1.71 indutch.
furthermore, our result is comparable tothe full unitrans using also translation (0.04 f1difference on average)..besides, advpicker achieves an average f1-score improvement of 1.83 over mbert-tladvand 2.95 over mbert-ft. these results well demon-strate the effectiveness of the proposed approach,which is mainly attributed to more effectively lever-aging unlabeled target language data and selectingthe language-independent data for cross-lingualtransfer..de.
es.
nl.
avg.
mbert99.08 99.66 98.98 99.2498.38 98.66 97.27 98.10mbert-ftmbert-tladv 79.62 82.89 77.45 79.99.table 3: accuracy of discriminators for different mod-els in the three target languages..language selected other âˆ†.
deesnlavg.
77.8776.4584.3379.55.
63.83 14.0469.237.2266.97 17.3666.68 12.87.table 4: teacher model f1 scores over target languagetraining sets, w/o adversarial approach and distillation..data type.
de.
es.
nl.
total.
selected data 9733 6724 12668 291257283other data.
2434 1681 3168.table 5: sentence numbers of the selected/other splitsin the target language training sets..4.3 quality of selected data.
language-independence we use the selecteddataset dsubset to train student models via knowl-edge distillation.
pÎ¸(y t-ner) in dsubset is calcu-.
lated over feature vectors generated by mbert-tladv.
to validate the language-independence ofthese feature vectors, we apply three discrimina-tors deï¬ned as in eq.
(3) to classify the token fea-.
749ture vectors from three different encoders: mbert,mbert-ft, and mbert-tladv..unlike in the adversarial learning setting, we ï¬xthe parameters of the three encoders and only trainthe discriminators.
we use each language trainingset to train discriminators and evaluate on eachtarget language corresponding test set.
table 3 re-ports the discriminator accuracy for 3 differentencoders.
we can see that the classiï¬cation accu-racy is reduced with adversarial training, whichsuggests that the similarity of feature vectors be-tween the source language and the target languageis improved; which further demonstrates the fea-ture vectors become more language-independentwhen adversarial training is applied.
pseudo labels to evaluatelanguage-independent quality of pseudo labels, we calculatethe f1 scores of the pseudo labels and the numberof sentences involved.
we denote language-independent data and language-speciï¬c data asâ€œselected dataâ€ and â€œother dataâ€ respectively..the.
table 4 reports the pseudo labels f1 scoresof both language-independent data and language-language usingspeciï¬c data for each targetmbert-tladv.
generally, the average f1 scoreof language-independent data is 12.87 pointshigher than language-speciï¬c data, which suggeststhat language-independent data has higher qual-ity pseudo-labels.
furthermore, the selected datacontains less language-speciï¬c information..table 5 reports the number of.
language-independent and language-speciï¬c examples foreach language.
from these results (tables 4, 5), weobserve that the selected data is still high-quality,even if we set a very loose threshold (80% of unla-beled data being selected)..4.4 model performance over selected/other.
data splits.
in order to better analyse the behaviour of ad-vpicker across data variations, we use the trainedlanguage discriminator to split the target languagetest sets into selected and other partitions (simi-larly to how the training set is processed).
table7 shows the different modelsâ€™s f1 scores for thepartitioned data..from table 7, we can draw these conclusions:1) as expected, models perform better over se-.
lected data than over other data;.
2) advpicker is only trained on selected data,but nonetheless outperforms all baseline models in.
both data partitions;.
3) advpickerâ€™s approach effectively selects ex-amples with better features and is not over-biasedtowards selected data..4.5 ablation study.
to validate the contributions of different processin the proposed advpicker, we introduce the fol-lowing variants of advpicker and baselines to per-form an ablation study: 1) advpicker w/o kd,which directly combines the prediction of test datafrom mbert-tladvs with different seeds withoutknowledge distillation on pseudo-labeled trainingdata.
2) advpicker w all-data, which trains a stu-dent model on all target-language pseudo-labeleddata generated by mbert-tladv.
3) mbert-ft,mbert ï¬ne-tuned on source-language labeleddata.
4) mbert-tladv (section 3.1), meaningmbert trained on source-language labeled datawith token-level adversarial learning..table 6 reports the performance of each methodand their performance drops compared to ad-vpicker.
moreover, we can draw more in-depthobservations as follows:.
1) comparing advpicker with advpicker w/okd and advpicker w all-data, we can see thatselecting the language-independent data is reason-able.
that also validates the effectiveness of themodel trained on language-independent data viaknowledge distillation..2) mbert-ft outperforms mbert-tladv.
suchresults well demonstrate that token-level adver-sarial learning is helpful to train a language-independent feature encoder and brings perfor-mance improvement..3) by comparing the f1 scores of advpicker wall-data and advpicker on the target languages, weobserve that training on selected data brings higherperformance improvements on larger datasets, e.g.,german [de] and dutch [nl], and lower improve-ments on the smaller spanish [es] dataset.
al-though selected data has high-quality pseudo la-bels, smaller sizes of selected datasets may limitperformance improvements..4.6 stability analysis.
because bert ï¬ne-tuning is known to be unsta-ble in few-shot tasks, as discussed in zhang et al.
(2021).
mbert-based methodsâ€™ performances onthe conll ner dataset are likely also unstable.
to evaluate the stability of advpicker, we compare.
750model.
de.
es.
nl.
avg.
75.02.advpicker72.59 (-2.43) 75.12 (-3.88) 80.34 (-2.56) 76.02 (-2.95)mbert-ft73.89 (-1.13) 76.92 (-2.08) 80.62 (-2.28) 77.14 (-1.83)mbert-tladvadvpicker w/o kd73.98 (-1.04) 77.91 (-1.09) 80.55 (-2.35) 77.48 (-1.49)advpicker w all-data 74.02 (-1.00) 78.72 (-0.28) 80.69 (-2.21) 77.81 (-1.16).
78.97.
82.90.
79.00.table 6: ablation study for the proposed advpicker, where numbers in parenthesis denote performance change..methods.
de (selected) de (other) es (selected) es (other) nl (selected) nl (other).
mbert-ftmbert-tladvunitrans w/o translationadvpicker.
73.6574.0574.4875.11.
70.6672.4971.7173.76.
77.2978.0477.2979.19.
70.3973.8673.1875.68.
81.6781.8383.1584.19.
69.8977.8970.3979.15.table 7: f1 scores over the select/other test set splits in different target languages.
advpicker has better perfor-mance also on other data for all languages..the standard deviation of f1 scores for mbert-ft,unitrans, and advpicker..table 2 includes the standard deviation of f1scores over ï¬ve runs for each model.
advpickerhas a lower average standard deviation in the threetarget languages than the other mbert-based meth-ods.
such results demonstrate that selected data canbring a degree of stability to the model, or limitinstability, as the student model in advpicker istrained on selected data with the soft labels fromother trained models..5 conclusion.
in this paper, we propose a novel approach to com-bine the feature-based method and pseudo labelingvia language adversarial learning for cross-lingualner.
advpicker is the ï¬rst successful attempt inselecting language-independent data by adversarialdiscriminator to cross-lingual ner.
our experi-mental results show that the proposed system bene-ï¬ts strongly from this new data selection processand outperforms existing state-of-the-art methods,even without requiring additional extra resources..references.
m. saiful bari, shaï¬q r. joty, and prathyusha jwalapu-ram.
2020. zero-resource cross-lingual named en-in the thirty-fourth aaai con-tity recognition.
ference on artiï¬cial intelligence, aaai 2020, thethirty-second innovative applications of artiï¬cialintelligence conference, iaai 2020, the tenth aaai.
symposium on educational advances in artiï¬cial in-telligence, eaai 2020, new york, ny, usa, febru-ary 7-12, 2020, pages 7415â€“7423.
aaai press..cristian buciluË˜a, rich caruana, and alexandruniculescu-mizil.
2006. model compression.
in pro-ceedings of the 12th acm sigkdd internationalconference on knowledge discovery and data min-ing, pages 535â€“541..hui chen, zijia lin, guiguang ding, jian-guang lou,yusen zhang, and bÂ¨orje f. karlsson.
2019a.
grn:gated relation network to enhance convolutionalneural network for named entity recognition.
in thethirty-third aaai conference on artiï¬cial intelli-gence, aaai 2019, the thirty-first innovative ap-plications of artiï¬cial intelligence conference, iaai2019, the ninth aaai symposium on educationaladvances in artiï¬cial intelligence, eaai 2019, hon-olulu, hawaii, usa, january 27 - february 1, 2019,pages 6236â€“6243.
aaai press..xilun chen, ahmed hassan awadallah, hany has-san, wei wang, and claire cardie.
2019b.
multi-source cross-lingual model transfer: learning whatto share.
in proceedings of the 57th annual meet-ing of the association for computational linguis-tics, pages 3098â€“3112, florence, italy.
associationfor computational linguistics..xilun chen, yu sun, ben athiwaratkun, claire cardie,and kilian weinberger.
2018. adversarial deep av-eraging networks for cross-lingual sentiment classi-ï¬cation.
transactions of the association for compu-tational linguistics, 6:557â€“570..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding..751of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171â€“4186, minneapolis, minnesota.
associ-ation for computational linguistics..benjamin farber, dayne freitag, nizar habash, andimproving ner in arabicowen rambow.
2008.in proceedings ofusing a morphological tagger.
the sixth international conference on language re-sources and evaluation (lrecâ€™08), marrakech, mo-rocco.
european language resources association(elra)..geoffrey hinton, oriol vinyals, and jeff dean.
2015.distilling the knowledge in a neural network.
arxivpreprint arxiv:1503.02531..hengtong hu, lingxi xie, richang hong, and qi tian.
2020. creating something from nothing: unsuper-vised knowledge distillation for cross-modal hash-in 2020 ieee/cvf conference on computering.
vision and pattern recognition, cvpr 2020, seat-tle, wa, usa, june 13-19, 2020, pages 3120â€“3129.
ieee..lifu huang, heng ji, and jonathan may.
2019. cross-lingual multi-level adversarial transfer to enhancein proceedings of thelow-resource name tagging.
2019 conference of the north american chapter ofthe association for computational linguistics: hu-man language technologies, volume 1 (long andshort papers), pages 3823â€“3833, minneapolis, min-nesota.
association for computational linguistics..alankar jain, bhargavi paranjape, and zachary c. lip-ton.
2019. entity projection via machine transla-in proceedings of thetion for cross-lingual ner.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 1083â€“1092, hong kong,china.
association for computational linguistics..minsoo kang, jonghwan mun, and bohyung han.
2020. towards oracle knowledge distillation within the thirty-fourthneural architecture search.
aaai conference on artiï¬cial intelligence, aaai2020, the thirty-second innovative applications ofartiï¬cial intelligence conference, iaai 2020, thetenth aaai symposium on educational advancesin artiï¬cial intelligence, eaai 2020, new york, ny,usa, february 7-12, 2020, pages 4404â€“4411.
aaaipress..phillip keung, yichao lu, and vikas bhardwaj.
2019.adversarial learning with contextual embeddings forzero-resource cross-lingual classiï¬cation and ner.
in proceedings of the 2019 conference on empiricalmethods in natural language processing and the9th international joint conference on natural lan-guage processing (emnlp-ijcnlp), pages 1355â€“1360, hong kong, china.
association for computa-tional linguistics..phillip keung, yichao lu, julian salazar, and vikasbhardwaj.
2020. donâ€™t use english dev: on thezero-shot cross-lingual evaluation of contextual em-beddings.
in proceedings of the 2020 conference onempirical methods in natural language processing(emnlp), pages 549â€“554, online.
association forcomputational linguistics..ilya loshchilov and frank hutter.
2019. decou-in 7th inter-pled weight decay regularization.
national conference on learning representations,iclr 2019, new orleans, la, usa, may 6-9, 2019.openreview.net..stephen mayhew, chen-tse tsai, and dan roth.
2017.cheap translation for cross-lingual named entityrecognition.
in proceedings of the 2017 conferenceon empirical methods in natural language process-ing, pages 2536â€“2545, copenhagen, denmark.
as-sociation for computational linguistics..diego mollÂ´a, menno van zaanen, and daniel smith.
2006. named entity recognition for question an-in proceedings of the australasian lan-swering.
guage technology workshop 2006, pages 51â€“58,sydney, australia..subhabrata mukherjee and ahmed hassan awadallah.
2020. xtremedistil: multi-stage distillation for mas-in proceedings of thesive multilingual models.
58th annual meeting of the association for compu-tational linguistics, pages 2221â€“2234, online.
as-sociation for computational linguistics..jian ni, georgiana dinu, and radu florian.
2017.weakly supervised cross-lingual named entity recog-nition via effective annotation and representationprojection.
in proceedings of the 55th annual meet-ing of the association for computational linguistics(volume 1: long papers), pages 1470â€“1480, vancou-ver, canada.
association for computational linguis-tics..jonas pfeiffer, ivan vuliÂ´c, iryna gurevych, and se-bastian ruder.
2020. mad-x: an adapter-basedframework for multi-task cross-lingual transfer.
in proceedings of the 2020 conference on empiricalmethods in natural language processing (emnlp),pages 7654â€“7673, online.
association for computa-tional linguistics..andrei a. rusu, sergio gomez colmenarejo, cÂ¸ aglargÂ¨ulcÂ¸ehre, guillaume desjardins,james kirk-patrick, razvan pascanu, volodymyr mnih, koraykavukcuoglu, and raia hadsell.
2016.policyin 4th international conference ondistillation.
learning representations, iclr 2016, san juan,puerto rico, may 2-4, 2016, conference trackproceedings..victor sanh, lysandre debut, julien chaumond, andthomas wolf.
2019. distilbert, a distilled version ofbert: smaller, faster, cheaper and lighter.
in pro-ceedings of the neurips workshop on energy efï¬-cient machine learning and cognitive computing(emc2)..752bert.
in proceedings of the 2019 conference onempirical methods in natural language processingand the 9th international joint conference on natu-ral language processing (emnlp-ijcnlp), pages833â€“844, hong kong, china.
association for com-putational linguistics..yonghui wu, mike schuster, zhifeng chen, quoc v le,mohammad norouzi, wolfgang macherey, maximkrikun, yuan cao, qin gao, klaus macherey, et al.
2016. googleâ€™s neural machine translation system:bridging the gap between human and machine trans-lation.
arxiv preprint arxiv:1609.08144..jiateng xie, zhilin yang, graham neubig, noah a.smith, and jaime carbonell.
2018. neural cross-lingual named entity recognition with minimal re-sources.
in proceedings of the 2018 conference onempirical methods in natural language processing,pages 369â€“379, brussels, belgium.
association forcomputational linguistics..meng zhang, yang liu, huanbo luan, and maosongsun.
2017. adversarial training for unsupervisedin proceedings of thebilingual lexicon induction.
55th annual meeting of the association for com-putational linguistics (volume 1: long papers),pages 1959â€“1970, vancouver, canada.
associationfor computational linguistics..tianyi zhang, felix wu, arzoo katiyar, kilian qweinberger, and yoav artzi.
2021. revisiting few-sample bert ï¬ne-tuning.
in international confer-ence on learning representations..joey tianyi zhou, hao zhang, di jin, hongyuan zhu,meng fang, rick siow mong goh, and kennethkwok.
2019. dual adversarial neural transfer forlow-resource named entity recognition.
in proceed-ings of the 57th annual meeting of the associationfor computational linguistics, pages 3461â€“3471,florence, italy.
association for computational lin-guistics..ayah zirikly and masato hagiwara.
2015. cross-lingual transfer of named entity recognizers withoutin proceedings of the 53rd an-parallel corpora.
nual meeting of the association for computationallinguistics and the 7th international joint confer-ence on natural language processing (volume 2:short papers), pages 390â€“396, beijing, china.
as-sociation for computational linguistics..oscar tÂ¨ackstrÂ¨om, ryan mcdonald, and jakob uszko-reit.
2012. cross-lingual word clusters for directin proceedings oftransfer of linguistic structure.
the 2012 conference of the north american chap-ter of the association for computational linguis-tics: human language technologies, pages 477â€“487, montrÂ´eal, canada.
association for computa-tional linguistics..erik f. tjong kim sang.
2002a..introduction to theconll-2002 shared task: language-independentnamed entity recognition.
in coling-02: the 6thconference on natural language learning 2002(conll-2002)..erik f. tjong kim sang.
2002b..introduction to theconll-2002 shared task: language-independentnamed entity recognition.
in coling-02: the 6thconference on natural language learning 2002(conll-2002)..chen-tse tsai, stephen mayhew, and dan roth.
2016.cross-lingual named entity recognition via wikiï¬-in proceedings of the 20th signll con-cation.
ference on computational natural language learn-ing, pages 219â€“228, berlin, germany.
associationfor computational linguistics..rongxiang weng, heng yu, shujian huang, shanbocheng, and weihua luo.
2020. acquiring knowl-edge from pre-trained modelto neural machinetranslation.
in proceedings of the aaai conferenceon artiï¬cial intelligence, volume 34, pages 9266â€“9273..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, remi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander rush.
2020. trans-formers: state-of-the-art natural language process-ing.
in proceedings of the 2020 conference on em-pirical methods in natural language processing:system demonstrations, pages 38â€“45, online.
asso-ciation for computational linguistics..qianhui wu, zijia lin, bÂ¨orje f. karlsson, biqinghuang, and jian-guang lou.
2020a.
unitrans: uni-fying model transfer and data transfer for cross-lingual named entity recognition with unlabeledin proceedings of the twenty-ninth interna-data.
tional joint conference on artiï¬cial intelligence, ij-cai 2020, pages 3926â€“3932.
ijcai.org..qianhui wu, zijia lin, guoxin wang, hui chen,bÂ¨orje f. karlsson, biqing huang, and chin-yew lin.
2020b.
enhanced meta-learning for cross-lingualnamed entity recognition with minimal resources.
inproceedings of the aaai conference on artiï¬cial in-telligence, volume 34, pages 9274â€“9281..shijie wu and mark dredze.
2019. beto, bentz, be-cas: the surprising cross-lingual effectiveness of.
753