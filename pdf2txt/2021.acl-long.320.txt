supporting land reuse of former open pit mining sitesusing text classiﬁcation and active learning.
christopher schr¨oder1,5, kim b ¨urgl1,4,5, yves annanias2,5, andreas niekler1,5,lydia m ¨uller1,4,5, daniel wiegreffe2,5, christian bender3,5, christoph mengs3,5,gerik scheuermann2,4,5, and gerhard heyer1,4,5.
1natural language processing group2image and signal processing group3institute of public finance and public management4institute for applied informatics (infai), leipzig, germany5leipzig university, germany{schroeder,buergl,annanias,aniekler}@informatik.uni-leipzig.de{lydia,daniel,scheuermann,heyer}@informatik.uni-leipzig.de{bender,mengs}@wifa.uni-leipzig.de.
abstract.
1.introduction.
open pit mines left many regions worldwideinhospitable or uninhabitable.
many sites areleft behind in a hazardous or contaminatedstate, show remnants of waste, or have otherrestrictions imposed upon them, e.g., for theprotection of human or nature.
such informa-tion has to be permanently managed in order toreuse those areas in the future.
in this work wepresent and evaluate an automated workﬂowfor supporting the post-mining management offormer lignite open pit mines in the easternpart of germany, where prior to any plannedland reuse, aforementioned information has tobe acquired to ensure the safety and validity ofsuch an endeavor.
usually, this information isfound in expert reports, either in the form ofpaper documents, or in the best case as dig-itized unstructured text—all of them in ger-man language.
however, due to the size andcomplexity of these documents, any inquiryis tedious and time-consuming, thereby slow-ing down or even obstructing the reuse of re-lated areas.
since no training data is available,we employ active learning in order to performmulti-label sentence classiﬁcation for two cat-egories of restrictions and seven categories oftopics.
the ﬁnal system integrates opticalcharacter recognition (ocr), active-learning-based text classiﬁcation, and geographic infor-mation system visualization in order to effec-tively extract, query, and visualize this infor-mation for any area of interest.
active learn-ing and text classiﬁcation results are twofold:whereas the restriction categories were rea-sonably accurate (>0.85 f1), the seven topic-oriented categories seemed to be complex evenfor human annotators and achieved mediocreevaluation scores (<0.70 f1)..in many parts of the world, raw materials weremined in open pit mines during the last century,leaving many of these regions inhospitable or unin-habitable.
to put these regions back into use, en-tire stretches of land must be renaturalized, whichmeans that land must be ecologically restored withthe aim to ultimately increase biodiversity, or recul-tivated, which means its productivity must be re-stored, e.g., reused for agriculture, recreational ar-eas, industrial parks, solar and wind farms, or asbuilding land (luc et al., 2015).
in the following,we subsume both renaturalization and recultivationunder land reuse.
for land reuse, it is essential thatall relevant information about the sites is retained,which used to be recorded in the form of textualreports.
such reports include information such as,among others, hazards, soil composition, or envi-ronmental factors.
therefore, having access to allthese reports, it can be determined if a site can bereused immediately, only under certain conditions,or not at all in the foreseeable future..for reaching a sustainable future, the unitednations (2015) has deﬁned objectives, called sus-tainable development goals (sdgs).
land reuse isa shared common denominator among several ofthose goals such as “zero hunger”, “clean waterand sanitation”, “sustainable cities and communi-ties”, “climate action”, “life below water”, and“life on land”.
moreover, it provides co-beneﬁt toall sdgs as shown by herrick et al.
(2019) anddirectly supports “life on land”.
by implication,anything that obstructs land reuse also impedes thefulﬁllment of several sdgs..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages4141–4152august1–6,2021.©2021associationforcomputationallinguistics4141this work deals with the real-world use case ofpost-mining management (kretschmann, 2020) offormer lignite open pit mines in the eastern partof germany.
here, a large number of such docu-ments exist, and moreover, there is metadata main-tained, which maps each document to its relatedarea.
apart from that, before any land can be reusedin these areas, it is legally required that local au-thorities must be consulted before proceeding anyfurther.
this process includes seeing through nu-merous legacy documents, which is laborious, time-consuming and delays a subsequent reuse of suchareas.
we address this issue by demonstrating andevaluating a workﬂow consisting of optical charac-ter recognition (ocr), text classiﬁcation and activelearning, whose results are then visualized by a ge-ographic information system (gis).
by automatinginformation extraction and making extracted resultsavailable through a gis, we increase efﬁciency bywhich information about a speciﬁc location of in-terest can be queried.
this can accelerate the reuseof land by supporting the efﬁciency of employeesmanaging these areas, and thereby contributes to-wards the fulﬁllment of several sdgs..this necessary review of a multitude of docu-ments, which is obligatory prior to any land reuse,is aggravated even more by germany’s federalstructure (german federal government, 2016) dueto which land management is a task of the mu-nicipalities.
the federal government, as well asthe states are responsible for the sdgs’ implemen-tation, which is then passed on to the municipal-ities, which therefore are effectively responsiblefor supporting sdgs.
municipalities, however,do not have a standardized software infrastructure(zern-breuer et al., 2020), which results in a hetero-geneous data management landscape and therebymakes the implementation of sdgs challenging,especially for small municipalities.
informationabout former lignite open pit mines is stored in in-dependent gises, related unstructured documentsare stored in dedicated storage systems (either inform of piles of paper, scanned documents, or evenas digitized text), and the connections between doc-uments and geographic coordinates are stored inyet other databases.
in order to obtain informationabout an area of interest, all information must becontextualized, compiled, and manually evaluated.
although the presented approach is tailored to-wards the post-mining management in eastern ger-many, this is relevant to many other countries in.
the world, which are also concerned with stoppinglignite and coal mining to reduce co2 emissions.
to give a few examples, belgium performed coalphase-out in 2016, sweden and austria in 2020;canada will follow in 2030, and germany in 2038.all of these countries will need to post-manageformer mining sites in order to reuse the affectedareas.
apart from lignite and coal mining, this isalso true for other mining sites.
once resources areexhausted or are no longer needed, land has to berenaturalized or recultivated or will stay desertedfor unknown time..2 foundations and related work.
sustainability issues have long been politically ig-nored, but became much more relevant in recentyears.
as a result, this societal challenge has re-cently started to get traction in computer science(gomes et al., 2019) and natural language process-ing (conforti et al., 2020), where only few previ-ous works study methods to support sdgs: con-forti et al.
(2020) classify user-perceived valueson unstructured interview text in order to gatherstructured data about the people’s subjective val-ues.
this is performed in developing countries toincrease the success of sustainability projects, eachtargeted at one or more sdgs, by aligning them tothe encountered values, so that the projects will bemore likely to be continued by the community aftertheir initial implementation.
similar to us, theyalso performs sentence classiﬁcation to supportsdgs, however, besides using data from a com-pletely different domain, we perform multi-labelclassiﬁcation, use more recent transformer-basedmodels, and integrate additional geospatial infor-mation.
pincet et al.
(2019) support the automaticclassiﬁcation of sdgs in reporting documents inthe form of an ofﬁcial api for the oecd (organisa-tion for economic co-operation and development),which is responsible for implementing sdgs andmonitoring the progress thereof.
this clearly showsthe problem of an increasing number of documentsrelevant for implementing sdgs, and also the needfor tools to support such processes..there are a variety of ocr engines available,with tesseract (smith, 1987) being a good startingpoint.
tesseract offers a number of pre-processingmechanisms for document images, however, it doesnot implement the full range of state-of-the-artocr.
image pre-processing as proposed and im-plemented by the ocr-d project (binmakhashen.
4142and mahmoud, 2019; neudecker et al., 2019), isbeneﬁcial to additionally extend the tool with thelatest developments in ocr..in recent years, text classiﬁcation, like manyother ﬁelds in natural language processing, hasexperienced a paradigm shift towards transformer-based models (vaswani et al., 2017; devlin et al.,2019), which raised the state-of-the-art results onmany tasks.
besides the impressive performancegains, the main advantage of using a pre-trainedmodel is that its performance can be translated tolow-data scenarios, which were previously chal-lenging due to deep models overﬁtting on smalldata.
transformers, however, have been shown towork well on small data (ein-dor et al., 2020; yuanet al., 2020), and consequently open up new possi-bilities on previously challenging tasks..geographic information systems are a commontechnological choice to visualize spatial data oncartographic maps and have been shown to be in-valuable for supporting sdgs (avtar et al., 2020).
using a gis, one can combine a database storingtextual information with the spatial data to supportexperts in the decision-making process or to enablethe exploration of data.
to support renaturaliza-tion of a river valley, matysik and absalon (2012)used a gis to analyze hydrological aspects in thearea and develop a plan for renaturalization.
simi-larly to our work, they also combined several lay-ers of features in the gis.
a recent toolbox of thecommercial arcgis software called locatext(esri) can connect a larger number of unstructureddatasets into a running gis, however, although itcan automatically link information and coordinatesfrom the data, it does not support the extraction andprocessing of unstructured information and otherattributes providing further information..3 data.
we use data from the lausitzer und mitteldeutschebergbauverwaltungsgesellschaft mbh (lmbv)1,who are responsible for the management and reuseof abandoned mining sites in the eastern part ofgermany.
for this purpose, they archive and man-age all documents related to sites in this area, andissue new documents if required.
moreover, theyare obligated to provide reliable information aboutthe managed lands for the public on request.
suchrequests require, among others, to inform aboutany restrictions for the speciﬁc area, which can be.
1https://de.wikipedia.org/wiki/lmbv.
found in the associated documents.
an illustratedexample is shown in figure 1..for research, the lmbv provided us with 31,605of such documents (16,883 for the region lausitz2,14,722 for the region mitteldeutschland3).
the old-est documents date back to the 1960s, but scanswere only produced within the last 20 years.
thedocuments encompass several different types, forexample, reports, drilling logs, expert opinions,statements, plans, maps, and correspondences.
thequality of the scans varies from excellent to fairquality.
moreover, some documents are stored inother digital formats (.doc, .docx, .odf) and othersare stored as scanned images.
the documents havedifferent origins: they are authored by the com-panies mining the open pit mine, by the lmbvmanaging the closed open pit mines, by companiesresponsible for certain subtasks such as buildinginfrastructure, or by other experts.
they includedocuments from the time when open pit mines wereactively mined but also documents created after themines were closed.
besides the documents, ourdataset contains over 30,000 geographic features.
these features are described as points, lines, poly-gons and multipolygons, and can be visualized ina gis.
in addition, these data are provided withadditional non-spatial information, such as the geo-graphical afﬁliation of the documents mentioned..3.1 labels.
in this work, the goal is to ﬁnd restrictions andtopics, which are described in table 1 and whichwill be used as labels during text classiﬁcation.
restrictions are formulated in many differentways, e.g., a speciﬁc action may be forbidden,an action may require speciﬁc preceding stepsto be allowed, or the action may be explicitlyallowed under certain circumstances.
moreover,a restriction may refer to certain topics, e.g.,restricting a construction method depending onthe weather.
regarding topic labels, due to thedifferent types of documents, they vary largely.
for example, geotechnical issues can be frequentlyfound in experts’ opinions from geotechnicalexperts but may also appear in reports, statementsor correspondence.
thus, topics are not limited tocertain type of document and within one documentor even one sentence more than one topic mayappear.
likewise, restrictions can be found in.
2https://en.wikipedia.org/wiki/lusatia3https://en.wikipedia.org/wiki/.
central_germany_(cultural_area).
4143figure 1: example of a typical documentation.
part of the textual reports are passages about restrictions or prohi-bitions in the described area.
(the background image consists of two photos, one by sludgeulper (left background,cc by-sa 2.0), and the other by johannes kazah (right background, cc by-sa 2.0).
the resulting image changesthe originals only by adding overlays (to the front) and is also licensed under the cc by-sa 2.0 license.).
most types of documents and describe knownissues with the associated area.
those labels aredeductively deﬁned and reﬂect the requirements ofthe most frequent requests to the lmbv.
since thislabel system is speciﬁcally deﬁned for this novelapproach, no training or pre-labeled data could beprovided by the lmbv, but for each label examplesentences and common keywords were deﬁned..3.2 ocr.
for documents which are not digitized yet, thetext is extracted using tesseract4 and best prac-tices regarding german language from the ocr-dcommunity (smith, 1987; neudecker et al., 2019;binmakhashen and mahmoud, 2019).
the majorchallenges here were: (1) the vast number of doc-uments make it infeasible to optimize ocr pa-rameters for each document, therefore ocr hasto be optimized with regard to the whole collec-tion.
(2) there is no manually transcribed evalu-ation data.
(3) the documents are written by hu-mans without any review process making erroneouswords or grammar very likely.
for these reasons,and because of the many varying document types,investigating ocr quality is impractical and there-fore outside the scope of this work.
however, weuse the built-in tesseract evaluation procedure tojudge the overall quality of the process and applyfurther ﬁltering to cope with difﬁcult documentsand insufﬁcient ocr quality..ocr pre-processing steps for the images in-cluded orientation analysis and rotation, resizingof the image (400dpi), denoising, lighting inten-sity correction, binarization, and deskewing.
light-.
4https://github.com/tesseract-ocr/.
tesseract.
ing intensity correction only improved the resultin some cases but worsened the result in others.
it is therefore only used if it improves the resultbased on the conﬁdence score from tesseract asexplained below.
denoising converts the imagesinto grayscales, applies a dilution ﬁlter, an erosionﬁlter, and ﬁnally, a median blur ﬁlter..the quality of the results is measured by evaluat-ing the conﬁdence score as produced by tesseractwhich provides a word level conﬁdence score re-ﬂecting the ocr quality.
we aggregated the wordlevel conﬁdence score to a page level conﬁdencescore by averaging over all recognized words, re-sulting in a score between 0 and 100%, and assign-ing pages without recognized text a score of 0%.
again, the document quality and layout is very het-erogeneous and annotating a test set for the ocrprocess would lack completeness.
we identiﬁed45,141 (mitteldeutschland) and 35,256 (lausitz)pages in the document dataset.
we accept all pagesfor our experimental dataset which are evaluatedwith a conﬁdence score of more than 75%.
withoutpre-processing only 45% of the pages are detectedwith a conﬁdence score of at least 75%.
the cor-rect pre-processing improved the ocr result to97% of pages exceeding the deﬁned threshold forthe region lausitz (from 44% to 93% for regionmitteldeutschland, respectively).
in 93% (lausitz)and 83% (mitteldeutschland) of the pages with aconﬁdence below 75% the original documents donot contain any recognizable text.
hence, the ma-jority of unrecognized or insufﬁciently recognizeddocuments does not contain proper amounts of text..3.3 datasets and splits.
in order to obtain both a point of reference for eval-uation and an initial set of labeled data for the initial.
4144noitcirtser.scipot.label.
description.
example.
s prohibition.
statements which actively prohibit or restrictactions in general or conditionally..machines heavier than 30t are forbidden, land-slide hazard..requirement.
requirements limit usages and/or are directiveswhat is to be done..the area must be secured with ’no trespassing’-signs..weather.
construction.
geotechnics.
weather-related phenomena, consequences, andprotection measures..shore areas must be avoided during heavy rain..statements about construction plans, construc-tion sites, or construction procedures..only one-storey buildings should be placedaround the marina..information related to the ground, e.g., aboutsoil, stability, or slopes..slopes must be protected against the effects ofthe weather..restricted area.
indicates a limited accessibility, mostly due tohazards, soil stability, or safety precautions..always keep a distance of at least 50m to theshore..planting.
plans, reports, or speciﬁc details about the typeof plant and location of plantings..native species of bushes must be planted on theslope, to stabilize it against rupture..environment.
for renaturalization, it is often strictly regulatedwhere to plant, what, types etc..forest operations are forbidden during breedingseason..disposal.
instructions concerning storage and disposal of(building) materials..contaminated soil must be cleaned and provablybe disposed of..table 1: description of restrictions and topics, illustrated by examples (translated from german into english)..active learning model, we manually labeled a sub-set of 2000 sentences.
for each label, we deﬁneda set of keywords (see appendix table 3), whichare used to ﬁnd sentences in the unlabeled data,that likely belong to that label.
this is necessarybecause of the high ratio of unlabeled to labeledsentences in most documents, i.e., a majority ofthe sentences in the complete dataset will not haveany label assigned.
keywords were used to locaterestrictions and prohibition candidates.
from thiscandidate pool, we select candidates for the topiccategories utilizing further keyword matching.
indoing so, we take a maximum of 150 examplesper topic category.
if no more than 300 candidatescan be found for a topic category, we only includehalf of them in the candidate list to leave exam-ples of such rare categories for active learning inour unlabeled dataset.
since we want to demon-strate the capabilities of active learning this is anecessary decision.
additionally, we added morethan 700 randomly drawn sentences, resulting ina dataset of 2000 sentences in total.
this datasetwas annotated by three different (non-expert) an-notators with the help of a guideline describingeach label.
we measured the inter-annotator agree-ment with krippendorff’s α (krippendorff, 2011)which resulted in values between 0.91 and 0.7, withrestricted area as the most agreed label and con-struction the least agreed label between annotators.
this conﬁrms our observation that labeling in this.
domain is challenging and needs domain expertise.
we combine the annotations of all annotators bymajority voting in order to obtain more stable judg-ments of our non-expert annotators (nowak andr¨uger, 2010).
“requirement” is the most frequentlabel, while “weather” is the least frequent.
thetrue label distribution is unknown, but at least someof the labels seem to occur very rarely.
we split theannotated dataset into training (500 samples), vali-dation (500 samples), and test (1000 samples) setusing iterative stratiﬁcation (sechidis et al., 2011)to preserve the label distribution in all three sets(see appendix, table 5)..3.4 geospatial connection.
the linkage of the non-spatial data (i.e., the doc-uments and predicted restriction and topic labels)and the spatial data (e.g., coordinates for certainareas) can be represented as a graph.
for this, thedocuments and the associated areas are expressedas nodes.
then, edges are used to link these docu-ment nodes to their corresponding area node.
thegraph serves as an efﬁcient data structure, which isnecessary to make the data available in a gis andto enable the answering of requests by linking andcollecting the required information..the predicted labels can be integrated into thedata model with the following procedure: for eachtopic (see table 1), an additional node is createdcarrying the label description as a node property..4145restrictions that have not been classiﬁed more pre-cisely by a topic are grouped together under ageneric topic node.
then, edges are created foreach restriction, pointing from the associated topicnode to the document node from which the restric-tion originated.
additional information about therestrictions is available as attributes of the respec-tive edges.
this includes the sentence from whichthe restriction is derived and the conﬁdence valuefrom the text classiﬁcation algorithm.
these at-tributes are attached to the edge instead of the doc-ument node itself, since a document can lead toseveral restrictions either related to the same topicor a different topic (e.g., “large installations maynot be built” [construction-related] and “may notenter shore areas during heavy rain” [weather, re-stricted area]).
thus, a document node may beconnected to (one or more) topic nodes via severaledges that contain more detailed information aboutrestriction and the corresponding sentence..many queries can be realized with this data struc-ture.
for example, it is possible to efﬁciently querywhich restrictions exist in the same topic, in thesame document, or in the same geographic area,since only the corresponding nodes need to be fol-lowed in the data model.
this enables, in particular,an exploratory search that incorporates informationfrom existing projects that may be relevant for agiven request (see the use case in section 6)..4 approach.
the goal of our approach is to detect restriction andtopic labels at the sentence level.
subsequently, wecan map predicted labels to geospatial data, whichis already available in a structured format.
thismeans, with a process chain of ocr, text classi-ﬁcation, and gis, we can effectively detect thepresence or absence of labels at geographic coor-dinates of interest.
in the end, this can be directlyused to manage land reuse efforts, thereby sup-porting aforementioned sdgs.
as existing ocrsolutions are tried and tested, and the geospatiallink is already given, the main challenge of thismethod is text classiﬁcation, namely: (1) thereis no predeﬁned industrial standard for the labelswhich are not formally deﬁned but given by someexemplary formulations and keywords providedby the lmbv.
consequently, the deﬁnitions areincomplete and new formulation not using the key-words are expected.
(2) the documents exhibit adomain-speciﬁc, often convoluted, vocabulary..4.1 text pre-processing.
since the following text classiﬁcation depends onthe quality of the raw text obtained through theocr step, which we observed to be rather noisyowing to the structure of some documents, weapplied a series of pre-processing steps: we detectword wraps and remove the hyphen, convert linebreaks into white space, and ﬁnally trim repeatedsequences of white space.
subsequently, sentencesegmentation was performed using syntok5.
inorder to ﬁlter out sentences which are obviouslyerroneous, e.g., sentences containing only gibber-ish words, we ﬁltered all sentences which violatethe properties of a valid sentence (goldhahn et al.,2012).
this was achieved by a set of regularexpressions and ﬁlter rules, which detect impropersentences, e.g., sentences which contain too manyspecial characters, start with a lowercase letter, orare missing a terminal punctuation character..4.2 text classiﬁcation and active learning.
using the extracted sentences described in section4.1 as input, our goal is to classify restriction andtopic labels.
in contrast to standard text classiﬁca-tion datasets, the lmbv data, like most real-worlddata, provides no labels.
manually labeling docu-ments, however, is time-consuming and thereforecostly, especially when some labels are very rare.
for this reason, we use active learning (lewis andgale, 1994), which works as follows: in an itera-tive process the active learner presents unlabeleddata to a user, which the user has to label.
the pur-pose of this is to reduce the total labeling effort, byidentifying samples that add the most value to thecurrent model.
the key for this is the query strat-egy, which selects examples to be labeled by theuser.
after labeling the presented samples, a newmodel is trained, and the loop is repeated, eitherfor a speciﬁc number of rounds, or until a stoppingcriterion is met.
we assume the pool-based sce-nario (settles, 2010), in which the active learnerhas access to all unlabeled data.
since no labels areprovided, and the percentage of sentences havingat least one label is quite small, randomly sam-pling data is not an option, and al is the obviouschoice.
because it is easier for the human annota-tor to focus on only a single set of labels duringthe al process, the text classiﬁcation is realizedusing one independent classiﬁer each for restric-.
5https://github.com/fnl/syntok.
4146tions and topics (see table 1).
as the single labelsunder both restrictions and topics are not mutuallyexclusive, we train a multi-hot-encoded multi-labelclassiﬁcation for both label sets..5 experiments.
we evaluate multi-label active learning performedby three human annotators, who each train a sen-tence classiﬁcation model for classifying restric-tions and topics, resulting in two runs per person..5.1 pre-processing and experimental setup.
starting from the initial model, which is trainedon the train set (described in section 3), activelearning is performed iteratively: (1) 10 unlabeledsentences are presented to the annotator; (2) theannotator may assign zero, one, or multiple labelsper sentence; (3) the newly-assigned labels areadded to the train set, and a new model is trained.
this process is repeated for 50 iterations..data we use train, validation and test splits, asdeﬁned in section 4.1, and an unlabeled pool con-sisting of 312,299 sentences..query strategy for the query strategy, which se-lects the sentences to be labeled, we use prediction-entropy-based (roy and mccallum, 2001) uncer-tainty sampling (lewis and gale, 1994), which se-lects the most uncertain samples, e.g., in this casethose whose predicted class posterior exhibits thehighest entropy.
since inference on transformersis computationally expensive, and we aim to keepthe waiting times at a minimum, at the beginningof each iteration, we subsample the whole unla-beled pool randomly by selecting 4096 examples(mukherjee and awadallah, 2020).
moreover, be-cause the ratio of unlabeled sentences to sentenceshaving at least one label is quite large, we adaptthe query strategy to balance classes, by consider-ing the class predictions and sampling evenly overthe labels.
in case this is not possible, e.g., whenthere is no prediction for a certain label, we ﬁllthe remainder with the remaining most uncertainsamples, regardless of the predicted class..is a larger gbert model available, we opted for thebase variant due to its efﬁciency, which results inlower turnaround times of an al step for the prac-titioner.
we encode the labels as multi-hot encodedvectors.
the model is trained using a softmax bi-nary cross-entropy loss..during each active learning iteration, the pre-vious model is ﬁne-tuned for 40 epochs using alearning rate of 5e−5 on the data that has been la-beled to this point.
to avoid overﬁtting, we stopearly when the validation loss has not changed formore than 5 epochs..5.3 results.
table 2 shows the classiﬁcation scores of afore-mentioned setting evaluated by three annotatorsand compared to an automated text classiﬁcationbaseline.
the baseline is a gbert-base model.
f1 b..label.
f1 ala3.
a2.
avg..restrictions.
topics.
a1.
0.960.86.
0.880.91.
0.710.630.500.920.730.790.72.
0.720.71.
0.930.84.
0.870.90.
0.530.580.580.890.780.730.73.
0.700.69.
0.960.86.
0.880.91.
0.730.640.540.910.690.770.74.
0.720.72.
0.940.84.
0.860.89.
0.770.630.530.900.610.730.72.
0.700.70.
0.950.85.
0.870.90.
0.740.630.520.910.680.760.73.
0.710.71.prohibitionrequirement.
micromacro.
weatherconstructiongeotechnicsrestr.
areaplantingenvironmentdisposal.
micromacro.
table 2: active learning experiments, performed bythree human annotators.
“avg.” is the annotator aver-age over all three runs.
“f1 al” shows the ﬁnal scores,broken down by annotator.
“f1 b.” is a text classiﬁca-tion baseline that is trained on the initial training set.
for each label and annotator, we used mcnemar’s test(mcnemar, 1947) with α = 0.05 to test for signiﬁcantchange in the predictions compared to the baseline: wereport obtained p-values, indicated by an underlined re-sult for p < 0.05, and bold text for p < 0.01..5.2 model and training.
regarding the classiﬁcation, we ﬁne-tune the pre-trained gbert-base model (chan et al., 2020),which has 110m parameters and is the best per-forming german transformer model for text classi-ﬁcation at this number of parameters.
while there.
trained on the initial data, i.e., without using al atall.
al improves overall both micro-f1 and macro-f1 for topics by up to 3 percentage points, whereasimprovements for restrictions seem marginal..while the overall result improves just slightly,looking at the single labels, we can see consider-.
4147able changes between plain text classiﬁcation andactive learning.
previously underperforming la-bels like “weather” and “construction” improveon average by 5 to 21 percentage points in f1.
smaller improvements can also be seen for “re-stricted area” and “environment”, and “disposal”stays about the same.
unfortunately, “geotech-nics” and “planting” and also drop in performanceby 6 and 10 percentage points respectively.
inter-estingly, when we compare the difference in therelative quantities of co-occurring labels beforeand after the al process, we ﬁnd that the labeledpool changed notably during al.
we observed that(1) the average number of labels per sentence in-creases; (2) label co-occurrences shift considerablyand some combinations even appear for the ﬁrsttime; (3) every combination of topic labels occurstogether in the data, which is not the case for ourkeyword-bootstrapped train set.
(the exact num-bers be seen in the appendix, figure 4-6)..all in all, this indicates that al is beneﬁcial andimproves classiﬁcation metrics by a small amount,and moreover, many samples with previously rarelyor even unseen label combinations are found.
ap-parently, as these notable changes only lead to asmall difference in f1, this new value of having.
more diverse label combinations is difﬁcult to mea-sure here against our keyword-bootstrapped test set.
the only solution to a more representative test set,however, would require massive annotation efforts,since labels may be very sparse..6 visualization and interaction use case.
as an example, we present a workﬂow regardingareas which may not be entered during heavy rainsfor safety reasons.
to answer a request (see sec-tion 3), which e.g., is asking if a speciﬁc area maybe entered, the expert uses the gis, centers themap on the corresponding area, and displays theassociated features (e.g., active dismantling areas,see figure 2 a).
to enable the expert to analyzethe different feature categories, the displayed fea-tures are colored by category as suggested by ware(2012).
since areas can overlap in the map display,all features are colored only semi-transparently..information immediately prohibiting certain ac-tivities is identiﬁed by clicking on a feature, whichdisplays the non-spatial data in an informationpanel (figure 2 a-b).
to keep the expert’s overviewof the selected features, they are represented witha striped texture.
all restrictions that result fromthe documents linked to the selected feature are.
figure 2: (a) two geographic features of type ”active dismantling” are displayed on a map.
one feature wasselected by mouse click (orange striped texture).
the weather map is shown as isobands, with precipitation valuesrepresented by shades of blue (dark blue tones indicate areas with high precipitation values).
the informationpanel is displayed on the right hand side.
it contains the non-spatial data of the selected geographic feature (b), aswell as the usage restrictions together with a list of other features with similar usage restrictions (c)..4148listed (figure 2 c).
the entries are grouped by therestriction type and sorted by a conﬁdence value(figure 2 c1 and c2).
the document title and thesentence from which the restriction is derived areindicated.
a click on the title opens a new windowfor reading the document.
this list provides theexpert with direct feedback on which documentsmight be relevant and, without reading them com-pletely, an overview of which usage restrictionsare present.
this information is crucial for the ex-perts, as it can have a signiﬁcant impact on plannedprojects and their planning time.
additionally, thearea described by a document can be superimposedwith weather data.
in this way, decisions regard-ing conditional restrictions (e.g., “may not entershore areas during heavy rain”) can also be mademore quickly and directly on the basis of the sys-tem.
the selected features overlap with a heavyrain area represented by isobands, therefore the re-quest is directly answered and access to the area iscurrently prohibited (figure 2 a)..however, for other restrictions, more informa-tion may be necessary, because experts often com-pare the region of interest with similar regions.
therefore, we provide a ﬁlter to highlight all fea-tures within the same restriction topic (figure 2 c).
by analyzing similar regions, the expert can de-rive recommendations for action, which might benecessary for the land reuse of an area.
recommen-dations for possible usage restrictions can also bederived in this way.
furthermore, this comparisoncan prevent actions from not being taken or frombeing taken too late, because the current informa-tion does not make them appear necessary, but itis clear from similar projects that they may never-theless become necessary.
this leads to a safe andquick reuse of regions maintained in that mannersince precautions can be taken in advance..7 conclusions and future work.
in this work, we have presented and evaluated asystem which automates information requests re-lated to the post-management of former open pitmines by leveraging unstructured and geospatialdata.
we used active learning for multi-label textclassiﬁcation to extract restrictions and topics fromunstructured text in legacy documents and visual-ized the results using a gis.
as a result, targetedqueries about restrictions and topics at speciﬁc ge-ographic locations can be obtained much more ef-ﬁciently, thereby speeding up the process of land.
reuse, which directly contributes to several sdgs.
further research is needed to shift recall towards100% to minimize false negatives, then correctingfalse positives in the system..acknowledgments.
we thank the anonymous reviewers for their valu-able and constructive feedback.
we also thank thelmbv for many interesting and fruitful discus-sions.
this research was partially funded by thedevelopment bank of saxony (sab) under projectnumbers 100335729 and 100400221..ethical considerations.
this work presents a workﬂow for the automaticinformation extraction in reports related to min-ing, construction and nature conservation.
the col-lected information represents issues such as accessrestrictions or hazards.
we are aware that misclassi-ﬁcation in the application can lead to people beingendangered or prevented from entering these re-gions for no reason.
misuse cannot be ruled out,but currently no speciﬁc example is known..to ensure that misclassiﬁcations do not impactthe stakeholders of the application, a quality assur-ance process will be used in the operating companyso that employees in the piloting phase manuallycheck where errors or information losses can be de-tected.
in addition, there will be quality assurancefor the application so that the probability of miss-ing restrictions is minimized.
furthermore, our re-sults could in theory lead to a decline in employeesneeded to read and check old documents, possiblyresulting in job losses.
our scenario, however, re-quires specialists, who are not easily replaceable..references.
ram avtar, ridhika aggarwal, ali kharrazi, pankajkumar, and tonni agustiono kurniawan.
2020. uti-lizing geospatial information to implement sdgsand monitor their progress.
environmental monitor-ing and assessment, 192:1–22..galal m. binmakhashen and sabri a. mahmoud.
2019.document layout analysis: a comprehensive survey.
acm comput.
surv., 52(6)..branden chan, stefan schweter, and timo m¨oller.
2020. german’s next language model.
in proceed-ings of the 28th international conference on com-putational linguistics, pages 6788–6796, barcelona,spain (online).
international committee on compu-tational linguistics..4149costanza conforti, stephanie hirmer, dai morgan,marco basaldella, and yau ben or.
2020. naturallanguage processing for achieving sustainable devel-opment: the case of neural labelling to enhance com-munity proﬁling.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing (emnlp), pages 8427–8444, online.
as-sociation for computational linguistics..jeffrey e. herrick,.
tanya abrahamse,.
pu-rushothaman c. abhilash, saleem h. ali, porﬁrioalvarez-torres, aliyu s. barau, cristina bran-quinho, ashwini chhatre, jean-luc chotte, andgraham p. von maltitz.
2019. land restoration forachieving the sustainable development goals: aninternational resource panel think piece.
unitednations environment programme..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4171–4186, minneapolis, minnesota.
associ-ation for computational linguistics..liat ein-dor, alon halfon, ariel gera, eyal shnarch,lena dankin, leshem choshen, marina danilevsky,ranit aharonov, yoav katz, and noam slonim.
2020. active learning for bert: an empiricalin proceedings of the 2020 conference onstudy.
empirical methods in natural language process-ing (emnlp), pages 7949–7962, online.
associa-tion for computational linguistics..esri..entity extraction software unstruc-- arcgis locatext..tured data analysishttps://www.esri.com/en-us/arcgis/products/locatext/overview,on 01/21/2021)..(last accessed.
2016..development.
federal government.
sustainable.
germanmanhttps://www.bundesregierung.de/resource/blob/998220/455740/7d1716e5d5576bec62c9d16ca908e80e/2017-06-20-langfassung-n-en-data.pdf,(last accessed on 05/27/2021)..strategy..ger-.
dirk goldhahn, thomas eckart, and uwe quasthoff.
2012. building large monolingual dictionaries at theleipzig corpora collection: from 100 to 200 lan-guages.
in proceedings of the eighth internationalconference on language resources and evaluation(lrec’12), pages 759–765, istanbul, turkey.
euro-pean language resources association (elra)..carla gomes, thomas dietterich, christopher barrett,jon conrad, bistra dilkina, stefano ermon, feifang, andrew farnsworth, alan fern, xiaoli fern,daniel fink, douglas fisher, alexander flecker,daniel freund, angela fuller, john gregoire, johnhopcroft, steve kelling, zico kolter, warren pow-ell, nicole sintov, john selker, bart selman, danielsheldon, david shmoys, milind tambe, weng-keen wong, christopher wood, xiaojian wu, yex-iang xue, amulya yadav, abdul-aziz yakubu, andmary lou zeeman.
2019. computational sustain-ability: computing for a better world and a sustain-able future.
commun.
acm, 62(9):56–65..j¨urgen kretschmann.
2020..post-mining—a holis-tic approach.
mining, metallurgy & exploration,37(5):1401–1409..klaus krippendorff.
2011. agreement and informationin the reliability of coding.
communication meth-ods and measures, 5(2):93–112..david d. lewis and william a. gale.
1994. a se-quential algorithm for training text classiﬁers.
insigir’94, pages 3–12.
springer..m. luc, u. somorowska, and j.b. szma´nda, editors.
2015. landscape analysis and planning.
springerinternational publishing..magdalena matysik and damian absalon.
2012. re-naturization plan for a river valley subject to highhuman impact-hydrological aspects.
polish journalof environmental studies, 21(2)..quinn mcnemar.
1947. note on the sampling errorof the difference between correlated proportions orpercentages.
psychometrika, 12(2):153–157..subhabrata mukherjee and ahmed awadallah.
2020.uncertainty-aware self-training for few-shot textin advances in neural informa-classiﬁcation.
tion processing systems, volume 33, pages 21199–21212. curran associates, inc..clemens neudecker, konstantin baierer, maria feder-busch, matthias boenig, kay-michael w¨urzner,volker hartmann, and elisa herrmann.
2019. ocr-d: an end-to-end open source ocr framework forin proceedings ofhistorical printed documents.
the 3rd international conference on digital accessto textual cultural heritage, datech2019, page53–58, new york, ny, usa.
association for com-puting machinery..stefanie nowak and stefan r¨uger.
2010. how reliableare annotations via crowdsourcing: a study aboutinter-annotator agreement for multi-label image an-in proceedings of the international con-notation.
ference on multimedia information retrieval, pages557–566..arnaud pincet, shu okabe, and martin pawelczyk.
2019. linking aid to the sustainable developmentgoals – a machine learning approach.
(52)..nicholas roy and andrew mccallum.
2001. towardoptimal active learning through sampling estimationin proceedings of the eigh-of error reduction.
teenth international conference on machine learn-ing, icml 01, pages 441–448.
morgan kaufmannpublishers inc..4150konstantinos sechidis, grigorios tsoumakas, and ioan-nis vlahavas.
2011. on the stratiﬁcation of multi-in joint european conference onlabel data.
machine learning and knowledge discovery indatabases, pages 145–158.
springer..burr settles.
2010. active learning literature survey.
technical report, university of wisconsin-madisondepartment of computer sciences..raymond wensley smith.
1987. the extraction andrecognition of text from multimedia document im-ages.
ph.d. thesis, university of bristol..united nations.
2015. sustainable development goals.
https://sdgs.un.org/goals, (last accessed on05/27/2021)..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in advances in neural information pro-cessing systems, volume 30, pages 5998–6008.
cur-ran associates, inc..colin ware.
2012. information visualization: percep-tion for design, 3 edition.
morgan kaufmann pub-lishers inc., san francisco, ca, usa..michelle yuan, hsuan-tien lin, and jordan boyd-graber.
2020. cold-start active learning throughin proceed-self-supervised language modeling.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages7935–7948, online.
association for computationallinguistics..rubina zern-breuer, margrit seckelmann, norareg¨os, heinrich lorei, kathrin annika kruse,and marco brunzel.
2020. voruntersuchung zureinf¨uhrung eines einheitlichen geodatenmanage-ments in rheinland-pfalz.
projekt rlp-gdm – pro-jektbericht.
speyrer arbeitshefte, (245):1–94..a data.
a.1 keywords.
for each label, the keywords used to create thedataset are shown in table 3..a.2.
inter-annotator agreement.
in table 4 we report krippendorff’s α and fleiss’ κfor three human annotators..a.3 absolute label occurrences.
table 5 shows the absolute label distribution andfigure 3 shows the co-occurrence among labels..figure 3: label co-occurrences..a.4 relative label co-occurrence.
we show the relative label co-occurrence for theinitial labeled set in table 4 (normalized per row).
on the other hand, table 5 shows the relative labelsco-occurrence of the samples selected by the querystrategy.
the difference between those two figuresis shown by figure 6..figure 4: samples found by keyword matching (la-beled data)..4151figure 5: samples found by the query strategy..table 4: krippendorff’s alpha and fleiss’ kappa foreach label, each sample in the dataset was annotatedby three different annotators..label.
krippen-dorff’s α.fleiss’ κ.prohibitionrequirementweatherconstructiongeotechnicsrestricted areaplantingenvironmentdisposal.
0.89880.83030.74000.69910.70950.91400.75790.75420.8118.
0.89950.83170.75060.70100.71500.91430.76530.75550.8138.label.
train test val.
total.
prohibitionrequirementweatherconstructiongeotechnicsrestricted areaplantingenvironmentdisposal.
4714917843469236834.
9329934168681364713569.
4714917843468246835.
1875976833613627394271138.table 5: label distribution in the train-, test-, and vali-dation data set.
figure 6: difference between the labeled data (afteractive learning) and the initial set..noitcirtser.scipot.label.
keywords.
english translation.
s prohibition.
’verboten’, ’nicht gestattet’, ’nicht erlaubt’, ’un-tersagt’, ’unbefugt’, ’darf nicht’.
’not permitted’, ’not allowed’, ’banned’, ’unau-thorized’, ’may not’.
requirement.
’m¨ussen’, ’muss’, ’darf’, ’nur’, ’maximal’,’beachten’.
’must’, ’must’(inﬂected), ’may’, ’only’, ’atmost’, ’consider’.
weather.
construction.
geotechnics.
’nebel’, ’wetter’, ’sturm’, ’starkniederschlag’,’frost’, ’trockenheit’, ’regen’, ’schnee’, ’tem-peratur’.
’fog’, ’weather’, ’storm’, ’heavy rainfall’, ’frost’,’drought’, ’rain’, ’snow’, ’temperature’.
’bebauung’, ’¨uberbauung’, ’errichten’, ’fen-ster’, ’mauer’.
’construction’, ’build on’, ’construct’, ’win-dow’, ’wall’.
’geotechnsch’, ’gel¨ande’, ’risse’, ’absenkung’,’boden’, ’sohle’.
’geotechnical’,’soil’, ’horizon’.
’terrain’,.
’crack’,.
’sinking’,.
restricted area.
’aufenthalt’, ’uferseitig’, ’betreten’, ’befahren’,’anlegen’.
’stay’, ’shore-sided’, ’enter’, ’drive on’, ’dock’.
planting.
’b¨aume’, ’baum’, ’pﬂanzen’, ’f¨allen’, ’forst’.
’trees’, ’tree’, ’ plants’, ’chop’, ’forest’.
environment.
’nester’, ’arten’, ’umwelt’, ’gesch¨utzt’.
’nests’, ’species’, ’environment’, ’protected’.
disposal.
’lager’, ’entsorg’, ’abfall’, ’verbringen’, ’verk-lappen’.
’store’, ’disposal’, ’waste’, ’remove’, ’dumping’.
table 3: keywords used for dataset generation (in german) and their english translation..4152