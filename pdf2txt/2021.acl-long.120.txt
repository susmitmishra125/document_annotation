leveraging type descriptions forzero-shot named entity recognition and classiﬁcation.
rami aly1, andreas vlachos1, ryan mcdonald2∗1computer laboratory, university of cambridge, u.k.2asapp{rami.aly|andreas.vlachos}@cl.cam.ac.uk, ryanmcd@asapp.com.
abstract.
a common issue in real-world applicationsof named entity recognition and classiﬁcation(nerc) is the absence of annotated data fortarget entity classes during training.
zero-shot learning approaches address this issue bylearning models that can transfer informationfrom observed classes in the training data tounseen classes.
this paper presents the ﬁrstapproach for zero-shot nerc, introducing anovel architecture that leverage the fact thattextual descriptions for many entity classes oc-cur naturally.
our architecture addresses thezero-shot nerc speciﬁc challenge that thenot-an-entity class is not well deﬁned, sincedifferent entity classes are considered in train-ing and testing.
for evaluation, we adapt twodatasets, ontonotes and medmentions, em-ulating the difﬁculty of real-world zero-shotlearning by testing models on the rarest en-tity classes.
our proposed approach outper-forms baselines adapted from machine read-ing comprehension and zero-shot text classiﬁ-cation.
furthermore, we assess the effect ofdifferent class descriptions for this task..1.introduction.
named entity recognition and classiﬁcation(nerc) is the task of identifying spans of textcorresponding to named entities and classifyingthese spans from a set of pre-deﬁned entityclasses.
a prevalent issue for many real-worldapplications is that annotated data does not readilyexist.
this motivates the focus on the zero-shotsetting (xian et al., 2018; wang et al., 2019),where annotated data is not available for theclasses of interest.
instead, information availablefrom observed classes must be transferred tounseen target classes..recently zero-shot approaches making use oftextual representations to represent entity classes.
∗ work done when author was working at google..were explored for entity linking (el) (logeswaranet al., 2019; wu et al., 2020) and named entity typ-ing (net) (obeidat et al., 2019), which are similarto the nerc subtask of named entity classiﬁcation(nec).
however, no previous work has addressedthe task of zero-shot nerc, which additionally re-quires the detection of which tokens make up anentity in addition to its type, i.e.
named entityrecognition (ner)..infrastructure (streets, bridges), [...]”.
this paper is the ﬁrst to study zero-shot nerc,by leveraging entity type descriptions.
the taskis illustrated in figure 1. during testing, the in-put is a sentence and a set of target entity classes.
each accompanied by its description, and the goalis to recognize and classify entities in these tar-get classes.
descriptions contain crucial informa-tion for the task.
given as input “shantou har-bour, a natural river seaport, opens to the southchina sea.” and a class facility in figure 1, us-ing a description “names of human-made struc-tures:aconnection between facility and shantou harbourcan be made without having seen an annotated ex-ample in training.
while using descriptions en-ables us to predict entity classes unseen in training,nerc poses the additional challenge of modellingthe negative class (non-entity tokens) as its deﬁ-nition includes different entity classes and tokensin training and testing.
it is possible that wordsobserved as non-entities during training belong toone of the test classes, as seen in figure 1: bothhuaqiao park, in training, and shantou harbour,during testing, are entities of the class facility,however, huaqiao park is labelled as a non-entityin the former..based on this insight we propose several archi-tectures for nerc based on cross-attention be-tween the sentence and the entity type descriptionsusing transformers (vaswani et al., 2017) com-bined with pre-training (devlin et al., 2019).
we.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1516–1528august1–6,2021.©2021associationforcomputationallinguistics1516figure 1: zero-shot named entity recognition and classiﬁcation..explore modelling the negative class by (i) usinga description for the negative class, (ii) modellingthe negative class directly, (iii) modelling the neg-ative class using the representations generated forthe classes corresponding to types..for evaluation we introduce zero-shot adapta-tions to two real-world nerc datasets with dis-tinct properties:the ontonotes (pradhan et al.,2013) as well as the highly domain-speciﬁc med-mentions dataset (mohan and li, 2019).
theadaptations adhere to recommendations to zero-shot evaluation (xian et al., 2018) by evaluatingmodels on the rarest classes while ensuring thatall class sets are disjoint.
our best model achievesa macro f1 of 0.45 on ontonotes-zs and 0.38on medmentions-zs, outperforming a state-of-the-art mrc model for nerc (li et al., 2020;sun et al., 2020) and an adapted zero-shot textclassiﬁcation model (yin et al., 2019).
an anal-ysis on the classiﬁcation and recognition task inisolation highlights the importance of the descrip-tion choice, ﬁnding that annotation guidelines re-sult in higher scores than the class name itself orwikipedia passages..2 zero-shot nerc.
in nerc, given a sentence s = w1, ..., wn oflength n and a description dc for each class c ∈cts in the test set, we predict a sequence of labelsˆy ∈ (cts)n, with n being the length of the sen-tence.
we model the task as multiclass classiﬁca-tion, which despite ignoring the sequential struc-.
ture of the output, it has been found to be compet-itive (lample et al., 2016; rei, 2017).
thus, wepredict the correct class for each token w at po-sition t: arg maxc∈cts f (s, wt, dc), using a suit-able function f modelling the semantic afﬁnitybetween wt and dc in the context of s. the param-eters of f need to be learned without annotateddata for cts, but with annotated data and descrip-tions for the training ctr classes..to model f we focus on the use of cross-attention (humeau et al., 2019; wolf et al., 2019b)in the form of a transformer encoder (vaswaniet al., 2017).
for each type description dc, thecross-attention encoder (x-enc) generates a vec-tor representation vt,c ∈ rh for a token wt in thesentence s:.
v1,c, ..., vn,c = x-enc(s, dc)..(1).
the vector vt,c of each token is then linearly trans-formed.
ot,c = vt,c · wt + b,(2)with vt,c ∈ rh and ot,c ∈ r. the value ot,c indi-cates how likely is that token wt belongs to entityclass c..in order to be able to recognize entities in addi-tion to classifying them, the scores for each tokenot,c1; ...; ot,ck are concatenated with a score for be-longing to the negative class ot,neg, correspondingto not belonging to any of the types considered:.
ot = (ot,c1; ...; ot,ck ; ot,neg)(3)with ot ∈ rk+1.
obtaining a good estimate forthis score is a key challenge in performing zero.
1517 nerc model dev     locationproductwork of art (woa)outsidenames of geographical locations.
these include mountain ranges, ...this can be the name of any product, generally model name ...facilitynames of man-made structures: infrastructure (streets, bridges), ...titles of books, songs, television programs or other creations ...oshantou harbour , a natural river seaport  ,    b-fac        i-fac      o          o          o             o      o   opens  to  the  south   china   sea   .
o        o     o     b-loc       i-loc     i-loc    o        testthe shantou science and technology museum o       b-org        i-org    i-org     i-org            i-orgcompleted construction in november  of    this       o                     o            o      b-date   i-date  i-date   year  near the  huaqiao  park  .
i-date  o       o             o            o      o   orgdatepersonoutsidethese are proper names of people, including ﬁctional people ....these are names of companies, government agencies ...used to classify a reference to a date or period ...otrainobservedclassesctr unseenclassescts sentence strwithannotation  sentence stswithannotation  shot nerc and we discuss it in the next section.
we then select the class with the highest scoreprobability after applying a softmax operation:.
ˆyt = arg max.
f (s, wt, dc).
c∈cts.
= arg max.
c∈cts.
ot,cc(cid:48)∈cts ot,c(cid:48).
..(cid:80).
(4).
we label this model sequential multiclass cross-attention model (smxm).
referring to the ini-tial example, cross-attention enables shantou har-bour to attend to infrastructure in the type descrip-tion of the class facility, generating a representa-tion for this token based on the type description inthe context of the sentence..cross-attention encoder the cross-attentionmodel is based on the pre-trained transformer en-coder bert (devlin et al., 2019) which allows themodel to capture surface-level information as wellas semantic aspects between all words of the input(jawahar et al., 2019).
for x-enc the input tuple(s, dc) is structured in the form: xx-enc = [cls] s[sep] dc [sep]..2.1 modelling the negative class.
as discussed in section 1, the non-entity class cre-ates a challenging setting it is possible that wordsobserved as non-entities during training belongto one of the test classes.
we explore three ap-proaches to modelling the negative class: (i) us-ing a (textual) description for the negative class,(ii) modelling the negative class directly, (iii) mod-elling the negative class using the representationsgenerated for the classes corresponding to types..description-based encoding assuming a de-scription for the negative class dneg, it is straight-forward to obtain a representation vt,neg for eachtoken belonging to it using the cross-attention en-coder, which is then transformed to a score via aweight vector wneg for this class:.
ot,neg = vt,neg · wt.
neg + bneg.
(5).
however, this approach requires a description todescribe something that is not rather than is.
thismakes it very difﬁcult in practice to make an in-formed decision on the most suitable description.
also, non-entity tokens are likely to differ betweentraining and testing, thus a ﬁxed description is un-likely to perform well..independent encoding the negative class canbe directly modelled since it is observed in thetraining data.
thus, instead of exploring cross-attention, each token is represented for the nega-tive class in the context of the sentence withouttaking any description into account:.
v1,neg, ..., vn,neg = enc(s),.
(6).
with enc being a standard transformer encoder(vaswani et al., 2017).
similar to the description-based approach, vt,neg is linearly transformed toot,neg using a separate vector wneg (c.f.
eq.
5)..class-aware encoding description-based andindependent encodings do not model the fact thatnot every entity labelled as a non-entity duringtraining is a non-entity during testing in zero-shotnerc.
instead, we propose to model the negativeclass by combining the representations generatedfor the other classes, as generated by the cross-attention encoder (eq.
1): vt,c0, ..., vt,ck.
eachvector is then linearly transformed, using wneg−cland then concatenated to a feature map m. wethen apply a max-pooling operation over this fea-ture set and take the maximum value:.
ot,neg−cl = max{m}..(7).
finally, we compute ot,neg by linearly combiningthe representation from the independent encodingand ot,neg−cl..2.2 training.
to prevent the cross-attention encoder from over-ﬁtting on the few class descriptions, we use a reg-ularizer in the form of entity masking, inspired bythe masked language modelling objective used inbert, to train the model on the training classesctr .
during training with a probability p (tunedas a hyperparameter) the entire entity that is to beclassiﬁed is masked in the input to the model.
thisregularization avoids lexical memorization and en-courages the model to learn entity context to classdescription afﬁnities, while still learning to incor-porate aspects of the entity itself (e.g.
capitaliza-tion, shape, morphology) and relating them to thetype description.
a cross-attention model for taskssuch as el is much less likely to overﬁt since eachentity is associated with a unique description andthere is a much larger number of them than entityclasses.
due to the label imbalance caused by the.
1518statistic.
ontonotes-zsdev.
train.
test.
medmentions-zs.
train.
dev.
test.
# sentences# words# total entities# compound entities# consecutive entities# consecutive entities of same class# unique mentions (not in train).
599241088503545763125779023448–.
852814772417859054939634.
82621527281754162812195495.
28226721552113095590313054514727–.
93022423581710806125120574.
93822417861431637152147721.table 1: quantitative statistics of zero-shot dataset ontonotes-zs and medmentions-zs..train.
person(15429),date(10922).
gpe(15405),.
org(12820),.
dev.
test.
norp(847), money†(274), ordinal†(232),percent†(177), event(143), product(72),law(40)cardinal†(945), time†(212), loc(179), workfac(135), quantity†(105),of art(166),language†(22).
biologic function(24989), chemical(22351), health-care activity(14764), anotomical structure(12571),finding(9811), spatial concept(7511),intellectualproduct(5994), research activity(5443), eukary-ote(4922), population group(3574), medical de-vice(1165)organization(452), injury or poisoning(434), clinicalattribute(404), virus(224), biomedical occupation ordiscipline(196)bacterium(449),or occupationalprofessionalgroup(360), food(321), body substance(212), bodysystem(89).
table 2: zero-shot class splits and number of occurrences for ontonotes-zs and medmentions-zs.
trivialclasses for which a rule-based system is sufﬁcient are denoted with †..negative class, we use class weights qc incorpo-rated to the cross-entropy loss:.
c(cid:88).
i=1.
qi · p(yt,i) · log(p(ˆyt,i))..(8).
while the factor q is kept to 1 for all non-negativeclasses, for the negative class q is set using theunderlying training dataset distributions using theratio# non-entity words and further tuned within thatrange as a hyperparameter..# entities.
3 evaluation setup.
3.1 datasets for zero-shot nerc.
we present adaptations to ontonotes (pradhanet al., 2013) and medmentions (mohan and li,2019) for zero-shot nerc evaluation.
ontonotesis a common benchmark dataset for nerc sys-tems while the more recent medmentions datasetconsists of domain-speciﬁc biomedical data.
theannotations in the latter are based on the uniﬁedmedical language system (umls) ontology (bo-denreider, 2004) and do not only include propernamed entities but also concepts.
for instance,in the passage “modeling nurse-patients”, mod-eling is annotated with the concept researchactivity, thus rendering it more challenging..the adaptations follow recommendations for(i).
zero-shot evaluation by xian et al.
(2018):.
zero-shot methods should be evaluated on therarer classes, as in real-world scenarios annotateddata is likely to be available for the more commonones, (ii) evaluation metrics should focus on per-class averaged scores to account for the imbalancein terms of samples per class, thus we evaluate ourmodels with the macro-averaged f1 metric, (iii)hyperparameters have to be tuned on a develop-ment set of classes disjoint from both the trainingand test set, (iv) pre-trained neural networks usedfor zero-shot learning can be trained on arbitraryamount of data as long as the training data doesnot contain samples of the test set..to create the zero-shot versions of bothontonotes and medmentions abiding by rule(i) we measure the frequencies of their respec-tive entity types and keep the four and elevenmost frequent ones in ontonotes and medmen-tions, respectively, for training.
the remain-ing ones are split between development and testset by sorting them by frequency and then as-signing them alternating between the two sets.
to create the zero-shot splits we use the defaultdata splits and remove all annotations of classesthat are not associated with the respective split.
quantitative statistics of ontonotes-zs andmedmentions-zs are shown in table 1. in ad-dition to ensuring that we evaluate on the rarer.
1519classes, we also wanted to ensure the classes con-sidered are not trivial to recognize.
for example,the class percent in ontonotes is only assignedto percentages, whose surface form follow regularpatterns, while work of art or product aremore difﬁcult to recognize.
based on the annota-tion guidelines of ontonotes, seven classes wereidentiﬁed to be trivial to recognize (c.f.
denotedwith † in table 2).
to verify this, a simple rule-based system developed for these classes achievedbetween 0.60 and 0.89 micro f1, only slightlyworse than the fully supervised state-of-the-artnerc model of (li et al., 2020) (see supplemen-tary material).
these classes were excluded fromour experiments.
we did not identify such trivialclasses in medmentions..3.2 entity type descriptions.
source avg.
#tokens longest desc.
shortest desc..glwnwiki.
snmtwiki.
575881.
3467142.
129164160.
102116221.
41319.
111417.table 3: quantitative characteristics for different entitytype description sources.
statistics measured in tokensand calculated over all classes..a basic description is to simply use the classname itself.
in addition, we consider three readilyavailable type description sources for each dataset.
the options for ontonotes are:.
annotation guidelines [gl] they have beenused to annotated the dataset.
these descriptionsare highly informative containing precise deﬁni-tions accompanied by examples, as they shouldhelp a human perform the task..wordnet [wn] secondly, descriptions of thelexical database wordnet are employed using it’ssynsets feature..wikipedia [wiki] the ﬁrst one to three sen-.
tences of the most related article to a class..for medmentions, we use the aforementioned.
wikipedia descriptions, as well as:.
umls semantic network [sn] since themedmentions dataset is based on the umls on-tology we explore the short descriptions providedby the umls semantic network browser1..1https://uts.nlm.nih.gov/.
semanticnetwork.
umls metathesaurus [mt] the metathe-saurus2 browseris a search engine that ag-glomerates information of different biomedicalsources.
for entity type not found in it, seman-tically similar or subordinate classes are used, e.g.
biomedical research for biomedicaloccupation or discipline.
quantitativecharacteristcs of the description types are shownin table 3..to obtain negative type descriptions, three man-ually selected sentences from the training set areused that are free of any named entities.
we alsoexplored alternating between multiple negative de-scriptions that we had compiled, however, resultswere generally worse..4 experiments.
4.1.implementation details.
all models are implemented using pytorch(paszke et al., 2017) and the huggingface im-plementation (wolf et al., 2019a) of bert, usingthe case-sensitive version of bert-large unlessotherwise stated.
the results reported are the av-erages of two runs..all i- or b- preﬁxes to a label were removed forsimplicity.
therefore, each entity class is deﬁnedby a single label.
this simpliﬁcation results in am-biguity for the nerc task in the case of two con-secutive named-entities of the same class, howeverit reduces the model parameters by half while af-fecting 5.8% of the entities across the validationand test splits of both datasets (c.f.
row # consec-utive entities of same class in table 1).
sentenceswithout any annotations were also excluded..the pre-training data of bert has been com-pared to the development and test splits of bothdatasets to ensure that it has not been pre-trainedon testing data (rule (iv) of xian et al.
(2018)) 3..the hyperparameters for each model weremainly optimized on the validation split of theontonotes dataset considering only the non-trivialclasses, and then used for the experiments withthe medmentions-zs dataset.
only the learn-ing rate was tuned for medmentions-zs sepa-rately.
the best model according to developmentmacro-averaged f1 during training was tested inall experiments on both datasets.
further details.
2https://uts.nlm.nih.gov/uts/umls3the dataset has been compared only to the latest.
wikipedia dump as the book corpus is not hosted anymore..1520on the hyperparameter choice are in the supple-mentary material..4.2 baseline models.
while a simple tf-idf similarity baseline that mea-sures the overlap between the sentence and en-tity description by computing the cosine similar-ity shown to be a good baseline for zero-shot en-tity linking (logeswaran et al., 2019), f1 scoreson nerc were consistently below 0.04 on bothdatasets.
similar observation applies to similarityscores based on word2vec embeddings (mikolovet al., 2013) as used in (yin et al., 2019), highlight-ing the difﬁculty of this task.
our baselines thusfocus on current state-of-the-art models in bothnerc and related zero-shot tasks..binary entailment model (bem) is an nercadjusted model of the state-of-the-art approachfor zero-shot text classiﬁcation (yin et al., 2019).
they employ bert, ﬁne-tuned on an entailmentdataset,to classify whether a class description(the text is about x) is entailed by the text.
toadapt this model to nerc, we modify the descrip-tion to the word is of type x with x being the en-tity class name, and classify each word instead ofthe entire sentence.
since their model generatesa binary output for each class, the negative pre-diction for all classes predicts the negative class.
by treating each sentence-description pair inde-pendently, the relationship between classes as wellas the complexity of the negative class in zero-shotevaluation is ignored.
we ﬁne-tune bert-largeon mnli (williams et al., 2018), as it performedbest in the experiments of (yin et al., 2019), be-fore training bem on the zero-shot datasets us-ing adjusted class weights, which has been cru-cial for successful training of the model; not usingit resulted in degenerated solutions in preliminaryexperiments.
the proposed entity masking objec-tive is not suitable for bem’s binary classiﬁcationapproach as it would simply learns to predict themasked token to be an entity during training..mrc for nerc is an approach by li et al.
(2020) who construct queries for entity classes andtransform nerc to a machine reading compre-hension task for fully supervised ﬂat and nestednerc.
their model generates a span by predict-ing start and end indices for each entity as wellas a matching score for each possible start-end in-dex.
predictions for each entity type are made in-dependently, similar to bem.
their model showed.
ontonotes-zs.
model.
dev.
test.
bemmrcsmxmsmxmbase.
token span token span0.110.280.180.150.250.350.200.30.
0.180.150.230.19.
0.230.220.450.42.medmentions-zs.
model.
dev.
test.
bemmrcsmxmsmxmbase.
token span token span0.220.280.260.190.270.330.210.31.
0.190.210.230.20.
0.340.230.380.30.
4:.
of nerc onmacro-averaged f1tableontonotes-zs and medmentions-zs,re-porting token-based and span-based scores for allbaselines and smxm with class-aware encoding.
bestresults are highlighted in bold.
base indicates a modelbased on the smaller bert-base encoder.
all othermodels use bert-large encoders..promising results for the transfer learning experi-ment when training on the conll03 dataset andtesting on ontonotes, with the latter consisting ofa superset of conll03 entity classes, yet it wasnot tested on completely distinct training and testlabels, i.e.
zero-shot learning.
however, results forour zero-shot task were too low to be considered.
we hypothesise two causes:i) in our zero-shotsetup the dataset is heavily imbalanced, as mosttoken spans are not entities (typically one to threeout of n2 in a sentence of length n) ii) an incorrectprediction in either the start index, end index, ormatching score results in an overall incorrect span,and the accuracy for each of these is unlikely to behigh in the zero shot setup.
thus, we simpliﬁedthe model by excluding the matching matrix, andwe use the start and end index with greedy closest-matching to compute the entity span, similar to(sun et al., 2020).
mrc also has been trained us-ing adjusted class weights..4.3 results.
nerc results for both datasets are shown in ta-ble 4, for both token and span-level f1.
weonly report results on the best performing en-tity description which is the same across allmodels, i.e.
annotation guidelines and metathe-saurus descriptions for ontonotes-zs and.
1521medmentions-zs, respectively; we discuss theimpact of description choice in the next section.
shown smxm results use class-aware encodingof the negative class since it performed betterthan the other approaches considered (c.f.
section4.4).
statistical signiﬁcance was determined usingthe two-tailed monte carlo permutation test with5000 repetitions with p < 0.05..our proposed model, smxm, performs signif-icantly better than all models on both datasets,with a token-level score of 0.45 on and 0.38 forontonotes-zs and medmentions-zs, re-spectively.
comparing smxm with smxmbase,trained on the smaller bert-base (335m vs109m parameters) highlights the value of largerscale pretraining for domain-speciﬁc applications.
scores decrease on both datasets when using thesmaller model, with a substantial decrease onmedmentions-zs to only 0.30. despite itssmaller size, smxm with bert-base remains com-petitive to both bem and mrc which use bert-large.
the bem baseline achieves signiﬁcantlybetter token-level scores than mrc for nerc onthe development split of ontonotes-zs and onboth splits of medmentions.
while the mrcfor nerc model achieves poor token-level re-sults, its span-level scores are more comparable tobem and smxm, even signiﬁcantly outperform-ing bem on the medmentions-zs develop-ment split despite a much lower token-level score.
mrc for nerc has the smallest delta between thetoken and span-level score out of all models, yetoverall scores remained low due to the difﬁcultyof inferring the correct start and end index basedonly on the description in a zero-shot setup andgeneralizing to new, unseen types, e.g.
determin-ing whether the article the belongs to an entityor not (the is part of date but generally not ofproduct)..per-class scores scores for each class usingsmxm are shown in table 5. for ontonotes,scores are comparable across the different classes,with work of art performing worse than theothers.
in contast, for medmentions some classesare recognized and classiﬁed with comparablyhigh accuracy, such as bacterium, while bodysubstance and body system score very low.
a possible explanation is the similarity (in seman-tics and/or description) between these classes andclasses used for training.
for instance, some ex-ample entities in body system’s description are.
also found in anatomical structure (e.g.
cardiovascular system).
this would further ex-plain the very high recall but low precision, as en-tities belonging to the training classes are (erro-neously) identiﬁed as entities of these test classes..classfaclocwork of artbacteriumbody substancebody systemfoodprof. or occ.
group.
precision0.350.390.380.550.090.080.330.31.recall0.750.820.350.790.580.870.680.65.f1-score0.480.530.360.660.170.160.470.44.table 5: class-based token-level macro-f1 scores ofsmxm on the test set of ontonotes-zs (top) andmedmentions-zs (bottom)..4.4 discussion.
analysis of entity descriptions results on thedevelopment set using smxm with the differententity descriptions introduced in section 3.2 areshown in table 6. annotation guideline descrip-tions performs signiﬁcantly better than all otherdescriptions on ontonotes-zs.
metathesaurusdescriptions work best on medmentions-zs,with semantic network descriptions performingonly slightly worse.
using the class name isa surprisingly strong baseline description, per-forming comparably to wordnet descriptions onontonotes-zs and even better than wikipediaon medmentions-zs.
while wikipedia workswell on general types, it performs poorly on thedomain-speciﬁc types of medmentions-zs..modelclass namewikiwn/sngl/mt.
ontonotes-zs medmentions-zsspanspan tokentoken0.180.280.180.250.190.270.210.320.210.290.200.260.220.310.230.35.table 6: averaged macro f1 of nerc on the dev setsfor smxm with different type descriptions..analysing the scores, we identiﬁed three prop-erties of descriptions with negative effect on per-formance: vagueness, noise, and negation.
mostumls based type descriptions are abstract or un-derspeciﬁed, and require either substantial back-ground information or expert knowledge to be.
1522the three domains of.
useful; for instance, eukaryote in sn descrip-life, alsotion (“one ofcalled eukarya.
these are organisms whose cellsare enclosed in membranes and possess a nu-cleus.”).
furthermore, many descriptions con-tain noise or unrelated information (e.g.
those ob-tained by wikipedia).
finally, classes deﬁned bynegations or cross-references to other classes re-sult in worse performance, as negated sentencesadd less information about the class in question.
cross-references cannot be processed by any ofthe models, as they cannot directly link parts of aclass’ description to another.
exploring this semi-structured knowledge is interesting future work.
on the other hand, we found that explicit examples(e,g.
“infrastructure (streets, bridges)”) and men-tions of syntactic and morphological cues (e.g.
“these are usually surrounded by quotation marksin the article [...]”) make the annotation guidelinesperform particularly well..to validate this qualitative analysis, we mod-iﬁed each dataset’s best performing descriptionwith the aim to make one worse and one better.
first, we worsen the annotation guidelines by re-moving all explicit mentions of entities and syn-tactic cues.
the token-based macro-f1 for nercwhen using smxm decreased by 0.05 when ex-plicit examples are removed.
secondly, to improvethe metathesaurus descriptions we removed nega-tions, made them less abstract, and added explicitexamples..the modiﬁcations on the umls descriptionsimprove the scores by around 0.03 on the devel-opment set.
we used the modiﬁed metathesaurusdescriptions for all models in result table 4 and ta-ble 7. only around forty minutes have been in-vested to modify the umls annotations withoutexpertise in the biomedical domain, likely leavingmuch room for improvements..non-entity class modelling we separately anal-ysed how well the different approaches model thenegative class.
results on the development setare reported in table 7. the token-level scoreof smxmca with the class-aware encoding of thenegative class outperforms both the independentencoding smxmind.
as well as the negative classdescription based encoding smxmdesc.
approachsigniﬁcantly on the nerc task, conﬁrming themotivation of this approach..modelsmxmdesc.
smxmind.
smxmca.
ontonotes-zs medmentions-zsspanspan tokentoken0.190.290.180.240.210.300.190.280.230.330.230.35.table 7: macro-averaged f1 of nerc on the dev set ofontonotes-zs and medmentions-zs for differ-ent approaches to modelling the negative class..alternative class splits whileswitchingclasses between the development and test splitresulted in overall similar results (tested on threedifferent splits for medmentions), reducing thenumber of training classes and redistributing themon the dev and test splits led to a substantialdecrease in performance.
results for the extremecase where the number of training classes formedmentions-zs has been reduced to the fourmost frequent ones (with the dev and test setshaving eight and nine classes, respectively) areshown in table 8. as seen, smxm still performsthe best, however, only with a score of 0.14..model.
dev.
test.
token span token span0.070.10bem0.05mrc0.070.09smxm 0.13.
0.060.080.09.
0.100.060.14.table 8: macro-averaged f1 of nerc on the modiﬁedclass splits with only four training classes and nine testclasses on medmentions-zs..complexity the complexity of our model’s andbaselines’ encoding step in terms of classes iso(c), with c being the number of test classes (in-cluding the negative class).
this is an increase incomplexity over o(1) in the traditional scenario,however, during training the gradients are accu-mulated across the inputs, leading to faster conver-gence.
with varying description lengths for differ-ent sources (c.f.
table 3), the input sequence lengthis another important factor to consider regardingthe model’s efﬁciency, leading to an overall com-plexity of o(cn 2), with n being the length ofthe input sequence.
in our experiments, the run-time with smxmbase was the shortest, followedby bem (due to the entailment descriptions beingmuch shorter), smxm, and last mrc..1523ﬁned class descriptions have also been exploredfor relation classiﬁcation (obamuyide and vla-chos, 2018) who pose the task as one of textualentailment.
obeidat et al.
(2019) use descriptionsfor zero-shot net, however, similar to a previousattempt by ma et al.
(2016), they use the under-lying hierarchy to only include unseen classes inthe leaves of the hierarchy to reduce the relevantunseen classes to only two or three..the only work on zero-shot word sequence la-belling (rei and søgaard, 2018) explores the trans-fer from labels on a sentence level objective (e.g.
sentiment analysis) to a token or phrase-basedannotation, similar to t¨ackstr¨om and mcdonald(2011).
guerini et al.
(2018) label their approachzero-shot named entity recognition, however, theyfocus on recognizing unseen entities not entityclasses.
finally, fritzler et al.
(2019) focusedon few-shot nerc using prototypical networks(snell et al., 2017).
they tested their model inthe zero-shot setting, but concluded that their ap-proach is not suitable for zero-shot learning as theresults on ontonotes were too low..6 conclusions & future work.
this paper explored the task of zero-shot nercwith entity type descriptions to transfer knowledgefrom observed to unseen classes.
we addressedthe zero-shot nerc speciﬁc challenge that thenot-an-entity class is not well deﬁned by propos-ing a multiclass architecture that uses class-awareencoding to model the negative class.
the modelswere evaluated based on zero-shot adaptations ofthe ontonotes and medmentions dataset.
the re-sults show that the proposed model outperformsstrong baselines and further indicate that high-quality entity descriptions (i.e.
annotation guide-lines) are an effective way to transfer knowledgefrom observed to unseen classes.
future work willaim to incorporate the dependencies between thelabels predicted..acknowledgements.
we thank the anonymous reviewers for their timeand effort giving us feedback on our paper.
thiswork was supported by the engineering and phys-ical sciences research council doctoral train-ing partnership (epsrc).
andreas vlachos is sup-ported by the erc grant averitec (ga 865958)..figure 2: learning behavior analysis of smxm andsmxm w/o entity masking on ontonotes-zs dev..entity masking finally, we study the impact ofentity masking in figure 2. first, we plot the val-idation f1 score during training for smxm andsmxm w/o entity masking using guideline anno-tations.
second, the training loss of the same mod-els in terms of cross-entropy (i.e.
eq.
8).
the topplot shows that smxm’s f1 score converges moreslowly but to a higher value than smxm’s highestvalue w/o masking by 0.03 points.
the model’svalidation f1 w/o entity masking decreases in lateriterations, indicating overﬁtting.
we conﬁrmedthis by observing a higher validation loss whenno masking is used.
interestingly, as seen in theloss plot (bottom), the training loss is much lowerwhen using entity masking.
this is likely due toentity masking providing additional implicit su-pervision to the model: masked tokens cannot bethe non-entity class.
for these masked tokens themodel can focus on the entity classiﬁcation in iso-lation which appears to help the model extractmore useful supervision signal, as indicated bythe higher validation f1 achieved.
when trainedwith masking, smxm’s training loss closely fol-lows the trend of the validation f1, indicating goodtransfer learning from the model’s training objec-tive to the zero-shot evaluation..5 related work.
state-of-the-art approaches to nerc include thebidirectional lstm-crf (lample et al., 2016),and more recently models based on the pre-trained transformer architectures, e.g.
bert (de-vlin et al., 2019).
these methods are unsuitablefor zero-shot learning, with exception to the ex-plored baselines in this paper (li et al., 2020; sunet al., 2020).
apart from nerc, manually de-.
15240.00.10.20.30.40.5f scoresmxmsmxm w/o masking050010001500200025003000number of steps1013×1024×1026×1022×1013×101training lossreferences.
olivier bodenreider.
2004. the uniﬁed medical lan-guage system (umls): integrating biomedical ter-minology.
nucleic acids research, 32:d267–d270..jason p.c.
chiu and eric nichols.
2016. named en-tity recognition with bidirectional lstm-cnns.
transactions of the association for computationallinguistics, 4:357–370..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language un-in proceedings of the 2019 confer-derstanding.
ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1, pages 4171–4186,minneapolis, mn, usa..alexander fritzler, varvara logacheva, and maksimkretov.
2019. few-shot classiﬁcation in named en-in proceedings of the 34thtity recognition task.
acm/sigapp symposium on applied computing,sac ’19, pages 993–1000, limassol, cyprus..abbas ghaddar and phillippe langlais.
2018. ro-bust lexical features for improved neural networkin proceedings of thenamed-entity recognition.
27th international conference on computationallinguistics, pages 1896–1907, santa fe, nm, usa..marco guerini, simone magnolini, vevake balaraman,and bernardo magnini.
2018. toward zero-shotentity recognition in task-oriented conversationalagents.
in proceedings of the 19th annual sigdialmeeting on discourse and dialogue, pages 317–326, melbourne, australia..samuel humeau, kurt shuster, marie-anne lachaux,and jason weston.
2019. poly-encoders: architec-tures and pre-training strategies for fast and accu-in international con-rate multi-sentence scoring.
ference on learning representations, new orleans,la, usa..ganesh jawahar, benoˆıt sagot, and djam´e seddah.
2019. what does bert learn about the structurein proceedings of the 57th annualof language?
meeting of the association for computational lin-guistics, pages 3651–3657, florence, italy..diederik p. kingma and jimmy ba.
2015. adam: ain 3rd inter-method for stochastic optimization.
national conference on learning representations,ca, usa..guillaume lample, miguel ballesteros, sandeep sub-ramanian, kazuya kawakami, and chris dyer.
2016.neural architectures for named entity recognition.
in proceedings of the 2016 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,pages 260–270, san diego, ca, california..peng-hsuan li, ruo-ping dong, yu-siang wang, ju-chieh chou, and wei-yun ma.
2017. leverag-ing linguistic structures for named entity recogni-tion with bidirectional recursive neural networks.
in proceedings of the 2017 conference on empiri-cal methods in natural language processing, pages2664–2669, copenhagen, denmark..xiaoya li, jingrong feng, yuxian meng, qinghonghan, fei wu, and jiwei li.
2020. a uniﬁed mrcin pro-framework for named entity recognition.
ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5849–5859, online..lajanugen logeswaran, ming-wei chang, kentonlee, kristina toutanova, jacob devlin, and honglaklee.
2019. zero-shot entity linking by readingentity descriptions.
in proceedings of the 57th an-nual meeting of the association for computationallinguistics, pages 3449–3460, florence, italy..ilya loshchilov and frank hutter.
2019. decoupledweight decay regularization.
in international con-ference on learning representations 2019, new or-leans, la, usa..yukun ma, erik cambria, and sa gao.
2016. la-bel embedding for zero-shot ﬁne-grained named en-in proceedings of coling 2016, thetity typing.
26th international conference on computationallinguistics: technical papers, pages 171–180, os-aka, japan..tomas mikolov, ilya sutskever, kai chen, greg s cor-rado, and jeff dean.
2013. distributed representa-tions of words and phrases and their composition-ality.
in advances in neural information processingsystems 26, pages 3111–3119, lake tahoe, usa..sunil mohan and donghui li.
2019. medmentions:a large biomedical corpus annotated with umlsin proceedings of the 2019 conferenceconcepts.
on automated knowledge base construction (akbc2019), amherst, ma, usa..abiola obamuyide and andreas vlachos.
2018. zero-shot relation classiﬁcation as textual entailment.
in proceedings of the first workshop on fact ex-traction and veriﬁcation (fever), pages 72–78,brussels, belgium..rasha obeidat, xiaoli fern, hamed shahbazi, andprasad tadepalli.
2019. description-based zero-shot fine-grained entity typing.
in proceedings ofthe 2019 conference of the north american chap-ter of the association for computational linguistics:human language technologies, volume 1, pages807–814, minneapolis, mn, usa..adam paszke, sam gross, soumith chintala, gre-gory chanan, edward yang, zachary devito, zem-ing lin, alban desmaison, luca antiga, and adamlerer.
2017. automatic differentiation in pytorch.
in 2017 conference on neural information process-ing systems, long beach, ca, usa..1525chapter of the association for computational lin-guistics: human language technologies, volume 1(long papers), pages 1112–1122, new orleans, la,usa..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, r’emi louf, morgan funtow-icz, and jamie brew.
2019a.
huggingface’s trans-formers: state-of-the-art natural language process-ing.
arxiv, abs/1910.03771..thomas wolf, victor sanh, julien chaumond, andclement delangue.
2019b.
transfertransfo: atransfer learning approach for neural network basedconversational agents.
arxiv, abs/1901.08149..ledell wu, fabio petroni, martin josifoski, sebas-tian riedel, and luke zettlemoyer.
2020. scal-able zero-shot entity linking with dense entity re-trieval.
in proceedings of the 2020 conference onempirical methods in natural language processing(emnlp), pages 6397–6407, online..yongqin xian, christoph h. lampert, bernt schiele,and zeynep akata.
2018. zero-shot learning - acomprehensive evaluation of the good, the bad andieee transactions on pattern analysisthe ugly.
and machine intelligence, 41:2251–2265..wenpeng yin, jamaal hay, and dan roth.
2019.benchmarking zero-shot text classiﬁcation:datasets, evaluation and entailment approach.
inproceedings of the 2019 conference on empiricalmethods in natural language processing andthe 9th international joint conference on naturallanguage processing, pages 3912–3921, hongkong, china..martin popel and ondˇrej bojar.
2018. training tipsfor the transformer model.
the prague bulletin ofmathematical linguistics, 110(1):43–70..sameer pradhan, alessandro moschitti, nianwen xue,hwee tou ng, anders bj¨orkelund, olga uryupina,yuchen zhang, and zhi zhong.
2013. towards ro-bust linguistic analysis using ontonotes.
in pro-ceedings of the seventeenth conference on com-putational natural language learning, pages 143–152, soﬁa, bulgaria..marek rei.
2017. semi-supervised multitask learn-in proceedings of theing for sequence labeling.
55th annual meeting of the association for compu-tational linguistics, pages 2121–2130, vancouver,canada..marek rei and anders søgaard.
2018. zero-shotsequence labeling: transferring knowledge fromin proceedings of the 2018sentences to tokens.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 1, pages 293–302,new orleans, la, usa..victor sanh, lysandre debut, julien chaumond, andthomas wolf.
2020. distilbert, a distilled versionof bert: smaller, faster, cheaper and lighter.
in5th workshop on energy efﬁcient machine learningand cognitive computing..jake snell, kevin swersky, and richard zemel.
2017.prototypical networks for few-shot learning.
in ad-vances in neural information processing systems30, pages 4077–4087, long beach, ca, usa..cong sun, zhihao yang, lei wang, yin zhang,hongfei lin, and jian wang.
2020.biomedi-cal named entity recognition using bert in the ma-chine reading comprehension framework.
arxiv,2009.01560..oscar t¨ackstr¨om and ryan mcdonald.
2011. discov-ering fine-grained sentiment with latent variablestructured prediction models.
in proceedings of the33rd conference on advances in information re-trieval, lecture notes in computer science, pages368–374, dublin, ireland..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in advances in neural information pro-cessing systems 30, pages 5998–6008, vancouver,canada..wei wang, vincent w. zheng, han yu, and chunyanmiao.
2019. a survey of zero-shot learning: set-tings, methods, and applications.
acm trans.
intell.
syst.
technol., 10(2):1–37..adina williams, nikita nangia, and samuel bowman.
2018. a broad-coverage challenge corpus for sen-tence understanding through inference.
in proceed-ings of the 2018 conference of the north american.
1526supplementary material.
6.1 details on the evaluation setup.
of.
rule.
money.
slightly.
versions.
severalthedifferentontonotes dataset have been used in papers.
our ontonotes version aligns with the ones usedin (li et al., 2017; ghaddar and langlais, 2018;chiu and nichols, 2016).
classpercent any token that is % and its preceding num-ber, as well as the preceding adverb such as’about’, ’around’, or ’approximately’.
any token [dollars, euro, yuan, pound,...] or its symbolic representation and pre-ceding numbers, incl.
[hundred(s)’, thou-sand(s)’, ’million(s)’, ’billion(s)’].
any word that is either ’ﬁrst’, ’second’, or’third’, or compound of ’th’ and a number.
language frequent languages (english, german,...)and if preceded by [in, into, speak, write,talk, listen, ...]’a.m’, ’p.m.’, ’morning’, ’evening’, ’night’,’minute(s)’, ’hour(s)’ etc.
and any preced-ing or consecutive numerical and relevantadverb/preposition..ordinal.
time.
quantity one of ca.
20 si units (incl..its abbrevi-ation) and preceding number and relevantadverb/preposition..cardinal cardinal is only marked if it is a nu-merical and not a year nor ordinal,money, percentage, nor quantity..table 9: rule-based approach on non-challengingclasses of ontonotes-zs..6.2 details on the experimental setup.
experiments were run on a quadro rtx 8000.the parameter vectors/matrices w and wneg havebeen randomly initialized from a uniform distribu-tion u (−.
b) with b =.
√.
√.
b,.
1in-features ..the models use the adam optimizer (kingmaand ba, 2015) with decoupled weight decay, calledadamw (loshchilov and hutter, 2019).
recom-mendations of related literature have been takeninto account when selecting the hyperparametersand search space (devlin et al., 2019; sanh et al.,2020; popel and bojar, 2018).
the tuned hyper-parameters are the batch size, learning rate lr,weight decay ld, linear dropout dr, entity mask-ing probability p and warmup steps wr.
allmodels use ld = 0, dr = 0.5, and wr = 0as they have not been very sensitive regardingthese parameters.
for the learning rate, the rateslrbem = 4e−6, lrm rc = 4e−6, lrsm xm =4e−6, were used4.
for medmentions, smxm uses.
lrsm xm = 7e−6.
interestingly, these optimallearning rates are lower than recommended in theoriginal paper (between 2e−5 and 5e−5) (devlinet al., 2019).
the batch size was set to 20 forbem and mrc5.
for smxm we use a batch sizeof 8 for ontonotes-zs6, which was the largestbatch size that ﬁtted into the gpu since smxmaccumulates the gradients when fed as input forx-enc.
for medmentions-zs, we had to fur-ther reduce the batch size to 5. the masking prob-ability p was set to 0.7 for smxm7.
a model wastrained for a maximum of 3 epochs.
for medmen-tions the class weight q for the negative class is setto 0.1 and for ontonotes to 0.01..the maximum sequence length to inputtobert was restricted to 300, with a maximumof 150 tokens for the description itself.
due tothe restrictions to gpu memory, we used a se-quence length of 200 when training smxm onmedmentions-zs, with 100 tokens being themaximum length of a type description..for training, all models further use i) an early-stop scheduler to stop the training after no im-provement on the validation f1 score was detectedfor three consecutive steps, ii) a scheduler that re-duces the learning rate linearly over the numberof trained steps until it reaches zero with the lasttraining step, similarly to the one described in (de-vlin et al., 2019).
the bert entailment model usedfor bem was trained on mnli with the defaulthyperparameters used in (devlin et al., 2019): lr= 2e−5, epochs= 3, and we used a batch size of= 100..span-level scores are computed using the seqe-.
val library8..6.2.1 details on the baselines.
we explored the model of li et al.
(2020) byboth re-implementing their paper and also by us-ing our zero-shot dataset on their publicly avail-able repository9.
several parameter settings wereexplored, with additional sanity checks.
trainingwas stopped after ten epochs.
yet, in both attemptsthe macro f1 for the best model stayed only barelyabove zero on ontonotes-zs.
regarding thementioned causes for the low zero-shot nerc.
5exploration range: [7, 25]6exploration range: [5, 8]7exploration range: [0.3 0.7]8https://pypi.org/project/seqeval/9https://github.com/shannonai/.
4exploration range: [1e−7,5e−5].
mrc-for-flat-nested-ner.
1527scores of mrc for nerc, we have additionallynoticed that in a fully supervised setting class-level scores when using the aforementioned repos-itory are very high for very frequently observedclasses, but comparably low for rare classes, in-dicating that substantial supervision is required toperform well, as the model is very sensitive to pre-diction errors as argued in the paper..6.2.2 example type descriptions.
classfac.
loc.
law.
event.
descriptionnames of man-made structures:in-frastructure (streets, bridges), buildings,monuments, etc.
belong to this type.
buildings that are referred to using thename of the company or organization thatuses them should be marked as fac whenthey refer to the physical structure ofthe building itself, usually in a locativeway: ”i’m reporting live from right out-side [massachusetts general hospital]”names of geographical locations otherthese include mountainthan gpes.
ranges, coasts, borders, planets, geo-coordinates, bodies of water.
also in-cluded in this category are named regionssuch as the middle east, areas, neighbor-hoods, continents and regions of conti-nents.
do not mark deictics or othernon-proper nouns: herea, there, every-where, etc..television pro-grams and other creations.
also includesawards.
these are usually surrounded byquotation marks in the article (though thequotations are not included in the annota-tion).
newspaper headlines should onlybe marked if they are referential.
in otherwords the headline of the article being an-notated should not be marked but if in thebody of the text here is a reference to anarticle, then it is markable as a work ofart.
any document that has been made into alaw, including named treaties and sectionsand chapters of named legal documents.
named hurricanes, battles, wars, sportsevents, attacks.
metonymic mentions(marked with a ∼) of the date or locationof an event, or of the organization(s) in-volved, are included)..work of art titles of books, songs,.
table 10: snippet of ontonotes nerc annotationguidelines.
all rights of these descriptions belong to(pradhan et al., 2013) and ratheon bbn technologies..1528