hierec: hierarchical user interest modeling forpersonalized news recommendation.
tao qi1, fangzhao wu2, chuhan wu1, peiru yang1, yang yu2, xing xie2 and yongfeng huang11department of electronic engineering & bnrist, tsinghua university, beijing 100084, china2microsoft research asia, beijing 100080, china{taoqi.qt, wufangzhao, wuchuhan15, peiruyang17}@gmail.comyfhuang@mail.tsinghua.edu.cn{t-yyu,xing.xie}@microsoft.com.
abstract.
user interest modeling is critical for personal-ized news recommendation.
existing news rec-ommendation methods usually learn a singleuser embedding for each user from their pre-vious behaviors to represent their overall inter-est.
however, user interest is usually diverseand multi-grained, which is difﬁcult to be ac-curately modeled by a single user embedding.
in this paper, we propose a news recommen-dation method with hierarchical user interestmodeling, named hierec.
instead of a sin-gle user embedding, in our method each useris represented in a hierarchical interest tree tobetter capture their diverse and multi-grainedinterest in news.
we use a three-level hierarchyto represent 1) overall user interest; 2) user in-terest in coarse-grained topics like sports; and3) user interest in ﬁne-grained topics like foot-ball.
moreover, we propose a hierarchical userinterest matching framework to match candi-date news with different levels of user interestfor more accurate user interest targeting.
ex-tensive experiments on two real-world datasetsvalidate our method can effectively improvethe performance of user modeling for person-alized news recommendation..1.introduction.
recently, massive people are habituated to readingnews articles on online news platforms, such asgoogle news and microsoft news (khattar et al.,2018; das et al., 2007).
to help users efﬁcientlyobtain their interested news information, person-alized news recommendation technique that aimsto recommend news according to user interests, iswidely used by these platforms (wu et al., 2020a;liu et al., 2010; lin et al., 2014)..user interest modeling is a critical step for per-sonalized news recommendation (wu et al., 2021;zheng et al., 2018; wu et al., 2020c).
existingmethods usually learn a single representation vector.
figure 1: click and non-click logs of an example user..to model overall user interests from users’ clickednews (okura et al., 2017; wu et al., 2020b; anet al., 2019).
for example, okura et al.
(2017)used a gru network to model user interests fromclicked news.
they used the latest hidden state ofgru as the user interest representation.
wu et al.
(2019e) used multi-head self-attention network tocapture user interests, and used an attentive pool-ing network to obtain a uniﬁed user representation.
however, user interest is usually diverse and multi-grained.
for example, as shown in fig.
1, a usermay have interest in movies, sports, ﬁnance andhealth at the same time.
in addition, for users whoare interested in sports, some of them may havegeneral interest in this area, while other users likethe example user in fig.
1 may only have interestin a speciﬁc sport like football.
however, it is dif-ﬁcult for these methods to accurately model thediverse and multi-grained user interest for newsrecommendation via a single user embedding..in this paper, we propose a personalized newsrecommendation approach with hierarchical userinterest modeling, named hierec, which can effec-tively capture the diverse and multi-grained userinterest.
our approach contains three levels of userinterest representations to model user interests indifferent aspects and granularities.
the ﬁrst oneis subtopic-level, which contains multiple interestrepresentations to model ﬁne-grained user interestsin different news subtopics (e.g., interest in footballand golf).
they are learned from embeddings ofsubtopics and the clicked news in the correspond-.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages5446–5456august1–6,2021.©2021associationforcomputationallinguistics5446ing subtopics.
the second one is topic-level, whichcontains multiple interest representations to capturecoarse-grained user interests in major news top-ics (e.g., interest in sports and ﬁnance).
they arelearned from embeddings of news topics and theirsubordinate subtopic-level interest representations.
the third one is user-level, which contains an inter-est representation to model overall user interests.
itis learned from topic-level interest representations.
besides, we propose a hierarchical user interestmatching framework to match candidate news withdifferent levels of interest representations to targetuser interests more accurately.
extensive experi-ments on two real-world datasets show that hiereccan effectively improve the accuracy of user inter-est modeling and news recommendation..user interest representation from representations ofclicked news via an attention network.
besides, allof these three methods adopted the inner productfor matching candidate news.
most existing meth-ods learn a single user embedding to represent theoverall user interests (wang et al., 2018; wu et al.,2019e,b).
however, user interests are usually verydiverse and multi-grained, which are difﬁcult tobe accurately modeled by a single user embedding.
different from these methods, we propose a hierar-chical user interest modeling framework to modeluser interests in different aspects and granularities.
in addition, we propose a hierarchical user interestmatching framework to understand user interest incandidate news from different interest granularitiesfor more accurate user interest targeting..2 related work.
3 hierec.
personalized news recommendation is an impor-tant intelligent application and is widely studied inrecent years (bansal et al., 2015; wu et al., 2019c;qi et al., 2020; ge et al., 2020).
existing meth-ods usually model news from its content, modeluser interest from user’s clicked news, and rec-ommend candidate news based on their relevancewith user interests (okura et al., 2017).
for exam-ple, okura et al.
(2017) utilized an auto-encoder tolearn news representations from news bodies.
theyapplied a gru network to capture user interestsfrom the sequence of users’ historical clicks andused the last hidden state vector of gru as userinterest representation.
besides, they proposed tomodel relevance between user interest and candi-date news based on the dot product of their rep-resentations.
wu et al.
(2019a) learned news rep-resentations from news titles, bodies, categories,and subcategories based on an attentive multi-viewlearning framework.
they build user interest rep-resentation based on the attentive aggregation ofclicked news representations.
an et al.
(2019) useda cnn network to learn news representations fromnews titles and categories.
they applied a grunetwork to user’s clicked news to build a short-term user interest representation and applied userid embedding to learn long-term user interest rep-resentation.
they further learned a uniﬁed userinterest representation based on the aggregation ofshort- and long-term user interest representation.
liu et al.
(2020) proposed to learn news represen-tations from news titles and entities via a knowl-edge graph attention network.
they also obtained.
in this section, we ﬁrst give a problem formulationof personalized news recommendation.
then weintroduce our hierec method in detail..3.1 problem formulation.
given a candidate news nc and a target user u,the goal is calculating an interest score o to mea-sure the interest of this user in the candidatenews.
each news n has a title, a topic t and asubtopic s. the title is composed of a text se-quence t = [w1, w2, ..., wt ] and an entity se-quence e = [e1, e2, ..., ee], where wi and ei re-spectively denote the i-th word and entity in newstitle, t and e respectively denote the number ofwords and entities.
we assume the user has mclicked news.
in hierec, we further divide theseclicks based on their topics and subtopics for hierar-chical user interest modeling.
more speciﬁcally, webuild a clicked topic set {ti|i = 1, ..., m} from top-ics of user’s clicks, where ti is the i-th clicked topicand m is the number of clicked topics.
we can fur-ther obtain a clicked subtopic set {sij|j = 1, ..., d}subordinate to each clicked topic ti, where sij is thej-th clicked subtopic subordinate to topic ti and dis the size of the set.
finally, user’s clicked news intopic ti and subtopic sij are divided into the samek |k = 1, ..., l}, where ni,jj = {ni,jclick group n ikdenotes the k-th clicked news in this group and l isthe number of clicked news in the group..3.2 hierarchical user interest modeling.
in general, user interest is usually very diverse andmulti-grained.
for example, according to fig.
1,.
5447figure 2: framework of hierarchical user interest modeling in hierec..the example user has interests in many differentaspects at the same time, such as sports, movies,and ﬁnance.
besides, for users who are interestedin sports, some of them may have general inter-ests in this area and may read news on differentkinds of sports, such as basketball, football, golf,and so on.
while other users (like the exampleuser in fig.
1) may only have interest in a speciﬁcsport like football.
understanding user interest indifferent aspects and granularities has the poten-tial to model user interests more accurately.
thus,we propose a hierarchical user interest modelingframework, which learns a hierarchical interest treeto capture diverse and multi-grained user interest.
as shown in fig.
2, hierec represents user interestsvia a three-level hierarchy..j is learned from n i.first, we learn multiple subtopic-level interestrepresentations to model ﬁne-grained user inter-ests in different news subtopics (e.g.
football andgolf).
the subtopic-level interest representation forsubtopic sij that is composed ofuser’s clicked news in subtopic sij. since clickednews may have different informativeness for mod-eling user interest, we adopt a subtopic-level atten-tion network to select informative clicked news formodeling user interest in subtopic sij:.
cij =.
γkni,j.
k , γk =.
l(cid:88).
k=1.
exp(φs(ni,jk ))p=1 exp(φs(ni,j.
p )).
(cid:80)l., (1).
k in n i.where γk denotes the attention weight of the k-thclicked news ni,jj , ni,jk is the representationof news ni,jk (section.
3.4 introduces how to obtainit) and φs(·) denotes a dense network.
besides, wealso adopt a subtopic embedding layer to capturesemantic information of different subtopics, from.
which we can obtain the embedding vector sij ofsubtopic sij. finally, we learn the subtopic-leveluser interest representation usi,j based on the com-j, i.e., usj and sibination of cij. similarly,we also learn subtopic-level interest representationsfor other subtopics clicked by the user..i,j = ci.
j + si.
second, we learn multiple topic-level interestrepresentations to model coarse-grained user in-terests in major news topics (e.g.
sports and ﬁ-nance).
the topic-level interest representation for aclicked topic ti is learned from subtopic-level inter-est representations {usi,j|j = 1, ..., d} of subtopics{sij|j = 1, ..., d} subordinate to the topic ti.
morespeciﬁcally, user interests in different subtopicsmay have different importance for modeling userinterest in a speciﬁc topic.
besides, the numberof clicked news on a subtopic may also reﬂect itsimportance for modeling topic-level user interest.
thus, we utilize a topic-level attention network toselect important subtopic-level user interest repre-sentations to model user interest in topic ti:.
zi =.
βjus.
i,j, βj =.
d(cid:88).
j=1.
exp(φt(vsi,j))k=1 exp(φt(vs.(cid:80)d.i,k)).
, (2).
i,j; ri.
i,j = [us.
j], riwhere vsj is the embedding vec-tor for the number of clicked news on subtopic sij,[·; ·] is the concatenation operation, βj is the atten-tion weight of usi,j, and φt(·) is a dense network.
besides, we also use a topic embedding layer tomodel semantic information of different topics anddrive the embedding vector ti for topic ti.
finally,we aggregate zi and ti to learn the topic-level userinterest representation uti = zi + ti.
similarly, we also learn topic-level interest repre-sentations for other clicked topics..i in topic ti: ut.
5448figure 3: framework of hierarchical user interest matching in hierec..third, we learn a user-level interest representa-tion ug to model overall user interests.
it is learnedfrom topic-level interest representations.
similarly,we adopt a user-level attention network to modelrelative importance of topic-level user interests tolearn user-level interest representation:.
ug =.
αiut.
i, αi =.
m(cid:88).
i=1.
exp(φg(vti))j=1 exp(φg(vt.j)).
(cid:80)m.,.
(3).
i = [ut.
where vti; ri], ri is the embedding vector forthe number of user’s clicked news on topic ti, αidenotes the attention weight of the i-th topic-levelinterest representation, and φg(·) denotes a densenetwork for calculating attention scores..3.3 hierarchical user interest matching.
matching between candidate news and user inter-ests at different granularities can provide variousclues for user interest targeting.
for example, ac-cording to fig.
1, although all of the 3rd, 4th, and5th news are about sports, the user only clicks the3rd news probably because of her ﬁne-grained in-terests in football rather than basketball and golf.
this implies that the matching between candidatenews and ﬁne-grained user interests is useful forpersonalized news recommendation.
besides, notall candidate news can match with ﬁne-grained userinterests.
for instance, a news on subtopic base-ball cannot match any ﬁne-grained interests of theexample user in fig.
1. fortunately, the coarse-grained user interests (i.e., interest in sports) andoverall user interests can match with this candidatenews.
this implies that matching candidate newswith coarse-grained user interests and overall userinterests is also important.
thus, we propose a hier-archical user interest matching framework, whichmodels user interests in candidate news from dif-ferent interest granularities.
as shown in fig.
3, it.
takes candidate news (including its representationnc, topic tc and subtopic sc) and hierarchical userinterest representation as input.
first, we matchcandidate news with overall user interests and cal-culate a user-level interest score og based on therelevance between nc and ug: og = nc · ug..second, topic-level interest representation uttcmodels coarse-grained user interests in the topic tcof candidate news.
it can provide coarse-grainedinformation to understand user interest in candidatenews.
thus, we match topic-level interest represen-tation uttc with candidate news nc as: ˆot = nc · uttc.
besides, we can infer users may be more inter-ested in topics that they have clicked more.
thus,we weights ˆot based on the ratio wtc of topic tcin historical clicked news and obtained topic-levelinterest score ot: ot = ˆot ∗ wtc .
besides, if the can-didate news does not belong to any user’s clickedtopics, we set ot as zero directly..third, subtopic-level interest representation usscmodels ﬁne-grained user interest in the subtopicsc of candidate news and can be used to captureﬁne-grained user interests in candidate news.
thus,we match subtopic-level interest representation usscand candidate news nc as: ˆos = nc · ussc similarly,we weights ˆos based on the ratio wsc of subtopic scin user’s clicked news and obtain the subtopic-levelinterest score: os = ˆos ∗ wsc ..finally, interest scores of three different levels.
are aggregated to an overall interest score o:.
o = λsos + λtot + (1 − λs − λt)og,.
(4).
where λt, λs, ∈ r+ are hyper-parameters for con-trolling the relative importance of interest scores ofdifferent levels.
besides, we have λt + λs < 1..3.4 news representation.
we introduce how to obtain news representationfrom texts and entities of news titles.
as shown in.
5449# news65,2381,126,508.
# topics1828.
# subtopics270-.
# users94,05750,605.
# clicks347,727473,697.mindfeeds.
table 1: statistic information of the two datasets..erec.
the ﬁrst one is the public mind dataset (wuet al., 2020d)1. it is constructed by user behaviordata collected from microsoft news from october12 to november 22, 2019 (six weeks), where userdata in the ﬁrst four weeks was used to constructusers’ reading history, user data in the penultimateweek was used for model training and user datain the last week was used for evaluation.
besides,mind contains off-the-shelf topic and subtopic la-bel for each news.
the second one (named feeds)is constructed by user behavior data sampled from acommercial news feeds app in microsoft from jan-uary 23 to april 01, 2020 (13 weeks).
we randomlysample 100,000 and 10,000 impressions from theﬁrst ten weeks to construct training and validationset, and 100,000 impressions from the last threeweeks to construct test data.
since feeds only con-tains topic label of news, we implement a simpli-ﬁed version of hierec with only user- and topic-level interest representations on feeds.
besides,following wu et al.
(2020d), users in feeds wereanonymized via hash algorithms and de-linkedfrom the production system to protect user privacy.
detailed information is summarized in table 1..next, we introduce experimental settings andhyper-parameters of hierec.
we use the ﬁrst 30words and 5 entities of news titles and users’ re-cent 50 clicked news in experiments.
we adoptpre-trained glove (pennington et al., 2014) wordembeddings and transe entity embeddings (bor-des et al., 2013) for initialization.
in hierec, theword and entity self-attention network output 400-and 100-dimensional vectors, respectively.
besides,the uniﬁed news representation is 400-dimensional.
attention networks (i.e., φs(·), φt(·), and φg(·))are implemented by single-layer dense networks.
besides, dimensions of topic and subtopic embed-dings are 400, both of which are randomly ini-tialized and ﬁne-tuned.
the hyper-parameters forcombining different interest scores, i.e.
λt and λs,are set to 0.15 and 0.7 respectively.
moreover, weutilize dropout technique (srivastava et al., 2014)and adam optimizer (kingma and ba, 2015) fortraining.
hierec is trained for 5 epochs with 0.0001.figure 4: news representation learning framework..fig.
4, we ﬁrst use a text encoder to model newstexts.
it ﬁrst applies a word embedding layer toenrich semantic information of the model.
next, itadopts a text self-attention network (vaswani et al.,2017) to learn word representations from contextsof news texts.
then, it uses a text attention net-work to learn text representation nt by aggregatingword representations.
besides texts, knowledgegraphs can also provide rich information for under-standing news content via entities in news (wanget al., 2018).
thus, we apply an entity encoder tolearn entity representation of news.
we ﬁrst use anentity embedding layer to incorporate informationfrom knowledge graphs into our model.
we furtherapply an entity self-attention network to capture re-latedness among entities.
next, we utilize an entityattention network to learn entity representation neof news by aggregating entities.
finally, we buildrepresentation n of news as: n = wtnt + wene,where wt and we are parameters..3.5 model training.
following (wu et al., 2019d), we utilize thence loss for model optimization.
given a pos-itive sample n+(a clicked news) in the trainingidataset o, we randomly select k negative sam-ples [n1i ] (non-clicked news) for it from thesame news impression displayed to the user u. thence loss l requires the positive sample shouldbe assigned a higher interest score o+than otherinegative samples [o1i ] and is formulated as:.
i , ..., nk.
i , ..., ok.l = −.
log.
|o|(cid:88).
i=1.
exp(o+i )i ) + (cid:80)kj=1 exp(oji ).
..exp(o+.
(5).
4 experiment.
4.1 experimental datasets and settings.
we conduct extensive experiments on two real-world datasets to evaluate the effectiveness of hi-.
1we use the small version of mind for quick experiments..this dataset is at https://msnews.github.io/index.html.
5450mind.
ebnrdkndannamlnpalsturnrmskredgnewsrecfimhierec.
auc61.62±0.1563.99±0.2364.68±0.1364.30±0.3064.28±0.5365.68±0.3565.43±0.1565.89±0.3165.91±0.2164.65±0.1467.95±0.14.
mrr28.07±0.1828.95±0.0829.78±0.1329.81±0.1729.64±0.3330.44±0.3930.74±0.1830.80±0.3230.50±0.2129.70±0.1732.87±0.08.
ndcg@530.55±0.2231.73±0.1432.63±0.2132.64±0.2432.28±0.3733.49±0.4533.13±0.1733.78±0.2733.56±0.2132.51±0.2536.36±0.07.
ndcg@1037.07±0.2138.38±0.1739.27±0.1539.11±0.2038.93±0.3939.95±0.3939.66±0.1540.23±0.2640.13±0.1839.30±0.1642.53±0.10.
auc63.48±0.3262.94±0.2262.67±0.4964.48±0.2464.02±0.6365.01±0.1365.27±0.1965.51±0.1165.23±0.1665.41±0.2366.23±0.10.
feeds.
mrr28.01±0.1828.05±0.2627.75±0.3428.99±0.1328.71±0.3929.28±0.0629.40±0.1529.57±0.0629.36±0.1129.57±0.1829.82±0.11.
ndcg@532.05±0.2332.15±0.3431.74±0.4433.37±0.1633.01±0.5033.74±0.0933.89±0.1634.04±0.0633.87±0.1334.08±0.2534.42±0.13.
ndcg@1037.64±0.2237.68±0.3637.42±0.4338.90±0.1838.55±0.4739.16±0.1139.34±0.1539.60±0.0539.44±0.1239.56±0.2339.94±0.13.
table 2: performance of different methods.
the improvement of hierec over the best baseline method is signiﬁcantat level p < 0.01 based on t-test..learning rate.
all hyper-parameters of hierec andbaseline methods are manually tuned on the valida-tion set.2 following wu et al.
(2019e), we use fourranking metrics, i.e., auc, mrr, ndcg@5, andndcg@10, for performance evaluation..4.2 main results.
we ﬁrst introduce the baseline methods we com-pared in experiments: (1) ebnr (okura et al.,2017): learning user representations from the se-quence user’s clicked news via a gru network.
(2) dkn (wang et al., 2018): using a candidate-aware attention network to learn user representa-tions.
(3) dan (zhu et al., 2019): using an attentivelstm network to learn user representations.
(4)naml (wu et al., 2019a): learning user represen-tations by attentively aggregating user’s clickednews.
(5) npa (wu et al., 2019b): learning newsand user representations via personalized attentionnetworks.
(6) lstur (an et al., 2019): model-ing short-term user interests from user’s clickednews via a gru network and long-term user in-terests from user-news interactions via user idembeddings.
(7) nrms (wu et al., 2019e): ap-plying multi-head self-attention networks to learnnews representations and user representations.
(8)kred (liu et al., 2020): proposing a knowledgegraph attention network to learn news represen-tations from texts and entities of news titles.
(9)gnewsrec (hu et al., 2020): modeling short-termuser interests from clicked news sequences via anattentive gru network and long-term user inter-ests from user-news click graph via a graph neuralnetwork.
(10) fim (wang et al., 2020): modelinguser interests in candidate news from semantic rel-evance of user’s clicked news and candidate news.
2https://github.com/julysinceandrew/hierec.
via a 3-d cnn network..each experiment is repeated 5 times.
the av-erage results and standard deviations are listed intable 2, from which we have several observations.
first, hierec signiﬁcantly outperforms other base-line methods which learn a single user embeddingto model overall user interests, such as nrms, npa,and naml.
this is because user interests are usu-ally diverse and multi-grained.
however, it is dif-ﬁcult for a single representation vector to modeluser interests in different aspects and granularities,which may be suboptimal for personalized newsrecommendation.
different from these methods,we propose a hierarchical user interest modelingframework, which can represent diverse and multi-grained user interests via a three-level hierarchy.
besides, we also propose a hierarchical user inter-est matching framework to match user interest withcandidate news from different granularities, whichcan better target user interests.
second, hiereccan signiﬁcantly outperform fim, which directlymodel user interests in candidate news from thesemantic relevance of candidate news and user’sclicked news.
this may be because fim did notconsider user interests from different granularitiesfor matching candidate news..4.3 effectiveness in user modeling.
to fairly compare different methods with hierecon the performance of interest modeling, we com-pare them based on the same news modelingmethod (the news modeling method introduced insection 3.4).
experimental results are summarizedin table 3 and we only show experimental resultson mind in the following sections.
table 3 showsthat hierec signiﬁcantly outperforms existing in-terest modeling methods.
this is because user in-.
5451namldknebnrlsturgnewsrecnrmshierec.
auc65.81±0.2766.03±0.2765.90±0.2766.02±0.1466.16±0.1466.04±0.2167.95±0.14.
mrr30.89±0.2131.17±0.2530.86±0.2131.16±0.1531.19±0.0531.20±0.1932.87±0.08.
ndcg@534.16±0.3034.47±0.3334.14±0.3034.37±0.1534.40±0.0934.53±0.2236.36±0.07.
ndcg@1040.55±0.2440.85±0.2940.58±0.2440.83±0.1240.82±0.1040.89±0.1842.53±0.10.
table 3: effect of hierec in user interest modeling..figure 6: recall rates of different methods..figure 5: effect of hierarchical user interest modeling..terests are usually diverse and multi-grained.
it isdifﬁcult for existing methods with single user em-bedding to capture user interests in different aspectsand granularities.
different from these methods,hierec learns a three-level hierarchy to representdiverse and multi-grained user interests..4.4 ablation study.
we evaluate the effectiveness of user interest rep-resentations of different levels by removing thecorresponding interest matching scores from eq.
4.results are shown in fig.
5 and we have severalﬁndings.
first, hierec with user- and topic- orsubtopic-level interest representation signiﬁcantlyoutperforms hierec with only user-level interestrepresentation.
this is because matching candi-date news with ﬁne-grained user interests has thepotential to improve the accuracy of news recom-mendation.
topic- and subtopic-level interest rep-resentation can model ﬁner-grained user intereststhan the user-level interest representation.
thus,they can provide additional information to matchcandidate news than user-level interest represen-tation.
second, hierec with interest representa-tions of three levels also outperforms hierec withuser- and topic- or subtopic-level interest represen-tation.
this may be because matching candidatenews with user interests of different granularitiescan help perform more accurate interest matching.
since topic- and subtopic-level interest representa-.
figure 7: performance of different methods on recom-mendation diversity..tion capture user interests at different granularities,incorporating both of them can further improve therecommendation performance..4.5 performance on recall and diversity.
next, we compare different user interest modelingmethods on the news recall task.3 since methodsthat model user interests with candidate news in-formation, e.g., dkn and gnewsrec, cannot beapplied in the news recall task due to efﬁciency is-sues (pal et al., 2020), we do not compare them inexperiments.
we evaluate the accuracy and diver-sity of top k recalled candidate news.
followingexisting works (pal et al., 2020; chen et al., 2018),the former is measured by recall rates, and the latteris measured by intra-list average distance (ilad).
for hierec, we employ subtopic-level interest rep-resentations to perform multi-channel news recalland equally integrate news recalled by differentinterest channels.
experimental results are summa-rized in fig.
6 and fig.
7, which show that hierecsigniﬁcantly outperforms other methods in termsof both recall rates and diversity.
this is becauseuser interests are usually very diverse and multi-.
3news recall task aims to recall a small number of candi-date news from a large news pool according to user interests..5452figure 8: recommendation results of hierec and gnewsrec for the same impression.
the news clicked by theuser in this impression is in blue and bold..didate news.
however, matching candidate newswith both overall and coarse-grained user interestsis important for personalized news recommenda-tion.
thus, a moderate λs, i.e., 0.65 or 0.7, issuitable for hierec.
third, when λs is ﬁxed, theperformance of hierec also ﬁrst gets better withthe increase of λt and gets worse when λt is toolarge.
this is because hierec cannot effectivelyutilize information of ot when λt is too small.
be-sides, hierec cannot effectively utilize informationof og and os when λt is too large.
thus, a moderateλt, i.e., 0.12 or 0.15, is suitable for hierec..4.7 case study.
we conduct a case study to show the superior per-formance of hierec.
we compare hierec withgnewsrec since gnewsrec achieves best aucscore in table 2 among baseline methods.
in fig.
8,we show the top 5 news recommended by hierecand gnewsrec in a randomly sampled impression.
besides, we also show the historical clicks of thetarget user in this impression.
we can ﬁnd that thetop 5 news recommended by gnewsrec is domi-nated by news on politics, which cannot compre-hensively cover different user interests.
this isbecause user interests are usually diverse and multi-grained.
however, it is difﬁcult for gnewsrec,which learns a single representation to model over-all user interests, to effectively capture user inter-ests in different aspects and granularities.
differentfrom gnewsrec, the top 5 news recommended byhierec are diverse and can cover topics that theuser may be interested in.
besides, the user clickeda news recommended by hierec.
this is becausehierec learns a hierarchical user interest represen-tation which can effectively model user interests indifferent aspects and granularities.
with the helpof the hierarchical user interest representation, hi-erec can match candidate news with user interestsin different aspects and granularities..figure 9: inﬂuence of hyper-parameters..grained, which are difﬁcult to be comprehensivelymodeled by a single representation vector.
dif-ferent from these methods, hierec hierarchicallyrepresents user interests and can better model userinterests in different aspects and granularities.
be-sides, this also implies that compared to existingpersonalized methods, hierec can help users ex-plore more diverse information and alleviate ﬁlterbubble issues (nguyen et al., 2014) to some extent..4.6 hyper-parameters analysis.
as shown in fig.
9, we analyze the inﬂuence oftwo important hyper-parameters of hierec (i.e.,λt, λs) used for combining different levels of in-terest scores.
first, when λt is ﬁxed, performanceof hierec ﬁrst gets better with the increase of λs.
this is because λs controls the importance of os.
bedsides, os measures the relevance of candidatenews and ﬁne-grained user interests, which canprovide accurate information to understand userinterests in the candidate news.
when λs is toosmall, hierec cannot effectively exploit informa-tion in os.
second, large value of λs also hurts theperformance of hierec.
this is because when λsis too large, hierec cannot effectively exploit user-and topic-level matching scores to recommend can-.
54535 conclusion.
in this paper, we propose a personalized news rec-ommendation method named hierec for hierarchi-cal user interest modeling, which can effectivelymodel diverse and multi-grained user interests.
hi-erec learns a three-level hierarchy to representuser interest in different aspects and granularity.
first, we learn multiple subtopic-level interest rep-resentations to model ﬁne-grained user interests indifferent news subtopics.
second, we learn mul-tiple topic-level interest representations to modelcoarse-grained user interests in several major newstopics.
third, we learn a user-level interest repre-sentation to model overall user interests.
besides,we propose a hierarchical user interest matchingframework to match candidate news with user in-terest from different granularity for more accurateuser interest targeting.
extensive experiments ontwo real-world datasets show the effectiveness ofhierec in user interest modeling..acknowledgments.
this work was supported by the national naturalscience foundation of china under grant numbersu1936208, u1705261, u1936216, and u1836204.
we thank tao di and wei he for their great com-ments and suggestions..ethics and impact statement.
in this paper, we present hierec to model diverseand multi-grained user interest.
hierec can beapplied to online news platforms for personalizednews recommendation, which can help platformsimprove user experience and help users ﬁnd in-terested news information.
although hierec canbring many beneﬁts, it may also have several po-tential risks, which we will discuss in detail..accuracy although hierec outperforms base-line methods in term of recommendation accuracy(table 2), it may also have some inaccurate recom-mendation results that users are not interested in.
users usually just ignore them and will not clickthem to read.
the user experience may be harmedand users may use the online news service less inthe future, or turn to other online news platforms.
privacy in hierec, we rely on user behaviordata centrally stored on the news platform formodel training and online services.
user behaviordata is usually privacy-sensitive, and its centralizedstorage may lead to privacy concerns and risks.
in.
the future, we will explore to train and deploy hi-erec in a more privacy-preserving way based onsome effective privacy protection techniques likefederated learning (qi et al., 2020)..diversity filter bubbles and echo chambers arethe common problem for many recommender sys-tems (nguyen et al., 2014), which harms user ex-perience.
improving recommendation diversity hasthe potential to alleviate the problem of ﬁlter bub-bles and echo chambers.
through experiments infig.
7, we ﬁnd that hierec can outperform manynews recommendation methods in term of recom-mendation diversity.
thus, compared with existingmethods, hierec has the potential to alleviate ﬁlterbubble problem to some extent.
besides, in order tofurther improve recommendation diversity, hiereccan be combined with some existing methods inthis ﬁeld like dpp (chen et al., 2018)..fake news and clickbait there may be somefake news and clickbait in some online platforms.
in order to handle the negative social impact and theuser experience harm brought by these fake newsand clickbait, online news platforms can use someexisting fake news detection and clickbait detectiontechniques such as (kumar et al., 2018; shu et al.,2019) to ﬁlter these kinds of news before applyinghierec for personalized recommendation..fairness like many other recommender sys-tems, hierec relies on user behavior data for modeltraining and online service.
the bias in user be-havior data may lead to some speciﬁc groups ofusers not be able to receive news information withsufﬁcient accuracy and diversity, and the recom-mendation results may be more suitable for somemajor populations.
recently, some fairness-awarerecommendation methods like fairrec (wu et al.,2021) have been proposed to eliminate bias and un-fairness in recommender systems.
we can combinehierec with these methods to improve the fairnessof the recommendation results and mitigate theharms for marginalized populations..misuse the proposed hierec method works ina data-driven way.
it trains the model from the userlogs and makes personalized recommendations tousers based on their interest inferred from theirclicked news.
however, in some extreme cases, therecommendation results may be maliciously ma-nipulated to inﬂuence users.
to avoid the potentialmisuse, the usage of hierec should comply withthe regulations and laws, and intentional manipula-tion should be prohibited..5454references.
mingxiao an, fangzhao wu, chuhan wu, kun zhang,zheng liu, and xing xie.
2019. neural news recom-mendation with long-and short-term user representa-tions.
in acl, pages 336–345..trapit bansal, mrinal das, and chiranjib bhat-tacharyya.
2015.content driven user proﬁlingfor comment-worthy recommendations of news andblog articles.
in recsys., pages 195–202..antoine bordes, nicolas usunier, alberto garcia-duran,jason weston, and oksana yakhnenko.
2013. translating embeddings for modeling multi-relational data.
in nips, pages 2787–2795..laming chen, guoxin zhang, and eric zhou.
2018.fast greedy map inference for determinantal pointinprocess to improve recommendation diversity.
nips, pages 5622–5633..abhinandan s das, mayur datar, ashutosh garg, andshyam rajaram.
2007. google news personaliza-inscalable online collaborative ﬁltering.
tion:www, pages 271–280..suyu ge, chuhan wu, fangzhao wu, tao qi, andyongfeng huang.
2020. graph enhanced represen-tation learning for news recommendation.
in www,pages 2863–2869..linmei hu, chen li, chuan shi, cheng yang, andchao shao.
2020. graph neural news recommen-dation with long-term and short-term interest model-ing.
ip&m, page 102142..dhruv khattar, vaibhav kumar, vasudeva varma, andmanish gupta.
2018. weave&rec: a word embed-ding based 3-d convolutional network for news rec-ommendation.
in cikm, pages 1855–1858..diederik p kingma and jimmy ba.
2015. adam: a.method for stochastic optimization.
in iclr..tien t nguyen, pik-mai hui, f maxwell harper, lorenterveen, and joseph a konstan.
2014. exploringthe ﬁlter bubble: the effect of using recommendersystems on content diversity.
in www, pages 677–686..shumpei okura, yukihiro tagami, shingo ono, andakira tajima.
2017. embedding-based news rec-ommendation for millions of users.
in kdd, pages1933–1942..aditya pal, chantat eksombatchai, yitong zhou,bo zhao, charles rosenberg, and jure leskovec.
2020. pinnersage: multi-modal user embeddinginframework for recommendations at pinterest.
kdd, pages 2311–2320..jeffrey pennington, richard socher, and christophermanning.
2014. glove: global vectors for word rep-resentation.
in emnlp, pages 1532–1543..tao qi, fangzhao wu, chuhan wu, yongfeng huang,and xing xie.
2020. privacy-preserving news rec-ommendation model learning.
in emnlp: findings,pages 1423–1432..kai shu, limeng cui, suhang wang, dongwon lee,and huan liu.
2019. defend: explainable fake newsdetection.
in kdd, pages 395–405..nitish srivastava, geoffrey hinton, alex krizhevsky,ilya sutskever, and ruslan salakhutdinov.
2014.dropout: a simple way to prevent neural networksfrom overﬁtting.
jmlr, pages 1929–1958..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in nips, pages 6000–6010..heyuan wang, fangzhao wu, zheng liu, and xingxie.
2020. fine-grained interest matching for neu-ral news recommendation.
in acl, pages 836–845..vaibhav kumar, dhruv khattar, siddhartha gairola,yash kumar lal, and vasudeva varma.
2018. iden-tifying clickbait: a multi-strategy approach usingneural networks.
in sigir, pages 1225–1228..hongwei wang, fuzheng zhang, xing xie, and minyiguo.
2018. dkn: deep knowledge-aware networkin www, pages 1835–for news recommendation.
1844..chen lin, runquan xie, xinjun guan, lei li, and taoli.
2014. personalized news recommendation viaimplicit social experts.
information sciences, pages1–18..chuhan wu, fangzhao wu, mingxiao an, jianqianghuang, yongfeng huang, and xing xie.
2019a.
neural news recommendation with attentive multi-view learning.
ijcai, pages 3863–3869..danyang liu, jianxun lian, shiyin wang, ying qiao,jiun-hung chen, guangzhong sun, and xing xie.
2020. kred: knowledge-aware document represen-tation for news recommendations.
in recsys., pages200–209..jiahui liu, peter dolan, and elin rønby pedersen.
2010. personalized news recommendation based onclick behavior.
in iui, pages 31–40..chuhan wu, fangzhao wu, mingxiao an, jianqianghuang, yongfeng huang, and xing xie.
2019b.
npa: neural news recommendation with personal-ized attention.
in kdd, pages 2576–2584..chuhan wu, fangzhao wu, mingxiao an, yongfenghuang, and xing xie.
2019c.
neural news recom-mendation with topic-aware news representation.
inacl, pages 1154–1159..5455chuhan wu, fangzhao wu, mingxiao an, tao qi,jianqiang huang, yongfeng huang, and xing xie.
2019d.
neural news recommendation with heteroge-neous user behavior.
in emnlp, pages 4876–4885..chuhan wu, fangzhao wu, suyu ge, tao qi,yongfeng huang, and xing xie.
2019e.
neu-ral news recommendation with multi-head self-attention.
in emnlp, pages 6390–6395..chuhan wu, fangzhao wu, tao qi, and yongfenghuang.
2020a.
sentirec: sentiment diversity-awareneural news recommendation.
in aacl, pages 44–53..chuhan wu, fangzhao wu, tao qi, and yongfenghuang.
2020b.
user modeling with click preferenceand reading satisfaction for news recommendation.
in ijcai, pages 3023–3029..chuhan wu, fangzhao wu, tao qi, jianxun lian,yongfeng huang, and xing xie.
2020c.
ptum: pre-training user model from unlabeled user behaviorsin emnlp: findings, pagesvia self-supervision.
1939–1944..chuhan wu, fangzhao wu, xiting wang, yongfenghuang, and xing xie.
2021. fairrec:fairness-awarenews recommendation with decomposed adversariallearning.
in aaai..fangzhao wu, ying qiao, jiun-hung chen, chuhanwu, tao qi, jianxun lian, danyang liu, xing xie,jianfeng gao, winnie wu, et al.
2020d.
mind: ainlarge-scale dataset for news recommendation.
acl, pages 3597–3606..guanjie zheng, fuzheng zhang, zihan zheng, yangxiang, nicholas jing yuan, xing xie, and zhen-hui li.
2018. drn: a deep reinforcement learn-ing framework for news recommendation.
in www,pages 167–176..qiannan zhu, xiaofei zhou, zeliang song, jianlongtan, and guo li.
2019. dan: deep attention neuralnetwork for news recommendation.
in aaai, pages5973–5980..5456