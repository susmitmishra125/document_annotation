increasing faithfulness in knowledge-grounded dialogue withcontrollable features.
hannah rashkin.
david reitter gaurav singh tomar.
dipanjan das.
google research, new york, ny{hrashkin, reitter, gtomar, dipanjand}@google.com.
abstract.
knowledge-grounded dialogue systems are in-tended to convey information that is based onevidence provided in a given source text.
wediscuss the challenges of training a generativeneural dialogue model for such systems thatis controlled to stay faithful to the evidence.
existing datasets contain a mix of conversa-tional responses that are faithful to selected ev-idence as well as more subjective or chit-chatstyle responses.
we propose different evalu-ation measures to disentangle these differentstyles of responses by quantifying the informa-tiveness and objectivity.
at training time, ad-ditional inputs based on these evaluation mea-sures are given to the dialogue model.
atgeneration time, these additional inputs act asstylistic controls that encourage the model togenerate responses that are faithful to the pro-vided evidence.
we also investigate the us-age of additional controls at decoding time us-ing resampling techniques.
in addition to au-tomatic metrics, we perform a human evalu-ation study where raters judge the output ofthese controlled generation models to be gener-ally more objective and faithful to the evidencecompared to baseline dialogue systems..1.introduction.
dialogue systems that strive to be informativeteachers are difﬁcultto build, despite recentprogress in training end-to-end systems that mimichuman language at a linguistic level.
these systemsbeneﬁt from vast training data and great representa-tional capacity; yet there are no controls (or trainingobjectives) available that ensure they are truthful.
a more limited goal for a system is to be faithful toone or more source documents that we implicitlytrust.
such a system might help educate users abouta particular topic through conversational interac-tion, or it might augment a task-oriented dialoguesystem by providing additional information about.
figure 1: excerpt from wizard of wikipedia (dinanet al., 2019) conversation.
this grounded dialogue in-cludes responses containing subjective or personal ex-periences as well as responses sharing information sup-ported by external documents..the process involved in, say, adding a new homeautomation device.
we assume that multi-turn con-versational interaction can help a human user learnto retain the new material..here, we investigate ways to stay faithful toinformation from a text document in a conversa-tion.
we approach this problem via the task ofknowledge-grounded dialogue, where a system pro-duces a dialogue response using a piece of evidencefrom a grounding document and a previous conver-sation history as input (as in figure 1).
whereaspersonachat-style tasks (zhang et al., 2018)may focus on dialogue systems that are meant to beengaging, this task focuses instead on systems thatare meant to be informative, meaning that they onlyshare veriﬁable information and exclude subjectiveor invented personal information..there are existing knowledge-grounded dia-logue datasets (e.g.
(ghazvininejad et al., 2018;dinan et al., 2019; qin et al., 2019)) that could.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages704–718august1–6,2021.©2021associationforcomputationallinguistics704i visit animal shelters fairly oftena "no-kill" shelter is an animal shelter that does not kill healthy or treatable animals even when the shelter is full, reserving euthanasia for terminally ill animals ...personal experiencegrounding documentthere's a really nice no-kill shelter by my house that i volunteer at on wednesdays!i see.
is a no kill shelter different from regular animal shelter?information supported by the grounding documentyes, a "no-kill" shelter is an animal shelter that does not kill healthy or treatable animals even when the shelter is full.userdifferent response stylesbe appropriate training resources for such an infor-mative dialogue agent.
however, we observe thatthese datasets often contain utterances with vary-ing conversation styles and intents, including someutterances that are more informative and some thatare chit-chat utterances or subjective commentary.
for instance, in figure 1, we show an example con-versation excerpt from the wizard of wikipedia(dinan et al., 2019) training set.
while some utter-ances are supported by the grounding documents(the second response), others include personal expe-riences and observations (as in the ﬁrst response).
because of this mix of conversations styles, wecannot ensure that models naively trained on thisdata will learn to generate only faithful, informativeutterances..in order to avoid this issue, one could collectnew datasets where the responses are more explic-itly constrained by the evidence, but this couldbe quite expensive and may be challenging to im-plement.
instead, in this paper, we propose analternate approach: we adapt techniques from con-trollable text generation in order to train dialoguemodels that learn to disentangle these conversationstyles within the data and can be controlled at gen-eration time to produce more grounded responses..we propose using multiple evaluation measuresthat are relevant to the faithfulness of a responseand use these to control the output of two com-monly used seq2seq models (gpt-2 (radford et al.,2019) and t5 (raffel et al., 2020)).
we investigatetwo methods for adding controllability.
first, weintegrate control code features based on the evalu-ation measures as special tokens prepended to theseq2seq input, drawing inspiration from domain-based control codes methods (keskar et al., 2019).
these special tokens are created using informationabout the gold response at training time, but areset to maximize the groundedness of the responsesat generation time.
second, we implement a formof resampling that directly restricts the output tosatisfy the proposed evaluation measures..in order to inspect the faithfulness and style ofthe responses, we use automatic evaluations (in-cluding bleu and the evaluation measures de-scribed) and human evaluations that are designedto focus on the degree to which the response isfaithfully representing information from the evi-dence.
our results show that using these control-lable generation techniques can improve the per-ceived faithfulness and objectivity.
we also show.
that the proposed evaluation measures correlatewith the human judgements, indicating that theseare appropriate measures for gauging speciﬁc as-pects of groundedness.
lastly, we conclude thepaper with some discussion of examples and possi-ble trade-offs..2 task.
we introduce a sub-task of knowledge-groundeddialogue where a dialogue agent is intended tobe informative and must not share hallucinations,which we deﬁne here as any information that isneither inferrable from nor directly stated by ex-ternal documents.
in this task, a system is givenevidence from a document (or documents) and aconversation history and must produce a responsethat is both faithful to the evidence and also natu-ral within the context of the previous conversationutterances.
because this task focuses on being in-formative to a user, the agent is not allowed toshare unsupported or subjective information (thisincludes invented personal traits - e.g.
“i love dogs,too!”).
additionally, it is not sufﬁcient to be purelyextractive as information from the evidence mayneed to be re-phrased to be a conversationally ap-propriate response (e.g.
if a user asked a questionthat is inferrable from the evidence but not directlystated)..to simplify the task for this paper, we assumethat an appropriate evidence span, e, has alreadybeen labelled.
we therefore study how to gener-ate an appropriate response y given the previousconversation history x and a chosen evidence e asinput..2.1 evaluation measures.
our goal is to design a dialogue model that is morefaithful and objective in how it relays evidence.
wepropose using a series of evaluation measures toestimate whether a response is (1) written in anobjective voice, (2) not sharing extra informationthat is not in the document and (3) entailed by thegrounding evidence.
in the modeling section (sec.
4), we describe how we incorporate these measuresinto a controllable generation framework..objective voice one form of hallucination iswhen a dialogue agent might share personal sto-ries or opinions.
it is common for dialogue agentsto learn this behavior as many dialogue datasetscontain instances of personal chit-chat even if thetask is aimed at grounded language.
we estimate.
705objective voice as a binary variable based on thepresence of ﬁrst person singular pronouns detectedusing a word list..lexical precision we also want to ensure thatthe response is not adding extra information fromwhat’s in the selected evidence.
to estimate this,we measure the precision of the unigrams in theresponse with respect to the evidence.
a high valueindicates that most of the words in the response arecontained somewhere in the evidence.
we use thismeasure because it is relevant to grounding preci-sion scores in previous work (tian et al., 2020) andbecause it can reasonably gauge how extractive theresponse is, but one drawback of this measure isthat it is based on lexical features which may notreﬂect semantic differences in the information be-ing shared (e.g.
dropping the word ‘not’ may yieldhigh lexical precision but a very different semanticmeaning from the original evidence).
we leaveinvestigation of more semantic-oriented measuresof the precision of information to future work..entailment lastly, we want to encourage themodel to produce a response that is semanticallyentailed by the source document.
we use a state-of-the-art natural language interference (nli) model(roberta trained on mnli (liu et al., 2019)) toestimate if a response is entailed by the evidence.1.
3 data.
wizard of wikipedia (dinan et al., 2019) is a re-cent, large-scale dataset of multi-turn knowledge-grounded dialogues between a “apprentice” anda “wizard”, who has access to information fromwikipedia documents.
the wizard labelled evi-dence spans within documents for each utterancethey made.
additionally, the development and testsets are split into two portions depending on if theconversation is about a topic that was seen or un-seen in the training data.
we use the gold-labelledevidence as input to the model in order to focuson improving the quality of generating responsesgiven such evidence and the previous dialogue his-tory.
we also focus on only modeling the utter-ances by the “wizard” in the cases where they areresponding to the “apprentice”.
we include datastatistics in table 1 and an example conversationexcerpt in figure 1..wizard of wikipedia (dinan et al., 2019).
train datadev (seen topics)dev (unseen topics)test (seen topics)test (unseen topics).
# wizard responses735713905389838423902.training responses.
% with ﬁrst personavg.
lexical prec.
wrt evid.
% predicted entailed.
44%0.4323%.
table 1: data statistics from the wizard of wikipediadataset..we note that even though wizard of wikipediais a knowledge-grounded dataset, there are manyutterances that also include information external tothe evidence (as noted in figure 1).
many conver-sation turns relay evidence while also embellishingwith chit-chat, opinion sharing, or interlocutors’own intuitions and world knowledge.
this is be-cause this dataset was collected by asking humancrowdworkers to converse with each other, and itis natural for humans to embellish and personalizetheir conversations even when discussing a doc-ument.
yet, for our goal of training informativedialogue agents, we need to train models that onlyrelay information that is found in the evidence..in order to avoid collecting new data, whichis costly and challenging, we investigate how totrain models with this data while discouraging themfrom hallucinating extra information that cannotbe conﬁrmed in the evidence.
one way to dealwith this challenge might be to only train with theportions of the data where the response is highlygrounded by the evidence.
however, in our calcu-lations (bottom of table 1), we ﬁnd that as muchas 44% of training set responses are in ﬁrst personand only 23% of responses are predicted to be en-tailed by the evidence, which indicates that a largeportion of training data would have to be excluded.
instead, our paper proposes a modeling techniquein which we incorporate different input features de-noting different conversational styles.
we can thentrain the model in a way that learns to use thesefeatures to disentangle the differences between ut-terances that are more faithful to the evidence vs.other types of utterances..4 modeling.
1we aggregate neutral and contradiction as “non-entailing”because we care mainly about detecting entailment rather thanthe distinctions between the other two standard nli categories..we investigate how to add controllable features toa large neural dialogue model in order to constrain.
706figure 2: modeling figure: in our modeling framework, a large pre-trained language model is used to encode theevidence and conversation history and produce a response.
we incorporate additional tokens (i.e.
control codes) totrain the model to recognize differences between types of utterance that are more or less grounded to the evidence.
at decoding time, we also investigate the signiﬁcance of using resampling methods..the amount of hallucinated text while also takingadvantage of the underlying ﬂuency of a large end-to-end neural model..4.1 generation model.
as our underlying dialogue model, we use neu-ral seq2seq architectures – t5 (raffel et al., 2020)and gpt-2 (radford et al., 2019), which are ar-chitectures used in state-of-the-art dialogue sys-tems (e.g.
dialogpt (zhang et al., 2020)).
weﬁne-tune these models on our grounded dialoguedataset.
the input to the model is a sequence of ev-idence tokens e1...ep and a dialogue history whichwe treat as a sequence of tokens x1...xm wherethe utterances are delimited by the speaker id (ei-ther <speaker1> or <speaker2>).
for thegpt-2 model, we also include special token-typeembeddings that are added to the byte-pair embed-ding tokens and position embeddings.
the token-type embeddings denote the segments of the inputthat belong to the evidence and the two differentspeakers.
we train the model to produce the nextconversation utterance y1...yn by minimizing thecross-entropy:.
lce = −.
log p(yi|y<i, x, e).
(1).
1n.n(cid:88).
i=1.
caveats of generative language models asnoted by the documentation with the gpt-2 release,we lack a complete understanding of language mod-els’ robustness and worst case behaviors.
even.
though training data for gpt-2 and t5 have beencarefully selected, these large datasets may con-tain sources with unfair distributions and factualinaccuracies, and thus the models and the resultinggenerated synthetic data may have inherited thesebiases.
additionally, the output generated by thesemodels may only succeed in being superﬁciallysimilar to human-written text or dialogue turns..4.2 adding controllable generation.
we describe two methods of adding controllabilityto the dialogue models to enhance the grounded-ness according to the evaluation measures fromsec.
2.1. first, we incorporate control features intothe input of the model.
second, we describe addi-tional decoding-time techniques using resampling..4.2.1 control code features.
we add control features as a way of encouragingthe underlying language model to disentangle dif-ferent conversations styles at training time.
weimplement this using the control code approach pre-viously introduced in ctrl (keskar et al., 2019).
first, we use the measures introduced in section 2.1to create control feature tokens based on how muchof the content of the response is grounded in thegold labelled evidence.
the control feature tokensc1...cn are prepended to the other tokens.
the train-.
707<high-prec>  control code sequence(§4.2.1)evidence sequenceconv history sequencetraining time:minimize cross-entropy of gold responsedecoding time: resampling (§4.2.2)output responsesatisfies constraints?ynresampleoutputfine-tuned lme1 e2 … ep<speaker1> x1 … xm<no-1st-person><entail>ing objective therefore becomes:.
5.1 set-up.
lce = −.
log p(yi|y<i, x, e, c).
(2).
1n.n(cid:88).
i=1.
at training time, we set control feature tokensbased on measures of entailment, lexical precision,and objective voice of the gold response.
at decod-ing time, control codes are set to the desired valuedfor these qualities (high entailment, high lexicalprecision, objective voice)..objective voicein order to encourage the modelto be only relaying objective information from theevidence, we include a control code for whether ornot the utterance contains ﬁrst-person pronouns(<first-person>,<no-first-person>).
atthe<no-first-person> control token..time, we.
decoding.
always.
use.
lexical precision we measure the lexical pre-cision of the response with respect to the evi-dence, splitting the training utterances into threeterciles (high, medium, and low).
we mapthe terciles to control codes to denote the pre-cision level (<high-prec>,<med-prec>, and<low-prec>).
at decoding time, we always use<high-prec>..entailment wecontrolforthe nlioutputthe(<entailed>,<non-entailed>).
decoding time, we always use <entailed>..codesclassiﬁerat.
addof.
4.2.2 controlled resamplingwhereas the control code method implicitly teachesthe model to use different styles, some applicationsmay require more direct control over the model out-put.
additionally, there may be situations where adialogue system cannot be re-trained.
we thereforealso investigate a method of implementing moredirect control at decoding time.
we experimentwith a resampling method that continues to sam-ple responses until one is found that satisﬁes theevaluation measures (high lexical precision, objec-tive voice, and predicted entailment).
to save oncomputational efﬁciency, we use a cut-off to avoidresampling more than d times..5 experiments.
we perform experiments using automatic metricsand human judgments to evaluate the effectivenessof the proposed controllable dialogue system andits various components..we use the huggingface library (wolf et al., 2020)versions of gpt-2 and t5.
we select training hy-perparameters based on cross-entropy of the de-velopment set.
we use a learning rate of 8e − 5and maximum gradient norm of 1, 3.5 for gpt-2, t5 respectively with adam to minimize thetraining loss (with 200 warm-up steps).
if the totalsequence length is greater than 1024, we truncatethe previous conversation turns until the sequenceis short enough.
we train for three epochs for allmodels.
for decoding, we use nucleus sampling(holtzman et al., 2020) with p = 0.6 and a min-imum generation length of ﬁve tokens (based onbetter bleu performance with the developmentset).
in our experiments with resampling, we arbi-trarily set d = 10..5.2 metrics.
we use both automatic metrics (sec.
5.3 and 5.4)and human ratings (sec.
5.5) to better understandperformance of our model and the effect of control-lable features..first, we use bleu to compare the model out-put to a gold reference.
while bleu gives a gen-eral sense of the ﬂuency, there are drawbacks toword-overlap metrics for evaluating open-endedgenerations like dialogue (liu et al., 2016).
ad-ditionally, comparing to a gold reference answerfails to measure the underlying question we hopeto interpret: whether the response is more objectiveand grounded to the evidence.
therefore, we alsoevaluate the output using the proposed evaluationmeasures from section 2.1. in addition to lexicalprecision, we also report the lexical recall of wordsfrom the evidence..but, the controllable models are controlled us-ing the same evaluation measures, so we expectthat these models may have an advantage in thesemetrics.
thus, we rely more on human evaluations(section 5.5).
we ask humans to evaluate the qual-ity along multiple aspects including whether theresponse is ﬂuent, relevant, supported/faithful, andobjective..5.3 ablation of control code features.
first we conduct an ablation study to investigatethe effects of each individual control code featurebeing used as model input.
table 2 shows the re-sults on the seen topics portion of the wizard ofwikipedia development set.
unsurprisingly, each.
708control codes.
b1.
b4 % n1p.
prec.
objectiv.
overlap w.r.t.
evid.
entail% entail.
gpt-2 + no control+ objective+ high lex prec+ entailment+ all.
t5 + no control+ objective+ high lex prec+ entailment+ all.
27.626.429.927.327.9.
28.627.429.627.827.4.bleub2.
b3.
12.512.815.113.914.8.
14.414.815.915.315.5.
8.18.610.49.410.2.
9.710.311.110.611.0.
6.06.47.97.17.7.
7.37.98.48.18.5.
49.998.163.480.599.4.
49.899.463.380.399.9.
56.462.370.672.676.6.
63.970.776.177.784.2.rec.
48.450.560.356.260.3.
50.153.459.857.360.7.
34.950.151.969.772.3.
44.465.160.780.089.4.table 2: ablation study: the effects of using different types of control codes for generation on the wizard ofwikipedia seen topic development set.
in addition to bleu, we measure objective voice by the percent of replieswhere there is no ﬁrst person (n1p).
we also measure the lexical precision and recall with respect to the wordsfrom the evidence.
lastly we compute the percentage of responses that are predicted to be entailed according toan mnli classiﬁer..seen topic.
model.
bleu n1p%.
b4.
w/ evid..prec.
rec.
unseen topic.
bleu n1p%.
b4.
w/ evid..prec.
rec.
e2e model (dinan et al., 2019)dodecadialogue (shuster et al., 2020)gpt-2 (none)gpt-2 (control codes)gpt-2 (resampling)gpt-2 (both)t5 (none)t5 (control codes)t5 (resampling)t5 (both).
1.510.06.27.87.68.97.68.68.28.4.
48.078.350.999.375.199.951.199.777.599.8.
47.981.156.176.670.483.164.084.373.385.0.
30.467.749.461.557.766.351.962.155.562.1.nli%.
29.370.334.273.871.493.945.189.074.794.0.
0.39.75.77.67.28.47.48.58.18.7.
37.677.752.199.276.299.851.499.478.599.8.
33.281.356.477.070.383.265.285.074.486.1.
21.766.548.360.356.564.751.961.555.562.2.nli%.
9.570.634.274.072.394.444.989.876.394.4.table 3: experimental results on the seen/unseen topic portions of the wizard of wikipedia test set.
we reportbleu-4, the percentage of responses that don’t use ﬁrst person language (n1p), precision and recall of words inthe response with the evidence and the proportion of responses that are predicted to be entailed by the evidence ..control feature generally helps in improving on themeasure that was used in its training.
however, wealso ﬁnd, more generally, that each type of controlcode feature does improve over the base model onall metrics.
results also show that using all con-trol code features together generally improves theperformance across the automatic metrics..5.4 automatic metric results on test set.
we show results on both portions of the wizard ofwikipedia test set in table 3. as baselines, we useﬁnetuned gpt-2 and t5 without any controllablefeatures or resampling.
we also include resultsthe end-to-end generative model (e2e) with goldknowledge that was introduced in the original wiz-ard of wikipedia paper (dinan et al., 2019) and themodel in the follow-up work on dodecadialogue.
(shuster et al., 2020).
these are transformer-basedarchitectures that use the evidence and conversationhistory as inputs but do not explicitly control themodel to be more faithful to the input.
in general,we ﬁnd that models with pre-trained or multi-tasktraining set-ups (dodecadialogue, gpt-2, and t5)have relatively consistent performance across boththe seen and unseen topic partitions of the test set,indicating that these models can generalize fairlywell to unseen topics..results generally show improvements over thebaselines when using control codes.
by addition-ally using resampling at decoding time, we seefurther improvements, though resampling is not aseffective on its own.
one explanation why resam-pling is not as effective is that it may be unableto ﬁnd a satisfactory response within d resampling.
709model.
fluency relevance faithfulness objectivity.
e2e model (dinan et al., 2019)dodecadialogue (shuster et al., 2020)t5 (none)t5 (control codes)t5 (resampling)t5 (both).
5.004.995.005.004.995.00.
4.614.734.844.66*4.774.82.
2.48***4.37*3.66***4.644.14***4.42*.
2.26***3.92**2.82***4.533.82***4.30.table 4: human quality ratings: *,** ,*** indicates that this result is signiﬁcantly different from the best result inthat column (bolded) with p-value < 0.05, < 0.01, < 0.001 respectively..turns, particularly if the underlying model has notbeen already trained in a controllable set-up.
sup-porting this, we ﬁnd that different choices of d hasmore of an impact on performance with the “justresampling” model than with the “control code +resampling” model..the controllable t5 models generally outper-form all of the other models in terms of the metricsfrom section 2.1. this may not be so surprisingsince these models are using the same metrics forcontrol inputs at training time.
the dodecadia-logue model outperforms our best model variant inthe bleu and recall metrics, but this may also berelated to the longer average token length of outputof that model (19 tokens on average) in comparisonto our model (16 tokens on average).
in order toget a more conclusive understanding of the perfor-mance differences, we perform a human evaluationstudy, described below..5.5 human evaluation.
we use human evaluations to gauge performanceacross multiple aspects of quality.
one aspectwhich we focus on is how much the information inthe responses is grounded in the evidence, whichwe consider to be a strong requirement for this task.
but, there are also other complementary aspectsof response quality that are important (e.g.
beingappropriate to the conversational context).
there-fore, we ask raters to judge a random subsampleof model responses from the test set in terms offour qualities: ﬂuency (how understandable andproﬁcient the language is), relevance (whether it isan appropriate reply to the conversation history),faithfulness (whether the reply is fully supportedby the evidence), and objectivity (whether the re-ply is fully objective, rather than sharing personalfeelings or experiences).2.
2the exact phrasing of the questions given to human raters.
is in the appendix..we subsample examples from the seen topicstest set, using 100 examples per model variant with3 human raters per example.
in order to give ratersmore ﬂexibility, they are asked to rate each qualityon a likert scale from 1 (low quality) to 5 (highquality).
we measure the agreement for each ofthe four qualities separately using krippendorff’salpha and ﬁnd that the agreement (0.8, 0.91, 0.88,0.96 respectively) is reliably high..in table 4, we include the averaged results fromthe human study.
we provide asterisks in everycase where a metric is signiﬁcantly different fromthe best result (bolded), as found with welch’st-test.
by adding the control code features andresampling, we do not see a drop in the ﬂuency,which is similarly high across all of the models.
infact, we see that most of the trade-off is betweenthe relevance of the response vs. the faithfulnessand objectivity..our results show the faithfulness and objectivityof the t5 models with control codes is signiﬁcantlyhigher than in the uncontrolled models (top threerows).
this is a promising indication that addingthese controllable features signiﬁcantly steers thegenerations towards making more grounded, ob-jective responses, with only a slight decrease inrelevance.
including resampling is not as effectivein promoting faithfulness and objectivity as the con-trol codes, though more faithful and objective thanthe base t5 model.
by using both control codesand resampling (bottom row), the t5 model is ableto achieve nearly the same level of faithfulness andobjectivity as with just using control codes, butwith higher relevance subscores..for the full set of annotated examples, we alsoﬁnd that the human scores for faithfulness and ob-jectivity correlate with measurements from the eval-uation measures that we described in section 2.1.for instance, the absence of ﬁrst person strongly.
710correlates with higher objectivity according to hu-man raters (pearson r value of 0.8 at p value< 0.001).
lexical precision and entailment mea-sures both strongly correlate with human percep-tions of faithfulness and objectivity, as well.3 thisconﬁrms that the evaluation measures that we pro-pose using as controls can be appropriate estimatesfor how humans might perceive the groundednessof a response.
however, these metrics do not corre-late to relevance or ﬂuency.
based on these obser-vations, it seems that these measures can be usefulto gauge the general groundedness of the responsebut should still be viewed in tandem with otherquality scores to get a more holistic understandingof performance..5.6 qualitative examples.
in table 5, we highlight some examples of modeloutput (we also provide additional examples in theappendix).
the responses in the controllable mod-els tend to be more concise in relaying informationfrom the evidence.
in the ﬁrst example, the control-lable model only shares information that is entailedby the evidence, excluding extra information aboutspices that is not easily veriﬁable within the docu-ment..this may also come with a slight trade-off withthe relevance of the replies, as in the second exam-ple where the response - while more faithful to theevidence - is not quite as pertinent to the previousconversation turn.
similarly, in the third example,the full model is faithfully citing the evidence but istoo extractive to the extent of including irrelevantdetails.
in the last example in table 5, both themodels make the same error where they incorrectlygive an afﬁrmative answer to the user’s questionabout george foreman even though they both iden-tify michael boehm as the correct inventor (a betteranswer would be “no, it was michael boehm.”).
this example is challenging because the answerto the user’s question is not directly stated in theevidence and requires extra inference rather thanjust extracting relevant words.
to address thesechallenges, one area for future work may be in-vestigating approaches that combine extractive andabstractive generation methods to be more delib-erately selective about which portions of evidenceare being used and how they are integrated withinformation about the conversational discourse..3the appendix includes a full table of correlation coefﬁ-.
cients.
6 related work.
knowledge-grounded dialogue there hasbeen signiﬁcant prior work in tasks for designingdialogue agents that are grounded by documentknowledge (dinan et al., 2019; qin et al., 2019;ghazvininejad et al., 2018; tian et al., 2020;gopalakrishnan et al., 2019; moghe et al., 2018).
these works investigate retrievingsome ofappropriate evidence (lian et al., 2019; menget al., 2020; kim et al., 2020), while we assumethat a piece of evidence has already been retrievedand focus instead on how to craft generations thatare more faithful to it.
our work is also novel ininvestigating controllable generation as one wayof disentangling evidence-based utterances frommore subjective utterances that may be present inthe training data..controlling hallucinations in text generationthere is a body of work that has previously stud-ied methods for integrating evidence in naturallanguage generation tasks, with a focus on reduc-ing hallucinations.
many of these works focuson other generation tasks such as summarization(maynez et al., 2020; zhao et al., 2020; cao et al.,2018; falke et al., 2019) or data-to-text generation(puduppully et al., 2019).
we investigate how theproblem of reducing hallucinations can be appliedto the task of knowledge grounded dialogue.
sim-ilar to our approach, filippova (2020) also usescontrol codes to reduce hallucinations but focusedinstead on data-to-text generation tasks..controllable text generation in order to con-trol the faithfulness of responses, we draw ontechniques from controllable text generation tasks.
most relevant is the development of control-code-style input tokens such as in ctrl (keskar et al.,2019) or the lft model of niu and bansal (2018).
others have used decoding-time re-ranking (falkeet al., 2019) to constrain the outputs in a way thatis similar to our resampling method.
controllablegeneration has also been used previously with open-ended dialogue data (see et al., 2019) to improvequalities such as the engagingness; however, ourwork focuses on knowledge-grounded dialoguesaiming to increase the faithfulness of the replies.
recently, wu et al.
(2020) used control phrases ascontrollable inputs to decrease hallucination as aform of content planning.
we similarly use con-trollable features to reduce hallucinations in knowl-edge grounded dialogues, but our model uses stylis-.
711document evidencecurry (, plural curries) is an umbrella term referring to a number of dishes originating in the cuisine of the indiansubcontinent.
conversation historyspeaker 1: i recently discovered a new love for indian foodspeaker 2: i don’t think i’ve ever had indian food.
can you recommend a good dish?
speaker 1: :) that is what i like to know since i just discovered it.
speaker 2: i know that curry is a popular spice used in indian cuisine!
some curries are spiced with leaves from the currytree!
speaker 1: what i do not understand, is curry a spice or a dish?
or both?
modelt5.
outputit’s a spice!
curry is an umbrella term referring to a number of dishes originating in the indiansubcontinent.
it’s an umbrella term referring to a number of dishes originating in the indian subcontinent!.
t5 with controls.
document evidencein recent years, unicycles have also been used in activities similar to mountain biking or trials.
conversation historyspeaker 2: so something interesting about me.
i ride unicycle, a bike-like thing with only one wheel.
speaker 1: that amazing, i have no sense of balance so even riding a bike is hard for memodelgpt-2gpt-2 with controls.
outputyeah i understand that.
i’m glad i didn’t have to worry about that.
what about you?
unicycles have also been used in activities similar to mountain biking or trials..document evidencechanel felt the time was right for the debut of a scent that would epitomize the ﬂapper and would speak to the liberatedspirit of the 1920s.
conversation historyspeaker 1: since i was young i have loved fashion.
speaker 2: have you heard of gabrielle ”coco” chanel?
she was the founder and namesake of the brand chanelspeaker 1: yes, i love that brand.
speaker 2: coco chanel’s ﬁrst perfume is something you’ve probably heard of: 5speaker 1: yes i have bought a few bottles in my life.
speaker 2: 5 was actually developed by a french-russian chemist called ernest beaux.
speaker 1: when did he make itmodelt5t5 with controls.
outputhe was making it in the 1920s.
chanel felt the time was right for the debut of a scent that would epitomize the ﬂapper and wouldspeak to the liberated spirit of the 1920s..document evidencethe concept for the grill was created by michael boehm of batavia, illinois.
conversation historyspeaker 1: i was thinking of buying a george foreman grill, do you know anything about them?
speaker 2: yes, it is a grill promoted by boxing great george foremanspeaker 1: interesting, did he invent the grill himself?
modelgpt-2gpt-2 with controls.
outputhe did and it was created by michael boehm of batavia, illinois.
yes, he did it by michael boehm of batavia, illinois.
table 5: generation examples from the wizard of wikipedia dev.
set..tic measures which can be seen as complementaryto content planning..objective and faithful to document-based evidence..7 conclusion.
in this paper, we investigate how to design knowl-edge grounded dialogue systems that are less proneto including hallucinations or subjective informa-tion.
we discuss three evaluation measures relatedto the groundedness of the response and discusstwo methods for integrating these metrics into acontrollable dialogue system.
we demonstrate thatthis controllable dialogue system is able to produceresponses that are perceived by humans to be more.
acknowledgements.
we would like to thank slav petrov and ankurparikh as well as the anonymous reviewers fortheir insightful comments and feedback.
we alsothank nouha dziri for sharing code and data re-sources.
we additionally thank ashwin kakarlaand his team for helping with human annotations..712impact statement.
in this paper, we study the problem of encouragingknowledge grounded dialogue agents to be morefaithful in generating information from trusted doc-uments.
the controllable models and evaluationmeasures proposed in this paper could beneﬁt gen-eral dialogue applications by constraining their out-put to only discuss information that is veriﬁable,which could ensure that these systems are moretrustworthy.
this could be valuable in a wide rangeof applications such as educational or information-seeking dialogue settings where the user needs tobe given accurate information.
as with other con-ditional generation models, this could also pose arisk if these models were misused by condition-ing on evidence from unreliable resources.
in ourwork, we mitigate this risk by carefully consideringthe source of our evidence and how it was curated.
before applying these models, others should simi-larly take into consideration whether their evidencesources are reliable and unbiased..references.
ziqiang cao, furu wei, wenjie li, and sujian li.
2018.faithful to the original: fact aware neural abstrac-in proceedings of the thirty-tive summarization.
second aaai conference on artiﬁcial intelligence,(aaai-18), the 30th innovative applications of arti-ﬁcial intelligence (iaai-18), and the 8th aaai sym-posium on educational advances in artiﬁcial intel-ligence (eaai-18), new orleans, louisiana, usa,february 2-7, 2018, pages 4784–4791.
aaai press..emily dinan, stephen roller, kurt shuster, angelafan, michael auli, and jason weston.
2019. wizardof wikipedia: knowledge-powered conversationalin 7th international conference on learn-agents.
ing representations, iclr 2019, new orleans, la,usa, may 6-9, 2019. openreview.net..tobias falke, leonardo f. r. ribeiro, prasetya ajieutama,ido dagan, and iryna gurevych.
2019.ranking generated summaries by correctness: an in-teresting but challenging application for natural lan-guage inference.
in proceedings of the 57th annualmeeting of the association for computational lin-guistics, pages 2214–2220, florence, italy.
associa-tion for computational linguistics..katja filippova.
2020..controlled hallucinations:learning to generate faithfully from noisy data.
inproceedings of the 2020 conference on empiricalmethods in natural language processing: findings,emnlp 2020, online event, 16-20 november 2020,pages 864–870.
association for computational lin-guistics..marjan ghazvininejad, chris brockett, ming-weichang, bill dolan, jianfeng gao, wen-tau yih, andmichel galley.
2018. a knowledge-grounded neuralin proceedings of the thirty-conversation model.
second aaai conference on artiﬁcial intelligence,(aaai-18), the 30th innovative applications of arti-ﬁcial intelligence (iaai-18), and the 8th aaai sym-posium on educational advances in artiﬁcial intel-ligence (eaai-18), new orleans, louisiana, usa,february 2-7, 2018, pages 5110–5117.
aaai press..karthik gopalakrishnan, behnam hedayatnia, qin-lang chen, anna gottardi, sanjeev kwatra, anuvenkatesh, raefer gabriel, and dilek hakkani-t¨ur.
2019.topical-chat: towards knowledge-grounded open-domain conversations.
in proc.
in-terspeech 2019, pages 1891–1895..ari holtzman, jan buys, li du, maxwell forbes, andyejin choi.
2020. the curious case of neural textin 8th international conference ondegeneration.
learning representations, iclr 2020, addis ababa,ethiopia, april 26-30, 2020. openreview.net..nitish shirish keskar, bryan mccann, lav r. varsh-ney, caiming xiong, and richard socher.
2019.ctrl: a conditional transformer language modelfor controllable generation.
corr, abs/1909.05858..byeongchang kim, jaewoo ahn, and gunhee kim.
2020. sequential latent knowledge selection forknowledge-grounded dialogue.
in 8th internationalconference on learning representations,iclr2020, addis ababa, ethiopia, april 26-30, 2020.openreview.net..rongzhong lian, min xie, fan wang, jinhua peng,and hua wu.
2019. learning to select knowledgein pro-for response generation in dialog systems.
ceedings of the twenty-eighth international jointconference on artiﬁcial intelligence, ijcai 2019,macao, china, august 10-16, 2019, pages 5081–5087..chia-wei liu, ryan lowe, iulian serban, mike nose-worthy, laurent charlin, and joelle pineau.
2016.how not to evaluate your dialogue system: anempirical study of unsupervised evaluation metricsfor dialogue response generation.
in proceedings ofthe 2016 conference on empirical methods in natu-ral language processing, pages 2122–2132, austin,texas.
association for computational linguistics..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
corr, abs/1907.11692..joshua maynez, shashi narayan, bernd bohnet, andryan mcdonald.
2020. on faithfulness and factu-ality in abstractive summarization.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics, pages 1906–1919, on-line.
association for computational linguistics..713proceedings of the 58th annual meeting of the as-sociation for computational linguistics, acl 2020,online, july 5-10, 2020, pages 650–659.
associa-tion for computational linguistics..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, r´emi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander m. rush.
2020.transformers: state-of-the-art natural language pro-cessing.
in proceedings of the 2020 conference onempirical methods in natural language processing:system demonstrations, pages 38–45, online.
asso-ciation for computational linguistics..zeqiu wu, michel galley, chris brockett, yizhe zhang,xiang gao, chris quirk, rik koncel-kedziorski,jianfeng gao, hannaneh hajishirzi, mari osten-dorf, and bill dolan.
2020.a controllablemodel of grounded response generation.
corr,abs/2005.00613..saizheng zhang, emily dinan, jack urbanek, arthurszlam, douwe kiela, and jason weston.
2018. per-sonalizing dialogue agents: i have a dog, do youin proceedings of the 56th an-have pets too?
nual meeting of the association for computationallinguistics (volume 1: long papers), pages 2204–2213, melbourne, australia.
association for com-putational linguistics..yizhe zhang, siqi sun, michel galley, yen-chun chen,chris brockett, xiang gao, jianfeng gao, jingjingliu, and bill dolan.
2020. dialogpt : large-scale generative pre-training for conversational re-in proceedings of the 58th an-sponse generation.
nual meeting of the association for computationallinguistics: system demonstrations, acl 2020, on-line, july 5-10, 2020, pages 270–278.
associationfor computational linguistics..zheng zhao, shay b. cohen, and bonnie webber.
2020.reducing quantity hallucinations in abstractive sum-marization.
in findings of the association for com-putational linguistics: emnlp 2020, pages 2237–2249, online.
association for computational lin-guistics..chuan meng, pengjie ren, zhumin chen, weiwei sun,zhaochun ren, zhaopeng tu, and maarten de rijke.
2020. dukenet: a dual knowledge interaction net-work for knowledge-grounded conversation.
in pro-ceedings of the 43rd international acm sigir con-ference on research and development in informationretrieval, sigir 2020, virtual event, china, july 25-30, 2020, pages 1151–1160.
acm..nikita moghe, siddhartha arora, suman banerjee, andmitesh m. khapra.
2018. towards exploiting back-ground knowledge for building conversation sys-in proceedings of the 2018 conference ontems.
empirical methods in natural language processing,pages 2322–2332, brussels, belgium.
associationfor computational linguistics..tong niu and mohit bansal.
2018. polite dialogue gen-eration without parallel data.
transactions of the as-sociation for computational linguistics, 6:373–389..ratish puduppully, li dong, and mirella lapata.
2019.data-to-text generation with content selection andplanning.
proceedings of the aaai conference onartiﬁcial intelligence, 33(01):6908–6915..lianhui qin, michel galley, chris brockett, xiaodongliu, xiang gao, bill dolan, yejin choi, and jian-feng gao.
2019. conversing by reading: contentfulneural conversation with on-demand machine read-ing.
in acl, pages 5427–5436, florence, italy.
as-sociation for computational linguistics..alec radford, jeff wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners..colin raffel, noam shazeer, adam roberts, katherinelee, sharan narang, michael matena, yanqi zhou,wei li, and peter j. liu.
2020. exploring the limitsof transfer learning with a uniﬁed text-to-text trans-former.
j. mach.
learn.
res., 21:140:1–140:67..abigail see, stephen roller, douwe kiela, and ja-son weston.
2019. what makes a good conver-sation?
how controllable attributes affect humanjudgments.
in proceedings of the 2019 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 1702–1723, minneapolis, minnesota.
associ-ation for computational linguistics..kurt shuster, da ju, stephen roller, emily dinan, y-lan boureau, and jason weston.
2020. the di-alogue dodecathlon: open-domain knowledge andimage grounded conversational agents.
in proceed-ings of the 58th annual meeting of the associationfor computational linguistics, pages 2453–2470,online.
association for computational linguistics..zhiliang tian, wei bi, dongkyu lee, lanqing xue,yiping song, xiaojiang liu, and nevin l. zhang.
2020. response-anticipated memory for on-demandinknowledge integration in response generation..714a appendix.
a.1 example wizard of wikipedia.
we include two full examples of wizard ofwikipedia (dinan et al., 2019) training conversa-tions in table 8..a.2 training over faithful responses only.
we additionally experiment with a baseline inwhich we train t5 over just the portions of thewizard of wikipedia training data where the evalu-ation measures are satisﬁed (table 6).
to do this,we ﬁltered the training set to only consist of theexamples which didn’t use ﬁrst person, had highlexical precision, and were entailed.
in spite ofthis being a much smaller training set (12k exam-ples), we ﬁnd that this model performs well inpractice, outperforming the base t5 model in allof the automatic metrics.
in comparison with thefully controlled model, we ﬁnd that it generallyperforms similarly in some metrics (e.g.
lexicalprecision is fairly similar), but with the nli-basedmetrics the controllable model may be slightly bet-ter (up to 2% higher).
an additional advantage ofthe controllable model is that it is robust enoughfor use with multiple styles of output depending onhow the controls are set, whereas the model trainedonly on the “faithful” portion of the training data ismore limited..a.3 human evaluation instructions.
the exact phrasing of the questions to human ratersis as follows:q1: fluency: is this response ﬂuent and grammati-cal?
q2: relevant: is this response a natural reply tothe previous utterance in the conversation?
q3: supported: are all parts of the responsesupported by the document?
(regardless of whetherit’s ﬂuent or relevant)q4: objective: does the response contain onlyobjective/factual information?.
human raters were asked to rate each answer ona scale from 1 (no not at all) to 5 (yes, very much)..a.4 correlations between human judgements.
and automatic metrics.
we observe that our proposed metrics generally cor-relate to human perceptions of whether a responseis faithful or objective.
we include pearson cor-relation coefﬁcients in table 7. to measure these,.
bleu n1p%99.6.b48.8.test (seen topic)w/ evid..prec85.6.rec62.3.bleu n1p%99.4.b48.5.test (unseen topic)w/ evid..prec86.1.rec61.1.nli%91.9.nli%91.5.table 6: training on faithful responses only: exper-imental results of a t5 model that was trained overonly “faithful” examples instead of using explicit con-trol codes or resampling.
we compared the human rating for each labelledexample vs. the automatic measurement for thatexample..a.5 example generation output.
we include some longer sets of examples in ta-bles 9 and 10. table 9 displays the generationsfrom ablation results of using different control codefeatures.
table 10 includes more examples withmore models..automatic metricno first personlexical prec wrt evidlexical rec wrt evid% entail.
human ratings.
flu0.020.030.02-0.04.rel-0.030.050.050.01.fai0.530.830.670.68.obj0.800.720.380.70.table 7: pearson’s r values between human metrics(ﬂuency, relevance, faithfulness, and objectivity) andautomatic metrics.
all of the correlation coefﬁcientsin the last two columns are statistically signiﬁcant atp < 0.001..715wizard of wikipedia training examples.
speaker.
utterance.
evidence.
apprentice hmm i thought it was only in france.
when did.
wizard.
apprentice.
wizard.
apprentice.
wizard.
apprentice.
wizard.
apprenticewizard.
the race ﬁrst take place?
the ﬁrst race was organized in 1903 to increasenewspaper sales of all things.
but it has grownquite a bit since then..that’s quite funny actually!
it’s certainly ex-tremely popular nowadays.
which is the mostsuccessful country to compete?
it is extremely popular.
i am actually not surewhich country historically has done best in it but inrecent years the us has done pretty well althoughthey have been found to have cheated.
it is a toughrace though so to do well over the whole 3 weektime frame it requires a ton of endurance.
it must be very tough to sustain such a level ofcompetitiveness for three weeks.
didn’t lancearmstrong get convicted of cheating - drugs ithink?
yeah he was found to have been doping after deny-ing it for years.
he was suspected for a lot of yearsthough.
in 2006 the launched an ofﬁcial investiga-tion and found him out.
that’s horrible.
should be ashamed of himself.
he really should be.
i think a ton of people do itthough.
there have been allegations of doping atthe tour de france ever since it started in 1903!.
i’m glad he got caught.
man.
i am really glad i went to college in the usi bet!
strong research suggests that us elite col-leges (mostly your ivy league schools) are thebest in the world..wizard.
apprentice yes.
i did not go to an ivy league college butwake forest where i went is also an excellentschool.
nice!!
somehow whenever i watch cfb wakeforest is usually playing even though i live intexas...laugh.
we have done better in football than bas-ketball in recent years though it was the oppositewhen i was at school at wake foresti mean yeah you guys won the acc champi-onship game a little more than a decade ago.
i’dsay that’s pretty football relevant!.
apprentice.
wizard.
apprentice.
wizard.
yes!
when i was at wake forest randolphchildress and rodney rogers were playing andmugsey bogues had just graduated.
tim duncancame just after memy boy timmy d the greatest spurs player ever toplay (i don’t count d robinson because he retiredright as i started watching)..apprentice yes.
and tim duncan is an amazingly nice per-son!
i am sad that even though i lived in austin inever went to see him play in san antonio.
i got to see them play once when i lived in sanantonio.
my (at the time) girlfriend’s dad had boxseats.
buffet fajitas omgthat sounds amazing!.
apprentice.
wizard.
the race was ﬁrst organized in 1903 to in-crease sales for the newspaper ”l’auto”;which is currently run by the amaury sportorganisation..like the other grand tours (the giro d’italiaand the vuelta a espa˜na) it consists of 21stages over a little more than 3 weeks..for much of his career lance armstrong facedpersistent allegations of doping but until 2006no ofﬁcial investigation was undertaken..there have been allegations of doping in thetour de france since the race began in 1903..strong research and funding have helpedmake america’s elite colleges and universitiesamong the world’s most prestigious makingthem particularly attractive to internationalstudents professors and researchers in the pur-suit of academic excellence..the wake forest demon deacons footballteam represents wake forest university in thesport of american football..wake forest defeated georgia tech by a 9–6score to win its ﬁrst acc football champi-onship since 1970 and its second in schoolhistory..many refer to duncan as the greatest spursplayer of all time..the san antonio spurs are an american pro-fessional basketball team based in san anto-nio texas..table 8: examples of wizard of wikipedia (dinan et al., 2019) conversations.
716document evidencealthough some origins in 18th century japan and 1830s europe, comic books were ﬁrst popularized in the unitedstates during the 1930s.
conversation historyspeaker 1: my son loves comic books, but i know literally nothing about them!
are you a comic book fan?
speaker 2: i know a bit about them.
comic books are a publication that has sequential panels that represent individualscenes.
speaker 1: sounds interesting!
what are some of the most popular comic books?
modelt5 (none).
outputcomic books originated in 18th century japan and 1830s europe.
super herocomic books are very popular, though comic books originated in japan in the18th century.
comic books have been popularized since the 18th century.
comic books originated in 18th century japan and 1830s europe.
some are japanese and europe.
well, comic books originated in 18th century japan and 1830s europe, but wereﬁrst popularized in the united states during the 1930s..t5 (<no-first-person>)t5 (<high-prec>)t5 (<entail>)t5 (all control codes).
document evidencea bagel with cream cheese is a common food pairing in american cuisine, the cuisine of new york city, and americanjewish cuisine, consisting in its basic form of an open-faced sandwich made of a bagel spread with cream cheese.
conversation historyspeaker 1: i like to make bagels.
speaker 2: i enjoy eating them.
they’re usually topped with seeds baked on the outer crust.
what kind of bagels doyou like?
speaker 1: i really like a whole wear bagel.
modelt5 (none).
outputyes, i love a bagel with cream cheese, it’s a common food pairing in americancuisine.
you’ve probably tried a bagel with cream cheese, but they’re a common pairingin american cuisine.
i love a bagel with cream cheese.
a bagel with cream cheese is a common food pairing in american cuisine.
the bagel with cream cheese is a common food pairing in american cuisine..t5 (<no-first-person>).
t5 (<high-prec>)t5 (<entail>)t5 (all control codes).
document evidencein 1963 their enormous popularity ﬁrst emerged as ”beatlemania”; as the group’s music grew in sophistication, ledby primary songwriters lennon and mccartney, the band were integral to pop music’s evolution into an art form andto the development of the counterculture of the 1960s.
conversation historyspeaker 1: i was raised on the beatles as a kid.
my parents played them all the timespeaker 2: they’re great!
they started in liverpool in 1960.speaker 1: yes and beetlemania hit the states in 1963. they were everywhereoutputmodelyes, they started to be so popular in 1963 that they became part of pop music’st5 (none)evolution.
it was the band that became part of the counterculture of the 1960s.
yes, and in 1963 their huge popularity ﬁrst emerged as beatlemania.
yes!
they were hugely popular!
they were great!
they were a part of pop music’s evolution into an art form..t5 (<no-first-person>)t5 (<high-prec>)t5 (<entail>)t5 (all control codes).
document evidencered hair (or ginger hair) occurs naturally in 1–2% of the human population.
conversation historyspeaker 1: hello my friend!
i had a tough time growing up, im a redhead!
bu tnow its getting better!
modelt5 (none)t5 (<no-first-person>)t5 (<high-prec>)t5 (<entail>)t5 (all control codes).
outputi love red hair.
it’s so common in 1-2% of the human population.
red hair occurs naturally in 1-2% of the human populationi have a red hair, which occurs naturally in 1–2% of the human population.
yea, it only occurs naturally in 1-2% of the human population.
red hair occurs naturally in 1–2% of the human population..table 9: model output from the wizard of wikipedia dev.
set with different control codes (not using resampling)..717document evidenceits popularity (as measured by equipment sales) in the united states peaked in 2007 and has been in a decline since.
conversation historyspeaker 1: i have always wanted to try snowboarding.
have you ever snowboarded?
modeldodecadialoguegpt-2 (none).
outputi have not, but i know it’s very popular in the united states.
i have never been but i do know that its popularity has declined in the us since2007.yes, it’s popular in the united states.
i have never been, but i’ve been to the united states and it’s been a while.
yes, it has been in a decline since 2007..gpt-2 (control codes)gpt-2 (resampling)gpt-2 (both).
document evidenceit can also be topped with additional vegetables, meats, and condiments, and can be made without cheese.
conversation historyspeaker 2: i love traditional italian food, especially pizza.
speaker 1: i like pizza to and spaghettimodeldodecadialoguet5 (none)t5 (control codes)t5 (resampling).
outputi like it topped with vegetables, meats, and condiments.
i love spaghetti.
it can be topped with vegetables and meats.
you can top it with vegetables, meats, and condiments.
i love spaghetti.
i love that it can be topped with vegetables, meats, and condi-ments.
it can be topped with vegetables, meats, and condiments..t5 (both).
document evidencethe concept for the grill was created by michael boehm of batavia, illinois.
conversation historyspeaker 1: i was thinking of buying a george foreman grill, do you know anything about them?
speaker 2: yes, it is a grill promoted by boxing great george foremanspeaker 1: interesting, did he invent the grill himself?
modeldodecadialoguegpt-2 (none)gpt-2 (control codes)gpt-2 (resampling)gpt-2 (both).
outputyes, the concept was created by michael boehm of batavia, illinoishe did and it was created by michael boehm of batavia, illinois.
yes, he created it by michael boehm of bataviano, but the concept for the grill was created by michael boehm of bataviayes, he did it by michael boehm of batavia, illinois.
dancing with the stars is the name of several international television series based on the format of the british tv series”strictly come dancing”, which is distributed by bbc worldwide, the commercial arm of the bbc.
conversation historyspeaker 1: have you ever seen dancing with the starts?
speaker 2: yes, i have seen dancing with the stars, there are so many versions produced across the world.
it is veryinteresting.
speaker 1: really!
i didnt know that!
what all countries have it?
modeldodecadialogue.
outputit is the name of several international television series based on the format of thebritish tv series ”strictly come dancing”, which is distributed by bbc worldwide,the commercial arm of the bbc.
the british tv series ”strictly come dancing” is the most popular.
british, uk, england, and japan.
it is the name of several international television series based on the format of thebritish tv series ”strictly come dancing”.
there is also the british tv series ”strictly come dancing”, which is distributed bybbc worldwide..t5 (none)t5 (control codes)t5 (resampling).
t5 (both).
table 10: additional model output examples from the wizard of wikipedia dev.
set..718