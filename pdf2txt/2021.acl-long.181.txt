cline: contrastive learning with semantic negative examples fornatural language understanding.
dong wang1,2∗ , ning ding1,2∗, piji li3† , hai-tao zheng1,2†1department of computer science and technology, tsinghua university2tsinghua shenzhen international graduate school, tsinghua university3tencent ai lab{wangd18,dingn18}@mails.tsinghua.edu.cnpijili@tencent.com,zheng.haitao@sz.tsinghua.edu.cn.
abstract.
despite pre-trained language models haveproven useful for learning high-quality seman-tic representations, these models are still vul-nerable to simple perturbations.
recent worksaimed to improve the robustness of pre-trainedmodels mainly focus on adversarial trainingfrom perturbed examples with similar seman-tics, neglecting the utilization of different oreven opposite semantics.
different from theimage processing ﬁeld, the text is discrete andfew word substitutions can cause signiﬁcant se-mantic changes.
to study the impact of seman-tics caused by small perturbations, we conducta series of pilot experiments and surprisinglyﬁnd that adversarial training is useless or evenharmful for the model to detect these semanticchanges.
to address this problem, we proposecontrastive learning with semantic negativeexamples (cline), which constructs seman-tic negative examples unsupervised to improvethe robustness under semantically adversarialattacking.
by comparing with similar and op-posite semantic examples, the model can ef-fectively perceive the semantic changes causedby small perturbations.
empirical results showthat our approach yields substantial improve-ments on a range of sentiment analysis, reason-ing, and reading comprehension tasks.
andcline also ensures the compactness withinthe same semantics and separability across dif-ferent semantics in sentence-level..1.introduction.
pre-trained language models (plms) such as bert(devlin et al., 2019) and roberta (liu et al.,2019) have been proved to be an effective way toimprove various natural language processing tasks.
however, recent works show that plms suffer from.
∗ equal contribution.
this work was mainly done when.
dong wang was an intern at tencent ai lab..† corresponding authors..sentence.
label.
predict.
creepy but ultimatelyunsatisfying thriller.
creepy but lastly unsat-isfying thriller.
creepy but ultimatelysatisfying thriller.
negative negative.
negative.
positive.
positive negative.
table 1: an adversarial example of sentiment analysisin movie reviews.
and the prediction results are fromthe bert (base version with 12 layers)..poor robustness when encountering adversarial ex-amples (jin et al., 2020; li et al., 2020; garg andramakrishnan, 2020; zang et al., 2020; lin et al.,2020a).
as shown in table 1, the bert model canbe fooled easily just by replacing ultimately with asimilar word lastly..to improve the robustness of plms, recent stud-ies attempt to adopt adversarial training on plms,which applies gradient-based perturbations to theword embeddings during training (miyato et al.,2017; zhu et al., 2020; jiang et al., 2020) or addshigh-quality adversarial textual examples to thetraining phase (wang and bansal, 2018; michelet al., 2019).
the primary goal of these adversarialmethods is to keep the label unchanged when the in-put has small changes.
these models yield promis-ing performance by constructing high-quality per-turbated examples and adopting adversarial mecha-nisms.
however, due to the discrete nature of nat-ural language, in many cases, small perturbationscan cause signiﬁcant changes in the semantics ofsentences.
as shown in table 1, negative senti-ment can be turned into a positive one by changingonly one word, but the model can not recognizethe change.
some recent works create contrastivesets (kaushik et al., 2020; gardner et al., 2020),.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages2332–2342august1–6,2021.©2021associationforcomputationallinguistics2332which manually perturb the test instances in smallbut meaningful ways that change the gold label.
in this paper, we denote the perturbated exampleswithout changed semantics as adversarial examplesand the ones with changed semantics as contrastiveexamples, and most of the methods to improverobustness of plms mainly focus on the former ex-amples, little study pays attention to the semanticnegative examples..the phenomenon makes us wonder can we traina bert that is both defensive against adversarialattacks and sensitive to semantic changes by usingboth adversarial and contrastive examples?
to an-swer that, we need to assess if the current robustmodels are meanwhile semantically sensitive.
weconduct sets of pilot experiments (section 2) tocompare the performances of vanilla plms andadversarially trained plms on the contrastive ex-amples.
we observe that while improving the ro-bustness of plms against adversarial attacks, theperformance on contrastive examples drops..to train a robust semantic-aware plm, we pro-pose contrastive learning with semantic negativeexamples (cline).
cline is a simple and effec-tive method to generate adversarial and contrastiveexamples and contrastively learn from both of them.
the contrastive manner has shown effectiveness inlearning sentence representations (luo et al., 2020;wu et al., 2020; gao et al., 2021), yet these studiesneglect the generation of negative instances.
incline, we use external semantic knowledge, i.e.,wordnet (miller, 1995), to generate adversarialand contrastive examples by unsupervised replac-ing few speciﬁc representative tokens.
equippedby replaced token detection and contrastive objec-tives, our method gathers similar sentences withsemblable semantics and disperse ones with differ-ent even opposite semantics, simultaneously im-proving the robustness and semantic sensitivity ofplms.
we conduct extensive experiments on sev-eral widely used text classiﬁcation benchmarks toverify the effectiveness of cline.
to be more spe-ciﬁc, our model achieves +1.6% absolute improve-ment on 4 contrastive test sets and +0.5% absoluteimprovement on 4 adversarial test sets comparedto roberta model (liu et al., 2019).
that is, withthe training on the proposed objectives, cline si-multaneously gains the robustness of adversarialattacks and sensitivity of semantic changes1..1the source code of cline will be publicly available at.
https://github.com/kandorm/cline.
2 pilot experiment and analysis.
to study how the adversarial training methods per-form on the adversarial set and contrastive set, weﬁrst conduct pilot experiments and detailed analy-ses in this section..2.1 model and datasets.
there are a considerable number of studies con-structing adversarial examples to attack large-scalepre-trained language models, of which we selecta popular method, textfooler (jin et al., 2020), asthe word-level adversarial attack model to constructadversarial examples.
recently, many researcherscreate contrastive sets to more accurately evaluate amodel’s true linguistic capabilities (kaushik et al.,2020; gardner et al., 2020).
based on these meth-ods, the following datasets are selected to constructadversarial and contrastive examples in our pilotexperiments and analyses:.
imdb (maas et al., 2011) is a sentiment analy-sis dataset and the task is to predict the sentiment(positive or negative) of a movie review..snli (bowman et al., 2015) is a natural lan-guage inference dataset to judge the relationshipbetween two sentences: whether the second sen-tence can be derived from entailment, contradiction,or neutral relationship with the ﬁrst sentence..to improve the generalization and robustnessof language models, many adversarial trainingmethods that minimize the maximal risk for label-preserving input perturbations have been proposed,and we select an adversarial training methodfreelb (zhu et al., 2020) for our pilot experiment.
we evaluate the vanilla bert (devlin et al., 2019)and roberta (liu et al., 2019), and the freelbversion on the adversarial set and contrastive set..2.2 result analysis.
table 2 shows a detailed comparison of differentmodels on the adversarial test set and the contrasttest set.
from the results, we can observe that, com-pared to the vanilla version, the adversarial trainingmethod freelb achieves higher accuracy on theadversarial sets, but suffers a considerable perfor-mance drop on the contrastive sets, especially forthe bert.
the results are consistent with the intu-ition in section 1, and also demonstrates that adver-sarial training is not suitable for the contrastive setand even brings negative effects.
intuitively, adver-sarial training tends to keep labels unchanged whilethe contrastive set tends to make small but label-.
2333model.
method.
imdb.
snli.
adv.
rev.
adv.
rev.
bert-base.
vanillafreelb 91.9 (+3.2).
88.7.
89.887.7 (−2.1).
48.656.1 (+7.5).
73.071.4 (−1.6).
roberta-base.
vanillafreelb.
93.995.2 (+1.3).
93.092.6 (−0.4).
55.158.1 (+3.0).
75.274.6 (−0.6).
table 2: accuracy (%) on the adversarial set (adv) compared to the contrastive set (rev) of vanilla models andadversarially trained models..imdb contrastive set.
jim henson’s muppets were a favorite of minesince childhood.
this ﬁlm on the other handmakes me feel dizziness in my head.
youwill see cameos by the then new york citymayor ed koch.
anyway, the ﬁlm turns 25this year and i hope the kids of today willlearn to appreciate the lightheartedness of theearly muppets gang over this.
it might beworth watching for kids but deﬁnitely not forknowledgeable adults like myself.
label: negativeprediction: positive.
table 3: wrong predictions made by the freelb ver-sion of bert on the contrastive set..changing modiﬁcations.
the adversarial trainingand contrastive examples seem to constitute a nat-ural contradiction, revealing that additional strate-gies need to be applied to the training phase forthe detection of the ﬁne-grained changes of seman-tics.
we provide a case study in section 2.3, whichfurther shows this difference..2.3 case study.
to further understand why the adversarial trainingmethod fails on the contrastive sets, we carry out athorough case study on imdb.
the examples wechoose here are predicted correctly by the vanillaversion of bert but incorrectly by the freelb ver-sion.
for the example in tabel 3, we can observethat many parts are expressing positive sentiments(red part) in the sentence, and a few parts are ex-pressing negative sentiments (blue parts).
overall,this case expresses negative sentiments, and thevanilla bert can accurately capture the negativesentiment of the whole document.
however, thefreelb version of bert may take the features ofnegative sentiment as noise and predict the wholedocument as a positive sentiment.
this result in-.
dicates that the adversarially trained bert couldbe fooled in a reversed way of traditional adversar-ial training.
from this case study, we can observethat the adversarial training methods may not besuitable for these semantic changed adversarial ex-amples, and to the best of our knowledge, thereis no defense method for this kind of adversarialattack.
thus, it is crucial to explore the appropriatemethods to learn changed semantics from semanticnegative examples..3 method.
as stated in the observations in section 2, we ex-plore strategies that could improve the sensitivityof plms.
in this section, we present cline, asimple and effective method to generate the adver-sarial and contrastive examples and learn from bothof them.
we start with the generation of adversar-ial and contrastive examples in section 3.1, andthen introduce the learning objectives of cline insection 3.2..3.1 generation of examples.
we expect that by contrasting sentences with thesame and different semantics, our model can bemore sensitive to the semantic changes.
to do so,we adopt the idea of contrastive learning, whichaims to learn the representation by concentratingpositive pairs and pushing negative pairs apart.
therefore it is essential to deﬁne appropriate pos-itive and negative pairs.
in this paper, we regardsentences with the same semantics as positive pairsand sentences with opposite semantics as negativepairs.
some works (alzantot et al., 2018; tan et al.,2020; wu et al., 2020) attempt to utilize data aug-mentation (such as synonym replacement, backtranslation, etc) to generate positive instances, butfew works pay attention to the negative instances.
and it is difﬁcult to obtain opposite semantic in-stances for textual examples..2334figure 1: an illustration of our model, note that we use the embedding of [cls] as the sentence representation..intuitively, when we replace the representativewords in a sentence with its antonym, the semanticof the sentence is easy to be irrelevant or even op-posite to the original sentence.
as shown in figure1, given the sentence “batman is an ﬁctional super-hero written by”, we can replace “ﬁctional” withits antonym “real-life”, and then we get a counter-factual sentence “batman is an real-life super-herowritten by”.
the latter contradicts the former andforms a negative pair with it..we generate two sentences from the original in-put sequence xori, which express substantially dif-ferent semantics but have few different words.
oneof the sentences is semantically close to xori (de-noted as xsyn), while the other is far from or evenopposite to xori (denoted as xant).
in speciﬁc, weutilize spacy2 to conduct segmentation and posfor the original sentences, extracting verbs, nouns,adjectives, and adverbs.
xsyn is generated by re-placing the extracted words with synonyms, hy-pernyms and morphological changes, and xant isgenerated by replacing them with antonyms andrandom words.
for xsyn, about 40% tokens arereplaced.
for xant, about 20% tokens are replaced..3.2 training objectives.
text encoder.
(i.e.,cline trains a neuraldeep transformer) eφ parameterized by φtokens x =that maps a sequence of input[x1, ..., xt ] to a sequence of representations h =[h1, .., ht ], hi∈[1:t ] ∈ rd, where d is the dimen-.
2https://github.com/explosion/spacy.
sion:.
h = eφ(x)..(1).
masked language modeling objective withrandom tokens masked by special symbols[mask], the input sequence is partially corrupted.
following bert (devlin et al., 2019), we adoptthe masked language model objective (denoted aslmlm), which reconstructs the sequence by pre-dicting the masked tokens.
replaced token detection objective on the ba-sis of xsyn and xant, we adopt an additional classi-ﬁer c for the two generated sequences and detectwhich tokens are replaced by conducting two-wayclassiﬁcation with a sigmoid output layer:.
p(xsyn, t) = sigmoid(w(cid:62)hsyn.
),.
p(xant, t) = sigmoid(w(cid:62)hant.
)..the loss, denoted as lrtd is computed by:.
t.t.lrtd =.
(cid:88).
t(cid:88).
−.
δtlog p(x(cid:48), t).
x(cid:48)∈{xsyn,xant}.
t=1.
− (1 − δt)log(1 − p(x(cid:48), t)),.
where δt = 1 when the token xt is corrupted, andδt = 0 otherwise.
contrastive objective the intuition of cline isto accurately predict if the semantics are changedwhen the original sentences are modiﬁed.
in otherwords, in feature space, the metric between hori.
(2).
(3).
(4).
2335batman is an ﬁctional super-hero written by batman is an imaginary super-hero created by batman is an real-life super-hero written bybert encoderbert encoderbert encodertoken-level classiﬁertoken-level classiﬁer00010010001000adversarial  example xsyncontrast example xantoriginal  example  xoripullpushlrtdlrtdsentence replctssentence repsentence repand hsyn should be close and the metric betweenhori and hant should be far.
thus, we develop acontrastive objective, where (xori, xsyn) is consid-ered a positive pair and (xori, xant) is negative.
weuse hc to denote the embedding of the special sym-bol [cls].
in the training of cline, we followthe setting of roberta (liu et al., 2019) to omitthe next sentence prediction (nsp) objective sinceprevious works have shown that nsp objective canhurt the performance on the downstream tasks (liuet al., 2019; joshi et al., 2020).
alternatively, adoptthe embedding of [cls] as the sentence repre-sentation for a contrastive objective.
the metricbetween sentence representations is calculated asthe dot product between [cls] embeddings:.
f (x∗, x(cid:48)) = exp(h∗(cid:62).
c h(cid:48).
c)..(5).
inspired by infonce, we deﬁne an objective lctsin the contrastive manner:.
lcts = −.
(cid:88).
x∈x.
log.
f (xori, xsyn)f (xori, xsyn) + f (xori, xant).
..(6)note that different from some contrastive strategiesthat usually randomly sample multiple negative ex-amples, we only utilize one xant as the negativeexample for training.
this is because the primarygoal of our pre-training objectives is to improvethe robustness under semantically adversarial at-tacking.
and we only focus on the negative sample(i.e., xant) that is generated for our goal, insteadof arbitrarily sampling other sentences from thepre-training corpus as negative samples..finally, we have the following training loss:.
l = λ1lmlm + λ2lrtd + λ3lcts,.
(7).
where λi is the task weighting learned by training..4 experiments.
we conduct extensive experiments and analyses toevaluate the effectiveness of cline.
in this sec-tion, we ﬁrstly introduce the implementation (sec-tion 4.1) and the datasets (section 4.2) we used,then we introduce the experiments on contrastivesets (section 4.3) and adversarial sets (section 4.4),respectively.
finally, we conduct the ablation study(section 4.5) and analysis about sentence represen-tation (section 4.6)..4.1.implementation.
but the ofﬁcial roberta-base model.
we train for30k steps with a batch size of 256 sequences ofmaximum length 512 tokens.
we use adam witha learning rate of 1e-4, β1 = 0.9, β2 = 0.999,(cid:15) =1e-8, l2 weight decay of 0.01, learning ratewarmup over the ﬁrst 500 steps, and linear decayof the learning rate.
we use 0.1 for dropout on alllayers and in attention.
the model is pre-trained on32 nvidia tesla v100 32gb gpus.
our model ispre-trained on a combination of bookcorpus (zhuet al., 2015) and english wikipedia datasets, thedata bert used for pre-training..4.2 datasets.
we evaluate our model on six text classiﬁcationtasks:.
• imdb (maas et al., 2011) is a sentiment anal-ysis dataset and the task is to predict the senti-ment (positive or negative) of a movie review..• snli (bowman et al., 2015) is a natural lan-guage inference dataset to judge the relation-ship between two sentences: whether the sec-ond sentence can be derived from entailment,contradiction, or neutral relationship with theﬁrst sentence..• perspectrum (chen et al., 2019) is anatural language inference dataset to predictwhether a relevant perspective is for/againstthe given claim..• boolq (clark et al., 2019) is a dataset of read-ing comprehension instances with boolean(yes or no) answers..• ag (zhang et al., 2015) is a sentence-level classiﬁcation with regard to four newstopics: world, sports, business, and sci-ence/technology..• mr (pang and lee, 2005) is a sentence-levelsentiment classiﬁcation on positive and nega-tive movie reviews..4.3 experiments on contrastive sets.
we evaluate our model on four contrastive sets:imdb, perspectrum, boolq and snli, whichwere provided by contrast sets3 (gardner et al.,2020).
we compare our approach with bert and.
to better acquire the knowledge from the existingpre-trained model, we did not train from scratch.
3https://github.com/allenai/.
contrast-sets.
2336model.
imdb.
perspectrum.
boolq.
ori.
rev con ori.
rev con ori.
rev con ori.
snlirev con.
bertroberta.
92.293.6.
89.893.0.
82.487.1.
74.780.6.
72.878.8.
57.665.0.
60.969.6.
57.660.6.
36.143.9.
89.890.8.
73.075.2.
65.167.8.cline.
94.5.
93.9.
88.5.
81.6.
80.2.
72.2.
73.9.
63.9.
47.8.
91.3.
76.0.
69.2.table 4: accuracy on the original test set (ori) and contrastive test set (rev).
contrast consistency (con) is a metricof whether a model makes correct predictions on every element in both the original test set and the contrastive testset..model.
method.
imdb.
ag mr.snli.
bert.
roberta.
cline.
vanillafreelb.
vanillafreelb.
vanillafreelb.
88.791.9.
93.995.2.
94.795.9.
88.893.3.
91.993.5.
92.394.2.
68.475.9.
79.781.0.
80.482.1.
48.656.1.
55.158.1.
55.458.7.table 5: accuracy on the adversarial test set..roberta across the original test set (ori) and con-trastive test set (rev).
contrast consistency (con)is a metric deﬁned by gardner et al.
(2020) to evalu-ate whether a model’s predictions are all correct forthe same examples in both the original test set andthe contrastive test set.
we ﬁne-tune each modelmany times using different learning rates (1e-5,2e-5,3e-5,4e-5,5e-5) and select the best result on thecontrastive test set..from the results shown in table 4, we can ob-serve that our model outperforms the baseline.
es-pecially in the contrast consistency metric, ourmethod signiﬁcantly outperforms other methods,which means our model is sensitive to the smallchange of semantic, rather than simply capturingthe characteristics of the dataset.
on the other hand,our model also has some improvement on the origi-nal test set, which means our method can boost theperformance of plms on the common examples..4.4 experiments on adversarial sets.
to evaluate the robustness of the model, we com-pare our model with bert and roberta on thevanilla version and freelb version across severaladversarial test sets.
instead of using an adversarialattacker to attack the model, we use the adversar-ial examples generated by textfooler (jin et al.,2020) as a benchmark to evaluate the performanceagainst adversarial examples.
textfooler identiﬁesthe important words in the text and then prioritizes.
to replace them with the most semantically similarand grammatically correct words..from the experimental results in table 5, wecan observe that our vanilla model achieves higheraccuracy on all the four benchmark datasets com-pared to the vanilla bert and roberta.
by con-structing similar semantic adversarial examplesand using the contrastive training objective, ourmodel can concentrate the representation of theoriginal example and the adversarial example, andthen achieve better robustness.
furthermore, ourmethod is in the pre-training stage, so it can alsobe combined with the existing adversarial trainingmethods.
compared with the freelb version ofbert and roberta, our model can achieve state-of-the-art (sota) performances on the adversarialsets.
experimental results on contrastive sets andadversarial sets show that our model is sensitiveto semantic changes and keeps robust at the sametime..4.5 ablation study.
to further analyze the effectiveness of different fac-tors of our cline, we choose perspectrum(chen et al., 2019) and boolq (clark et al., 2019)as benchmark datasets and report the ablation testin terms of 1) w/o rtd: we remove the replacedtoken detection objective (lrtd) in our model toverify whether our model mainly beneﬁts from thecontrastive objective.
2) w/o hard negative: wereplace the constructed negative examples with ran-dom sampling examples to verify whether the neg-ative examples constructed by unsupervised wordsubstitution are better.
we also add 1% and 10%settings, meaning using only 1% / 10% data of thetraining set, to simulate a low-resource scenarioand observe how the model performance acrossdifferent datasets and settings.
from table 6, wecan observe that: 1) our cline outperformanceroberta on all settings, which indicates that ourmethod is universal and robust.
especially in the.
2337dataset.
model.
perspectrum.
boolq.
1%rev con ori.
10%rev con ori.
100%rev con.
60.459.453.054.8.
52.852.549.049.3.
33.629.014.713.8.
33.732.230.027.5.
75.173.471.472.4.
68.168.068.165.2.
69.167.768.866.8.
54.053.753.453.1.
55.353.038.245.2.
36.135.835.232.8.
81.681.180.980.6.
73.972.569.669.6.
80.278.378.278.8.
63.963.061.860.6.
72.268.965.965.0.
47.846.644.543.9.ori.
71.467.359.055.8.
66.764.860.160.9.clinew/o rtdw/o hard negativeroberta.
clinew/o rtdw/o hard negativeroberta.
table 6: ablation study on the original test set (ori) and contrastive test set (rev) of perspectrum (accuracy)and boolq (accuracy).
1% / 10% indicate using 1% / 10% supervised training data respectively.
contrast consis-tency (con) is a metric of whether a model makes correct predictions on every element in both the original test setand the contrastive test set..model.
cls mean bs.
bert42.4cline-b 58.0.robertacline-r 42.1.
–.
45.259.2.
42.542.8.
47.066.8.
45.149.4.the max hits(%) on all.
table 7:layers of thetransformer-based encoder.
we compute cosinesimilarity between sentence representations with the[cls] token (cls) and the mean-pooling of thesentence embedding (mean).
and bs is short forbertscore.
cline-b means our model trained fromthe bert-base model and cline-r means our modeltrained from the roberta-base model..low-resource scenario (1% and 10% supervisedtraining data), our method shows a prominent im-provement.
2) compared to the cline, w/o rtdjust has a little bit of performance degradation.
this proves that the improvement of performancemainly beneﬁts from the contrastive objective andthe replaced token detection objective can furthermake the model sensitive to the change of thewords.
3) compared to cline, we can see that thew/o hard negative has a signiﬁcant performancedegradation in most settings, proving the effective-ness of constructing hard negative instances..4.6 sentence semantic representation.
to evaluate the semantic sensitivity of the models,we generate 9626 sentence triplets from a sentence-level sentiment analysis dataset mr (pang and lee,2005).
each of the triples contains an originalsentence xori from mr, a sentence with similar.
semantics xsyn and a sentence with opposite se-mantic xant.
we generate xsyn/xant by replacing aword in xori with its synonym/antonym from word-net (miller, 1995).
and then we compute the co-sine similarity between sentence pairs with [cls]token and the mean-pooling of all tokens.
andwe also use a sota algorithm, bertscore (zhanget al., 2020) to compute similarity scores of sen-tence pairs.
we consider cases in which the modelcorrectly identiﬁes the semantic relationship (e.g.,if bertscore(xori,xsyn)>bertscore(xori,xant)) ashits.
and higher hits means the model can betterdistinguish the sentences, which express substan-tially different semantics but have few differentwords..we show the max hits on all layers (from 1 to12) of transformers-based encoder in table 7. wecan observe: 1) in the bert model, using the[cls] token as sentence representation achievesworse results than mean-pooling, which shows thesame conclusion as sentence-bert (reimers andgurevych, 2019).
and because roberta omitsthe nsp objective, so its result of cls has no mean-ing.
2) the bertscore can compute semantic sim-ilarity better than other methods and our methodcline-b can further improve the hits.
3) by con-structing positive and negative examples for con-trastive learning in pre-training stage, our methodcline-b and cline-r learn better sentence rep-resentation and detect small semantic changes.
4)we can observe that the roberta has less hitsthan bert, and our cline-b has signiﬁcant im-provement compared to bert.
we speculate thatthere may be two reasons, the ﬁrst is that bertcan better identify sentence-level semantic changes.
2338because it has been trained with the next sentenceprediction (nsp) objective in the pre-training stage.
and the second is that the bert is not trainedenough, so it can not represent sentence semanticswell, and our method can improve the semanticrepresentation ability of the model..5 related work.
5.1 pre-trained language models.
the plms have proven their advantages in cap-turing implicit language features.
two main re-search directions of plms are autoregressive (ar)pre-training (such as gpt (radford et al., 2018))and denoising autoencoding (dae) pre-training(such as bert (devlin et al., 2019)).
ar pre-training aims to predict the next word based onprevious tokens but lacks the modeling of the bidi-rectional context.
and dae pre-training aims toreconstruct the input sequences using left and rightcontext.
however, previous works mainly focuson the token-level pre-training tasks and ignoremodeling the global semantic of sentences..5.2 adversarial training.
to make neural networks more robust to adversar-ial examples, many defense strategies have beenproposed, and adversarial training is widely con-sidered to be the most effective.
different from theimage domain, it is more challenging to deal withtext data due to its discrete property, which is hardto optimize.
previous works focus on heuristics forcreating adversarial examples in the black-box set-ting.
belinkov and bisk (2018) manipulate everyword in a sentence with synthetic or natural noisein machine translation systems.
iyyer et al.
(2018)leverage back-translated to produce paraphrasesthat have different sentence structures.
recently,miyato et al.
(2017) extend adversarial and virtualadversarial training (miyato et al., 2019) to textclassiﬁcation tasks by applying perturbations toword embeddings rather than discrete input sym-bols.
following this, many adversarial trainingmethods in the text domain have been proposedand have been applied to the state-of-the-art plms.
li and qiu (2020) introduce a token-level pertur-bation to improves the robustness of plms.
zhuet al.
(2020) use the gradients obtained in adver-sarial training to boost the performance of plms.
although many studies seem to achieve a robustrepresentation, our pilot experiments (section 2)show that there is still a long way to go..5.3 contrastive learning.
contrastive learning is an unsupervised representa-tion learning method, which has been widely usedin learning graph representations (velickovic et al.,2019), visual representations (van den oord et al.,2018; he et al., 2020; chen et al., 2020), responserepresentations (lin et al., 2020b; su et al., 2020),text representations (iter et al., 2020; ding et al.,2021) and structured world models (kipf et al.,2020).
the main idea is to learn a representation bycontrasting positive pairs and negative pairs, whichaims to concentrate positive samples and push apartnegative samples.
in natural language process-ing (nlp), contrastive self-supervised learning hasbeen widely used for learning better sentence repre-sentations.
logeswaran and lee (2018) sample twocontiguous sentences for positive pairs and the sen-tences from the other document as negative pairs.
luo et al.
(2020) present contrastive pretrainingfor learning denoised sequence representations in aself-supervised manner.
wu et al.
(2020) presentmultiple sentence-level augmentation strategies forcontrastive sentence representation learning.
themain difference between these works is their var-ious deﬁnitions of positive examples.
however,recent works pay little attention to the constructionof negative examples, only using simple randomsampling sentences.
in this paper, we propose anegative example construction strategy with oppo-site semantics to improve the sentence representa-tion learning and the robustness of the pre-trainedlanguage model..6 conclusion.
in this paper, we focus on one speciﬁc problemhow to train a pre-trained language model withrobustness against adversarial attacks and sensi-tivity to small changed semantics.
we proposecline, a simple and effective method to tackle thechallenge.
in the training phase of cline, it au-tomatically generates the adversarial example andsemantic negative example to the original sentence.
and then the model is trained by three objectives tomake full utilization of both sides of examples.
em-pirical results demonstrate that our method couldconsiderably improve the sensitivity of pre-trainedlanguage models and meanwhile gain robustness..acknowledgments.
this research is supported by national natural sci-ence foundation of china (grant no.
61773229.
2339and 6201101015), tencent ai lab rhino-birdjr202032),focused research program (no.
shenzhen giiso information technology co.ltd., natural science foundation of guangdongprovince (grant no.
2021a1515012640), thebasic research fund of shenzhen city (grandno.
jcyj20190813165003837), and overseascooperation research fund of graduate schoolat shenzhen, tsinghua university (grant no.
hw2018002)..references.
moustafa alzantot, yash sharma, ahmed elgohary,bo-jhang ho, mani b. srivastava, and kai-weichang.
2018. generating natural language adver-in proceedings of the 2018 con-sarial examples.
ference on empirical methods in natural languageprocessing, brussels, belgium, october 31 - novem-ber 4, 2018, pages 2890–2896.
association for com-putational linguistics..yonatan belinkov and yonatan bisk.
2018. syntheticand natural noise both break neural machine trans-in 6th international conference on learn-lation.
ing representations, iclr 2018, vancouver, bc,canada, april 30 - may 3, 2018, conference trackproceedings.
openreview.net..samuel r. bowman, gabor angeli, christopher potts,and christopher d. manning.
2015. a large an-notated corpus for learning natural language infer-in proceedings of the 2015 conference onence.
empirical methods in natural language processing,emnlp 2015, lisbon, portugal, september 17-21,2015, pages 632–642.
the association for compu-tational linguistics..sihao chen, daniel khashabi, wenpeng yin, chriscallison-burch, and dan roth.
2019. seeing thingsfrom a different angle: discovering diverse perspec-tives about claims.
in proceedings of the 2019 con-ference of the north american chapter of the asso-ciation for computational linguistics: human lan-guage technologies, naacl-hlt 2019, minneapo-lis, mn, usa, june 2-7, 2019, volume 1 (long andshort papers), pages 542–557.
association for com-putational linguistics..ting chen, simon kornblith, mohammad norouzi,and geoffrey e. hinton.
2020. a simple frameworkfor contrastive learning of visual representations.
inproceedings of the 37th international conference onmachine learning, icml 2020, 13-18 july 2020,virtual event, volume 119 of proceedings of ma-chine learning research, pages 1597–1607.
pmlr..christopher clark, kenton lee, ming-wei chang,tom kwiatkowski, michael collins, and kristinatoutanova.
2019. boolq: exploring the surprisingin proceed-difﬁculty of natural yes/no questions.
ings of the 2019 conference of the north american.
chapter of the association for computational lin-guistics: human language technologies, naacl-hlt 2019, minneapolis, mn, usa, june 2-7, 2019,volume 1 (long and short papers), pages 2924–2936. association for computational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-in proceedings of the 2019 conferencestanding.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, naacl-hlt 2019, minneapolis, mn,usa, june 2-7, 2019, volume 1 (long and short pa-pers), pages 4171–4186.
association for computa-tional linguistics..ning ding, xiaobin wang, yao fu, guangwei xu, ruiwang, pengjun xie, ying shen, fei huang, hai-taozheng, and rui zhang.
2021. prototypical repre-in inter-sentation learning for relation extraction.
national conference on learning representations..tianyu gao, xingcheng yao, and danqi chen.
2021.simcse: simple contrastive learning of sentence em-beddings.
corr, abs/2104.08821..matt gardner, yoav artzi, victoria basmova, jonathanberant, ben bogin, sihao chen, pradeep dasigi,dheeru dua, yanai elazar, ananth gottumukkala,nitish gupta, hannaneh hajishirzi, gabriel ilharco,daniel khashabi, kevin lin, jiangming liu, nel-son f. liu, phoebe mulcaire, qiang ning, sameersingh, noah a. smith, sanjay subramanian, reuttsarfaty, eric wallace, ally zhang, and ben zhou.
2020. evaluating models’ local decision boundariesvia contrast sets.
in proceedings of the 2020 con-ference on empirical methods in natural languageprocessing: findings, emnlp 2020, online event,16-20 november 2020, pages 1307–1323.
associa-tion for computational linguistics..siddhant garg and goutham ramakrishnan.
2020.bae: bert-based adversarial examples for text clas-in proceedings of the 2020 conferencesiﬁcation.
on empirical methods in natural language process-ing, emnlp 2020, online, november 16-20, 2020,pages 6174–6181.
association for computationallinguistics..kaiming he, haoqi fan, yuxin wu, saining xie, andross b. girshick.
2020. momentum contrast for un-in 2020supervised visual representation learning.
ieee/cvf conference on computer vision and pat-tern recognition, cvpr 2020, seattle, wa, usa,june 13-19, 2020, pages 9726–9735.
ieee..dan iter, kelvin guu, larry lansing, and dan jurafsky.
2020. pretraining with contrastive sentence objec-tives improves discourse performance of languagein proceedings of the 58th annual meet-models.
ing of the association for computational linguistics,acl 2020, online, july 5-10, 2020, pages 4859–4870. association for computational linguistics..2340mohit iyyer, john wieting, kevin gimpel, and lukezettlemoyer.
2018. adversarial example generationwith syntactically controlled paraphrase networks.
in proceedings of the 2018 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,naacl-hlt 2018, new orleans, louisiana, usa,june 1-6, 2018, volume 1 (long papers), pages1875–1885.
association for computational linguis-tics..haoming jiang, pengcheng he, weizhu chen, xi-aodong liu, jianfeng gao, and tuo zhao.
2020.smart: robust and efﬁcient ﬁne-tuning for pre-trained natural language models through principledin proceedings of theregularized optimization.
58th annual meeting of the association for compu-tational linguistics, acl 2020, online, july 5-10,2020, pages 2177–2190.
association for computa-tional linguistics..di jin, zhijing jin, joey tianyi zhou, and peterszolovits.
2020. is bert really robust?
a strongbaseline for natural language attack on text classiﬁ-in the thirty-fourth aaaication and entailment.
conference on artiﬁcial intelligence, aaai 2020,new york, ny, usa, february 7-12, 2020, pages8018–8025.
aaai press..mandar joshi, danqi chen, yinhan liu, daniel s.weld, luke zettlemoyer, and omer levy.
2020.spanbert:improving pre-training by representingand predicting spans.
trans.
assoc.
comput.
lin-guistics, 8:64–77..divyansh kaushik,.
eduard h. hovy,.
andzachary chase lipton.
2020. learning the differ-ence that makes a difference with counterfactually-augmented data.
in 8th international conference onlearning representations, iclr 2020, addis ababa,ethiopia, april 26-30, 2020. openreview.net..thomas n. kipf, elise van der pol, and max welling.
2020. contrastive learning of structured world mod-in 8th international conference on learningels.
representations, iclr 2020, addis ababa, ethiopia,april 26-30, 2020. openreview.net..linyang li, ruotian ma, qipeng guo, xiangyang xue,and xipeng qiu.
2020. bert-attack: adversar-in proceed-ial attack against bert using bert.
ings of the 2020 conference on empirical methodsin natural language processing, emnlp 2020, on-line, november 16-20, 2020, pages 6193–6202.
as-sociation for computational linguistics..linyang li and xipeng qiu.
2020. textat: adversar-ial training for natural language understanding withtoken-level perturbation.
corr, abs/2004.14543..gongqi lin, yuan miao, xiaoyong yang, wenwu ou,lizhen cui, wei guo, and chunyan miao.
2020a.
commonsense knowledge adversarial dataset that.
in 16th international con-challenges electra.
ference on control, automation, robotics and vi-sion, icarcv 2020, shenzhen, china, december13-15, 2020, pages 315–320.
ieee..zibo lin, deng cai, yan wang, xiaojiang liu, haitaozheng, and shuming shi.
2020b.
the world isnot binary: learning to rank with grayscale datafor dialogue response selection.
in proceedings ofthe 2020 conference on empirical methods in nat-ural language processing, emnlp 2020, online,november 16-20, 2020, pages 9220–9229.
associ-ation for computational linguistics..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
corr, abs/1907.11692..lajanugen logeswaran and honglak lee.
2018. anefﬁcient framework for learning sentence represen-tations.
in 6th international conference on learn-ing representations, iclr 2018, vancouver, bc,canada, april 30 - may 3, 2018, conference trackproceedings.
openreview.net..fuli luo, pengcheng yang, shicheng li, xuanchengren, and xu sun.
2020. capt: contrastive pre-training for learning denoised sequence representa-tions.
corr, abs/2010.06351..andrew l. maas, raymond e. daly, peter t. pham,dan huang, andrew y. ng, and christopher potts.
2011. learning word vectors for sentiment analysis.
in the 49th annual meeting of the association forcomputational linguistics: human language tech-nologies, proceedings of the conference, 19-24 june,2011, portland, oregon, usa, pages 142–150.
theassociation for computer linguistics..paul michel, xian li, graham neubig,.
andjuan miguel pino.
2019. on evaluation of ad-versarial perturbations for sequence-to-sequencein proceedings of the 2019 conferencemodels.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, naacl-hlt 2019, minneapolis,mn, usa, june 2-7, 2019, volume 1 (long andshort papers), pages 3103–3114.
association forcomputational linguistics..george a. miller.
1995. wordnet: a lexical database.
for english.
commun.
acm, 38(11):39–41..takeru miyato, andrew m. dai, and ian j. good-fellow.
2017. adversarial training methods forin 5th inter-semi-supervised text classiﬁcation.
national conference on learning representations,iclr 2017, toulon, france, april 24-26, 2017, con-ference track proceedings.
openreview.net..takeru miyato, shin-ichi maeda, masanori koyama,and shin ishii.
2019. virtual adversarial training:.
2341yuan zang, fanchao qi, chenghao yang, zhiyuan liu,meng zhang, qun liu, and maosong sun.
2020.word-level textual adversarial attacking as combina-torial optimization.
in proceedings of the 58th an-nual meeting of the association for computationallinguistics, acl 2020, online, july 5-10, 2020,pages 6066–6080.
association for computationallinguistics..tianyi zhang, varsha kishore, felix wu, kilian q.weinberger, and yoav artzi.
2020. bertscore: eval-in 8th inter-uating text generation with bert.
national conference on learning representations,iclr 2020, addis ababa, ethiopia, april 26-30,2020. openreview.net..xiang zhang, junbo jake zhao, and yann lecun.
2015.character-level convolutional networks for text clas-siﬁcation.
in advances in neural information pro-cessing systems 28: annual conference on neuralinformation processing systems 2015, december 7-12, 2015, montreal, quebec, canada, pages 649–657..chen zhu, yu cheng, zhe gan, siqi sun, tom gold-stein, and jingjing liu.
2020. freelb: enhanced ad-versarial training for natural language understanding.
in 8th international conference on learning repre-sentations, iclr 2020, addis ababa, ethiopia, april26-30, 2020. openreview.net..yukun zhu, ryan kiros, richard s. zemel, ruslansalakhutdinov, raquel urtasun, antonio torralba,and sanja fidler.
2015. aligning books and movies:towards story-like visual explanations by watchingin 2015 ieee interna-movies and reading books.
tional conference on computer vision, iccv 2015,santiago, chile, december 7-13, 2015, pages 19–27.
ieee computer society..a regularization method for supervised and semi-ieee trans.
pattern anal.
supervised learning.
mach.
intell., 41(8):1979–1993..a¨aron van den oord, yazhe li, and oriol vinyals.
2018. representation learning with contrastive pre-dictive coding.
corr, abs/1807.03748..bo pang and lillian lee.
2005. seeing stars: exploit-ing class relationships for sentiment categorizationwith respect to rating scales.
in acl 2005, 43rd an-nual meeting of the association for computationallinguistics, proceedings of the conference, 25-30june 2005, university of michigan, usa, pages 115–124. the association for computer linguistics..alec radford, karthik narasimhan, tim salimans, andimproving language under-.
ilya sutskever.
2018.standing by generative pre-training..nils reimers and iryna gurevych.
2019. sentence-bert: sentence embeddings using siamese bert-networks.
in proceedings of the 2019 conference onempirical methods in natural language processingand the 9th international joint conference on nat-ural language processing, emnlp-ijcnlp 2019,hong kong, china, november 3-7, 2019, pages3980–3990.
association for computational linguis-tics..yixuan su, deng cai, qingyu zhou, zibo lin, si-mon baker, yunbo cao, shuming shi, nigel col-lier, and yan wang.
2020. dialogue response selec-tion with hierarchical curriculum learning.
corr,abs/2012.14756..it’s morphin’ time!.
samson tan, shaﬁq r. joty, min-yen kan, and richardsocher.
2020.combatinglinguistic discrimination with inﬂectional perturba-tions.
in proceedings of the 58th annual meeting ofthe association for computational linguistics, acl2020, online, july 5-10, 2020, pages 2920–2935.
association for computational linguistics..petar velickovic, william fedus, william l. hamil-ton, pietro li`o, yoshua bengio, and r. devonin 7th inter-hjelm.
2019. deep graph infomax.
national conference on learning representations,iclr 2019, new orleans, la, usa, may 6-9, 2019.openreview.net..yicheng wang and mohit bansal.
2018. robust ma-chine comprehension models via adversarial train-ing.
in proceedings of the 2018 conference of thenorth american chapter of the association for com-putational linguistics: human language technolo-gies, naacl-hlt, new orleans, louisiana, usa,june 1-6, 2018, volume 2 (short papers), pages 575–581. association for computational linguistics..zhuofeng wu, sinong wang, jiatao gu, madiankhabsa, fei sun, and hao ma.
2020. clear: con-trastive learning for sentence representation.
corr,abs/2012.15466..2342