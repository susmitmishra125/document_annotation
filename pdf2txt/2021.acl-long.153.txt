crafting adversarial examples for neural machine translation.
xinze zhang1, 2, ∗ junzhe zhang1 zhenhua chen1 kun he1, †1school of computer science and technology,2school of management,huazhong university of science and technology{xinze,junzhezhang,zhenhuachen,brooklet60}@hust.edu.cn.
abstract.
effective adversary generation for neural ma-chine translation (nmt) is a crucial prereq-uisite for building robust machine translationsystems.
in this work, we investigate veri-table evaluations of nmt adversarial attacks,and propose a novel method to craft nmtadversarial examples.
we ﬁrst show the cur-rent nmt adversarial attacks may be improp-erly estimated by the commonly used mono-directionaltranslation, and we propose toleverage the round-trip translation technique tobuild valid metrics for evaluating nmt adver-sarial attacks.
our intuition is that an effec-tive nmt adversarial example, which imposesminor shifting on the source and degradesthe translation dramatically, would naturallylead to a semantic-destroyed round-trip trans-lation result.
we then propose a promisingblack-box attack method called word saliencyspeedup local search (wsls) that could ef-fectively attack the mainstream nmt archi-tectures.
comprehensive experiments demon-strate that the proposed metrics could accu-rately evaluate the attack effectiveness, and theproposed wsls could signiﬁcantly break thestate-of-art nmt models with small perturba-tion.
besides, wsls exhibits strong trans-ferability on attacking baidu and bing onlinetranslators..1.introduction.
recent studies have revealed that neural machinetranslation (nmt), which has achieved remarkableprogress in advancing the quality of machine trans-lation, is fragile when attacked by some crafted per-turbations (belinkov and bisk, 2018; cheng et al.,2019, 2020; wallace et al., 2020).
even if the per-turbations on inputs are small and imperceptible tohumans, the translation quality could be degraded.
∗the four authors contributed equally.
† corresponding author: kun he..john biden just win the election.
input xtrans.
y 约翰·拜登刚刚赢得了大选约翰·拜登刚刚赢得了选举ref.
input x(cid:48)john biden just lost the electiontrans.
y(cid:48) 约翰·拜登刚刚赢得了大选.
table 1: a real example of adversarial generation forgoogle translation with antonym substitution (i.e., winto lost) which reverses the semantics on the source butpreserves the same translation exactly (reported in oc-tober, 2020)..dramatically, raising increasing attention to adver-sarial defenses for building robust machine transla-tion systems as well as its prerequisite researcheson building effective nmt adversarial attacks.
ascharacter level perturbations usually lead to lexicalerrors and are easily corrected by spell checkingtools (ren et al., 2019; zou et al., 2020), in thiswork, we focus on crafting word level adversarialexamples that could maintain lexical and grammat-ical correctness and hence are more realistic..an essential issue of crafting nmt adversar-ial examples is how to deﬁne “what is an effec-tive nmt adversarial attack”.
researchers haveprovided an intuitive deﬁnition that an nmt ad-versarial example should preserve the semanticmeaning on the source but destroy the translationperformance with respect to the reference transla-tion (michel et al., 2019; niu et al., 2020).
cor-respondingly, the attack criteria are proposed asthe absolute degradation or relative degradationagainst the reference translation (ebrahimi et al.,2018; michel et al., 2019; niu et al., 2020; zouet al., 2020).
to craft a perturbation that maintainsthe semantics as well as grammatical correctnessfollowing the above deﬁnition and evaluation, avariety of methods to impose word replacementshave been proposed in recent studies (michel et al.,2019; cheng et al., 2019, 2020; zou et al., 2020),making it a commonly used paradigm for nmtattacks..proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages1967–1977august1–6,2021.©2021associationforcomputationallinguistics1967reference sentenceref.
: the chairperson of the conference expressedin a speech that high and new technologies have pro-moted the development of the nations in asia, europe,and america..ref.
(cid:48)×: the chairperson of the conference expressedin a speech that the high-level leadership has pro-moted the growth of the nations in asia, europe, andamerica..ref.
(cid:48)√: the chairperson of the convention expressedin a speech that the high-level leadership has pro-moted the development of the nations in asia, europe,and america..×: 会议主席在发言中称, 高层促进了亚洲和欧美国.
chinese→english translationx: 会议主席在发言中认为, 高新技术促进了亚洲和欧美国家的发展。y: in his speech, the chairman of the meeting heldthat high and new technologies have promoted thedevelopment of asian and european countries.
x(cid:48)家的成长。y(cid:48)×: in his speech, the chairman of the meetingsaid that the high-level leadership has promotedthe growth of asian and european countries.
x(cid:48)√: 代表大会主席在发言中称, 高层促进了亚洲和欧美国家的发展。y(cid:48)√: in his speech, the chairman of the npc standingcommittee said that the high-level leadership haspromoted the development of asian and europeancountries..table 2: two examples of adversarial generation for rnnsearch based nmt model with synonym substitution.
the left column contains the ground-truth references.
the right column contains the corresponding original input x,×, effective adversarial example x(cid:48)√, and their neural translations.
the effectivenoneffective adversarial example x(cid:48)and noneffective attack locations are marked in orange and blue, respectively..however, there exist potential pitfalls overlookedin existing researches.
first, it is possible to craftan effective attack on the nmt models by revers-ing the semantics on the source, as illustrated intable 11. meanwhile, since the antonyms are po-tentially in the neighborhood of the victim word inthe embedding space, just as the same as the syn-onyms, it is entirely possible to produce opposingsemantics when replacing a word with its neigh-bors, making the proposed attack method break thedeﬁnition..furthermore, there is a risk of evaluating theattacks directly using the reference translation.
dif-fers to the classiﬁcation tasks, even if the pertur-bation is small to be synonymous with the orig-inal word in the source, the actual ground-truthreference may be changed due to the substitution.
table 2 illustrates a typical failing adversarial ex-ample x(cid:48)× and a successful example x(cid:48)√, wherex(cid:48)× could be falsely distinguished as effective dueto the missing of ground-truth reference ref.
(cid:48)2.
×obviously, x(cid:48) would be correctly distinguished ifwe have the actual ground-truth reference of x(cid:48).
however, the actual ground-truth reference of theperturbed input is notoriously difﬁcult to be builtbeforehand, making the nmt attack hardly to beevaluated veritably..in this work, in order to craft appropriate nmtadversarial examples, we introduce new deﬁnition.
and metrics for the machine translation adversariesby leveraging the round-trip translation, the pro-cess of translating text from the source to targetlanguage and translating the result back into thesource language.
our intuition is that an effectivenmt adversarial example, which imposes minorshifting on the input and degrades the translationdramatically, would naturally lead to a semantic de-stroying round-trip translation result.
based on ournew deﬁnition and metrics, we propose a promis-ing black-box attack method called word saliencyspeedup local search (wsls) that could effec-tively attack the mainstream nmt architectures,e.g.
rnn and transformer..our main contributions are as follows:.
• we introduce an appropriate deﬁnition ofnmt adversary and the deriving evaluationmetrics, which are capable of estimating theadversaries only using source information,and tackle well the challenge of missingground-truth reference after the perturbation..• we propose a novel black-box word levelnmt attack method that could effectively at-tack the mainstream nmt models, and exhibithigh transferability when attacking popularonline translators..2 nmt adversary generation.
1this is a real case reported on google transla-see details in:tion community in october, 2020.https://support.google.com/translate/thread/78771708?hl=en.
×) = 2.86,.
2bleu(ref, y) = 39.20 → bleu(ref, y(cid:48)×) = 61.34 → bleu(y, y(cid:48).
bleu(x, x(cid:48).
×) = 49.83..let x denote the source language space consistingof all possible source sentences and y denote thetarget language space.
given two nmt models, theprimal source-to-target nmt model mx→y aims to.
1968learn a forward mapping f : x → y to maximizep (yref |x) where x ∈ x and yref ∈ y, while thedual target-to-source nmt model my→x aims tolearn the backward mapping g : y → x .
after thetraining, nmt can correctly reconstruct the sourcesentence ˆx = g(f (x)).
in the following, we ﬁrstgive the deﬁnition of nmt adversarial examples,then introduce our word substitution based black-box adversarial attack method..2.1 deﬁnition on nmt adversarial examples.
given a subset of (test) sentences t ∈ x and asmall constant (cid:15), we summarize previous works(belinkov and bisk, 2018; ebrahimi et al., 2018;michel et al., 2019) and give their conception ofnmt adversarial examples as follows.
deﬁnition 1 (nmt adversarial example).
annmt adversarial example is a sentence ina = {x(cid:48) ∈ x |∃x ∈ t , (cid:107)x(cid:48) − x(cid:107) < (cid:15) ∧.
st(y, yref ) ≥ γ ∧ st(y(cid:48), yref ) < γ(cid:48)},.
where y = f (x), y(cid:48) = f (x(cid:48)), and st(·, ·) is a met-ric for evaluating the similarity of two sentences,and γ (or γ(cid:48), γ(cid:48) < γ) is threshold we can accept(or refuse) for the translation quality ..a smaller γ(cid:48) indicates a more strict deﬁnition of.
the nmt adversarial example..in contrast to the adversarial examples in imagedomain (szegedy et al., 2014), we argue that takingyref as the reference sentence for x(cid:48) is not appro-priate because the perturbation might change thesemantic of x to some extent, causing that deﬁni-tion 1 is not appropriate.
to address this problem,we propose to evaluate the similarity between thebenign sentence x and the reconstructed sentenceˆx, as well as the similarity between the adversarialsentence x(cid:48) and the reconstructed adversarial sen-tence ˆx(cid:48).
we introduce a new deﬁnition of nmtadversarial example basing on the round-trip trans-lation..deﬁnition 2 (nmt adversarial example).
annmt adversarial example is a sentence ina = {x(cid:48) ∈ x |∃x ∈ t , (cid:107)x(cid:48) − x(cid:107) < (cid:15) ∧st(y, yref ) ≥ γ ∧ st(x, ˆx) ≥ δ ∧ e(x, x(cid:48)) ≥ α},where e(x, x(cid:48)) = st(x, ˆx) − st(x(cid:48), ˆx(cid:48)) is deﬁnedas the adversarial effect for nmt.
and, the recon-structed ˆx and ˆx(cid:48) are generated with round-triptranslation: ˆx = g(f (x)), ˆx(cid:48) = g(f (x(cid:48)))..a larger e indicates that the generated sentencex(cid:48) can not be well reconstructed by round-trip trans-lation when compared with the reconstruction qual-ity of the source sentence x. here α is a threshold.
ranging in [0, 1] to determine whether x(cid:48) is an nmtadversarial example.
a larger α indicates a morestrict deﬁnition of the nmt adversarial example.
in this work, we use the bleu score (papineniet al., 2002) to evaluate the similarity between twosentences..based on deﬁnition 2, we further provide twometrics, i.e., mean decrease (md) and mean per-centage decrease (mpd) to estimate the translationadversaries appropriately.
md directly presents theaverage degradation of the reconstruction quality,and mpd reduces the bias of the original qualityin terms of the relative degradation.
the proposedmd is deﬁned as:.
m d =.
1n.n(cid:88).
i.di,.
(1).
(2).
(3).
where n is the number of victim sentences, di isthe decreasing reconstruction quality of the adver-sarial example x(cid:48).
i, denoted as:.
(cid:26) 0.di =.
st(xi, ˆxi) − st(x(cid:48).
if st(xi, ˆxi) = 0,i, ˆx(cid:48)i) otherwise..similarly, mpd is deﬁned as:.
m p d =.
p di,.
1n.n(cid:88).
i.where p di is denoted as:(cid:40) 0.p di =.
st(xi, ˆxi)−st(x(cid:48).
st(xi,ˆxi).
if st(xi, ˆxi) = 0,i,ˆx(cid:48)i)otherwise..(4).
in practice, except for the constraints in deﬁni-tion 2, adversarial examples should also satisfy thelexical and syntactical constraints so that they arehard for human to perceive.
therefore, the correctword in the source sentence must be replaced withother correct words instead of misspelled word tomeet the lexical constraint.
besides, to keep thegrammatical correctness and syntax consistency,the modiﬁcation should not change the syntacticrelation of each word in the source sentence..to meet all the above constraints, we propose anovel nmt adversarial attack method by substitut-ing words with their neighbors selected from theparser ﬁlter to generate reasonable and effectiveadversarial examples..2.2 wsls attack.
there are two phases in the proposed wordsaliency speedup local search (wsls) attack.
1969greedy substitution.
for each position i, wecan substitute word wi with wji ∈ wi to obtain anadversary x(cid:48) = {w1, .
.
.
, wji , .
.
.
, wn}, and evalu-ate the adversarial effect e(x, x(cid:48)) by reconstruc-tion.
then we select a word w∗i that yields the mostsigniﬁcant degradation:.
w∗.
i = arg maxwji ∈wi.
e(x, x(cid:48))..(5).
it is straightforward to generate an initial adver-sary through a random order greedy replacement(rogr) method, which is to randomly select po-sitions expected to make substitutions, then itera-tively replace the word with its neighbors by eq.
5on the selected positions in a random order..however, the initial result has a signiﬁcant im-pact on the ﬁnal result of the local search.
if thelocal search phase starts with a near-optimal solu-tion, it is likely to ﬁnd a more powerful adversaryafter the local search process.
therefore, we designa greedy algorithm called greedy order greedy re-placement (gogr) for the initialization, which isdepicted in part b of figure 1..in the gogr algorithm, at each step we enu-merate all possible positions we haven’t attackedyet, and for each position we try to substitute wordi ∈ wi according to eq.
5,wi ∈ x with word w∗then we choose the best w∗ among the possiblepositions, and iteratively substitute words until wesubstitute enough words..w∗ = arg max.
e(x, x(cid:48)).
(6).
i∈n.
maxwji ∈wi.
2.2.2 word saliency.
to speed up the local search process, we adopt theword saliency, used for text classiﬁcation attack,to sort the word positions in which the word hasnot been replaced yet.
in this way, we can skip thepositions that may lead to low attack effect so as tospeedup the search process..for text classiﬁcation task, li et al.
(2016) pro-pose the concept of word saliency that refers to thedegree of change in the output of text classiﬁcationmodel when a word is set to the “unknown” token.
ren et al.
(2019) incorporate the word saliency togenerate adversarial examples for text classiﬁca-tion.
to adopt the concept of word saliency fornmt, we regard the output of a mlm for the wordas a more general concept of word saliency, whichis independent of the speciﬁc tasks..figure 1:illustration of the proposed wsls attackmethod.
for a source sentence x, we ﬁrst generatethe valid victim locations, substitution candidates, andsaliency scores to prepare the attack, then craft an ini-tial adversarial example x(cid:48) by the greedy order greedyreplacement (gogr) followed by the word saliencyspeedup local search (wsls) to promote the adversar-ial quality..method.
at the ﬁrst phase, we design initial strate-gies to obtain an initial example x(cid:48).
at the secondphase, we present a local search algorithm accel-erated by word saliency to optimize the perturbedexample..2.2.1.initialization strategy.
candidates.
for a word wi in the source sen-tence x = {w1, .
.
.
, wi, .
.
.
, wn}, where i denotesthe position of word wi in the sentence, we ﬁrstbuild a candidate set wi ∈ d where d is the dic-tionary consisting of all the legal words.
in thiswork, we build the candidate set by ﬁnding the kclosest neighbors in the word embedding space:wi = {w1i }.
then we ﬁlter the candi-dates based on the parsing, as shown in part a offigure 13. note that the combination of them canimpose minor shifting on the source so as to meetthe lexical and semantic constraints, as discussedin section 2.1. in our experiments, we use the pre-trained mask language model (mlm) to extract theembedding space to follow the black-box setting..i , .
.
.
, wk.
3this is important to rule out invalid victim locationswherein the token (e.g., punctuation) is nonsense, and ensurethe perturbations keep grammatical correctness..1970(a) saliency walk.
(b) random walk.
(c) certain walk.
figure 2: illustration of the walks used in the local search..deﬁnition 3 (word saliency).
for a sentencex = {w1, .
.
.
, wi, .
.
.
, wn} and a mask languagemodel (mlm) m , the word saliency of wi is de-ﬁned as s(x, wi) = 1 − p (wi|¯xi, m ) where ¯xi ={w1, .
.
.
, wi−1, mask, wi+1 .
.
.
, wn} and “mask”means the word is masked in the sentence..through deﬁnition 3, the higher word saliencyrepresents the lower context-dependent probabil-ity, which can be caused by numerous reasonablesubstitutions or rare syntax structure, indicatingweaker word positions that are easier to be attacked.
in this work, as shown in part c of figure 1,we calculate the word saliency s(x, wi) for all po-sitions before the local search phase, making thelocal search efﬁciently inquire the word saliency..2.2.3 local search strategy.
in the local search phase, as shown in part d offigure 1 and detailed in figure 2, there are threetypes of walks, namely saliency walk, random walkand certain walk, used to update x(cid:48) to promote theattack quality..to explore and exploit the search space, we de-ﬁne some basic operations and walks to evolve theadversaries.
a mute operator is to restore an ex-ecuted perturbation w∗i to its original word wi tomutate the adversary.
a prune operator is to ex-clude a portion of candidate locations where theperturbations will not be imposed to narrow downthe search area.
a tabu operator indicates thatthe last perturbed location is forbidden to be ma-nipulated in the current iteration.
as illustrated infigure 2, the three operators are utilized in the localsearch walks (part d).
we interpret the three walksas follows..saliency walk.
we ﬁrst design an efﬁcient walkfor the search, called the saliency walk (sw), to.
make a balanced exploration and exploitation inthe neighbourhood of the well initialized solutiongenerated by the aforementioned gogr algorithm.
during the saliency walk, as shown in figure 2a,at the current iteration (t), we mute each perturbedword to generate a set of partial solutions, sortedin the ascending order of the saliency score, soas to give higher priority to the perturbations withhigher word saliency on the locations.
then weprune other unperturbed words according to thedescending order of the saliency score, and querycandidate substitutions for each of the remainingwords.
then candidate adversaries, consisting ofthe concatenation of each partial solution with eachcandidate substitution, are evaluated by eq.
2 itera-tively..to accelerate the saliency walk, we have an earlystop strategy: if the current best adversarial effectin the enumeration of the candidate adversaries atthe present iteration (t), denoted as pbest(t) = e∗,is better than pbest(t−1) (the best adversarial effectat the previous iteration (t − 1)), i.e.
pbest(t) ≥pbest(t−1), then we terminate the enumeration ofthe candidates and pass the state of pbest(t) as wellas the tabu operator to the next walk, otherwise thestate of pbest(t−1) will be passed to the next walkand the tabu location is expired..random walk.
to avoid the current adversarialexample get trapped in a local optimum, we de-sign an effective mutation walk, called the randomwalk (rw), to mutate the current solution.
duringthe random walk, as shown in figure 2b, we ran-domly mute a perturbed word to generate a partialsolution, and query the candidate substitutions foreach of the unperturbed words as in saliency walk.
then we concatenate the partial solution with eachcandidate substitution to build the candidate adver-.
1971saries, among which the best solution is used toupdate pbest(t).
after that, the tabu operator willbe forcibly passed to the next walk, reinforcing theexploration ability of the wsls algorithm..certain walk.
to do a sufﬁcient exploitationafter the random walk as a mutation, we design thecertain walk (cw).
as shown in figure 2c, certainwalk is similar to saliency walk but it removes theprune operation to enlarge the neighborhood space.
to trade off the efﬁciency and search time, weadopt one saliency walk followed by random walk,certain walk, random walk and certain walk, toconstruct one round of local search, denoted as{sw, rw, cw, rw, cw}, as shown in part d offigure 1. besides, we bring an early-stop-ﬁnetunemechanism to the wsls method.
for any walkin wsls, if there exists an adversarial candidatethat updates the historically best adversarial effect,this adversarial candidate will be immediately setas the initial solution to start a new local search.
otherwise, the wsls will stop after the ending ofthe current round 4..3 experiments.
3.1 experimental setup.
we conduct experiments on the chinese-english(zh-en), english-german (en-de), and english-russian (en-ru) translation tasks..for the zh→en translation task, we use ldccorpus5 consisting of 1.25m sentence pairs, anduse nist (mt) datasets6 to craft the attacks.
fol-lowing the preprocessing in zhang et al.
(2019),we limit the source and target vocabulary to themost frequent 30k words, remove sentences longerthan 50 words from the training data, and use nist2002 as the validation set for the model selection.
for this translation task, we implement our attackson two state-of-art word-level nmt models.
1)rnnsearch (bahdanau et al., 2015) has an encoderconsists of forward and backward rnns each hav-ing 1000 hidden units and a decoder with 1000hidden units.
denote this model as “rnns.” for ab-breviation.
2) transformer comprises six layersof transformer with 512 hidden units and 8 headsin both encoder and decoder, which mimics thehyperparameters in (vaswani et al., 2017).
denotethis model as “transf.” for abbreviation.
for the or-.
4code is available at https://github.com/jhl-hust/.
advnmt-wsls/..5ldc 2002e18, 2003e14, 2004t08, 2005t06.
6nist 2002, 2003, 2004, 2005, 2006, 2008..acle back-translation (en→zh), we use a sub-wordlevel transformer as our oracle model which wastrained with ldc datasets and then ﬁnetuned withthe nist datasets..for the en→de and en→ru translation tasks,we use wmt19 test sets to craft the adversaries,and implement our attacks on the winner modelsof the wmt19 en→de and en→ru sub-tracks7.
speciﬁcally, the en→de model and en→ru modelare both subword-level transformer, where a jointbyte pair encodings (bpe) with 32k split oper-ations is applied for en→de, and separate bpeencodings with 24k split operations is appliedfor each language in en→ru (ng et al., 2019).
we denote these two models as “bpe-transf.”for abbreviation.
for the oracle back-translation(de→en, ru→en), the best submitted nmt mod-els in wmt19 are used as our oracle models whichare further ﬁnetuned with 90% of the previouswmt test sets and validated with the remainingsets..as for the reference result, table 3 and table 4show the case-insensitive bleu scores for forward-translation, back-translation, and round-trip transla-tion on the selected language pairs.
we observe thatthe word-level victim models (rnns.
and transf.)
achieve an average bleu score of 36.71 and 41.55for zh→en translation respectively, demonstrat-ing the accuracy of these two models on translat-ing the original chinese sentences.
for the back-translation, the oracle models achieve an averagebleu score of 82.9 for en→zh translation, as wellas a bleu score of 54.83 and 57.24 for de→enand ru→en translations respectively, indicatingthat the oracle models are reliable enough in theback-translation stage for the source reconstruction.
besides, the reconstruction quality of the victimmodels are reported in table 3 and table 4, wherethe source sentences are back-translated by the or-acle models in the round-trip translation, show-ing that the source language is reconstructed wellenough by the cooperation of forward-translationand oracle back-translation..furthermore, to enhance the authenticity of theattack performance, we removed the noisy data,which could not be correctly identiﬁed as the corre-sponding language sentences by online translators,and we also excluded sentences longer than 50words in the nist datasets, ensuring that the attack.
7https://github.com/pytorch/fairseq/tree/master/examples/.
translation..1972translation model mt02 mt03 mt04 mt05 mt06 mt08 avg.
forward.
rnns.
transf..40.0743.70.
37.4242.31.
40.3044.25.
37.4842.73.
36.5242.22.
28.4834.06.
36.7141.55.back.
oracle.
88.63.
84.55.
79.14.
80.69.
85.26.
79.34.
82.94.round-trip.
rnns.
transf..55.4670.90.
44.4359.62.
55.2768.44.
44.9760.92.
46.9961.78.
36.9151.06.
47.3462.12.table 3: case-insensitive bleu scores (%) for forward-translation (zh→en), back-translation (en→zh), andround-trip translation (zh→en→zh) on zh-en language pair.
“avg” represents the average score of all datasets..language pair.
translation.
forward back round-trip.
en-deen-ru.
46.2947.23.
56.1958.16.
61.8757.60.table 4: case-insensitive bleu scores (%) of bpe-transf.
for forward-translation, back-translation, andround-trip translation on en-de and en-ru languagepairs..results are credible8..as for the parameter settings of the attack meth-ods, we use pyltp9 as the parser checking tool andgenerate the top 10 nearest parser-ﬁltered words toconstruct the candidate sets for each word.
to gen-erate the word saliency, two state-of-art whole wordmasking bert are utilized as the mlm for the chi-nese10 and english11 languages respectively.
andthe prune operators implemented in sw and rwwill reserve the highest ﬁve word saliency locationsand their word candidates.
finally, the adversariesare crafted by substituting 20% words..3.2 attack results.
to demonstrate our proposed wsls method, weimplement ast-lexcial (cheng et al., 2018) as ablack-box baseline, wherein ast-lexcial sharesthe same idea of random order random replace-ment.
besides, the naive rogr method can beconsidered as another black-box counterpart of thewhite-box knn method in michel et al.
(2019) thatrandomly selects the word positions and greedilyselects the neighbor words based on the gradientloss..8after the preprocessing, the size of the original nistdatasets are reduced from 878 to 617 (mt02), 919 to 793(mt03), 1788 to 1495 (mt04), 1082 to 907 (mt05), 1664 to988 (mt06), and 1357 to 789 (mt08).
9https://github.com/hit-scir/pyltp.
10https://huggingface.co/hﬂ/chinese-bert-wwm-ext.
11https://huggingface.co/bert-large-uncased-whole-word-.
masking..as shown in table 5 and table 6, both gogrand wsls have the md scores close to the orig-inal reconstruction scores for rnns., transf., andbpe-transf., and their attack results are much bet-ter than that of ast-lexical as well as rogr.
itshows that both wsls and gogr can effectivelyattack various nmt models under the standard ofdeﬁnition 2. wsls is superior to gogr, indicat-ing that the local search phase can further promotethe attack quality.
speciﬁcally, the mpd score ofwsls is almost 1.5 higher than that of gogr,which is more obvious as compared to the mdmetric, revealing the rationality of mpd also..3.3 ablation study.
we do ablation study on the wsls algorithm intable 7. here “init” is for the method used forinitialization, ws indicates whether we use wordsaliency to speedup the local search, ls indicateswhether we use local search or other variants ofwalk sequence for the local search..from table 7 we observe that: 1) the initializa-tion of gogr exhibits signiﬁcantly better resultsthan rogr, and also converges faster than rogr;2) wsls without word saliency speedup, denotedas wsls1, exhibits slightly higher attack resultsbut the running times are much longer than wsls.
thus, we choose wsls to have a good tradeoff onattack quality and time..3.4 transferability.
to test the transferability of our method, we trans-fer our crafted adversarial examples on nist 2002dataset to attack the online baidu and bing transla-tors.
as shown in table 8, the attack effectivenessis signiﬁcant.
it degrades the reconstruction qualityof baidu and bing with more than 20 bleu points,demonstrating the high transferability..in addition, we provide two adversarial exam-ples in table 9, generated by wsls on the rnns.
model, that can effectively attack the online bing.
1973md.
rnns..transf..metrics model method mt02 mt03 mt04 mt05 mt06 mt08 avg25.7823.6133.1230.6443.1339.7843.4540.1534.2832.7842.9641.8856.9754.9657.5155.4743.1744.4169.3670.7192.6393.0893.8694.2348.6345.0370.7570.4294.3894.4595.6095.69.ast-lexicalrogrgogrwslsast-lexicalrogrgogrwslsast-lexicalrogrgogrwslsast-lexicalrogrgogrwsls.
26.4233.3442.8242.8435.7243.6456.5257.0242.5969.0091.9293.1151.4072.1793.9495.08.
20.4326.1332.7433.0328.8836.1445.2545.6942.269.2690.1291.8043.3273.0192.7294.32.
23.8332.0041.6141.9632.9242.2756.9157.3939.6667.2792.6293.6848.9169.5095.0996.27.
29.1638.0450.7251.1936.7245.7562.8563.5142.2169.5094.0895.1750.8869.0194.8195.97.
29.0638.5451.0951.5138.6548.0965.3466.0351.2470.4293.9695.1852.2570.3695.2596.24.transf..rnns..mpd.
table 5: md and mpd results (%) on rnns.
and transf.
attacked by various methods on the preprocessed nistdatasets.
a higher result indicates a better attack method..metrics.
task.
method.
ast-lexical rogr gogr wsls.
md.
mpd.
en-deen-ru.
en-deen-ru.
26.4728.02.
42.7742.96.
38.7836.59.
64.1966.56.
52.8549.21.
90.7491.15.
54.5749.92.
92.2292.48.transfer victim.
baidu(41.81)bing(38.15).
rnns.
transf.
rnns.
transf..methodsrogr gogr wsls18.6118.3019.9617.3016.8919.6415.5115.2917.5914.6814.8217.13.table 6: md and mpd results (%) on bpe-transf.
at-tacked by various methods on wmt19 test sets..methodrogrgogrwsls1wsls2wsls.
init ws(cid:55)rogr(cid:55)gogr(cid:55)gogr(cid:55)rogrgogr (cid:51).
ls(cid:55)(cid:55).
time md mpd70.3648.090.3495.2565.342.87r+c 25.4796.6067.10r+c 33.2794.8165.6296.2466.038.23std..table 7: the ablation study on transf.
with ablativealgorithms (r, c, std.
indicate random walk, certainwalk and standard wsls algorithm) on mt02 dataset.
the running time is in minutes per sentence..and baidu translators, respectively.
it demonstratesthat wsls could craft adversarial examples withstrong readability and high transferability..4 related work.
in recent years, adversarial examples have attractedincreasing attention in the area of natural languageprocessing (nlp), mainly on text classiﬁcation (jiaand liang, 2017; ren et al., 2019; wang et al.,2021).
for neural machine translation (nmt),there are also some adversary works emergingquickly (belinkov and bisk, 2018; ebrahimi et al.,2018; michel et al., 2019; cheng et al., 2019; niuet al., 2020; wallace et al., 2020)..table 8: reconstruction quality on baidu and bingonline translators for the adversaries generated on thezh→en task using mt02 dataset, wherein the ad-versaries are reconstructed by the online translators(zh→en) and oracle (en→zh).
by contrast, the benignreconstruction quality is in the bracket..on the character level, a few adversarial attacksby manipulating character perturbations have beenproposed since 2018. belinkov and bisk (2018)confront nmt models with synthetic and naturalmisspelling noises, and show that character-basednmt models are easy to be attacked by characterlevel perturbation.
ebrahimi et al.
(2018) proposeto attack the character level nmt models by ma-nipulating the character-level insertion, swap anddeletion.
similarly, michel et al.
(2019) performa gradient-based attack that processes words insource sentences to maximize the translation loss.
to attack against production mt systems, wallaceet al.
(2020) imitate the popular online translatorsand manipulate the perturbations based on the gra-dient of the adversarial loss with the imitation mod-els.
the above four works also incorporate adver-sarial training to improve the robustness of nmt.
however, the character level perturbations arehard to be applied into confronting practical nmtmodels, as these perturbations signiﬁcantly reduce.
1974table 9: two examples of attacking online translators,in which the adversaries are generated on the rnns.
model using wsls..acknowledgements.
x(cid:48): 代表大会主席在发言中称, 高层促进了亚洲和欧美国家的发展。ref.
(cid:48): the chairperson of the convention expressedin a speech that the high-level leadership has pro-moted the development of the nations in asia, europe,and america.
baidu: in his speech, the president of the nationalpeople’s congress said that high-level leaders havepromoted the growth of asian and european coun-tries.
x(cid:48):彼得森重申, 世卫组织主要关切的难题是防止诸如疾病、痢疾等疫情暴发, 这些患者可能造成成千上万的人罹难 。ref.
(cid:48): peterson reiterated that the who’s main con-cern is the challenge of preventing outbreaks such asdisease and dysentery, these patients may cause thou-sands of deaths.
bing: peterson reiterated that the who’s mainconcern is to prevent outbreaks such as disease anddysentery , which can cause thousands of deaths..the readability and also could be easily correctedby spell checkers (ren et al., 2019; zou et al.,2020).
on the other hand, word level adversariescould maintain lexical and grammatical correct-ness, which are more realistic but more challengingto generate.
cheng et al.
(2018) craft the adver-saries with randomly sampled perturbed positions,and then replace the words according to the cosinesimilarity of the embedding vectors between theoriginal word and the neighbors.
cheng et al.
(2019) propose a gradient-based attack methodthat replaces the original word with the candidatesgenerated by integrated language model.
michelet al.
(2019) generate adversaries by substitutingthe word with its nearest neighbors, which are in-formed by the gradient of the victim models.
(zouet al., 2020) introduce a reinforced learning basedmethod to craft the attacks following michel et al.
(2019) to deﬁne the reward and substitution candi-date set..existing word level.
translation attacks aremainly white-box, wherein the attacker can accessall the information of the victim model.
besides,there is a risk of guiding the attacks to directly usethe degradation of reference translation, since theactual references may be changed by word substi-tution.
thus, there exists few study on the effectiveword level attack for nmt, especially in the blackbox setting.
this study ﬁlls this gap and sheds light.
on black-box word level nmt attacks..5 conclusion.
we introduce an appropriate deﬁnition of adversar-ial examples as well as the deriving evaluation mea-sures for the adversarial attacks on neural machinetranslation (nmt) models.
following our deﬁni-tion and metrics, we propose a promising black-box nmt attack method called the word saliencyspeedup local search (wsls), in which a generaldeﬁnition of word saliency by leveraging the strongrepresentation capability of pre-trained languagemodels is also introduced.
experiments demon-strate that the proposed method could achieve pow-erful attack performance, that effectively breaksthe mainstream rnn and transformer based nmtmodels.
further, our method could craft adver-saries with strong readability as well as high trans-ferability to the popular online translators..this work is supported by national natural sciencefoundation (62076105) and microsft researchasia collaborative research fund (99245180).
wethank xiaosen wang for helpful suggestions on ourwork..references.
dzmitry bahdanau, kyunghyun cho, and yoshua ben-gio.
2015. neural machine translation by jointlyin proceedings oflearning to align and translate.
the international conference on learning represen-tations..yonatan belinkov and yonatan bisk.
2018. syntheticand natural noise both break neural machine transla-tion.
in proceedings of the international conferenceon learning representations..yong cheng, lu jiang, and wolfgang macherey.
2019.robust neural machine translation with doubly ad-versarial inputs.
in proceedings of the 57th annualmeeting of the association for computational lin-guistics..yong cheng, lu jiang, wolfgang macherey, and jacobeisenstein.
2020. advaug: robust data augmenta-tion for neural machine translation.
in proceedingsof the 58th annual meeting of the association forcomputational linguistics..yong cheng, zhaopeng tu, fandong meng, junjiezhai, and yang liu.
2018. towards robust neuralmachine translation.
in proceedings of the 56th an-nual meeting of the association for computationallinguistics..1975marta r costa-juss`a and jos´e ar fonollosa.
2016.character-based neural machine translation.
in pro-ceedings of the 54th annual meeting of the associa-tion for computational linguistics..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training of deepbidirectional transformers for language understand-ing.
in proceedings of the north american chapterof the association for computational linguistics..javid ebrahimi, daniel lowd, and dejing dou.
2018.on adversarial examples for character-level neuralmachine translation.
in proceedings of the interna-tional conference on computational linguistics..di he, yingce xia, tao qin, liwei wang, nenghai yu,tie-yan liu, and wei-ying ma.
2016. dual learningfor machine translation.
in proceedings of the ad-vances in neural information processing systems..robin jia and percy liang.
2017. adversarial exam-ples for evaluating reading comprehension systems.
in proceedings of the empirical methods in naturallanguage processing..guillaume lample and alexis conneau.
2019. cross-lingual language model pretraining.
in proceedingsof the advances in neural information processingsystems..jiwei li, xinlei chen, eduard hovy, and dan jurafsky.
2016. visualizing and understanding neural modelsin nlp.
in proceedings of the north american chap-ter of the association for computational linguistics..paul michel, xian li, graham neubig, and juan pino.
2019. on evaluation of adversarial perturbationsin proceedingsfor sequence-to-sequence models.
of the north american chapter of the associationfor computational linguistics..nathan ng, kyra yee, alexei baevski, myle ott,face-michael auli, and sergey edunov.
2019.book fair’s wmt19 news translation task submission.
in proceedings of the 4th conference on machinetranslation..xing niu, prashant mathur, georgiana dinu, and yaseral-onaizan.
2020. evaluating robustness to inputperturbations for neural machine translation.
in pro-ceedings of the 58th annual meeting of the associa-tion for computational linguistics..kishore papineni, salim roukos, todd ward, and wei-jing zhu.
2002. bleu: a method for automatic eval-uation of machine translation.
in proceedings of the40th annual meeting of the association for compu-tational linguistics..shuhuai ren, yihe deng, kun he, and wanxiang che.
2019. generating natural language adversarial ex-amples through probability weighted word saliency.
in proceedings of the 57th annual meeting of theassociation for computational linguistics..christian szegedy, wojciech zaremba, ilya sutskever,joan bruna, dumitru erhan, ian j. goodfellow, androb fergus.
2014.intriguing properties of neuralnetworks.
proceedings of the international confer-ence on learning representations..ashish vaswani, noam shazeer, niki parmar, jakobuszkoreit, llion jones, aidan n gomez, łukaszkaiser, and illia polosukhin.
2017. attention is allyou need.
in proceedings of the advances in neuralinformation processing systems..eric wallace, mitchell stern, and dawn song.
2020.imitation attacks and defenses for black-box ma-chine translation systems.
in proceedings of empir-ical methods in natural language processing..xiaosen wang, yichen yang, yihe deng, and kun he.
2021. adversarial training with fast gradient projec-tion method against synonym substitution based textattacks.
in proceedings of the aaai conference onartiﬁcial intelligence..wen zhang, yang feng, fandong meng, di you, andqun liu.
2019. bridging the gap between trainingand inference for neural machine translation.
in pro-ceedings of the 57th annual meeting of the associa-tion for computational linguistics..wei zou, shujian huang, jun xie, xinyu dai, and jia-jun chen.
2020. a reinforced generation of adver-sarial samples for neural machine translation.
inproceedings of the 58th annual meeting of the as-sociation for computational linguistics..appendix.
in the appendix, we provide necessary backgroundof neural machine translation (nmt), pre-trainedlanguage models, and the back-translation tech-nique used in related works.
besides, screenshotsof table 8 are also provided..neural machine translation.
typical nmtmodels follow an encoder-decoder architecturewith attention mechanisms (zhang et al., 2019).
the encoder encodes the source language to a la-tent representation space, and the decoder is a neu-ral language model that decodes representations inthe latent space to another language domain.
eitherthe encoder or the decoder can be built on recurrentneural networks (bahdanau et al., 2015), convolu-tional neural networks (costa-juss`a and fonollosa,2016), or transformer networks (vaswani et al.,2017).
in this work, we applied two versions of neu-ral network architecture for the encoder/decodermodels: rnn and transformer..pre-trained language model.
recently, pre-trained language models, such as mask language.
1976figure 3: an example of attacking the baidu translator, in which the adversarial example is generated on the rnns.
model using wsls..figure 4: an example of attacking bing translator, in which the adversarial example is generated on the rnns.
model using wsls..that the back-translation technique makes it possi-ble to evaluate nmt adversarial attacks withoutground-truth references for the perturbed sentences,and we propose to evaluate the proposed nmt at-tack method basing on the reconstruction results ofthe original inputs and the perturbed examples..models (mlm) (devlin et al., 2019), have achieveda powerful initialization for the nmt encodermodels.
mlm pre-trains the encoder for a betterlanguage understanding on the encoded languageby randomly masking some tokens in continuousmonolingual text streams and predicting these to-kens.
to predict the masked tokens, the languagemodel pays attention to the relative language parts,which encourages the model to have a better under-standing on the language.
inspired by the powerfullanguage understanding ability of the pre-trainedlanguage models, and following the black-box set-ting, we use the pre-trained mlm to estimate theword saliency and build the word embedding spacefor adversarial attacks..back-translation.
there are a lot of works forimproving the nmt performance by leveragingthe back translation, which uses not only parallelcorpus but also monolingual corpus for training thenmt models (he et al., 2016; lample and con-neau, 2019).
previous works on back-translationdemonstrate the ability of the dual nmt models toreconstruct the language.
in this work, we observe.
1977