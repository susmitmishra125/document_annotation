one time of interaction may not be enough: go deep with aninteraction-over-interaction network for response selection in dialogues.
chongyang tao1, wei wu2, can xu2, wenpeng hu1, dongyan zhao1,3 and rui yan1,3∗1institute of computer science and technology, peking university, beijing, china2microsoft corporation, beijing, china3center for data science, peking university, beijing, china1,3{chongyangtao,wenpeng.hu,zhaody,ruiyan}@pku.edu.cn2{wuwei,caxu}@microsoft.com.
abstract.
currently,researchers have paid great at-tention to retrieval-based dialogues in open-domain.
in particular, people study the prob-lem by investigating context-response match-ing for multi-turn response selection basedon publicly recognized benchmark data sets.
state-of-the-art methods require a responseto interact with each utterance in a contextfrom the beginning, but the interaction is per-formed in a shallow way.
in this work,we let utterance-response interaction go deepby proposing an interaction-over-interactionnetwork (ioi).
the model performs match-ing by stacking multiple interaction blocksin which residual information from one timeof interaction initiates the interaction processagain.
thus, matching information within anutterance-response pair is extracted from theinteraction of the pair in an iterative fashion,and the information ﬂows along the chain ofthe blocks via representations.
evaluation re-sults on three benchmark data sets indicate thatioi can signiﬁcantly outperform state-of-the-art methods in terms of various matching met-rics.
through further analysis, we also unveilhow the depth of interaction affects the perfor-mance of ioi..1.introduction.
building a chitchat style dialogue systems in open-domain for human-machine conversations has at-tracted increasing attention in the conversationalartiﬁcial intelligence (ai) community.
generallyspeaking, there are two approaches to implement-ing such a conversational system.
the ﬁrst ap-proach leverages techniques of information re-trieval (lowe et al., 2015; wu et al., 2017; yanand zhao, 2018), and selects a proper responsefrom an index; while the second approach di-rectly synthesizes a response with a natural lan-.
∗corresponding author: rui yan (ruiyan@pku.edu.cn)..guage generation model estimated from a large-scale conversation corpus (serban et al., 2016; liet al., 2017b).
in this work, we study the prob-lem of multi-turn response selection for retrieval-based dialogue systems where the input is a con-versation context consisting of a sequence of utter-ances.
compared with generation-based methods,retrieval-based methods are superior in terms ofresponse ﬂuency and diversity, and thus have beenwidely applied in commercial chatbots such as thesocial bot xiaoice (shum et al., 2018) from mi-crosoft, and the e-commerce assistant alime as-sist from alibaba group (li et al., 2017a)..a key step in multi-turn response selection isto measure the matching degree between a con-versation context and a response candidate.
state-of-the-art methods (wu et al., 2017; zhou et al.,2018b) perform matching within a representation-interaction-aggregation framework (wu et al.,2018b) where matching signals in each utterance-response pair are distilled from their interactionbased on their representations, and then are ag-gregated as a matching score.
although utterance-response interaction has proven to be crucial to theperformance of the matching models (wu et al.,2017), it is executed in a rather shallow mannerwhere matching between an utterance and a re-sponse candidate is determined only by one stepof interaction on each type or each layer of rep-in this paper, we attempt to moveresentations.
from shallow interaction to deep interaction, andconsider context-response matching with multi-ple steps of interaction where residual informationfrom one time of interaction, which is generallyignored by existing methods, is leveraged for ad-ditional interactions.
the underlying motivation isthat if a model extracts some matching informa-tion from utterance-response pairs in one step ofinteraction, then by stacking multiple such steps,the model can gradually accumulate useful signals.
proceedingsofthe57thannualmeetingoftheassociationforcomputationallinguistics,pages1–11florence,italy,july28-august2,2019.c(cid:13)2019associationforcomputationallinguistics1for matching and ﬁnally capture the semantic rela-tionship between a context and a response candi-date in a more comprehensive way..we propose an interaction-over-interaction net-work (ioi) for context-response matching, throughwhich we aim to investigate: (1) how to make in-teraction go deep in a matching model; and (2) ifthe depth of interaction really matters in terms ofmatching performance.
a key component in ioi isan interaction block.
taking a pair of utterance-response as input, the block ﬁrst lets the utteranceand the response attend to themselves, and thenmeasures interaction of the pair by an attention-based interaction function.
the results of the in-teraction are concatenated with the self-attentionrepresentations and then compressed to new rep-resentations of the utterance-response pair as theoutput of the block.
built on top of the interac-tion block, ioi initializes each utterance-responsepair via pre-trained word embeddings, and thenpasses the initial representations through a chainof interaction blocks which conduct several roundsof representation-interaction-representation oper-ations and let the utterance and the response inter-act with each other in an iterative way.
differentblocks could distill different levels of matching in-formation in an utterance-response pair.
to sufﬁ-ciently leverage the information, a matching scoreis ﬁrst calculated in each block through aggre-gating matching vectors of all utterance-responsepairs, and then the block-wise matching scores arecombined as the ﬁnal matching degree of the con-text and the response candidate..we conduct experiments on three benchmarkdata sets:the ubuntu dialogue corpus (loweet al., 2015), the douban conversation corpus(wu et al., 2017), and the e-commerce dialoguecorpus (zhang et al., 2018b).
evaluation resultsindicate that ioi can signiﬁcantly outperform state-of-the-art methods with 7 interaction blocks overall metrics on all the three benchmarks.
comparedwith deep attention matching network (dam),the best performing baseline on all the three datasets, ioi achieves 2.9% absolute improvement onr10@1 on the ubuntu data, 2.3% absolute im-provement on map on the douban data, and3.7% absolute improvement on r10@1 on the e-commerce data.
through more quantitative anal-ysis, we also show that depth indeed brings im-provement to the performance of ioi, as ioi with1 interaction block performs worse than dam on.
the douban data and the e-commerce data, and onthe ubuntu data, the gap on r10@1 between ioiand dam is only 1.1%.
moreover, the improve-ment brought by depth mainly comes from shortcontexts..our contributions in this paper are three-folds:(1) proposal of a novel interaction-over-interactionnetwork which enables deep-level matching withcarefully designed interaction block chains; (2)empirical veriﬁcation of the effectiveness of themodel on three benchmarks; and (3) empiri-cal study on the relationship between interactiondepth and model performance..2 related work.
existing methods for building an open-domain di-alogue system can be categorized into two groups.
the ﬁrst group learns response generation mod-els under an encoder-decoder framework.
on topof the basic sequence-to-sequence with attentionarchitecture (vinyals and le, 2015; shang et al.,2015; tao et al., 2018), various extensions havebeen made to tackle the “safe response” problem(li et al., 2015; mou et al., 2016; xing et al., 2017;zhao et al., 2017; song et al., 2018); to gener-ate responses with speciﬁc personas or emotions(li et al., 2016a; zhang et al., 2018a; zhou et al.,2018a); and to pursue better optimization strate-gies (li et al., 2017b, 2016b)..the second group learns a matching modelof a human input and a response candidate forresponse selection.
along this line,the focusof research starts from single-turn response se-lection by setting the human input as a singlemessage (wang et al., 2013; hu et al., 2014;wang et al., 2015), and moves to context-responsematching for multi-turn response selection re-cently.
representative methods include the duallstm model (lowe et al., 2015), the deep learn-ing to respond architecture (yan et al., 2016), themulti-view matching model (zhou et al., 2016),the sequential matching network (wu et al., 2017,2018b), and the deep attention matching net-work (zhou et al., 2018b).
besides model design,some attention is also paid to the learning prob-lem of matching models (wu et al., 2018a).
ourwork belongs to the second group.
the proposedinteraction-over-interaction network is unique inthat it performs matching by stacking multipleinteraction blocks, and thus extends the shallowinteraction in state-of-the-art methods to a deep.
2figure 1: architecture of interaction-over-interaction network..form.
as far as we know, this is the ﬁrst archi-tecture that realizes deep interaction for multi-turnresponse selection..encouraged by the big success of deep neuralarchitectures such as resnet (he et al., 2016) andinception (szegedy et al., 2015) in computer vi-sion, researchers have studied if they can achievesimilar results with deep neural networks on nlptasks.
although deep models have not yet broughtbreakthroughs to nlp as they do to computer vi-sion, they have proven effective in a few tasks suchas text classiﬁcation (conneau et al., 2017), natu-ral language inference (kim et al., 2018; tay et al.,2018), and question answering (tay et al., 2018;kim et al., 2018), etc.
in this work, we attemptto improve the accuracy of multi-turn response se-lection in retrieval-based dialogue systems by in-creasing the depth of context-response interactionin matching.
through extensive studies on bench-marks, we show that depth can bring signiﬁcantimprovement to model performance on the task..3 problem formalization.
there is a conversation data setsuppose thatd = {(yi, ci, ri)}ni=1.
∀i ∈ {1, .
.
.
, n }, ci ={ui,1, .
.
.
, ui,li} represents a conversation contextwith ui,k the k-th turn, ri is a response candidate,and yi ∈ {0, 1} denotes a label with yi = 1indicating ri a proper response for ci, otherwiseyi = 0. the task is to learn a matching modelg(·, ·) from d, and thus for a new context-responsepair (c, r), g(c, r) measures the matching degree.
between c and r..in the following sections, we will elaborate howto deﬁne g(·, ·) to achieve deep interaction be-tween c and r, and how to learn such a deep modelfrom d..4.interaction-over-interaction network.
we deﬁne g(·, ·) as an interaction-over-interactionnetwork (ioi).
figure 1 illustrates the architectureof ioi.
the model pairs each utterance in a con-text with a response candidate, and then aggre-gates matching information from all the pairs asa matching score of the context and the responsecandidate.
for each pair, ioi starts from initial rep-resentations of the utterance and the response, andthen feeds the pair to stacked interaction blocks.
each block represents the utterance and the re-sponse by letting them interact with each otherbased on the interactions before.
matching signalsare ﬁrst accumulated along the sequence of the ut-terances in each block, and then combined alongthe chain of blocks as the ﬁnal matching score.
be-low we will describe details of components of ioiand how to learn the model with d..4.1.initial representations.
given an utterance u in a context c and a re-sponse candidate r, u and r are initialized as eu =[eu,1, · · · , eu,m] and er = [er,1, · · · , er,n] respec-tively.
∀i ∈ {1, .
.
.
, m} and ∀j ∈ {1, .
.
.
, n},eu,i and er,j are representations of the i-th wordof u and the j-th word of r respectively which.
3gru...utterance-1responseutterance-ninitial representationgru...gru...gru...interaction block 1interaction block 2interaction block lgrugruresponsegrug(c,r):   self-attention :   interaction operation :   add operationt11v11tn1vn1t12v12tn2vn2tnlvnlt1lv1lare obtained by pre-training word2vec (mikolovet al., 2013) on d. eu and er are then processedby stacked interaction blocks that model differentlevels of interaction between u and r and generatematching signals..4.2.interaction block.
the stacked interaction blocks share the samein a nutshell, each block isinternal structure.
composed of a self-attention module that captureslong-term dependencies within an utterance anda response, an interaction module that modelsthe interaction between the utterance and the re-sponse, and a compression module that condensesthe results of the ﬁrst two modules into representa-tions of the utterance and the response as output ofthe block.
the output is then utilized as the inputof the next block..before diving to details of the block, we ﬁrstgenerally describe an attention mechanism thatlays a foundation for the self-attention module andthe interaction module.
let q ∈ rnq×d andk ∈ rnk×d be a query and a key respectively,where nq and nk denote numbers of words and dis the embedding size, then attention from q to kis deﬁned as.
ˆq = s(q, k) · k,.
(1).
where s(·, ·) is a function for attention weight cal-culation.
here, we exploit the symmetric functionin (huang et al., 2017b) as s(·, ·) which is givenby:.
s(q, k) = softmax(f (qw)df (kw)(cid:62)).
(2).
in equation (2), f is a relu activation function,d is a diagonal matrix, and both d ∈ rd×d andw ∈ rd×d are parameters to estimate from train-ing data.
intuitively, in equation (1), each entry ofk is weighted by an importance score deﬁned bythe similarity of an entry of q and an entry of k.the entries of k are then linearly combined withthe weights to form a new representation of q..a residual connection (he et al., 2016) and alayer normalization (ba et al., 2016) are then ap-plied to ˆq as ˜q.
after that, ˜q is fed to a feedforward network which is formulated as.
round of residual connection and layer normaliza-tion.
for ease of presentation, we denote the entireattention mechanism as fat t (q, k)..let uk−1 and rk−1 be the input of the k-thblock where u0 = eu and r0 = er, then theself-attention module is deﬁned as.
ˆuk = fatt(uk−1, uk−1),ˆrk = fatt(rk−1, rk−1)..the interaction module ﬁrst lets uk−1 and rk−1attend to each other by.
kukr.= fatt(uk−1, rk−1),= fatt(rk−1, uk−1)..then uk−1 and rk−1 further interact with urespectively, which can be formulated as.
kand r.k˜uk = uk−1 (cid:12) uk˜rk = rk−1 (cid:12) r.,.
,.
(4).
(5).
(6).
(7).
k.(8).
(9).
where (cid:12) denotes element-wise multiplication.
fi-nally, the compression module updates uk−1 andrk−1 to uk and rk as the output of the block.
suppose that ekr,i are the i-th entries ofu,i and ekuk and rk respectively, then ekr,i are cal-culated by.
u,i and ek.
eku,i = relu(wp.
+ bp) + ek−1u,i ,.
(10).
ekr,i = relu(wp.
+ bp) + ek−1r,i.
,.
(11).
{u,r},i, ˜ek.
{u,r},i, ek.
where wp ∈ r4d×d and bp are learnable projec-tion weights and biases, ˆek{u,r},i,{u,r},i are the i-th entries of { ˆu, ˆr}k,and ek−1{u, r}k, { ˜u, ˜r}k, and {u, r}k−1, respectively.
inspired by huang et al.
(2017a), we also intro-duce direct connections from initial representa-tions to all their corresponding subsequent blocks...
.
.
.
.
.
.
.
ek−1u,iˆeku,ieku,i˜eku,iek−1r,iˆekr,iekr,i˜ekr,i.
relu( ˜qw1 + b1)w2 + b2,.
(3).
4.3 matching aggregation.
where w{1,2} ∈ rd×d and b{1,2} are parame-ters.
the output of the attention mechanism is de-ﬁned with the result of equation (3) after another.
suppose that c = (u1, .
.
.
, ul) is a conversationcontext with ui the i-th utterance, then in the k-th interaction block, we construct three similarity.
4matrices by.
5 learning methods.
mk.
i,1 =.
uk−1i.
· (rk−1)(cid:62)√.
,.
ˆuk.
di · ( ˆrk)(cid:62)√dkki · (ru√d.)(cid:62).
,.
,.
mk.
i,2 =.
mk.
i,3 =.
we consider two strategies to learn an ioi modelfrom the training data d. the ﬁrst strategy es-timates the parameters of ioi (denoted as θ) byminimizing a global loss function that is formu-lated as.
(12).
kki and r.where uk−1and rk−1 are the input of the k-thii and ˆrk are deﬁned by equations (4-5),block, ˆukand uare calculated by equations (6-7).
the three matrices are then concatenated into a 3-i ∈ rmi×n×3 which can bed matching tensor tkwritten as.
tk.
i = mk.
i,1 ⊕ mk.
i,2 ⊕ mk.
i,3,.
(13).
where ⊕ denotes a concatenation operation, andmi and n refer to numbers of words in ui and rrespectively..a.we.
exploit.
convolutional neural.
net-work (krizhevsky et al., 2012) to extract matchingfeatures from tki .
the output of the ﬁnal featuremaps are ﬂattened and mapped to a d-dimensionalmatching vector vki with a linear transformation.
(vkl ) is then fed to a gru (chung et al.,2014) to capture temporal relationship among(u1, .
.
.
, ul).
∀i ∈ {1, .
.
.
, l}, the i-th hidden stateof the gru model is given by.
1, · · · , vk.
i = gru(vkhk.
i , hk.
i−1),.
(14).
where hk0 is randomly initialized.
a matchingscore for context c and response candidate r in thek-th block is deﬁned as.
gk(c, r) = σ(hk.
l · wo + bo),.
(15).
where wo and bo are parameters, and σ(·) is a sig-moid function.
finally, g(c, r) is deﬁned by.
g(c, r) =.
gk(c, r),.
(16).
l(cid:88).
k=1.
where l is the number of interaction blocks inioi.
note that we deﬁne g(c, r) with all blocksrather than only with the last block.
this is mo-tivated by (1) only using the last block will maketraining of ioi difﬁcult due to the gradient van-ishing/exploding problem; and (2) different blocksmay capture different levels of matching informa-tion in (c, r), and thus leveraging all of them couldenhance matching accuracy..−.
n(cid:88).
i=1.
(cid:2)yi log(g(ci, ri))+(1−yi) log(1−g(ci, ri))(cid:3)..(17)in the second strategy, we construct a local lossfunction for each block and minimize the summa-tion of the local loss functions.
by this means,each block can be directly supervised by the la-bels in d during learning.
the learning objectiveis then deﬁned as.
l(cid:88).
n(cid:88).
−.
k=1.
i=1.
(cid:2)yi log(gk(ci, ri)).
+ (1 − yi) log(1 − gk(ci, ri))(cid:3)..(18).
we compare the two learning strategies throughempirical studies, as will be reported in the nextsection.
in both strategies, θ are optimized usingback-propagation with adam algorithm (kingmaand ba, 2015)..6 experiments.
we test the proposed ioi on three benchmark datasets for multi-turn response selection..6.1 experimental setup.
the ﬁrst data we use is the ubuntu dialogue cor-pus (lowe et al., 2015) which is a multi-turn en-glish conversation data set constructed from chatlogs of the ubuntu forum.
we use the versionprovided by xu et al.
(2017).
the data contains1 million context-response pairs for training, and0.5 million pairs for validation and test.
in all thethree sets, positive responses are human responses,while negative ones are randomly sampled.
theratio of the positive and the negative is 1:1 in thetraining set, and 1:9 in both the validation set andthe test set.
following lowe et al.
(2015), we em-ploy recall at position k in n candidates (rn@k)as evaluation metrics..the second data set is the douban conversationcorpus (wu et al., 2017) that consists of multi-turn chinese conversations collected from doubangroup1.
there are 1 million context-response pairs.
1https://www.douban.com/group.
5for training, 50 thousand pairs for validation, and6, 670 pairs for testing.
in the training set and thevalidation set, the last turn of each conversationis taken as a positive response and a negative re-sponse is randomly sampled.
for each context inthe test set, 10 response candidates are retrievedfrom an index and their appropriateness regard-ing to the context is annotated by human labelers.
following wu et al.
(2017), we employ rn@ks,mean average precision (map), mean reciprocalrank (mrr) and precision at position 1 (p@1) asevaluation metrics..finally, we choose the e-commerce dialoguecorpus (zhang et al., 2018b) as an experimen-tal data set.
the data consists of multi-turn real-world conversations between customers and cus-tomer service staff in taobao2, which is the largeste-commerce platform in china.
it contains 1 mil-lion context-response pairs for training, and 10thousand pairs for validation and test.
positive re-sponses in this data are real human responses, andnegative candidates are automatically constructedby ranking the response corpus based on conver-sation history augmented messages using apachelucene3.
the ratio of the positive and the neg-ative is 1:1 in training and validation, and 1:9 intest.
following (zhang et al., 2018b), we employr10@1, r10@2, and r10@5 as evaluation metrics..6.2 baselines.
we compare ioi with the following models:.
single-turn matching models: these models,including rnn (lowe et al., 2015), cnn (loweet al., 2015), lstm (lowe et al., 2015), bil-stm (kadlec et al., 2015), mv-lstm (wan et al.,2016) and match-lstm (wang and jiang, 2016),perform context-response matching by concate-nating all utterances in a context into a single longdocument and calculating a matching score be-tween the document and a response candidate..multi-view (zhou et al., 2016): the model cal-culates matching degree between a context anda response candidate from both a word sequenceview and an utterance sequence view..dl2r (yan et al., 2016): the model ﬁrst refor-mulates the last utterance with previous turns ina context with different approaches.
a responsecandidate and the reformulated message are thenrepresented by a composition of rnn and cnn..2https://www.taobao.com3http://lucene.apache.org/.
finally, a matching score is computed with theconcatenation of the representations..smn (wu et al., 2017): the model lets each ut-terance in a context interact with a response can-didate at the beginning, and then transforms inter-action matrices into a matching vector with cnn.
the matching vectors are ﬁnally accumulated withan rnn as a matching score..dua (zhang et al., 2018b): the model considersthe relationship among utterances within a contextby exploiting deep utterance aggregation to forma ﬁne-grained context representation.
each re-ﬁned utterance then matches with a response can-didate, and their matching degree is ﬁnally calcu-lated through an aggregation on turns..dam (zhou et al., 2018b): the model lets eachutterance in a context interact with a response can-didate at different levels of representations ob-tained by a stacked self-attention module and across-attention module..for the ubuntu data and the douban data, sinceresults of all baselines under ﬁne-tuning are avail-able in zhou et al.
(2018b), we directly copy thenumbers from the paper.
for the e-commercedata, zhang et al.
(2018b) report performance ofall baselines except dam.
thus, we copy all avail-able numbers from the paper and implement damwith the published code4.
in order to conduct sta-tistical tests, we also run the code of dam on theubuntu data and the douban data..6.3.implementation details.
in ioi, we set the size of word embedding as 200.for the cnn in matching aggregation, we set thewindow size of convolution and pooling kernels as(3, 3), and the strides as (1, 1) and (3, 3) respec-tively.
the number of convolution kernels is 32 inthe ﬁrst layer and 16 in the second layer.
the di-mension of the hidden states of gru is set as 200.following wu et al.
(2017), we limit the length ofa context to 10 turns and the length of an utterance(either from a context or from a response candi-date) to 50 words.
truncation or zero-padding isapplied to a context or a response candidate whennecessary.
we gradually increase the number ofinteraction blocks (i.e., l) in ioi, and ﬁnally setl = 7 in comparison with the baseline models.
inoptimization, we choose 0.2 as a dropout rate, and50 as the size of mini-batches.
the learning rateis initialized as 0.0005, and exponentially decayed.
4 https://github.com/baidu/dialogue.
6metrics.
ubuntu corpus.
douban corpus.
modelsrnn (lowe et al., 2015)cnn (lowe et al., 2015)lstm (lowe et al., 2015)bilstm (kadlec et al., 2015)dl2r (yan et al., 2016)mv-lstm (wan et al., 2016)match-lstm (wang and jiang, 2016)multi-view (zhou et al., 2016)smn (wu et al., 2017)dua(zhang et al., 2018b)dam (zhou et al., 2018b)ioi-globalioi-local.
r2@1 r10@1 r10@2 r10@5 map mrr p@1 r10@1 r10@2 r10@50.5890.7680.6470.8480.7200.9010.7160.8950.7050.8990.7100.9060.7200.9040.7290.9080.7240.9260.780-0.7570.9380.7810.9410.7860.947.
0.1180.1210.1870.1840.1930.2020.2020.2020.2330.2430.2540.2630.269.
0.5470.6840.7840.7800.7830.8040.7990.8010.8470.8680.8740.8790.894.
0.8190.8960.9490.9440.9440.9460.9440.9510.9610.9620.9690.9700.974.
0.3900.4170.4850.4790.4880.4980.5000.5050.5290.5510.5500.5660.573.
0.4220.4400.5270.5140.5270.5380.5370.5430.5690.5990.6010.6080.621.
0.2230.2520.3430.3300.3420.3510.3480.3500.3960.4210.4100.4360.451.
0.4030.5490.6380.6300.6260.6530.6530.6620.7260.7520.7670.7780.796.
0.2080.2260.3200.3130.3300.3480.3450.3420.3970.4210.4270.4330.444.table 1: evaluation results on the ubuntu data and the douban data.
numbers in bold mean that the improvementto the best performing baseline is statistically signiﬁcant (t-test with p-value < 0.05)..metrics.
modelsrnn (lowe et al., 2015)cnn (lowe et al., 2015)lstm (lowe et al., 2015)bilstm (kadlec et al., 2015)dl2r (yan et al., 2016)mv-lstm (wan et al., 2016)match-lstm (wang and jiang, 2016)multi-view (zhou et al., 2016)smn (wu et al., 2017)dua(zhang et al., 2018b)dam (zhou et al., 2018b)ioi-globalioi-local.
r10@1 r10@2 r10@5.
0.3250.3280.3650.3550.3990.4120.4100.4210.4530.5010.5260.5540.563.
0.4630.5150.5360.5250.5710.5910.5900.6010.6540.7000.7270.7470.768.
0.7750.7920.8280.8250.8420.8570.8580.8610.8860.9210.9330.9420.950.table 2: evaluation results on the e-commerce data.
numbers in bold mean that the improvement to thebest performing baseline is statistically signiﬁcant (t-test with p-value < 0.05)..during training..6.4 evaluation results.
table 1 and table 2 report evaluation results on thethree data sets where ioi-global and ioi-local rep-resent models learned with objective (17) and ob-jective (18) respectively.
we can see that both ioi-local and ioi-global outperform the best perform-ing baseline, and improvements from ioi-local onall metrics and from ioi-global on a few met-rics are statistically signiﬁcant (t-test with p-value< 0.05).
ioi-local is consistently better than ioi-global over all metrics on all the three data sets,demonstrating that directly supervising each blockin learning can lead to a more optimal deep struc-ture than optimizing the ﬁnal matching model..6.5 discussions.
in this section, we make some further analysiswith ioi-local to understand (1) how depth of in-.
figure 2: performance of ioi under different numbersof the interaction blocks..teraction affects the performance of ioi; (2) howcontext length affects the performance of ioi; and(3) importance of different components of ioi withrespect to matching accuracy..impact of interaction depth.
figure 2 illus-trates how the performance of ioi changes with re-spect to the number of interaction blocks on testsets of the three data.
from the chart, we ob-serve a consistent trend over the three data sets:there is signiﬁcant improvement during the ﬁrstfew blocks, and then the performance of the modelbecomes stable.
the results indicate that depthof interaction indeed matters in terms of match-ing accuracy.
with shallow interaction (l = 1),ioi performs worse than dam on the douban dataand the e-commerce data.
only after the interac-tion goes deep (l ≥ 5), improvement from ioi.
70.780.790.80r10@10.7780.7890.7930.7940.7950.7950.7960.794ubuntue-commercedouban0.450.500.55r10@10.4670.5160.5280.5370.5540.5630.5630.56112345678# interaction blocks0.400.420.44p@10.4020.4210.4300.4320.4410.4400.4440.441modelsioiioi-eioi- ˆeioi-eioi- ˜eioi-m1ioi-m2ioi-m3.
metrics.
ubuntu data.
e-commerce data.
douban datar2@1 r10@1 r10@2 map mrr p@1 r10@1 r10@2 r10@50.9470.6210.9470.9430.6160.9470.9410.6130.9460.9430.6130.9470.9440.6160.9470.9430.6110.9460.9420.6050.9440.9460.6150.946.
0.7960.7940.7900.7930.7950.7930.7880.793.
0.5630.5590.5570.5600.5620.5570.5510.558.
0.4440.4380.4330.4390.4410.4360.4270.438.
0.7680.7620.7490.7540.7400.7430.7390.748.
0.8940.8910.8880.8900.8910.8900.8860.889.
0.5730.5680.5650.5660.5710.5680.5620.567.table 3: evaluation results of the ablation study on the three data sets..(a) r10@1 vs. average utterance length.
(b) r10@1 vs. number of turns.
figure 3: performance of ioi across contexts with different lengths on the ubuntu data..to dam on the two data becomes signiﬁcant.
onthe ubuntu data, improvement to dam from thedeep model (l = 7) is more than twice as much asthat from the shallow model (l = 1).
the perfor-mance of ioi becomes stable earlier on the ubuntudata than it does on the other two data.
this maystem from the different nature of test sets of thethree data.
the test set of the ubuntu data is inlarge size and built by random sampling, while thetest sets of the other two data are smaller and con-structed through response retrieval..impact of context length.
context length ismeasured by (1) number of turns in a context and(2) average length of utterances in a context.
fig-ure 3 shows how the performance of ioi variesacross contexts with different lengths, where webin test examples of the ubuntu data into bucketsand compare ioi (l = 7) with its shallow version(l = 1) and dam.
we ﬁnd that (1) ioi, either in adeep form or in a shallow form, is good at dealingwith contexts with long utterances, as the modelachieves better performance on longer utterances;(2) overall, ioi performs well on contexts withmore turns, although too many turns (e.g., ≥ 8) isstill challenging; (3) a deep form of our model isalways better than its shallow form, no matter how.
we measure context length, and the gap betweenthe two forms is bigger on short contexts than it ison long contexts, indicating that depth mainly im-proves matching accuracy on short contexts; and(4) trends of dam in both charts are consistentwith those reported in (zhou et al., 2018b), and onboth short contexts and long contexts, ioi is supe-rior to dam..(ek−1.
u,i (˜ek.
u,i (ˆek.
r,i ), ˆek.
r,i), and ˜ek.
ablation study.
finally, we examine how dif-ferent components of ioi affects its performance.
first, we remove ek−1r,i), eku,iu,i(ekr,i) one by one from equation(10) and equation (11), and denote the models asioi-e, ioi- ˆe, ioi-e, and ioi- ˜e respectively.
then,we keep all representations in equation (10) andequation (11), and remove mki,2, and mki,3one by one from equation (13).
the models arenamed ioi-m1, ioi-m2, and ioi-m3 respectively.
table 3 reports the ablation results5.
we concludethat (1) all representations are useful in represent-ing the information ﬂow along the chain of inter-action blocks and capturing the matching infor-mation between an utterance-response pair withinthe blocks, as removing any component gener-.
i,1, mk.
5due to space limitation, we only report results on main.
metrics..8(0, 10](10, 20](20, 30](30, 50]average utterance length (words)0.7250.7500.7750.8000.8250.850r10@1damioi-1lioi-7l[2, 4][5, 7][8, 10]context length (turns)0.750.760.770.780.790.800.81r10@1damioi-1lioi-7lally causes performance drop on all the three datasets; and (2) in terms of component importance,ˆe > e > e > ˜e and m2 > m1 ≈ m3, meaningthat self-attention (i.e., ˆe) and cross-attention (i.e.,e) are more important than others in informationﬂow representation, and self-attention (i.e., thoseused for calculating m2) convey more matchingsignals.
note that these results are obtained withioi (l = 7).
we also check the ablation resultsof ioi (l = 1) and do not see much differenceon overall trends and relative gaps among differ-ent ablated models..7 conclusions and future work.
that.
we present an interaction-over-interaction net-lets utterance-response inter-work (ioi)action in context-response matching go deep.
depth of the model comes from stacking multi-ple interaction blocks that execute representation-interaction-representation in an iterative manner.
evaluation results on three benchmarks indicatethat ioi can signiﬁcantly outperform baselinemethods with moderate depth.
in the future, weplan to integrate our ioi model with models likeelmo (peters et al., 2018) and bert (devlinet al., 2018) to study if the performance of ioi canbe further improved..acknowledgement.
we would like to thank the anonymous re-viewers for their constructive comments.
thiswork was supported by the national key re-search and development program of china (no.
2017yfc0804001), the national science foun-dation of china (nsfc nos.
61672058 and61876196)..references.
jimmy lei ba, jamie ryan kiros, and geoffrey e hin-arxiv preprint.
ton.
2016. layer normalization.
arxiv:1607.06450..junyoung chung, caglar gulcehre, kyunghyun cho,and yoshua bengio.
2014. empirical evaluation ofgated recurrent neural networks on sequence model-ing.
arxiv preprint arxiv:1412.3555..alexis conneau, holger schwenk, lo¨ıc barrault, andyann lecun.
2017. very deep convolutional net-works for text classiﬁcation.
in proceedings of the15th conference of the european chapter of the as-sociation for computational linguistics: volume 1,long papers, pages 1107–1116..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training ofdeep bidirectional transformers for language under-standing.
arxiv preprint arxiv:1810.04805..kaiming he, xiangyu zhang, shaoqing ren, and jiansun.
2016. deep residual learning for image recog-in proceedings of the ieee conference onnition.
computer vision and pattern recognition, pages 770–778..baotian hu, zhengdong lu, hang li, and qingcaichen.
2014. convolutional neural network archi-tectures for matching natural language sentences.
in advances in neural information processing sys-tems, pages 2042–2050..gao huang, zhuang liu, laurens van der maaten, andkilian q weinberger.
2017a.
densely connectedconvolutional networks.
in proceedings of the ieeeconference on computer vision and pattern recogni-tion, pages 4700–4708..hsin-yuan huang, chenguang zhu, yelong shen, andweizhu chen.
2017b.
fusionnet: fusing via fully-aware attention with application to machine compre-in international conference on learninghension.
representations..rudolf kadlec, martin schmid, and jan kleindienst.
2015. improved deep learning baselines for ubuntucorpus dialogs.
arxiv preprint arxiv:1510.03753..seonhoon kim, jin-hyuk hong, inho kang, and no-jun kwak.
2018. semantic sentence matching withdensely-connected recurrent and co-attentive infor-mation.
arxiv preprint arxiv:1805.11360..diederik p kingma and jimmy ba.
2015. adam: amethod for stochastic optimization.
in internationalconference on learning representations..alex krizhevsky, ilya sutskever, and geoffrey e hin-ton.
2012.imagenet classiﬁcation with deep con-volutional neural networks.
in advances in neuralinformation processing systems, pages 1097–1105..feng-lin li, minghui qiu, haiqing chen, xiong-wei wang, xing gao, jun huang, juwei ren,zhongzhou zhao, weipeng zhao, lei wang, et al.
2017a.
alime assist: an intelligent assistant for cre-ating an innovative e-commerce experience.
in pro-ceedings of the 2017 acm on conference on infor-mation and knowledge management, pages 2495–2498..jiwei li, michel galley, chris brockett, jianfeng gao,and bill dolan.
2015. a diversity-promoting objec-tive function for neural conversation models.
pro-ceedings of the 2016 conference of the north amer-ican chapter of the association for computationallinguistics: human language technologies, pages110–119..9jiwei li, michel galley, chris brockett, georgios sp-ithourakis, jianfeng gao, and bill dolan.
2016a.
apersona-based neural conversation model.
in asso-ciation for computational linguistics, pages 994–1003..yiping song, rui yan, cheng-te li, jian-yun nie,ming zhang, and dongyan zhao.
2018. an ensem-ble of retrieval-based and generation-based human-in ijcai, pagescomputer conversation systems.
4382–4388..jiwei li, will monroe, alan ritter, dan jurafsky,michel galley, and jianfeng gao.
2016b.
deep rein-forcement learning for dialogue generation.
in pro-ceedings of the 2016 conference on empirical meth-ods in natural language processing, pages 1192–1202..christian szegedy, wei liu, yangqing jia, pierresermanet, scott reed, dragomir anguelov, du-mitru erhan, vincent vanhoucke, and andrew ra-binovich.
2015. going deeper with convolutions.
inproceedings of the ieee conference on computer vi-sion and pattern recognition, pages 1–9..jiwei li, will monroe, tianlin shi, s˙ebastien jean,alan ritter, and dan jurafsky.
2017b.
adversariallearning for neural dialogue generation.
in proceed-ings of the 2017 conference on empirical methodsin natural language processing, pages 2157–2169..ryan lowe, nissan pow, iulian serban, and joellepineau.
2015. the ubuntu dialogue corpus: a largedataset for research in unstructured multi-turn dia-logue systems.
in proceedings of the 16th annualmeeting of the special interest group on discourseand dialogue, pages 285–294..tomas mikolov, ilya sutskever, kai chen, greg s cor-rado, and jeff dean.
2013. distributed representa-tions of words and phrases and their compositional-in advances in neural information processingity.
systems, pages 3111–3119..lili mou, yiping song, rui yan, ge li, lu zhang,and zhi jin.
2016. sequence to backward and for-ward sequences: a content-introducing approach toin proceedingsgenerative short-text conversation.
of coling 2016, the 26th international confer-ence on computational linguistics: technical pa-pers, pages 3349–3358..matthew e peters, mark neumann, mohit iyyer, mattgardner, christopher clark, kenton lee, and lukezettlemoyer.
2018. deep contextualized word rep-in proceedings of the 2018 confer-resentations.
ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1 (long papers), pages2227–2237..iulian vlad serban, alessandro sordoni, yoshua ben-gio, aaron c. courville, and joelle pineau.
2016.end-to-end dialogue systems using generative hier-in aaai, pagesarchical neural network models.
3776–3784..lifeng shang, zhengdong lu, and hang li.
2015.neural responding machine for short-text conversa-tion.
in proceedings of the 53rd annual meeting ofthe association for computational linguistics andthe 7th international joint conference on naturallanguage processing, pages 1577–1586..heung-yeung shum, xiaodong he, and di li.
2018.from eliza to xiaoice: challenges and opportuni-ties with social chatbots.
frontiers of it & ee,19(1):10–26..chongyang tao, shen gao, mingyue shang, wei wu,dongyan zhao, and rui yan.
2018. get the point ofmy utterance!
learning towards effective responsesin ijcai,with multi-head attention mechanism.
pages 4418–4424..yi tay, luu anh tuan, and siu cheung hui.
2018.co-stack residual afﬁnity networks with multi-levelattention reﬁnement for matching text sequences.
in proceedings of the 2018 conference on empiri-cal methods in natural language processing, pages4492–4502..oriol vinyals and quoc le.
2015. a neural conversa-tional model.
arxiv preprint arxiv:1506.05869..shengxian wan, yanyan lan, jun xu, jiafeng guo,liang pang, and xueqi cheng.
2016. match-srnn:modeling the recursive matching structure with spa-tial rnn.
in ijcai, pages 2922–2928..hao wang, zhengdong lu, hang li, and enhongchen.
2013. a dataset for research on short-textconversations.
in proceedings of the 2013 confer-ence on empirical methods in natural languageprocessing, pages 935–945..mingxuan wang, zhengdong lu, hang li, and qunliu.
2015. syntax-based deep matching of shortin proceedings of the twenty-fourth inter-texts.
national joint conference on artiﬁcial intelligence,pages 1354–1361..shuohang wang and jing jiang.
2016. learning nat-in proceed-ural language inference with lstm.
ings of the 2016 conference of the north ameri-can chapter of the association for computationallinguistics: human language technologies, pages1442–1451..yu wu, wei wu, zhoujun li, and ming zhou.
2018a.
learning matching models with weak supervisionfor response selection in retrieval-based chatbots.
inproceedings of the 56th annual meeting of the as-sociation for computational linguistics (volume 2:short papers), pages 420–425..yu wu, wei wu, chen xing, can xu, zhoujunli, and ming zhou.
2018b.
a sequential match-ing framework for multi-turn response selection inretrieval-based chatbots.
computational linguis-tics, 45(1):163–197..10xiangyang zhou, lu li, daxiang dong, yi liu, yingchen, wayne xin zhao, dianhai yu, and hua wu.
2018b.
multi-turn response selection for chatbotswith deep attention matching network.
in proceed-ings of the 56th annual meeting of the associationfor computational linguistics (volume 1: long pa-pers), volume 1, pages 1118–1127..yu wu, wei wu, chen xing, ming zhou, and zhou-sequential matching network: ajun li.
2017.new architecture for multi-turn response selectionin proceedings of thein retrieval-based chatbots.
55th annual meeting of the association for compu-tational linguistics, volume 1, pages 496–505..chen xing, wei wu, yu wu, jie liu, yalou huang,ming zhou, and wei-ying ma.
2017. topic awareneural response generation.
in aaai, pages 3351–3357..zhen xu, bingquan liu, baoxun wang, chengjie sun,and xiaolong wang.
2017.incorporating loose-structured knowledge into lstm with recall gate forconversation modeling.
in proceedings of the 2017international joint conference on neural networks,pages 3506–3513..rui yan, yiping song, and hua wu.
2016. learningto respond with deep neural networks for retrieval-based human-computer conversation system.
in si-gir, pages 55–64..rui yan and dongyan zhao.
2018. coupled contextmodeling for deep chit-chat: towards conversationsin proceedings ofbetween human and computer.
the 24th acm sigkdd international conference onknowledge discovery & data mining, pages 2574–2583. acm..saizheng zhang, emily dinan, jack urbanek, arthurszlam, douwe kiela, and jason weston.
2018a.
personalizing dialogue agents: i have a dog, do youin proceedings of the 56th an-have pets too?
nual meeting of the association for computationallinguistics (volume 1: long papers), pages 2204–2213..zhuosheng zhang, jiangtong li, pengfei zhu, haizhao, and gongshen liu.
2018b.
modeling multi-turn conversation with deep utterance aggregation.
in proceedings of the 27th international conferenceon computational linguistics, pages 3740–3752.
association for computational linguistics..tiancheng zhao, ran zhao, and maxine eskenazi.
2017. learning discourse-level diversity for neuraldialog models using conditional variational autoen-in proceedings of the 55th annual meet-coders.
ing of the association for computational linguistics(volume 1: long papers), volume 1, pages 654–664..hao zhou, minlie huang, tianyang zhang, xiaoyanzhu, and bing liu.
2018a.
emotional chatting ma-chine: emotional conversation generation with in-ternal and external memory.
in the thirty-secondaaai conference on artiﬁcial intelligence, pages730–738..xiangyang zhou, daxiang dong, hua wu, shiqi zhao,dianhai yu, hao tian, xuan liu, and rui yan.
2016.multi-view response selection for human-computerin proceedings of the 2016 confer-conversation.
ence on empirical methods in natural languageprocessing, pages 372–381..11