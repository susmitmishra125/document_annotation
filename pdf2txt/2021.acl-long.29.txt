aspect-category-opinion-sentiment quadruple extractionwith implicit aspects and opinions.
hongjie cai‚àó rui xia‚àó‚Ä†.
jianfei yu.
school of computer science and engineering,nanjing university of science and technology, china{hjcai, rxia, jfyu}@njust.edu.cn.
abstract.
product reviews contain a large number of im-plicit aspects and opinions.
however, mostof the existing studies in aspect-based senti-ment analysis ignored this problem.
in thiswork, we introduce a new task, named aspect-category-opinion-sentiment (acos) quadru-ple extraction, with the goal to extract allaspect-category-opinion-sentiment quadruplesin a review sentence and provide full supportfor aspect-based sentiment analysis with im-plicit aspects and opinions.
we further con-struct two new datasets restaurant-acos andlaptop-acos for this new task.
the for-mer is an extension of the semeval restau-rant dataset;the latter is a brand new lap-top dataset with much larger size than the se-meval laptop dataset.
both contain the an-notations of not only aspect-category-opinion-sentiment quadruples but also implicit aspectsand opinions.
we Ô¨Ånally benchmark thetask with four baseline systems.
experimentsdemonstrate the feasibility of the new taskand its advantage in extracting and describ-ing implicit aspects and implicit opinions inabsa.
the two datasets and source code offour systems are publicly released at https://github.com/nustm/acos..1.introduction.
as a Ô¨Åne-grained sentiment analysis task, aspect-based sentiment analysis (absa) has received con-tinuous attention.
its core task is to extract theopinion target described by an entity and its aspect(collectively referred to as aspect) from product re-views, and identify the sentiment toward the aspect(liu, 2012).
the standard aspect-based sentimentanalysis task includes two basic subtasks: aspectextraction and aspect-based sentiment classiÔ¨Åca-tion.
by integrating the two subtasks, one can.
‚àó equal contribution.
‚Ä† corresponding author..figure 1: an example of the aspect-category-opinion-sentiment quadruple extraction task..restaurant laptop.
explicit aspect & explicit opinionimplicit aspect & explicit opinionexplicit aspect & implicit opinionimplicit aspect & implicit opinion.
63.34% 56.06%19.47% 17.54%12.38% 27.55%14.83% 8.24%.
table 1: the percentage of review sentences with ex-plicit and implicit aspect/opinion..identify an aspect-sentiment pair (g, s), where gis an aspect term, and s is the sentiment polaritytoward the aspect.
(hu and liu, 2004; qiu et al.,2011) pointed out that the correlation between theaspect term and the opinion term is helpful forbetter absa.
the following studies in this direc-tion includes aspect-opinion co-extraction (wanget al., 2016a, 2017; yu et al., 2018; li et al., 2018;dai and song, 2019), aspect-opinion pair extrac-tion (chen et al., 2020a; zhao et al., 2020), andaspect-opinion-sentiment triple extraction (penget al., 2020; xu et al., 2020; wu et al., 2020; maoet al., 2021), etc..however, most of the existing studies only con-sidered the extraction of explicit aspects and opin-ions, while ignored the implicit ones.
in fact, prod-uct reviews contain a large amount of implicit as-pects and opinions.
table 1 summarizes the per-centage of implicit aspects and opinions in the.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages340‚Äì350august1‚Äì6,2021.¬©2021associationforcomputationallinguistics340review sentencelooks nice, and the surfaceis smooth, but certain appstake seconds to respond.aspect-category-opinion-sentimentquadruple extractionsurface-design-smooth-positivenull-design-nice-positiveapps-software-null-negativesemeval restaurant dataset and our new laptopdataset.
it can be seen that nearly 44% of the re-view sentences contain implicit aspects or implicitopinions in the laptop domain, and the percent-age of sentences containing both implicit aspectsand implicit opinions also exceeds 8%.
similarpercentages can be observed in the restaurant do-main.
although some studies have attempted tosolve the implicit aspect problem (liu et al., 2005;poria et al., 2014; chen and chen, 2016; wan et al.,2020) or the implicit opinion problem (lazhar andguiyassa, 2016) from respective perspectives, thereis still a lack of a uniÔ¨Åed framework that fully dis-cusses and solves the implicit aspect and implicitopinion problems..in this work, we introduce a new task namedaspect-category-opinion-sentiment(acos)quadruple extraction, with the goal to extractall aspect-category-opinion-sentiment quadruplesin a review sentence, and provide full supportfor aspect-level sentiment analysis with implicitaspects and opinions.
as shown in figure 1, in thereview sentence ‚Äúlooks nice and the surface issmooth, but certain apps take seconds to respond‚Äù,surface is an aspect, design is its category, smoothis the opinion toward this aspect, and positive isthe corresponding sentiment.
the four elementsare combined into an explicit quadruple surface-design-smooth-positive.
in addition to that, thereare two other quadruples that need to be extracted:null-design-nice-positive which contains animplicit aspect, and apps-software-null-negativewhich contains an implicit opinion..the new acos quadruple extraction task has.
the following two challenges:.
‚Ä¢ in term of dataset, so far there was no avail-able dataset that is fully annotated with aspect-category-opinion-sentiment quadruples includ-ing all implicit aspects and opinions;.
‚Ä¢ in terms of modeling complexity, the task in-cludes two extraction problems (aspect extrac-tion, opinion extraction) and two classiÔ¨Åcationproblems (category classiÔ¨Åcation, sentiment clas-siÔ¨Åcation).
it is challenging to effectively modelthe four subtasks together to construct quadru-ples containing implicit aspects and implicitopinions..to address these issues, we further constructtwo new datasets, restaurant-acos and laptop-acos, for the new task.
the former is an exten-sion of the existing semeval restaurant dataset,.
based on which we add the annotation of im-plicit aspects, implicit opinions, and the quadru-ples.
the latter is a brand new one collected fromthe amazon laptop domain.
it has twice size ofthe semeval loptop dataset, and is annotated withquadruples containing all explicit/implicit aspectsand opinions..we Ô¨Ånally benchmark the task by establish-ing four baseline systems, double-propagation-acos, jet-acos, tas-bert-acos andextract-classify-acos, by adapting the repre-sentative approaches in aspect-opinion pair extrac-tion, aspect-category-opinion triple extraction oraspect-opinion-sentiment triple extraction to acosquadruple extraction.
the experiments on the twoacos datasets demonstrate the feasibility of thenew acos quadruple extraction task and its ef-fectiveness in extracting and describing implicitaspects and implicit opinions..the contributions of this work can be summa-.
rized as follows:.
‚Ä¢ we introduce a new task named aspect-category-opinion-sentiment quadruple extrac-tion, to address the implicit aspects/opinions is-sues in absa;.
‚Ä¢ we construct two new datasets for the task, withacos quadruple annotations including implicitaspects/opinions;.
‚Ä¢ we benchmark the task with four baseline sys-tems.
the experiments demonstrate the newtask‚Äôs advantage in addressing the implicit as-pect/opinion issues..2 task.
we Ô¨Årst deÔ¨Åne the four elements of the acosquadruple extraction task based on (liu, 2012).
(peng et al., 2020; mao et al., 2021) providedgood summaries of recent tasks and terminology inabsa.
for simplicity, in this paper we use aspect,category, opinion and sentiment to denote aspectterm, aspect category, opinion term and sentimentpolarity, respectively.
they are deÔ¨Åned as follows:.
‚Ä¢ aspect denotes an entity and its aspect indicat-ing the opinion target, which is normally a wordor phrase in the text;.
‚Ä¢ category represents a unique predeÔ¨Åned cate-.
gory for the aspect in a particular domain;.
‚Ä¢ opinion refers the subjective statement on anaspect, which is normally a subjective word orphrase in the text;.
341‚Ä¢ sentiment is the predeÔ¨Åned semantic orientation(e.g., positive, negative, or neutral) toward theaspect..aspect-category-opinion-sentiment (acos)quadruple extraction is then deÔ¨Åned as a task toextract a set of aspect-category-opinion-sentimentquadruples described in a review sentence contain-ing n words r=[w1, .
.
.
, wn]:.
sacos = {.
.
.
, ai-cj-ok-sl, .
.
.},.
(1).
where ai-cj-ok-sl denotes an aspect-category-opinion-sentiment quadruple, ai is the extractedaspect, cj ‚àà c is its category, ok is the extractedopinion, and sl ‚àà {positive, neutral, negative} isits corresponding sentiment.1.
note that a review sentence usually contains mul-tiple aspects and opinions.
the acos quadru-ple extraction task does not only identify four el-ements, but also combine them into a set of validquadruples, meanwhile considering implicit as-pects/opinions.
as the implicit aspect/opinion isnot explicitly expressed as a word or phrase, incase of implicit aspect we set a as null and usecategory c to describe the opinion target, and incase of implicit opinion we set o as null and usesentiment s to describe the semantic orientation..3 datasets.
we construct two new datasets, restaurant-acosand laptop-acos, for the acos quadruple ex-traction task..3.1 source.
the restaurant-acos dataset is constructed basedon the semeval 2016 restaurant dataset (pontikiet al., 2016) and its expansion datasets (fan et al.,2019; xu et al., 2020)..laptop-acos is a brand new laptop datasetcollected from the amazon platform at the years of2017 and 2018 (covering ten types of laptops undersix brands such as asus, acer, samsung, lenovo,mbp, msi and so on).
it contains 4,076 reviewsentences, much larger than the semeval laptopdatasets..1similarly, the previous representative tasks in absa canalso be denoted by the combination of the above elements, e.g.,aspect-sentiment (as) pair extraction (mitchell et al., 2013;zhang et al., 2015), aspect-opinion (ao) pair extraction (chenet al., 2020a; zhao et al., 2020), aspect-opinion-sentiment(aos) triple extraction (peng et al., 2020; xu et al., 2020;wu et al., 2020; mao et al., 2021; chen et al., 2021), aspect-category-sentiment (acs) triple extraction (wan et al., 2020),etc..#categories#sentencess ea & eoia & eoea & ioia & ioall.
elpurdauq#.
#quadruples#sentences.
restaurant-acos.
laptop-acos.
1322862429 (66.40%)530 (14.49%)350 (9.57%)349 (9.54%)3658.
12140763269 (56.77%)910 (15.80%)1237 (21.48%)342 (5.94%)5758.
1.60.
1.42.table 2: statistics of our two acos quadrupledatasets.
ea, eo, ia and io denote explicit aspect,explicit opinion, implicit aspect, and implicit opinion,respectively.
#categories represents the number of as-pect categories which are consistent with that in (pon-tiki et al., 2016)..3.2 annotation.
the semeval 2016 restaurant dataset (pontikiet al., 2016) was annotated with explicit and im-plicit aspects, categories, and sentiment.
(fan et al.,2019; xu et al., 2020) further added the opinionannotations.
we integrate their annotations to con-struct aspect-category-opinion-sentiment quadru-ples and further annotate the implicit opinions..for laptop-acos, we annotate the four ele-ments and their corresponding quadruples all byourselves.
we employ the aspect categories de-Ô¨Åned in the semeval 2016 laptop dataset.
twophd students familiar with aspect-based sentimentanalysis are selected as annotators for independentannotation with the annotation tool introduced by(yang et al., 2017a).
the strict quadruple match-ing f1 score between two annotators is 75.86%,which indicates a substantial agreement betweentwo annotators (kim and klinger, 2018).
in case ofdisagreement, a third expert will be asked to makethe Ô¨Ånal decision..3.3 statistics and analysis.
the basic statistics of the two datasets are reportedin table 2. the restaurant-acos dataset con-tains 2286 sentences with 3658 quadruples, andthe laptop-acos dataset contains 4076 sentenceswith 5758 quadruples.
as we have mentioned, alarge percentage of the quadruples contain implicitaspects or implicit opinions.
by comparing twodatasets, it can be observed that laptop-acoshas higher percentage of implicit opinions thanrestaurant-acos..in table 3, we further compare our two acosdatasets with the existing representative datasets.
342sentence aspect category opinion sentiment.
as ao aos acspair pair triple triple quadruple.
acos.
restaurant-2014 (pontiki et al., 2014)laptop-2014 (pontiki et al., 2014)restaurant-2016 (pontiki et al., 2016)laptop-2016 (pontiki et al., 2016)restaurant-2014-ao (fan et al., 2019)restaurant-2016-ao (fan et al., 2019)restaurant-2014-aos (xu et al., 2020)restaurant-2016-aos (xu et al., 2020)restaurant-acos (ours)laptop-acos (ours).
3841191022952612212514072068139322864076.
482730123122-350319683399194631104958.
4738-30013705----29674992.
----361021463443210133355378.
4534301231223705--3399194631104958.
------.
482730123182---.
----409222943399 3908 39081946 2247 22473155 3571 35755035 5726 5731.
--3364-----33355227.
--------36585758.table 3: the comparison between the sizes of our two acos quadruple datasets and existing representativeabsa datasets.
as, ao, aos, and acs denote aspect-sentiment, aspect-opinion, aspect-opinion-sentiment,and aspect-category-sentiment, respectively..in absa.
restaurant 2014/2016 and laptop2014/2016 denote the semeval 2014/2016 restau-rant and laptop datasets, respectively.
restaurant2014/2016 contains the annotations of aspect, cate-gory and sentiment.
it should be noted the categorydeÔ¨Ånitions in two datasets are different.
laptop2014 contains only the annotations of aspect andsentiment, while laptop 2016 contains only theannotations of category and sentiment..restaurant-2014-ao and restaurant-2016-aoare two aspect-opinion pair datasets proposed by(fan et al., 2019), based on restaurant 2014 and2016, respectively.
they removed the sentenceswith implicit aspects and added the opinion an-notations.
(xu et al., 2020) further added senti-ment which was originally included in resturant2014/2016 to restaurant-2014/2016-ao, and ob-tained two aspect-opinion-sentiment triple datasets:restaurant-2014-aos and restaurant-2016-aos.
for restaurant-acos, we integrate the aboveannotations to construct acos quadruples.
but itshould be noted that we keep the sentences withimplicit aspects in restaurant-2016, and further an-notate the implicit opinions.
as a result, the size(including sentences, ao pairs and aos triples)of restaurant-acos is about 1.6 times that ofrestaurant-2016-ao and restaurant-2016-aos..the new laptop-acos has 4076 review sen-tences.
the numbers of annotations for aspect,category, opinion and sentiment are 4958, 4992,5378 and 4958, respectively.
by combining theseelements, we construct 5035 as pairs, 5726 aopairs, 5731 aos triples, 5227 acs triples and5758 acos quadruples, nearly twice the size ofrestaurant-acos.2.
2it is worth noting that the restaurant-acos and laptop-.
4 methods.
we benchmark the acos quadruple extrac-tion task with four baseline systems, namely,jet-acos, tas-double-propagation-acos,bert-acos and extract-classify-acos, byadapting the representative approaches in aspect-opinion pair extraction, aspect-category-opiniontriple extraction or aspect-opinion-sentiment tripleextraction to acos quadruple extraction..4.1 double-propagation-acos.
since double propagation (dp) is one of the rep-resentative rule-based methods for aspect-opinion-sentiment triple extraction (qiu et al., 2011), wepropose to adapt it to our acos quadruple extrac-tion task by Ô¨Årst extracting all the aspect-opinion-sentiment triples, followed by assigning the aspectcategory for each extracted triple.
we name theadapted approach as double-propagation-acos.
speciÔ¨Åcally, we Ô¨Årst follow the dp algorithm toextract the aspect-opinion-sentiment triples, wherewe utilize the syntactic relations between aspectsand opinions to iteratively extract them in eachreview, and rely on the sentiment lexicon to assignsentiments (i.e., positive, negative, and neutral)to aspects and opinions in a bootstrapping manner.
second, to identify the aspect category of eachextracted triple, we use the following strategy: ifthe aspect in the triple is in the training set, we takeits most co-occurred aspect category as the Ô¨Ånalaspect category; otherwise, we adopt the aspect.
acos datasets are available for all subtasks in absa, includ-ing aspect-based sentiment classiÔ¨Åcation, aspect-sentimentpair extraction, aspect-opinion pair extraction, aspect-opinion-sentiment triple extraction, aspect-category-sentiment tripleextraction, etc..343category of the nearest aspect in the input reviewas the Ô¨Ånal aspect category..based on the two steps mentioned above, wecan extract the acos quadruples in each reviewsentence..4.2.jet-acos.
as one of the state-of-the-art approaches for aspect-opinion-sentiment triple extraction, jet (xu et al.,2020) introduced an end-to-end framework to thistask, by combining the identiÔ¨Åcation of aspects,their corresponding opinions, and their sentimentpolarities with a position-aware tagging scheme3.
similar to double-propagation-acos, we adaptjet to our task by Ô¨Årst extracting the triple withjet, followed by predicting the aspect category foreach extracted triple..speciÔ¨Åcally, we Ô¨Årst obtain the candidate aspect-opinion-sentiment triples based on jet, and thendesign a bert-based model to get the aspect cat-egory of the extracted triples.
given the reviewsentence r, we Ô¨Årst feed it to bert to get thecontext-aware token representation h as follows:.
h =[h[cls], hr, h[sep]],.
(2).
where hr = [h1, .
.
.
, hn] is the output represen-tation for r. next, given an extracted triple a-o-s,we can obtain the representation of the aspect andthe opinion as ua = avg(ha) and uo = avg(ho),where avg(ha) and avg(ho) are the average vec-tors of words in the aspect ha and the opinion ho,respectively.
we then concatenate ua and uo, andfeed it to a fully-connected layer with the sigmoidfunction for each category c:.
yc = sigmoid(w (cid:62).
c [ua; uo] + bc)..(3).
given a-o-s and c, yc = 1 indicates a valid quadru-ple, and yc = 0 indicates an invalid quadruple..in the training stage, we adopt the standard bi-nary cross-entropy loss for optimization.
in theinference stage, we combine the extracted aspect-opinion-sentiment triples from jet and our pre-dicted aspect categories to get all the quadruplesfrom each review sentence..3jet contains two variants, i.e., jett and jeto.
jettaims to identify the aspects, the offset of their correspondingopinions, and their sentiment polarity; whereas jeto aims toidentify the opinions, the offset of their corresponding aspects,and their sentiment polarity.
we employ jeto to extract theaspect-opinion-sentiment triple, as it has been shown to obtainbetter performance than jett..4.3 tas-bert-acos.
tas-bert (wan et al., 2020) is one of the state-of-the-art method for aspect-category-sentiment tripleextraction, which integrates aspect category-basedsentiment classiÔ¨Åcation and aspect extraction in auniÔ¨Åed framework by attaching the aspect categoryand the sentiment polarity to the review sentenceand using it as the input of bert.
to adapt tas-bert to our acos extraction task, we proposeto adopt the input transformation strategy in tas-bert to perform category-sentiment conditionalaspect-opinion co-extraction, following by Ô¨Ålteringout the invalid aspect-opinion pairs to form the Ô¨Ånalquadruples..speciÔ¨Åcally, given a review sentence r, an aspectcategory c ‚àà c, and a sentiment s ‚àà s, the input isconstructed as follows:.
x =[[cls], r, [sep], c, s, [sep]],.
(4).
we then feed x to bert to get the context-awaretoken representation h:.
h =[h[cls], hr, h[sep], hcs, h[sep]],.
(5).
where hr = [h1, .
.
.
, hn] is the output representa-tion for r, hcs is the output representation for theconcatenation of c and s, and h[cls] is used forcategory-sentiment veriÔ¨Åcation..we then perform aspect-opinion co-extractionover h by modeling it as a single sequence label-ing task.
speciÔ¨Åcally, we employ a modiÔ¨Åed begin-inside-outside (bio) tagging scheme, which con-sists of Ô¨Åve tags: {ba, ia, bo, io, o}, indicatingthe beginning and inside of the aspect, the begin-ning and inside of the opinion, and others.
we feedhr to a crf layer to extract the aspects and opin-ions in r with respect to the input category c andsentiment s as follows:.
y ao = [yao.
1 , .
.
.
, yao.
n ] = crf(h1, .
.
.
, hn); (6).
next, we perform cartesian product on the ex-tracted aspects and opinions to obtain a set of can-didate aspect-category-opinion-sentiment quadru-ples:.
sacos = {a1-c1-o1-s1, ..., a|a|-c|c|-o|o|-s|s|},(7)where |a| and |o| are the number of extracted as-pects and opinions, |c| and |s| are the number ofdetected categories and sentiment..344training.
validation.
testing.
restaurant-acoslaptop-acos.
15312934.
170326.
585816.table 4: the division of training, validation, and testingsets..we further apply two binary classiÔ¨Åcation taskson the [cls] tokens to predict whether there isimplicit aspect or implicit opinion.
thus, we canobtain the potential aspect set sa, opinion set so,and perform cartesian product on sa and so toobtain a set of candidate aspect-opinion pairs:.
sao = {a1-o1, ..., a|a|-o|o|}..(10).
next, we model the category-sentiment classiÔ¨Å-cation as a multiple multi-class classiÔ¨Åcation prob-lem.
speciÔ¨Åcally, for each category c, we concate-nate the average vectors of each aspect-opinion paira-o, and feed them to a fully-connected layer withsoftmax function as follows:.
saoc = softmax(w (cid:62).
aoc[ua; uo] + baoc),.
(11).
where saoc ‚àà {positive, negative, neutral, invalid}denotes its sentiment given current a-o and c, orindicates an invalid quadruple..5 experiments.
we evaluate the performance of four baselines sys-tems on two acos quadruple datasets..5.1 experimental settings and evaluation.
metrics.
in extract-classify-acos, we adopt bertbase(devlin et al., 2018) as the basic encoder, whichconsists of 12 stacked transformer blocks.
duringtraining, we use the adamw optimizer of bertwith weight decay Ô¨Åx.
the maximum length of thereview sentence is set to 128, covering all sentencesin two datasets.
we set the batch size and learningrates in aspect opinion co-extraction and category-sentiment classiÔ¨Åcation as [32, 2e-5] and [16, 3e-5], respectively.
the dropout rate is set as 0.1.the batch size and learning rate in the categoryclassiÔ¨Åcation of jet-acos and the aspect-opinionpair Ô¨Åltering in tas-bert-acos are all set as [8,5e-5], other settings of these two modules are thesame as extract-classify-acos..figure 2: the structure of extract-classify-acos..on the basis of sacos, we average the vectorsof tokens in the aspect and opinion, and then feedtheir concatenation [ua; uo] to a quadruple Ô¨Ålter:.
yacos = sigmoid(w (cid:62)[ua; uo] + b),.
(8).
where yacos = 1 indicates a valid quadruple, andyacos = 0 indicates an invalid quadruple..4.4 extract-classify-acos.
finally, we propose extract-classify-acos byadapting one of the representative aspect-opinionco-extraction system (wang et al., 2017) to ouracos quadruple extraction task.
speciÔ¨Åcally, theÔ¨Årst step performs aspect-opinion co-extraction,and the second step predicts category-sentimentgiven the extracted aspect-opinion pairs..as shown in figure 2, we Ô¨Årst insert two [cls]tokens at the beginning and the end of the reviewsentence r, and then feed the transformed input tobert to obtain the context-aware token represen-tations h as follows:.
h =[h[cls], hr, h[cls]],.
(9).
similar to the method in tas-bert-acos, theexplicit aspect-opinion co-extraction is based on acrf layer with the modiÔ¨Åed bio tagging scheme..we divide the original dataset into a trainingset, a validation set and a testing set according totable 4..345‚Ä¶‚Ä¶‚Ä¶explicit aspect opinion co-extraction[cls]looks nice, and the surface ‚Ä¶ to respond.
[cls]bert‚Ñé2‚Ä¶‚Ñéùëõ‚àí1aspect-opinion pairingcategory-sentiment classificationcandidate aspect-opinion pairs‚Ñéclsimplicit aspectprediction‚Ñéclsimplicit opinionprediction‚Ñé1‚Ñéùëõcandidate aspectsùëé|a|ùëé1‚Ä¶ùëú1candidate opinionsùëú|ùëÇ|‚Ä¶‚Ä¶‚Ä¶ùëé1-ùëêùëó1-ùëú2-ùë†ùëô1ùëé2-ùëêùëó2-ùëú1-ùë†ùëô2‚Ä¶valid aspect-category-opinion-sentiment quadruples‚Ä¶ùëé1-o1ùëé1-o2ùëé1-o|ùëÇ|ùëé|ùê¥|-o1ùëé|ùê¥|-o2ùëé|ùê¥|-o|ùëÇ|method.
restaurant-acosr.p.f1.
laptop-acosr.p.f1.
double-propagation-acosjet-acostas-bert-acosextract-classify-acos.
0.34670.59810.26290.3854.
0.15080.28940.46290.5296.
0.21040.39010.33530.4461.
0.13040.44520.47150.4556.
0.00570.16250.19220.2948.
0.08000.23810.27310.3580.table 5: main results of the aspect-category-opinion-sentiment quadruple extraction task..method.
restaurant-acos.
laptop-acos.
ea & eo ia & eo ea & io ia & io ea & eo ia & eo ea & io ia & io.
double-propagation-acosjet-acostas-bert-acosextract-classify-acos.
0.26020.52300.33600.4496.n/an/a0.31840.3466.n/an/a0.14030.2386.n/an/a0.39760.3370.
0.09800.35700.26100.3539.n/an/a0.41540.3900.n/an/a0.10900.1682.n/an/a0.21150.1858.table 6: f1 score on testing subsets with different aspect & opinion types.
ea, eo, ia and io denote explicitaspect, explicit opinion, implicit aspect and implicit opinion, respectively.
n/a means the model can not deal withthe corresponding type..in evaluation, a quadruple is viewed as correctif and only if the four elements as well as theircombination are exactly the same as those in thegold quadruple.
on this basis, we calculate theprecision and recall, and use f1 score as the Ô¨Ånalevaluation metric for aocs quadruple extraction..5.2 main results.
table 5 reports the acos quadruple extractionperformance of four different systems on the twodatasets.
it can be seen that double-propagation-acos gets the lowest performance.
it is reasonablethat only using rules is somehow difÔ¨Åcult to iden-tify multiple implicit elements and their complexcombinations in reviews..jet-acos and tas-bert-acos achieve com-parable f1 performance: the former is better onrestaurant-acos dataset and the latter is better onlaptop-acos..extract-classify-acos achieves the best per-formance among four baseline systems.
it out-performs jet-acos by 5.60 percentage pointson restaurant-acos and outperforms tas-bert-acos by 8.49 percentage points on laptop-acos,respectively.
the main advantage is that extract-classify-acos can achieve robustly higher recallscore.
in comparison, jet-acos has higher orcomparable precision score but its recall is muchlower..it is also worth noting that the f1 score ofextract-classify-acos on both datasets are nothigh (0.4461 and 0.3580).
it is reasonable becausethe evaluation metric is based on exact matching.
and the acos quadruple extraction is a more com-plicated task than the traditional absa tasks..5.3 effectiveness of modeling of implicit.
aspects/opinions.
as we have mentioned, a large percentage of re-view sentences contain implicit aspects/opinions.
therefore, efÔ¨Åcient modeling ofimplicit as-pects/opinions is of great importance..to investigate the ability of different systems inaddressing the implicit aspects/opinion problem, intable 6 we split the testing set into four subsetsand observe the performance on different subsets:1) ea & eo denotes the subset with explicit as-pects and explicit opinions; 2) ia & eo denotesthe subset with implicit aspects and explicit opin-ions; 3) ea & io denotes the subset with explicitaspects and implicit opinions; 4) ia & io denotesthe subset with both implicit aspects and implicitopinions..among four systems, double-propagation-acos and jet-acos can only address ea &eo, while tas-bert-acos and extract-classify-acos can support both implicit aspects and im-plicit opinions.
they show comparable ability inmodeling the implicit aspects/opinions.
extract-classify-acos is better in case of ia & eo andea & io on restaurant-acos, while tas-bert-acos is better in case of ia & eo and ia & ioon laptop-acos.
but extract-classify-acos per-forms signiÔ¨Åcantly better in case of ea & eo ontwo datasets..we further compare the performance on differ-.
346aspect & opinion type.
ea & eo.
ia & eo.
ea & io.
ia & io.
review sentence.
keyboard is comfortable and screen is sharp..nice, i ordered this just for simpleweb browsing and personal use..i noticed the battery went down to67% for no reason..we waited for an hour to beseated..aspair.
aopair.
acstriple.
aostriple.
racl (chen and qian, 2020).
sdrn (chen et al., 2020a).
tas-bert (wan et al., 2020).
jet (xu et al., 2020).
jet-acos.
acosquadruple.
tas-bert-acos.
extract-classify-acos.
screen-pos (cid:51)keyboard-pos (cid:51)screen-sharp (cid:51)keyboard-comfortable (cid:51)screen-design&feature-pos (cid:51)keyboard-usability-pos (cid:51)screen-sharp-pos (cid:51)keyboard-comfortable-pos (cid:51)screen-performance-sharp-pos (cid:55)keyboard-usability-comfortable-pos (cid:51)screen-design&feature-sharp-pos (cid:51)keyboard-usability-comfortable-pos (cid:51)screen-design&feature-sharp-pos (cid:51)keyboard-usability-comfortable-pos (cid:51).
n/a.
n/a.
(cid:55).
n/a.
n/a.
(cid:55).
battery-performance-neg (cid:51).
(cid:55).
n/a.
n/a.
n/a.
n/a.
n/a.
(cid:55).
n/a.
n/a.
battery-performance-null-neg (cid:51) null-service-null-neg (cid:51).
null-general-nice-pos (cid:51).
battery-performance-null-neg (cid:51) null-service-null-neg (cid:51).
table 7: the predictions of some representative approaches in Ô¨Åve absa tasks on review sentences with differentaspect & opinion types.
ea, eo, ia and io denote explicit aspect, explicit opinion, implicit aspect and implicitopinion, respectively.
n/a stands for non-available; (cid:51) and (cid:55) denote correct and false predictions, respectively..ent subsets.
the result shows that the worst perfor-mance is obtained on ea & io rather than ia &io.
one possible reason is that the categories cor-responding to ia & io are relatively regular thanea & io, and is easier to predict..5.4 case study.
in table 7, we further conduct case study bycomparing the predictions of some representa-tive approaches on Ô¨Åve absa tasks includingaspect-sentiment (as) pair extraction, aspect-opinion (ao) pair extraction, aspect-category-sentiment(acs) triple extraction, aspect-opinion-sentiment (aos) triple extraction, andacos extraction..we choose four different sentences according towhether the aspect/opinion is explicit or implicit,and observe the predictions obtained by differentit can be observed that: 1) raclapproaches.
(chen and qian, 2020) accurately extracts the aspairs in case of ea & eo, but it does not sup-port implicit aspects and it fails to make predic-tions in case of ea & io on our testing sentence;2) sdrn (chen et al., 2020a) is only capable ofaspect-opinion pair extraction in case of ea & eo;3) jet (xu et al., 2020) can only extract aspect-opinion-sentiment triples in case of ea & eo; 4)although tas-bert (wan et al., 2020) supportsaspect-category-sentiment triple extraction for ei-ther implicit aspect or implicit opinion, it fails togive accurate predictions in case of ia & eo and ia& io on our testing sentences; 5) as for the threeacos baseline systems, jet-acos is only capa-ble of acos quadruple extraction in case of ea &eo, and has a false prediction.
tas-bert-acosand extract-classify-acos support acos quadru-.
ple extraction in case of both implicit aspects andimplicit opinions.
tas-bert-acos performs bet-ter than jet-acos but still fails in the case of ia& eo.
extract-classify-acos performs generallythe best and produces more accurate predictions inall cases..6 related work.
aspect-based sentiment analysis (absa) hasdrawn wide attention during the last decade.
as acore task of absa, aspect-based sentiment clas-siÔ¨Åcation (absc) which aims to detect the senti-ment of a given aspect has been extensively studiedin the literature (jiang et al., 2011; vo and zhang,2015; tang et al., 2015; wang et al., 2016b; tanget al., 2016; zhang et al., 2016; yang et al., 2017b;ma et al., 2017; zhang et al., 2018; wang et al.,2018, 2019; xu et al., 2019; tang et al., 2020; chenet al., 2020b)..in recent years, on the basis of traditional absc,a series of expansion tasks have appeared in thisÔ¨Åeld.
we divide these work into the following fourcategories:.
aspect-sentiment pair extraction.
it also canbe viewed as joint aspect extraction and absc.
(mitchell et al., 2013) Ô¨Årst explored the open-domain aspect-sentiment extraction task by de-signing a variety of conditional random Ô¨Åeld-based models based on traditional discrete fea-tures.
with the recent trend of deep learning, re-searchers have proposed various neural pipelineapproaches (zhang et al., 2015; hu et al., 2019)or joint learning approaches for this task (li et al.,2019; luo et al., 2019; he et al., 2019; chen andqian, 2020)..347aspect-opinion pair extraction.
(hu and liu,2004) Ô¨Årst addressed the task in a pipeline manner.
(chen et al., 2020a) proposed to extract aspect-opinion pairs with a double-channel recurrent net-work while taking the correlation between aspectsand opinions into consideration.
(zhao et al., 2020)designed a span-based multi-task learning frame-work to extract aspect-opinion pairs jointly.
thework on aspect-opinion co-extraction (wang et al.,2016a, 2017; yu et al., 2018) can be viewed as theÔ¨Årst stage of aspect-opinion pair extraction..aspect-opinion-sentiment triple extraction.
considering the relation between aspect and opin-ion, (hu and liu, 2004) designed a feature-basedopinion summary system, which identiÔ¨Åes explicitaspect, opinion and sentiment, and integrates theminto review opinion summaries.
(qiu et al., 2011)further proposed a double propagation method toutilize the syntactic relations between aspects andopinions to iteratively extract the aspect-opinion-sentiment triples.
more recently, (peng et al., 2020)proposed a two-stage framework to Ô¨Årst extractaspect-sentiment pairs and opinions separately, fol-lowed by matching them to obtain aspect-opinion-sentiment triples.
(xu et al., 2020) further proposedan end-to-end position-aware tagging scheme tomodel the relations among aspect, opinion and sen-timent.
(wu et al., 2020) proposed a grid taggingscheme to address this problem.
(mao et al., 2021;chen et al., 2021) transformed the triple extrac-tion task into multi-turn machine reading compre-hension task and achieved state-of-the-art perfor-mances..aspect-category-sentiment triple extrac-tion.
previous two categories only focus on explicitaspect-based sentiment analysis, while ignoring theimplicit aspects.
to address this issue, (liu et al.,2005) designed rule-based method to Ô¨Ånd the cor-responding implicit aspects through the opinionexisting in the review sentence.
with the recentadvances of pre-trained models, (wan et al., 2020)proposed a bert-based architecture to address thistask in an end-to-end fashion..since the problem of implicit aspect and implicitopinion has not been systematically addressedin previous studies, in this work we introduce anew task for aspect-category-opinion-sentiment(acos) quadruple extraction with implicit as-pects and opinions, construct two acos quadrupledatasets, and benchmark the task with four baselinesystems..7 conclusions and future work.
in this paper, we introduce a new task, aspect-category-opinion-sentiment (acos) quadrupleextraction, aiming to systematically address theimplicit aspect/opinion problem.
we construct twonew datasets for this task, with acos annotationsincluding implicit aspects and implicit opinions.
we Ô¨Ånally benchmark the task with four baselinesystems.
experiments demonstrate the advantagesof the new task in aspect-based sentiment analysiswith implicit aspects/opinions..the focus of this paper is the introduction of thenew task and datasets.
the proposed four base-line systems are relatively simple and leave muchroom for further improvements.
we welcome fu-ture work proposing stronger models on this task.
we also welcome the usage of our datasets on theother absa tasks..acknowledgments.
this work was supported by the natural sci-ence foundation of china (no.
62076133 and62006117), and the natural science foundationof jiangsu province for young scholars (no.
bk20200463) and distinguished young scholars(no.
bk20200018)..references.
huan-yuan chen and hsin-hsi chen.
2016..implicitpolarity and implicit aspect recognition in opinionin proceedings of the 54th annual meet-mining.
ing of the association for computational linguistics(acl), pages 20‚Äì25..shaowei chen, jie liu, yu wang, wenzheng zhang,and ziming chi.
2020a.
synchronous double-channel recurrent network for aspect-opinion pairextraction.
in proceedings of the 58th annual meet-ing of the association for computational linguistics(acl), pages 6515‚Äì6524..shaowei chen, yu wang, jie liu, and yuelin wang.
2021. bidirectional machine reading comprehen-sion for aspect sentiment triplet extraction.
in pro-ceedings of the 35th aaai conference on artiÔ¨Åcialintelligence (aaai), pages 12666‚Äì12674..xiao chen, changlong sun, jingjing wang, shoushanli, luo si, min zhang, and guodong zhou.
2020b.
aspect sentiment classiÔ¨Åcation with document-levelin proceedings ofsentiment preference modeling.
the 58th annual meeting of the association for com-putational linguistics (acl), pages 3667‚Äì3677..348zhuang chen and tieyun qian.
2020. relation-awarecollaborative learning for uniÔ¨Åed aspect-based sen-timent analysis.
in proceedings of the 58th annualmeeting of the association for computational lin-guistics (acl), pages 3685‚Äì3694..hongliang dai and yangqiu song.
2019. neuralaspect and opinion term extraction with minedarxiv preprintrules as weak supervision.
arxiv:1907.03750..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2018. bert: pre-training of deepbidirectional transformers for language understand-ing.
arxiv preprint arxiv:1810.04805..zhifang fan, zhen wu, xinyu dai, shujian huang, andjiajun chen.
2019. target-oriented opinion wordsextraction with target-fused neural sequence label-ing.
in proceedings of the 2019 conference of thenorth american chapter of the association for com-putational linguistics (naacl), pages 2509‚Äì2518..ruidan he, wee sun lee, hwee tou ng, and danieldahlmeier.
2019. an interactive multi-task learn-ing network for end-to-end aspect-based sentimentanalysis.
in proceedings of the 57th annual meet-ing of the association for computational linguistics(acl), pages 504‚Äì515..minghao hu, yuxing peng, zhen huang, dongshengli, and yiwei lv.
2019. open-domain targeted sen-timent analysis via span-based extraction and clas-siÔ¨Åcation.
in proceedings of the 57th annual meet-ing of the association for computational linguistics(acl), pages 537‚Äì546..minqing hu and bing liu.
2004. mining and summa-rizing customer reviews.
in proceedings of the tenthacm sigkdd international conference on knowl-edge discovery and data mining, pages 168‚Äì177..long jiang, mo yu, ming zhou, xiaohua liu, andtiejun zhao.
2011. target-dependent twitter senti-ment classiÔ¨Åcation.
in proceedings of the 49th an-nual meeting of the association for computationallinguistics (acl), pages 151‚Äì160..evgeny kim and roman klinger.
2018. who feelswhat and why?
annotation of a literature corpuswith semantic roles of emotions.
in proceedings ofthe 27th international conference on computationallinguistics (coling), pages 1345‚Äì1359..farek lazhar and yamina tlili guiyassa.
2016. miningexplicit and implicit opinions from reviews.
int.
j.data min.
model.
manag., 8:75‚Äì92..xin li, lidong bing, piji li, and wai lam.
2019. auniÔ¨Åed model for opinion target extraction and tar-get sentiment prediction.
in proceedings of the 33rdaaai conference on artiÔ¨Åcial intelligence (aaai),pages 6714‚Äì6721..xin li, lidong bing, piji li, wai lam, and zhimouyang.
2018. aspect term extraction with history at-tention and selective transformation.
arxiv preprintarxiv:1805.00760..bing liu.
2012. sentiment analysis and opinion min-ing.
synthesis lectures on human language technolo-gies, pages 1‚Äì167..bing liu, minqing hu, and junsheng cheng.
2005.opinion observer: analyzing and comparing opin-ions on the web.
in proceedings of the 14th interna-tional conference on world wide web (www), pages342‚Äì351..huaishao luo, tianrui li, bing liu, and junbozhang.
2019. doer: dual cross-shared rnn foraspect term-polarity co-extraction.
arxiv preprintarxiv:1906.01794..dehong ma, sujian li, xiaodong zhang, and houfengwang.
2017.interactive attention networks foraspect-level sentiment classiÔ¨Åcation.
arxiv preprintarxiv:1709.00893..yue mao, yi shen, chao yu, and longjun cai.
2021. a joint training dual-mrc framework forarxiv preprintaspect based sentiment analysis.
arxiv:2101.00816..margaret mitchell, jacqui aguilar, theresa wilson,and benjamin van durme.
2013. open domain tar-in proceedings of the 2013 con-geted sentiment.
ference on empirical methods in natural languageprocessing (emnlp), pages 1643‚Äì1654..haiyun peng, lu xu, lidong bing, fei huang, wei lu,and luo si.
2020. knowing what, how and why:a near complete solution for aspect-based sentimentanalysis.
in proceedings of the 34th aaai confer-ence on artiÔ¨Åcial intelligence (aaai), pages 8600‚Äì8607..maria pontiki, dimitrios galanis, haris papageor-giou, ion androutsopoulos, suresh manandhar, mo-hammad al-smadi, mahmoud al-ayyoub, yanyanzhao, bing qin, orph¬¥ee de clercq, et al.
2016.semeval-2016 task 5: aspect based sentiment anal-ysis.
in international workshop on semantic evalua-tion, pages 19‚Äì30..maria pontiki, dimitris galanis, john pavlopoulos,ion androutsopoulos, andharris papageorgiou,suresh manandhar.
2014. semeval-2014 task 4: as-pect based sentiment analysis.
in proceedings of the8th international workshop on semantic evaluation(semeval 2014), pages 27‚Äì35, dublin, ireland.
as-sociation for computational linguistics..soujanya poria, erik cambria, lun-wei ku, chen gui,and alexander gelbukh.
2014. a rule-based ap-proach to aspect extraction from product reviews.
in proceedings of the second workshop on naturallanguage processing for social media (socialnlp),pages 28‚Äì37..349guang qiu, bing liu, jiajun bu, and chun chen.
2011. opinion word expansion and target extractionthrough double propagation.
computational linguis-tics, 37(1):9‚Äì27..duyu tang, bing qin, xiaocheng feng,.
andtarget-ting liu.
2015.dependent sentiment classiÔ¨Åcation.
arxiv preprintarxiv:1512.01100..effective lstms for.
duyu tang, bing qin, and ting liu.
2016. aspectlevel sentiment classiÔ¨Åcation with deep memory net-work.
arxiv preprint arxiv:1605.08900..hao tang, donghong ji, chenliang li, and qijizhou.
2020. dependency graph enhanced dual-transformer structure for aspect-based sentimentin proceedings of the 58th annualclassiÔ¨Åcation.
meeting of the association for computational lin-guistics (acl), pages 6578‚Äì6588..duy-tin vo and yue zhang.
2015. target-dependenttwitter sentiment classiÔ¨Åcation with rich automaticin proceedings of the 24th internationalfeatures.
joint conference on artiÔ¨Åcial intelligence (ijcai),pages 1347‚Äì1353..zhen wu, chengcan ying, fei zhao, zhifang fan,xinyu dai, and rui xia.
2020. grid tagging schemefor end-to-end Ô¨Åne-grained opinion extraction.
inproceedings of the 2020 conference on empiricalmethods in natural language processing: findings,pages 2576‚Äì2585..hu xu, bing liu, lei shu, and s yu philip.
2019. bertpost-training for review reading comprehension andaspect-based sentiment analysis.
in proceedings ofthe 2019 conference of the north american chap-ter of the association for computational linguistics(naacl), pages 2324‚Äì2335..lu xu, hao li, wei lu, and lidong bing.
2020.position-aware tagging for aspect sentiment tripletextraction.
arxiv preprint arxiv:2010.02609..jie yang, yue zhang, linwei li, and xingxuan li.
2017a.
yedda: a lightweight collaborative text spanannotation tool.
arxiv preprint arxiv:1711.03759..min yang, wenting tu, jingxuan wang, fei xu, andxiaojun chen.
2017b.
attention based lstm for tar-get dependent sentiment classiÔ¨Åcation.
in proceed-ings of the thirty-first aaai conference on artiÔ¨Å-cial intelligence (aaai), pages 5013‚Äì5014..hai wan, yufei yang, jianfeng du, yanan liu, kunxunqi, and jeff z pan.
2020. target-aspect-sentimentjoint detection for aspect-based sentiment analysis.
in proceedings of the 34th aaai conference on ar-tiÔ¨Åcial intelligence (aaai), pages 9122‚Äì9129..jianfei yu, jing jiang, and rui xia.
2018. global in-ference for aspect and opinion terms co-extractionieee/acmbased on multi-task neural networks.
transactions on audio, speech, and language pro-cessing, 27(1):168‚Äì177..lei zhang, shuai wang, and bing liu.
2018. deeplearning for sentiment analysis: a survey.
wileyinterdisciplinary reviews: data mining and knowl-edge discovery, 8(4):e1253..meishan zhang, yue zhang, and duy-tin vo.
2015.neural networks for open domain targeted sentiment.
in proceedings of the 2015 conference on empiricalmethods in natural language processing (emnlp),pages 612‚Äì621..meishan zhang, yue zhang, and duy-tin vo.
2016.gated neural networks for targeted sentiment anal-ysis.
in proceedings of the 30th aaai conferenceon artiÔ¨Åcial intelligence (aaai), pages 3087‚Äì3093..he zhao, longtao huang, rong zhang, quan lu, et al.
2020. spanmlt: a span-based multi-task learningframework for pair-wise aspect and opinion termsextraction.
in proceedings of the 58th annual meet-ing of the association for computational linguistics(acl), pages 3239‚Äì3248..jingjing wang, changlong sun, shoushan li, xi-aozhong liu, luo si, min zhang, and guodongzhou.
2019. aspect sentiment classiÔ¨Åcation towardsquestion-answering with reinforced bidirectional at-tention network.
in proceedings of the 57th annualmeeting of the association for computational lin-guistics (acl), pages 3548‚Äì3557..shuai wang, sahisnu mazumder, bing liu, mianweizhou, and yi chang.
2018. target-sensitive mem-ory networks for aspect sentiment classiÔ¨Åcation.
inproceedings of the 56th annual meeting of the asso-ciation for computational linguistics (acl), pages957‚Äì967..wenya wang, sinno jialin pan, daniel dahlmeier, andxiaokui xiao.
2016a.
recursive neural conditionalrandom Ô¨Åelds for aspect-based sentiment analysis.
arxiv preprint arxiv:1603.06679..wenya wang, sinno jialin pan, daniel dahlmeier, andxiaokui xiao.
2017. coupled multi-layer attentionsfor co-extraction of aspect and opinion terms.
inproceedings of the 31st aaai conference on arti-Ô¨Åcial intelligence (aaai), pages 3316‚Äì3322..yequan wang, minlie huang, xiaoyan zhu, andli zhao.
2016b.
attention-based lstm for aspect-level sentiment classiÔ¨Åcation.
in proceedings of the2016 conference on empirical methods in naturallanguage processing (emnlp), pages 606‚Äì615..350