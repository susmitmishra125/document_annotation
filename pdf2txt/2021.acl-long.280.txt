bert is to nlp what alexnet is to cv:can pre-trained language models identify analogies?.
asahi ushio, luis espinosa-anke, steven schockaert, jose camacho-colladoscardiff nlp, school of computer science and informaticscardiff university, united kingdom{ushioa,espinosa-ankel,schockaerts1,camachocolladosj}@cardiff.ac.uk.
abstract.
analogies play a central role in human com-monsense reasoning.
the ability to recognizeanalogies such as “eye is to seeing what ear isto hearing”, sometimes referred to as analogi-cal proportions, shape how we structure knowl-edge and understand language.
surprisingly,however, the task of identifying such analogieshas not yet received much attention in the lan-guage model era.
in this paper, we analyzethe capabilities of transformer-based languagemodels on this unsupervised task, using bench-marks obtained from educational settings, aswell as more commonly used datasets.
we ﬁndthat off-the-shelf language models can identifyanalogies to a certain extent, but struggle withabstract and complex relations, and results arehighly sensitive to model architecture and hy-perparameters.
overall the best results wereobtained with gpt-2 and roberta, whileconﬁgurations using bert were not able tooutperform word embedding models.
our re-sults raise important questions for future workabout how, and to what extent, pre-trainedlanguage models capture knowledge about ab-stract semantic relations.1.
1.introduction.
one of the most widely discussed properties ofword embeddings has been their surprising abil-ity to model certain types of relational similari-ties in terms of word vector differences (mikolov.
while the title is probably self-explanatory, this is a smallnote explaining it.
bert is to nlp what alexnet is to cv ismaking an analogy on what the bert and alexnet modelsrepresented for natural language processing (nlp) and com-puter vision (cv), respectively.
they both brought a paradigmshift in how research was undertaken in their correspondingdisciplines and this is what the analogy refers to.
reproduceandtheare.
ex-ourfollowinghttps://github.com/asahi417/.
1sourceperimentalrepository:analogy-language-model.
todataavailable.
coderesults.
in.
query:.
candidates:.
word:language.
paint:portrait(1)poetry:rhythm(2)note:music(3)tale:story(4)(5) week:year.
table 1: an example analogy task from the satdataset.
the third candidate is the answer to the query..et al., 2013a; vylomova et al., 2016; allen andhospedales, 2019; ethayarajh et al., 2019).
theunderlying assumption is that when “a is to b whatc is to d” the word vector differences b − a andd − c are expected to be similar, where we write xfor the embedding of a word x. while this assump-tion holds for some types of syntactic relations,for semantic relations this holds to a much morelimited degree than was suggested in early work(linzen, 2016; schluter, 2018).
moreover, the mostcommonly used benchmarks have focused on spe-ciﬁc and well-deﬁned semantic relations such as“capital of”, rather than the more abstract notion ofrelational similarity that is often needed for solvingthe kind of psychometric analogy problems thatcan be found in iq tests and educational settings.
an example of such a problem is shown in table 1.given the central role of analogy in human cog-nition, it is nonetheless important to understand theextent to which nlp models are able to solve thesemore abstract analogy problems.
besides its valueas an intrinsic benchmark for lexical semantics,the ability to recognize analogies is indeed impor-tant in the contexts of human creativity (holyoaket al., 1996), innovation (hope et al., 2017), com-putational creativity (goel, 2019) and education(pardos and nam, 2020).
analogies are also aprerequisite to build ai systems for the legal do-main (ashley, 1988; walton, 2010) and are used inmachine learning (miclet et al., 2008; hug et al.,.
proceedingsofthe59thannualmeetingoftheassociationforcomputationallinguisticsandthe11thinternationaljointconferenceonnaturallanguageprocessing,pages3609–3624august1–6,2021.©2021associationforcomputationallinguistics36092016; h¨ullermeier, 2020) and for ontology align-ment (raad and evermann, 2015), among others.
within nlp, however, the task of recognizinganalogies has received relatively little attention.
tosolve such problems, turney (2005) proposed la-tent relational analysis (lra), which was essen-tially designed as a relational counterpart to latentsemantic analysis (landauer and dumais, 1997).
somewhat surprisingly, perhaps, despite the sub-stantial progress that word embeddings and lan-guage models (lms) have enabled in nlp, lrastill represents the current state-of-the-art in solv-ing abstract word analogy problems.
when go-ing beyond a purely unsupervised setting, however,gpt-3 was recently found to obtain slightly betterresults (brown et al., 2020)..the aim of this paper is to analyze the ability ofpre-trained lms to recognize analogies.
our focusis on the zero-shot setting, where lms are usedwithout ﬁne-tuning.
to predict whether two wordpairs (a, b) and (c, d) are likely to be analogical,we need a prompt, i.e.
a template that is used to con-struct the input to the lm, and a scoring function.
we extensively analyze the impact of both of thesechoices, as well as the differences between differ-ent lms.
when the prompt and scoring functionare carefully calibrated, we ﬁnd that gpt-2 can out-perform lra, standard word embeddings as wellas the published results for gpt-3 in the zero-shotsetting.
however, we also ﬁnd that these resultsare highly sensitive to the choice of the prompt, aswell as two hyperparameters in our scoring func-tion, with the optimal choices not being consistentacross different datasets.
moreover, using bertleads to considerably weaker results, underperform-ing even standard word embeddings in all of theconsidered conﬁgurations.
these ﬁndings suggestthat while transformer-based lms learn relationalknowledge to a meaningful extent, more work isneeded to understand how such knowledge is en-coded, and how it can be exploited..2 related work.
2.1 understanding pre-trained lms.
since their recent dominance in standard nlpbenchmarks (peters et al., 2018a; devlin et al.,2019; liu et al., 2019), pre-trained language mod-els have been extensively studied.
this has mainlybeen done through probing tasks, which are aimedat understanding the knowledge that is implicitlycaptured by their parameters.
after the initial focus.
on understanding pre-trained lstm-based lms(peters et al., 2018b), attention has now shifted to-ward transformer-based models.
the main aspectsthat have been studied in recent years are syntax(goldberg, 2019; saphra and lopez, 2019; hewittand manning, 2019; van schijndel et al., 2019;jawahar et al., 2019; tenney et al., 2019b) and se-mantics (ettinger, 2019; tenney et al., 2019a).
fora more complete overview on analyses of the differ-ent properties of transformer-based lms, we referto rogers et al.
(2021)..despite the rise in probing analyses for lmsand the importance of analogical reasoning in hu-man cognition, understanding the analogical capa-bilities of lms remains understudied.
the mostsimilar works have focused on capturing relationalknowledge from lms (in particular the type ofinformation available in knowledge graphs).
forinstance, petroni et al.
(2019) analyzed to whatextent lms could ﬁll manually-deﬁned templatessuch as “dante was born in [mask]”.
follow-upworks extended this initial approach by automat-ically generating templates and ﬁne-tuning lmson them (bouraoui et al., 2020; jiang et al., 2020),showing an improved performance.
in this paper,we focus on the analogical knowledge that is en-coded in pre-trained lms, without the extra step ofﬁne-tuning on additional data..2.2 word analogy probing.
word analogies have been used as a standard in-trinsic evaluation task for measuring the quality ofword embeddings.
mikolov et al.
(2013b) showedthat word embeddings, in particular word2vec em-beddings, were able to solve analogy problems bysimple vector operations (e.g.
king - man + woman= queen).
the motivation for this task dates backto the connectionism theory (feldman and ballard,1982) in cognitive science.
in particular, neuralnetworks were thought to be able to model emer-gent concepts (hopﬁeld, 1982; hinton, 1986) bylearning distributed representations across an em-bedding space (hinton et al., 1986), similar to theproperties that word embeddings displayed in theanalogy task.
more recent works have proposednew mathematical theories and experiments to un-derstand the analogical capabilities of word embed-dings, attempting to understand their linear alge-braic structure (arora et al., 2016; gittens et al.,2017; allen and hospedales, 2019) or by explic-itly studying their compositional nature (levy and.
3610goldberg, 2014; paperno and baroni, 2016; etha-yarajh et al., 2019; chiang et al., 2020)..3 word analogies.
however, recent works have questioned the im-pressive results displayed by word embeddingsin this task.
in many cases simple baselines ex-cluding the input pair (or query) were competitive(linzen, 2016).
simultaneously, some researchershave found that many relationships may not beretrieved in the embedding space by simple lineartransformations (drozd et al., 2016; bouraoui et al.,2018) and others argued that the standard evalu-ation procedure has limitations (schluter, 2018).
new datasets and measures have also been intro-duced to address some of these issues (gladkovaet al., 2016; fournier et al., 2020).
finally, in thecontext of bias detection, for which analogies havebeen used as a proxy (bolukbasi et al., 2016), it hasalso been found that word analogies may misguideor hide the real relationships existing in the vectorspace (gonen and goldberg, 2019; nissim et al.,2020)..as far as language models are concerned, wordanalogies have not been explored to the same ex-tent as for word embeddings.
recently, brown et al.
(2020) evaluated the unsupervised capabilities ofgpt-3 by evaluating it on the sat analogies dataset(turney et al., 2003), which we also include in ourevaluation (see section 3.2).
however, the evalu-ation is limited to a single dataset (i.e., sat) andmodel (i.e., gpt-3), and the general capabilities oflanguage models were not investigated..despite their limitations, analogy tests remainappealing for evaluating the ability of embeddingsand language models to identify abstract relation-ships.
to mitigate the aforementioned methodolog-ical issues, in this work we rely on analogy testsfrom educational resources, where the task is tocomplete analogical proportions, given only theﬁrst word pair.
in contrast, word embedding mod-els have mostly been evaluated using a predictivetask, in which three of the four words are given.
moreover, the considered datasets are focused onabstract analogies, whereas the most commonlyused datasets only include well-deﬁned semanticrelations such as “capital of”.
for completeness,however, we also show results on these standarddatasets.
we furthermore experiment with severalsimple baselines to understand possible artifactspresent in the different datasets..in this section, we describe the word analogy for-mulation that is used for our experiments (section3.1).
subsequently, we provide an overview of thedatasets used in our experiments (section 3.2)..3.1 task description.
we frame the analogy task in terms of analogicalproportions (prade and richard, 2017).
given aquery word pair (hq, tq) and a list of candidateanswer pairs {(hi, ti)}ni=1, the goal is to ﬁnd thecandidate answer pair that has the most similarrelation to the query pair.
table 1 shows a samplequery and candidate answers drawn from one of thedatasets used in our evaluation (see section 3.2)..3.2 analogy datasets.
we split analogy datasets in two types, based onhow the analogy problems were constructed..3.2.1 psychometric analogy tests.
word analogy tests are commonly used in assess-ments of linguistic and cognitive ability.
for in-stance, in the past, such tests were included in thesat exams, which are a us college admissiontest.
turney et al.
(2003) collected a benchmarkof 374 word analogy problems, consisting primar-ily of problems from these sat tests.
aimed atcollege applicants, these problems are designed tobe challenging for humans.
a key challenge fornlp systems is that solving these problems oftenrequires identifying ﬁne-grained semantic differ-ences between word pairs that belong to the samecoarse-grained relation.
for instance, in the caseof table 1, we could say that “a year consists ofweeks” like “language consists of words”, but theweek-year pair is nonetheless less similar to word-language than note-music..another analogy benchmark was constructed byboteanu and chernova (2015), who used word anal-ogy problems from an educational resource2.
theyused in particular unit 2 of the analogy problemsfrom the educational site.
these problems havethe same form as those from the sat benchmark,but rather than college applicants, they are aimedat children in grades 4 to 12 from the us schoolsystem (i.e.
from age 9 onwards).
in this paper, wewill also include this unit 2 benchmark.
more-over, we have collected another benchmark from.
2https://www.englishforeveryone.org/.
topics/analogies.html.
3611dataset.
satunit 2unit 4googlebats.
data size(val / test).
no.
candidates.
no.
groups.
37 / 33724 / 22848 / 43250 / 500199 / 1799.
55,4,35,4,344.
29523.table 2: high-level statistics of the analogy datasetsafter uniﬁcation: data size, number of candidates andnumber of group partitions..the unit 4 problems on the same website.
theseunit 4 problems are organised in 5 difﬁcultylevels: high-beginning, low-intermediate, high-intermediate, low-advanced and high-advanced.
the low-advanced level is stated to be at the levelof the sat tests, whereas the high-advanced levelis stated to be at the level of the gre test (which isused for admission into graduate schools)..3.2.2 lexical semantics benchmarks.
since the introduction of word2vec (mikolov et al.,2013a), the problem of modelling analogies hasbeen commonly used as an intrinsic benchmark forword embedding models.
however, the datasetsthat have been used in that context are focusedon well-deﬁned and relatively coarse-grained rela-tions.
the google analogy dataset (mikolov et al.,2013b) has been one of the most commonly usedbenchmarks for intrinsic evaluation of word em-beddings.
this dataset contains a mix of semanticand morphological relations such as capital-of andsingular-plural, respectively.
however, its cover-age has been shown to be limiting, and bats (glad-kova et al., 2016) was developed in an attempt toaddress its main shortcomings.
bats includes alarger number of concepts and relations, which aresplit into four categories: lexicographic, encyclope-dic, and derivational and inﬂectional morphology.
as pointed out above, these datasets were tai-lored to the evaluation of word embeddings in apredictive setting.
to provide an evaluation set-ting which is comparable to the benchmarks ob-tained from human analogy tests, we constructedword analogy problems from the google and batsdatasets, by choosing for each correct analogypair a number of negative examples.
the result-ing benchmark thus follows the same format asdescribed in section 3.1. to obtain sufﬁcientlychallenging negative examples, for each query pair(e.g.
paris-france) we extracted three negative in-.
figure 1: solving a word analogy problem by selectingone with the highest lm score among the candidates..stances: (1) two random words from the head of theinput relation type (e.g.
rome-oslo); (2) two ran-dom words from the tail of the input relation type(e.g.
germany-canada); (3) a random word pairfrom a relation type of the same high-level categoryas the input relation type (e.g.
argentina-peso).3.
3.2.3 uniﬁcation and statisticstable 2 provides an overview of our datasets.
theinstances from each dataset are organised intogroups.
in the case of google and bats, thesegroups refer to the relation types (e.g.
semantic ormorphological in the case of google).
in the caseof unit 2 and unit 4, the groups refer to the dif-ﬁculty level.
for the sat dataset, we consider twogroups, capturing whether the instances come froman actual sat test or not.
finally, we randomlysample 10% of each group in each dataset to con-struct a validation set, and regard the remainingdata as the test set..4 methodology.
in this section, we explain our strategy for usingpretrained lms to solve analogy problems withoutﬁne-tuning.
first, in section 4.1 we explain howeach relation pair is converted into a natural sen-tence to be fed into the lm.
in section 4.2, we thendiscuss a number of scoring functions that can beused to select the most plausible answer candidate.
finally, we take advantage of the fact that analog-ical proportion is invariant to particular permuta-tions, which allows for a natural extension of theproposed scoring functions (section 4.3).
figure 1shows a high-level overview of our methodology..4.1 relation pair prompting.
we deﬁne a prompting function tt(w1, w2, w3, w4)that takes four placeholders and a template type t,.
3in order to avoid adding various correct answers to thequery, we avoided adding negative pairs from all country-oftype relations, and from similar lexicographic relations inthe bats dataset with more than one relation type, namelyantonyms, synonyms, meronyms and hyponyms..3612and returns a sentence in which the placeholderswere replaced by the words w1, w2, w3, and w4.
for instance, given a query “word:language” anda candidate “note:music”, the prompting functionproduces.
tto-as(“word”, “language”, “note”, “music”) =“word is to language as note is to music”.
where we use the template type to-as here..using manually speciﬁed template types can re-sult in a sub-optimal textual representation.
forthis reason, recent studies have proposed auto-prompting strategies, which optimize the templatetype on a training set (shin et al., 2020), paraphras-ing (jiang et al., 2020), additional prompt genera-tion model (gao et al., 2020), and corpus-driventemplate mining (bouraoui et al., 2020).
how-ever, none of these approaches can be applied tounsupervised settings.
thus, we do not exploreauto-prompting methods in this work.
instead, wewill consider a number of different template typesin the experiments, and assess the sensitivity of theresults to the choice of template type..4.2 scoring function.
perplexity.
we ﬁrst deﬁne perplexity, which iswidely used as a sentence re-ranking metric (chanet al., 2016; gulcehre et al., 2015).
given a sen-tence x, for autoregressive lms such as lstmbased models (zaremba et al., 2014) and gpts(radford et al., 2018, 2019; brown et al., 2020),perplexity can be computed as.
f (x) = exp.
−.
log pauto(xj|xj−1).
 (1).
.
.
m(cid:88).
j=1.
where x is tokenized as [x1...xm] and pauto(x|x)is the likelihood from an autoregressive lm’snext token prediction.
for masked lms suchas bert (devlin et al., 2019) and roberta(liu et al., 2019), we instead use pseudo-perplexity, which is deﬁned as in (1) butwith pmask(xj|x\j) instead of pauto(xj|xj−1),〈mask〉xj+1 .
.
.
xm] andwhere x\j = [x1 .
.
.
xj1pmask(xj|x\j) is the pseudo-likelihood (wang andcho, 2019) that the masked token is xj.
pmi.
although perplexity is well-suited to capturethe ﬂuency of a sentence, it may not be the bestchoice to test the plausibility of a given analogicalproportion candidate.
as an alternative, we pro-pose a scoring function that focuses speciﬁcally.
figure 2: positive and negative permutations for a rela-tion pair (a:b)-(c:d)..on words from the two given pairs.
to this end,we propose to use an approximation of point-wisemutual information (pmi), based on perplexity..pmi is deﬁned as the difference between a condi-tional and marginal log-likelihood.
in our case, weconsider the conditional likelihood of ti given hiand the query pair (recall from section 3.1 thath and t represent the head and tail of a givenword pair, respectively), i.e.
p (ti|hq, tq, hi), andthe marginal likelihood over hi, i.e.
p (ti|hq, tq).
subsequently, the pmi-inspired scoring function isdeﬁned as.
r(ti|hi, hq, tq) = log p (ti|hi, hq, tq).
− α · log p (ti|hq, tq).
(2).
where α is a hyperparameter to control the effectof the marginal likelihood.
the pmi score corre-sponds to the speciﬁc case where α = 1. however,davison et al.
(2019) found that using a hyperpa-rameter to balance the impact of the conditional andmarginal probabilities can signiﬁcantly improve theresults.
the probabilities in (2) are estimated byassuming that the answer candidates are the onlypossible word pairs that need to be considered.
byrelying on this closed-world assumption, we canestimate marginal probabilities based on perplex-ity, which we found to give better results than themasking based strategy from davison et al.
(2019).
in particular, we estimate these probabilities as.
p (ti|hq, tq, hi) = −.
p (ti|hq, tq) = −.
f (tt(hq, tq, hi, tk)).
f (tt(hq, tq, hi, ti))n(cid:80)k=1n(cid:80)k=1nn(cid:80)(cid:80)l=1k=1.
f (tt(hq, tq, hk, ti)).
f (tt(hq, tq, hk, tl)).
3613where n is the number of answer candidates forthe given query.
equivalently, since pmi is sym-metric, we can consider the difference between thelogs of p (hi|hq, tq, ti) and p (hi|hq, tq).
whilethis leads to the same pmi value in theory, due tothe way in which we approximate the probabilities,this symmetric approach will lead to a differentscore.
we thus combine both scores with an ag-gregation function ag.
this aggregation functiontakes a list of scores and outputs an aggregatedvalue.
as an example, given a list [1, 2, 3, 4], wewrite amean([1, 2, 3, 4]) = 2.5 for the mean andaval1([1, 2, 3, 4]) = 1 for the ﬁrst element.
givensuch an aggregation function, we deﬁne the follow-ing pmi-based score.
to the standard axiomatic characterization, when-ever we have an analogical proportion a : b :: c : d(meaning “a is to b what c is to d”), it also holdsthat c : d :: a : b and a : c :: b : d are ana-logical proportions.
it follows from this that forany given analogical proportion a : b :: c : dthere are eight permutations of the four elementsa, b, c, d that form analogical proportions.
theseeight permutations, along with the 16 “negativepermutations”, are shown in figure 2..to take advantage of the different permutationsof analogical proportions, we propose the followinganalogical proportion (ap) score:.
ap(hq, tq, hi, ti) = agpos(p) − β · agneg(n) (4).
spmi(ti, hi|hq, tq) = ag (r).
(3).
where we consider basic aggregation operationsover the list r = [r(ti|hi, hq, tq), r(hi|ti, hq, tq)],such as the mean, max, and min value.
the choiceof using only one of the scores r(ti|hi, hq, tq),r(hi|ti, hq, tq) is viewed as a special case, in whichthe aggregation function g simply returns the ﬁrstor the second item.
mppl.
we also experiment with a third scoringfunction, which borrows ideas from both perplexityand pmi.
in particular, we propose the marginallikelihood biased perplexity (mppl) deﬁned as.
p = [s(a, b|c, d)](a:b,c:d)∈pn = [s(a, b|c, d)](a:b,c:d)∈n.
where p and n correspond to the list of positiveand negative permutations of the candidate ana-logical proportion hq : tq :: hi : ti in the ordershown in figure 2, β is a hyperparameter to con-trol the impact of the negative permutations, ands(a, b|c, d) is a scoring function as described insection 4.2. here agpos and agneg refer to the ag-gregation functions that are used to combine thescores for the positive and negative permutationsrespectively, where these aggregation functions aredeﬁned as in section 4.2. to solve an analogy prob-lem, we simply choose the answer candidate thatresults in the highest value of ap(ti, hi, hq, tq)..smppl(ti, hi|hq, tq) = log sppl(ti, hi|hq, tq)− αt · log p (ti|hq, tq)− αh · log p (hi|hq, tq).
5 evaluation.
where αt and αh are hyperparameters, and sppl isa normalized perplexity deﬁned as.
in this section, we evaluate language models on theﬁve analogy datasets presented in section 3..sppl(ti, hi|hq, tq) = −.
f (tt(hq, tq, hi, ti)).
..f (tt(hq, tq, hk, tk)).
n(cid:80)k=1.
the mppl score extends perplexity with two biasterms.
it is motivated from the insight that treatingα as a hyperparameter in (2) can lead to betterresults than ﬁxing α = 1. by tuning αt and αh,we can essentially inﬂuence to what extent answercandidates involving semantically similar words tothe query pair should be favored..4.3 permutation invariance.
the formalization of analogical proportions datesback to aristotle (barbot et al., 2019).
according.
5.1 experimental setting.
we consider three transformer-based lms of a dif-ferent nature: two masked lms, namely bert (de-vlin et al., 2019) and roberta (liu et al., 2019),and gpt-2, as a prominent example of an auto-regressive language model.
each pretrained modelwas fetched from the huggingface transformerslibrary (wolf et al., 2019), from which we usebert-large-cased, roberta-large, andgpt2-xl respectively.
for parameter selection,we run grid search on β, α, αh, αt, t, g, gpos, andgneg for each model and select the conﬁgurationwhich achieves the best accuracy on each validationset.
we experiment with the three scoring functionspresented in section 4.2, i.e., sppl (perplexity),.
3614model.
score tuned.
(cid:88).
(cid:88)(cid:88).
(cid:88).
(cid:88)(cid:88).
(cid:88).
(cid:88)(cid:88).
bert.
ml.gpt-2.
roberta.
fasttextgloveword2vecpmirandom.
ew.esab.sppl.
spmi.
smppl.
sppl.
spmi.
smppl.
sppl.
spmi.
smppl-----.
sat32.939.827.040.441.835.950.434.451.056.742.453.735.951.353.447.847.841.823.320.0.u232.941.732.042.544.741.248.744.737.750.949.157.042.549.158.343.046.540.432.923.6.u4 google bats61.580.834.067.986.841.059.174.031.268.187.027.867.988.841.263.580.444.975.993.251.262.862.843.379.891.050.581.295.249.569.790.849.180.593.655.860.860.844.077.292.438.757.478.493.696.672.040.768.796.039.863.893.239.642.757.439.125.025.024.2.avg48.455.444.753.256.953.263.949.662.066.760.268.148.861.768.260.059.855.839.123.6.table 3: accuracy results on each analogy dataset, categorized into language models (lm), word embeddings(we), and baselines (base).
all lms use the analogical proportion (ap) function described in section 4.3. thedefault conﬁguration for ap includes α = αh = αt = β = 0, gpos = g = val1, and t = to-as.
note thatsppl = smppl with the default conﬁguration.
average accuracy (avg) across datasets is included in the last column..spmi and smppl.
possible values for each hyperpa-rameter (including the selection of six prompts andan ablation test on the scoring function) and thebest conﬁgurations that were found by grid searchare provided in the appendix..as baseline methods, we also consider threepre-trained word embedding models, which havebeen shown to provide competitive results in anal-ogy tasks, as explained in section 2.2: word2vec(mikolov et al., 2013a), glove (pennington et al.,2014), and fasttext (bojanowski et al., 2017).
forthe word embedding models, we simply representword pairs by taking the difference between theirembeddings4.
we then choose the answer candi-date with the highest cosine similarity to the queryin terms of this vector difference.
to put the resultsinto context, we also include two simple statisti-cal baselines.
first, we report the expected ran-dom performance.
second, we use a method basedon each word pair’s pmi in a given corpus.
wethen select the answer candidate with the highest.
4vector differences have been found to be the most robustencoding method in the context of word analogies (hakamiand bollegala, 2017)..pmi as the prediction.
note that the query wordpair is completely ignored in this case.
this pmiscore is the well-known word-pair association met-ric introduced by church and hanks (1990) forlexicographic purposes (speciﬁcally, collocationextraction), which compares the probability of ob-serving two words together with the probabilities ofobserving them independently (chance).
the pmiscores in our experiments were computed using theenglish wikipedia with a ﬁxed window size 10..5.2 results.
table 3 shows our main results.
as far as the com-parison among lms is concerned, roberta andgpt-2 consistently outperform bert.
among theap variants, smppl achieves substantially better re-sults than spmi or sppl in most cases.
we alsoobserve that word embeddings perform surpris-ingly well, with fasttext and glove outperform-ing bert on most datasets, as well as gpt-2 androberta with default hyperparameters.
fasttextachieves the best overall accuracy on the googledataset, conﬁrming that this dataset is particularlywell-suited to word embeddings (see section 2.2)..3615model.
score.
tuned accuracy.
sppl.
spmi.
smppl.
sppl.
spmi.
sppl.
sppl.
spmi.
(cid:88).
(cid:88)(cid:88).
(cid:88).
(cid:88)(cid:88).
(cid:88).
(cid:88)(cid:88).
(cid:88).
bert.
gpt-2.
lm.
roberta.
gpt-3.
lrafasttextgloveword2vecpmirandom.
smpplzero-shotfew-shot------.
-.
we.
base.
32.640.4*26.841.2*42.8*41.456.2*34.756.8*57.8*49.655.8*42.554.0*55.8*53.765.2*56.449.748.942.823.320.0.table 4: accuracy results for the full sat dataset.
re-sults marked with * are not directly comparable as theywere tuned on full data (for our models) or use trainingdata (for gpt-3 few-shot).
these results are includedto provide an upper bound only.
results in italics weretaken from the original papers..in order to compare with published results fromprior work, we carried out an additional experimenton the full sat dataset (i.e., without splitting it intovalidation and test).
table 4 shows the results.
gpt-3 (brown et al., 2020) and lra (turney, 2005) areadded for comparison.
given the variability of theresults depending on the tuning procedure, we havealso reported results of conﬁgurations that weretuned on the entire set, to provide an upper boundon what is possible within the proposed unsuper-vised setting.
this result shows that even withoptimal hyperparameter values, lms barely outper-form the performance of the simpler lra model.
gpt-3 similarly fails to outperform lra in thezero-shot setting..6 analysis.
we now take a closer look into our results to investi-gate parameter sensitivity, the correlation betweenmodel performance and human difﬁculty levels,and possible dataset artifacts.
the following analy-sis focuses on smppl as it achieved the best resultsamong the lm based scoring functions..figure 3: box plot of the relative improvement ontest accuracy in each dataset over all conﬁgurations ofsmppl grouped by gpos.
here valk corresponds to kthpositive permutation shown in figure 2..parameter sensitivity we found that optimalvalues of the parameters α and β are highly depen-dent on the dataset, while other parameters suchas the template type t vary across lms.
on theother hand, as shown in figure 3, the optimal per-mutations of the templates are relatively consistent,with the original ordering a : b :: c : d typicallyachieving the best results.
the results degrade mostfor permutations that mix the two word pairs (e.g.
a : c :: b : d).
in the appendix we include an abla-tion study for the sensitivity and relevance of otherparameters and design choices..difﬁculty levels to increase our understandingof what makes an analogy problem difﬁcult forlms, we compare the results for each difﬁcultylevel.5 recall from section 3.2 that the u2 andu4 datasets come from educational resources andare split by difﬁculty level.
figure 4 shows theresults of all lms (tuned setting), fasttext andthe pmi baseline according to these difﬁculty lev-els.
broadly speaking, we can see that instancesthat are harder for humans are also harder for theconsidered models.
the analogies in the mostdifﬁcult levels are generally more abstract (e.g.
witness : testimony :: generator : electricity), orcontain obscure or infrequent words (e.g.
grouch :cantakerous :: palace : ornate).6.
5for sat, google and bats, there are no difﬁculty levelsavailable, but we show the results split by high-level categoriesin the appendix.
we also note that the number of candidatesin u2 and u4 vary from three to ﬁve, so results per difﬁcultylevel are not fully comparable.
however, they do reﬂect theactual difﬁculty of the educational tests..6in the appendix we include more examples with errors.
made by roberta in easy instances..3616mask sat u2 u4 google bats.
t fullrheadebtail.
a fulltrheadebtailor.41.8 44.7 41.231.8 28.1 34.333.5 31.6 38.2.
53.4 58.3 57.438.6 37.7 41.035.6 37.3 40.5.
88.872.064.2.
93.660.655.8.
67.962.463.1.
78.454.564.2.table 5: accuracy results by masking head or tail of thecandidate answers.
results in the top row correspondto the full model without masking..ﬁguration and tuning on these artiﬁcially-modiﬁeddatasets.as can be seen in table 5, a non-trivialperformance is achieved for all datasets, which sug-gests that the words from the answer pair tend tobe more similar to the words from the query thanthe words from negative examples..7 conclusion.
in this paper, we have presented an extensive anal-ysis of the ability of language models to identifyanalogies.
to this end, we ﬁrst compiled datasetswith psychometric analogy problems from educa-tional resources, covering a wide range of difﬁ-culty levels and topics.
we also recast two stan-dard benchmarks, the google and bats analogydatasets, into the same style of problems.
then, weproposed standard techniques to apply languagemodels to the unsupervised task of solving theseanalogy problems.
our empirical results shed lighton the strengths and limitations of various models.
to directly answer the question posed in the title,our conclusion is that language models can identifyanalogies to a certain extent, but not all languagemodels are able to achieve a meaningful improve-ment over word embeddings (whose limitations inanalogy tasks are well documented).
on the otherhand, when carefully tuned, some language mod-els are able to achieve state-of-the-art results.
weemphasize that results are highly sensitive to thechosen hyperparameters (which deﬁne the scoringfunction and the prompt among others).
furtherresearch could focus on the selection of these opti-mal hyperparameters, including automatizing thesearch or generation of prompts, along the linesof bouraoui et al.
(2020) and shin et al.
(2020),respectively.
finally, clearly lms might still beable to learn to solve analogy tasks when givenappropriate training data, which is an aspect thatwe leave for future work..figure 4: test accuracy in u2 and u4 per difﬁcultylevel.
lms use smppl with the best conﬁguration tunedin the corresponding validation sets..hypothesis only recently, several researchershave found that standard nlp benchmarks, suchas snli (bowman et al., 2015) for language in-ference, contain several annotation artifacts thatmakes the task simpler for automatic models (po-liak et al., 2018; gururangan et al., 2018).
one oftheir most relevant ﬁndings is that models which donot even consider the premise can reach high accu-racy.
more generally, these issues have been foundto be problematic in nlp models (linzen, 2020)and neural networks more generally (geirhos et al.,2020).
according to the results shown in table 3,we already found that the pmi baseline achieved anon-trivial performance, even outperforming bertin a few settings and datasets.
this suggests thatseveral implausible negative examples are includedin the analogy datasets.
as a further exploration ofsuch artifacts, here we analyse the analogue of ahypothesis-only baseline.
in particular, for this anal-ysis, we masked the head or tail of the candidateanswer in all evaluation instances.
then, we testthe masked language models with the same ap con-.
3617references.
carl allen and timothy hospedales.
2019. analo-gies explained: towards understanding word em-beddings.
in international conference on machinelearning, pages 223–231..sanjeev arora, yuanzhi li, yingyu liang, tengyu ma,and andrej risteski.
2016. a latent variable modelapproach to pmi-based word embeddings.
transac-tions of the association for computational linguis-tics, 4:385–399..kevin d ashley.
1988. arguing by analogy in law: acase-based model.
in analogical reasoning, pages205–224.
springer..nelly barbot, laurent miclet, and henri prade.
2019.analogy between concepts.
artiﬁcial intelligence,275:487–539..piotr bojanowski, edouard grave, armand joulin, andtomas mikolov.
2017. enriching word vectors withsubword information.
transactions of the associa-tion of computational linguistics, 5(1):135–146..tolga bolukbasi, kai-wei chang, james y zou,venkatesh saligrama, and adam t kalai.
2016.man is to computer programmer as woman is toin ad-homemaker?
debiasing word embeddings.
vances in neural information processing systems,pages 4349–4357..adrian boteanu and sonia chernova.
2015. solvingand explaining analogy questions using semanticnetworks.
in proceedings of the aaai conferenceon artiﬁcial intelligence..zied bouraoui, jose camacho-collados, and steveninducing relational knowledgeschockaert.
2020.from bert.
in proceedings of the aaai conferenceon artiﬁcial intelligence, volume 34, pages 7456–7463..zied bouraoui, shoaib jameel, and steven schockaert.
2018. relation induction in word embeddings revis-ited.
in proceedings of the 27th international con-ference on computational linguistics, pages 1627–1637, santa fe, new mexico, usa.
association forcomputational linguistics..samuel r. bowman, gabor angeli, christopher potts,and christopher d. manning.
2015. a large anno-tated corpus for learning natural language inference.
in proceedings of the 2015 conference on empiri-cal methods in natural language processing, pages632–642, lisbon, portugal.
association for compu-tational linguistics..tom b. brown, benjamin mann, nick ryder, melaniesubbiah, jared kaplan, prafulla dhariwal, arvindneelakantan, pranav shyam, girish sastry, amandaaskell, sandhini agarwal, ariel herbert-voss,gretchen krueger, tom henighan, rewon child,aditya ramesh, daniel m. ziegler, jeffrey wu,clemens winter, christopher hesse, mark chen,.
eric sigler, mateusz litwin, scott gray, benjaminchess, jack clark, christopher berner, sam mc-candlish, alec radford, ilya sutskever, and darioamodei.
2020. language models are few-shot learn-in annual conference on neural informationers.
processing systems..william chan, navdeep jaitly, quoc le, and oriolvinyals.
2016. listen, attend and spell: a neuralnetwork for large vocabulary conversational speechin 2016 ieee international confer-recognition.
ence on acoustics, speech and signal processing(icassp), pages 4960–4964.
ieee..hsiao-yu chiang,.
jose camacho-collados,.
andzachary pardos.
2020. understanding the source ofin pro-semantic regularities in word embeddings.
ceedings of the 24th conference on computationalnatural language learning, pages 119–131, online.
association for computational linguistics..kenneth church and patrick hanks.
1990. word as-sociation norms, mutual information, and lexicogra-phy.
computational linguistics, 16(1):22–29..joe davison, joshua feldman, and alexander m rush.
2019. commonsense knowledge mining from pre-in proceedings of the 2019 con-trained models.
ference on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing, pages 1173–1178..jacob devlin, ming-wei chang, kenton lee, andkristina toutanova.
2019. bert: pre-training ofdeep bidirectional transformers for language under-standing.
in proceedings of the 2019 conference ofthe north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 1 (long and short papers), pages4171–4186..aleksandr drozd, anna gladkova, and satoshi mat-suoka.
2016. word embeddings, analogies, andmachine learning: beyond king-man+ woman=queen.
in proceedings of coling 2016, the 26th in-ternational conference on computational linguistics:technical papers, pages 3519–3530..kawin ethayarajh, david duvenaud, and graeme hirst.
2019. towards understanding linear word analo-in proceedings of the 57th annual meetinggies.
of the association for computational linguistics,pages 3253–3262..allyson ettinger.
2019. what bert is not: lessons froma new suite of psycholinguistic diagnostics for lan-guage models.
transactions of the association forcomputational linguistics, 8:34–48..jerome a. feldman and dana h. ballard.
1982. con-nectionist models and their properties.
cognitivescience, 6(3):205–254..3618louis fournier, emmanuel dupoux, and ewan dun-bar.
2020. analogies minus analogy test: measur-ing regularities in word embeddings.
in proceedingsof the 24th conference on computational naturallanguage learning, pages 365–375, online.
asso-ciation for computational linguistics..tianyu gao, adam fisch, and danqi chen.
2020.making pre-trained language models better few-shotlearners.
arxiv preprint arxiv:2012.15723..robert geirhos,.
j¨orn-henrik jacobsen, claudiomichaelis, richard zemel, wieland brendel,matthias bethge, and felix a wichmann.
2020.shortcut learning in deep neural networks.
naturemachine intelligence, 2(11):665–673..alex gittens, dimitris achlioptas, and michael w ma-honey.
2017. skip-gram- zipf+ uniform= vector ad-in proceedings of the 55th annual meet-ditivity.
ing of the association for computational linguistics(volume 1: long papers), pages 69–76..anna gladkova, aleksandr drozd, and satoshi mat-suoka.
2016. analogy-based detection of morpho-logical and semantic relations with word embed-dings: what works and what doesn’t.
in proceedingsof the student research workshop at naacl, pages8–15..ashok goel.
2019. computational design, analogy,in computational creativity, pages.
and creativity.
141–158.
springer..yoav goldberg.
2019. assessing bert’s syntactic abili-.
ties.
arxiv preprint arxiv:1901.05287..hila gonen and yoav goldberg.
2019. lipstick on apig: debiasing methods cover up systematic genderbiases in word embeddings but do not remove them.
in proceedings of the 2019 conference of the northamerican chapter of the association for computa-tional linguistics: human language technologies,volume 1 (long and short papers), pages 609–614..caglar gulcehre, orhan firat, kelvin xu, kyunghyuncho, loic barrault, huei-chi lin, fethi bougares,holger schwenk, and yoshua bengio.
2015. on us-ing monolingual corpora in neural machine transla-tion.
arxiv preprint arxiv:1503.03535..suchin gururangan, swabha swayamdipta, omerlevy, roy schwartz, samuel bowman, and noah a.smith.
2018. annotation artifacts in natural lan-in proceedings of the 2018guage inference data.
conference of the north american chapter of theassociation for computational linguistics: humanlanguage technologies, volume 2 (short papers),pages 107–112, new orleans, louisiana.
associa-tion for computational linguistics..john hewitt and christopher d. manning.
2019. astructural probe for ﬁnding syntax in word repre-sentations.
in proceedings of the 2019 conferenceof the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 4129–4138, minneapolis, minnesota.
associ-ation for computational linguistics..geoffrey e. hinton.
1986. learning distributed repre-sentations of concepts.
in proceedings of the eighthannual conference of the cognitive science society,volume 1, page 12. amherst, ma..geoffrey e. hinton, james l. mcclelland, and david e.rumelhart.
1986. distributed representations.
par-allel distributed processing: explorations in the mi-crostructure of cognition, vol.
1, pages 77–109..keith j holyoak, keith james holyoak, and paul tha-gard.
1996. mental leaps: analogy in creativethought.
mit press..tom hope, joel chan, aniket kittur, and dafna sha-haf.
2017. accelerating innovation through analogymining.
in proceedings of the 23rd acm sigkddinternational conference on knowledge discoveryand data mining, pages 235–243..john j. hopﬁeld.
1982. neural networks and physi-cal systems with emergent collective computationalabilities.
proceedings of the national academy ofsciences, 79(8):2554–2558..nicolas hug, henri prade, gilles richard, and math-ieu serrurier.
2016. analogical classiﬁers: a theo-in proceedings of the twenty-retical perspective.
second european conference on artiﬁcial intelli-gence, pages 689–697..eyke h¨ullermeier.
2020. towards analogy-based ex-in internationalplanations in machine learning.
conference on modeling decisions for artiﬁcial in-telligence, pages 205–217..ganesh jawahar, benoˆıt sagot, and djam´e seddah.
2019. what does bert learn about the structurein proceedings of the 57th annualof language?
meeting of the association for computational lin-guistics, pages 3651–3657, florence, italy.
associa-tion for computational linguistics..zhengbao jiang, frank f. xu, jun araki, and grahamneubig.
2020. how can we know what languagemodels know?
transactions of the association forcomputational linguistics, 8:423–438..thomas k. landauer and susan t. dumais.
1997. asolution to plato’s problem: the latent semanticanalysis theory of acquisition, induction, and rep-resentation of knowledge.
psychological review,104(2):211..huda hakami and danushka bollegala.
2017. com-positional approaches for representing relations be-tween words: a comparative study.
knowledge-based systems, 136:172–182..omer levy and yoav goldberg.
2014. linguisticregularities in sparse and explicit word representa-in proceedings of the eighteenth confer-tions.
ence on computational natural language learning,.
3619pages 171–180, ann arbor, michigan.
associationfor computational linguistics..tal linzen.
2016. issues in evaluating semantic spacesin proceedings of the 1stusing word analogies.
workshop on evaluating vector-space representa-tions for nlp, pages 13–18..tal linzen.
2020. how can we accelerate progress to-wards human-like linguistic generalization?
in pro-ceedings of the 58th annual meeting of the asso-ciation for computational linguistics, pages 5210–5217, online.
association for computational lin-guistics..yinhan liu, myle ott, naman goyal, jingfei du, man-dar joshi, danqi chen, omer levy, mike lewis,luke zettlemoyer, and veselin stoyanov.
2019.roberta: a robustly optimized bert pretraining ap-proach.
corr, abs/1907.11692..laurent miclet, sabri bayoudh, and arnaud delhay.
2008. analogical dissimilarity: deﬁnition, algo-rithms and two experiments in machine learning.
journal of artiﬁcial intelligence research, 32:793–824..tomas mikolov, ilya sutskever, kai chen, greg s cor-rado, and jeff dean.
2013a.
distributed representa-tions of words and phrases and their compositional-in advances in neural information processingity.
systems, pages 3111–3119..tomas mikolov, wen-tau yih, and geoffrey zweig.
2013b.
linguistic regularities in continuous spacein proceedings of hlt-word representations.
naacl, pages 746–751..malvina nissim, rik van noord, and rob van der goot.
2020. fair is better than sensational: man is to doc-tor as woman is to doctor.
computational linguis-tics, 46(2):487–497..denis paperno and marco baroni.
2016. when thewhole is less than the sum of its parts: how compo-sition affects pmi values in distributional semanticvectors.
computational linguistics, 42(2):345–350..zachary a. pardos and andrew j. h. nam.
2020. auniversity map of course knowledge.
plos one,15(9)..jeffrey pennington, richard socher, and christopher dmanning.
2014. glove: global vectors for wordin proceedings of emnlp, pagesrepresentation.
1532–1543..matthew peters, mark neumann, mohit iyyer, mattgardner, christopher clark, kenton lee, and lukezettlemoyer.
2018a.
deep contextualized word rep-in proceedings of the 2018 confer-resentations.
ence of the north american chapter of the associ-ation for computational linguistics: human lan-guage technologies, volume 1 (long papers), pages2227–2237, new orleans, louisiana.
associationfor computational linguistics..matthew peters, mark neumann, luke zettlemoyer,and wen-tau yih.
2018b.
dissecting contextualword embeddings: architecture and representation.
in proceedings ofthe 2018 conference on em-pirical methods in natural language processing,pages 1499–1509, brussels, belgium.
associationfor computational linguistics..fabio petroni, tim rockt¨aschel, sebastian riedel,patrick lewis, anton bakhtin, yuxiang wu, andalexander miller.
2019. language models as knowl-in proceedings of the 2019 confer-edge bases?
ence on empirical methods in natural languageprocessing and the 9th international joint confer-ence on natural language processing (emnlp-ijcnlp), pages 2463–2473..adam poliak, jason naradowsky, aparajita haldar,rachel rudinger, and benjamin van durme.
2018.hypothesis only baselines in natural language in-in proceedings of the seventh joint con-ference.
ference on lexical and computational semantics,pages 180–191, new orleans, louisiana.
associa-tion for computational linguistics..henri prade and gilles richard.
2017. analogical pro-portions and analogical reasoning-an introduction.
in international conference on case-based reason-ing, pages 16–32.
springer..elie raad and joerg evermann.
2015. the role of anal-ogy in ontology alignment: a study on lisa.
cogni-tive systems research, 33:1–16..alec radford, karthik narasimhan, tim salimans, andimproving language under-.
ilya sutskever.
2018.standing by generative pre-training..alec radford, jeff wu, rewon child, david luan,dario amodei, and ilya sutskever.
2019. languagemodels are unsupervised multitask learners..anna rogers, olga kovaleva, and anna rumshisky.
2021. a primer in bertology: what we know abouthow bert works.
transactions of the association forcomputational linguistics, 8:842–866..naomi saphra and adam lopez.
2019. understand-ing learning dynamics of language models within proceedings of the 2019 conferencesvcca.
of the north american chapter of the associationfor computational linguistics: human languagetechnologies, volume 1 (long and short papers),pages 3257–3267, minneapolis, minnesota.
associ-ation for computational linguistics..marten van schijndel, aaron mueller, and tal linzen.
2019. quantity doesn’t buy quality syntax within proceedings of theneural language models.
2019 conference on empirical methods in natu-ral language processing and the 9th internationaljoint conference on natural language processing(emnlp-ijcnlp), pages 5831–5837, hong kong,china.
association for computational linguistics..3620natalie schluter.
2018. the word analogy testingin proceedings of the 2018 conference ofcaveat.
the north american chapter of the association forcomputational linguistics: human language tech-nologies, volume 2 (short papers), pages 242–246..clara ma, yacine jernite, julien plu, canwen xu,teven le scao, sylvain gugger, mariama drame,quentin lhoest, and alexander m. rush.
2019.huggingface’s transformers: state-of-the-art naturallanguage processing.
arxiv, abs/1910.03771..taylor shin, yasaman razeghi, robert l. logan iv,eric wallace, and sameer singh.
2020. autoprompt:eliciting knowledge from language models within proceed-automatically generated prompts.
ings of the 2020 conference on empirical methodsin natural language processing (emnlp), pages4222–4235, online.
association for computationallinguistics..ian tenney, dipanjan das, and ellie pavlick.
2019a.
bert rediscovers the classical nlp pipeline.
inproceedings of the 57th annual meeting of the asso-ciation for computational linguistics, pages 4593–4601, florence, italy.
association for computationallinguistics..ian tenney, patrick xia, berlin chen, alex wang,adam poliak, r. thomas mccoy, najoung kim,benjamin van durme, samuel r. bowman, dipan-jan das, and ellie pavlick.
2019b.
what do youlearn from context?
probing for sentence structurein contextualized word representations.
in proceed-ing of the 7th international conference on learningrepresentations (iclr)..peter d. turney.
2005. measuring semantic similar-ity by latent relational analysis.
in proc.
of ijcai,pages 1136–1141..peter d. turney, michael l. littman, jeffrey bigham,and victor shnayder.
2003. combining independentmodules in lexical multiple-choice problems.
in re-cent advances in natural language processing iii,pages 101–110..ekaterina vylomova, laura rimell, trevor cohn, andtimothy baldwin.
2016. take and took, gaggle andgoose, book and read: evaluating the utility of vec-tor differences for lexical relation learning.
in pro-ceedings of the 54th annual meeting of the asso-ciation for computational linguistics, pages 1671–1682..douglas walton.
2010. similarity, precedent and argu-ment from analogy.
artiﬁcial intelligence and law,18(3):217–246..alex wang and kyunghyun cho.
2019. bert hasa mouth, and it must speak: bert as a markovin proceedings ofrandom ﬁeld language model.
the workshop on methods for optimizing and eval-uating neural language generation, pages 30–36,minneapolis, minnesota.
association for computa-tional linguistics..thomas wolf, lysandre debut, victor sanh, julienchaumond, clement delangue, anthony moi, pier-ric cistac, tim rault, r´emi louf, morgan funtow-icz, joe davison, sam shleifer, patrick von platen,.
wojciech zaremba, ilya sutskever, and oriol vinyals.
recurrent neural network regularization..2014.arxiv preprint arxiv:1409.2329..a experimental details.
in our grid search to ﬁnd the optimal conﬁgura-tion for each dataset and language model, eachparameter was selected within the values shown intable 6. as the coefﬁcient of marginal likelihoodα, αh, αt, we considered negative values as well aswe hypothesized that the marginal likelihood couldbe beneﬁcial for lms as a way to leverage lexicalknowledge of the head and tail words..additionally, table 7 shows the set of customtemplates (or prompts) used in our experiments.
fi-nally, tables 8, 9, and 10 include the best conﬁgura-tion based on each validation set in for spmi, smppland the hypothesis-only baseline, respectively..parameter value.
ααhαtβggposgneg.
-0.4, -0.2, 0, 0.2, 0.4-0.4, -0.2, 0, 0.2, 0.4-0.4, -0.2, 0, 0.2, 0.40, 0.2, 0.4, 0.6, 0.8, 1.0max,mean,min,val1,val2max,mean,min,val1,...,val8max,mean,min,val1,...,val16.
table 6: hyperparameters with each search space..type.
template.
to-asto-what.
rel-same.
what-to.
she-as.
as-what.
[w1] is to [w2] as [w3] is to [w4][w1] is to [w2] what [w3] is to [w4]the relation between [w1] and [w2]is the same as the relation between[w3] and [w4].
what [w1] is to [w2], [w3] is to [w4]she explained to him that [w1] isto [w2] as [w3] is to [w4]as i explained earlier, what [w1] isto [w2] is essentially the same aswhat [w3] is to [w4]..table 7: custom templates used in our experiments.
each has four placeholders [w1, ..., w4] and they are ful-ﬁlled by words from a relation pair..3621g.α.gpos.
gneg.
mask data.
table 8: the best conﬁguration of spmi score..data.
satu2u4googlebats.
satu2u4googlebats.
satu2u4googlebats.
data.
satu2u4googlebats.
satu2u4googlebats.
satu2u4googlebats.
treb.
2-tpg.atrebor.treb.
2-tpg.atrebor.val2val2val1val1val1.
val2val2val2val1val1.
minminval2val1max.
αh.
-0.20.0-0.20.40.0.
-0.4-0.2-0.2-0.20.4.
0.20.40.20.20.2.val12val5-0.4-0.4 mean meanval70.4 maxval11val1-0.4val1val11-0.4.val1val3-0.40.0val4val4-0.4 mean meanval110.0 meanval6val1-0.4.
-0.4min0.4 mean0.0 meanval1-0.4-0.4 mean.
val7val4val4val6val11.
αt.
gpos.
gneg.
-0.4val5val5-0.2 mean meanminval70.4val12val5-0.2minval80.0.
0.2val1val30.2 mean mean0.2 mean mean-0.4 mean meanval5val1-0.4.
0.20.40.20.2-0.2.val5val1val1val1val5.
val11val4val1val6val11.
β.
0.40.61.00.40.4.
0.60.60.60.40.4.
0.20.60.80.40.6.β.
0.20.80.40.60.4.
0.80.80.80.80.8.
0.20.40.40.20.4.t.what-towhat-torel-sameshe-asshe-as.
rel-samerel-samerel-sameas-whatrel-same.
as-whatwhat-toto-aswhat-towhat-to.
t.what-toshe-asto-asshe-aswhat-to.
rel-sameas-whatrel-samerel-samerel-same.
as-whatwhat-toas-whatwhat-towhat-to.
table 9: the best conﬁguration of smppl score..b additional ablation results.
we show a few more complementary results to ourmain experiments..treb.atrebor.head.
tail.
head.
tail.
gpos.
val5val5meanval5val5val3val7val4val7val7.
val5val5val7val5val5meanval7meanval7val7.
t.to-whatto-asto-asshe-asto-aswhat-toto-whatrel-sameas-whatto-as.
as-whatrel-sameshe-aswhat-toshe-aswhat-torel-samewhat-toas-whatwhat-to.
satu2u4googlebatssatu2u4googlebats.
satu2u4googlebatssatu2u4googlebats.
table 10: the best conﬁgurations for hypothesis-onlyscores..ble 11 shows the test accuracy on each dataset.
asone can see, ap scores outperform other methodswith a great margin..score.
sat u2 u4 google bats.
treb.embedding 24.0 22.4 26.6mask pmi 25.2 23.3 31.5spmi40.4 42.5 27.8smppl41.8 44.7 41.2.a embedding 40.4 42.5 27.8tmask pmi 43.0 36.8 39.4rebspmi51.3 49.1 38.7orsmppl53.4 58.3 57.4.
28.261.287.088.8.
87.069.292.493.6.
28.346.268.167.9.
68.158.377.278.4.table 11: test accuracy tuned on each validation set..b.1 alternative scoring functions.
as alternative scoring functions for lm, we havetried two other scores: pmi score based on maskedtoken prediction (davison et al., 2019) (mask pmi)and cosine similarity between the embedding dif-ference of a relation pair similar to what used inword-embedding models.
for embedding method,we give a prompted sentence to lm to get the lastlayer’s hidden state for each word in the given pairand we take the difference between them, which weregard as the embedding vector for the pair.
finallywe pick up the most similar candidate in terms ofthe cosine similarity with the query embedding.
ta-.
b.2 parameter sensitivity: template type t.figure 5 shows the box plot of relative improve-ment across all datasets grouped by t and the re-sults indicate that there is a mild trend that certaintemplates tend to perform well, but not signiﬁcantuniversal selectivity can be found across datasets..b.3 parameter sensitivity: aggregation.
method gneg.
figure 6 shows the box plot of relative improve-ment across all datasets grouped by gneg.
unlikegpos we show in figure 3, they do not give a strongsignals over datasets..3622figure 5: box plot of the relative improvement ontest accuracy in each dataset over all conﬁgurations ofsmppl grouped by template type..figure 7: bats (top) and google (bottom) results splitby high-level categories..presumably chosen because water is assumed tobe a near-synonym of food.
in the third example(wrench:tool), the hypnernymy relation is confusedwith a meronymy relation in the selected candidatetree:forest.
in the last three examples, the modelhas selected answers which seem reasonable.
in thefourth example, beautiful:pretty, terrible:bad andbrave:valiant can all be considered to be synonympairs.
in the ﬁfth example, vehicle:transport isclearly the correct answer, but the pair song:singis nonetheless relationally similar to shield:protect.
in the last example, we can think of being sad asan emotional state, like being sick is a health state,which provides some justiﬁcation for the predictedanswer.
on the other hand, the gold answer is basedon the argument that someone who is sick lackshealth like someone who is scared lacks courage..figure 6: box plot of the relative improvement ontest accuracy in each dataset over all conﬁgurations ofsmppl grouped by gneg.
here valk corresponds to kthpositive permutation shown in figure 2..b.4 relation types in bats/google.
figure 7 shows the results of different languagemodels with the smppl scoring function on the dif-ferent categories of the bats and google datasets..c error analysis.
table 12 shows all examples from the u2 datasetof the easiest difﬁculy (i.e.
grade 4), which weremisclassiﬁed by roberta, with smppl tuned onthe validation set.
we can see a few typical issueswith word embeddings and language models.
forinstance, in the ﬁrst example, the model confusesthe antonym pair right:wrong with synonymy.
inthe second example, we have that someone who ispoor lacks money, while someone who is hungrylacks food.
however, the selected candidate pairis hungy:water rather than hungry:food, which is.
3623query.
candidates.
hilarious:funny.
poor:money.
wrench:tool.
right:wrong, hard:boring, nice:crazy,great:good.
tired:energy, angry:emotion, hot:ice,hungry:water.
cow:milk, radio:sound, tree:forest,carrot:vegetable.
beautiful:pretty.
terrible:bad, brave:valiant, new:old,tall:skinny.
shield:protect.
computer:talk, vehicle:transport,pencil:make, song:sing.
sick:health.
sad:emotion, tall:intelligence,scared:courage, smart:energy.
table 12: model prediction examples from robertawith smppl tuned on the validation set.
gold answersare shown in bold, while the model predictions are un-derlined..3624