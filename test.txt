section TITLE
id pdf2json/2021.acl-long.245.pdf.json
from O
machine O
translation O
to O
code-switching O
: O
generating O
high-quality O
code-switched O
text O

section ABSTRACT
id pdf2json/2021.acl-long.245.pdf.json
generating O
code-switched O
text O
is O
a O
problem O
of O
growing O
interest O
, O
especially O
given O
the O
scarcity O
of O
corpora O
containing O
large O
volumes O
of O
real O
code-switched O
text O
. O

section ABSTRACT
id pdf2json/2021.acl-long.245.pdf.json
in O
this O
work O
, O
we O
adapt O
a O
state-of-the-art O
neural O
machine O
translation O
model O
to O
generate O
hindi-english O
codeswitched O
sentences O
starting O
from O
monolingual O
hindi O
sentences O
. O

section ABSTRACT
id pdf2json/2021.acl-long.245.pdf.json
we O
outline O
a O
carefully O
designed O
curriculum O
of O
pretraining O
steps O
, O
including O
the O
use O
of O
synthetic O
code-switched O
text O
, O
that O
enable O
themodel O
to O
generate O
high-quality O
codeswitched O
text O
. O

section ABSTRACT
id pdf2json/2021.acl-long.245.pdf.json
using O
text O
generated O
from O
our O
model O
as O
data O
augmentation O
, O
we O
show O
significant O
reductions O
in O
perplexity O
on O
a O
language O
modeling O
task O
, O
compared O
to O
using O
text O
from O
other O
generative O
models O
of O
cs O
text O
. O

section ABSTRACT
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
show O
improvements O
using O
our O
text O
for O
a O
downstream O
code-switched O
natural O
language O
inference O
task O
. O

section ABSTRACT
id pdf2json/2021.acl-long.245.pdf.json
our O
generated O
text O
is O
further O
subjected O
to O
a O
rigorous O
evaluation O
using O
a O
human O
evaluation O
study O
and O
a O
range O
of O
objective O
metrics O
, O
where O
we O
show O
performance O
comparable O
( O
and O
sometimes O
even O
superior O
) O
to O
codeswitched O
text O
obtained O
via O
crowd O
workers O
who O
are O
native O
hindi O
speakers O
. O

section 0
id pdf2json/2021.acl-long.245.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
3154–3169 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.245.pdf.json
©2021 O
association O
for O
computational O
linguistics O
3154 O

section 1
id pdf2json/2021.acl-long.245.pdf.json
code-switching O
( O
cs O
) O
refers O
to O
the O
linguistic O
phenomenon O
of O
using O
more O
than O
one O
language O
within O
a O
single O
sentence O
or O
conversation O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
cs O
appears O
naturally O
in O
conversational O
speech O
among O
multilingual O
speakers O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
the O
main O
challenge O
with O
building O
models O
for O
conversational O
cs O
text O
is O
that O
we O
do O
not O
have O
access O
to O
large O
amounts O
of O
cs O
text O
that O
is O
conversational O
in O
style O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
one O
might O
consider O
using O
social O
media O
text O
that O
contains O
cs O
and O
is O
more O
readily O
available O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
however O
, O
the O
latter O
is O
quite O
different O
from O
conversational O
cs O
text O
in O
its O
vocabulary O
( O
e.g. O
, O
due O
to O
the O
frequent O
use O
of O
abbreviated O
slang O
terms O
, O
∗work O
done O
while O
first O
two O
authors O
were O
students O
at O
iit O
bombay O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
hashtags O
and O
mentions O
) O
, O
in O
its O
sentence O
structure O
( O
e.g. O
, O
due O
to O
character O
limits O
in O
tweets O
) O
and O
in O
its O
word O
forms O
( O
e.g. O
, O
due O
to O
transliteration O
being O
commonly O
employed O
in O
social O
media O
posts O
) O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
this O
motivates O
the O
need O
for O
a O
generative O
model O
of O
realistic O
cs O
text O
that O
can O
be O
sampled O
to O
subsequently O
train O
models O
for O
cs O
text O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
in O
this O
work O
, O
we O
tackle O
the O
problem O
of O
generating O
high-quality O
cs O
text O
using O
only O
limited O
amounts O
of O
real O
cs O
text O
during O
training O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
assume O
access O
to O
large O
amounts O
of O
monolingual O
text O
in O
the O
component O
languages O
and O
parallel O
text O
in O
both O
languages O
, O
which O
is O
a O
reasonable O
assumption O
to O
make O
for O
many O
of O
the O
world O
’ O
s O
languages O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
focus O
on O
hindi-english O
cs O
text O
where O
the O
matrix O
( O
dominant O
) O
language O
is O
hindi O
and O
the O
embedded O
language O
is O
english.1 O
rather O
than O
train O
a O
generative O
model O
, O
we O
treat O
this O
problem O
as O
a O
translation O
task O
where O
the O
source O
and O
target O
languages O
are O
monolingual O
hindi O
text O
and O
hindi-english O
cs O
text O
, O
respectively O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
use O
the O
monolingual O
hindi O
text O
to O
construct O
synthetic O
cs O
sentences O
using O
simple O
techniques O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
show O
that O
synthetic O
cs O
text O
, O
albeit O
being O
naive O
in O
its O
construction O
, O
plays O
an O
important O
role O
in O
improving O
our O
model O
’ O
s O
ability O
to O
capture O
cs O
patterns O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
draw O
inspiration O
from O
the O
large O
body O
of O
recent O
work O
on O
unsupervised O
machine O
translation O
( O
lample O
et O
al. O
, O
2018a O
, O
b O
) O
to O
design O
our O
model O
, O
which O
will O
henceforth O
be O
referred O
to O
as O
translation O
for O
code-switching O
, O
or O
tcs O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
tcs O
, O
once O
trained O
, O
will O
convert O
a O
monolingual O
hindi O
sentence O
into O
a O
hindi-english O
cs O
sentence O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
tcs O
makes O
effective O
use O
of O
parallel O
text O
when O
it O
is O
available O
and O
uses O
backtranslation-based O
objective O
functions O
with O
monolingual O
text O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
1given O
the O
non-trivial O
effort O
involved O
in O
collecting O
annotations O
from O
professional O
annotators O
and O
crowd O
workers O
, O
we O
focused O
on O
a O
single O
language O
pair O
( O
hindi-english O
) O
and O
leave O
explorations O
on O
more O
language O
pairs O
for O
future O
work O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
below O
, O
we O
summarize O
our O
main O
contributions O
: O
1 O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
propose O
a O
state-of-the-art O
translation O
model O
that O
generates O
hindi-english O
cs O
text O
starting O
from O
monolingual O
hindi O
text O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
this O
model O
requires O
very O
small O
amounts O
of O
real O
cs O
text O
, O
uses O
both O
supervised O
and O
unsupervised O
training O
objectives O
and O
considerably O
benefits O
from O
a O
carefully O
designed O
training O
curriculum O
, O
that O
includes O
pretraining O
with O
synthetically O
constructed O
cs O
sentences O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
2 O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
introduce O
a O
new O
hindi-english O
cs O
text O
corpus O
in O
this O
work.2 O
each O
cs O
sentence O
is O
accompanied O
by O
its O
monolingual O
hindi O
translation O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
designed O
a O
crowdsourcing O
task O
to O
collect O
cs O
variants O
of O
monolingual O
hindi O
sentences O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
the O
crowdsourced O
cs O
sentences O
were O
manually O
verified O
and O
form O
a O
part O
of O
our O
new O
dataset O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
3 O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
use O
sentences O
generated O
from O
our O
model O
to O
train O
language O
models O
for O
hindi-english O
cs O
text O
and O
show O
significant O
improvements O
in O
perplexity O
compared O
to O
other O
approaches O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
4 O
. O

section 1
id pdf2json/2021.acl-long.245.pdf.json
we O
present O
a O
rigorous O
evaluation O
of O
the O
quality O
of O
our O
generated O
text O
using O
multiple O
objective O
metrics O
and O
a O
human O
evaluation O
study O
, O
and O
they O
clearly O
show O
that O
the O
sentences O
generated O
by O
our O
model O
are O
superior O
in O
quality O
and O
successfully O
capture O
naturally O
occurring O
cs O
patterns O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
early O
approaches O
of O
language O
modeling O
for O
codeswitched O
text O
included O
class-based O
n-gram O
models O
( O
yeh O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
) O
, O
factored O
language O
models O
that O
exploited O
a O
large O
number O
of O
syntactic O
and O
semantic O
features O
( O
adel O
et O
al. O
, O
2015 O
) O
, O
and O
recurrent O
neural O
language O
models O
( O
adel O
et O
al. O
, O
2013 O
) O
for O
cs O
text O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
all O
these O
approaches O
relied O
on O
access O
to O
real O
cs O
text O
to O
train O
the O
language O
models O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
towards O
alleviating O
this O
dependence O
on O
real O
cs O
text O
, O
there O
has O
been O
prior O
work O
on O
learning O
code-switched O
language O
models O
from O
bilingual O
data O
( O
li O
and O
fung O
, O
2014b O
, O
a O
; O
garg O
et O
al. O
, O
2018b O
) O
and O
a O
more O
recent O
direction O
that O
explores O
the O
possibility O
of O
generating O
synthetic O
cs O
sentences O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
pratapa O
et O
al. O
, O
2018 O
) O
presents O
a O
technique O
to O
generate O
synthetic O
cs O
text O
that O
grammatically O
adheres O
to O
a O
linguistic O
theory O
2the O
new O
dataset O
and O
relevant O
code O
is O
available O
at O
: O
https O
: O
//www.cse.iitb.ac.in/~pjyothi/tcs O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
of O
code-switching O
known O
as O
the O
equivalence O
constraint O
( O
ec O
) O
theory O
( O
poplack O
, O
1979 O
; O
sankoff O
, O
1998 O
) O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
lee O
and O
li O
( O
2020 O
) O
proposed O
a O
bilingual O
attention O
language O
model O
for O
cs O
text O
trained O
solely O
using O
a O
parallel O
corpus O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
another O
recent O
line O
of O
work O
has O
explored O
neural O
generative O
models O
for O
cs O
text O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
garg O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2018a O
) O
use O
a O
sequence O
generative O
adversarial O
network O
( O
seqgan O
( O
yu O
et O
al. O
, O
2017 O
) O
) O
trained O
on O
real O
cs O
text O
to O
generate O
sentences O
that O
are O
used O
to O
aid O
language O
model O
training O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
another O
gan-based O
method O
proposed O
by O
chang O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2019 O
) O
aims O
to O
predict O
the O
probability O
of O
switching O
at O
each O
token O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
winata O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2018 O
) O
and O
winata O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2019 O
) O
use O
a O
sequence-to-sequence O
model O
enabled O
with O
a O
copy O
mechanism O
( O
pointer O
network O
( O
vinyals O
et O
al. O
, O
2015 O
) O
) O
to O
generate O
cs O
data O
by O
leveraging O
parallel O
monolingual O
translations O
from O
a O
limited O
source O
of O
cs O
data O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
samanta O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2019 O
) O
proposed O
a O
hierarchical O
variational O
autoencoder-based O
model O
tailored O
for O
code-switching O
that O
takes O
into O
account O
both O
syntactic O
information O
and O
language O
switching O
signals O
via O
the O
use O
of O
language O
tags O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
we O
present O
a O
comparison O
of O
tcs O
with O
both O
samanta O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2019 O
) O
and O
garg O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2018a O
) O
in O
section O
5.2.1 O
. O
) O

section 2
id pdf2json/2021.acl-long.245.pdf.json
in O
a O
departure O
from O
using O
generative O
models O
for O
cs O
text O
, O
we O
view O
this O
problem O
as O
one O
of O
sequence O
transduction O
where O
we O
train O
a O
model O
to O
convert O
a O
monolingual O
sentence O
into O
its O
cs O
counterpart O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
chang O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2019 O
) O
; O
gao O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
( O
2019 O
) O
use O
gan-based O
models O
to O
modify O
monolingual O
sentences O
into O
cs O
sentences O
, O
while O
we O
treat O
this O
problem O
of O
cs O
generation O
as O
a O
translation O
task O
and O
draw O
inspiration O
from O
the O
growing O
body O
of O
recent O
work O
on O
neural O
unsupervised O
machine O
translation O
models O
( O
lample O
et O
al. O
, O
2018a O
, O
b O
) O
to O
build O
an O
effective O
model O
of O
cs O
text O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
the O
idea O
of O
using O
translation O
models O
for O
codeswitching O
has O
been O
explored O
in O
early O
work O
( O
vu O
et O
al. O
, O
2012 O
; O
li O
and O
fung O
, O
2013 O
; O
dhar O
et O
al. O
, O
2018 O
) O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
concurrent O
with O
our O
work O
, O
there O
have O
been O
efforts O
towards O
building O
translation O
models O
from O
english O
to O
cs O
text O
( O
solorio O
et O
al. O
, O
2021 O
) O
and O
cs O
text O
to O
english O
( O
gupta O
et O
al. O
, O
2021 O
) O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
while O
these O
works O
focus O
on O
translating O
from O
the O
embedded O
language O
( O
english O
) O
to O
the O
cs O
text O
or O
vice-versa O
, O
our O
approach O
starts O
with O
sentences O
in O
thematrix O
language O
( O
hindi O
) O
which O
is O
the O
more O
dominant O
language O
in O
the O
cs O
text O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
also O
, O
ours O
is O
the O
first O
work O
, O
to O
our O
knowledge O
, O
to O
repurpose O
an O
unsupervised O
neural O
machine O
translation O
model O
to O
translate O
monolingual O
sentences O
into O
cs O
text O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
powerful O
pretrained O
models O
like O
mbart O
( O
liu O
et O
al. O
, O
2020 O
) O
have O
been O
used O
for O
codemixed O
translation O
tasks O
in O
concurrent O
work O
( O
gautam O
et O
al. O
, O
2021 O
) O
. O

section 2
id pdf2json/2021.acl-long.245.pdf.json
we O
will O
further O
explore O
the O
use O
of O
synthetic O
text O
with O
such O
models O
as O
part O
of O
future O
work O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
figure O
1 O
shows O
the O
overall O
architecture O
of O
our O
model O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
this O
is O
largely O
motivated O
by O
prior O
work O
on O
unsupervised O
neural O
machine O
translation O
( O
lample O
et O
al. O
, O
2018a O
, O
b O
) O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
the O
model O
comprises O
of O
three O
layers O
of O
stacked O
transformer O
( O
vaswani O
et O
al. O
, O
2017 O
) O
encoder O
and O
decoder O
layers O
, O
two O
of O
which O
are O
shared O
and O
the O
remaining O
layer O
is O
private O
to O
each O
language O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
monolingual O
hindi O
( O
i.e O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
the O
source O
language O
) O
has O
its O
own O
private O
encoder O
and O
decoder O
layers O
( O
denoted O
by O
encp0 O
and O
decp0 O
, O
respectively O
) O
while O
english O
and O
hindi-english O
cs O
text O
jointly O
make O
use O
of O
the O
remaining O
private O
encoder O
and O
decoder O
layers O
( O
denoted O
by O
encp1 O
and O
decp1 O
, O
respectively O
) O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
in O
our O
model O
, O
the O
target O
language O
is O
either O
english O
or O
cs O
text O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
ideally O
, O
we O
would O
like O
encp1 O
and O
decp1 O
to O
be O
trained O
only O
using O
cs O
text O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
however O
, O
due O
to O
the O
paucity O
of O
cs O
text O
, O
we O
also O
use O
text O
in O
the O
embedded O
language O
( O
i.e O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
english O
) O
to O
train O
these O
layers O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
next O
, O
we O
outline O
the O
three O
main O
training O
steps O
of O
tcs O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
( O
i O
) O
denoising O
autoencoding O
( O
dae O
) O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
we O
use O
monolingual O
text O
in O
each O
language O
to O
estimate O
language O
models O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
in O
lample O
et O
al O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
( O
2018b O
) O
, O
this O
is O
achieved O
via O
denoising O
autoencoding O
where O
an O
autoencoder O
is O
used O
to O
reconstruct O
a O
sentence O
given O
a O
noisy O
version O
as O
its O
input O
whose O
structure O
is O
altered O
by O
dropping O
and O
swapping O
words O
arbitrarily O
( O
lample O
et O
al. O
, O
2018a O
) O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
the O
loss O
incurred O
in O
this O
step O
is O
denoted O
by O
ldae O
and O
is O
composed O
of O
two O
terms O
based O
on O
the O
reconstruction O
of O
the O
source O
and O
target O
language O
sentences O
, O
respectively O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
( O
ii O
) O
backtranslation O
( O
bt O
) O
: O
once O
the O
layers O
are O
initialized O
, O
one O
can O
use O
non-parallel O
text O
in O
both O
languages O
to O
generate O
a O
pseudo-parallel O
corpus O
of O
backtranslated O
pairs O
( O
sennrich O
et O
al. O
, O
2015 O
) O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
that O
is O
, O
a O
corpus O
of O
parallel O
text O
is O
constructed O
by O
translating O
sentences O
in O
the O
source O
language O
via O
the O
pipeline O
, O
encp0 O
, O
encsh O
, O
decsh O
and O
decp1 O
, O
and O
translating O
target O
sentences O
back O
to O
the O
source O
language O
via O
encp1 O
, O
encsh O
, O
decsh O
and O
decp0 O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
the O
backtranslation O
loss O
lbt O
is O
composed O
of O
crossentropy O
losses O
from O
using O
these O
pseudo-parallel O
sentences O
in O
both O
directions O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
( O
iii O
) O
cross-entropy O
loss O
( O
ce O
) O
: O
both O
the O
previous O
steps O
used O
unsupervised O
training O
objectives O
and O
make O
use O
of O
non-parallel O
text O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
with O
access O
to O
parallel O
text O
, O
one O
can O
use O
the O
standard O
supervised O
cross-entropy O
loss O
( O
denoted O
by O
lce O
) O
to O
train O
the O
translation O
models O
( O
i.e O
. O

section 3
id pdf2json/2021.acl-long.245.pdf.json
going O
from O
encp0 O
to O
decp1 O
and O
encp1 O
to O
decp0 O
via O
the O
common O
shared O
layers O
) O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
apart O
from O
the O
use O
of O
parallel O
text O
and O
monolingual O
text O
employed O
in O
training O
tcs O
, O
we O
also O
construct O
large O
volumes O
of O
synthetic O
cs O
text O
using O
two O
simple O
techniques O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
this O
synthetic O
cs O
text O
is O
nonparallel O
and O
is O
used O
to O
optimize O
both O
ldae O
and O
lbt O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
the O
role O
of O
the O
synthetic O
cs O
text O
is O
to O
expose O
tcs O
to O
various O
cs O
patterns O
( O
even O
if O
noisy O
) O
, O
thereby O
encouraging O
the O
model O
to O
code-switch O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
the O
final O
step O
of O
finetuning O
using O
all-cs O
enables O
model O
to O
mimic O
switching O
patterns O
of O
real O
cs O
texts O
the O
first O
technique O
( O
named O
lex O
) O
is O
a O
simple O
heuristic-based O
technique O
that O
constructs O
a O
cs O
sentence O
by O
traversing O
a O
hindi O
sentence O
and O
randomly O
replacing O
a O
word O
by O
its O
english O
translation O
using O
a O
bilingual O
lexicon O
( O
conneau O
et O
al. O
, O
2017 O
) O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
the O
probability O
of O
replacing O
a O
word O
is O
chosen O
to O
match O
the O
switching O
distribution O
in O
real O
cs O
text O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
the O
second O
technique O
( O
named O
emt O
) O
is O
more O
linguistically O
aware O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
following O
the O
methodology O
proposed O
by O
bhat O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
( O
2016 O
) O
that O
is O
based O
on O
the O
embedded O
matrix O
theory O
( O
emt O
) O
for O
code-switching O
, O
we O
apply O
clause O
substitution O
methods O
to O
monolingual O
text O
to O
construct O
synthetic O
cs O
text O
. O

section 4
id pdf2json/2021.acl-long.245.pdf.json
from O
inspecting O
english O
parse O
trees O
, O
we O
found O
that O
replacing O
embedded O
sentence O
clauses O
or O
subordinate O
clauses O
with O
their O
hindi O
translations O
would O
likely O
produce O
cs O
text O
that O
appears O
somewhat O
natural O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
we O
introduce O
a O
new O
hindi-english O
cs O
dataset O
, O
that O
we O
will O
refer O
to O
as O
all-cs O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
it O
is O
partitioned O
into O
two O
subsets O
, O
movie-cs O
and O
treebank-cs O
, O
based O
on O
their O
respective O
sources O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
movie-cs O
consists O
of O
conversational O
hindi-english O
cs O
text O
extracted O
from O
30 O
contemporary O
bollywood O
scripts O
that O
were O
publicly O
available.3 O
the O
hindi O
words O
in O
these O
sentences O
were O
all O
romanized O
with O
potentially O
multiple O
non-canonical O
forms O
existing O
for O
the O
same O
hindi O
token O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
we O
employed O
a O
professional O
annotation O
company O
to O
convert O
the O
romanized O
hindi O
words O
into O
their O
respective O
backtransliterated O
forms O
rendered O
in O
devanagari O
script O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
asked O
the O
annotators O
to O
provide O
monolingual O
hindi O
translations O
for O
all O
these O
sentences O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
using O
these O
monolingual O
hindi O
sentences O
as O
a O
starting O
point O
, O
we O
additionally O
crowdsourced O
for O
cs O
sentences O
via O
amazon O
’ O
s O
mechanical O
turk O
( O
mturk O
) O
( O
amazon O
, O
2005 O
) O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
table O
1 O
shows O
two O
hindi O
sentences O
frommovie-cs O
and O
treebank-cs O
, O
along O
with O
the O
different O
variants O
of O
cs O
sentences O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
turkers O
were O
asked O
to O
convert O
a O
monolingual O
hindi O
sentence O
into O
a O
natural-sounding O
cs O
variant O
that O
was O
semantically O
identical O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
each O
turker O
had O
to O
work O
on O
five O
hindi O
sentences O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
we O
developed O
a O
web O
interface O
using O
which O
turkers O
could O
easily O
copy O
parts O
of O
the O
hindi O
sentence O
they O
wanted O
to O
retain O
and O
splice O
in O
english O
segments O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
more O
details O
about O
this O
interface O
, O
the O
crowdsourcing O
task O
and O
worker O
statistics O
are O
available O
in O
appendix O
a. O
all-cs O
comprises O
a O
second O
subset O
of O
cs O
sentences O
, O
treebank-cs O
, O
that O
was O
crowdsourcing O
usingmturk O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
we O
extracted O
5292monolingual O
hindi O
sentences O
( O
with O
sentence O
lengths O
less O
than O
or O
equal O
to O
15 O
words O
) O
from O
the O
publicly O
available O
hindi O
dependency O
treebank O
that O
contains O
dependency O
parses.4 O
these O
annotations O
parse O
each O
hindi O
sentence O
into O
chunks O
, O
where O
a O
chunk O
is O
defined O
as O
3https O
: O
//www.filmcompanion.in/category/fc-pro/scripts/ O
https O
: O
//moifightclub.com/category/scripts/ O
4http O
: O
//ltrc.iiit.ac.in/treebank_h2014/ O
a O
minimal O
, O
non O
recursive O
phrase O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
turkers O
were O
asked O
to O
convert O
at O
least O
one O
hindi O
chunk O
into O
english O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
this O
was O
done O
in O
an O
attempt O
to O
elicit O
longer O
spans O
of O
english O
segments O
within O
each O
sentence O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
figure O
2 O
shows O
the O
sentence O
length O
distributions O
for O
movie-cs O
and O
treebank-cs O
, O
along O
with O
histograms O
accumulating O
english O
segments O
of O
different O
lengths O
in O
both O
subsets O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
we O
clearly O
see O
a O
larger O
fraction O
of O
english O
segments O
with O
lengths O
within O
the O
range O
[ O
2-6 O
] O
in O
treebank-cs O
compared O
to O
movie-cs O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
table O
2 O
provides O
detailed O
statistics O
of O
the O
new O
cs O
dataset O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
report O
two O
metrics O
proposed O
by O
guzmán O
et O
al O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
( O
2017 O
) O
to O
measure O
the O
amount O
of O
code-switching O
present O
in O
this O
new O
corpus O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
monolingual O
index O
( O
m-index O
) O
is O
a O
value O
between O
0 O
and O
1 O
that O
quantifies O
the O
amount O
of O
mixing O
between O
languages O
( O
0 O
denotes O
a O
purelymonolingual O
corpus O
and O
1 O
denotes O
equal O
mixing O
from O
both O
languages O
) O
and O
i-index O
measures O
the O
fraction O
of O
switching O
points O
in O
the O
corpus O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
we O
observe O
treebank-cs O
exhibits O
higher O
m-index O
and O
i-index O
values O
compared O
to O
movie-cs O
indicating O
more O
code-switching O
overall O
. O

section 6
id pdf2json/2021.acl-long.245.pdf.json
all-cs O
also O
contains O
a O
non-trivial O
number O
of O
named O
entities O
( O
nes O
) O
which O
are O
replaced O
by O
an O
ne O
tag O
in O
all O
our O
language O
modeling O
experiments O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
parallel O
hindi-english O
text O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
as O
described O
in O
section O
5 O
, O
tcs O
uses O
parallel O
text O
for O
supervised O
training O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
for O
this O
purpose O
, O
we O
use O
the O
iit O
bombay O
english-hindi O
corpus O
( O
kunchukuttan O
et O
al. O
, O
2017 O
) O
containing O
parallel O
hindi-english O
text O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
construct O
a O
larger O
parallel O
corpus O
using O
text O
from O
the O
opensubtitles O
( O
opsub O
) O
corpus O
( O
lison O
and O
tiedemann O
, O
2016 O
) O
that O
is O
more O
conversational O
and O
hence O
more O
similar O
in O
style O
to O
movie-cs O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
we O
chose O
~1 O
million O
english O
sentences O
( O
opsub-en O
) O
, O
where O
each O
sentence O
contained O
an O
embedded O
clause O
or O
a O
subordinate O
clause O
to O
support O
the O
construction O
of O
emt O
lines O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
we O
used O
the O
google O
translate O
api O
to O
obtain O
hindi O
translations O
for O
all O
these O
sentences O
( O
opsub-hi O
) O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
henceforth O
, O
we O
use O
opsub O
to O
refer O
to O
this O
parallel O
corpus O
of O
opsub-en O
paired O
with O
opsub-hi O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
we O
extracted O
318k O
sentences O
from O
the O
iitb O
corpus O
after O
thresholding O
on O
length O
( O
5-15 O
) O
and O
considering O
overlap O
in O
vocabulary O
with O
opsub O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
( O
one O
could O
avoid O
the O
use O
of O
an O
external O
service O
like O
google O
translate O
and O
use O
existing O
parallel O
text O
( O
zhang O
et O
al. O
, O
2020 O
) O
) O
in O
conjunction O
with O
a O
word O
aligner O
to O
construct O
emt O
lines O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
opsub O
, O
being O
more O
conversational O
in O
style O
, O
turns O
out O
to O
be O
a O
better O
pretraining O
corpus O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
a O
detailed O
comparison O
of O
these O
choices O
is O
described O
in O
appendix O
h. O
) O
synthetic O
cs O
datasets O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
as O
mentioned O
in O
section O
3.1 O
, O
we O
use O
two O
simple O
techniques O
lex O
and O
emt O
to O
generate O
synthetic O
cs O
text O
, O
which O
in O
turn O
is O
used O
to O
train O
tcs O
in O
an O
unsupervised O
training O
phase O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
for O
each O
hindi O
monolingual O
sentence O
in O
opsub O
, O
we O
generate O
two O
lex O
and O
two O
emt O
synthetic O
cs O
sentences O
giving O
us O
opsub-lex O
and O
opsub-emt O
, O
respectively O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
generate O
five O
lex O
and O
five O
emt O
lines O
for O
each O
monolingual O
sentence O
in O
all-cs O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
in O
order O
to O
generate O
emt O
lines O
, O
we O
first O
translate O
the O
monolingual O
hindi O
sentences O
in O
all-cs O
to O
english O
using O
google O
translate O
and O
then O
follow O
the O
emt O
generation O
scheme O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
this O
results O
in O
two O
datasets O
, O
all-cs-lex O
and O
all-cs-emt O
, O
which O
appear O
in O
later O
evaluations O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
( O
appendix O
b O
contains O
more O
details O
about O
emt O
applied O
to O
opus O
and O
all-cs O
. O
) O

section 7
id pdf2json/2021.acl-long.245.pdf.json
datasets O
from O
existing O
approaches O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
( O
i O
) O
vacs O
( O
samanta O
et O
al. O
, O
2019 O
) O
is O
a O
hierarchical O
variational O
autoencoder-based O
model O
designed O
to O
generate O
cs O
text O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
we O
train O
two O
vacs O
models O
, O
one O
on O
all-cs O
( O
vacsv1 O
) O
and O
the O
other O
on O
opsub-emt O
followed O
by O
all-cs O
( O
vacsv2 O
) O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
( O
ii O
) O
garg O
et O
al O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
( O
2018a O
) O
use O
seqgan O
( O
yu O
et O
al. O
, O
2017 O
) O
– O
a O
gan-based O
sequence O
generation O
model O
– O
to O
generate O
cs O
sentences O
by O
providing O
an O
rnnlm O
as O
the O
generator O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
as O
with O
vacs O
, O
we O
train O
two O
seqgan5 O
models O
, O
one O
on O
all-cs O
( O
seqganv1 O
) O
and O
one O
on O
opsub-emt O
followed O
by O
all-cs O
( O
seqganv2 O
) O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
samples O
are O
drawn O
from O
both O
seqgan O
and O
vacs O
by O
first O
drawing O
a O
random O
sample O
from O
the O
standard O
normal O
distribution O
in O
the O
learned O
latent O
space O
and O
then O
decoding O
via O
an O
rnn-based O
generator O
for O
seqgan O
and O
a O
vae-based O
decoder O
for O
vacs O
. O

section 7
id pdf2json/2021.acl-long.245.pdf.json
we O
sample O
~2m O
lines O
for O
each O
dataset O
to O
match O
the O
size O
of O
the O
other O
synthetic O
datasets O
. O

section 8
id pdf2json/2021.acl-long.245.pdf.json
first O
, O
we O
investigate O
various O
training O
curricula O
to O
train O
tcs O
and O
identify O
the O
best O
training O
strategy O
by O
evaluating O
bleu O
scores O
on O
the O
test O
set O
of O
all-cs O
( O
§5.1 O
) O
. O

section 8
id pdf2json/2021.acl-long.245.pdf.json
next O
, O
we O
compare O
the O
output O
from O
tcs O
with O
synthetic O
cs O
text O
generated O
by O
other O
methods O
( O
§5.2 O
) O
. O

section 8
id pdf2json/2021.acl-long.245.pdf.json
we O
approach O
this O
via O
language O
modeling O
( O
§5.2.1 O
) O
, O
human O
evaluations O
( O
§5.2.2 O
) O
and O
two O
downstream O
tasks—natural O
language O
inference O
and O
sentiment O
analysis—involving O
real O
cs O
text O
( O
§5.2.3 O
) O
. O

section 8
id pdf2json/2021.acl-long.245.pdf.json
apart O
from O
these O
tasks O
, O
we O
also O
present O
four O
different O
objective O
evaluation O
metrics O
to O
evaluate O
synthetic O
cs O
text O
: O
bertscore O
, O
accuracy O
of O
a O
bert-based O
classifier O
and O
two O
diversity O
scores O
( O
§5.3 O
) O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
table O
3 O
shows O
the O
importance O
of O
various O
training O
curricula O
in O
training O
tcs O
; O
these O
models O
are O
evaluated O
using O
bleu O
( O
papineni O
et O
al. O
, O
2002 O
) O
scores O
computed O
with O
the O
ground-truth O
cs O
sentences O
for O
5https O
: O
//github.com/suragnair/seqgan O
the O
test O
set O
of O
all-cs.we O
start O
with O
supervised O
pretraining O
of O
tcs O
using O
the O
two O
parallel O
datasets O
we O
have O
in O
hand O
– O
iitb O
and O
opsub O
( O
system O
a O
) O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
a O
is O
then O
further O
finetuned O
with O
real O
cs O
text O
in O
allcs O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
the O
improvements O
in O
bleu O
scores O
moving O
from O
systemo O
( O
trained O
only O
on O
all-cs O
) O
to O
system O
b O
illustrate O
the O
benefits O
of O
pretraining O
tcs O
using O
hindi-english O
parallel O
text O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
systems O
c O
and O
d O
in O
table O
3 O
use O
our O
synthetic O
cs O
datasets O
opsub-lex O
and O
opsub-emt O
, O
respectively O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
these O
systems O
are O
further O
finetuned O
on O
allcs O
using O
both O
unsupervised O
and O
supervised O
training O
objectives O
to O
give O
c1 O
, O
c2 O
, O
d1 O
and O
d2 O
, O
respectively O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
comparing O
these O
four O
systems O
with O
system O
b O
shows O
the O
importance O
of O
using O
synthetic O
cs O
for O
pretraining O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
further O
, O
comparingc1 O
againstd1 O
and O
c2 O
against O
d2 O
, O
we O
observe O
that O
opsub-emt O
is O
indeed O
a O
better O
choice O
for O
pretraining O
compared O
to O
opsub-lex O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
also O
, O
supervised O
finetuning O
with O
allcs O
is O
clearly O
superior O
to O
unsupervised O
finetuning O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
henceforth O
, O
systemsd1 O
andd2 O
will O
be O
referred O
to O
as O
tcs O
( O
u O
) O
and O
tcs O
( O
s O
) O
, O
respectively O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
while O
having O
access O
to O
parallel O
cs O
data O
is O
an O
advantage O
, O
we O
argue O
that O
the O
benefits O
of O
having O
parallel O
data O
only O
marginally O
increase O
after O
a O
threshold O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
figure O
3 O
shows O
how O
bleu O
scores O
vary O
when O
changing O
the O
amount O
of O
parallel O
cs O
text O
used O
to O
traind2 O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
we O
observe O
that O
bleu O
increases O
substantially O
when O
we O
increase O
cs O
data O
from O
1000 O
lines O
to O
5000 O
lines O
, O
after O
which O
there O
is O
a O
trend O
of O
diminishing O
returns O
. O

section 9
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
find O
that O
d1 O
( O
that O
uses O
the O
data O
in O
all-cs O
as O
non-parallel O
text O
) O
is O
as O
good O
as O
the O
model O
trained O
using O
4000 O
lines O
of O
parallel O
text O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
we O
use O
text O
generated O
by O
our O
model O
to O
train O
a O
language O
model O
( O
lm O
) O
and O
evaluate O
perplexities O
on O
the O
test O
set O
of O
all-cs O
to O
show O
how O
closely O
sentences O
from O
tcs O
mimic O
real O
cs O
text O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
we O
use O
a O
state-of-the-art O
rnnlm O
model O
awd-lstmlm O
merity O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
( O
2018 O
) O
as O
a O
blackbox O
lm O
and O
only O
experiment O
with O
different O
training O
datasets O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
the O
model O
uses O
three O
lstm O
layers O
of O
1200 O
hidden O
units O
with O
weight O
tying O
and O
300-dimensional O
word O
embeddings O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
in O
initial O
runs O
, O
we O
trained O
our O
language O
model O
on O
the O
large O
parallel/synthetic O
cs O
datasets O
and O
finetuned O
on O
the O
all-cs O
data O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
however O
, O
this O
training O
strategy O
was O
prone O
to O
overfitting O
on O
all-cs O
data O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
to O
counter O
this O
problem O
of O
forgetting O
during O
the O
pretrain-finetuning O
steps O
, O
we O
adopted O
the O
mix-review O
strategy O
proposed O
by O
he O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
( O
2021 O
) O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
the O
training O
sentences O
from O
all-cs O
remain O
constant O
through O
the O
epochs O
and O
the O
amount O
of O
pretraining O
data O
is O
exponentially O
decayed O
with O
each O
epoch O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
this O
greatly O
alleviates O
the O
forgetting O
problem O
in O
our O
model O
, O
and O
leads O
to O
better O
overall O
perplexities O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
additional O
details O
about O
these O
lms O
are O
provided O
in O
appendix O
e. O
table O
4 O
shows O
test O
perplexities O
using O
different O
training O
curricula O
and O
data O
generated O
using O
two O
prior O
approaches O
, O
vacs O
and O
seqgan O
. O

section 11
id pdf2json/2021.acl-long.245.pdf.json
sentences O
generated O
using O
tcs O
yield O
the O
largest O
reductions O
in O
test O
perplexities O
, O
compared O
to O
all O
other O
approaches O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
we O
evaluated O
the O
quality O
of O
sentences O
generated O
by O
tcs O
using O
a O
human O
evaluation O
study O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
we O
sampled O
150 O
sentences O
each O
, O
using O
both O
tcs O
( O
u O
) O
and O
tcs O
( O
s O
) O
, O
starting O
from O
monolingual O
hindi O
sentences O
in O
the O
evaluation O
sets O
of O
all-cs O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
the O
sentences O
were O
chosen O
such O
that O
they O
were O
consistent O
with O
the O
length O
distribution O
of O
all-cs O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
for O
the O
sake O
of O
comparison O
, O
corresponding O
to O
the O
above-mentioned O
150 O
monolingual O
hindi O
samples O
, O
we O
also O
chose O
150 O
cs O
sentences O
each O
from O
all-cs-lex O
and O
allcs-emt O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
along O
with O
the O
ground-truth O
cs O
sentences O
from O
all-cs O
, O
this O
resulted O
in O
a O
total O
of O
750 O
sentences.6 O
these O
sentences O
were O
given O
to O
three O
linguistic O
experts O
in O
hindi O
and O
they O
were O
asked O
to O
provide O
scores O
ranging O
between O
1 O
and O
5 O
( O
1 O
for O
worst O
, O
5 O
for O
best O
) O
under O
three O
heads O
: O
“ O
syntactic O
correctness O
” O
, O
“ O
semantic O
correctness O
” O
and O
“ O
naturalness O
” O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
table O
5 O
shows O
that O
the O
sentences O
generated O
using O
tcs O
( O
s O
) O
and O
tcs O
( O
u O
) O
are O
far O
superior O
to O
the O
emt O
and O
lex O
sentences O
on O
all O
three O
criteria O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
tcs O
( O
s O
) O
is O
quite O
close O
in O
overall O
quality O
to O
the O
real O
sentences O
and O
tcs O
( O
u O
) O
fares O
worse O
, O
but O
only O
by O
a O
small O
margin O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
table O
6 O
shows O
some O
illustrative O
examples O
of O
code-switching O
using O
tcs O
( O
u O
) O
on O
test O
samples O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
show O
some O
examples O
of O
code-switching O
generated O
using O
moviecs O
मैं O
खुश O
हँू O
तुमने O
नो O
टस O
कया O
( O
i O
am O
glad O
you O
noticed O
) O
i O
am O
happy O
तुमने O
notice O
कया O
नह O
ं O
मैं O
तुमसे O
बहुत O
प्यार O
करता O
हँू O
सच O
में O
ले O
कन O
िसफर् O
एक O
दोस्त O
क O
तरह O
( O
no O
i O
really O
love O
you O
but O
just O
like O
a O
friend O
) O
नह O
ं O
i O
love O
you O
very O
much O
सच O
में O
but O
िसफर् O
एक O
friend O
क O
तरह O
within O
monolingual O
sentences O
from O
opsub O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
we O
observe O
that O
the O
model O
is O
able O
to O
introduce O
long O
contiguous O
spans O
of O
english O
words O
( O
e.g O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
“ O
meeting O
next O
week O
” O
, O
“ O
but O
it O
is O
clear O
” O
, O
etc O
. O
) O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
the O
model O
also O
displays O
the O
ability O
to O
meaningfully O
switch O
multiple O
times O
within O
the O
same O
sentence O
( O
e.g. O
, O
“ O
i O
love O
you O
very O
much O
” O
, O
“ O
but O
” O
, O
“ O
friend O
” O
) O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
there O
are O
also O
interesting O
cases O
of O
english O
segments O
that O
appear O
to O
be O
ungrammatical O
but O
make O
sense O
in O
the O
cs O
context O
( O
e.g. O
, O
“ O
because O
i O
know O
main O
dish O
” O
, O
etc O
. O

section 12
id pdf2json/2021.acl-long.245.pdf.json
) O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
gluecos O
( O
khanuja O
et O
al. O
, O
2020 O
) O
is O
an O
evaluation O
benchmark O
spanning O
six O
natural O
language O
tasks O
for O
code-switched O
english-hindi O
and O
english-spanish O
data O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
the O
authors O
observe O
that O
m-bert O
( O
pires O
et O
al. O
, O
2019 O
) O
consistently O
outperforms O
cross-lingual O
embedding O
techniques O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
furthermore O
, O
pretraining O
m-bert O
on O
small O
amounts O
of O
code-switched O
text O
improves O
its O
performance O
in O
most O
cases O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
for O
our O
evaluation O
, O
we O
select O
two O
tasks O
that O
require O
semantic O
understanding O
: O
natural O
language O
inference O
( O
nli O
) O
and O
sentiment O
analysis O
( O
sa O
) O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
we O
sample O
100k O
monolingual O
sentences O
from O
opsub-hi O
and O
select O
corresponding O
lex O
, O
emt O
and O
tcs O
( O
s O
) O
sentences O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
m-bert O
is O
then O
trained O
using O
the O
masked O
language O
modelling O
( O
mlm O
) O
objective O
on O
text O
from O
all O
4 O
systems O
( O
including O
opsub-hi O
) O
for O
2 O
epochs O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
train O
m-bert O
on O
21k O
sentences O
from O
all-cs O
( O
real O
cs O
) O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
finally O
, O
these O
pretrained O
models O
are O
fine-tuned O
on O
the O
selected O
gluecos O
tasks O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
( O
more O
details O
are O
in O
appendix O
g. O
) O
table O
7 O
lists O
the O
accuracies O
and O
f1 O
scores O
using O
different O
pretraining O
schemes O
for O
both O
nli O
and O
sentiment O
analysis O
, O
respectively O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
plain O
monolingual O
pretraining O
by O
itself O
leads O
to O
performance O
improvements O
on O
both O
tasks O
, O
presumably O
due O
to O
domain O
similarity O
betweengluecos O
( O
movie O
scripts O
, O
social O
media O
etc O
. O
) O

section 13
id pdf2json/2021.acl-long.245.pdf.json
and O
opsub O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
as O
mentioned O
in O
khanuja O
et O
al O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
( O
2020 O
) O
, O
pretraining O
on O
cs O
text O
further O
improves O
performance O
for O
both O
nli O
and O
sa O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
among O
the O
synthetic O
methods O
, O
tcs O
( O
s O
) O
has O
consistently O
better O
scores O
than O
lex O
and O
emt O
. O

section 13
id pdf2json/2021.acl-long.245.pdf.json
for O
sa O
, O
tcs O
( O
s O
) O
even O
outperforms O
pretraining O
on O
real O
cs O
text O
from O
all-cs O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
bertscore O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
bertscore O
( O
zhang* O
et O
al. O
, O
2020 O
) O
is O
a O
recently-proposed O
evaluation O
metric O
for O
text O
generation O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
similarity O
scores O
are O
computed O
between O
each O
token O
in O
the O
candidate O
sentence O
and O
each O
token O
in O
the O
reference O
sentence O
, O
using O
contextual O
bert O
embeddings O
( O
devlin O
et O
al. O
, O
2018 O
) O
of O
the O
tokens O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
we O
use O
this O
as O
an O
additional O
objective O
metric O
to O
evaluate O
the O
quality O
of O
the O
sentences O
generated O
using O
tcs O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
we O
use O
the O
real O
monolingual O
sentence O
as O
the O
reference O
and O
the O
generated O
cs O
sentence O
as O
the O
candidate O
, O
excluding O
sentences O
from O
tcs O
( O
s O
) O
and O
tcs O
( O
u O
) O
that O
exactly O
match O
the O
real O
sentence O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
since O
our O
data O
is O
hindi-english O
cs O
text O
, O
we O
use O
multilingual O
bert O
( O
m-bert O
) O
( O
pires O
et O
al. O
, O
2019 O
) O
for O
high-quality O
multilingual O
representations O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
table O
8 O
outlines O
our O
main O
results O
on O
the O
test O
set O
of O
all-cs O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
tcs O
sometimes O
generates O
purely O
monolingual O
sentences O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
this O
might O
unfairly O
tilt O
the O
scores O
in O
favour O
of O
tcs O
since O
the O
reference O
sentences O
are O
also O
monolingual O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
to O
discount O
for O
such O
biases O
, O
we O
remove O
sentences O
generated O
by O
tcs O
( O
u O
) O
and O
tcs O
( O
s O
) O
that O
are O
purely O
monolingual O
( O
row O
label O
“ O
mono O
” O
in O
bertscore O
) O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
sentences O
having O
< O
unk O
> O
tokens O
( O
labeled O
“ O
unk O
” O
) O
are O
also O
filtered O
out O
since O
these O
tokens O
are O
only O
generated O
by O
tcs O
for O
out-of-vocabulary O
words O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
“ O
unk O
& O
mono O
” O
refers O
to O
applying O
both O
these O
filters O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
emt O
lines O
consistently O
show O
the O
worst O
performance O
, O
which O
is O
primarily O
due O
to O
the O
somewhat O
poor O
quality O
of O
translations O
involved O
in O
generating O
these O
lines O
( O
refer O
to O
appendix O
b O
) O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
with O
removing O
both O
monolingual O
and O
< O
unk O
> O
tokens O
, O
we O
observe O
that O
tcs O
( O
u O
) O
and O
tcs O
( O
s O
) O
yield O
the O
highest O
bertscores O
, O
even O
outperforming O
the O
bertscore O
on O
real O
data O
obtained O
from O
the O
turkers O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
bert-based O
classifier O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
in O
this O
evaluation O
, O
we O
use O
m-bert O
( O
pires O
et O
al. O
, O
2019 O
) O
to O
build O
a O
classifier O
that O
distinguishes O
real O
cs O
sentences O
from O
synthetically O
generated O
ones O
( O
fake O
) O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
when O
subject O
to O
examples O
from O
high-quality O
generators O
, O
the O
classifier O
should O
find O
it O
hard O
to O
tell O
apart O
real O
from O
fake O
samples O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
we O
add O
a O
fully O
connected O
layer O
over O
the O
m-bert O
base O
architecture O
that O
takes O
the O
[ O
cls O
] O
token O
as O
its O
input O
to O
predict O
the O
probability O
of O
the O
sentence O
being O
real O
or O
fake O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
fake O
sentences O
are O
drawn O
from O
the O
union O
of O
tcs O
( O
u O
) O
, O
tcs O
( O
s O
) O
, O
all-cs-lex O
and O
all-cs-emt O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
in O
order O
to O
alleviate O
the O
class O
imbalance O
problem O
, O
we O
oversample O
the O
real O
sentences O
by O
a O
factor O
of O
5 O
and O
shuffle O
the O
data O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
the O
model O
converges O
after O
training O
for O
5 O
epochs O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
we O
see O
in O
table O
8 O
that O
the O
classification O
accuracy O
of O
whether O
a O
sample O
is O
fake O
or O
not O
is O
lowest O
for O
the O
outputs O
from O
tcs O
among O
the O
different O
generation O
techniques O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
measuring O
diversity O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
we O
are O
interested O
in O
finding O
out O
how O
diverse O
the O
predictions O
from O
tcs O
are O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
we O
propose O
a O
simplemeasure O
of O
diversity O
in O
the O
cs O
variants O
that O
is O
based O
on O
how O
effectively O
sentences O
can O
be O
compressed O
using O
the O
gzip O
utility.7 O
we O
considered O
using O
byte O
pair O
encoding O
( O
bpe O
) O
( O
gage O
, O
1994 O
) O
as O
a O
measure O
of O
data O
compression O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
however O
, O
bpe O
operates O
at O
the O
level O
of O
individual O
words O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
two O
word O
sequences O
“ O
w1 O
w2 O
w3 O
” O
and O
“ O
w3 O
w2 O
w1 O
” O
would O
be O
identically O
compressed O
by O
a O
bpe O
tokenizer O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
we O
would O
ideally O
like O
to O
account O
for O
such O
diversity O
and O
not O
discard O
this O
information O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
gzip O
uses O
lempel-ziv O
coding O
( O
ziv O
and O
lempel O
, O
1977 O
) O
that O
considers O
substrings O
of O
characters O
during O
compression O
, O
thus O
allowing O
for O
diversity O
in O
word O
ordering O
to O
be O
captured O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
our O
diversity O
measure O
d O
is O
simply O
the O
following O
: O
for O
a O
given O
set O
of O
cs O
sentences O
, O
run O
gzip O
on O
each O
sentence O
individually O
and O
sum O
the O
resulting O
file O
sizes O
( O
s1 O
) O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
next O
, O
paste O
all O
the O
cs O
sentences O
into O
a O
single O
file O
and O
run O
gzip O
on O
it O
to O
get O
a O
file O
of O
size O
s2 O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
then O
, O
d O
= O
s1−s2 O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
smallerd O
scores O
indicate O
larger O
diversity O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
if O
the O
variants O
of O
a O
sentence O
are O
dissimilar O
to O
one O
another O
and O
hence O
very O
diverse O
, O
then O
s2 O
would O
be O
large O
thus O
leading O
to O
smaller O
values O
of O
d. O
table O
8 O
shows O
the O
diversity O
scores O
for O
different O
techniques O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
both O
tcs O
( O
s O
) O
and O
tcs O
( O
u O
) O
have O
a O
higher O
diversity O
score O
compared O
to O
lex O
and O
emt O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
tcs O
( O
u O
) O
exceeds O
even O
the O
responses O
received O
viamturk O
( O
real O
) O
in O
diversity O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
we O
note O
here O
that O
diversity O
, O
by O
itself O
, O
is O
not O
necessarily O
a O
desirable O
trait O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
our O
goal O
is O
to O
generate O
sentences O
that O
are O
diverse O
while O
being O
natural O
and O
semanticallymeaningful O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
the O
latter O
properties O
for O
text O
from O
tcs O
( O
s O
) O
and O
tcs O
( O
u O
) O
have O
already O
been O
verified O
in O
our O
human O
evaluation O
study O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
zhu O
et O
al O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
( O
2018 O
) O
propose O
self-bleu O
score O
as O
a O
metric O
to O
evaluate O
the O
diversity O
of O
generated O
data O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
7http O
: O
//www.gzip.org/ O
however O
, O
using O
self-bleu O
is O
slightly O
problematic O
in O
our O
setting O
as O
systems O
like O
lex O
that O
switch O
words O
at O
random O
positions O
would O
result O
in O
low O
self-bleu O
( O
indicating O
high O
diversity O
) O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
this O
is O
indeed O
the O
case O
, O
as O
shown O
in O
table O
8 O
- O
lex O
, O
emt O
give O
lower O
self-bleu O
scores O
as O
compared O
to O
tcs O
. O

section 14
id pdf2json/2021.acl-long.245.pdf.json
however O
, O
note O
that O
the O
scores O
of O
the O
tcs O
models O
are O
comparable O
to O
that O
of O
real O
cs O
data O
. O

section 15
id pdf2json/2021.acl-long.245.pdf.json
in O
this O
work O
, O
we O
present O
a O
neural O
translation O
model O
for O
cs O
text O
that O
transduces O
monolingual O
hindi O
sentences O
into O
realistic O
hindi-english O
cs O
text O
. O

section 15
id pdf2json/2021.acl-long.245.pdf.json
text O
generated O
by O
our O
model O
is O
evaluated O
using O
a O
number O
of O
different O
objective O
metrics O
, O
along O
with O
lm O
, O
nli O
and O
sentiment O
analysis O
tasks O
, O
and O
a O
detailed O
human O
evaluation O
study O
. O

section 15
id pdf2json/2021.acl-long.245.pdf.json
the O
role O
of O
synthetic O
data O
in O
training O
such O
models O
merits O
a O
more O
detailed O
investigation O
which O
we O
leave O
for O
future O
work O
. O

section 16
id pdf2json/2021.acl-long.245.pdf.json
we O
thank O
all O
the O
anonymous O
reviewers O
for O
their O
constructive O
feedback O
which O
helped O
improve O
the O
presentation O
of O
this O
work O
. O

section 16
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
thank O
all O
the O
volunteers O
who O
helped O
with O
the O
collection O
of O
cs O
text O
that O
is O
released O
as O
part O
of O
our O
dataset O
, O
all-cs O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
figure O
4 O
depicts O
the O
portal O
used O
to O
collect O
data O
using O
amazon O
’ O
s O
mechanical O
turk O
platform O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
the O
collection O
was O
done O
in O
two O
rounds O
, O
first O
for O
moviecs O
and O
then O
for O
treebank-cs O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
with O
treebank-cs O
, O
the O
sentences O
were O
first O
divided O
into O
chunks O
and O
the O
turkers O
were O
providedwith O
a O
sentence O
grouped O
into O
chunks O
as O
shown O
in O
figure O
4 O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
they O
were O
required O
to O
switch O
at O
least O
one O
chunk O
in O
the O
sentence O
entirely O
to O
english O
so O
as O
to O
ensure O
a O
longer O
span O
of O
english O
words O
in O
the O
resulting O
cs O
sentence O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
a O
suggestion O
box O
converted O
transliterated O
hindi O
words O
into O
devanagari O
and O
also O
provided O
english O
suggestions O
to O
aid O
the O
workers O
in O
completing O
their O
task O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
with O
movie-cs O
, O
since O
there O
were O
no O
chunk O
labels O
associated O
with O
the O
sentences O
, O
they O
were O
tokenized O
into O
words O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
on O
mturk O
, O
we O
selected O
workers O
with O
hit O
approval O
rate O
of O
90 O
% O
and O
location O
restricted O
to O
countries O
with O
significant O
hindi O
speakers O
- O
australia O
, O
bahrain O
, O
canada O
, O
india O
, O
kuwait O
, O
malaysia O
, O
mauritius O
, O
myanmar O
, O
nepal O
, O
netherlands O
, O
new O
zealand O
, O
oman O
, O
pakistan O
, O
qatar O
, O
saudi O
arabia O
, O
singapore O
, O
south O
africa O
, O
sri O
lanka O
, O
thailand O
, O
united O
arab O
emirates O
, O
unitedkingdom O
, O
united O
states O
of O
america O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
it O
was O
clearly O
specified O
in O
the O
guidelines O
that O
the O
task O
must O
be O
attempted O
by O
native O
hindi O
speakers O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
each O
response O
was O
manually O
checked O
before O
approving O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
turkers O
were O
paid O
$ O
0.15 O
for O
working O
on O
5 O
sentences O
( O
roughly O
takes O
3-4 O
minutes O
) O
. O

section 17
id pdf2json/2021.acl-long.245.pdf.json
this O
amounts O
to O
$ O
2.25- O
$ O
3/hr O
which O
is O
in O
the O
ballpark O
of O
a O
median O
hourly O
wage O
on O
mturk O
of O
~ O
$ O
2/hr O
( O
hara O
et O
al. O
, O
2018 O
) O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
following O
the O
methodology O
described O
in O
( O
bhat O
et O
al. O
, O
2016 O
) O
, O
we O
apply O
clause O
substitution O
methodology O
to O
produce O
emt O
sentences O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
to O
create O
opsub-emt O
, O
we O
start O
with O
the O
gold O
english O
sentence O
that O
contains O
either O
embedded O
sentence O
clauses O
( O
s O
) O
or O
subordinate O
clauses O
( O
sbar O
) O
and O
swap O
one O
or O
more O
of O
them O
with O
their O
hindi O
translations O
to O
produce O
an O
emt O
synthetic O
cs O
sentence O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
due O
to O
the O
lack O
of O
gold O
english O
translations O
available O
for O
all-cs O
sentences O
, O
we O
used O
the O
google O
translate O
api O
to O
first O
acquire O
their O
english O
translation O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
many O
of O
the O
sentences O
in O
all-cs O
are O
shorter O
in O
length O
and O
do O
not O
contain O
the O
abovementioned O
clauses O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
so O
, O
we O
also O
considered O
inverted O
declarative O
sentence O
clauses O
( O
sinv O
) O
, O
inverted O
question O
clauses O
( O
sq O
) O
and O
direct O
question O
clauses O
( O
sbarq O
) O
in O
addition O
to O
s O
and O
sbar O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
in O
case O
none O
of O
the O
clause O
level O
tags O
were O
present O
, O
we O
considered O
the O
following O
phrase O
level O
tags O
as O
switching O
candidates O
: O
noun O
phrase O
( O
np O
) O
, O
verb O
phrase O
( O
vp O
) O
, O
adjective O
phrase O
( O
adjp O
) O
and O
adverb O
phase O
( O
advp O
) O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
owing O
to O
the O
shorter O
length O
and O
lack O
of O
clauselevel O
tags O
, O
we O
switch O
only O
one O
tag O
per O
sentence O
for O
all-cs-emt O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
the O
choice O
of O
which O
clause O
to O
switch O
was O
made O
empirically O
by O
observing O
what O
switches O
caused O
the O
resulting O
sentence O
to O
resemble O
a O
naturally O
occurring O
cs O
sentence O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
one O
can O
also O
use O
the O
toolkit O
provided O
by O
rizvi O
et O
al O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
( O
2021 O
) O
for O
generating O
emt O
lines O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
c O
implementation O
details O
: O
tcs O
as O
an O
initialisation O
step O
, O
we O
learn O
the O
token O
embeddings O
( O
mikolov O
et O
al. O
, O
2013 O
) O
on O
the O
same O
corpus O
using O
skipgram O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
the O
embedding O
dimension O
was O
set O
to O
be O
256 O
and O
the O
encoder-decoder O
layers O
share O
these O
lookup O
tables O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
adam O
optimiser O
with O
a O
learning O
rate O
of O
0.0001was O
used O
to O
train O
the O
model O
. O

section 18
id pdf2json/2021.acl-long.245.pdf.json
validation O
bleu O
scores O
on O
( O
hi O
→ O
eng/cs O
) O
translations O
and O
( O
en O
→ O
hi O
→ O
en O
) O
reconstructions O
were O
used O
as O
metrics O
to O
save O
the O
best O
model O
for O
tcs O
( O
s O
) O
and O
tcs O
( O
u O
) O
, O
respectively O
. O

section 19
id pdf2json/2021.acl-long.245.pdf.json
the O
150 O
samples O
evaluated O
in O
table O
5 O
were O
taken O
entirely O
from O
test/validation O
splits O
. O

section 19
id pdf2json/2021.acl-long.245.pdf.json
we O
undertook O
an O
alternate O
human O
evaluation O
experiment O
involving O
100 O
real O
cs O
sentences O
and O
its O
corresponding O
cs O
sentences O
using O
lex O
, O
emt O
, O
tcs O
( O
u O
) O
and O
tcs O
( O
s O
) O
. O

section 19
id pdf2json/2021.acl-long.245.pdf.json
out O
of O
these O
100 O
sentences O
, O
40 O
of O
them O
came O
entirely O
from O
the O
test O
and O
validation O
splits O
and O
the O
remaining O
60 O
are O
training O
sentences O
which O
we O
filtered O
tomake O
sure O
that O
sentences O
generated O
by O
tcs O
( O
s O
) O
and O
tcs O
( O
u O
) O
never O
exactly O
matched O
the O
real O
cs O
sentence O
. O

section 19
id pdf2json/2021.acl-long.245.pdf.json
the O
table O
below O
( O
table O
9 O
) O
reports O
the O
evaluations O
on O
the O
complete O
set O
of O
100 O
sentences O
from O
5 O
datasets O
. O

section 19
id pdf2json/2021.acl-long.245.pdf.json
we O
observe O
that O
the O
trend O
remains O
exactly O
the O
same O
as O
in O
table O
5 O
, O
with O
tcs O
( O
s O
) O
being O
very O
close O
to O
real O
cs O
sentences O
in O
its O
evaluation O
and O
tcs O
( O
u O
) O
trailing O
behind O
tcs O
( O
s O
) O
. O

section 20
id pdf2json/2021.acl-long.245.pdf.json
the O
awd-lstm O
language O
model O
was O
trained O
for O
100 O
epochs O
with O
a O
batch O
size O
of O
80 O
and O
a O
sequence O
length O
of O
70 O
in O
each O
batch O
. O

section 20
id pdf2json/2021.acl-long.245.pdf.json
the O
learning O
rate O
was O
set O
at O
30 O
. O

section 20
id pdf2json/2021.acl-long.245.pdf.json
the O
model O
uses O
nt-asgd O
, O
a O
variant O
of O
the O
averaged O
stochastic O
gradient O
method O
, O
to O
update O
the O
weights O
. O

section 20
id pdf2json/2021.acl-long.245.pdf.json
the O
mix-review O
decay O
parameter O
was O
set O
to O
0.9 O
. O

section 20
id pdf2json/2021.acl-long.245.pdf.json
this O
implies O
that O
the O
fraction O
of O
pretraining O
batches O
being O
considered O
at O
the O
end O
ofn O
epochs O
is O
0.9n O
, O
starting O
from O
all O
batches O
initially O
. O

section 20
id pdf2json/2021.acl-long.245.pdf.json
two O
decay O
coefficients O
{ O
0.8 O
, O
0.9 O
} O
were O
tested O
and O
0.9 O
was O
chosen O
based O
on O
validation O
perplexities O
. O

section 21
id pdf2json/2021.acl-long.245.pdf.json
the O
sentences O
in O
table O
10 O
have O
been O
generated O
on O
the O
test O
and O
validation O
splits O
of O
all-cs O
as O
well O
as O
the O
opsub O
dataset O
. O

section 21
id pdf2json/2021.acl-long.245.pdf.json
overall O
, O
they O
depict O
how O
the O
model O
is O
able O
to O
retain O
context O
over O
long O
sentences O
( O
e.g O
. O

section 21
id pdf2json/2021.acl-long.245.pdf.json
“ O
and O
social O
sectors O
” O
) O
and O
performmeaningful O
switching O
over O
large O
spans O
of O
words O
( O
e.g O
. O

section 21
id pdf2json/2021.acl-long.245.pdf.json
“ O
old O
conversation O
writer O
media O
” O
, O
“ O
regularly O
security O
practices O
” O
) O
. O

section 21
id pdf2json/2021.acl-long.245.pdf.json
we O
also O
note O
that O
at O
times O
, O
the O
model O
uses O
words O
which O
are O
different O
from O
the O
natural O
english O
translations O
of O
the O
sentence O
, O
which O
are O
appropriate O
within O
the O
context O
of O
a O
cs O
sentence O
( O
e.g O
. O

section 21
id pdf2json/2021.acl-long.245.pdf.json
the O
use O
of O
“ O
manage O
” O
instead O
of O
“ O
manageable O
” O
) O
. O

section 22
id pdf2json/2021.acl-long.245.pdf.json
for O
masked O
language O
modeling O
( O
mlm O
) O
, O
we O
select O
the O
default O
parameters O
for O
the O
learning O
rate O
( O
5e-5 O
) O
, O
batch O
masking O
probability O
( O
0.15 O
) O
, O
sequence O
length O
( O
512 O
) O
. O

section 22
id pdf2json/2021.acl-long.245.pdf.json
the O
models O
are O
trained O
for O
2 O
epochs O
with O
a O
batch O
size O
of O
4 O
and O
gradient O
accumulation O
step O
of O
10 O
. O

section 22
id pdf2json/2021.acl-long.245.pdf.json
for O
task O
specific O
fine O
tuning O
we O
rely O
on O
the O
official O
training O
scripts O
provided O
by O
gluecos O
repository O
. O

section 22
id pdf2json/2021.acl-long.245.pdf.json
8 O
we O
train O
the O
models O
for O
5 O
seed O
( O
0,1,2,3 O
and O
4 O
) O
and O
report O
mean O
and O
standard O
deviations O
of O
accuracy O
and O
f1 O
for O
nli O
and O
sentiment O
analysis O
respectively O

section 23
id pdf2json/2021.acl-long.245.pdf.json
dataset O
the O
additional O
corpus O
on O
which O
experiments O
were O
performed O
is O
opus-100 O
( O
zhang O
et O
al. O
, O
2020 O
) O
which O
was O
sampled O
from O
the O
original O
opus O
corpus O
( O
tiedemann O
, O
2012 O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
primary O
difference O
between O
opsub O
and O
opus-100 O
is O
that O
opsub O
does O
not O
have O
manual O
hindi O
translations O
8https O
: O
//github.com/microsoft/gluecos O
generated O
using O
movie-cs O
सारे O
पुराने O
बातचीत O
लेखक O
मी O
डया O
और O
राजनीित O
में O
जमा O
हो O
गए O
हैं O
( O
all O
the O
old O
conversation O
writers O
have O
gathered O
in O
media O
and O
politics O
) O
सारे O
old O
conversation O
writer O
media O
और O
politics O
में O
जमा O
हो O
गए O
हैं O
क्या O
बात O
है O
तुमने O
आखर O
बार O
कब O
पाट O
क O
थी O
( O
what O
is O
the O
last O
time O
you O
had O
a O
party O
) O
क्या O
बात O
है O
तुमने O
last O
time O
party O
कब O
क O
थी O
तू O
अपने O
कमरे O
में O
जा O
यार O
आप O
दोनों O
कृपया O
शांत O
हो O
जाओ O
( O
you O
go O
to O
your O
room O
man O
please O
relax O
both O
of O
you O
) O
तू O
अपने O
room O
में O
जा O
यार O
आप O
दोनों O
please O
calm O
down O
generated O
using O
treebankcs O
यह O
पॉिलसी O
पित O
प O
ी O
के O
संयु O
नाम O
से O
थी O
( O
this O
policy O
was O
in O
the O
joint O
name O
of O
husband O
and O
wife O
) O
यह O
policy O
husband O
wife O
के O
joint O
नाम O
से O
थी O
स्कूलों O
में O
तो O
िनयिमत O
रूप O
से O
सुरक्षा O
अभ्यास O
कराए O
जाने O
लगे O
हैं O
( O
regular O
safety O
exercises O
are O
being O
conducted O
in O
schools O
) O
schools O
में O
तो O
regularly O
security O
practice O
कये O
जाने O
लगे O
हैं O
इसमें O
बुिनयाद O
कृ O
ष O
और O
सामा O
जक O
के्षऽों O
में O
सावर्जिनक O
िनवेशभी O
शािमल O
है O
( O
it O
also O
includes O
public O
investment O
in O
basic O
agricultural O
and O
social O
sectors O
) O
इसमें O
बुिनयाद O
farming O
and O
social O
areas O
में O
public O
investment O
भी O
शािमल O
है O
of O
its O
sentences O
and O
requires O
the O
use O
of O
an O
external O
api O
such O
as O
google O
translate O
for O
translation O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
however O
, O
opus-100 O
has O
manually O
annotated O
sentences O
as O
part O
of O
the O
corpus O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
source O
of O
opus-100 O
ranges O
from O
movie O
subtitles O
to O
gnome O
documentation O
to O
the O
bible O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
we O
extract O
340k O
sentences O
from O
opus-100 O
corpus O
after O
thresholding O
on O
length O
( O
5-15 O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
we O
offer O
this O
comparison O
of O
systems O
trained O
on O
opsub O
and O
opus-100 O
to O
show O
how O
our O
models O
fare O
when O
using O
two O
datasets O
that O
are O
very O
different O
in O
their O
composition O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
lex O
lines O
generation O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
generation O
of O
lex O
lines O
is O
straightforward O
and O
requires O
only O
a O
bilingual O
lexicon O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
for O
each O
monolingual O
hindi O
sentence O
we O
generate O
~5 O
sentences O
on O
opus-100 O
resulting O
in O
opus-100-lex O
( O
to O
roughly O
match O
the O
size O
of O
opsub-lex O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
emt O
lines O
generation O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
for O
generation O
of O
emt O
lines O
we O
have O
two O
strategies O
depending O
on O
the O
availability O
of O
tools O
( O
parsers O
, O
translation O
service O
, O
aligners O
, O
etc O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
first O
strategy O
requires O
a O
translation O
service O
( O
either O
in-house O
or O
publicly O
available O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
we O
substitute O
the O
embedded O
clause O
from O
parse O
trees O
of O
english O
sentences O
with O
their O
hindi O
translations O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
this O
strategy O
does O
not O
require O
a O
parallel O
hindi O
corpus O
and O
has O
been O
previously O
used O
for O
generating O
opsub-emt O
and O
all-cs-emt O
( O
described O
in O
detail O
in O
appendix O
b O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
second O
strategy O
, O
that O
is O
used O
to O
generate O
opus-100-emt O
, O
requires O
a O
parallel O
corpus O
, O
a O
constituent O
parser O
in O
english O
and O
a O
word O
aligner O
between O
parallel O
sentences O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
opus-100 O
sentences O
are O
aligned O
using O
simalign O
( O
jalili O
sabet O
et O
al. O
, O
2020 O
) O
and O
embedded O
clauses O
from O
parse O
trees O
of O
english O
sentences O
are O
replaced O
by O
hindi O
clauses O
using O
word O
aligners O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
here O
again O
, O
for O
each O
monolingual O
hindi O
sentenece O
we O
generate O
~5 O
emt O
sentences O
( O
strategy-2 O
) O
on O
opus-100 O
resulting O
in O
opus-100-emt O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
curriculum O
training O
experiments O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
table O
11 O
provides O
a O
walkthrough O
of O
systems O
using O
various O
training O
curricula O
that O
are O
evaluated O
for O
two O
different O
choices O
of O
datasets O
- O
opsub O
vs O
opus-100 O
differing O
in O
the O
generation O
of O
emt O
lines O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
models O
are O
evaluated O
using O
bleu O
( O
papineni O
et O
al. O
, O
2002 O
) O
scores O
computed O
on O
the O
test O
set O
of O
all-cs O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
vo- O
cabulary O
is O
generated O
by O
combining O
train O
sets O
of O
all O
datasets O
to O
be O
used O
in O
the O
curricula O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
it O
is O
126,576 O
when O
x O
= O
opsub O
and O
164,350 O
when O
x O
= O
opus100 O
( O
opsub O
shows O
a O
higher O
overlap O
in O
vocabulary O
with O
all-cs O
compared O
to O
opus-100 O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
marginal O
difference O
in O
system O
o O
for O
opsub O
and O
opus-100 O
is O
attributed O
to O
differences O
in O
the O
size O
of O
the O
vocabulary O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
opsub O
being O
conversational O
in O
nature O
, O
is O
a O
better O
pretraining O
corpus O
compared O
to O
opus-100 O
as O
seen O
from O
system O
a O
, O
the O
sources O
of O
the O
latter O
being O
gnome O
documentations O
and O
the O
bible O
, O
apart O
from O
movie O
subtitles O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
results O
for O
c1 O
, O
c2 O
, O
d1 O
, O
d2 O
are O
consistently O
better O
when O
x O
= O
opsub O
versus O
when O
x O
= O
opus100 O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
we O
choose O
to O
highlight O
four O
models O
from O
table O
11 O
which O
together O
demonstrate O
multiple O
use-cases O
of O
tcs O
in O
table O
12 O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
tcs O
( O
lex O
) O
refers O
to O
( O
c2 O
, O
x=opsub O
) O
, O
tcs O
( O
u O
) O
refers O
to O
( O
d1 O
, O
x=opsub O
) O
, O
tcs O
( O
s O
) O
refers O
to O
( O
d2 O
, O
x=opsub O
) O
and O
tcs O
( O
simalign O
) O
refers O
to O
( O
d2 O
, O
x=opus-100 O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
language O
modelling O
experiments O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
table O
13 O
shows O
results O
from O
lm O
experiments O
( O
using O
the O
same O
setup O
as O
in O
section O
5.2.1 O
) O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
the O
values O
for O
tcs O
( O
s O
) O
and O
tcs O
( O
u O
) O
have O
been O
reproduced O
here O
for O
ease O
of O
comparison O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
( O
note O
that O
tcs O
( O
simalign O
) O
does O
not O
perform O
as O
well O
as O
the O
other O
models O
since O
the O
sentences O
for O
training O
the O
language O
model O
are O
generated O
on O
opsub O
for O
all O
the O
models O
here O
, O
but O
tcs O
( O
simalign O
) O
has O
been O
trained O
on O
opus-100 O
. O
) O

section 23
id pdf2json/2021.acl-long.245.pdf.json
evaluation O
metrics O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
table O
14 O
shows O
the O
results O
of O
the O
three O
objective O
evaluation O
metrics O
on O
the O
additional O
tcs O
models O
. O

section 23
id pdf2json/2021.acl-long.245.pdf.json
in O
comparison O
with O
the O
results O
in O
table O
8 O
, O
we O
observe O
that O
tcs O
( O
lex O
) O
and O
tcs O
( O
simalign O
) O
perform O
comparably O
to O
tcs O
( O
s O
) O
and O
tcs O
( O
u O
) O
on O
all O
metrics O
. O

section TITLE
id pdf2json/2021.acl-long.345.pdf.json
evaluating O
entity O
disambiguation O
and O
the O
role O
of O
popularity O
in O
retrieval-based O
nlp O

section ABSTRACT
id pdf2json/2021.acl-long.345.pdf.json
retrieval O
is O
a O
core O
component O
for O
open-domain O
nlp O
tasks O
. O

section ABSTRACT
id pdf2json/2021.acl-long.345.pdf.json
in O
open-domain O
tasks O
, O
multiple O
entities O
can O
share O
a O
name O
, O
making O
disambiguation O
an O
inherent O
yet O
under-explored O
problem O
. O

section ABSTRACT
id pdf2json/2021.acl-long.345.pdf.json
we O
propose O
an O
evaluation O
benchmark O
for O
assessing O
the O
entity O
disambiguation O
capabilities O
of O
these O
retrievers O
, O
which O
we O
call O
ambiguous O
entity O
retrieval O
( O
amber O
) O
sets O
. O

section ABSTRACT
id pdf2json/2021.acl-long.345.pdf.json
we O
define O
an O
amber O
set O
as O
a O
collection O
of O
entities O
that O
share O
a O
name O
along O
with O
queries O
about O
those O
entities O
. O

section ABSTRACT
id pdf2json/2021.acl-long.345.pdf.json
by O
covering O
the O
set O
of O
entities O
for O
polysemous O
names O
, O
amber O
sets O
act O
as O
a O
challenging O
test O
of O
entity O
disambiguation O
. O

section ABSTRACT
id pdf2json/2021.acl-long.345.pdf.json
we O
create O
amber O
sets O
for O
three O
popular O
open-domain O
tasks O
: O
fact O
checking O
, O
slot O
filling O
, O
and O
question O
answering O
, O
and O
evaluate O
a O
diverse O
set O
of O
retrievers O
. O

section ABSTRACT
id pdf2json/2021.acl-long.345.pdf.json
we O
find O
that O
the O
retrievers O
exhibit O
popularity O
bias O
, O
significantly O
under-performing O
on O
rarer O
entities O
that O
share O
a O
name O
, O
e.g. O
, O
they O
are O
twice O
as O
likely O
to O
retrieve O
erroneous O
documents O
on O
queries O
for O
the O
less O
popular O
entity O
under O
the O
same O
name O
. O

section ABSTRACT
id pdf2json/2021.acl-long.345.pdf.json
these O
experiments O
on O
amber O
sets O
show O
their O
utility O
as O
an O
evaluation O
tool O
and O
highlight O
the O
weaknesses O
of O
popular O
retrieval O
systems.1 O

section 0
id pdf2json/2021.acl-long.345.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
4472–4485 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.345.pdf.json
©2021 O
association O
for O
computational O
linguistics O
4472 O

section 1
id pdf2json/2021.acl-long.345.pdf.json
substantial O
progress O
in O
nlp O
has O
been O
made O
on O
“ O
closed O
” O
tasks O
, O
where O
queries O
are O
paired O
with O
relevant O
documents O
( O
rajpurkar O
et O
al. O
, O
2016 O
; O
dua O
et O
al. O
, O
2019 O
) O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
however O
, O
there O
is O
growing O
interest O
in O
“ O
opendomain O
” O
tasks O
, O
where O
relevant O
documents O
need O
to O
be O
retrieved O
from O
a O
knowledge O
source O
before O
an O
nlp O
system O
can O
perform O
reasoning O
and O
produce O
an O
answer O
( O
chen O
et O
al. O
, O
2017 O
; O
petroni O
et O
al. O
, O
2021 O
) O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
the O
open-domain O
setting O
better O
reflects O
real-world O
usage O
for O
tasks O
where O
relevant O
information O
is O
generally O
not O
provided O
( O
e.g. O
, O
fact O
checking O
) O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
∗work O
started O
during O
an O
internship O
at O
apple O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
1the O
amber O
sets O
used O
in O
this O
paper O
and O
the O
code O
to O
generate O
them O
are O
available O
at O
https O
: O
//github.com/ O
anthonywchen/amber-sets O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
because O
success O
hinges O
on O
finding O
relevant O
documents O
, O
open-domain O
progress O
has O
been O
closely O
tied O
to O
improvements O
in O
retrieval O
systems2 O
( O
lee O
et O
al. O
, O
2019 O
; O
karpukhin O
et O
al. O
, O
2020 O
; O
lewis O
et O
al. O
, O
2020b O
) O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
a O
crucial O
challenge O
when O
interacting O
with O
a O
large O
knowledge O
source O
( O
e.g. O
, O
wikipedia O
) O
is O
entity O
ambiguity O
, O
the O
phenomenon O
where O
a O
single O
name O
can O
map O
to O
multiple O
entities O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
resolving O
this O
ambiguity O
is O
referred O
to O
as O
entity O
disambiguation O
and O
is O
an O
important O
step O
for O
effective O
retrieval O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
for O
example O
, O
given O
the O
query O
“ O
what O
musical O
instrument O
does O
abe O
lincoln O
play O
? O
” O
, O
documents O
about O
the O
musician O
should O
rank O
higher O
than O
other O
entities O
with O
the O
same O
name O
( O
figure O
1 O
) O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
although O
entity O
disambiguation O
has O
been O
extensively O
studied O
in O
entity O
linking O
( O
hoffart O
et O
al. O
, O
2011 O
; O
rao O
et O
al. O
, O
2013 O
; O
sevgili O
et O
al. O
, O
2for O
example O
, O
replacing O
the O
bm25 O
retriever O
with O
dpr O
on O
natural O
questions O
increases O
exact O
match O
by O
15 O
points O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
2020 O
) O
and O
search O
( O
balog O
et O
al. O
, O
2010 O
, O
2011 O
) O
, O
in O
the O
context O
of O
open-domain O
nlp O
, O
it O
is O
unclear O
how O
good O
retrieval O
systems O
are O
when O
faced O
with O
queries O
with O
ambiguous O
entities O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
evaluating O
entity O
ambiguity O
is O
challenging O
because O
the O
popularity O
of O
entities O
follows O
a O
long-tail O
( O
figure O
2 O
) O
and O
rare O
entities O
are O
seldom O
covered O
in O
naturally-occurring O
datasets O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
in O
this O
paper O
we O
introduce O
amber O
sets O
, O
a O
benchmark O
for O
evaluating O
the O
entity O
disambiguation O
capabilities O
of O
retrievers O
across O
multiple O
nlp O
tasks O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
each O
amber O
set O
is O
a O
collection O
of O
wikidata O
entities O
that O
share O
a O
name O
, O
and O
their O
corresponding O
queries O
for O
specific O
nlp O
tasks O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
for O
each O
set O
, O
we O
define O
the O
head O
entity O
as O
the O
most O
popular O
entity O
and O
tail O
entities O
as O
the O
less O
popular O
ones O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
by O
creating O
queries O
for O
multiple O
entities O
that O
share O
a O
name O
, O
amber O
sets O
provide O
an O
accurate O
test O
of O
entity O
disambiguation O
capabilities O
of O
retrievers O
and O
help O
assess O
the O
role O
of O
entity O
popularity O
in O
disambiguation O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
we O
show O
examples O
of O
amber O
sets O
for O
the O
question O
answering O
task O
in O
table O
1 O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
we O
automatically O
create O
amber O
sets O
by O
mining O
the O
wikidata O
knowledge O
graph O
( O
vrandecic O
and O
krötzsch O
, O
2014 O
) O
for O
relevant O
names O
and O
entities O
, O
and O
leveraging O
task-specific O
templates O
to O
generate O
inputs O
for O
three O
tasks O
: O
fact O
checking O
, O
slot O
filling O
, O
and O
question O
answering O
( O
figure O
3 O
) O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
in O
total O
, O
our O
amber O
sets O
contain O
80k O
task-specific O
queries O
which O
we O
align O
to O
the O
wikipedia O
snapshot O
from O
kilt O
( O
petroni O
et O
al. O
, O
2021 O
) O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
we O
use O
amber O
sets O
to O
conduct O
a O
systematic O
study O
of O
various O
retrieval O
systems O
that O
operate O
under O
different O
principles O
, O
such O
as O
token O
overlap O
and O
dense O
embedding O
similarity O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
retrievers O
perform O
very O
differently O
on O
amber O
sets O
in O
terms O
of O
absolute O
retrieval O
numbers O
, O
with O
bootleg O
( O
orr O
et O
al. O
, O
2020 O
) O
, O
an O
entity-linking-based O
retriever O
, O
performing O
best O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
despite O
these O
differences O
, O
all O
retrievers O
exhibit O
a O
large O
degree O
of O
popularity O
bias O
, O
underperforming O
on O
inputs O
concerning O
tail O
entities O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
tfidf O
, O
a O
token-based O
retriever O
, O
performs O
about O
four O
times O
worse O
on O
tail O
entity O
inputs O
compared O
to O
head O
entity O
inputs O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
even O
with O
bootleg O
, O
the O
best O
performing O
retriever O
, O
performance O
on O
tail O
entities O
is O
still O
1.5 O
times O
lower O
than O
on O
head O
entities O
. O

section 1
id pdf2json/2021.acl-long.345.pdf.json
our O
results O
on O
amber O
sets O
demonstrate O
that O
there O
is O
significant O
work O
to O
be O
done O
on O
making O
retrievers O
robust O
in O
handling O
entity O
disambiguation O
. O

section 2
id pdf2json/2021.acl-long.345.pdf.json
retrieving O
relevant O
documents O
from O
large O
knowledge O
sources O
such O
as O
wikipedia O
is O
an O
important O
first O
step O
in O
the O
open-domain O
pipeline O
. O

section 2
id pdf2json/2021.acl-long.345.pdf.json
an O
inherent O
problem O
in O
working O
with O
such O
sources O
is O
entity O
disambiguation O
: O
resolving O
a O
name O
( O
mention O
) O
to O
an O
entity O
in O
the O
knowledge O
source O
. O

section 2
id pdf2json/2021.acl-long.345.pdf.json
entity O
disambiguation O
can O
be O
challenging O
because O
many O
entities O
share O
a O
name O
, O
and O
the O
popularity O
of O
entities O
follows O
a O
long-tail O
distribution O
( O
figure O
2 O
) O
. O

section 2
id pdf2json/2021.acl-long.345.pdf.json
despite O
the O
importance O
of O
entity O
disambiguation O
, O
it O
remains O
an O
understudied O
problem O
for O
open-domain O
nlp O
. O

section 2
id pdf2json/2021.acl-long.345.pdf.json
we O
introduce O
amber O
sets O
for O
evaluating O
entity O
disambiguation O
capabilities O
of O
retrievers O
and O
analyze O
the O
role O
of O
entity O
popularity O
in O
disambiguation O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
we O
first O
provide O
an O
intuition O
for O
an O
amber O
set O
before O
concretely O
defining O
one O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
consider O
two O
entities O
, O
a O
president O
and O
a O
musician O
, O
both O
of O
which O
have O
the O
name O
“ O
abe O
lincoln O
” O
( O
figure O
1 O
) O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
now O
, O
consider O
the O
query O
“ O
which O
battle O
did O
abe O
lincoln O
fight O
in O
? O
” O
and O
assume O
a O
retriever O
correctly O
returns O
the O
article O
about O
the O
president O
for O
this O
query O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
simply O
because O
the O
correct O
document O
was O
retrieved O
does O
not O
mean O
a O
retriever O
has O
the O
ability O
to O
disambiguate O
between O
the O
president O
and O
the O
musician O
, O
as O
the O
president O
is O
much O
more O
popular O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
we O
should O
only O
be O
confident O
in O
its O
ability O
to O
disambiguate O
entities O
if O
we O
also O
pose O
a O
query O
about O
the O
less O
popular O
musician O
and O
the O
retriever O
again O
returns O
the O
correct O
document O
( O
as O
opposed O
to O
the O
document O
about O
the O
president O
) O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
based O
on O
this O
intuition O
, O
we O
define O
an O
amber O
set O
as O
a O
collection O
of O
queries O
that O
satisfy O
the O
following O
: O
• O
criteria O
1 O
: O
polysemous O
name O
: O
the O
queries O
in O
an O
amber O
set O
are O
all O
about O
entities O
that O
share O
a O
common O
name O
( O
e.g. O
, O
abe O
lincoln O
) O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
• O
criteria O
2 O
: O
disparity O
in O
popularity O
: O
an O
amber O
set O
contains O
queries O
about O
both O
the O
most O
popular O
entity O
for O
a O
name O
( O
the O
head O
entity O
) O
, O
e.g. O
, O
the O
president O
, O
and O
the O
less O
popular O
entities O
( O
the O
tail O
entities O
) O
, O
e.g. O
, O
the O
musician O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
• O
criteria O
3 O
: O
resolvable O
ambiguity O
: O
the O
content O
of O
the O
query O
should O
be O
sufficient O
to O
resolve O
to O
the O
correct O
entity O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
the O
query O
“ O
which O
battle O
did O
abe O
lincoln O
fight O
in O
? O
” O
satisfies O
this O
criteria O
, O
because O
there O
is O
only O
one O
abe O
lincoln O
that O
fought O
in O
a O
war O
, O
while O
“ O
where O
was O
abe O
lincoln O
born O
? O
” O
does O
not O
since O
it O
applies O
to O
all O
abe O
lincolns O
. O

section 3
id pdf2json/2021.acl-long.345.pdf.json
we O
provide O
examples O
of O
amber O
sets O
for O
the O
task O
of O
question O
answering O
in O
table O
1 O
. O

section 4
id pdf2json/2021.acl-long.345.pdf.json
in O
this O
work O
, O
we O
create O
amber O
sets O
for O
three O
tasks O
: O
fact O
checking O
, O
slot O
filling O
, O
and O
question O
answering O
( O
table O
2 O
) O
. O

section 4
id pdf2json/2021.acl-long.345.pdf.json
we O
consider O
these O
three O
tasks O
for O
three O
reasons O
. O

section 4
id pdf2json/2021.acl-long.345.pdf.json
first O
, O
these O
three O
set O
of O
tasks O
are O
diverse O
in O
nature O
. O

section 4
id pdf2json/2021.acl-long.345.pdf.json
in O
this O
work O
, O
slot O
filling O
is O
a O
generation O
task O
, O
question O
answering O
is O
a O
span O
selection O
task O
, O
and O
fact O
checking O
is O
a O
classification O
task O
. O

section 4
id pdf2json/2021.acl-long.345.pdf.json
second O
, O
the O
training O
sets O
available O
for O
each O
task O
are O
quite O
disparate O
. O

section 4
id pdf2json/2021.acl-long.345.pdf.json
the O
largest O
fact O
checking O
training O
set O
, O
fever O
( O
thorne O
et O
al. O
, O
2018 O
) O
, O
has O
80k O
instances O
, O
while O
the O
slot O
filling O
dataset O
, O
t-rex O
( O
elsahar O
et O
al. O
, O
2018 O
) O
, O
has O
over O
2 O
million O
instances O
. O

section 4
id pdf2json/2021.acl-long.345.pdf.json
the O
final O
reason O
we O
study O
these O
three O
tasks O
is O
that O
their O
inputs O
are O
short O
and O
easy O
to O
create O
. O

section 5
id pdf2json/2021.acl-long.345.pdf.json
while O
amber O
sets O
can O
be O
manually O
created O
, O
doing O
so O
can O
be O
time-consuming O
, O
requiring O
a O
human O
to O
manually O
scour O
a O
knowledge O
base O
for O
polysemous O
names O
and O
related O
entities O
before O
manually O
writing O
queries O
for O
those O
entities O
. O

section 5
id pdf2json/2021.acl-long.345.pdf.json
instead O
, O
we O
present O
a O
pipeline O
for O
automatically O
creating O
amber O
sets O
using O
the O
wikidata O
knowledge O
graph O
( O
vrandecic O
and O
krötzsch O
, O
2014 O
) O
. O

section 5
id pdf2json/2021.acl-long.345.pdf.json
in O
this O
section O
, O
we O
describe O
two O
different O
collections O
of O
amber O
sets O
, O
and O
discuss O
our O
automatic O
pipeline O
for O
creating O
amber O
sets O
. O

section 6
id pdf2json/2021.acl-long.345.pdf.json
a O
natural O
question O
is O
“ O
how O
do O
retrievers O
handle O
entity O
ambiguity O
when O
two O
entities O
have O
the O
same O
entity O
type O
as O
opposed O
when O
they O
have O
different O
types O
? O
” O
. O

section 6
id pdf2json/2021.acl-long.345.pdf.json
to O
answer O
this O
question O
, O
we O
create O
two O
collections O
of O
amber O
sets O
. O

section 6
id pdf2json/2021.acl-long.345.pdf.json
the O
first O
is O
amberh O
, O
a O
collection O
of O
amber O
sets O
where O
all O
entities O
are O
humans O
. O

section 6
id pdf2json/2021.acl-long.345.pdf.json
the O
choice O
to O
restrict O
amber-h O
to O
humans O
is O
motivated O
by O
the O
fact O
that O
humans O
have O
properties O
that O
help O
distinguish O
themselves O
from O
other O
humans O
, O
generally O
based O
on O
occupation O
. O

section 6
id pdf2json/2021.acl-long.345.pdf.json
the O
second O
is O
amber-n O
, O
a O
collection O
of O
amber O
sets O
where O
all O
entities O
contained O
are O
non-humans O
, O
and O
disambiguation O
of O
a O
name O
is O
between O
non-human O
entities O
with O
different O
entity O
types O
. O

section 6
id pdf2json/2021.acl-long.345.pdf.json
this O
is O
because O
a O
non-human O
entity O
, O
like O
a O
movie O
, O
does O
not O
generally O
have O
a O
single O
distinguishing O
property O
to O
distinguish O
from O
other O
movies O
. O

section 6
id pdf2json/2021.acl-long.345.pdf.json
this O
makes O
it O
natural O
to O
compare O
non-human O
entities O
to O
other O
non-human O
entities O
with O
different O
types O
. O

section 6
id pdf2json/2021.acl-long.345.pdf.json
we O
specify O
the O
entity O
types O
in O
each O
collection O
in O
table O
3 O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
we O
now O
describe O
a O
pipeline O
to O
automatically O
create O
amber O
sets O
for O
three O
tasks O
: O
fact O
checking O
, O
slot O
filling O
, O
and O
question O
answering O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
we O
provide O
a O
visualization O
of O
the O
pipeline O
in O
figure O
3 O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
collecting O
names O
and O
entities O
we O
begin O
by O
collecting O
all O
entity O
aliases3 O
in O
wikidata O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
from O
these O
aliases O
, O
we O
filter O
for O
those O
that O
are O
shared O
by O
multiple O
wikidata O
entities O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
each O
entity O
in O
wikidata O
is O
represented O
by O
a O
unique O
qid O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
the O
entities O
must O
have O
an O
entity O
type O
from O
table O
3 O
depending O
on O
the O
collection O
we O
are O
collecting O
amber O
sets O
for O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
each O
alias O
and O
associated O
entities O
form O
the O
basis O
for O
an O
amber O
set O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
within O
each O
set O
, O
we O
define O
the O
head O
and O
tail O
entities O
based O
on O
the O
number O
of O
wikipedia O
page O
views O
for O
the O
month O
of O
october O
2019 O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
we O
filter O
out O
amber O
sets O
where O
the O
percentage O
gap O
in O
popularity O
between O
the O
head O
entity O
and O
the O
most O
popular O
tail O
entity O
is O
less O
than O
10 O
% O
to O
account O
for O
noise O
in O
the O
monthly O
page O
views O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
collecting O
distinguishing O
properties O
we O
gather O
properties O
and O
associated O
values O
for O
each O
entity O
from O
wikidata O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
we O
only O
retain O
properties O
that O
are O
in O
a O
specified O
list O
( O
table O
3 O
) O
, O
as O
they O
are O
useful O
for O
resolving O
ambiguity O
( O
criteria O
3 O
) O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
we O
also O
filter O
a O
property O
if O
two O
entities O
within O
an O
amber O
set O
have O
that O
property O
, O
ensuring O
that O
the O
remaining O
properties O
can O
be O
used O
to O
disambiguate O
between O
entities O
with O
the O
same O
name O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
these O
properties O
are O
used O
to O
instantiate O
the O
queries O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
aligning O
entities O
to O
wikipedia O
we O
use O
the O
kilt O
wikipedia O
snapshot O
( O
petroni O
et O
al. O
, O
2021 O
) O
as O
3aliases O
are O
all O
possible O
names O
for O
an O
entity O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
the O
knowledge O
source O
for O
amber O
sets O
for O
better O
reproducibility O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
each O
wikipedia O
document O
in O
kilt O
has O
an O
associated O
qid O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
for O
each O
entity O
, O
we O
find O
all O
wikipedia O
documents O
with O
that O
associated O
qid O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
after O
this O
alignment O
, O
we O
apply O
a O
round O
of O
filtering O
on O
the O
tuples O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
for O
each O
tuple O
, O
we O
check O
that O
the O
value O
of O
the O
tuple O
is O
within O
the O
first O
350 O
tokens O
of O
the O
aligned O
wikipedia O
article O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
if O
not O
, O
we O
remove O
the O
tuple.4 O
aligned O
wikipedia O
articles O
that O
contain O
the O
tuple O
value O
serve O
as O
gold O
documents O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
instantiating O
amber O
instances O
recall O
that O
our O
goal O
was O
to O
create O
amber O
sets O
for O
three O
tasks O
: O
fact O
checking O
, O
slot O
filling O
, O
and O
question O
answering O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
we O
are O
able O
to O
create O
queries O
for O
all O
three O
tasks O
simultaneously O
using O
the O
collected O
wikidata O
tuples O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
for O
question O
answering O
and O
fact O
checking O
, O
we O
use O
templates O
based O
on O
properties O
to O
instantiate O
inputs O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
three O
of O
the O
authors O
wrote O
a O
template O
each O
for O
each O
property O
for O
the O
two O
tasks O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
duplicate O
templates O
are O
removed O
, O
resulting O
in O
an O
average O
of O
3 O
question O
answering O
templates O
per O
property O
and O
2.7 O
fact O
checking O
templates O
per O
property O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
see O
appendix O
b O
for O
the O
complete O
list O
of O
templates O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
for O
slot O
filling O
, O
we O
create O
a O
single O
input O
from O
each O
wikidata O
tuple O
by O
concatenating O
the O
amber O
set O
name O
with O
the O
property O
name O
, O
and O
using O
the O
value O
of O
the O
tuple O
as O
the O
answer O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
for O
question O
answering O
, O
we O
also O
create O
a O
single O
input O
for O
each O
tuple O
by O
filling O
in O
the O
template O
with O
the O
amber O
set O
name O
and O
using O
the O
value O
of O
the O
tuple O
as O
the O
answer O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
for O
fact O
checking O
, O
we O
create O
two O
inputs O
for O
each O
tuple O
, O
one O
claim O
that O
is O
true O
using O
the O
tuple O
value O
and O
one O
claim O
that O
is O
false O
. O

section 7
id pdf2json/2021.acl-long.345.pdf.json
the O
false O
claim O
is O
created O
by O
finding O
the O
most O
popular O
value O
for O
the O
tuple O
property O
that O
does O
not O
match O
the O
tuple O
value5 O
. O

section 8
id pdf2json/2021.acl-long.345.pdf.json
we O
provide O
statistics O
for O
amber O
sets O
in O
table O
4 O
. O

section 8
id pdf2json/2021.acl-long.345.pdf.json
on O
average O
, O
each O
amber O
set O
has O
about O
three O
entities O
that O
share O
the O
same O
name O
. O

section 8
id pdf2json/2021.acl-long.345.pdf.json
of O
these O
three O
entities O
, O
on O
average O
, O
only O
two O
have O
properties O
after O
filtering O
. O

section 8
id pdf2json/2021.acl-long.345.pdf.json
in O
total O
, O
our O
amber O
sets O
contain O
about O
80k O
task-specific O
input O
queries O
. O

section 8
id pdf2json/2021.acl-long.345.pdf.json
4this O
reduces O
the O
number O
of O
tuples O
for O
amber-h O
from O
17,079 O
to O
5,942 O
and O
for O
amber-n O
from O
22,219 O
to O
13,804 O
. O

section 8
id pdf2json/2021.acl-long.345.pdf.json
5 O
the O
most O
popular O
instrument O
in O
wikidata O
is O
piano O
. O

section 8
id pdf2json/2021.acl-long.345.pdf.json
therefore O
, O
given O
the O
true O
claim O
“ O
abe O
lincoln O
played O
the O
trombone. O
” O
, O
the O
false O
claim O
would O
be O
“ O
abe O
lincoln O
played O
the O
piano. O
” O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
since O
our O
pipeline O
is O
automated O
and O
relies O
on O
wikipedia O
and O
wikidata O
, O
there O
are O
a O
few O
limitations O
worth O
noting O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
amber O
sets O
will O
be O
affected O
by O
incompleteness O
of O
the O
knowledge O
source O
, O
sometimes O
resulting O
ambiguous O
queries O
if O
a O
property O
is O
missing O
from O
wikidata O
, O
but O
answerable O
from O
wikipedia O
text O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
for O
this O
reason O
, O
we O
only O
select O
a O
few O
properties O
for O
each O
type O
( O
table O
3 O
) O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
second O
, O
even O
though O
we O
author O
multiple O
templates O
for O
each O
property O
, O
the O
reliance O
on O
these O
templates O
limits O
the O
syntactic O
diversity O
in O
the O
queries O
( O
not O
a O
critical O
concern O
, O
since O
we O
are O
only O
evaluating O
existing O
models O
) O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
also O
, O
we O
use O
wikipedia O
page O
views O
as O
a O
proxy O
for O
real-world O
popularity O
of O
entities O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
defining O
popularity O
in O
this O
way O
may O
be O
problematic O
, O
as O
page O
views O
for O
an O
entity O
can O
fluctuate O
, O
and O
may O
make O
our O
pipeline O
difficult O
to O
generalize O
to O
other O
knowledge O
sources O
, O
where O
this O
information O
may O
not O
be O
available O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
several O
design O
choices O
in O
creating O
amber O
sets O
are O
worth O
further O
investigation O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
we O
limit O
amber O
sets O
to O
a O
pre-specified O
list O
of O
entity O
types O
and O
properties O
to O
ensure O
that O
entities O
in O
an O
amber O
set O
are O
distinguishable O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
this O
precludes O
other O
properties O
that O
may O
be O
useful O
in O
distinguishing O
entities O
, O
reducing O
the O
diversity O
in O
amber O
sets O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
another O
design O
choice O
is O
we O
allow O
any O
alias O
in O
wikidata O
to O
form O
an O
amber O
sets O
, O
however O
, O
not O
all O
aliases O
are O
canonical O
ways O
to O
refer O
to O
the O
entity O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
for O
instance O
, O
shaquille O
o O
’ O
neal O
has O
the O
unusual O
alias O
“ O
the O
big O
cactus O
” O
, O
potentially O
leading O
to O
a O
somewhat O
unrealistic O
query O
“ O
what O
sport O
did O
the O
big O
cactus O
play O
? O
” O
. O

section 9
id pdf2json/2021.acl-long.345.pdf.json
we O
plan O
to O
revisit O
the O
these O
design O
choices O
in O
future O
work O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
retrieval O
systems O
the O
primary O
focus O
of O
this O
work O
is O
to O
evaluate O
entity O
ambiguity O
of O
retrieval O
systems O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
we O
consider O
four O
retrievers O
based O
on O
different O
retrieval O
paradigms O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
the O
first O
three O
are O
tf-idf O
, O
a O
token-based O
retriever O
using O
sparse O
embeddings O
, O
dpr O
( O
karpukhin O
et O
al. O
, O
2020 O
) O
, O
a O
dense O
embedding O
based O
retriever O
, O
and O
blink O
( O
wu O
et O
al. O
, O
2020 O
) O
, O
a O
linker-based O
retriever O
which O
ranks O
documents O
based O
on O
input O
entities O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
these O
three O
retrievers O
have O
been O
thoroughly O
evaluated O
on O
a O
number O
of O
open-domain O
tasks O
in O
petroni O
et O
al O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
( O
2021 O
) O
with O
no O
obvious O
winner O
across O
tasks O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
encouraged O
by O
the O
disambiguation O
success O
on O
rare O
entities O
by O
orr O
et O
al O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
( O
2020 O
) O
, O
we O
also O
evaluate O
a O
retriever O
based O
on O
bootleg O
, O
another O
entity O
linker O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
we O
provide O
additional O
details O
about O
these O
retrievers O
in O
appendix O
d. O
downstream O
models O
the O
dominant O
approach O
to O
open-domain O
tasks O
is O
a O
two-stage O
process O
where O
a O
retriever O
first O
finds O
relevant O
documents O
, O
followed O
by O
a O
downstream O
model O
that O
processes O
these O
documents O
to O
produce O
an O
answer O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
we O
evaluate O
the O
end-to-end O
performance O
on O
amber O
sets O
by O
training O
downstream O
nlp O
models O
on O
our O
tasks O
of O
interest O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
for O
fact O
checking O
, O
we O
fine-tune O
a O
bert O
classifier O
( O
devlin O
et O
al. O
, O
2019 O
) O
on O
fever O
( O
thorne O
et O
al. O
, O
2018 O
) O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
for O
question O
answering O
, O
we O
fine-tune O
a O
roberta O
model O
( O
liu O
et O
al. O
, O
2019 O
) O
on O
natural O
questions O
( O
kwiatkowski O
et O
al. O
, O
2019 O
) O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
for O
slot O
filling O
, O
a O
generation O
task O
, O
we O
fine-tune O
a O
bart O
model O
( O
lewis O
et O
al. O
, O
2020a O
) O
on O
t-rex O
( O
elsahar O
et O
al. O
, O
2018 O
) O
. O

section 10
id pdf2json/2021.acl-long.345.pdf.json
we O
provide O
example O
training O
instances O
in O
table O
2 O
and O
additional O
details O
on O
the O
models O
in O
appendix O
e. O
we O
use O
the O
allennlp O
and O
huggingface O
transformers O
library O
to O
finetune O
our O
downstream O
models O
( O
gardner O
et O
al. O
, O
2018 O
; O
wolf O
et O
al. O
, O
2020 O
) O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
in O
this O
section O
, O
we O
evaluate O
existing O
open-domain O
nlp O
pipelines O
using O
amber O
sets O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
we O
also O
conduct O
a O
user O
study O
to O
evaluate O
the O
quality O
of O
the O
queries O
in O
the O
amber O
sets O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
top O
document O
retrieval O
we O
report O
retrieval O
performance O
in O
table O
5 O
in O
terms O
of O
retriever O
accuracy O
@ O
1 O
( O
the O
% O
of O
instances O
where O
the O
first O
retrieved O
document O
is O
the O
gold O
document O
) O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
for O
each O
task O
, O
we O
report O
values O
on O
the O
entire O
amber O
set O
( O
“ O
all O
” O
) O
, O
as O
well O
as O
instances O
corresponding O
only O
to O
“ O
head O
” O
entities O
or O
to O
“ O
tail O
” O
entities O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
we O
also O
report O
a O
metric O
we O
call O
all O
correct O
( O
∀ O
) O
, O
the O
fraction O
of O
amber O
sets O
in O
which O
all O
queries O
had O
the O
correct O
document O
retrieved O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
all O
retrievers O
do O
better O
on O
head O
entities O
compared O
to O
tail O
entities O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
since O
blink O
, O
bootleg O
, O
and O
dpr O
are O
initialized O
using O
pre-trained O
language O
models O
, O
they O
may O
have O
a O
predisposition O
towards O
being O
biased O
to O
more O
popular O
entities O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
however O
, O
we O
find O
tf-idf O
also O
does O
better O
on O
head O
entities O
, O
perhaps O
because O
more O
popular O
entities O
have O
longer O
wikipedia O
pages O
, O
possibly O
increasing O
term-frequency O
scores O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
second O
, O
there O
are O
large O
discrepancies O
between O
a O
retriever O
’ O
s O
performance O
on O
different O
tasks O
for O
an O
amber O
collection O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
for O
instance O
, O
dpr O
does O
substantially O
worse O
on O
slot O
filling O
compared O
to O
its O
performance O
on O
question O
answering O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
this O
is O
surprising O
since O
queries O
for O
all O
tasks O
are O
created O
from O
the O
same O
set O
of O
wikidata O
tuples O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
finally O
, O
we O
find O
that O
retrievers O
are O
mostly O
incorrect O
on O
getting O
all O
the O
queries O
in O
a O
set O
correct O
, O
with O
some O
receiving O
a O
∀ O
score O
of O
0 O
on O
some O
tasks O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
overall O
, O
we O
find O
that O
the O
bootleg O
retriever O
on O
average O
does O
the O
best O
across O
tasks O
, O
however O
there O
is O
significant O
scope O
for O
improvement O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
entity O
confusion O
to O
explicitly O
evaluate O
whether O
retrievers O
get O
confused O
by O
entities O
in O
the O
same O
amber O
set O
, O
we O
compute O
entity O
confusion O
for O
retrievers O
defined O
as O
the O
percentage O
of O
queries O
where O
the O
retriever O
ranks O
a O
document O
for O
an O
incorrect O
entity O
from O
the O
same O
amber O
set O
over O
the O
gold O
document O
( O
table O
6 O
) O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
we O
find O
that O
across O
retrievers O
, O
tasks O
, O
and O
amber O
collections O
, O
entity O
confusion O
is O
twice O
as O
high O
for O
tail O
entity O
inputs O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
this O
result O
indicates O
that O
the O
popularity O
of O
an O
entity O
for O
a O
given O
name O
plays O
a O
significant O
role O
in O
retrieval O
performance O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
effect O
of O
popularity O
gap O
since O
the O
difference O
in O
popularity O
between O
the O
head O
and O
tail O
entities O
can O
vary O
considerably O
, O
these O
results O
obfuscate O
the O
effect O
of O
the O
size O
of O
the O
popularity O
gap O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
we O
explore O
how O
the O
gap O
in O
popularity O
between O
head O
and O
tail O
entities O
translates O
to O
the O
gaps O
in O
performance O
on O
their O
associated O
queries O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
for O
a O
head O
entity O
with O
popularity O
ph O
and O
a O
tail O
entity O
with O
popularity O
pt O
from O
the O
same O
amber O
set O
, O
we O
calculate O
popularity O
gap O
, O
ph−pt O
pt O
, O
and O
bin O
associated O
head/tail O
inputs O
based O
on O
the O
gap6 O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
for O
each O
bin O
, O
we O
calculate O
the O
difference O
in O
accuracy O
@ O
1 O
between O
the O
head O
and O
tail O
entity O
queries O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
results O
for O
qa O
amber O
sets O
( O
figure O
4 O
) O
show O
that O
there O
is O
a O
strong O
correlation O
between O
the O
popularity O
gap O
and O
the O
difference O
in O
performance O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
end O
to O
end O
results O
we O
evaluate O
end O
to O
end O
performance O
in O
several O
evaluation O
settings O
with O
all O
results O
provided O
in O
table O
7 O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
the O
metrics O
used O
are O
f1 O
for O
slot O
filling O
and O
question O
answering O
and O
accuracy O
for O
fact O
checking O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
in O
the O
“ O
oracle O
” O
setting O
, O
we O
directly O
provide O
the O
downstream O
nlp O
model O
the O
gold O
document O
, O
and O
find O
that O
the O
gap O
between O
head O
entities O
and O
tail O
entities O
is O
fairly O
small O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
this O
suggests O
that O
in O
closed O
nlp O
settings O
, O
where O
the O
gold O
document O
is O
known O
, O
entity O
disambiguation O
is O
not O
a O
major O
concern O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
in O
the O
regular O
retrieval O
setting O
, O
we O
provide O
the O
model O
the O
top O
20 O
documents O
as O
ranked O
by O
a O
retrieval O
system O
( O
blink O
and O
dpr O
) O
, O
and O
find O
that O
retrievers O
still O
perform O
better O
on O
head O
entity O
queries O
( O
see O
appendix O
a O
) O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
the O
downstream O
systems O
that O
use O
retrieved O
documents O
display O
a O
noticeable O
gap O
in O
end-to-end O
performance O
between O
head O
and O
tail O
entity O
inputs O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
this O
is O
expected O
, O
as O
retrieval O
systems O
perform O
worse O
on O
tail O
entities O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
user O
study O
amber O
sets O
are O
created O
in O
a O
largely O
automatic O
process O
, O
raising O
questions O
about O
data O
quality O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
to O
address O
these O
questions O
, O
we O
conduct O
a O
small O
user O
study O
on O
amber O
sets O
to O
evaluate O
whether O
the O
queries O
are O
resolvable O
by O
humans O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
we O
present O
a O
query O
from O
a O
qa O
amber O
set O
along O
with O
three O
documents O
for O
the O
entities O
from O
the O
same O
amber O
set O
, O
one O
of O
which O
is O
the O
gold O
document O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
we O
first O
ask O
the O
user O
to O
select O
the O
relevant O
document O
, O
then O
we O
ask O
the O
user O
to O
select O
an O
answer O
span O
from O
the O
selected O
document O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
in O
total O
, O
we O
asked O
7 O
subjects O
to O
examine O
about O
120 O
queries O
across O
amberh O
and O
amber-n O
, O
and O
computed O
their O
accuracy O
in O
6bin O
width O
of O
20 O
% O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
queries O
with O
a O
popularity O
gap O
higher O
than O
100 O
% O
are O
binned O
into O
the O
highest O
bin O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
selecting O
the O
correct O
document O
and O
answer O
( O
table O
8 O
) O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
we O
also O
compare O
retrievers O
for O
this O
task O
, O
i.e O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
select O
from O
3 O
documents O
for O
the O
same O
queries O
, O
and O
find O
that O
humans O
perform O
very O
well O
on O
the O
document O
selection O
task O
compared O
to O
retrievers O
on O
both O
sets O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
we O
also O
compare O
the O
accuracy O
of O
answer O
selection O
, O
and O
see O
that O
the O
closed O
domain O
nlp O
model O
( O
fine-tuned O
bert O
) O
is O
as O
almost O
accurate O
as O
humans O
on O
the O
same O
set O
of O
queries7 O
. O

section 11
id pdf2json/2021.acl-long.345.pdf.json
this O
further O
confirms O
that O
closed O
nlp O
models O
are O
not O
the O
source O
of O
bias O
towards O
head O
entities O
, O
but O
the O
retrievers O
are O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
entity O
ambiguity O
as O
previously O
mentioned O
, O
entity O
ambiguity O
is O
when O
a O
single O
name O
can O
match O
multiple O
entities O
in O
a O
knowledge O
source O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
entity O
ambiguity O
has O
been O
most O
studied O
in O
the O
context O
of O
entity O
linking O
( O
rao O
et O
al. O
, O
2013 O
) O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
to O
improve O
disambiguation O
, O
entity O
linkers O
have O
included O
auxiliary O
information O
such O
as O
entity O
types O
( O
onoe O
and O
durrett O
, O
2020 O
) O
and O
entity O
descriptions O
( O
logeswaran O
et O
al. O
, O
2019 O
) O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
a O
recent O
thread O
of O
work O
aims O
to O
study O
how O
language O
models O
recall O
and O
leverage O
information O
about O
names O
and O
entities O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
prabhakaran O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
( O
2019 O
) O
shows O
that O
names O
can O
have O
a O
measurable O
effect O
on O
the O
prediction O
of O
sentiment O
analysis O
systems O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
shwartz O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
( O
2020 O
) O
demonstrates O
that O
pre-trained O
language O
models O
implicitly O
resolve O
entity O
ambiguity O
by O
grounding O
names O
to O
entities O
based O
on O
the O
pretraining O
corpus O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
the O
problem O
of O
entity O
ambiguity O
also O
appears O
implicitly O
in O
entity-centric O
tasks O
such O
as O
determining O
the O
semantic O
relatedness O
between O
entities O
( O
hoffart O
et O
al. O
, O
2012 O
) O
and O
entity-oriented O
7the O
relatively O
low O
answer O
score O
is O
due O
to O
artifacts O
in O
using O
em O
for O
qa O
evaluation O
, O
and O
is O
consistent O
with O
human O
performance O
on O
span O
selection O
( O
rajpurkar O
et O
al. O
, O
2016 O
) O
) O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
search O
( O
balog O
et O
al. O
, O
2010 O
, O
2011 O
) O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
we O
draw O
inspiration O
from O
these O
works O
by O
studying O
entity O
ambiguity O
in O
the O
context O
of O
open-domain O
nlp O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
popularity O
bias O
system O
’ O
s O
that O
perform O
worse O
on O
the O
long-tail O
suffer O
from O
what O
is O
known O
as O
popularity O
bias O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
this O
problem O
has O
been O
studied O
extensively O
in O
the O
recommendation O
systems O
literature O
, O
where O
recommendation O
systems O
are O
known O
to O
often O
ignore O
the O
long-tail O
of O
products O
and O
instead O
recommend O
very O
popular O
items O
( O
abdollahpouri O
et O
al. O
, O
2017 O
; O
chen O
et O
al. O
, O
2020 O
) O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
this O
has O
the O
effect O
of O
unfairly O
hurting O
users O
who O
would O
prefer O
these O
less-popular O
items O
( O
abdollahpouri O
et O
al. O
, O
2019 O
; O
ciampaglia O
et O
al. O
, O
2018 O
) O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
we O
explore O
popularity O
bias O
from O
the O
angle O
of O
retrieval O
as O
opposed O
to O
recommendation O
, O
and O
find O
popularity O
bias O
exists O
in O
retrieval O
systems O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
open-domain O
ambiguity O
ambiguity O
is O
an O
inherent O
problem O
when O
it O
comes O
to O
open-domain O
reasoning O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
min O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
( O
2020 O
) O
showed O
that O
half O
of O
instances O
sampled O
from O
natural O
questions O
are O
ambiguous O
, O
with O
multiple O
correct O
answers O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
amber O
sets O
are O
similar O
in O
that O
the O
ambiguity O
is O
in O
terms O
of O
the O
entity O
in O
the O
query O
, O
however O
, O
in O
contrast O
to O
natural O
questions O
, O
amber O
set O
inputs O
have O
been O
constructed O
such O
that O
the O
ambiguity O
is O
resolvable O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
challenge O
sets O
there O
have O
been O
many O
evaluation O
sets O
specifically O
designed O
to O
assess O
a O
model O
’ O
s O
ability O
to O
handle O
a O
specific O
phenomenon O
( O
naik O
et O
al. O
, O
2018 O
; O
zhao O
et O
al. O
, O
2018 O
; O
mccoy O
et O
al. O
, O
2019 O
; O
warstadt O
et O
al. O
, O
2020 O
; O
richardson O
et O
al. O
, O
2020 O
; O
jeretic O
et O
al. O
, O
2020 O
; O
ribeiro O
et O
al. O
, O
2019 O
) O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
some O
of O
these O
challenge O
sets O
, O
similar O
to O
amber O
sets O
, O
use O
templates O
to O
generate O
a O
large O
amount O
of O
evaluation O
data O
quickly O
( O
richardson O
et O
al. O
, O
2020 O
; O
mccoy O
et O
al. O
, O
2019 O
; O
ribeiro O
et O
al. O
, O
2020 O
) O
. O

section 12
id pdf2json/2021.acl-long.345.pdf.json
amber O
sets O
can O
be O
viewed O
as O
a O
challenge O
set O
for O
assessing O
opendomain O
systems O
’ O
ability O
to O
handle O
entity O
ambiguity O
. O

section 13
id pdf2json/2021.acl-long.345.pdf.json
entity O
ambiguity O
is O
an O
inherent O
problem O
in O
retrieval O
, O
as O
many O
entities O
can O
share O
a O
name O
. O

section 13
id pdf2json/2021.acl-long.345.pdf.json
for O
evaluating O
disambiguation O
capabilities O
of O
retrievers O
, O
we O
introduce O
amber O
sets O
; O
an O
amber O
set O
is O
a O
collection O
of O
task-specific O
queries O
about O
entities O
that O
share O
a O
name O
, O
but O
the O
queries O
have O
sufficient O
content O
to O
resolve O
the O
correct O
entity O
. O

section 13
id pdf2json/2021.acl-long.345.pdf.json
we O
create O
a O
broad O
range O
of O
amber O
sets O
, O
covering O
many O
entity O
types O
, O
with O
input O
queries O
for O
three O
open-domain O
nlp O
tasks O
: O
fact O
checking O
, O
slot O
filling O
, O
and O
question O
answering O
. O

section 13
id pdf2json/2021.acl-long.345.pdf.json
our O
experiments O
demonstrate O
the O
struggles O
of O
current O
retrievers O
in O
handling O
entity O
ambiguity O
. O

section 13
id pdf2json/2021.acl-long.345.pdf.json
in O
particular O
, O
we O
find O
that O
the O
popularity O
of O
an O
entity O
in O
relation O
to O
other O
entities O
that O
share O
a O
name O
plays O
a O
significant O
role O
during O
disambiguation O
. O

section 13
id pdf2json/2021.acl-long.345.pdf.json
for O
instance O
, O
we O
find O
that O
all O
tested O
retrievers O
are O
about O
twice O
as O
likely O
to O
retrieve O
erroneous O
documents O
when O
dealing O
with O
less O
popular O
entities O
than O
the O
most O
popular O
entity O
with O
the O
same O
name O
. O

section 13
id pdf2json/2021.acl-long.345.pdf.json
future O
goals O
include O
improving O
entity O
disambiguation O
capabilities O
of O
retrievers O
, O
perhaps O
more O
directly O
incorporating O
ideas O
from O
entity O
linking O
and O
coreference O
resolution O
. O

section 13
id pdf2json/2021.acl-long.345.pdf.json
the O
amber O
sets O
and O
the O
code O
for O
the O
generation O
pipeline O
is O
available O
at O
https O
: O
//github.com/anthonywchen/amber-sets O
. O

section 14
id pdf2json/2021.acl-long.345.pdf.json
we O
would O
like O
to O
thank O
jo O
daiber O
, O
michael O
tu O
, O
russ O
webb O
, O
matt O
gardner O
, O
robert O
logan O
, O
sherry O
tongshuang O
wu O
, O
and O
the O
anonymous O
reviewers O
for O
providing O
valuable O
feedback O
for O
our O
work O
. O

section 14
id pdf2json/2021.acl-long.345.pdf.json
this O
work O
is O
funded O
in O
part O
by O
the O
darpa O
mcs O
program O
under O
contract O
no O
. O

section 14
id pdf2json/2021.acl-long.345.pdf.json
n660011924033 O
with O
the O
united O
states O
office O
of O
naval O
research O
. O

section 15
id pdf2json/2021.acl-long.345.pdf.json
we O
provide O
results O
for O
top-20 O
retrieval O
in O
table O
9 O
. O

section 15
id pdf2json/2021.acl-long.345.pdf.json
top-20 O
retrieval O
is O
used O
for O
providing O
documents O
in O
the O
end-to-end O
evaluation O
setting O
. O

section 15
id pdf2json/2021.acl-long.345.pdf.json
in O
this O
setting O
, O
retrieval O
accuracy O
measures O
whether O
a O
gold O
document O
appears O
in O
one O
of O
the O
top-20 O
retrieved O
documents O
. O

section 15
id pdf2json/2021.acl-long.345.pdf.json
similar O
to O
top-1 O
retrieval O
, O
retrievers O
continue O
to O
perform O
better O
on O
head O
queries O
. O

section 16
id pdf2json/2021.acl-long.345.pdf.json
table O
10 O
contains O
the O
templates O
used O
to O
instantiate O
the O
task-specific O
inputs O
. O

section 16
id pdf2json/2021.acl-long.345.pdf.json
templates O
were O
written O
on O
a O
per-property O
basis O
. O

section 16
id pdf2json/2021.acl-long.345.pdf.json
we O
note O
that O
many O
of O
the O
properties O
share O
templates O
that O
are O
very O
similar O
. O

section 17
id pdf2json/2021.acl-long.345.pdf.json
all O
experiments O
( O
e.g. O
, O
training O
baselines O
, O
generating O
amber O
sets O
, O
etc O
. O
) O

section 17
id pdf2json/2021.acl-long.345.pdf.json
were O
conducted O
on O
a O
machine O
with O
500 O
gb O
of O
ram O
, O
64 O
cpus O
, O
and O
using O
an O
nvidia O
titanrtx O
with O
24 O
gb O
of O
ram O
. O

section 17
id pdf2json/2021.acl-long.345.pdf.json
retrieval O
on O
a O
collection O
of O
amber O
sets O
takes O
about O
12 O
hours O
for O
the O
most O
time-consuming O
retriever O
, O
blink O
. O

section 17
id pdf2json/2021.acl-long.345.pdf.json
training O
a O
downstream O
model O
takes O
roughly O
5 O
hours O
and O
inference O
on O
a O
collection O
of O
amber O
sets O
takes O
less O
than O
30 O
minutes O
. O

section 18
id pdf2json/2021.acl-long.345.pdf.json
for O
blink O
, O
dpr O
, O
and O
tf-idf O
, O
we O
use O
the O
retriever O
code O
in O
the O
kilt O
repository O
released O
by O
facebook8 O
. O

section 18
id pdf2json/2021.acl-long.345.pdf.json
for O
bootleg O
, O
we O
use O
the O
code O
provided O
by O
the O
hazy O
research O
group9 O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
for O
question O
answering O
, O
we O
train O
a O
roberta-large O
model O
on O
natural O
questions O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
we O
use O
the O
negative O
documents O
in O
natural O
questions O
to O
train O
a O
“ O
noanswer O
” O
classifier O
using O
the O
[ O
cls O
] O
token O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
during O
inference O
, O
we O
take O
the O
highest-scoring O
span O
where O
the O
answer O
is O
not O
classified O
as O
“ O
no-answer O
” O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
for O
slot O
filling O
, O
we O
train O
a O
bart-base O
model O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
for O
each O
slot O
filling O
instance O
, O
we O
train O
with O
the O
top O
non-gold O
document O
retrieved O
by O
tf-idf O
as O
a O
negative O
document O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
for O
this O
negative O
document O
, O
we O
train O
the O
model O
to O
generate O
a O
“ O
none O
” O
token O
, O
and O
during O
inference O
, O
we O
take O
the O
highest O
scoring O
answer O
that O
is O
8https O
: O
//github.com/facebookresearch/ O
kilt O
9https O
: O
//github.com/hazyresearch/ O
bootleg O
not O
“ O
none O
” O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
for O
fact O
checking O
, O
we O
train O
a O
three-way O
( O
i.e. O
, O
supports O
, O
refutes O
, O
neutral O
) O
bertbase O
classifier O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
similar O
to O
slot O
filling O
, O
we O
train O
with O
the O
top O
non-gold O
document O
retrieved O
by O
tf-idf O
as O
a O
negative O
document O
and O
train O
the O
model O
to O
classify O
this O
negative O
document O
as O
neutral O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
during O
inference O
, O
we O
take O
the O
highest O
scoring O
prediction O
that O
is O
not O
neutral O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
when O
training O
baselines O
models O
, O
we O
do O
not O
tune O
over O
hyperparameters O
and O
train O
with O
a O
batch O
size O
of O
32 O
for O
3 O
epochs O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
property O
question O
answering O
template O
fact O
checking O
template O
a O
m O
be O
r O
-h O
instrument O
which O
musical O
instrument O
did O
$ O
name O
play O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
musical O
instrument O
does O
$ O
name O
play O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
instrument O
does O
$ O
name O
play O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
plays O
the O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
plays O
the O
musical O
instrument O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
the O
$ O
object O
is O
played O
by O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
movement O
what O
movement O
did O
$ O
name O
participate O
in O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
which O
movement O
is O
$ O
name O
associated O
with O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
movement O
is O
$ O
name O
associated O
with O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
was O
a O
member O
of O
the O
$ O
object O
movement O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
participated O
in O
the O
$ O
object O
movement O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
was O
a O
part O
of O
the O
$ O
object O
movement O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
appears O
in O
what O
works O
does O
the O
fictional O
entity O
$ O
name O
appear O
in O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
work O
is O
the O
character O
$ O
name O
present O
in O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
which O
work O
was O
the O
character O
$ O
name O
in O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
is O
a O
character O
in O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
is O
a O
fictional O
character O
in O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
features O
the O
fictional O
character O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
doctoral O
student O
who O
were O
the O
doctoral O
students O
of O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
who O
are O
$ O
name O
’ O
s O
doctoral O
students O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
who O
did O
$ O
name O
advise O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
has O
a O
doctoral O
student O
named O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
’ O
s O
doctoral O
student O
is O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
advised O
their O
student O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
military O
branch O
what O
branch O
of O
the O
military O
does O
$ O
name O
belong O
to O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
which O
military O
branch O
does O
$ O
name O
belong O
to O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
military O
branch O
is O
$ O
name O
affiliated O
with O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
is O
a O
member O
of O
the O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
belongs O
to O
the O
military O
branch O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
belongs O
to O
the O
$ O
object O
branch O
of O
the O
military O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
sports O
position O
what O
is O
the O
position O
that O
$ O
name O
plays O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
position O
does O
$ O
name O
play O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
which O
position O
does O
$ O
name O
play O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
plays O
the O
$ O
object O
position O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
plays O
as O
a O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
sports O
team O
$ O
name O
plays O
for O
which O
team O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
team O
does O
$ O
name O
play O
for O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
which O
team O
does O
$ O
name O
play O
for O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
is O
a O
player O
on O
the O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
plays O
for O
the O
$ O
object O
team O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
plays O
for O
the O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
battles O
or O
wars O
what O
were O
the O
wars O
that O
$ O
name O
participated O
in O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
which O
battle O
did O
$ O
name O
fight O
in O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
which O
war O
did O
$ O
name O
fight O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
fought O
in O
the O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
fought O
in O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
sport O
which O
sport O
does O
$ O
name O
participate O
in O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
which O
sport O
does O
$ O
name O
play O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
sport O
does O
$ O
name O
play O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
plays O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
plays O
the O
sport O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
a O
m O
be O
r O
-n O
performer O
who O
performs O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
who O
is O
the O
performer O
of O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
who O
performed O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
performs O
in O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
is O
the O
performer O
of O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
was O
performed O
by O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
record O
label O
what O
is O
the O
record O
label O
of O
$ O
name O
. O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
is O
the O
record O
label O
for O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
belongs O
to O
which O
record O
label O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
is O
the O
record O
label O
for O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
’ O
s O
record O
label O
is O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
tracklist O
what O
song O
appears O
in O
the O
album O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
song O
appears O
on O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
are O
the O
tracks O
in O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
belongs O
to O
$ O
object O
tracklist O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
is O
on O
the O
release O
of O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
is O
a O
song O
in O
the O
$ O
name O
tracklist O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
industry O
which O
industry O
is O
$ O
name O
in O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
in O
what O
industry O
is O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
is O
$ O
name O
’ O
s O
industry O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
is O
in O
the O
industry O
of O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
the O
company O
$ O
name O
is O
in O
the O
$ O
object O
industry O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
’ O
s O
industry O
is O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
population O
what O
is O
the O
total O
population O
of O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
what O
is O
the O
population O
of O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
how O
many O
people O
live O
in O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
the O
population O
of O
$ O
name O
is O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
’ O
s O
population O
is O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
has O
a O
population O
of O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
cast O
member O
who O
acted O
in O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
who O
is O
a O
cast O
member O
on O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
who O
starred O
in O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
was O
a O
cast O
member O
in O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
appeared O
in O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
acted O
in O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
screenwriter O
who O
was O
the O
screenwriter O
for O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
who O
was O
screenwriter O
for O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
who O
is O
$ O
name O
’ O
s O
screenwriter O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
’ O
s O
screenwriter O
is O
$ O
object O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
wrote O
the O
screenplay O
of O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
object O
screenwrote O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
# O
seasons O
how O
many O
seasons O
are O
there O
in O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
how O
many O
seasons O
does O
$ O
name O
have O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
how O
many O
seasons O
were O
there O
in O
$ O
name O
? O

section 19
id pdf2json/2021.acl-long.345.pdf.json
there O
were O
$ O
object O
seasons O
in O
$ O
name O
. O

section 19
id pdf2json/2021.acl-long.345.pdf.json
$ O
name O
has O
$ O
object O
seasons O
. O

section TITLE
id pdf2json/2021.acl-long.155.pdf.json
glancing O
transformer O
for O
non-autoregressive O
neural O
machine O
translation O

section ABSTRACT
id pdf2json/2021.acl-long.155.pdf.json
recent O
work O
on O
non-autoregressive O
neural O
machine O
translation O
( O
nat O
) O
aims O
at O
improving O
the O
efficiency O
by O
parallel O
decoding O
without O
sacrificing O
the O
quality O
. O

section ABSTRACT
id pdf2json/2021.acl-long.155.pdf.json
however O
, O
existing O
nat O
methods O
are O
either O
inferior O
to O
transformer O
or O
require O
multiple O
decoding O
passes O
, O
leading O
to O
reduced O
speedup O
. O

section ABSTRACT
id pdf2json/2021.acl-long.155.pdf.json
we O
propose O
the O
glancing O
language O
model O
( O
glm O
) O
for O
single-pass O
parallel O
generation O
models O
. O

section ABSTRACT
id pdf2json/2021.acl-long.155.pdf.json
with O
glm O
, O
we O
develop O
glancing O
transformer O
( O
glat O
) O
for O
machine O
translation O
. O

section ABSTRACT
id pdf2json/2021.acl-long.155.pdf.json
with O
only O
single-pass O
parallel O
decoding O
, O
glat O
is O
able O
to O
generate O
high-quality O
translation O
with O
8×-15× O
speedup O
. O

section ABSTRACT
id pdf2json/2021.acl-long.155.pdf.json
note O
that O
glat O
does O
not O
modify O
the O
network O
architecture O
, O
which O
is O
a O
training O
method O
to O
learn O
word O
interdependency O
. O

section ABSTRACT
id pdf2json/2021.acl-long.155.pdf.json
experiments O
on O
multiple O
wmt O
language O
directions O
show O
that O
glat O
outperforms O
all O
previous O
single O
pass O
non-autoregressive O
methods O
, O
and O
is O
nearly O
comparable O
to O
transformer O
, O
reducing O
the O
gap O
to O
0.25-0.9 O
bleu O
points O
. O

section 0
id pdf2json/2021.acl-long.155.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
1993–2003 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.155.pdf.json
©2021 O
association O
for O
computational O
linguistics O
1993 O

section 1
id pdf2json/2021.acl-long.155.pdf.json
transformer O
has O
been O
the O
most O
widely O
used O
architecture O
for O
machine O
translation O
( O
vaswani O
et O
al. O
, O
2017 O
) O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
despite O
its O
strong O
performance O
, O
the O
decoding O
of O
transformer O
is O
inefficient O
as O
it O
adopts O
the O
sequential O
auto-regressive O
factorization O
for O
its O
probability O
model O
( O
figure O
1a O
) O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
recent O
work O
such O
as O
the O
non-autoregressive O
transformer O
( O
nat O
) O
, O
aims O
to O
decode O
target O
tokens O
in O
parallel O
to O
speed O
up O
the O
generation O
( O
gu O
et O
al. O
, O
2018 O
) O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
however O
, O
the O
vanilla O
nat O
still O
lags O
behind O
the O
transformer O
in O
translation O
quality O
– O
with O
a O
gap O
of O
about O
7.0 O
bleu O
points O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
nat O
assumes O
the O
conditional O
independence O
of O
the O
target O
tokens O
given O
the O
source O
sentence O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
we O
suspect O
that O
nat O
’ O
s O
conditional O
independence O
assumption O
prevents O
learning O
word O
interdependency O
in O
the O
target O
∗the O
work O
was O
done O
when O
the O
first O
author O
was O
an O
intern O
at O
bytedance O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
̂y1 O
̂y2 O
̂y4 O
̂y5 O
̂y3 O
h1 O
h2 O
h3 O
h4 O
h5 O
nat O
decodingh O
h′ O
glancing O
sampling O
hamming O
distance O
n O
( O
̂y O
, O
y O
) O
= O
3 O
y1 O
y2 O
y3 O
y4 O
y5 O
̂y1 O
̂y2 O
̂y4 O
̂y5 O
̂y3 O
y1 O
y3 O
y5 O
replace O
inputs O
0.8 O
0.5 O
0.7 O
0.6 O
0.9 O
h2 O
h4 O
y1 O
y2 O
y1 O
y2 O
y5 O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y3 O
y4 O
y3 O
y4 O
[ O
bos O
] O
y1 O
y2 O
y5 O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y3 O
y4 O
h2 O
h4h1 O
h3 O
h5 O
a O
tt O
en O
tio O
n O
r O
an O
do O
m O
m O
as O
ki O
ng O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y1 O
y4 O
y5 O
[ O
mask O
] O
[ O
mask O
] O
y2 O
y3y1 O
y5y4 O
a O
tt O
en O
tio O
n O
an O
apple O
in O
the O
car O
ein O
apfel O
im O
auto O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y1 O
h2 O
y5h4y3 O
y2 O
y4 O
g O
la O
nc O
in O
g O
sa O
m O
pl O
in O
g O
y3y1 O
y5 O
ein O
apfel O
im O
auto O
an O
apple O
in O
the O
car O
a O
tt O
en O
tio O
n O
ein O
apfel O
im O
auto O
ein O
apfel O
im O
auto O
apple O
in O
apple O
the O
an O
the O
car O
an O
apple O
in O
the O
an O
in O
car O
a O
tt O
en O
tio O
n O
( O
a O
) O
sequential O
lm O
̂y1 O
̂y2 O
̂y4 O
̂y5 O
̂y3 O
h1 O
h2 O
h3 O
h4 O
h5 O
nat O
decodingh O
h′ O
glancing O
sampling O
hamming O
distance O
n O
( O
̂y O
, O
y O
) O
= O
3 O
y1 O
y2 O
y3 O
y4 O
y5 O
̂y1 O
̂y2 O
̂y4 O
̂y5 O
̂y3 O
y1 O
y3 O
y5 O
replace O
inputs O
0.8 O
0.5 O
0.7 O
0.6 O
0.9 O
h2 O
h4 O
y1 O
y2 O
y1 O
y2 O
y5 O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y3 O
y4 O
y3 O
y4 O
[ O
bos O
] O
y1 O
y2 O
y5 O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y3 O
y4 O
h2 O
4h1 O
3 O
5 O
a O
tt O
en O
tio O
n O
r O
an O
do O
m O
m O
as O
ki O
ng O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y1 O
y4 O
y5 O
[ O
mask O
] O
[ O
mask O
] O
y2 O
y3y1 O
y5y4 O
a O
tt O
en O
tio O
n O
an O
apple O
in O
the O
car O
ein O
apfel O
im O
auto O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y1 O
h2 O
y54y3 O
y2 O
y4 O
g O
la O
nc O
in O
g O
sa O
m O
pl O
in O
g O
y3y1 O
y5 O
ein O
apfel O
im O
auto O
an O
apple O
in O
the O
car O
a O
tt O
en O
tio O
n O
ein O
apfel O
im O
auto O
ein O
apfel O
im O
auto O
apple O
in O
apple O
the O
an O
the O
car O
an O
apple O
in O
the O
an O
in O
car O
a O
tt O
en O
tio O
n O
( O
b O
) O
cond O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
independent O
lm O
̂ O
̂ O
̂ O
5̂ O
̂ O
5 O
′ O
li O
i O
i O
t O
( O
, O
̂ O
) O
5 O
̂ O
̂ O
̂ O
5̂ O
̂ O
1 O
3 O
5 O
eplace O
inputs O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
2 O
4 O
y1 O
y2 O
y1 O
y2 O
y5 O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y3 O
y4 O
y3 O
y4 O
[ O
bos O
] O
y1 O
y2 O
y5 O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y3 O
y4 O
h2 O
h4h1 O
h3 O
h5 O
a O
tt O
en O
tio O
n O
r O
an O
do O
m O
m O
as O
ki O
ng O
ec O
er O
[ O
as O
] O
[ O
as O
] O
y2 O
y3y1 O
y5y4 O
a O
tt O
en O
tio O
n O
an O
apple O
in O
the O
car O
ein O
pfel O
i O
uto O
ec O
er O
2 O
4 O
2 O
y4 O
g O
la O
nc O
in O
g O
sa O
m O
pl O
in O
g O
31 O
y5 O
ein O
pfel O
i O
uto O
an O
apple O
in O
the O
car O
a O
tt O
en O
tio O
n O
i O
f O
l O
i O
i O
t O
apple O
in O
apple O
the O
t O
r O
an O
apple O
in O
the O
i O
r O
a O
tt O
en O
tio O
n O
( O
c O
) O
masked O
lm O
( O
mlm O
) O
̂y1 O
̂y2 O
̂y4 O
̂y5 O
̂y3 O
h1 O
h2 O
h3 O
h4 O
h5 O
nat O
decodingh O
h′ O
glancing O
sampling O
hamming O
distance O
n O
( O
̂y O
, O
y O
) O
= O
3 O
y1 O
y2 O
y3 O
y4 O
y5 O
̂y1 O
̂y2 O
̂y4 O
̂y5 O
̂y3 O
y1 O
y3 O
y5 O
replace O
inputs O
0.8 O
0.5 O
0.7 O
0.6 O
0.9 O
h2 O
h4 O
y1 O
y2 O
y1 O
y2 O
y5 O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y3 O
y4 O
y3 O
y4 O
[ O
bos O
] O
y1 O
y2 O
y5 O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y3 O
y4 O
h2 O
h4h1 O
h3 O
h5 O
a O
tt O
en O
tio O
n O
r O
an O
do O
m O
m O
as O
ki O
ng O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y1 O
y4 O
y5 O
[ O
mask O
] O
[ O
mask O
] O
y2 O
y3y1 O
y5y4 O
a O
tt O
en O
tio O
n O
an O
apple O
in O
the O
car O
ein O
apfel O
im O
auto O
decoder O
encoder O
x1 O
x2 O
x3 O
x4 O
y1 O
h2 O
y5h4y3 O
y2 O
y4 O
g O
la O
nc O
in O
g O
sa O
m O
pl O
in O
g O
y3y1 O
y5 O
ein O
apfel O
im O
auto O
an O
apple O
in O
the O
car O
a O
tt O
en O
tio O
n O
ein O
apfel O
im O
auto O
ein O
apfel O
im O
auto O
apple O
in O
apple O
the O
an O
the O
car O
an O
apple O
in O
the O
an O
in O
car O
a O
tt O
en O
tio O
n O
( O
d O
) O
glancing O
lm O
( O
glm O
) O
figure O
1 O
: O
probabilistic O
models O
for O
machine O
translation O
methods O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
( O
b O
) O
vanilla O
nat O
uses O
conditional O
indepedent O
lm O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
( O
c O
) O
mask-predict O
nat O
uses O
mlm O
and O
requires O
multiple O
passes O
of O
decoding O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
( O
d O
) O
our O
proposed O
glm O
leverages O
the O
decoder O
prediction O
to O
decide O
g O
ancing O
sampling O
policy O
during O
training O
and O
only O
requires O
one O
pass O
of O
decoding O
during O
inference O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
sentence O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
notice O
that O
such O
word O
interdependency O
is O
crucial O
, O
as O
the O
transformer O
explicitly O
captures O
that O
via O
decoding O
from O
left O
to O
right O
( O
figure O
1a O
) O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
several O
remedies O
are O
proposed O
( O
ghazvininejad O
et O
al. O
, O
2019 O
; O
gu O
et O
al. O
, O
2019 O
) O
to O
capture O
word O
interdependency O
while O
keeping O
parallel O
decoding O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
their O
common O
idea O
is O
to O
decode O
the O
target O
tokens O
iteratively O
while O
each O
pass O
of O
decoding O
is O
trained O
using O
the O
masked O
language O
model O
( O
figure O
1c O
) O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
since O
these O
methods O
require O
multiple O
passes O
of O
decoding O
, O
its O
generation O
speed O
is O
measurably O
slower O
than O
the O
vanilla O
nat O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
with O
single-pass O
generation O
only O
, O
these O
methods O
still O
largely O
lag O
behind O
the O
autoregressive O
transformer O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
one O
open O
question O
is O
whether O
a O
complete O
parallel O
decoding O
model O
can O
achieve O
comparable O
machine O
translation O
performance O
to O
the O
transformer O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
it O
should O
be O
non-autoregressive O
and O
take O
only O
one O
pass O
of O
decoding O
during O
the O
inference O
time O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
to O
address O
the O
quest O
, O
we O
propose O
glancing O
language O
model O
( O
glm O
) O
, O
a O
new O
method O
to O
train O
a O
probabilistic O
sequence O
model O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
based O
on O
glm O
, O
we O
develop O
the O
glancing O
transformer O
( O
glat O
) O
for O
neural O
machine O
translation O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
it O
achieves O
parallel O
text O
generation O
with O
only O
single O
decoding O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
yet O
, O
it O
outperforms O
previous O
nat O
methods O
and O
achieves O
comparable O
performance O
as O
the O
strong O
transformer O
baseline O
in O
multiple O
cases O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
intuitively O
, O
glm O
adopts O
a O
adaptive O
glancing O
sampling O
strategy O
, O
which O
glances O
at O
some O
fragments O
of O
the O
reference O
if O
the O
reference O
is O
too O
difficult O
to O
fit O
in O
the O
training O
of O
glat O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
correspondingly O
, O
when O
the O
model O
is O
well O
tuned O
, O
it O
will O
adaptively O
reduce O
the O
percentage O
of O
glancing O
sampling O
, O
making O
sure O
that O
the O
resulting O
model O
could O
learn O
to O
generate O
the O
whole O
sentence O
in O
the O
single-pass O
fashion O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
the O
gradual O
learning O
process O
smooths O
the O
learning O
curve O
of O
single-pass O
parallel O
generation O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
specifically O
, O
our O
proposed O
glm O
differs O
from O
mlm O
in O
two O
aspects O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
firstly O
, O
glm O
proposes O
an O
adaptive O
glancing O
sampling O
strategy O
, O
which O
enables O
glat O
to O
generate O
sentences O
in O
a O
one-iteration O
way O
, O
working O
by O
gradual O
training O
instead O
of O
iterative O
inference O
( O
see O
figure O
1d O
) O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
generally O
, O
glm O
is O
quite O
similar O
to O
curriculum O
learning O
( O
bengio O
et O
al. O
, O
2009 O
) O
in O
spirit O
, O
namely O
first O
learning O
to O
generate O
some O
fragments O
and O
gradually O
moving O
to O
learn O
the O
whole O
sentences O
( O
from O
easy O
to O
hard O
) O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
to O
achieve O
the O
adaptive O
glancing O
sampling O
, O
glm O
performs O
decoding O
twice O
in O
training O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
the O
first O
decoding O
is O
the O
same O
as O
the O
vanilla O
nat O
, O
and O
the O
prediction O
accuracy O
indicates O
whether O
the O
current O
reference O
is O
“ O
difficult O
” O
for O
fitting O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
in O
the O
second O
decoding O
, O
glm O
gets O
words O
of O
the O
reference O
via O
glancing O
sampling O
according O
to O
the O
first O
decoding O
, O
and O
learn O
to O
predict O
the O
remaining O
words O
that O
are O
not O
sampled O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
note O
that O
only O
the O
second O
decoding O
will O
update O
the O
model O
parameters O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
secondly O
, O
instead O
of O
using O
the O
[ O
mask O
] O
token O
, O
glm O
directly O
uses O
representations O
from O
the O
encoder O
at O
corresponding O
positions O
, O
which O
is O
more O
natural O
and O
could O
enhance O
the O
interactions O
between O
sampled O
words O
and O
signals O
from O
the O
encoder O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
note O
that O
glat O
does O
not O
modify O
the O
network O
architecture O
, O
which O
is O
a O
training O
method O
to O
explicityly O
learn O
word O
interdependency O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
experimental O
results O
show O
that O
glat O
obtains O
significant O
improvements O
( O
about O
5 O
bleu O
) O
on O
standard O
benchmarks O
compared O
to O
the O
vanilla O
nat O
, O
without O
losing O
inference O
speedup O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
glat O
achieves O
competitive O
results O
against O
iterative O
approaches O
like O
mask-predict O
( O
ghazvininejad O
et O
al. O
, O
2019 O
) O
, O
even O
outperforming O
the O
mask-predict O
model O
on O
wmt14 O
de-en O
and O
wmt16 O
ro-en O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
compared O
to O
the O
strong O
at O
baseline O
, O
glat O
can O
still O
close O
the O
performance O
gap O
within O
0.9 O
bleu O
point O
while O
keeping O
7.9× O
speed-up O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
empirically O
, O
we O
even O
find O
that O
glat O
outperforms O
at O
when O
the O
length O
of O
the O
reference O
is O
less O
than O
20 O
on O
wmt14 O
de-en O
. O

section 1
id pdf2json/2021.acl-long.155.pdf.json
we O
speculate O
this O
is O
because O
glm O
could O
capture O
bidirectional O
context O
for O
generation O
while O
its O
left-to-right O
counterpart O
is O
only O
unidirectional O
, O
which O
indicates O
the O
potential O
of O
parallel O
generation O
approaches O
like O
glat O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
we O
state O
and O
compare O
different O
probability O
models O
for O
machine O
translation O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
a O
machine O
translation O
task O
can O
be O
formally O
defined O
as O
a O
sequence O
to O
sequence O
generation O
problem O
: O
given O
the O
source O
sentence O
x O
= O
{ O
x1 O
, O
x2 O
, O
... O
, O
xn O
} O
, O
to O
generate O
the O
target O
sentence O
y O
= O
{ O
y1 O
, O
y2 O
, O
... O
, O
yt O
} O
according O
to O
the O
conditional O
probability O
p O
( O
y O
|x O
; O
θ O
) O
, O
where O
θ O
denotes O
the O
parameter O
set O
of O
a O
network O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
different O
methods O
factorize O
the O
conditional O
probability O
differently O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
the O
transformer O
uses O
the O
autoregressive O
factorization O
to O
maximize O
the O
following O
likelihood O
: O
lat O
= O
logp O
( O
y O
|x O
; O
θ O
) O
= O
t∑ O
t=1 O
log O
p O
( O
yt|y O
< O
t O
, O
x O
; O
θ O
) O
, O
where O
y O
< O
t O
= O
{ O
[ O
bos O
] O
, O
y1 O
, O
... O
, O
yt−1 O
} O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
for O
simplicity O
, O
we O
omit O
the O
number O
of O
samples O
in O
the O
equation O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
note O
the O
training O
of O
at O
adopts O
left-to-right O
teacher O
forcing O
on O
the O
target O
tokens O
( O
vaswani O
et O
al. O
, O
2017 O
) O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
the O
word O
interdependency O
is O
learned O
in O
a O
unidirectional O
way O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
during O
inference O
, O
the O
preceding O
predicted O
token O
is O
fed O
into O
the O
decoder O
to O
generate O
the O
next O
token O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
the O
vanilla O
nat O
consists O
of O
the O
same O
encoder O
as O
the O
transformer O
and O
a O
parallel O
decoder O
with O
layers O
of O
multi-head O
attention O
( O
gu O
et O
al. O
, O
2018 O
) O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
during O
training O
, O
it O
uses O
the O
conditional O
independent O
factorization O
for O
the O
target O
sentence O
: O
lnat O
= O
t∑ O
t=1 O
logp O
( O
yt|x O
; O
θ O
) O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
nat O
decodingh O
h′ O
glancing O
sampling O
y1 O
y3 O
y5 O
h2 O
h4 O
hamming O
distance O
n O
( O
̂y O
, O
y O
) O
= O
3 O
replace O
inputs O
y1 O
y2 O
y3 O
y4 O
y5 O
̂y1 O
̂y2 O
̂y4 O
̂y5 O
̂y3 O
0.8 O
0.5 O
0.7 O
0.6 O
0.9 O
̂y1 O
̂y2 O
̂y4 O
̂y5 O
̂y3 O
h1 O
h2 O
h3 O
h4 O
h5 O
notice O
that O
, O
nat O
’ O
s O
log-likelihood O
is O
an O
approximation O
to O
the O
full O
log-likelihood O
logp O
( O
y O
|x O
; O
θ O
) O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
during O
inference O
, O
the O
encoder O
representation O
is O
copied O
as O
the O
input O
to O
the O
decoder O
, O
therefore O
all O
tokens O
on O
the O
target O
side O
can O
be O
generated O
in O
parallel O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
such O
a O
conditional O
independence O
assumption O
does O
not O
hold O
in O
general O
, O
which O
explains O
the O
inferior O
performance O
of O
nat O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
multi-pass O
iterative O
decoding O
approaches O
such O
as O
mask-predict O
( O
ghazvininejad O
et O
al. O
, O
2019 O
) O
extends O
the O
vanilla O
nat O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
it O
still O
uses O
the O
conditional O
independent O
factorization O
, O
together O
with O
the O
random O
masking O
scheme O
: O
lmlm O
= O
∑ O
yt∈rm O
( O
y O
) O
log O
p O
( O
yt|φ O
( O
y O
, O
rm O
( O
y O
) O
) O
, O
x O
; O
θ O
) O
, O
where O
rm O
( O
y O
) O
is O
a O
set O
of O
randomly O
selected O
words O
from O
y O
, O
and O
φ O
( O
· O
) O
replaces O
these O
selected O
words O
in O
y O
with O
the O
[ O
mask O
] O
token O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
for O
example O
in O
figure O
1c O
, O
rm O
( O
y O
) O
= O
{ O
y2 O
, O
y3 O
} O
, O
φ O
( O
y O
, O
rm O
( O
y O
) O
) O
= O
{ O
y1 O
, O
[ O
mask O
] O
, O
[ O
mask O
] O
, O
y4 O
, O
y5 O
} O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
the O
number O
of O
masked O
tokens O
distributes O
uniformly O
from O
1 O
to O
the O
total O
number O
of O
tokens O
in O
the O
target O
sequence O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
such O
training O
objective O
is O
used O
to O
learn O
a O
refinement O
model O
θ O
that O
can O
predict O
the O
masked O
tokens O
given O
the O
source O
sentence O
x O
and O
words O
generated O
in O
the O
previous O
iteration O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
the O
vanilla O
nat O
breaks O
word O
interdependency O
, O
while O
mlm O
requires O
multiple O
passes O
of O
decoding O
to O
re-establish O
the O
word O
interdependency O
. O

section 2
id pdf2json/2021.acl-long.155.pdf.json
our O
goal O
in O
this O
work O
is O
to O
design O
a O
better O
probability O
model O
and O
a O
training O
objective O
to O
enable O
word O
interdependency O
learning O
for O
single-pass O
parallel O
generation O
. O

section 3
id pdf2json/2021.acl-long.155.pdf.json
in O
this O
section O
, O
we O
present O
glat O
in O
detail O
. O

section 3
id pdf2json/2021.acl-long.155.pdf.json
glat O
uses O
the O
same O
encoder-decoder O
architecture O
as O
the O
vanilla O
nat O
( O
gu O
et O
al. O
, O
2018 O
) O
. O

section 3
id pdf2json/2021.acl-long.155.pdf.json
glat O
differs O
from O
the O
vanilla O
nat O
in O
that O
it O
explicitly O
encourages O
word O
interdependency O
via O
training O
with O
glancing O
language O
model O
( O
glm O
) O
. O

section 3
id pdf2json/2021.acl-long.155.pdf.json
it O
differs O
from O
the O
iterative O
nat O
with O
mlm O
in O
that O
it O
is O
trained O
to O
produce O
single O
pass O
parallel O
decoding O
while O
mlm O
is O
used O
for O
prediction O
refinement O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
given O
the O
input O
source O
sentence O
x O
= O
{ O
x1 O
, O
x2 O
, O
... O
, O
xn O
} O
, O
the O
task O
is O
to O
predict O
y O
= O
{ O
y1 O
, O
y2 O
, O
... O
, O
yt O
} O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
the O
glancing O
transformer O
( O
glat O
) O
formulates O
a O
glancing O
language O
model O
( O
glm O
) O
during O
training O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
it O
maximizes O
the O
following O
: O
lglm O
= O
∑ O
yt∈gs O
( O
y O
, O
ŷ O
) O
log O
p O
( O
yt|gs O
( O
y O
, O
ŷ O
) O
, O
x O
; O
θ O
) O
( O
1 O
) O
where O
, O
ŷ O
is O
the O
initial O
predicted O
tokens O
, O
and O
gs O
( O
y O
, O
ŷ O
) O
is O
a O
subset O
of O
tokens O
selected O
via O
the O
glancing O
sampling O
strategy O
( O
figure O
2 O
, O
described O
in O
detail O
in O
the O
next O
section O
) O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
the O
glancing O
sampling O
strategy O
selects O
those O
words O
from O
the O
target O
sentence O
by O
comparing O
the O
initial O
prediction O
against O
the O
ground-truth O
tokens O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
it O
selects O
more O
tokens O
and O
feeds O
the O
embeddings O
of O
these O
tokens O
into O
the O
decoder O
input O
if O
the O
network O
’ O
s O
initial O
prediction O
is O
less O
accurate O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
gs O
( O
y O
, O
ŷ O
) O
is O
the O
remaining O
subset O
of O
tokens O
within O
the O
target O
y O
but O
not O
selected O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
the O
training O
loss O
above O
is O
calculated O
against O
these O
remaining O
tokens O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
glat O
adopts O
similar O
encoder-decoder O
architecture O
as O
the O
transformer O
with O
some O
modification O
( O
figure O
1d O
) O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
its O
encoder O
fencis O
the O
same O
multihead O
attention O
layers O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
its O
decoder O
fdec O
include O
multiple O
layers O
of O
multi-head O
attention O
where O
each O
layer O
attends O
to O
the O
full O
sequence O
of O
both O
encoder O
representation O
and O
the O
previous O
layer O
of O
decoder O
representation O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
during O
the O
initial O
prediction O
, O
the O
input O
to O
the O
decoder O
h O
= O
{ O
h1 O
, O
h2 O
, O
... O
, O
ht O
} O
are O
copied O
from O
the O
encoder O
output O
using O
either O
uniform O
copy O
or O
soft O
copy O
( O
wei O
et O
al. O
, O
2019 O
) O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
the O
initial O
tokens O
ŷ O
are O
predicted O
using O
argmax O
decoding O
with O
fdec O
( O
fenc O
( O
x O
; O
θ O
) O
, O
h O
; O
θ O
) O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
to O
calculate O
the O
loss O
lglm O
, O
we O
compare O
the O
initial O
prediction O
ŷ O
against O
the O
ground-truth O
to O
select O
tokens O
within O
the O
target O
sentence O
, O
i.e O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
gs O
( O
y O
, O
ŷ O
) O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
we O
then O
replace O
those O
sampled O
indices O
of O
h O
’ O
s O
with O
corresponding O
target O
word O
embeddings O
, O
h O
′ O
= O
rp O
( O
embyt∈gs O
( O
y O
, O
ŷ O
) O
( O
yt O
) O
, O
h O
) O
, O
where O
rp O
replaces O
the O
corresponding O
indices O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
namely O
, O
if O
a O
token O
in O
the O
target O
is O
sampled O
, O
its O
word O
embedding O
replaces O
the O
corresponding O
h. O
here O
the O
word O
embeddings O
are O
obtained O
from O
the O
softmax O
embedding O
matrix O
of O
the O
decoder O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
the O
updated O
h O
′ O
is O
then O
fed O
into O
the O
decoder O
fdec O
again O
to O
calculate O
the O
output O
token O
probability O
. O

section 4
id pdf2json/2021.acl-long.155.pdf.json
specifically O
, O
the O
output O
probabilities O
of O
remaining O
tokens O
p O
( O
yt|gs O
( O
y O
, O
ŷ O
) O
, O
x O
; O
θ O
) O
are O
computed O
with O
fdec O
( O
h O
′ O
, O
fenc O
( O
x O
; O
θ O
) O
; O
θ O
) O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
one O
important O
component O
of O
glm O
is O
to O
adaptively O
select O
the O
positions O
of O
tokens O
from O
the O
target O
sentence O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
those O
selected O
tokens O
provide O
“ O
correct O
” O
information O
from O
the O
ground-truth O
target O
, O
therefore O
it O
helps O
training O
the O
decoder O
to O
predict O
the O
rest O
nonselected O
tokens O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
intuitively O
, O
our O
adaptive O
sampling O
strategy O
guides O
the O
model O
to O
first O
learn O
the O
generation O
of O
fragments O
and O
then O
gradually O
turn O
to O
the O
whole O
sentences O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
our O
glancing O
sampling O
strategy O
selects O
many O
words O
at O
the O
start O
of O
the O
training O
, O
when O
the O
model O
is O
not O
yet O
well O
tuned O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
as O
the O
model O
gets O
better O
progressively O
, O
the O
sampling O
strategy O
will O
sample O
fewer O
words O
to O
enable O
the O
model O
to O
learn O
the O
parallel O
generation O
of O
the O
whole O
sentence O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
note O
that O
the O
sampling O
strategy O
is O
crucial O
in O
the O
training O
of O
glat O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
as O
illustrated O
in O
figure O
2 O
, O
the O
glancing O
sampling O
could O
be O
divided O
into O
two O
steps O
: O
first O
deciding O
a O
sampling O
number O
s O
, O
and O
then O
randomly O
selecting O
s O
words O
from O
the O
reference O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
the O
sampling O
number O
s O
will O
be O
larger O
when O
the O
model O
is O
poorly O
trained O
and O
decreases O
along O
the O
training O
process O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
note O
that O
we O
choose O
to O
randomly O
select O
the O
s O
words O
from O
the O
reference O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
the O
random O
reference O
word O
selection O
is O
simple O
and O
yields O
good O
performance O
empirically O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
formally O
, O
given O
the O
input O
x O
, O
its O
predicted O
sentence O
ŷ O
and O
its O
reference O
y O
, O
the O
goal O
of O
glancing O
sampling O
function O
gs O
( O
y O
, O
ŷ O
) O
is O
to O
obtain O
a O
subset O
of O
words O
sampled O
from O
y O
: O
gs O
( O
y O
, O
ŷ O
) O
= O
random O
( O
y O
, O
s O
( O
y O
, O
ŷ O
) O
) O
( O
2 O
) O
here O
, O
random O
( O
y O
, O
s O
) O
is O
randomly O
selecting O
s O
tokens O
from O
y O
, O
and O
s O
is O
computed O
by O
comparing O
the O
difference O
between O
ŷ O
and O
y O
, O
s O
( O
y O
, O
ŷ O
) O
= O
λ O
· O
d O
( O
y O
, O
ŷ O
) O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
the O
sampling O
ratio O
λ O
is O
a O
hyper-parameter O
to O
more O
flexibly O
control O
the O
number O
of O
sampled O
tokens O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
d O
( O
y O
, O
ŷ O
) O
is O
a O
metric O
for O
measuring O
the O
differences O
between O
y O
and O
ŷ O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
we O
adopt O
the O
hamming O
distance O
( O
hamming O
, O
1950 O
) O
as O
the O
metric O
, O
which O
is O
computed O
as O
d O
( O
y O
, O
ŷ O
) O
= O
∑t O
t=1 O
( O
yt O
6= O
ŷt O
) O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
with O
d O
( O
y O
, O
ŷ O
) O
, O
the O
sampling O
number O
can O
be O
decided O
adaptively O
considering O
the O
current O
trained O
model O
’ O
s O
prediction O
capability O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
for O
situations O
that O
y O
and O
ŷ O
have O
different O
lengths O
, O
d O
( O
y O
, O
ŷ O
) O
could O
be O
other O
distances O
such O
as O
levenshtein O
distance O
( O
levenshtein O
, O
1966 O
) O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
alternative O
glancing O
sampling O
strategy O
can O
be O
adopted O
as O
well O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
for O
example O
, O
one O
simple O
alternative O
strategy O
is O
to O
set O
the O
number O
of O
sampled O
tokens O
to O
be O
proportional O
to O
the O
target O
sentence O
length O
, O
i.e O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
s O
= O
λ O
∗ O
t O
. O

section 5
id pdf2json/2021.acl-long.155.pdf.json
we O
will O
evaluate O
the O
effects O
of O
these O
variations O
in O
the O
experiment O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
glat O
only O
modifies O
the O
training O
procedure O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
its O
inference O
is O
fully O
parallel O
with O
only O
a O
single O
pass O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
for O
parallel O
generation O
, O
we O
need O
to O
decide O
the O
output O
lengths O
before O
decoding O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
a O
simple O
way O
to O
decide O
the O
output O
lengths O
is O
predicting O
length O
with O
representations O
from O
the O
encoder O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
in O
glat O
, O
the O
length O
prediction O
is O
implemented O
as O
in O
ghazvininejad O
et O
al O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
( O
2019 O
) O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
an O
additional O
[ O
length O
] O
token O
is O
added O
to O
the O
source O
input O
, O
and O
the O
encoder O
output O
for O
the O
[ O
length O
] O
token O
is O
used O
to O
predict O
the O
length O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
we O
also O
use O
two O
more O
complex O
methods O
to O
better O
decide O
the O
output O
lengths O
: O
noisy O
parallel O
decoding O
( O
npd O
) O
and O
connectionist O
temporal O
classification O
( O
ctc O
) O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
for O
npd O
( O
gu O
et O
al. O
, O
2018 O
) O
, O
we O
first O
predict O
m O
target O
length O
candidates O
, O
then O
generate O
output O
sequences O
with O
argmax O
decoding O
for O
each O
target O
length O
candidate O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
then O
we O
use O
a O
pre-trained O
transformer O
to O
rank O
these O
sequences O
and O
identify O
the O
best O
overall O
output O
as O
the O
final O
output O
. O

section 6
id pdf2json/2021.acl-long.155.pdf.json
for O
ctc O
( O
graves O
et O
al. O
, O
2006 O
) O
, O
following O
libovickỳ O
and O
helcl O
( O
2018 O
) O
, O
we O
first O
set O
the O
max O
output O
length O
to O
twice O
the O
source O
input O
length O
, O
and O
remove O
the O
blanks O
and O
repeated O
tokens O
after O
generation O
. O

section 7
id pdf2json/2021.acl-long.155.pdf.json
in O
this O
section O
, O
we O
first O
introduce O
the O
settings O
of O
our O
experiments O
, O
then O
report O
the O
main O
results O
compared O
with O
several O
strong O
baselines O
. O

section 7
id pdf2json/2021.acl-long.155.pdf.json
ablation O
studies O
and O
further O
analysis O
are O
also O
included O
to O
verify O
the O
effects O
of O
different O
components O
used O
in O
glat O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
datasets O
we O
conduct O
experiments O
on O
three O
machine O
translation O
benchmarks O
: O
wmt14 O
en-de O
( O
4.5m O
translation O
pairs O
) O
, O
wmt16 O
en-ro O
( O
610k O
translation O
pairs O
) O
, O
and O
iwslt16 O
de-en O
( O
150k O
translation O
pairs O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
these O
datasets O
are O
tokenized O
and O
segmented O
into O
subword O
units O
using O
bpe O
encodings O
( O
sennrich O
et O
al. O
, O
2016 O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
we O
preprocess O
wmt14 O
en-de O
by O
following O
the O
data O
preprocessing O
in O
vaswani O
et O
al O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
( O
2017 O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
for O
wmt16 O
en-ro O
and O
iwslt16 O
de-en O
, O
we O
use O
the O
processed O
data O
provided O
in O
lee O
et O
al O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
( O
2018 O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
knowledge O
distillation O
following O
previous O
work O
( O
gu O
et O
al. O
, O
2018 O
; O
lee O
et O
al. O
, O
2018 O
; O
wang O
et O
al. O
, O
2019 O
) O
, O
we O
also O
use O
sequence-level O
knowledge O
distillation O
for O
all O
datasets O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
we O
employ O
the O
transformer O
with O
the O
base O
setting O
in O
vaswani O
et O
al O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
( O
2017 O
) O
as O
the O
teacher O
for O
knowledge O
distillation O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
then O
, O
we O
train O
our O
glat O
on O
distilled O
data O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
baselines O
and O
setup O
we O
compare O
our O
method O
with O
the O
base O
transformer O
and O
strong O
representative O
nat O
baselines O
in O
table O
1 O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
for O
all O
our O
tasks O
, O
we O
obtain O
other O
nat O
models O
’ O
performance O
by O
directly O
using O
the O
performance O
figures O
reported O
in O
their O
papers O
if O
they O
are O
available O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
we O
adopt O
the O
vanilla O
model O
which O
copies O
source O
input O
uniformly O
in O
gu O
et O
al O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
( O
2018 O
) O
as O
our O
base O
model O
( O
nat-base O
) O
and O
replace O
the O
uniformcopy O
with O
attention O
mechanism O
using O
positions O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
note O
that O
the O
output O
length O
does O
not O
equal O
the O
length O
of O
reference O
in O
models O
using O
ctc O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
therefore O
, O
for O
glat O
with O
ctc O
, O
we O
adopt O
longest O
common O
subsequence O
distance O
for O
compar- O
ing O
y O
and O
ŷ O
, O
and O
the O
glancing O
target O
is O
the O
target O
alignment O
that O
maximize O
the O
output O
probability O
argmaxa∈b−1 O
( O
y O
) O
p O
( O
a|x O
; O
θ O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
b−1 O
is O
the O
mapping O
proposed O
in O
( O
graves O
et O
al. O
, O
2006 O
) O
, O
which O
expand O
the O
reference O
to O
the O
length O
of O
output O
by O
inserting O
blanks O
or O
repeating O
words O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
for O
wmt O
datasets O
, O
we O
follow O
the O
hyperparameters O
of O
the O
base O
transformer O
in O
vaswani O
et O
al O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
( O
2017 O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
and O
we O
choose O
a O
smaller O
setting O
for O
iwslt16 O
, O
as O
iwslt16 O
is O
a O
smaller O
dataset O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
for O
iwslt16 O
, O
we O
use O
5 O
layers O
for O
encoder O
and O
decoder O
, O
and O
set O
the O
model O
size O
dmodel O
to O
256 O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
using O
nvidia O
v100 O
gpus O
, O
we O
train O
the O
model O
with O
batches O
of O
64k/8k O
tokens O
for O
wmt/iwslt O
datasets O
, O
respectively O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
we O
set O
the O
dropout O
rate O
to O
0.1 O
and O
use O
adam O
optimizer O
( O
kingma O
and O
ba O
, O
2014 O
) O
with O
β O
= O
( O
0.9 O
, O
0.999 O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
for O
wmt O
datasets O
, O
the O
learning O
rate O
warms O
up O
to O
5e− O
4 O
in O
4k O
steps O
and O
gradually O
decays O
according O
to O
inverse O
square O
root O
schedule O
in O
vaswani O
et O
al O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
( O
2017 O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
as O
for O
iwslt16 O
de-en O
, O
we O
adopt O
linear O
annealing O
( O
from O
3e− O
4 O
to O
1e− O
5 O
) O
as O
in O
lee O
et O
al O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
( O
2018 O
) O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
for O
the O
hyper-parameter O
λ O
, O
we O
adopt O
linear O
annealing O
from O
0.5 O
to O
0.3 O
for O
wmt O
datasets O
and O
a O
fixed O
value O
of O
0.5 O
for O
iwslt16 O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
the O
final O
model O
is O
created O
by O
averaging O
the O
5 O
best O
checkpoints O
chosen O
by O
validation O
bleu O
scores O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
we O
report O
tokenized O
bleu O
for O
all O
the O
datasets O
used O
in O
experiment O
. O

section 8
id pdf2json/2021.acl-long.155.pdf.json
we O
measure O
the O
average O
latency O
per O
sentence O
on O
a O
single O
nvidia O
1080ti O
gpu O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
the O
main O
results O
on O
the O
benchmarks O
are O
presented O
in O
table O
1 O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
glat O
significantly O
improves O
the O
translation O
quality O
and O
outperforms O
strong O
baselines O
by O
a O
large O
margin O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
our O
method O
introduces O
explicit O
word O
interdependency O
modeling O
for O
the O
decoder O
and O
gradually O
learns O
simultaneous O
generation O
of O
whole O
sequences O
, O
enabling O
the O
model O
to O
better O
capture O
the O
underlying O
data O
structure O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
compared O
to O
models O
with O
iterative O
decoding O
, O
our O
method O
completely O
maintains O
the O
inference O
efficiency O
advantage O
of O
fully O
non-autoregressive O
models O
, O
since O
glat O
generate O
with O
a O
single O
pass O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
compared O
with O
the O
baselines O
, O
we O
highlight O
our O
empirical O
advantages O
: O
• O
glat O
is O
highly O
effective O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
compared O
with O
the O
vanilla O
nat-base O
models O
, O
glat O
obtains O
significant O
improvements O
( O
about O
5 O
bleu O
) O
on O
ende/de-en O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
additionally O
, O
glat O
also O
outperforms O
other O
fully O
non-autoregressive O
models O
with O
a O
substantial O
margin O
( O
almost O
+2 O
bleu O
points O
on O
average O
) O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
the O
results O
are O
even O
very O
close O
to O
those O
of O
the O
at O
model O
, O
which O
shows O
great O
potential O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
• O
glat O
is O
simple O
and O
can O
be O
applied O
to O
other O
nat O
models O
flexibly O
, O
as O
we O
only O
modify O
the O
training O
process O
by O
reference O
glancing O
while O
keeping O
inference O
unchanged O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
for O
comparison O
, O
nat-dcrf O
utilizes O
crf O
to O
generate O
sequentially O
; O
nat-ir O
and O
mask-predict O
models O
need O
multiple O
decoding O
iterations O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
• O
ctc O
and O
npd O
use O
different O
approaches O
to O
determine O
the O
best O
output O
length O
, O
and O
they O
have O
their O
own O
advantages O
and O
disadvantages O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
ctc O
requires O
the O
output O
length O
to O
be O
longer O
than O
the O
exact O
target O
length O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
with O
longer O
output O
lengths O
, O
the O
training O
will O
consume O
more O
time O
and O
gpu O
memory O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
as O
for O
npd O
, O
with O
a O
certain O
number O
of O
length O
reranking O
candidates O
, O
the O
inference O
speed O
will O
be O
slower O
than O
models O
using O
ctc O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
note O
that O
npd O
can O
use O
pretrained O
at O
models O
or O
the O
non-autoregressive O
model O
itself O
to O
rerank O
multiple O
outputs O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
we O
also O
present O
a O
scatter O
plot O
in O
figure O
3 O
, O
displaying O
the O
trend O
of O
speed-up O
and O
bleu O
with O
different O
nat O
models O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
it O
is O
shown O
that O
the O
point O
of O
glat O
is O
located O
on O
the O
top-right O
of O
the O
competing O
methods O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
obviously O
, O
glat O
outperforms O
our O
competitors O
in O
bleu O
if O
speed-up O
is O
controlled O
, O
and O
in O
speed-up O
if O
bleu O
is O
controlled O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
this O
indicates O
that O
glat O
outperforms O
previous O
nat O
methods O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
although O
iterative O
models O
like O
mask-predict O
achieves O
competitive O
bleu O
scores O
, O
they O
only O
maintain O
minor O
speed O
advantages O
over O
at O
. O

section 9
id pdf2json/2021.acl-long.155.pdf.json
in O
contrast O
, O
fully O
non-autoregressive O
models O
remarkably O
improve O
the O
inference O
speed O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
effect O
of O
source O
input O
length O
to O
analyze O
the O
effect O
of O
source O
input O
length O
on O
the O
models O
’ O
performance O
, O
we O
split O
the O
source O
sentences O
into O
different O
intervals O
by O
length O
after O
bpe O
and O
compute O
the O
bleu O
score O
for O
each O
interval O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
the O
histogram O
of O
results O
is O
presented O
in O
figure O
4 O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
nat-base O
’ O
s O
performance O
drops O
sharply O
for O
long O
sentences O
, O
while O
the O
gradual O
learning O
process O
enables O
glat O
to O
boost O
the O
performance O
by O
a O
large O
margin O
, O
especially O
for O
long O
sentences O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
we O
also O
find O
that O
glat O
outperforms O
autoregressive O
transformer O
when O
the O
source O
input O
length O
is O
smaller O
than O
20 O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
glat O
reduces O
repetition O
we O
also O
measure O
the O
percentage O
of O
repeated O
tokens O
on O
test O
set O
of O
wmt14 O
en-de O
and O
wmt14 O
de-en O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
table O
2 O
presents O
the O
token O
repetition O
ratio O
of O
sentences O
generated O
by O
nat-base O
and O
glat O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
the O
results O
show O
that O
glat O
significantly O
reduces O
the O
occurrence O
of O
repetition O
, O
and O
the O
repetition O
ratio O
can O
be O
further O
reduced O
with O
npd O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
we O
think O
an O
important O
cause O
of O
the O
improvement O
is O
better O
interdependency O
modeling O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
since O
glat O
explicitly O
encourages O
word O
interdependency O
modeling O
to O
better O
capture O
the O
dependency O
between O
target O
tokens O
, O
wrong O
generation O
patterns O
, O
such O
as O
repetition O
, O
can O
be O
largely O
avoided O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
glat O
achieves O
strong O
results O
without O
multiple O
iterations O
we O
conduct O
experiments O
of O
glat O
with O
more O
than O
one O
decoding O
iteration O
in O
inference O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
we O
adopt O
the O
inference O
algorithm O
in O
mask-predict O
for O
multiple-iteration O
decoding O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
the O
results O
are O
shown O
in O
figure O
5 O
. O

section 10
id pdf2json/2021.acl-long.155.pdf.json
we O
find O
that O
glat O
can O
achieve O
decent O
performances O
with O
only O
one O
decoding O
iteration O
, O
while O
further O
iterations O
only O
obtain O
minor O
improvements O
of O
0.2∼0.3 O
bleu O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
effectiveness O
of O
the O
adaptive O
sampling O
number O
to O
validate O
the O
effectiveness O
of O
the O
adaptive O
sampling O
strategy O
for O
the O
sampling O
number O
s O
( O
y O
, O
ŷ O
) O
, O
we O
also O
introduce O
two O
fixed O
approaches O
for O
comparison O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
first O
one O
decides O
the O
sampling O
number O
with O
λ∗t O
, O
where O
t O
is O
the O
length O
of O
y O
, O
and O
λ O
is O
a O
constant O
ratio O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
second O
one O
is O
relatively O
flexible O
, O
which O
sets O
a O
start O
ratio O
of O
λs O
and O
an O
end O
ratio O
λe O
, O
and O
linearly O
reduces O
the O
sampling O
number O
from O
λs O
∗ O
t O
to O
λe O
∗ O
t O
along O
the O
training O
process O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
as O
shown O
in O
table O
3 O
and O
table O
4 O
, O
our O
adaptive O
approach O
( O
adaptive O
in O
the O
table O
) O
outperforms O
the O
baseline O
models O
with O
big O
margins O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
results O
confirm O
our O
intuition O
that O
the O
sampling O
schedule O
affects O
the O
generation O
performance O
of O
our O
nat O
model O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
sampling O
strategy O
, O
which O
first O
offers O
relatively O
easy O
generation O
problems O
and O
then O
turns O
harder O
, O
benefits O
the O
final O
performance O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
besides O
, O
even O
with O
the O
simplest O
constant O
ratio O
, O
glat O
still O
achieves O
remarkable O
results O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
when O
set O
λ O
= O
0.2 O
, O
it O
even O
outperforms O
the O
baseline O
λ O
= O
0.0 O
by O
2.5 O
bleu O
points O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
experiments O
potentially O
support O
that O
it O
is O
beneficial O
to O
learn O
the O
generation O
of O
fragments O
at O
the O
start O
and O
gradually O
transfer O
to O
the O
whole O
sequence O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
flexible O
decreasing O
ratio O
method O
works O
better O
than O
the O
constant O
one O
, O
and O
our O
proposed O
adaptive O
approaches O
achieve O
the O
best O
results O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
influence O
of O
reference O
word O
selection O
to O
analyze O
how O
the O
strategies O
of O
selecting O
reference O
words O
affect O
glancing O
sampling O
, O
we O
conduct O
experiments O
with O
different O
selection O
strategies O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
by O
default O
, O
we O
assume O
all O
the O
words O
in O
the O
reference O
are O
equally O
important O
and O
randomly O
choose O
reference O
words O
for O
glancing O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
besides O
the O
random O
strategy O
, O
we O
devise O
four O
other O
selection O
methods O
considering O
the O
prediction O
of O
first O
decoding O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
for O
pref O
and O
1−pref O
, O
the O
sampling O
probability O
of O
each O
reference O
word O
is O
proportional O
to O
the O
output O
probability O
for O
the O
reference O
word O
pref O
and O
the O
probability O
1− O
pref O
, O
respectively O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
similar O
to O
the O
word O
selection O
strategy O
for O
masking O
words O
during O
inference O
in O
mask-predict O
, O
we O
also O
add O
two O
strategies O
related O
to O
the O
prediction O
confidence O
: O
`` O
most O
certain O
'' O
and O
`` O
most O
uncertain O
. O
'' O

section 11
id pdf2json/2021.acl-long.155.pdf.json
we O
choose O
the O
positions O
where O
predictions O
have O
higher O
confidence O
for O
`` O
most O
certain O
'' O
, O
and O
vise O
versa O
for O
`` O
most O
uncertain O
. O
'' O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
results O
for O
different O
selection O
methods O
are O
listed O
in O
table O
5 O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
in O
comparisons O
, O
the O
model O
with O
the O
selection O
strategy O
1− O
pref O
outperforms O
the O
one O
with O
pref O
, O
indicating O
that O
words O
hard O
to O
predict O
are O
more O
important O
for O
glancing O
in O
training O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
and O
we O
find O
that O
the O
random O
strategy O
performs O
a O
little O
better O
than O
the O
two O
confidence-based O
strategies O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
we O
think O
this O
indicates O
that O
introducing O
more O
randomness O
in O
sampling O
enable O
glat O
to O
explore O
more O
interdependency O
among O
target O
words O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
we O
adopt O
the O
random O
strategy O
for O
its O
simplicity O
and O
good O
performance O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
comparison O
of O
different O
distances O
for O
glancing O
sampling O
we O
conduct O
experiments O
with O
two O
distances O
for O
comparing O
the O
predictions O
of O
the O
first O
decoding O
and O
references O
, O
and O
the O
results O
are O
presented O
in O
table O
6 O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
experimental O
results O
show O
that O
both O
distances O
can O
be O
used O
to O
improve O
the O
quality O
of O
one-iteration O
generation O
, O
and O
glat O
with O
hamming O
distance O
is O
better O
than O
glat O
with O
levenshtein O
distance O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
especially O
when O
there O
is O
no O
target O
length O
reranking O
, O
glat O
with O
hamming O
distance O
outperforms O
glat O
with O
levenshtein O
distance O
by O
about O
0.7 O
bleu O
and O
0.9 O
bleu O
on O
wmt14 O
en-de O
and O
de-en O
respectively O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
we O
think O
hamming O
distance O
is O
more O
strict O
than O
levenshtein O
distance O
because O
only O
the O
same O
words O
on O
the O
corresponding O
positions O
are O
regarded O
as O
correct O
, O
which O
is O
more O
consistent O
with O
the O
training O
of O
glat O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
advantages O
of O
glat O
over O
mask-predict O
to O
study O
the O
effects O
of O
sampling O
strategy O
and O
decoder O
inputs O
of O
glat O
, O
we O
conduct O
experiments O
for O
replacing O
these O
two O
modules O
in O
glat O
with O
the O
corresponding O
part O
in O
mask-predict O
, O
respectively O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
results O
are O
presented O
in O
table O
7 O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
glat O
employs O
glancing O
sampling O
strategy O
instead O
of O
the O
uniform O
sampling O
strategy O
used O
in O
mask-predict O
, O
and O
replaces O
the O
[ O
mask O
] O
token O
inputs O
with O
source O
representations O
from O
the O
encoder O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
the O
results O
show O
that O
the O
glancing O
sampling O
strategy O
outperforms O
the O
uniform O
sampling O
strategy O
by O
5∼6 O
bleu O
points O
, O
and O
feeding O
representations O
from O
the O
encoder O
as O
the O
decoder O
input O
could O
still O
improve O
the O
strong O
baseline O
by O
0.2∼0.3 O
bleu O
points O
after O
adopting O
glancing O
sampling O
. O

section 11
id pdf2json/2021.acl-long.155.pdf.json
to O
sum O
up O
, O
the O
adaptive O
glanc- O
ing O
sampling O
approach O
contributes O
the O
most O
to O
the O
final O
improvement O
, O
and O
the O
use O
of O
representations O
from O
the O
encoder O
also O
helps O
a O
bit O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
fully O
non-autoregressive O
models O
a O
line O
of O
work O
introduces O
various O
forms O
of O
latent O
variables O
to O
reduce O
the O
model O
’ O
s O
burden O
of O
dealing O
with O
dependencies O
among O
output O
words O
( O
gu O
et O
al. O
, O
2018 O
; O
ma O
et O
al. O
, O
2019 O
; O
bao O
et O
al. O
, O
2019 O
; O
ran O
et O
al. O
, O
2019 O
; O
bao O
et O
al. O
, O
2021 O
) O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
another O
branch O
of O
work O
considers O
transferring O
the O
knowledge O
from O
autoregressive O
models O
to O
non-autoregressive O
models O
( O
wei O
et O
al. O
, O
2019 O
; O
li O
et O
al. O
, O
2019 O
; O
guo O
et O
al. O
, O
2020a O
; O
sun O
and O
yang O
, O
2020 O
) O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
besides O
, O
there O
are O
also O
some O
work O
that O
apply O
different O
training O
objectives O
to O
train O
nonautoregressive O
models O
( O
libovickỳ O
and O
helcl O
, O
2018 O
; O
shao O
et O
al. O
, O
2020 O
; O
ghazvininejad O
et O
al. O
, O
2020a O
) O
, O
add O
regularization O
terms O
( O
wang O
et O
al. O
, O
2019 O
; O
guo O
et O
al. O
, O
2019 O
) O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
non-autoregressive O
models O
with O
structured O
decoding O
to O
model O
the O
dependencies O
between O
words O
, O
sun O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
( O
2019 O
) O
introduces O
a O
crf O
inference O
module O
in O
nat O
and O
performs O
additional O
sequential O
decoding O
after O
the O
non-autoregressive O
computation O
in O
inference O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
deng O
and O
rush O
( O
2020 O
) O
proposes O
cascaded O
crf O
decoding O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
since O
glat O
only O
performs O
single-pass O
non-autoregressive O
generation O
, O
our O
approach O
is O
orthogonal O
to O
the O
method O
proposed O
in O
sun O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
( O
2019 O
) O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
we O
can O
also O
combine O
our O
approach O
with O
the O
structured O
decoding O
methods O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
non-autoregressive O
models O
with O
iterative O
refinement O
a O
series O
of O
work O
are O
devoted O
to O
semiautoregressive O
models O
that O
refine O
the O
outputs O
with O
multi-pass O
iterative O
decoding O
( O
lee O
et O
al. O
, O
2018 O
; O
miao O
et O
al. O
, O
2019 O
; O
gu O
et O
al. O
, O
2019 O
; O
ghazvininejad O
et O
al. O
, O
2019 O
, O
2020b O
; O
kasai O
et O
al. O
, O
2020 O
; O
li O
et O
al. O
, O
2020 O
) O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
lee O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
( O
2018 O
) O
proposed O
a O
method O
of O
iterative O
refinement O
based O
on O
denoising O
autoencoder O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
gu O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
( O
2019 O
) O
utilized O
insertion O
and O
deletion O
to O
refine O
the O
outputs O
in O
inference O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
ghazvininejad O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
( O
2019 O
) O
trained O
the O
model O
with O
the O
masked O
language O
model O
, O
and O
the O
model O
iteratively O
replaces O
masked O
tokens O
with O
new O
outputs O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
( O
li O
et O
al. O
, O
2020 O
) O
first O
predict O
the O
left O
token O
and O
right O
token O
for O
each O
position O
, O
and O
decode O
the O
final O
token O
at O
the O
current O
position O
conditioned O
on O
the O
left-and-right O
tokens O
predicted O
before O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
despite O
the O
relatively O
better O
accuracy O
, O
the O
multiple O
decoding O
iterations O
reduce O
the O
inference O
efficiency O
of O
non-autoregressive O
models O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
scheduled O
sampling O
to O
alleviate O
exposure O
bias O
in O
autoregressive O
models O
, O
previous O
work O
attempts O
to O
close O
the O
gap O
between O
training O
and O
inference O
by O
scheduled O
sampling O
( O
bengio O
et O
al. O
, O
2015 O
; O
mihaylova O
and O
martins O
, O
2019 O
) O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
although O
scheduled O
sampling O
also O
modifies O
decoder O
inputs O
in O
training O
, O
there O
are O
mainly O
two O
differences O
between O
our O
work O
and O
scheduled O
sampling O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
firstly O
, O
scheduled O
sampling O
mixes O
up O
the O
predicted O
sequence O
and O
the O
gold O
target O
sequence O
, O
and O
our O
method O
does O
not O
mix O
predicted O
sequences O
into O
decoder O
inputs O
. O

section 12
id pdf2json/2021.acl-long.155.pdf.json
besides O
, O
glat O
aims O
to O
learn O
word O
interdependency O
for O
single-pass O
parallel O
generation O
and O
scheduled O
sampling O
is O
designed O
for O
alleviating O
exposure O
bias O
. O

section 13
id pdf2json/2021.acl-long.155.pdf.json
in O
this O
paper O
, O
we O
propose O
glancing O
transformer O
with O
a O
glancing O
language O
model O
to O
improve O
the O
performance O
of O
single-pass O
parallel O
generation O
models O
. O

section 13
id pdf2json/2021.acl-long.155.pdf.json
with O
the O
glancing O
language O
model O
, O
the O
model O
starts O
from O
learning O
the O
generation O
of O
sequence O
fragments O
and O
gradually O
moving O
to O
whole O
sequences O
. O

section 13
id pdf2json/2021.acl-long.155.pdf.json
experimental O
results O
show O
that O
our O
approach O
significantly O
improves O
the O
performance O
of O
non-autoregressive O
machine O
translation O
with O
single-pass O
parallel O
generation O
. O

section 13
id pdf2json/2021.acl-long.155.pdf.json
as O
glat O
achieves O
competitive O
performance O
compared O
with O
autoregressive O
models O
, O
applying O
our O
approach O
to O
other O
generation O
tasks O
is O
a O
promising O
direction O
for O
future O
work O
. O

section 14
id pdf2json/2021.acl-long.155.pdf.json
we O
thank O
all O
the O
anonymous O
reviewers O
for O
their O
valuable O
comments O
. O

section 14
id pdf2json/2021.acl-long.155.pdf.json
hao O
zhou O
and O
lei O
li O
are O
corresponding O
authors O
. O

section TITLE
id pdf2json/2021.acl-long.272.pdf.json
diversifying O
dialog O
generation O
via O
adaptive O
label O
smoothing O

section ABSTRACT
id pdf2json/2021.acl-long.272.pdf.json
neural O
dialogue O
generation O
models O
trained O
with O
the O
one-hot O
target O
distribution O
suffer O
from O
the O
over-confidence O
issue O
, O
which O
leads O
to O
poor O
generation O
diversity O
as O
widely O
reported O
in O
the O
literature O
. O

section ABSTRACT
id pdf2json/2021.acl-long.272.pdf.json
although O
existing O
approaches O
such O
as O
label O
smoothing O
can O
alleviate O
this O
issue O
, O
they O
fail O
to O
adapt O
to O
diverse O
dialog O
contexts O
. O

section ABSTRACT
id pdf2json/2021.acl-long.272.pdf.json
in O
this O
paper O
, O
we O
propose O
an O
adaptive O
label O
smoothing O
( O
adalabel O
) O
approach O
that O
can O
adaptively O
estimate O
a O
target O
label O
distribution O
at O
each O
time O
step O
for O
different O
contexts O
. O

section ABSTRACT
id pdf2json/2021.acl-long.272.pdf.json
the O
maximum O
probability O
in O
the O
predicted O
distribution O
is O
used O
to O
modify O
the O
soft O
target O
distribution O
produced O
by O
a O
novel O
light-weight O
bi-directional O
decoder O
module O
. O

section ABSTRACT
id pdf2json/2021.acl-long.272.pdf.json
the O
resulting O
target O
distribution O
is O
aware O
of O
both O
previous O
and O
future O
contexts O
and O
is O
adjusted O
to O
avoid O
over-training O
the O
dialogue O
model O
. O

section ABSTRACT
id pdf2json/2021.acl-long.272.pdf.json
our O
model O
can O
be O
trained O
in O
an O
endto-end O
manner O
. O

section ABSTRACT
id pdf2json/2021.acl-long.272.pdf.json
extensive O
experiments O
on O
two O
benchmark O
datasets O
show O
that O
our O
approach O
outperforms O
various O
competitive O
baselines O
in O
producing O
diverse O
responses O
. O

section 0
id pdf2json/2021.acl-long.272.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
3507–3520 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.272.pdf.json
©2021 O
association O
for O
computational O
linguistics O
3507 O

section 1
id pdf2json/2021.acl-long.272.pdf.json
the O
success O
of O
neural O
models O
has O
greatly O
advanced O
the O
research O
of O
dialog O
generation O
( O
huang O
et O
al. O
, O
2020 O
; O
wang O
et O
al. O
, O
2020 O
; O
zhang O
et O
al. O
, O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
however O
, O
most O
of O
these O
models O
suffer O
from O
a O
lowdiversity O
issue O
where O
models O
tend O
to O
generate O
bland O
and O
generic O
responses O
such O
as O
i O
don O
’ O
t O
know O
or O
i O
’ O
m O
ok O
( O
li O
et O
al. O
, O
2016 O
) O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
although O
various O
approaches O
have O
been O
proposed O
to O
tackle O
this O
issue O
( O
li O
et O
al. O
, O
2016 O
; O
zhao O
et O
al. O
, O
2017 O
; O
du O
et O
al. O
, O
2018 O
; O
zhou O
et O
al. O
, O
2018 O
; O
welleck O
et O
al. O
, O
2020 O
; O
zheng O
et O
al. O
, O
2020b O
) O
, O
there O
are O
still O
remarkable O
gaps O
between O
responses O
generated O
by O
neural O
models O
and O
those O
from O
humans O
( O
holtzman O
et O
al. O
, O
2020 O
) O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
further O
, O
some O
existing O
methods O
may O
even O
harm O
the O
fluency O
or O
coherence O
when O
improving O
the O
diversity O
of O
generated O
∗ O
equal O
contribution O
† O
corresponding O
author O
: O
aihuang O
@ O
tsinghua.edu.cn O
responses O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
( O
ippolito O
et O
al. O
, O
2019 O
; O
massarelli O
et O
al. O
, O
2020 O
; O
zheng O
et O
al. O
, O
2020a O
) O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
recently O
, O
jiang O
and O
de O
rijke O
( O
2018 O
) O
; O
jiang O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
( O
2019 O
) O
show O
that O
there O
is O
a O
strong O
connection O
between O
the O
low-diversity O
problem O
and O
the O
overconfidence O
issue O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
i.e. O
, O
over-confident O
dialogue O
models O
tend O
to O
produce O
low-diversity O
responses O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
one O
of O
the O
reasons O
can O
be O
attributed O
to O
the O
supervision O
target O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
training O
a O
dialogue O
generation O
model O
with O
the O
maximum O
likelihood O
estimation O
( O
mle O
) O
objective O
under O
the O
hard O
target O
( O
i.e. O
, O
one-hot O
distribution O
as O
ground O
truth O
) O
makes O
the O
model O
favor O
high-frequency O
tokens O
and O
produce O
over-confident O
probability O
estimation O
( O
gowda O
and O
may O
, O
2020 O
) O
, O
which O
ultimately O
leads O
to O
poor O
calibration O
( O
mukhoti O
et O
al. O
, O
2020 O
) O
, O
and O
thus O
low O
diversity O
( O
jiang O
et O
al. O
, O
2019 O
) O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
hinton O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
( O
2015 O
) O
and O
yang O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
( O
2018 O
) O
suggest O
that O
the O
ideal O
training O
target O
should O
be O
a O
soft O
target O
that O
assigns O
probability O
mass O
on O
multiple O
valid O
candidates O
( O
see O
figure O
1 O
) O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
with O
such O
a O
soft O
target O
, O
the O
over-confidence O
issue O
can O
be O
alleviated O
( O
müller O
et O
al. O
, O
2019 O
) O
, O
and O
thus O
the O
diversity O
of O
the O
output O
responses O
can O
be O
improved O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
unfortunately O
, O
the O
ideal O
soft O
target O
is O
challenging O
to O
obtain O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
early O
works O
try O
to O
tackle O
this O
issue O
using O
label O
smoothing O
( O
szegedy O
et O
al. O
, O
2016 O
) O
, O
i.e. O
, O
a O
small O
probability O
is O
uniformly O
assigned O
to O
nontarget O
words O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
however O
, O
the O
target O
distribution O
constructed O
in O
this O
way O
is O
far O
from O
ideal O
: O
first O
, O
the O
probability O
of O
the O
target O
word O
is O
chosen O
manually O
and O
fixed O
, O
which O
can O
not O
adapt O
to O
different O
contexts O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
however O
, O
as O
holtzman O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
( O
2020 O
) O
demonstrated O
, O
human O
text O
distribution O
exhibits O
remarkable O
fluctuations O
in O
the O
per-token O
perplexity O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
we O
argue O
that O
different O
target O
probabilities O
should O
be O
used O
for O
different O
contexts O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
second O
, O
the O
uniform O
assignment O
of O
the O
probability O
mass O
on O
non-target O
words O
ignores O
the O
semantic O
relationship O
between O
the O
context O
and O
each O
word O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
ideally O
, O
a O
word O
should O
receive O
more O
probability O
mass O
if O
it O
is O
more O
relevant O
to O
the O
context O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
for O
the O
example O
shown O
in O
figure O
1 O
, O
word O
“ O
fun O
” O
is O
more O
likely O
to O
appear O
behind O
the O
context O
“ O
i O
make O
the O
robots O
seem O
more O
” O
than O
word O
“ O
bank O
” O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
to O
address O
the O
above O
issue O
, O
we O
propose O
an O
adaptive O
label O
smoothing O
( O
adalabel O
) O
method O
that O
can O
dynamically O
estimate O
a O
soft O
target O
distribution O
at O
each O
time O
step O
for O
different O
contexts O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
for O
each O
target O
word O
yt O
in O
the O
training O
data O
, O
the O
probability O
distribution O
predicted O
by O
the O
current O
model O
is O
first O
obtained O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
the O
maximum O
probability O
pmax O
in O
this O
distribution O
measures O
the O
confidence O
of O
the O
current O
prediction O
, O
i.e. O
, O
a O
higher O
pmax O
means O
higher O
confidence O
for O
the O
current O
prediction O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
to O
avoid O
over-confidence O
, O
we O
use O
pmax O
as O
the O
supervision O
signal O
for O
the O
target O
word O
yt O
in O
the O
training O
process O
so O
that O
the O
model O
will O
not O
be O
optimized O
towards O
yt O
when O
it O
correctly O
predicts O
yt O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
a O
word-level O
factor O
is O
also O
introduced O
to O
facilitate O
the O
learning O
of O
low-frequency O
words O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
we O
introduce O
a O
novel O
auxiliary O
decoder O
module O
da O
to O
produce O
the O
supervision O
signals O
for O
these O
non-target O
words O
in O
each O
training O
step O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
da O
only O
contains O
one O
transformer O
block O
, O
and O
it O
is O
optimized O
to O
predict O
words O
based O
on O
bi-directional O
contexts O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
a O
novel O
target-mask O
attention O
scheme O
is O
devised O
to O
prevent O
da O
from O
seeing O
the O
target O
word O
in O
the O
training O
process O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
this O
scheme O
also O
enables O
parallel O
training O
and O
inference O
of O
da O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
we O
perform O
extensive O
experiments O
on O
two O
benchmark O
datasets O
: O
dailydialog O
and O
opensubtitles O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
our O
method O
outperforms O
various O
competitive O
baselines O
and O
significantly O
improves O
the O
diversity O
of O
generated O
responses O
while O
ensuring O
fluency O
and O
coherency O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
our O
major O
contributions O
are O
summarized O
: O
1 O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
we O
propose O
adalabel O
, O
a O
method O
that O
can O
produce O
a O
soft O
target O
distribution O
considering O
the O
current O
context O
and O
the O
model O
’ O
s O
confidence O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
adalabel O
ensures O
that O
the O
dialogue O
model O
will O
not O
be O
optimized O
toward O
the O
target O
word O
yt O
if O
yt O
has O
been O
correctly O
predicted O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
this O
prevents O
our O
model O
from O
being O
over-confident O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
2 O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
we O
introduce O
a O
light-weight O
bi-directional O
decoder O
that O
can O
produce O
context-aware O
supervision O
signals O
for O
non-target O
words O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
a O
novel O
target-mask O
attention O
scheme O
is O
devised O
to O
facilitate O
the O
parallel O
training O
and O
inference O
of O
this O
decoder O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
3 O
. O

section 1
id pdf2json/2021.acl-long.272.pdf.json
extensive O
experiments O
on O
two O
benchmark O
dialogue O
datasets O
with O
both O
automatic O
and O
human O
evaluation O
results O
show O
that O
our O
method O
helps O
to O
alleviate O
the O
model O
over-confident O
issue O
and O
significantly O
improves O
the O
model O
’ O
s O
diversity O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
diversity O
promotion O
: O
existing O
approaches O
for O
solving O
the O
low O
diversity O
issue O
of O
neural O
dialogue O
models O
generally O
involve O
two O
categories O
: O
the O
first O
category O
is O
training-based O
, O
where O
new O
training O
objectives O
are O
designed O
( O
li O
et O
al. O
, O
2016 O
; O
zhang O
et O
al. O
, O
2018 O
; O
gao O
et O
al. O
, O
2019 O
) O
or O
latent O
variables O
are O
introduced O
( O
zhao O
et O
al. O
, O
2017 O
; O
zhou O
et O
al. O
, O
2018 O
) O
in O
the O
dialogue O
model O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
some O
methods O
also O
try O
to O
refine O
the O
training O
target O
used O
in O
the O
mle O
loss O
( O
choi O
et O
al. O
, O
2020 O
; O
jiang O
et O
al. O
, O
2019 O
; O
li O
et O
al. O
, O
2019 O
) O
, O
or O
directly O
penalize O
the O
trivial O
responses O
with O
auxiliary O
loss O
terms O
( O
welleck O
et O
al. O
, O
2020 O
; O
li O
et O
al. O
, O
2020 O
) O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
unlike O
these O
existing O
approaches O
, O
our O
method O
tries O
to O
adaptively O
adjust O
the O
training O
target O
by O
utilizing O
the O
current O
predictions O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
the O
second O
category O
is O
decoding-based O
, O
in O
which O
different O
heuristic O
decoding O
rules O
are O
designed O
( O
holtzman O
et O
al. O
, O
2020 O
; O
kulikov O
et O
al. O
, O
2019 O
) O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
these O
decoding O
techniques O
are O
independent O
of O
the O
model O
setting O
, O
and O
our O
method O
can O
be O
used O
in O
combination O
with O
these O
techniques O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
confidence O
calibration O
: O
modern O
deep O
neural O
networks O
suffer O
from O
the O
over-confidence O
issue O
( O
guo O
et O
al. O
, O
2017 O
; O
kumar O
and O
sarawagi O
, O
2019 O
) O
, O
and O
various O
remedies O
are O
proposed O
( O
pereyra O
et O
al. O
, O
2017 O
; O
mukhoti O
et O
al. O
, O
2020 O
; O
lin O
et O
al. O
, O
2017 O
) O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
following O
the O
work O
of O
jiang O
and O
de O
rijke O
( O
2018 O
) O
; O
jiang O
et O
al O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
( O
2019 O
) O
, O
our O
method O
is O
proposed O
to O
tackle O
the O
overconfidence O
issue O
to O
improve O
the O
diversity O
of O
the O
generated O
responses O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
however O
, O
different O
from O
existing O
approaches O
, O
our O
method O
enables O
more O
flexible O
controls O
over O
the O
target O
distribution O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
knowledge O
distillation O
: O
another O
important O
technique O
similar O
to O
our O
work O
is O
knowledge O
distilla- O
tion O
, O
in O
which O
a O
learned O
teacher O
model O
is O
distilled O
to O
a O
student O
model O
by O
minimizing O
a O
kl O
term O
( O
hinton O
et O
al. O
, O
2015 O
; O
kim O
and O
rush O
, O
2016 O
) O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
the O
most O
related O
work O
comparing O
to O
ours O
is O
the O
c-mlm O
approach O
( O
chen O
et O
al. O
, O
2020 O
) O
, O
in O
which O
a O
bert O
model O
is O
fine-tuned O
to O
be O
a O
teacher O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
our O
approach O
and O
c-mlm O
’ O
s O
primary O
difference O
is O
that O
our O
auxiliary O
decoder O
da O
is O
a O
one O
layer O
module O
that O
is O
jointly O
trained O
with O
the O
dialogue O
model O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
however O
, O
the O
bert O
teacher O
in O
c-mlm O
contains O
much O
more O
parameters O
, O
and O
it O
is O
trained O
using O
an O
expensive O
pretrained O
and O
then O
fine-tuned O
process O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
the O
target-masked O
attention O
scheme O
in O
da O
enables O
parallel O
inferences O
of O
v O
for O
each O
training O
sequence O
y O
. O

section 2
id pdf2json/2021.acl-long.272.pdf.json
in O
contrast O
, O
multiple O
independent O
forward O
passes O
are O
required O
for O
the O
bert O
teacher O
. O

section 4
id pdf2json/2021.acl-long.272.pdf.json
the O
goal O
of O
generative O
dialogue O
modeling O
is O
to O
learn O
a O
conditional O
probability O
distribution O
p O
( O
y O
|x O
) O
, O
where O
x O
is O
the O
dialogue O
context O
, O
y O
= O
y1 O
, O
... O
, O
yt O
is O
a O
response O
word O
sequence O
, O
and O
yi O
∈ O
v O
is O
a O
word O
from O
the O
vocabulary O
v O
. O

section 4
id pdf2json/2021.acl-long.272.pdf.json
in O
an O
auto-regressive O
manner O
, O
p O
( O
y O
|x O
) O
is O
factorized O
as O
∏ O
t O
p O
( O
yt|y O
< O
t O
, O
x O
) O
. O

section 4
id pdf2json/2021.acl-long.272.pdf.json
for O
each O
target O
word O
yt O
in O
the O
training O
sequence O
y O
, O
a O
conventional O
mle O
training O
approach O
try O
to O
optimize O
the O
following O
cross O
entropy O
loss O
: O
l O
( O
q O
, O
p O
) O
= O
− O
∑ O
wk∈v O
qklog O
[ O
p O
( O
wk|y O
< O
t O
, O
x O
) O
] O
, O
( O
1 O
) O
where O
q O
is O
a O
one-hot O
distribution O
( O
i.e. O
, O
a O
hard O
target O
) O
that O
assigns O
a O
probability O
of O
1 O
for O
the O
target O
word O
yt O
and O
0 O
otherwise O
, O
i.e. O
, O
qk O
= O
1 O
only O
when O
wk O
= O
yt O
. O

section 4
id pdf2json/2021.acl-long.272.pdf.json
for O
simplicity O
of O
notation O
, O
we O
abbreviate O
the O
dependency O
of O
yt O
in O
the O
notation O
of O
each O
distribution O
in O
our O
paper O
, O
i.e. O
, O
different O
target O
word O
yt O
in O
y O
corresponds O
to O
different O
values O
of O
q O
and O
p O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
we O
propose O
to O
adaptively O
construct O
a O
soft O
target O
distribution O
q′ O
to O
replace O
q O
in O
eq O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
1 O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
q′ O
= O
ε O
· O
q O
+ O
( O
1− O
ε O
) O
· O
v O
, O
( O
2 O
) O
where O
ε O
∈ O
[ O
0 O
, O
1 O
] O
is O
an O
adaption O
factor O
, O
and O
v O
is O
an O
auxiliary O
distribution O
vector O
that O
depends O
on O
the O
current O
time O
step O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
( O
see O
figure O
2 O
for O
an O
overview O
) O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
in O
this O
study O
, O
we O
constrain O
v O
to O
assign O
zero O
probability O
for O
the O
target O
word O
yt O
and O
non-zero O
probabilities O
for O
these O
non-target O
words O
v6=yt O
= O
{ O
yi|yi O
∈ O
v O
, O
yi O
6= O
yt O
} O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
this O
constraint O
allows O
us O
to O
explicitly O
control O
the O
supervisions O
assigned O
to O
yt O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
the O
first O
term O
ε O
· O
q O
and O
the O
second O
term O
( O
1− O
ε O
) O
· O
v O
in O
eq O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
2 O
respectively O
determines O
how O
much O
probability O
q′ O
assigns O
to O
yt O
and O
v6=yt O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
this O
setting O
differs O
from O
conventional O
knowledge O
distillation O
( O
kim O
and O
rush O
, O
2016 O
) O
because O
it O
facilitates O
more O
flexible O
controls O
over O
q′ O
, O
so O
that O
we O
can O
use O
the O
factor O
ε O
to O
determine O
the O
supervision O
signal O
provided O
for O
the O
target O
word O
yt O
. O

section 5
id pdf2json/2021.acl-long.272.pdf.json
the O
following O
sections O
detail O
how O
to O
compute O
ε O
and O
v O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
we O
control O
the O
probability O
of O
the O
target O
word O
yt O
in O
p′ O
by O
manipulating O
the O
adaption O
factor O
ε O
in O
eq O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
2 O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
for O
a O
training O
dialogue O
pair O
〈x O
, O
y O
〉 O
and O
each O
target O
word O
yt O
∈ O
y O
, O
the O
current O
distribution O
p O
( O
·|y O
< O
t O
, O
x O
) O
is O
first O
calculated O
, O
and O
the O
maximum O
probability O
in O
this O
distribution O
is O
obtained O
: O
pmax O
= O
max O
wk∈v O
p O
( O
wk|y O
< O
t O
, O
x O
) O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
( O
3 O
) O
ε O
is O
then O
obtained O
: O
ε O
= O
max O
( O
pmax O
, O
λ O
) O
, O
( O
4 O
) O
where O
λ O
serves O
as O
a O
lower-bound O
of O
ε O
( O
i.e. O
, O
ε O
≥ O
λ O
) O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
the O
basic O
intuition O
behind O
eq O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
4 O
is O
to O
set O
ε O
= O
pmax O
when O
pmax O
is O
reasonably O
large O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
this O
design O
prevents O
our O
model O
from O
receiving O
supervisions O
sharper O
than O
pmax O
, O
when O
the O
current O
prediction O
is O
confidence O
enough O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
further O
, O
to O
ensure O
that O
the O
target O
word O
yt O
always O
receives O
the O
largest O
probability O
in O
q′ O
, O
i.e. O
, O
to O
ensure O
ε O
> O
( O
1− O
ε O
) O
·max O
( O
v O
) O
( O
see O
eq O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
2 O
) O
, O
in O
which O
max O
( O
v O
) O
is O
the O
maximum O
probabilities O
for O
non-target O
words O
v6=yt O
, O
we O
have O
to O
enforce O
ε O
> O
max O
( O
v O
) O
1+max O
( O
v O
) O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
thus O
we O
propose O
to O
calculate O
the O
lower-bound O
λ O
of O
ε O
as O
: O
λ O
= O
max O
( O
v O
) O
1 O
+ O
max O
( O
v O
) O
+ O
η O
, O
( O
5 O
) O
where O
η O
> O
0 O
is O
a O
hyper-parameter O
that O
controls O
the O
margin O
between O
the O
probability O
of O
the O
target O
word O
and O
non-target O
words O
in O
p′ O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
to O
facilitate O
faster O
converge O
and O
better O
learning O
of O
low-probability O
words O
, O
an O
empirical O
factor O
α O
∈ O
[ O
0 O
, O
1 O
] O
is O
further O
introduced O
to O
adjust O
the O
calculation O
of O
ε O
on O
the O
basis O
of O
eq O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
4 O
: O
ε O
= O
1− O
α O
· O
( O
1−max O
( O
pmax O
, O
λ O
) O
) O
, O
( O
6 O
) O
where O
α O
is O
calculated O
as O
the O
relative O
ratio O
to O
pmax O
: O
α O
= O
[ O
p O
( O
yt|y O
< O
t O
, O
x O
) O
pmax O
] O
2 O
, O
( O
7 O
) O
where O
p O
( O
yt|y O
< O
t O
, O
x O
) O
is O
the O
probability O
for O
the O
target O
word O
yt O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
eq O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
6 O
and O
eq O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
4 O
is O
equivalent O
if O
α O
= O
1 O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
intuitively O
, O
α O
accelerates O
the O
training O
of O
lowfrequency O
words O
because O
if O
yt O
is O
of O
low-frequency O
in O
the O
corpus O
, O
then O
yt O
is O
usually O
under-trained O
and O
thus O
p O
( O
yt|y O
< O
t O
, O
x O
) O
is O
generally O
small O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
this O
leads O
to O
a O
small O
α O
and O
thus O
increases O
the O
probability O
for O
yt O
in O
p′ O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
ε O
, O
λ O
and O
α O
are O
all O
time-step O
specific O
variables O
, O
whereas O
η O
is O
a O
fixed O
hyper-parameter O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
this O
allows O
the O
values O
adapt O
to O
dynamic O
contexts O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
in O
our O
experiments O
, O
eq O
. O

section 6
id pdf2json/2021.acl-long.272.pdf.json
6 O
is O
used O
to O
calculate O
ε O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
the O
auxiliary O
distribution O
v O
in O
eq O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
2 O
is O
calculated O
using O
an O
auxiliary O
decoder O
da O
, O
which O
is O
a O
singlelayer O
transformer-based O
decoder O
that O
is O
jointly O
optimized O
with O
the O
generation O
model O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
figure O
3 O
shows O
the O
structure O
ofda O
, O
in O
which O
a O
novel O
target-masked O
attention O
scheme O
is O
devised O
to O
mask O
each O
target O
word O
yt O
in O
the O
self O
attention O
module O
of O
the O
decoder O
when O
calculating O
the O
corresponding O
v O
( O
see O
figure O
3b O
and O
3c O
) O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
in O
this O
way O
, O
bi-directional O
contexts O
can O
be O
utilized O
when O
predicting O
the O
auxiliary O
distribution O
v O
for O
yt O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
it O
is O
important O
to O
use O
only O
one O
decoder O
layer O
in O
da O
because O
stacking O
multiple O
layers O
in O
da O
leaks O
the O
information O
of O
yt O
to O
v. O
note O
that O
using O
one O
layer O
in O
da O
does O
not O
necessarily O
downgrade O
its O
performance O
( O
kasai O
et O
al. O
, O
2021 O
) O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
our O
experiment O
results O
in O
section O
5.1 O
indicate O
that O
with O
the O
help O
of O
bi-directional O
contexts O
, O
the O
accuracy O
of O
da O
largely O
outperforms O
the O
unidirectional O
dialogue O
decoder O
that O
is O
much O
deeper O
than O
da O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
for O
a O
training O
response O
y O
, O
the O
structure O
of O
da O
enables O
us O
infer O
the O
auxiliary O
distribution O
in O
parallel O
for O
all O
the O
target O
words O
in O
y O
within O
a O
single O
forward O
pass O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
this O
differs O
from O
the O
bert O
teacher O
used O
by O
chen O
et O
al O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
( O
2020 O
) O
, O
in O
which O
multiple O
independent O
forward O
passes O
are O
needed O
to O
get O
the O
teacher O
distributions O
for O
all O
the O
words O
in O
y O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
when O
training O
da O
, O
the O
following O
standard O
mle O
loss O
is O
optimized O
for O
each O
target O
word O
yt O
: O
l O
( O
q O
, O
v O
) O
= O
− O
|v|∑ O
k=1 O
qklogvk O
, O
( O
8 O
) O
in O
which O
the O
notation O
of O
qk O
follows O
eq O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
1 O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
the O
outputs O
ofda O
are O
used O
as O
the O
logits O
to O
infer O
v O
to O
be O
further O
used O
in O
eq O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
2 O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
the O
logit O
of O
the O
target O
word O
yt O
is O
masked O
to−∞ O
before O
softmax O
to O
ensure O
yt O
always O
receives O
zero O
probability O
in O
v. O
moreover O
, O
we O
also O
follow O
the O
approach O
used O
by O
tang O
et O
al O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
( O
2020 O
) O
to O
truncate O
the O
head O
and O
tail O
of O
the O
remaining O
logits O
before O
inferring O
v O
in O
eq O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
2 O
, O
i.e. O
, O
all O
the O
logits O
are O
ranked O
in O
a O
descending O
order O
and O
only O
the O
logits O
ranked O
from O
n O
to O
m O
are O
kept O
while O
the O
rest O
logits O
are O
masked O
to O
−∞ O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
this O
masks O
the O
head O
and O
tail O
probabilities O
in O
v O
to O
zero O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
we O
argue O
that O
truncating O
the O
tail O
probabilities O
of O
v O
filters O
noises O
, O
and O
truncating O
the O
head O
probabilities O
of O
v O
encourages O
the O
dialogue O
model O
to O
focus O
more O
on O
low-probability O
words O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
in O
our O
experiments O
, O
we O
set O
n O
= O
2 O
and O
m O
= O
500 O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
an O
extensive O
hyperparameter O
search O
indicates O
that O
our O
method O
is O
not O
sensitive O
to O
the O
value O
of O
n O
and O
m. O
there O
are O
two O
major O
differences O
between O
our O
auxiliary O
decoder O
da O
and O
the O
teacher O
model O
used O
in O
conventional O
knowledge O
distillation O
approaches O
: O
first O
, O
conventional O
teacher O
models O
usually O
carry O
more O
parameters O
than O
their O
students O
, O
whereas O
da O
is O
rather O
light-weight O
. O

section 7
id pdf2json/2021.acl-long.272.pdf.json
second O
, O
conventional O
teacher O
models O
are O
typically O
pre-trained O
before O
being O
utilized O
in O
the O
distillation O
process O
, O
whereas O
da O
is O
trained O
jointly O
with O
our O
dialogue O
model O
. O

section 9
id pdf2json/2021.acl-long.272.pdf.json
we O
use O
two O
benchmark O
datasets O
for O
open-domain O
dialogue O
generation O
: O
dailydialog O
( O
li O
et O
al. O
, O
2017 O
) O
is O
a O
high-quality O
multi-turn O
dialogue O
dataset O
that O
is O
collected O
from O
daily O
conversations O
. O

section 9
id pdf2json/2021.acl-long.272.pdf.json
opensubtitles O
1 O
contains O
dialogues O
collected O
from O
movie O
subtitles O
. O

section 9
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
we O
follow O
li O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.272.pdf.json
( O
2016 O
) O
and O
jiang O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.272.pdf.json
( O
2019 O
) O
to O
focus O
on O
short O
conversations O
, O
i.e. O
, O
dialogues O
with O
posts O
or O
responses O
longer O
than O
100 O
tokens O
are O
removed O
. O

section 9
id pdf2json/2021.acl-long.272.pdf.json
see O
table O
1 O
for O
more O
details O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
the O
backbone O
of O
our O
model O
is O
the O
transformerbased O
sequence O
to O
sequence O
model O
( O
vaswani O
et O
al. O
, O
2017 O
) O
, O
and O
most O
hyper-parameters O
follow O
cai O
et O
al O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
( O
2020 O
) O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
the O
encoder O
and O
decoder O
each O
contains O
6 O
layers O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
each O
layer O
has O
8 O
attention O
heads O
, O
and O
the O
hidden O
size O
is O
set O
to O
512 O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
the O
auxiliary O
decoder O
da O
follows O
the O
same O
hyper-parameter O
setting O
as O
the O
dialogue O
decoder O
, O
but O
it O
only O
contains O
one O
layer O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
the O
wordpiece O
tokenizer O
provided O
by O
1http O
: O
//opus.nlpl.eu/opensubtitles.php O
bert O
( O
devlin O
et O
al. O
, O
2019 O
) O
is O
used O
, O
and O
the O
adam O
optimizer O
( O
kingma O
and O
ba O
, O
2015 O
) O
is O
employed O
to O
train O
our O
model O
from O
random O
initializations O
with O
a O
learning O
rate O
of O
1e-4 O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
η O
in O
eq O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
5 O
is O
set O
to O
0.2 O
for O
all O
datasets O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
see O
appendix O
a O
for O
more O
details O
. O

section 10
id pdf2json/2021.acl-long.272.pdf.json
2 O

section 11
id pdf2json/2021.acl-long.272.pdf.json
we O
compared O
our O
method O
with O
two O
groups O
of O
baselines O
that O
try O
to O
tackle O
the O
over-confidence O
issue O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
the O
first O
group O
modifies O
the O
training O
target O
used O
to O
compute O
the O
loss O
function O
: O
1 O
) O
ls O
( O
szegedy O
et O
al. O
, O
2016 O
) O
: O
uses O
the O
label O
smoothing O
approach O
to O
construct O
a O
target O
distribution O
by O
adding O
the O
onehot O
target O
and O
a O
uniform O
distribution O
; O
2 O
) O
fl O
( O
lin O
et O
al. O
, O
2017 O
) O
: O
uses O
the O
focal O
loss O
to O
down-weigh O
well-classified O
tokens O
in O
each O
time O
step O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
3 O
) O
face O
( O
jiang O
et O
al. O
, O
2019 O
) O
: O
uses O
the O
frequency-aware O
crossentropy O
loss O
to O
balance O
per-token O
training O
losses O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
relative O
low O
losses O
are O
assigned O
to O
high-frequency O
words O
to O
explicitly O
tackle O
the O
overconfidence O
issue O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
we O
used O
the O
best O
performing O
“ O
pre-weigh O
” O
version O
in O
our O
experiments O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
4 O
) O
f2 O
( O
choi O
et O
al. O
, O
2020 O
) O
: O
factorizes O
the O
target O
distribution O
based O
on O
the O
token O
frequencies O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
the O
second O
group O
of O
baselines O
add O
some O
penalty O
term O
to O
the O
standard O
mle O
loss O
: O
5 O
) O
cp O
( O
pereyra O
et O
al. O
, O
2017 O
) O
: O
a O
confidence O
penalty O
term O
is O
added O
to O
regularize O
the O
entropy O
of O
the O
model O
, O
so O
that O
over-confident O
predictions O
are O
penalized O
; O
6 O
) O
ul O
( O
welleck O
et O
al. O
, O
2020 O
) O
: O
an O
unlikelihood O
loss O
term O
is O
added O
to O
penalize O
the O
frequently O
generated O
words O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
7 O
) O
nl O
( O
he O
and O
glass O
, O
2020 O
) O
: O
works O
similarly O
with O
baseline O
ul O
except O
a O
negative O
loss O
term O
is O
used O
instead O
of O
the O
unlikelihood O
loss O
term O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
8 O
) O
d2gpo O
( O
li O
et O
al. O
, O
2019 O
) O
: O
augments O
the O
mle O
loss O
with O
a O
data-dependent O
gaussian O
prior O
objective O
to O
assign O
different O
losses O
for O
different O
non-target O
words O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
we O
also O
compared O
to O
: O
9 O
) O
ce O
: O
a O
vanilla O
seq2seq O
model O
trained O
with O
the O
cross-entropy O
loss O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
for O
fair O
comparisons O
, O
the O
c-mlm O
model O
proposed O
by O
chen O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
( O
2020 O
) O
is O
not O
used O
as O
our O
baseline O
since O
the O
bert O
teacher O
in O
c-mlm O
requires O
a O
large O
amount O
of O
extra O
data O
to O
pre-train O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
nevertheless O
, O
adalabel O
still O
surpasses O
c-mlm O
on O
various O
metrics O
( O
see O
appendix O
f O
for O
more O
analysis O
) O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
all O
our O
baselines O
are O
adapted O
from O
the O
authors O
’ O
official O
codes O
with O
the O
same O
backbone O
architecture O
and O
hyper-parameters O
as O
our O
model O
( O
see O
details O
in O
appendix O
b O
) O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
following O
the O
original O
setting O
, O
a O
train- O
2our O
code O
is O
available O
at O
: O
https O
: O
//github.com/ O
lemon234071/adalabel O
and-refine O
strategy O
is O
used O
in O
baseline O
3 O
, O
6 O
, O
and O
7 O
, O
i.e. O
, O
these O
baselines O
are O
refined O
based O
on O
ce O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
we O
follow O
the O
setting O
of O
jiang O
et O
al O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
( O
2019 O
) O
to O
use O
deterministic O
decoding O
scheme O
( O
particularly O
, O
greedy O
decoding O
) O
for O
our O
model O
and O
all O
baselines O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
our O
method O
can O
be O
adapted O
to O
other O
decoding O
schemes O
such O
as O
beam-search O
or O
top-k O
sampling O
. O

section 11
id pdf2json/2021.acl-long.272.pdf.json
see O
appendix O
c O
for O
more O
detailed O
analysis O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
metrics O
: O
we O
first O
used O
automatic O
metrics O
to O
evaluate O
our O
method O
: O
1 O
) O
distinct O
( O
dist O
) O
( O
li O
et O
al. O
, O
2016 O
) O
calculates O
the O
proportion O
of O
unique O
n-grams O
( O
n=1 O
, O
2 O
) O
in O
the O
generated O
responses O
, O
which O
is O
widely O
used O
to O
measure O
the O
response O
diversity O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
2 O
) O
entropy O
( O
ent O
) O
( O
zhang O
et O
al. O
, O
2018 O
) O
evaluates O
how O
evenly O
the O
empirical O
n-gram O
( O
n=1 O
, O
2 O
) O
distribution O
is O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
higher O
sores O
mean O
more O
diverse O
of O
the O
response O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
3 O
) O
lowfrequency O
token O
ratio O
( O
lf O
) O
( O
li O
et O
al. O
, O
2019 O
) O
further O
measures O
the O
model O
diversity O
by O
counting O
the O
ratio O
of O
low-frequency O
words O
in O
the O
generated O
responses O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
we O
chose O
words O
with O
a O
frequency O
less O
than O
100 O
in O
each O
corpus O
as O
low-frequency O
words O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
over-confident O
models O
tend O
to O
omit O
low-frequency O
words O
( O
i.e. O
, O
get O
low O
lf O
scores O
) O
and O
yield O
less O
diversified O
responses O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
4 O
) O
bleu O
( O
papineni O
et O
al. O
, O
2002 O
) O
measures O
n-gram O
( O
n=2 O
, O
3 O
, O
4 O
) O
overlap O
between O
the O
generated O
responses O
and O
references O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
results O
: O
as O
shown O
in O
table O
2 O
, O
our O
method O
adalabel O
outperforms O
all O
the O
baselines O
by O
large O
margins O
on O
all O
the O
datasets O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
we O
can O
further O
observe O
that O
: O
1 O
) O
adalabel O
achieves O
the O
best O
diversity O
scores O
( O
dist-1,2 O
, O
ent-1,2 O
, O
and O
lf O
) O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
this O
indicates O
that O
our O
method O
yields O
better O
training O
targets O
that O
help O
to O
produce O
more O
diverse O
responses O
; O
2 O
) O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
the O
models O
that O
explicitly O
tackle O
the O
over-confidence O
issue O
( O
i.e. O
, O
adalabel O
and O
face O
) O
generally O
outperform O
other O
baselines O
in O
diversity-related O
metrics O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
for O
example O
, O
face O
obtains O
the O
second-best O
diversity O
scores O
( O
i.e. O
, O
dist O
, O
ent O
, O
and O
lf O
) O
on O
the O
opensubtitles O
dataset O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
this O
verifies O
our O
motivation O
that O
alleviating O
the O
over-confidence O
issue O
helps O
to O
produce O
more O
diverse O
responses O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
our O
method O
also O
outperforms O
all O
the O
baselines O
using O
the O
stochastic O
decoding O
scheme O
. O

section 12
id pdf2json/2021.acl-long.272.pdf.json
please O
refer O
to O
appendix O
c O
for O
more O
details O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
metrics O
: O
pairwise O
manual O
evaluations O
are O
conducted O
to O
further O
validate O
our O
method O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
for O
a O
given O
dialogue O
post O
, O
our O
model O
’ O
s O
response O
is O
paired O
with O
the O
one O
from O
a O
baseline O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
three O
individual O
annotators O
were O
employed O
to O
rank O
each O
response O
pair O
from O
three O
aspects O
: O
1 O
) O
fluency O
( O
flu O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
) O
: O
which O
response O
is O
more O
fluent O
; O
2 O
) O
coherency O
( O
coh O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
) O
: O
which O
response O
is O
more O
coherent O
to O
the O
context O
; O
3 O
) O
informativeness O
( O
info O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
) O
: O
which O
response O
contains O
more O
informative O
content O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
we O
also O
asked O
the O
annotator O
to O
choose O
an O
overall O
preferred O
response O
( O
pref O
. O
) O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
ties O
were O
allowed O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
results O
: O
200 O
posts O
were O
randomly O
sampled O
from O
each O
of O
these O
two O
datasets O
, O
respectively O
, O
and O
totally O
3.6k O
response O
pairs O
were O
generated O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
the O
inter-rater O
annotation O
agreement O
was O
measured O
using O
fleiss O
’ O
s O
kappa O
κ O
( O
fleiss O
, O
1971 O
) O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
particularly O
, O
the O
κ O
value O
on O
dailydialog O
, O
opensubtitles O
dataset O
was O
0.59 O
and O
0.55 O
, O
respectively O
, O
indicating O
moderate O
agreement O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
as O
shown O
in O
table O
3 O
, O
adalabel O
outperforms O
all O
the O
baselines O
on O
the O
informativeness O
measure O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
this O
means O
that O
our O
method O
can O
respond O
with O
more O
informative O
content O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
we O
can O
further O
observe O
that O
: O
1 O
) O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
all O
models O
achieve O
competitive O
fluency O
because O
it O
is O
easy O
for O
neural O
models O
to O
produce O
fluent O
responses O
by O
yielding O
trivial O
responses O
like O
“ O
i O
don O
’ O
t O
know O
” O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
however O
, O
our O
model O
surpasses O
most O
baselines O
in O
terms O
of O
fluency O
while O
ensuring O
high O
diversity O
scores O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
this O
demonstrates O
the O
superiority O
of O
our O
method O
in O
producing O
high O
quality O
responses O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
2 O
) O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
adalabel O
produces O
more O
coherent O
responses O
comparing O
to O
most O
baselines O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
this O
verifies O
that O
our O
model O
does O
not O
sacrifice O
the O
response O
quality O
when O
achieving O
high O
diversity O
scores O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
in O
fact O
, O
by O
controlling O
the O
model O
’ O
s O
confidence O
, O
more O
lowfrequency O
words O
are O
encouraged O
, O
and O
thus O
adalabel O
can O
produce O
more O
relevant O
and O
coherent O
responses O
. O

section 13
id pdf2json/2021.acl-long.272.pdf.json
this O
claim O
is O
further O
verified O
by O
observing O
that O
our O
model O
achieves O
the O
best O
overall O
preference O
score O
among O
all O
the O
baselines O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
ablation O
studies O
were O
performed O
to O
verify O
the O
effect O
of O
each O
component O
in O
our O
method O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
two O
groups O
of O
variants O
were O
tested O
: O
the O
first O
group O
validates O
the O
effectiveness O
of O
the O
calculated O
target O
word O
probability O
, O
i.e. O
, O
ε O
: O
1 O
) O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
w/o O
ε O
directly O
sets O
a O
fixed O
value O
for O
ε O
in O
eq O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
2 O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
the O
specific O
value O
of O
ε O
is O
searched O
from O
0.1 O
to O
0.7 O
with O
a O
stride O
of O
0.1 O
; O
2 O
) O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
w/o O
α O
omits O
the O
empirical O
factor O
α O
in O
calculating O
ε O
, O
i.e. O
, O
the O
value O
of O
ε O
in O
eq O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
2 O
is O
calculated O
using O
eq O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
4 O
in O
instead O
of O
eq O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
6 O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
the O
second O
group O
validates O
the O
effectiveness O
of O
the O
non-target O
word O
probabilities O
produced O
by O
da O
, O
i.e. O
, O
v O
: O
3 O
) O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
orig O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
v O
does O
not O
truncate O
the O
head O
of O
v O
when O
inferring O
from O
da O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
the O
truncation O
for O
the O
tail O
of O
v O
is O
still O
applied O
since O
its O
effectiveness O
has O
already O
been O
proved O
in O
previous O
studies O
( O
tang O
et O
al. O
, O
2020 O
; O
tan O
et O
al. O
, O
2019 O
) O
; O
4 O
) O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
uniform O
uses O
an O
uniform O
distribution O
as O
v O
in O
eq O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
2 O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
different O
from O
the O
baseline O
ls O
, O
the O
value O
of O
ε O
is O
calculated O
using O
eq O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
6 O
in O
this O
ablation O
model O
, O
whereas O
the O
value O
of O
ε O
in O
the O
baseline O
ls O
is O
fixed O
; O
5 O
) O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
rand O
use O
a O
random O
distributions O
as O
v O
in O
eq O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
2 O
; O
6 O
) O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
bert O
follows O
the O
work O
of O
chen O
et O
al O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
( O
2020 O
) O
to O
fine-tune O
a O
pre-trained O
bert O
model O
to O
produce O
v. O
note O
that O
our O
dialogue O
model O
may O
benefit O
from O
the O
multi-task O
training O
of O
da O
since O
da O
shares O
the O
same O
encoder O
with O
our O
dialogue O
model O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
optimizing O
eq O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
8 O
may O
help O
the O
encoder O
to O
capture O
better O
features O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
for O
fair O
comparison O
, O
we O
kept O
the O
task O
of O
optimizing O
da O
in O
ablation O
models O
4-6 O
although O
it O
is O
not O
used O
to O
infer O
v. O
table O
4 O
shows O
the O
results O
of O
ablation O
models O
on O
the O
dailydialog O
dataset O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
as O
can O
be O
seen O
from O
the O
first O
two O
rows O
, O
our O
method O
to O
adaptively O
calculate O
ε O
helps O
to O
improve O
the O
performance O
of O
our O
model O
by O
a O
large O
margin O
, O
and O
the O
empirical O
adjustment O
factor O
α O
helps O
to O
further O
improve O
our O
performance O
by O
facilitating O
the O
learning O
of O
low-probability O
words O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
the O
performance O
of O
ablation O
models O
3-6 O
in O
table O
4 O
proves O
that O
v O
captures O
reliable O
distribution O
and O
helps O
our O
model O
produce O
more O
diverse O
responses O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
truncating O
the O
head O
distribution O
of O
v O
enables O
the O
dialogue O
model O
to O
focus O
more O
on O
the O
low-frequency O
words O
and O
thus O
facilitates O
more O
informative O
responses O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
it O
is O
also O
interesting O
to O
note O
that O
our O
auxiliary O
decoder O
da O
surpasses O
the O
bert O
teacher O
used O
by O
chen O
et O
al O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
( O
2020 O
) O
in O
helping O
the O
dialogue O
model O
to O
produce O
more O
diverse O
responses O
. O

section 14
id pdf2json/2021.acl-long.272.pdf.json
this O
further O
proves O
the O
effectiveness O
of O
da O
considering O
that O
bert O
contains O
6 O
times O
parameters O
than O
da O
and O
consumes O
much O
more O
computation O
resources O
. O

section 16
id pdf2json/2021.acl-long.272.pdf.json
to O
further O
test O
the O
performance O
of O
da O
, O
we O
evaluated O
the O
averaged O
accuracy O
score O
of O
da O
when O
predicting O
each O
target O
word O
in O
the O
test O
set O
( O
first O
row O
in O
table O
5 O
) O
. O

section 16
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
a O
target O
word O
yt O
in O
the O
reference O
response O
is O
determined O
to O
be O
correctly O
predicted O
if O
it O
is O
top-ranked O
in O
the O
predicted O
distribution O
p O
( O
·|y O
< O
t O
, O
x O
) O
. O

section 16
id pdf2json/2021.acl-long.272.pdf.json
a O
better O
decoder O
is O
generally O
believed O
to O
obtain O
a O
higher O
accuracy O
. O

section 16
id pdf2json/2021.acl-long.272.pdf.json
table O
5 O
also O
reports O
the O
uni-directional O
dialogue O
decoders O
’ O
accuracy O
in O
adalabel O
and O
ce O
. O

section 16
id pdf2json/2021.acl-long.272.pdf.json
it O
can O
be O
seen O
that O
da O
can O
make O
substantially O
more O
accurate O
predictions O
with O
the O
help O
of O
modeling O
bi-directional O
contexts O
using O
only O
one O
layer O
. O

section 16
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
the O
dialogue O
model O
’ O
s O
decoder O
in O
adalabel O
, O
which O
is O
guided O
by O
da O
, O
achieves O
better O
accuracies O
than O
the O
ce O
. O

section 16
id pdf2json/2021.acl-long.272.pdf.json
this O
further O
proves O
that O
our O
light-weight O
da O
is O
capable O
of O
producing O
effective O
v O
. O

section 17
id pdf2json/2021.acl-long.272.pdf.json
we O
also O
visualized O
the O
distribution O
of O
confidence O
scores O
assigned O
by O
each O
dialogue O
model O
to O
highfrequency O
words O
. O

section 17
id pdf2json/2021.acl-long.272.pdf.json
figure O
4 O
shows O
the O
results O
of O
four O
best O
performing O
models O
on O
the O
opensubtitles O
dataset O
. O

section 17
id pdf2json/2021.acl-long.272.pdf.json
the O
spikes O
of O
high O
confidence O
score O
observed O
in O
figure O
4b O
and O
4d O
indicate O
that O
ce O
and O
face O
assign O
extremely O
high O
confidence O
scores O
to O
a O
large O
number O
of O
high-frequency O
words O
. O

section 17
id pdf2json/2021.acl-long.272.pdf.json
although O
the O
smoothed O
labels O
in O
ls O
manage O
to O
alleviate O
these O
high-confidence-spikes O
( O
figure O
4c O
) O
, O
a O
considerable O
amount O
of O
words O
still O
receives O
high O
confidence O
scores O
in O
ls O
. O

section 17
id pdf2json/2021.acl-long.272.pdf.json
our O
model O
outperforms O
all O
the O
baselines O
to O
avoid O
assigning O
over-confidence O
scores O
, O
thus O
alleviating O
the O
over-confidence O
issue O
. O

section 17
id pdf2json/2021.acl-long.272.pdf.json
a O
similar O
trend O
is O
also O
observed O
on O
the O
dailydialog O
dataset O
( O
see O
appendix O
d O
for O
results O
of O
all O
models O
on O
both O
datasets O
) O
. O

section 18
id pdf2json/2021.acl-long.272.pdf.json
over-confident O
models O
produce O
less O
diversified O
responses O
because O
they O
usually O
under-estimate O
rare O
words O
. O

section 18
id pdf2json/2021.acl-long.272.pdf.json
to O
evaluate O
the O
effectiveness O
of O
adalabel O
, O
we O
tested O
whether O
adalabel O
encourages O
more O
“ O
rare O
words O
” O
in O
its O
generations O
. O

section 18
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
the O
ratio O
of O
generated O
tokens O
corresponding O
to O
different O
token O
frequency O
bins O
is O
calculated O
, O
and O
the O
results O
on O
the O
opensubtitles O
dataset O
are O
shown O
in O
figure O
5 O
. O

section 18
id pdf2json/2021.acl-long.272.pdf.json
it O
can O
be O
seen O
that O
adalabel O
produces O
more O
rare O
words O
in O
the O
generated O
responses O
than O
other O
baselines O
. O

section 18
id pdf2json/2021.acl-long.272.pdf.json
similar O
results O
are O
also O
observed O
on O
the O
dailydialog O
dataset O
( O
see O
appendix O
e O
) O
. O

section 19
id pdf2json/2021.acl-long.272.pdf.json
we O
address O
the O
low-diversity O
issue O
of O
neural O
dialogue O
models O
by O
introducing O
an O
adaptive O
label O
smoothing O
approach O
, O
adalabel O
. O

section 19
id pdf2json/2021.acl-long.272.pdf.json
in O
our O
method O
, O
the O
probability O
of O
each O
target O
word O
is O
estimated O
based O
on O
the O
current O
dialogue O
model O
’ O
s O
prediction O
, O
and O
the O
probabilities O
for O
these O
non-target O
words O
are O
calculated O
using O
a O
novel O
auxiliary O
decoder O
da O
. O

section 19
id pdf2json/2021.acl-long.272.pdf.json
a O
target-masked O
attention O
scheme O
is O
introduced O
inda O
to O
help O
capture O
forward O
and O
backward O
contexts O
. O

section 19
id pdf2json/2021.acl-long.272.pdf.json
we O
evaluate O
our O
method O
on O
two O
benchmark O
datasets O
: O
dailydialog O
and O
opensubtitles O
. O

section 19
id pdf2json/2021.acl-long.272.pdf.json
extensive O
experiments O
show O
that O
our O
method O
effectively O
alleviates O
the O
over-confidence O
issue O
and O
improves O
the O
diversity O
of O
the O
generated O
responses O
. O

section 19
id pdf2json/2021.acl-long.272.pdf.json
as O
future O
work O
, O
we O
believe O
this O
method O
is O
extensible O
to O
other O
text O
generation O
tasks O
. O

section 20
id pdf2json/2021.acl-long.272.pdf.json
this O
work O
was O
partly O
supported O
by O
the O
nsfc O
projects O
( O
key O
project O
with O
no O
. O

section 20
id pdf2json/2021.acl-long.272.pdf.json
61936010 O
and O
regular O
project O
with O
no O
. O

section 20
id pdf2json/2021.acl-long.272.pdf.json
61876096 O
) O
. O

section 20
id pdf2json/2021.acl-long.272.pdf.json
this O
work O
was O
also O
supported O
by O
the O
guoqiang O
institute O
of O
tsinghua O
university O
, O
with O
grant O
no O
. O

section 20
id pdf2json/2021.acl-long.272.pdf.json
2019gqg1 O
and O
2020gqg0005 O
. O

section 20
id pdf2json/2021.acl-long.272.pdf.json
we O
thank O
jinchao O
zhang O
and O
yao O
qiu O
for O
early O
discussions O
and O
insightful O
comments O
of O
this O
work O
. O

section 21
id pdf2json/2021.acl-long.272.pdf.json
this O
appendix O
contains O
more O
implementation O
details O
of O
our O
baselines O
. O

section 21
id pdf2json/2021.acl-long.272.pdf.json
all O
the O
baselines O
utilize O
the O
same O
backbone O
architecture O
and O
basic O
hyperparameter O
settings O
as O
our O
model O
( O
see O
appendix O
a O
) O
. O

section 21
id pdf2json/2021.acl-long.272.pdf.json
the O
hyper-parameters O
specialized O
for O
each O
baseline O
is O
determined O
with O
the O
grid O
search O
based O
on O
the O
dist O
measures O
on O
the O
validation O
set O
: O
for O
label O
smoothing O
( O
ls O
) O
, O
we O
searched O
the O
smoothing O
parameter O
in O
[ O
0.05 O
, O
0.1 O
, O
0.2 O
, O
0.3 O
, O
0.4 O
, O
0.5 O
] O
, O
and O
found O
0.1 O
works O
best O
on O
all O
the O
datasets O
; O
for O
confidence O
penalty O
( O
cp O
) O
, O
we O
searched O
the O
weight O
of O
penalty O
in O
[ O
0.0005 O
, O
0.001 O
, O
0.01 O
, O
0.05 O
, O
0.1 O
] O
and O
found O
0.05 O
works O
best O
on O
all O
the O
datasets O
while O
ensuring O
the O
loss O
to O
be O
positive O
; O
for O
focal O
loss O
( O
fl O
) O
, O
we O
searched O
the O
hyperparameter O
γ O
in O
[ O
0.1 O
, O
0.5 O
, O
1 O
, O
2 O
, O
3 O
] O
, O
and O
found O
2 O
works O
best O
on O
all O
the O
datasets O
. O

section 21
id pdf2json/2021.acl-long.272.pdf.json
for O
unlikelihood O
loss O
( O
ul O
) O
, O
we O
searched O
the O
weight O
of O
penalty O
in O
[ O
1 O
, O
10 O
, O
100 O
, O
1000 O
] O
, O
and O
select O
1000 O
on O
all O
the O
datasets O
. O

section 21
id pdf2json/2021.acl-long.272.pdf.json
for O
face O
, O
we O
experiment O
with O
the O
output O
token O
frequency O
& O
pre-weigh O
version O
, O
which O
is O
reported O
to O
be O
the O
best O
version O
of O
face O
. O

section 21
id pdf2json/2021.acl-long.272.pdf.json
for O
negative O
loss O
( O
nl O
) O
, O
f2-softmax O
( O
f2 O
) O
and O
datadependent O
gaussian O
prior O
objective O
( O
d2gpo O
) O
, O
the O
selection O
of O
hyper-parameters O
follows O
the O
author O
’ O
s O
suggestion O
. O

section 22
id pdf2json/2021.acl-long.272.pdf.json
this O
appendix O
reports O
our O
model O
’ O
s O
automatic O
evaluation O
results O
and O
all O
the O
baselines O
when O
different O
decoding O
schemes O
are O
used O
. O

section 22
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
table O
6 O
shows O
the O
results O
for O
the O
beam O
search O
decoding O
scheme O
( O
beam O
size O
of O
5 O
) O
, O
and O
table O
7 O
shows O
the O
results O
when O
the O
top-k O
decoding O
scheme O
( O
k O
= O
10 O
) O
is O
used O
. O

section 22
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
for O
the O
f2-softmax O
, O
we O
use O
the O
decoupled O
top-k O
sampling O
as O
the O
authors O
suggested O
. O

section 22
id pdf2json/2021.acl-long.272.pdf.json
as O
can O
be O
seen O
from O
table O
6 O
and O
7 O
, O
our O
method O
outperforms O
all O
the O
baselines O
on O
the O
diversityrelated O
scores O
( O
i.e. O
, O
dist O
, O
ent O
, O
and O
lf O
) O
by O
a O
large O
margin O
. O

section 22
id pdf2json/2021.acl-long.272.pdf.json
this O
indicates O
that O
our O
method O
can O
produce O
more O
diverse O
responses O
even O
with O
the O
stochastic O
based O
decoding O
scheme O
. O

section 22
id pdf2json/2021.acl-long.272.pdf.json
we O
also O
include O
the O
results O
of O
adalabel O
when O
the O
greedy O
decoding O
scheme O
is O
used O
in O
table O
6 O
and O
table O
7 O
( O
the O
second O
line O
from O
the O
bottom O
) O
. O

section 22
id pdf2json/2021.acl-long.272.pdf.json
it O
is O
interesting O
to O
see O
that O
the O
greedily O
decoded O
responses O
from O
adalabel O
are O
more O
diverse O
than O
some O
baselines O
that O
are O
decoded O
using O
the O
sampling O
scheme O
( O
see O
table O
7 O
) O
. O

section 22
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
our O
model O
adalabel O
with O
the O
greedy O
decoding O
scheme O
achieves O
the O
best O
bleu O
among O
all O
the O
baselines O
on O
both O
datasets O
. O

section 23
id pdf2json/2021.acl-long.272.pdf.json
this O
appendix O
reports O
the O
prediction O
confidence O
scores O
assigned O
by O
each O
model O
to O
high-frequency O
words O
. O

section 23
id pdf2json/2021.acl-long.272.pdf.json
specifically O
, O
words O
occupying O
the O
top O
40 O
% O
of O
the O
frequency O
mass O
in O
the O
training O
set O
of O
each O
dataset O
are O
regarded O
as O
high-frequency O
words O
. O

section 23
id pdf2json/2021.acl-long.272.pdf.json
figure O
6 O
shows O
the O
results O
of O
our O
model O
and O
all O
the O
baselines O
on O
the O
dailydialog O
dataset O
. O

section 23
id pdf2json/2021.acl-long.272.pdf.json
figure O
7 O
shows O
the O
results O
of O
our O
model O
and O
all O
the O
baselines O
on O
the O
opensubtitles O
dataset O
. O

section 23
id pdf2json/2021.acl-long.272.pdf.json
it O
can O
be O
seen O
that O
most O
of O
our O
baselines O
assign O
extremely O
high O
confidence O
scores O
( O
nearly O
1.0 O
) O
to O
these O
high-frequency O
words O
, O
and O
thus O
resulting O
in O
a O
spike O
of O
high O
confidence O
scores O
in O
the O
plotted O
distribution O
. O

section 23
id pdf2json/2021.acl-long.272.pdf.json
our O
model O
outperforms O
all O
the O
baselines O
in O
avoiding O
assigning O
extremely O
high O
confidence O
scores O
to O
these O
highfrequency O
words O
. O

section 24
id pdf2json/2021.acl-long.272.pdf.json
this O
appendix O
shows O
the O
distribution O
of O
rare O
words O
in O
the O
generated O
responses O
on O
the O
dailydialog O
dataset O
( O
see O
figure O
8 O
) O
. O

section 24
id pdf2json/2021.acl-long.272.pdf.json
it O
can O
be O
seen O
that O
more O
“ O
rare O
words O
” O
are O
predicted O
by O
our O
method O
on O
the O
dailydialog O
dataset O
. O

section 24
id pdf2json/2021.acl-long.272.pdf.json
this O
observation O
is O
in O
line O
with O
the O
results O
on O
the O
opensubtitles O
dataset O
as O
reported O
in O
section O
5.3 O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
this O
appendix O
provides O
more O
experiment O
results O
comparing O
to O
the O
cmlm O
model O
( O
chen O
et O
al. O
, O
2020 O
) O
: O
1 O
) O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
cmlm O
exactly O
follows O
the O
setting O
of O
chen O
et O
al O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
( O
2020 O
) O
, O
i.e. O
, O
the O
teacher O
distribution O
produced O
by O
model O
bleu-3,4 O
dist-1,2 O
ent-1,2 O
lf O
1 O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
cmlm O
6.18 O
4.09 O
2.20 O
11.83 O
4.59 O
6.79 O
4.62 O
2 O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
cmlm+ε O
9.36 O
7.31 O
3.78 O
21.05 O
4.96 O
7.61 O
6.88 O
3 O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
cmlm+ε+da O
11.6 O
9.34 O
3.67 O
20.97 O
5.02 O
7.71 O
7.28 O
adalabel O
13.38 O
11.01 O
3.96 O
23.53 O
5.17 O
8.00 O
8.49 O
table O
8 O
: O
ablation O
study O
results O
based O
on O
bert O
on O
dailydialog O
( O
% O
) O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
the O
bert O
model O
is O
merged O
with O
the O
one-hot O
distribution O
using O
a O
fixed O
ε O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
2 O
) O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
cmlm+ε O
adaptively O
adjust O
the O
value O
of O
ε O
using O
eq O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
6 O
in O
our O
paper O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
3 O
) O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
cmlm+ε+da O
add O
an O
additional O
training O
task O
to O
optimize O
the O
auxiliary O
decoder O
da O
on O
the O
basis O
of O
cmlm+ε O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
it O
is O
expected O
that O
optimizing O
da O
help O
our O
dialogue O
encoder O
to O
capture O
better O
representations O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
the O
trainedda O
is O
not O
used O
in O
the O
training O
and O
inference O
phase O
of O
our O
dialogue O
model O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
note O
that O
the O
last O
model O
cmlm+ε+da O
is O
the O
same O
with O
our O
ablation O
model O
6 O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
bert O
as O
reported O
in O
our O
paper O
. O

section 25
id pdf2json/2021.acl-long.272.pdf.json
as O
can O
be O
seen O
table O
8 O
, O
our O
approach O
to O
adaptively O
change O
ε O
helps O
to O
produce O
better O
dialogue O
responses O
, O
and O
the O
training O
of O
da O
helps O
our O
dialogue O
encoder O
to O
learn O
better O
representations O
. O

section 26
id pdf2json/2021.acl-long.272.pdf.json
we O
sampled O
some O
generated O
cases O
on O
the O
dailydialog O
and O
opensubtitles O
dataset O
. O

section 26
id pdf2json/2021.acl-long.272.pdf.json
the O
results O
of O
our O
model O
and O
some O
competitive O
baselines O
are O
shown O
in O
table O
9 O
and O
table O
10 O
. O

section 26
id pdf2json/2021.acl-long.272.pdf.json
it O
can O
be O
seen O
that O
the O
responses O
generated O
by O
our O
method O
are O
coherent O
to O
the O
context O
and O
contain O
richer O
contents O
. O

section 26
id pdf2json/2021.acl-long.272.pdf.json
moreover O
, O
our O
model O
also O
produces O
more O
rare O
words O
that O
make O
our O
response O
more O
diverse O
. O

section TITLE
id pdf2json/2021.acl-long.53.pdf.json
breaking O
down O
the O
invisible O
wall O
of O
informal O
fallacies O
in O
online O
discussions O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
people O
debate O
on O
a O
variety O
of O
topics O
on O
online O
platforms O
such O
as O
reddit O
, O
or O
facebook O
. O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
debates O
can O
be O
lengthy O
, O
with O
users O
exchanging O
a O
wealth O
of O
information O
and O
opinions O
. O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
however O
, O
conversations O
do O
not O
always O
go O
smoothly O
, O
and O
users O
sometimes O
engage O
in O
unsound O
argumentation O
techniques O
to O
prove O
a O
claim O
. O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
these O
techniques O
are O
called O
fallacies O
. O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
fallacies O
are O
persuasive O
arguments O
that O
provide O
insufficient O
or O
incorrect O
evidence O
to O
support O
the O
claim O
. O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
paper O
, O
we O
study O
the O
most O
frequent O
fallacies O
on O
reddit O
, O
and O
we O
present O
them O
using O
the O
pragma-dialectical O
theory O
of O
argumentation O
. O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
we O
construct O
a O
new O
annotated O
dataset O
of O
fallacies O
, O
using O
user O
comments O
containing O
fallacy O
mentions O
as O
noisy O
labels O
, O
and O
cleaning O
the O
data O
via O
crowdsourcing O
. O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
finally O
, O
we O
study O
the O
task O
of O
classifying O
fallacies O
using O
neural O
models O
. O

section ABSTRACT
id pdf2json/2021.acl-long.53.pdf.json
we O
find O
that O
generally O
the O
models O
perform O
better O
in O
the O
presence O
of O
conversational O
context.we O
have O
released O
the O
data O
and O
the O
code O
at O
github.com/sahaisaumya/informal_ O
fallacies O
. O

section 0
id pdf2json/2021.acl-long.53.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
644–657 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.53.pdf.json
©2021 O
association O
for O
computational O
linguistics O
644 O

section 1
id pdf2json/2021.acl-long.53.pdf.json
argumentation O
plays O
a O
critical O
part O
in O
our O
lives O
as O
it O
helps O
us O
make O
decisions O
and O
reason O
about O
the O
world O
around O
us O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
studies O
( O
sanders O
et O
al. O
, O
1994 O
) O
have O
shown O
that O
learning O
how O
to O
argue O
increases O
the O
ability O
to O
identify O
weak O
arguments O
and O
decreases O
the O
tendency O
to O
use O
verbal O
aggressiveness O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
fallacies O
are O
weak O
arguments O
that O
seem O
convincing O
, O
however O
, O
their O
evidence O
does O
not O
prove O
or O
disprove O
the O
argument O
’ O
s O
conclusion O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
fallacies O
are O
usually O
divided O
into O
formal O
and O
informal O
, O
where O
the O
former O
can O
be O
easily O
described O
using O
logical O
representations O
, O
while O
for O
the O
latter O
, O
an O
analysis O
of O
the O
content O
is O
more O
appropriate O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
fallacies O
are O
prevalent O
in O
public O
part O
of O
this O
work O
was O
done O
while O
the O
first O
author O
was O
an O
intern O
at O
inria O
, O
france O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
discourse O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
for O
example O
, O
the O
new O
york O
times O
labeled O
the O
tweets O
of O
donald O
trump O
between O
2015 O
and O
2020 O
and O
found O
thousands O
of O
insults O
addressed O
to O
his O
adversaries O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
if O
made O
in O
an O
argument O
, O
an O
insult O
is O
an O
ad O
hominem O
fallacy O
: O
an O
attack O
on O
the O
opponent O
rather O
than O
on O
their O
argument O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
in O
private O
conversations O
, O
other O
types O
of O
fallacies O
might O
be O
more O
prevalent O
, O
for O
example O
, O
appeal O
to O
tradition O
or O
appeal O
to O
nature O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
appeal O
to O
tradition O
dismisses O
calls O
to O
improve O
gender O
equality O
by O
stating O
that O
“ O
women O
have O
always O
occupied O
this O
place O
in O
society O
” O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
appeal O
to O
nature O
is O
often O
used O
to O
ignore O
calls O
to O
be O
inclusive O
of O
the O
lgbtq+ O
community O
by O
stating O
“ O
gender O
is O
binary O
” O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
the O
underlying O
premises O
of O
such O
arguments O
are O
“ O
traditions O
are O
correct O
” O
and O
“ O
what O
occurs O
in O
nature O
is O
good O
” O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
creating O
a O
dataset O
of O
fallacious O
arguments O
is O
difficult O
, O
given O
that O
there O
are O
over O
100 O
types O
of O
fallacious O
arguments O
( O
scalambrino O
, O
2018 O
) O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
there O
have O
been O
several O
attempts O
to O
create O
comprehensive O
datasets O
: O
habernal O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
( O
2017 O
) O
proposed O
a O
game O
in O
which O
players O
add O
fallacies O
in O
the O
hope O
of O
fouling O
other O
participants O
, O
in O
habernal O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
( O
2018a O
) O
ad O
hominem O
fallacies O
are O
found O
using O
a O
subreddit O
’ O
s O
rule O
violations O
, O
while O
in O
da O
san O
martino O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
( O
2019 O
) O
fallacies O
are O
annotated O
together O
with O
other O
propaganda O
techniques O
in O
news O
articles O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
however O
, O
our O
work O
is O
the O
first O
to O
propose O
a O
viable O
solution O
for O
finding O
fallacious O
arguments O
belonging O
to O
many O
different O
fallacy O
types O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
work O
, O
we O
study O
fallacies O
in O
public O
discussions O
on O
online O
forums O
. O

section 1
id pdf2json/2021.acl-long.53.pdf.json
our O
salient O
contributions O
are O
: O
i O
) O
we O
align O
informal O
fallacies O
mentioned O
on O
reddit O
within O
the O
pragma-dialectic O
theory O
of O
argumentation O
( O
van O
eemeren O
and O
grootendorst O
, O
1995 O
) O
; O
ii O
) O
we O
design O
a O
methodology O
for O
mining O
and O
labeling O
easily O
fallacies O
in O
online O
discussions O
; O
iii O
) O
we O
construct O
a O
large O
and O
balanced O
dataset O
of O
fallacious O
arguments O
; O
iv O
) O
finally O
, O
we O
evaluate O
several O
neural O
models O
on O
the O
task O
of O
predicting O
fallacious O
argu- O
ments O
, O
and O
we O
find O
that O
taking O
into O
consideration O
additional O
conversational O
context O
is O
important O
for O
this O
task O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
humans O
use O
argumentation O
when O
they O
evaluate O
the O
validity O
of O
new O
ideas O
, O
or O
they O
want O
to O
solve O
a O
difference O
of O
opinion O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
an O
argument O
contains O
: O
i O
) O
a O
proposition O
called O
claim O
, O
conclusion O
or O
standpoint O
, O
to O
be O
validated O
; O
ii O
) O
the O
premises O
called O
also O
evidence O
, O
which O
are O
the O
backing O
propositions O
; O
iii O
) O
an O
inference O
relation O
between O
the O
evidence O
and O
conclusion O
that O
validates O
or O
disproves O
the O
conclusion O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
a O
fallacy O
is O
a O
flawed O
argument O
, O
where O
the O
inference O
relation O
or O
the O
premises O
are O
incorrect O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
fallacies O
are O
generally O
divided O
into O
formal O
and O
informal O
fallacies O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
formal O
fallacies O
are O
arguments O
that O
can O
be O
easily O
represented O
as O
invalid O
logical O
formulas O
, O
such O
as O
denying O
the O
antecedent O
, O
which O
is O
a O
wrong O
application O
of O
modus O
tollens O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
although O
many O
informal O
fallacies O
can O
be O
also O
represented O
as O
invalid O
arguments O
, O
informal O
fallacies O
are O
easier O
to O
describe O
and O
understand O
without O
resorting O
to O
logical O
representations O
( O
hansen O
, O
2020 O
) O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
work O
, O
we O
follow O
the O
pragma O
dialectic O
theory O
of O
argumentation O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
the O
theory O
developed O
by O
van O
eemeren O
and O
grootendorst O
( O
1995 O
) O
views O
argumentation O
as O
a O
complex O
speech O
act O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
the O
dialectical O
aspect O
is O
represented O
by O
two O
parties O
who O
try O
to O
resolve O
a O
difference O
of O
opinion O
by O
engaging O
in O
a O
discussion O
, O
each O
party O
making O
a O
move O
towards O
resolution O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
the O
pragmatic O
aspect O
describes O
the O
moves O
in O
the O
discussion O
as O
speech O
acts O
, O
more O
precisely O
as O
the O
illocutionary O
acts O
introduced O
by O
searle O
( O
1979 O
) O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
van O
eemeren O
and O
grootendorst O
( O
1995 O
) O
also O
developed O
ten O
rules O
which O
should O
guide O
argumentative O
discussions O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
the O
goal O
of O
the O
rules O
is O
to O
further O
the O
understanding O
of O
the O
difference O
of O
opinions O
and O
to O
create O
a O
fruitful O
discussion O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
for O
example O
, O
a O
rule O
states O
that O
parties O
must O
not O
prevent O
each O
other O
from O
advancing O
standpoints O
or O
from O
casting O
doubt O
on O
standpoints O
, O
while O
a O
second O
rule O
asks O
that O
a O
party O
may O
defend O
a O
standpoint O
only O
by O
advancing O
argumentation O
relating O
to O
that O
standpoint O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
an O
argument O
that O
prevents O
the O
resolution O
and O
thus O
violates O
one O
of O
the O
rules O
is O
a O
fallacy O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
in O
our O
work O
, O
we O
align O
frequent O
fallacies O
on O
reddit O
with O
these O
rules O
, O
with O
the O
goal O
of O
formalizing O
their O
definitions O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
another O
well-known O
model O
that O
considers O
fallacies O
is O
the O
argumentation O
scheme O
introduced O
by O
douglas O
walton O
( O
walton O
, O
2005 O
) O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
a O
scheme O
consists O
of O
a O
conclusion O
, O
a O
set O
of O
premises O
, O
and O
a O
set O
of O
critical O
questions O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
the O
critical O
questions O
should O
be O
answered O
in O
order O
to O
prove O
that O
the O
premises O
support O
the O
conclusion O
, O
hence O
the O
argument O
is O
not O
a O
fallacy O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
for O
example O
, O
the O
scheme O
for O
an O
argument O
from O
expert O
opinion O
( O
walton O
, O
2005 O
) O
has O
the O
premises O
e O
is O
an O
expert O
in O
domain O
d O
, O
e O
asserts O
that O
a O
is O
known O
to O
be O
true O
, O
a O
is O
within O
d O
and O
the O
conclusion O
therefore O
, O
a O
may O
plausibly O
be O
taken O
to O
be O
true O
. O

section 3
id pdf2json/2021.acl-long.53.pdf.json
some O
critical O
questions O
for O
this O
scheme O
are O
: O
i O
) O
trustworthiness O
: O
is O
e O
personally O
reliable O
as O
a O
source O
? O

section 3
id pdf2json/2021.acl-long.53.pdf.json
ii O
) O
backup O
evidence O
: O
is O
e O
’ O
s O
assertion O
based O
on O
evidence O
? O

section 3
id pdf2json/2021.acl-long.53.pdf.json
argumentation O
schemes O
have O
two O
main O
drawbacks O
: O
first O
, O
for O
each O
new O
fallacy O
, O
a O
new O
scheme O
should O
exist O
or O
be O
defined O
; O
and O
second O
, O
in O
the O
context O
of O
labeling O
an O
existing O
argument O
, O
many O
of O
the O
critical O
questions O
might O
be O
unanswerable O
as O
none O
of O
the O
parties O
discussed O
them O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
an O
initial O
effort O
for O
creating O
an O
extensive O
dataset O
of O
fallacies O
was O
made O
in O
habernal O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
( O
2017 O
) O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
the O
authors O
created O
a O
platform O
for O
educative O
games O
, O
where O
players O
learn O
how O
to O
become O
better O
debaters O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
new O
fallacies O
are O
added O
to O
the O
platform O
by O
players O
that O
try O
to O
earn O
points O
by O
fouling O
other O
participants O
with O
invalid O
arguments O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
a O
follow-up O
on O
this O
work O
( O
habernal O
et O
al. O
, O
2018a O
) O
mentioned O
a O
dataset O
of O
only O
around O
300 O
arguments O
created O
via O
the O
platform O
, O
thus O
showing O
the O
need O
of O
finding O
other O
methods O
for O
creating O
larger O
datasets O
of O
fallacies O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
ad O
hominem O
fallacies O
in O
conversations O
have O
been O
addressed O
in O
( O
habernal O
et O
al. O
, O
2018b O
) O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
the O
authors O
used O
the O
subreddit O
changemyview O
, O
which O
is O
a O
forum O
for O
civilized O
discussions O
, O
“ O
a O
place O
to O
post O
an O
opinion O
you O
accept O
may O
be O
flawed O
, O
in O
an O
effort O
to O
understand O
other O
perspectives O
on O
the O
issue O
” O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
the O
dataset O
of O
fallacies O
consists O
of O
comments O
that O
were O
removed O
by O
the O
moderators O
as O
they O
violated O
the O
rule O
of O
not O
being O
rude O
or O
hostile O
, O
hence O
committing O
an O
ad O
hominem O
fallacy O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
fallacious O
arguments O
are O
often O
made O
in O
the O
dissemination O
of O
propaganda O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
in O
da O
san O
martino O
et O
al O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
( O
2019 O
) O
, O
the O
authors O
annotate O
journal O
articles O
with O
18 O
propaganda O
techniques O
, O
out O
of O
which O
12 O
techniques O
are O
fallacies O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
although O
an O
important O
resource O
in O
the O
study O
of O
fallacies O
, O
their O
labelling O
method O
and O
dataset O
have O
a O
few O
drawbacks O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
first O
, O
the O
dataset O
is O
highly O
unbalanced O
with O
6 O
fallacies O
having O
a O
fair O
number O
of O
mentions O
: O
name-calling O
( O
1294 O
) O
, O
appeal O
to O
fear O
and O
prejudice O
( O
367 O
) O
, O
flag-waving O
( O
330 O
) O
, O
causal O
oversimplification O
( O
233 O
) O
, O
appeal O
to O
authority O
( O
169 O
) O
, O
black O
and O
white O
fallacy O
( O
134 O
) O
, O
and O
6 O
fallacies O
having O
less O
than O
100 O
mentions O
: O
whataboutism O
( O
76 O
) O
, O
reductio O
ad O
hitlerum O
( O
66 O
) O
, O
red O
herring O
( O
48 O
) O
, O
bandwagon O
( O
17 O
) O
, O
labeling O
, O
obfuscation O
or O
intentional O
vagueness O
( O
17 O
) O
, O
straw O
men O
( O
15 O
) O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
second O
, O
the O
task O
of O
finding O
the O
correct O
label O
for O
a O
span O
of O
text O
from O
a O
large O
set O
of O
labels O
( O
18 O
in O
their O
case O
) O
is O
intellectually O
complex O
and O
time-consuming O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
our O
work O
focuses O
on O
collecting O
and O
annotating O
a O
balanced O
dataset O
of O
fallacy O
mentions O
while O
providing O
a O
methodology O
that O
can O
easily O
scale O
to O
a O
larger O
number O
of O
fallacies O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
in O
our O
approach O
, O
an O
annotator O
has O
to O
just O
verify O
that O
a O
comment O
contains O
one O
type O
of O
fallacy O
. O

section 4
id pdf2json/2021.acl-long.53.pdf.json
in O
addition O
, O
we O
target O
fallacies O
in O
online O
conversations O
, O
where O
the O
style O
of O
argumentation O
is O
less O
structured O
than O
in O
a O
journal O
article O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
finding O
a O
large O
sample O
of O
fallacious O
arguments O
is O
a O
challenging O
task O
as O
it O
assumes O
going O
through O
long O
conversations O
, O
finding O
arguments O
, O
and O
then O
verifying O
if O
the O
arguments O
are O
sound O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
another O
major O
issue O
, O
even O
if O
we O
recognize O
the O
argument O
is O
flawed O
, O
is O
to O
find O
the O
exact O
fallacy O
that O
is O
committed O
, O
given O
that O
more O
than O
100 O
types O
of O
fallacies O
have O
been O
proposed O
in O
the O
literature O
( O
scalambrino O
, O
2018 O
) O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
our O
goal O
is O
to O
construct O
an O
annotated O
dataset O
of O
fallacies O
using O
a O
mixed O
strategy O
: O
i O
) O
first O
, O
as O
noisy O
labels O
, O
we O
leverage O
user O
comments O
that O
mention O
the O
name O
of O
a O
fallacy O
, O
and O
second O
, O
ii O
) O
we O
clean O
this O
dataset O
by O
removing O
false-positive O
samples O
via O
crowdsourcing O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
our O
intuition O
is O
that O
a O
person O
will O
mention O
a O
fallacy O
as O
a O
reply O
to O
another O
comment O
to O
highlight O
that O
the O
previous O
comment O
’ O
s O
argument O
is O
fallacious O
, O
as O
shown O
in O
figure O
1 O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
this O
might O
not O
always O
be O
the O
case O
, O
as O
users O
could O
discuss O
fallacies O
in O
general O
, O
hence O
the O
need O
to O
further O
label O
the O
discussion O
using O
crowdsourcing O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
we O
use O
the O
pushshift O
reddit O
api O
( O
baumgartner O
et O
al. O
, O
2020 O
) O
to O
retrieve O
data O
from O
reddit O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
api O
allows O
searching O
comments O
and O
submissions O
by O
their O
ids O
or O
by O
a O
set O
of O
keywords O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
we O
start O
by O
making O
an O
exhaustive O
list O
of O
fallacies O
informed O
by O
wikipedia O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
we O
chose O
wikipedia O
as O
a O
resource O
for O
creating O
the O
list O
of O
fallacies O
as O
it O
is O
one O
of O
the O
most O
well-known O
sources O
of O
information O
, O
hence O
a O
reddit O
user O
could O
peruse O
it O
easily O
to O
understand O
what O
fallacy O
was O
committed O
in O
the O
discussion O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
for O
each O
fallacy O
we O
find O
all O
its O
different O
designations O
, O
for O
example O
, O
appeal O
to O
tradition O
is O
also O
known O
under O
its O
latin O
name O
, O
argumentum O
ad O
antiquitatem O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
we O
then O
do O
a O
keyword O
search O
for O
these O
fallacy O
types O
on O
reddit O
comments O
, O
restricting O
the O
results O
to O
one O
year O
, O
may O
2019 O
to O
may O
2020 O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
we O
retrieve O
in O
total O
105k O
comments O
that O
match O
at O
least O
one O
fallacy O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
for O
comparison O
, O
in O
2019 O
, O
1.7 O
billion O
comments O
were O
posted O
on O
reddit O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
while O
it O
is O
very O
likely O
that O
many O
more O
posts O
contain O
fallacies O
, O
the O
small O
number O
of O
matches O
highlights O
the O
importance O
of O
choosing O
with O
care O
the O
comments O
to O
annotate O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
to O
understand O
in O
which O
subreddits O
people O
were O
more O
likely O
to O
mention O
names O
of O
fallacies O
, O
we O
compute O
the O
top O
10 O
subreddits O
with O
the O
highest O
ratio O
of O
matched O
comments O
per O
number O
of O
subscribers O
, O
as O
shown O
in O
table O
1 O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
subreddits O
are O
broadly O
divided O
into O
subreddits O
on O
religion O
, O
morality O
, O
and O
science O
, O
with O
one O
subreddit O
dedicated O
to O
discussions O
on O
fallacies O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
subreddits O
’ O
focus O
is O
on O
debating O
, O
which O
involves O
creating O
, O
defending O
, O
and O
attacking O
arguments O
, O
therefore O
accusing O
the O
opponent O
of O
committing O
a O
fallacy O
might O
win O
you O
the O
debate O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
from O
the O
list O
of O
most O
frequently O
mentioned O
fallacies O
we O
retained O
the O
top O
fallacies O
with O
more O
than O
400 O
mentions O
, O
resulting O
in O
32 O
fallacy O
types O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
this O
shortlist O
of O
frequent O
fallacies O
is O
presented O
in O
our O
appendix O
a O
, O
with O
a O
definition O
, O
example O
, O
and O
argumentation O
rule O
violation O
( O
according O
to O
the O
pragma O
dialectic O
theory O
) O
for O
each O
fallacy O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
from O
this O
shortlist O
we O
do O
not O
consider O
the O
fallacies O
that O
were O
already O
studied O
in O
habernal O
et O
al O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
( O
2018b O
) O
, O
as O
their O
labeled O
dataset O
is O
also O
based O
on O
reddit O
comments O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
we O
do O
not O
exclude O
fallacy O
types O
annotated O
in O
da O
san O
martino O
et O
al O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
( O
2019 O
) O
, O
as O
these O
are O
fallacious O
arguments O
in O
journal O
articles O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
we O
take O
random O
samples O
of O
20 O
comments O
that O
mention O
one O
of O
our O
frequent O
fallacies O
and O
the O
comment O
to O
which O
they O
reply O
( O
the O
potential O
fallacious O
comment O
) O
, O
and O
we O
check O
if O
the O
users O
have O
a O
good O
understanding O
of O
the O
respective O
fallacies O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
we O
keep O
the O
fallacies O
for O
which O
users O
generally O
had O
a O
correct O
sense O
of O
their O
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
in O
addition O
, O
we O
filter O
fallacy O
types O
if O
more O
than O
60 O
% O
of O
potential O
fallacious O
comments O
were O
not O
true O
fallacious O
arguments O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
these O
conditions O
assure O
that O
the O
comments O
we O
will O
label O
have O
good O
quality O
and O
that O
we O
will O
find O
sufficient O
actual O
fallacy O
examples O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
remaining O
fallacies O
are O
selected O
for O
the O
creation O
of O
an O
annotated O
dataset O
of O
fallacies O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
these O
8 O
fallacies O
are O
: O
appeal O
to O
authority O
/ O
argument O
from O
authority O
fallacy O
/ O
argumentum O
ad O
verecundiam O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
claim O
is O
supported O
by O
the O
opinion O
of O
a O
person O
with O
authority O
, O
hence O
the O
claim O
is O
true O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
being O
vegan O
makes O
no O
sense O
because O
my O
father O
said O
so O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
appeal O
to O
majority O
/ O
bandwagon O
argument O
/ O
appeal O
to O
widespread O
belief O
/ O
appeal O
to O
the O
people O
fallacy O
/ O
argumentum O
ad O
populum O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
a O
claim O
is O
true O
because O
many O
people O
believe O
it O
to O
be O
true O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
being O
vegan O
makes O
no O
sense O
because O
so O
many O
of O
us O
are O
meat O
eaters O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
appeal O
to O
nature O
/ O
naturalistic O
fallacy O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
an O
action O
a O
is O
justified/unjustified O
because O
it O
occurs/does O
not O
occur O
in O
nature O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
being O
vegan O
makes O
no O
sense O
as O
our O
body O
is O
designed O
for O
eating O
meat O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
appeal O
to O
tradition O
fallacy O
/ O
argumentum O
ad O
antiquitatem O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
an O
action O
a O
is O
justified/unjustified O
because O
it O
has O
always O
been O
considered O
as O
such O
in O
the O
past O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
being O
vegan O
makes O
no O
sense O
as O
our O
ancestors O
have O
been O
meat O
eaters O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
appeal O
to O
worse O
problems O
/ O
relative O
privation O
/ O
not O
as O
bad O
as O
fallacy O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
there O
exists O
problem O
a O
that O
is O
worse O
than O
problem O
b O
, O
therefore O
b O
is O
justified O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
black-or-white O
/ O
false O
dilemma O
/ O
false O
dichotomy O
/ O
bifurcation O
fallacy O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
, O
the O
claim O
is O
that O
only O
an O
event/action O
a O
should O
be O
considered O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
first O
premise O
is O
that O
only O
two O
events O
, O
a O
and O
b O
are O
possible O
when O
there O
is O
at O
least O
a O
third O
event O
c O
possible O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
second O
premise O
is O
that O
one O
of O
the O
events O
is O
bad O
, O
for O
example O
b O
, O
thus O
only O
event O
a O
should O
be O
considered O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
you O
must O
wear O
a O
mask O
each O
time O
you O
go O
out O
, O
otherwise O
, O
you O
will O
die O
of O
covid-19 O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
hasty O
generalization O
fallacy O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
claim O
is O
supported O
by O
insufficient O
evidence O
through O
inductive O
generalization O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
more O
precisely O
, O
we O
know O
that O
predicate O
p O
is O
true O
for O
a O
population O
sample O
, O
and O
we O
suppose O
it O
is O
true O
for O
the O
entire O
population O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
however O
, O
the O
sample O
is O
too O
small O
or O
it O
is O
not O
representative O
of O
the O
population O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
first O
week O
of O
september O
has O
been O
sunny O
, O
which O
means O
the O
rest O
of O
the O
month O
will O
be O
the O
same O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
slippery O
slope O
/ O
thin O
edge O
of O
the O
wedge O
/ O
camel O
’ O
s O
nose O
fallacy O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
a O
small O
event O
a O
will O
have O
a O
big O
unwanted O
consequence O
c. O
there O
is O
at O
least O
one O
more O
event O
b O
in O
the O
chain O
of O
causality O
( O
a O
will O
cause O
b O
, O
b O
will O
cause O
c O
) O
, O
hence O
the O
slippery O
slope O
name O
of O
the O
fallacy O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
if O
you O
break O
your O
diet O
and O
have O
one O
cookie O
tonight O
, O
you O
will O
just O
want O
to O
eat O
10 O
cookies O
tomorrow O
and O
20 O
the O
day O
after O
, O
and O
before O
you O
know O
it O
, O
you O
will O
have O
gained O
back O
the O
15 O
pounds O
you O
lost O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
rule O
violation O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
according O
to O
the O
pragma O
dialectic O
theory O
, O
an O
argument O
is O
a O
fallacy O
if O
it O
violates O
a O
critical O
discussion O
rule O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
arguments O
above O
violate O
one O
of O
two O
rules O
, O
hence O
they O
are O
fallacies O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
the O
first O
rule O
violated O
states O
that O
defending O
a O
claim O
must O
occur O
through O
an O
appropriate O
argumentation O
scheme O
that O
is O
correctly O
applied O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
argumentation O
schemes O
in O
van O
eemeren O
and O
grootendorst O
( O
1995 O
) O
are O
different O
than O
schemes O
in O
walton O
( O
2005 O
) O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
they O
are O
a O
formalization O
of O
the O
relation O
between O
the O
evidence O
presented O
and O
the O
standpoint O
to O
be O
defended O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
this O
rule O
is O
violated O
by O
all O
fallacies O
, O
except O
blackor-white O
. O

section 5
id pdf2json/2021.acl-long.53.pdf.json
for O
example O
, O
in O
slippery O
slope O
, O
the O
argumentation O
is O
not O
valid O
as O
there O
is O
no O
clear O
causality O
chain O
between O
a O
and O
c. O
black-or-white O
fallacy O
violates O
the O
rule O
that O
a O
party O
should O
not O
falsely O
present O
a O
premise O
as O
an O
accepted O
starting O
point O
, O
by O
stating O
that O
only O
events O
a O
and O
b O
are O
possible O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
noisy O
labels O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
used O
amazon O
mechanical O
turk O
to O
create O
our O
annotated O
dataset O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
selected O
4 O
master O
annotators O
, O
which O
had O
the O
highest O
agreement O
with O
the O
authors O
on O
identifying O
a O
set O
of O
fallacies O
( O
70 O
samples O
) O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
an O
annotation O
task O
, O
defined O
as O
a O
hit1 O
consists O
of O
10 O
items O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
each O
item O
presents O
a O
sample O
extracted O
from O
a O
reddit O
discussion O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
a O
reddit O
discussion O
is O
started O
by O
a O
submission O
, O
e.g. O
, O
a O
news O
article O
or O
a O
piece O
of O
text O
, O
to O
which O
users O
engage O
by O
writing O
comments O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
comments O
and O
submission O
are O
organized O
in O
a O
tree-like O
structure O
: O
the O
submission O
is O
the O
root O
, O
and O
comments O
are O
nodes O
in O
the O
tree O
; O
we O
will O
use O
the O
terms O
grandparent O
, O
parent O
, O
and O
child O
to O
denote O
relations O
between O
comments O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
a O
sample O
given O
for O
annotation O
includes O
the O
title O
and O
the O
link O
of O
the O
original O
reddit O
submission O
and O
four O
comments O
: O
• O
the O
comment O
containing O
the O
mention O
of O
the O
fallacy O
( O
this O
is O
the O
label O
comment O
) O
; O
• O
the O
parent O
of O
the O
label O
comment O
, O
which O
should O
contain O
the O
fallacious O
argument O
( O
the O
comment O
of O
interest O
or O
coi O
) O
; O
• O
the O
parent O
of O
the O
coi O
, O
to O
give O
more O
context O
for O
the O
discussion O
; O
• O
a O
direct O
reply O
to O
the O
label O
comment O
; O
preference O
was O
given O
to O
replies O
that O
had O
the O
same O
author O
as O
the O
coi O
; O
if O
no O
such O
comment O
existed O
, O
then O
we O
choose O
the O
top-rated O
comment O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
an O
example O
of O
a O
sample O
is O
shown O
in O
figure O
1 O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
1human O
intelligence O
task O
on O
amazon O
turk O
for O
each O
fallacy O
described O
in O
section O
3 O
, O
we O
retrieve O
all O
the O
label O
comments O
mentioning O
it O
and O
the O
context O
needed O
for O
creating O
a O
sample O
discussion O
( O
item O
) O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
keep O
the O
items O
for O
which O
: O
i O
) O
the O
comments O
are O
relatively O
short O
: O
the O
label O
comment O
has O
less O
than O
500 O
characters O
( O
a O
shorter O
text O
will O
more O
likely O
be O
an O
accusation O
of O
committing O
a O
fallacy O
) O
, O
and O
the O
other O
comments O
have O
less O
than O
1000 O
characters O
; O
ii O
) O
we O
have O
enough O
context O
to O
understand O
the O
discussion O
: O
the O
coi O
is O
a O
direct O
reply O
to O
the O
submission O
or O
the O
child O
comment O
of O
a O
direct O
reply O
; O
iii O
) O
the O
coi O
or O
its O
parent O
do O
not O
contain O
the O
substring O
‘ O
fallac O
’ O
, O
a O
sign O
that O
this O
could O
be O
a O
discussion O
on O
fallacies O
and O
therefore O
the O
coi O
does O
not O
contain O
a O
fallacious O
argument O
, O
but O
it O
merely O
discusses O
or O
points O
out O
one O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
iv O
) O
we O
have O
access O
to O
the O
original O
discussion O
: O
the O
user O
or O
a O
moderator O
did O
not O
delete O
the O
comments O
, O
and O
the O
submission O
is O
not O
from O
a O
banned O
subreddit O
( O
the O
annotators O
can O
visit O
the O
link O
provided O
with O
the O
submission O
title O
) O
; O
v O
) O
all O
the O
comments O
are O
in O
english O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
crowdsourcing O
task O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
workers O
were O
presented O
with O
concise O
descriptions O
of O
the O
main O
concepts O
involved O
: O
argument O
, O
claim O
, O
evidence O
and O
fallacy O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
all O
the O
items O
in O
a O
hit O
have O
to O
be O
annotated O
only O
for O
one O
fallacy O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
for O
example O
, O
we O
retrieved O
all O
the O
items O
where O
the O
label O
comment O
mentioned O
“ O
hasty O
generalization O
fallacy O
” O
and O
we O
split O
them O
into O
hits O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
note O
that O
the O
fallacy O
committed O
in O
the O
comment O
might O
not O
be O
the O
same O
as O
the O
one O
signaled O
by O
the O
user O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
however O
, O
the O
authors O
have O
reviewed O
a O
large O
sample O
of O
comments O
( O
for O
the O
third O
vote O
explained O
further O
in O
this O
section O
) O
and O
did O
not O
encounter O
this O
situation O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
hence O
, O
even O
if O
this O
might O
still O
occur O
, O
it O
should O
be O
rare O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
for O
each O
selected O
fallacy O
, O
we O
offered O
the O
definition O
together O
with O
an O
example O
of O
the O
fallacy O
, O
where O
we O
identified O
the O
claim O
and O
evidence O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
furthermore O
, O
we O
instruct O
the O
workers O
not O
to O
label O
as O
a O
fallacy O
a O
comment O
that O
is O
sarcastic O
( O
sometimes O
accompanied O
by O
the O
explicit O
tag O
“ O
/s O
” O
) O
or O
a O
comment O
that O
is O
disproving O
the O
fallacy O
, O
e.g. O
, O
who O
would O
think O
that O
we O
shouldn O
’ O
t O
become O
vegans O
just O
because O
our O
body O
is O
able O
to O
digest O
meat O
? O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
workers O
are O
asked O
if O
the O
fallacy O
occurs O
in O
the O
comment O
of O
interest O
and O
if O
yes O
, O
they O
are O
prompted O
to O
highlight O
the O
corresponding O
text O
span O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
they O
are O
also O
asked O
to O
write O
the O
claim O
that O
is O
addressed O
by O
the O
comment O
of O
interest O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
finally O
, O
they O
have O
to O
answer O
a O
question O
specific O
to O
each O
fallacy O
to O
prove O
their O
good O
understanding O
of O
the O
task O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
questions O
are O
: O
i O
) O
appeal O
to O
authority O
: O
“ O
what O
authority O
is O
being O
appealed O
to O
in O
the O
comment O
of O
interest O
, O
and O
hence O
is O
used O
as O
the O
basis O
for O
the O
argument O
? O
” O
; O
ii O
) O
appeal O
to O
majority O
: O
no O
question O
; O
iii O
) O
appeal O
to O
nature O
: O
“ O
what O
natural O
phenomenon/event/activity O
is O
considered O
natural O
here O
? O
” O
iv O
) O
appeal O
to O
tradition O
: O
“ O
what O
tradition O
is O
being O
appealed O
to O
in O
the O
comment O
of O
interest O
, O
and O
hence O
is O
used O
as O
the O
basis O
for O
the O
argument O
? O
” O
; O
v O
) O
appeal O
to O
worse O
problems O
: O
“ O
describe O
why O
the O
current O
problem O
( O
problem O
1 O
) O
is O
not O
a O
trivial O
issue. O
” O
vi O
) O
black-or-white O
: O
“ O
name O
any O
additional O
alternative O
, O
which O
is O
possible O
but O
is O
not O
mentioned O
in O
the O
comment O
of O
interest. O
” O
vii O
) O
hasty O
generalization O
: O
“ O
describe O
a O
case O
where O
the O
( O
hasty O
) O
generalization O
will O
fail. O
” O
viii O
) O
slippery O
slope O
: O
“ O
please O
list O
any O
one O
event O
in O
the O
chain O
of O
slippery O
slope O
argument. O
” O
by O
answering O
these O
questions O
, O
the O
workers O
would O
take O
the O
time O
to O
understand O
why O
the O
argument O
was O
a O
fallacy O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
annotated O
dataset O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
a O
hit O
is O
annotated O
by O
two O
workers O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
compute O
the O
cohen O
’ O
s O
κ O
agreement O
for O
the O
task O
of O
deciding O
if O
a O
comment O
contains O
a O
fallacy O
( O
comment-level O
annotation O
) O
, O
and O
γ O
inter-annotator O
agreement O
( O
mathet O
et O
al. O
, O
2015 O
) O
for O
the O
task O
of O
highlighting O
the O
tokens O
of O
the O
fallacy O
within O
the O
coi O
( O
token-level O
annotation O
) O
, O
as O
shown O
in O
table O
2 O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
for O
both O
measures O
, O
1. O
implies O
perfect O
agreement O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
comment-level O
annotation O
agreement O
varies O
from O
fair O
( O
black-or-white O
and O
hasty O
generalization O
) O
to O
substantial O
( O
appeal O
to O
authority O
) O
, O
with O
the O
majority O
of O
fallacies O
in O
the O
moderate O
interval O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
tokenlevel O
agreement O
is O
moderate O
for O
appeal O
to O
worse O
problems O
and O
substantial O
for O
the O
rest O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
in O
addition O
to O
the O
workers O
’ O
votes O
, O
an O
expert O
annotator O
casts O
a O
third O
vote O
on O
comments O
, O
whenever O
there O
is O
a O
disagreement O
on O
the O
label O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
a O
comment O
is O
marked O
as O
fallacious O
if O
it O
has O
received O
two O
fallacy O
votes O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
corresponding O
fallacious O
tokens O
of O
the O
comment O
are O
the O
union O
of O
the O
tokens O
highlighted O
by O
the O
annotators O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
annotated O
comments O
until O
we O
reached O
roughly O
200 O
fallacious O
comments O
per O
fallacy O
type O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
details O
of O
the O
dataset O
are O
presented O
in O
table O
3 O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
total O
size O
of O
our O
annotated O
dataset O
, O
including O
comments O
and O
tokens O
that O
are O
non O
fallacious O
, O
consists O
of O
3358 O
comments O
and O
160k O
tokens O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
observe O
that O
to O
find O
1708 O
fallacious O
comments O
, O
we O
annotated O
only O
about O
two O
times O
more O
comments O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
this O
shows O
that O
our O
technique O
of O
finding O
fallacious O
comments O
is O
efficient O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
investigate O
if O
the O
label O
comment O
( O
i.e. O
, O
the O
comment O
containing O
mention O
of O
the O
fallacy O
) O
is O
truly O
indicative O
of O
a O
fallacy O
in O
the O
coi O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
this O
can O
be O
useful O
for O
flagging O
the O
label O
comments O
that O
are O
likely O
to O
point O
to O
fallacious O
coi O
, O
therefore O
eliminating O
or O
reducing O
the O
need O
for O
crowdsourcing O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
our O
intuition O
is O
that O
a O
classification O
method O
might O
differentiate O
when O
comments O
are O
accusations O
or O
just O
mention O
of O
fallacies O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
to O
investigate O
this O
, O
we O
used O
the O
fallacy/no-fallacy O
annotation O
as O
classes O
for O
label O
comment O
and O
trained O
a O
binary O
bert O
classifier O
( O
devlin O
et O
al. O
, O
2019 O
) O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
obtained O
an O
f1 O
score O
of O
67.41 O
, O
indicating O
that O
the O
label O
comment O
’ O
s O
content O
is O
not O
sufficiently O
reliable O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
in O
conclusion O
, O
human O
annotators O
are O
still O
needed O
for O
annotating O
the O
true O
class O
of O
the O
coi O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
non O
fallacious O
comments O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
comments O
for O
which O
two O
annotators O
confirmed O
they O
were O
not O
fallacious O
represent O
our O
annotated O
negatives O
( O
1650 O
comments O
) O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
in O
order O
to O
have O
a O
more O
diverse O
set O
of O
negative O
examples O
, O
i.e O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
on O
similar O
and O
different O
topics O
, O
we O
construct O
a O
second O
set O
of O
negative O
examples O
( O
6400 O
comments O
) O
as O
follows O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
retrieve O
all O
the O
users O
that O
wrote O
a O
label O
comment O
to O
a O
coi O
and O
the O
coi O
was O
identified O
as O
fallacious O
in O
the O
annotation O
, O
our O
gold O
users O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
take O
all O
their O
comments O
after O
the O
timestamp O
of O
the O
label O
comment O
that O
do O
not O
mention O
a O
fallacy O
name O
, O
and O
retrieve O
their O
parent O
comment O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
for O
each O
comment O
in O
the O
annotated O
dataset O
, O
we O
select O
one O
sample O
from O
our O
pool O
of O
parent O
comments O
from O
the O
same O
subreddit O
( O
if O
this O
exists O
) O
and O
one O
from O
a O
subreddit O
not O
seen O
in O
the O
annotated O
dataset O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
we O
retrieve O
a O
total O
of O
6400 O
samples O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
these O
comments O
are O
used O
together O
with O
the O
annotated O
dataset O
, O
to O
create O
our O
full O
dataset O
, O
used O
to O
train O
classification O
models O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
the O
intuition O
of O
the O
sampling O
strategy O
is O
that O
, O
the O
gold O
users O
were O
able O
to O
recognize O
true O
fallacies O
at O
least O
one O
time O
, O
so O
they O
should O
spot O
other O
fallacies O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
hence O
, O
if O
they O
reply O
to O
a O
comment O
without O
flagging O
it O
, O
the O
parent O
comment O
is O
likely O
to O
be O
non O
fallacious O
. O

section 6
id pdf2json/2021.acl-long.53.pdf.json
there O
could O
be O
fallacious O
comments O
in O
this O
sample O
; O
however O
, O
we O
consider O
it O
less O
likely O
than O
a O
random O
sample O
. O

section 7
id pdf2json/2021.acl-long.53.pdf.json
tasks O
. O

section 7
id pdf2json/2021.acl-long.53.pdf.json
we O
address O
four O
tasks O
leveraging O
our O
annotated O
dataset O
, O
listed O
in O
the O
order O
of O
increasing O
granularity O
: O
i O
) O
comment-level O
( O
cl O
) O
fallacy O
identification O
( O
binary O
task O
of O
predicting O
if O
a O
comment O
is O
fallacious O
or O
not O
) O
; O
ii O
) O
comment-level O
fallacy O
type O
identification O
( O
multi O
class O
prediction O
of O
the O
type O
of O
fallacy O
, O
with O
non-fallacious O
as O
one O
class O
in O
the O
9 O
classes O
) O
; O
iii O
) O
token-level O
( O
tl O
) O
fallacy O
identification O
( O
binary O
task O
of O
predicting O
if O
tokens O
in O
the O
coi O
belong O
to O
a O
fallacy O
or O
not O
) O
; O
iv O
) O
token-level O
fallacy O
type O
identification O
( O
multi O
class O
prediction O
of O
tokens O
in O
the O
coi O
into O
one O
of O
the O
eight O
fallacy O
classes O
or O
the O
non-fallacy O
class O
) O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
random O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
generate O
predictions O
by O
respecting O
the O
class O
distributions O
in O
the O
training O
set O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
bert O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
fine-tune O
bert O
by O
adding O
a O
linear O
layer O
on O
top O
of O
generated O
contextual O
representations O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
use O
the O
token O
level O
embedding O
in O
token O
detection O
tasks O
and O
[ O
cls O
] O
embedding O
in O
the O
case O
of O
classification O
tasks O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
mgn O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
adopt O
the O
best O
architecture O
reported O
in O
da O
san O
martino O
et O
al O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
( O
2019 O
) O
, O
which O
is O
a O
multigranularity O
network O
that O
uses O
lower O
granularity O
sentence-level O
( O
which O
is O
comment-level O
in O
this O
setting O
) O
representation O
together O
with O
higher O
granularity O
token-level O
representations O
to O
jointly O
train O
the O
network O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
set O
the O
dimension O
of O
lower O
granularity O
embedding O
representation O
equal O
to O
the O
number O
of O
classes O
in O
the O
task O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
jointly O
train O
tasks O
where O
number O
of O
classes O
are O
the O
same O
, O
that O
is O
, O
cl O
& O
tl O
fallacy O
identification O
tasks O
are O
trained O
together O
and O
so O
are O
cl O
& O
tl O
fallacy O
type O
identification O
tasks O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
use O
sigmoid O
activation O
as O
it O
is O
the O
best O
model O
for O
their O
fragment O
( O
token O
) O
level O
classification O
and O
is O
comparable O
for O
the O
sentence O
level O
classifier O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
this O
model O
has O
been O
shown O
to O
give O
good O
results O
for O
predicting O
propaganda O
techniques O
, O
which O
include O
fallacies O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
conversation O
context O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
our O
dataset O
is O
rich O
in O
textual O
information O
related O
to O
the O
coi O
, O
which O
could O
improve O
prediction O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
define O
context O
as O
the O
parent O
comment O
of O
coi O
( O
if O
it O
exists O
, O
the O
string O
“ O
none O
” O
otherwise O
) O
or O
the O
submission O
title O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
this O
is O
provided O
to O
the O
classifier O
in O
the O
format O
: O
[ O
cls O
] O
coi O
tokens O
[ O
sep O
] O
context O
tokens O
[ O
sep O
] O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
the O
context O
tokens O
get O
a O
‘ O
non-fallacy O
’ O
token-level O
label O
at O
the O
training O
time O
, O
but O
during O
the O
validation O
or O
test O
set O
evaluation O
, O
only O
the O
coi O
token O
labels O
are O
used O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
the O
[ O
cls O
] O
token O
is O
used O
for O
cl O
tasks O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
this O
results O
in O
four O
extensions O
of O
the O
previous O
models O
: O
bert-t O
, O
bert-p O
, O
mgn-t O
, O
mgn-p O
, O
where O
t O
stands O
for O
title O
and O
p O
for O
parent O
comment O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
setup O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
use O
pytorch O
( O
paszke O
et O
al. O
, O
2019 O
) O
and O
the O
pre-trained O
bert O
model O
( O
devlin O
et O
al. O
, O
2019 O
; O
wolf O
et O
al. O
, O
2020 O
) O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
fine-tune O
bert O
using O
batch O
size O
8 O
, O
maximum O
sequence O
length O
256 O
for O
coi O
& O
64 O
for O
context O
, O
and O
monitored O
the O
macro-averaged O
f12 O
score O
on O
the O
validation O
set O
, O
as O
identification O
of O
all O
classes O
is O
equally O
important O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
use O
the O
adamw O
optimizer O
, O
with O
a O
learning O
rate O
of O
5e−5 O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
weigh O
the O
cross-entropy O
loss O
function O
according O
to O
the O
class O
distribution O
in O
training O
data O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
split O
the O
dataset O
into O
training O
( O
70 O
% O
) O
, O
validation O
( O
20 O
% O
) O
and O
test O
( O
10 O
% O
) O
sets O
, O
hence O
the O
full O
dataset O
has O
6823 O
, O
1950 O
& O
977 O
and O
annotated O
dataset O
has O
2351 O
, O
671 O
& O
336 O
comments O
respectively O
. O

section 8
id pdf2json/2021.acl-long.53.pdf.json
we O
repeat O
the O
experiments O
with O
5 O
different O
random O
seeds O
for O
the O
network O
intialization O
and O
we O
average O
the O
results O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
in O
table O
4 O
, O
we O
show O
the O
results O
of O
comment O
level O
fallacy O
and O
fallacy O
type O
identification O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
all O
the O
results O
are O
macro O
scores O
( O
precision O
, O
recall O
and O
f1 O
) O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
the O
mgn O
models O
obtain O
the O
best O
results O
, O
most O
often O
when O
context O
is O
added O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
the O
full O
dataset O
provides O
a O
wider O
mix O
of O
topics O
via O
noisy O
negative O
sam- O
2all O
reported O
f1 O
scores O
are O
macro O
f1 O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
ples O
and O
pronounces O
the O
class O
imbalance O
, O
closer O
to O
a O
real O
sample O
of O
reddit O
conversations O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
despite O
this O
, O
the O
classifier O
is O
able O
to O
learn O
across O
all O
four O
tasks O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
table O
5 O
presents O
the O
results O
for O
token O
level O
fallacy O
and O
fallacy O
type O
identification O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
bert O
mod- O
els O
obtain O
better O
results O
for O
the O
multi O
class O
setting O
, O
while O
mgn O
for O
the O
binary O
setting O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
this O
is O
comparable O
with O
the O
results O
reported O
in O
da O
san O
martino O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
( O
2019 O
) O
, O
where O
the O
authors O
observe O
a O
smaller O
improvement O
in O
classification O
for O
the O
token O
level O
prediction O
using O
mgn O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
adding O
more O
context O
in O
the O
form O
of O
title O
or O
parent O
of O
the O
coi O
generally O
led O
to O
improved O
performance O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
while O
the O
results O
are O
slightly O
better O
when O
adding O
the O
title O
, O
the O
differences O
are O
small O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
speculate O
that O
parent O
and O
coi O
provided O
a O
complete O
argument O
, O
making O
fallacy O
detection O
a O
bit O
easier O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
in O
table O
6 O
, O
we O
show O
the O
f1 O
score O
per O
fallacy O
class O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
appeal O
to O
authority O
, O
nature O
, O
and O
tradition O
perform O
well O
( O
f1 O
> O
40 O
% O
) O
across O
all O
four O
tasks O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
hasty O
generalization O
has O
a O
rather O
poor O
performance O
; O
this O
can O
be O
attributed O
to O
this O
fallacy O
’ O
s O
general O
difficulty O
, O
given O
that O
the O
workers O
also O
had O
low O
agreement O
on O
this O
fallacy O
( O
table O
2 O
) O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
observe O
that O
generally O
the O
comment O
level O
prediction O
task O
is O
easier O
than O
the O
token O
level O
prediction O
, O
which O
is O
expected O
due O
to O
the O
granularity O
difference O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
topical O
confounds O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
while O
fallacies O
might O
appear O
more O
frequently O
in O
discussions O
on O
certain O
topics O
, O
a O
fallacy O
detection O
approach O
should O
identify O
the O
underlying O
argument O
structure O
, O
and O
not O
just O
the O
presence O
of O
a O
topic O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
for O
example O
, O
we O
do O
not O
want O
to O
label O
all O
discussions O
about O
nature O
as O
appeal O
to O
nature O
fallacies O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
to O
identify O
if O
the O
classifiers O
are O
sensitive O
to O
topical O
biases O
, O
we O
use O
the O
approach O
presented O
in O
( O
kumar O
et O
al. O
, O
2019 O
) O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
compute O
statistically O
overrepresented O
tokens O
in O
each O
propaganda O
technique O
in O
the O
training O
set O
using O
log-odds O
ratio O
with O
dirichlet O
prior O
( O
monroe O
et O
al. O
, O
2008 O
) O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
present O
the O
top O
10 O
tokens O
per O
fallacy O
in O
table O
7 O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
observe O
that O
for O
appeal O
to O
authority O
, O
nature O
and O
tradition O
, O
the O
tokens O
are O
topically O
cohesive O
, O
as O
they O
revolve O
around O
notions O
of O
authority O
, O
nature O
and O
tradition O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
for O
the O
other O
fallacies O
, O
while O
it O
is O
intuitive O
why O
some O
words O
may O
be O
overrepresented O
, O
there O
is O
no O
clear O
topical O
cohesiveness O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
to O
verify O
that O
our O
classifiers O
learn O
linguistic O
patterns O
and O
not O
topics O
, O
we O
replace O
the O
top O
30 O
tokens O
strongly O
associated O
with O
each O
fallacy O
( O
computed O
from O
the O
training O
set O
) O
with O
a O
special O
token O
in O
the O
test O
set O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
evaluate O
only O
the O
comment O
level O
prediction O
, O
as O
results O
on O
the O
token O
level O
might O
be O
hard O
to O
interpret O
given O
that O
we O
replace O
tokens O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
show O
the O
results O
in O
table O
8 O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
observe O
a O
large O
decrease O
in O
f1 O
score O
( O
more O
than O
10 O
% O
on O
the O
full O
data O
) O
for O
2 O
fallacies O
: O
appeal O
to O
nature O
and O
appeal O
to O
tradition O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
a O
big O
drop O
in O
the O
f1 O
score O
on O
the O
full O
data O
is O
more O
significant O
than O
on O
the O
annotated O
data O
, O
as O
the O
classifier O
would O
have O
seen O
more O
negative O
examples O
containing O
the O
confounds O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
given O
the O
observed O
decrease O
in O
f1 O
score O
for O
these O
fallacies O
, O
an O
important O
future O
direction O
is O
to O
annotate O
more O
discussions O
containing O
the O
overrepresented O
words O
to O
find O
a O
better O
quality O
negative O
set O
, O
i.e. O
, O
non-fallacious O
comments O
on O
the O
same O
topics O
. O

section 9
id pdf2json/2021.acl-long.53.pdf.json
we O
note O
that O
for O
the O
other O
fallacies O
, O
the O
models O
appear O
to O
learn O
more O
complex O
language O
structures O
as O
they O
are O
less O
sensitive O
to O
the O
removal O
of O
the O
overrepresented O
words O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
work O
, O
we O
present O
a O
methodology O
for O
mining O
and O
labeling O
fallacious O
comments O
in O
online O
discussions O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
we O
find O
frequent O
fallacy O
mentions O
on O
reddit O
and O
the O
subreddits O
in O
which O
they O
are O
the O
most O
prevalent O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
we O
create O
a O
large O
corpus O
of O
annotated O
comments O
and O
experiment O
with O
several O
neural O
methods O
for O
classification O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
we O
explore O
methods O
that O
consider O
the O
context O
of O
the O
discussion O
, O
and O
we O
show O
that O
they O
give O
better O
results O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
there O
are O
several O
exciting O
directions O
for O
continuing O
this O
work O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
first O
, O
using O
our O
methodology O
, O
we O
can O
annotate O
more O
comments O
for O
the O
eight O
fallacies O
we O
studied O
in O
this O
paper O
, O
we O
can O
improve O
the O
negative O
example O
set O
or O
explore O
other O
types O
of O
fallacies O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
second O
, O
we O
can O
study O
another O
aspect O
of O
the O
discussion O
, O
the O
speech O
acts O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
according O
to O
the O
pragma O
dialectic O
theory O
, O
an O
argument O
is O
composed O
of O
several O
speech O
acts O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
investigating O
if O
certain O
speech O
acts O
are O
more O
prevalent O
in O
fallacious O
discussions O
might O
lead O
to O
improved O
detection O
of O
fallacies O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
lastly O
, O
in O
the O
pragma O
dialectic O
theory O
of O
argumentation O
, O
fallacies O
are O
violations O
of O
rules O
of O
critical O
discussion O
, O
for O
example O
, O
the O
fallacies O
we O
annotated O
violate O
two O
rules O
, O
as O
described O
in O
section O
3 O
. O

section 10
id pdf2json/2021.acl-long.53.pdf.json
given O
the O
significant O
number O
of O
fallacy O
types O
, O
we O
believe O
that O
a O
hierarchical O
approach O
to O
their O
detection O
could O
prove O
more O
efficient O
: O
identifying O
if O
a O
conversation O
violates O
one O
of O
the O
ten O
rules O
of O
critical O
conversation O
, O
and O
then O
for O
that O
particular O
rule O
identifying O
the O
type O
of O
fallacy O
. O

section 11
id pdf2json/2021.acl-long.53.pdf.json
we O
would O
like O
to O
thank O
the O
acl O
reviewers O
for O
their O
helpful O
feedback O
. O

section 11
id pdf2json/2021.acl-long.53.pdf.json
we O
would O
also O
like O
to O
thank O
meghana O
m. O
bhat O
and O
dravyansh O
sharma O
for O
their O
helpful O
comments O
on O
the O
initial O
draft O
. O

section 11
id pdf2json/2021.acl-long.53.pdf.json
this O
work O
was O
performed O
using O
hpc O
resources O
from O
genciidris O
( O
grant O
2020-ad011011614 O
) O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
appendix O
, O
we O
review O
the O
most O
frequent O
fallacies O
on O
reddit O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
our O
goal O
is O
to O
understand O
how O
easy O
would O
be O
to O
annotate O
such O
fallacies O
, O
by O
looking O
at O
their O
definition O
and O
examples O
of O
how O
well O
reddit O
users O
understand O
those O
definitions O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
let O
a O
, O
b O
, O
c O
, O
d O
be O
examples O
of O
persons O
, O
events O
, O
or O
actions O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
an O
argument O
consists O
of O
a O
standpoint O
s O
( O
known O
also O
as O
a O
claim O
or O
conclusion O
) O
and O
the O
supporting O
evidence O
( O
known O
also O
as O
the O
premises O
) O
for O
the O
standpoint O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
let O
the O
person O
making/supporting O
the O
standpoint O
be O
referred O
to O
as O
the O
protagonist O
and O
the O
person O
disputing O
the O
standpoint O
as O
the O
antagonist O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
when O
referring O
to O
either O
protagonist O
or O
antagonist O
, O
we O
use O
the O
term O
party O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
an O
argumentation O
scheme O
is O
a O
formalization O
of O
the O
relation O
between O
the O
evidence O
presented O
and O
the O
standpoint O
to O
be O
defended O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
types O
of O
schemes O
: O
• O
symptomatic O
argumentation O
: O
what O
is O
stated O
in O
the O
argument O
premise O
is O
an O
expression O
or O
a O
sign O
of O
what O
is O
stated O
in O
the O
conclusion O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
• O
argumentation O
based O
on O
similarities O
: O
analogy O
between O
what O
is O
stated O
in O
the O
argument O
premise O
and O
what O
is O
stated O
in O
the O
conclusion O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
• O
instrumental O
argumentation O
: O
argument O
and O
the O
conclusion O
are O
linked O
by O
a O
very O
broad O
relation O
of O
causality O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
fallacies O
are O
classified O
based O
on O
the O
argumentation O
rules O
they O
break O
out O
of O
the O
ten O
introduced O
in O
( O
van O
eemeren O
and O
grootendorst O
, O
1995 O
) O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
each O
fallacy O
is O
presented O
by O
giving O
all O
its O
possible O
name O
variations O
that O
link O
back O
to O
the O
same O
definition O
, O
its O
definition O
, O
and O
an O
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
1 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
parties O
must O
not O
prevent O
each O
other O
from O
advancing O
standpoints O
or O
casting O
doubt O
on O
standpoints O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
genetic O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
antagonist O
rejects O
a O
claim O
stating O
that O
the O
source O
of O
the O
claim O
should O
not O
be O
trusted O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
unexpressed O
premise O
is O
that O
every O
claim O
coming O
from O
the O
same O
source O
is O
likely O
to O
be O
false O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
fox O
news O
always O
writes O
junk O
news O
, O
i O
am O
sure O
that O
hunter O
biden O
did O
not O
break O
the O
law O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
ad O
hominem O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
antagonist O
rejects O
a O
standpoint O
based O
not O
on O
the O
strength O
of O
the O
argument O
, O
but O
on O
perceived O
flaws O
of O
the O
protagonist O
, O
who O
is O
defending O
it O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
you O
are O
such O
a O
bad O
student O
, O
i O
don O
’ O
t O
believe O
you O
got O
an O
a O
at O
maths O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
association O
/ O
( O
guilt O
by/ O
honor O
by O
) O
association O
/ O
reductio O
ad O
hitlerum O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
antagonist O
is O
disproving O
the O
claim O
of O
the O
protagonist O
by O
stating O
that O
this O
claim O
was O
supported O
by O
a O
bad O
group O
, O
hence O
the O
protagonist O
is O
also O
a O
bad O
person O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
you O
say O
public O
healthcare O
is O
a O
good O
thing O
, O
but O
the O
communists O
say O
the O
same O
thing O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
tu O
quoque O
/ O
appeal O
to O
hypocrisy O
/ O
whataboutism O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
, O
the O
protagonist O
makes O
a O
claim O
s. O
the O
antagonist O
states O
that O
the O
claim O
s O
is O
in O
contradiction O
with O
the O
previous O
actions/attitudes O
of O
the O
protagonist O
( O
showing O
hypocrisy O
) O
, O
thus O
the O
claim O
must O
be O
false O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
to O
the O
statement O
“ O
putin O
is O
a O
killer O
” O
, O
trump O
responded O
, O
“ O
there O
are O
a O
lot O
of O
killers O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
you O
think O
our O
country O
’ O
s O
so O
innocent O
? O
” O
- O
interview O
with O
fox O
news O
’ O
bill O
o O
’ O
reilly O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
poisoning O
the O
well O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
this O
argument O
is O
a O
preemptive O
ad O
hominem O
, O
where O
the O
protagonist O
is O
attacked O
before O
advancing O
a O
standpoint O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
i O
am O
sure O
anna O
will O
say O
she O
gave O
the O
money O
back O
, O
but O
you O
know O
she O
always O
lies O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
2 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
party O
that O
advances O
a O
standpoint O
is O
obliged O
to O
defend O
it O
if O
the O
other O
party O
asks O
him O
to O
do O
so O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
argumentum O
ad O
ignorantiam O
/ O
onus O
probandi O
/ O
burden O
of O
proof O
/ O
argument O
from O
ignorance O
/ O
appeal O
to O
ignorance O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
claims O
that O
a O
standpoint O
must O
be O
true O
because O
there O
is O
no O
or O
not O
sufficient O
evidence O
against O
it O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
as O
pointed O
out O
in O
( O
van O
eemeren O
and O
grootendorst O
, O
1995 O
) O
, O
there O
can O
be O
two O
situations O
: O
i O
) O
the O
protagonist O
is O
challenging O
the O
antagonist O
to O
prove O
that O
their O
standpoint O
is O
wrong O
( O
rule O
2 O
) O
or O
ii O
) O
the O
protagonist O
is O
stating O
that O
because O
the O
negation O
of O
their O
standpoint O
can O
not O
be O
proven O
true O
, O
then O
their O
standpoint O
is O
true O
( O
rule O
9 O
) O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
i O
have O
heard O
that O
vaccines O
are O
bad O
, O
prove O
me O
that O
they O
are O
good O
for O
your O
health O
! O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
3 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
party O
’ O
s O
attack O
on O
a O
standpoint O
must O
relate O
to O
the O
standpoint O
that O
has O
indeed O
been O
advanced O
by O
the O
other O
party O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
straw O
man O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
antagonist O
is O
: O
i O
) O
distorting O
the O
standpoint O
advanced O
by O
the O
protagonist O
( O
rule O
3 O
) O
or O
ii O
) O
attributing O
a O
false O
standpoint O
( O
rule O
5 O
) O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
protagonist O
: O
i O
believe O
that O
women O
should O
have O
the O
right O
to O
abortion O
in O
the O
first O
term O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
antagonist O
: O
so O
you O
’ O
re O
okay O
with O
killing O
babies O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
nirvana O
/ O
perfect O
solution O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
, O
the O
protagonist O
is O
advancing O
the O
claim O
that O
an O
action O
a O
is O
desirable O
as O
it O
will O
achieve O
a O
positive O
result O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
antagonist O
rebuts O
this O
claim O
by O
stating O
that O
a O
will O
not O
achieve O
the O
perfect O
outcome O
, O
even O
if O
the O
perfect O
outcome O
is O
not O
specified O
in O
the O
claim O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
antagonist O
modifies O
the O
claim O
, O
by O
stating O
“ O
action O
a O
will O
achieve O
the O
perfect O
outcome O
” O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
protagonist O
: O
using O
less O
plastic O
is O
good O
for O
the O
planet O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
antagonist O
: O
we O
need O
to O
stop O
using O
plastic O
altogether O
to O
make O
any O
progress O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
moving O
the O
goalposts O
/ O
raising O
the O
bar O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
this O
fallacy O
is O
similar O
to O
the O
nirvana O
fallacy O
, O
however O
, O
the O
antagonist O
is O
not O
aiming O
for O
the O
perfect O
outcome O
, O
but O
for O
better O
outcome O
than O
the O
one O
initially O
described O
by O
the O
protagonist O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
we O
should O
stop O
killing O
animals O
for O
food O
, O
they O
feel O
pain O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
what O
about O
plants O
, O
how O
do O
you O
know O
if O
they O
don O
’ O
t O
feel O
? O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
4 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
party O
may O
defend O
his O
standpoint O
only O
by O
advancing O
argumentation O
relating O
to O
that O
standpoint O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
ignoratio O
elenchi O
/ O
irrelevant O
conclusion O
/ O
missing O
the O
point O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
, O
the O
protagonist O
uses O
premises O
that O
are O
irrelevant O
to O
the O
claim O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
his O
policies O
are O
not O
good O
enough O
, O
but O
my O
cousin O
says O
he O
talks O
well O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
5 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
party O
may O
not O
falsely O
present O
something O
as O
a O
premise O
that O
has O
been O
left O
unexpressed O
by O
the O
other O
party O
or O
deny O
a O
premise O
that O
they O
himself O
have O
left O
implicit O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
straw O
man O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
already O
defined O
for O
rule O
3 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
6 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
party O
may O
not O
falsely O
present O
a O
premise O
as O
an O
accepted O
starting O
point O
nor O
deny O
a O
premise O
representing O
an O
accepted O
starting O
point O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
circulus O
in O
demonstrando O
/ O
petitio O
principii O
/ O
begging O
the O
question O
/ O
circular O
reasoning O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
, O
the O
evidence O
assumes O
that O
the O
claim O
is O
true O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
everyone O
likes O
me O
because O
i O
am O
the O
most O
liked O
politician O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
plurium O
interrogationum O
/ O
fallacy O
of O
many O
questions O
/ O
fallacy O
of O
presuppositions O
/ O
complex O
question O
/ O
loaded O
question O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
standpoint O
brought O
forward O
by O
the O
protagonist O
is O
implying O
that O
at O
least O
another O
standpoint O
should O
be O
true O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
annie O
is O
a O
better O
person O
than O
that O
horrible O
guy O
john O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
false O
dilemma O
/ O
false O
dichotomy O
/ O
bifurcation O
/ O
black-or-white O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
pushes O
the O
standpoint O
s O
that O
only O
the O
event O
or O
action O
a O
should O
be O
considered O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
first O
premise O
is O
that O
only O
two O
events O
a O
and O
b O
are O
possible O
, O
when O
there O
is O
at O
least O
a O
third O
event O
c O
possible O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
second O
premise O
is O
that O
one O
of O
the O
events O
is O
bad O
, O
for O
example O
b O
, O
thus O
only O
event O
a O
should O
be O
considered O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
you O
must O
wear O
a O
mask O
each O
time O
you O
go O
out O
, O
otherwise O
you O
will O
die O
of O
covid-19 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
7 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
party O
may O
not O
regard O
a O
standpoint O
as O
conclusively O
defended O
if O
the O
defense O
does O
not O
take O
place O
by O
means O
of O
an O
appropriate O
argumentation O
scheme O
that O
is O
correctly O
applied O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
relative O
privation O
/ O
appeal O
to O
worse O
problems O
/ O
not O
as O
bad O
as O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
states O
that O
there O
exists O
a O
that O
is O
worse O
than O
b O
, O
therefore O
b O
is O
justified O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
applied O
argumentation O
scheme O
is O
argumentation O
based O
on O
similarity O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
and O
b O
are O
both O
bad O
actions O
, O
events O
or O
people O
, O
but O
instead O
of O
stressing O
the O
similarity O
, O
the O
protagonist O
tries O
to O
stress O
how O
a O
is O
bad O
, O
thus O
making O
b O
look O
better O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
you O
shouldn O
’ O
t O
complain O
if O
the O
food O
is O
stale O
as O
there O
are O
millions O
of O
people O
starving O
who O
would O
be O
grateful O
for O
any O
meal O
they O
get O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
gambler O
’ O
s O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
defends O
a O
probabilistic O
claim O
such O
as O
“ O
an O
event O
a O
is O
very O
likely O
to O
occur O
” O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
mistake O
in O
argumentation O
appears O
if O
the O
evidence O
is O
based O
on O
falsely O
supposing O
that O
event O
a O
and O
event O
b O
are O
dependent O
, O
so O
if O
event O
a O
occurs O
, O
the O
probability O
of O
b O
occurring O
changes O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
this O
argument O
violates O
rule O
7 O
as O
is O
it O
based O
on O
a O
faulty O
application O
of O
instrumental O
argumentation O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
my O
coin O
landed O
twice O
in O
a O
row O
on O
heads O
, O
hence O
it O
should O
land O
next O
on O
tails O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
slippery O
slope O
/ O
thin O
edge O
of O
the O
wedge O
/ O
camel O
’ O
s O
nose O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
this O
fallacy O
consists O
in O
claiming O
that O
a O
small O
event O
a O
has O
a O
big O
unwanted O
consequence O
c. O
there O
is O
at O
least O
one O
more O
event O
b O
in O
the O
chain O
of O
causality O
( O
a O
will O
cause O
b O
, O
b O
will O
cause O
c O
) O
, O
hence O
the O
slippery O
slope O
name O
of O
the O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
this O
argument O
violates O
rule O
7 O
, O
as O
the O
instrumental O
argumentation O
does O
not O
hold O
given O
that O
there O
is O
no O
clear O
causality O
chain O
between O
a O
and O
c. O
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
if O
you O
break O
your O
diet O
and O
have O
one O
cookie O
tonight O
, O
you O
will O
just O
want O
to O
eat O
10 O
cookies O
tomorrow O
and O
20 O
the O
day O
after O
, O
and O
before O
you O
know O
it O
, O
you O
will O
have O
gained O
back O
the O
15 O
pounds O
you O
lost O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
no O
true O
scotsman O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
tries O
to O
make O
a O
generalization O
, O
which O
is O
a O
valid O
instrumental O
argumentation O
scheme O
: O
when O
a O
predicate O
p O
is O
true O
for O
an O
arbitrary O
member O
of O
a O
group O
, O
then O
it O
is O
true O
for O
any O
member O
of O
the O
group O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
however O
, O
it O
changes O
the O
definition O
of O
the O
predicate O
p O
, O
so O
therefore O
the O
argument O
violates O
rule O
7 O
, O
as O
the O
instrumental O
argumentation O
does O
not O
hold O
anymore O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
“ O
no O
scotsman O
puts O
sugar O
on O
his O
porridge O
” O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
post O
hoc O
ergo O
propter O
hoc O
/ O
temporal O
sequence O
implies O
causation O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
states O
that O
because O
event O
a O
occurred O
first O
and O
event O
b O
occurred O
second O
, O
a O
caused O
b O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
this O
argument O
violates O
rule O
7 O
, O
as O
it O
tries O
to O
present O
an O
instrumental O
argumentation O
, O
without O
providing O
evidence O
that O
shows O
how O
event O
a O
and O
b O
are O
linked O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
my O
boyfriend O
left O
me O
after O
he O
saw O
you O
, O
it O
must O
have O
been O
something O
you O
said O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
argumentum O
ad O
verecundiam O
/ O
appeal O
to O
authority O
/ O
argument O
from O
authority O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
, O
because O
the O
claim O
is O
supported O
by O
the O
opinion O
of O
a O
person O
with O
authority O
, O
then O
the O
claim O
is O
true O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
7 O
is O
violated O
because O
the O
symptomatic O
argumentation O
is O
incorrectly O
used O
: O
while O
authorities O
can O
make O
true O
claims O
, O
we O
can O
not O
consider O
them O
true O
as O
such O
if O
they O
are O
not O
backed O
up O
by O
evidence O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
being O
vegan O
makes O
no O
sense O
because O
my O
father O
said O
so O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
argumentum O
ad O
populum O
/ O
appeal O
to O
widespread O
belief O
/ O
bandwagon O
argument O
/ O
appeal O
to O
the O
majority O
/ O
appeal O
to O
the O
people O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
claim O
is O
presented O
as O
true O
because O
many O
people O
believe O
it O
to O
be O
true O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
7 O
is O
violated O
because O
the O
symptomatic O
argumentation O
is O
not O
used O
correctly O
: O
while O
people O
do O
believe O
many O
things O
that O
are O
true O
, O
belief O
is O
not O
sufficient O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
being O
vegan O
makes O
no O
sense O
because O
so O
many O
of O
us O
are O
meat O
eaters O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
appeal O
to O
nature O
/ O
naturalistic O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
states O
that O
an O
action O
a O
is O
justified O
or O
good O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
premise O
is O
that O
action O
a O
is O
good O
because O
it O
is O
natural O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
argument O
violates O
rule O
7 O
as O
it O
uses O
the O
symptomatic O
argumentation O
in O
a O
wrong O
way O
: O
some O
actions O
that O
are O
natural O
are O
good O
, O
however O
we O
can O
not O
conclude O
they O
are O
good O
because O
they O
are O
natural O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
being O
vegan O
makes O
no O
sense O
as O
our O
body O
is O
designed O
for O
eating O
meat O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
argumentum O
ad O
antiquitatem O
/ O
appeal O
to O
tradition O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
states O
that O
an O
action O
a O
is O
justified O
or O
good O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
premise O
is O
that O
it O
has O
always O
been O
considered O
as O
such O
in O
the O
past O
, O
but O
no O
further O
justification O
is O
given O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
unexpressed O
premise O
of O
the O
argument O
is O
that O
everything O
that O
is O
done O
since O
a O
long O
time O
is O
good O
or O
justified O
as O
it O
has O
withstood O
criticism O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
however O
, O
this O
premise O
is O
also O
an O
opinion O
and O
not O
a O
fact O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
being O
vegan O
makes O
no O
sense O
as O
our O
ancestors O
have O
been O
meat O
eaters O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
divine O
/ O
argument O
from O
incredulity O
/ O
appeal O
to O
common O
sense O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
standpoint O
appears O
incredible O
and O
not O
common O
sense O
from O
the O
perspective O
of O
the O
antagonist O
, O
and O
such O
it O
can O
be O
dismissed O
as O
false O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
addition O
, O
everything O
that O
appears O
as O
common O
sense O
should O
be O
true O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
argument O
uses O
the O
symptomatic O
argumentation O
in O
a O
wrong O
way O
: O
some O
actions O
that O
are O
incredible O
are O
false O
, O
however O
we O
can O
not O
conclude O
that O
all O
incredible O
actions O
are O
false O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
as O
disinfectant O
is O
efficient O
against O
covid-19 O
, O
it O
should O
be O
effective O
also O
if O
we O
drink O
it O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
hasty O
generalization O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
, O
the O
claim O
is O
supported O
by O
insufficient O
evidence O
through O
inductive O
generalization O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
more O
precisely O
, O
we O
know O
that O
predicate O
p O
is O
true O
for O
a O
sample O
of O
a O
population O
and O
we O
suppose O
it O
is O
true O
for O
the O
entire O
population O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
however O
, O
in O
this O
case O
the O
sample O
is O
either O
too O
small O
or O
it O
is O
not O
representative O
of O
the O
population O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
first O
two O
weeks O
of O
september O
were O
sunny O
, O
it O
means O
the O
rest O
of O
the O
month O
will O
be O
the O
same O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
volvo O
/ O
anecdotal O
/ O
proof O
by O
selected O
instances O
/ O
person O
who O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
this O
fallacy O
is O
very O
similar O
to O
the O
hasty O
generalization O
, O
as O
a O
claim O
is O
not O
supported O
by O
sufficient O
evidence O
, O
but O
only O
a O
small O
set O
of O
examples O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
difference O
between O
the O
two O
fallacies O
is O
that O
the O
examples O
in O
anecdotal O
fallacy O
are O
usually O
personal O
examples O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
two O
years O
ago O
when O
i O
visited O
paris O
in O
september O
it O
was O
so O
nice O
and O
sunny O
, O
i O
am O
sure O
this O
year O
it O
will O
be O
the O
same O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
cherry O
picking O
/ O
suppressed O
evidence O
/ O
incomplete O
evidence O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
, O
a O
claim O
is O
backed O
by O
incomplete O
evidence O
, O
that O
is O
only O
a O
subset O
of O
facts O
that O
support O
the O
claim O
, O
while O
a O
large O
body O
of O
facts O
is O
overlooked O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
my O
son O
is O
very O
smart O
, O
look O
he O
got O
an O
a O
at O
english O
! O

section 12
id pdf2json/2021.acl-long.53.pdf.json
but O
what O
about O
all O
his O
bad O
grades O
before O
that O
? O

section 12
id pdf2json/2021.acl-long.53.pdf.json
accident O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
premises O
brought O
forward O
are O
generalizations O
that O
do O
not O
apply O
to O
the O
specific O
instances O
mentioned O
in O
the O
claim O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
people O
bleed O
when O
they O
are O
ill O
, O
it O
means O
that O
your O
period O
is O
a O
sign O
of O
an O
illness O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
fallacy O
of O
composition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
claim O
is O
that O
a O
property O
p O
is O
true O
of O
a O
finite O
set O
s O
, O
also O
called O
in O
literature O
a O
whole O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
evidence O
is O
that O
the O
property O
p O
is O
true O
for O
an O
element O
e O
that O
is O
part O
of O
s. O
the O
unexpressed O
premise O
is O
that O
all O
the O
elements O
of O
the O
set O
are O
similar O
, O
which O
might O
be O
false O
and O
needs O
evidence O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
while O
this O
is O
similar O
to O
hasty O
generalization O
, O
in O
the O
latter O
there O
is O
no O
notion O
of O
a O
whole O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
7 O
is O
violated O
, O
as O
the O
instrumental O
argumentation O
does O
not O
hold O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
because O
the O
leaves O
of O
a O
tree O
are O
green O
, O
the O
tree O
is O
also O
green O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
fallacy O
of O
division O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
fallacies O
of O
composition O
and O
division O
are O
the O
converse O
of O
one O
another O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
claim O
is O
that O
something O
is O
true O
of O
an O
element O
e O
( O
let O
this O
be O
a O
property O
p O
) O
, O
which O
belongs O
to O
a O
set O
s O
, O
called O
a O
whole O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
evidence O
is O
that O
p O
is O
true O
for O
the O
set O
s. O
the O
unexpressed O
premise O
is O
that O
all O
the O
elements O
of O
the O
set O
are O
similar O
, O
which O
might O
be O
false O
and O
needs O
evidence O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
if O
this O
tree O
is O
100 O
years O
old O
, O
then O
each O
branch O
is O
100 O
years O
old O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
argumentum O
ad O
temperantiam O
/ O
argument O
to O
moderation O
/ O
false O
compromise O
/ O
middle O
ground O
fallacy O
/ O
fallacy O
of O
the O
mean O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
let O
s1 O
and O
s2 O
be O
two O
standpoints O
that O
represent O
very O
different O
opinions O
on O
the O
same O
topic O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
claim O
is O
that O
a O
third O
statement O
, O
s3 O
, O
which O
is O
the O
middle O
point O
between O
the O
two O
, O
is O
true O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
s1 O
: O
we O
are O
having O
financial O
issues O
, O
we O
should O
fire O
all O
new O
hires O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
s2 O
: O
no O
, O
we O
shouldn O
’ O
t O
fire O
any O
of O
the O
new O
people O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
s3 O
: O
we O
should O
fire O
half O
of O
them O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
continuum O
/ O
sorites O
/ O
line-drawing O
/ O
bald O
man O
fallacy O
/ O
fallacy O
of O
the O
beard O
/ O
fallacy O
of O
the O
heap O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
let O
s1 O
and O
s2 O
be O
two O
extreme O
standpoints O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
because O
there O
isn O
’ O
t O
a O
clear O
point O
where O
we O
pass O
from O
s1 O
to O
s2 O
, O
it O
is O
supposed O
that O
there O
is O
no O
difference O
between O
them O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
once O
you O
drink O
a O
sip O
of O
alcohol O
you O
will O
become O
irresponsible O
and O
put O
your O
life O
in O
danger O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
8 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
his O
argumentation O
a O
party O
may O
only O
use O
arguments O
that O
are O
logically O
valid O
or O
capable O
of O
being O
validated O
by O
making O
explicit O
one O
or O
more O
unexpressed O
premises O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
special O
pleading O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
the O
protagonist O
applies O
rules O
or O
principles O
to O
other O
people O
or O
situations O
, O
but O
says O
this O
does O
not O
apply O
to O
the O
current O
situation O
without O
providing O
a O
justification O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
this O
is O
an O
application O
of O
a O
double O
standard O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
while O
it O
is O
true O
he O
is O
only O
a O
teenager O
, O
i O
am O
sure O
he O
wasn O
’ O
t O
raped O
, O
he O
wanted O
to O
have O
intercourse O
with O
that O
woman O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
9 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
failed O
defense O
of O
a O
standpoint O
must O
result O
in O
the O
party O
that O
put O
forward O
the O
standpoint O
retracting O
it O
and O
a O
conclusive O
defense O
in O
the O
other O
party O
retracting O
his O
doubt O
about O
the O
standpoint O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
argumentum O
ad O
ignorantiam O
/ O
onus O
probandi O
/ O
burden O
of O
proof O
/ O
argument O
from O
ignorance O
/ O
appeal O
to O
ignorance O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
already O
defined O
for O
rule O
2 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
rule O
10 O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
a O
party O
must O
not O
use O
formulations O
that O
are O
insufficiently O
clear O
or O
confusingly O
ambiguous O
and O
he O
must O
interpret O
the O
other O
party O
’ O
s O
formulations O
as O
carefully O
and O
accurately O
as O
possible O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
equivocation O
fallacy O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
definition O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
in O
this O
argument O
a O
word O
or O
expression O
is O
used O
with O
multiple O
meanings O
, O
thus O
trying O
to O
capitalize O
on O
the O
confusion O
to O
approve O
or O
disprove O
a O
claim O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
example O
. O

section 12
id pdf2json/2021.acl-long.53.pdf.json
if O
americans O
are O
free O
, O
why O
do O
they O
have O
prisons O
? O

section 12
id pdf2json/2021.acl-long.53.pdf.json
- O
here O
freedom O
has O
two O
meanings O
: O
the O
right O
to O
speak O
and O
act O
as O
one O
wants O
and O
the O
state O
of O
being O
imprisoned O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
worker O
compensation O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
before O
assigning O
the O
tasks O
to O
crowd O
workers O
, O
the O
authors O
did O
several O
rounds O
of O
annotations O
themselves O
to O
determine O
the O
average O
time O
it O
takes O
to O
finish O
one O
hit O
( O
10 O
fallacies O
) O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
on O
an O
average O
it O
took O
about O
20 O
minutes O
to O
annotate O
10 O
fallacies O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
so O
we O
paid O
workers O
$ O
5 O
per O
hit O
, O
averaging O
to O
$ O
15/hour O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
we O
still O
provided O
them O
1 O
hour O
, O
in O
order O
to O
not O
put O
them O
under O
undue O
stress O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
also O
, O
we O
did O
not O
request O
any O
personal O
information O
or O
opinions O
from O
the O
workers O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
banned O
and O
deleted O
content O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
subreddits O
are O
closely O
monitored O
by O
the O
moderators O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
users O
have O
to O
comply O
with O
reddit O
’ O
s O
content O
policy O
, O
a O
lists O
a O
set O
of O
rules O
enforced O
by O
the O
admins O
on O
every O
community O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
any O
rule O
violation O
( O
like O
bullying O
, O
use O
of O
hate O
speech O
, O
attacking O
marginalized O
or O
vulnerable O
groups O
, O
etc O
. O
) O

section 13
id pdf2json/2021.acl-long.53.pdf.json
leads O
to O
the O
removal O
of O
posts/comments O
and O
, O
in O
some O
cases O
, O
banning O
a O
subreddit O
if O
the O
moderators O
fail O
to O
comply O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
the O
removal O
of O
such O
comments O
and O
posts O
ensures O
that O
we O
do O
not O
have O
any O
banned O
or O
deleted O
content O
in O
our O
dataset O
either O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
privacy O
of O
authors O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
none O
of O
our O
proposed O
methods O
does O
any O
profiling O
of O
reddit O
users O
who O
made O
comments O
that O
appeared O
in O
our O
dataset O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
no O
identification O
of O
post/comment O
or O
their O
authors O
appears O
in O
our O
final O
dataset O
or O
input O
to O
the O
models O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
data O
quality O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
we O
describe O
our O
data O
collection O
process O
extensively O
in O
section O
4 O
. O

section 13
id pdf2json/2021.acl-long.53.pdf.json
all O
the O
data O
samples O
appearing O
are O
annotated O
by O
two O
workers O
and O
resolved O
by O
authors O
if O
there O
is O
a O
disagreement O
between O
the O
workers O
. O

section TITLE
id pdf2json/2021.acl-long.557.pdf.json
transition-based O
bubble O
parsing O
: O
improvements O
on O
coordination O
structure O
prediction O

section ABSTRACT
id pdf2json/2021.acl-long.557.pdf.json
we O
propose O
a O
transition-based O
bubble O
parser O
to O
perform O
coordination O
structure O
identification O
and O
dependency-based O
syntactic O
analysis O
simultaneously O
. O

section ABSTRACT
id pdf2json/2021.acl-long.557.pdf.json
bubble O
representations O
were O
proposed O
in O
the O
formal O
linguistics O
literature O
decades O
ago O
; O
they O
enhance O
dependency O
trees O
by O
encoding O
coordination O
boundaries O
and O
internal O
relationships O
within O
coordination O
structures O
explicitly O
. O

section ABSTRACT
id pdf2json/2021.acl-long.557.pdf.json
in O
this O
paper O
, O
we O
introduce O
a O
transition O
system O
and O
neural O
models O
for O
parsing O
these O
bubble-enhanced O
structures O
. O

section ABSTRACT
id pdf2json/2021.acl-long.557.pdf.json
experimental O
results O
on O
the O
english O
penn O
treebank O
and O
the O
english O
genia O
corpus O
show O
that O
our O
parsers O
beat O
previous O
state-of-the-art O
approaches O
on O
the O
task O
of O
coordination O
structure O
prediction O
, O
especially O
for O
the O
subset O
of O
sentences O
with O
complex O
coordination O
structures.1 O

section 0
id pdf2json/2021.acl-long.557.pdf.json
proceedings O
of O
the O
59th O
annual O
meeting O
of O
the O
association O
for O
computational O
linguistics O
and O
the O
11th O
international O
joint O
conference O
on O
natural O
language O
processing O
, O
pages O
7167–7182 O
august O
1–6 O
, O
2021 O
. O

section 0
id pdf2json/2021.acl-long.557.pdf.json
©2021 O
association O
for O
computational O
linguistics O
7167 O

section 1
id pdf2json/2021.acl-long.557.pdf.json
coordination O
structures O
are O
prevalent O
in O
treebank O
data O
( O
ficler O
and O
goldberg O
, O
2016a O
) O
, O
especially O
in O
long O
sentences O
( O
kurohashi O
and O
nagao O
, O
1994 O
) O
, O
and O
they O
are O
among O
the O
most O
challenging O
constructions O
for O
nlp O
models O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
difficulties O
in O
correctly O
identifying O
coordination O
structures O
have O
consistently O
contributed O
to O
a O
significant O
portion O
of O
errors O
in O
stateof-the-art O
parsers O
( O
collins O
, O
2003 O
; O
goldberg O
and O
elhadad O
, O
2010 O
; O
ficler O
and O
goldberg O
, O
2017 O
) O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
these O
errors O
can O
further O
propagate O
to O
downstream O
nlp O
modules O
and O
applications O
, O
and O
limit O
their O
performance O
and O
utility O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
for O
example O
, O
saha O
et O
al O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
( O
2017 O
) O
report O
that O
missing O
conjuncts O
account O
for O
two-thirds O
of O
the O
errors O
in O
recall O
made O
by O
their O
open O
information O
extraction O
system O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
coordination O
constructions O
are O
particularly O
challenging O
for O
the O
widely-adopted O
dependency-based O
paradigm O
of O
syntactic O
analysis O
, O
since O
the O
asymmetric O
definition O
of O
head-modifier O
dependency O
relations O
is O
not O
directly O
compatible O
with O
the O
symmetric O
1code O
at O
github.com/tzshi/bubble-parser-acl21 O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
bubble O
tree O
: O
i O
prefer O
hot O
coffee O
or O
tea O
and O
a O
bun O
conj O
cc O
conj O
amod O
conj O
cc O
conjdetnsubj O
obj O
ud O
tree O
: O
i O
prefer O
hot O
coffee O
or O
tea O
and O
a O
bun O
nsubj O
obj O
amod O
conj O
cc O
conj O
cc O
det O
figure O
1 O
: O
bubble O
tree O
and O
( O
basic O
) O
ud O
tree O
for O
the O
same O
example O
sentence O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
( O
for O
clarity O
, O
we O
omit O
punctuation O
and O
single-word O
bubble O
boundaries O
. O
) O

section 1
id pdf2json/2021.acl-long.557.pdf.json
bubbles O
explicitly O
encode O
the O
scope O
of O
the O
shared O
modifier O
hot O
with O
respect O
to O
the O
nested O
coordination O
, O
whereas O
the O
ud O
tree O
gives O
both O
tea O
and O
bun O
identical O
relationships O
to O
hot O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
nature O
of O
the O
relations O
among O
the O
participating O
conjuncts O
and O
coordinators.2 O
existing O
treebanks O
usually O
resort O
to O
introducing O
special O
relations O
to O
represent O
coordination O
structures O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
but O
, O
there O
remain O
theoretical O
and O
empirical O
challenges O
regarding O
how O
to O
most O
effectively O
encode O
information O
like O
modifier O
sharing O
relations O
while O
still O
permitting O
accurate O
statistical O
syntactic O
analysis O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
in O
this O
paper O
, O
we O
explore O
kahane O
’ O
s O
( O
1997 O
) O
alternative O
solution O
: O
extend O
the O
dependency-tree O
representation O
by O
introducing O
bubble O
structures O
to O
explicitly O
encode O
coordination O
boundaries O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
the O
coheads O
within O
a O
bubble O
enjoy O
a O
symmetric O
relationship O
, O
as O
befits O
a O
model O
of O
conjunction O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
further O
, O
bubble O
trees O
support O
representation O
of O
nested O
coordination O
, O
with O
the O
scope O
of O
shared O
modifiers O
identifiable O
by O
the O
attachment O
sites O
of O
bubble O
arcs O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
figure O
1 O
compares O
a O
bubble O
tree O
against O
a O
universal O
dependencies O
( O
ud O
; O
nivre O
et O
al. O
, O
2016 O
, O
2020 O
) O
tree O
for O
the O
same O
sentence O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
yet O
, O
despite O
theses O
advantages O
, O
implementation O
2rambow O
( O
2010 O
) O
comments O
on O
other O
divergences O
between O
syntactic O
representation O
and O
syntactic O
phenomena O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
of O
the O
formalism O
was O
not O
broadly O
pursued O
, O
for O
reasons O
unknown O
to O
us O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
given O
its O
appealing O
and O
intuitive O
treatment O
of O
coordination O
phenomena O
, O
we O
revisit O
the O
bubble O
tree O
formalism O
, O
introducing O
and O
implementing O
a O
transition-based O
solution O
for O
parsing O
bubble O
trees O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
our O
transition O
system O
, O
bubblehybrid O
, O
extends O
the O
arc-hybrid O
transition O
system O
( O
kuhlmann O
et O
al. O
, O
2011 O
) O
with O
three O
bubble-specific O
transitions O
, O
each O
corresponding O
to O
opening O
, O
expanding O
, O
and O
closing O
bubbles O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
we O
show O
that O
our O
transition O
system O
is O
both O
sound O
and O
complete O
with O
respect O
to O
projective O
bubble O
trees O
( O
defined O
in O
§ O
2.2 O
) O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
experiments O
on O
the O
english O
penn O
treebank O
( O
ptb O
; O
marcus O
et O
al. O
, O
1993 O
) O
extended O
with O
coordination O
annotation O
( O
ficler O
and O
goldberg O
, O
2016a O
) O
and O
the O
english O
genia O
treebank O
( O
kim O
et O
al. O
, O
2003 O
) O
demonstrate O
the O
effectiveness O
of O
our O
proposed O
transition-based O
bubble O
parsing O
on O
the O
task O
of O
coordination O
structure O
prediction O
. O

section 1
id pdf2json/2021.acl-long.557.pdf.json
our O
method O
achieves O
state-of-the-art O
performance O
on O
both O
datasets O
and O
improves O
accuracy O
on O
the O
subset O
of O
sentences O
exhibiting O
complex O
coordination O
structures O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
a O
dependency O
tree O
encodes O
syntactic O
relations O
via O
directed O
bilexical O
dependency O
edges O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
these O
are O
natural O
for O
representing O
argument O
and O
adjunct O
modification O
, O
but O
popel O
et O
al O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
( O
2013 O
) O
point O
out O
that O
“ O
dependency O
representation O
is O
at O
a O
loss O
when O
it O
comes O
to O
representing O
paratactic O
linguistic O
phenomena O
such O
as O
coordination O
, O
whose O
nature O
is O
symmetric O
( O
two O
or O
more O
conjuncts O
play O
the O
same O
role O
) O
, O
as O
opposed O
to O
the O
head-modifier O
asymmetry O
of O
dependencies O
” O
( O
pg O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
517 O
) O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
if O
one O
nonetheless O
persists O
in O
using O
dependency O
relations O
to O
annotate O
all O
syntactic O
structures O
, O
as O
is O
common O
practice O
in O
most O
dependency O
treebanks O
( O
hajič O
et O
al. O
, O
2001 O
; O
nivre O
et O
al. O
, O
2016 O
, O
inter O
alia O
) O
, O
then O
one O
must O
introduce O
special O
relations O
to O
represent O
coordination O
structures O
and O
promote O
one O
element O
from O
each O
coordinated O
phrase O
to O
become O
the O
“ O
representational O
head O
” O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
one O
choice O
is O
to O
specify O
one O
of O
the O
conjuncts O
as O
the O
“ O
head O
” O
( O
mel O
’ O
čuk O
, O
1988 O
, O
2003 O
; O
järvinen O
and O
tapanainen O
, O
1998 O
; O
lombardo O
and O
lesmo O
, O
1998 O
) O
( O
e.g. O
, O
in O
figure O
1 O
, O
the O
visually O
asymmetric O
“ O
conj O
” O
relation O
between O
“ O
coffee O
” O
and O
“ O
tea O
” O
is O
overloaded O
to O
admit O
a O
symmetric O
relationship O
) O
, O
but O
it O
is O
then O
non-trivial O
to O
distinguish O
shared O
modifiers O
from O
private O
ones O
( O
e.g. O
, O
in O
the O
ud O
tree O
at O
the O
bottom O
of O
figure O
1 O
, O
it O
is O
difficult O
to O
tell O
that O
“ O
hot O
” O
is O
private O
to O
“ O
coffee O
” O
and O
“ O
tea O
” O
, O
which O
share O
it O
, O
but O
“ O
hot O
” O
does O
not O
modify O
“ O
bun O
” O
) O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
another O
choice O
is O
let O
one O
of O
the O
coordinators O
dominate O
the O
phrase O
( O
hajič O
et O
al. O
, O
2001 O
, O
2020 O
) O
, O
but O
the O
coordinator O
does O
not O
directly O
capture O
the O
syntactic O
category O
of O
the O
coordinated O
phrase O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
decisions O
on O
which O
of O
these O
dependency-based O
fixes O
is O
more O
workable O
are O
further O
complicated O
by O
the O
interaction O
between O
representation O
styles O
and O
their O
learnability O
in O
statistical O
parsing O
( O
nilsson O
et O
al. O
, O
2006 O
; O
johansson O
and O
nugues O
, O
2007 O
; O
rehbein O
et O
al. O
, O
2017 O
) O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
enhanced O
ud O
a O
tactic O
used O
by O
many O
recent O
releases O
of O
ud O
treebanks O
is O
to O
introduce O
certain O
extra O
edges O
and O
non-lexical O
nodes O
( O
schuster O
and O
manning O
, O
2016 O
; O
nivre O
et O
al. O
, O
2018 O
; O
bouma O
et O
al. O
, O
2020 O
) O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
while O
some O
of O
the O
theoretical O
issues O
still O
persist O
in O
this O
approach O
with O
respect O
to O
capturing O
the O
symmetric O
nature O
of O
relations O
between O
conjuncts O
, O
this O
solution O
better O
represents O
shared O
modifiers O
in O
coordinations O
, O
and O
so O
is O
a O
promising O
direction O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
in O
work O
concurrent O
with O
our O
own O
, O
grünewald O
et O
al O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
( O
2021 O
) O
manually O
correct O
the O
coordination O
structure O
annotations O
in O
an O
english O
treebank O
under O
the O
enhanced O
ud O
representation O
format O
. O

section 3
id pdf2json/2021.acl-long.557.pdf.json
we O
leave O
it O
to O
future O
work O
to O
explore O
the O
feasibility O
of O
automatic O
conversion O
of O
coordination O
structure O
representations O
between O
enhanced O
ud O
trees O
and O
bubble O
trees O
, O
which O
we O
discuss O
next O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
an O
alternative O
solution O
to O
the O
coordination-independency-trees O
dilemma O
is O
to O
permit O
certain O
restricted O
phrase-inspired O
constructs O
for O
such O
structures O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
indeed O
, O
tesnière O
’ O
s O
( O
1959 O
) O
seminal O
work O
on O
dependency O
grammar O
does O
not O
describe O
all O
syntactic O
relations O
in O
terms O
of O
dependencies O
, O
but O
rather O
reserves O
a O
primitive O
relation O
for O
connecting O
coordinated O
items O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
hudson O
( O
1984 O
) O
further O
extends O
this O
idea O
by O
introducing O
explicit O
markings O
of O
coordination O
boundaries O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
in O
this O
paper O
, O
we O
revisit O
bubble O
trees O
, O
a O
representational O
device O
along O
the O
same O
vein O
introduced O
by O
kahane O
( O
1997 O
) O
for O
syntactic O
representation O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
( O
kahane O
credits O
gladkij O
( O
1968 O
) O
with O
a O
formal O
study O
. O
) O

section 4
id pdf2json/2021.acl-long.557.pdf.json
bubbles O
are O
used O
to O
denote O
coordinated O
phrases O
; O
otherwise O
, O
asymmetric O
dependency O
relations O
are O
retained O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
conjuncts O
immediately O
within O
the O
bubble O
may O
co-head O
the O
bubble O
, O
and O
the O
bubble O
itself O
may O
establish O
dependencies O
with O
its O
governor O
and O
modifiers O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
figure O
1 O
depicts O
an O
example O
bubble O
tree O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
we O
now O
formally O
define O
bubble O
trees O
and O
their O
projective O
subset O
, O
which O
will O
become O
the O
focus O
of O
our O
transition-based O
parser O
in O
§3 O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
the O
following O
formal O
descriptions O
are O
adapted O
from O
kahane O
( O
1997 O
) O
, O
tailored O
to O
the O
presentation O
of O
our O
parser O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
formal O
definition O
given O
a O
dependency-relation O
label O
set O
l O
, O
we O
define O
a O
bubble O
tree O
for O
a O
lengthn O
sentence O
w O
= O
w1 O
, O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
, O
wn O
to O
be O
a O
quadruple O
( O
v O
, O
b O
, O
φ O
, O
a O
) O
, O
where O
v O
= O
{ O
rt O
, O
w1 O
, O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
, O
wn O
} O
is O
the O
ground O
set O
of O
nodes O
( O
rt O
is O
the O
dummy O
root O
) O
, O
b O
is O
a O
set O
of O
bubbles O
, O
the O
function O
φ O
: O
b O
7→ O
( O
2v O
\ O
{ O
∅ O
} O
) O
gives O
the O
content O
of O
each O
bubble O
as O
a O
non-empty3 O
subset O
of O
v O
, O
and O
a O
⊂ O
b O
× O
l×b O
defines O
a O
labeled O
directed O
tree O
over O
b O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
given O
labeled O
directed O
tree O
a O
, O
we O
say O
α1 O
→ O
α2 O
if O
and O
only O
if O
( O
α1 O
, O
l O
, O
α2 O
) O
∈ O
a O
for O
some O
l. O
we O
denote O
the O
reflexive O
transitive O
closure O
of O
relation→ O
by O
∗→ O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
bubble O
tree O
( O
v O
, O
b O
, O
φ O
, O
a O
) O
is O
well-formed O
if O
and O
only O
if O
it O
satisfies O
the O
following O
conditions:4 O
• O
no O
partial O
overlap O
: O
∀α1 O
, O
α2 O
∈ O
b O
, O
either O
φ O
( O
α1 O
) O
∩ O
φ O
( O
α2 O
) O
= O
∅ O
or O
φ O
( O
α1 O
) O
⊆ O
φ O
( O
α2 O
) O
or O
φ O
( O
α2 O
) O
⊆ O
φ O
( O
α1 O
) O
; O
• O
non-duplication O
: O
there O
exists O
no O
non-identical O
α1 O
, O
α2 O
∈ O
b O
such O
that O
φ O
( O
α1 O
) O
= O
φ O
( O
α2 O
) O
; O
• O
lexical O
coverage O
: O
for O
any O
singleton O
( O
i.e. O
, O
oneelement O
) O
set O
s O
in O
2v O
, O
∃α O
∈ O
b O
such O
that O
φ O
( O
α O
) O
= O
s O
; O
• O
roothood O
: O
the O
root O
rt O
appears O
in O
exactly O
one O
bubble O
, O
a O
singleton O
that O
is O
the O
root O
of O
the O
tree O
defined O
by O
a O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
• O
containment O
: O
if O
∃α1 O
, O
α2 O
∈ O
b O
such O
that O
φ O
( O
α2 O
) O
⊂ O
φ O
( O
α1 O
) O
, O
then O
α1 O
∗→ O
α2 O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
projectivity O
our O
parser O
focuses O
on O
the O
subclass O
of O
projective O
well-formed O
bubble O
trees O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
visually O
, O
a O
projective O
bubble O
tree O
only O
contains O
bubbles O
covering O
a O
consecutive O
sequence O
of O
words O
( O
such O
that O
we O
can O
draw O
boxes O
around O
the O
span O
of O
words O
to O
represent O
them O
) O
and O
can O
be O
drawn O
with O
all O
arcs O
arranged O
spatially O
above O
the O
sentence O
where O
no O
two O
arcs O
or O
bubble O
boundaries O
cross O
each O
other O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
the O
bubble O
tree O
in O
figure O
1 O
is O
projective O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
formally O
, O
we O
define O
the O
projection O
ψ O
( O
α O
) O
∈ O
2v O
of O
a O
bubble O
α O
∈ O
b O
to O
be O
all O
nodes O
the O
bubble O
and O
its O
subtree O
cover O
, O
that O
is O
, O
v O
∈ O
ψ O
( O
α O
) O
if O
and O
only O
if O
α O
∗→ O
α′ O
and O
v O
∈ O
φ O
( O
α′ O
) O
for O
some O
α′ O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
then O
, O
we O
can O
define O
a O
well-formed O
bubble O
tree O
to O
be O
projective O
if O
and O
only O
if O
it O
additionally O
satisfies O
the O
following O
: O
• O
continuous O
coverage O
: O
for O
any O
bubble O
α O
∈ O
b O
, O
if O
wi O
, O
wj O
∈ O
φ O
( O
α O
) O
and O
i O
< O
k O
< O
j O
, O
then O
wk O
∈ O
φ O
( O
α O
) O
; O
3our O
definition O
does O
not O
allow O
empty O
nodes O
; O
we O
leave O
it O
to O
future O
work O
to O
support O
them O
for O
gapping O
constructions O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
4we O
do O
not O
use O
β O
for O
bubbles O
because O
we O
reserve O
the O
β O
symbol O
for O
our O
parser O
’ O
s O
buffer O
. O

section 4
id pdf2json/2021.acl-long.557.pdf.json
• O
continuous O
projections O
: O
for O
any O
bubble O
α O
∈ O
b O
, O
if O
wi O
, O
wj O
∈ O
ψ O
( O
α O
) O
and O
i O
< O
k O
< O
j O
, O
then O
wk O
∈ O
ψ O
( O
α O
) O
; O
• O
contained O
projections O
: O
for O
α1 O
, O
α2 O
∈ O
b O
, O
if O
α1 O
∗→ O
α2 O
, O
then O
either O
ψ O
( O
α2 O
) O
⊂ O
φ O
( O
α1 O
) O
or O
ψ O
( O
α2 O
) O
∩ O
φ O
( O
α1 O
) O
= O
∅ O
. O

section 5
id pdf2json/2021.acl-long.557.pdf.json
although O
, O
as O
we O
have O
seen O
, O
bubble O
trees O
have O
theoretical O
benefits O
in O
representing O
coordination O
structures O
that O
interface O
with O
an O
overall O
dependencybased O
analysis O
, O
there O
has O
been O
a O
lack O
of O
parser O
implementations O
capable O
of O
handling O
such O
representations O
. O

section 5
id pdf2json/2021.acl-long.557.pdf.json
in O
this O
section O
, O
we O
fill O
this O
gap O
by O
introducing O
a O
transition O
system O
that O
can O
incrementally O
build O
projective O
bubble O
trees O
. O

section 5
id pdf2json/2021.acl-long.557.pdf.json
transition-based O
approaches O
are O
popular O
in O
dependency O
parsing O
( O
nivre O
, O
2008 O
; O
kübler O
et O
al. O
, O
2009 O
) O
. O

section 5
id pdf2json/2021.acl-long.557.pdf.json
we O
propose O
to O
extend O
the O
arc-hybrid O
transition O
system O
( O
kuhlmann O
et O
al. O
, O
2011 O
) O
with O
transitions O
specific O
to O
bubble O
structures.5 O

section 6
id pdf2json/2021.acl-long.557.pdf.json
a O
transition O
system O
consists O
of O
a O
data O
structure O
describing O
the O
intermediate O
parser O
states O
, O
called O
configurations O
; O
specifications O
of O
the O
initial O
and O
terminal O
configurations O
; O
and O
an O
inventory O
of O
transitions O
that O
advance O
the O
parser O
in O
configuration O
space O
towards O
reaching O
a O
terminal O
configuration O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
our O
transition O
system O
uses O
a O
similar O
configuration O
data O
structure O
to O
that O
of O
arc-hybrid O
, O
which O
consists O
of O
a O
stack O
, O
a O
buffer O
, O
and O
the O
partiallycommitted O
syntactic O
analysis O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
initially O
, O
the O
stack O
only O
contains O
a O
singleton O
bubble O
corresponding O
to O
{ O
rt O
} O
, O
and O
the O
buffer O
contains O
singleton O
bubbles O
, O
each O
representing O
a O
token O
in O
the O
sentence O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
then O
, O
through O
taking O
transitions O
one O
at O
a O
time O
, O
the O
parser O
can O
incrementally O
move O
items O
from O
the O
buffer O
to O
the O
stack O
, O
or O
reduce O
items O
by O
attaching O
them O
to O
other O
bubbles O
or O
merging O
them O
into O
larger O
bubbles O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
eventually O
, O
the O
parser O
should O
arrive O
at O
a O
terminal O
configuration O
where O
the O
stack O
contains O
the O
singleton O
bubble O
of O
{ O
rt O
} O
again O
, O
but O
the O
buffer O
is O
empty O
as O
all O
the O
tokens O
are O
now O
attached O
to O
or O
contained O
in O
other O
bubbles O
that O
are O
now O
descendants O
of O
the O
5our O
strategy O
can O
be O
adapted O
to O
other O
transition O
systems O
as O
well O
; O
we O
focus O
on O
arc-hybrid O
here O
because O
of O
its O
comparatively O
small O
inventory O
of O
transitions O
, O
absence O
of O
spurious O
ambiguities O
( O
there O
is O
a O
one-to-one O
mapping O
between O
a O
gold O
tree O
and O
a O
valid O
transition O
sequence O
) O
, O
and O
abundance O
of O
existing O
implementations O
( O
e.g. O
, O
kiperwasser O
and O
goldberg O
, O
2016 O
) O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
stack O
buffer O
( O
initial O
) O
rt O
i O
prefer O
hot O
coffee O
or O
tea O
and O
a O
bun O
shift O
===⇒ O
rt O
i O
prefer O
hot O
coffee O
or O
tea O
and O
a O
bun O
leftarcnsubj O
=======⇒ O
rt O
prefer O
i O
hot O
coffee O
or O
tea O
and O
a O
bun O
nsubj O
shift O
===⇒ O
rt O
prefer O
hot O
coffee O
or O
tea O
and O
a O
bun O
shift O
===⇒ O
rt O
prefer O
hot O
coffee O
or O
tea O
and O
a O
bun O
shift O
===⇒ O
rt O
prefer O
hot O
coffee O
or O
tea O
and O
a O
bun O
shift O
===⇒ O
rt O
prefer O
hot O
coffee O
or O
tea O
and O
a O
bun O
bubbleopencc========⇒ O
rt O
prefer O
hot O
coffee O
or O
conj O
cc O
tea O
and O
a O
bun O
shift O
===⇒ O
rt O
prefer O
hot O
coffee O
or O
tea O
conj O
cc O
and O
a O
bun O
bubbleattachconj O
==========⇒ O
rt O
prefer O
hot O
coffee O
or O
tea O
conj O
cc O
conj O
and O
a O
bun O
bubbleclose O
========⇒ O
rt O
prefer O
hot O
and O
a O
bun O
leftarcamod=======⇒ O
rt O
prefer O
hot O
and O
a O
bun O
amod O
shift O
===⇒ O
rt O
prefer O
and O
a O
bun O
shift O
===⇒ O
rt O
prefer O
and O
a O
bun O
bubbleopencc========⇒ O
rt O
prefer O
and O
conj O
cc O
a O
bun O
shift O
===⇒ O
rt O
prefer O
and O
a O
conj O
cc O
bun O
leftarcdet======⇒ O
rt O
prefer O
and O
conj O
cc O
bun O
a O
det O
shift O
===⇒ O
rt O
prefer O
and O
bun O
conj O
cc O
∅ O
bubbleattachconj O
==========⇒ O
rt O
prefer O
and O
bun O
conj O
cc O
conj O
∅ O
bubbleclose O
========⇒ O
rt O
prefer O
shift O
===⇒ O
rt O
prefer O
∅ O
rightarcobj O
=======⇒ O
rt O
prefer O
dobj O
∅ O
rightarcroot=======⇒ O
rt O
prefer O
root O
∅ O
( O
terminal O
) O
figure O
2 O
: O
step-by-step O
visualization O
of O
the O
stack O
and O
buffer O
during O
parsing O
of O
the O
example O
sentence O
in O
figure O
1 O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
for O
steps O
following O
an O
attachment O
or O
bubbleclose O
transition O
, O
the O
detailed O
subtree O
or O
internal O
bubble O
structure O
is O
omitted O
for O
visual O
clarity O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
for O
the O
same O
reason O
, O
we O
omit O
drawing O
the O
boundaries O
around O
singleton O
bubbles O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
{ O
rt O
} O
singleton O
, O
and O
we O
can O
retrieve O
a O
completed O
bubble-tree O
parse O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
table O
1 O
lists O
the O
available O
transitions O
in O
our O
bubble-hybrid O
system O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
the O
shift O
, O
leftarc O
, O
and O
rightarc O
transitions O
are O
as O
in O
the O
arc-hybrid O
system O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
we O
introduce O
three O
new O
transitions O
to O
handle O
coordination-related O
bubbles O
: O
bubbleopen O
puts O
the O
first O
two O
items O
on O
the O
stack O
into O
an O
open O
bubble O
, O
with O
the O
first O
item O
in O
the O
bubble O
, O
i.e. O
, O
previously O
the O
second O
topmost O
item O
on O
the O
stack O
, O
labeled O
as O
the O
first O
conjunct O
of O
the O
resulting O
bubble O
; O
bubbleattach O
absorbs O
the O
topmost O
item O
on O
the O
stack O
into O
the O
open O
bubble O
that O
is O
at O
the O
second O
topmost O
position O
; O
and O
finally O
, O
bubbleclose O
closes O
the O
open O
bubble O
at O
the O
top O
of O
the O
stack O
and O
moves O
it O
to O
the O
buffer O
, O
which O
then O
allows O
it O
to O
take O
modifiers O
from O
its O
left O
through O
leftarc O
transitions O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
figure O
2 O
visualizes O
the O
stack O
and O
buffer O
throughout O
the O
process O
of O
parsing O
the O
example O
sentence O
in O
figure O
1 O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
in O
particular O
, O
the O
last O
two O
steps O
in O
the O
left O
column O
of O
figure O
2 O
show O
the O
bubble O
corresponding O
to O
the O
phrase O
“ O
coffee O
or O
tea O
” O
receiving O
its O
left O
modifier O
“ O
hot O
” O
through O
a O
leftarc O
transition O
after O
it O
is O
put O
back O
on O
the O
buffer O
by O
a O
bubbleclose O
transition O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
formal O
definition O
our O
transition O
system O
is O
a O
quadruple O
( O
c O
, O
t O
, O
ci O
, O
cτ O
) O
, O
where O
c O
is O
the O
set O
of O
configurations O
to O
be O
defined O
shortly O
, O
t O
is O
the O
set O
of O
transitions O
with O
each O
element O
being O
a O
partial O
function O
t O
∈ O
t O
: O
c O
7⇀ O
c O
, O
ci O
maps O
a O
sentence O
to O
its O
intial O
configuration O
, O
and O
cτ O
⊂ O
c O
is O
a O
set O
of O
terminal O
configurations O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
each O
configuration O
c O
∈ O
c O
is O
a O
septuple O
( O
σ O
, O
β O
, O
v O
, O
b O
, O
φ O
, O
a O
, O
o O
) O
, O
where O
v O
, O
b O
, O
φ O
, O
and O
a O
define O
a O
partially-recognized O
bubble O
tree O
, O
σ O
and O
β O
are O
each O
an O
( O
ordered O
) O
list O
of O
items O
in O
b O
, O
and O
o O
⊂ O
b O
is O
a O
set O
of O
open O
bubbles O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
for O
a O
sentence O
w O
= O
w1 O
, O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
, O
wn O
, O
we O
let O
ci O
( O
w O
) O
= O
( O
σ0 O
, O
β0 O
, O
v O
, O
b0 O
, O
φ0 O
, O
{ O
} O
, O
{ O
} O
) O
, O
where O
v O
= O
{ O
rt O
, O
w1 O
, O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
, O
wn O
} O
, O
b0 O
contains O
n O
+ O
1 O
items O
, O
φ0 O
( O
b00 O
) O
= O
{ O
rt O
} O
, O
φ0 O
( O
b0i O
) O
= O
{ O
wi O
} O
for O
i O
from O
1 O
to O
n O
, O
σ0 O
= O
[ O
b00 O
] O
, O
and O
β0 O
= O
[ O
b01 O
, O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
, O
b0n O
] O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
we O
write O
σ|s1 O
and O
b1|β O
to O
denote O
a O
stack O
and O
a O
buffer O
with O
their O
topmost O
items O
being O
s1 O
and O
b1 O
and O
the O
remainders O
being O
σ O
and O
β O
respectively O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
we O
also O
omit O
the O
constant O
v O
in O
describing O
c O
when O
the O
context O
is O
clear O
. O

section 6
id pdf2json/2021.acl-long.557.pdf.json
for O
the O
transitions O
t O
, O
we O
have O
: O
• O
shift O
[ O
( O
σ O
, O
b1|β O
, O
b O
, O
φ O
, O
a O
, O
o O
) O
] O
= O
( O
σ|b1 O
, O
β O
, O
b O
, O
φ O
, O
a O
, O
o O
) O
; O
• O
leftarclbl O
[ O
( O
σ|s1 O
, O
b1|β O
, O
b O
, O
φ O
, O
a O
, O
o O
) O
] O
= O
( O
σ O
, O
b1|β O
, O
b O
, O
φ O
, O
a O
∪ O
{ O
( O
b1 O
, O
lbl O
, O
s1 O
) O
} O
, O
o O
) O
; O
• O
rightarclbl O
[ O
( O
σ|s2|s1 O
, O
β O
, O
b O
, O
φ O
, O
a O
, O
o O
) O
] O
= O
( O
σ|s2 O
, O
β O
, O
b O
, O
φ O
, O
a O
∪ O
{ O
( O
s2 O
, O
lbl O
, O
s1 O
) O
} O
, O
o O
) O
; O
• O
bubbleopenlbl O
[ O
( O
σ|s2|s1 O
, O
β O
, O
b O
, O
φ O
, O
a O
, O
o O
) O
] O
= O
( O
σ|α O
, O
β O
, O
b O
∪ O
{ O
α O
} O
, O
φ′ O
, O
a∪ O
{ O
( O
α O
, O
conj O
, O
s2 O
) O
, O
( O
α O
, O
lbl O
, O
s1 O
) O
} O
, O
o O
∪ O
{ O
α O
} O
) O
, O
where O
α O
is O
a O
new O
bubble O
, O
and O
φ′ O
= O
φ O
d O
{ O
α O
7→ O
ψ O
( O
s2 O
) O
∪ O
ψ O
( O
s1 O
) O
} O
( O
i.e. O
, O
φ′ O
is O
almost O
the O
same O
as O
φ O
, O
but O
with O
α O
added O
to O
the O
function O
’ O
s O
domain O
, O
mapped O
by O
the O
new O
function O
to O
cover O
the O
projections O
of O
both O
s2 O
and O
s1 O
) O
; O
• O
bubbleattachlbl O
[ O
( O
σ|s2|s1 O
, O
β O
, O
b O
, O
φ O
, O
a O
, O
o O
) O
] O
= O
( O
σ|s2 O
, O
β O
, O
b O
, O
φ′ O
, O
a∪ O
{ O
s2 O
, O
lbl O
, O
s1 O
} O
, O
o O
) O
, O
where O
φ′ O
= O
φ O
d O
{ O
s2 O
7→ O
φ O
( O
s2 O
) O
∪ O
ψ O
( O
s1 O
) O
} O
; O
• O
bubbleclose O
[ O
( O
σ|s1 O
, O
β O
, O
b O
, O
φ O
, O
a O
, O
o O
) O
] O
= O
( O
σ O
, O
s1|β O
, O
b O
, O
φ O
, O
a O
, O
o\ O
{ O
s1 O
} O
) O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
in O
this O
section O
, O
we O
show O
that O
our O
bubble-hybrid O
transition O
system O
is O
both O
sound O
and O
complete O
( O
defined O
below O
) O
with O
respect O
to O
the O
subclass O
of O
projective O
bubble O
trees.6 O
define O
a O
valid O
transition O
sequence O
π O
= O
t1 O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
, O
tm O
for O
a O
given O
sentencew O
to O
be O
a O
sequence O
such O
that O
for O
the O
corresponding O
sequence O
of O
configurations O
c0 O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
, O
cm O
, O
we O
have O
c0 O
= O
ci O
( O
w O
) O
, O
ci O
= O
ti O
( O
ci−1 O
) O
, O
and O
cm O
∈ O
cτ O
, O
we O
can O
then O
state O
soundness O
and O
completeness O
properties O
, O
and O
present O
highlevel O
proof O
sketches O
below O
, O
adapted O
from O
nivre O
’ O
s O
( O
2008 O
) O
proof O
frameworks O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
lemma O
1 O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
( O
soundness O
) O
every O
valid O
transition O
sequence O
π O
produces O
a O
projective O
bubble O
tree O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
proof O
sketch O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
we O
examine O
the O
requirements O
for O
a O
projective O
bubble O
tree O
one O
by O
one O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
the O
set O
of O
edges O
satisfies O
the O
tree O
constraints O
since O
every O
bubble O
except O
for O
the O
singleton O
bubble O
of O
rt O
must O
have O
an O
in-degree O
of O
one O
to O
have O
been O
reduced O
from O
the O
stack O
, O
and O
the O
topological O
order O
of O
reductions O
implies O
acyclicness O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
lexical O
coverage O
is O
guaranteed O
by O
ci O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
roothood O
is O
safeguarded O
by O
the O
transition O
pre-conditions O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
non-duplication O
is O
ensured O
because O
newly-created O
bubbles O
are O
strictly O
larger O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
all O
the O
other O
properties O
can O
be O
proved O
by O
induction O
over O
the O
lengths O
of O
transition O
sequence O
prefixes O
since O
each O
of O
our O
transitions O
preserves O
zero O
partial O
overlap O
, O
containment O
, O
and O
projectivity O
constraints O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
lemma O
2 O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
( O
completeness O
) O
for O
every O
projective O
bubble O
tree O
over O
any O
given O
sentencew O
, O
there O
exists O
a O
corresponding O
valid O
transition O
sequence O
π O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
proof O
sketch O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
the O
proof O
proceeds O
by O
strong O
induction O
on O
sentence O
length O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
we O
omit O
relation O
labels O
without O
loss O
of O
generality O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
the O
base O
case O
of O
|w O
| O
= O
1 O
is O
trivial O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
for O
the O
inductive O
step O
, O
we O
enumerate O
how O
to O
decompose O
the O
tree O
’ O
s O
top-level O
6more O
precisely O
, O
our O
transition O
system O
handles O
the O
subset O
where O
each O
non-singleton O
bubble O
has O
≥ O
2 O
internal O
children O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
structure O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
( O
1 O
) O
when O
the O
root O
has O
multiple O
children O
: O
due O
to O
projectivity O
, O
each O
child O
bubble O
tree O
τi O
covers O
a O
consecutive O
span O
of O
words O
wxi O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
, O
wyi O
that O
are O
shorter O
than O
|w O
| O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
based O
on O
the O
induction O
hypothesis O
, O
there O
exisits O
a O
valid O
transition O
sequence O
πi O
to O
construct O
the O
child O
tree O
over O
rt O
, O
wxi O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
, O
wyi O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
here O
we O
let O
πi O
to O
denote O
the O
transition O
sequence O
excluding O
the O
always-present O
final O
rightarc O
transition O
that O
attaches O
the O
subtree O
to O
rt O
; O
this O
is O
for O
explicit O
illustration O
of O
what O
transitions O
to O
take O
once O
the O
subtrees O
are O
constructed O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
the O
full O
tree O
can O
be O
constructed O
by O
π O
= O
π1 O
, O
rightarc O
, O
π2 O
, O
rightarc O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
( O
expanding O
each O
πi O
sequence O
into O
its O
component O
transitions O
) O
, O
where O
we O
simply O
attach O
each O
subtree O
to O
rt O
immediately O
after O
it O
is O
constructed O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
( O
2 O
) O
when O
the O
root O
has O
a O
single O
child O
bubble O
α O
, O
we O
can O
not O
directly O
use O
the O
induction O
hypothesis O
since O
α O
covers O
the O
same O
number O
of O
words O
as O
w O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
thus O
we O
need O
to O
further O
enumerate O
the O
top-level O
structure O
of O
α O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
( O
2a O
) O
if O
α O
has O
children O
with O
their O
projections O
outside O
of O
φ O
( O
α O
) O
, O
then O
we O
can O
find O
a O
sequence O
π0 O
for O
constructing O
the O
shorter-length O
bubble O
α O
and O
placing O
it O
on O
the O
buffer O
( O
this O
corresponds O
to O
an O
empty O
transition O
sequence O
if O
α O
is O
a O
singleton O
; O
otherwise O
, O
π0 O
ends O
with O
a O
bubbleclose O
transition O
) O
and O
πis O
for O
α O
’ O
s O
outside O
children O
; O
say O
it O
has O
l O
children O
left O
of O
its O
contents O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
we O
construct O
the O
entire O
tree O
via O
π O
= O
π1 O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
, O
πl O
, O
π0 O
, O
leftarc O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
, O
leftarc O
, O
shift O
, O
πl+1 O
, O
rightarc O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
, O
rightarc O
, O
where O
we O
first O
construct O
all O
the O
left O
outside O
children O
and O
leave O
them O
on O
the O
stack O
, O
next O
build O
the O
bubble O
α O
and O
use O
leftarc O
transitions O
to O
attach O
its O
left O
children O
while O
it O
is O
on O
the O
buffer O
, O
then O
shift O
α O
to O
the O
stack O
before O
finally O
continuing O
on O
building O
its O
right O
children O
subtrees O
, O
each O
immediately O
followed O
by O
a O
rightarc O
transition O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
( O
2b O
) O
if O
α O
is O
a O
non-singleton O
bubble O
without O
any O
outside O
children O
, O
but O
each O
of O
its O
inside O
children O
can O
be O
parsed O
through O
πi O
based O
on O
the O
inductive O
hypothesis O
, O
then O
we O
can O
define O
π O
= O
π1 O
, O
π2 O
, O
bubbleopen O
, O
π3 O
, O
bubbleattach O
, O
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
. O

section 7
id pdf2json/2021.acl-long.557.pdf.json
, O
bubbleclose O
, O
shift O
, O
rightarc O
, O
where O
we O
use O
a O
bubbleopen O
transition O
once O
the O
first O
two O
bubble-internal O
children O
are O
built O
, O
each O
subsequent O
child O
is O
attached O
via O
bubbleattach O
immediately O
after O
construction O
, O
and O
the O
final O
three O
transitions O
ensure O
proper O
closing O
of O
the O
bubble O
and O
its O
attachment O
to O
rt O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
our O
model O
architecture O
largely O
follows O
that O
of O
kiperwasser O
and O
goldberg O
’ O
s O
( O
2016 O
) O
neural O
arc- O
hybrid O
parser O
, O
but O
we O
additionally O
introduce O
feature O
composition O
for O
non-singleton O
bubbles O
, O
and O
a O
rescoring O
module O
to O
reduce O
frequent O
coordinationboundary O
prediction O
errors O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
our O
model O
has O
five O
components O
: O
feature O
extraction O
, O
bubble-feature O
composition O
, O
transition O
scoring O
, O
label O
scoring O
, O
and O
boundary O
subtree O
rescoring O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
feature O
extraction O
we O
first O
extract O
contextualized O
features O
for O
each O
token O
using O
a O
bidirectional O
lstm O
( O
graves O
and O
schmidhuber O
, O
2005 O
) O
: O
[ O
w0 O
, O
w1 O
, O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
, O
wn O
] O
= O
bi-lstm O
( O
[ O
rt O
, O
w1 O
, O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
, O
wn O
] O
) O
, O
where O
the O
inputs O
to O
the O
bi-lstm O
are O
concatenations O
of O
word O
embeddings O
, O
pos-tag O
embeddings O
, O
and O
character-level O
lstm O
embeddings O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
we O
also O
report O
experiments O
replacing O
the O
bi-lstm O
with O
pre-trained O
bert O
features O
( O
devlin O
et O
al. O
, O
2019 O
) O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
bubble-feature O
composition O
we O
initialize O
the O
features7 O
for O
each O
singleton O
bubble O
bi O
in O
the O
initial O
configuration O
to O
be O
vbi O
= O
wi O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
for O
a O
non-singleton O
bubble O
α O
, O
we O
use O
recursively O
composed O
features O
vα O
= O
g O
( O
{ O
vα′ O
| O
( O
α O
, O
conj O
, O
α′ O
) O
∈ O
a O
} O
) O
, O
where O
g O
is O
a O
composition O
function O
combining O
features O
from O
the O
co-heads O
( O
conjuncts O
) O
immediately O
inside O
the O
bubble.8 O
for O
our O
model O
, O
for O
any O
v O
′ O
= O
{ O
vi1 O
, O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
, O
vin O
} O
, O
we O
set O
g O
( O
v O
′ O
) O
= O
tanh O
( O
wg O
·mean O
( O
v O
′ O
) O
) O
, O
where O
mean O
( O
) O
computes O
element-wise O
averages O
and O
wg O
is O
a O
learnable O
square O
matrix O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
we O
also O
experiment O
with O
a O
parameter-free O
version O
: O
g O
= O
mean O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
neither O
of O
the O
feature O
functions O
distinguishes O
between O
open O
and O
closed O
bubbles O
, O
so O
we O
append O
to O
each O
v O
vector O
an O
indicator-feature O
embedding O
based O
on O
whether O
the O
bubble O
is O
open O
, O
closed O
, O
or O
singleton O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
transition O
scoring O
given O
the O
current O
parser O
configuration O
c O
, O
the O
model O
predicts O
the O
best O
unlabeled O
transition O
to O
take O
among O
all O
valid O
transitions O
valid O
( O
c O
) O
whose O
pre-conditions O
are O
satisfied O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
we O
7we O
adopt O
the O
convenient O
abuse O
of O
notation O
of O
allowing O
indexing O
by O
arbitrary O
objects O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
8comparing O
with O
the O
subtree-feature O
composition O
functions O
in O
dependency O
parsing O
that O
are O
motivated O
by O
asymmetric O
headed O
constructions O
( O
dyer O
et O
al. O
, O
2015 O
; O
de O
lhoneux O
et O
al. O
, O
2019 O
; O
basirat O
and O
nivre O
, O
2021 O
) O
, O
our O
definition O
focuses O
on O
composing O
features O
from O
an O
unordered O
set O
of O
vectors O
representing O
the O
conjuncts O
in O
a O
bubble O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
the O
composition O
function O
is O
recursively O
applied O
when O
there O
are O
nested O
bubbles O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
model O
the O
log-linear O
probability O
of O
taking O
an O
action O
with O
a O
multi-layer O
perceptron O
( O
mlp O
) O
: O
p O
( O
t|c O
) O
∝ O
exp O
( O
mlptranst O
( O
[ O
vs3 O
◦vs2 O
◦vs1 O
◦vb1 O
] O
) O
) O
, O
where O
◦ O
denotes O
vector O
concatenation O
, O
s1 O
through O
s3 O
are O
the O
first O
through O
third O
topmost O
items O
on O
the O
stack O
, O
and O
b1 O
is O
the O
immediately O
accessible O
buffer O
item O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
we O
experiment O
with O
varying O
the O
number O
of O
stack O
items O
to O
extract O
features O
from O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
label O
scoring O
we O
separate O
edge-label O
prediction O
from O
( O
unlabeled O
) O
transition O
prediction O
, O
but O
the O
scoring O
function O
takes O
a O
similar O
form O
: O
p O
( O
l|c O
, O
t O
) O
∝ O
exp O
( O
mlplbll O
( O
[ O
vh O
( O
c O
, O
t O
) O
◦ O
vd O
( O
c O
, O
t O
) O
] O
) O
) O
, O
where O
( O
h O
( O
c O
, O
t O
) O
, O
l O
, O
d O
( O
c O
, O
t O
) O
) O
is O
the O
edge O
to O
be O
added O
into O
the O
partial O
bubble O
tree O
in O
t O
( O
c O
) O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
boundary O
subtree O
rescoring O
in O
our O
preliminary O
error O
analysis O
, O
we O
find O
that O
our O
models O
tend O
to O
make O
more O
mistakes O
at O
the O
boundaries O
of O
full O
coordination O
phrases O
than O
at O
the O
internal O
conjunct O
boundaries O
, O
due O
to O
incorrect O
attachments O
of O
children O
choosing O
between O
the O
phrasal O
bubble O
and O
the O
first/last O
conjunct O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
for O
example O
, O
our O
initial O
model O
predicts O
“ O
if O
you O
owned O
it O
and O
liked O
it O
friday O
” O
instead O
of O
the O
annotated O
“ O
if O
you O
owned O
it O
and O
liked O
it O
friday O
” O
( O
the O
predicted O
and O
gold O
conjuncts O
are O
both O
italicized O
and O
underlined O
) O
, O
incorrectly O
attaching O
“ O
friday O
” O
to O
“ O
liked O
” O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
we O
attribute O
this O
problem O
to O
the O
greedy O
nature O
of O
our O
first O
formulation O
of O
the O
parser O
, O
and O
propose O
to O
mitigate O
the O
issue O
through O
rescoring O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
to O
rescore O
boundary O
attachments O
of O
a O
non-singleton O
bubble O
α O
, O
for O
each O
of O
the O
left O
dependents O
d O
of O
α O
and O
its O
first O
conjunct O
αf O
, O
we O
( O
re O
) O
-decide O
the O
attachment O
via O
p O
( O
α→ O
d|αf O
) O
= O
logistic O
( O
mlpre O
( O
[ O
vd◦vα◦vαf O
] O
) O
) O
, O
and O
similarly O
for O
the O
last O
conjunct O
αl O
and O
a O
potential O
right O
dependent O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
training O
and O
inference O
our O
parser O
is O
a O
locallytrained O
greedy O
parser O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
in O
training O
, O
we O
optimize O
the O
model O
parameters O
to O
maximize O
the O
log-likelihoods O
of O
predicting O
the O
target O
transitions O
and O
labels O
along O
the O
paths O
generating O
the O
gold O
bubble O
trees O
, O
and O
the O
log-likelihoods O
of O
the O
correct O
attachments O
in O
rescoring O
; O
9 O
during O
inference O
, O
the O
parser O
greedily O
commits O
to O
the O
highest-scoring O
transition O
and O
label O
for O
each O
of O
its O
current O
parser O
configurations O
, O
and O
after O
reaching O
a O
terminal O
configuration O
, O
it O
rescores O
and O
readjusts O
all O
boundary O
subtree O
attachments O
. O

section 8
id pdf2json/2021.acl-long.557.pdf.json
9we O
leave O
the O
definition O
of O
dynamic O
oracles O
( O
goldberg O
and O
nivre O
, O
2013 O
) O
for O
bubble O
tree O
parsing O
to O
future O
work O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
task O
and O
evaluation O
we O
validate O
the O
utility O
of O
our O
transition-based O
parser O
using O
the O
task O
of O
coordination O
structure O
prediction O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
given O
an O
input O
sentence O
, O
the O
task O
is O
to O
identify O
all O
coordination O
structures O
and O
the O
spans O
for O
all O
their O
conjuncts O
within O
that O
sentence O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
we O
mainly O
evaluate O
based O
on O
exact O
metrics O
which O
count O
a O
prediction O
of O
a O
coordination O
structure O
as O
correct O
if O
and O
only O
if O
all O
of O
its O
conjunct O
spans O
are O
correct O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
to O
facilitate O
comparison O
with O
pre-existing O
systems O
that O
do O
not O
attempt O
to O
identify O
all O
conjunct O
boundaries O
, O
following O
teranishi O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
( O
2017 O
, O
2019 O
) O
, O
we O
also O
consider O
inner O
( O
=only O
consider O
the O
correctness O
of O
the O
two O
conjuncts O
adjacent O
to O
the O
coordinator O
) O
and O
whole O
( O
=only O
consider O
the O
boundary O
of O
the O
whole O
coordinated O
phrase O
) O
metrics O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
data O
and O
experimental O
setup O
we O
experiment O
with O
two O
english O
datasets O
, O
the O
penn O
treebank O
( O
ptb O
; O
marcus O
et O
al. O
, O
1993 O
, O
newswire O
) O
with O
added O
coordination O
annotations O
( O
ficler O
and O
goldberg O
, O
2016a O
) O
and O
the O
genia O
treebank O
( O
kim O
et O
al. O
, O
2003 O
, O
research O
abstracts O
) O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
we O
use O
the O
conversion O
tool O
distributed O
with O
the O
stanford O
parser O
( O
schuster O
and O
manning O
, O
2016 O
) O
to O
extract O
ud O
trees O
from O
the O
ptbstyle O
phrase-structure O
annotations O
, O
which O
we O
then O
merge O
with O
coordination O
annotations O
to O
form O
bub- O
ble O
trees O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
we O
follow O
prior O
work O
in O
reporting O
ptb O
results O
on O
its O
standard O
splits O
and O
genia O
results O
using O
5-fold O
cross-validation.10 O
during O
training O
( O
but O
not O
test O
) O
, O
we O
discard O
all O
non-projective O
sentences O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
see O
appendix O
a O
for O
dataset O
pre-processing O
and O
statistics O
and O
appendix O
b O
for O
implementation O
details O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
baseline O
systems O
we O
compare O
our O
models O
with O
several O
baseline O
systems O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
hara O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
( O
2009 O
, O
hsom09 O
) O
use O
edit O
graphs O
to O
explicitly O
align O
coordinated O
conjuncts O
based O
on O
the O
idea O
that O
they O
are O
usually O
similar O
; O
ficler O
and O
goldberg O
( O
2016b O
, O
fg16 O
) O
score O
candidate O
coordinations O
extracted O
from O
a O
phrase-structure O
parser O
by O
modeling O
their O
symme- O
10we O
affirm O
that O
, O
as O
is O
best O
practice O
, O
only O
two O
testset/crossval-suite O
runs O
occurred O
( O
one O
with O
bert O
and O
one O
without O
) O
, O
happening O
after O
we O
fixed O
everything O
else O
; O
that O
is O
, O
no O
other O
models O
were O
tried O
after O
seeing O
the O
first O
test-set/cross-validation O
results O
with O
and O
without O
bert O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
try O
and O
replaceability O
properties O
; O
teranishi O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
( O
2017 O
, O
tsm17 O
) O
directly O
predict O
boundaries O
of O
coordinated O
phrases O
and O
then O
split O
them O
into O
conjuncts O
; O
11 O
teranishi O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
( O
2019 O
, O
tsm19 O
) O
use O
separate O
neural O
models O
to O
score O
the O
inner O
and O
outer O
boundaries O
of O
conjuncts O
relative O
to O
the O
coordinators O
, O
and O
then O
use O
a O
chart O
parser O
to O
find O
the O
globallyoptimal O
coordination O
structures O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
main O
results O
table O
2 O
and O
table O
3 O
show O
the O
main O
evaluation O
results O
on O
the O
ptb O
and O
genia O
datasets O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
our O
models O
surpass O
all O
prior O
results O
on O
both O
datasets O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
while O
the O
bert O
improvements O
may O
not O
seem O
surprising O
, O
we O
note O
that O
teranishi O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
( O
2019 O
) O
report O
that O
their O
pre-trained O
language O
models O
— O
specifically O
, O
static O
elmo O
embeddings O
— O
fail O
to O
improve O
their O
model O
performance O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
general O
parsing O
results O
we O
also O
evaluate O
our O
models O
on O
standard O
parsing O
metrics O
by O
converting O
the O
predicted O
bubble O
trees O
to O
ud-style O
dependency O
trees O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
on O
ptb O
, O
our O
parsers O
reach O
unlabeled O
and O
labeled O
attachment O
scores O
( O
uas/las O
) O
of O
95.81/94.46 O
with O
bert O
and O
94.49/92.88 O
with O
bilstm O
, O
which O
are O
similar O
to O
the O
scores O
of O
prior O
transition-based O
parsers O
equipped O
with O
similar O
feature O
extractors O
( O
kiperwasser O
and O
goldberg O
, O
2016 O
; O
mohammadshahi O
and O
henderson O
, O
2020 O
) O
.12 O
table O
4 O
compares O
the O
general O
parsing O
results O
of O
our O
bubble O
parser O
and O
an O
edge-factored O
graph-based O
dependency O
parser O
based O
on O
dozat O
and O
manning O
’ O
s O
( O
2017 O
) O
parser O
architecture O
and O
the O
same O
feature O
encoder O
as O
our O
parser O
and O
trained O
on O
the O
same O
data O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
our O
bubble O
parser O
shows O
a O
slight O
improvement O
on O
identifying O
the O
“ O
conj O
” O
relations O
, O
despite O
having O
a O
lower O
overall O
accuracy O
due O
to O
the O
greedy O
nature O
of O
our O
transition-based O
decoder O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
additionally O
, O
our O
11we O
report O
results O
for O
the O
extended O
model O
of O
tsm17 O
as O
described O
by O
teranishi O
et O
al O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
( O
2019 O
) O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
12results O
are O
not O
strictly O
comparable O
with O
previous O
ptb O
evaluations O
that O
mostly O
focus O
on O
non-ud O
dependency O
conversions O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
table O
4 O
makes O
a O
self-contained O
comparison O
using O
the O
same O
ud-based O
and O
coordination-merged O
data O
conversions O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
bubble O
parser O
simultaneously O
predicts O
the O
boundaries O
of O
each O
coordinated O
phrase O
and O
conjuct O
, O
while O
a O
typical O
dependency O
parser O
can O
not O
produce O
such O
structures O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
model O
analysis O
table O
5 O
shows O
results O
of O
our O
models O
with O
alternative O
bubble-feature O
composition O
functions O
and O
varying O
feature-set O
sizes O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
we O
find O
that O
the O
parameterized O
form O
of O
composition O
function O
g O
performs O
better O
, O
and O
the O
f1 O
scores O
mostly O
degrade O
as O
we O
use O
fewer O
features O
from O
the O
stack O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
interestingly O
, O
the O
importance O
of O
our O
rescoring O
module O
becomes O
more O
prominent O
when O
we O
use O
fewer O
features O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
our O
results O
resonate O
with O
shi O
et O
al. O
’ O
s O
( O
2017 O
) O
findings O
on O
arc-hybrid O
that O
we O
need O
at O
least O
one O
stack O
item O
but O
not O
necessarily O
two O
. O

section 9
id pdf2json/2021.acl-long.557.pdf.json
table O
6 O
shows O
that O
our O
model O
performs O
better O
than O
previous O
methods O
on O
complex O
sentences O
with O
multiple O
coordination O
structures O
and/or O
more O
than O
two O
conjuncts O
, O
especially O
when O
we O
use O
bert O
as O
feature O
extractor O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
coordination O
structure O
prediction O
very O
early O
work O
with O
heuristic O
, O
non-learning-based O
approaches O
( O
agarwal O
and O
boggess O
, O
1992 O
; O
kurohashi O
and O
nagao O
, O
1994 O
) O
typically O
report O
difficulties O
in O
distinguishing O
shared O
modifiers O
from O
private O
ones O
, O
although O
such O
heuristics O
have O
been O
recently O
incorporated O
in O
unsupervised O
work O
( O
sawada O
et O
al. O
, O
2020 O
) O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
generally O
, O
researchers O
have O
focused O
on O
symmetry O
principles O
, O
seeking O
to O
align O
conjuncts O
( O
kurohashi O
and O
nagao O
, O
1994 O
; O
shimbo O
and O
hara O
, O
2007 O
; O
hara O
et O
al. O
, O
2009 O
; O
hanamoto O
et O
al. O
, O
2012 O
) O
, O
since O
coordinated O
conjuncts O
tend O
to O
be O
semantically O
and O
syntactically O
similar O
( O
hogan O
, O
2007 O
) O
, O
as O
attested O
to O
by O
psycholinguistic O
evidence O
of O
structural O
parallelism O
( O
frazier O
et O
al. O
, O
1984 O
, O
2000 O
; O
dubey O
et O
al. O
, O
2005 O
) O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
ficler O
and O
goldberg O
( O
2016a O
) O
and O
teranishi O
et O
al O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
( O
2017 O
) O
additionally O
leverage O
the O
linguistic O
principle O
of O
replaceability O
— O
one O
can O
typically O
replace O
a O
coordinated O
phrase O
with O
one O
of O
its O
conjuncts O
without O
the O
sentence O
becoming O
incoherent O
; O
this O
idea O
has O
resulted O
in O
improved O
open O
information O
extraction O
( O
saha O
and O
mausam O
, O
2018 O
) O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
using O
these O
principles O
may O
further O
improve O
our O
parser O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
coordination O
in O
constituency O
grammar O
while O
our O
paper O
mainly O
focuses O
on O
enhancing O
dependency-based O
syntactic O
analysis O
with O
coordination O
structures O
, O
coordination O
is O
a O
well-studied O
topic O
in O
constituency-based O
syntax O
( O
zhang O
, O
2009 O
) O
, O
including O
proposals O
and O
treatments O
under O
lexical O
functional O
grammar O
( O
kaplan O
and O
maxwell O
iii O
, O
1988 O
) O
, O
tree-adjoining O
grammar O
( O
sarkar O
and O
joshi O
, O
1996 O
; O
han O
and O
sarkar O
, O
2017 O
) O
, O
and O
combinatory O
categorial O
grammar O
( O
steedman O
, O
1996 O
, O
2000 O
) O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
tesnière O
dependency O
structure O
sangati O
and O
mazza O
( O
2009 O
) O
propose O
a O
representation O
that O
is O
faithful O
to O
tesnière O
’ O
s O
( O
1959 O
) O
original O
framework O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
similar O
to O
bubble O
trees O
, O
their O
structures O
include O
special O
attention O
to O
coordination O
structures O
respecting O
conjunct O
symmetry O
, O
but O
they O
also O
include O
constructs O
to O
handle O
other O
syntactic O
notions O
currently O
beyond O
our O
parser O
’ O
s O
scope.13 O
such O
representations O
have O
been O
used O
for O
re-ranking O
( O
sangati O
, O
2010 O
) O
, O
but O
not O
for O
( O
direct O
) O
parsing O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
perhaps O
our O
work O
can O
inspire O
a O
future O
tesnière O
dependency O
structure O
parser O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
non-constituent O
coordination O
seemingly O
incomplete O
( O
non-constituent O
) O
conjuncts O
are O
particularly O
challenging O
( O
milward O
, O
1994 O
) O
, O
and O
our O
bubble O
parser O
currently O
has O
no O
special O
mechanism O
for O
them O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
dependency-based O
analyses O
have O
adapted O
by O
extending O
to O
a O
graph O
structure O
( O
gerdes O
and O
kahane O
, O
2015 O
) O
or O
explicitly O
representing O
elided O
elements O
( O
schuster O
et O
al. O
, O
2017 O
) O
. O

section 10
id pdf2json/2021.acl-long.557.pdf.json
it O
may O
be O
straightforward O
to O
integrate O
the O
latter O
into O
our O
parser O
, O
à O
la O
kahane O
’ O
s O
( O
1997 O
) O
proposal O
of O
phonologically-empty O
bubbles O
. O

section 11
id pdf2json/2021.acl-long.557.pdf.json
we O
revisit O
kahane O
’ O
s O
( O
1997 O
) O
bubble O
tree O
representations O
for O
explicitly O
encoding O
coordination O
boundaries O
as O
a O
viable O
alternative O
to O
existing O
mechanisms O
in O
dependency-based O
analysis O
of O
coordination O
structures O
. O

section 11
id pdf2json/2021.acl-long.557.pdf.json
we O
introduce O
a O
transition O
system O
that O
is O
both O
sound O
and O
complete O
with O
respect O
to O
the O
subclass O
of O
projective O
bubble O
trees O
. O

section 11
id pdf2json/2021.acl-long.557.pdf.json
empirically O
, O
our O
bubble O
parsers O
achieve O
state-of-the-art O
results O
on O
the O
task O
of O
coordination O
structure O
prediction O
on O
two O
english O
datasets O
. O

section 11
id pdf2json/2021.acl-long.557.pdf.json
future O
work O
may O
extend O
the O
research O
scope O
to O
other O
languages O
, O
graph-based O
, O
and O
non-projective O
parsing O
methods O
. O

section 11
id pdf2json/2021.acl-long.557.pdf.json
acknowledgements O
we O
thank O
the O
anonymous O
reviewers O
for O
their O
constructive O
comments O
, O
yue O
guo O
for O
discussion O
, O
and O
hiroki O
teranishi O
for O
help O
with O
experiment O
setup O
. O

section 11
id pdf2json/2021.acl-long.557.pdf.json
this O
work O
was O
supported O
in O
part O
by O
a O
bloomberg O
data O
science O
ph.d. O
fellowship O
to O
tianze O
shi O
and O
a O
gift O
from O
bloomberg O
to O
lillian O
lee O
. O

section 11
id pdf2json/2021.acl-long.557.pdf.json
13for O
example O
, O
differentiating O
content O
and O
function O
words O
which O
has O
recently O
been O
explored O
by O
basirat O
and O
nivre O
( O
2021 O
) O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
we O
follow O
teranishi O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
( O
2019 O
) O
and O
use O
the O
same O
dataset O
splits O
and O
pre-processing O
steps O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
for O
the O
penn O
treebank O
( O
ptb O
; O
marcus O
et O
al. O
, O
1993 O
) O
data O
with O
added O
coordination O
annotations O
( O
ficler O
and O
goldberg O
, O
2016a O
) O
, O
we O
use O
wsj O
sections O
02-21 O
for O
training O
, O
section O
22 O
for O
development O
, O
and O
section O
23 O
for O
test O
sets O
respectively O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
we O
also O
use O
teranishi O
et O
al. O
’ O
s O
( O
2019 O
) O
pre-processing O
steps O
in O
stripping O
quotation O
marks O
surrounding O
ptb O
coordinated O
phrases O
to O
normalize O
irregular O
coordinations O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
this O
results O
in O
39,832/1,700/2,416 O
sentences O
and O
19,890/848/1,099 O
coordination O
structures O
in O
train/dev/test O
splits O
respectively O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
for O
the O
genia O
treebank O
( O
kim O
et O
al. O
, O
2003 O
) O
, O
we O
use O
the O
beta O
version O
of O
the O
corpus O
and O
follow O
the O
same O
5-fold O
crossvalidation O
splits O
as O
teranishi O
et O
al O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
( O
2019 O
) O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
in O
total O
, O
genia O
contains O
2,508 O
sentences O
and O
3,598 O
coordination O
structures O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
to O
derive O
bubble O
tree O
representations O
, O
we O
first O
convert O
the O
ptb-style O
phrase-structure O
trees O
in O
both O
treebanks O
with O
the O
conversion O
tool O
( O
schuster O
and O
manning O
, O
2016 O
) O
provided O
by O
the O
stanford O
corenlp O
toolkit O
version O
4.2.0 O
into O
universal O
dependencies O
( O
ud O
; O
nivre O
et O
al. O
, O
2016 O
) O
style O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
we O
then O
merge O
the O
ud O
trees O
with O
the O
bubbles O
formed O
by O
the O
coordination O
boundaries O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
we O
define O
the O
boundaries O
to O
be O
from O
the O
beginning O
of O
the O
first O
conjunct O
to O
the O
end O
of O
the O
last O
conjunct O
for O
each O
coordinated O
phrase O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
we O
attach O
all O
conjuncts O
to O
their O
corresponding O
bubbles O
with O
a O
“ O
conj O
” O
label O
, O
and O
map O
any O
“ O
conj O
” O
-labeled O
dependencies O
outside O
an O
annotated O
coordination O
to O
“ O
dep O
” O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
we O
resolve O
modifier O
scope O
ambiguities O
according O
to O
conjunct O
annotations O
: O
if O
the O
modifier O
is O
within O
the O
span O
of O
a O
conjunct O
, O
then O
it O
is O
a O
private O
modifier O
; O
otherwise O
, O
it O
is O
a O
shared O
modifier O
to O
the O
entire O
coordinated O
phrase O
and O
we O
attach O
it O
to O
the O
phrasal O
bubble O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
since O
our O
transition O
system O
targets O
projective O
bubble O
trees O
, O
we O
filter O
out O
any O
non-projective O
trees O
during O
training O
( O
but O
still O
evaluate O
on O
them O
during O
testing O
) O
. O

section 12
id pdf2json/2021.acl-long.557.pdf.json
we O
retain O
39,678 O
sentences O
, O
or O
99.6 O
% O
of O
the O
ptb O
training O
set O
, O
and O
2,429 O
sentences O
, O
or O
96.9 O
% O
of O
the O
genia O
dataset O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
our O
implementation O
( O
https O
: O
//www.github.com/ O
tzshi/bubble-parser-acl21 O
) O
is O
based O
on O
pytorch O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
we O
train O
our O
models O
by O
using O
the O
adam O
optimizer O
( O
kingma O
and O
ba O
, O
2015 O
) O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
after O
a O
fixed O
number O
of O
optimization O
steps O
( O
3,200 O
steps O
for O
ptb O
and O
adam O
optimizer O
: O
initial O
learning O
rate O
for O
bi-lstm O
10−3 O
initial O
learning O
rate O
for O
bert O
10−5 O
β1 O
0.9 O
β2 O
0.999 O
10−8 O
minibatch O
size O
8 O
linear O
warmup O
steps O
800 O
gradient O
clipping O
l2 O
norm O
5.0 O
inputs O
to O
bi-lstm O
: O
word-embedding O
dimensionality O
100 O
pos O
tag-embedding O
dimensionality O
32 O
character O
bi-lstm O
layers O
1 O
character O
bi-lstm O
dimensionality O
128 O
bi-lstm O
: O
number O
of O
layers O
3 O
dimensionality O
800 O
dropout O
0.3 O
mlps O
( O
same O
for O
all O
mlps O
) O
: O
number O
of O
hidden O
layers O
1 O
hidden O
layer O
dimensionality O
400 O
activation O
function O
relu O
dropout O
0.3 O
table O
a1 O
: O
hyperparameters O
of O
our O
models O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
800 O
steps O
for O
genia O
, O
based O
on O
their O
training O
set O
sizes O
) O
, O
we O
perform O
an O
evaluation O
on O
the O
dev O
set O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
if O
the O
dev O
set O
performance O
fails O
to O
improve O
within O
5 O
consecutive O
evaluation O
rounds O
, O
we O
multiply O
the O
learning O
rate O
by O
0.1 O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
we O
terminate O
model O
training O
when O
the O
learning O
rate O
has O
dropped O
three O
times O
, O
and O
select O
the O
best O
model O
checkpoint O
based O
on O
dev O
set O
f1 O
scores O
according O
to O
the O
“ O
exact O
” O
metrics.14 O
for O
the O
bert O
feature O
extractor O
, O
we O
finetune O
the O
pretrained O
case-sensitive O
bertbase O
model O
through O
the O
transformers O
package.15 O
for O
the O
non-bert O
model O
, O
we O
use O
pre-trained O
glove O
embeddings O
( O
pennington O
et O
al. O
, O
2014 O
) O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
following O
prior O
practice O
, O
we O
embed O
gold O
pos O
tags O
as O
input O
features O
when O
using O
bi-lstm O
for O
the O
models O
trained O
on O
the O
genia O
dataset O
, O
but O
we O
omit O
the O
pos O
tag O
embeddings O
for O
the O
ptb O
dataset O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
the O
training O
process O
for O
each O
model O
takes O
roughly O
10 O
hours O
using O
an O
rtx O
2080 O
ti O
gpu O
; O
model O
inference O
speed O
is O
41.9 O
sentences O
per O
second.16 O
we O
select O
our O
hyperparameters O
by O
hand O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
due O
to O
computational O
constraints O
, O
our O
hand-tuning O
has O
been O
limited O
to O
setting O
the O
dropout O
rates O
, O
and O
from O
the O
candidates O
set O
of O
{ O
0.0 O
, O
0.1 O
, O
0.3 O
, O
0.5 O
} O
we O
chose O
14even O
though O
we O
report O
recall O
on O
genia O
, O
model O
selection O
is O
still O
performed O
using O
f1 O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
15github.com/huggingface/transformers O
16we O
have O
not O
yet O
done O
extensive O
optimization O
regarding O
gpu O
batching O
for O
greedy O
transition-based O
parsers O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
0.3 O
based O
on O
dev-set O
performance O
. O

section 13
id pdf2json/2021.acl-long.557.pdf.json
our O
hyperparameters O
are O
listed O
in O
table O
a1 O
. O

section 14
id pdf2json/2021.acl-long.557.pdf.json
table O
a2 O
and O
table O
a3 O
include O
detailed O
evaluation O
results O
on O
the O
ptb O
and O
genia O
datasets O
. O

